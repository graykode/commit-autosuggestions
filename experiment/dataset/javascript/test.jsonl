{"commit_tokens": ["Fixed", "bug", "where", "systems", "were", "required", "psykick", "instead", "of", "psykick2d"], "add_tokens": "psykickVersion = 'psykick2d' ;", "del_tokens": "psykickVersion = 'psykick' ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "tests", "to", "clone", "and", "allow", "to", "clone", "a", "null", "object"], "add_tokens": "if ( obj === undefined || typeof obj !== 'object' ) {", "del_tokens": "if ( ! obj || typeof obj !== 'object' ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "from", "double", "to", "single", "quote", "string", "."], "add_tokens": "return $ ( '.title a' ) . map ( function ( ) {", "del_tokens": "return $ ( \".title a\" ) . map ( function ( ) {", "commit_type": "change"}
{"commit_tokens": ["Changed", "look", "and", "feel", ".", "Added", "texture", ".", "Enhanced", "UI", "."], "add_tokens": "if ( ! $ ( this . el ) . hasClass ( 'selected' ) ) { $ ( this . el ) . fadeTo ( 100 , 1 ) ; } if ( ! $ ( this . el ) . hasClass ( 'selected' ) ) { $ ( this . el ) . fadeTo ( 100 , this . originalOpacity ) ; }", "del_tokens": "$ ( this . el ) . fadeTo ( 100 , 1 ) ; $ ( this . el ) . fadeTo ( 100 , this . originalOpacity ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "minimal", "example", "application", "."], "add_tokens": "template : '<div class=\"map\"></div>' , var $el = element [ 0 ] , if ( attrs . marker ) { ( function ( ) { }", "del_tokens": "template : '<div class=\"thumbnail\"><div class=\"map\"></div></div>' , var $el = element . find ( \".map\" ) [ 0 ] , if ( attrs . marker ) { ( function ( ) { }", "commit_type": "add"}
{"commit_tokens": ["Used", "path", "-", "to", "-", "url", "module"], "add_tokens": "var norma = require ( 'norma' ) ; var request = require ( 'request' ) ; var debug = require ( 'debug' ) ( 'waif:pipe' ) ; var Uri = require ( './state/uri' ) ; var pathToUrl = require ( 'path-to-url' ) ; var proxyUrl = pathToUrl ( args . url , req . params ) ;", "del_tokens": "var norma = require ( 'norma' ) ; var request = require ( 'request' ) ; var debug = require ( 'debug' ) ( 'waif:pipe' ) ; var Uri = require ( './state/uri' ) ; var proxyUrl = args . url ; Object . keys ( req . params ) . forEach ( function ( key ) { proxyUrl = proxyUrl . replace ( ':' + key , req . params [ key ] ) ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["Update", "up", "to", "changes", "in", "es5", "-", "ext"], "add_tokens": ", assign = require ( 'es5-ext/object/assign-multiple' ) mods = assign ( { d ( assign ( { } , scope . _cliColorData , mod ) ) ) ; proto = Object . create ( Function . prototype , assign ( map ( mods , function ( mod ) { d ( assign ( { } , this . _cliColorData , { d ( assign ( { } , this . _cliColorData , {", "del_tokens": ", extend = require ( 'es5-ext/object/extend' ) mods = extend ( { d ( extend ( { } , scope . _cliColorData , mod ) ) ) ; proto = Object . create ( Function . prototype , extend ( map ( mods , function ( mod ) { d ( extend ( { } , this . _cliColorData , { d ( extend ( { } , this . _cliColorData , {", "commit_type": "update"}
{"commit_tokens": ["added", "RFC", "4226", "sample", "tests"], "add_tokens": "import hotpDigest from './hotpDigest' ; const hmac = hotpDigest ( secret , counter , opt . encoding , opt . algorithm ) ;", "del_tokens": "import crypto from 'crypto' ; import intToHex from '../utils/intToHex' ; // Convert secret to encoding for hmacSecret const hmacSecret = new Buffer ( secret , opt . encoding ) ; // Ensure counter is a buffer or string (for HMAC creation) let hexCounter = intToHex ( counter ) ; hexCounter = leftPad ( hexCounter , 16 ) ; // HMAC creation const cryptoHmac = crypto . createHmac ( opt . algorithm , hmacSecret ) ; // Update HMAC with the counter const hmac = cryptoHmac . update ( new Buffer ( hexCounter , 'hex' ) ) . digest ( 'hex' ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "new", "sinon", "syntax"], "add_tokens": "var stub = sinon . stub ( ) . throws ( ) ; sinon . stub ( utils , 'readFileGlobs' ) . callsFake ( function ( ) {", "del_tokens": "sinon . stub ( utils , 'readFileGlobs' , function ( ) {", "commit_type": "update"}
{"commit_tokens": ["added", "logger", "for", "some", "info", "used", "browserify", "or", "budo", "args"], "add_tokens": "const args = process . argv const l = args . length let dest for ( let i = 0 ; i < l ; i ++ ) { let arg = args [ i ] if ( arg === '--css' ) { dest = args [ i + 1 ] break } else if ( arg === '-o' || arg === '--outfile' ) { dest = args [ i + 1 ] . split ( '.' ) dest [ dest . length - 1 ] = 'css' dest = dest . join ( '.' ) break } } exports . dest = dest", "del_tokens": "exports . dest = 'bundle.css'", "commit_type": "add"}
{"commit_tokens": ["use", "single", "global", "instance", "with", "multiple", "requires"], "add_tokens": "var immutable = global . __immutable_core__ = global . __immutable_core__ || {", "del_tokens": "var immutable = global . __immutable_core__ = {", "commit_type": "use"}
{"commit_tokens": ["Improve", "error", "output", "when", "run", "step", "fails", "during", "test", "run"], "add_tokens": "} , res => { acc . push ( { req , res } ) return res )", "del_tokens": ")", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "bug", "-", "need", "to", "delete", "added", "file", "property", "on", "required", "input", "check", ".", "Override", "method", "to", "post", "if", "files", "is", "specified", "in", "IODOpts", "."], "add_tokens": "var method = apiType === IOD . TYPES . JOB || ! _ . isEmpty ( IODOpts . files ) ?", "del_tokens": "var method = apiType === IOD . TYPES . JOB ?", "commit_type": "fix"}
{"commit_tokens": ["Add", "backgroundColor", "option", "to", "set", "color", "of", "the", "background", "on", "SignaturePad#clear", "."], "add_tokens": "this . penColor = opts . penColor || \"black\" ; this . backgroundColor = opts . backgroundColor || \"rgba(0,0,0,0)\" ; this . clear ( ) ; var ctx = this . _ctx , canvas = this . _canvas ; ctx . fillStyle = this . backgroundColor ; ctx . fillRect ( 0 , 0 , canvas . width , canvas . height ) ; this . _ctx . fillStyle = this . penColor ;", "del_tokens": "this . color = opts . color || \"black\" ; this . _reset ( ) ; this . _ctx . clearRect ( 0 , 0 , this . _canvas . width , this . _canvas . height ) ; this . _ctx . fillStyle = this . color ;", "commit_type": "add"}
{"commit_tokens": ["Add", "special", "treatment", "for", "bool", "attributes"], "add_tokens": "let validUnquotedRegex = / ^[^\\s>\"'<=`]*$ / , // Attributes that are boolean booleanRegex = / ^allowfullscreen|async|autofocus|autoplay|checked|compact|controls|declare|default|defaultchecked|defaultmuted|defaultselected|defer|disabled|enabled|formnovalidate|hidden|indeterminate|inert|ismap|itemscope|loop|multiple|muted|nohref|noresize|noshade|novalidate|nowrap|open|pauseonexit|readonly|required|reversed|scoped|seamless|selected|sortable|spellcheck|truespeed|typemustmatch|visible$ / i * @ param { boolean } [ options . boolAttribute = false ] } else if ( options . boolAttribute && value && booleanRegex . test ( attribute . name ) ) { // Boolean attributes don't need a value value = '' let firstPart = attribute . parts [ 0 ] if ( options . boolAttribute && booleanRegex . test ( attribute . name ) && attribute . parts . length === 1 && firstPart . type === 'ejs-escaped' ) { // Special case for <tag attr=\"<%=value%>\">, treat this as: // <tag<%if (value) {%> attr<%}%>> // Since attr is boolean, we don't want to output it // when `value` is falsy newTokens . push ( { type : 'ejs-eval' , start : firstPart . start , end : firstPart . end , content : ` ${ firstPart . content } ` } ) appendText ( ` ${ attribute . name } ` ) lastIsUnquoted = false newTokens . push ( { type : 'ejs-eval' , start : firstPart . start , end : firstPart . end , content : '}' } ) continue }", "del_tokens": "let validUnquotedRegex = / ^[^\\s>\"'<=`]*$ /", "commit_type": "add"}
{"commit_tokens": ["Adding", "sanity", "check", "to", "verify", "that", "a", "control", "frame", "is", "not", "fragmented", "."], "add_tokens": "if ( this . opcode >= 0x08 ) { if ( this . length > 125 ) { this . protocolError = true ; this . dropReason = \"Illegal control frame longer than 125 bytes.\" return true ; } if ( ! this . fin ) { this . protocolError = true ; this . dropReason = \"Control frames must not be fragmented.\" ; return true ; }", "del_tokens": "if ( this . opcode >= 0x08 && this . length > 125 ) { this . protocolError = true ; this . dropReason = \"Illegal control frame longer than 125 bytes.\" return true ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "webhooks", "registration"], "add_tokens": "var prefixLength = 0 ; if ( this . prefix ) { prefixLength = this . prefix . length ; // Check if prefix matches if ( this . prefix != text . substring ( 0 , prefixLength ) ) { debug ( \"text does not start with the command prefix: \" + this . prefix + \" => ignoring...\" ) ; return null ; } var splitted = text . substring ( prefixLength ) . split ( ' ' ) ;", "del_tokens": "if ( this . prefix && ( this . prefix != text . charAt ( 0 ) ) ) { debug ( \"text does not start with the command prefix: \" + this . prefix + \" => ignoring...\" ) ; return null ; var splitted = text . substring ( 1 ) . split ( ' ' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "zero", "number", "passed", "to", "trigger", "eventData"], "add_tokens": "var data = ( typeof eventData === 'undefined' || eventData === null ) ? { } : eventData ;", "del_tokens": "var data = eventData || { } ;", "commit_type": "fix"}
{"commit_tokens": ["add", "common", "computed", "properties", "to", "popup", "-", "menu"], "add_tokens": "import w from \"../computed/w\" ; willChange : w ( ) ,", "del_tokens": "var w = Ember . String . w ; willChange : function ( key , value ) { if ( value ) { var observers = value ; if ( typeof value === \"string\" ) { observers = w ( value ) ; } return observers ; } return [ ] ; } . property ( ) ,", "commit_type": "add"}
{"commit_tokens": ["added", "samsung", "flag", "import", "key", "mappings", "from", "sf", ".", "object"], "add_tokens": "var samsung = window . hasOwnProperty ( 'sf' ) if ( samsung ) { keyCodes = { } for ( var key in sf . key ) { var code = sf . key [ key ] key = key . charAt ( 0 ) . toUpperCase ( ) + key . slice ( 1 ) . toLowerCase ( ) if ( key == \"Enter\" ) key = \"Select\" keyCodes [ code ] = key } }", "del_tokens": "/* qml.core javascript code */", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "and", "make", "everything", "async"], "add_tokens": "setTimeout ( function ( ) { map . set ( 'mapbox-style' , glStyle ) ; setTimeout ( function ( ) { processStyle ( style , map ) ; } , 0 ) ;", "del_tokens": "window . setTimeout ( function ( ) { map . set ( 'mapbox-style' , glStyle ) ; processStyle ( style , map ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "error", "when", "padding", "is", "no", "supported"], "add_tokens": "// fail silently for now, log warning later on", "del_tokens": "throw new Error ( \"Your ffmpeg version \" + meta . ffmpegversion + \" does not support padding\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "pad", "emulators", "to", "return", "an", "event", "object", "with", "various", "info"], "add_tokens": "Input . setupKeyboardDPadKeys ( function ( e ) { player1 . handlePadMsg ( { pad : e . pad , dir : e . info . direction } ) ;", "del_tokens": "Input . setupKeyboardDPadKeys ( function ( padId , dir ) { player1 . handlePadMsg ( { pad : padId , dir : dir } ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "frames", "longer", "than", "65535", "bytes", "."], "add_tokens": "if ( this . length > 0xffff ) { } else if ( this . length > 125 ) { length = 126 ;", "del_tokens": "if ( this . length > 125 ) { length = 126 ; } else if ( this . length > 0xffff ) {", "commit_type": "fix"}
{"commit_tokens": ["Moved", "as", "()", "/", "_toNestedString", "()", "/", "_aliasToString", "()", "to", "Select"], "add_tokens": "// subquery aliasing Select . prototype . _toNestedString = function ( opts ) { return '(' + this . _toString ( opts ) + ')' + this . _aliasToString ( opts ) ; } ; Select . prototype . _aliasToString = function ( opts ) { if ( ! this . _alias ) return '' ; return ' ' + autoQuote ( this . _alias ) ; } ; Select . prototype . as = function ( alias ) { this . _alias = alias ; return this ; } ;", "del_tokens": "Statement . prototype . _toNestedString = function ( opts ) { return '(' + this . _toString ( opts ) + ')' + this . _aliasToString ( opts ) ; } ; Statement . prototype . _aliasToString = function ( opts ) { if ( ! this . _alias ) return '' ; return ' ' + autoQuote ( this . _alias ) ; } ; // subquery aliasing Statement . prototype . as = function ( alias ) { this . _alias = alias ; return this ; } ;", "commit_type": "move"}
{"commit_tokens": ["add", "removeTags", "removeDetails", "assign", "tests", "of", "Alert", "api"], "add_tokens": "removeTags : function ( data , config , cb ) { api . delete ( this . baseURL + 'tags' , data , config , cb ) ; } , removeDetails : function ( data , config , cb ) { api . delete ( this . baseURL + 'details' , data , config , cb ) ; } ,", "del_tokens": "/ *removeTags: function (data, config, cb) { api . delete ( this . baseURL , data , config , cb ) ; } , * / / *removeDetails: function (data, config, cb) { api . delete ( this . baseURL , data , config , cb ) ; } , * /", "commit_type": "add"}
{"commit_tokens": ["Fix", "query", "generation", "for", "array", "of", "subscriptions", "use", "-", "case"], "add_tokens": "const boolQuery = createBoolQuery ( operation , getQuery ( comp , queryList ) ) ;", "del_tokens": "const boolQuery = getQuery ( comp , queryList ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "only", ".", "Whoops", "."], "add_tokens": "test . serial ( '[Success] Check for sitemap.xml' , async t => { test . serial ( '[Success] Create a customer' , async t => { test . serial ( '[Fail] Try create a duplicate customer' , async t => {", "del_tokens": "test . serial . only ( '[Success] Check for sitemap.xml' , async t => { test . serial . only ( '[Success] Create a customer' , async t => { test . serial . only ( '[Fail] Try create a duplicate customer' , async t => {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "incorrect", "end", "tag", "in", "redirects"], "add_tokens": "'</body>\\n' + '</html>\\n'", "del_tokens": "'</body>\\n'", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "cleanup", "mechanism", "for", "generated", "widget", "areas", "."], "add_tokens": "] , function ( ng , $ , log , layoutModule , widgetLoader ) { link : function ( scope ) { ( area . hidden ? ' style=\"display: none;\"' : '' ) + ' data-added-by-page-directive></div>' ; pageElement ( ) . append ( $compile ( defaultAreaHtml ) ( scope ) ) ; pageElement ( ) . children ( '[data-added-by-page-directive]' ) . each ( function ( i , child ) { // prior to AngularJS 1.2.x element would reference the element where originally the // data-ax-page directive was set on. Possibly due to changes to ng-include in 1.2.x element // now only is the HTML comment marking the place where ng-include once was. We therefore // need to find the correct element again manually. function pageElement ( ) { return $ ( 'body' ) . find ( '[data-ax-page]:first,[ax-page]:first' ) . eq ( 0 ) ; }", "del_tokens": "'../../utilities/assert' , ] , function ( ng , $ , log , layoutModule , assert , widgetLoader ) { link : function ( scope , element ) { ( area . hidden ? ' style=\"display: none;\"' : '' ) + ' data-added-by-page-directive></div>' ; // prior to AngularJS 1.2.x element would reference the element where originally the // data-ax-page directive was set on. Possibly due to changes to ng-include in 1.2.x element // now only is the HTML comment marking the place where ng-include once was. We therefore // need to find the correct element again manually. $ ( 'body' ) . find ( '[data-ax-page]:first,[ax-page]:first' ) . eq ( 0 ) . append ( $compile ( defaultAreaHtml ) ( scope ) ) ; element . children ( '[data-added-by-page-directive]' ) . each ( function ( child ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "getColors", "predefined", "colors", "for", "sink", "displays"], "add_tokens": "const colors = [ 'steelblue' , 'orange' , '#00e600' , '#ff0000' , 'purple' , '#224153' ] ; export const getColors = function ( type , nbr ) { switch ( type ) { case 'signal' : return colors [ 0 ] ; // steelblue break ; case 'bpf' : if ( nbr <= colors . length ) { return colors . slice ( 0 , nbr ) ; } else { const _colors = colors . slice ( 0 ) ; while ( _colors . length < nbr ) _colors . push ( getRandomColor ( ) ) ; return _colors ; } break ; case 'waveform' : return [ colors [ 0 ] , colors [ 5 ] ] ; // steelblue / darkblue break ; case 'marker' : return colors [ 3 ] ; // red break ; case 'spectrum' : return colors [ 2 ] ; // green break ; } } ;", "del_tokens": "const colors = [ 'steelblue' , 'red' , 'orange' , 'green' , 'purple' ] ;", "commit_type": "add"}
{"commit_tokens": ["fix", "links", "with", "asset", "path"], "add_tokens": "href = { props . getPathPrefix ( link . href ) } key = { i } >", "del_tokens": "href = { link . href } key = { i } >", "commit_type": "fix"}
{"commit_tokens": ["move", "Query#stream", "()", "to", "RecordStream#stream", "()"], "add_tokens": "* Query ( extends RecordStream implements Receivable ) Query . super_ . apply ( this ) ; this . receivable = true ; * Auto start query when pipe ( ) is called . var dest = RecordStream . prototype . pipe . apply ( this , arguments ) ; return dest ;", "del_tokens": "* Query Query . super_ . apply ( this ) ; * Auto start query when pipe called . var dist = RecordStream . prototype . pipe . apply ( this , arguments ) ; return dist ; / ** * Create ReadableStream instance for serializing records * / Query . prototype . stream = function ( type ) { type = type || 'csv' ; var recStream ; if ( type === \"csv\" ) { recStream = new RecordStream . CSVStream ( ) ; } if ( ! recStream ) { throw new Error ( \"No stream type defined for '\" + type + \"'.\" ) ; } this . pipe ( recStream ) ; return recStream . stream ( ) ; // get readable stream instance } ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "prettier", "config", "to", "remove", "unecessary", "diff"], "add_tokens": "cwd : __dirname } } } ] extensions : [ '.re' , '.ml' , '.js' ] libraryTarget : 'commonjs2' }", "del_tokens": "cwd : __dirname , } , } , } , ] , extensions : [ '.re' , '.ml' , '.js' ] , libraryTarget : 'commonjs2' , } ,", "commit_type": "fix"}
{"commit_tokens": ["Changed", "log", "level", "from", "warn", "to", "info", "for", "404", "calls", "since", "they", "are", "not", "an", "issue", "that", "needs", "to", "be", "resolved", "."], "add_tokens": "log . info ( err . message ) ;", "del_tokens": "log . warn ( err . message ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "default", "configuration", "for", "the", "maxScenarios", "rule"], "add_tokens": "var _ = require ( 'lodash' ) ; var defaultConfig = { 'maxScenarios' : 10 } ; function maxScenariosPerFile ( feature , unused , config ) { var mergedConfiguration = _ . merge ( { } , defaultConfig , config ) ; var maxScenarios = mergedConfiguration . maxScenarios ; availableConfigs : defaultConfig", "del_tokens": "function maxScenariosPerFile ( feature , _ , config ) { var maxScenarios = config . maxScenarios ; availableConfigs : { 'maxScenarios' : 10 }", "commit_type": "fix"}
{"commit_tokens": ["removed", "confusing", "use", "of", "constants"], "add_tokens": "rpio . write ( DAT , rpio . LOW ) ; rpio . write ( CLK , rpio . HIGH ) ; rpio . write ( CLK , rpio . LOW ) ; rpio . write ( DAT , rpio . LOW ) ; rpio . write ( CLK , rpio . HIGH ) ; rpio . write ( CLK , rpio . LOW ) ; for ( var i = 0 ; i < 8 ; i ++ ) { rpio . write ( CLK , rpio . HIGH ) ; rpio . write ( CLK , rpio . LOW ) ;", "del_tokens": "rpio . write ( DAT , 0 ) ; rpio . write ( CLK , 1 ) ; rpio . write ( CLK , 0 ) ; var pulses = NUM_PIXELS * NUM_PIXELS / 2 ; rpio . write ( DAT , 0 ) ; rpio . write ( CLK , 1 ) ; rpio . write ( CLK , 0 ) ; for ( var i = 0 ; i < NUM_PIXELS ; i ++ ) { rpio . write ( CLK , 1 ) ; rpio . write ( CLK , 0 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "bug", "-", "killer", "in", "example"], "add_tokens": "var FileWatcher = require ( \"../lib\" ) , Logger = require ( \"bug-killer\" ) ; FileWatcher ( __dirname + \"/test.txt\" , function ( err , ev , path ) { if ( err ) { return Logger . log ( err , \"error\" ) ; } Logger . log ( [ ev , path ] . join ( \" \" ) ) ;", "del_tokens": "var FileWatcher = require ( \"../lib\" ) ; FileWatcher ( __dirname + \"/test.txt\" , function ( err , ev ) { console . log ( err || ev ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "methods", "for", "creating", "trees", "with", "base64", "blobs", "."], "add_tokens": "* @ method createBlob Github3 . prototype . createBlob = function ( repo , name , content , callback ) { var blob = { \"content\" : new Buffer ( content ) . toString ( \"base64\" ) , \"encoding\" : \"base64\" } ; return this . _post ( '/repos/' + name + '/' + repo + '/git/blobs' , JSON . stringify ( blob ) , callback ) ; } ; / *! * Repository tree * @ class Github3 * @ method createTreeWithBlob * / Github3 . prototype . createTreeWithBlob = function ( repo , name , path , blob_sha , last_tree_sha , callback ) { var new_tree = { \"base_tree\" : last_tree_sha , \"tree\" : [ { \"path\" : path , \"mode\" : \"100644\" , \"type\" : \"blob\" , \"sha\" : blob_sha } ] } ; return this . _post ( '/repos/' + name + '/' + repo + '/git/trees' , JSON . stringify ( new_tree ) , callback ) ; } ; / *! * Repository tree * @ class Github3 * @ method createTreeAndAddFile * /", "del_tokens": "* @ method createTreeAndAddFile", "commit_type": "add"}
{"commit_tokens": ["added", "caching", "for", "namespace", "details", "in", "luigi", "-", "config"], "add_tokens": "/ ** * We ' * execute getNamespace twice at the same time and we only * want to do one rest call . * * @ param { string } namespaceName * @ returns { Promise } nsPromise * / const cacheName = '_console_namespace_promise_cache_' ; if ( ! window [ cacheName ] ) { window [ cacheName ] = { } ; } const cache = window [ cacheName ] ; if ( ! cache [ namespaceName ] ) { cache [ namespaceName ] = fetchFromKyma ( ` ${ k8sServerUrl } ${ namespaceName } ` ) ; } return await cache [ namespaceName ] ;", "del_tokens": "return fetchFromKyma ( ` ${ k8sServerUrl } ${ namespaceName } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "Pull", "Request", "number", "display"], "add_tokens": "changelog . push ( ` ${ pr . title } \\\\ ${ pr . number } ${ pr . html_url } ${ pr . user . login } ${ pr . user . html_url } \\n ` ) ;", "del_tokens": "changelog . push ( ` ${ pr . title } ${ pr . number } ${ pr . html_url } ${ pr . user . login } ${ pr . user . html_url } \\n ` ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "pug", "compilation", "to", "the", "site"], "add_tokens": "gulp . src ( 'website-src/custom-styles.scss' )", "del_tokens": "import path from 'path' ; gulp . src ( 'website/custom-styles.scss' )", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "configure", "the", "instrumenter", "using", "coverage", ".", "options", "object", "."], "add_tokens": "Instrumenter = require ( 'istanbul' ) . Instrumenter ; instrumenter , bender . checkDeps ( module . exports . name , 'conf' , 'logger' , 'applications' , 'plugins' ) ; instrumenter = new Instrumenter ( bender . conf . coverage && bender . conf . coverage . options ) ; function Transformer ( file , res ) { util . inherits ( Transformer , stream . Transform ) ; Transformer . prototype . _transform = function ( chunk , encoding , callback ) { Transformer . prototype . _flush = function ( callback ) { . pipe ( new Transformer ( filePath , res ) ) . pipe ( new Transformer ( filePath , res ) )", "del_tokens": "instrumenter = new ( require ( 'istanbul' ) . Instrumenter ) ( ) ; bender . checkDeps ( module . exports . name , 'logger' , 'applications' , 'plugins' ) ; function Instrumenter ( file , res ) { util . inherits ( Instrumenter , stream . Transform ) ; Instrumenter . prototype . _transform = function ( chunk , encoding , callback ) { Instrumenter . prototype . _flush = function ( callback ) { . pipe ( new Instrumenter ( filePath , res ) ) . pipe ( new Instrumenter ( filePath , res ) )", "commit_type": "allow"}
{"commit_tokens": ["Allow", "custom", "layouts", "in", "the", "color", "picker", "and", "automatically", "choose", "a", "layout", "based", "on", "platform"], "add_tokens": "* @ param { Object } [ meta ] - override the meta module . exports . clayConfig = function ( types , build , autoRegister , settings , meta ) { module . exports . meta ( meta )", "del_tokens": "module . exports . clayConfig = function ( types , build , autoRegister , settings ) { module . exports . meta ( )", "commit_type": "allow"}
{"commit_tokens": ["Remove", "stray", "comma", "(", "closure", "-", "compiler", ")"], "add_tokens": "'X-CloudMine-Agent' : 'JS/0.9'", "del_tokens": "'X-CloudMine-Agent' : 'JS/0.9' ,", "commit_type": "remove"}
{"commit_tokens": ["moving", "error", "handling", "from", "trendData", "to", "errorHandling", "file"], "add_tokens": "const timePeriodConverter = require ( __dirname + '/../resources/timePeriodConverter.js' ) ; if ( obj . timePeriod && timePeriodConverter ( obj . timePeriod ) instanceof Error ) return timePeriodConverter ( obj . timePeriod ) ;", "del_tokens": "", "commit_type": "move"}
{"commit_tokens": ["Add", "a", "code", "coverage", "report"], "add_tokens": "tasks : [ 'jshint:validate' , 'jasmine:specs' ] , tasks : [ 'jshint:spec' , 'jasmine:specs' ] , specs : { keepRunner : true , } } , coverage : { src : \"<%= jasmine.specs.src %>\" , options : { vendor : \"<%= jasmine.specs.options.vendor %>\" , specs : \"<%= jasmine.specs.options.specs %>\" , helpers : \"<%= jasmine.specs.options.helpers %>\" , template : require ( 'grunt-template-jasmine-istanbul' ) , templateOptions : { coverage : 'coverage.json' , report : [ { type : 'text-summary' } , { type : 'lcovonly' } , { type : 'html' , options : { dir : 'coverage' } } ] , thresholds : { lines : 75 , statements : 75 , branches : 75 , functions : 90 } } grunt . registerTask ( 'build' , [ 'jshint:validate' , 'jasmine:specs' , 'uglify' , 'docco' ] ) ;", "del_tokens": "tasks : [ 'jshint:validate' , 'jasmine' ] , tasks : [ 'jshint:spec' , 'jasmine' ] , pivotal : { keepRunner : true grunt . registerTask ( 'build' , [ 'jshint:validate' , 'jasmine' , 'uglify' , 'docco' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "w", "type", "of", "word"], "add_tokens": "if ( options . format ) { this . _elements . push ( \"<say-as interpret-as=\\'\" + options . interpretParams + \"\\'\" + \" format=\\'\" + options . format + \"'>\" + options . word + \"</say-as>\" ) ; Speech . prototype . typeOfWord = function ( options ) { this . _present ( options . word , \"The word provided to Speech#spell(..) was null or undefined.\" ) ; if ( options . role ) { this . _elements . push ( \"<w role=\\'\" + options . role + \"'>\" + options . word + \"</w>\" ) } } ;", "del_tokens": "if ( options . format ) { this . _elements . push ( \"<say-as interpret-as=\\'\" + options . interpretParams + \"\\'\" + \" format=\\'\" + options . format + \"'>\" + options . word + \"</say-as>\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "attach", "logic", "from", "queue", "to", "integreat"], "add_tokens": "workers , queue let queueHandler = null let pushToQueue = ( queue ) ? queue . push . bind ( queue ) : null const great = { pushToQueue } , / ** * Detach Integreat from queue . Will unsubscribe dispatch method . * @ returns { void } * / detachQueue ( ) { if ( queue && queueHandler ) { queue . unsubscribe ( queueHandler ) queueHandler = null } queue = null pushToQueue = null if ( queue ) { queueHandler = queue . subscribe ( great . dispatch . bind ( great ) ) } return great", "del_tokens": "workers return { queue : null , queue : this . queue", "commit_type": "move"}
{"commit_tokens": ["remove", "DOM", "and", "Style", "dependencies"], "add_tokens": "var labelStyle = { \"position\" : \"absolute\" , \"fontSize\" : this . options . axisLabelFontSize + \"px\" , \"zIndex\" : 10 , \"color\" : this . options . axisLabelColor . toRGBString ( ) , \"width\" : this . options . axisLabelWidth + \"px\" , \"overflow\" : \"hidden\" } ; var makeDiv = function ( txt ) { var div = document . createElement ( \"div\" ) ; for ( var name in labelStyle ) { div . style [ name ] = labelStyle [ name ] ; div . appendChild ( document . createTextNode ( txt ) ) ; return div ; var label = makeDiv ( tick [ 1 ] ) ; var label = makeDiv ( tick [ 1 ] ) ;", "del_tokens": "var labelStyle = { \"style\" : { \"position\" : \"absolute\" , \"fontSize\" : this . options . axisLabelFontSize + \"px\" , \"zIndex\" : 10 , \"color\" : this . options . axisLabelColor . toRGBString ( ) , \"width\" : this . options . axisLabelWidth + \"px\" , \"overflow\" : \"hidden\" var label = DIV ( labelStyle , tick [ 1 ] ) ; var label = DIV ( labelStyle , tick [ 1 ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "for", "race", "condition", "that", "can", "arise", "when", "one", "tween", "causes", "others", "to", "be", "removed"], "add_tokens": "* Advances all tweens . This typically uses the Ticker class ( available in the EaselJS library ) , but you can call it manually if you prefer to use var tweens = Tween . _tweens . slice ( ) ; // to avoid race conditions. if ( ( paused && ! tween . ignoreGlobalPause ) || tween . _paused ) { continue ; } if ( tweens [ i ] . _target == target ) { tweens [ i ] . _paused = true ; tweens . splice ( i , 1 ) ; } // TODO: this approach might fail if a dev is using sealed objects in ES5", "del_tokens": "* Advances all tweens . This typically uses the Ticker class ( when available ) , but you can call it manually if you prefer to use var tweens = Tween . _tweens ; if ( paused && ! tween . ignoreGlobalPause ) { continue ; } if ( tweens [ i ] . _target == target ) { tweens . splice ( i , 1 ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "stubbed", "peer", "/", "content", "abstractions", "(", "peer", "works", "fully", "on", "browser", "side", ")", "datt", ".", "js", "is", "ready", "to", "have", "tests", "added"], "add_tokens": "var Peer = require ( './peer' )", "del_tokens": "var Peer = null if ( process . browser ) { Peer = require ( 'peerjs' ) }", "commit_type": "add"}
{"commit_tokens": ["Changed", "default", "list", "from", "paragraph", "to", "inline", "."], "add_tokens": "files : [ 'index.js' , 'Gruntfile.js' , 'src/**/*.js' , 'spec/**/*.js' ] downshow : {", "del_tokens": "files : [ 'index.js' , 'Gruntfile.js' , 'src/**/*.js' , 'spec/**/*.js' ] , options : { browser : true } build : {", "commit_type": "change"}
{"commit_tokens": ["using", "npm", "-", "tools", "to", "check", "urls"], "add_tokens": "var isUrl = require ( 'npm-utils' ) . isUrl ; / * * / // version = version.substr(version.indexOf('#') + 1); console . log ( 'Cannot handle git repos, skipping' , name , 'at' , version ) ;", "del_tokens": "var VerEx = require ( 'verbal-expressions' ) ; version = version . substr ( version . indexOf ( '#' ) + 1 ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "media", "feature", "to", "number", "-", "leading", "-", "zero"], "add_tokens": "css . eachDecl ( decl => { check ( decl . value , decl ) } ) css . eachAtRule ( atRule => { check ( atRule . params , atRule ) } ) function check ( source , node ) { if ( source . indexOf ( \".\" ) === - 1 ) { return } if ( expectation === \"always\" && ! lacksLeadingZero ( source ) ) { return } if ( expectation === \"never\" && ! containsLeadingZero ( source ) ) { return } node , }", "del_tokens": "css . eachDecl ( function ( decl ) { const value = decl . value if ( value . indexOf ( \".\" ) === - 1 ) { return } if ( expectation === \"always\" && ! lacksLeadingZero ( value ) ) { return } if ( expectation === \"never\" && ! containsLeadingZero ( value ) ) { return } node : decl , } )", "commit_type": "add"}
{"commit_tokens": ["added", "recipient", "card", "methods", "to", "Recipients", "resource"], "add_tokens": "* RecipientCard is similar to CustomerCard in that , upon instantiation , it * requires a recipientId , and therefore each of its methods only * on a returned recipient object . * E . g . recipientObject . cards . retrieve ( cardId ) * ( As opposed to the also - supported stripe . Recipient . retrieveCard ( recipientId , cardId ) )", "del_tokens": "* CustomerCard is a unique resource in that , upon instantiation , * requires a customerId , and therefore each of its methods only * on a returned customer object . * E . g . customerObject . cards . retrieve ( cardId ) * ( As opposed to the also - supported stripe . Customer . retrieveCard ( custId , cardId ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "missing", "=", "in", "delete", "uri"], "add_tokens": "return this . sendDelete ( httpEndPoint + '/projection/' + name + '?deleteStateStream=' + deleteStateStream + '&deleteCheckpointStream=' + deleteCheckpointStream + '&deleteEmittedStreams=' + deleteEmittedStreams , '' , userCredentials , HTTP_OK ) ;", "del_tokens": "return this . sendDelete ( httpEndPoint + '/projection/' + name + '?deleteStateStream=' + deleteStateStream + '&deleteCheckpointStream' + deleteCheckpointStream + '&deleteEmittedStreams=' + deleteEmittedStreams , '' , userCredentials , HTTP_OK ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "init", "W", "as", "the", "averaged", "local", "regression", "beta", "vector", "and", "change", "the", "rho", "and", "eps", "values"], "add_tokens": "// return local regression result for W initialization result . betaVector = regression . oneShot ( biasedX , result . y , lambda ) // filter based on first passed in ROI", "del_tokens": "// filter based on first passed in ROI", "commit_type": "make"}
{"commit_tokens": ["updated", "readme", "tweaked", "url", "form", "to", "avoid", "one", "302", "set", "license", "to", "GPL", "v3"], "add_tokens": "* By Nathan Friedly - http : //nfriedly.com", "del_tokens": "* Copyright Nathan Friedly - http : //nfriedly.com - MIT License", "commit_type": "update"}
{"commit_tokens": ["Add", "tests", "for", "patching", "unkeyed", "children", "and", "implement", "text", "node", "patching"], "add_tokens": "const oldElement = oldVirtualNode . element if ( newVirtualNode . text ) { oldElement . nodeValue = newVirtualNode . text } else { patchChildren ( oldElement , oldVirtualNode . children , newVirtualNode . children ) patchAttributes ( oldElement , oldVirtualNode . props , newVirtualNode . props ) } newVirtualNode . element = oldElement", "del_tokens": "const element = oldVirtualNode . element patchAttributes ( element , oldVirtualNode . props , newVirtualNode . props ) patchChildren ( element , oldVirtualNode . children , newVirtualNode . children ) newVirtualNode . element = element", "commit_type": "add"}
{"commit_tokens": ["Added", "formatting", "to", "cssFrom", "and", "jsFrom", "output", "."], "add_tokens": "var ml = '\\n <link rel=\"stylesheet\" type=\"text/css\" href=\"' + srcPath + '\"/>' ; var ml = '\\n <script type=\"text/javascript\" src=\"' + srcPath + '\"></script>' ;", "del_tokens": "var ml = '<link rel=\"stylesheet\" type=\"text/css\" href=\"' + srcPath + '\"/>' ; var ml = '<script type=\"text/javascript\" src=\"' + srcPath + '\"></script>' ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "function", "name", "in", "alpha", ".", "js"], "add_tokens": "node . Alpha = function Alpha ( val ) {", "del_tokens": "node . Alpha = function URL ( val ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "configure", "()", "to", "take", "any", "number", "of", "keys"], "add_tokens": "for ( var key in settings ) { if ( siad . hasOwnProperty ( key ) ) { siad [ key ] = settings [ key ] || siad [ key ] } }", "del_tokens": "siad . path = settings . path || siad . path siad . address = settings . address || siad . address siad . command = settings . command || siad . command", "commit_type": "allow"}
{"commit_tokens": ["Improve", "code", "style", "of", "the", "iam", "plugin"], "add_tokens": ". action ( function action ( policyIdentifier , options ) { const parameters = cliTools . processCliArgs ( arguments ) ; / ** * Prepare the list of questions for the prompt * @ param { Object } parameters - the parameters that have already been passed to the cli * @ param { Object } choicesLists - lists of values for closed choice parameters * @ return { Array } * / * @ param { Object } parameters - the parameters provided in the command and in the prompt * @ return { Promise < null > }", "del_tokens": ". action ( function ( policyIdentifier , options ) { let parameters = cliTools . processCliArgs ( arguments ) ; * @ param { Object } parameters [ description ] * @ return void", "commit_type": "improve"}
{"commit_tokens": ["added", "documentation", "for", "configuring", "globals"], "add_tokens": "//ModalServiceProvider.configureOptions({closeDelay:500});", "del_tokens": "//ModalServiceProvider.setDefaultCloseDelay(500);", "commit_type": "add"}
{"commit_tokens": ["Remove", "event", ".", "preventDefault", "and", "use", "CSS", "instead"], "add_tokens": "handleSort ( prop , event ) { if ( event ) { event . preventDefault ( ) ; }", "del_tokens": "onMouseDown : ( event ) => { event . preventDefault ( ) ; } , handleSort ( prop ) {", "commit_type": "remove"}
{"commit_tokens": ["Use", "self", ".", "FastBoot", "as", "more", "reliable", "check"], "add_tokens": "if ( self . FastBoot ) { return ; } if ( self . FastBoot ) { return ; } if ( self . FastBoot ) { return ; }", "del_tokens": "if ( ! self . document ) { return ; } if ( ! self . document ) { return ; } if ( ! self . document ) { return ; }", "commit_type": "use"}
{"commit_tokens": ["Move", "spec", "/", "dale", "-", "chall", "-", "formula", ".", "spec", ".", "js", "to", "test", ".", "js"], "add_tokens": "daleChallFormula = require ( './' ) ;", "del_tokens": "daleChallFormula = require ( '..' ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "activity", "for", "create", "a", "tag"], "add_tokens": "async function createTag ( req , res ) { await Activity . query ( ) . insert ( { id : uuid ( ) , user_id : req . user . id , action_type_id : 1 , activity_tag : newTag . id , } ) ;", "del_tokens": "async function createTag ( req , res , next ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "few", "regexes", "used", "in", "some", "utility", "functions"], "add_tokens": ". replace ( / - / g , ' ' ) . replace ( / \\s+ / g , '-' ) ; return match . toUpperCase ( ) . replace ( / \\s+ / g , '' ) ;", "del_tokens": ". replace ( ' ' , '-' ) ; return match . toUpperCase ( ) . replace ( ' ' , '' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "code", "to", "fix", "some", "issues", "caused", "by", "Joi", "update", ".", "Still", "some", "tests", "left", "to", "fix", "."], "add_tokens": "readModelBase [ associationName ] = Joi . array ( ) . items ( Joi . object ( ) . unknown ( ) ) ; readModelBase [ association . linkingModel ] = Joi . object ( ) . unknown ( ) . allow ( null ) ; readModelBase [ associationName ] = Joi . object ( ) . unknown ( ) . allow ( null ) ; } ) ;", "del_tokens": "else { attributeReadModel = attributeReadModel . optional ( ) ; } readModelBase [ associationName ] = Joi . array ( ) . items ( Joi . object ( ) . unknown ( ) ) . optional ( ) ; readModelBase [ association . linkingModel ] = Joi . object ( ) . unknown ( ) . allow ( null ) . optional ( ) ; readModelBase [ associationName ] = Joi . object ( ) . unknown ( ) . allow ( null ) . optional ( ) ; } else { attributeUpdateModel = attributeUpdateModel . optional ( ) ; } ) . optional ( ) ; } else { attributeCreateModel = attributeCreateModel . optional ( ) ; else { attributeAssociationModel = attributeAssociationModel . optional ( ) ; }", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "regression", "where", "icons", "never", "show", "up", ".", "Prevent", "result", "highlighting", "from", "injecting", "empty", "tags", "when", "input", "is", "blank"], "add_tokens": "if ( this . _input . value . length > 0 ) { resultItem . innerHTML += this . highlight ( feature . properties . label , this . _input . value ) ; }", "del_tokens": "resultItem . innerHTML = this . highlight ( feature . properties . label , this . _input . value ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "decrypt", "in", "case", "secretbox_open", "fails"], "add_tokens": "if ( plainText && encoding ) {", "del_tokens": "if ( encoding ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "dependency", "on", "swagen", "-", "core", "and", "moved", "Transformer", "and", "Parser", "code", "into", "the", "project", "."], "add_tokens": "const Parser = require ( '../_parser' ) ; const Transformer = require ( '../_transformer/transformer' ) ; const parser = new Parser ( swagger ) ; const transformer = new Transformer ( profile ) ;", "del_tokens": "const swagenCore = require ( 'swagen-core' ) ; const parser = new swagenCore . Parser ( swagger ) ; const transformer = new swagenCore . transformer . Transformer ( profile ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "base", "of", "user", "and", "auth", "system"], "add_tokens": "var Workspace = require ( './workspace' ) . Workspace ; function setup ( options , imports , register ) { var workspace = new Workspace ( path . resolve ( __dirname , '..' , '..' ) ) ; \"workspace\" : workspace", "del_tokens": "function setup ( options , imports , register ) { \"workspace\" : { root : path . resolve ( __dirname , '..' , '..' ) , mtime : null }", "commit_type": "add"}
{"commit_tokens": ["Update", "communication", ".", "js", "by", "capitalizing", "the", "ZimbraError", "function"], "add_tokens": "communicationErrors . ZimbraError (", "del_tokens": "communicationErrors . zimbraError (", "commit_type": "update"}
{"commit_tokens": ["Added", "more", "row", "processing", "."], "add_tokens": "_getRow : function ( r ) { var row = this . _getRow ( cell . row ) ; if ( value [ 0 ] != undefined ) { // contiguous array - start at column 1 var index = 1 ; _ . each ( value , function ( item ) { self . getCell ( row , index ++ ) . value = item ; } ) ; } else { // sparse array - assign columns by index _ . each ( value , function ( item , index ) { self . getCell ( row , index ) . value = item ; } ) ; } getRow : function ( number ) { return this . _getRow ( number ) . values ; } , eachRow : function ( iteratee ) { this . _rows . forEach ( function ( row ) { iteratee ( row . number , row . values ) ; } ) ; } ,", "del_tokens": "getRow : function ( r ) { var row = this . getRow ( cell . row ) ; _ . each ( value , function ( item , index ) { self . getCell ( row , index + 1 ) . value = item ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "when", "upload", "ended", "with", "ENOENT"], "add_tokens": "ino : stat . ino if ( node . directory ) { node . ctime = stat . ctime ; node . mtime = stat . mtime ; node . size = stat . size ; }", "del_tokens": "ino : stat . ino , mtime : stat . mtime , ctime : stat . ctime , size : stat . size node . size = stat . size ; node . ctime = stat . ctime ; node . mtime = stat . mtime ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "tests", "to", "include", "new", "additions", "as", "well", "as", "refactored", "the", "way", "some", "tests", "run"], "add_tokens": "var poolConfig = require ( './helpers/connection' ) , Helenus , conn ,", "del_tokens": "var poolConfig = require ( './helpers/pool' ) , Helenus , conn ,", "commit_type": "update"}
{"commit_tokens": ["Move", "atom", "from", "submodule", "to", "npm", "package", "dependency"], "add_tokens": "gravity . VERSION = '0.7.0' ; atom = require ( 'atom-js' ) ,", "del_tokens": "gravity . VERSION = '0.6.20' ; atom = require ( './atom/atom' ) ,", "commit_type": "move"}
{"commit_tokens": ["added", "bridge", "to", "send", "and", "onMessage", "methods"], "add_tokens": "< WebViewEx ref = \"myWebView\" style = { { flex : 1 } } url = \"http://google.com\" / >", "del_tokens": "< WebViewEx ref = \"myWebView\" style = { { flex : 1 } } url = \"http://google.com\" / >", "commit_type": "add"}
{"commit_tokens": ["fixing", "dest", "directory", "detection", "and", "adding", "flatten", "to", "examples"], "add_tokens": "if ( _ . endsWith ( path . normalize ( dest ) , path . sep ) ) {", "del_tokens": "if ( _ . endsWith ( dest , path . sep ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "ui", ":", "rootFieldId", "uiSchema", "directive", "."], "add_tokens": "const uiSchema = \"uiSchema\" in props ? props . uiSchema : this . props . uiSchema ; const formData = getDefaultFormState ( schema , props . formData , definitions ) ; const idSchema = toIdSchema ( schema , uiSchema [ \"ui:rootFieldId\" ] , definitions ) ;", "del_tokens": "const formData = getDefaultFormState ( schema , props . formData , definitions ) || null ; const idSchema = toIdSchema ( schema , undefined , definitions ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "var", "to", "reference", "config", ".", "rule"], "add_tokens": "var rule = config . rule ; var selectors = rule . selectors ; node : rule ,", "del_tokens": "var selectors = config . rule . selectors ; node : config . rule ,", "commit_type": "add"}
{"commit_tokens": ["Add", "fix", "for", "objects", "with", "circular", "references", "causing", "maximum", "call", "stack", "size", "exceeded"], "add_tokens": "const fclone = require ( 'fclone' ) // Replace circular values with '[Circular]' const obj = fclone ( val ) if ( isObject ( obj ) ) { return removeKeysFromObject ( obj , props , recursive ) return removeKeysFromArray ( obj , props , recursive )", "del_tokens": "if ( isObject ( val ) ) { return removeKeysFromObject ( val , props , recursive ) return removeKeysFromArray ( val , props , recursive )", "commit_type": "add"}
{"commit_tokens": ["Add", "global", "variables", "feature", "."], "add_tokens": "import { config } from '../../config' ; if ( variables . indexOf ( node . name ) == - 1 && config . globals . indexOf ( node . name ) == - 1 ) {", "del_tokens": "if ( variables . indexOf ( node . name ) == - 1 ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "current", "timestamp", "for", "x", "-", "shunter", "-", "deploy", "-", "timestamp", "header", "in", "development", "mode"], "add_tokens": "req . headers [ 'X-Shunter-Deploy-Timestamp' ] = config . env . isDevelopment ( ) ? Date . now ( ) : deployTimestamp ;", "del_tokens": "req . headers [ 'X-Shunter-Deploy-Timestamp' ] = deployTimestamp ;", "commit_type": "use"}
{"commit_tokens": ["Make", "baseUrlWorkAround", "do", "not", "crash", "IE"], "add_tokens": "arrayFrom ( nodes ) . forEach ( function ( node ) { if ( ! node . attributes ) { return ; } var match = URI_FUNC_REGEX . exec ( node . getAttribute ( attribute . localName ) ) ; // Do not touch urls with unexpected prefix if ( match && match [ 1 ] . indexOf ( currentUrlPrefix ) === 0 ) { node . setAttribute ( attribute . localName , 'url(' + newUrlPrefix + match [ 1 ] . split ( currentUrlPrefix ) [ 1 ] + ')' ) ; }", "del_tokens": "var attributes = arrayFrom ( nodes ) . reduce ( function ( attributes , node ) { attributes . push ( attribute ) ; return attributes ; } , [ ] ) ; attributes . forEach ( function ( attribute ) { var match = URI_FUNC_REGEX . exec ( attribute . value ) ; // Do not touch urls with unexpected prefix if ( match && match [ 1 ] . indexOf ( currentUrlPrefix ) === 0 ) { attribute . value = 'url(' + newUrlPrefix + match [ 1 ] . split ( currentUrlPrefix ) [ 1 ] + ')' }", "commit_type": "make"}
{"commit_tokens": ["Create", "a", "new", "build", "of", "the", "example", "site", "which", "has", "the", "correct", "series", "items", "css", "example", "."], "add_tokens": "* // false; * *", "del_tokens": "* console . log ( chart . x . domain . $dirty ) // false; * console . log ( chart . features ( ) ) ; * console . log ( chart . features ( ) ) ;", "commit_type": "create"}
{"commit_tokens": ["added", "btoa", "to", "supplort", "Node"], "add_tokens": "var btoa ; if ( typeof window === 'undefined' ) { btoa = require ( 'btoa' ) ; } else { btoa = window . btoa ; } attachments . push ( { 'name' : name , 'data' : btoa ( content ) } )", "del_tokens": "attachments . push ( { 'name' : name , 'data' : window . btoa ( content ) } )", "commit_type": "add"}
{"commit_tokens": ["add", "samples", "and", "express", "public", "files", "fix"], "add_tokens": "exp . use ( express . static ( path . join ( root . vulpejs . dir , 'ui/public' ) ) ) ;", "del_tokens": "exp . use ( express . static ( path . join ( root . vulpejs . dir , 'ui/public' ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "a", "read", "loop", "in", "sensor", "classes"], "add_tokens": "var Sensor = function ( adapter , input_port , manualStartReadLoop ) { this . value = null ; this . _readLoopActive = false ; this . _lastReadLoopErr = null ; if ( ! manualStartReadLoop ) this . startReadLoop ( ) ; Sensor . prototype . startReadLoop = function ( ) { this . _readLoopActive = true ; this . _readLoop ( ) ; } Sensor . prototype . _readLoop = function ( ) { if ( this . _readLoopActive ) { this . read ( function ( err , value ) { if ( err ) this . _lastReadLoopErr = err ; var emitReady = this . value == null ; this . value = value ; //on(\"ready\") gets called if this was the first //successful read loop call since the last stopReadLoop() //or during the first successful iteration of the read loop if ( emitReady ) this . emit ( \"ready\" , value ) ; this . emit ( \"data\" , value ) ; } . bind ( this ) ) ; } } Sensor . prototype . stopReadLoop = function ( ) { this . _readLoopActive = false ; this . value = null ; }", "del_tokens": "var Sensor = function ( adapter , input_port ) {", "commit_type": "implement"}
{"commit_tokens": ["fix", "false", "positive", "in", "prop", "shorthand"], "add_tokens": "function canUseShorthand ( func ) { if ( methodSupportsShorthand ( node ) && canUseShorthand ( lodashUtil . getLodashIteratee ( node ) ) ) {", "del_tokens": "function shouldPreferProp ( func ) { if ( methodSupportsShorthand ( node ) && shouldPreferProp ( lodashUtil . getLodashIteratee ( node ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "protocol", "option", "(", "enables", "https", "support", ")"], "add_tokens": "protocol : 'http' , this . request . addHost ( this . options . host , this . options . port , this . options . protocol ) ; var port = host . port || self . options . port ; var protocol = host . protocol || self . options . protocol ; self . request . addHost ( host . host , port , protocol ) ;", "del_tokens": "this . request . addHost ( this . options . host , this . options . port ) ; self . request . addHost ( host . host , host . port || self . options . port ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "prettier", "to", "web", "-", "config", "."], "add_tokens": "\"eslint.js\" , \"prettier.config.js\" \".prettierignore\" ,", "del_tokens": "\"eslint.js\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "error", "handling", "for", "recognising", "command", "line", "options"], "add_tokens": "throw new Error ( \"Socket type not understood: \" + argv . socket ) ;", "del_tokens": "console . log ( \"Socket type not understood: \" + argv . socket ) ; options . path = DEFAULT_SOCKET ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "base", "url", "bug"], "add_tokens": "serverConfig . mount . push ( [ config . baseUrl || '/' , outputFolder ] ) ;", "del_tokens": "serverConfig . mount . push ( [ config . baseUrl , outputFolder ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "and", "logging", "to", "alignment", "app"], "add_tokens": "log . debug ( 'Selection cleared:' ) ; log . debug ( 'Drawing Monitors' ) ; // This function draws a rectangle representing each monitor, and defines the associated interactivity log . debug ( 'Loaded Clients.json' ) ; // Ensure the monitorGrid SVG is empty // Use the contents of Clients.json to construct a list recording the id and position of each monitor, // and the horizontal and vertical shifts applied to it. // Pick a scale which will scale the bounding-box of the monitors to fit inside the browser window // create a D3 brush, to enable the selection of monitors // Draw a rectangle for each monitor; apply class indexMonitor to monitor with clientId of 0 // Register a callback that will fire when user clicks on a rectangle // Broadcast an initial message, so that the viewers draw their alignment patterns // When an arrow key is pressed, adjust shifts for monitors accordingly, // and broadcast a message listing new offsets. // When escape key is pressed, clear selection of monitors. // When the user clicks and drags to brush a rectangular region, // select any rectangles that are completely enclosed // (except the index monitor, if the checkbox locking its position is checked) // This function makes any adjustments required when locked-monitor is checked/unchecked // unselect index monitor if the checkbox to lock it is checked // The rectangle representing the index monitor should have the .indexMonitor class applied // (and hence be styled differently), if and only if the checkbox to lock it is checked function displayJSON ( ) { // Construct array listing the position of each screen after applying shift // Display new space dimensions (this will have increased in scrreens have been shifted outwards) // Display JSON serialization of layout (with initial '{' and final '}' removed) d3 . select ( '#clients-json' ) . text ( layoutJSON . substr ( 1 , layoutJSON . length - 2 ) ) ;", "del_tokens": "// unselect index monitor if necessary displayJSON = function ( ) { d3 . select ( '#clients-json' ) . text ( exportOffsets ( ) ) ; } ; function exportOffsets ( ) { let x = [ ] ; d3 . selectAll ( '.monitor' ) . each ( function ( d ) { x . push ( d ) ; } ) ; return layoutJSON . substr ( 1 , layoutJSON . length - 2 ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "generate", "correct", "code", "on", "Windows"], "add_tokens": "config . angularBaseWorkaround ? 'require(\"' + path . resolve ( __dirname , 'lib/web/angular-base-workaround' ) . replace ( / \\\\ / g , \"/\" ) + '\");' : '' ,", "del_tokens": "config . angularBaseWorkaround ? 'require(\"' + path . resolve ( __dirname , 'lib/web/angular-base-workaround' ) + '\");' : '' ,", "commit_type": "make"}
{"commit_tokens": ["Fixed", "paths", "for", "case", "sensitive", "filesystems"], "add_tokens": "readability = require ( \"../readabilitySAX\" ) ,", "del_tokens": "readability = require ( \"../readabilitysax\" ) ,", "commit_type": "fix"}
{"commit_tokens": ["added", "get", "-", "var", "-", "value", "test"], "add_tokens": "import is from '../node_modules/is' ; import message from './_message.js' ; function resolveVarValue ( name , values ) { if ( is . undef ( values ) || is . args . empty ( arguments ) ) { message ( 'Variable cannot be resolved' ) ; return undefined ; } if ( ! is . string ( name ) || ! is . object ( values ) ) { message ( 'Check arguments type' ) ; return undefined ; }", "del_tokens": "function resolveVarValue ( name , values = { } ) {", "commit_type": "add"}
{"commit_tokens": ["Moved", "os", "specific", "actions", "to", "seperate", "files"], "add_tokens": "autostart = require ( './index.js' ) , autostart . isAutostartEnabled ( argv . n , function ( err , isEnabled ) {", "del_tokens": "autostart = require ( './lib/index.js' ) , autostart . isAutostartEnabled ( argv . n , function ( isEnabled , err ) {", "commit_type": "move"}
{"commit_tokens": ["changing", "EJS", "files", "to", ".", "ejs"], "add_tokens": "this . templatePath ( 'gulpfile.js.ejs' ) , console . log ( 'Installing Pattern Lab; please be patient...' ) ;", "del_tokens": "this . templatePath ( 'gulpfile.js' ) ,", "commit_type": "change"}
{"commit_tokens": ["Fix", "issue", "where", "MenuList", "would", "block", "enter", "event", "even", "when", "nothing", "was"], "add_tokens": "// The natural highlight is where the highlight would be if no lock is active. if ( this . _keyboardTakenByIndex != null || this . _listItems . length === 0 ) { if ( visibleHighlightedIndex != null ) { mEvent = new ChosenEvent ( 'chosen' , true ) ; event . preventDefault ( ) ; event . stopPropagation ( ) ; } if ( visibleHighlightedIndex != null ) { mEvent = new MenuEvent ( 'left' ) ; } if ( visibleHighlightedIndex != null ) { mEvent = new MenuEvent ( 'right' ) ; }", "del_tokens": "if ( this . _keyboardTakenByIndex != null ) { mEvent = new ChosenEvent ( 'chosen' , true ) ; event . preventDefault ( ) ; event . stopPropagation ( ) ; mEvent = new MenuEvent ( 'left' ) ; mEvent = new MenuEvent ( 'right' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "closure", "context", "for", "row", ".", "get", "."], "add_tokens": "row . get = ( function ( row ) { return function ( name ) { var cellIndex = name ; if ( typeof cellIndex === 'string' ) { cellIndex = meta . columns [ '_col_' + name ] ; } return row [ cellIndex ] ; } ) ( row ) ;", "del_tokens": "row . get = function ( name ) { var cellIndex = name ; if ( typeof cellIndex === 'string' ) { cellIndex = meta . columns [ '_col_' + name ] ; return row [ cellIndex ] ; }", "commit_type": "add"}
{"commit_tokens": ["add", "options", "for", "http", "datasource", "to", "create", "()"], "add_tokens": "var timeout = _ref . timeout ; var headers = _ref . headers ; var source = router && new _falcorHttpDatasource2 . default ( router , { timeout : timeout , headers : headers } ) ;", "del_tokens": "var source = router && new _falcorHttpDatasource2 . default ( router ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "TDD", "for", "matrixMultiply", "."], "add_tokens": "describe ( \"matrixMultiply()\" , function ( ) { [ [ ( 1 * 4 ) , ( 1 * 5 ) , ( 1 * 6 ) ] , [ ( 2 * 4 ) , ( 2 * 5 ) , ( 2 * 6 ) ] , [ ( 3 * 4 ) , ( 3 * 4 ) , ( 3 * 6 ) ] ] )", "del_tokens": "describe ( \"multiplyElementWise()\" , function ( ) { [ [ ( 1 * 4 ) + ( 1 * 5 ) + ( 1 * 6 ) ] , [ ( 2 * 4 ) + ( 2 * 5 ) + ( 2 * 6 ) ] , [ ( 3 * 4 ) + ( 3 * 4 ) + ( 3 * 6 ) ] ] )", "commit_type": "fix"}
{"commit_tokens": ["move", "helper", "function", "to", "bottom", "of", "file"], "add_tokens": "function getBrowserRTC ( ) { if ( typeof window === 'undefined' ) return null var wrtc = { RTCPeerConnection : window . mozRTCPeerConnection || window . RTCPeerConnection || window . webkitRTCPeerConnection , RTCSessionDescription : window . mozRTCSessionDescription || window . RTCSessionDescription || window . webkitRTCSessionDescription , RTCIceCandidate : window . mozRTCIceCandidate || window . RTCIceCandidate || window . webkitRTCIceCandidate } if ( ! wrtc . RTCPeerConnection ) return null return wrtc }", "del_tokens": "function getBrowserRTC ( ) { if ( typeof window === 'undefined' ) return null var wrtc = { RTCPeerConnection : window . mozRTCPeerConnection || window . RTCPeerConnection || window . webkitRTCPeerConnection , RTCSessionDescription : window . mozRTCSessionDescription || window . RTCSessionDescription || window . webkitRTCSessionDescription , RTCIceCandidate : window . mozRTCIceCandidate || window . RTCIceCandidate || window . webkitRTCIceCandidate } if ( ! wrtc . RTCPeerConnection ) return null return wrtc }", "commit_type": "move"}
{"commit_tokens": ["Use", "a", "deep", "copy", "of", "requestParamsJSON", "in", "callbacks"], "add_tokens": "_responseHandler : function ( requestParamsJSONCopy , req , callback ) { if ( response [ requestParamsJSONCopy . Action + 'Response' ] ) { response = response [ requestParamsJSONCopy . Action + 'Response' ] ; if ( response [ requestParamsJSONCopy . Action + 'Result' ] ) { response = response [ requestParamsJSONCopy . Action + 'Result' ] ; var requestParamsJSONCopy = JSON . parse ( JSON . stringify ( self . requestParamsJSON ) ) req . on ( 'response' , self . _responseHandler ( requestParamsJSONCopy , req , callback ) ) ;", "del_tokens": "_responseHandler : function ( req , callback ) { if ( response [ self . requestParamsJSON . Action + 'Response' ] ) { response = response [ self . requestParamsJSON . Action + 'Response' ] ; if ( response [ self . requestParamsJSON . Action + 'Result' ] ) { response = response [ self . requestParamsJSON . Action + 'Result' ] ; req . on ( 'response' , self . _responseHandler ( req , callback ) ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "assertions", "for", "nested", "tareting", "and", "douvle", "constraints"], "add_tokens": "require ( '../index.js' ) ; //delayed addition of physics body component to controllers due to AFRAME 0.4.0 changes AFRAME . registerComponent ( 'controller-loaded' , { init : function ( ) { this . el . addEventListener ( 'model-loaded' , function ( ) { this . addState ( 'loaded' ) ; } ) ; } } ) ;", "del_tokens": "require ( '../index.js' ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "packages", ";", "Updated", "ESLint", "rules", ";", "Updated", "Travis", "CI", "NodeJS", "versions"], "add_tokens": "outputFile : \"eslint.xml\" , format : \"jslint-xml\" , silent : true", "del_tokens": "\"output-file\" : \"eslint.xml\" , \"format\" : \"jslint-xml\" , \"silent\" : true", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "magic", "plus", "that", "will", "wipe", "empty", "flags", ":", ")"], "add_tokens": "( options . flags || '' ) . toUpperCase ( ) . split ( / \\s*,+\\s* / ) ) ;", "del_tokens": "( options . flags || '' ) . toUpperCase ( ) . split ( / \\s*,\\s* / ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "http", ":", "as", "a", "default", "protocol"], "add_tokens": "// Normally, the page is loaded from http or https, so not specifying a protocol // will result in a (valid) protocol-relative url. However, this won't work if // the protocol is something else, like 'file:' var defaultProtocol = global . location . protocol . search ( / ^https?:$ / ) === - 1 ? 'http:' : '' var protocol = opts . protocol || defaultProtocol", "del_tokens": "var protocol = opts . protocol || ''", "commit_type": "use"}
{"commit_tokens": ["Fixed", ":", "combiner", "script", "to", "make", "it", "working", "with", "parse5", "."], "add_tokens": "combine ( old , elem ) ; combine ( html . children , elem ) ;", "del_tokens": "combine ( old . children , elem . children ) ; combine ( html . children , [ elem ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typos", "in", "plugin", "file", "fixed", "options", ".", "md", "file", "errors"], "add_tokens": "// Remove map style from container // Remove namespaced events * Some errors use alert by default . This is overridable with the callbackNotify option * Checks to see if all the property values in the object are empty * @ param markerWidth { number } width of marker * @ returns { Object } extended location data object * @ param firstRun { boolean } initial load check // Check filters here to handle selected filtering after page reload // Append the no results message", "del_tokens": "// Remove map style from cotnainer // Remove namespached events * Some errors use alert by default . This is overrideable with the callbackNotify option * Checks to see if all the perperty values in the object are empty * @ param markerWidth { number } width of mearker * @ returns { Object } extendded location data object * @ param firstRun { boolean } inital load check // Check filteres here to handle selected filtering after page reload // Append the no rsults message", "commit_type": "fix"}
{"commit_tokens": ["Added", "Collapsible", "toggle", "for", "whole", "static", "div"], "add_tokens": "< div className = \"static\" onClick = { this . toggleVisibility } > < div className = \"button\" > < / div >", "del_tokens": "< div className = \"static\" > < div className = \"button\" onClick = { this . toggleVisibility } > < / div >", "commit_type": "add"}
{"commit_tokens": ["Added", "required", "relationships", "fixed", "a", "bug", "with", "relationship", "generation"], "add_tokens": "this . isInjectedFieldInFromRequired = merged . isInjectedFieldInFromRequired ; this . isInjectedFieldInToRequired = merged . isInjectedFieldInToRequired ; return ` ${ this . type } ${ this . from . name } ${ ( this . injectedFieldInFrom ) ? ` ${ this . injectedFieldInFrom } ` : '' } ${ this . to . name } ${ ( this . injectedFieldInTo ) ? ` ${ this . injectedFieldInTo } ` : '' } ` ; string += ` ${ this . injectedFieldInFrom } ${ this . isInjectedFieldInFromRequired ? ' required' : '' } ` string += ` ${ this . injectedFieldInTo } ${ this . isInjectedFieldInToRequired ? ' required' : '' } ` ; isInjectedFieldInFromRequired : false , isInjectedFieldInToRequired : false ,", "del_tokens": "return ` ${ this . type } ${ this . from . name } ${ ( this . injectedFieldInFrom ) ? ` ${ this . injectedFieldInFrom } ` : '' } ${ this . to . name } ${ ( this . injectedFieldInTo ) ? ` ${ this . injectedFieldInTo } ` : '' } ` ; string += ` ${ this . injectedFieldInFrom } ` string += ` ${ this . injectedFieldInTo } ` ;", "commit_type": "add"}
{"commit_tokens": ["Add", "open", "and", "close", "methods", "."], "add_tokens": "/ ** * Open an escape sequence . * * @ param code The color code . * @ param attr An optional attribute code . * / function open ( code , attr ) { return attr ? ANSI_OPEN + attr + ';' + code + ANSI_FINAL : ANSI_OPEN + code + ANSI_FINAL ; } / ** * Concatenate a close sequence . * * @ param value The value to close . * / function close ( value ) { return value + ANSI_CLOSE ; } * @ param loose Whether to keep the escape sequence open . function stringify ( value , code , attr , loose ) { var s = open ( code , attr ) ; s += loose ? value : close ( value ) ;", "del_tokens": "function stringify ( value , code , attr ) { var s = attr ? ANSI_OPEN + attr + ';' + code + ANSI_FINAL : ANSI_OPEN + code + ANSI_FINAL ; s += value + ANSI_CLOSE ;", "commit_type": "add"}
{"commit_tokens": ["fix", "peer", "depdendency", "and", "use", "slate", "-", "hotkeys", "package"], "add_tokens": "import hotkeys from \"slate-hotkeys\" ; if ( hotkeys . isUndo ( e ) ) { } else if ( hotkeys . isRedo ( e ) ) {", "del_tokens": "import isHotkey from \"is-hotkey\" ; import { environments } from \"@vericus/slate-kit-plugins-utils\" ; const UNDO = isHotkey ( \"mod+z\" ) ; const REDO_MAC = isHotkey ( \"mod+shift+z\" ) ; const REDO_OTHER = isHotkey ( \"mod+y\" ) ; const REDO = e => ( environments . IS_MAC ? REDO_MAC ( e ) : REDO_OTHER ( e ) ) ; if ( UNDO ( e ) ) { } else if ( REDO ( e ) ) {", "commit_type": "fix"}
{"commit_tokens": ["moving", "formly", "-", "form", "to", "support", "SSR"], "add_tokens": "import FormlyForm from './FormlyForm' ;", "del_tokens": "import FormlyForm from './FormlyForm.vue' ;", "commit_type": "move"}
{"commit_tokens": ["add", "notes", "default", "to", "not", "show", "queued"], "add_tokens": "if ( search . validationState !== 'queued' ) { qs . push ( 'NOT state:queued' ) ; }", "del_tokens": "if ( search . validationState !== 'queued' ) { qs . push ( 'NOT state:queued' ) ; }", "commit_type": "add"}
{"commit_tokens": ["Remove", "unnecessary", "priv", ".", "set", "(", "this", "...", ")"], "add_tokens": "} grunt", "del_tokens": "} // priv.set(this, refs);", "commit_type": "remove"}
{"commit_tokens": ["Use", "=", ">", "syntax", "for", "function"], "add_tokens": "} ) . on ( 'error' , ( ) => done ( ) ) ; // transport err", "del_tokens": "} ) . on ( 'error' , done ( ) ) ; // transport err", "commit_type": "use"}
{"commit_tokens": ["Fixed", ":", "prevent", "node", "exception", "if", "parent", "does", "not", "exist", "or", "is", "undefined"], "add_tokens": "if ( rule . parent && rule . parent . type === 'atrule' ) { return } ;", "del_tokens": "if ( rule . parent . type === 'atrule' ) { return } ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", ":", "do", "not", "delete", "field", "if", "not", "set", "by", "client"], "add_tokens": "var roles = user . getRoles ( ) ? user . getRoles ( ) : [ ] ; roles = Array . isArray ( roles ) ? roles : [ roles ] ; if ( roles . indexOf ( 'guest' ) < 0 ) roles . push ( 'guest' ) ; if ( roles . indexOf ( 'authenticated' ) < 0 ) roles . push ( 'authenticated' ) ; var allowed = isAllowed ( category + \".\" + group , roles , function ( allowed ) {", "del_tokens": "var allowed = isAllowed ( category + \".\" + group , user . getRoles ( ) , function ( allowed ) { roles = roles ? roles : [ ] ; roles = Array . isArray ( roles ) ? roles : [ roles ] ; if ( roles . indexOf ( 'guest' ) < 0 ) roles . push ( 'guest' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "\\", "in", "front", "of", "functions", "in", "the", "parser"], "add_tokens": "return new LexResult ( match [ 0 ] , match [ 0 ] , pos + match [ 0 ] . length ) ;", "del_tokens": "return new LexResult ( match [ 1 ] , match [ 0 ] , pos + match [ 0 ] . length ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "callback", "call", "for", "autoconnect"], "add_tokens": "self . connect ( dc , clb ) ; } else if ( deviceOrId . id && ! device . connect ) { } else if ( ! deviceOrId . connect ) { device = null ; } if ( ! device ) { var err = new Error ( 'Device not found!' ) ; if ( this . log ) { this . log ( err . message ) ; } if ( callback ) { callback ( err ) ; } return ; } else if ( deviceOrId . id && ! deviceOrId . disconnect ) { } else if ( ! deviceOrId . disconnect ) { device = null ; var err = new Error ( 'Device not found!' ) ; if ( this . log ) { this . log ( err . message ) ; } if ( callback ) { callback ( err ) ; }", "del_tokens": "self . connect ( dc ) ; } else if ( deviceOrId . id ) { } else if ( deviceOrId . id ) { if ( this . log ) this . log ( 'Device not connected!' ) ; if ( callback ) { callback ( new Error ( 'Device not connected!' ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fix", "tests", ".", "remove", "old", "cases", ".", "remove", "tests", "of", "unused", "methods"], "add_tokens": "sh1_1 . field ( 'myField' ) . like ( sh2 ) ; Schema . get ( 'attachExampleSchema' ) . field ( 'myField' ) . like ( sh2 ) ; var sc1 = new Schema ( 'hello2' ) . like ( sh4 ) ; sc2 . like ( sc1 ) ; // add sh1 sc3 . like ( Schema . get ( 'hello2' ) ) ; // add sc1 sh1 . field ( 'inner' ) . like ( sc3 ) ;", "del_tokens": "sh2 . clone ( ) . attachTo ( sh1_1 , 'myField' ) ; sh2 . clone ( ) . attachTo ( 'attachExampleSchema' , 'myField' ) ; var sc1 = new Schema ( 'hello2' ) . object ( sh4 ) ; sc2 . object ( sc1 ) ; // add sh1 sc3 . object ( 'hello2' ) ; // add sc1 sc3 . attachTo ( sh1 , 'inner' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "params", "on", "getChildren", "endpoint"], "add_tokens": "getChildren : function ( id , params , callback ) { if ( ! ! ( params && params . constructor && params . call && params . apply ) ) { callback = params ; params = { } ; } params . id = id ; blnApiRequest . sendRequest ( 'get' , '/collection/children' , params , ( err , result ) => {", "del_tokens": "getChildren : function ( id , callback ) { blnApiRequest . sendRequest ( 'get' , '/collection/children' , { id : id } , ( err , result ) => {", "commit_type": "allow"}
{"commit_tokens": ["remove", "duplicate", "hbs", "helper", "file"], "add_tokens": "const hbs = require ( 'express-hbs' ) ; require ( 'handlebars-helpers' ) ( { handlebars : hbs } ) ;", "del_tokens": "const hbs = require ( './hbshelpers' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "chrome", "issue", "karma", "and", "travis"], "add_tokens": "browserList . push ( 'ChromeCanary' ) ; } ,", "del_tokens": "} ,", "commit_type": "fix"}
{"commit_tokens": ["add", "additional", "tests", "for", "other", "CSS", "preprocesors"], "add_tokens": "\"tmp/config-namespace.scss\" , \"tmp/config-namespace.sass\" , \"tmp/config-namespace.less\" , \"tmp/config-namespace.styl\"", "del_tokens": "\"tmp/config-namespace.scss\"", "commit_type": "add"}
{"commit_tokens": ["improved", "space", "count", "after", "replacement", "in", "toString"], "add_tokens": "} else if ( this [ p ] ) { xml = xml . replace ( ' ' , ' ' ) ;", "del_tokens": "} else if ( this [ p ] ) {", "commit_type": "improve"}
{"commit_tokens": ["allow", "to", "opt", "-", "in", "using", "keydown", "instead", "of", "keyup"], "add_tokens": "exports . activate = function ( event ) { if ( ! event ) { event = 'keyup' ; } documentListener = EventListener . listen ( document , event , handle ) ;", "del_tokens": "exports . activate = function ( ) { documentListener = EventListener . listen ( document , 'keyup' , handle ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "minimal", "debug", "trace", "in", "http", "client"], "add_tokens": "this . Debug ( 2 , \"%s Dev %s Data %s ignored moved %dm<%dm ?\" , this . count , this . devid , moved , this . controller . svcopts . mindist ) ;", "del_tokens": "this . Debug ( 2 , \"Data %s/%s ignored moved %dm<%dm ?\" , this . count , data . count , moved , this . controller . svcopts . mindist ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "travis", "and", "fix", "broken", "tests", "in", "phantomjs"], "add_tokens": "/ ** binds a function to a context @ method bind @ param { Function } func @ param { Object } context @ return { Function } ** / var bind = function ( func , context ) { return function ( ) { func . apply ( context , Array . prototype . slice . call ( arguments ) ) ; } ; } ; host . addEventListener ( eventName , bind ( handler , context ) , false ) ;", "del_tokens": "host . addEventListener ( eventName , handler . bind ( context ) , false ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "problem", "with", "conditionals", "inside", "a", "loop"], "add_tokens": "return new RegExp ( \"<!--[\\\\s]*BEGIN \" + block + \"[\\\\s]*-->[\\\\s\\\\S]*?<!--[\\\\s]*END \" + block + \"[\\\\s]*-->\" , 'g' ) ; match = matches [ i ] . replace ( statement , '' ) . replace ( / [\\s|\\S]<!-- IF[\\s\\S]*ENDIF[\\s\\S]*-->[\\s|\\S] / gi , '<!-- NESTED -->' ) , for ( var x = 0 , xx = nestedConditionals . length ; x < xx ; x ++ ) { template = template . replace ( '<!-- NESTED -->' , nestedConditionals [ x ] ) ; }", "del_tokens": "return new RegExp ( \"<!--[\\\\s]*BEGIN \" + block + \"[\\\\s]*-->[\\\\s\\\\S]*<!--[\\\\s]*END \" + block + \"[\\\\s]*-->\" , 'g' ) ; match = matches [ i ] . replace ( statement , '' ) . replace ( / [\\s|\\S]<!-- IF[\\s\\S]*ENDIF[\\s\\S]*-->[\\s|\\S] / , '<!-- NESTED -->' ) , template = template . replace ( '<!-- NESTED -->' , nestedConditionals [ 0 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "util", "/", "stringify", "and", "fix", "bugs"], "add_tokens": "import typify , { LIST , SET , STRING } from './typify' ; export default function stringify ( value , quotationMarks = true ) { } else if ( type === STRING && quotationMarks ) { return '\"' + value + '\"' ;", "del_tokens": "import typify , { LIST , SET } from './typify' ; export default function stringify ( value ) {", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "documentation", "and", "fixed", "field", "and", "parameter", "names"], "add_tokens": "constructor ( indexName , keyPath , unique = false , multiEntry = false ) { this . keyPath = keyPath", "del_tokens": "constructor ( indexName , keyPaths , unique = false , multiEntry = false ) { this . keyPaths = keyPaths", "commit_type": "update"}
{"commit_tokens": ["Made", "inline", "list", "better", "fixed", "issue", "when", "complicated", "obj"], "add_tokens": "return normalizeSchema ( loaded , loader ) ; return normalizeSchema ( rest , loader ) ; } , loader ) ;", "del_tokens": "return normalizeSchema ( loaded ) ; return normalizeSchema ( rest ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "ping", "verify", "check", "to", "make", "sure", "hq", ".", "bridge", "is", "really", "on", "on", "the", "scout"], "add_tokens": "if ( pingInterval < 1500 ) pingInterval = 1500 ; var pingVerify ; if ( o . type == \"ping\" ) { return pingVerify = Date . now ( ) ; } pingVerify = Date . now ( ) ; // ideally we add a hq.isbridging property if ( Date . now ( ) - pingVerify > pingInterval * 2 ) { console . log ( \"<master> ping's have not been verified for \" , Date . now ( ) - pingVerify , 'ms. killing.' ) ; return connected . kill ( \"SIGKILL\" ) ; } if ( verbose ) console . log ( 'verbose!' ) ; s . on ( 'data' , function ( data ) { if ( verbose ) { } try { if ( data && data . type == \"report\" && data . report . type == \"uptime\" ) { process . send ( { type : \"ping\" } ) ; } } catch ( e ) { console . log ( 'worker erroro ' + e + '' ) } } ) ;", "del_tokens": "if ( verbose ) { console . log ( 'verbose!' ) ; s . on ( 'data' , function ( data ) { } ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "Node", ".", "JS", "server", "sample", "file", "with", "documentation", "in", "the", "header"], "add_tokens": "node_port : process . argv [ 2 ] || 3000 , uploadpath : __dirname + '/uploads/' // Direct async xhr stream data upload, yeah baby. var ws = fs . createWriteStream ( tmpfile ) ; console . log ( \"uploadFile() - req.xhr - could not open writestream.\" ) ; callback ( { success : false , error : \"Sorry, could not open writestream.\" } ) ; req . on ( 'data' , function ( data ) {", "del_tokens": "node_port : process . argv [ 2 ] || 3000 , uploadpath : __dirname + '/uploads/' // Direct async xhr stream data upload, yeah baby. var ws = fs . createWriteStream ( tmpfile ) ; console . log ( \"uploadFile() - req.xhr - could not open writestream.\" ) ; callback ( { success : false , error : \"Sorry, could not open writestream.\" } ) ; req . on ( 'data' , function ( data ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "tests", "for", "new", "flatwhite", "component", "structure"], "add_tokens": "var navEntries = $ ( '.test-stylegen-main-nav > ul > li > a' ) ; var childLinks = nav . find ( '.test-stylegen-children' ) ; if ( $ ( '.test-stylegen-preflight' ) . length !== 1 ) {", "del_tokens": "var navEntries = $ ( '.test-stylegen-main-nav > a' ) ; var childLinks = nav . find ( '.children' ) ; if ( $ ( '.preflight-text' ) . length !== 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "logic", "to", "flatten", "grunt", "files", "array"], "add_tokens": "var flattenedArray = [ ] ; var dest = srcDestFileMapping . dest ; srcDestFileMapping . src . forEach ( function ( src ) { flattenedArray . push ( { src : src , dest : dest } ) ; } ) ; gruntFilesMappingList = gruntFilesMappingList . concat ( flattenedArray ) ;", "del_tokens": "gruntFilesMappingList . push ( srcDestFileMapping ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "pre", "-", "hybi", "-", "17", "compatibility"], "add_tokens": "var protocolPrefix = \"HyBi-\" ; options . protocolVersion = options . protocolVersion || protocolVersion ; if ( options . protocolVersion != 8 && options . protocolVersion != 13 ) { throw 'unsupported protocol version' ; } var key = new Buffer ( protocolPrefix + options . protocolVersion ) . toString ( 'base64' ) ; 'Sec-WebSocket-Version' : options . protocolVersion , if ( options . origin ) { if ( options . protocolVersion < 13 ) requestOptions . headers [ 'Sec-WebSocket-Origin' ] = options . origin ; else requestOptions . headers . origin = options . origin ; }", "del_tokens": "var protocol = \"HyBi-17\" ; var key = new Buffer ( protocol ) . toString ( 'base64' ) ; 'Sec-WebSocket-Version' : protocolVersion , if ( options . origin ) requestOptions . headers . origin = options . origin ;", "commit_type": "add"}
{"commit_tokens": ["Added", "saucelabs", "testing", "via", "zuul", "."], "add_tokens": "* @ param { String } name * @ param { Object } options * @ param { Function ( Object ) } options . fn * @ param { Object } options . hash", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "exception", "tests", "and", "fix", "comment", "whitespace", "trimming"], "add_tokens": "input = input . trim ( ) ;", "del_tokens": "// We'll likely want to store the filter rule at this point input = input . trim ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "variable", "call", ".", "generate", "instead", "of", ".", "generateEach"], "add_tokens": "var tasks = setTasks ( app , options . env . configFile , val ) ; app . generate ( tasks , next ) ; function setTasks ( app , configFile , tasks ) { if ( ! exists ( configFile ) ) {", "del_tokens": "app . debug ( 'command > %s: \"%j\"' , key , val ) ; var tasks = setTasks ( app , options . env . configfile , val ) ; app . generateEach ( tasks , next ) ; function setTasks ( app , configfile , tasks ) { if ( ! exists ( configfile ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Changing", "exports", "to", "methods", "only", "."], "add_tokens": "require ( 'directory' ) ( function ( fn , filename ) { module . exports [ filename ] = fn } )", "del_tokens": "module . exports = function ( models ) { require ( 'directory' ) ( function ( module , filename ) { models . plugin ( module , options ) } ) }", "commit_type": "change"}
{"commit_tokens": ["remove", "global", "flag", "from", "the", "re"], "add_tokens": "var re = new RegExp ( delims [ 0 ] + '([\\\\s\\\\S]+?)' + delims [ 1 ] ) ;", "del_tokens": "var re = new RegExp ( delims [ 0 ] + '([\\\\s\\\\S]+?)' + delims [ 1 ] , 'g' ) ;", "commit_type": "remove"}
{"commit_tokens": ["create", "method", "and", "error", "codes"], "add_tokens": "if ( req . accepts ( 'html' ) || req . is ( 'html' ) ) { if ( req . accepts ( 'html' ) || req . is ( 'html' ) ) {", "del_tokens": "if ( req . accepts ( 'html' ) ) { if ( req . accepts ( 'html' ) ) {", "commit_type": "create"}
{"commit_tokens": ["move", "connect", "method", "to", "index"], "add_tokens": "const cayley = require ( 'cayley' ) ; const GET = require ( './lib/cayley_get' ) ; if ( typeof GET [ method ] !== 'function' ) { data . readable = GET [ method ] . apply ( null , query_args ) ; // export the cayley client for custom use connect : ( scope , state , args , data , next ) => { state . client = cayley ( scope . env . db ) ; state . g = state . client . graph ; return next ? next ( null , data ) : data ; } ,", "del_tokens": "const cayley = require ( './lib/cayley' ) ; if ( typeof cayley [ method ] !== 'function' ) { data . readable = cayley [ method ] . apply ( null , query_args ) ; connect : cayley . connect ,", "commit_type": "move"}
{"commit_tokens": ["made", "edges", "point", "from", "there", "origin"], "add_tokens": "' shape = \"plaintext\"\\n' + return { text : str + ': ' + ( v . isList ? '[' + v . type + ']' : v . type ) + deprecationReason , name : v . name + 'port' , } // rows.unshift(\"<B>\" + v.name + \"</B>\"); var result = v . name + ' ' ; result += '[label=<<TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\">' ; result += '<TR><TD><B>' + v . name + '</B></TD></TR>' ; result += rows . map ( function ( row ) { return '<TR><TD PORT=\"' + row . name + '\">' + row . text + '</TD></TR>' ; } ) ; result += '</TABLE>>];' return result ; // return v.name + ' [label=<<TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"><TR><TD>' + rows.join('</TD></TR><TR><TD>') + '</TD></TR></TABLE>>];'; a . push ( v . name + ':' + f . name + 'port' + ' -> ' + f . type ) ;", "del_tokens": "' shape = \"ellipse\"\\n' + return str + ': ' + ( v . isList ? '[' + v . type + ']' : v . type ) + deprecationReason ; rows . unshift ( \"<B>\" + v . name + \"</B>\" ) ; return v . name + ' [label=<' + rows . join ( ' | ' ) + '> shape=\"record\"];' ; a . push ( v . name + ' -> ' + f . type ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "when", "the", "blueprint", "property", "is", "defined", "on", "mainModule"], "add_tokens": "// Create a new application. // Initialize the application. app . init ( ) ;", "del_tokens": "// Create a new application, initialize the application, and return the // application to the caller. app . init ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Adds", ".", "each", "and", "makes", ".", "map", "also", "collect", "result", "."], "add_tokens": "// ## jam.each( array, iterator( next, element, index ) ) // Execute the given `iterator` function for each element given in the `array`. The // iterator is given a `next` function and the element to act on. func . each = function ( array , iterator ) { // Builds another JAM chain internally // ## jam.map( array, iterator( next, element, index ) ) // Works exactly like the `each` helper but if a value is passed to the iterator's // `next` function, it is collected into a new array which will be passed to the next // function in the JAM chain after `map`. func . map = function ( array , iterator ) { ensureArray ( array , 'array' ) ; ensureFunc ( iterator , 'iterator' ) ; return function ( next ) { // Builds another JAM chain internally and collect results. // TODO: Dry with .each? var chain = jam ( jam . identity ) , count = array . length , result = [ ] ; for ( var i = 0 ; i < count ; i ++ ) ( function ( element , i ) { chain = chain ( function ( next , previous ) { result . push ( previous ) ; iterator ( next , element , i ) ; } ) ; } ) ( array [ i ] , i ) ; chain = chain ( function ( next , last ) { result . push ( last ) ; result . shift ( ) ; // discard first undefined element next ( null , result ) ; } ) ; return chain ( next ) ; } ; } ;", "del_tokens": "// ## jam.map( array, iterator( next, element, index ) ) // Execute the given `iterator` for each element given in the `array`. The iterator is // given a `next` function and the element to act on. func . map = function ( array , iterator ) { // Builds another JAM chain internally.", "commit_type": "add"}
{"commit_tokens": ["Updated", "BuildJS", "to", "allow", "optional", "include", "paths"], "add_tokens": "function buildJS ( src , filename , dest , applyHeader , doBrowserSync , forceIncludePaths ) { forceIncludePaths = forceIncludePaths || false ; . pipe ( gulpif ( forceIncludePaths , include ( { includePaths : [ path . dirname ( src ) , __dirname , config . packagesPath ] } ) , include ( ) ) ) < << << << HEAD === === = return buildJS ( config . src . jsPath + '/framework.js' , 'framework.min.js' , config . dist . jsPath , true , true , false ) ; >>> >>> > Updated BuildJS to allow optional include paths return buildJS ( config . docs . src . jsPath + '/docs.js' , 'docs.min.js' , config . docs . dist . jsPath , true , false , true ) ;", "del_tokens": "function buildJS ( src , filename , dest , applyHeader , doBrowserSync ) { . pipe ( include ( { includePaths : [ path . dirname ( src ) , __dirname , config . packagesPath ] } ) ) return buildJS ( config . docs . src . jsPath + '/docs.js' , 'docs.min.js' , config . docs . dist . jsPath , true , false ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "correct", "home", "directory", "on", "windows"], "add_tokens": "var homeEnv = process . platform === 'win32' ? 'USERPROFILE' : 'HOME' ; var portFile = process . env [ homeEnv ] + '/.eslint_d_port' ;", "del_tokens": "var portFile = process . env . HOME + '/.eslint_d_port' ;", "commit_type": "use"}
{"commit_tokens": ["Add", "patchArea", ".", "js", "and", "unchangedArea", ".", "js"], "add_tokens": "var n_pathlogic = 27 ;", "del_tokens": "var n_pathlogic = 20 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "static", "properties", "and", "make", "this", "inside", "static", "methods", "point", "to", "the", "class", "."], "add_tokens": "function wrap ( object , caller ) { return function ( ) { return object . apply ( caller , arguments ) ; } ; clas . init = wrap ( clas . call , ctor ) ; clas . extend = function ( exts ) { for ( var e in exts ) { if ( exts . hasOwnProperty ( e ) ) { var isStatic = e [ 0 ] === '$' , value = exts [ e ] ; if ( typeof value === 'function' ) { clas [ e ] = isStatic ? wrap ( value , clas ) : wrap ( clas . call , clas . prototype [ e ] = value ) ; } else if ( isStatic ) { clas [ e ] = value ; }", "del_tokens": "function wrap ( method ) { return function ( ) { return clas . call . apply ( method , arguments ) ; } ; clas . init = wrap ( ctor ) ; clas . extend = function ( methods ) { for ( var f in methods ) { if ( methods . hasOwnProperty ( f ) ) { clas [ f ] = f [ 0 ] != '$' ? wrap ( clas . prototype [ f ] = methods [ f ] ) : methods [ f ] ;", "commit_type": "add"}
{"commit_tokens": ["move", "safe", "hook", "to", "a", "file"], "add_tokens": "var SafeHook = require ( './lib/safe-hook.js' ) ; type : SafeHook ( 'range' ) , // SafeHook for IE9 + type='range'", "del_tokens": "function SafeHook ( value ) { if ( ! ( this instanceof SafeHook ) ) { return new SafeHook ( value ) ; } this . value = value ; } SafeHook . prototype . hook = function hook ( elem , propName ) { try { elem [ propName ] = this . value ; } catch ( error ) { /* ignore */ } } ; type : SafeHook ( 'range' ) ,", "commit_type": "move"}
{"commit_tokens": ["use", "script", "-", "onload", "component"], "add_tokens": "var onload = require ( 'script-onload' ) ; onload ( script , callback ) ;", "del_tokens": "if ( script . addEventListener ) { script . addEventListener ( 'load' , function ( event ) { callback ( null , event ) ; } , false ) ; script . addEventListener ( 'error' , function ( event ) { callback ( new Error ( 'Failed to load the script.' ) , event ) ; } , false ) ; } else if ( script . attachEvent ) { script . attachEvent ( 'onreadystatechange' , function ( event ) { if ( / complete|loaded / . test ( script . readyState ) ) { callback ( null , event ) ; } } ) ; }", "commit_type": "use"}
{"commit_tokens": ["Use", "a", "proxy", "emitter", "to", "avoid", "going", "over", "maxListeners", "."], "add_tokens": "function checkValidity ( eventSpecs ) { 'use strict' ; } module . exports = checkValidity ;", "del_tokens": "module . exports = function ( eventSpecs ) { } ;", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "check", "to", "see", "if", "a", "mongo", "id", "is", "passed", "in", "and", "created", "an", "objectid", "for", "it", ".", "If", "not", "it", "will", "pass", "it", "through", "."], "add_tokens": "log = config . log , ObjectID = require ( 'mongodb' ) . ObjectID ; var primaryKey = id ; //If the passed in value is a mongo id then create a valid ObjectID. Not doing this will result in matches not being returned. if ( id . match ( / ^[0-9a-fA-F]{24}$ / ) ) { primaryKey = new ObjectID ( id ) ; } database . collection ( COLLECTION_NAME ) . findOne ( { _id : primaryKey } , function ( err , doc ) {", "del_tokens": "log = config . log ; database . collection ( COLLECTION_NAME ) . findOne ( { _id : id } , function ( err , doc ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "various", "configurations"], "add_tokens": "// On focus spec in mocha we need to return the test result and need to", "del_tokens": "// On focus spec in mocha we need to return the test result and need to", "commit_type": "add"}
{"commit_tokens": ["Removing", "sorting", "leaving", "it", "to", "the", "lib"], "add_tokens": "// Perform no sorting", "del_tokens": "// Sort the items by their height items . sort ( function ( a , b ) { if ( b . width === a . width ) { return b . height - a . height ; } return b . width - a . width ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "grunt", "configuration", "instrument", "files", "list", "."], "add_tokens": "files : [ '*.js' , 'lib/*.js' , 'model/*.js' ] ,", "del_tokens": "files : [ 'index.js' , 'config.js' , '**/*.js' ] ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "2", "helpers", ":", "vimeo", "&", "youtube"], "add_tokens": "require ( './pullquote' ) ; require ( './youtube' ) ; require ( './vimeo' ) ;", "del_tokens": "require ( './pullquote' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "docs", "minor", "cleanup", "."], "add_tokens": "var open = buildRegexGroup ( delims [ 0 ] , opts ) ; var close = buildRegexGroup ( delims [ 1 ] , opts ) ; var block = opts . matter + close + opts . body + opts . end ; evaluate : new RegExp ( opts . beginning + open + block , opts . flags ) , interpolate : new RegExp ( opts . beginning + open + '=' + block , opts . flags ) , escape : new RegExp ( opts . beginning + open + '-' + block , opts . flags ) ,", "del_tokens": "opts . open = buildRegexGroup ( delims [ 0 ] , opts ) ; opts . close = buildRegexGroup ( delims [ 1 ] , opts ) ; var block = opts . matter + opts . close + opts . body + opts . end ; evaluate : new RegExp ( opts . beginning + opts . open + block , opts . flags ) , interpolate : new RegExp ( opts . beginning + opts . open + '=' + block , opts . flags ) , escape : new RegExp ( opts . beginning + opts . open + '-' + block , opts . flags ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "duck", "typing", "to", "instanceof", "tests"], "add_tokens": "return ( part instanceof NodePart || ( part && part . getValue !== undefined && typeof part . name === 'undefined' ) ) ; return ( part instanceof AttributePart || ( part && part . getValue !== undefined && typeof part . name !== 'undefined' ) ) ;", "del_tokens": "return part instanceof NodePart || typeof part . name === 'undefined' ; return part instanceof AttributePart || typeof part . name !== 'undefined' ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "import", "{", "props", "}", "from", "@stamp", "/", "shortcut", "utilities", "importing"], "add_tokens": "'use strict' ; return this && this . compose ? this . compose ( param ) : compose ( param ) ;", "del_tokens": "return this . compose ( param ) ;", "commit_type": "allow"}
{"commit_tokens": ["Adds", "CartoDBLayers", ".", "Fixes", "tests", ".", "Adds", "CartoDBLayer", "to", "the", "map", "example"], "add_tokens": "visible : true , type : 'Tiled' type : 'CartoDB' , if ( layer . get ( 'type' ) == \"Tiled\" ) {", "del_tokens": "TILED : 'tiled' , visible : true initialize : function ( ) { this . set ( { 'type' : \"Tile\" } ) ; } , initialize : function ( ) { this . set ( { 'type' : 'CartoDB' } ) ; } , if ( layer . get ( 'type' ) == \"Tile\" ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "failure", "when", "passing", "non", "quantity", "to", "isCompatible"], "add_tokens": "if ( ! ( other instanceof Qty ) ) { return false ; } if ( other . signature !== undefined ) {", "del_tokens": "else if ( other . signature !== undefined ) {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "search", "button", "control", "."], "add_tokens": "' <input type=\"text\" class=\"form-control\" name=\"text2search\" id=\"text2search\"\\n' + ' maxlength=\"13\" placeholder=\"' + ctx . t ( 'search' ) + '\">\\n' + ' <button type=\"submit\" class=\"btn btn-default\" id=\"btnSearch\" disabled=\"disabled\">\\n' +", "del_tokens": "' <input type=\"text\" class=\"form-control\" name=\"text2search\" placeholder=\"' + ctx . t ( 'search' ) + '\">\\n' + ' <button type=\"submit\" class=\"btn btn-default\">\\n' +", "commit_type": "add"}
{"commit_tokens": ["Fix", "bundle", "loading", "on", "production", "middleware"], "add_tokens": "var bundles = trees . config . bundles . reduce ( function ( acc , bundle ) { acc [ bundle . id ] = bundle ; return acc ; } , { } ) ; bundles [ params . bundle ]", "del_tokens": "trees . config . bundles [ params . bundle ]", "commit_type": "fix"}
{"commit_tokens": ["added", "gulp", "task", "to", "clean", "paper", "bootstrap", "css", "font", "import"], "add_tokens": "var deleteLines = require ( 'gulp-delete-lines' ) ; 'bower_components/bootstrap/dist/css/bootstrap-theme.min.css' , bower_clean_paper_boostrap_css : [ 'bower_components/bootswatch/paper/bootstrap.css' ] , //particular cases : example : bootsrap paper theme from bootswatch (need to clean #import font from googleapi) gulp . src ( paths . bower_clean_paper_boostrap_css , { cwd : bases . app } ) . pipe ( deleteLines ( { 'filters' : [ / ^@import url / ] } ) ) . pipe ( concat ( 'bootstrap.min.css' ) ) . pipe ( cssmin ( ) ) . pipe ( gulp . dest ( bases . app + 'public/lib/css/' ) ) ;", "del_tokens": "'bower_components/bootstrap/dist/css/bootstrap-theme.min.css' , 'bower_components/bootswatch/paper/bootstrap.min.css' ,", "commit_type": "add"}
{"commit_tokens": ["update", "schema", "move", "definition", "to", "under", "routes", "property"], "add_tokens": "_ . forEach ( opts . enroute . routes , function ( methods , routeName ) {", "del_tokens": "_ . forEach ( opts . enroute , function ( methods , routeName ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "tests", "for", "compareHtmlAttrsAsJSON", "option"], "add_tokens": "htmlDiffer . isEqual ( files . html1 , files . html2 ) . must . be . true ( ) ; it ( 'must sort content of attrs' , function ( ) { var files = readFiles ( '6.html' , '_6.html' ) ; htmlDiffer . isEqual ( files . html1 , files . html2 , { compareHtmlAttrsAsJSON : [ 'a' , 'b' ] } ) . must . be . true ( ) ; } ) ;", "del_tokens": "htmlDiffer . isEqual ( files . html1 , files . html2 , { ignoreHtmlAttrs : [ 'id' , 'for' ] } ) . must . be . true ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "published", "docs", "and", "rerunning", "all", "tests", "."], "add_tokens": "this . emptyLine = m . char ( ' \\t' ) . zeroOrMore . then ( m . newLine ) . ast ; this . simpleLine = m . seq ( this . emptyLine . not , this . specialLineStart . not , m . notEnd , this . restOfLine ) . ast ; this . content = m . choice ( this . heading , this . list , this . quote , this . codeBlock , this . paragraph , this . emptyLine ) ;", "del_tokens": "this . simpleLine = m . seq ( this . specialLineStart . not , m . notEnd , this . restOfLine ) . ast ; this . content = m . choice ( this . heading , this . list , this . quote , this . codeBlock , this . paragraph ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "multithread", "and", "multiple", "targets", "support"], "add_tokens": "return new GDB ( child ) it ( 'executes custom python code and returns results' , async ( ) => { await gdb . init ( ) let res = await gdb . execPy ( 'print(\"Hello\\\\nWorld!\")' ) expect ( res ) . to . equal ( 'Hello\\nWorld!\\n' ) // TODO: the example with multiple files will make more sense", "del_tokens": "return new GDB ( child , { token : 'GDBJS^' } ) it ( 'executes custom python code' , async ( ) => { await gdb . execPy ( 'print(\"Hello World!\")' )", "commit_type": "add"}
{"commit_tokens": ["Adding", "hooks", "for", "plugins", "to", "attach", "to", "jsPDF", "instantiator", "."], "add_tokens": "function jsPDF ( /** String */ orientation , /** String */ unit , /** String */ format ) { // applying plugins (more methods) on top of built-in API. // this is intentional as we allow plugins to override // built-ins if ( jsPDF . API ) { var api = jsPDF . API , plugin for ( plugin in api ) { if ( api . hasOwnProperty ( plugin ) ) { _jsPDF [ plugin ] = api [ plugin ] } } } jsPDF . API = { }", "del_tokens": "var jsPDF = function ( /** String */ orientation , /** String */ unit , /** String */ format ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "wrapper", "function", "in", "between", "the", "user", "defined", "method", "and", "ObjC", "land", ".", "Makes", "the", "tests", "/", "extend", ".", "js", "test", "work", "."], "add_tokens": ", rtnType = parsed [ 0 ] , argTypes = parsed [ 1 ] , ffiCb = new core . Callback ( types . convert ( parsed ) , wrapper ) , self = this // the wrapper function is required to wrap passed in arguments and to unwrap // the return value (when necessary). function wrapper ( ) { var args = core . wrapValues ( arguments , argTypes ) , rtn = callback . apply ( self , args ) return core . unwrapValue ( rtn , rtnType ) }", "del_tokens": ", ffiCb = new core . Callback ( types . convert ( parsed ) , callback )", "commit_type": "add"}
{"commit_tokens": ["adds", "conversion", "to", "8", "-", "bit", "tiff"], "add_tokens": "module . exports = function ( infile , outfile , callback ) { wmtiff ( infile , outfile , callback ) ; } ;", "del_tokens": "module . exports = wmtiff ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "bunch", "of", "stuff"], "add_tokens": "consensus . block = function ( params , callback ) { qs : params", "del_tokens": "consensus . block = function ( height , callback ) { qs : { height : height }", "commit_type": "add"}
{"commit_tokens": ["Add", "exports", "for", "signature", "verification"], "add_tokens": "// For signature verification in KeyPair.js nacl . gf = gf ; nacl . unpackneg = unpackneg ; nacl . reduce = reduce ; nacl . scalarmult = scalarmult ; nacl . scalarbase = scalarbase ; nacl . add = add ; nacl . pack = pack ;", "del_tokens": "nacl . verifySIgnature = function ( msg , sig , publicKey ) { checkArrayTypes ( msg , sig , publicKey ) ; if ( sig . length !== crypto_sign_BYTES ) console . log ( sig . length ) ; throw new Error ( 'bad signature size' ) ; if ( publicKey . length !== crypto_sign_PUBLICKEYBYTES ) throw new Error ( 'bad public key size' ) ; var sm = new Uint8Array ( crypto_sign_BYTES + msg . length ) ; var m = new Uint8Array ( crypto_sign_BYTES + msg . length ) ; var i ; for ( i = 0 ; i < crypto_sign_BYTES ; i ++ ) sm [ i ] = sig [ i ] ; for ( i = 0 ; i < msg . length ; i ++ ) sm [ i + crypto_sign_BYTES ] = msg [ i ] ; return ( crypto_sign_open ( m , sm , sm . length , publicKey ) >= 0 ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "remaining", "database", "tables", ".", "NB", "these", "changes", "are", "added", "into", "the", "existing", "migration", "001", "so", "any", "existing", "database", "will", "have", "to", "be", "dropped"], "add_tokens": "client . query ( 'TRUNCATE ' + tableName + ' CASCADE' , function ( err , result ) {", "del_tokens": "client . query ( 'TRUNCATE ' + tableName , function ( err , result ) {", "commit_type": "add"}
{"commit_tokens": ["added", "change", "for", "steps", "."], "add_tokens": "logger . info ( \"Approving openSTValue contract with \" , toDisplayST ( toStakeAmount ) ) ; logger . info ( \"Current Allowance:\" , allowance ) ;", "del_tokens": "logger . info ( \"Approving StakingContract with \" , toDisplayST ( toStakeAmount ) ) ; logger . info ( \"Current Allowance:\" , allowance ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "TeoriaInterval#simple", "to", "work", "with", "weird", "intervals"], "add_tokens": "// Get the (upwards) base interval (with quality) var simple = intervals [ this . base ( ) ] ; simple = add ( simple , mul ( sharp , this . qualityValue ( ) ) ) ; // Turn it around if necessary if ( ! ignore ) simple = this . direction ( ) === 'down' ? mul ( simple , - 1 ) : simple ; return new TeoriaInterval ( simple ) ;", "del_tokens": "var number = this . value ( ) ; if ( number > 8 || number < - 8 ) number = number % 7 || ( number > 0 ? 7 : - 7 ) ; var str = this . quality ( ) + ( ignore ? Math . abs ( number ) : number ) ; return teoria . interval ( str ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", ".", "git", "to", "defaults"], "add_tokens": "var _ignoreList = [ '.hostrignore' , 'node_modules' , '.git' ] ;", "del_tokens": "var _ignoreList = [ '.hostrignore' , 'node_modules' ] ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "regexp", "detection", "fail", "in", "Safari", "Opera", "and", "Firefox", ":", "("], "add_tokens": "if ( tweet === undefined ) return '' ; } else if ( ( { } ) . toString . call ( search [ 'not' ] ) !== '[object Array]' ) {", "del_tokens": "} else if ( typeof search [ 'not' ] == 'function' ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "gulp", "-", "mocha", "and", "changed", "default", "test", "script", "in", "package", ".", "json"], "add_tokens": "var mocha = require ( 'gulp-mocha' ) ; var handleMochaError = function ( err ) { console . log ( 'Mocha encountered an error, exiting with status 1' ) ; console . log ( 'Error:' , err . message ) ; process . exit ( 1 ) ; } ; gulp . task ( 'lint' , function ( ) { gulp . task ( 'mocha' , function ( ) { var mochaErr ; return gulp . src ( [ 'test/**/*.js' ] , { read : false } ) . pipe ( mocha ( { reporter : 'nyan' } ) ) . on ( 'error' , function ( err ) { console . error ( 'ERROR:' , err . message ) ; console . error ( 'Stack:' , err . stack ) ; mochaErr = err ; } ) . on ( 'end' , function ( ) { if ( mochaErr ) return handleMochaError ( mochaErr ) ; // Force mocha to exit, because gulp-mocha is stupid. process . exit ( ) ; } ) ; ; } ) ;", "del_tokens": "gulp . task ( 'lint' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "aliases", "to", "named", "types", "."], "add_tokens": "* correct schema , especially when it contains type references . // Create a record type. { name : 'age' , type : 'int' }", "del_tokens": "* correct schema . // Integer type with custom random generator. var ageType = new avsc . types . PrimitiveType ( 'int' ) ; ageType . random = function ( ) { return 100 * Math . random ( ) ; } ; // Create a new record type with this age field. { name : 'age' , type : ageType }", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "override", "Model", "clear", "()", "function"], "add_tokens": "* Clear the document data . This can be overridden at schema level using < code > Schema . set ( ) < / code>. if ( typeof this . schema . options . clear === 'function' ) { this . schema . options . clear . call ( this ) ; } else { _ . each ( this . schema . descriptor , ( properties , index ) => { clearField . call ( this [ _privateKey ] . _this , index , properties ) ; } ) ; }", "del_tokens": "* Clear the document data . _ . each ( this . schema . descriptor , ( properties , index ) => { clearField . call ( this [ _privateKey ] . _this , index , properties ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "control", "to", "containerSelector", "option", "."], "add_tokens": "this . options = StickySidebar . extend ( DEFAULTS , options ) ; this . container = this . sidebar . parentElement ; // Container wrapper of the sidebar. if ( this . options . containerSelector ) { var containers = document . querySelectorAll ( this . options . containerSelector ) ; containers . forEach ( ( container , item ) => { if ( ! container . contains ( this . sidebar ) ) return ; this . container = container ; } ) ; if ( ! containers . length ) throw new Error ( \"The container does not contains on the sidebar.\" ) ; } element . style . position = 'relative' ; for ( let key in defaults ) {", "del_tokens": "this . options = StickySidebar . extend ( StickySidebar . DEFAULTS , options ) ; this . container = null ; // Sidebar container element. var containers = document . querySelectorAll ( this . options . containerSelector ) ; containers . forEach ( ( container , item ) => { if ( ! container . contains ( this . sidebar ) ) return ; this . container = container ; } ) ; if ( null === this . container ) throw new Error ( \"The container does not contains on the sidebar.\" ) ; if ( 'static' == getComputedStyle ( element ) . position ) element . style . position = 'relative' ; for ( key in defaults ) {", "commit_type": "add"}
{"commit_tokens": ["update", "websocket", "-", "broker", ".", "js"], "add_tokens": "onnewthing : function ( ) { return 0 ; } , onstart : function ( ) { return 0 ; }", "del_tokens": "onnewthing : function ( ) { return 0 ; }", "commit_type": "update"}
{"commit_tokens": ["use", "merge", "instead", "of", "extend", "add", "isGenerator", "util"], "add_tokens": "require ( 'mixin-deep' , 'merge' ) ; utils . isGenerator = function ( val ) { return utils . isApp ( val , 'Generator' ) ; } ;", "del_tokens": "require ( 'extend-shallow' , 'extend' ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "comments", "around", "our", "dirty", "bit", "management"], "add_tokens": "// then we can never get back to a non-dirty state. // Make sure we can't undo back to the previous content. // This should be 0, but just to be safe... // Remember which position in the undo stack we're at as of the last save. // When we're exactly at that position again, we know we're not dirty.", "del_tokens": "// TODO: This doesn't currently work properly with undo because of brackets-app issue #9. // So files get dirty, but they never get un-dirty. // then we can never get back to non-dirty state.", "commit_type": "add"}
{"commit_tokens": ["removed", "old", "encode", "/", "decode", "functions"], "add_tokens": "} ;", "del_tokens": "var w_json = new Worker ( 'submitJobDelayedJson' , function ( payload , worker ) { try { var task = gearsloth . decodeJsonTask ( payload ) ; save ( task , worker ) ; } catch ( err ) { logger . err ( err ) ; } } ) ; } ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "bug", "in", "api", "sobject", "and", "improve", "error", "handling"], "add_tokens": "if ( ! api ) return this . onError ( { error_code : 21 , message : this . req . params . name + \" is not implemented in Proxy\" } ) ; else return this . onError ( { error_code : 21 , message : api + \" is not implemented in Proxy\" } ) ;", "del_tokens": "if ( ! api ) return this . onError ( { error_code : 21 , message : this . req . params . name + \" is not available\" } ) ; else return this . onError ( { error_code : 21 , message : api + \" is not available\" } ) ;", "commit_type": "fix"}
{"commit_tokens": ["move", "amd", "to", "the", "end"], "add_tokens": "] , function ( franky ) {", "del_tokens": "] , function ( franky ) {", "commit_type": "move"}
{"commit_tokens": ["Change", "from", "relative", "to", "absolute", "paths", "for", "tempDir"], "add_tokens": "var outputDir = path . resolve ( path . join ( process . cwd ( ) , options . tempDir || 'assets' ) ) ; var tempDir = path . resolve ( path . join ( process . cwd ( ) , this . options . tempDir || 'assets' ) ) ;", "del_tokens": "var outputDir = path . resolve ( options . tempDir || 'assets' ) ; var tempDir = this . options . tempDir || \"assets\" ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "scale", "issue", "when", "moving", "annotations"], "add_tokens": "let svg = findSVGContainer ( target [ 0 ] ) ; deltaX : OVERLAY_BORDER_SIZE + scrollLeft + scaleDown ( svg , { x : overlay . offsetLeft - offsetLeft } ) . x - x , deltaY : OVERLAY_BORDER_SIZE + scrollTop + scaleDown ( svg , { y : overlay . offsetTop - offsetTop } ) . y - y } ; let { deltaX , deltaY } = getDelta ( 'x' , 'y' ) ;", "del_tokens": "let svg = findSVGAtPoint ( e . clientX , e . clientY ) ; deltaY : OVERLAY_BORDER_SIZE + scrollTop + ( overlay . offsetTop - offsetTop ) - y , deltaX : OVERLAY_BORDER_SIZE + scrollLeft + ( overlay . offsetLeft - offsetLeft ) - x } // TODO Scale is off when dragging annotation position let { deltaY , deltaX } = getDelta ( 'x' , 'y' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "window", "path", "to", "be", "platform", "aka", "travis", "generic"], "add_tokens": "folder = module . exports . outputDir + '/assets' ;", "del_tokens": "folder = module . exports . outputDir + '\\\\assets' ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "another", "test", "for", "get", "-", "code", "clean", "up", "jshint", "issues", "."], "add_tokens": "var absval ; absval = Math . abs ( val ) ; absval = Math . abs ( val ) ; for ( var encIdx in amqpType . encodings ) { var curEncoding = amqpType . encodings [ encIdx ] ;", "del_tokens": "var absval = Math . abs ( val ) ; var absval = Math . abs ( val ) ; for ( var idx in amqpType . encodings ) { var curEncoding = amqpType . encodings [ idx ] ;", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "tests", "by", "readding", "the", "parameters"], "add_tokens": "var promise = loadBank ( ctx , this . nameToUrl ( name ) , undefined , undefined , notes ) . then ( function ( buffers ) {", "del_tokens": "var promise = loadBank ( ctx , this . nameToUrl ( name ) , notes ) . then ( function ( buffers ) {", "commit_type": "fix"}
{"commit_tokens": ["moved", "order", "of", "CORS", "CORS", "is", "now", "allowed", "before", "cloudcomponent", "is", "initiated"], "add_tokens": "var twitterCloudComponent = require ( \"./api/twitterCloudComponent\" ) ; app . use ( \"/twitter\" , twitterCloudComponent ) ;", "del_tokens": "var twitterCloudComponent = require ( \"./api/twitterCloudComponent\" ) ; app . use ( \"/twitter\" , twitterCloudComponent ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "method", "names", "for", "better", "semantics", "."], "add_tokens": "const depth = ( this . tree !== null ) ? this . tree . depth ( ) : - 1 ; octants = this . tree . findOctantsByLevel ( level ) ;", "del_tokens": "const depth = ( this . tree !== null ) ? this . tree . getDepth ( ) : - 1 ; octants = this . tree . getOctantsByLevel ( level ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "bug", "in", "path", "based", "sampling", "where", "null", "parameter", "would", "not", "match", "any", "rule", "."], "add_tokens": "// Any null parameters provided will be considered an implicit match. if ( rule . default || ( serviceName == null || ( Utils . wildcardMatch ( rule . service_name , serviceName ) ) && ( httpMethod == null || Utils . wildcardMatch ( rule . http_method , httpMethod ) ) && ( urlPath == null || Utils . wildcardMatch ( rule . url_path , urlPath ) ) ) ) {", "del_tokens": "if ( rule . default || ( Utils . wildcardMatch ( rule . service_name , serviceName ) && Utils . wildcardMatch ( rule . http_method , httpMethod ) && Utils . wildcardMatch ( rule . url_path , urlPath ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "getters", "and", "setters", "section", "to", "the", "README", "."], "add_tokens": "var inherits = require ( 'inherits' ) ; Test . prototype . end = function ( err ) { } , { \"/Users/philipwalton/Projects/mozart/node_modules/browserify/node_modules/insert-module-globals/node_modules/process/browser.js\" : 8 , \"deep-equal\" : 40 , \"defined\" : 43 , \"events\" : 6 , \"inherits\" : 44 , \"path\" : 9 , \"stream\" : 11 } ] , 40 : [ function ( require , module , exports ) {", "del_tokens": "var inherits = require ( 'util' ) . inherits ; Test . prototype . end = function ( err ) { } , { \"/Users/philipwalton/Projects/mozart/node_modules/browserify/node_modules/insert-module-globals/node_modules/process/browser.js\" : 8 , \"deep-equal\" : 40 , \"defined\" : 43 , \"events\" : 6 , \"path\" : 9 , \"stream\" : 11 , \"util\" : 19 } ] , 40 : [ function ( require , module , exports ) {", "commit_type": "add"}
{"commit_tokens": ["changed", "to", "not", "settings", "when", "undefined", "&", "add", "files", "and", "ignore", "option"], "add_tokens": "options . require = options . require || [ ] ; var files = ( options . files || [ ] ) . concat ( ( options . getFiles && options . getFiles ( ) ) || [ ] ) ; var requires = _getRequiresFromFiles ( files ) ; var ignore = options . ignore || [ ] ; if ( _ ( ignore ) . contains ( require ) ) return ; if ( _ ( ignore ) . contains ( require ) ) return ;", "del_tokens": "options . require = options . require || utils . componentNames ( _workdir ) ; var files = options . getFiles ( ) var requires = _getRequiresFromFiles ( files )", "commit_type": "change"}
{"commit_tokens": ["Fix", "to", "ACLCollection", "roles", "mapping"], "add_tokens": "if ( ! actor ) return roles ; var canAccess = this . canAccess ( options . action , options . actor ) ;", "del_tokens": "if ( ! actor || ! model ) return roles ; var canAccess = this . canAccess ( options . action , options . actor , this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "the", "close", "callback", "wasn", "t", "called", "in", "newer", "version", "of", "node"], "add_tokens": "return null ; return next ( ) ; return enumerateBefore ( beforeList ) ; self . __server = undefined ; if ( ! this . __server ) { return null ; } if ( oldVersion ) { return null ;", "del_tokens": "return ; next ( ) ; enumerateBefore ( beforeList ) ; this . __server = undefined ; if ( ! this . __server ) { return ; } if ( ! oldVersion ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "bug", "w", "/", "the", "loop", "causing", "a", "null", "exception", "."], "add_tokens": "for ( var i = 0 ; i < hiddenElements . length ; i ++ ) {", "del_tokens": "for ( var i = 0 ; hiddenElements . length ; i ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "errors", "reducer", "to", "correctly", "update", "on", "LISTENER_ERROR", "dispatch", "-", "https", ":", "//", "github", ".", "com", "/", "prescottprue", "/", "react", "-", "redux", "-", "firebase", "/", "issues", "/", "386"], "add_tokens": "if ( ! meta ) { case LISTENER_ERROR : return [ ... state , pathFromMeta ( meta ) ] ; return state . filter ( lId => lId !== pathFromMeta ( meta ) ) ; if ( ! meta ) { const listenerPath = pathFromMeta ( meta ) ; [ listenerPath ] : payload , const errorObj = { id : meta . id , error : payload } ; [ listenerPath ] : state [ listenerPath ] ? [ ... state [ listenerPath ] , errorObj ] : [ errorObj ] , return { ... state , [ listenerPath ] : [ ] , } ; return { ... state , [ listenerPath ] : state [ listenerPath ] . filter ( lId => lId !== meta . id ) , } ;", "del_tokens": "if ( ! meta || ! meta . id ) { return [ ... state , meta . id ] ; return state . filter ( lId => lId !== meta . id ) ; if ( ! meta || ! meta . id ) { [ meta . id ] : payload , [ pathFromMeta ( meta ) ] : payload , return [ ] ; return state . filter ( lId => lId !== payload . id ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "Edits", "button", "to", "Edit"], "add_tokens": "inner_html += '<div class=\"col-xs-6 col-md-2 col-lg-1 text-right no-side-pad pad-bottom\"><a href=\"/' + conn_name + \"/\" + db_name + \"/\" + coll_name + \"/edit/\" + data [ i ] . _id + '?type=' + typeof data [ i ] . _id + '\" class=\"btn btn-success btn-sm\">Edit</a></div>' ;", "del_tokens": "inner_html += '<div class=\"col-xs-6 col-md-2 col-lg-1 text-right pad-bottom\"><a href=\"/' + conn_name + \"/\" + db_name + \"/\" + coll_name + \"/edit/\" + data [ i ] . _id + '?type=' + typeof data [ i ] . _id + '\" class=\"btn btn-success btn-sm\">Edits</a></div>' ;", "commit_type": "change"}
{"commit_tokens": ["use", "config", "from", "d3", "-", "loom"], "add_tokens": "import babelrc from 'babelrc-rollup' let external = Object . keys ( pkg . dependencies ) external , babel ( babelrc ( ) ) globals : { 'd3-collection' : 'd3' , 'd3-array' : 'd3' , 'd3-interpolate' : 'd3' , 'd3-path' : 'd3' } globals : { 'd3-collection' : 'd3' , 'd3-array' : 'd3' , 'd3-interpolate' : 'd3' , 'd3-path' : 'd3' } external , plugins : [ babel ( babel ( babelrc ( ) ) ) ]", "del_tokens": "external : [ 'd3-array' , 'd3' , 'd3-collection' , 'd3-shape' ] , babel ( { exclude : [ 'node_modules/**' ] } ) globals : [ 'd3-array' , 'd3' , 'd3-collection:d3' , 'd3-shape:d3' ] globals : [ 'd3-array' , 'd3' , 'd3-collection:d3' , 'd3-shape:d3' ] external : [ 'd3-array' , 'd3' , 'd3-collection' , 'd3-shape' ] , plugins : [ babel ( { exclude : [ 'node_modules/**' ] } ) ]", "commit_type": "use"}
{"commit_tokens": ["Updated", "tests", "for", "termination", "conditions"], "add_tokens": "validateArgs ( goodUrl , { resume : false } , ( err , data ) => assert . fail ( 'Unexpected error: ' + err . message ) ) ;", "del_tokens": "validateArgs ( goodUrl , { resume : true } , ( err , data ) => assert . fail ( 'Unexpected error: ' + err . message ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "info", "to", "README", ".", "Renamed", "test", "to", "sample"], "add_tokens": "console . log ( '\\n\\nRegular console' ) ; console . log ( '---------------\\n' ) ; console . log ( '--------------------------------------\\n' ) ; require ( './index' ) . enhance ( logLevel ) ;", "del_tokens": "// Dependency var econsole = require ( './index' ) console . log ( '\\n\\nRegular console\\n' ) ; console . log ( '---------------' ) ; console . log ( '--------------------------------------' ) ; econsole . enhance ( logLevel )", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "update", "a", "status", "with", "a", "callback", "function"], "add_tokens": "const payloadResult = typeof payload === 'function' ? payload ( nextValues [ name ] ) : payload ; nextValues [ name ] = { ... nextValues [ name ] , ... payloadResult } ;", "del_tokens": "nextValues [ name ] = { ... nextValues [ name ] , ... payload } ;", "commit_type": "allow"}
{"commit_tokens": ["added", "node", "version", "to", "package", ".", "js"], "add_tokens": ". version ( '0.2.2' )", "del_tokens": ". version ( '0.2.1' )", "commit_type": "add"}
{"commit_tokens": ["Remove", "pagination", "controls", "if", "page", "count", "drops", "below", "two"], "add_tokens": "var defaultLinkGroupSize = 3 , defaultClientLimit = 250 , defaultPerPage = 50 ; $scope . linkGroupSize = typeof lgs === 'number' ? lgs : defaultLinkGroupSize ; $scope . clientLimit = typeof cl === 'number' ? cl : defaultClientLimit ; for ( i = Math . min ( 3 , quantizedIndex ( $scope . perPage || defaultPerPage ) ) ; $scope . numItems = 0 ; $scope . numPages = Math . ceil ( $scope . numItems / ( $scope . perPage || defaultPerPage ) ) ; var pp = $scope . perPage || defaultPerPage ; var pp = quantize ( $scope . perPage || defaultPerPage ) ;", "del_tokens": "$scope . paginated = false ; $scope . linkGroupSize = typeof lgs === 'number' ? lgs : 3 ; $scope . clientLimit = typeof cl === 'number' ? cl : 250 ; for ( i = Math . min ( 3 , quantizedIndex ( $scope . perPage || 250 ) ) ; $scope . numPages = $scope . numItems = 0 ; $scope . paginated = true ; $scope . numPages = Math . ceil ( response . total / ( $scope . perPage || 1 ) ) ; var pp = $scope . perPage || 100 ; var pp = quantize ( $scope . perPage || 100 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "$schema", "keyword", "in", "root"], "add_tokens": "let schema = schemaForm ( canonical ) ; schema = addRootKeywords ( schema ) ; cb ( err , schema ) ; function addRootKeywords ( schema ) { schema [ '$schema' ] = 'http://json-schema.org/draft-04/schema#' ; return schema ; }", "del_tokens": "cb ( err , schemaForm ( canonical ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "local", "tests", "and", "expand", "file", "assert", "coverage", "."], "add_tokens": ". withOptions ( { 'skip-install' : true , projectName : 'drupal8' , projectDescription : 'test drupal8 project' , drupalDistroVersion : '8.x' // Distribution-specific makefile. // gtd scaffolding dotfiles are copying. 'src/modules/.gitkeep' , // General-purpose behat.yml is not overridden. 'test/behat.yml' , // Behat example tests are present.", "del_tokens": ". withOptions ( { 'skip-install' : true } ) . withPrompt ( { 'drupalDistroVersion-drupal' : '8.0.x'", "commit_type": "fix"}
{"commit_tokens": ["Adds", "maxHeight", "prop", "to", "chatfeed"], "add_tokens": "messages : [ new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( { maxHeight : 250 ,", "del_tokens": "messages : [ new _lib . Message ( { id : 1 , message : 'Hey guys!' , senderName : 'Mark' } ) , new _lib . Message ( {", "commit_type": "add"}
{"commit_tokens": ["fixed", "Firefox", "issue", "in", "accordion"], "add_tokens": "window . event . cancelBubble = true ; window . event . cancelBubble = true ; window . event . cancelBubble = true ;", "del_tokens": "window . event . cancelBubble = true ; window . event . cancelBubble = true ; window . event . cancelBubble = true ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "broken", "node", "text", "select", "feature"], "add_tokens": "item . drag (", "del_tokens": "shape . drag (", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "functionality", "to", "the", "quick", "-", "run", "tool"], "add_tokens": "'read(\"HARDWARE_INSTALLED\")' , 'write(\"WIFI_SSID_DEFAULT\", \"5PoundBass\")' , 'open(\"LJM_dtT7\",\"LJM_ctUSB\",\"LJM_idANY\")' , 'open(\"LJM_dtT7\",\"LJM_ctUSB\",\"LJM_idANY\")' , 'read(\"WIFI_IP\")' , 'listAll(\"LJM_dtT7\",\"LJM_ctWiFi\")' , ] configureWifiTJ = [ 'open(\"LJM_dtT7\",\"LJM_ctUSB\",\"LJM_idANY\")' , 'write(\"POWER_WIFI\",0)' , 'write(\"WIFI_SSID_DEFAULT\", \"linksys-johnson-hifi\")' , 'write(\"WIFI_PASSWORD_DEFAULT\", \"timmarychriskevin\")' , 'write(\"WIFI_DHCP_ENABLE_DEFAULT\",0)' , 'write(\"WIFI_APPLY_SETTINGS\",1)' , 'write(\"POWER_WIFI\",1)' , 'close()' configureWifiTJ , // 10", "del_tokens": "'write(\"WIFI_SSID_DEFAULT\", \"5poundbass\")' , 'open(\"LJM_dtT7\",\"LJM_ctANY\",\"470010533\")' , 'open(\"LJM_dtT7\",\"LJM_ctANY\",\"470010533\")' , 'listAll(\"LJM_dtT7\",\"LJM_ctANY\")' ,", "commit_type": "add"}
{"commit_tokens": ["use", "setState", "/", "getState", "from", "react", "-", "mixin", "-", "manager"], "add_tokens": "var getState = React . mixins . getState ; var setState = React . mixins . setState ; / ** * Return the model specified by a ReactComponent property key * /", "del_tokens": "function setState ( state , context ) { if ( context . isMounted ( ) ) { context . setState ( state ) ; } else if ( context . state ) { _ . extend ( context . state , state ) ; } else { // if we aren't mounted, we will get an exception if we try to set the state // so keep a placeholder state until we're mounted // this is mainly useful if setModel is called on getInitialState context . __react_backbone_state = _ . extend ( context . __react_backbone_state || { } , state ) ; } } function getState ( key , context ) { var state = context . state , initState = context . __react_backbone_state ; return ( state && state [ key ] ) || ( initState && initState [ key ] ) ; }", "commit_type": "use"}
{"commit_tokens": ["Updated", "test", "fixed", "bugs", "and", "added", "new", "challenger", "leagues", "endpoint"], "add_tokens": "lollib . prototype . getChallengerLeagueByGametype = function ( region , type , cb ) { var url = this . generateUrl ( { region : region , path : '/v2.3/league/challenger' , query : { type : type } } ) ; // https://prod.api.pvp.net/api/lol/euw/v2.3/league/challenger?type=RANKED_SOLO_5x5&api_key=94f44207-a683-4b27-a7da-790a3ef66c6c this . makeRequest ( url , cb ) ; } ; /* DDragon Private API */ lollib . prototype . getChampionsData = function ( version , locale , cb ) { 'TUTORIAL_GAME' : 'Tutorial game' , 'RANKED_SOLO_5x5' : 'Ranked SoloQ' , 'RANKED_TEAM_5x5' : 'Ranked Team 5v5' , 'RANKED_TEAM_3x3' : 'Ranked Team 3v3'", "del_tokens": "lollib . prototype . getChampions = function ( version , locale , cb ) { 'TUTORIAL_GAME' : 'Tutorial game'", "commit_type": "update"}
{"commit_tokens": ["Update", "for", "createClient", "fix", "."], "add_tokens": "// this.logger('RollingSpider#createClient');", "del_tokens": "this . logger ( 'RollingSpider#createClient' ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "hoist", "-", "non", "-", "react", "-", "statics"], "add_tokens": "// Recompile pre-existing getInitialProps", "del_tokens": "// import hoistNonReactStatic from 'hoist-non-react-statics' // Recompile pre-existing pageProps // if (WrappedComponent.getInitialProps) { // pageProps = { // ...pageProps, // ...await WrappedComponent.getInitialProps(ctx), // } // } // ... and renders the wrapped component with the fresh data! // Notice that we pass through any additional props", "commit_type": "remove"}
{"commit_tokens": ["Use", "grunt", "instead", "of", "makefile"], "add_tokens": "( function ( undefined ) { 'use strict' ; Struct . _handlerMaker = function ( obj , props ) { var checker = Struct . typeChecker ; if ( name in props || name === INSPECTOR_PROP_NAME ) { if ( isNullOrUndefined ( val ) || Struct . isStructType ( type , val ) || Struct . util . isType ( type , val ) ) { } ; function isNullOrUndefined ( val ) { return val === null || val === undefined ; } ) ( ) ;", "del_tokens": "function handlerMaker ( obj , props ) { if ( name in props || name == INSPECTOR_PROP_NAME ) { if ( isNullOrUndefined ( val ) || isStructType ( type , val ) || isType ( type , val ) ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "the", "ability", "to", "check", "unique", "of", "a", "flat", "array"], "add_tokens": "if ( key ) { var hashCheck = { } ; for ( i in items ) { var value = items [ i ] [ key ] ; if ( typeof ( hashCheck [ value ] ) !== 'undefined' ) { delete items [ i ] ; } else { hashCheck [ value ] = true ; } } } else { var o = { } , i , l = items . length , r = [ ] ; for ( i = 0 ; i < l ; i += 1 ) { o [ items [ i ] ] = items [ i ] ; } for ( i in o ) { r . push ( o [ i ] ) ; items = r ;", "del_tokens": "var hashCheck = { } ; for ( i in items ) { var value = items [ i ] [ key ] ; if ( typeof ( hashCheck [ value ] ) !== 'undefined' ) { delete items [ i ] ; } else { hashCheck [ value ] = true ;", "commit_type": "add"}
{"commit_tokens": ["Use", "BN", ".", "toBuffer", "()"], "add_tokens": "return num . toBuffer ( 'be' , 32 ) ; return toTwos ( num ) . toBuffer ( 'be' , 32 ) ;", "del_tokens": "return new Buffer ( num . toArray ( 'be' , 32 ) ) ; return new Buffer ( toTwos ( num ) . toArray ( 'be' , 32 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "ability", "to", "filter", "on", "a", "per", "transform", "and", "dependency", "provider", "level", "based", "on", "moduleMeta", ".", "location"], "add_tokens": "function canExecuteProvider ( provider ) { if ( provider . filter && ! provider . filter . test ( moduleMeta . location ) ) { return false ; } if ( provider . ignore && provider . ignore . test ( moduleMeta . location ) ) { return false ; } } // Run dependency pipeline return manager . pipelines . dependency . runAll ( moduleMeta , canExecuteProvider ) . then ( dependenciesFinished , Utils . forwardError ) ; return Promise . all ( loading ) . then ( dependenciesFetched , Utils . forwardError ) ;", "del_tokens": "return manager . pipelines . dependency . runAll ( moduleMeta ) . then ( dependenciesFinished , Utils . forwardError ) ; return Promise . all ( loading ) . then ( dependenciesFetched , Utils . forwardError ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "toJSON", "()", "support", "."], "add_tokens": "// TODO: Add fully qualified class name as required attribute and use it here as '$class' and '$module'. Data . prototype . toJSON = function ( ) { ret = { } ; for ( var k = 0 ; k < this . _members . length ; k ++ ) { ret [ this . _members [ k ] . name ] = this . _members [ k ] . toJSON ( this [ this . _members [ k ] . name ] ) ; } return ret ; } ; Data . prototype . toString = function ( ) { return JSON . stringify ( this . toJSON ( ) ) ; }", "del_tokens": "// TODO: Implement toString() for data and types.", "commit_type": "add"}
{"commit_tokens": ["Add", "optional", "arg", "support", "for", "usage", "display", "."], "add_tokens": "exit ( new Error ( util . format ( 'Usage: %s %s %s' , programName , commandName , commandArgs . map ( function ( arg ) { return util . format ( ( arg . optional ) ? '[%s]' : '<%s>' , arg . name ) ; } ) ) ) ) ;", "del_tokens": "exit ( new Error ( util . format ( 'Usage: %s %s <%s>' , programName , commandName , _ . pluck ( commandArgs , 'name' ) . join ( '> <' ) ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "readme", ".", "Fixed", "core", "debug", "message"], "add_tokens": "* version : 0.3 .53 VERSION = '0.3.53' , cout ( \"module:gengo, fn: core, Input\" ) . info ( ) ;", "del_tokens": "* version : 0.3 .52 VERSION = '0.3.52' , cout ( \"fn, core, fn: core, Input\" ) . info ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "failing", "test", "case", "to", "show", "bug", "."], "add_tokens": "expect ( Luc . isNumber ( NaN ) ) . to . be ( false ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "carcass", ".", "Use", "lodash", "."], "add_tokens": "var carcass , highland , _ ; highland = carcass . highland ; _ = require ( 'lodash' ) ; return highland . flatMap ( function ( item ) { if ( _ . isFunction ( parser ) ) { if ( _ . isObject ( parser ) && ( parser . parse != null ) ) { stream = highland ( this . source ( ) ) ; if ( _ . isArray ( parser ) ) { stream = stream . reduce ( { } , _ . merge ) ;", "del_tokens": "var carcass , extend , isArray , isFunction , isObject , _ ; isArray = require ( 'util' ) . isArray ; _ = carcass . highland ; extend = carcass . Object . extendDeep ; isObject = carcass . Object . isObject ; isFunction = carcass . Function . isFunction ; return _ . flatMap ( function ( item ) { if ( isFunction ( parser ) ) { if ( isObject ( parser ) && ( parser . parse != null ) ) { stream = _ ( this . source ( ) ) ; if ( isArray ( parser ) ) { stream = stream . reduce ( { } , extend ) ;", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "use", "straight", "client", "binaries", "."], "add_tokens": "var Http = require ( 'http' ) , Stack = require ( 'stack' ) , TopCube = require ( '../topcube.js' ) ; Http . createServer ( Stack ( ) ) . listen ( 7569 ) ; TopCube ( { url : 'http://localhost:7569' , name : 'Creationix' , width : 800 , height : 600 } ) ;", "del_tokens": "var Stack = require ( 'stack' ) , TopCube = require ( 'topcube' ) ; TopCube ( Stack ( ) , 800 , 600 ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "license", "file", "target", "only", "if", "src", "exists"], "add_tokens": "if ( fileobj ) { files [ 'LICENSE-' + license ] = fileobj . rel ; }", "del_tokens": "files [ 'LICENSE-' + license ] = fileobj ? fileobj . rel : null ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "initial", "testing", "suites", "and", "settings", "."], "add_tokens": "return this ; if ( tagManager . selected ) return Promise . resolve ( tagManager ) ; return tagManager ; var selectTask = tagManager ? tagManager . select ( ) : Promise . resolve ( tagManager ) ;", "del_tokens": "if ( tagManager . selected ) return Promise . resolve ( true ) ; var selectTask = tagManager ? tagManager . select ( ) : Promise . resolve ( true ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "style", "element", "from", "body", "to", "head"], "add_tokens": "document . head . appendChild ( style ) ;", "del_tokens": "document . body . appendChild ( style ) ;", "commit_type": "move"}
{"commit_tokens": ["allow", "skip", "boolean", "to", "be", "a", "string", "message"], "add_tokens": "skip : check . or ( check . bool , check . unemptyString ) ,", "del_tokens": "function or ( ) { var predicates = Array . prototype . slice . call ( arguments , 0 ) ; la ( predicates . length , 'empty list of arguments to or' ) ; return function orCheck ( ) { var values = Array . prototype . slice . call ( arguments , 0 ) ; return predicates . some ( function ( predicate ) { return predicate . apply ( null , values ) ; } ) ; } ; } skip : or ( check . bool , check . unemptyString ) ,", "commit_type": "allow"}
{"commit_tokens": ["added", "ifError", "method", "for", "assert", "module"], "add_tokens": "'doesNotThrow' , 'ifError'", "del_tokens": "'doesNotThrow'", "commit_type": "add"}
{"commit_tokens": ["fixing", "element", "not", "available", "on", "render"], "add_tokens": "if ( schedule . length === iteration + 1 && done ) { done ( ) ; }", "del_tokens": "if ( schedule . length === iteration + 1 && done ) { done ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "two", "quick", "bugs", "from", "the", "JSLint", "overhaul", "."], "add_tokens": "return typeof i == 'undefined' ? this . cur : this . cur [ i ] ; eval ( 'f = function(a,i){return ' + f + '}' ) ;", "del_tokens": "return i === null ? this . cur : this . cur [ i ] ; f = new Function ( 'a' , 'i' , 'return ' + f ) ;", "commit_type": "fix"}
{"commit_tokens": ["creating", "asynchron", "terrytory", "update", "structure"], "add_tokens": "socket . emit ( 'connectToBranch' , \"test\" ) ; } ) ; socket . on ( 'connectToBranchAck' , function ( msg ) { console . log ( \"selectBranchAck\" ) ; process . exit ( 0 ) ; } ) ; socket . on ( 'connectToBranchNack' , function ( msg ) { console . log ( \"selectBranchNack\" ) ; } ) ;", "del_tokens": "} )", "commit_type": "create"}
{"commit_tokens": ["Move", "benchmark", "/", "index", ".", "js", "to", "benchmark", ".", "js"], "add_tokens": "distance = require ( './' ) ;", "del_tokens": "distance = require ( '..' ) ;", "commit_type": "move"}
{"commit_tokens": ["Adding", "descriptive", "error", "message", "for", "invalid", "form", "states"], "add_tokens": "undefined , let state = reducer ( undefined , action ) ;", "del_tokens": "initialFieldState , let state = { } ; state = reducer ( state , action ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "unique", "IDs", "to", "accordion", "added", "props", "and", "proptypes", "missing", "state", "handle", "and", "testing"], "add_tokens": "< Accordion header = \"Open and close me\" > Some content of the accordion < a href = \"#sdfsdf\" > here < / a> :) < / Accordion > < hr / > < h2 > Accordions with open/close props < / h2 > < Accordion open = \"false\" header = \"Closed\" > Some content of the accordion < a href = \"#sdfsdf\" > here < / a> :D < / Accordion > < Accordion open = \"true\" header = \"Open\" > Some content of the accordion < a href = \"#sdfsdf\" > here < / a> 8) < h2 > Accordions with custom open function < / h2 > < Accordion open = \"false\" header = \"With custom function\" onOpen = { ( ) => { console . log ( 'yay!' ) ; } } >", "del_tokens": "< Accordion > Some content of the accordion < a href = \"#sdfsdf\" > here < / a> < h2 > Closed accordion < / h2 > < Accordion open = \"false\" >", "commit_type": "add"}
{"commit_tokens": ["Use", "jsfft", "-", "for", "-", "meyda", "package"], "add_tokens": "import * as fft from 'jsfft-for-meyda' ; import { ComplexArray } from 'jsfft-for-meyda' ;", "del_tokens": "import * as fft from 'jsfft' ; import { ComplexArray } from 'jsfft' ;", "commit_type": "use"}
{"commit_tokens": ["fix", "relPath", "when", "only", "pages", "are", "in", "subdirectories"], "add_tokens": "var u = generator . util ; var relPath = u . relPath ( pwindow . location . pathname ) ; $css = p$ ( '<link rel=\"stylesheet\" href=\"' + relPath + '/pub/css/pub-preview.css\">' ) ; var $script = p$ ( '<script src=\"' + relPath + '/pub/js/pub-preview.js\"></script>' ) ;", "del_tokens": "$css = p$ ( '<link rel=\"stylesheet\" href=\"./pub/css/pub-preview.css\">' ) ; var $script = p$ ( '<script src=\"./pub/js/pub-preview.js\"></script>' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "all", "issues", "found", "with", "mixins", "."], "add_tokens": "stat ; command = 'mocha -R list Classify.verifications.js' ; console . log ( 'Running verifications tests..' ) ; console . log ( '-------------------------------------------------' ) ; var exitCode ; exitCode = 1 ; } else { exitCode = 0 ; } command = 'mocha -R list Classify.functional.js' ; console . log ( 'Running functional tests..' ) ; console . log ( '-------------------------------------------------' ) ; if ( process . platform === 'win32' ) { tests = cp . spawn ( 'cmd' , [ '/s' , '/c' , command ] , { customFds : [ 0 , 1 , 2 ] } ) ; tests = cp . spawn ( 'sh' , [ '-c' , command ] , { customFds : [ 0 , 1 , 2 ] } ) ; tests . on ( 'exit' , function ( code ) { if ( code !== 0 ) { process . exit ( 1 ) ; } else { process . exit ( exitCode ) ; } } ) ;", "del_tokens": "stat , cwd ; cwd = process . cwd ( ) ; command = 'mocha -R list Classify.functional.js' ; command += ' && mocha -R list Classify.verifications.js' ; process . chdir ( cwd ) ; process . exit ( 1 ) ; process . exit ( 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "js", "hint", "and", "fix", "project"], "add_tokens": "'use strict' ; } ; } ; } ; } ; 'use strict' ; } ; } ; } ; 'use strict' ; } ; } . bind ( this ) ; params . callback = function ( ) { } ; } ;", "del_tokens": "} } } } } } } } } . bind ( this ) params . callback = function ( ) { } }", "commit_type": "add"}
{"commit_tokens": ["remove", "mouse", ".", "position", "attribute"], "add_tokens": "x : null , y : null self . mouse . x = x ; self . mouse . y = y ; self . mouse . x = x ; self . mouse . y = y ;", "del_tokens": "position : { x : null , y : null } self . mouse . position . x = x ; self . mouse . position . y = y ; self . mouse . position . x = x ; self . mouse . position . y = y ;", "commit_type": "remove"}
{"commit_tokens": ["added", "get", "not_called", "as", "negated", "called"], "add_tokens": "expect ( myfoo . baz ) . to . have . been . not_called ;", "del_tokens": "// expect(myfoo.baz).to.not.have.been.called; / * err ( function ( ) { expect ( myfoo . bar ) . to . not . have . been . called ; } , 'expected method \\'bar\\' to not have been called' ) ; * /", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "removed", "last", "/", "first", "/", "size", "()"], "add_tokens": "i = this . items ( ) , s = i . size ( ) , n = s > 0 && ( ( o . wrap && o . wrap !== 'first' ) || ( i . filter ( ':jcarouselitemlast' ) . index ( ) < ( s - 1 ) ) || ( this . tail && ! this . inTail ) ) ? true : false , p = s > 0 && ( ( o . wrap && o . wrap !== 'last' ) || ( i . filter ( ':jcarouselitemfirst' ) . index ( ) > 0 ) || ( this . tail && this . inTail ) ) ? true : false ;", "del_tokens": "s = this . size ( ) , n = s > 0 && ( ( o . wrap && o . wrap !== 'first' ) || ( this . index ( this . last ) < ( s - 1 ) ) || ( this . tail && ! this . inTail ) ) ? true : false , p = s > 0 && ( ( o . wrap && o . wrap !== 'last' ) || ( this . index ( this . first ) > 0 ) || ( this . tail && this . inTail ) ) ? true : false ;", "commit_type": "fix"}
{"commit_tokens": ["add", "default", "styles", "in", "the", "dist", "package"], "add_tokens": "themesDir : 'src/styles/**/*' // copy styles in the 'dist' folder pump ( [ gulp . src ( [ config . themesDir ] ) , gulp . dest ( ` ${ config . outputDir } ` ) ] ) ; '@angular/common/http' : 'ng.http' ,", "del_tokens": "themesDir : 'src/themes/default/*.scss' ///////////////////////////////////////////////////////////////////////////// // Themes Task ///////////////////////////////////////////////////////////////////////////// // gulp.task('themes', () => { // var result = sass.renderSync({ // file: '/path/to/file.scss', // data: 'body{background:blue; a{color:black;}}', // outputStyle: 'compressed', // outFile: '/to/my/output.css', // sourceMap: true, // or an absolute or relative (to outFile) path // importer: function(url, prev, done) { // // url is the path in import as is, which LibSass encountered. // // prev is the previously resolved path. // // done is an optional callback, either consume it or return value synchronously. // // this.options contains this options hash // someAsyncFunction(url, prev, function(result){ // done({ // file: result.path, // only one of them is required, see section Special Behaviours. // contents: result.data // }); // }); // // OR // var result = someSyncFunction(url, prev); // return {file: result.path, contents: result.data}; // } // })); // const processors = [ // stripInlineComments, // autoprefixer, // cssnano // ]; // const test = (stylePath) => { // if (/\\.(scss|sass)$/.test(ext[0])) { // let sassObj = sass.renderSync({ file: stylePath }); // if (sassObj && sassObj['css']) { // let css = sassObj.css.toString('utf8'); // } // return gulp.src(config.themesDir) // .pipe(sass()) // .pipe(cssnano({ // autoprefixer: {browsers: supported, add: true} // })) // .pipe(gulp.dest(`${config.outputDir}/themes/css`)); // });", "commit_type": "add"}
{"commit_tokens": ["Adds", "Noscript", "-", "Tags", "to", "the", "tag", "-", "blacklist"], "add_tokens": "if ( [ 'CODE' , 'PRE' , 'SCRIPT' , 'STYLE' , 'NOSCRIPT' ] . indexOf ( el . nodeName . toUpperCase ( ) ) !== - 1 ) {", "del_tokens": "if ( [ 'CODE' , 'PRE' , 'SCRIPT' , 'STYLE' ] . indexOf ( el . nodeName . toUpperCase ( ) ) !== - 1 ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "third", "parameter", "from", "verifyPassword"], "add_tokens": "if ( ! user ) { cb ( null , false ) ; return ; }", "del_tokens": "if ( ! user ) { cb ( null , false , null ) ; return ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "node", ".", "js", "support", "for", "Ed25519Signature2018", "."], "add_tokens": "EcdsaKoblitzSignature2016 : require ( './suites/EcdsaKoblitzSignature2016' ) , Ed25519Signature2018 : require ( './suites/Ed25519Signature2018' ) , } ; 'Ed25519Signature2018' ,", "del_tokens": "EcdsaKoblitzSignature2016 : require ( './suites/EcdsaKoblitzSignature2016' ) , }", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "authorizer", "actionList", "has", "completed", "before", "starting", "server", "and", "returning", "from", "init"], "add_tokens": "Host . prototype . init = function ( config , done ) { var startServer = function ( ) { this . server = http . createServer ( this . app ) . listen ( this . config . port || 8800 ) ; this . configureWebsockets ( ) ; this . configureSocketIO ( ) ; console . log ( 'autohost listening on port ' , ( this . config . port || 8800 ) ) ; if ( done ) done ( ) ; } . bind ( this ) ; this . authorizer . actionList ( list , function ( ) { startServer ( ) ; } ) ; } else { startServer ( ) ;", "del_tokens": "Host . prototype . init = function ( config ) { this . authorizer . actionList ( list , function ( ) { } ) ; this . server = http . createServer ( this . app ) . listen ( this . config . port || 8800 ) ; this . configureWebsockets ( ) ; this . configureSocketIO ( ) ; console . log ( 'autohost listening on port ' , ( this . config . port || 8800 ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "instant", "improve", "site", "speed"], "add_tokens": "InstantClickChangeFns . push ( function ( ) { // auto complete for components", "del_tokens": "$ ( function ( ) { // auto complete for components", "commit_type": "add"}
{"commit_tokens": ["Adding", "factory", "constructor", "and", "tests"], "add_tokens": "window . LD = x ; } ( function ( contextOrData , context ) { // if only the first parameter is supplied, then use it as the context and return a factory function // to create documents var asFactory = ! context ; context = context || contextOrData ; // if two parameters are provided then use the second parameter, otherwise use the first parameter. // create a regex for this alias // return a new function to process the property name // select the json targetted by this path if ( asFactory ) { // if one parameter was supplied, return the factory function return function ( dataContext ) { return new QueryNode ( dataContext ) ; } } else { // if two parameters were supplied, return the QueryNode directly return new QueryNode ( contextOrData ) ; }", "del_tokens": "window . LD = x ; } ( function ( dataContext , context ) { // create a regex for this alias // return a new function to process the property name // select the json targetted by this path return new QueryNode ( dataContext ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "duplicate", "reference", "fields", "would", "not", "be", "detected"], "add_tokens": "var capitalize = require ( 'lodash/string/capitalize' ) ; var description = pluralize ( model . name ) + ' belonging to this ' + ref . model . name ; if ( find ( reverseRefs , { field : refName } ) || ref . model . fields [ refName ] ) { // @TODO find a better name algo resolve mechanism // `thread_id` should naturally be `threads`, while `old_thread_id` should be.. something else refName += capitalize ( camelCase ( referenceColumn ) ) . replace ( / Id$ / , '' ) ; description += '..? (' + referenceColumn + ')' ; description : description ,", "del_tokens": "var getPrimaryKey = require ( '../util/get-primary-key' ) ; if ( find ( model . reverseRefs , { field : refName } ) || ref . model . fields [ refName ] ) { refName += 'Ref' ; description : pluralize ( model . name ) + ' belonging to this ' + ref . model . name ,", "commit_type": "fix"}
{"commit_tokens": ["implementing", "@@getChangesDependencyRecord", "on", "the", "live", ".", "text", "event", "handler"], "add_tokens": "assert . expect ( 3 ) ; new Set ( [ text ] ) , 'whatChangesMe(<div>) shows the observation' ) ; assert . deepEqual ( canReflectDeps . getDependencyDataOf ( text ) . whatIChange . mutate . valueDependencies , new Set ( [ div ] ) , 'whatChangesMe(observation) shows the <div>'", "del_tokens": "assert . expect ( 2 ) ; new Set ( [ text ] )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "wrong", "type", "in", "fetch_image"], "add_tokens": "return $ . cloudinary . image ( public_id , $ . extend ( { type : 'fetch' } , options ) ) ;", "del_tokens": "return $ . cloudinary . image ( public_id , $ . extend ( { type : 'fetch_image' } , options ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "validations", "to", "dev", "stage", "only"], "add_tokens": "if ( process . env . NODE_ENV !== 'production' ) { if ( ! stores && ! store ) { throw new Error ( 'Must define either store or stores' ) } if ( stores && store ) { throw new Error ( 'Cannot define both store and stores' ) }", "del_tokens": "if ( ! stores && ! store ) { throw new Error ( 'Must define either store or stores' ) } if ( stores && store ) { throw new Error ( 'Cannot define both store and stores' )", "commit_type": "move"}
{"commit_tokens": ["Use", "[]", "to", "initialize", "array"], "add_tokens": "maps = [ ] ; maps . push ( arguments [ i ] ) ;", "del_tokens": "maps = Array ( argLen ) ; maps [ i ] = arguments [ i ] ;", "commit_type": "use"}
{"commit_tokens": ["add", "tests", "for", "increased", "coverage"], "add_tokens": "frameworks : [ 'browserify' , 'tap' ] , files : [ './test-build/test/**/*.js' ] , browsers : [ 'FirefoxHeadless' , 'ChromeHeadless' ] ,", "del_tokens": "frameworks : [ 'browserify' , 'detectBrowsers' , 'tap' ] , files : [ './test-build/test/index.js' ] , detectBrowsers : { enabled : true , usePhantomJS : false , postDetection : function ( availableBrowsers ) { return [ 'FirefoxHeadless' ] } , } ,", "commit_type": "add"}
{"commit_tokens": ["fix", "not", "to", "touch", "content_type", "when", "posting", "a", "buffer"], "add_tokens": "if ( is ( data ) . a ( Object ) && ! Buffer . isBuffer ( data ) ) {", "del_tokens": "if ( is ( data ) . a ( Object ) ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "most", "of", "tests", "WIP"], "add_tokens": "ask ( { port : server . port , method : 'post' , body : test , bodyEncoding : 'json' } , function ( error , response ) { ask ( { port : server . port , method : 'put' , body : test , bodyEncoding : 'json' } , function ( error , response ) { assert . isNull ( error , 'no errors occured' ) ;", "del_tokens": "ask ( { port : server . port , method : 'post' , body : test } , function ( error , response ) { ask ( { port : server . port , method : 'put' , body : test } , function ( error , response ) { assert . strictEqual ( error , null , 'no errors occured' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "build", "into", "seperate", "file"], "add_tokens": "build = require ( './build' ) ; build . call ( this , client ) ;", "del_tokens": "controller = require ( './controller' ) , handshake = require ( './handshake' ) ; client . socket . on ( 'data' , function ( data ) { if ( client . shaking ) socket . end ( 'Ayy lmao' ) ; else { if ( ! client . shook ) handshake ( client , data ) ; else controller ( client , data ) ; } } ) ; client . socket . on ( 'end' , ( ) => { this . _clients . slice ( client . id , 1 ) ; socket . destroy ( ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "doc", "formatting", "to", "fixed", "messed", "up", "param", "tables"], "add_tokens": "doc = doc . replace ( / \\*{2}Kind\\*{2}:.*\\n / g , '' ) ; doc = doc . replace ( / \\s{4,}(?= [^|]+\\|$) / gm , '' ) ;", "del_tokens": "doc = doc . replace ( / [*]{2}Kind[*]{2}:.*\\n / g , '' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "run", "tests", "for", "single", "category"], "add_tokens": "} , WebAtoms : { global . WebAtoms = global . window . WebAtoms ; var p = WebAtoms . Unit . TestRunner . instance . run ( process . argv [ 2 ] ) ;", "del_tokens": "var p = WebAtoms . Unit . TestRunner . instance . run ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "durable", "property", "on", "both", "receiver", "and", "sender", "nodes"], "add_tokens": "this . durable = n . durable this . expirypolicy = n . expirypolicy target : { address : node . address , dynamic : node . dynamic , durable : node . durable , expiry_policy : node . expirypolicy } , autosettle : node . autosettle , var options = { host : node . endpointConfig . host , port : node . endpointConfig . port } this . durable = n . durable this . expirypolicy = n . expirypolicy source : { address : node . address , dynamic : node . dynamic , durable : node . durable , expiry_policy : node . expirypolicy } , autoaccept : node . autoaccept , var options = { host : node . endpointConfig . host , port : node . endpointConfig . port }", "del_tokens": "target : { address : node . address , dynamic : node . dynamic } , autosettle : node . autosettle , var options = { host : node . endpointConfig . host , port : node . endpointConfig . port } source : { address : node . address , dynamic : node . dynamic } , autoaccept : node . autoaccept , var options = { host : node . endpointConfig . host , port : node . endpointConfig . port }", "commit_type": "add"}
{"commit_tokens": ["remove", "redundant", "try", "/", "catch"], "add_tokens": "return error ; return this . handleResponse ( response . status , headersToObject ( response . headers ) , this . parseErrorResponse ( response . statusText ) || error , requestData ) ;", "del_tokens": "let returnedError ; returnedError = error ; try { const headersObject = headersToObject ( response . headers ) ; returnedError = this . handleResponse ( response . status , headersObject , this . parseErrorResponse ( response . statusText ) || error , requestData ) ; } catch ( e ) { throw e ; } return returnedError ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "hoodie", "specific", "fields", "to", "public_fields"], "add_tokens": "'name' , 'roles' , 'derived_key' , 'salt' , 'database' , 'ownerHash' , 'updatedAt' , 'signedUpAt' , 'type'", "del_tokens": "'name' , 'roles' , 'derived_key' , 'salt'", "commit_type": "add"}
{"commit_tokens": ["Add", "max", "-", "size", "property"], "add_tokens": "this . server . use ( bodyParser . json ( { limit : \"10mb\" } ) ) ; this . server . use ( bodyParser . urlencoded ( { limit : \"10mb\" , extended : false } ) ) ;", "del_tokens": "this . server . use ( bodyParser . urlencoded ( { extended : false } ) ) ; this . server . use ( bodyParser . json ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "styling", "to", "search"], "add_tokens": "url : reflection . url , classes : reflection . cssClasses", "del_tokens": "url : reflection . url", "commit_type": "add"}
{"commit_tokens": ["add", "a", "base", "provider", "tag", "for", "the", "simulated", "runs", "to", "more", "closely", "match", "reality"], "add_tokens": ". pipe ( plugins . jshint . reporter ( 'jshint-stylish' , { verbose : true } ) ) ;", "del_tokens": ". pipe ( plugins . jshint . reporter ( 'jshint-stylish' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "and", "change", "reporter", "output"], "add_tokens": "let message = ` ${ filePath } \\n ` ; this . log ( ` \\n ${ filePath } \\n \\n ` , \"red\" , true ) ; this . log ( ` ${ dups . length + 1 } \\n ` , \"cyan\" , true ) ; let message = ` \\n ${ this . getLocation ( source ) } \\n ` ; this . log ( ` ${ message } ${ sourceCode } \\n ` ) ; return ` ${ message } ${ generate ( dup ) . code } \\n ` ; this . log ( \"\\n\" ) ; this . log ( \"\\n\" ) ;", "del_tokens": "let message = ` ${ filePath } \\n ` ; this . log ( ` \\n ${ filePath } \\n \\n ` , \"red\" , true ) ; this . log ( sourceCode , \"white\" ) ; this . log ( ` \\n ${ dups . length } \\n ` , \"cyan\" ) ; return ` ${ message } ${ generate ( dup ) . code } ` ; console . log ( \"\\n\" ) ; console . log ( \"\\n\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "on", "condor", "/", "simple", "."], "add_tokens": "var p = spawn ( cmd , opts ) ; //, {cwd: __dirname}); p . stdout . on ( 'data' , function ( data ) { p . stderr . on ( 'data' , function ( data ) { p . on ( 'error' , function ( err ) { p . on ( 'exit' , function ( code , signal ) { exports . remove = function ( opts , callback ) { return condor_simple ( 'condor_rm' , opts ) . nodeify ( callback ) ; / * if ( typeof id === 'array' ) { console . log ( \"array given. passing everything\" ) ; console . dir ( id ) ; return condor_simple ( 'condor_rm' , id ) . nodeify ( callback ) ; } else { //must be a single id return condor_simple ( 'condor_rm' , [ id ] ) . nodeify ( callback ) ; } * /", "del_tokens": "cmd = spawn ( cmd , opts ) ; //, {cwd: __dirname}); cmd . stdout . on ( 'data' , function ( data ) { cmd . stderr . on ( 'data' , function ( data ) { cmd . on ( 'error' , function ( err ) { cmd . on ( 'exit' , function ( code , signal ) { exports . remove = function ( id , callback ) { return condor_simple ( 'condor_rm' , [ id ] ) . nodeify ( callback ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "null", "/", "undefined", "init"], "add_tokens": "* @ license Complex . js v1 .4 .0 22 / 06 / 2015 if ( a === null || a === undefined ) { P [ 'r' ] = 0 ; P [ 'i' ] = 0 ; } else if ( b !== undefined ) {", "del_tokens": "* @ license Complex . js v1 .2 .0 22 / 06 / 2015 if ( b !== undefined ) {", "commit_type": "fix"}
{"commit_tokens": ["adds", "a", "static", "make", "()", "method", "as", "an", "alternative", "to", "the", "Validator", "constructor"], "add_tokens": "required : \"You're missing :required\"", "del_tokens": "required : 'You\\'re missing :required'", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "app", "modes"], "add_tokens": "if ( index !== - 1 ) { if ( error ) { if ( error ) {", "del_tokens": "if ( index !== - 1 ) { if ( error ) { if ( error ) {", "commit_type": "add"}
{"commit_tokens": ["Updating", "environment", "variables", "to", "be", "more", "syslog", "specific"], "add_tokens": "if ( 'NODE_LOGGER_SYSLOG_FACILITY' in process . env && process . env . NODE_LOGGER_SYSLOG_FACILITY ) { options . facility = process . env . NODE_LOGGER_SYSLOG_FACILITY ; if ( 'NODE_LOGGER_SYSLOG_APPNAME' in process . env && process . env . NODE_LOGGER_SYSLOG_APPNAME ) { options . tag = process . env . NODE_LOGGER_SYSLOG_APPNAME ;", "del_tokens": "if ( 'NODE_LOGGER_FACILITY' in process . env && process . env . NODE_LOGGER_FACILITY ) { options . facility = process . env . NODE_LOGGER_FACILITY ; if ( 'NODE_LOGGER_APPNAME' in process . env && process . env . NODE_LOGGER_APPNAME ) { options . tag = process . env . NODE_LOGGER_APPNAME ;", "commit_type": "update"}
{"commit_tokens": ["add", "id", "to", "component", "and", "use", "for", "registry", "lookup"], "add_tokens": "this . allInstances = { } ; this . allInstances [ instance . identity ] = inst ; delete this . allInstances [ instance . identity ] ; this . findInstanceInfo = function ( instance ) { return this . allInstances [ instance . identity ] || null ;", "del_tokens": "this . allInstances = [ ] ; this . allInstances . push ( inst ) ; var index = this . allInstances . indexOf ( instInfo ) ; ( index > - 1 ) && this . allInstances . splice ( index , 1 ) ; this . findInstanceInfo = function ( which ) { var testFn ; if ( which . node ) { //by instance (returns matched instance) testFn = function ( inst ) { return inst . instance === which } ; } else { //by node (returns array of matches) testFn = function ( inst ) { return inst . instance . node === which } ; } var matches = this . allInstances . filter ( testFn ) ; if ( ! matches . length ) { return which . node ? null : [ ] ; } return which . node ? matches [ 0 ] : matches ;", "commit_type": "add"}
{"commit_tokens": ["Added", "Okaidia", "theme", "to", "theme", "switcher", "."], "add_tokens": "'prism-funky' : 'Funky' , 'okaidia' : 'Okaidia'", "del_tokens": "'prism-funky' : 'Funky'", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "closure", "scope", "in", "run", "-", "sequence"], "add_tokens": "addTask ( tasks [ name ] ) ; function addTask ( task ) { // create the unique subtasks task . subtasks . forEach ( function ( subtask ) { gulp . task ( subtask . name , subtask . parm1 , subtask . parm2 ) ; } ) ; var args = task . subtasks . map ( function ( subtask ) { return subtask . name ; } ) ; // create the master task which is dependent on all of the subtasks gulp . task ( task . name , function ( ) { runSequence . apply ( null , args ) ; } ) ; } tasks [ name ] . name = name ;", "del_tokens": "var task = tasks [ name ] ; // create the unique subtasks task . subtasks . forEach ( function ( subtask ) { gulp . task ( subtask . name , subtask . parm1 , subtask . parm2 ) ; } ) ; // create the master task which runs each of the subtasks in sequence gulp . task ( name , function ( ) { var args = task . subtasks . map ( function ( subtask ) { return subtask . name ; } ) ; runSequence . apply ( null , args ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "code", "content", "to", "be", "string"], "add_tokens": "if ( Array . isArray ( input . content ) ) { c += input . content . join ( \"\\n\" ) ; } else { c += input . content ; } c += \"\\n```\" ;", "del_tokens": "c += input . content . join ( \"\\n\" ) + \"\\n\" ; c += \"```\" ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "IE", "bug", "when", "handling", "anchor", "click", "routing"], "add_tokens": "// IE11 prefixes extra slash on absolute links const path = ( el . pathname + el . search ) . replace ( / \\/\\/ / , '/' )", "del_tokens": "const path = el . pathname + el . search", "commit_type": "fix"}
{"commit_tokens": ["add", "position", "fixed", "selector", "option", "and", "use", "travis", "-", "ci"], "add_tokens": "function processJSON ( json ) { var json ; try { json = JSON . parse ( chunk ) ; processJSON ( json ) ; } catch ( e ) { console . log ( 'Multiple files were chunked together.' ) try { var array = '[' + chunk . split ( '}{' ) . join ( '},{' ) + ']' ; json = JSON . parse ( array ) ; json . forEach ( function ( item ) { processJSON ( item ) ; } ) } catch ( e ) { } }", "del_tokens": "function processJSON ( string ) { var json = JSON . parse ( string ) ; processJSON ( chunk ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "matchers", "to", "the", "readme", "file", ".", "removing", "the", "focus", "matcher", "."], "add_tokens": "} ) ( ) ;", "del_tokens": "toHaveFocus : function ( ) { var _this = this ; var activeElement = browser . driver . switchTo ( ) . activeElement ( ) ; return this . actual . getOuterHtml ( ) . then ( function ( html1 ) { return activeElement . getOuterHtml ( ) . then ( function ( html2 ) { helpers . createMessage ( _this , 'Expected ' + html1 . substring ( 0 , 40 ) + '{{not}} to have focus, but focus is on ' + html2 . substring ( 0 , 40 ) + '...' ) ; return html1 === html2 ; } ) ; } ) ; } , } ) ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "sandbox", "for", "lambdas", "that", "have", "a", "period", "in", "their", "name"], "add_tokens": "var path = route === '/' ? '-index' : route . replace ( / \\/ / g , '-' ) . replace ( '.' , '-' ) . replace ( / : / g , '000' )", "del_tokens": "var path = route === '/' ? '-index' : route . replace ( / \\/ / g , '-' ) . replace ( / : / g , '000' )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "analytics", "for", "default", "web", "bin"], "add_tokens": "var userId = download . req . query . user ;", "del_tokens": "var userId = req . query . user ;", "commit_type": "fix"}
{"commit_tokens": ["make", "find_node", "symbolic", "link", "aware"], "add_tokens": "function ELoop ( message ) { this . message = message || '' ; } ELoop . prototype = new Error ( ) ; ELoop . prototype . name = \"ELoop\" ; ELoop . prototype . constructor = ELoop ; EIO : EIO , ELoop : ELoop", "del_tokens": "EIO : EIO", "commit_type": "make"}
{"commit_tokens": ["add", "support", "for", "inline", "=", "inline"], "add_tokens": "return new RegExp ( '<([a-zA-Z]+)\\\\b[^>]*?\\\\s(?:' + attribute + ' [^>]*?|' + attribute + '|' + attribute + '=([\\\\\\'\\\\\\\"])(?:true|' + attribute + ')\\\\2[^>]*?)>(?:<\\\\/\\\\1\\\\s?>)?' , 'gm' ) ; } ;", "del_tokens": "return new RegExp ( '<([a-zA-Z]+)\\\\b[^>]*?\\\\s(?:' + attribute + ' [^>]*?|' + attribute + '|' + attribute + '=([\\\\\\'\\\\\\\"])true\\\\2[^>]*?)>(?:<\\\\/\\\\1\\\\s?>)?' , 'gm' ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "sortable", "functionality", "to", "arrays"], "add_tokens": "{ name : 'ember-redux' , target : '^1.0.0' } , { name : 'ember-sortable' , target : '^1.8.1' }", "del_tokens": "{ name : 'ember-redux' , target : '^1.0.0' }", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "hashkey", "generation", "for", "circle", "styles", "and", "code", "clean", "up"], "add_tokens": "'icon-size' , 'circle-radius' var cache_key = paint [ 'circle-radius' ] ( zoom ) + '.' + paint [ 'circle-stroke-color' ] ( zoom ) + '.' + paint [ 'circle-color' ] ( zoom ) ; style . setZIndex ( i ) ; styles [ stylesLength ] = style ;", "del_tokens": "'icon-size' 'circle-radius' , var cache_key = paint [ 'circle-radius' ] + '.' + paint [ 'circle-stroke-color' ] + '.' + paint [ 'circle-color' ] ; if ( style ) { style . setZIndex ( i ) ; styles [ stylesLength ] = style ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "rendering", "at", "browser", "zoom", "levels"], "add_tokens": "cssElement : \"\\n{:selector:}:before {\\n\\twidth: {:width:}em;\\n\\theight: {:height:}em;\\n\\tbackground-position: {:relativex:}% 0;\\n}\\n\" , cssSpriteImage : \"\\n{:selector:} {\\n\\tcontent:' ';\\n\\tvertical-align:middle;\\n\\tdisplay: inline-block;\\n\\tbackground-image: url(\\\"{:spriteUrl:}\\\");\\n\\tbackground-repeat: no-repeat;\\n\\tbackground-size: {:backgroundSize:};\\n}\\n\" , utils . makePath ( config . svgPath , sprite . path , config ) , sprite module . exports . renderSvg = function ( cssSVGSpriteImageRule , svgSelectors , path , sprite ) { selector : svgSelectors . map ( function ( el ) { return el + \":before\" ; } ) . join ( \",\\n\" ) , spriteUrl : path , backgroundSize : ( sprite . width / 10 ) + \"em \" + ( sprite . height / 10 ) + \"em\" relativex : element . relativex", "del_tokens": "cssElement : \"\\n{:selector:}:before {\\n\\twidth: {:width:}em;\\n\\theight: {:height:}em;\\n\\tbackground-position: {:relativex:}% 0;\\n\\tbackground-size: auto {:backgroundSize:}%;\\n}\\n\" , cssSpriteImage : \"\\n{:selector:} {\\n\\tcontent:' ';\\n\\tvertical-align:middle;\\n\\tdisplay: inline-block;\\n\\tbackground-image: url(\\\"{:spriteUrl:}\\\");\\n\\tbackground-repeat: no-repeat;\\n}\\n\" , element . backgroundSize = ( sprite . height / element . height ) * 100 ; utils . makePath ( config . svgPath , sprite . path , config ) module . exports . renderSvg = function ( cssSVGSpriteImageRule , svgSelectors , path ) { selector : svgSelectors . map ( function ( el ) { return el + \":before\" ; } ) . join ( \",\\n\" ) , spriteUrl : path relativex : element . relativex , backgroundSize : element . backgroundSize", "commit_type": "fix"}
{"commit_tokens": ["Use", "pow", "()", "instead", "of", "shifting", "for", "fixed", "-", "types"], "add_tokens": "return encodeSingle ( 'uint256' , parseNumber ( arg ) . mul ( new BN ( 2 ) . pow ( new BN ( size [ 1 ] ) ) ) ) return encodeSingle ( 'int256' , parseNumber ( arg ) . mul ( new BN ( 2 ) . pow ( new BN ( size [ 1 ] ) ) ) ) return num . div ( new BN ( 2 ) . pow ( new BN ( size [ 1 ] ) ) ) return num . div ( new BN ( 2 ) . pow ( new BN ( size [ 1 ] ) ) )", "del_tokens": "return encodeSingle ( 'uint256' , new BN ( arg ) . imul ( new BN ( 1 ) . iushln ( size [ 1 ] ) ) ) return encodeSingle ( 'int256' , new BN ( arg ) . imul ( new BN ( 1 ) . iushln ( size [ 1 ] ) ) ) return num . div ( new BN ( 1 ) . iushln ( size [ 1 ] ) ) return num . div ( new BN ( 1 ) . iushln ( size [ 1 ] ) )", "commit_type": "use"}
{"commit_tokens": ["fix", "comma", "-", ".", "-"], "add_tokens": "description : 'Generates a placeholder bundle config.' ,", "del_tokens": "description : 'Generates a placeholder bundle config.'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "in", "StringStream", ":", "read"], "add_tokens": "buffer : result eventsHandler", "del_tokens": "buffer : this . consolidateString ( ) result", "commit_type": "fix"}
{"commit_tokens": ["add", "bind", "to", "default", "build"], "add_tokens": "* Franky JavaScript Library v1 .0 .13 * Date : 2015 - 03 - 18 T09 : 37 Z franky . version = \"1.0.13\" ; // Native bind is too slow. // [See](http://jsperf.com/nativebind-vs-custombind) franky . bind = function ( func , context ) { return function ( ) { return func . apply ( context , arguments ) ; } ; } ;", "del_tokens": "* Franky JavaScript Library v1 .0 .12 * Date : 2015 - 01 - 12 T15 : 57 Z franky . version = \"1.0.12\" ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "little", "regex", "error"], "add_tokens": "route = route . replace ( / \\/ / g , '\\\\/' ) . replace ( / \\* / g , '[^/]*' ) ;", "del_tokens": "route = route . replace ( / \\/ / g , '\\\\/' ) . replace ( / \\* / , '[^/]*' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", ".", "none", "change", "file", "arguments", "from", "watch", "-", "additional"], "add_tokens": "var changingDeps = { } ; changingDeps [ id ] = true ; browserify . emit ( 'update' , Object . keys ( changingDeps ) ) ; changingDeps = { } ;", "del_tokens": "browserify . emit ( 'update' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "require", "(", "fs", ")", "onto", "own", "line", "to", "accomodate", "brfs", "bug"], "add_tokens": "format = require ( 'util' ) . format ; // Needs to be on another line since github.com/substack/brfs/issues/28. var fs = require ( 'fs' ) ;", "del_tokens": "format = require ( 'util' ) . format , fs = require ( 'fs' ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "factory", "function", "to", "create", "new", "core", "."], "add_tokens": "var _default = ( function ( ) { function _default ( opts ) { _classCallCheck ( this , _default ) ; _createClass ( _default , [ { return _default ; exports [ 'default' ] = _default ;", "del_tokens": "var Transloadit = ( function ( ) { function Transloadit ( opts ) { _classCallCheck ( this , Transloadit ) ; _createClass ( Transloadit , [ { return Transloadit ; exports [ 'default' ] = Transloadit ;", "commit_type": "add"}
{"commit_tokens": ["removed", "fs", "-", "extra", "due", "to", "a", "double", "-", "callback", "scenario", "in", "readJson"], "add_tokens": "var fs = require ( 'fs' ) ; fs . readFile ( configFilePath , check ( console . log ( 'readFile returned failure!' , err ) ; function ( data ) { var configObj = null ; try { configObj = JSON . parse ( data ) ; } catch ( err ) { cb ( err ) ; }", "del_tokens": "var fs = require ( 'fs-extra' ) ; fs . readJson ( configFilePath , check ( function ( configObj ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "swapped", "shape", "/", "options", "arguments"], "add_tokens": "// swap dst/o if ( ( isObj ( dst ) || typeof dst === 'string' || Array . isArray ( dst ) ) && o && ! isObj ( o ) ) { if ( ! dst ) dst = console var pixels = pxls ( data , [ o . width , o . height ] )", "del_tokens": "if ( ! dst ) dst = console if ( isObj ( dst ) && o && ! isObj ( o ) ) { var pixels = pxls ( data )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "hooks", "for", "watch", "mode"], "add_tokens": "compiler . hooks . watchRun . tap ( PLUGIN_NAME , this . handleWatchRun . bind ( this ) ) ; handleWatchRun ( )", "del_tokens": "const handleBeforeRun = this . handleBeforeRun . bind ( this ) ; compiler . hooks . beforeRun . tap ( PLUGIN_NAME , handleBeforeRun ) ; compiler . hooks . watchRun . tap ( PLUGIN_NAME , handleBeforeRun ) ; this . assetNames . clear ( ) ; handleBeforeRun ( )", "commit_type": "update"}
{"commit_tokens": ["Fix", "unicode", "escape", "sequence", "error", "handling", "."], "add_tokens": "var hexits , i ; for ( i = 0 ; i < 4 ; i += 1 ) { if ( isHexit ( character ) ) { hexits += character ; } } if ( hexits . length === 4 ) { return String . fromCharCode ( parseInt ( hexits , 16 ) ) ; error ( character , 'hex digit' ) ; return '\\\\u' + hexits + character ; return isDigit ( character ) || checkCharacter ( character , 'a' , 'f' ) ;", "del_tokens": "var hexits ; do { hexits += character ; } while ( isHexit ( character ) && hexits . length < 4 ) if ( hexits . length !== 4 ) { error ( character , 'hex digit' ) ; return String . fromCharCode ( parseInt ( hexits , 16 ) ) ; return isDigit ( character ) || checkCharacter ( character , 'a' , 'h' ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "prefetch", "support", "w", "/", "tests", "and", "docs"], "add_tokens": "/ ** * Setup prefetch options for consumer channel ( ` ` ) * Equivalent to http : //www.squaremobius.net/amqp.node/channel_api.html#channel_prefetch * @ param { Number } count the maximum number of messages sent over the channel that can be awaiting ack * @ param { Boolean } [ global ] flag specifying if prefetch is global ( true ) or per - channel ( false ) , default : false * / prefetch ( /* count, global */ ) { const args = assertArgs ( arguments , { 'count' : 'number' , '[global]' : 'boolean' } ) this . prefetchOpts = { count : args . count , global : args . global } } , yield createAppChannel ( self , 'consumerChannel' ) // uses: self.connection, self.prefetchOpts", "del_tokens": "yield createAppChannel ( self , 'consumerChannel' ) // uses: self.connection", "commit_type": "add"}
{"commit_tokens": ["Added", "checks", "for", "user", "-", "tailored", "send", "function"], "add_tokens": "fbbot . on ( payloadType , function ( payload , send ) t . equal ( typeof send , 'function' , 'expect send function for each message event' ) ;", "del_tokens": "fbbot . on ( payloadType , function ( payload )", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "default", "language", "to", "default"], "add_tokens": "angular . autoValidate . errorMessages [ 'default' ] = { var currentCulture = 'default' ,", "del_tokens": "angular . autoValidate . errorMessages [ 'en-us' ] = angular . autoValidate . errorMessages [ 'en-gb' ] = { var currentCulture = 'en-gb' ,", "commit_type": "change"}
{"commit_tokens": ["Added", "proxy", "support", "for", "request", "and", "response"], "add_tokens": "var net = require ( 'net' ) , sys = require ( 'sys' ) , var Connection = function ( ) { this . established = false ; if ( config . use_proxy ) { this . check_port = config . proxy_port ; this . check_host = config . proxy_host ; } else { this . check_port = 80 ; this . check_host = 'www.google.com' ; } this . connect = function ( ) { var stream = net . createConnection ( parseInt ( this . check_port ) , this . check_host ) ; this . connect ( ) ; module . exports = Connection ;", "del_tokens": "var net = require ( 'net' ) , sys = require ( 'sys' ) , var check_port = 80 ; var check_host = 'www.google.com' ; var Connection = function ( host , port ) { var established = false ; var connect = function ( ) { var stream = net . createConnection ( parseInt ( port ) , host ) ; connect ( ) ; exports . check = function ( ) { return new Connection ( check_host , check_port ) ; }", "commit_type": "add"}
{"commit_tokens": ["fix", "auth", "request", "Content", "-", "Type", "header"], "add_tokens": "} try { body = JSON . parse ( body ) ; } catch ( e ) { return callback ( new Error ( 'failed to parse response body: ' + body ) ) ; }", "del_tokens": "} , json : true", "commit_type": "fix"}
{"commit_tokens": ["added", "(", "c", ")", "contributors"], "add_tokens": "* Copyright ( c ) 2012 , Twitter Inc . and other contributors * Released under the MIT License", "del_tokens": "* Copyright ( c ) 2012 , Twitter Inc . All rights reserved . * Copyrights licensed under the MIT License . See the accompanying LICENSE file for terms .", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "test", "data", "to", "prevent", "duplicates"], "add_tokens": "for ( let i = 1 ; i <= 3 ; i ++ ) { // We are testing for up to 3 spaces and for empty strings well use this // condition to prevent duplicates. if ( targetString === '' ) { result . push ( [ ' ' , ... rest ] ) result . push ( [ ' ' , ... rest ] ) result . push ( [ ' ' , ... rest ] ) continue } // Other strings, add up to 3 spaces to the left and right. for ( let i = 1 ; i <= 3 ; i ++ ) { const LENGHT = targetString . length result . push ( [ pad ( targetString , LENGHT + i ) , ... rest ] ) result . push ( [ pad ( LENGHT + i , targetString ) , ... rest ] )", "del_tokens": "for ( let i = 1 ; i < 3 ; i ++ ) { for ( let i = 1 ; i < 3 ; i ++ ) { result . push ( [ pad ( targetString , i ) , ... rest ] ) result . push ( [ pad ( i , targetString ) , ... rest ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "scripts", "and", "style", "support"], "add_tokens": "unformatted : [ ] ,", "del_tokens": "unformatted : [ 'script' , 'style' ] ,", "commit_type": "add"}
{"commit_tokens": ["Update", "simple", "-", "html", "-", "tokenizer", "to", "231aa960e613"], "add_tokens": "this . token . addToAttributeName ( char ) ;", "del_tokens": "this . token . addToAttributeName ( char . toLowerCase ( ) ) ; } else if ( isUpper ( char ) ) { this . token . addToTagName ( char . toLowerCase ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "the", "schema", "for", "inheritableOptions", "more", "precise"], "add_tokens": "$ref : '#/definitions/option/properties/name' ,", "del_tokens": "type : 'string' ,", "commit_type": "make"}
{"commit_tokens": ["added", "sensor", ".", "on", "(", "change", ")", "event", "using", "the", "new", "averageValue", "code"], "add_tokens": "//set up the on(\"change\") event this . _lastAvg = null ; this . on ( \"data\" , function ( val , avgValue ) { if ( this . _lastAvg == null ) { this . _lastAvg = avgValue ; } else { if ( this . _changed ( this . _lastAvg , avgValue ) ) { this . emit ( \"change\" , avgValue , this . _lastAvg ) ; } this . _lastAvg = avgValue ; } } . bind ( this ) ) ;", "del_tokens": "//TODO: implement on(\"change\")", "commit_type": "add"}
{"commit_tokens": ["Remove", "leftover", "console", ".", "log"], "add_tokens": "privkey : new Buffer ( pki . privateKeyToPem ( keys . privateKey ) )", "del_tokens": "console . log ( pem ) privkey : pki . privateKeyToPem ( keys . privateKey )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "compressing", "a", "zero", "-", "sized", "stream"], "add_tokens": "if ( d === null ) return XXH . digest ( c )", "del_tokens": "if ( d === null ) return XXH . digest ( c )", "commit_type": "fix"}
{"commit_tokens": ["creating", "and", "adding", "a", "custom", "-", "editor", "-", "style", ".", "css"], "add_tokens": ". pipe ( gulp . dest ( './css' ) ) . pipe ( rename ( 'custom-editor-style.css' ) ) var stream = gulp . src ( './sass/*.scss' ) . pipe ( gulp . dest ( './css' ) ) . pipe ( rename ( 'custom-editor-style.css' ) ) return stream ; var stream = gulp . src ( basePaths . node + 'bootstrap/dist/js/**/*.js' ) return stream ;", "del_tokens": "gulp . src ( './sass/*.scss' ) gulp . src ( basePaths . node + 'bootstrap/dist/js/**/*.js' )", "commit_type": "create"}
{"commit_tokens": ["Add", "new", "line", "to", "end", "-", "of", "-", "file", "and", "delete", "_navigation", ".", "scss"], "add_tokens": "} ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "ability", "for", "deep", "models", "in", "modelReducer"], "add_tokens": "var modelPath = ( 0 , _toPath2 . default ) ( model ) ; if ( ! action . model ) return state ; if ( path [ 0 ] !== modelPath [ 0 ] ) { var localPath = path . slice ( modelPath . length ) ;", "del_tokens": "if ( path [ 0 ] !== model ) { var localPath = path . slice ( 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "error", "handlers"], "add_tokens": "this . errorHandlers = [ ] ; this . error = function ( middleware ) { this . errorHandlers . push . apply ( this . errorHandlers , flatten ( middleware ) ) ; } ; var that = this ; return that . handleError ( err , req , res , next ) ; this . handleError = function ( err , req , res , next ) { var errorHandlers = this . errorHandlers ; var i = 0 ; function processNext ( err ) { if ( ! err ) return next ( ) ; var handler = errorHandlers [ i ++ ] ; if ( ! handler || i > errorHandlers . length ) return next ( err ) ; handler ( err , req , res , processNext ) ; } processNext ( err ) ; } ; } ;", "del_tokens": "return next ( err ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "build", "tool", "for", "chrome", "extension", "updated", "icon"], "add_tokens": "chrome . devtools . inspectedWindow . eval ( fetaStr , function ( result , isException ) { if ( isException ) alert ( \"the page is not using jQuery\" ) ; else alert ( \"The page is using jQuery v\" + result ) ; } ) ; } ) ;", "del_tokens": "loadFeta ( ) ; / *chrome.devtools.inspectedWindow.eval( \"typeof jQuery !== 'undefined'\" , function ( result , isException ) { if ( isException ) alert ( \"the page is not using jQuery\" ) ; else alert ( \"The page is using jQuery v\" + result ) ; } ) ; * / } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "recursion", "issue", "when", "using", "es6", "-", "promise"], "add_tokens": "// Silently ignore invalid or empty input. if ( objType ( opt ) !== 'object' ) { return this ; } // Cast self into a Promise to avoid es6-promise recursively defining `then`. var selfPromise = ( '_state' in self ) ? Worker . convert ( Object . assign ( { } , self ) , Promise . prototype ) : self ; var returnVal = Promise . prototype . then . call ( selfPromise , function then_pre ( val ) { // Cast self into a Promise to avoid es6-promise recursively defining `then`. var selfPromise = ( '_state' in self ) ? Worker . convert ( Object . assign ( { } , self ) , Promise . prototype ) : self ; var returnVal = Promise . prototype . then . call ( selfPromise , onFulfilled , onRejected ) ;", "del_tokens": "// TODO: Test null/undefined input to this function. var returnVal = Promise . prototype . then . call ( self , function then_pre ( val ) { var returnVal = Promise . prototype . then . call ( self , onFulfilled , onRejected ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "custom", "[]", "and", "[]", "=", "using", "collection", "getters", "and", "setters", "."], "add_tokens": "addFeatureOption ( 'blockBinding' , Kind . es6 ) ; addFeatureOption ( 'restParameters' , Kind . es6 ) ; addFeatureOption ( 'spread' , Kind . es6 ) ; addFeatureOption ( 'modules' , Kind . harmony ) ; addFeatureOption ( 'collections' , Kind . experimental ) ; addBoolOption ( 'debug' ) ;", "del_tokens": "addFeatureOption ( 'spread' , Kind . es6 ) ; addFeatureOption ( 'restParameters' , Kind . es6 ) ; addFeatureOption ( 'blockBinding' , Kind . es6 ) ; addFeatureOption ( 'modules' , Kind . harmony ) ; addBoolOption ( 'debug' ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "angular", "html", "page", "name"], "add_tokens": "templateUrl : 'app/pages/<%= pageSetFolder %>/<%= page.pageAngularName %>.html' ,", "del_tokens": "templateUrl : 'app/pages/<%= pageSetFolder %>/<%= page.pageName %>.html' ,", "commit_type": "fix"}
{"commit_tokens": ["remove", "support", "for", "crypto", ".", "pseudoRandomBytes", "in", "node", "11", "+"], "add_tokens": "var v11plus = semver . gte ( process . version , '11.0.0' ) ; var toWrap = [ ] ; if ( ! v11plus ) { toWrap . push ( 'pseudoRandomBytes' ) ; } massWrap ( crypto , toWrap , activator ) ;", "del_tokens": "massWrap ( crypto , [ 'pseudoRandomBytes' , ] , activator ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "closing", "bracket", "for", "alpha", "not", "showing"], "add_tokens": "return \"alpha(opacity=\" + ( this . value . toCSS ? this . value . toCSS ( ) : this . value ) + \")\" ;", "del_tokens": "return \"alpha(opacity=\" + ( this . value . toCSS ? this . value . toCSS ( ) : this . value + \")\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "grunt", "to", "project", "and", "updated", "readme"], "add_tokens": "} ; } ; } ; } ) ;", "del_tokens": "} } } } )", "commit_type": "add"}
{"commit_tokens": ["Add", "parser", "tests", "for", "data", ".", "json", "and", "fix", "discovered", "issues"], "add_tokens": "if ( ! xml ) { callback ( new Error ( 'XML input was null or empty' ) , presskit ) return } if ( ! json ) { callback ( new Error ( 'JSON input was null or empty' ) , presskit ) return } try { var o = JSON . parse ( json ) } catch ( err ) { callback ( err , presskit ) return }", "del_tokens": "if ( ! xml ) callback ( new Error ( 'XML input was null or empty' ) , presskit ) if ( ! json ) callback ( new Error ( 'JSON input was null or empty' ) , presskit ) var o = JSON . parse ( json )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "clean", "task", "to", "cleanup", "the", "branch", ".", "*", "files", "generated", "by", "tests"], "add_tokens": "'use strict' ; module . exports = function ( grunt ) { clean : [ 'test/**/branch.*' ] , 'Gruntfile.js' , 'tasks/**/*.js' , 'test/**/*.js' grunt . loadNpmTasks ( 'grunt-contrib-clean' ) ; grunt . registerTask ( 'default' , [ 'clean' , 'jshint' , 'nodeunit' ] ) ; } ;", "del_tokens": "'use strict' ; module . exports = function ( grunt ) { 'Gruntfile.js' , 'tasks/**/*.js' , 'test/**/*.js' grunt . registerTask ( 'default' , [ 'jshint' , 'nodeunit' ] ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["use", "event", ".", "scope", "in", "your", "event", "handlers", "to", "get", "the", "scope"], "add_tokens": "currentInnerScope = \"\" , scope = currentInnerScope , / *functionLookUp allows us to store functions in D.fx after D . linkJsAndDom ( ) and use the functions that are in D . fx at that moment . event . scope = scope ; The public D . vr . a variable returns this private js variable console . warn ( \"D.vr.x= string || bool , not undefined!\" ) ; D . vr [ scope ] [ variableName ] D . el [ scope ] [ elementName ] currentInnerScope = scope ; currentInnerScope = \"\" ; 1. D . templateRender 4. Use D . forgetScope to let the garbage collector free space in memory", "del_tokens": "/ *functionLookUp allows us to store functions in dom99.fx after dom99 . linkJsAndDom ( ) and use the functions that are in D . fx at that moment . The public dom99 . vr . a variable returns this private js variable console . warn ( \"dom99.vr.x= string || bool , not undefined!\" ) ; dom99 . vr [ scope ] [ variableName ] dom99 . el [ scope ] [ elementName ] } if ( ! variablesSubscribers . hasOwnProperty ( scope ) ) { //usingInnerScope = true; //usingInnerScope = false; 1. dom99 . templateRender 4. Use dom99 . forgetScope to let the garbage collector free space in memory", "commit_type": "use"}
{"commit_tokens": ["Remove", "defaultParams", "implemenetation", "replacing", "occurances", "with", "_", ".", "extend"], "add_tokens": "var _ = require ( 'lodash' ) ; params = _ . extend ( {", "del_tokens": "var defaultParams = require ( '../utils' ) . defaultParams ; params = defaultParams ( {", "commit_type": "remove"}
{"commit_tokens": ["Updating", "the", "employees", "unit", "test", "with", "a", "CREATE", "TABLE", "statement", "."], "add_tokens": "db . connect ( function ( error ) { var sql = 'CREATE TABLE IF NOT EXISTS `employees` (`id` int(10) unsigned NOT NULL AUTO_INCREMENT, `firstName` varchar(45) NOT NULL, `lastName` varchar(45) NOT NULL, `age` tinyint(3) unsigned DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;' ; if ( error ) return done ( error ) ; db . query ( sql , done ) ; } ) ;", "del_tokens": "db . connect ( done ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "build", "options", "not", "being", "exported"], "add_tokens": "export function getBuildOptions ( args ) {", "del_tokens": "function getBuildOptions ( args ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "waves", "-", "block", "default", "as", "not", "necessary"], "add_tokens": "classes = classes || [ ] ;", "del_tokens": "classes = classes || [ 'waves-block' ] ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "injection", "issue", "for", "testing", "purposes"], "add_tokens": "var dep = deps [ param ] ; paramModules . push ( dep || deps [ param ] || me . injector . loadModule ( param , moduleStack ) ) ;", "del_tokens": "paramModules . push ( deps [ param ] || me . injector . loadModule ( param , moduleStack ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "segment", "as", "word", "to", "define", "pie", "segments"], "add_tokens": "const makeSegmentTransitionStyle = ( duration , easing ) => ( { let lastSegmentAngle = props . startAngle ; ? makeSegmentTransitionStyle ( props . animationDuration , props . animationEasing ) // Hide/reveal a segment? const startAngle = lastSegmentAngle ; lastSegmentAngle += dataEntry . degrees ; this . hideSegments = true ; this . hideSegments = false ; { makeSegments ( normalizedData , this . props , this . hideSegments ) }", "del_tokens": "const makePathTransitionStyle = ( duration , easing ) => ( { let lastPathAngle = props . startAngle ; ? makePathTransitionStyle ( props . animationDuration , props . animationEasing ) // Hide/reveal a path segment? const startAngle = lastPathAngle ; lastPathAngle += dataEntry . degrees ; this . hidePaths = true ; this . hidePaths = false ; { makeSegments ( normalizedData , this . props , this . hidePaths ) }", "commit_type": "use"}
{"commit_tokens": ["Use", "opn", "to", "open", "the", "default", "browser", "in", "a", "cross", "-", "platform", "way"], "add_tokens": "var opn = require ( 'opn' ) ; opn ( 'http://localhost:3000/' ) ;", "del_tokens": "try { execSync ( 'ps cax | grep \"Google Chrome\"' ) ; execSync ( 'open -a \"Google Chrome\" http://localhost:3000/' ) ; } catch ( e ) { // Do nothing if Chrome isn't opened or cannot be opened }", "commit_type": "use"}
{"commit_tokens": ["Add", "option", "to", "ignore", "methods", "for", "sort", "-", "object", "-", "props", "rule"], "add_tokens": "var ignoreMethods = context . options [ 0 ] . ignoreMethods ; if ( ignoreMethods && prop . value . type === \"FunctionExpression\" ) { return prop ; } var lastPropId , propId ; if ( prop . key . type === \"Identifier\" ) { lastPropId = lastProp . key . name ; propId = prop . key . name ; } else if ( prop . key . type === \"Literal\" ) { lastPropId = lastProp . key . value ; propId = prop . key . value ; } if ( propId == null ) console . log ( prop ) ; lastPropId = lastPropId . toLowerCase ( ) ; propId = propId . toLowerCase ( ) ; if ( propId < lastPropId ) { \"sort-object-props\" : [ 1 , { ignoreCase : true , ignoreMethods : false } ]", "del_tokens": "var lastPropName = lastProp . key . name ; var propName = prop . key . name ; lastPropName = lastPropName . toLowerCase ( ) ; propName = propName . toLowerCase ( ) ; if ( propName < lastPropName ) { \"sort-object-props\" : [ 1 , \"ignoreCase\" ]", "commit_type": "add"}
{"commit_tokens": ["fix", "window", "title", "background", "color", "etc"], "add_tokens": "title : 'Patchwork' , backgroundColor : '#EEE' ,", "del_tokens": "title : 'Ferment' , backgroundColor : '#444' ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "spaces", "to", "align", "columns"], "add_tokens": "var each = Array . prototype . forEach ; var accordions = [ ] ; } . debounce ( 100 ) ) ;", "del_tokens": "var each = Array . prototype . forEach ; var accordions = [ ] ; } . debounce ( 100 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "test", "for", "setting", "even", "when", "unnecessary"], "add_tokens": "// Fallback `imagemagick' setting (to rollback when no longer using the engine) options . imagemagick = options . imagemagick || false ; console . log ( 'options.imagemagick' , options . imagemagick ) ;", "del_tokens": "console . log ( 'settings2' , settings ) ;", "commit_type": "add"}
{"commit_tokens": ["improved", "subscribed", "status", "accuracy", "for", "aggregator"], "add_tokens": "if ( ! aggregator . subscribed ) { aggregator . subscribed = false ;", "del_tokens": "var shutdown = false ; if ( shutdown ) { shutdown = true ; aggregator . subscribed = false ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "babel", "transformation", "of", "json", "file", "import", "string", "literal"], "add_tokens": "const renameImportTransform = require ( './transforms/rename-import-json' ) ; const renamedSource = renameJSXTransform ( templateContent , 'component' , componentName ) ; const sourceWithRenamedImport = renameImportTransform ( renamedSource , componentName ) ; sourceWithRenamedImport ,", "del_tokens": "renameJSXTransform ( templateContent , 'Component' , componentName ) ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "FB", "example", "using", "virtualhost", "."], "add_tokens": "var base_url = 'http://example.com:7070' ;", "del_tokens": "var base_url = 'http://127.0.0.1:7070' ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "changing", "attributes", "from", "module", "options"], "add_tokens": "if ( typeof options . html5embed . audio_attributes === \"undefined\" ) { options . html5embed . audio_attributes = 'controls preload=\"metadata\"' } return [ '<audio ' + options . html5embed . audio_attributes + '>' , if ( typeof options . html5embed . video_attributes === \"undefined\" ) { options . html5embed . video_attributes = 'controls preload=\"metadata\"' } return [ '<video ' + options . html5embed . video_attributes + '>' , opt . html5embed = options . html5embed ; opt . html5embed = options . html5embed ;", "del_tokens": "return [ '<audio width=\"320\" controls class=\"audioplayer\"' , return [ '<video width=\"320\" height=\"240\" class=\"audioplayer\" controls>' ,", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "a", "getter", "only", "function"], "add_tokens": "for ( i in self . __rPermissions [ binding . arg ] ) { for ( i in binding . value ) { for ( i in self . __rPermissions [ binding . arg ] ) { while ( ( item = preParams [ i ++ ] ) ) { var currScriptFn = document . currentScript currScriptFn = currScriptFn || ( function ( ) { notGlobal = Boolean ( currScriptFn . getAttribute ( 'notGlobal' ) ) } catch ( idk ) { console . error ( idk ) } /* global Vue */", "del_tokens": "for ( var i in self . __rPermissions [ binding . arg ] ) { for ( var i in binding . value ) { for ( var i in self . __rPermissions [ binding . arg ] ) { while ( item = preParams [ i ++ ] ) { vnode . __r document . currentScript = document . currentScript || ( function ( ) { notGlobal = Boolean ( document . currentScript . getAttribute ( 'notGlobal' ) ) } catch ( e ) { e }", "commit_type": "fix"}
{"commit_tokens": ["implemented", "length", "of", "nodeview", "interface"], "add_tokens": "function extendStringTable ( st ) { st . getEntry = getStringTableEntry ; } function createNodesView ( pg ) { var length ; if ( pg . nodes . length !== 0 ) { throw new Error ( 'primitivegroup.nodes.length !== 0 not supported yet' ) ; } length = 0 ; if ( pg . dense ) { length = pg . dense . id . length ; } return { length : length } ; } function extendPrimitiveGroup ( pg ) { pg . nodesView = createNodesView ( pg ) ; } var data , i ; // extend stringtable extendStringTable ( data . stringtable ) ; // extend primitivegroup for ( i = 0 ; i < data . primitivegroup . length ; ++ i ) { extendPrimitiveGroup ( data . primitivegroup [ i ] ) ; }", "del_tokens": "var data ; data . stringtable . getEntry = getStringTableEntry ;", "commit_type": "implement"}
{"commit_tokens": ["allowing", "teardown", "of", "all", "handlers"], "add_tokens": "off : function ( handler , queueName ) { if ( handler === undefined ) { if ( queueName === undefined ) { this . handlers . delete ( [ ] ) ; } else { this . handlers . delete ( [ queueName ] ) ; } this . handlers . delete ( [ queueName || \"mutate\" , handler ] ) ;", "del_tokens": "off : function ( handler , queue ) { if ( ! handler ) { this . handlers . delete ( [ queue || \"mutate\" ] ) ; this . handlers . delete ( [ queue || \"mutate\" , handler ] ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "bower", "config", "to", "unit", "tests"], "add_tokens": "define ( [ \"lib/rjasmine/dist/rjasmine\" , \"lib/jquery/dist/jquery.min\" ] , function ( rjasmine ) {", "del_tokens": "define ( [ \"libs/js/rjasmine\" , \"libs/js/jquery-1.11.0.min\" ] , function ( rjasmine ) {", "commit_type": "add"}
{"commit_tokens": ["updated", "to", "the", "lates", "message", ".", "js", ";", "-", ")"], "add_tokens": "var keySafe = key . replace ( / - / , '_' ) . toLowerCase ( ) ; var valueSafe = value . replace ( / ^\\s+ / g , '' ) . replace ( / \\s+$ / g , '' ) ; if ( keySafe . match ( / variable / ) !== null ) { var variable = valueSafe . split ( \"=\" ) ; this . variables [ variable [ 0 ] ] = variable [ 1 ] ; } else { this . set ( keySafe , valueSafe ) ; }", "del_tokens": "this . set ( key . replace ( / - / , '_' ) . toLowerCase ( ) , value . replace ( / ^\\s+ / g , '' ) . replace ( / \\s+$ / g , '' ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "page", "dimension", "specification", "in", "page", "at", "-", "rules"], "add_tokens": "this . pageManager = new vivliostyle . page . PageManager ( cascadeInstance , this . style . pageScope , this . rootPageBoxInstance , self , docElementStyle ) ; // If there is a page master generated for @page rules, use it. var pageMaster = this . pageManager . getPageRulePageMaster ( ) ; if ( pageMaster ) { return pageMaster ; } var pageMasters = /** @type {Array.<adapt.pm.PageMasterInstance>} */ ( this . rootPageBoxInstance . children ) ; pageMaster = pageMasters [ i ] ; // Skip a page master generated for @page rules if ( pageMaster . pageBox . pseudoName === vivliostyle . page . pageRuleMasterPseudoName ) continue ;", "del_tokens": "this . pageManager = new vivliostyle . page . PageManager ( cascadeInstance , rootBox . scope , self , docElementStyle ) ; var pageMasters = /** @type {Array.<adapt.pm.PageMasterInstance>} */ ( this . rootPageBoxInstance . children ) ; var pageMaster = pageMasters [ i ] ; pageMaster = this . pageManager . getPageRuleAppliedPageMaster ( pageMaster ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "IPFS_GATEWAY_PROTOCOL", "env", "var", ".", "Update", "README"], "add_tokens": "// If connecting to a local IPFS daemon, set envionment variables: // IPFS_DOMAIN = 127.0.0.1 // IPFS_API_PORT = 5001 // IPFS_GATEWAY_PORT = 8080 // IPFS_GATEWAY_PROTOCOL = http this . ipfsProtocol = process . env . IPFS_GATEWAY_PROTOCOL || 'https'", "del_tokens": "// If connecting to a local IPFS daemon, set envionment variables // IPFS_DOMAIN = 127.0.0.1 and IPFS_API_PORT = 5001 this . ipfsProtocol = 'https'", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "CertificateManagerOnline", "and", "Native", "CertificateManager"], "add_tokens": "uu$ . CertificateManagerOnline = { if ( ! b$ . App . getSerialNumber ( ) ) return if ( ! b$ . App . getSerialNumber ( ) ) return if ( ! b$ . App . getSerialNumber ( ) ) return if ( ! b$ . App . getSerialNumber ( ) ) return if ( ! b$ . App . getSerialNumber ( ) ) return", "del_tokens": "uu$ . CertificateManager = {", "commit_type": "add"}
{"commit_tokens": ["added", "ENV", "option", "to", "skip", "the", "tests", "updated", "docs"], "add_tokens": "if ( ! force && ! process . env . SKIP_NODE_SASS_TESTS ) {", "del_tokens": "if ( ! force ) {", "commit_type": "add"}
{"commit_tokens": ["added", "binding", "support", "for", "nested", "components"], "add_tokens": "ApiService . addViewApi ( controller ) ;", "del_tokens": "ApiService . bindApiDownward ( controller ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "forward", "url", "to", "controller"], "add_tokens": "parsedUrl : core . copy ( this . parsedUrl ) , forwardUrl : this . forward . bind ( this )", "del_tokens": "parsedUrl : core . copy ( this . parsedUrl )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bubbles", "positioning", "when", "the", "handleSize", "is", "modified", "."], "add_tokens": "this . setWidth ( this . selBar , Math . abs ( this . maxH . rzsl - this . minH . rzsl ) + this . handleHalfWidth ) ;", "del_tokens": "this . setWidth ( this . selBar , Math . abs ( this . maxH . rzsl - this . minH . rzsl ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "decodeURI", "call", ".", "Now", "gzip", "compression", "level", "is", "not", "sent", "to", "the", "client", "."], "add_tokens": "rsc : decodeURI ( location . href ) . slice ( prefix . length ) . replace ( / (\\?|#).*$ / , '' ) , code : code", "del_tokens": "gzip = wapp_gzip , rsc : location . href . slice ( prefix . length ) . replace ( / (\\?|#).*$ / , '' ) , code : code , gzip : gzip gzip = null ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "zoom", "."], "add_tokens": "describe ( \"zoom\" , function ( ) { it ( \"should support a decimal value\" , function ( ) { test_cloudinary_url ( \"test\" , { zoom : 1.2 } , window . location . protocol + \"//res.cloudinary.com/test123/image/upload/z_1.2/test\" , { } ) ; } ) } )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "on", "insert", "WIP"], "add_tokens": "function $contains ( a , b ) { if ( Array . isArray ( a ) ) { return a . indexOf ( b ) !== - 1 ; } if ( typeof a === 'string' ) { return a . indexOf ( b ) !== - 1 ; } if ( typeof a === 'object' ) { return a . hasOwnProperty ( b ) ; } } '$regex' : $regex , '$contains' : $contains doc . meta = { } ;", "del_tokens": "'$regex' : $regex", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "local", "auth", "service"], "add_tokens": "if ( ! func ) { func = function ( err , user , info ) { req . user = user return next ( err ) ; } } self . _passport . authenticate ( serviceName , self . _getService ( req ) . conf ( ) . authconf , func ) ( req , res , function ( err ) { next ( err ) } ) next ( err )", "del_tokens": "self . _passport . authenticate ( serviceName , self . _getService ( req ) . conf ( ) . authconf , func ) ( req , res , next ) if ( err ) { return next ( err ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "mutable", "variable", ".", "Derp", "."], "add_tokens": "( function ( e ) { DelimiterStream . prototype [ e ] = function ( ) { this . readableStream [ e ] . apply ( this . readableStream , arguments ) ; } ; } ( passthruEvents . pop ( ) ) ) ;", "del_tokens": "var e = passthruEvents . pop ( ) ; DelimiterStream . prototype [ e ] = function ( ) { this . readableStream [ e ] . apply ( this . readableStream , arguments ) ; } ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "pass", "a", "promise", "as", "data", "object", "."], "add_tokens": "var qVar = undefined ; var rootScope = undefined ; inject ( function ( _SpringDataRestAdapter_ , $httpBackend , $q , $rootScope ) { qVar = $q ; rootScope = $rootScope ; this . q = qVar ; this . rootScope = rootScope ;", "del_tokens": "inject ( function ( _SpringDataRestAdapter_ , $httpBackend ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "debug", "registry", "server", "to", "register"], "add_tokens": "var registryServer = process . env . REGISTRY_SERVER || 'http://registry.jsonresume.org' ; . post ( registryServer + '/user' )", "del_tokens": ". post ( 'http://registry.jsonresume.org/user' )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "mainFile", "value", "."], "add_tokens": ", mainFile = package . components . scripts [ 0 ]", "del_tokens": ", mainFile = package . components . scripts", "commit_type": "fix"}
{"commit_tokens": ["make", "ngrok", "an", "dev", "dependency"], "add_tokens": "const ngrok = requireIfExists ( 'ngrok' ) ; // start ngrok if enabled if ( ngrok && config . tunnel ) { if ( ngrok ) ngrok . kill ( ) ; / ** * Get the module if it exists , otherwise get null . * @ param { string } name * @ returns { * } * / function requireIfExists ( name ) { try { return require ( name ) ; } catch ( e ) { if ( e . code === 'MODULE_NOT_FOUND' ) return null ; throw e ; } }", "del_tokens": "const ngrok = require ( 'ngrok' ) ; // start ngrock if enabled if ( config . tunnel ) { ngrok . kill ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "error", "if", "bundle", "dependency", "threshold", "was", "reached"], "add_tokens": "var threshold = 10 ; while ( ! _ . isEmpty ( dependencies ) && count <= threshold ) { if ( count >= threshold ) { throw new Error ( 'Bundle dependency list could not be created within the depth threshold' ) ; }", "del_tokens": "while ( ! _ . isEmpty ( dependencies ) && count < 10 ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "ntlm", ":", "boolean", "option", "to", "lib", "/", "proxy", ".", "js", "which", "when", "true", "adds", "a", "proxy", "handler", "from", "http", "-", "proxy", "to", "split", "ntlm", "auth", "headers", "into", "two", "fields", "instead", "of", "a", "single", "array", "."], "add_tokens": "//To Support NTLM auth if ( opts . ntlm ) { proxy . on ( 'proxyRes' , function ( proxyRes ) { var key = 'www-authenticate' ; proxyRes . headers [ key ] = proxyRes . headers [ key ] && proxyRes . headers [ key ] . split ( ',' ) ; } ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "to", "use", "logger", ".", "info", "()", "method"], "add_tokens": "it ( 'logger is called if elapsed time is above configured one' , async function ( ) { console . info = function ( what ) { logWasCalled = what && what . action && what . action === 'acquire' ; // uncomment the following line for debugging // consoleLogFunc.apply(console, arguments);", "del_tokens": "it ( 'log is called if elapsed time is above configured one' , async function ( ) { console . error = function ( what ) { const whatObj = JSON . parse ( what ) ; logWasCalled = whatObj && whatObj . action && whatObj . action === 'acquire' ; consoleLogFunc . apply ( console , arguments ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "Tooltip", "bug", "in", "Chrome"], "add_tokens": "$ ( '[data-rel=tooltip]' ) . tooltip ( { container : 'body' } ) ;", "del_tokens": "$ ( '[data-rel=tooltip]' ) . tooltip ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "in", "ota", "help", "output"], "add_tokens": "+ \"is used to select the target. To set it, run e.g. \\\"pinoccio config ota.default-target 123\\\".\\n\"", "del_tokens": "+ \"is used to select the target. To set it, run e.g. \\\"ota config ota.default-target 123\\\".\\n\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "test", "of", "polyline", "feature"], "add_tokens": "if ( attrs . testing ) { if ( attrs . testing ) { // Expose the markers object, for testing purposes if ( attrs . testing ) { if ( attrs . testing ) { if ( attrs . testing ) { if ( attrs . path && scope . path ) { // For testing purposes if ( attrs . testing ) { scope . polyline = polyline ; }", "del_tokens": "leafletMarkers : \"=leafletMarkers\" , if ( attrs . map ) { if ( attrs . leafletMarkers ) { // Expose the map object, for testing purposes if ( attrs . leafletMarkers ) { if ( attrs . leafletMarkers ) { if ( attrs . leafletMarkers ) { if ( attrs . path ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "hook", "for", "cancelling", "transitions"], "add_tokens": "urlStore . addChangeListener ( this . _handleRouteChange . bind ( this ) ) ; _handleRouteChange : function ( ) { var currentPath = urlStore . getCurrentPath ( ) ; // TODO: Use route handlers here to determine whether or // not the transition should be cancelled. this . _updateComponentProps ( currentPath ) ; } ,", "del_tokens": "urlStore . addChangeListener ( function ( ) { this . _updateComponentProps ( urlStore . getCurrentPath ( ) ) ; } . bind ( this ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "nested", "cells"], "add_tokens": "if ( cell . extends ) { results . push ( this . _validateSubCell ( ` ${ path } ` , cell . extends , subModel ) ) } _ . forEach ( ( child , index ) => { results . push ( this . _validateCell ( ` ${ path } ${ index } ` , child , subModel ) ) } )", "del_tokens": "results . push ( this . _validateSubCell ( ` ${ path } ` , cell . extends , subModel ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "stable", "A", "-", "Frame", "for", "now", "."], "add_tokens": "var AFRAME = window . AFRAME . aframeCore || window . AFRAME ;", "del_tokens": "var AFRAME = require ( 'aframe' ) ;", "commit_type": "use"}
{"commit_tokens": ["adding", "ability", "to", "increment", "version", "number", "to", "build"], "add_tokens": "pkg : grunt . file . readJSON ( 'package.json' ) , // \"grunt-version\": \"https://github.com/kswedberg/grunt-version/tarball/master\" version : { check : { src : [ 'package.json' ] } , release : { options : { release : 'patch' } , src : [ 'package.json' ] } } , //\"grunt-version\": \"https://github.com/kswedberg/grunt-version/tarball/master\" // issue with putting this in the package.json file, is that it updates it's own line since it has version\": in it. grunt . loadNpmTasks ( 'grunt-version' ) ;", "del_tokens": "pkg : '<json:package.json>' ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "JSDoc", "for", "Bootstrap", "s", "modal", "extern"], "add_tokens": "* @ param { ( string | Object . < string , * > ) = } opt_options", "del_tokens": "* @ param { string | Object . < string , * > | undefined } opt_options", "commit_type": "fix"}
{"commit_tokens": ["updated", "subgrunt", "to", "this", ".", "filesSrc"], "add_tokens": "// Run Gruntfiles in given directories. grunt . util . async . forEachSeries ( this . filesSrc , function ( gruntfile , next ) {", "del_tokens": "// Run sub-grunt files in all projects. var files = grunt . file . expandFiles ( this . file . src ) ; grunt . util . async . forEachSeries ( files , function ( gruntfile , next ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "CREATE", "to", "BlobUtilities", ".", "SharedAccessPermissions", "and", "Added", "CREATE", "to", "FileUtilities", ".", "SharedAccessPermissions"], "add_tokens": "ADD : 'a' , CREATE : 'c' ,", "del_tokens": "ADD : 'a' ,", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "excluded", "strings", "from", "the", "output"], "add_tokens": "entities : true , exclude : [ 'html' , 'js' ] } ) , dummyTag = [ '<my-tag>' , '<p>{ hi }</p>' , 'this.hi = \"hi\"' , '<style scoped>' , ' :scope { color: red; }' , '</style>' , '</my-tag>' ] . join ( '\\n' ) expect ( compiler . compile ( dummyTag , { exclude : [ 'html' ] } ) ) . to . be ( \"riot.tag2('my-tag', '', 'my-tag,[riot-tag=\\\"my-tag\\\"] { color: red; }', '', function(opts) {\\nthis.hi = \\\"hi\\\"\\n\\n});\" ) expect ( compiler . compile ( dummyTag , { } ) ) . to . be ( \"riot.tag2('my-tag', '', 'my-tag,[riot-tag=\\\"my-tag\\\"] { color: red; }', '', function(opts) {\\n});\" ) expect ( compiler . compile ( dummyTag , { exclude : [ 'css' ] } ) ) . to . be ( \"riot.tag2('my-tag', '<p>{hi}</p>', '', '', function(opts) {\\nthis.hi = \\\"hi\\\"\\n\\n}, '{ }');\" ) expect ( parts [ 0 ] . html ) . to . not . match ( / style / )", "del_tokens": "entities : true , } )", "commit_type": "remove"}
{"commit_tokens": ["Use", ".", "worker", "()", "to", "run", "things"], "add_tokens": "\" var app = Elm.Main.worker();\\n\" +", "del_tokens": "\" var app = Elm.Main.embed({appendChild: function() {}});\\n\" +", "commit_type": "use"}
{"commit_tokens": ["Updated", "paths", "to", "platform", "-", "specific", "config", ".", "xml", "files", "."], "add_tokens": "ios : path . join ( projectRoot , 'platforms' , 'ios' , path . basename ( projectRoot ) , 'config.xml' ) , android : path . join ( projectRoot , 'platforms' , 'android' , 'res' , 'xml' , 'config.xml' )", "del_tokens": "ios : path . join ( projectRoot , 'platforms/ios/' , path . basename ( projectRoot ) , 'config.xml' ) , android : path . join ( projectRoot , 'platforms/android/res/xml/config.xml' )", "commit_type": "update"}
{"commit_tokens": ["Add", "some", "more", "to", "test", ".", "x", "fix", "test", "description", "in", "union", "test"], "add_tokens": "describe ( 'Union.isValid' , function ( ) { it ( \"returns true for instances of the union\" , function ( ) {", "del_tokens": "describe ( 'Struct.isValid' , function ( ) { it ( \"returns true for instances of the struct\" , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["fixing", "bug", "in", "fakery", ".", "g", ".", "fullname", "()"], "add_tokens": "return providers . firstname ( ) + ' ' + providers . lastname ( ) ;", "del_tokens": "return store . firstname ( ) + ' ' + store . lastname ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["adds", "activeDuration", "default", "5", "minutes"], "add_tokens": "const ACTIVE_DURATION = 1000 * 60 * 5 ; this . activeDuration = opts . activeDuration ; var expiresAt = this . createdAt + this . duration ; var now = Date . now ( ) ; if ( expiresAt < now ) // if expiration is soon, push back a few minutes to not interrupt user else if ( expiresAt - now < this . activeDuration ) { this . createdAt += this . activeDuration ; this . dirty = true ; this . updateDefaultExpires ( ) ; } opts . activeDuration = 'activeDuration' in opts ? opts . activeDuration : ACTIVE_DURATION ;", "del_tokens": "if ( ( this . createdAt + this . duration ) < new Date ( ) . getTime ( ) )", "commit_type": "add"}
{"commit_tokens": ["making", "the", "package", "use", "the", "same", "db", "connection", "that", "the", "modules", "use", "and", "require", "package", "for", "settings", "on", "moduleLoad", "event", "(", "refactor", "needed", ")"], "add_tokens": "var database = container . get ( 'database' ) ; // Load the package module for mongoose require ( '../modules/package' ) ( database ) ; if ( path . indexOf ( '.' + ext ) == - 1 ) return ; return string . charAt ( 0 ) . toUpperCase ( ) + string . slice ( 1 ) ;", "del_tokens": "// Load the package module for mongoose require ( '../modules/package' ) ; if ( path . indexOf ( '.' + ext ) == - 1 ) return ; return string . charAt ( 0 ) . toUpperCase ( ) + string . slice ( 1 ) ;", "commit_type": "make"}
{"commit_tokens": ["move", "test", "reports", "to", "new", "repo", ":", "zenozeng", "/", "p5", ".", "js", "-", "svg", "-", "test", "-", "reports"], "add_tokens": "dir : 'test/report/coverage/' ,", "del_tokens": "dir : 'test/coverage/' ,", "commit_type": "move"}
{"commit_tokens": ["Implement", "support", "for", "not", "requeueing", "nacked", "messages"], "add_tokens": "var nackFun = function ( requeue ) { subChannel . nack ( message , false , requeue ) ;", "del_tokens": "var nackFun = function ( ) { subChannel . nack ( message ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "test", "for", "polyfill", "and", "replaced", "rejects", "with", "throws"], "add_tokens": "return new Promise ( resolve => if ( error ) throw new Error ( error ) ; else throw new Error ( ` ${ type } ${ pathStr } ` ) ; return new Promise ( resolve => if ( error ) throw new Error ( error ) ; return new Promise ( resolve => else throw new Error ( data ) ; return new Promise ( resolve => if ( error ) throw new Error ( error ) ; return new Promise ( resolve => if ( error ) throw new Error ( error ) ;", "del_tokens": "return new Promise ( ( resolve , reject ) => if ( error ) reject ( new Error ( error ) ) ; else reject ( new Error ( ` ${ type } ${ pathStr } ` ) ) ; return new Promise ( ( resolve , reject ) => if ( error ) reject ( new Error ( error ) ) ; return new Promise ( ( resolve , reject ) => else reject ( new Error ( data ) ) ; return new Promise ( ( resolve , reject ) => if ( error ) reject ( new Error ( error ) ) ; return new Promise ( ( resolve , reject ) => if ( error ) reject ( new Error ( error ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "HttpRequestService", "handle", "no", "conten", "-", "type", "header"], "add_tokens": "if ( responseContentIsJson ( res ) ) { req . abort ( ) ; throw e ; } ) ; / ** * Does this response contain JSON ? * * @ param response * @ returns { boolean } * / function responseContentIsJson ( response ) { return response . headers [ \"content-type\" ] && response . headers [ \"content-type\" ] . indexOf ( \"application/json\" ) === 0 ; }", "del_tokens": "if ( res . headers [ \"content-type\" ] . indexOf ( \"application/json\" ) === 0 ) { req . abort ( ) ; throw e ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["use", "old", "2", ">", "&1", "redirect", "operator"], "add_tokens": "cmd = '(' + command + ') > ' + tempName + ' 2>&1' ;", "del_tokens": "cmd = '(' + command + ') &> ' + tempName ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "proxying", "to", "a", "URL", "without", "path"], "add_tokens": "// This is different from normalizePath because in this case we want to // remove the trailing slash even for '/' this . proxyToPath = proxyUrl . pathname . replace ( new RegExp ( '/$' ) , '' ) ;", "del_tokens": "this . proxyToPath = proxyUrl . pathname ;", "commit_type": "fix"}
{"commit_tokens": ["made", "version", "regex", "case", "-", "insensitive", "and", "raised", "version", "requirement", "for", "padding"], "add_tokens": "var getVersion = / ffmpeg version (?:(\\d+)\\.)?(?:(\\d+)\\.)?(\\*|\\d+) / i . exec ( stderr ) ;", "del_tokens": "var getVersion = / ffmpeg version (?:(\\d+)\\.)?(?:(\\d+)\\.)?(\\*|\\d+) / . exec ( stderr ) ; console . log ( stderr ) ; console . log ( getVersion ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "-", "i", "-", "L", "flags", "for", "consistency"], "add_tokens": "withoutWatchapp : ! ! conf [ 'without-watchapp' ] || ! ! conf . w , if ( conf . identities || conf . L ) { - L , -- identities List local codesign identities - i , -- identity 1 C4D1A . . Specify hash - id of the identity to use", "del_tokens": "withoutWatchapp : ! ! conf [ 'without-watchapp' ] || ! ! conf . w , if ( conf . identities || conf . I ) { - i , -- identities List local codesign identities - I , -- identity 1 C4D1A . . Specify hash - id of the identity to use", "commit_type": "fix"}
{"commit_tokens": ["Remove", "\\", "n", "from", "user", "agent", "test", "expect", "calls", "to", "support", "Windows"], "add_tokens": "return expect ( stdout ) . to . match ( / ^cakeUserAgent / ) ; return expect ( stdout ) . to . match ( / ^cakeUserAgent / ) ;", "del_tokens": "return expect ( stdout ) . to . match ( / ^cakeUserAgent\\n / ) ; return expect ( stdout ) . to . match ( / ^cakeUserAgent\\n / ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "missing", "bundle", "exec", "to", "jekyll", "serve", "gulptask"], "add_tokens": "const jekyll = childProc . spawn ( 'bundle' , [ 'exec' , 'jekyll' ,", "del_tokens": "const jekyll = childProc . spawn ( 'jekyll' , [", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "error", "code", "overriding"], "add_tokens": "module . exports = Terror . create ( 'AskerError' , {", "del_tokens": "var AskerError = Terror . create ( 'AskerError' , { // Override Terror UNKNOWN_ERROR code AskerError . CODES [ 'UNKNOWN_ERROR' ] = 908 ; AskerError . MESSAGES [ 908 ] = 'Unknown error during request %requestId% processing %timings% %url%' ; AskerError . CODE_NAMES [ 908 ] = 'UNKNOWN_ERROR' ; module . exports = AskerError ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "a", "postRegistrationHandler", "setting", "."], "add_tokens": "if ( req . app . get ( 'stormpathPostRegistrationHandler' ) ) { req . app . get ( 'stormpathPostRegistrationHandler' ) ( res . locals . user , res , function ( ) { var url = req . query . next || req . app . get ( 'stormpathRedirectUrl' ) ; res . redirect ( 302 , url ) ; } ) ; } else { var url = req . query . next || req . app . get ( 'stormpathRedirectUrl' ) ; res . redirect ( 302 , url ) ; }", "del_tokens": "var url = req . query . next || req . app . get ( 'stormpathRedirectUrl' ) ; res . redirect ( 302 , url ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "issues", "and", "renamed", "ejs", "back", "to", "js"], "add_tokens": "< % if ( errorHandlingStrategy === 'lenient' ) { % > if ( platformElement ) { platformElement . remove ( icon ) ; return generate ( function ( err ) { if ( err ) { < % if ( errorHandlingStrategy === 'warn' ) { % > < % } else if ( errorHandlingStrategy === 'throw' ) { % >", "del_tokens": "< % if ( errorHandlingStrategy === \"lenient\" ) { % > if ( platformElement ) { platformElement . remove ( icon ) ; return generate ( function ( error ) { if ( error ) { < % if ( errorHandlingStrategy === \"warn\" ) { % > < % } else if ( errorHandlingStrategy === \"throw\" ) { % >", "commit_type": "fix"}
{"commit_tokens": ["Improve", "extension", "install", "error", "and", "output", "handling"], "add_tokens": "var streams = require ( '../utils/streams' ) ; var stdout = streams . stdout ( function ( ) { } ) ; stdout . restore ( ) ; deferred . reject ( shell . createError ( 'Unable to install extension module \"%s\"' , moduleName ) ) ; try { extension . initialize ( shell , function ( error , result ) { if ( error ) { deferred . reject ( shell . createError ( 'Error initializing extension' ) ) ; } else { shell . loadedExtensions [ name ] = true ; deferred . resolve ( result ) ; } } ) ; } catch ( e ) { deferred . reject ( shell . createError ( 'Error initializing extension' ) ) ; }", "del_tokens": "deferred . reject ( error ) ; extension . initialize ( shell , function ( error , result ) { if ( error ) { deferred . reject ( error ) ; } else { shell . loadedExtensions [ name ] = true ; deferred . resolve ( result ) ; } } ) ;", "commit_type": "improve"}
{"commit_tokens": ["using", "foreach", "for", "children", "test"], "add_tokens": "* - when a ` ` , it will run the fn against each node , where they are * expected to throw if they are invalid . node . children . forEach ( children ) ;", "del_tokens": "* - when a ` ` , it will ensure that the child nodes all match the * test in that function . ( ie : ` ` must return true ) assert ( node . children . every ( children ) , 'expected the child nodes to pass the function test' ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "all", "polyline", "known", "bugs"], "add_tokens": "isEditable : true , } , addPolyline : function ( ) { this . get ( 'polylines' ) . addObject ( { isEditable : false , path : [ { lat : 0 , lng : 0 } , { lat : 1 , lng : 0 } ] } ) ; } , removePolyline : function ( polyline ) { this . get ( 'polylines' ) . removeObject ( polyline ) ; } , addPolylinePathItem : function ( path ) { path . addObject ( { lat : 1 , lng : 1 } ) ; } , removePolylinePathItem : function ( path , item ) { path . removeObject ( item ) ;", "del_tokens": "editable : true ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "dot", "notation"], "add_tokens": "arguments . src += arguments . varName + \" = arguments.env[\" + JSON . stringify ( arguments . varName ) + \"]; \" ;", "del_tokens": "arguments . src += arguments . varName + \" = arguments.env.\" + arguments . varName + \"; \" ;", "commit_type": "add"}
{"commit_tokens": ["Use", "scoped", "version", "of", "browser", "-", "detection", "dep"], "add_tokens": "var isAndroid = require ( '@braintree/browser-detection/is-android' ) ; var isChrome = require ( '@braintree/browser-detection/is-chrome' ) ; var isIos = require ( '@braintree/browser-detection/is-ios' ) ; var isIE9 = require ( '@braintree/browser-detection/is-ie9' ) ;", "del_tokens": "var isAndroid = require ( 'browser-detection/is-android' ) ; var isChrome = require ( 'browser-detection/is-chrome' ) ; var isIos = require ( 'browser-detection/is-ios' ) ; var isIE9 = require ( 'browser-detection/is-ie9' ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "compact", "literal", "tests", "for", "ES6", "and", "updated", "intro", "of", "readme"], "add_tokens": "{ code : \"var obj = { otherObj: { foo: function foo() { foo(); } } }\" } , { code : \"var obj = { foo() { } }\" , ecmaFeatures : { objectLiteralShorthandMethods : true } } { code : \"var obj = { otherObj: { foo: function() { foo(); } } }\" , errors : [ { message : \"\\\"foo\\\" has no defined method name. Use syntax - foo: function foo {..}.\" , type : \"Identifier\" } ] } , { code : \"var obj = { foo() { foo(); } }\" , errors : [ { message : \"\\\"foo\\\" has no defined method name. Use syntax - foo: function foo {..}.\" , type : \"Identifier\" } ] , ecmaFeatures : { objectLiteralShorthandMethods : true } }", "del_tokens": "{ code : \"var obj = { otherObj: { foo: function foo() { foo(); } } }\" } { code : \"var obj = { otherObj: { foo: function() { foo(); } } }\" , errors : [ { message : \"\\\"foo\\\" has no defined method name. Use syntax - foo: function foo {..}.\" , type : \"Identifier\" } ] }", "commit_type": "add"}
{"commit_tokens": ["move", "static", "files", "before", "sessions"], "add_tokens": "// Do we have sand-static? if ( sand . static && sand . static . middleware ) { this . app . use ( sand . static . middleware . bind ( sand . static ) ) ; } // Add public static files routes this . app . use ( express . static ( this . config . staticFileDirectory ) ) ;", "del_tokens": "// Do we have sand-static? if ( sand . static && sand . static . middleware ) { this . app . use ( sand . static . middleware . bind ( sand . static ) ) ; } // Add public static files routes this . app . use ( express . static ( this . config . staticFileDirectory ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Implement", "and", "test", "commonjsify", "transform"], "add_tokens": "gulp . task ( 'jshint' , 'Check JavaScript syntax errors' , function ( ) {", "del_tokens": "gulp . task ( 'jshint' , 'Check JavaScript sintax errors' , function ( ) {", "commit_type": "implement"}
{"commit_tokens": ["update", "specific", "block", "on", "instance", "start"], "add_tokens": "var specific ; debugger ; specific = { imageId : inst . ImageId , instanceId : inst . InstanceId , publicIpAddress : inst . PublicIpAddress , privateIpAddress : inst . PrivateIpAddress , securityGroups : inst . SecurityGroups , tags : inst . Tags } ; cb ( null , specific ) ; out . preview ( { cmd : 'start instances' , host : null , user : null , keyPath : null } ) ; pollInstanceStart ( _ec2 , instance , function ( err , newSpecific ) { debugger ; system . topology . containers [ instance . InstanceId ] . specific = newSpecific ;", "del_tokens": "cb ( null ) ; pollInstanceStart ( _ec2 , instance , function ( err ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "option", "to", "disable", "processing", "input", "source", "maps"], "add_tokens": "if ( this . options . inputSourcemaps !== false ) { var originalMap = sourceMapResolve . resolveSync ( content , file , fs . readFileSync ) ; if ( originalMap ) { var map = new SourceMapConsumer ( originalMap . map ) ; var relativeTo = originalMap . sourcesRelativeTo ; this . map . applySourceMap ( map , file , urix ( path . dirname ( relativeTo ) ) ) ; }", "del_tokens": "var originalMap = sourceMapResolve . resolveSync ( content , file , fs . readFileSync ) ; if ( originalMap ) { var map = new SourceMapConsumer ( originalMap . map ) ; var relativeTo = originalMap . sourcesRelativeTo ; this . map . applySourceMap ( map , file , urix ( path . dirname ( relativeTo ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "little", "bug", "that", "wont", "activate", "an", "already", "open", "tab", "from", "binding"], "add_tokens": "define ( [ 'knockout' , 'knockout-mapping' , 'jquery' , 'cms/modules/translator' , 'amplify' ] , function ( ko , koMapping , $ , translator , amplify ) {", "del_tokens": "define ( [ 'knockout' , 'knockout-mapping' , 'jquery' , 'modules/translator' , 'amplify' ] , function ( ko , koMapping , $ , translator , amplify ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "the", "ability", "to", "specify", "an", "outfile", "during", "temp", "dir", "usage"], "add_tokens": "var outOpts = xtend ( argv , { __to : entryMapping ( ) } ) getOutput ( outOpts , function ( err , output ) { function entryMapping ( ) { var mapTo var first = argv . _ [ 0 ] var parts = first . split ( ':' ) if ( parts . length > 1 ) { var from = parts [ 0 ] var to = parts [ 1 ] argv . _ [ 0 ] = from //clean up original arguments for watchify var idx = args . indexOf ( first ) if ( idx >= 0 ) args [ idx ] = from mapTo = to } return mapTo }", "del_tokens": "getOutput ( argv , function ( err , output ) {", "commit_type": "add"}
{"commit_tokens": ["move", "FrameLoader", "default", "configuration", "values", "to", "the", "constructor"], "add_tokens": "config = config || { } ; config . cancelDelay = config . cancelDelay || 5000 ; this . config = config ; var handle = window . setTimeout ( cancel , self . config . cancelDelay ) ;", "del_tokens": "this . config = config || { } ; var handle = window . setTimeout ( cancel , self . cancelDelay || 5000 ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "bug", "dealing", "with", "the", "ID", "property", "on", "Traits", "and", "Values", "within", "/", "src", "/", "profiles", "/", "v2", "/", "index", ".", "js", ".", "The", "replace", "routine", "had", "failed", "to", "turn", "Openess", "to", "Change", "into", "Openess", "-", "to", "-", "Change", ".", "Instead", "it", "was", "doing", "a", "non", "-", "global", "replace", "and", "so", "the", "ID", "was", "incorrectly", "turned", "into", "Openess", "-", "to", "Change", "(", "with", "only", "1", "dash", ")", "."], "add_tokens": "id : f . id . replace ( / _ / g , '-' ) . replace ( / / g , '-' ) , id : v . id . replace ( / _ / g , '-' ) . replace ( / / g , '-' ) ,", "del_tokens": "id : f . id . replace ( '_' , '-' ) . replace ( ' ' , '-' ) , id : v . id . replace ( '_' , '-' ) . replace ( ' ' , '-' ) ,", "commit_type": "fix"}
{"commit_tokens": ["making", "unimplemented", "tests", "fail", "@sbezboro"], "add_tokens": "it ( \"should be IMPLEMENTED\" , function ( done ) { expect ( 1 ) . to . equal ( 0 ) ; done ( ) ; } ) ; expect ( 1 ) . to . equal ( 0 ) ; it ( \"should be IMPLEMENTED\" , function ( done ) { expect ( 1 ) . to . equal ( 0 ) ; done ( ) ; } ) ;", "del_tokens": "// Implement me // Implement me...", "commit_type": "make"}
{"commit_tokens": ["use", "initRecorder", "for", "accurate", "syncing", "in", "MRecordRTC"], "add_tokens": "// Last time updated: 2016-01-18 1:39:49 PM UTC if ( ! this . mediaType . video ) { this . audioRecorder . startRecording ( ) ; } if ( ! this . mediaType . audio ) { this . videoRecorder . startRecording ( ) ; } } if ( this . mediaType . audio && this . mediaType . video ) { var self = this ; self . videoRecorder . initRecorder ( function ( ) { self . audioRecorder . initRecorder ( function ( ) { // Both recorders are ready to record things accurately self . videoRecorder . startRecording ( ) ; self . audioRecorder . startRecording ( ) ; } ) ; } ) ;", "del_tokens": "// Last time updated at Monday, January 18th, 2016, 10:49:23 AM this . audioRecorder . startRecording ( ) ; this . videoRecorder . startRecording ( ) ;", "commit_type": "use"}
{"commit_tokens": ["remove", "babel", "output", "from", "git"], "add_tokens": "out . success ( \"listing schemas\\n\" ) ; console . log ( ` ${ schema . methods } ${ schema . endpoint } ${ schema . description } ${ schema . filepath } ` ) ;", "del_tokens": "out . success ( \"listing schemas:\\n\" ) ; console . log ( ` ${ schema . methods } ${ schema . endpoint } ${ schema . description } ${ schema . filepath } ` ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "basic", "priority", "support", "debug", "mode", "&", "HEAD", "fix"], "add_tokens": "try { //https://github.com/joshfire/node-pool var Pool = require ( '../../node-pool/lib/generic-pool.js' ) . Pool ; } catch ( e ) { var Pool = require ( 'generic-pool' ) . Pool ; } \"method\" : \"GET\" , \"priority\" : 0 if ( toQueue [ \"debug\" ] ) { if ( error ) { console . log ( \"Error \" + error + \" when fetching \" + toQueue [ \"uri\" ] . href ) ; } else { console . log ( \"Got \" + toQueue [ \"uri\" ] . href + \" (\" + body . length + \" bytes)...\" ) ; } } response . request = toQueue ; if ( toQueue [ \"jQueryify\" ] && toQueue [ \"method\" ] != \"HEAD\" ) { if ( toQueue [ \"debug\" ] ) console . log ( \"Fetching \" + toQueue [ \"uri\" ] + \" ...\" ) ; } , toQueue [ \"priority\" ] ) ;", "del_tokens": "Pool = require ( 'generic-pool' ) . Pool , \"method\" : \"GET\" if ( toQueue [ \"jQueryify\" ] ) { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "simple", "token", "auth", "strategy"], "add_tokens": "test ( 'should load defaults' , ( t ) => { // Check for an adapter we know will be there - the rest is tested in // utils/loadDefaults-test.js", "del_tokens": "test ( 'should load default adapters' , ( t ) => { test ( 'should load mappers' , ( t ) => { const great = new Integreat ( ) great . loadDefaults ( ) t . is ( typeof great . getMapper ( 'date' ) , 'function' ) t . is ( typeof great . getMapper ( 'float' ) , 'function' ) t . is ( typeof great . getMapper ( 'integer' ) , 'function' ) } )", "commit_type": "add"}
{"commit_tokens": ["Allow", "skipping", "by", "chaining", "with", ".", "skip", "()", "."], "add_tokens": "function skipify ( test , s = true ) { test . _skip = s ; return test ; } function unskipify ( test , s = true ) { test . _unskip = s ; return test ; } function _testGroup ( reporter , skipping ) { yield t ( group , ! t . _unskip && ( t . _skip || skipping ) ) ; // Allow skipping/unskipping by chaining: `testGroup(...).skip()`. _testGroup . skip = function ( s ) { return skipify ( this , s ) ; } ; _testGroup . unskip = function ( s ) { return unskipify ( this , s ) ; } ; return _testGroup ; // Allow skipping/unskipping by chaining: `test(...).skip()`. _test . skip = function ( s ) { return skipify ( this , s ) ; } ; _test . unskip = function ( s ) { return unskipify ( this , s ) ; } ; return _test ;", "del_tokens": "function skipify ( test , s = true ) { test . skip = s ; return test ; } function unskipify ( test , s = true ) { test . unskip = s ; return test ; } return function _testGroup ( reporter , skipping ) { yield t ( group , ! t . unskip && ( t . skip || skipping ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "path", "-", "to", "-", "regexp", "module", "."], "add_tokens": "var pathToRegexp = require ( 'path-to-regexp' ) ; var params = [ ] ; pathToRegexp ( base + ':' + id , params ) ; var param = params [ i ] . name , paramIdx = i ;", "del_tokens": "var params = Route . patternToParamNames ( base + ':' + id ) ; var param = params [ i ] , paramIdx = i ;", "commit_type": "use"}
{"commit_tokens": ["make", "nodestack", "svailable", "to", "Core"], "add_tokens": "var error = { status : 401 , message : 'Insufficient privileges to perform this action.' , name : 'AccessError' } ; promise . reject ( error ) ;", "del_tokens": "this . registerApiCoreEvents ( ) ; / ** * Registers core level events * * @ return { void } * / FacetApiCore . prototype . registerApiCoreEvents = function ( ) { var _this = this ; // set the nodeStack (contains req, res, next keys) this . intercom . on ( 'facet:init:nodestack' , function initNodeStack ( nodeStack , force ) { if ( _ . isEmpty ( _this . nodeStack ) || force ) { _this . nodeStack = nodeStack ; } } ) ; } ; promise . reject ( 'Insufficient privileges to perform this action.' ) ;", "commit_type": "make"}
{"commit_tokens": ["Removed", "unused", "name", "field", "from", "tradeRequest", "event"], "add_tokens": "this . emit ( 'tradeRequest' , new SteamID ( body . other_steamid . toString ( ) ) , function ( accept ) { this . emit ( 'tradeResponse' , new SteamID ( body . other_steamid . toString ( ) ) , body . response , { this . emit ( 'tradeStarted' , new SteamID ( body . other_steamid . toString ( ) ) ) ;", "del_tokens": "// TODO: See if other_name is actually filled in, and remove if not this . emit ( 'tradeRequest' , body . other_name , new SteamID ( body . other_steamid ) , function ( accept ) { this . emit ( 'tradeResponse' , new SteamID ( body . other_steamid ) , body . response , { this . emit ( 'tradeStarted' , new SteamID ( body . other_steamid ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "test", "-", "projects", "install", "/", "build", ":", "webpack", "4", "changes"], "add_tokens": "'use strict' ; const path = require ( 'path' ) ; output : { filename : 'main.js' , path : path . resolve ( __dirname , 'dist' ) } , output : { filename : 'renderer.js' , path : path . resolve ( __dirname , 'dist' ) } ,", "del_tokens": "output : { filename : 'main.js' } , output : { filename : 'renderer.js' } ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "asset", "and", "image", "widgets"], "add_tokens": "angular . module ( 'bauhaus.asset.services' ) . factory ( 'AssetUploadService' , function ( $resource ) {", "del_tokens": "angular . module ( 'bauhaus.asset.services' ) . factory ( 'AssetService' , function ( $resource ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "be", "more", "continuable", "friendly", "."], "add_tokens": "if ( typeof body === \"function\" ) { else if ( ! callback ) return request . bind ( null , method , url , body ) ;", "del_tokens": "if ( typeof body === \"function\" && callback === undefined ) { if ( ! callback ) return request . bind ( this , accessToken , method , url , body ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "mock", "webservice", "ws", "package", "version", "and", "sdk", "version"], "add_tokens": ", WebSocket = require ( 'ws' ) , WebSocketServer = WebSocket . Server function send ( ws , data ) { // is it a valid client and open ? if ( ws . readyState === WebSocket . OPEN ) { ws . send ( data ) ; } } send ( ws , message ) ; } ) ; ws . on ( 'error' , function ( e ) { console . error ( \"got error\" , e ) ; send ( ws , JSON . stringify ( message ) ) ;", "del_tokens": ", url = require ( 'url' ) , WebSocketServer = require ( 'ws' ) . Server var location = url . parse ( ws . upgradeReq . url , true ) ; ws . send ( message ) ; ws . send ( JSON . stringify ( message ) ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "methods", "to", "convert", "entity", "data", "to", "jhipster", "format"], "add_tokens": "parse : JDLReader . parse , parseFromFiles : JDLReader . parseFromFiles , convertToEntityJson : JDLReader . convertToEntityJson", "del_tokens": "parse : JDLReader . read , parseFromFiles : JDLReader . readFiles", "commit_type": "add"}
{"commit_tokens": ["Changed", "test", "to", "do", "real", "deep", "require", "."], "add_tokens": "'b' : { 'c' : { type : String , required : true }", "del_tokens": "type : Object , required : 'implicit' , schema : { 'b' : { type : String , required : true }", "commit_type": "change"}
{"commit_tokens": ["Implemented", "dir", "config", "a", "configure", "file", "in", "a", "route", "config", "directory", "that", "allows", "the", "sub", "-", "route", "to", "be", "customized", "(", "as", "a", "a", "start", ")", "."], "add_tokens": "// Default the sub-route for the directory to the name of the file // system directory. var subRouteName = dir . name ; // If the directory has a 'route.js' load it as a route config for the directory. var dirConfigPath = path . join ( dir . path , 'route.js' ) ; if ( fileMgr . fileExists ( dirConfigPath ) ) { // Require in the user-defined directory config. var dirConfig = require ( this . _formatPathForRequire ( dirConfigPath ) ) ; console . log ( 'dir config: ' ) ; logVerbose ( 'Loaded dir config: ' + dirConfigPath ) ; if ( dirConfig . route ) { // Retreive the route name from the directory config, if it is specified. subRouteName = dirConfig . route ; } } var route = this . _formatPathAsRoute ( path . join ( dir . parentRoute , subRouteName ) ) ; // If the directory contains a 'get.js' load it is as config for HTTP get. var getConfigPath = path . join ( dir . path , 'get.js' ) ; if ( fileMgr . fileExists ( getConfigPath ) ) { // Require in the user-defined HTTP get config. var getConfig = require ( this . _formatPathForRequire ( getConfigPath ) ) ; logVerbose ( 'Loaded HTTP get config: ' + getConfigPath ) ;", "del_tokens": "var route = this . _formatPathAsRoute ( path . join ( dir . parentRoute , dir . name ) ) ; // If the directory contains a 'get.js' load it is as a route config. var getJsPath = path . join ( dir . path , 'get.js' ) ; if ( fileMgr . fileExists ( getJsPath ) ) { // Require in the user-defined route config. var getConfig = require ( this . _formatPathForRequire ( getJsPath ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "bug", "that", "getTransaction", "()", "always", "returns", "the", "format", "error"], "add_tokens": "'version' , 'timestamp' ,", "del_tokens": "'status' , 'timestamp' , 'signature' ,", "commit_type": "fix"}
{"commit_tokens": ["fixed", "unreachable", "/", "untested", "shim", "for", "matches"], "add_tokens": "var parentNode = this . parentNode ; parentNode . querySelectorAll ( selector ) ,", "del_tokens": "parentNode . querySelector ( selector ) ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "of", "AMD", "and", "common", ".", "js", "module"], "add_tokens": "; ( function ( window , factory ) { \"use strict\" ; // AMD. Register as an anonymous module. Wrap in function so we have access // to root via `this`. if ( typeof define === \"function\" && define . amd ) { define ( [ ] , function ( ) { return factory . apply ( window ) ; } ) ; } // Node. Does not work with strict CommonJS, but only CommonJS-like // environments that support module.exports, like Node. else if ( typeof exports === \"object\" ) { module . exports = factory . call ( window ) ; } // Browser globals. else { window . Waves = factory . call ( window ) ; } } ) ( typeof global === \"object\" ? global : this , function ( ) { \"use strict\" ; return Waves ; } ) ;", "del_tokens": "; ( function ( window ) { 'use strict' ; window . Waves = Waves ; } ) ( window ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "name", "of", "the", "promise", "test", "adapter", "to", "be", "...", "adapter!"], "add_tokens": "function adapter ( ) { promisesAplusTests ( { deferred : adapter } , function ( err ) {", "del_tokens": "function deferred ( ) { promisesAplusTests ( { deferred : deferred } , function ( err ) {", "commit_type": "update"}
{"commit_tokens": ["Use", "request", "module", "for", "node", "and", "request", "for", "browser"], "add_tokens": "const request = require ( './includes/request.js' ) ; if ( process . env . npm_package_version ) { if ( requestData ) {", "del_tokens": "const request = require ( 'reqwest' ) ; if ( process . env . npm_package_version ) { if ( requestData ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "comments", "to", "message", "builder"], "add_tokens": "/ ** * Creates a deepstream message string , based on the * provided parameters * * @ param { String } topic One of CONSTANTS . TOPIC * @ param { String } action One of CONSTANTS . ACTIONS * @ param { Array } data An array of strings or JSON - serializable objects * * @ returns { String } deepstream message string * / } ; / ** * Creates a deepstream error message string based on the provided * arguments * * @ param { String } topic One of CONSTANTS . TOPIC - error messages might either be send on * the generic ERROR topic or on the topic that caused the error * * @ param { String } type One of CONSTANTS . EVENT * @ param { String } message A generic error message * * @ returns { String } deepstream error message string * / exports . getErrorMsg = function ( topic , type , message ) { return topic + SEP + 'E' + SEP + type + SEP + message ; } ;", "del_tokens": "exports . getErrorMsg = function ( topic , type , message ) { return topic + SEP + 'E' + SEP + type + SEP + message ; } ; } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "copy", "images", "in", "module", "folders", "to", "the", "output", "images", "folder", "."], "add_tokens": "lineEndings : undefined , addModuleImagesToStaticFiles : true", "del_tokens": "lineEndings : undefined", "commit_type": "add"}
{"commit_tokens": ["add", "UI", "options", "for", "interval", "conf", "level", "and", "mult", "test", "correction"], "add_tokens": "Abba . Experiment = function ( numVariations , baselineNumSuccesses , baselineNumTrials , intervalAlpha ) { var intervalAlpha = intervalAlpha / this . _numComparisons ; // Bonferroni correction this . _intervalZCriticalValue = normal . inverseSurvival ( intervalAlpha / 2 ) ; . pEstimate ( this . _intervalZCriticalValue ) . valueWithInterval ( this . _intervalZCriticalValue , this . _baseline . pEstimate ( 0 ) . value ) ; . pEstimate ( this . _intervalZCriticalValue ) . valueWithInterval ( this . _intervalZCriticalValue , trial . pEstimate ( 0 ) . value ) , . differenceRatio ( this . _intervalZCriticalValue ) . valueWithInterval ( this . _intervalZCriticalValue , comparison . differenceRatio ( 0 ) . value ) ,", "del_tokens": "Abba . Experiment = function ( numVariations , baselineNumSuccesses , baselineNumTrials , baseAlpha ) { var alpha = baseAlpha / this . _numComparisons // Bonferroni correction // all z-values are two-tailed this . _zCriticalValue = normal . inverseSurvival ( alpha / 2 ) ; . pEstimate ( this . _zCriticalValue ) . valueWithInterval ( this . _zCriticalValue , this . _baseline . pEstimate ( 0 ) . value ) ; . pEstimate ( this . _zCriticalValue ) . valueWithInterval ( this . _zCriticalValue , trial . pEstimate ( 0 ) . value ) , . differenceRatio ( this . _zCriticalValue ) . valueWithInterval ( this . _zCriticalValue , comparison . differenceRatio ( 0 ) . value ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "task", "cancellation"], "add_tokens": "return Q . resolve ( self . job . run ( ) ) ;", "del_tokens": "self . job . run ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "improvements", "to", "the", "editable", "-", "positioning", "padding", "matching", "of", "bold", "font", "style", "..."], "add_tokens": "jsio ( 'import browser.ItemValueView' ) ; jsio ( 'import browser.ItemReferenceView' ) ; this . showAt = function ( itemView , preventLayout ) { this . _focusedView = itemView ; this . _focusedView . subscribe ( 'Resize' , bind ( this , '_layoutHandler' ) ) ; if ( itemView instanceof browser . ItemReferenceView ) { this . _element . className = 'ItemFocus onReferenceItemView' ; } else if ( itemView instanceof browser . ItemValueView ) { this . _element . className = 'ItemFocus onValueItemView' ; } else { this . _element . className = 'ItemFocus' ; } this . removeFrom = function ( itemView ) { if ( this . _focusedView == itemView ) { if ( ! this . _focusedView ) { return ; } var dim = dimensions . getDimensions ( this . _focusedView . getElement ( ) ) ;", "del_tokens": "this . addClassName ( 'ItemFocus' ) ; this . showAt = function ( item , preventLayout ) { this . _focusedItem = item ; this . _focusedItem . subscribe ( 'Resize' , this . _layoutHandler ) ; this . removeFrom = function ( item ) { if ( this . _focusedItem == item ) { if ( ! this . _focusedItem ) { return ; } var dim = dimensions . getDimensions ( this . _focusedItem . getElement ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "more", "info", "to", "the", "default", "error", "handler"], "add_tokens": "server = restify . createServer ( ) , util = require ( 'util' ) ; console . log ( \"======== Uncaught exception =========\" ) ; console . log ( \"In: \" , req . url , req . method ) ; if ( Object . keys ( req . params ) . length > 0 ) { console . log ( \"Params: \" , util . inspect ( req . params ) . replace ( / \\n / g , '' ) ) ; } console . log ( \"Headers: \" , util . inspect ( req . headers ) . replace ( / \\n / g , '' ) ) ;", "del_tokens": "server = restify . createServer ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "encoding", "of", "32", "-", "bit", "product", "IDs"], "add_tokens": "data . writeUInt16LE ( ( suffix . productId >> 16 ) & 0xffff , offs ) ; data . writeUInt16LE ( suffix . productId & 0xffff , offs + 2 ) ;", "del_tokens": "data . writeUInt32LE ( suffix . productId , offs ) ;", "commit_type": "fix"}
{"commit_tokens": ["improve", "comments", "for", "test", "runner"], "add_tokens": "/ ** * Read test / cases directory and filter all ` ` files , then remove * this extension for each file in the collection and prepare to test . * / return ~ file . indexOf ( '.styl' ) ; // bitwise flip to treat result as truthy. / * * For each ` ` and ` ` pair in ` ` , compile stylus to css * and compare actual result to expected css . * /", "del_tokens": "// test cases return ~ file . indexOf ( '.styl' ) ;", "commit_type": "improve"}
{"commit_tokens": ["use", "Mumbe", ".", "proto", "filename"], "add_tokens": "var builder = protobufjs . loadProtoFile ( path . join ( __dirname , 'Mumble.proto' ) ) ;", "del_tokens": "var builder = protobufjs . loadProtoFile ( path . join ( __dirname , mumble . proto ) ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "angularjs", "annotate", "support", "before", "uglify"], "add_tokens": "var ngAnnotate = require ( \"ng-annotate\" ) ; var res = ngAnnotate ( String ( fs . readFileSync ( file ) ) , { add : true } ) ; var result = UglifyJS . minify ( res . src , { } , fromString : true", "del_tokens": "var result = UglifyJS . minify ( file , { }", "commit_type": "add"}
{"commit_tokens": ["add", "html5", "support", "for", "ie"], "add_tokens": "i18n : '../lib/require/i18n' , modernizer : '../lib/modernizr' , html5shiv : '../lib/html5shiv' 'app' , 'bootstrap' , /*'modernizer'*/ ,", "del_tokens": "i18n : '../lib/require/i18n' 'app' , 'bootstrap' ,", "commit_type": "add"}
{"commit_tokens": ["Use", "parent", "-", "require", "to", "load", "plugins"], "add_tokens": "var prequire = require ( 'parent-require' ) ; var plugin = prequire ( \"seminarjs-\" + plugin ) ;", "del_tokens": "var plugin = require ( \"seminarjs-\" + plugin ) ;", "commit_type": "use"}
{"commit_tokens": ["Made", "unix", "the", "same", "as", "osx"], "add_tokens": "getDetailNaN ( 'df | grep ' + drive + ' | awk \\'{print $6}\\'' , function ( e , d ) { if ( d ) d = d . trim ( ) ; callback ( e , d ) ; } ) ;", "del_tokens": "getDetailNaN ( 'df | grep ' + drive + ' | awk \\'{print $6}\\'' , callback ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "nick", "into", "jade", "file"], "add_tokens": "//console.log(request.url); uri = url . parse ( request . url , true ) ;", "del_tokens": "console . log ( request . url ) ; uri = url . parse ( request . url ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "FileFollower", "for", "tail", "-", "f", "functionality"], "add_tokens": ", FileFollower = require ( './file-follower' ) , follow : follow fs . statSync ( f ) ; return true ; if ( e . errno === constants . ENOENT ) return false ; throw e ; function follow ( f , lineFn ) { var ff = new FileFollower ( f ) ; ff . on ( 'line' , lineFn ) ; return { stop : ff . stopFollowing . bind ( ff ) } ; }", "del_tokens": "fs . statSync ( f ) return true if ( e . errno === constants . ENOENT ) return false throw e", "commit_type": "add"}
{"commit_tokens": ["move", "lib", "/", "term", ".", "js", "to", "src", "/", "term", ".", "js", "."], "add_tokens": "term . path = __dirname + '/../src/term.js' ; return term . _Terminal = require ( '../src/term' ) ;", "del_tokens": "term . path = __dirname + '/term.js' ; return term . _Terminal = require ( './term' ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", ":", "Command", "Editor", "(", "CLI", ")"], "add_tokens": "it ( 'Execute as init mode with --yes option' , function ( done ) { var gen = spawn ( 'node' , [ __dirname + '/../scripts/generator.js' , 'init' , '--yes' ] , {", "del_tokens": "it ( 'Execute with --init && --yes' , function ( done ) { var gen = spawn ( 'node' , [ __dirname + '/../scripts/generator.js' , '--init' , '--yes' ] , {", "commit_type": "add"}
{"commit_tokens": ["implement", "out", "of", "bound", "wrapping"], "add_tokens": "CellularAutomata . prototype . outOfBoundWrapping = false ; * @ param { int | string } outOfBoundValue if ( outOfBoundValue === 'wrap' ) { this . outOfBoundWrapping = true ; this . outOfBoundValue = 0 ; } else { this . outOfBoundWrapping = false ; this . outOfBoundValue = outOfBoundValue | 0 ; } if ( this . outOfBoundWrapping ) { // euclidean modulo currentArgumentValue = currentArgumentValue % this . shape [ dimension ] ; currentArgumentValue = currentArgumentValue < 0 ? currentArgumentValue + Math . abs ( this . shape [ dimension ] ) : currentArgumentValue ; internalArrayIndex += currentArgumentValue * stride [ dimension ] ; } else { isOutOfBound = true ; }", "del_tokens": "* @ param { int } outOfBoundValue this . outOfBoundValue = outOfBoundValue | 0 ; isOutOfBound = true ;", "commit_type": "implement"}
{"commit_tokens": ["adds", "option", "to", "define", "scopes", ".", "see", ":", "https", ":", "//", "github", ".", "com", "/", "dwyl", "/", "hapi", "-", "auth", "-", "google", "/", "issues", "/", "4"], "add_tokens": "var opts = { REDIRECT_URL : '/googleauth' , // must match google app redirect URI handler : require ( './google_oauth_handler.js' ) , // your handler scope : 'https://www.googleapis.com/auth/plus.profile.emails.read' // profile } ;", "del_tokens": "var opts = { REDIRECT_URL : server . info . uri + '/googleauth' , handler : require ( './google_oauth_handler.js' ) } ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "httpstatus$", "to", "be", "passed", "to", "defaultresponder"], "add_tokens": "if ( ~ k . indexOf ( '$' ) && 'http$' !== k && 'httpstatus$' !== k ) {", "del_tokens": "if ( ~ k . indexOf ( '$' ) && 'http$' !== k ) {", "commit_type": "allow"}
{"commit_tokens": ["fixed", "a", "typo", "in", "vsdoc", "for", "amplify", ".", "store"], "add_tokens": "amplify . store = function ( key , value , options ) {", "del_tokens": "amplify . store = functional ( key , value , options ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "variable", "name", "from", "self", "to", "name", "in", "Test", "constructor", "."], "add_tokens": "var test = Object . create ( Test . prototype , test . assert = options . Assert ( test ) return test", "del_tokens": "var self = Object . create ( Test . prototype , self . assert = options . Assert ( self ) return self", "commit_type": "change"}
{"commit_tokens": ["Allow", "only", "name", "url", "keys", "for", "win32", "."], "add_tokens": "for ( var key in options ) { // Omit keys besides name & url for now until options // parsing bugs are resolved. if ( process . platform === 'win32' && ( key !== 'name' || key !== 'url' ) ) continue ; args . push ( '--' + key + '=' + options [ key ] ) ; }", "del_tokens": "for ( var key in options ) args . push ( '--' + key + '=' + options [ key ] ) ;", "commit_type": "allow"}
{"commit_tokens": ["Implemented", "onUpdate", "and", "onComplete", "to", "chief", "returning", "props"], "add_tokens": "onUpdate : onUpdate . bind ( undefined , onTargetInState ) function onUpdate ( onTargetInState , state , stateName , time ) { // console.log(arguments); if ( opts . onUpdate ) { opts . onUpdate ( state , stateName ) ; } onInState ( opts . states [ stateChief ] , stateChief ) ;", "del_tokens": "onUpdate : options . onUpdate || onUpdate . bind ( undefined , onTargetInState ) function onUpdate ( onTargetInState , state ) { onInState ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Implement", "separate", "tests", "for", "merge", "package", "."], "add_tokens": "test ( 'Function merge' , function ( nest ) {", "del_tokens": "test ( 'Deep array merge' , function ( nest ) {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "IE10", "CORS", "-", "related", "bug"], "add_tokens": "* v1 .6 .1 var isIElte9 = document . all && ! window . atob ; if ( isCrossDomain && isIElte9 ) {", "del_tokens": "* v1 .6 .0 if ( isCrossDomain && typeof XDomainRequest !== \"undefined\" ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "undocumented", "auto", "looping", ".", "The", "next", "step", "is", "to", "implement", "different", "setting", "for", "song", "loop", "playlist", "loop", "and", "global", "loop", "."], "add_tokens": "/ * Ensure we don ' * / let songOverflow = false ; songOverflow = true ; if ( ! songOverflow || config . repeat ) AmplitudeCore . play ( ) ; AmplitudeVisualSync . syncMainPlayPause ( ) ; AmplitudeVisualSync . syncSongPlayPause ( null , nextIndex ) ; function setNextPlaylist ( playlist ) { AmplitudeVisualSync . syncMainPlayPause ( ) ; AmplitudeVisualSync . syncPlaylistPlayPause ( playlist ) ; AmplitudeVisualSync . syncSongPlayPause ( playlist , nextIndex ) ;", "del_tokens": "AmplitudeCore . play ( ) ; AmplitudeVisualSync . syncMainPlayPause ( 'playing' ) ; AmplitudeVisualSync . syncSongPlayPause ( null , nextIndex , 'playing' ) ; function setNextPlaylist ( playlist ) { AmplitudeVisualSync . syncMainPlayPause ( 'playing' ) ; AmplitudeVisualSync . syncPlaylistPlayPause ( playlist , 'playing' ) ; AmplitudeVisualSync . syncSongPlayPause ( playlist , nextIndex , 'playing' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "in", "both", "of", "Franck", "s", "suggested", "fixes", "jQuery", ".", "class", "and", "foo", "+", "bar", ".", "split", "(", ")", "."], "add_tokens": "var e = ( \"blur,focus,contextmenu,load,resize,scroll,unload,click,dblclick,\" + \"change,reset,select,submit,keydown,keypress,keyup\" ) . split ( \",\" ) ;", "del_tokens": "var e = \"blur,focus,contextmenu,load,resize,scroll,unload,click,dblclick,\" + \"change,reset,select,submit,keydown,keypress,keyup,abort,error,ready\" . split ( \",\" ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "and", "create", "variables", "initialisation", "inside", "newly", "created", "constructor"], "add_tokens": "constructor : function ( ... args ) { // eslint-disable-line object-shorthand generator . apply ( this , args ) ; this . entityConfig = this . options . entityConfig ; this . defaultTableName = this . options . entityConfig . entityClass ; } , this . log ( this . entityConfig ) ; let ORMFile = jhipsterVar . javaDir + '/domain/' + this . entityConfig . entityClass + '.java' ; jhipsterFunc . updateEntityConfig ( this . entityConfig . filename , 'entityTableName' , desiredTableName ) ;", "del_tokens": "this . defaultTableName = this . options . entityConfig . entityClass ; let ORMFile = jhipsterVar . javaDir + '/domain/' + this . options . entityConfig . entityClass + '.java' ; jhipsterFunc . updateEntityConfig ( this . options . entityConfig . filename , 'entityTableName' , desiredTableName ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "jsdoc", "comment", "for", ".", "schema", "()"], "add_tokens": "/ ** * calculates schema of a collection by sampling some of the documents * * @ param { Object } options * * @ returns { Object } the schema document with counts ( $c ) , types ( $t ) , * an array flag ( $a ) and probability of occurrence * given the parent field ( $p ) . * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "IV", "is", "part", "of", "the", "HMAC", "we", "don", "t", "want", "a", "partial", "decryption", "oracle", "in", "our", "midst", "."], "add_tokens": "hmacAlg . update ( iv ) ; hmacAlg . update ( ciphertext ) ; var iv = base64urldecode ( components [ 0 ] ) ; // make sure IV is right length if ( iv . length != 16 ) return ; // check hmac hmacAlg . update ( iv ) ; // eventually we want to use HKDF. For now we'll do something simpler.", "del_tokens": "hmacAlg . update ( ciphertext ) ; // check hmac var iv = base64urldecode ( components [ 0 ] ) ; // eventually we want to use HKDF. For now we'll do something simpler.", "commit_type": "make"}
{"commit_tokens": ["Use", "Fingerprint32", "instead", "of", "Hash32", "."], "add_tokens": "var farm32 = require ( 'farmhash' ) . fingerprint32 ;", "del_tokens": "var farm32 = require ( 'farmhash' ) . hash32 ;", "commit_type": "use"}
{"commit_tokens": ["Add", "min", "and", "max", "params", "to", "the", "repeat", "helper"], "add_tokens": "} else if ( arguments . length === 1 ) { options = min ; if ( typeof options . hash . min === 'number' && typeof options . hash . max === 'number' ) { total = utils . randomInt ( options . hash . min , options . hash . max ) ; } else { throw new Error ( 'The repeat helper requires either a single count value, or both min and max values' ) ; }", "del_tokens": "} else { throw new Error ( 'The repeat helper requires a numeric param' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "linkAssociations", "for", "sideloaded", "records", "(", "2nd", "level", "associations", ")"], "add_tokens": "json [ documentIdentifier ] = [ ] ; json [ documentIdentifier ] = [ prepareOneRecord ( records ) ] ; if ( array . length > 0 ) { if ( ! _ . isNumber ( array [ 0 ] ) && ! _ . isString ( array [ 0 ] ) ) { // this is probably an array of records var model = sails . models [ pluralize ( key , 1 ) ] ; console . log ( \"Sideloaded records model: \" , model . identity ) ; Ember . linkAssociations ( model , array ) ; } }", "del_tokens": "json [ documentIdentifier ] = plural ? [ ] : { } ; json [ documentIdentifier ] = prepareOneRecord ( records ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "initial", "values", "for", "NumberController", "and", "StringController"], "add_tokens": "this . py = this . y = this . initialValue = this . object [ this . propertyName ] ; _this . inc = _this . initialValue ; // possibly push to an array here so that // we have a record of \"defined\" / \"presets\" // ????", "del_tokens": "this . py = this . y = 0 ; _this . inc = 0 ;", "commit_type": "add"}
{"commit_tokens": ["added", "mouseover", "/", "mouseout", "integration", "to", "hoverable"], "add_tokens": "this . dispatchMouseEvent ( 'mouseover' , evt ) ; this . dispatchMouseEvent ( 'mouseout' , evt ) ; } , dispatchMouseEvent : function ( type , superHandsEvt ) { var mEvt = new MouseEvent ( type , { relatedTarget : superHandsEvt . detail . hand } ) ; this . el . dispatchEvent ( mEvt ) ; }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["adding", "use", "strict", "to", "the", "top", "of", "each", "file"], "add_tokens": "'use strict' ; date = arguments [ 0 ] . date ;", "del_tokens": "date = arguments [ 0 ] . date", "commit_type": "add"}
{"commit_tokens": ["Use", "Regular", "expressions", "to", "test", "for", "remote", "HTMLCS"], "add_tokens": "htmlcs : __dirname + '/vendor/HTMLCS.js' , if ( / ^(https?|file):\\/\\/ / . test ( options . htmlcs ) ) { // Include remote URL page . includeJs ( options . htmlcs , function ( included ) { if ( ! included ) { return next ( new Error ( 'Pa11y was unable to include scripts in the page' ) ) ; // Inject local file page . injectJs ( options . htmlcs , function ( injected ) { if ( ! injected ) { return next ( new Error ( 'Pa11y was unable to inject scripts into the page' ) ) ;", "del_tokens": "var location = __dirname + '/vendor/HTMLCS.js' ; var fs = require ( 'fs' ) ; if ( options . htmlcs !== 'local' ) { location = options . htmlcs ; } if ( fs . existsSync ( location ) ) { // it is a local file page . injectJs ( location , function ( injected ) { if ( ! injected ) { return next ( new Error ( 'Pa11y was unable to inject scripts into the page' ) ) ; // it is probably a URL, so try to include it page . includeJs ( location , function ( included ) { if ( ! included ) { return next ( new Error ( 'Pa11y was unable to include scripts into the page' ) ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "unit", "test", "for", "command", "remove"], "add_tokens": "fs . readdirSync = jest . fn ( ( path ) => { return readdirSync ( path ) } )", "del_tokens": "fs . readdirSync = readdirSync", "commit_type": "add"}
{"commit_tokens": ["Add", "natural", "join", "to", "NRAEnv", "--", "with", "non", "-", "optimal", "translation", "to", "NNRC"], "add_tokens": "importScripts ( \"../../runtimes/javascript/qcert-runtime.js\" , \"qcertWhiskDispatch.js\" , \"../../bin/qcertJS.js\" ) ;", "del_tokens": "importScripts ( \"qcert-runtime.js\" , \"qcertWhiskDispatch.js\" , \"qcertJS.js\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "empty", "params", ".", "$select"], "add_tokens": "if ( fp . isNil ( params . $select ) || fp . isEmpty ( params . $select ) ) { params . $select = params . query . $select ; }", "del_tokens": "params . $select = params . $select || params . query . $select ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "display", "descriptions"], "add_tokens": "* v1 .10 .0 addDescriptionHover ( selectionContainer ) ; function addDescriptionHover ( selectionContainer ) { var description = $ ( \"<span class='description'>?</span>\" ) ; var targets = $ ( selectionContainer ) . find ( \"div.item[data-description]\" ) ; description . prependTo ( targets ) ; $ ( \"div.item > span.description\" ) . unbind ( ) . mouseenter ( function ( ) { var item = $ ( this ) . parent ( ) ; var description = item . attr ( 'data-description' ) ; var descriptionDiv = document . createElement ( 'div' ) ; descriptionDiv . className = \"temp-description-popup\" ; descriptionDiv . innerHTML = description ; descriptionDiv . style . position = 'absolute' ; item . append ( descriptionDiv ) ; } ) . mouseleave ( function ( ) { $ ( \"div.temp-description-popup\" ) . remove ( ) ; } ) ; }", "del_tokens": "* v1 .9 .1", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "in", "UnitsAnswerComponent"], "add_tokens": "\"defaultUnits\" : \"wtdAQZ3\" ,", "del_tokens": "\"defaultUnits\" : \"gVQSSfG\" ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "two", "small", "typos", "in", "comments"], "add_tokens": "// shimmable in ie8. We need to make sure we don't inadvertently copy across any * Checks that a class provides a prototype that will fulfil a protocol . } ) ;", "del_tokens": "// shimmable in ie8. We need to make sure we don't inadvertantly copy across any * Checks that a class provides a prototype that will fulfill a protocol . } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "download", "files", "to", "the", "Node", ".", "js", "example", "."], "add_tokens": "var fs = require ( 'fs' ) , path = require ( 'path' ) , util = require ( 'util' ) , Stream = require ( 'stream' ) . Stream ; // Pipe chunks directly in to an existsing WritableStream // r.write(identifier, response); // r.write(identifier, response, {end:false}); // // var stream = fs.createWriteStream(filename); // r.write(identifier, stream); // stream.on('data', function(data){...}); // stream.on('end', function(){...}); $ . write = function ( identifier , writableStream , options ) { options = options || { } ; options . end = ( typeof options [ 'end' ] == 'undefined' ? true : options [ 'end' ] ) ; // Iterate over each chunk var pipeChunk = function ( number ) { var chunkFilename = getChunkFilename ( number , identifier ) ; path . exists ( chunkFilename , function ( exists ) { if ( exists ) { // If the chunk with the current number exists, // then create a ReadStream from the file // and pipe it to the specified writableStream. var sourceStream = fs . createReadStream ( chunkFilename ) ; sourceStream . pipe ( writableStream , { end : false } ) ; sourceStream . on ( 'end' , function ( ) { // When the chunk is fully streamed, // jump to the next one pipeChunk ( number + 1 ) ; } ) ; } else { // When all the chunks have been piped, end the stream if ( options . end ) writableStream . end ( ) ; } } ) ; } pipeChunk ( 1 ) ; }", "del_tokens": "var fs = require ( 'fs' ) , path = require ( 'path' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "var", "for", "the", "defaults", "variable"], "add_tokens": "var defaults = {", "del_tokens": "defaults = {", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "with", "logging", "in", "SimpleQueuedHandler", "handler"], "add_tokens": "var log = this . _log ; log . error ( 'handle for' , type , 'failed:' , e . stack ) ;", "del_tokens": "this . _log . error ( 'handle for' , type , 'failed:' , e . stack ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "proper", "run", "all", "tests", "more", "tests", "some", "fixes"], "add_tokens": "if ( resolver !== null ) { resolver . fail ( failedWith ) ; resolver = null ; }", "del_tokens": "resolver . fail ( failedWith ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "collection", ".", "count", "is", "ignoring", "options"], "add_tokens": "return col . count ( query , opts ) return col . distinct ( field , query , opts )", "del_tokens": "return col . count ( query ) return col . distinct ( field , query )", "commit_type": "fix"}
{"commit_tokens": ["Add", "hide", "-", "on", "-", "click", "option", "(", "defaults", "to", "true", ")"], "add_tokens": "timeout : attrs . nsPopoverTimeout || 1.5 , hideOnClick : attrs . nsPopoverHideOnClick === 'true' || attrs . nsPopoverHideOnClick === undefined if ( options . hideOnClick ) { // Hide the popover without delay on click events. $popover . on ( 'click' , function ( ) { hider_ . hide ( $popover , 0 ) ; } ) ; }", "del_tokens": "timeout : attrs . nsPopoverTimeout || 1.5 // Hide the popover without delay on click events. $popover . on ( 'click' , function ( ) { hider_ . hide ( $popover , 0 ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "localName", "to", "nodeName", "."], "add_tokens": "if ( criteria && criteria . call ( null , node ) === true ) list . push ( node ) ; criteria = function ( _node ) { return ( _node . nodeType === 1 && _node . namespaceURI === ns ) ; criteria = function ( _node ) { return ( _node . nodeType === 1 && _node . namespaceURI === ns && _node . nodeName === tagName ) ; _getElementsByTagNameNS = func ; return func ( node , ns , prefix , tagName ) ; return this . type + \" \" + this . code + \": \" + this . message + \" (source: \" + this . source + \")\" ;", "del_tokens": "if ( criteria && criteria ( node ) === true ) list . push ( node ) ; criteria = function ( node ) { return ( node . nodeType === 1 && node . namespaceURI === ns ) ; criteria = function ( node ) { return ( node . nodeType === 1 && node . namespaceURI === ns && node . localName === tagName ) ; return ( _getElementsByTagNameNS = func ) ( node , ns , prefix , tagName ) ; return this . type + \" \" + this . code + \": \" + this . message ;", "commit_type": "change"}
{"commit_tokens": ["Added", "the", "extra", "manage", "params", "to", "the", "angular", "and", "mediator", "wrappers"], "add_tokens": "syncService . manage = function ( datasetId , options , queryParams , metaData ) { managerPromise = $q . when ( sync . manage ( datasetId , options , queryParams , metaData ) ) ;", "del_tokens": "syncService . manage = function ( datasetId ) { managerPromise = $q . when ( sync . manage ( datasetId ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "uuid", "a", "new", "type", "for", "use", "in", "set", "commands", "."], "add_tokens": "var minimist = require ( 'minimist' ) ; var _ = require ( 'lodash' ) ; var argv = minimist ( process . argv . slice ( 2 ) ) ; //Get the tags we need to run. var tags = argv . t || argv . tags || [ ] ; if ( ! _ . isArray ( tags ) ) { tags = [ tags ] ; } var tagArgs = tags . map ( function ( tag ) { return '-t ' + tag ; } ) . join ( ' ' ) ; '-r lib/steps.js -r test/steps/ -f pretty ' + tagArgs ,", "del_tokens": "'-r lib/steps.js -r test/steps/ -f pretty' ,", "commit_type": "make"}
{"commit_tokens": ["fixed", "typo", "in", "SMemory", ".", "js"], "add_tokens": "return this . getShadowObjectOfObject ( this . getFrame ( name ) ) ;", "del_tokens": "return this . getShadowObjectOfObject ( this . getFrame ( name ) ) l", "commit_type": "fix"}
{"commit_tokens": ["Using", "requestAlwaysAuthorization", "in", "example", "app", "to", "make", "monitoring", "work", "on", "iOS", "8", "."], "add_tokens": "EstimoteBeacons . requestAlwaysAuthorization ( ) ; EstimoteBeacons . requestAlwaysAuthorization ( ) ;", "del_tokens": "EstimoteBeacons . requestWhenInUseAuthorization ( ) ; EstimoteBeacons . requestWhenInUseAuthorization ( ) ;", "commit_type": "use"}
{"commit_tokens": ["changed", "some", "things", "in", "the", "chaining", "version"], "add_tokens": "function _isArray ( arg ) { return Object . prototype . toString . call ( arg ) == '[object Array]' ; } map = Array . prototype . map ? function ( array , func ) { return array . map ( func ) ; } : _map , isArray = Array . isArray || _isArray ; function fromDom ( a ) { a = isArray ( a ) ? a : [ a ] ; return new DomObject ( a ) ; } each ( this . a , $dom . empty ) ; window . $dom = { onready : $dom . onready , get : get , create : create , fromDom : fromDom } ;", "del_tokens": "map = Array . prototype . map ? function ( array , func ) { return array . map ( func ) ; } : _map ; each ( this . a , function ( elt ) { $dom . empty ( elt ) ; } ) ; DomObject . onready = $dom . onready ; DomObject . get = get ; DomObject . create = create ; window . $dom = DomObject ;", "commit_type": "change"}
{"commit_tokens": ["remove", "stray", "argument", "in", "merge", "()"], "add_tokens": "return assocIfDifferent ( obj , key , merge ( targetVal , resolvedSourceVal , resolver ) ) ;", "del_tokens": "return assocIfDifferent ( obj , key , merge ( targetVal , resolvedSourceVal , resolver ) , i . assoc ) ;", "commit_type": "remove"}
{"commit_tokens": ["Improve", "error", "handling", "and", "messaging", "."], "add_tokens": "if ( code !== 0 ) { return grunt . log . error ( 'The following error occured while trying to upload to sonar: ' + error ) ;", "del_tokens": "if ( code === 1 ) { return grunt . log . error ( 'Something went wrong while trying to upload to sonar. ' ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "shadow", "behaviour", "when", "both", "copy", "and", "revertOnSpill", "===", "true"], "add_tokens": "} else if ( o . revertOnSpill === true && ! o . copy ) { if ( ( o . copy || o . removeOnSpill === true ) && item . parentElement !== null ) {", "del_tokens": "} else if ( o . revertOnSpill === true ) { if ( o . removeOnSpill === true && item . parentElement !== null ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "empty", "string", "as", "default", "parameter", "value", "when", "returning", "the", "available", "resources", "instead", "of", "undefined", "."], "add_tokens": "* Returns the template parameters of the given url as object . e . g . from this url * 'http://localhost:8080/categories{?page,size,sort}' it will return the following object : * { 'page' : \"\" , 'size' : \"\" , 'sort' : \"\" } * @ returns { object } the object containing the template parameters templateParametersObject [ value ] = \"\" ;", "del_tokens": "* Returns the template parameters of the given url as array . e . g . from this url * 'http://localhost:8080/categories{?page,size,sort}' it will return the following array : * [ 'page' , 'size' , 'sort' ] * @ returns { object } the array containing the template parameters templateParametersObject [ value ] = undefined ;", "commit_type": "add"}
{"commit_tokens": ["Add", "placeholders", "for", "io", "builtins", "to", "improve", "error", "message"], "add_tokens": "var v = tab [ key ] ; return v === undefined ? null : v ;", "del_tokens": "return tab [ key ] ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "promise", "bug", "added", "quickhelp"], "add_tokens": "console . log ( chalk . cyan ( art ) ) ; } exports . quickHelp = function ( handler ) { let txt = '' ; txt += chalk . underline . cyan ( 'Commands' + os . EOL ) ; txt += '* Pass --help after any <context> <action> to get conextual help.' + os . EOL + os . EOL ; let contexts = Object . keys ( handler ) ; contexts . forEach ( function ( ctx ) { txt += '\"' + ctx + '\" actions:' + os . EOL ; let actions = Object . keys ( handler [ ctx ] ) ; actions . forEach ( function ( action ) { txt += chalk . cyan ( ' ' + action + os . EOL ) ; } , this ) ; } , this ) ; console . log ( txt ) ;", "del_tokens": "console . log ( chalk . yellow ( art ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "simple", "Template", "constructor", "to", "simplify", "code"], "add_tokens": "return Template ( function ( context ) { } , [ parameter ] ) ; return Template ( function ( ) { } , [ ] ) ; // Constructs a template function with `parameters` property. function Template ( fn , parameters ) { fn . parameters = parameters ; return fn ; }", "del_tokens": "var template = function ( context ) { } ; template . parameters = [ parameter ] ; return template ; var template = function ( context ) { } ; template . parameters = [ ] ; return template ;", "commit_type": "add"}
{"commit_tokens": ["Implementing", "error", "on", "error", "stream", "in", "listObjects"], "add_tokens": "stream . emit ( 'error' , e ) return queue . push ( null )", "del_tokens": "return queue . pipe ( null )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "bug", "that", "prevented", "vertical", "rhythm", "scaling", "for", "0", "values"], "add_tokens": "if ( size === undefined || size == null ) { return size", "del_tokens": "if ( ! size ) { return null", "commit_type": "fix"}
{"commit_tokens": ["Make", "pstarter", "running", "for", "project", "since", "it", "needs", "to", "adjust", "if", "anyone", "wants", "to", "use", "it", "anyway", "."], "add_tokens": "console . log ( 'Parent pid: ' + process . pid ) ; var r = parseInt ( Math . random ( ) * 10000 ) + 6000 ; console . log ( 'will die in ' + r + ' ms' ) ; setTimeout ( function ( ) { throw Error ( 'DADA' ) ; } , r ) ;", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "user", "token", "in", "client", ".", "open", "()"], "add_tokens": "if ( creds . username ) { method = 'POST' ; body = creds ; } else if ( creds . token ) { this . _token = creds . token ; } else { throw new Error ( 'credentials must be username/password or token.' ) ; }", "del_tokens": "method = 'POST' ; body = creds ;", "commit_type": "add"}
{"commit_tokens": ["Change", "default", "dev", "port", "for", "styleguide", "from", "3000", "to", "3003"], "add_tokens": "const devServerPort = process . env . HOT_RAILS_PORT || 3503 ;", "del_tokens": "const devServerPort = process . env . HOT_RAILS_PORT || 3500 ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "regression", "with", "the", "shaking", "bug", "being", "back"], "add_tokens": "// apply gravity (if any) if ( this . gravity ) { // apply a constant gravity (if not on a ladder) vel . y += ! this . onladder ? ( this . gravity * me . timer . tick ) : 0 ; // check if falling / jumping this . falling = ( vel . y > 0 ) ; this . jumping = this . falling ? false : this . jumping ; }", "del_tokens": "// apply a constant gravity (if not on a ladder) vel . y += ! this . onladder ? ( this . gravity * me . timer . tick ) : 0 ; // check if falling / jumping this . falling = ( vel . y > 0 ) ; this . jumping = this . falling ? false : this . jumping ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "configurable", "HTML", "header", "and", "footer", "."], "add_tokens": "/ ** * Configurable settings for the cheat sheet header and footer . Both are HTML , and the header * overrides the normal title if specified . * @ type { String } * / this . templateHeader = null ; this . templateFooter = null ; '<h4 class=\"cfp-hotkeys-title\" ng-if=\"!header\">{{ title }}</h4>' + '<div ng-bind-html=\"header\" ng-if=\"header\"></div>' + '<div ng-bind-html=\"footer\" ng-if=\"footer\"></div>' + / ** * Holds the header HTML for the help menu * @ type { String } * / scope . header = this . templateHeader ; / ** * Holds the footer HTML for the help menu * @ type { String } * / scope . footer = this . templateFooter ; _add ( 'esc' , previousEsc . description , toggleCheatSheet , null , [ 'INPUT' , 'SELECT' , 'TEXTAREA' ] ) ;", "del_tokens": "'<h4 class=\"cfp-hotkeys-title\">{{ title }}</h4>' + _add ( 'esc' , previousEsc . description , toggleCheatSheet , null , [ 'INPUT' , 'SELECT' , 'TEXTAREA' ] )", "commit_type": "add"}
{"commit_tokens": ["updating", "example", "to", "use", ".", "files"], "add_tokens": "gc . files ( [ 'scaffolds.json' , 'package.json' ] , function ( err , results ) {", "del_tokens": "var async = require ( 'async' ) ; console . log ( gc ) ; async . map ( [ 'scaffolds.json' , 'package.json' ] , function ( file , next ) { gc . file ( file , next ) ; } , function ( err , results ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "up", "some", "compiler", "errors"], "add_tokens": "var person = new Person ( this . createsend , this . clientId , emailAddress ) ;", "del_tokens": "var person = new Person ( this . createsend , this . clientId , emailaddress ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "the", "gauge", "widget"], "add_tokens": "/ *deccoboard.loadConfiguration({ } , } ] , ] } ) ; * /", "del_tokens": "deccoboard . loadConfiguration ( { } / * , } * / ] / * , ] * / } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "strict", "equal", "comparison", "."], "add_tokens": "if ( options && options . indentation === 'tab' ) {", "del_tokens": "if ( options && options . indentation == 'tab' ) {", "commit_type": "use"}
{"commit_tokens": ["fixed", "watch", "mode", "bug", "and", "added", "logs"], "add_tokens": "if ( ! process . env [ 'monkey.watch' ] ) { log . debug ( '[cuke-monkey][session-manager] watch mode is false, not reusing a session' ) ; log . debug ( '[cuke-monkey][session-manager]' , 'monkey patching the browser object' ) ;", "del_tokens": "if ( ! ! process . env [ 'watch' ] ) { log . debug ( '[cuke-monkey][session-manager] watch mode is true, not reusing a session' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "mock", "login", "/", "logout", "page"], "add_tokens": "use : 'mockAuth' , mockAuth : { authorizeUrl : ` ${ window . location . origin } ` , logoutUrl : ` ${ window . location . origin } ` , post_logout_redirect_uri : '/logout.html' , authorizeMethod : 'GET' , oAuthData : { client_id : 'egDuozijY5SVr0NSIowUP1dT6RVqHnlp' } } ,", "del_tokens": "// use: 'oAuth2ImplicitGrant',", "commit_type": "add"}
{"commit_tokens": ["Changed", "wait", "timer", "of", "linter", "to", "1s"], "add_tokens": "setTimeout ( ( ) => { } , 1000 ) ;", "del_tokens": "setTimeout ( ( ) => { } , 5000 ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "empty", "string", "for", "default", "dataTransfer"], "add_tokens": "e . dataTransfer . setData ( 'text' , '' ) ;", "del_tokens": "e . dataTransfer . setData ( 'text' , $element . text ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "how", "we", "create", "AST", "nodes", "."], "add_tokens": "var node = new AstNode ( _this , p . input , originalIndex , p . index ) ;", "del_tokens": "var node = new AstNode ( r , p . input , originalIndex , p . index ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "code", "flow", "graph", "."], "add_tokens": "var graph = new CodeFlowGraph ( document . getElementById ( 'demo' ) ) ; // console.log(event.data); if ( data . path [ data . path . length - 1 ] . startsWith ( 'anonymous' ) ) { return ; } graph . insertNode ( data ) ; // console.log(data);", "del_tokens": "var execGraph = new ExecutionGraph ( ) ; execGraph . insertNode ( data ) ; console . log ( data ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "escape", "arguments", "of", "function"], "add_tokens": "/ *! OpenCrisp PathJS - v0.4.2 - 2015-10-16 '|' + '\\\\$([\\\\w]+)\\\\s?(?![\\\\w\\\\.:])' + // [11] varName for includet values obj . _args = JSON . parse ( '[' + score [ 3 ] . replace ( / \\\\\\) / , ')' ) + ']' ) ; // console.log('PathFunction.exec', this.name() );", "del_tokens": "/ *! OpenCrisp PathJS - v0.4.1 - 2015-10-13 '|' + '\\\\$([\\\\w]+)\\\\s?(?![\\\\w\\\\.:])' + // [11] varName for includet values obj . _args = JSON . parse ( '[' + score [ 3 ] + ']' ) ; // console.log('PathFunction.exec', node, this.name() );", "commit_type": "fix"}
{"commit_tokens": ["added", "hook", "for", "building", "source"], "add_tokens": "@ param [ exitCb ] { Function } Function to call when exiting function . @ param [ sourceCb ] { Function } Function to call when building the source for a function . function insertEnterExitHooksSync ( filename , enterCb , exitCb , sourceCb ) { transform : [ 'enter-exit' ] , hookFilename : filename , hookSourceCb : sourceCb", "del_tokens": "@ param exitCb { Function } Function to call when exiting function . function insertEnterExitHooksSync ( filename , enterCb , exitCb ) { transform : [ 'enter-exit' ] , hookFilename : filename", "commit_type": "add"}
{"commit_tokens": ["Added", "async", "test", "to", "ComputedProperties", "tests", "to", "ensure", "only", "one", "computed", "property", "re", "-", "evaluation", "on", "bulk", "change", "."], "add_tokens": "QUnit . test ( 'Rebound Data - Computed Properties' , function ( assert ) { stop ( ) ; setTimeout ( function ( ) { start ( ) ; equal ( window . count , 1 , 'Repetitive changes to a Collection recompute a Computed Property that depends on it only once after all changes are made.' ) ; } , 0 ) ;", "del_tokens": "QUnit . test ( 'Rebound Data - Computed Properties' , function ( ) { debugger ; debugger ; equal ( window . count , 1 , 'Repetitive changes to a Collection recompute a Computed Property that depends on it only once after all changes are made.' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "osc", "send", "data", "type", "check"], "add_tokens": "/*! osc-js - v0.1.1 - 2014-08-10 by marmorkuchen.net */ if ( this . _socket ) { if ( sData && sData . buffer && sData . buffer instanceof ArrayBuffer ) { this . _socket . send ( sData . buffer ) ; return true ; } else { return false ; } throw \"OSCSocket Error: WebSocket is not ready to send OSC data\" ;", "del_tokens": "/*! osc-js - v0.1.0 - 2014-05-14 by marmorkuchen.net */ if ( sData && sData instanceof ArrayBuffer ) { this . _socket . send ( sData . buffer ) ; return true ; return false ;", "commit_type": "fix"}
{"commit_tokens": ["use", "file", "-", "reader", "adds", ".", "dryRun", "method"], "add_tokens": "require ( 'file-reader' , 'reader' ) ; require ( 'resolve-glob' , 'glob' ) ;", "del_tokens": "require ( 'resolve-glob' , 'glob' ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "plugin", "preparing", "event", "plugin", "params", "bug"], "add_tokens": "plugin : self ,", "del_tokens": "route : self ,", "commit_type": "fix"}
{"commit_tokens": ["changes", "the", "way", "css", "bower", "files", "gets", "renamed", "to", "scss"], "add_tokens": "tasks : [ 'watch:livereload' , 'connect' ] grunt . registerTask ( 'build' , [ 'copy:build' , 'sass' , 'requirejs' ] ) ; grunt . registerTask ( 'dev' , [ 'parallel:dev' ] ) ;", "del_tokens": "} , bowerDependencies : { files : [ 'bower_components/**/*.css' ] , tasks : [ 'copy:bowerDependenciesAsSCSS' ] tasks : [ 'watch:livereload' , 'watch:bowerDependencies' , 'connect' ] grunt . registerTask ( 'build' , [ 'copy:bowerDependenciesAsSCSS' , 'copy:build' , 'sass' , 'requirejs' ] ) ; grunt . registerTask ( 'dev' , [ 'copy:bowerDependenciesAsSCSS' , 'parallel:dev' ] ) ;", "commit_type": "change"}
{"commit_tokens": ["Make", "OK", "/", "FAIL", "bold", "."], "add_tokens": "this . _write ( ` ${ this . indent } ${ result . name } ` + ` ${ Style . bold ( passed ? Style . green ( \"OK\" ) : Style . red ( \"FAIL\" ) ) } ` ) ;", "del_tokens": "this . _write ( ` ${ this . indent } ${ result . name } ${ passed ? Style . green ( \"OK\" ) : Style . red ( \"FAIL\" ) } ` ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "Prettier", "for", "code", "style"], "add_tokens": "Object . keys ( err . info ) . forEach ( key => { if ( ! has ( error , key ) && has ( err . info , key ) ) error [ key ] = err . info [ key ] ;", "del_tokens": "Object . keys ( err . info ) . forEach ( ( key ) => { if ( ! has ( error , key ) && has ( err . info , key ) ) error [ key ] = err . info [ key ] ;", "commit_type": "use"}
{"commit_tokens": ["Make", "TabList", "controlled", "when", "selectedIndex", "prop", "is", "0"], "add_tokens": "Hello World Hello World if ( props . selectedIndex === undefined ) { return ( this . props . selectedIndex === undefined ) ? this . state . selectedIndex : this . props . selectedIndex if ( this . props . selectedIndex === undefined ) {", "del_tokens": "{ faker . lorem . paragraphs ( ) } { faker . lorem . paragraphs ( ) } if ( ! props . selectedIndex ) { return this . props . selectedIndex || this . state . selectedIndex if ( ! this . props . selectedIndex ) {", "commit_type": "make"}
{"commit_tokens": ["fixed", "typo", "and", "param", "name"], "add_tokens": "param : 'url_or_script' , info : 'get the CPU, bandwidth and memory utilization data from test'", "del_tokens": "param : 'url|script' , info : 'get the CPU, bandwidth and memory utilizations data from test'", "commit_type": "fix"}
{"commit_tokens": ["Move", "incompatible", "argument", "checking", "to", "bin", "file"], "add_tokens": "if ( argv . metallicRoughness + argv . specularGlossiness + argv . materialsCommon > 1 ) { console . error ( 'Only one material type may be set from [--metallicRoughness, --specularGlossiness, --materialsCommon].' ) ; process . exit ( 1 ) ; } if ( defined ( argv . metallicRoughnessOcclusionTexture ) && defined ( argv . specularGlossinessTexture ) ) { console . error ( '--metallicRoughnessOcclusionTexture and --specularGlossinessTexture cannot both be set.' ) ; process . exit ( 1 ) ; } obj2gltf ( objPath , gltfPath , options ) . then ( function ( ) { console . timeEnd ( 'Total' ) ; } ) . catch ( function ( error ) { console . log ( error . message ) ; } ) ;", "del_tokens": "try { obj2gltf ( objPath , gltfPath , options ) . then ( function ( ) { console . timeEnd ( 'Total' ) ; } ) . catch ( function ( error ) { console . log ( error . message ) ; } ) ; } catch ( error ) { console . log ( error . message ) ; }", "commit_type": "move"}
{"commit_tokens": ["use", "custom", "createApiVisitor", "and", "createApiMethod", "in", "buildDocumentationAst", ".", "js"], "add_tokens": "function createApiInterface ( node ) { export default createApiInterface ;", "del_tokens": "function createPlayerApiInterface ( node ) { export default createPlayerApiInterface ;", "commit_type": "use"}
{"commit_tokens": ["use", "use", "types", "from", "known"], "add_tokens": "const generators = require ( 'yeoman-generator' ) ; const knownPluginTypes = require ( '../../utils/known' ) . plugin . types ;", "del_tokens": "var generators = require ( 'yeoman-generator' ) ; const knownPluginTypes = [ 'app' , 'bundle' , 'lib' , 'server' , 'service' ] ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "up", "my", "linter", "and", "fix", "up", "all", "the", "bits", "I", "missed", "while", "it", "was", "broken"], "add_tokens": "} ;", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "layer", "of", "ACL", "to", "collections", ".", "If", "Collection", "permissions", "are", "defined", "check", "ACL", "based", "on", "those", "first", "."], "add_tokens": "var ACLCollection = require ( './acl_collection' ) ; ACLIndexMixin . initACL = ACLCollection . prototype . initACL ; ACLIndexMixin . canAccess = ACLCollection . prototype . canAccess ; ACLIndexMixin . getRoles = ACLCollection . prototype . getRoles ;", "del_tokens": "initACL : function ( ) { this . acl = new acl . ACL ( this . permissions ) ; } , canAccess : function ( action , actor , model ) { return this . acl . assert ( this . getRoles ( actor , model ) , action ) ; } , getRoles : function ( actor , model ) { var roles = [ ] ; if ( ! actor || ! model ) return roles ; if ( model && actor && model . id === actor . id ) { roles . push ( 'owner' ) ; } roles = _ . uniq ( ( actor . roles || [ ] ) . concat ( roles ) ) ; return roles ; } ,", "commit_type": "add"}
{"commit_tokens": ["move", "utils", "only", "apply", "layouts", "once"], "add_tokens": "assert . equal ( err . message , 'expected layout name to be a string or falsey, not undefined' ) ;", "del_tokens": "assert . equal ( err . message , 'expected layout name to be a string' ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "so", "pagination", "does", "not", "show", "from", "1", "to", "x", "when", "there", "are", "0", "results"], "add_tokens": "* It formats requests to required format and parses the * from : ( res . data . count === 0 ) ? 0 : res . data . skip + 1 , return $window . localStorage . getItem ( KEY_API_TOKEN ) ; config . headers = { Authorization : 'OAuth ' + token } ;", "del_tokens": "* It formats requests to required format and parses the * from : res . data . skip + 1 , return $window . localStorage . getItem ( KEY_API_TOKEN ) ; ; config . headers = { Authorization : 'OAuth ' + token }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "additional", "explicit", "dependencies", "on", "OT"], "add_tokens": "Tracer . initGlobalTracer ( lib . tracer ( opts ) ) ; // eslint-disable-line no-undef", "del_tokens": "import OpenTracing from 'opentracing' ; OpenTracing . initGlobalTracer ( lib . tracer ( opts ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "mapping", "of", "log", "level"], "add_tokens": "acetate . log . level = options . logLevel ;", "del_tokens": "acetate . log . logLevel = options . logLevel ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "req", ".", "sessionOptions", "a", "shallow", "clone", "to", "override", "per", "-", "request"], "add_tokens": "req . sessionOptions = Object . create ( opts ) req . sessionKey = name json = cookies . get ( name , req . sessionOptions ) cookies . set ( name , '' , req . sessionOptions )", "del_tokens": "req . sessionOptions = opts ; req . sessionKey = name ; json = cookies . get ( name , opts ) ; cookies . set ( name , '' , opts ) ;", "commit_type": "make"}
{"commit_tokens": ["removed", "dependencies", "and", "added", "more", "functions"], "add_tokens": "return new Promise ( function ( resolve , reject ) { Promise . all ( cbs ) . then ( function ( ) {", "del_tokens": "var promise = require ( 'bluebird' ) ; return new promise ( function ( resolve , reject ) { promise . all ( cbs ) . then ( function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "tests", "to", "confirm", "that", "constructor", "args", "override", "Express", "settings"], "add_tokens": "it ( 'should render a partial from the directory set in constructor' , function ( done ) { var renderer = mustacheExpress ( 'test/test02' , '.mustache' ) ; renderer ( 'test/test03/index.mustache' , { name : 'someone' , settings : { views : 'test/test03' } } , function ( err , result ) { should . not . exist ( err ) ; should . exist ( result ) ; result . should . eql ( 'Hey, someone' ) ; done ( ) ; } ) ; } ) ; it ( 'should use the partial extension set in constructor' , function ( done ) { var renderer = mustacheExpress ( 'test/test09' , '.m' ) ; renderer ( 'test/test09/index.mustache' , { settings : { 'view engine' : 'mustache' } } , function ( err , result ) { should . not . exist ( err ) ; should . exist ( result ) ; result . should . eql ( 'Partial: partial.m' ) ; done ( ) ; } ) ; } ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "remaining", "warnings", "in", "lint", ":", "scripts"], "add_tokens": "if ( { } . hasOwnProperty . call ( events , key ) ) { method = events [ key ] ; if ( isFunction ( this [ method ] ) ) method = this [ method ] ; if ( method ) { match = key . match ( delegateEventSplitter ) ; this . delegate ( match [ 1 ] , match [ 2 ] , bind ( method , this ) ) ; } }", "del_tokens": "method = events [ key ] ; if ( isFunction ( this [ method ] ) ) method = this [ method ] ; if ( ! method ) continue ; match = key . match ( delegateEventSplitter ) ; this . delegate ( match [ 1 ] , match [ 2 ] , bind ( method , this ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "first", "tests", "for", "marking", "unstable", "right", "now"], "add_tokens": "} ] , preLoaders : [ { test : / \\.js$ / , include : / src\\/main / , loader : \"jshint-loader\" } ]", "del_tokens": "} ]", "commit_type": "add"}
{"commit_tokens": ["remove", "benchmark", "add", "workspace", "and", "plugins"], "add_tokens": "name : startCase ( pkg . name ) . replace ( / @vericus / g , \"\" ) . replace ( / / g , \"\" ) ,", "del_tokens": "name : startCase ( pkg . name ) . replace ( / / g , \"\" ) ,", "commit_type": "remove"}
{"commit_tokens": ["added", "input", "editor", "to", "build"], "add_tokens": "src : [ '<banner>' , 'src/inline-attachment.js' , 'src/input.inline-attachment.js' ] ,", "del_tokens": "src : [ '<banner>' , 'src/inline-attachment.js' ] ,", "commit_type": "add"}
{"commit_tokens": ["Move", "hyperlinks", "(", "and", "jsPDF", "-", "plugin", ")", "to", "plugins", "dir"], "add_tokens": "import './plugin/jspdf-plugin.js' ;", "del_tokens": "import './jspdf-plugin.js' ; // Get the locations of all hyperlinks. if ( opt . enableLinks ) { // Find all anchor tags and get the container's bounds for reference. opt . links = [ ] ; var links = container . querySelectorAll ( 'a' ) ; var containerRect = unitConvert ( container . getBoundingClientRect ( ) , pageSize . k ) ; // Treat each client rect as a separate link (for text-wrapping). Array . prototype . forEach . call ( links , function ( link ) { var clientRects = link . getClientRects ( ) ; for ( var i = 0 ; i < clientRects . length ; i ++ ) { var clientRect = unitConvert ( clientRects [ i ] , pageSize . k ) ; clientRect . left -= containerRect . left ; clientRect . top -= containerRect . top ; opt . links . push ( { el : link , clientRect : clientRect } ) ; } } ) ; }", "commit_type": "move"}
{"commit_tokens": ["Allow", "target", "to", "be", "specified", "from", "the", "Gruntfile", "options", ".", "If", "not", "provided", "default", "to", "noarch"], "add_tokens": "var target = options . targetArch || 'noarch' ;", "del_tokens": "var target = 'noarch' ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "regex", "for", "<", "0", "values"], "add_tokens": "var remgex = / (\\d*\\.?\\d+)rem / i ;", "del_tokens": "var remgex = / (\\d+(\\.\\d+)?)rem / i ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "the", "client", "and", "tests", "work", "on", "IE"], "add_tokens": "\"use strict\" ; var ECHOENDPOINT_URL = \"http://\" + document . location . host + \"/echo\" ; var transportTypes = [ signalR . TransportType . WebSockets ] ; if ( typeof EventSource !== \"undefined\" ) { getTransportTypes ( ) . forEach ( function ( t ) { return action ( t ) ; } ) ; var protocols = [ new signalR . JsonHubProtocol ( ) , new signalRMsgPack . MessagePackHubProtocol ( ) ] ; getTransportTypes ( ) . forEach ( function ( t ) { return protocols . forEach ( function ( p ) { return action ( t , p ) ; } ) ; } ) ; }", "del_tokens": "const ECHOENDPOINT_URL = ` ${ document . location . host } ` ; let transportTypes = [ signalR . TransportType . WebSockets ] ; if ( typeof ( EventSource ) !== \"undefined\" ) { getTransportTypes ( ) . forEach ( t => action ( t ) ) ; let protocols = [ new signalR . JsonHubProtocol ( ) , new signalRMsgPack . MessagePackHubProtocol ( ) ] ; getTransportTypes ( ) . forEach ( t => protocols . forEach ( p => action ( t , p ) ) ) ; }", "commit_type": "make"}
{"commit_tokens": ["use", "bounding", "spheres", "for", "center", "and", "auto", "-", "zoom"], "add_tokens": "function Sphere ( center , radius ) { this . _center = center || vec3 . create ( ) ; this . _radius = radius || 1.0 ; } Sphere . prototype . center = function ( ) { return this . _center ; } ; Sphere . prototype . radius = function ( ) { return this . _radius ; } ; catmullRomSplineNumPoints : catmullRomSplineNumPoints , Sphere : Sphere", "del_tokens": "catmullRomSplineNumPoints : catmullRomSplineNumPoints", "commit_type": "use"}
{"commit_tokens": ["added", "callback", "as", "optional", "param", "to", "shell", ".", "nscript"], "add_tokens": "onOut : function ( cb ) { // TODO: rename to onData & onErrorData? // FEATURE: onLine, like onOut, but for each line", "del_tokens": "onOut : function ( cb ) {", "commit_type": "add"}
{"commit_tokens": ["use", "getPropName", "insetad", "of", "getPropExpression"], "add_tokens": "[ attrs [ getPropName ( prop ) ] , getPropConfig ( prop ) ] :", "del_tokens": "[ attrs [ getPropExpression ( prop ) ] , getPropConfig ( prop ) ] :", "commit_type": "use"}
{"commit_tokens": ["Added", "browser", "-", "usable", "output", "of", "webpack", ":", "dist", "/", "origin", ".", "js"], "add_tokens": "var serverConfig = { } var clientConfig = { entry : './src/index.js' , output : { filename : './dist/origin.js' , libraryTarget : 'window' } , devtool : 'inline-source-map' , target : 'web' , module : { loaders : [ { test : / \\.js$ / , exclude : / (node_modules|bower_components) / , loader : 'babel-loader' , query : { presets : [ 'babel-preset-es2015' ] , plugins : [ 'transform-class-properties' ] } } ] } } module . exports = [ serverConfig , clientConfig ] ;", "del_tokens": "module . exports = { } ;", "commit_type": "add"}
{"commit_tokens": ["Use", "fn", "for", "creating", "session", "and", "triggering", "event"], "add_tokens": "function makeSession ( connection , payload ) { var session = new Session ( payload ) ; connection . createInstance ( session ) ; Session . trigger ( 'created' , [ session ] ) ; return session ; } return makeSession ( self , payload ) ; return makeSession ( self , payload ) ;", "del_tokens": "var session = new Session ( payload ) ; self . createInstance ( session ) ; Session . trigger ( 'created' , [ session ] ) ; self . createInstance ( payload ) ; Session . trigger ( 'created' , [ payload ] ) ; return resolve ( new Session ( payload ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Create", "a", "component", "for", "widget", "configurations", "."], "add_tokens": "let yPosition = ( pdf . internal . pageSize . getHeight ( ) - resizeDimensions . height - 70 ) / 2 ; if ( yPosition < 70 ) { yPosition += 70 ;", "del_tokens": "let yPosition = ( pdf . internal . pageSize . getHeight ( ) - resizeDimensions . height - 50 ) / 2 ; if ( yPosition < 40 ) { yPosition += 85 ; alert ( yPosition ) ; alert ( printHeight + ' :: ' + printWidth ) ;", "commit_type": "create"}
{"commit_tokens": ["Allow", "KARMA_BROWSER", "to", "be", "an", "array"], "add_tokens": "process . env . KARMA_BROWSER . split ( / \\s+,\\s+ / ) . forEach ( browser => { BROWSERS . push ( browser ) ; PLUGINS . push ( ` ${ browser . toLowerCase ( ) } ` ) ; } ) ; if ( process . platform === 'darwin' ) { BROWSERS . push ( 'Safari' ) ; }", "del_tokens": "BROWSERS . push ( process . env . KARMA_BROWSER ) ; PLUGINS . push ( ` ${ process . env . KARMA_BROWSER . toLowerCase ( ) } ` ) ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "enum", "export", "by", "upgrading", "closure", "compiler"], "add_tokens": "var EnumTest1 ; ( function ( EnumTest1 ) { EnumTest1 [ EnumTest1 [ \"XYZ\" ] = 0 ] = \"XYZ\" ; EnumTest1 [ EnumTest1 [ \"PI\" ] = 3.14159 ] = \"PI\" ; } ) ( EnumTest1 || ( EnumTest1 = { } ) ) ; /** @type {EnumTest1} */ EnumTest1 . XYZ = 0 ; /** @type {EnumTest1} */ EnumTest1 . PI = 3.14159 ; /** @typedef {number} */ // This additional exported enum is here to exercise the fix for issue #51. export var EnumTest2 ; ( function ( EnumTest2 ) { EnumTest2 [ EnumTest2 [ \"XYZ\" ] = 0 ] = \"XYZ\" ; EnumTest2 [ EnumTest2 [ \"PI\" ] = 3.14159 ] = \"PI\" ; } ) ( EnumTest2 || ( EnumTest2 = { } ) ) ; /** @type {EnumTest2} */ EnumTest2 . XYZ = 0 ; /** @type {EnumTest2} */ EnumTest2 . PI = 3.14159 ;", "del_tokens": "var FooEnum ; ( function ( FooEnum ) { FooEnum [ FooEnum [ \"XYZ\" ] = 0 ] = \"XYZ\" ; FooEnum [ FooEnum [ \"PI\" ] = 3.14159 ] = \"PI\" ; } ) ( FooEnum || ( FooEnum = { } ) ) ; /** @type {FooEnum} */ FooEnum . XYZ = 0 ; /** @type {FooEnum} */ FooEnum . PI = 3.14159 ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "node", ".", "js"], "add_tokens": "( function ( global ) { global . Interface = function Interface ( nameOrNameSpace , name ) { global . Module = function Module ( nameOrNameSpace , name ) { global . Class = function Class ( classNameOrNameSpace , className ) { } ( typeof window === 'undefined' ? exports : window ) ) ;", "del_tokens": "var Interface = function Interface ( nameOrNameSpace , name ) { var Module = function Module ( nameOrNameSpace , name ) { var Class = function Class ( classNameOrNameSpace , className ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "Hub", "class", "io", "property", "bug"], "add_tokens": "if ( options . io ) this . io = options . io ;", "del_tokens": "if ( options . app ) this . io = options . io ;", "commit_type": "fix"}
{"commit_tokens": ["use", "a", "configuration", "option", "to", "enable", "use", "of", "embedded", "file", "resources"], "add_tokens": "'../utilities/path' , '../portal/configuration' ] , function ( assert , string , path , configuration ) { var ENTRY_TYPE_FILE = 1 ; this . useEmbedded_ = configuration . get ( 'file_resource_provider.useEmbedded' , false ) ; if ( self . useEmbedded_ ) { return typeof ( value ) === 'string' ? value : ( value === ENTRY_TYPE_FILE ) ; } else { return typeof ( value ) === 'string' || ( value === ENTRY_TYPE_FILE ) ; }", "del_tokens": "'../utilities/path' ] , function ( assert , string , path ) { return typeof ( value ) === 'string' ? value : ( value === 1 ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "un", "-", "init", "on", "app", "quit"], "add_tokens": "stop ( ) ; app . quit ( ) ; process . exit ( 1 ) ; app . quit ( ) ;", "del_tokens": "app . quit ( ) ; process . exit ( 1 ) ; // eslint-disable-line unicorn/no-process-exit", "commit_type": "fix"}
{"commit_tokens": ["allow", "mirror", "parent", "node", "to", "be", "configured"], "add_tokens": "if ( o . mirrorContainer === void 0 ) { o . mirrorContainer = body ; } o . mirrorContainer . appendChild ( _mirror ) ; addClass ( o . mirrorContainer , 'gu-unselectable' ) ; rmClass ( o . mirrorContainer , 'gu-unselectable' ) ;", "del_tokens": "body . appendChild ( _mirror ) ; addClass ( body , 'gu-unselectable' ) ; rmClass ( body , 'gu-unselectable' ) ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "event", "if", "not", "originalEvent"], "add_tokens": "var e = event . originalEvent || event ;", "del_tokens": "var e = event . originalEvent ;", "commit_type": "use"}
{"commit_tokens": ["Use", "camel", "case", "for", "node", "/", "edge", "/", "graph", "attrs"], "add_tokens": "defaultInt ( g . attrs , \"nodeSep\" , 50 ) ; defaultFloat ( attrs , \"strokeWidth\" , 1.5 ) ; defaultVal ( attrs , \"fontColor\" , \"#333\" ) ; defaultVal ( attrs , \"fontName\" , \"Times New Roman\" ) ; defaultInt ( attrs , \"fontSize\" , 14 ) ; defaultFloat ( attrs , \"strokeWidth\" , 1.5 ) ;", "del_tokens": "defaultInt ( g . attrs , \"nodesep\" , 50 ) ; defaultFloat ( attrs , \"strokewidth\" , 1.5 ) ; defaultVal ( attrs , \"fontcolor\" , \"#333\" ) ; defaultVal ( attrs , \"fontname\" , \"Times New Roman\" ) ; defaultInt ( attrs , \"fontsize\" , 14 ) ; defaultFloat ( attrs , \"strokewidth\" , 1.5 ) ;", "commit_type": "use"}
{"commit_tokens": ["Change", "toggleSlider", "to", "just", "toggle"], "add_tokens": "current . after ( $ ( useLink ) . on ( 'click' , function ( event ) { $this . toggle ( this , current , event ) } ) . attr ( { 'data-readmore-js-toggle' : '' , 'aria-controls' : id } ) ) ; toggle : function ( trigger , element , event ) { $trigger . replaceWith ( $ ( $this . options [ newLink ] ) . on ( 'click' , function ( event ) { $this . toggle ( this , element , event ) } ) . attr ( { 'data-readmore-js-toggle' : '' , 'aria-controls' : $element . attr ( 'id' ) } ) ) ;", "del_tokens": "current . after ( $ ( useLink ) . on ( 'click' , function ( event ) { $this . toggleSlider ( this , current , event ) } ) . attr ( { 'data-readmore-js-toggle' : '' , 'aria-controls' : id } ) ) ; toggleSlider : function ( trigger , element , event ) $trigger . replaceWith ( $ ( $this . options [ newLink ] ) . on ( 'click' , function ( event ) { $this . toggleSlider ( this , element , event ) } ) . attr ( { 'data-readmore-js-toggle' : '' , 'aria-controls' : $element . attr ( 'id' ) } ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Upgrade", "hut", "-", "build", "and", "fix", "lint"], "add_tokens": "'use strict' ; }", "del_tokens": "}", "commit_type": "upgrade"}
{"commit_tokens": ["Update", "app", ".", "js", "and", ".", "gitignore"], "add_tokens": "} ( jQuery ) ) ;", "del_tokens": "} ( jQuery ) ) ; ( function ( i , s , o , g , r , a , m ) { i [ 'GoogleAnalyticsObject' ] = r ; i [ r ] = i [ r ] || function ( ) { ( i [ r ] . q = i [ r ] . q || [ ] ) . push ( arguments ) } , i [ r ] . l = 1 * new Date ( ) ; a = s . createElement ( o ) , m = s . getElementsByTagName ( o ) [ 0 ] ; a . async = 1 ; a . src = g ; m . parentNode . insertBefore ( a , m ) } ) ( window , document , 'script' , '//www.google-analytics.com/analytics.js' , 'ga' ) ; ga ( 'create' , 'UA-46680343-1' , 'almsaeedstudio.com' ) ; ga ( 'send' , 'pageview' ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "abstract", "function", "(", "avoid", "parsing", "a", "function", "body", ")"], "add_tokens": "result . methods . push ( [ flags ] . concat ( this . read_function ( false , flags [ 2 ] === 1 ) ) ) ;", "del_tokens": "result . methods . push ( [ flags ] . concat ( this . read_function ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "an", "option", "to", "clear", "the", "console"], "add_tokens": "this . onError = options . onError ; this . shouldClearConsole = Boolean ( options . clearConsole ) ; this . clearConsole ( ) ; this . clearConsole ( ) ; clearConsole ( ) { if ( this . shouldClearConsole ) { output . clearConsole ( ) ; } } if ( this . onError ) { this . onError ( level , processedErrors ) ;", "del_tokens": "this . notifier = options . notifier ; output . clearConsole ( ) ; output . clearConsole ( ) ; if ( this . notifier ) { this . notifier ( level , processedErrors ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "a", "script", "to", "do", "shared", "annotation", "counts", ";", "test", "for", "val"], "add_tokens": "amigo . version . release = \"20121020\" ;", "del_tokens": "amigo . version . release = \"20121018\" ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "pseudo", "random", "if", "an", "env", "variable", "was", "set", "."], "add_tokens": "// if we allow less good entropy, do it. otherwise, puke. if ( process . env . RAND_ALLOW_PRNG ) { buf = crypto . pseudoRandomBytes ( self . bufferSize ) ; } else { throw ( err ) ; }", "del_tokens": "// TODO: generate less good entropy throw ( err ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "method", "to", "get", "authenticated", "user"], "add_tokens": "[ this . id ? '/users/' + this . id : '/user' ] . concat ( _ . toArray ( arguments ) ) // Get a single user", "del_tokens": "[ '/user/' + this . id ] . concat ( _ . toArray ( arguments ) ) // Get details about the repository", "commit_type": "add"}
{"commit_tokens": ["add", "choice", "for", "virtualenv", "in", "ueber", "generator"], "add_tokens": "constructor ( args , options ) { super ( args , options ) ; this . option ( 'venv' , { alias : 'v' } ) } prompting ( ) { return this . prompt ( { type : 'list' , name : 'virtualEnvironment' , message : 'Virtual Environment' , store : true , choices : [ 'vagrant' , 'conda' , 'virtualenv' ] , default : 'vagrant' when : ! this . optiosn . venv } ) . then ( ( props ) => { this . venv = props . virtualEnvironment || this . options . venv ; } ) ; } default ( ) { this . composeWith ( ` ${ this . venv } ` , { options : this . options } , { local : require . resolve ( ` ${ this . venv } ` ) } ) ; }", "del_tokens": "// prompting() { // return this.prompt([]).then((props) => { // // }); // }", "commit_type": "add"}
{"commit_tokens": ["Move", "order", "spec", "into", "index", "definitions"], "add_tokens": "order : 'desc' , }", "del_tokens": "} , order : 'desc'", "commit_type": "move"}
{"commit_tokens": ["fixing", "bug", "and", "updating", "readme"], "add_tokens": "result . path = x . path ;", "del_tokens": "result . path = path ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "exception", "handling", "when", "writing", "to", "file"], "add_tokens": "try { fs . writeFileSync ( filePath , xml , 'utf-8' ) ; } catch ( exc ) { debug ( 'problem writing results: ' + exc ) ; }", "del_tokens": "fs . writeFileSync ( filePath , xml , 'utf-8' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "Countable", ".", "once"], "add_tokens": "once : function ( elements , callback , options ) {", "del_tokens": "once : function ( callback , options ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "initial", "support", "for", "aggregation", "functions", ":", "MIN", "MAX"], "add_tokens": "store . execute ( 'INSERT DATA { <http://example/book3> <http://example.com/vocab#title> <http://test.com/example> }' , function ( result , msg ) {", "del_tokens": "store . execute ( 'INSERT DATA { <http://example/book3> <http://example.com/vocab#title> <http://test.com/example> }' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Update", "instrument", "file", "info", "objects"], "add_tokens": "if ( file . code ) { // TODO code as string // mod; } else if ( file . path ) { mod = require ( file . path ) ; if ( ! mod . name ) { mod . name = getFileName ( file . path ) ; } } else { mod = file ; } throw new Error ( 'Missing instrument filename from module exports.' ) ; hooks [ key ] . push ( { 'callback' : mod [ key ] , 'name' : mod . name } ) ; var apiContext = [ api . createSubContext ( data . name ) , options && options . config [ data . name ] ] ; var callers = requireFilesAndMapToLists ( options . instrument ) ;", "del_tokens": "mod = file ; throw new Error ( 'Missing name' ) ; hooks [ key ] . push ( { callback : mod [ key ] , name : mod . name } ) ; var apiContext = [ api . createSubContext ( data . name ) , options && options . config [ data . name ] ] ; var callers = requireFilesAndMapToLists ( options . hooks ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", "import", "and", "disable", "flair", "tests", "temporarily"], "add_tokens": "import resolveFlair from '../resolveFlair' describe . skip ( 'Function resolveFlair', () >", "del_tokens": "import { resolveFlair } from '..' describe ( 'Function resolveFlair', () >", "commit_type": "change"}
{"commit_tokens": ["moved", "afterEach", "after", "test", "after", "functions"], "add_tokens": "if ( ! afterEach ) { // make sure `afterEach` is defined afterEach = [ ] ; } else if ( ! ( afterEach instanceof Array ) ) { // make sure `afterEach` is an array afterEach = [ afterEach ] ; } // iterate over all `afterEach` functions, add to `queue` afterEach . forEach ( function ( fn ) { queue . push ( fn ) ; } ) ;", "del_tokens": "if ( ! afterEach ) { // make sure `afterEach` is defined afterEach = [ ] ; } else if ( ! ( afterEach instanceof Array ) ) { // make sure `afterEach` is an array afterEach = [ afterEach ] ; } // iterate over all `afterEach` functions, add to `queue` afterEach . forEach ( function ( fn ) { queue . push ( fn ) ; } ) ;", "commit_type": "move"}
{"commit_tokens": ["Move", "dir", "check", "to", "inside", "create", "function"], "add_tokens": "if ( ! hasDataDirectory ( ) ) { logger . error ( 'Could not find whosonfirst data directory in configuration' ) ; process . exit ( 2 ) ; } var directory = peliasConfig . imports . whosonfirst . datapath ; if ( directory . slice ( - 1 ) !== '/' ) { directory = directory + '/' ; } startWorker ( directory , layer , function ( err , worker ) { function startWorker ( directory , layer , callback ) { } function hasDataDirectory ( ) { return peliasConfig . imports . hasOwnProperty ( 'whosonfirst' ) && peliasConfig . imports . whosonfirst . hasOwnProperty ( 'datapath' ) ; }", "del_tokens": "function hasDataDirectory ( ) { return peliasConfig . imports . hasOwnProperty ( 'whosonfirst' ) && peliasConfig . imports . whosonfirst . hasOwnProperty ( 'datapath' ) ; } if ( ! hasDataDirectory ( ) ) { console . error ( 'Could not find whosonfirst data directory in configuration' ) ; process . exit ( 2 ) ; } var directory = peliasConfig . imports . whosonfirst . datapath ; if ( directory . slice ( - 1 ) !== '/' ) { directory = directory + '/' ; } startWorker ( layer , function ( err , worker ) { function startWorker ( layer , callback ) { }", "commit_type": "move"}
{"commit_tokens": ["removed", "caching", "data", "for", "improving", "speed"], "add_tokens": "* * { callback : func ( ) { } } * / if ( pOptions )", "del_tokens": "exports . Cache = { } ; * if cache true files do not writes on disk , just saves * in Minify Cache * { cache : false , gzip : true , callback : func ( ) { } } / *   js- *      pCache_b *       * / if ( pOptions && pOptions . cache ) { exports . Cache [ lFileName ] = final_code ; Util . log ( 'file ' + minFileName + ' saved to cache...' ) ; } * / if ( pOptions ) { if ( pOptions . cache ) { exports . Cache [ minFileName ] = pFinalCode ; Util . log ( 'file ' + minFileName + ' saved to cache...' ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "response", "handler"], "add_tokens": "globalResponseInterceptor : function ( dataset_id , params , cb ) { return cb ( ) ; } , doResponseInterceptor : function ( dataset_id , params , cb ) { self . getDataset ( dataset_id , function ( err , dataset ) { if ( err ) return cb ( err ) ; if ( dataset . responseInterceptor ) { dataset . responseInterceptor ( dataset_id , params , cb ) ; } else { self . globalResponseInterceptor ( dataset_id , params , cb ) ; } } ) ; } , setGlobalResponseInterceptor : generateGlobalSetter ( 'globalResponseInterceptor' , self ) , doResponseInterceptor : self . doResponseInterceptor ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Remove", "use", "of", "webview", "tag", "and", "instead", "rely", "on", "browser", "window"], "add_tokens": "}", "del_tokens": "} , { label : 'Toggle Web Developer Tools' , accelerator : ( function ( ) { if ( process . platform == 'darwin' ) return 'Alt+Command+J' ; else return 'Ctrl+Shift+J' ; } ) ( ) , click : function ( item , focusedWindow ) { if ( focusedWindow ) { mainWindow . webContents . send ( 'toggle-dev-tools' , true ) ; } } } ,", "commit_type": "remove"}
{"commit_tokens": ["Use", "Handlebars", "to", "provide", "more", "flexible", "and", "robust", "templating", "."], "add_tokens": "template : '{{> fixes}}{{> features}}\\n' , partials : { features : '{{#each features}}{{> feature}}{{/each}}' , feature : '{{this}}' , fixes : '{{#each fixes}}{{> fix}}{{/each}}' , fix : '{{this}}' } , empty_partial : { options : { log : 'test/fixtures/log_fixes_only' , dest : 'tmp/changelog_empty' }", "del_tokens": "templates : { main : '{{fixes}}{{features}}\\n' , change : '{{change}}' , empty : 'none'", "commit_type": "use"}
{"commit_tokens": ["Removed", "some", "http", "steps", "and", "added", "some", "tests", "."], "add_tokens": "this . Given ( / ^I set (?:property|the) (.+) to (.+)$ / , function ( propertyString , valueString , done ) { this . Given ( / ^I check (?:property|the) (.+) equals (.+)$ / , function ( propertyString , valueString , done ) { this . Given ( / ^I check (?:property|the) (.+) has type (\\S+)$ / , function ( propertyString , expected , done ) { this . Given ( / ^I remove (?:property|the) (.+)$ / , function ( propertyString , done ) {", "del_tokens": "this . Given ( / ^I set property (.+) to (.+)$ / , function ( propertyString , valueString , done ) { this . Given ( / ^I check property (.+) equals (.+)$ / , function ( propertyString , valueString , done ) { this . Given ( / ^I check property (.+) has type (\\S+)$ / , function ( propertyString , expected , done ) { this . Given ( / ^I remove property (.+)$ / , function ( propertyString , done ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "inconsistent", "behaviour", "in", "reporting", "errors", "."], "add_tokens": "assert . equal ( MeadCo . ScriptX . Print . version , \"1.5.3.5\" , \"MeadCo.ScriptX.Print.version ok\" ) ;", "del_tokens": "assert . equal ( MeadCo . ScriptX . Print . version , \"1.5.3.4\" , \"MeadCo.ScriptX.Print.version ok\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "metadata", "parser", "on", "record", "metadata", "feature"], "add_tokens": "var data = fs . readFileSync ( __filename . replace ( / \\.js$ / i , '.json' ) , 'utf-8' ) ; var config = JSON . parse ( data , function ( key , value ) { if ( typeof value == 'string' ) { var template = _ . template ( value ) ; value = template ( { openbiz : this } ) ; } return value ; } ) ; metadata . _metadata = config . RecordMetadata ; if ( typeof defaults != 'undefined' && features . enableMetadata ) { if ( typeof defaults . visibility != 'undefined' ) { if ( typeof defaults . visibility . scope != 'undefined' ) { metadata . _metadata . visibility . scope . default = defaults . visibility . scope ; } }", "del_tokens": "metadata . _metadata = require ( __filename . replace ( / \\.js$ / i , '.json' ) ) . RecordMetadata ; if ( typeof defaults == 'undefined' ) defaults = { } ; if ( typeof defaults . visibility . scope != 'undefined' ) { metadata . _metadata . visibility . scope . default = defaults . visibility . scope ;", "commit_type": "add"}
{"commit_tokens": ["Added", "wait", "for", "nav", "-", "home", "in", "attempt", "to", "fix", "failure", "in", "TravisCI"], "add_tokens": "var navElem = ptor_waitForElementById ( \"nav-home\" ) ; expect ( navElem . getAttribute ( \"class\" ) ) . toBe ( \"active\" ) ;", "del_tokens": "expect ( $ ( '#nav-home' ) . getAttribute ( \"class\" ) ) . toBe ( \"active\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "input", "event", "type", "to", "supported", "events"], "add_tokens": "'contextmenu' , 'dblclick' , 'input' ] ;", "del_tokens": "'contextmenu' , 'dblclick' ] ;", "commit_type": "add"}
{"commit_tokens": ["Added", "failing", "class", "attr", "code"], "add_tokens": "'test code attrs class' : function ( assert ) { assert . equal ( '<p class=\"tj\"></p>' , render ( 'p(class: name)' , { locals : { name : 'tj' } } ) ) ; assert . equal ( '<p class=\"default\"></p>' , render ( 'p(class: name || \"default\")' , { locals : { name : null } } ) ) ; assert . equal ( '<p class=\"foo default\"></p>' , render ( 'p.foo(class: name || \"default\")' , { locals : { name : null } } ) ) ; assert . equal ( '<p class=\"default foo\"></p>' , render ( 'p(class: name || \"default\").foo' , { locals : { name : null } } ) ) ; } ,", "del_tokens": "// TODO: special case class", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "ignore", "option", "to", "ignore", "by", "code", "and", "type"], "add_tokens": "return messages . map ( processMessage ) . filter ( isMessageWanted ) ; function isMessageWanted ( message ) { if ( options . ignore . indexOf ( message . code . toLowerCase ( ) ) !== - 1 ) { return false ; } if ( options . ignore . indexOf ( message . type ) !== - 1 ) { return false ; } return true ; }", "del_tokens": "return messages . map ( processMessage ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "options", "to", "terser", "for", "speed", "and", "sourcemaps"], "add_tokens": "new TerserPlugin ( { cache : true , parallel : true , sourceMap : true , extractComments : true , } ) ,", "del_tokens": "new TerserPlugin ( ) ,", "commit_type": "add"}
{"commit_tokens": ["update", "all", "dependencies", "to", "latest"], "add_tokens": "import { google } from 'googleapis' ;", "del_tokens": "import google from 'googleapis' ;", "commit_type": "update"}
{"commit_tokens": ["fix", "comments", "in", "notification", "example"], "add_tokens": "// check to see if we can add directly // if we had added directly then schedule remove // everytime we remove an item, if queued, send action to display one // after we queue an item, if display is already clear // we add in a displayQueued to ensure things aren't stuck // if we have opening(s) and queued, display them // schedule removes for those displayed", "del_tokens": "// check to see if it is valid to start, > 0", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "contextification", "-", "interpolation", "error"], "add_tokens": "version : '0.1.4' , output = \"function \" + escapeVar + \"(t){return (''+t).replace(/</g,'&lt;')};\" + output ;", "del_tokens": "version : '0.1.3' , output = \"function \" + escapeVar + \"(t){\" + \"var r={'<':'&lt;','&':'&amp;','>':'&gt;'};\" + \"return (''+t).replace(/[<&>]/g,function(m){return r[m]})};\" + output ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "days", "until", "next", "for", "circus"], "add_tokens": "var daysUntilNext = ( 7 - ( ( Math . floor ( ( now / 1000 ) / ( 24 * 60 * 60 ) ) ) + 1 ) % ( 7 * LOCATIONS . length ) % 7 ) + daysToAdd ;", "del_tokens": "var daysUntilNext = ( 7 - ( ( Math . floor ( ( Date . now ( ) / 1000 ) / ( 24 * 60 * 60 ) ) ) + 3 ) % ( 7 * LOCATIONS . length ) % 7 ) + daysToAdd ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "bin", "file", "handling"], "add_tokens": "nutella . version = '0.5.1' ;", "del_tokens": "nutella . version = '0.5.0' ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "any", "controlled", "non", "-", "read", "-", "only", "input", "component", "+", "unit", "tests"], "add_tokens": "var isReadOnlyValue = function isReadOnlyValue ( control ) { return control . type == 'input' && ~ [ 'radio' , 'checkbox' ] . indexOf ( control . props . type ) ; } ; var dispatchChange = control . props . hasOwnProperty ( 'value' ) && isReadOnlyValue ( control ) ? function ( ) {", "del_tokens": "var dispatchChange = control . props . hasOwnProperty ( 'value' ) && controlType !== 'text' ? function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "base64", "to", "transfer", "nonce"], "add_tokens": "const base64js = require ( 'base64-js' ) ; return generateSecureRandom ( length ) . then ( ( nonce ) => { const nonceString = base64js . fromByteArray ( nonce ) ; // FIXME: Fix bytearray conversion const nonceString = originalNonce ;", "del_tokens": "import { Utf8ArrayToStr } from './src/utils' ; return generateSecureRandom ( length ) . then ( nonce => { const nonceString = nonce . toString ( ) ; const nonceString = Utf8ArrayToStr ( originalNonce ) ;", "commit_type": "use"}
{"commit_tokens": ["Change", "pg", ".", "js", "dependency", "to", "pg"], "add_tokens": "delete require . cache [ require . resolve ( 'pg' ) ] var pg = require ( 'pg' ) ;", "del_tokens": "delete require . cache [ require . resolve ( 'pg.js' ) ] var pg = require ( 'pg.js' ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "property", "to", "make", "an", "question", "optional"], "add_tokens": "if ( _ . has ( question , 'optional' ) && question . optional && answer !== null ) { question . validators = [ ] ; } } ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "madlib", "-", "settings", "to", "peer", "dependency"], "add_tokens": "return allXdmConfigs [ cleanHostName ] ;", "del_tokens": "return allXdmConfigs [ cleanName ] ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "aldo", "-", "server", ".", "js", "example"], "add_tokens": "const { createServer } = require ( '..' )", "del_tokens": "const { createServer } = require ( '../lib' )", "commit_type": "fix"}
{"commit_tokens": ["added", "possibility", "for", "inmemory", "implementation", "to", "search", "with", "multiple", "values"], "add_tokens": "var keys = _ . keys ( query ) ; var values = _ . values ( query ) ; var found = false ; for ( var i in keys ) { var key = keys [ i ] ; var deepFound = deepFind ( vm , key ) ; if ( _ . isArray ( deepFound ) && deepFound . length > 0 ) { found = true ; } else if ( deepFound === values [ i ] ) { found = true ; } else { found = false ; break ; } return found ;", "del_tokens": "var deepFound = deepFind ( vm , _ . keys ( query ) [ 0 ] ) ; if ( _ . isArray ( deepFound ) && deepFound . length > 0 ) { return true ; } else if ( deepFound === _ . values ( query ) [ 0 ] ) { return true ; return false ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "group", "node", "to", "avoid", "extra", "newline", "and", "indent"], "add_tokens": "for ( let i = 0 ; i < node . repeat . count ; i ++ ) { clone . repeat . value = i + 1 ; if ( clone . isGroup ) { while ( clone . children . length > 0 ) { clone . firstChild . repeat = clone . repeat ; node . parent . insertBefore ( clone . firstChild , node ) ; } } else { node . parent . insertBefore ( clone , node ) ; } node . parent . removeChild ( node ) ;", "del_tokens": "for ( let i = 1 ; i < node . repeat . count ; i ++ ) { clone . repeat . value = i ; node . parent . insertBefore ( clone , node ) ; node . repeat . value = node . repeat . count ;", "commit_type": "remove"}
{"commit_tokens": ["adding", "more", "tests", "and", "started", "working", "on", "utils", ".", "getFilePaths"], "add_tokens": "{ expand : true , cwd : 'tasks' , src : [ '**/*' ] , dest : 'test/' }", "del_tokens": "{ expand : true , cwd : 'tasks' , src : [ '**/*' ] , dest : 'tasks/' }", "commit_type": "add"}
{"commit_tokens": ["Add", "initial", "implementation", "of", "devices", "and", "connectedDevices", "functions", "."], "add_tokens": "* this library . All operations which were in progress completes with / ** * Returns a list of known peripherals by their identifiers . * @ param { Array < DeviceId > } deviceIdentifiers List of device identifiers . * / async devices ( deviceIdentifiers : Array < DeviceId > ) : Promise < Array < Device >> { const nativeDevices = await this . _callPromise ( BleModule . devices ( deviceIdentifiers ) ) return nativeDevices . map ( ( nativeDevice : NativeDevice ) => { return new Device ( nativeDevice , this ) } ) } / ** * Returns a list of the peripherals ( containing any of the specified services ) currently connected to the system . * @ param { Array < UUID > } serviceUUIDs List of service UUIDs . Device must contain as list one of them to be listed . * / async connectedDevices ( serviceUUIDs : Array < UUID > ) : Promise < Array < Device >> { const nativeDevices = await this . _callPromise ( BleModule . connectedDevices ( serviceUUIDs ) ) return nativeDevices . map ( ( nativeDevice : NativeDevice ) => { return new Device ( nativeDevice , this ) } ) } // Mark: Connection management ---------------------------------------------------------------------------------------", "del_tokens": "* this library . All operations which were in progress completes with", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "way", "handlers", "were", "stored", ";", "they", "are", "now", "put", "into", "an", "object", "with", "a", "random", "ID", "generated", "which", "should", "be", "faster", "when", "dealing", "with", "large", "lists", "and", "deleting", "(", "sorting", "was", "not", "necessary", ")", ".", "Added", "an", "additional", "exceptional", "handler", "for", "invalid", "messages", "."], "add_tokens": "} , ThrowInvalidMessage : function ( ) { throw \"The message is not valid\" ; } ( ) ) ) ;", "del_tokens": "} ( ) ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "cases", "when", "an", "erroneous", "path", "is", "returned"], "add_tokens": "it ( 'Issue #4.1' , function ( ) { it ( 'Issue #4.2' , function ( ) { var graph = new UndirectedGraph ( ) ; graph . addNode ( 0 ) ; graph . addNode ( 1 ) ; graph . addNode ( 2 ) ; graph . addEdge ( 0 , 1 ) ; var path = library . bidirectional ( graph , 2 , 0 ) ; assert . strictEqual ( path , null ) ; path = library . bidirectional ( graph , 0 , 2 ) ; assert . strictEqual ( path , null ) ; } ) ;", "del_tokens": "it ( 'Issue #4.' , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "allowSleep", "property", "so", "that", "sleep", "can", "be", "disabled"], "add_tokens": "assert . isTrue ( this . scene . systems . physics . world . allowSleep ) allowSleep : false , assert . isFalse ( this . el . body . allowSleep )", "del_tokens": "assert . isNotOk ( this . el . body . allowSleep , 'no extranous setting of allowSleep' )", "commit_type": "add"}
{"commit_tokens": ["Added", "stub", "for", "exception", "testing"], "add_tokens": "const PluginError = require ( 'gulp-util' ) . PluginError ; const PLUGIN_NAME = 'gulp-hologram' ; throw new PluginError ( 'gulp-holograph' , 'No file contents.' ) ;", "del_tokens": "return cb ( null , file ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "wrapper", "to", "T3", "for", "CommonJS"], "add_tokens": "SRC_FILES = [ 'lib/wrap-start.partial' , 'lib/box.js' , 'lib/event-target.js' , 'lib/context.js' , 'lib/application.js' , 'lib/wrap-end.partial' ] , TESTING_FILES = [ 'lib/wrap-start.partial' , 'lib/box.js' , 'lib/event-target.js' , 'lib/application-stub.js' , 'lib/test-service-provider.js' , 'lib/wrap-end.partial' ] ,", "del_tokens": "SRC_FILES = [ 'lib/box.js' , 'lib/event-target.js' , 'lib/context.js' , 'lib/application.js' ] , TESTING_FILES = [ 'lib/box.js' , 'lib/event-target.js' , 'lib/application-stub.js' , 'lib/test-service-provider.js' ] ,", "commit_type": "add"}
{"commit_tokens": ["Add", "sandbox", "restoration", "to", "tests"], "add_tokens": "beforeEach ( function ( done ) { afterEach ( function ( done ) { this . sandbox . restore ( ) ; done ( ) ; } ) ;", "del_tokens": "before ( function ( done ) {", "commit_type": "add"}
{"commit_tokens": ["updating", "configuration", "to", "directly", "accept", "and", "process", "options"], "add_tokens": ", underscore = require ( 'underscore' ) function CommonConfig ( options ) { underscore . extend ( this , CommonConfig . _DEFAULT ) applyOptions . call ( this , options ) } CommonConfig . _defaultMiddleware = defaultMiddleware CommonConfig . _DEFAULT = { middleware : defaultMiddleware , folder : process . cwd ( ) , cacheControl : 'no-cache' } function applyOptions ( options ) { if ( ! options ) return if ( options . port ) this . port = options . port if ( options . base ) this . folder = options . base if ( options . cache ) this . cacheControl = options . cache if ( options . middleware ) this . middleware = options . middleware this . options = options }", "del_tokens": "function CommonConfig ( ) { } CommonConfig . defaultMiddleware = defaultMiddleware CommonConfig . DEFAULT = { middleware : defaultMiddleware }", "commit_type": "update"}
{"commit_tokens": ["Adding", "fix", "for", "initialize", "method", "on", "the", "prototype"], "add_tokens": "onRowLinkClick : function ( event ) {", "del_tokens": "onRowLinkClick : function onRowLinkClick ( event ) { * @ param { Object } event Mouse event for click on the table .", "commit_type": "add"}
{"commit_tokens": ["Add", "separate", "index", "files", "for", "module", "definitions", "."], "add_tokens": "var module = angular . module ( 'coa.auth' ) ;", "del_tokens": "var module = angular . module ( 'coa.auth' , [ 'coa.data' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "back", "path", ".", "resolve"], "add_tokens": "var baseConfig = JSON . parse ( fs . readFileSync ( path . resolve ( _ . isString ( params . config ) ? params . config : '.jsbeautifyrc' ) ) ) ;", "del_tokens": "var baseConfig = JSON . parse ( fs . readFileSync ( path . resolve ( params . config || '.jsbeautifyrc' ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "wrong", "Content", "-", "Length", "in", "POST", "requests"], "add_tokens": "'Content-Length' : Buffer . byteLength ( data , 'utf8' )", "del_tokens": "'Content-Length' : data . length", "commit_type": "fix"}
{"commit_tokens": ["Added", "slug", "/", "id", "API", "for", "GET", "/", "posts", "/", "{", "id", "slug", "}"], "add_tokens": "exports . findById = findById ; function findByAuto ( param ) { var fn , asInt = parseInt ( param , 10 ) ; fn = isNaN ( asInt ) ? findBySlug : findById ; fn . apply ( null , arguments ) ; } exports . findByAuto = findByAuto ; findByAuto ( req . params . post , function ( post ) {", "del_tokens": "exports . findBySlug = findBySlug ; findBySlug ( req . params . post , function ( post ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "exposing", "core", "as", "the", "default", "app"], "add_tokens": "exports . PROJECT_ROOT = __dirname ; module . exports = exports . core ;", "del_tokens": "exports = exports . core ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "depency", "on", "Bluebird", "."], "add_tokens": "var AnyPromise = require ( 'any-promise' ) return new AnyPromise ( function ( resolve ) { resolve ( fn ( process . argv . slice ( 2 ) ) ) } ) . then ( onSuccess , onError )", "del_tokens": "var Bluebird = require ( 'bluebird' ) // Extract real error from Bluebird's wrapper. if ( value instanceof Bluebird . OperationalError ) { value = value . cause } return Bluebird . try ( fn , [ process . argv . slice ( 2 ) ] ) . then ( onSuccess , onError )", "commit_type": "remove"}
{"commit_tokens": ["make", "setBuffersAndAttribute", "accept", "a", "VertexArrayInfo"], "add_tokens": "* @ param { ( module : twgl . ProgramInfo | Object . < string , function > ) } setters A ` ProgramInfo ` as returned from { @ link module : twgl . createProgrmaInfo } or Attribute setters as returned from { @ link module : twgl . createAttributeSetters } * @ param { ( module : twgl . BufferInfo | module : twgl . vertexArrayInfo ) } buffers a ` ` as returned from { @ link module : twgl . createBufferInfoFromArrays } . * or a ` ` as returned from { @ link module : twgl . createVertexArrayInfo } if ( buffers . vertexArrayObject ) { gl . bindVertexArray ( buffers . vertexArrayObject ) ; } else { setAttributes ( programInfo . attribSetters || programInfo , buffers . attribs ) ; if ( buffers . indices ) { gl . bindBuffer ( gl . ELEMENT_ARRAY_BUFFER , buffers . indices ) ; }", "del_tokens": "* @ param { ( module : twgl . ProgramInfo | Object . < string , function > ) } setters A ` ProgramInfo ` ` createProgrmaInfo ` ` createAttributeSetters ` * @ param { module : twgl . BufferInfo } buffers a BufferInfo as returned from ` ` . setAttributes ( programInfo . attribSetters || programInfo , buffers . attribs ) ; if ( buffers . indices ) { gl . bindBuffer ( gl . ELEMENT_ARRAY_BUFFER , buffers . indices ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "semicolons", "and", "fixed", "a", "throw"], "add_tokens": "throw new Error ( 'The specified column must be a positive integer.' ) ; } else if ( n >= M [ 0 ] . length ) { throw new Error ( 'The specified column must be between 0 and the number of columns - 1.' ) ; throw new Error ( 'The reordered matrix must have the same number of rows as the original matrix.' ) ; throw new Error ( 'The desired order of the rows must be positive integers.' ) ; throw new Error ( 'The desired order of the rows must start at 0 and end at the number of rows - 1.' ) ; result . push ( M [ L [ i ] ] ) ; throw new Error ( 'The desired order of the rows must be positive integers.' ) ; throw new Error ( 'The desired order of the rows must start at 0 and end at the number of rows - 1.' ) ; return matrix . reorderRows ( M , L ) ; return matrix . reorderCols ( M , L ) ; throw new Error ( 'Matrix size must be at least 2x2.' ) ; row ++ ; col -- ;", "del_tokens": "throw new Error ( 'The specified column must be a positive integer.' ) } else if ( n >= M [ 0 ] ) { throw new Error ( 'The specified column must be between 0 and the number of columns - 1.' ) throw new Error ( 'The reordered matrix must have the same number of rows as the original matrix.' ) throw new Error ( 'The desired order of the rows must be positive integers.' ) throw new Error ( 'The desired order of the rows must start at 0 and end at the number of rows - 1.' ) result . push ( M [ L [ i ] ] ) throw new Error ( 'The desired order of the rows must be positive integers.' ) throw new Error ( 'The desired order of the rows must start at 0 and end at the number of rows - 1.' ) return matrix . reorderRows ( M , L ) return matrix . reorderCols ( M , L ) throw new Error ( 'Matrix size must be at least 2x2.' ) row ++ ; col -- ;", "commit_type": "add"}
{"commit_tokens": ["improve", "tests", "to", "reduce", "random", "failure", "and", "use", "reconnected", "event"], "add_tokens": "var gateway = null ; afterEach ( function ( done ) { if ( gateway ) { gateway . disconnect ( done ) ; gateway = null ; } else { done ( ) ; } } ) ; it ( 'should connect, send state, and receive a command' , function ( done ) { this . timeout ( 8000 ) ; gateway = new Gateway ( { setImmediate ( function ( ) { gateway . sendState ( { temperature : 100 } ) ; } ) ; done ( ) ; gateway = new Gateway ( { setImmediate ( function ( ) { gateway . mqtt . client . publish ( '/losant/not-this-device/state' ) ; } ) ; gateway . on ( 'reconnected' , function ( ) { setImmediate ( function ( ) { } ) ; done ( ) ;", "del_tokens": "it ( 'should connect, send state, and receive a command' , function ( done ) { var gateway = new Gateway ( { gateway . sendState ( { temperature : 100 } ) ; gateway . disconnect ( done ) ; var gateway = new Gateway ( { gateway . mqtt . client . publish ( '/losant/not-this-device/state' ) ; gateway . on ( 'reconnect' , function ( ) { setTimeout ( function ( ) { } , 500 ) ; gateway . disconnect ( done ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "package", ".", "json", "travis", "and", "eslint", "test"], "add_tokens": "// Based on http://krazydad.com/tutorials/makecolors.php var nybHexString = '0123456789ABCDEF' ; if ( typeof ( param ) == 'number' ) { var ret = 'M' + this . _labelStart . x + ',' + this . _labelStart . y ; ret += 'L ' + this . _labelMid . x + ',' + this . _labelMid . y ; ret += 'L ' + this . _labelEnd . x + ', ' + this . _labelEnd . y ; } ) ;", "del_tokens": "//Based on http://krazydad.com/tutorials/makecolors.php var nybHexString = \"0123456789ABCDEF\" ; if ( typeof ( param ) == \"number\" ) { var ret = \"M\" + this . _labelStart . x + \",\" + this . _labelStart . y ; ret += \"L \" + this . _labelMid . x + \",\" + this . _labelMid . y ; ret += \"L \" + this . _labelEnd . x + \", \" + this . _labelEnd . y ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "optional", "use", "of", "destination"], "add_tokens": "var destination = files [ file ] . destination || '.' destination : files [ filename ] . destination || path . join ( path . dirname ( filename ) , '.' )", "del_tokens": "var destination = files [ file ] . destination || false destination : files [ filename ] . destination", "commit_type": "add"}
{"commit_tokens": ["removed", "faulty", "test", "case", "which", "has", "side", "effects", "on", "servers", "with", "different", "timezones"], "add_tokens": "assert . equal ( results [ 1 ] . updatedDate . getTime ( ) , new Date ( '2014-10-20T05:44:15Z' ) . getTime ( ) ) ;", "del_tokens": "rssDir + 'rss.2.xml' , it ( 'should parse updatedDate with invalid timezone to valid date with correct timezone' , function ( ) { assert . equal ( results [ 1 ] . updatedDate . getTime ( ) , new Date ( '2015-06-23T05:38:22.000Z' ) . getTime ( ) ) ; } ) ; assert . equal ( results [ 2 ] . updatedDate . getTime ( ) , new Date ( '2014-10-20T05:44:15Z' ) . getTime ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "faster", "method", "getting", "valeu", "based", "on", "path"], "add_tokens": "* @ param path * @ param def function getByPath ( obj , path ) { for ( var i = 0 , path = path . split ( '.' ) , len = path . length ; i < len ; i ++ ) { if ( ! obj || typeof obj !== 'object' ) return false ; obj = obj [ path [ i ] ] ; if ( typeof obj === 'undefined' ) return false ;", "del_tokens": "* @ param string function getByPath ( obj , string ) { var segs = string . split ( \".\" ) ; while ( segs . length ) { var n = segs . shift ( ) ; if ( n in obj ) { obj = obj [ n ] ; } else { return false ; }", "commit_type": "use"}
{"commit_tokens": ["Add", "patched", "bunyan", "version", "-", "Use", "bunyan", "parser", "as", "module"], "add_tokens": "const bunyan = require ( \"./bunyan\" ) //we have patched that one const Transform = require ( \"stream\" ) . Transform const through = new Transform ( { transform ( data , enc , cb ) { this . push ( data ) cb ( ) } const fakeProcess = { //the whole object is a lie env : process . env , versions : process . versions , platform : process . platform , stdin : through , stdout : process . stderr , stderr : process . stderr , on : ( ) => { } , //exit: code => exit(code) } bunyan ( fakeProcess ) process . stdout = through", "del_tokens": "const cp = require ( \"child_process\" ) const bunyan = cp . spawn ( process . argv [ 0 ] , [ __dirname + \"/node_modules/.bin/bunyan\" ] , { stdio : [ \"pipe\" , process . stderr , process . stderr ] process . stdout = bunyan . stdin", "commit_type": "add"}
{"commit_tokens": ["Move", "CacheMissError", "into", "separate", "file"], "add_tokens": "import CacheMissError from './cache-miss-error' ;", "del_tokens": "function CacheMissError ( ) { var err = Error . apply ( this , arguments ) ; err . name = this . name = 'CacheMissError' ; this . message = err . message ; this . stack = err . stack ; } CacheMissError . prototype = Object . create ( Error . prototype , { constructor : { value : CacheMissError , writable : true , configurable : true , } , } ) ;", "commit_type": "move"}
{"commit_tokens": ["fix", "giving", "car", "to", "top", "player"], "add_tokens": "// Given an object and point relating to that object, // returns a set of coords representing the same point with // respect to the parent. // TODO: refactor out var pointDistance ; if ( oppositeRad !== 0 ) pointDistance = distFromFocal * Math . sin ( focalAngleRad ) / Math . sin ( oppositeRad ) ; else pointDistance = distFromFocal * 2 ; coords . x - dispObj . regX + dispObj . x ; coords . y - dispObj . regY + dispObj . y ; stage . addChildAt ( user . playerBox , 0 ) ;", "del_tokens": "var pointDistance = distFromFocal * Math . sin ( focalAngleRad ) / Math . sin ( oppositeRad ) ; coords . x - dispObj . regX ; coords . y - dispObj . regY ; carCoords . x += user . playerBox . x ; carCoords . y += user . playerBox . y ; stage . addChild ( user . playerBox ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "stupid", "mistake", "with", "hard", "-", "coded", "access", "token", "."], "add_tokens": "\"Authorization\" : \"Basic \" + self . authToken , \"Content-Type\" : \"application/x-www-form-urlencoded\" , self . Dbg ( \"Got Six Flags access token \" + result . access_token ) ; token : result . access_token , 'Connection' : 'Keep-Alive' ,", "del_tokens": "\"Authorization\" : \"Basic \" + self . authToken token : \"9a5c8a8f54cf073f00ab7e01e06e46f5\" , //result.access_token, \"Content-Type\" : \"application/x-www-form-urlencoded\" ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "HTMLEntity", "escaping", "to", "Lists", "and", "LSets", "."], "add_tokens": "var result = String . fromCharCode ( decodeHTMLEntities . entityTable [ c . substring ( 1 , c . indexOf ( \"\\;\" ) ) ] ) ; return result ;", "del_tokens": "console . log ( \"before: \" , string ) ; console . log ( \"before: \" , string ) ; console . log ( c ) ; //convert to number var charCode = decodeHTMLEntities . entityTable [ c . substring ( 1 , c . indexOf ( \"\\;\" ) ) ] ; console . log ( charCode ) ; var result = String . fromCharCode ( charCode ) ; console . log ( result ) ; return result ; // (decodeHTMLEntities.entityTable[c.charCodeAt(0)] || '#'+c.charCodeAt(0)) + ';';", "commit_type": "add"}
{"commit_tokens": ["removed", "comments", "and", "patched", "parameter", "name", "and", "potential", "undefined", "error"], "add_tokens": "function set_extended_attribute ( context , path_or_fd , name , value , flag , callback ) { if ( typeof path_or_fd == 'string' ) { find_node ( context , path_or_fd , set_xattr ) ; else if ( typeof path_or_fd == 'object' && typeof path_or_fd . id == 'string' ) { context . get ( path_or_fd . id , set_xattr ) ;", "del_tokens": "function set_extended_attribute ( context , path , name , value , flag , callback ) { if ( typeof path == 'string' ) { find_node ( context , path , set_xattr ) ; else if ( typeof path . id == 'string' ) { context . get ( path . id , set_xattr ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "shim", "for", "Date", ".", "now", "()"], "add_tokens": "// Shims for browsers not supporting our needs, mainly IE / * * Make Date . now safe for IE < 9 * https : //developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects/Date/now * / if ( ! Date . now ) { Date . now = function ( ) { return + ( new Date ( ) ) ; } ; }", "del_tokens": "// Make sure we have JSON in general", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "catalan", "and", "fixing", "French", "and", "Spanish"], "add_tokens": "'ca_ES' : { prefixAgo : 'fa' , prefixFromNow : 'd\\'aqu', suffixAgo : null , suffixFromNow : null , seconds : ' \\' minute : ' \\' minutes : '%d minuts' , hour : ' \\' hours : 'prop de %d hores' , day : 'un dia' , days : '%d dies' , month : 'prop d\\'un mes' , months : '%d mesos' , year : 'prop d\\'un any' , years : '%d anys' , numbers : [ ] } , prefixFromNow : 'en' , suffixFromNow : null , prefixFromNow : 'en' , suffixFromNow : null , day : 'un da', days : '%d das', year : 'un ao', years : '%d aos', ] ) ;", "del_tokens": "prefixFromNow : null , suffixFromNow : 'from now' , prefixFromNow : null , suffixFromNow : 'apartir de ahora' , day : 'un dia' , days : '%d dias' , year : 'un a\\xf1o' , years : '%d a\\xf1os' , ] ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "em", "and", "strong", "elements"], "add_tokens": "it ( \"should work with em tags\" , function ( ) { md . render ( \"_foo {bar}_\" ) . should . containEql ( \"<em class=\\\"bar\\\">foo</em>\" ) ; } ) ; it ( \"should work with strong tags\" , function ( ) { md . render ( \"__foo {bar}__\" ) . should . containEql ( \"<strong class=\\\"bar\\\">foo</strong>\" ) ; } ) ;", "del_tokens": "it ( \"should work with em and strong tags\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "frame", "info", "to", "Extra", "payload"], "add_tokens": "extra : { frame_info : { } } isOpbeatInstalled = false , frameInfoCounter = 1 ; // Construct a frame message to be added to the Extra tab because // Opbeat.com interface currently doesn't show column number in stacktrace var frameMessage = 'File: ' + ( frame . url || '?' ) + ', Line: ' + ( frame . line || '?' ) + ', Column: ' + ( frame . column || '?' ) + ', Func: ' + ( frame . func || '?' ) ; // Add frame message to Extra payload globalOptions . extra . frame_info [ 'frame_' + frameInfoCounter ++ ] = frameMessage ; // Clear extra frame info after each send globalOptions . extra . frame_info = { } ; frameInfoCounter = 1 ;", "del_tokens": "extra : { } isOpbeatInstalled = false ;", "commit_type": "add"}
{"commit_tokens": ["fix", "indention", "and", "bad", "brackets"], "add_tokens": "' note: {\\n' + ' label: \"Longer text to show text wrapping\",\\n' + ' title: \"Annotations :)\"\\n' + ' },\\n' + ' //can use x, y directly instead of data\\n' + ' data: { date: \"18-Sep-09\", close: 185.02 },\\n' + ' dy: 137,\\n' + ` ${ curveText !== '' || subjectText !== '' ? ',' : '' } \\n ` + '}]\\n' +", "del_tokens": "' note: { label: \"Longer text to show text wrapping\",\\n' + ' title: \"Annotations :)\" },\\n' + ' //can use x, y directly instead of data\\n' + ' data: {date: \"18-Sep-09\", close: 185.02},\\n' + ' dy: 137,\\n' + ` ${ curveText !== '' || subjectText !== '' ? ',' : '' } \\n ` + ' }]\\n' +", "commit_type": "fix"}
{"commit_tokens": ["adding", "cache", "dir", "to", "doc", ":", "pub", "task"], "add_tokens": ". pipe ( publish ( { cacheDir : '.tmp' } ) ) ;", "del_tokens": ". pipe ( publish ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "comparing", "media", "types", "with", "quoted", "values"], "add_tokens": "var name = p [ 0 ] ; var value = p [ 1 ] ; set [ name ] = value && value [ 0 ] === '\"' && value [ value . length - 1 ] === '\"' ? value . substr ( 1 , value . length - 2 ) : value ; return set ;", "del_tokens": "set [ p [ 0 ] ] = p [ 1 ] ; return set", "commit_type": "fix"}
{"commit_tokens": ["adds", "adapter", ".", "action", "tests", "needs", "refactor"], "add_tokens": "! ( actionConstraints . type === 'select' || actionConstraints . type === 'button' || actionConstraints . type === 'dialog_submission' ) ) { return new TypeError ( 'Type must be \\'select\\', \\'button\\', or \\'dialog_submission\\'' ) ;", "del_tokens": "! ( actionConstraints . type === 'select' || actionConstraints . type === 'button' ) ) { return new TypeError ( 'Type must be \\'select\\' or \\'button\\'' ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "modeljs", "as", "a", "Node", "library", "."], "add_tokens": "( function ( globalNS , undefined ) { //globalNS === window in the browser or GLOBAL in nodejs if ( globalNS . console && globalNS . console [ level ] ) { globalNS . console [ level ] ( message ) ; var oldModel = globalNS . Model ; globalNS . Model = oldModel ; if ( typeof exports !== 'undefined' ) { if ( typeof module !== 'undefined' && module . exports ) { exports = module . exports = Model ; } exports . Model = Model ; } else { /** @global */ window [ \"Model\" ] = Model ; } } ( this ) ) ; //this === window in the browser and GLOBAL in node", "del_tokens": "( function ( window , undefined ) { if ( window . console && window . console [ level ] ) { window . console [ level ] ( message ) ; var oldModel = window . Model ; window . Model = oldModel ; /** @global */ window . Model = Model ; } ( window ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bugs", "and", "initial", "published", "version"], "add_tokens": "//TODO: get rid of react warning that styles are being mutated const STYLES = { width : '10px' , height : '70px' , backgroundColor : 'rgba(0, 97, 128, 0.682353)' , position : 'relative' , left : 10 , zIndex : 1 , } this . mouseMovement = this . currentlyDragging const updatedStyles = Object . assign ( { } , STYLES , { } ) ; < div id = \"sliderBar\" style = { updatedStyles } > < / div >", "del_tokens": "this . mouseMovement = this . currentlyDragging const styles = { } < div id = \"sliderBar\" style = { styles } > < / div >", "commit_type": "fix"}
{"commit_tokens": ["added", "bibtexmisc", "formatting", "style", "to", "the", "parser"], "add_tokens": "else if ( format == 'bibtexmisc' || format == 'bm' ) { return require ( '../core/model/formats/bibtexmisc' ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "Uncaught", "Error", "exception", "bug", "(", "node", ":", "every", "stream", "gets", "the", "socket", "error", "propagated", ")"], "add_tokens": "socket . on ( 'error' , errorEmit ) conn . on ( 'error' , errorEmit ) self . listener . on ( 'error' , errorEmit ) socket . on ( 'error' , errorEmit ) conn . on ( 'error' , errorEmit ) stream . on ( 'error' , errorEmit ) function registerHandles ( stream ) { log . info ( 'Registering protocol handlers on new stream' ) stream . on ( 'error' , errorEmit ) msH . handle ( stream ) function errorEmit ( err ) { self . emit ( 'error' , err ) }", "del_tokens": "socket . on ( 'error' , function ( err ) { // self.emit('error', err) } ) socket . on ( 'close' , function ( ) { } ) conn . on ( 'error' , function ( err ) { // self.emit('error', err) } ) conn . on ( 'close' , function ( ) { } ) self . listener . on ( 'error' , function ( err ) { self . emit ( 'error' , err ) } ) socket . on ( 'error' , function ( err ) { self . emit ( 'error' , err ) } ) conn . on ( 'error' , function ( err ) { self . emit ( 'error' , err ) } ) function registerHandles ( spdyStream ) { log . info ( 'Preparing stream to handle the registered protocols' ) msH . handle ( spdyStream )", "commit_type": "fix"}
{"commit_tokens": ["fix", "condition", "on", "template", "call"], "add_tokens": "value : 'static' , value : 'dynamic' , value : 'forms' , value : 'workflow' , this . pageType = prompt . pageType ;", "del_tokens": "const BaseGenerator = require ( 'generator-jhipster/generators/generator-base' ) ; value : 'Static' , value : 'Dynamic' , value : 'Forms' , value : 'Workflow' ,", "commit_type": "fix"}
{"commit_tokens": ["make", "GameFlow", "handle", "both", "ctx", "and", "G"], "add_tokens": "* Helper to create a reducer that manages ctx ( and G ) . reducer : ( state , action ) => { const args = [ state ] . concat ( action . args ) ; export function GameFlow ( config ) { const endTurn = ( { G , ctx } ) => { // Return new state. return { G , ctx : { ... ctx , currentPlayer , turn , winner } } ; const endPhase = ( { G , ctx } ) => { return { G , ctx : { ... ctx , phase , _phaseNum } } ; events = { endTurn , endPhase } ;", "del_tokens": "* Helper to create a reducer that manages ctx . reducer : ( state , action , G ) => { const args = [ state , G ] . concat ( action . args ) ; export const GameFlow = config => { const endTurn = ( ctx , G ) => { // Return new ctx. return { ... ctx , currentPlayer , turn , winner } ; const endPhase = ctx => { return { ... ctx , phase , _phaseNum } ; events = { endTurn , endPhase } ;", "commit_type": "make"}
{"commit_tokens": ["fix", "issue", "on", "log", "display"], "add_tokens": "var desc = document . getElementById ( \"description\" ) ; desc . innerHTML = h ; if ( ! d . errors ) { json . set ( d , \"errors\" , [ ] ) ; } layout . errorList ( d . errors ) . render ( \"logs\" ) ; this . data . errors . push ( msg ) ;", "del_tokens": "var d = document . getElementById ( \"description\" ) ; d . innerHTML = h ; var d = this . data ; if ( ! d . errors ) { json . set ( d , \"errors\" , [ ] ) ; } d . errors . push ( msg ) ; layout . errorList ( d . errors ) . render ( \"logs\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "Sass", "options", "unique", "."], "add_tokens": "return this . merge ( { } , this . sassOptions || { } , { return this . merge ( { } , this . sassOptions || { } , {", "del_tokens": "return this . merge ( this . sassOptions || { } , { return this . merge ( this . sassOptions || { } , {", "commit_type": "make"}
{"commit_tokens": ["add", "yarn", "and", "nsp", "validators"], "add_tokens": "} , yarn : { versionCheck : 'yarn -V' , versionValidate : ( result , version ) => version === result . trim ( ) } , nsp : { versionCheck : 'nsp -v' , versionValidate : ( result , version ) => version === result . trim ( ) } ,", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Add", "option", ".", "value", "as", "last", "resort", "fallback"], "add_tokens": "optionText = el . innerHTML || el . innerContent || el . innerText || el . childNodes [ 0 ] . nodeValue || el . value ; optionText = el . innerHTML || el . innerContent || el . innerText || el . childNodes [ 0 ] . nodeValue || el . value ;", "del_tokens": "optionText = el . innerHTML || el . innerContent || el . innerText || el . childNodes [ 0 ] . nodeValue ; optionText = el . innerHTML || el . innerContent || el . innerText || el . childNodes [ 0 ] . nodeValue ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "attach", "&", "flow", "encoding", "tests", "and", "bugs", "found", "during", "testing", "."], "add_tokens": "this . encode ( val . getValue ( ) || [ ] , buf ) ;", "del_tokens": "this . encode ( val . value || [ ] , buf ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "add", "low", "power", "sleep", "mode", "option", "."], "add_tokens": "\"c/config/hardware.xml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\" ?>\\n<hardware>\\n <sleeposc enable=\\\"true\\\" ppm=\\\"30\\\" />\\n <txpower power=\\\"15\\\" bias=\\\"5\\\" />\\n <otaboot source=\\\"internal\\\" />\\n <sleep enable=\\\"true\\\" max_mode=\\\"1\\\" />\\n</hardware>\\n\" ,", "del_tokens": "\"c/config/hardware.xml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\" ?>\\n<hardware>\\n <sleeposc enable=\\\"true\\\" ppm=\\\"30\\\" />\\n <txpower power=\\\"15\\\" bias=\\\"5\\\" />\\n <otaboot source=\\\"internal\\\" />\\n</hardware>\\n\" ,", "commit_type": "update"}
{"commit_tokens": ["change", "getAllImport", "output", "to", "loc", "and", "range"], "add_tokens": "range : { start : res . index , end : res . index + res [ 0 ] . length , } , loc : mapLocToRange ( lineStart , res . index , res . index + res [ 0 ] . length ) ,", "del_tokens": "start : res . index , end : res . index + res [ 0 ] . length , range : mapLocToRange ( lineStart , res . index , res . index + res [ 0 ] . length ) ,", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "statsd", "mapper", "."], "add_tokens": "var datum = data . events [ metric ] ; return mapMetric ( prefix , metric , datum . end - datum . start ) ; var datum = data . durations [ metric ] ; if ( check . number ( datum ) ) { return mapMetric ( prefix , metric , datum ) ;", "del_tokens": "var eventPrefix , datum = data . events [ metric ] ; eventPrefix = prefix + metric + '.' ; return mapMetric ( eventPrefix , datum . end - datum . start , 'ms' ) ; if ( check . number ( data [ metric ] ) ) { return mapMetric ( prefix , metric , data , 'ms' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "greaterThan", "and", "lessThan", "functions", "."], "add_tokens": "module . exports = require ( './lib/validation.helper' ) ;", "del_tokens": "module . exports = require ( \"./lib/validation.helper\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "removing", "whitespace", "inside", "media", "query", "definition", "."], "add_tokens": "replace ( / ([\\(\\{\\}:;=,\\n]) / g , '$1' ) ; replace ( / ([!\\)\\{\\};=,\\n]) / g , '$1' ) ;", "del_tokens": "replace ( / ([\\{\\}:;=,\\n]) / g , '$1' ) ; replace ( / ([!\\{\\};=,\\n]) / g , '$1' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "logs", "and", "reactivate", "command"], "add_tokens": "process . stderr . write ( eol + obj . err . code + eol + obj . err . message + eol + obj . reason . stack + eol ) ; process . stderr . write ( eol + obj . reason . code + eol + obj . reason . stack + eol ) ;", "del_tokens": "process . stderr . write ( eol + obj . err . code + eol + obj . err . message + eol ) ; process . stderr . write ( eol + obj . reason . code + eol + JSON . stringify ( obj . reason , null , 2 ) + eol ) ;", "commit_type": "improve"}
{"commit_tokens": ["fixed", "undefined", "in", "object", "mapproperties"], "add_tokens": "let resultObj = Object . create ( Object . prototype ) ;", "del_tokens": "let resultObj = Object . create ( null ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "bin", "/", "breakneck", "to", "generate", "docs", "from", "Mustache", "template"], "add_tokens": "var colors = _ . map ( [ 'primary' , 'info' , 'success' , 'warning' , 'danger' , 'default' ] , function ( brand ) { return $ ( '.' + brand , palette ) . css ( 'background-color' ) ; } ) ; _ ( spec . results ( ) . getItems ( ) ) var section = $ ( this ) . closest ( 'section' ) ; var methodId = section . attr ( 'id' ) ; _ . each ( benchmarks [ methodId ] , function ( benchmark , name ) {", "del_tokens": "//= require lib/jasmine //= require lib/benchmark //= require lib/jquery //= require lib/lazy //= require lib/highcharts //= require lib/hightables var colors = Lazy ( [ 'primary' , 'info' , 'success' , 'warning' , 'danger' , 'default' ] ) . map ( function ( brand ) { return $ ( '.' + brand , palette ) . css ( 'background-color' ) ; } ) . toArray ( ) ; Lazy ( spec . results ( ) . getItems ( ) ) var section = $ ( this ) . closest ( 'section' ) ; var method = $ ( 'h1' , section ) . text ( ) ; Lazy ( benchmarks [ method ] ) . each ( function ( benchmark , name ) {", "commit_type": "update"}
{"commit_tokens": ["fixed", "rendering", "issues", "with", "nunjucks", "."], "add_tokens": "try { return viewEngine . render ( path , vars , cb ) ; } catch ( e ) { return cb ( e ) ; } if ( ! res . _headerSent ) res . status ( 404 ) ; if ( ! res . _headerSent ) res . status ( 500 ) ; if ( ! res . _headerSent ) res . status ( 500 ) ;", "del_tokens": "return viewEngine . render ( path , vars , cb ) ; res . status ( 404 ) ; res . status ( 500 ) ; res . status ( 500 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "iterating", "over", "subscribes", "array"], "add_tokens": "for ( var i = 0 ; i < this . subscribes . length ; i ++ ) { var sub = this . subscribes [ i ] ; this . subscribes . splice ( i -- , 1 ) ; for ( var i = 0 ; i < this . subscribes . length ; i ++ ) { for ( var i = 0 ; i < this . subscribes . length ; i ++ ) { var sub = this . subscribes [ i ] ; this . subscribes . splice ( i -- , 1 ) ;", "del_tokens": "for ( var t in this . subscribes ) { var sub = this . subscribes [ t ] ; delete this . subscribes [ t ] ; for ( var i in this . subscribes ) { for ( var t in this . subscribes ) { var sub = this . subscribes [ t ] ; delete this . subscribes [ t ] ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "dynamic", "requires", "(", "only", "when", "compiling", "for", "--", "node", ")"], "add_tokens": "var argument = node . arguments [ 0 ] var required = argument . type === 'Literal' ? argument . value : null if ( required !== null && row . deps [ required ] && moduleExists ( row . deps [ required ] ) ) { } else if ( required !== null ) {", "del_tokens": "var required = node . arguments [ 0 ] . value if ( row . deps [ required ] && moduleExists ( row . deps [ required ] ) ) { } else {", "commit_type": "fix"}
{"commit_tokens": ["Make", "example", "documentation", "region", "-", "specific", "in", "names", "()"], "add_tokens": "* \"id\" : 10000042 , * \"name\" : \"Metropolis\"", "del_tokens": "* \"id\" : 1000171 , * \"name\" : \"Republic University\"", "commit_type": "make"}
{"commit_tokens": ["Fix", "View", ".", "requestRender", "args", "bug"], "add_tokens": "var renderArgs = arguments ; self . render . apply ( self , renderArgs ) ;", "del_tokens": "self . render . apply ( self , arguments ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "small", "bug", "where", "dirty", "was", "continuously", "set", "when", "trying", "to", "bounce", "in", "a", "direction", "with", "no", "bounce"], "add_tokens": "_viewport = new Viewport ( _renderer . stage , { div : _renderer . div , pauseOnBlur : true , preventDefault : false } )", "del_tokens": "_viewport = new Viewport ( _renderer . stage , { div : _renderer . div , pauseOnBlur : true , preventDefault : true } )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "and", "lint", "errors"], "add_tokens": ") ;", "del_tokens": "import Utils from '../utils/utils' ; ) ; ;", "commit_type": "fix"}
{"commit_tokens": ["adds", ".", "flags", "()", "method"], "add_tokens": "app . option ( { x : 'x' , y : 'y' , z : 'z' } ) app . option ( { a : 'a' , b : 'b' , c : 'c' } ) ; app . option ( 'foo' , { x : 'x' , y : 'y' , z : 'z' } ) app . option ( 'bar' , { a : 'a' , b : 'b' , c : 'c' } ) ;", "del_tokens": "app . option ( { x : 'x' , y : 'y' , z : 'z' } ) . option ( { a : 'a' , b : 'b' , c : 'c' } ) ; app . option ( 'foo' , { x : 'x' , y : 'y' , z : 'z' } ) . option ( 'bar' , { a : 'a' , b : 'b' , c : 'c' } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "BOM", "codification", "to", "windows", "files"], "add_tokens": "processFolders ( wwwPath , platform ) ; function processFolders ( wwwPath , platform ) { processFiles ( path . join ( wwwPath , folder , platform ) ) ; function processFiles ( dir , platform ) { compress ( file , platform ) ; function compress ( file , platform ) { result , bomHelper = \"windows\" === platform ? \"\\xEF\\xBB\\xBF\" : \"\" ; fs . writeFileSync ( file , bomHepler + result . code , 'utf8' ) ; // overwrite the original unminified file fs . writeFileSync ( file , bomHepler + result . styles , 'utf8' ) ; // overwrite the original unminified file", "del_tokens": "processFolders ( wwwPath ) ; function processFolders ( wwwPath ) { processFiles ( path . join ( wwwPath , folder ) ) ; function processFiles ( dir ) { compress ( file ) ; function compress ( file ) { result ; fs . writeFileSync ( file , result . code , 'utf8' ) ; // overwrite the original unminified file fs . writeFileSync ( file , result . styles , 'utf8' ) ; // overwrite the original unminified file", "commit_type": "add"}
{"commit_tokens": ["Add", "burn", "test", "w", "/", "investor", "count"], "add_tokens": "let currentInvestorCount = await I_SecurityToken . investorCount ( ) ; let currentBalance = await I_SecurityToken . balanceOf ( account_temp ) ; // console.log(currentInvestorCount.toString(), currentBalance.toString()); let tx = await I_SecurityToken . burn ( currentBalance , { from : account_temp } ) ; // console.log(tx.logs[0].args._value.toNumber(), currentBalance.toNumber()); assert . equal ( tx . logs [ 0 ] . args . _value . toNumber ( ) , currentBalance . toNumber ( ) ) ; let newInvestorCount = await I_SecurityToken . investorCount ( ) ; // console.log(newInvestorCount.toString()); assert . equal ( newInvestorCount . toNumber ( ) + 1 , currentInvestorCount . toNumber ( ) , \"Investor count drops by one\" ) ;", "del_tokens": "let tx = await I_SecurityToken . burn ( web3 . utils . toWei ( '1' , 'ether' ) , { from : account_temp } ) ; assert . equal ( tx . logs [ 0 ] . args . _value , web3 . utils . toWei ( '1' , 'ether' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "an", "SVM", "classifier", "layer", "can", "be", "used", "instead", "of", "softmax"], "add_tokens": "if ( def . type === 'softmax' || def . type === 'svm' ) { case 'svm' : this . layers . push ( new global . SVMLayer ( def ) ) ; break ; if ( t === 'svm' ) { L = new global . SVMLayer ( ) ; }", "del_tokens": "if ( def . type === 'softmax' ) {", "commit_type": "add"}
{"commit_tokens": ["added", "serializable", "property", "option", "and", "updated", "tests", "and", "docs"], "add_tokens": "dateToISO : true , serializable : false", "del_tokens": "dateToISO : true", "commit_type": "add"}
{"commit_tokens": ["move", "config", "wrapper", "to", "seperate", "file"], "add_tokens": "var ConfigWrapper = require ( './config-wrapper.js' ) ; var localConfigWrapper = ConfigWrapper ( configState ) ; config . get = localConfigWrapper . get ; config . set = localConfigWrapper . set ;", "del_tokens": "var getPath = require ( 'dotty' ) . get ; var putPath = require ( 'dotty' ) . put ; var deepExtend = require ( 'deep-extend' ) ; config . get = getKey ; config . set = setKey ; function getKey ( keyPath ) { if ( ! keyPath ) { return configState ; } return getPath ( configState , keyPath ) ; } function setKey ( keyPath , value ) { if ( typeof keyPath !== 'string' && ! Array . isArray ( keyPath ) ) { throw errors . InvalidKeyPath ( { keyPath : keyPath } ) ; } var v = getKey ( keyPath ) ; if ( typeof v === 'object' && v !== null ) { v = deepExtend ( { } , v , value ) ; } else { v = value ; } return putPath ( configState , keyPath , v ) ; }", "commit_type": "move"}
{"commit_tokens": ["Allow", "to", "block", "the", "display", "of", "the", "popup", "when", "hovering", "a", "feature"], "add_tokens": "blockHoverPopupOnClick : false , this . _popupBlocked = false ; if ( e . type === 'click' && this . options . showInspectMapPopupOnHover && this . options . blockHoverPopupOnClick ) { this . _popupBlocked = ! this . _popupBlocked ; } if ( e . type === 'click' && this . options . showMapPopupOnHover && this . options . blockHoverPopupOnClick ) { this . _popupBlocked = ! this . _popupBlocked ; } if ( ! this . _popupBlocked && this . _popup ) {", "del_tokens": "if ( this . _popup ) {", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "installer", "to", "work", "on", "dev", "vm"], "add_tokens": "if ( ! ( path === base || path . substr ( 0 , root . length ) === root ) && ( path . substr ( 0 , process . env . HOME . length ) !== process . env . HOME ) ) {", "del_tokens": "if ( ! ( path === base || path . substr ( 0 , root . length ) === root ) ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "whitelist", "of", "server", "commands", "that", "are", "safe", "to", "process", "before", "registration"], "add_tokens": "// commands allowed to be processed before registration (001) var preregAllowedCommands = [ '001' , 'PING' , 'NOTICE' ] ; // either already registered (001) or it's a command that's allowed to be received before registration if ( server . nickname !== null || ~ preregAllowedCommands . indexOf ( parseResult . command ) ) { serverCommandHandlers [ parseResult . command ] ( parseResult . args . length , [ server . user , server . user . servers . indexOf ( server ) , // serverIdx server , ( parseResult . origin !== null ? utils . parseOrigin ( parseResult . origin ) : null ) ] . concat ( parseResult . args ) ) ; } else { server . user . applyStateChange ( 'Error' , server . toWindowPath ( ) , 'Server protocol violation: Received ' + parseResult . command + ' before registration.' ) ; }", "del_tokens": "// if we are the quitter if ( server . nickname === origin . nick ) { // do we need to do anything special? } serverCommandHandlers [ parseResult . command ] ( parseResult . args . length , [ server . user , server . user . servers . indexOf ( server ) , // serverIdx server , ( parseResult . origin !== null ? utils . parseOrigin ( parseResult . origin ) : null ) ] . concat ( parseResult . args ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "default", "-", "index"], "add_tokens": "io . error ( err . stack )", "del_tokens": "io . error ( err . stack || err . message )", "commit_type": "add"}
{"commit_tokens": ["Use", "Date", ".", "now", "instead", "of", "new", "Date", "()", ".", "getTime"], "add_tokens": "return Date . now ( ) / 1000 ;", "del_tokens": "return new Date ( ) . getTime ( ) / 1000 ;", "commit_type": "use"}
{"commit_tokens": ["added", "es", "lint", "and", "cleaned", "up", "code"], "add_tokens": "} ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Use", "predefined", "mocha", "test", "generator"], "add_tokens": "lib = eslint ( lib , { testGenerator : 'mocha' } ) ; tests = eslint ( tests , { testGenerator : 'mocha' } ) ;", "del_tokens": "var escape = require ( 'js-string-escape' ) ; lib = eslint ( lib , { testGenerator : generateESLintTest } ) ; tests = eslint ( tests , { testGenerator : generateESLintTest } ) ; function generateESLintTest ( relativePath , errors , results ) { var passed = ! results . errorCount || results . errorCount . length === 0 ; var messages = '' ; if ( results . messages ) { messages = escape ( '\\n\\n' + renderESLintErrors ( results . messages ) ) ; } return \"describe('ESLint | \" + relativePath + \"', function() {\\n\" + \" it('should pass ESLint', function() { \" + \" if (!\" + passed + \") throw new Error('ESLint failed\" + messages + \"');\" + \" });\" + \"});\" ; } function renderESLintErrors ( errors ) { return errors . map ( function ( error ) { return error . line + ':' + error . column + ' - ' + error . message + ' (' + error . ruleId + ')' ; } ) . join ( '\\n' ) ; }", "commit_type": "use"}
{"commit_tokens": ["Updated", "logging", "messages", "with", "Cedar", "component", "names"], "add_tokens": "assert . equal ( enabled , \"function (c){var o='<p>\\\\n <br>\\\\n</p>';return o}\" ) ; assert . equal ( template . toString ( ) , \"function (c){var o='<br>';if(c.a){for(var d,a=0,b=c.x.length;a<b;++a){d=c.x[a];o+='\\\\n<i>Hi</i>'}}return o}\" ) ; assert . equal ( e . message , '[Ltl] Failed to compile template. Unexpected token !' ) ; assert . equal ( e . message , '[Ltl] Failed to compile template. Unexpected token !' ) ; assert . equal ( e . message , '[Ltl] Failed to compile \"wtf\". Unexpected token !' ) ; assert . equal ( e . message , '[Ltl] Failed to compile \"wtf\". Unexpected token !' ) ;", "del_tokens": "assert . equal ( enabled , \"function (c){var o='<p>' +\\n' <br></p>';return o}\" ) ; assert . equal ( template . toString ( ) , \"function (c){var o='<br>' +\\n'';if(c.a){\\n for(var d,a=0,b=c.x.length;a<b;++a){d=c.x[a];\\n o+='<i>Hi</i>'}}return o}\" ) ; assert . equal ( e . message , 'Ltl failed to compile template. Unexpected token !' ) ; assert . equal ( e . message , 'Ltl failed to compile template. Unexpected token !' ) ; assert . equal ( e . message , 'Ltl failed to compile \"wtf\". Unexpected token !' ) ; assert . equal ( e . message , 'Ltl failed to compile \"wtf\". Unexpected token !' ) ;", "commit_type": "update"}
{"commit_tokens": ["Changed", "test", "to", "mocha", "fixed", "login"], "add_tokens": "server . use ( restify . bodyParser ( ) ) ; server . use ( middleware . authorizationHandler ( server ) ) ; users . attach ( server ) ;", "del_tokens": "server . use ( restify . authorizationParser ( ) ) ; server . use ( middleware . authorizationHandler ( server ) ) server . use ( restify . bodyParser ( ) ) ; users ( server ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "usage", "description", "bump", "version"], "add_tokens": ". describe ( 's' , 'use stdin as input' ) . usage ( 'Usage:\\n\\t$0 [options] -f filename\\n\\t$0 [options] -s' ) ,", "del_tokens": ". describe ( 's' , 'use stdin' ) . usage ( 'Usage:\\n\\t$0 [options] -f filename' ) ,", "commit_type": "fix"}
{"commit_tokens": ["add", "proper", "cached", "preloads", "add", "example", "for", "preloading", "objects"], "add_tokens": "require ( './models/user' ) . load ( 1 ) . ready ( function ( user ) { console . log ( 'individual load:' ) ; require ( './models/preload' ) . getAll ( ) . preload ( 'user_id' ) . ready ( function ( preloads ) { console . log ( 'preloads:' ) ; console . log ( preloads ) ; } ) . error ( function ( err ) { throw err ; } ) ;", "del_tokens": "var UserModel = require ( './models/user' ) ; UserModel . load ( 1 ) . ready ( function ( user ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "can", ".", "viewInsert"], "add_tokens": "var canSymbol = require ( \"can-symbol\" ) ; var viewInsertSymbol = canSymbol . for ( \"can.viewInsert\" ) ; live . html = function ( el , compute , parentNode , nodeListOrOptions ) { var data ; var makeAndPut ; var nodeList ; var nodes ; var options ; // nodeListOrOptions can either be a NodeList or an object with a nodeList property if ( nodeListOrOptions !== undefined ) { if ( Array . isArray ( nodeListOrOptions ) ) { nodeList = nodeListOrOptions ; } else { nodeList = nodeListOrOptions . nodeList ; options = nodeListOrOptions ; } } // Receives the compute output (must be some DOM representation, a function, // or an object with the can.viewInsert symbol) // If val has the can.viewInsert symbol, call it and get something usable for val back if ( val && typeof val [ viewInsertSymbol ] === \"function\" ) { val = val [ viewInsertSymbol ] ( options ) ; } var isFunction = typeof val === \"function\" ; // translate val into a document fragment if it's DOM-like var frag = makeFrag ( isFunction ? \"\" : val ) ; // previous set of nodes var oldNodes = makeArray ( nodes ) ;", "del_tokens": "live . html = function ( el , compute , parentNode , nodeList ) { var data , makeAndPut , nodes ; // Receives the compute output (must be some DOM representation or a function) var isFunction = typeof val === \"function\" , // translate val into a document fragment if it's DOM-like frag = makeFrag ( isFunction ? \"\" : val ) , // previous set of nodes oldNodes = makeArray ( nodes ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "markdown", "sdk", "and", "tests", "fix", "highlight"], "add_tokens": "if ( language === 'html' ) { language = 'xml' ; } if ( language === 'html' ) { return 'html' ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Allow", "each", "partials", "dir", "to", "be", "configured"], "add_tokens": "var dirOptions = options ; dirOptions = utils . extend ( { } , options , dir ) ; dir = dir . dir ; return this . getTemplates ( dir , dirOptions ) . then ( function ( templates ) { namespace : dirOptions . namespace", "del_tokens": "var namespace ; namespace = dir . namespace ; dir = dir . dir ; return this . getTemplates ( dir , options ) . then ( function ( templates ) { namespace : namespace", "commit_type": "allow"}
{"commit_tokens": ["use", "path", ".", "join", "to", "make", "sure", "/", "count", "is", "correct"], "add_tokens": "var path = require ( 'path' ) ; 'request' , 'forward' , 'listen' , 'use' , 'start' , 'stop' , 'on' , 'config' args [ 0 ] = proto + host + path . join ( this . url , args [ 0 ] ) ;", "del_tokens": "'request' , 'forward' , 'listen' , 'use' , 'start' , 'stop' , 'on' , 'config' args [ 0 ] = proto + host + this . url + args [ 0 ] ;", "commit_type": "use"}
{"commit_tokens": ["Make", "everything", "work", "add", "a", "custom", "example", "showing", "doing", "everything", "custom", "."], "add_tokens": "//Zoom on cluster click or spiderfy if we are at the lowest level", "del_tokens": "//Zoom cluster click or spiderfy if we are at the lowest level", "commit_type": "make"}
{"commit_tokens": ["Fix", "property", "names", "in", "create", "-", "attributes", ".", "js"], "add_tokens": "if ( v !== this . _location ) { this . _gl . bindAttribLocation ( this . _program , v , this . _name ) this . _gl . linkProgram ( this . _program ) this . _relink ( ) }", "del_tokens": "if ( v !== this . location ) { this . gl . bindAttribLocation ( this . _program , v , this . _name ) this . gl . linkProgram ( this . _program ) this . relink ( ) }", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "pulling", "the", "template", "from", "a", "module", "s", "property", "."], "add_tokens": "var templateSource , //if a module is being loaded, and that module as a `template` property (of type `string` or `function`) - use that property as the source of the template. if ( bindingContext . $module && bindingContext . $module . template && ( typeof bindingContext . $module . template === 'string' || typeof bindingContext . $module . template === 'function' ) ) { if ( typeof bindingContext . $module . template === 'string' ) { templateSource = { 'text' : function ( ) { return bindingContext . $module . template ; } } ; } else { templateSource = { 'text' : bindingContext . $module . template } ; } } else { templateSource = engine . makeTemplateSource ( template , templateDocument ) ; }", "del_tokens": "var templateSource = engine . makeTemplateSource ( template , templateDocument ) ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "add", "remove", "and", "clear", "to", "be", "chained", "."], "add_tokens": "var matcher = new Qlobber ( ) ; @ return { Qlobber } The qlobber ( for chaining ) . return this ; @ return { Qlobber } The qlobber ( for chaining ) . return this ; @ return { Array } List of values that matched the topic . This may contain duplicates . @ return { Qlobber } The qlobber ( for chaining ) . return this ;", "del_tokens": "var matcher = new Qlobber ( { remove_duplicates : true } ) ; @ return { Array } List of values that matched the topic . This may contain duplicates if more than one matcher matches the topic with the same value .", "commit_type": "allow"}
{"commit_tokens": ["add", "function", "for", "revert", "console", "object", "override"], "add_tokens": "function dontColorMyConsole ( ) { console . warn = oldConsoleWarn ; console . info = oldConsoleInfo ; console . error = oldConsoleError ; } 'colorMyConsole' : colorMyConsole , 'dontColorMyConsole' : dontColorMyConsole", "del_tokens": "'colorMyConsole' : colorMyConsole", "commit_type": "add"}
{"commit_tokens": ["Added", "DEBUG_COLORED", "to", "force", "colored", "output"], "add_tokens": "return isatty || ( process . env [ 'DEBUG_COLORED' ] == 'true' )", "del_tokens": "return isatty", "commit_type": "add"}
{"commit_tokens": ["Fix", "transform", "exits", "when", "it", "finds", "a", "block", "without", "styles"], "add_tokens": "const Test1 = ( ) => ( < div > < span > test < / span > < Component / > < style jsx > { ` span { color : red ; } ` } < / style > < / div > ) const Test2 = ( ) => < span > test < / span > const Test3 = ( ) => (", "del_tokens": "const Test = ( ) => < span > test < / span > const Test2 = ( ) => (", "commit_type": "fix"}
{"commit_tokens": ["fixed", "csv", "/", "json", "accepted", "responses"], "add_tokens": "var jsonreq = require ( \"httpplease/plugins/jsonrequest\" ) ; jsonReqHttp = http . use ( jsonreq ) . use ( promises ( Promise ) ) ; // http = http.use(promises(Promise)); version : \"1.2\" , req = jsonReqHttp ; \"body\" : data , \"headers\" : { \"Accept\" : \"*/*\" } \"url\" : myurl , \"headers\" : { \"Accept\" : \"*/*\" }", "del_tokens": "http = http . use ( promises ( Promise ) ) ; version : \"1.1\" , req = http ; \"body\" : data \"url\" : myurl", "commit_type": "fix"}
{"commit_tokens": ["added", "feature", "to", "modify", "s", "and", "v", "range"], "add_tokens": "var s , v , sMax , vMax ; if ( options . luminosity ) { if ( options . luminosity === 'dark' ) { console . log ( 'dark color requested!!!' ) ; vMax = color . vMin / 2 + 50 ; sMax = color . sMin / 2 + 50 ; } ; if ( options . luminosity === 'dull' ) { } ; if ( options . luminosity === 'bright' ) { } ; } else { vMax = 100 ; sMax = 100 ; }", "del_tokens": "var s , v ; console . log ( color )", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", "and", "version", "numbers"], "add_tokens": "jQuery Wookmark plugin 0.2 @ version 0.2 @ copyright ( c ) 2009 - 2012 Christoph Ono ( www . wookmark . com )", "del_tokens": "jQuery Wookmark plugin 0.1 @ version 0.1 @ copyright ( c ) 2009 - 2011 Christoph Ono ( www . wookmark . com )", "commit_type": "update"}
{"commit_tokens": ["Add", "an", "option", "to", "the", "example", "."], "add_tokens": "var zog = 'zog' ; var opt = { } ; console . log ( zog + ' tells \"Hello, ' + args . join ( ' ' ) + '\"' ) ; message : 'tell ' + zog if ( answers . zog === zog ) { console . log ( zog + ' ' + zog ) ; opt . foobar = function ( callback , args ) { if ( args ) { zog = args [ 0 ] ; } else { zog = 'lokthar' ; } callback ( ) ; } ; var options = [ { name : '-f, --foobar' , desc : 'zog is foobar' , options : { params : { required : 'who' } } , handler : opt . foobar } ] ; callback ( null , commands , options ) ;", "del_tokens": "console . log ( 'Hello, ' + args . join ( ' ' ) ) ; message : 'tell zog' if ( answers . zog === 'zog' ) { console . log ( 'zog zog' ) ; callback ( null , commands ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "to", "declare", "Entry", "as", "a", "local", "variable", "."], "add_tokens": "var Entry = require ( __dirname + '/../entry' ) ;", "del_tokens": "Entry = require ( __dirname + '/../entry' ) ;", "commit_type": "make"}
{"commit_tokens": ["Allows", "to", "use", "forms", "with", "controllerAs", "syntax"], "add_tokens": "var vm = this ; vm . character = \"Fry\" ; vm . checkValidity = function ( ) { return vm . ExampleForm . $valid ; } $httpBackend . when ( 'GET' , 'some/formtemplate.html' ) . respond ( \"<form name='formCtrl.ExampleForm'><input type='text' name='exampleInput'></form>\" ) ; it ( 'should correct process form with controllerAs.form syntax' , function ( ) { $httpBackend . expectGET ( 'some/formtemplate.html' ) ; ModalService . showModal ( { controller : 'ControllerAsController' , controllerAs : 'formCtrl' , templateUrl : 'some/formtemplate.html' } ) . then ( function ( modal ) { expect ( modal . scope . formCtrl . ExampleForm ) . not . toBeUndefined ( ) ; expect ( modal . scope . formCtrl . checkValidity ( ) ) . toBe ( true ) ; } ) ; $httpBackend . flush ( ) ; } ) ; } ) ;", "del_tokens": "this . character = \"Fry\" ; } ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "maxKeepAlive", "=", "0", "not", "set", "bug", ";", "add", "unittest", "."], "add_tokens": "options = options || { } ; self . maxKeepAliveTime = parseInt ( options . maxKeepAliveTime , 10 ) ; if ( isNaN ( self . maxKeepAliveTime ) ) { self . maxKeepAliveTime = 60000 ; }", "del_tokens": "self . maxKeepAliveTime = parseInt ( options . maxKeepAliveTime , 10 ) || 60000 ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "MANPATH", "in", "dev", "mode", "."], "add_tokens": "var manpath = __dirname", "del_tokens": "var manpath = '.'", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "elements", "in", "root", "with", "Fragments"], "add_tokens": "function createFragment ( nodes ) { var fragment = document . createDocumentFragment ( ) for ( var i = 0 ; i < nodes . length ; i ++ ) { if ( typeof nodes [ i ] === 'string' ) nodes [ i ] = document . createTextNode ( nodes [ i ] ) fragment . appendChild ( nodes [ i ] ) } return fragment } module . exports = hyperx ( nanoHtmlCreateElement , { comments : true , createFragment : createFragment } )", "del_tokens": "module . exports = hyperx ( nanoHtmlCreateElement , { comments : true } )", "commit_type": "allow"}
{"commit_tokens": ["Use", "anymatch", "module", "directly", "in", "test"], "add_tokens": "var anymatch = require ( 'anymatch' ) ; assert ( anymatch ( matchers , sortable [ 3 ] ) ) ;", "del_tokens": "assert ( anysort . match ( matchers , sortable [ 3 ] ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "basic", "working", "tests", "."], "add_tokens": "it ( \"loads basic script\" , function ( done ) { var url = base . appUrl + \"test/func/fixtures/basic.html\" ; . url ( url ) // Check errors . getText ( \"#error\" ) . then ( function ( text ) { expect ( text ) . to . not . be . ok ; // Verify load . getText ( \"#content #basic-script\" ) . then ( function ( text ) { expect ( text ) . to . equal ( \"Basic Script\" ) ; } ) . getText ( \"#content #after-load\" ) . then ( function ( text ) { expect ( text ) . to . equal ( \"After Load\" ) ;", "del_tokens": "it ( \"TODO IMPLEMENT A TEST\" , function ( done ) { . url ( \"http://backbone-testing.com/notes/app/\" ) // Create a note. . setValue ( \"input#note-new-input\" , \"Delete Test\" ) . click ( \"button#note-create\" ) . getText ( \".notes-item .note-title\" ) . then ( function ( text ) { expect ( text ) . to . equal ( \"Delete Test\" ) ; // Delete a note . click ( \".notes-item .note-delete\" ) . isExisting ( \".notes-item .note-delete\" ) . then ( function ( exists ) { expect ( exists ) . to . be . false ;", "commit_type": "add"}
{"commit_tokens": ["Make", "WebSocketServer", "able", "to", "attach", "to", "a", "HTTP", "server"], "add_tokens": "if ( typeof options !== 'object' || ( typeof options . port == 'undefined' && typeof options . server == 'undefined' ) ) { throw new TypeError ( '`port` or a `server` must be provided' ) ; if ( ! options . server ) { this . _server = http . createServer ( function ( req , res ) { res . writeHead ( 200 , { 'Content-Type' : 'text/plain' } ) ; res . end ( 'okay' ) ; } ) ; this . _server . listen ( options . port , options . host || '127.0.0.1' , callback ) ; } else { this . _server = options . server ; }", "del_tokens": "if ( typeof options !== 'object' || typeof options . port == 'undefined' ) { throw new Error ( 'port must be provided' ) ; this . _server = http . createServer ( function ( req , res ) { res . writeHead ( 200 , { 'Content-Type' : 'text/plain' } ) ; res . end ( 'okay' ) ; } ) ; this . _server . listen ( options . port , '127.0.0.1' , function ( ) { if ( typeof callback == 'function' ) callback ( ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "jsdoc", "to", "source", "file"], "add_tokens": "/ *! * merge - descriptors * Copyright ( c ) 2014 Jonathan Ong * MIT Licensed * / / ** * Module exports . * @ public * / module . exports = merge / ** * Merge the property descriptors of ` ` into ` ` * * @ param { object } dest Object to add descriptors to * @ param { object } src Object to clone descriptors from * @ returns { object } Reference to dest * @ public * / function merge ( dest , src ) { Object . getOwnPropertyNames ( src ) . forEach ( function forEachOwnPropertyName ( name ) { }", "del_tokens": "module . exports = function ( dest , src ) { Object . getOwnPropertyNames ( src ) . forEach ( function ( name ) { }", "commit_type": "add"}
{"commit_tokens": ["Added", "deep", "object", "cloning", "to", "set", "+", "context", "tests", "to", "ensure", "references", "dont", "bugger", "up", "the", "results"], "add_tokens": "var _ = require ( 'lodash' ) ; . then ( function ( next ) { contexts . push ( _ . cloneDeep ( this ) ) ; next ( ) } ) . then ( function ( next ) { contexts . push ( _ . cloneDeep ( this ) ) ; next ( ) } ) . then ( function ( next ) { contexts . push ( _ . cloneDeep ( this ) ) ; next ( ) } ) . then ( function ( next ) { contexts . push ( _ . cloneDeep ( this ) ) ; next ( ) } )", "del_tokens": ". then ( function ( next ) { contexts . push ( this ) ; next ( ) } ) . then ( function ( next ) { contexts . push ( this ) ; next ( ) } ) . then ( function ( next ) { contexts . push ( this ) ; next ( ) } ) . then ( function ( next ) { contexts . push ( this ) ; next ( ) } )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "in", "KM", ".", "define", "that", "may", "define", "a", "uri", "which", "not", "absolutized"], "add_tokens": "i < last && _define ( EMPTY , U , U , absolutizeURI ( arg ) ) ;", "del_tokens": "i < last && _define ( EMPTY , U , U , arg ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "bug", "when", "creating", "folder"], "add_tokens": "module . exports . createFolder = function ( folder , callback ) { // If it exists, execute callback if ( exists && typeof callback === \"function\" ) { callback ( ) ; return ; } if ( typeof callback === \"function\" ) { callback ( ) ; } } ; module . exports . copyFile = function ( source , destination ) { fs . createReadStream ( source ) . pipe ( fs . createWriteStream ( destination ) ) ;", "del_tokens": "module . exports . generateFolder = function ( folder ) { if ( exists ) return ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "testcase", "matching", "too", "many", "specs"], "add_tokens": "for ( const verifiedSpec in testcaseParseResults . tree [ matchSuite ] . testcaseHash [ testcase ] . specVerifyHash ) { verifiedSpecs [ verifiedSpec ] = true ;", "del_tokens": "for ( const testcaseId in testcaseParseResults . tree [ matchSuite ] . testcaseHash ) { for ( const verifiedSpec in testcaseParseResults . tree [ matchSuite ] . testcaseHash [ testcaseId ] . specVerifyHash ) { verifiedSpecs [ verifiedSpec ] = true ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "focused", "state", "blur", "/", "focus", "methods", ".", "Improved", "key", "nav"], "add_tokens": "var focusedNode = tree . getFocusedNode ( ) ; if ( focusedNode ) { moveFocusDownFrom ( focusedNode ) ; focusedNode . toggleSelect ( ) ; break ; case keyCodes . LEFT : focusedNode . collapse ( ) ; moveFocusUpFrom ( focusedNode ) ; break ; case keyCodes . RIGHT : focusedNode . expand ( ) ; moveFocusDownFrom ( focusedNode ) ; break ; case keyCodes . UP : moveFocusUpFrom ( focusedNode ) ; function moveFocusDownFrom ( startingNode ) { next . focus ( ) ; function moveFocusUpFrom ( startingNode ) { prev . focus ( ) ;", "del_tokens": "var selected = tree . getSelectedNodes ( ) ; if ( selected . length === 1 ) { var focusedNode = selected [ 0 ] ; case keyCodes . UP : moveSelectionUpFrom ( focusedNode ) ; break ; moveSelectionDownFrom ( focusedNode ) ; focusedNode . toggleCollapse ( ) ; function moveSelectionDownFrom ( startingNode ) { next . select ( ) ; function moveSelectionUpFrom ( startingNode ) { prev . select ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "hang", "on", "linux", "install"], "add_tokens": "if ( rootPath == '' ) return console . log ( 'Failed to find package path, started looking in ' + runningPath ) ; if ( stderr ) { console . log ( 'error running bash script: ' + stderr ) ; return ; } if ( stderr ) { console . log ( 'error running bash script: ' + stderr ) ; return ; } var newPath = path . resolve ( currentPath , '..' ) ; if ( newPath == currentPath ) { return '' ; //something balked } else { currentPath = newPath ; //continue looking }", "del_tokens": "currentPath = path . resolve ( currentPath , '..' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "first", "couple", "tests", "for", "taxonomy", "category", "and", "tag"], "add_tokens": "/ ** * Process the endpoint query ' * ( This query string will only be valid for collection endpoints such as / posts ) * * @ method _queryStr * @ return { String } A query string representing the specified filter parameters * / var taxonomyTerms ; taxonomyTerms = this . _taxonomyFilters [ taxonomy ] || [ ] ; taxonomyTerms = taxonomyTerms . concat ( term ) ; taxonomyTerms . push ( term ) ; this . _taxonomyFilters = _ . unique ( taxonomyTerms . sort ( ) , true ) ; return this . taxonomy ( 'tag' , tag ) ;", "del_tokens": "this . _taxonomyFilters [ taxonomy ] = this . _taxonomyFilters [ taxonomy ] || [ ] ; this . _taxonomyFilters [ taxonomy ] = this . _taxonomyFilters [ taxonomy ] . concat ( term ) ; this . _taxonomyFilters [ taxonomy ] . push ( term ) ; this . _taxonomyFilters = _ . unique ( this . _taxonomyFilters . sort ( ) , true ) ; return this . tag ( 'tag' , tag ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "data", "-", "nav", "docs"], "add_tokens": "var commander = require ( 'commander' ) ; /* App config */ // Args . option ( '-p, --port [number]' , 'Server port (default: ' + global . opts . core . common . port + ')' , global . opts . core . common . port ) // Optimization if ( commander . port ) { port = parseInt ( commander . port ) ; } var portString = port . toString ( ) ; console . log ( dateString + ' [SOURCE] lauched on http://localhost:' . blue + portString . red + ' in ' . blue + MODE . blue + ' mode...' . blue ) ;", "del_tokens": "/* Args */ . option ( '-p, --port [number]' , 'Server port (default: ' + global . opts . common . port + ')' , global . opts . common . port ) /* Args */ /* Optimization */ if ( ! module . parent ) { var port = global . opts . common . port ; if ( commander . port ) { port = parseInt ( commander . port ) ; } var portString = global . opts . core . common . port . toString ( ) ; console . log ( dateString + ' [SOURCE] lauched on ' . blue + portString . red + ' port in ' . blue + MODE . blue + ' mode...' . blue ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "not", "addong", "to", "W"], "add_tokens": "W . CountedCallbackMixin = {", "del_tokens": "var CountedCallbackMixin = {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "view", ".", "parent", "()", "to", "return", "this", ".", "options", ".", "parent", "if", "this", ".", "__current_parent", "isn", "t", "set", "which", "can", "occur", "when", "trying", "to", "access", "this", ".", "parent", "()", "from", "view", "initializer"], "add_tokens": "//when accessing parent during initializer, this.__current_parent is not set yet // so return this.options.parent if it exists return this . __current_parent || this . options . parent ;", "del_tokens": "return this . __current_parent ;", "commit_type": "update"}
{"commit_tokens": ["added", "a", "few", "simple", "effects", "updated", "todo"], "add_tokens": "function eff_t0_8 ( ch , data ) { // set panning ch . pan = data ; } function eff_t0_9 ( ch , data ) { // sample offset ch . off = data * 256 ; } eff_t0_a , // 5, same as A on first tick eff_t0_8 , // 8 eff_t0_9 , // 9 eff_t0_a , // a function eff_t1_5 ( ch ) { // portamento + volume slide eff_t1_a ( ch ) ; eff_t1_3 ( ch ) ; } function eff_nop ( ) { } eff_t1_5 , // 5 eff_t1_6 , // 6 eff_nop , // 8 eff_nop , // 9 eff_nop , // c", "del_tokens": "eff_unimplemented_t0 , // 5 eff_unimplemented_t0 , // 8 eff_unimplemented_t0 , // 9 eff_t0_a , eff_unimplemented , // 5 eff_t1_6 , eff_unimplemented , // 8 eff_unimplemented , // 9 eff_unimplemented , // c", "commit_type": "add"}
{"commit_tokens": ["Implemented", "delete", "cookies", "command", "."], "add_tokens": "SOURCE : \"source\" , COOKIE : \"cookie\" } else if ( req . urlParsed . file === _const . COOKIE ) { if ( req . method === \"DELETE\" ) { console . log ( \"Handling delete cookie command...\" ) ; _deleteCookieCommand ( req , res ) ; console . log ( \"Cookies deleted.\" ) ; return ; } _deleteCookieCommand = function ( req , res ) { _session . getCurrentWindow ( ) . evaluate ( function ( ) { var p = document . cookie . split ( \";\" ) ; for ( i = p . length - 1 ; i >= 0 ; -- i ) { var key = p [ i ] . split ( \"=\" ) ; document . cookie = key + \"=\" ; } } ) ; res . success ( _session . getId ( ) ) ; } ,", "del_tokens": "SOURCE : \"source\"", "commit_type": "implement"}
{"commit_tokens": ["Fix", "test", "environment", "support", "for", "IE6", "through", "IE9"], "add_tokens": "if ( el . addEventListener ) { el . addEventListener ( \"load\" , done ) ; } else { el . onreadystatechange = function ( ) { if ( done && ( ! this . readyState || this . readyState === \"loaded\" || this . readyState === \"complete\" ) ) { done ( ) ; done = null ; } } ; } document . getElementsByTagName ( 'head' ) [ 0 ] . appendChild ( el ) ; var idx , length , parts ; for ( idx = 0 , length = params . length ; idx < length ; ++ idx ) { parts = params [ idx ] . split ( \"=\" ) ; }", "del_tokens": "el . addEventListener ( \"load\" , done ) ; document . head . appendChild ( el ) ; params . forEach ( function ( param ) { var parts = param . split ( \"=\" ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "config", "to", "show", "full", "file", "path", "in", "output", "JSON"], "add_tokens": "if ( opts . showFilePath ) { spritesheet [ fileName ] = result ; } else { var fileName = filePath . substring ( filePath . lastIndexOf ( '/' ) + 1 ) ; spritesheet [ fileName ] = result ; }", "del_tokens": "var fileName = filePath . substring ( filePath . lastIndexOf ( '/' ) + 1 ) ; spritesheet [ fileName ] = result ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "transform", "-", "properties", "module"], "add_tokens": "// if(once('console.log.eventStore' + eventReference)){ // HTMLElement.addEventListener('click',function(){ // console.log('test',HTMLElement) // },false) // }", "del_tokens": "if ( once ( 'console.log.eventStore' ) ) { console . info ( 'eventStore registry' , eventStore$1 ) ; HTMLElement . addEventListener ( 'click' , function ( ) { alert ( 'test' ) ; } , false ) ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "ability", "to", "configure", "algolia", "search"], "add_tokens": "const apiKey = process . env . GATSBY_ALGOLIA_API_KEY ; if ( ! apiKey ) { return ; } apiKey : apiKey , return apiKey ? ( ) : null ;", "del_tokens": "apiKey : '8b7e07f448cec6e39fa301bf82ac83d6' , return ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "(", "missing", "var", ")"], "add_tokens": "return render ( newLexed ) ;", "del_tokens": "return render ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "path", "file", "to", "tween", "folder"], "add_tokens": "Path : require ( './tween/Path' )", "del_tokens": "Path : require ( './extra/Path' )", "commit_type": "move"}
{"commit_tokens": ["Fix", "typo", "iddle", "-", ">", "idle"], "add_tokens": "items . push ( browsers [ i ] . name + ' is ' + ( browsers [ i ] . isReady ? 'idle' : 'executing' ) ) ;", "del_tokens": "items . push ( browsers [ i ] . name + ' is ' + ( browsers [ i ] . isReady ? 'iddle' : 'executing' ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "util", "functions", "to", "the", "top"], "add_tokens": "/ ** * Check if the argument is an array . * * @ param { any } arg * @ returns { Boolean } * / function isArray ( arg ) { return Array . isArray ( arg ) } / ** * Check if the argument is an object . * * @ param { any } arg * @ returns { Boolean } * / function isObject ( arg ) { return arg === Object ( arg ) && Object . prototype . toString . call ( arg ) !== '[object Array]' }", "del_tokens": "/ ** * Check if the argument is an array . * * @ param { any } arg * @ returns { Boolean } * / function isArray ( arg ) { return Array . isArray ( arg ) } / ** * Check if the argument is an object . * * @ param { any } arg * @ returns { Boolean } * / function isObject ( arg ) { return arg === Object ( arg ) && Object . prototype . toString . call ( arg ) !== '[object Array]' }", "commit_type": "move"}
{"commit_tokens": ["Use", "newer", "babel", "and", "core", "-", "js"], "add_tokens": "stage : 0", "del_tokens": "experimental : true", "commit_type": "use"}
{"commit_tokens": ["Move", "to", "JavaScript", "Standard", "codestyle", "to", "conform", "with", "IPFS", "JS", "Community", "Guidelines", "fix", "some", "mem", "leaks", "found"], "add_tokens": "var util = require ( './util' ) if ( util . isBrowser ( ) ) { window . Buffer = require ( 'buffer/' ) . Buffer // Immutable block of data var Block = function ( data ) { if ( ! data ) { return null } var buf = new Buffer ( data ) var multihash = util . hash ( buf ) this . key = function ( ) { return multihash } this . data = function ( ) { return buf } return this module . exports = Block", "del_tokens": "var util = require ( './util' ) ; if ( util . isBrowser ( ) ) { window . Buffer = require ( 'buffer/' ) . Buffer ; //Immutable block of data var Block = function ( data ) { if ( ! data ) { return null ; } var data = new Buffer ( data ) ; var multihash = util . hash ( data ) ; this . key = function ( ) { return multihash } this . data = function ( ) { return data } return this ; module . exports = Block ;", "commit_type": "move"}
{"commit_tokens": ["removed", "the", "storage", "specific", "code", "to", "make", "registry", "storage", "agnostic"], "add_tokens": "let config = require ( '../config' ) ; let storage = config . storage let tarball = yield storage . fileExists ( key ) console . error ( ` ${ key } ` + key ) yield storage . putStreamAsync ( tarball , key , { tarball = yield storage . streamFile ( key ) } else { tarball = yield storage . streamFile ( key ) if ( ! config . storage ) { tarball . size = tarball . headers [ 'content-length' ] }", "del_tokens": "let s3 = require ( './s3' ) let tarball = yield s3 . stream ( key ) console . error ( ` ${ key } ` ) yield s3 . putStreamAsync ( tarball , key , { tarball = yield s3 . stream ( key ) tarball . size = tarball . headers [ 'content-length' ]", "commit_type": "remove"}
{"commit_tokens": ["allow", "undefined", "in", "the", "first", "position", "of", "callbacks"], "add_tokens": "var calleeName = node . callee . name if ( errorArg && ! couldBeError ( errorArg ) && isCallback ( calleeName ) ) { context . report ( node , 'Unexpected literal in error position of callback.' )", "del_tokens": "if ( errorArg && isCallback ( node . callee . name ) ) { if ( ! couldBeError ( errorArg ) ) { context . report ( node , 'Unexpected literal in error position of callback.' ) } else if ( node . arguments . length > 1 && errorArg . type === 'Identifier' ) { if ( errorArg . name === 'undefined' ) { context . report ( node , 'Expected \"null\" instead of \"undefined\" in error position of callback.' ) } }", "commit_type": "allow"}
{"commit_tokens": ["updated", "funList", "in", "ChainedAnalyses", "and", "ChainedAnalysesNoCheck", "with", "onReady"], "add_tokens": "var funList = [ \"_return\" , \"_throw\" , \"_with\" , \"binaryPre\" , \"binary\" , \"conditional\" , \"declare\" , \"endExecution\" , \"endExpression\" , \"forinObject\" , \"functionEnter\" , \"functionExit\" , \"getFieldPre\" , \"getField\" , \"instrumentCodePre\" , \"instrumentCode\" , \"invokeFunPre\" , \"invokeFun\" , \"literal\" , \"onReady\" , \"putFieldPre\" , \"putField\" , \"read\" , \"runInstrumentedFunctionBody\" , \"scriptEnter\" , \"scriptExit\" , \"unaryPre\" , \"unary\" , \"write\" ] ;", "del_tokens": "var funList = [ \"invokeFunPre\" , \"invokeFun\" , \"literal\" , \"forinObject\" , \"declare\" , \"getFieldPre\" , \"getField\" , \"putFieldPre\" , \"putField\" , \"read\" , \"write\" , \"functionEnter\" , \"functionExit\" , \"scriptEnter\" , \"scriptExit\" , \"binaryPre\" , \"binary\" , \"unaryPre\" , \"unary\" , \"conditional\" , \"instrumentCodePre\" , \"instrumentCode\" , \"_return\" , \"_throw\" , \"_with\" , \"endExpression\" , \"endExecution\" , \"runInstrumentedFunctionBody\" ] ;", "commit_type": "update"}
{"commit_tokens": ["updated", "Makefile", "and", "got", "chartbeat", "passing", "again"], "add_tokens": "} , 400 ) ;", "del_tokens": "} , 100 ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "merge", "to", "take", "many", "arguments"], "add_tokens": "merge ( ... ss ) { return this . stateMachine ( ( a , value , observer ) => { if ( ! f ( a , value ) ) { observer . next ( value ) } return value", "del_tokens": "merge ( ss ) { return this . stateMachine ( ( a , value ) => { let emit if ( ! f ( a , value ) ) { emit = value } return { value , emit }", "commit_type": "allow"}
{"commit_tokens": ["added", "cirle", "shapes", "and", "constraint", "debugging"], "add_tokens": "if ( ! ! _arg . size ) { engine . world . bounds . max = { x : _arg . size . x , y : _arg . size . y } ; } if ( ! ! _arg . renderingMode && _arg . renderingMode === 'Canvas' ) { RenderingMode = '2D, Canvas' ; } } this . engine = engine ; this . world = engine . world ; destroy : function ( ) { } , engine : { } , world : { }", "del_tokens": "} engine . world . bounds . max = { x : Crafty . viewport . width , y : Crafty . viewport . height } ; // add a mouse controlled constraint var _mouseConstraint = Matter . MouseConstraint . create ( engine ) ; World . add ( engine . world , _mouseConstraint ) ; destroy : function ( ) { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "manual", "mocks", "when", "using", "inline", "loaders"], "add_tokens": "var last = require ( './localloader!lodash/array/last' ) ; last = require ( './localloader!lodash/array/last.js' ) ;", "del_tokens": "var last = require ( 'lodash/array/last' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "the", "last", "responsivity", "issues", "in", "the", "skin", "and", "prepared", "captions", "and", "subtitles", "."], "add_tokens": "var del = require ( 'del' ) ; ' * <%= pkg.name %> - <%= pkg.description %>' , ' * @link <%= pkg.homepage %>' , ' * @license <%= pkg.license %>' , ' * ' , ' * <%= pkg.name %> includes some scripts provided under different licenses by their authors. Please see the project sources via <%= pkg.homepage %> in order to learn which projects are included and how you may use them.' , ' */' , '' ] . join ( '\\n' ) ; gulp . task ( 'build' , [ 'build-afterglow' ] , function ( ) { del ( [ './dist/tmp' ] ) ; } ) ; gulp . task ( 'build-afterglow' , [ 'compilecomponents' ] , function ( ) { './dist/tmp/components.js' , . pipe ( plugins . uglify ( ) . on ( 'error' , plugins . util . log ) ) gulp . task ( 'compilecomponents' , function ( ) { return gulp . src ( [ './src/videojs/components/TopControlBar.js' , './src/videojs/components/LightboxCloseButton.js' ] ) . pipe ( plugins . browserify2 ( { fileName : 'components.js' , transform : require ( '6to5ify' ) , options : { debug : false } } ) ) . pipe ( gulp . dest ( 'dist/tmp/' ) ) ; } ) ;", "del_tokens": "' * <%= pkg.name %> - <%= pkg.description %>' , ' * @link <%= pkg.homepage %>' , ' * @license <%= pkg.license %>' , ' * ' , ' * <%= pkg.name %> includes some scripts provided under different licenses by their authors. Please see the project sources via <%= pkg.homepage %> in order to learn which projects are included and how you may use them.' , ' */' , '' ] . join ( '\\n' ) ; gulp . task ( 'build' , function ( ) { . pipe ( plugins . uglifyjs ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "reference", "to", "cursor", "s", "continue", "method"], "add_tokens": "onItem ( cursor . value , cursor , cursorTransaction ) ;", "del_tokens": "var next = cursor [ 'continue' ] ; onItem ( cursor . value , cursor , cursorTransaction , next ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "configuration", "allowing", "the", "client", "to", "be", "notified", "of", "idle", "transactions", "also", "transaction", "that", "are", "idle", "for", "to", "long", "are", "now", "aborted", "automatically"], "add_tokens": "options : Symbol ( \"options\" ) , * @ param { { idleTransactions : { ttl : number , warningDelay : number , observer : function ( Transaction , boolean ) } } } options * Entity manager options . See the constructor of the * { @ linkcode EntityManagerFactory } for details . * @ see EntityManagerFactory # constructor constructor ( databaseConnection , options , entityKeyPaths ) { / ** * The entity manager configuration . * * @ type { { idleTransactions : { ttl : number , warningDelay : number , observer : function ( Transaction , boolean ) } } } * / this [ PRIVATE . options ] = options return new TransactionRunner ( transaction , db . objectStoreNames [ 0 ] , this [ PRIVATE . options ] . idleTransactions )", "del_tokens": "constructor ( databaseConnection , entityKeyPaths ) { return new TransactionRunner ( transaction , db . objectStoreNames [ 0 ] )", "commit_type": "add"}
{"commit_tokens": ["Improves", "the", "way", "default", "values", "are", "managed", "for", "Aria", "Templates", "tests", "configuration", "."], "add_tokens": "var merge = require ( '../../merge.js' ) ; var AriaTemplatesTests = function ( campaign , inputConfig ) { // Default values for the config: var testConfig = { rootFolderPath : '/' , bootstrap : null , // the default value depends on the rootFolderPath, that's why it is processed later debug : true , memCheckMode : true , classpaths : { includes : [ ] , excludes : [ ] } , files : { includes : [ ] , excludes : [ ] } } ; merge ( testConfig , inputConfig ) ; if ( ! testConfig . bootstrap ) { testConfig . bootstrap = testConfig . rootFolderPath + 'aria/bootstrap.js' } var rootFolderPath = testConfig . rootFolderPath ; this . bootstrap = testConfig . bootstrap ;", "del_tokens": "var AriaTemplatesTests = function ( campaign , testConfig ) { var rootFolderPath = testConfig . rootFolderPath || '/' ; if ( ariaConfig . memCheckMode == null ) { ariaConfig . memCheckMode = true ; } if ( ariaConfig . debug == null ) { ariaConfig . debug = true ; } this . bootstrap = testConfig . bootstrap || rootFolderPath + 'aria/bootstrap.js' ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "new", "check", "for", "null"], "add_tokens": "// check if the target is null if it is // set the result as the source, this // should be fine since if the source is // null it isn't overriding and if it // isn't null it is overriding if ( target [ key ] === null ) { result [ key ] = source [ key ] ; } else if ( typeof target [ key ] === 'object' && ! ( target [ key ] instanceof Array ) ) { // check if the current target object value is an object", "del_tokens": "// check if the current target object value is an object if ( typeof target [ key ] === 'object' && ! ( target [ key ] instanceof Array ) ) {", "commit_type": "add"}
{"commit_tokens": ["added", "check", "for", "app", "locals"], "add_tokens": "if ( resources . app && resources . app . locals ) { applocals = resources . app . locals ; } else if ( applocals ) { else { renderResponseData ( ) ; }", "del_tokens": "applocals = resources . app . locals ; else {", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "more", "test", "cases", "."], "add_tokens": "// Unclosed elements throws ( 'unclosed string' , 'a[href=\"wow]' ) ; throws ( 'unclosed comment' , '/* oops' ) ; throws ( 'bad pseudo element' , 'button::\"after\"' ) ;", "del_tokens": "throws ( 'bad pseudo element' , 'button::\"after\"' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "eslint", "-", "disable", "consistent", "-", "return", "to", "html", "template"], "add_tokens": "data = \"(function() {\\n /* eslint-disable consistent-return */\\n var __templateData = \" + ( JSON . stringify ( data ) ) + \";\\n if (typeof define === 'function' && define.amd) {\\n define([], function() {\\n return __templateData;\\n });\\n } else if (typeof module === 'object' && module && module.exports) {\\n module.exports = __templateData;\\n } else {\\n return __templateData;\\n }\\n})();\" ;", "del_tokens": "data = \"(function() {\\n var __templateData = \" + ( JSON . stringify ( data ) ) + \";\\n if (typeof define === 'function' && define.amd) {\\n define([], function() {\\n return __templateData;\\n });\\n } else if (typeof module === 'object' && module && module.exports) {\\n module.exports = __templateData;\\n } else {\\n return __templateData;\\n }\\n})();\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "TL", "/", "BL", "/", "TR", "/", "BR", "docking", "positions", "in", "the", "HUD", "."], "add_tokens": "'dock' : 'br' ,", "del_tokens": "'dock' : 'bottom' ,", "commit_type": "add"}
{"commit_tokens": ["removed", "the", "only", "these", "tests", "flag"], "add_tokens": "describe ( \"RecordFetcher\" , ( ) => {", "del_tokens": "fdescribe ( \"RecordFetcher\" , ( ) => {", "commit_type": "remove"}
{"commit_tokens": ["Added", "Constantinople", "difficulty", "bomb", "delay"], "add_tokens": "// max((2 if len(parent.uncles) else 1) - ((timestamp - parent.timestamp) // 9), -99) (EIP100) } if ( this . _common . hardforkGteHardfork ( hardfork , 'constantinople' ) ) { // Constantinople difficulty bomb delay (EIP1234) num . isubn ( 5000000 ) if ( num . ltn ( 0 ) ) { num = new BN ( 0 ) } } else if ( this . _common . hardforkGteHardfork ( hardfork , 'byzantium' ) ) { // Byzantium difficulty bomb delay (EIP649)", "del_tokens": "// max((2 if len(parent.uncles) else 1) - ((timestamp - parent.timestamp) // 9), -99) // Byzantium difficulty bomb delay", "commit_type": "add"}
{"commit_tokens": ["added", "equitangular", "-", "to", "-", "rectilinear", "converter", "(", "via", "web", "worker", ")", "and", "cubical", "projection", "support"], "add_tokens": "// \"three\": \"THREE\", // \"jquery\": \"jquery\"", "del_tokens": "\"three\" : \"THREE\" , \"jquery\" : \"jquery\"", "commit_type": "add"}
{"commit_tokens": ["Add", "cli#exec", "for", "simple", "shell", "command", "execution", "."], "add_tokens": "describe ( 'child_process' , function ( ) { it ( 'should ' , function ( done ) { mocks = { child_process_exec_err : new Error ( 'someerror' ) , child_process_exec_stdout : 'somestdout' , child_process_exec_stderr : 'somestderr' } var child_process = mock . child_process ( checks , mocks ) ; child_process . exec ( 'somecommand' , function cb ( err , stdout , stderr ) { checks . child_process_cb_args = cb . arguments ; done ( ) ; } ) ; checks . child_process_exec__args . length . should . equal ( 2 ) ; checks . child_process_exec__args [ 0 ] . should . equal ( 'somecommand' ) ; checks . child_process_exec__args [ 1 ] . should . be . a ( 'function' ) ; checks . child_process_cb_args . length . should . equal ( 3 ) ; checks . child_process_cb_args [ 0 ] . message . should . equal ( 'someerror' ) ; checks . child_process_cb_args [ 1 ] . should . equal ( 'somestdout' ) ; checks . child_process_cb_args [ 2 ] . should . equal ( 'somestderr' ) ; } ) ; } ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["updated", "for", "newer", "version", "of", "haba"], "add_tokens": "haba = require ( 'haba' ) . loader ( ) ;", "del_tokens": "haba = require ( 'haba' ) ( ) ;", "commit_type": "update"}
{"commit_tokens": ["remove", "pool", "party", "-", "no", "notable", "speed", "improvement"], "add_tokens": "var BindableSetter , Binding , DeepPropertyWatcher , bindableSetter , options , toarray , type , utils , DeepPropertyWatcher = require ( \"./deepPropertyWatcher2\" ) ; listeners . push ( new DeepPropertyWatcher ( {", "del_tokens": "var BindableSetter , Binding , bindableSetter , deepPropertyWatcher , options , toarray , type , utils , deepPropertyWatcher = require ( \"./deepPropertyWatcher2\" ) ; listeners . push ( deepPropertyWatcher . create ( {", "commit_type": "remove"}
{"commit_tokens": ["Adding", "extras", "(", "site", "image", "assets", "etc", ")", "."], "add_tokens": "console . log ( process . cwd ( ) + '/bin/GhostKnife/ghostknife' , [ tempFile , where . x , where . y , size . width , size . height , 3000 , 10000 , filename ] ) ; callback ( new Error ( code ) ) ;", "del_tokens": "callback . fail ( new Error ( code ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "example", "to", "check", "for", "query", "and", "body", "parameters", "."], "add_tokens": "app . use ( express . urlencoded ( { extended : false } ) ) app . use ( express . json ( ) ) const master = req . query . master res . send ( ` hello / duplicate with : master = $ { master } and ${ req . query . boss } ` ) res . send ( ` ${ req . params . id } ` ) res . send ( ` hello / foo with : master = $ { req . body . master } and ${ req . body . boss } ` )", "del_tokens": "res . send ( 'hello /duplicate' ) res . send ( 'hello /duplicate' ) res . send ( 'hello /foo' )", "commit_type": "update"}
{"commit_tokens": ["removed", "rule", "loading", "from", "Linter", "class"], "add_tokens": "var lodash = require ( 'lodash' ) , requireAll = require ( 'require-all' ) , Linter = require ( './linter' ) ; var htmllint = module . exports = function ( html , opts ) { return htmllint . defaultLinter . lint ( html , opts ) ; htmllint . Linter = Linter ; htmllint . rules = lodash . values ( requireAll ( { dirname : __dirname + '/rules' , filter : / (.+)\\.js / } ) ) . reduce ( function ( obj , rule ) { obj [ rule . name ] = rule ; return obj ; } , { } ) ; htmllint . defaultLinter = new Linter ( htmllint . rules ) ;", "del_tokens": "var Linter = require ( './linter' ) , linter = new Linter ( ) ; module . exports = function ( html , opts ) { return linter . lint ( html , opts ) ; module . exports . Linter = Linter ; module . exports . defaultLinter = linter ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "PageParserHandler", "for", "@page", "rule", "handling", ";", "add", "cascading", "mechanism", "for", "@page", "rule"], "add_tokens": "/** @type {!adapt.csscasc.ActionTable} */ this . pagetypes = { } ; adapt . csscasc . copyTable ( this . pagetypes , r . pagetypes ) ; /** @type {?string} */ this . currentPageType = null ; // do not apply page rules this . currentPageType = null ; // Apply page rules only when currentPageType is not null if ( this . currentPageType !== null ) { this . applyAction ( this . code . pagetypes , this . currentPageType ) ; // We represent page rules without selectors by *, though it is illegal in CSS this . applyAction ( this . code . pagetypes , \"*\" ) ; } / ** * @ protected * @ param { adapt . csscasc . CascadeAction } action * @ return { void } * / adapt . csscasc . CascadeParserHandler . prototype . insertNonPrimary = function ( action ) { this . cascade . insertInTable ( this . cascade . tags , \"*\" , action ) ; } ; this . insertNonPrimary ( action ) ;", "del_tokens": "this . cascade . insertInTable ( this . cascade . tags , \"*\" , action ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "grunt", "banner", "in", "favor", "of", "browserify", "banner", "feature"], "add_tokens": "build : { banner : '/*! <%= pkg.name %> v<%= pkg.version %> - <%= grunt.template.today(\"yyyy-mm-dd\") %>. (c) <%= grunt.template.today(\"yyyy\") %> Miguel Castillo. Licensed under MIT */' , detectGlobals : false , standalone : 'roolio' build : { grunt . registerTask ( 'build' , [ 'jshint:all' , 'browserify:build' , 'uglify:build' ] ) ;", "del_tokens": "'build' : { 'detectGlobals' : false , 'standalone' : 'roolio' 'build' : { } , usebanner : { 'build' : { options : { position : 'top' , banner : '/*! <%= pkg.name %> v<%= pkg.version %> - <%= grunt.template.today(\"yyyy-mm-dd\") %>. (c) <%= grunt.template.today(\"yyyy\") %> Miguel Castillo. Licensed under MIT */' , linebreak : true } , files : { src : [ 'dist/**.js' ] } } grunt . loadNpmTasks ( 'grunt-banner' ) ; grunt . registerTask ( 'build' , [ 'jshint:all' , 'browserify:build' , 'usebanner:build' , 'uglify:build' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "offset", "and", "endOffset", "optional"], "add_tokens": "* array of one of the previous . ll [ 0 ] instanceof L . LatLng || } , * Changes the patterns used by this decorator * Changes the patterns used by this decorator pattern . offset = patternDef . offset ? parseFloat ( patternDef . offset ) : 0 ; pattern . endOffset = patternDef . endOffset ? parseFloat ( patternDef . endOffset ) : 0 ; * on the path repeat = pattern . repeat / pathPixelLength ; * keeping the cache .", "del_tokens": "* array of one of the previous . ll [ 0 ] instanceof L . LatLng || } , * Changes the patterns used by this decorator * Changes the patterns used by this decorator pattern . offset = parseFloat ( patternDef . offset ) ; pattern . endOffset = parseFloat ( patternDef . endOffset ) ; // TODO: 0 => not pixel dependant => 0% * on the path repeat = pattern . repeat / pathPixelLength ; * keeping the cache .", "commit_type": "make"}
{"commit_tokens": ["add", "more", "tests", "for", "=="], "add_tokens": "/* @flow */ ( 1 == 1 ) ; ( \"foo\" == \"bar\" ) ; ( 1 == null ) ; ( null == 1 ) ; ( 1 == \"\" ) ; // error ( \"\" == 1 ) ; // error var x = ( null : ? number ) ; ( x == 1 ) ; ( 1 == x ) ; // TODO: should not error!", "del_tokens": "var x = ( 1 == null ) ; var y = ( 1 == \"\" ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "we", "have", "a", "src", "set", "before", "pausing"], "add_tokens": "//only try to pause the player when initialised with a source already if ( ! ! player . currentSrc ( ) ) { player . pause ( ) ; }", "del_tokens": "player . pause ( ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "json", "output", "option", "to", "devices", "command"], "add_tokens": "// json output mode . option ( '--json' , 'Display output JSON encoded' , false ) // force silent mode! SilentMode ( options . json === true || _cli . silent === true ) ; _nodemcutool . devices ( _cli . port , _cli . baud , showAll , options . json ) ;", "del_tokens": "// silent mode ? SilentMode ( _cli . silent === true ) ; _nodemcutool . devices ( _cli . port , _cli . baud , showAll ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "line", "-", "dasharray", "feature"], "add_tokens": "const getDashed = c3ss => { let val = getExecutedFn ( 'stroke-dasharray' , LR , c3ss ) ; return val === 'none' ? undefined : val ; } ; blend : getBlend ( c3ss ) , dash : getDashed ( c3ss )", "del_tokens": "blend : getBlend ( c3ss )", "commit_type": "add"}
{"commit_tokens": ["add", "searches", "groups", "and", "keys", "proxies"], "add_tokens": "escape = require ( 'querystring' ) . escape , function $proxy ( ctx , target , prefix , postfix , encode ) { var argument = args [ 0 ] . toString ( ) ; if ( encode ) argument = escape ( argument ) ; args [ 0 ] = join ( prefix , argument , postfix ) ;", "del_tokens": "function $proxy ( ctx , target , prefix , postfix ) { args [ 0 ] = join ( prefix , args [ 0 ] . toString ( ) , postfix ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "regExp", "at", "Case", "6"], "add_tokens": "var async1 = async_test ( 'Case 6: hash changed to content[hash=\"case(\\\\d+)\"]' ) ; var async3 = async_test ( 'Case 6: hash changed to content[hash=\"case(\\\\d+)/case(\\\\d+)\"]' ) ; async3 . next ( ) ; } ) ; window . addEventListener ( 'hashchange' , check_hash ) ; window . location . hash = \"case62\" ; } ) ; async3 . next = async3 . step_func ( _ => { var check_hash = async3 . step_func ( ( e ) => { window . removeEventListener ( 'hashchange' , check_hash ) ; var content1 = document . querySelector ( '#case6-1' ) ; var content2 = document . querySelector ( '#case6-11' ) ; assert_false ( content1 . hidden ) ; assert_false ( content2 . hidden ) ; document . body . removeChild ( div ) ; async3 . done ( ) ; window . location . hash = \"case66/case67\" ;", "del_tokens": "var async1 = async_test ( 'Case 6: hash changed to content[hash=\"case(\\d+)\"]' ) ; document . body . removeChild ( div ) ; window . location . hash = \"case62\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "ttl", "to", "dns", "-", "component"], "add_tokens": "reader . readUint8 ( ) , reader . readUint8 ( ) ] , ttl : ttl } ) ;", "del_tokens": "reader . readUint8 ( ) , reader . readUint8 ( ) ] } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "unpaired", "setImmediate", "and", "clearImmediate"], "add_tokens": "clearImmediate ( this . _sendTimer ) ;", "del_tokens": "clearTimeout ( this . _sendTimer ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "rule", "prefer", "-", "get"], "add_tokens": "function isEquivalentExp ( a , b ) { return _ . isEqual ( a , b , function ( left , right , key ) { if ( _ . includes ( [ 'loc' , 'range' , 'computed' ] , key ) ) { return true ; } if ( key === 'property' ) { var leftValue = left . name || left . value ; var rightValue = right . name || right . value ; return leftValue === rightValue ; } } ) ; } isCallFromObject : isCallFromObject , isEquivalentExp : isEquivalentExp", "del_tokens": "isCallFromObject : isCallFromObject", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "exposed", "by", "additional", "tests", "in", "the", "previous", "commit", ".", "Patch", "release"], "add_tokens": "appendExpression ( '(' , token , ')' , false )", "del_tokens": "appendExpression ( null , token , null , true )", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "few", "LJM", "function", "calls", "."], "add_tokens": "// 'list_all': true,", "del_tokens": "'list_all' : true ,", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "for", "Backbone", ".", "Collection", "in", "attribute", "ownership", ".", "Updated", "rake", "scripts", "to", "have", "a", "package", "task", "."], "add_tokens": "if ( ( value instanceof Backbone . Model ) || ( value instanceof Backbone . Collection ) ) return value ; // Backbone.Model has incompatible destroy (DELETE on server) if ( ( value instanceof Backbone . Model ) || ( value instanceof Backbone . Collection ) ) return value ; // Backbone.Model has incompatible destroy (DELETE on server)", "del_tokens": "if ( value instanceof Backbone . Model ) return value ; // Backbone.Model has incompatible destroy (DELETE on server) if ( value instanceof Backbone . Model ) return value ; // Backbone.Model has incompatible destroy (DELETE on server)", "commit_type": "add"}
{"commit_tokens": ["Fix", "bugs", "discovered", "when", "implementing"], "add_tokens": "jsonKeys : [ 'title' ]", "del_tokens": "transKeys : [ 'title' ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "media", "option", ";", "Better", "command", "-", "line", "argument", "parsing"], "add_tokens": "function extract_stylesheets ( dom , options ) { var media = _ . union ( [ 'screen' , 'all' ] , options . media ) , stylesheets ; /* Match only specified media attributes, plus defaults */ media = 'link[rel=\"stylesheet\"]:not(media),' + media . map ( function ( selector ) { return 'link[rel=\"stylesheet\"]' + '[media=\"' + selector + '\"]' ; } ) . join ( ', ' ) ; stylesheets = dom ( media ) ;", "del_tokens": "function extract_stylesheets ( dom ) { var stylesheets = dom ( 'link[rel=\"stylesheet\"]' ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "possible", "to", "watch", "certain", "file", "as", "a", "dep", "to", "another", "file"], "add_tokens": "this . emitPaths = { } ; _ . each ( this . emitPaths [ cleanFilename ] , function ( cleanFilename ) { this . emit ( 'update' , cleanFilename , stats ) ; } , this ) ; FileWatcher . prototype . subscribe = function ( filepath , emitPath ) { emitPath = emitPath ? this . sear . _cleanPath ( emitPath ) : cleanFilename ; this . emitPaths [ cleanFilename ] = this . emitPaths [ cleanFilename ] || [ ] ; if ( this . emitPaths [ cleanFilename ] . indexOf ( emitPath ) === - 1 ) { this . emitPaths [ cleanFilename ] . push ( emitPath ) ; }", "del_tokens": "this . emit ( 'update' , cleanFilename , stats ) ; FileWatcher . prototype . subscribe = function ( filepath ) {", "commit_type": "make"}
{"commit_tokens": ["Adding", "minClusterSize", "to", "blocking", "clusterer"], "add_tokens": "/ ** * Defaults . * / const DEFAULTS = { minClusterSize : 2 } ; * @ param { function } blocks - Function returning the document blocks . * @ param { function } distance - Distance function to use . * @ param { number } minClusterSize - Minimum number of items in cluster . * @ param { number } radius - Radius of the clusters . minClusterSize = options . minClusterSize || DEFAULTS . minClusterSize , if ( set . size >= minClusterSize ) clusters . push ( Array . from ( set ) ) ;", "del_tokens": "* @ param { function } blocks - Function returning the documents ' * @ param { function } distance - Distance function to use . * @ param { number } radius - Radius of the clusters . clusters . push ( Array . from ( set ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "svg", "position", "in", "firefox"], "add_tokens": "/ *! cal-heatmap v2.0.1 (Thu Mar 07 2013 15:45:21)", "del_tokens": "/ *! cal-heatmap v2.0.0 (Wed Mar 06 2013 23:26:49) . attr ( \"transform\" , \"translate(0, 1)\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "FROM", "to", "UPDATE", "for", "Postgres", "flavour", "."], "add_tokens": "blocks || ( blocks = [ new cls . StringBlock ( options , 'UPDATE' ) , new cls . UpdateTableBlock ( options ) , new cls . SetFieldBlock ( options ) , new cls . FromTableBlock ( _extend ( { } , options , { allowNested : true } ) ) , new cls . WhereBlock ( options ) , new cls . OrderByBlock ( options ) , new cls . LimitBlock ( options ) , new cls . ReturningBlock ( options ) ] ) ;", "del_tokens": "blocks || ( blocks = [ new cls . StringBlock ( options , 'UPDATE' ) , new cls . UpdateTableBlock ( options ) , new cls . SetFieldBlock ( options ) , new cls . WhereBlock ( options ) , new cls . OrderByBlock ( options ) , new cls . LimitBlock ( options ) , new cls . ReturningBlock ( options ) ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "issue", "autoFetch", "becomes", "always", "true"], "add_tokens": "var autoFetch = options . autoFetch || self . _autoFetch ;", "del_tokens": "var autoFetch = options . autoFetch || self . autoFetch ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "readInput", "function", "to", "utils", ".", "js", "."], "add_tokens": ", utils = require ( '../utils' ) utils . readInput ( function ( input ) { utils . readInput ( function ( input ) { utils . readInput ( function ( input ) {", "del_tokens": "intervals . readInput ( function ( input ) { intervals . readInput ( function ( input ) { intervals . readInput ( function ( input ) {", "commit_type": "move"}
{"commit_tokens": ["Moving", "validations", "to", "model", "instead", "of", "controllers", "."], "add_tokens": "export default DS . Model . extend ( Ember . Validations . Mixin , {", "del_tokens": "export default DS . Model . extend ( {", "commit_type": "move"}
{"commit_tokens": ["fixing", "metadata", "names", "with", "slash", "at", "end"], "add_tokens": "/* jshint -W097 */ 'use strict' ; var expect = require ( 'chai' ) . expect ; it ( \"should parse metadata Block with a slash a the end of the name\" , ( ) => { var test = \"hello/metadata/:\\n author: Erykah Badu\\n\" ; var tree = parser . parse ( test ) ; expect ( tree . metadata [ 'hello/metadata/' ] . metadata [ 'author' ] . value ) . to . equal ( 'Erykah Badu' ) ; } ) ;", "del_tokens": "var { expect } = require ( 'chai' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "tests", "for", "non", "-", "cased", "headers"], "add_tokens": "expect ( res . rawHeaders ) . to . equal ( 'foo: bar' ) ; expect ( res . rawHeaders ) . to . equal ( 'foo: bar' ) ; expect ( res . rawHeaders ) . to . equal ( 'foo: bar' ) ; expect ( res . rawHeaders ) . to . equal ( 'foo: baz' ) ; expect ( state . headers . foo ) . to . equal ( 'bar' ) ;", "del_tokens": "expect ( res . rawHeaders ) . to . equal ( 'Foo: bar' ) ; expect ( res . rawHeaders ) . to . equal ( 'Foo: bar' ) ; expect ( res . rawHeaders ) . to . equal ( 'Foo: bar' ) ; expect ( res . rawHeaders ) . to . equal ( 'Foo: baz' ) ; expect ( state . headers . Foo ) . to . equal ( 'bar' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "stylis", "-", "rule", "-", "sheet", "plugin"], "add_tokens": "'span{color:red;}' , '@supports (display:-webkit-box) or (display:-webkit-flex) or (display:-ms-flexbox) or (display:flex){div{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}' '@import \"./test.css\"' , '@supports (display:-webkit-box) or (display:-webkit-flex) or (display:-ms-flexbox) or (display:flex){div{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}' , assert ( ` ` , [ 'div.jsx-123{color:red;}' , '.jsx-123::-webkit-input-placeholder{color:green;}' , '.jsx-123::-moz-placeholder{color:green;}' , '.jsx-123:-ms-input-placeholder{color:green;}' , '.jsx-123::placeholder{color:green;}' ] , '.jsx-123' )", "del_tokens": "'span{color:red;}' , '@supports (display:flex){div{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}' '@supports (display:flex){div{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}' , '@import \"./test.css\"' ,", "commit_type": "use"}
{"commit_tokens": ["add", "better", "checks", "with", "less", "branches", "to", "emoticons"], "add_tokens": "baseURL : 'https://cors-anywhere.herokuapp.com/'", "del_tokens": "baseURL : 'https://cors-anywhere.herokuapp.com/' , headers : { 'Origin' : 'foobar' }", "commit_type": "add"}
{"commit_tokens": ["Add", "image", "button", "to", "inline", "tooltip"], "add_tokens": "new Node . Inline ( params . type , null , params . text , params . attrs ) )", "del_tokens": "new Node ( params . type , params . text , params . attrs ) )", "commit_type": "add"}
{"commit_tokens": ["fixing", "unit", "tests", "failed", "in", "NodeJS", "8", "+"], "add_tokens": "let DefinedModel ; eval ( ` ${ modelName } extends baseClass { constructor ( ... args ) { super ( ... args ) ; }", "del_tokens": "const DefinedModel = eval ( ` ${ modelName } extends baseClass { constructor ( ) { super ( ... arguments ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "use", "as", "attribute", "option", "."], "add_tokens": "var sprintf = require ( 'sprintf' ) . sprintf ; stripNulls : true , useAsAttribute : null , // An array of keys which are used as attributes instead of being // used as a separate tag. Only applies to the XML serializer and // elements which have a parent. var i , def , stype , keys , item , src , value , result , selem ; value = obj . toString ( ) ; if ( ( this . options . useAsAttribute && this . options . useAsAttribute . indexOf ( key ) !== - 1 ) ) { if ( ! elem ) { throw new Error ( sprintf ( '%s should be used as an attribute, but it doesn\\'t ' + 'have a parent element' , key ) ) ; } elem . set ( key , value ) ; return elem ; } else { return this . _addElement ( elem , key , null , value ) ; }", "del_tokens": "stripNulls : true var i , def , stype , keys , item , src , result , selem ; return this . _addElement ( elem , key , null , obj . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "helper", "function", "to", "get", "validation", "function"], "add_tokens": "it ( 'should validate a mongo-id correctly' , function ( ) { it ( 'should validate a float number correctly' , function ( ) { var res1 = val . formats . numberFloat ( 2.66 ) ; var res2 = val . formats . numberFloat ( 3 ) ; var res3 = val . formats . numberFloat ( 2 , 88 ) ; expect ( res1 . valid ) . toBe ( true ) ; expect ( res1 . errors . length ) . toBe ( 0 ) ; expect ( res2 . valid ) . toBe ( false ) ; expect ( res2 . errors . length ) . toBe ( 1 ) ; expect ( res3 . valid ) . toBe ( false ) ; expect ( res3 . errors . length ) . toBe ( 1 ) ; } ) ;", "del_tokens": "it ( 'should validate an url correctly' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "normal", "-", "module", "-", "factory", "after", "-", "resolve", "paths"], "add_tokens": "var resource = _path2 [ 'default' ] . resolve ( compiler . context , result . resource ) ; if ( resource !== runtimePath ) {", "del_tokens": "if ( result . resource !== runtimePath ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "new", "syntax", "for", "@event"], "add_tokens": "return params . map ( genParam ) ; / ** * Generates doc for method or event parameter * / function genParam ( param ) { params : doclet . params . map ( genParam )", "del_tokens": "return params . map ( genMethodParam ) ; function genMethodParam ( param ) { data : { properties : doclet . properties . map ( genEventProperty ) } function genEventProperty ( property ) { var res = { name : property . name , description : property . description } ; if ( property . type ) { res . types = property . type . names ; } return res ; }", "commit_type": "use"}
{"commit_tokens": ["Created", "packet", ".", "coffee", "."], "add_tokens": "'a 3 byte ASCII string' : function ( topic ) { topic . parse ( \"n8[3]|ascii()\" , function ( field , engine ) { } , 'a 3 byte ASCII string' : function ( topic ) { var buffer = [ ] ; var invoked = false ; topic . reset ( ) ; topic . serialize ( \"n8[3]|ascii()\" , \"ABC\" , function ( engine ) { assert . equal ( engine . getBytesWritten ( ) , 3 ) ; invoked = true ; } ) ; topic . write ( buffer , 0 , 10 ) ; assert . isTrue ( invoked ) ; assert . deepEqual ( buffer , [ 0x41 , 0x42 , 0x43 ] ) ;", "del_tokens": "'a 3 transformed to ASCII' : function ( topic ) { topic . parse ( \"n8[3]|str('ascii')\" , function ( field , engine ) {", "commit_type": "create"}
{"commit_tokens": ["add", "ts", "declarations", "for", "Relation", "enum"], "add_tokens": "} ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["add", "spring", "fx", "and", "update", "demo"], "add_tokens": "src : [ 'demo/index.html' , 'demo/index.css' , 'demo/bundle.js' ] , // Live site dry run 'clean:check' ,", "del_tokens": "src : [ 'demo/index.html' , 'demo/index.css' , 'build/mfb-menu.js' ] , // Live site dry run: test locally before pushing. // In .grunt look for the folder 'check' and see if everything's ok //grunt.registerTask('livecheck', ['clean:check','gh-pages:check']); 'clean:live' ,", "commit_type": "add"}
{"commit_tokens": ["added", "fullscreen", "api", "and", "pointer", "lock", "support"], "add_tokens": "var shell = require ( \"../shell\" ) ( { fullscreen : true } )", "del_tokens": "var shell = require ( \"../shell\" ) ( )", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "way", "tile", "height", "is", "calculated", "to", "not", "be", "terrible"], "add_tokens": "/ ** * functional approximation just isn ' * so unless we store a float , this is the other option - * / const approx = ( - 100 + 200 * tile / 255 ) * 10 ; return Math . round ( Math . ceil ( approx / 5 ) * 5 ) ;", "del_tokens": "return Math . round ( - 100 + 200 * tile / 255 ) ;", "commit_type": "fix"}
{"commit_tokens": ["uses", "only", "modern", "can", "-", "dom", "-", "mutate"], "add_tokens": "/ *var map = new Map({ assert . ok ( true , 'should not throw' ) ; * /", "del_tokens": "var nodeLists = require ( \"can-view-nodelist\" ) ; QUnit . skip ( 'text binding is memory safe (#666)' , function ( assert ) { nodeLists . nodeMap . clear ( ) ; var div = document . createElement ( 'div' ) , span = document . createElement ( 'span' ) , text = compute ( function ( ) { return 'foo' ; } ) ; div . appendChild ( span ) ; domMutateNode . appendChild . call ( this . fixture , div ) ; live . text ( span , text , div ) ; domMutateNode . removeChild . call ( this . fixture , div ) ; var done = assert . async ( ) ; setTimeout ( function ( ) { assert . ok ( ! nodeLists . nodeMap . size , 'nothing in nodeMap' ) ; done ( ) ; } , 100 ) ; } ) ; var map = new Map ( { assert . ok ( true , 'should not throw' ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "generator", "function", "name", "for", "koa", "debug"], "add_tokens": "return function * passportInitialize ( next ) { return function * passportAuthenticate ( next ) { }", "del_tokens": "return function * ( next ) { return function * ( next ) { }", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "default", "error", "handler", ".", "Prevents", "hangs", "in", "error", "path", "."], "add_tokens": "// Provide a default error handler to prevent hangs. if ( ! remote . onError ) { remote . onError = function ( request , remote , options , deferred , data ) { data = JSON . parse ( data ) ; deferred . resolve ( JSON . stringify ( { 'sessionId' : data . sessionId , value : - 1 } ) ) ; } remote . onError . call ( this , response , remote , options , deferred , this . data ) ;", "del_tokens": "if ( remote . onError ) { remote . onError . call ( this , response , remote , options , deferred , this . data ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "array", "index", "instead", "of", "Buffer", ".", "get"], "add_tokens": "if ( haystack [ i + j ] !== needle [ j ] ) {", "del_tokens": "if ( haystack . get ( i + j ) !== needle . get ( j ) ) {", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "the", "possibility", "of", "more", "than", "two", "hash", "functions", "."], "add_tokens": "// Create hash functions object. var hashFunctions = { md5 : md5 , sha512 : sha512 } ; // customBase64Hash // ---------------- // Compute a custom Base-64-encoded hash. var customBase64Hash = function ( str , hashFunction ) { // Compute hexadecimal hash and convert it to Base-64. var hash = hashFunction ( str ) . toString ( encBase64 ) ; // Return a custom version of the hash. return customBase64 ( hash ) ; } ; // customBase64 // ------------ // Replace non-alphanumeric characters and padding in the Base-64 alphabet to var customBase64 = function ( str ) { } ; Passwd = customBase64Hash ( Passwd , Method ) ; if ( ! hashFunctions . hasOwnProperty ( options . method ) ) { throw new Error ( 'Method not supported: ' + options . method ) ; hashFunctions [ options . method ]", "del_tokens": "// gp2_b64_hash // ------------ // Compute a custom base64-encoded MD5 or SHA-512 hash. function gp2_b64_hash ( Input , Method ) { var hash = ( Method == 'sha512' ) ? sha512 ( Input ) : md5 ( Input ) ; return gp2_custom_base64 ( hash . toString ( encBase64 ) ) ; } // gp2_custom_base64 // ----------------- // Replace non-alphanumeric characters and padding in the Base64 alphabet to function gp2_custom_base64 ( str ) { } Passwd = gp2_b64_hash ( Passwd , Method ) ; if ( [ 'md5' , 'sha512' ] . indexOf ( options . method ) === - 1 ) { throw new Error ( 'Unknown method ' + options . method ) ; options . method", "commit_type": "allow"}
{"commit_tokens": ["Use", "let", "instead", "of", "var", "fix", "build"], "add_tokens": "let flattenRename = config . rename . split ( \" \" ) ; let renameMap = { } ; for ( let i = 0 ; i < flattenRename . length ; i = i + 2 ) {", "del_tokens": "var flattenRename = config . rename . split ( \" \" ) ; var renameMap = { } ; for ( var i = 0 ; i < flattenRename . length ; i = i + 2 ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "metrics", "of", "font", "-", "family"], "add_tokens": "uniqueFontFamily : [ ] , // if it contains font-family if ( declaration . property . indexOf ( 'font-family' ) > - 1 ) { var formatedFontNamesStr = declaration . value . replace ( / (\\!important|\"|') / g , '' ) . trim ( ) ; formatedFontNamesStr . split ( ',' ) . forEach ( function ( fontName ) { result . uniqueFontFamily . push ( fontName ) ; } ) ; } // Sort `font-family` property. result . uniqueFontFamily = _ . sortBy ( _ . uniq ( result . uniqueFontFamily ) ) ; * { Number } totalUniqueFontFamilies , * { String } uniqueFontSize , * { String } uniqueFontFamily , if ( this . options . totalUniqueFontFamilies ) { analysis . totalUniqueFontFamilies = declarationAnalysis . uniqueFontFamily . length ; } if ( this . options . uniqueFontFamily ) { analysis . uniqueFontFamily = declarationAnalysis . uniqueFontFamily ; }", "del_tokens": "* { String } uniqueColor ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "conditional", "assignment", "from", "module"], "add_tokens": "length , length = ruleset . length ; while ( ++ index < length ) { rule = ruleset [ index ] ;", "del_tokens": "while ( rule = ruleset [ ++ index ] ) {", "commit_type": "remove"}
{"commit_tokens": ["Implementing", "new", "component", "Table", "(", "no", "doc", ".", "yet!", ")"], "add_tokens": "import React , { PropTypes } from 'react' ; onClickButton ( e ) { this . props . onClick ( e ) ;", "del_tokens": "import React , { PropTypes } from 'react' ; onClickButton ( ) { this . props . onClick ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "shadow", "polyfill", "for", "the", "main", "part", "of", "the", "attachShadow", "()", "spec", "."], "add_tokens": "import polyfill from '../../../src/shadow/polyfill' ; let host , light1 , light2 , root , slot , text ; host = create ( 'div' ) ; root = polyfill ( host ) ; root . appendChild ( slot ) ; let anotherHost , anotherNode , anotherRoot , anotherSlot ; anotherHost = create ( 'div' ) ; anotherRoot = polyfill ( anotherHost ) ; anotherRoot . appendChild ( anotherSlot ) ;", "del_tokens": "import polyfill from '../../../src/host/polyfill' ; let host , light1 , light2 , slot , text ; host = create ( 'div' , [ slot ] ) ; polyfill ( host ) ; let anotherHost , anotherNode , anotherSlot ; anotherHost = create ( 'div' , [ anotherSlot ] ) ; polyfill ( anotherHost ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "env", "and", "the", "script", "to", "update", "gh", "-", "pages"], "add_tokens": "locationType : process . env . EMBER_CLI_LOCATION_TYPE || 'auto' ,", "del_tokens": "locationType : 'auto' ,", "commit_type": "update"}
{"commit_tokens": ["Adding", "more", "adb", "commands", "and", "unit", "tests"], "add_tokens": "import _fs from 'fs' ; ncp = B . promisify ( _ncp ) , fs = { lstat : B . promisify ( _fs . lstat ) , readdir : B . promisify ( _fs . readdir ) , writeFile : B . promisify ( _fs . writeFile ) } ; export { mkdirp , mv , rimraf , ncp , fs } ;", "del_tokens": "ncp = B . promisify ( _ncp ) ; export { mkdirp , mv , rimraf , ncp } ;", "commit_type": "add"}
{"commit_tokens": ["created", "install", "command", "and", "moved", "cli", "to", "local", "-", "cli", "directory"], "add_tokens": "switch ( args [ 0 ] ) { case 'init' : break ; default : break ;", "del_tokens": "if ( args [ 0 ] === 'init' ) { } else {", "commit_type": "create"}
{"commit_tokens": ["Fix", "bug", "Cannot", "read", "undefined", "property", "of", "NormalDistribution"], "add_tokens": "var Abba = function ( ) { } ; module . exports . Abba = Abba ;", "del_tokens": "this . Abba = ( function ( Abba , jStat ) { return Abba ; } ( this . Abba || { } , jStat ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "allowWarnings", "option", "to", "print", "warnings", "without", "failing"], "add_tokens": "Object . defineProperty ( exports , \"__esModule\" , { value : true } ) ; // save off pluginOptions so we can get it in `report()` tslintPlugin . pluginOptions = pluginOptions ; if ( options . allowWarnings === undefined ) { options . allowWarnings = false ; } var failureCount = file . tslint . errorCount ; if ( ! options . allowWarnings ) { failureCount += file . tslint . warningCount ; } // if any errors were found, print all warnings and errors else { // if only warnings were emitted, format and print them if ( options . allowWarnings && file . tslint . warningCount > 0 ) { // figure out which formatter the user requested in `tslintPlugin()` and construct one var formatterConstructor = TSLint . findFormatter ( tslintPlugin . pluginOptions . formatter ) ; var formatter = new formatterConstructor ( ) ; // get just the warnings var warnings = file . tslint . failures . filter ( function ( failure ) { return failure . getRuleSeverity ( ) === \"warning\" ; } ) ; // print the output of those console . log ( formatter . format ( warnings ) ) ; } }", "del_tokens": "var failureCount = file . tslint . errorCount + file . tslint . warningCount ; Object . defineProperty ( exports , \"__esModule\" , { value : true } ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "node", "extend", "function", "to", "custom"], "add_tokens": "var extend = require ( './lib/extend' ) ;", "del_tokens": "var util = require ( 'util' ) ; var extend = util . inherits . bind ( util ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "DateUtil", "to", "debug", "-", "utils"], "add_tokens": "'emDateUtil' , Users , DateUtil ) { em . DateUtil = DateUtil ;", "del_tokens": "Users ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "isImplementedBy", "."], "add_tokens": "isImplementedBy ( obj ) { const delegate = is ( Function , obj ) ? obj . prototype : obj ;", "del_tokens": "isImplementedBy ( delegate ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "package", ".", "json", "adding", "subDoc", "support"], "add_tokens": "var findSubDoc = function ( config , cb ) { Model . findOne ( config . conditions , config . fields , config . options , function ( err , doc ) { var subDoc ; if ( doc ) { while ( config . subDoc && config . subDoc . subDoc ) { subDoc = doc [ config . subDoc . path ] ; //doc[path].id(urlParam) config . subDoc = config . subDoc . subDoc ; doc = subDoc ; } subDoc = doc [ config . subDoc . path ] ; cb ( err , subDoc ) ; } else { cb ( err ) ; } } ) ; findSubDoc ( config , cb ) ;", "del_tokens": "var findParentDoc = function ( config , callback ) { Model . find ( config . conditions , config . fields , config . options , callback ) ; var callback = function ( err , doc ) { if ( doc ) { //find the subDoc and return } else { cb ( err ) ; } } ; findParentDoc ( config , callback ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "Event", ".", "changed", "()"], "add_tokens": "changeYd = Symbol ( ) , stateChange = new Resolver ( ) , this [ changeYd ] = stateChange . yielded ; changed : function ( ) { return this [ changeYd ] ; } , var ev , firstDigit , code , sc ; sc = stateChange ; stateChange = new Resolver ( ) ; sc . accept ( ) ; sc = stateChange ; stateChange = new Resolver ( ) ; sc . accept ( ) ;", "del_tokens": "var ev , firstDigit , code ;", "commit_type": "add"}
{"commit_tokens": ["Use", "jquery", "event", "handling", "instead", "of", "addEventListener"], "add_tokens": "window . console . log ( \"changed\" ) ; window . console . log ( \"error\" ) ; jQuery ( document ) . bind ( change , fullScreenChangeHandler ) ; jQuery ( document ) . bind ( error , fullScreenErrorHandler ) ;", "del_tokens": "document . addEventListener ( change , fullScreenChangeHandler , true ) ; document . addEventListener ( error , fullScreenErrorHandler , true ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "sure", "collection", "-", "view", "operates", "on", "a", "copy", "of", "the", "original", "array"], "add_tokens": "this . _current = this . _source . toArray ( ) . concat ( ) ;", "del_tokens": "this . _current = this . _source . toArray ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "shipit", "-", "cli", "."], "add_tokens": "var Shipit = require ( 'shipit-cli' ) ; // Expose task. grunt . registerTask ( 'shipit' , 'Shipit Task' , function ( env ) { grunt . shipit . environment = env ; // Support legacy options. if ( ! config . default && config . options ) config . default = config . options ;", "del_tokens": "/ ** * Module dependencies . * / var path = require ( 'path' ) ; var Shipit = require ( '../lib/shipit' ) ; / ** * Expose task . * / grunt . loadTasks ( path . join ( __dirname , 'deploy' ) ) ; grunt . loadTasks ( path . join ( __dirname , 'rollback' ) ) ; grunt . registerTask ( 'shipit' , 'Shipit Task' , function ( stage ) { grunt . shipit . stage = stage ;", "commit_type": "use"}
{"commit_tokens": ["updated", "links", "to", "point", "to", "organisation"], "add_tokens": "// https://raw.githubusercontent.com/mock-server/mockserver/master/mockserver-core/src/main/resources/org/mockserver/socket/CertificateAuthorityCertificate.pem path : \"/mock-server/mockserver/master/mockserver-core/src/main/resources/org/mockserver/socket/CertificateAuthorityCertificate.pem\" ,", "del_tokens": "// https://raw.githubusercontent.com/jamesdbloom/mockserver/master/mockserver-core/src/main/resources/org/mockserver/socket/CertificateAuthorityCertificate.pem path : \"/jamesdbloom/mockserver/master/mockserver-core/src/main/resources/org/mockserver/socket/CertificateAuthorityCertificate.pem\" ,", "commit_type": "update"}
{"commit_tokens": ["Fix", "simple", "db", ".", "put", "(", "key", "value", ")"], "add_tokens": "if ( typeof options . defaultVersion != \"function\" ) throw new Error ( \"defaultVersion generator must be a function.\" ) if ( options == null ) options = { } if ( options == null ) options = { }", "del_tokens": "if ( typeof options . defaultVersion != \"function\" ) throw new Error ( \"defaultVersion generator must be a function.\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "addImage", "()", "."], "add_tokens": "this . headImage ( identifier , function ( err , res ) { if ( err && err != 404 ) { return callback ( err ) ; } callback ( undef , res . statusCode == 200 ) ; self . imageIdentifierExists ( imageIdentifier , callback ) ; fs . ReadStream ( imgPath ) . pipe ( request . put ( url , function ( err , res ) { if ( err ) { return callback ( err ) ; } else if ( res . statusCode != 201 ) { return callback ( res . statusCode , null , res ) ; } return callback ( undef , res . headers [ 'x-imbo-imageidentifier' ] , res ) ; } ) ) ;", "del_tokens": "self . headImage ( identifier , function ( err , rss ) { callback ( res . statusCode == 200 ) ; self . headImage ( imageIdentifier , function ( err , res ) { callback ( undef , res . statusCode == 200 ) ; } ) ; fs . ReadStream ( imgPath ) . pipe ( request . put ( url , callback ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "the", "ability", "to", "call", "a", "method", "in", "one", "-", "line", "inclusion", "of", "noder", "."], "add_tokens": "return context . execModuleCall ( main ) ; contextProto . execModuleCall = function ( moduleFilename ) { return this . moduleExecute ( this . getModule ( this . moduleResolve ( this . rootModule , moduleFilename ) ) ) ; } ;", "del_tokens": "var execCallModule = require ( './execCallModule.js' ) ; return execCallModule ( context , main ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "time", "-", "domain", "array", "size"], "add_tokens": "this . timeDomain = new Uint8Array ( this . analyser . fftSize )", "del_tokens": "this . timeDomain = new Uint8Array ( this . analyser . frequencyBinCount )", "commit_type": "fix"}
{"commit_tokens": ["Make", "typeof", "null", "===", "null"], "add_tokens": "function typeOf ( val ) { return val === null ? 'null' : typeof val ; } superGet : superGet , typeof : typeOf", "del_tokens": "superGet : superGet", "commit_type": "make"}
{"commit_tokens": ["Make", "the", "mustache", "path", "select", "on", "v1", "vs", "v2", ";", "fix", "tests"], "add_tokens": "Handlebars . registerHelper ( \"systemifv2\" , function ( version ) { if ( version [ 0 ] === \"2\" ) { return \".system\" ; } else { return \"\" ; } } ) ; 'mustache' : Handlebars . compile ( 'http://v2.canjs.com/release/{{version}}/can.view.mustache{{systemifv2 version}}.js' ) ,", "del_tokens": "'mustache' : Handlebars . compile ( 'http://v2.canjs.com/release/{{version}}/can.view.mustache.system.js' ) ,", "commit_type": "make"}
{"commit_tokens": ["Adding", "isFreshWater", "param", "for", "partial", "pressure", "at", "depth", "calculations"], "add_tokens": "$self . partialPressureAtDepth = function ( depth , volumeFraction , isFreshWater ) { /// <param name=\"isFreshWater\" type=\"Boolean\">True to calculate against the weight density of fresh water versus salt.</param> var p = $self . depthInMetersToBars ( depth , isFreshWater ) ;", "del_tokens": "$self . partialPressureAtDepth = function ( depth , volumeFraction ) { var p = $self . depthInMetersToBars ( depth ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "Make", "default", "return", "type", "to", "void", "for", "@action", "or", "IBAction", "marked", "method", "."], "add_tokens": "types = [ returnType ? returnType . name : ( node . action ? \"void\" : \"id\" ) ] ,", "del_tokens": "types = [ returnType ? returnType . name : \"id\" ] ,", "commit_type": "fix"}
{"commit_tokens": ["fixed", "remoteStorageMock", ".", "js", "to", "handle", "the", "schema", "validation", "a", "bit", "better", "though", "it", "should", "probably", "be", "automated", "more", "using", "an", "existing", "schema", "validator"], "add_tokens": "if ( obj [ key ] === undefined ) { if ( _ . schema [ type ] . properties [ key ] . required ) { return false ; } } if ( ( obj [ key ] !== undefined ) && ( typeof obj [ key ] !== _ . schema [ type ] . properties [ key ] . type ) ) { return false ; } ( ! obj [ key ] ) ) { return false ; } if ( typeof _ . on [ 'error' ] === 'function' ) { _ . on [ 'error' ] ( 'error validating object' ) ; }", "del_tokens": "if ( obj [ key ] === undefined ) { return false ; } if ( typeof obj [ key ] !== _ . schema [ type ] . properties [ key ] . type ) { return false ; } ( ! obj [ key ] ) ) { return false ; } if ( typeof _ . on [ 'error' ] === 'function' ) { _ . on [ 'error' ] ( 'error validating object' ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Move", "layout", "related", "code", "into", "the", "same", "directory"], "add_tokens": "require ( \"../common\" ) ;", "del_tokens": "require ( \"./common\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Create", "several", "utility", "methods", "for", "code", "generation", ".", "Update", "DataFrame", "to", "use", "them", "."], "add_tokens": "function Column ( kernelP , refIdP , column ) {", "del_tokens": "var Column = function ( kernelP , refIdP , column ) {", "commit_type": "create"}
{"commit_tokens": ["fix", "bug", "with", "id", "-", "only", "detection"], "add_tokens": "attrs = attrs || this . attributes ; if ( this . isNew ( ) || _ . isEqual ( attrs , { id : this . id } ) ) { log ( 'new or only id' ) ; if ( model . _resetOps ) model . _resetOps ( ) ;", "del_tokens": "if ( this . isNew ( ) || _ . isEqual ( attrs || this . attributes , { id : this . id } ) ) { if ( ! this . isNew ( ) && parsed . id !== this . id ) return ; model . _ops = null ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "ftdi", ".", "open", "signature", "to", "be", "able", "to", "open", "using", "a", "serial", "an", "index", "or", "the", "first", "device", "available"], "add_tokens": "ftdi . open ( 0 ) ;", "del_tokens": "ftdi . open ( ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "some", "basic", "coverage", "for", "additive", "smoothing", "and", "sparse", "observations"], "add_tokens": "value = observation [ key ] ; this . classFeatures [ label ] [ value ] ++ ; // give an extra for smoothing this . classFeatures [ label ] [ value ] = 1 + this . smoothing ;", "del_tokens": "value = observation [ key ] ; this . classFeatures [ label ] [ value ] ++ ; // give an extra for smoothing this . classFeatures [ label ] [ value ] = 1 + this . smoothing ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "parser", "regex", "for", "$", "character"], "add_tokens": "var result = str . match ( / ^\\s+((.|\\s)+)? / ) ; module . exports . mkextract = mkextract ;", "del_tokens": "var result = str . match ( / ^\\s+([^$]+)? / ) ; module . exports . mkextract = mkextract ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "call", "stack", "to", "error", "printouts"], "add_tokens": "that . _log ( 'Exception: ' + ( err && err . stack ) ? err . stack : err ) ; that . _log ( \"Ignoring Exception Caught from Callback: \" + ( err && err . stack ) ? err . stack : err ) ;", "del_tokens": "that . _log ( 'Exception: ' + err ) ; that . _log ( \"Ignoring Exception Caught from Callback: \" + err ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "TODO", "."], "add_tokens": "// TODO: Implement tag option", "del_tokens": "// TODO: Impliment tag option", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "skip", "validation", "and", "return", "default", "added", "preValidate", "transform"], "add_tokens": "var transforms = merge ( { preValidate : function ( value ) { return value ; } } , resolvableConfig . transforms ) ; var value = transforms . preValidate ( resolver . fn ( ) ) ;", "del_tokens": "var value = resolver . fn ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "explicit", "checks", "for", "undefined", "rather", "than", "truthy", "check", "."], "add_tokens": "/* global angular */ pollCount = mock . pollCount === undefined ? mock . pollCount : 2 ; var mocks = scenarioMocks . getMocks ( scenarioName ) ; for ( var i in mocks ) { setupHttpBackendForMockResource ( deferred , mocks [ i ] ) ; } if ( scenarioFromURL === undefined ) { if ( mockData [ scenarioToLoad ] !== undefined ) { $log . error ( 'Mocks not found for scenario: ' + scenarioToLoad ) ; if ( globalDelay !== undefined ) { var matchedMockIndex = 0 ; for ( var i in availableMocks ) { var mock = availableMocks [ i ] ; if ( sameMethod && sameURL ) { matchedMockIndex = i ; break ; } }", "del_tokens": "/* global angular, _ */ pollCount = _ . has ( mock , 'pollCount' ) ? mock . pollCount : 2 ; _ . forOwn ( scenarioMocks . getMocks ( scenarioName ) , function ( mock ) { setupHttpBackendForMockResource ( deferred , mock ) ; } ) ; if ( _ . isUndefined ( scenarioFromURL ) ) { if ( _ . has ( mockData , scenarioToLoad ) ) { $log . log ( 'Mocks not found for scenario: ' + scenarioToLoad ) ; if ( globalDelay ) { var matchedMockIndex = _ . findIndex ( availableMocks , function ( mock ) { return sameMethod && sameURL ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "importing", "from", "multiple", "sources"], "add_tokens": "} ) . reduce ( async ( customSelectorsPromise , source ) => { const customSelectors = await customSelectorsPromise } , Promise . resolve ( { } ) ) ;", "del_tokens": "} ) . reduce ( async ( customSelectors , source ) => { } , { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "iOS", "platform", "check", "in", "Media", ".", "prototype", ".", "setRate"], "add_tokens": "if ( device . platform == 'iOS' ) { exec ( null , null , \"Media\" , \"setVolume\" , [ this . id , volume ] ) ; } else { console . warn ( 'media.setRate method is currently not supported for' , device . platform , 'platform.' ) }", "del_tokens": "exec ( null , null , \"Media\" , \"setVolume\" , [ this . id , volume ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Changing", "byte", "ordering", "in", "advertising", "settings", "register", "data", "parsing"], "add_tokens": "reg . eddystoneInterval = 0x02 ; expect ( bytesHexString ) . to . equal ( '02030100' ) ; reg . eddystoneInterval = 0x02 ; expect ( reg . getBytes ( ) ) . to . equal ( '02030100' ) ; reg . eddystoneInterval = 0x04 ; expect ( reg . getBytes ( ) ) . to . equal ( '04030500' ) ; expect ( reg . getBytes ( ) ) . to . equal ( '02030100' ) ; expect ( reg . getBytes ( ) ) . to . equal ( '00030100' ) ;", "del_tokens": "reg . eddystoneInterval = 0x03 ; expect ( bytesHexString ) . to . equal ( '03030100' ) ; reg . eddystoneInterval = 0x03 ; expect ( reg . getBytes ( ) ) . to . equal ( '03030100' ) ; reg . eddystoneInterval = 0x02 ; expect ( reg . getBytes ( ) ) . to . equal ( '03020500' ) ; expect ( reg . getBytes ( ) ) . to . equal ( '03020100' ) ; expect ( reg . getBytes ( ) ) . to . equal ( '03000100' ) ;", "commit_type": "change"}
{"commit_tokens": ["Make", "fs", "mock", "async", "without", "flush", "()"], "add_tokens": "// public API process . nextTick ( function ( ) { process . nextTick ( function ( ) {", "del_tokens": "var queue = [ ] ; queue . push ( function ( ) { queue . push ( function ( ) { e . flush = function ( ) { var fns = queue ; queue = [ ] ; while ( fns . length ) fns . shift ( ) ( ) ; }", "commit_type": "make"}
{"commit_tokens": ["Add", "checkbox", "grid", "slider", "and", "spinbox"], "add_tokens": "Grid , Slider , < Window name = \"Hi\" height = { 640 } width = { 480 } margined = { true } > < Grid padded = { true } > row = { 0 } column = { 0 } < TextInput onChanged = { text => console . log ( text ) } row = { 0 } column = { 1 } > < Slider onChanged = { value => console . log ( value ) } row = { 0 } column = { 2 } span = { { x : 3 , y : 1 } } / > < / Grid >", "del_tokens": "Group , < Window name = \"Hi\" height = { 640 } width = { 480 } menuBar = { true } > < Group title = \"A group\" padded = { true } > stretchy = { true } label = \"Don't press the button\" < TextInput label = \"Very secret\" multiline = { false } stretchy = { false } secure = { true } onChanged = { text => console . log ( text ) } > < / Group >", "commit_type": "add"}
{"commit_tokens": ["added", "animation", "support", "to", "Marker"], "add_tokens": "title = _props . title , animation = _props . animation ; draggable : draggable , animation : animation } ) ;", "del_tokens": "title = _props . title ; draggable : draggable } ) ;", "commit_type": "add"}
{"commit_tokens": ["UPdated", "built", "files", "+", "webpack", "plugin", "for", "babel", "helpers"], "add_tokens": "const WebpackBabelExternalsPlugin = require ( 'webpack-babel-external-helpers-2' ) ; new WebpackBabelExternalsPlugin ( /* plugin options object */ ) , ) ;", "del_tokens": ")", "commit_type": "update"}
{"commit_tokens": ["Added", "ANY", "/", "ALL", "/", "SOME", "quantifiers"], "add_tokens": "exists = sql . exists , eqAny = sql . eqAny ; it ( 'should support = ANY (subquery) quantifier' , function ( ) { check ( select ( ) . from ( 'user' ) . where ( eqAny ( 'user.id' , select ( 'user_id' ) . from ( 'address' ) ) ) , 'SELECT * FROM user WHERE user.id = ANY (SELECT user_id FROM address)' ) ; } ) ;", "del_tokens": "exists = sql . exists ;", "commit_type": "add"}
{"commit_tokens": ["Use", "strict", "inequality", "when", "checking", "nodes", "else", "IE9", "incorrectly", "evaluates", "node1!", "=", "node2", "as", "false", "."], "add_tokens": "// See http://b/2964418 . IE9 appears to evaluate '!=' incorrectly, so // using '!==' instead. // TODO(user): Possibly revert this change if/when IE9 fixes the issue. while ( node && node !== elem ) {", "del_tokens": "while ( node && node . parentNode && node != elem ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "linting", "to", "the", "examples", "folder", "and", "cleaned", "up", "the", "gulpfile", "."], "add_tokens": "$ ( function ( ) { var center = { lat : 49.47216 , lng : - 123.77307 } ; var offsetCenter = function ( dx , dy ) { return { lat : center . lat + dx , lng : center . lng + dy } ; $ . each ( positions , function ( i , e ) {", "del_tokens": "$ ( function ( ) { var center = { lat : 49.47216 , lng : - 123.77307 } ; var offsetCenter = function ( dx , dy ) { return { lat : center . lat + dx , lng : center . lng + dy } ; $ . each ( positions , function ( i , e ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "jsdom", "dependency", "from", "browser", "test"], "add_tokens": "var jsdom = module . require ( \"jsdom\" ) . jsdom ;", "del_tokens": "var jsdom = require ( \"jsdom\" ) . jsdom ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "log", "when", "debug", "is", "enabled", ".", "More", "accurate", "locations", "in", "final", "log"], "add_tokens": "jshint : { all : [ 'tasks/*.js' ] , options : { jshintrc : '.jshintrc' , } , } ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "escape", "-", "html", "instead", "of", "he", "lib", "for", "html", "encoding", "for", "performance", "boost"], "add_tokens": "const escapeHtml = require ( \"escape-html\" ) ; const htmlStringEscape = str => { if ( typeof str === \"boolean\" || typeof str === \"number\" ) { return String ( str ) ; } return escapeHtml ( str ) ; } ;", "del_tokens": "const { encode } = require ( \"he\" ) ; const ENCODE_OPTS = { strict : true } ; const htmlStringEscape = str => encode ( str , ENCODE_OPTS ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "dest", "optional", "when", "a", "config", "file", "is", "set"], "add_tokens": "if ( ! grunt . file . exists ( params . destination ) && ! params . configure ) {", "del_tokens": "if ( ! grunt . file . exists ( params . destination ) ) {", "commit_type": "make"}
{"commit_tokens": ["Updating", "deps", "and", "removing", "perf", "debugging"], "add_tokens": "//var newrelic = require('newrelic'); if ( ! renderedPage ) { return ; }", "del_tokens": "// if we get here, the request is valid so process it and then return the rendered page if ( ! renderedPage ) { return ; }", "commit_type": "update"}
{"commit_tokens": ["Add", "https", "option", "to", "allow", "secure", "dev", "server"], "add_tokens": ". boolean ( \"https\" ) . describe ( \"https\" ) if ( argv [ \"https\" ] ) options . https = true ; var protocol = options . https ? \"https\" : \"http\" ; console . log ( protocol + \"://localhost:\" + argv . port + \"/\" ) ; console . log ( protocol + \"://localhost:\" + argv . port + \"/webpack-dev-server/\" ) ;", "del_tokens": "console . log ( \"http://localhost:\" + argv . port + \"/\" ) ; console . log ( \"http://localhost:\" + argv . port + \"/webpack-dev-server/\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "contenxt", "to", "debug", "alerts"], "add_tokens": "var context = config . alert_context || \"Runner alert\" ; console . log ( \"[%s] %s\" , context , subject ) ; params . context = context ;", "del_tokens": "console . log ( \"[Alert] %s\" , subject ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "template", "vars", "modified", "autoprefixer", "in", "helper"], "add_tokens": "indentType : 'tab' , Postcss ( [ Autoprefixer ( { browsers : [ 'last 2 versions' , 'ie 8' , 'ie 9' , 'ie 10' ] } ) ] ) Fs . writeFileSync ( file , prefixed . css ) ; HELPER . log . success ( ` ${ Chalk . yellow ( file ) } ` ) ;", "del_tokens": "const Exec = require ( 'child_process' ) . exec ; Postcss ( [ Autoprefixer ] ) Fs . writeFileSync ( file , prefixed . css ) ; HELPER . log . success ( ` ${ Chalk . yellow ( file ) } ` ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "fragment", "by", "URI", "and", "Meta", "length"], "add_tokens": "if ( ( ! params . id || params . id === '' ) && ( ! params . uri || params . uri === '' ) ) { return 'You must enter a valid id or uri' var sql if ( params . id ) { sql = 'INSERT into Fragment values (:id, :start, :end, NULL, NOW())' } else { sql = 'INSERT into Fragment Select m.id, :start, :end, NULL, NOW() from Media m where m.uri = :uri' } conn . query ( sql , { replacements : { \"id\" : params . id , \"start\" : params . start , \"end\" : params . end , \"uri\" : params . uri } } ) . then ( function ( ret ) { var sql = \"select a.uri, a.id, max(f.end) end, a.contentType, max(f.rating) mrat from Media a , Fragment f, Meta m where a.id = f.id and m.id = a.id and contentType = 'video' and end < m.length group by f.id having mrat >= 9 order by RAND() limit 1\"", "del_tokens": "if ( ! params . id || params . id === '' ) { return 'You must enter a valid id' var sql = 'INSERT into Fragment values (:id, :start, :end, NULL, NOW())' conn . query ( sql , { replacements : { \"id\" : params . id , \"start\" : params . start , \"end\" : params . end } } ) . then ( function ( ret ) { var sql = \"select a.uri, a.id, max(f.end) end, a.contentType, max(f.rating) mrat from Media a , Fragment f where a.id = f.id and contentType = 'video' group by f.id having mrat >= 9 order by RAND() limit 1\"", "commit_type": "add"}
{"commit_tokens": ["Add", "input", "throbber", "and", "embeds", "for", "uploads"], "add_tokens": "var url = '/files/' + savedFile . _id + '/' + encodeURIComponent ( savedFile . name ) ; url : url , message : file . name + ' has been saved!' , url : url", "del_tokens": "url : '/files/' + savedFile . _id + '/' + encodeURIComponent ( savedFile . name ) , message : file . name + ' has been saved!'", "commit_type": "add"}
{"commit_tokens": ["create", "object", "-", "get", "from", "object", "-", "tools"], "add_tokens": "var test = require ( 'tape' ) ; var o = require ( '../' ) ; } ; t . strictEqual ( o . get ( fixture , 'one' ) , 1 ) ; t . strictEqual ( o . get ( fixture , 'two.three' ) , 3 ) ; t . strictEqual ( o . get ( fixture , 'two.four.five' ) , 5 ) ; } ) ; } ) ; t . strictEqual ( o . get ( fixture , 'ksfjglfshg' ) , undefined ) ; t . end ( ) ; } ) ;", "del_tokens": "var test = require ( 'tape' ) var o = require ( '../' ) } t . strictEqual ( o . get ( fixture , 'one' ) , 1 ) t . strictEqual ( o . get ( fixture , 'two.three' ) , 3 ) t . strictEqual ( o . get ( fixture , 'two.four.five' ) , 5 ) } ) } ) t . strictEqual ( o . get ( fixture , 'ksfjglfshg' ) , undefined ) t . end ( ) } )", "commit_type": "create"}
{"commit_tokens": ["Use", "debug", "to", "log", "startup", "message"], "add_tokens": "log ( \"Nails server listening on \" + iface + \":\" + port ) ;", "del_tokens": "console . log ( \"Nails server listening on \" + iface + \":\" + port ) ;", "commit_type": "use"}
{"commit_tokens": ["makes", "git", "ranges", "work", "right"], "add_tokens": "var requestedRange = childPkg . version ; if ( ! SemVer . validRange ( childPkg . version ) ) { if ( / ^[\\w_\\-]+\\/[\\w_\\-]+(#[\\w_\\-]+)?$ / . test ( requestedRange ) ) { requestedRange = \"git+https://github.com/\" + requestedRange ; if ( ! / (#[\\w_\\-]+)?$ / . test ( requestedRange ) ) { requestedRange += \"#master\" ; } } } var version = versions [ requestedRange ] ; if ( ! version ) { versions [ requestedRange ] = childPkg ; context . paths [ childPkg . origFileUrl ] = version ;", "del_tokens": "if ( ! versions [ childPkg . version ] ) { versions [ childPkg . version ] = childPkg ; context . paths [ childPkg . origFileUrl ] = versions [ childPkg . version ] ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "unused", "callback", "in", "connection", ".", "getSocket", "()"], "add_tokens": "// Last time updated at Thursday, November 19th, 2015, 5:02:50 PM connectSocket ( callback ) ; } else if ( callback ) { callback ( socket ) ;", "del_tokens": "// Last time updated at Thursday, November 19th, 2015, 4:57:21 PM connectSocket ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "symlink", "or", "copy", "to", "avoid", "failures", "on", "windows"], "add_tokens": "var rimraf = require ( 'rimraf' ) . sync ; try { symlinkOrCopy ( sassCacheDir , this . sassCompileDir + '/.sass-cache' ) ; } catch ( err ) { console . log ( '[broccoli-compass] Warning: can\\'t symlink or copy .sass-cache directory:\\n\\t' , err . message ) ; } try { rimraf ( self . sassCompileDir + '/.sass-cache' ) ; } catch ( err ) { console . log ( '[broccoli-compass] Warning: cannot unlink or delete .sass-cache directory:\\n\\t' , err . message ) ; }", "del_tokens": "fs . symlinkSync ( sassCacheDir , this . sassCompileDir + '/.sass-cache' ) ; fs . unlinkSync ( self . sassCompileDir + '/.sass-cache' ) ;", "commit_type": "use"}
{"commit_tokens": ["adds", "the", "after", "()", "operator"], "add_tokens": "let handled = false ; // some operators modify before the target query // e.g. after() actually has two queries // TODO clean this up to unify design with `modifyAnswerWithCall`. `handled` is icky switch ( callee ) { case 'after' : handled = true ; let [ goalpostQuery ] = args ; let goalpostNode = resolveIndividualQuery ( ast , root , code , goalpostQuery , engine , opts ) ; opts . after = goalpostNode . end ; break ; } if ( ! handled ) { answer = modifyAnswerWithCall ( ast , code , callee , args , engine , answer ) ; }", "del_tokens": "answer = modifyAnswerWithCall ( ast , code , callee , args , engine , answer ) ;", "commit_type": "add"}
{"commit_tokens": ["makes", "more", "sense", "to", "store", "the", "lastIndex", "with", "the", "match", ".", "The", "change", "is", "consistent", "with", "the", "README", ":", ")", ".", "Also", "remove", "our", "marker", "from", "the", "string", "when", "finished", "."], "add_tokens": "startRe = string [ this . _id ] || 0 , matches = [ ] , found = false , res [ 1 ] = res [ 1 ] . concat ( lastIndex ) ; that . emit ( res [ 0 ] , res [ 0 ] , res [ 1 ] ) ; delete string [ this . _id ] ;", "del_tokens": "startRe = string [ this . _id ] || 0 , matches = [ ] , found = false , offset , that . emit ( res [ 0 ] , res [ 0 ] , res [ 1 ] . concat ( lastIndex ) ) ; offset = re . lastIndex ; string [ this . _id ] = 0 ; else matches . push ( offset ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "simple", "sort", "icon", "to", "datatable"], "add_tokens": "this . colSortIdx = - 1 ; if ( mythis . colSortIdx >= 0 ) { this . data . sort ( function ( a , b ) { return mythis . columns [ mythis . colSortIdx ] . sorter ( a , b , mythis . columns [ mythis . colSortIdx ] . dir ) ; } ) ; } var sortContent = '<i class=\"icon-placeholder\"></i>' , colDir = self . source . columns [ i ] . dir ; if ( self . source . colSortIdx == i ) { sortContent = '<i class=\"icon-chevron-' + ( colDir == 'asc' ? 'up' : 'down' ) + '\"></i>' ; } content . push ( '<th class=\"row-' + i + '\"><a data-col-idx=\"' + i + '\" data-sort=\"sort\" href=\"#\">' + this . source . columns [ i ] . name + ' ' + sortContent + '</a></th>' ) ;", "del_tokens": "this . colSortIdx = 0 ; this . data . sort ( function ( a , b ) { return mythis . columns [ mythis . colSortIdx ] . sorter ( a , b , mythis . columns [ mythis . colSortIdx ] . dir ) ; } ) ; content . push ( '<th class=\"row-' + i + '\"><a data-col-idx=\"' + i + '\" data-sort=\"sort\" href=\"#\">' + this . source . columns [ i ] . name + '</a></th>' ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "node", "removed", "from", "example", "until", "it", "works"], "add_tokens": "//g.removeNode(\"1\");", "del_tokens": "g . removeNode ( \"1\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Making", "sure", "that", "we", "have", "a", "watching", "mode", "while", "running", "the", "tests", "+", "ignoring", "encoding", "issue", "in", "PhantomJS"], "add_tokens": "var args = require ( './test/args' ) ; var getBrowser = args . getBrowser ; var isWatching = args . isWatching ; singleRun : ! isWatching ( ) , module . exports . getBrowser = getBrowser ;", "del_tokens": "var getBrowser = function ( ) { if ( process . argv [ 2 ] ) { return process . argv [ 2 ] . replace ( '--browser=' , '' ) ; } return 'PhantomJS' ; } ; singleRun : true ,", "commit_type": "make"}
{"commit_tokens": ["implementing", "map", "-", "sequence", "tests", "to", "switch", "to", "normal", "when", "mapped", "to", "escape"], "add_tokens": "function isEsc ( s ) { return s . trim ( ) . slice ( 0 , 3 ) . toLowerCase ( ) === 'esc' ; } var self = module . exports = function override_ttyWrite ( rli ) { // use set timeout instead of interval, to allow threshold to be changed function popBufferDuringInsert ( ) { var s = buf . pop ( ) ; if ( ! s ) return ; original_ttyWrite . call ( rli , null , { name : s } ) ; setTimeout ( popBufferDuringInsert , self . threshold ) ; } setTimeout ( popBufferDuringInsert , self . threshold ) ; if ( ! normal ) { var m = map . matchInsert ( key . name , buf ) ; if ( ! m ) return original_ttyWrite . apply ( rli , arguments ) ; if ( m === true ) return buf . push ( key . name ) ; if ( isEsc ( m ) ) return normalMode ( ) ; // TODO: otherwise simulate the keypress that the sequence maps to } , threshold : 200 / *if (typeof $repl !== 'undefined') { } * /", "del_tokens": "module . exports = function override_ttyWrite ( rli ) { if ( ! normal ) return original_ttyWrite . apply ( rli , arguments ) ; if ( typeof $repl !== 'undefined' ) { }", "commit_type": "implement"}
{"commit_tokens": ["made", "args", "with", "=", "in", "middle", "work", "."], "add_tokens": "cmd += \" \" + _this . _fixPath ( arg ) ; arg = arg . replace ( / =~\\/ / , '=' + process . env [ 'HOME' ] + '/' ) ; arg = arg . replace ( / =.\\/ / , '=' + path . resolve ( './' ) + '/' ) ;", "del_tokens": "cmd += \" \" + arg ;", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "digits", "DGT_LOG_START_TIME", "register", "as", "a", "buffer", "register", "."], "add_tokens": "// Digit registers: 'DGT_FLASH_READ' , 'DGT_FLASH_WRITE' , 'DGT_LOG_START_TIME' ,", "del_tokens": "'DGT_FLASH_READ' , 'DGT_FLASH_WRITE' ,", "commit_type": "add"}
{"commit_tokens": ["adding", "firefox", "and", "ie", "support"], "add_tokens": "var info = options . getLineInfo ( stackIncrease ) var sourceLines = getFunctionCallLines ( info . file , functionName , info . line ) file : path . basename ( info . file ) , line : info . line , column : info . column", "del_tokens": "var stackTrace = require ( 'stack-trace' ) var backTrace = stackTrace . get ( ) ; var stackPosition = backTrace [ 2 + stackIncrease ] var filename = stackPosition . getFileName ( ) var lineNumber = stackPosition . getLineNumber ( ) var column = stackPosition . getColumnNumber ( ) var sourceLines = getFunctionCallLines ( filename , functionName , lineNumber ) file : path . basename ( filename ) , line : lineNumber , column : column", "commit_type": "add"}
{"commit_tokens": ["Add", "acl", "query", "string", "for", "setBucketACL", "()"], "add_tokens": "// we should make sure to set this query parameter, but the call apparently succeeds without it to s3 // To differentiate this functionality from makeBucket() lets do it anyways. var query = ` ` ; path : ` ${ bucket } ${ query } ` ,", "del_tokens": "path : ` ${ bucket } ` , acl : \"\" ,", "commit_type": "add"}
{"commit_tokens": ["move", "sqlinject", "prevention", "to", "cons", ".", "formatlabel"], "add_tokens": "* Format a Neo4j Label string into lower case , single spaced . Has SQL - injection prevention . labelStr = labelStr || '' var legal = cons . isAtomic ( labelStr ) ; // SQL injection scan here if ( ! legal ) { throw new Error ( \"individual label cannot contain space.\" ) } ;", "del_tokens": "* Format a Neo4j Label string into lower case , single spaced var legal = _ . prod ( _ . map ( labels , cons . isAtomic ) ) ; // SQL injection scan here if ( ! legal ) { throw new Error ( \"individual label cannot contain space.\" ) } ;", "commit_type": "move"}
{"commit_tokens": ["Added", "thread", "pool", "for", "PhantomJS"], "add_tokens": "options , numThreads ; if ( typeof files === 'string' ) { numThreads = 1 ; } else { numThreads = files . length ; } phantom . init . bind ( null , numThreads ) ,", "del_tokens": "options ; phantom . init ,", "commit_type": "add"}
{"commit_tokens": ["remove", "worthless", ".", "only", "()"], "add_tokens": "describe ( 'Structure' , ( ) => {", "del_tokens": "describe . only ( 'Structure' , ( ) => {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "regression", "due", "to", "FAB", "-", "1787"], "add_tokens": "return resolve ( client . setUserContext ( member ) ) ;", "del_tokens": "return client . setUserContext ( member ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "a", "few", "listings", "+", "revision", "retrieval"], "add_tokens": "body : { items : listing } body : { items : res . body . items . map ( function ( row ) { return row . tid ; } ) }", "del_tokens": "body : listing body : res . body . items . map ( function ( row ) { return row . tid ; } )", "commit_type": "implement"}
{"commit_tokens": ["updating", "format", "of", "assertion", "errors", "messages", "in", "tests", "to", "allow", "for", "the", "field", "order", "change"], "add_tokens": "\" } ],\\n\" + \" \\\"body\\\" : \\\"someBody\\\"\\n\" + \" } ],\\n\" + \" \\\"body\\\" : \\\"someBody\\\"\\n\" + \" } ],\\n\" + \" \\\"body\\\" : \\\"someBody\\\"\\n\" +", "del_tokens": "\" \\\"body\\\" : \\\"someBody\\\",\\n\" + \" } ]\\n\" + \" \\\"body\\\" : \\\"someBody\\\",\\n\" + \" } ]\\n\" + \" \\\"body\\\" : \\\"someBody\\\",\\n\" + \" } ]\\n\" +", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "\\", "overline"], "add_tokens": "katex : \"mord\" , overline : \"mord\" overline : function ( group , options , prev ) { var innerGroup = buildGroup ( group . value . result , options . withStyle ( options . style . cramp ( ) ) . deepen ( ) ) ; // The theta variable in the TeXbook var lineWidth = fontMetrics . metrics . defaultRuleThickness ; var line = makeSpan ( [ \"overline-line\" ] , [ makeSpan ( [ ] ) ] ) ; var inner = makeSpan ( [ \"overline-inner\" ] , [ innerGroup ] ) ; var fixIE = makeSpan ( [ \"fix-ie\" ] , [ ] ) ; line . style . top = ( - inner . height - 3 * lineWidth ) + \"em\" ; // The line is supposed to have 1 extra line width above it in height // (TeXbook pg. 443, nr. 9) line . height = inner . height + 5 * lineWidth ; return makeSpan ( [ \"overline\" , \"mord\" ] , [ line , inner , fixIE ] , options . getColor ( ) ) ; } ,", "del_tokens": "katex : \"mord\"", "commit_type": "add"}
{"commit_tokens": ["Add", "error", "processing", "and", "let", "-", "syntax"], "add_tokens": "function unquoteHandler ( frame , code , stack ) { function letSyntax ( frame , code , stack ) { let name = code . cdr . car ; if ( ! name || name . type !== SYMBOL ) { throw new Error ( 'let-syntax expects a symbol' ) ; } if ( stack . scope . car [ name . value ] ) { throw new Error ( 'Syntax ' + name . value + ' conflicts' ) ; } let transCode = code . cdr . cdr . car ; let transName = transCode . car ; if ( ! transName || transName . type !== SYMBOL ) { throw new Error ( 'Transformer name must be a symbol' ) ; } let transFunc = transformers [ transName . value ] ; if ( ! transFunc ) { throw new Error ( 'Unsupported transformer type' ) ; } let transObj = transFunc ( transCode ) ; // Apply the transform object to root scope stack . scope . car [ name . value ] = transObj ; // Don't process child nodes frame . result = code ; return stack ; } 'let-syntax' : letSyntax , 'letrec-syntax' : letSyntax ,", "del_tokens": "function unquoteHandler ( frame , code , stack ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bluebird", "warning", "(", "https", ":", "//", "github", ".", "com", "/", "kisenka", "/", "svg", "-", "sprite", "-", "loader", "/", "issues", "/", "91#issuecomment", "-", "297690801", ")"], "add_tokens": ". then ( ( ) => { done ( ) ; return true ; } )", "del_tokens": ". then ( ( ) => done ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "zip", "archive", "to", "dist"], "add_tokens": "/ *! FuelUX - v2.0.0 - 2012-07-07", "del_tokens": "/ *! FuelUX - v2.0.0 - 2012-07-06", "commit_type": "add"}
{"commit_tokens": ["Allow", "error", "(", "undefined", ")"], "add_tokens": "if ( typeof e === \"undefined\" ) { console . error ( '... Uhoh. Got error %s ...' , e ) ; } else { console . error ( '... Uhoh. Got error %s ...' , e . message ) ; console . error ( e . stack ) ; if ( e . code !== 'EADDRINUSE' ) return ; console . error ( ) ; console . error ( 'You already have a server listening on %s' , this . port ) ; console . error ( 'You should stop it and try again.' ) ; console . error ( ) ; }", "del_tokens": "console . error ( '... Uhoh. Got error %s ...' , e . message ) ; console . error ( e . stack ) ; if ( e . code !== 'EADDRINUSE' ) return ; console . error ( ) ; console . error ( 'You already have a server listening on %s' , this . port ) ; console . error ( 'You should stop it and try again.' ) ; console . error ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "logging", "in", "a", "few", "places"], "add_tokens": "logger . error ( moduleName + ' tracing might not work as ' + file +", "del_tokens": "logger . warn ( moduleName + ' tracing might not work as ' + file +", "commit_type": "update"}
{"commit_tokens": ["Added", "TODO", "comment", "for", "unit", "tests"], "add_tokens": "/ * Do unit - tests for : send method behavior onsuccess callback onfailure callback * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "chimp", "widgets", "to", "cucumber", "world"], "add_tokens": "log = require ( '../log' ) , widgets = require ( 'chimp-widgets' ) ; widgets . driver . api = global . browser ; this . widgets = widgets ;", "del_tokens": "log = require ( '../log' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "colonizers", "-", "dev", "dependency"], "add_tokens": "var path = require ( 'path' ) , gulp = require ( 'gulp' ) , concat = require ( 'gulp-concat' ) , insert = require ( 'gulp-insert' ) , replace = require ( 'gulp-replace' ) , var paths , head , foot ; paths = [ ] ; head = 'var jQuery = require(\\'jquery\\'),\\n $ = jQuery;\\n\\n' ; foot = '\\n\\nmodule.exports = jQuery;\\n' ; paths = paths . map ( function ( p ) { return path . join ( __dirname , p ) ; } ) ; return gulp . src ( paths ) . pipe ( replace ( 'window.jQuery' , 'jQuery' ) ) . pipe ( replace ( 'window.$' , '$' ) ) . pipe ( concat ( 'jquery-plugins.js' ) ) . pipe ( insert . wrap ( head , foot ) ) ;", "del_tokens": "var gulp = require ( 'gulp' ) , dev = require ( 'colonizers-dev' ) , return dev . gulp . bundleJqueryPlugins ( __dirname , [ ] ) . pipe ( gulp . dest ( 'vendor' ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "broken", "reference", "from", "example"], "add_tokens": "value : this . state . value + step ,", "del_tokens": "value : self . state . value + step ,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unneeded", "argument", "for", "bool", "flags"], "add_tokens": "- u , -- upload - sources Upload source files referenced by the source map - o , -- overwrite Overwite previously uploaded source maps -- upload - sources", "del_tokens": "- u , -- upload - sources BOOL Upload source files referenced by the source map - o , -- overwrite BOOL Overwite previously uploaded source maps -- upload - sources true", "commit_type": "remove"}
{"commit_tokens": ["add", "unit", "test", "for", "config", ".", "js"], "add_tokens": "this . _s = { } // setting/store/superlative  config * config, .", "del_tokens": "this . _s = { } // setting superlative  config * config, .   .", "commit_type": "add"}
{"commit_tokens": ["Changed", "order", "tests", "to", "use", "satisfy", "instead", "of", "deep", "equal"], "add_tokens": "const maxLength = 50 ;", "del_tokens": "const maxLength = 10 ;", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "sample", "generator", "."], "add_tokens": "let generator = require ( './lib/generator' ) ; let output = generator ( definition ) ; fs . writeFileSync ( path . resolve ( currentDir , outputFile ) , output , 'utf8' ) ;", "del_tokens": "fs . writeFileSync ( path . resolve ( currentDir , outputFile ) , JSON . stringify ( definition , null , 4 ) , 'utf8' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "support", "for", "postMessage", "in", "kff", ".", "setZeroTimeout", "for", "older", "IE", "(", "unreliable", ")", "."], "add_tokens": "event . stopPropagation ( ) ; if ( callbacks . length > 0 ) callbacks . shift ( ) ( ) ; if ( 'postMessage' in window && 'addEventListener' in window ) window . addEventListener ( 'message' , handleMessage , true ) ;", "del_tokens": "if ( 'stopPropagation' in event ) event . stopPropagation ( ) ; if ( callbacks . length !== 0 ) callbacks . shift ( ) ( ) ; if ( 'postMessage' in window ) if ( 'addEventListener' in window ) window . addEventListener ( 'message' , handleMessage , true ) ; else if ( 'attachEvent' in window ) window . attachEvent ( 'onmessage' , handleMessage ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "bug", "when", "tag", "is", "not", "an", "array"], "add_tokens": "var extname = path . extname ( source ) ; render . render ( meta . _content , extname , function ( err , result ) { if ( _ . isArray ( meta . tags ) ) { } else if ( _ . isString ( meta . tags ) ) { meta . tags = [ { name : meta . tags , permalink : config . tag_dir + '/' + meta . tags + '/' } ] ;", "del_tokens": "render . render ( meta . _content , 'md' , function ( err , result ) { if ( meta . tags ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "filter", "to", "match", "against", "data", "attribute"], "add_tokens": "} else { return object && object . data === value ;", "del_tokens": "return object === value ;", "commit_type": "update"}
{"commit_tokens": ["fix", "mem", "and", "cpu", "metrics"], "add_tokens": "vmstats . memory . cache * 1024 ,", "del_tokens": "vmstat . cache * 1024 ,", "commit_type": "fix"}
{"commit_tokens": ["Added", ".", "m", "extension", "for", "objective", "C", "to", "list", "of", "C", "style", "languages"], "add_tokens": "} ) , [ 'c' , 'cc' , 'cpp' , 'cxx' , 'cyc' , 'm' ] ) ;", "del_tokens": "} ) , [ 'c' , 'cc' , 'cpp' , 'cxx' , 'cyc' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "example", "in", "docs", "."], "add_tokens": "* createjs . Tween . get ( target ) . to ( { guide : { path : [ 0 , 0 , 0 , 200 , 200 , 200 , 200 , 0 , 0 , 0 ] } } , 7000 ) ;", "del_tokens": "* Tween . get ( target ) . to ( { guide : { path : [ 0 , 0 , 0 , 200 , 200 , 200 , 200 , 0 , 0 , 0 ] } } , 7000 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "initDir", "call", "in", "update", "command"], "add_tokens": "install . initDir ( opt , function ( err , opt , cfg ) {", "del_tokens": "install . initDir ( '.' , opt , function ( err , opt , cfg ) {", "commit_type": "fix"}
{"commit_tokens": ["Change", "calling", "conventions", "for", "route", "creation"], "add_tokens": "module . exports = Route ;", "del_tokens": "module . exports = { Route : Route } ;", "commit_type": "change"}
{"commit_tokens": ["fix", "browser", "build", "simplify", "docs", "cleanup"], "add_tokens": "/* globals javascriptBarcodeReader */ javascriptBarcodeReader ( img , { barcode : type , type : subType , } ) . then ( code => { console . log ( ` ${ code } ` ) alert ( ` ${ code } ` ) // eslint-disable-line } )", "del_tokens": "const barcodeDecoder = require ( '../src' ) const res = barcodeDecoder ( img , { barcode : type , type : subType } ) // only one iteration when dev mode if ( process && process . env . NODE_ENV === 'development' ) { console . log ( res ) } else { // eslint-disable-next-line alert ( res ) }", "commit_type": "fix"}
{"commit_tokens": ["Added", "qunit", "test", "suite", "."], "add_tokens": "me . report . passed ( driver . sessionID , success , function ( ) { done ( success ) ; } ) ; me . report . passed ( driver . sessionID , success , function ( ) { done ( success ) ; } ) ;", "del_tokens": "me . report . passed ( browser . sessionID , status , function ( ) { } ) ; done ( success ) ; done ( success ) ;", "commit_type": "add"}
{"commit_tokens": ["improve", "error", "message", "when", "flow", "can", "t", "complete", "list", "the", "non", "-", "started", "remaining", "tasks"], "add_tokens": "var NO_TASKS_RUNNING_WONT_COMPLETE = 'no tasks running, flow will not complete, remaining tasks: %s' ; if ( ! tasksRunning . length ) { var remainingTasks = tasks . filter ( function ( t ) { return ( ! t . status ) ; } ) ; var remainingTNames = remainingTasks . map ( function ( t ) { return t . name ; } ) ; var errMsg = sprintf ( NO_TASKS_RUNNING_WONT_COMPLETE , remainingTNames . join ( ', ' ) ) ; handleError ( { } , new Error ( errMsg ) ) ; }", "del_tokens": "var NO_TASKS_RUNNING_WONT_COMPLETE = 'no tasks running, flow will not complete' ; if ( ! tasksRunning . length ) handleError ( { } , new Error ( NO_TASKS_RUNNING_WONT_COMPLETE ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["fix", "failing", "test", "and", "clean", "up"], "add_tokens": "if ( attrs . load ) { controller . inUpdateCycle = false ; if ( ! angular . isUndefined ( attrs . center ) || ! angular . isUndefined ( attrs . zoom ) ) { if ( controller . inUpdateCycle ) { controller . inUpdateCycle = true ; controller . inUpdateCycle = false ; if ( controller . inUpdateCycle ) { controller . inUpdateCycle = true ; controller . inUpdateCycle = false ; controller : function ( $attrs ) {", "del_tokens": "if ( controller . load ) { scope . inUpdateCycle = false ; if ( ! angular . isUndefined ( controller . center ) || ! angular . isUndefined ( controller . zoom ) ) { if ( scope . inUpdateCycle ) { scope . inUpdateCycle = true ; scope . inUpdateCycle = false ; if ( scope . inUpdateCycle ) { scope . inUpdateCycle = true ; scope . inUpdateCycle = false ; controller : function ( /*$scope, $element, */ $attrs ) {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "test", "for", "error", "in", "statObject"], "add_tokens": "it ( 'should pass error to callback' , ( done ) => { Nock ( 'http://localhost:9000' ) . head ( '/bucket/object' ) . reply ( 400 , generateError ( 'status' , 'message' , 'requestid' , 'resource' ) ) client . statObject ( 'bucket' , 'object' , checkError ( 'status' , 'message' , 'requestid' , 'resource' , ( r ) => { Assert . equal ( r , null ) done ( ) } ) )", "del_tokens": "it . skip ( 'should pass error to callback' , ( done ) => {", "commit_type": "add"}
{"commit_tokens": ["Add", "notice", "to", "gfm", ".", "js"], "add_tokens": "// NOTE: This has been modified from the original version to remove linking GitHub-only references, like references to issues using #X.", "del_tokens": "// CodeMirror, copyright (c) by Marijn Haverbeke and others // Distributed under an MIT license: http://codemirror.net/LICENSE", "commit_type": "add"}
{"commit_tokens": ["Make", "tests", "more", "self", "-", "contained", "and", "fleshed", "out"], "add_tokens": "cd ( 'tests' ) ; ls ( \"*.elm\" ) . forEach ( function ( testToRun ) { if ( / Passing\\.elm$ / . test ( testToRun ) ) { echo ( \"### Testing \" + testToRun ) ; assertTestSuccess ( testToRun ) ; } else if ( / Failing\\.elm$ / . test ( testToRun ) ) { echo ( \"### Testing \" + testToRun ) ; assertTestFailure ( testToRun ) ; } else { echo ( \"Tried to run \" + testToRun + \" but it has an invalid filename; node-test-runner tests should fit the pattern \\\"*Passing.elm\\\" or \\\"*Failing.elm\\\"\" ) ; process . exit ( 1 ) ; } } ) ; cd ( '..' ) ;", "del_tokens": "echo ( filename + ': Testing examples...' ) ; cd ( 'examples/tests' ) ; echo ( \"### Testing FailingTests.elm ###\" ) ; assertTestSuccess ( 'PassingTests.elm' ) ; echo ( \"### Testing FailingTests.elm ###\" ) ; assertTestFailure ( 'FailingTests.elm' ) ; echo ( \"### Testing TodoTests.elm ###\" ) ; assertTestFailure ( 'TodoTests.elm' ) ; cd ( '../..' ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "bad", "previous", "improvement", "by", "me"], "add_tokens": "this . options . onAfterViewLoad . call ( this , this . options . view ) ;", "del_tokens": "this . options . onAfterViewLoad ( this . options . view ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", ":", "Map", "-", "Bad", "null", "value", "handling", "in", "data"], "add_tokens": "it ( 'handles shitty data 4' , function ( ) { var data = { a : 1 , b : null } ; var schema = { a : 'b' } ; expect ( PotatoMasher . map ( data , schema , { keep : true , removeChanged : true } ) ) . to . deep . equal ( { a : null } ) ; } ) ; var schema = [ { a : 'a.2' , b : 'a.0' } ] ; . equal ( [ [ 1 , 3 , 4 , 5 ] , 42 , { a : 4 , b : 1 } ] ) ;", "del_tokens": "var schema = [ { a : 'a.2' , b : 'a.0' } ] ; . equal ( [ [ 1 , 3 , 4 , 5 ] , 42 , { a : 4 , b : 1 } ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "allow", "calling", "the", "constructor", "without", "a", "source", "."], "add_tokens": "let player = null ; let open = false ; if ( source ) { player = spawnPlayer ( source , output ) ; open = true ; }", "del_tokens": "let player = spawnPlayer ( source , output ) ; let open = true ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "before", "()", ".", "Change", "testTape", "to", "test"], "add_tokens": "import test from 'tape' ;", "del_tokens": "import tapeTest from 'tape' ; const before = ( ) => { } ; const test = ( title , cb ) => { tapeTest ( title , ( ... args ) => { before ( ) ; cb ( ... args ) ; } ) ; } ;", "commit_type": "remove"}
{"commit_tokens": ["add", "event", "to", "close", "in", "dialog"], "add_tokens": "'click .cancel' : '_cancel' , 'click .close' : '_cancel'", "del_tokens": "'click .cancel' : '_cancel'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "standalone", "player", "without", "XMView", "hung", "in", "an", "infinite", "loop"], "add_tokens": "offset += tickduration ; player . cur_ticksamp += tickduration ; buflen -= tickduration ;", "del_tokens": "offset += tickduration ; player . cur_ticksamp += tickduration ; buflen -= tickduration ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "bug", "in", "deepEqual", "that", "was", "failing", "if", "empty", "array", "was", "compared", "to", "non", "-", "empty", "one", "."], "add_tokens": "return utils . isArray ( a ) && utils . isArray ( b ) && a . length === b . length &&", "del_tokens": "return utils . isArray ( a ) && utils . isArray ( b ) &&", "commit_type": "fix"}
{"commit_tokens": ["remove", "the", "break", "condition", "of", "styles", "transform", "process"], "add_tokens": "style . push ( this$1 . css [ v ] ) ; *", "del_tokens": "if ( typeof this$1 . css [ v ] === 'number' ) { style . push ( this$1 . css [ v ] ) ; } *", "commit_type": "remove"}
{"commit_tokens": ["remove", "reliance", "on", "second", "controller"], "add_tokens": "var bookRouteHandler = bookController . read ( { bookRouteHandler ( req ) ; var bookRouteHandler = bookController . read ( { bookRouteHandler ( { params : { } } ) ; var bookRouteHandler = bookController . read ( { bookRouteHandler ( req ) ; var bookRouteHandler = bookController . read ( { bookRouteHandler ( req ) ; var bookRouteHandler = bookController . read ( { bookRouteHandler ( req ) ; var bookRouteHandler = bookController . read ( { bookRouteHandler ( req ) ;", "del_tokens": "const authorController = require ( '../../../../../fixtures/controllers/authors' ) ; var authorRouteHandler = authorController . read ( { authorRouteHandler ( req ) ; var authorRouteHandler = authorController . read ( { authorRouteHandler ( { params : { } } ) ; var authorRouteHandler = authorController . read ( { authorRouteHandler ( req ) ; var authorRouteHandler = authorController . read ( { authorRouteHandler ( req ) ; var authorRouteHandler = authorController . read ( { authorRouteHandler ( req ) ; var authorRouteHandler = authorController . read ( { authorRouteHandler ( req ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "failed", "tests", "summary", "a", "bit", "more", "concise", "."], "add_tokens": "console . error ( 'Failed:' , JSON . stringify ( results . failed , null , 2 ) ) ;", "del_tokens": "console . error ( 'Failed tests:' , JSON . stringify ( results . failed , null , 2 ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "ref", "()", "helper", "for", "Struct", "instances", "."], "add_tokens": "this . ref = function ref ( ) { return this . __wrappedPointer__ ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "error", ".", "clear", "property", "writeable", "in", "case", "error", "is", "reprocessed"], "add_tokens": "writable : true ,", "del_tokens": "} else { value . isInitializer = true", "commit_type": "make"}
{"commit_tokens": ["Improve", "error", "handling", "on", "publish", "."], "add_tokens": "// TODO: This option appears to have no effect. Investigate why. this . _exchange . publish ( topic , msg , options , function ( hadError , err ) { err = err || new Error ( 'Failed to publish message to topic \"' + topic + '\"' ) ; return cb ( err ) ; return cb ( ) ;", "del_tokens": "// TODO: This option appears to have no effect. Why? this . _exchange . publish ( topic , msg , options , function ( hadError ) { var err ; err = new Error ( 'Failed to publish message to topic \"' + topic + '\"' ) ; return cb ( err ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "new", "parameter", "for", "configuring", "gridline", "-", "intervals", "."], "add_tokens": "gridlineInterval : [ Function , Number ] , } , handleGridlineInterval ( ) { const { gridlineInterval } = this if ( typeof gridlineInterval === 'number' ) { return function ( i ) { return i % gridlineInterval === 0 } } if ( isFn ( gridlineInterval ) ) { return gridlineInterval } this . gridline && points . reduce ( ( all , p , i ) => { if ( ! this . handleGridlineInterval || this . handleGridlineInterval ( i ) ) { all . push ( h ( 'line' , { } ) ) } return all } , [ ] )", "del_tokens": "this . gridline && points . map ( ( p , i ) => h ( 'line' , { } ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "index", "shown", "on", "console"], "add_tokens": "i = 0 , length = fail [ LENGTH ] ; log ( \" \" + ( ++ i ) + \". \" + fail [ i - 1 ] ) // just to add a bit of sugar return result ;", "del_tokens": "i = 0 , length = fail . length ; log ( \" \" + ( ++ i ) + \". \" + fail [ i ] )", "commit_type": "fix"}
{"commit_tokens": ["use", "JSON5", "for", "relaxed", "json", "handling"], "add_tokens": "var JSON5 = require ( 'json5' ) ; if ( \"string\" == typeof ( chunk ) ) { chunk = JSON5 . parse ( chunk ) || { } ; } // auto json parse if ( \"string\" == typeof ( chunk ) ) { chunk = JSON5 . parse ( chunk ) || { } ; } // auto json parse", "del_tokens": "if ( \"string\" == typeof ( chunk ) ) { chunk = JSON . parse ( chunk ) || { } ; } // auto json parse if ( \"string\" == typeof ( chunk ) ) { chunk = JSON . parse ( chunk ) || { } ; } // auto json parse", "commit_type": "use"}
{"commit_tokens": ["add", "a", "flow", "after", "upload", "file", "success"], "add_tokens": "owner . request ( 'after-send-file' , [ file , ret , headers ] , function ( ) { file . setStatus ( Status . COMPLETE ) ; owner . trigger ( 'uploadComplete' , file ) ; tr . destroy ( ) ; } ) . fail ( function ( reason ) { tr . trigger ( 'error' , reason ) ; } ) ;", "del_tokens": "file . setStatus ( Status . COMPLETE ) ; owner . trigger ( 'uploadComplete' , file ) ; tr . destroy ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "a", "few", "case", "sensitive", "issue", "with", "running", "perfcascade", "on", "a", "Linux", ".", "Mac", "OS", "X", "is", "case", "insensitive", "by", "default", "with", "it", "s", "file", "system", "."], "add_tokens": "/*PerfCascade build:08/03/2016 */ // maybe we could finetune these numbers if ( matches . authority . length > 17 ) { return matches . authority . substr ( 0 , 17 ) + \"...\" + p [ p . length - 1 ] . substr ( - 15 ) ; } return matches . authority + \"...\" + p [ p . length - 1 ] . substr ( - 15 ) ; //Add create and add warnings return entry [ name ] || entry [ \"_\" + name ] || entry . request [ name ] || entry . request [ \"_\" + name ] || \"\" ; \"Browser Priority\" : getExp ( \"priority\" ) || getExp ( \"initialPriority\" ) ,", "del_tokens": "/*PerfCascade build:21/02/2016 */ return matches . authority + \"/\" + p p . l e ngth - 1 ; //Add create and add warnings return entry [ name ] || entry [ \"_\" + name ] || \"\" ; \"Browser Priority\" : getExp ( \"priority\" ) ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "Content", "-", "Type", "header", "configurable", "."], "add_tokens": "var resolve = resolvers [ options . resolve || 'amd' ] ( { baseDir : root } ) , mime = options . mime || 'text/javascript' ; res . setHeader ( 'Content-Type' , mime ) ;", "del_tokens": "var resolve = resolvers [ options . resolve || 'amd' ] ( { baseDir : root } ) ; res . setHeader ( 'Content-Type' , 'application/javascript' ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "progress", "bar", "indicating", "the", "download", "status"], "add_tokens": "var progress = require ( 'progress' ) ; // one progressbar for all downloads var bar ; clearProgressbar : function ( ) { bar && bar . terminate ( ) ; bar = null ; } , rq = request ( url ) , len , stream ; function format ( statusCode ) { return statusCode + ': ' + require ( 'http' ) . STATUS_CODES [ statusCode ] ; } bar && bar . terminate ( ) ; len = parseInt ( res . headers [ 'content-length' ] , 10 ) ; msg : 'Recieved status code ' + format ( res . statusCode ) } else if ( len ) { if ( ! bar ) { bar = new progress ( ' downloading [:bar] :percent :etas' , { complete : '=' , incomplete : '-' , width : 20 , total : len } ) ; } else { bar . total += len ; } rq . on ( 'data' , function ( chunk ) { len && bar && bar . tick ( chunk . length ) ; } ) ;", "del_tokens": "stream , rq = request ( url ) ; msg : \"Recieved status code \" + format ( res . statusCode ) return ; } function format ( statusCode ) { return statusCode + \": \" + require ( \"http\" ) . STATUS_CODES [ statusCode ]", "commit_type": "add"}
{"commit_tokens": ["Removing", "guaranteed", "-", "superfluous", "check", "."], "add_tokens": "var level = this . config . messageLevel ;", "del_tokens": "var level = this . config . messageLevel || 'log' ;", "commit_type": "remove"}
{"commit_tokens": ["update", "the", "match", "method", "to", "give", "precedence", "to", "regular", "fragments"], "add_tokens": "// Check that if this fragment is a namedParam, // we never override a regular fragment. if ( ! this . isNamedParam ( key ) || ! action . method ) { if ( isString ( value ) ) { action . method = value ; } else { action . method = value . method ; this . mergeOptions ( value . options ) ; } this . actions . push ( action ) ; } else if ( fragment === '/*' ) { else if ( this . isNamedParam ( fragment ) ) { return ( uri !== '/' && uri !== '' ) ; } } , / ** @ method isNamedParam @ param { String } fragment @ return { Boolean } ** / isNamedParam : function ( fragment ) { return fragment . indexOf ( '/:' ) === 0 ;", "del_tokens": "if ( isString ( value ) ) { action . method = value ; } else { action . method = value . method ; this . mergeOptions ( value . options ) ; } this . actions . push ( action ) ; prefix = fragment . substr ( 0 , 2 ) , else if ( fragment === '/*' || prefix === '/:' ) {", "commit_type": "update"}
{"commit_tokens": ["Created", "Flow", "elements", "Action", "Decision", "Reply"], "add_tokens": "uuid = require ( 'node-uuid' ) , Flow = require ( './flow/Flow' ) , Action = require ( './flow/Action' ) , Reply = require ( './flow/Reply' ) , Decision = require ( './flow/Decision' ) ;", "del_tokens": "uuid = require ( 'node-uuid' ) ;", "commit_type": "create"}
{"commit_tokens": ["Add", "custom", ".", "count", "()", "method", "for", "optimized", "record", "counting", "."], "add_tokens": "* Find all records matching provided criteria . / ** * Count * * Count records matching provided criteria . This function * is memory optimized version of find . * * @ param { String } connectionName * @ param { String } collectionName * @ param { Object } options * @ param { Function } callback * / count : function ( connectionName , collectionName , options , cb ) { options = options || { } ; var connectionObject = connections [ connectionName ] ; var collection = connectionObject . collections [ collectionName ] ; // Find all matching documents collection . count ( options , function ( err , recordCount ) { if ( err ) return cb ( err ) ; cb ( null , recordCount ) ; } ) ; } ,", "del_tokens": "* Find all matching documents in a colletion .", "commit_type": "add"}
{"commit_tokens": ["Implemented", "close", "and", "improved", "the", "tests", "with", "it"], "add_tokens": "var multiaddr = options . multiaddr if ( multiaddr ) { // no need to pass that to the transports delete options . multiaddr } if ( multiaddr ) { self . peerInfo . multiaddrs . push ( multiaddr ) // Iterates all the listeners closing them // one by one. It calls back once all are closed. self . closeAllListeners = function ( callback ) { var transportNames = Object . keys ( self . transports ) async . each ( transportNames , self . closeListener , callback ) } // Closes both transport listeners and // connections. It calls back once everything // is closed async . parallel ( [ self . closeAllListeners , self . closeConns ] , callback )", "del_tokens": "if ( options . multiaddr ) { self . peerInfo . multiaddrs . push ( options . multiaddr ) // close everything", "commit_type": "implement"}
{"commit_tokens": ["Use", "a", "more", "generic", "REPL", "prompt"], "add_tokens": "'prompt' : ' >>> '", "del_tokens": "'prompt' : 'chrome> ' ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "logLevel", "for", "incorrect", "dimensions", "."], "add_tokens": "throw log ( options . logLevel , 'lv1' , [ 'Lazysprite:' , gutil . colors . red ( path . relative ( process . cwd ( ) , image . path ) ) , '`2x` image should have' + throw log ( options . logLevel , 'lv1' , [ 'Lazysprite:' , gutil . colors . red ( path . relative ( process . cwd ( ) , image . path ) ) , '`3x` image should have' +", "del_tokens": "throw log ( options . logLevel , 'lv3' , [ 'Lazysprite:' , gutil . colors . red ( path . relative ( process . cwd ( ) , image . path ) ) , '`2x` image should have' + throw log ( options . logLevel , 'lv3' , [ 'Lazysprite:' , gutil . colors . red ( path . relative ( process . cwd ( ) , image . path ) ) , '`3x` image should have' +", "commit_type": "fix"}
{"commit_tokens": ["Adds", "tests", "for", "resource", "collections", "spec"], "add_tokens": "var string = \"Pretender: non-existing \" + verb + \" \" + path , request console . error ( string ) ; throw ( string ) ;", "del_tokens": "console . log ( \"Pretender: non-existing \" + verb + \" \" + path , request ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "send", "code", "to", "the", "client", "from", "outside", "a", "view", "also", "fixed", "executing", "those", "script", "blocks", "."], "add_tokens": "} ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "with", "Xenon", "firmware"], "add_tokens": "// start over, test for Mesh modular firmware which has a different offset than Photon/Electron modular firmware", "del_tokens": "// start over, test for Core monolithic firmware which has a different offset than modular firmware", "commit_type": "add"}
{"commit_tokens": ["Removing", "root", "Pathitem", "was", "not", "worth", "doing", "as", "it", "caused", "lots", "of", "code", "complexity"], "add_tokens": "return makeAsync ( SyncLocalStorage , 1 ) ;", "del_tokens": "return makeAsync ( SyncLocalStorage , 0 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "docket", "parser", "version", "to", "fix", "bootstrap", "vuln", "and", "fixed", "regex", "bugs"], "add_tokens": "docket . title ( ` ` ) ;", "del_tokens": "docket . title ( ` ` ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "styles", "and", "fix", "pointer", "position"], "add_tokens": "Rectangle . ofElement ( $pointer [ 0 ] , 'borders' ) ) ;", "del_tokens": "Rectangle . ofElement ( $pointer [ 0 ] ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "fastboot", "-", "fetch", ".", "js", "to", "public", "/"], "add_tokens": "updateFastBootManifest : function ( manifest ) { manifest . vendorFiles . push ( 'ember-fetch/fastboot-fetch.js' ) ;", "del_tokens": "updateFastBootManifest : function ( manifest ) { var fastbootFetchPath = path . resolve ( __dirname + '/assets/fastboot-fetch.js' ) ; manifest . vendorFiles . push ( fastbootFetchPath ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "return", "value", "of", "cache", "miss", "to", "undefined"], "add_tokens": "expect ( function ( ) { new View ( { template : \"#template\" } ) ; } ) . to . throw ( Error , \"Invalid return value. The custom loadTemplate function must return a jQuery instance\" ) ; expect ( function ( ) { new View ( { template : \"#template\" } ) ; } ) . to . throw ( Error , \"Invalid return value. The custom loadTemplate function must return a jQuery instance\" ) ;", "del_tokens": "expect ( function ( ) { new View ( { template : \"#template\" } ) ; } ) . to . throw ( Error , \"Invalid return value. Custom loadTemplate function must return a jQuery instance\" ) ; expect ( function ( ) { new View ( { template : \"#template\" } ) ; } ) . to . throw ( Error , \"Invalid return value. Custom loadTemplate function must return a jQuery instance\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "test", "for", "empty", "request", "and", "for", "path", "parsing", "on", "vanilla", "http"], "add_tokens": "expect ( req . params ) . to . deep . equal ( [ 'with' , 'path' ] ) ; } } , { mode : 'reqres' , errorHandler : err => err && done ( err ) } ) ( request , null ) ; describe ( 'Empty request' , function ( ) { function testEmptyRequest ( ) { return function ( done ) { modofun . gcloud ( { test : ( ) => { done ( new Error ( 'Should have failed!' ) ) ; } } , { errorHandler : err => { expect ( err ) . to . be . an ( 'error' ) ; done ( ) ; } } ) ( { } , { } ) ; } } it ( 'should fail and throw an error' , testEmptyRequest ( ) ) ; } ) ; done ( new Error ( 'Should have thrown exception' ) ) ;", "del_tokens": "} } , { mode : 'reqres' } ) ( request , null , err => err && done ( err ) ) ; done ( 'Should have thrown exception' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "most", "console", ".", "log"], "add_tokens": "catch ( e ) { cb ( null , os ) }", "del_tokens": "catch ( e ) { console . log ( e ) ; cb ( null , os ) }", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "syntax", "bugs", "in", "instruments", ".", "js", ".", "Fixed", "a", "bug", "in", "logging", "of", "results", "to", "console", ".", "Moved", "the", "networking", "request", "to", "a", "different", "file", "in", "preperation", "for", "future", "changes"], "add_tokens": "net = require ( 'net' ) , var tunnelingAgent ; tunnelingAgent = tunnel . httpsOverHttp ( { host : match [ 2 ] , \"agent\" : ( proxy !== null ? tunnelingAgent : false ) } if ( trackedMethod . selected === true ) }", "del_tokens": "var tunnelingAgent = tunnel . httpsOverHttp ( { host : match [ 2 ] , \"agent\" : ( proxy != null ? tunnelingAgent : false ) } if ( trackedMethod . selected === true ) }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "legacy", "code", "for", "node", "<", "4"], "add_tokens": "actualGlobals = Object . keys ( context ) ; actualGlobals = Object . keys ( context ) ;", "del_tokens": "actualGlobals = Object . keys ( context ) . filter ( function ( key ) { // node v0.10 does not set a constructor property on the context // node v0.11 does set a constructor property // so just lets filter it, because it doesn't make sense to mock it anyway return key !== \"constructor\" ; } ) ; actualGlobals = Object . keys ( context ) . filter ( function ( key ) { // node v0.10 does not set a constructor property on the context // node v0.11 does set a constructor property // so just lets filter it, because it doesn't make sense to mock it anyway return key !== \"constructor\" } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Changed", "public", "path", "to", "include", "repo", "name", "for", "gh", "-", "pages"], "add_tokens": "render ( new Worker ( '/react-worker-dom/dist/dbmonster/worker-impl.js#rows=' + ENV . rows + '&timeout=' + ENV . timeout ) , document . getElementById ( 'topLevelContainer-' + i ) ) ;", "del_tokens": "render ( new Worker ( '/dist/dbmonster/worker-impl.js#rows=' + ENV . rows + '&timeout=' + ENV . timeout ) , document . getElementById ( 'topLevelContainer-' + i ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "texture", "index", "when", "texture", "is", "shared", "by", "multiple", "material", "values"], "add_tokens": "return textureIndex ; return { index : textureIndex } ; return getTexture ( gltf , image ) ; return getTexture ( gltf , image ) ; var packOcclusion = ( defined ( occlusionImage ) && options . packOcclusion ) || defined ( options . metallicRoughnessOcclusionTexture ) ;", "del_tokens": "return { index : textureIndex } ; return textureIndex ; return addTexture ( gltf , image ) ; return addTexture ( gltf , image ) ; var packOcclusion = defined ( occlusionImage ) && options . packOcclusion || defined ( options . metallicRoughnessOcclusionTexture ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "override", "path", "for", "historyApiFallback", "option"], "add_tokens": "var fallbackPath = typeof options . historyApiFallback === 'string' ? options . historyApiFallback : '/index.html' readFileFromContentBase ( options . contentBase , fallbackPath , function ( error , content , filePath ) {", "del_tokens": "readFileFromContentBase ( options . contentBase , '/index.html' , function ( error , content , filePath ) {", "commit_type": "allow"}
{"commit_tokens": ["Add", "tests", "for", "config", "verifier", "and", "config", "parser", "and", "make", "tests", "use", "the", "dist", "files", "instead", "of", "the", "src", "files"], "add_tokens": "var verifyConfig = require ( '../dist/config-verifier.js' ) ; it ( 'rule config that\\'s not properly configured to \"on/off\"' , function ( ) { assert . deepEqual ( verifyConfig ( { 'no-files-without-scenarios' : 'o' , 'new-line-at-eof' : [ 'o' , 'yes' ] , 'indentation' : [ 'o' , { 'Feature' : 1 , 'Background' : 1 , 'Scenario' : 1 , 'Step' : 1 , 'given' : 1 , 'and' : 1 } ] } ) , [ 'Invalid rule configuration for \"no-files-without-scenarios\" - The the config should be \"on\" or \"off\"' , 'Invalid rule configuration for \"new-line-at-eof\" - The first part of the config should be \"on\" or \"off\"' , 'Invalid rule configuration for \"indentation\" - The first part of the config should be \"on\" or \"off\"' ] ) ; } ) ; it ( 'an array configuration doesn\\'t have exactly 2 parts' , function ( ) { assert . deepEqual ( verifyConfig ( { 'new-line-at-eof' : [ 'on' ] } ) , [ 'Invalid rule configuration for \"new-line-at-eof\" - The config should only have 2 parts.' ] ) ; assert . deepEqual ( verifyConfig ( { 'new-line-at-eof' : [ 'on' , 'yes' , 'p3' ] } ) , [ 'Invalid rule configuration for \"new-line-at-eof\" - The config should only have 2 parts.' ] ) ; } ) ;", "del_tokens": "var verifyConfig = require ( '../src/config-verifier.js' ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "sample", "of", "getUrl", "of", "BlobService", "and", "FileService"], "add_tokens": "* var sharedAccessPolicy = { * AccessPolicy : { * Permissions : azure . BlobUtilities . SharedAccessPermissions . READ , * Start : startDate , * Expiry : expiryDate * } , * } ; * * var sasToken = blobService . generateSharedAccessSignature ( containerName , blobName , sharedAccessPolicy ) ; * var sasUrl = blobService . getUrl ( containerName , blobName , sasToken ) ;", "del_tokens": "* //create a SAS that expires in an hour * var sasToken = blobService . generateSharedAccessSignature ( containerName , blobName , { AccessPolicy : { Expiry : azure . date . minutesFromNow ( 60 ) ; } } ) ; * var sasUrl = blobService . getUrl ( containerName , blobName , sasToken , true ) ;", "commit_type": "update"}
{"commit_tokens": ["moved", "SPM", "metric", "format", "from", "spmsender", "to", "agent", "allowing", "plugable", "format", "lines"], "add_tokens": "return ( config . get ( key ) == null ) if ( checked . length === 0 ) done ( 'missing config values: ' + checked )", "del_tokens": "return ( config . get ( key ) != null || false ) if ( cfgValue . length == checked . length ) done ( 'not all default values set ' + checked )", "commit_type": "move"}
{"commit_tokens": ["Remove", "loop", "and", "use", "next", "/", "prevEdit", "in", "getNode"], "add_tokens": "if ( ! node || ! isStatic ( node ) ) { return node ; } return node [ direction + \"Edit\" ] ;", "del_tokens": "while ( node && ( node . token . type == \"static\" || node . token . type == \"regex\" ) ) { node = node [ direction ] ; } return node ;", "commit_type": "remove"}
{"commit_tokens": ["move", "helper", "and", "gulp", "setup", "to", "constructor", ".", "Do", "not", "call", "condense", "in", "constructor", "."], "add_tokens": "this . gulp = gulp || require ( 'gulp' ) ; ; var helpers = require ( './loaders/all-helpers' ) ( { particleLoader : this . particleLoader , handlebars : this . handlebars } ) ; var gulp = this . gulp ;", "del_tokens": "this . gulp = gulp ; this . condense ( ) ; var gulp = this . gulp || require ( 'gulp' ) ; var helpers = require ( './loaders/all-helpers' ) ( { particleLoader : this . particleLoader , handlebars : this . handlebars } ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "undefined", "descriptions", "."], "add_tokens": "message : parameter . Description ? key + '. ' + parameter . Description : key ,", "del_tokens": "message : key + '. ' + parameter . Description || key ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "to", "filter", "PRs", "by", "labels"], "add_tokens": "const { assign , chain , flatMap , find , isEmpty , range } = require ( 'lodash' ) ; constructor ( { base , futureRelease , futureReleaseTag , labels , owner , repo , token } ) { this . labels = labels ; . filter ( ( { labels } ) => isEmpty ( this . labels ) || ! chain ( labels ) . map ( 'name' ) . intersection ( this . labels ) . isEmpty ( ) . value ( ) )", "del_tokens": "const { assign , chain , flatMap , find , range } = require ( 'lodash' ) ; constructor ( { base , futureRelease , futureReleaseTag , owner , repo , token } ) {", "commit_type": "add"}
{"commit_tokens": ["use", "Nan", "::", "AsyncQueueWorker", "for", "pull", "(", "will", "have", "to", "reissue", "call", "from", "js", "until", "EOS", ")"], "add_tokens": "var gstreamer = require ( \"..\" ) ; var pipeline = new gstreamer . Pipeline ( \"videotestsrc num-buffers=15 ! appsink name=sink\" ) ; var pull = function ( ) { appsink . pull ( function ( buf ) { if ( buf ) { console . log ( \"BUFFER size\" , buf . length ) ; pull ( ) ; } else { console . log ( \"NULL BUFFER\" ) ; setTimeout ( pull , 500 ) ; } } ) ; } ; pull ( ) ;", "del_tokens": "var gstreamer = require ( '..' ) ; var pipeline = new gstreamer . Pipeline ( \"videotestsrc ! appsink name=sink\" ) ; appsink . pull ( function ( buf ) { console . log ( \"BUFFER size\" , buf . length ) ; } , function ( caps ) { console . log ( \"CAPS\" , caps ) ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "frame", "event", "type", "an", "option"], "add_tokens": "opts = _ . defaults ( opts || { } , { frameEventName : this . useAnimationLoop ( ) ? 'animationFrame' : 'connectionFrame' } ) ; this . frameEventName = opts . frameEventName ; this . on ( this . frameEventName , function ( frame ) { controller . processFinishedFrame ( frame ) ; } ) ; this . on ( this . frameEventName , callback ) ; controller . once ( controller . frameEventName , immediateRunnerCallback ) ; this . once ( this . frameEventName , immediateRunnerCallback ) ; this . emit ( 'connectionFrame' , frame ) ; } Controller . prototype . processFinishedFrame = function ( frame ) { this . lastFrame = frame ; if ( frame . valid ) { this . lastValidFrame = frame ; }", "del_tokens": "this . on ( this . useAnimationLoop ( ) ? 'animationFrame' : 'frame' , callback ) ; controller . once ( controller . useAnimationLoop ( ) ? 'animationFrame' : 'frame' , immediateRunnerCallback ) ; this . once ( this . useAnimationLoop ( ) ? 'animationFrame' : 'frame' , immediateRunnerCallback ) ; this . lastFrame = frame ; if ( this . lastFrame . valid ) this . lastValidFrame = this . lastFrame ;", "commit_type": "make"}
{"commit_tokens": ["use", "npmCmd", "wrapper", "from", "context", "."], "add_tokens": "// Interval in between HTTP checks in ms var HTTP_CHECK_INTERVAL = 1000 var tsh = ctx . shellWrap ( ctx . npmCmd + \" test\" ) } , HTTP_CHECK_INTERVAL ) var saucesh = ctx . shellWrap ( ctx . npmCmd + \" run-script sauce\" ) prepare : ctx . npmCmd + \" install\" ,", "del_tokens": "var tsh = ctx . shellWrap ( \"npm test\" ) } , 1000 ) var saucesh = ctx . shellWrap ( \"npm run-script sauce\" ) prepare : \"npm install\" ,", "commit_type": "use"}
{"commit_tokens": ["remove", "isNormalized", "check", "before", "calling", ".", "config", ".", "process"], "add_tokens": "var debug = require ( 'debug' ) ( 'base:generators' ) ; debug ( 'initializing <%s>, called from <%s>' , __filename , module . parent . id ) ; if ( typeof generator . config !== 'undefined' ) { generator . option ( config ) ;", "del_tokens": "var debug = require ( 'debug' ) ( 'base:base-generators' ) ; if ( typeof generator . config !== 'undefined' && ! config . isNormalized ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "tests", "duplication", "tests", "passing"], "add_tokens": "var observe = function ( obj ) { if ( ! canReflect . isSymbolLike ( key ) && ! canReflect . isObservableLike ( value ) && canReflect . isPlainObject ( value ) ) { console . log ( key ) // observe(target[key]); } if ( change ) { module . exports = observe ;", "del_tokens": "module . exports = function ( obj ) { if ( change ) {", "commit_type": "add"}
{"commit_tokens": ["added", "base", "to", "model", "definition", "for", "extending", "models"], "add_tokens": "var util = require ( 'util' ) ; var def = null ; if ( desc . base ) { def = findDefinition ( this . definitions , desc . base ) ; if ( ! def ) { throw new Error ( util . format ( 'Unknown base model \"%s\" when define model \"%s\"' , desc . base , name ) ) ; } def = findDefinition ( this . definitions , name ) ; if ( def ) { name = def . name ; } else { desc . name = name ; } if ( def ) desc = _ . merge ( _ . cloneDeep ( def ) , desc ) ; var DEF_KEYS = [ 'name' , 'base' , 'properties' , 'fields' , 'relations' , 'settings' ] ;", "del_tokens": "var def ; def = findDefinition ( this . definitions , name ) ; if ( def ) { name = def . name ; desc = _ . merge ( _ . cloneDeep ( def ) , desc ) ; desc . name = name ; var DEF_KEYS = [ 'name' , 'properties' , 'fields' , 'relations' , 'settings' ] ;", "commit_type": "add"}
{"commit_tokens": ["Upgraded", "to", "an", "even", "better", "modularized", "way!"], "add_tokens": "module . exports = { augment : require ( './lib/augment.js' ) , setup : require ( './lib/setup.js' ) } ;", "del_tokens": "process . DIRNAME = __dirname ; module . exports = require ( './lib/f_.js' ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "a", "minified", "version", "of", "the", "build", "for", "browsers", "."], "add_tokens": "grunt . loadNpmTasks ( \"grunt-contrib-uglify\" ) ; cwd : \"./src/\" , src : \"./**/*.js\" , dest : \"./build/\" position : \"top\" , } , uglify : { build : { files : { \"build/toposort.min.js\" : \"build/toposort.js\" } } grunt . registerTask ( \"build\" , [ \"clean:build\" , \"babel:build\" , \"usebanner:license\" , \"uglify:build\" ] ) ;", "del_tokens": "cwd : \"./src/\" , src : \"./**/*.js\" , dest : \"./build/\" position : \"top\" , grunt . registerTask ( \"build\" , [ \"clean:build\" , \"babel:build\" , \"usebanner:license\" ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "relative", "path", "issue", "with", "Windows", "system"], "add_tokens": ". then ( function ( address ) { var fromRelativeSource = isPath ? process . cwd ( ) : file . base ; // take first path from gulp location or current file var originalRelativePath = path . relative ( fromRelativeSource , path . resolve ( address . replace ( 'file:' , '' ) . replace ( '.js' , '' ) ) ) ; var originalRelativePathArray = originalRelativePath . split ( path . sep ) ; var posixRelativePath = path . posix . join . apply ( this , originalRelativePathArray ) ; posixRelativePath replacements [ i ] = posixRelativePath ;", "del_tokens": ". then ( function ( address ) { address . replace ( 'file:' , '' ) . replace ( '.js' , '' ) replacements [ i ] = path . relative ( file . base , address . replace ( 'file:' , '' ) . replace ( '.js' , '' ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["made", "fontResize", "accept", "an", "accessor", "function"], "add_tokens": "fontResize = constant ( false ) , const resize = fontResize ( d , i ) ; box . fontResize = function ( _ ) { return arguments . length ? ( fontResize = typeof _ === \"function\" ? _ : constant ( _ ) , box ) : fontResize ; } ;", "del_tokens": "resize = false , box . resize = function ( _ ) { return arguments . length ? ( resize = _ , box ) : resize ; } ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "<bot", ">", "tag", "matching", "in", "triggers"], "add_tokens": "regexp = regexp . replace ( new RegExp ( \"<bot \" + this . quotemeta ( name ) + \">\" ) , rep . toLowerCase ( ) ) ;", "del_tokens": "regexp = regexp . replace ( new RegExp ( \"<bot \" + this . quotemeta ( name ) + \">\" ) , rep ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "own", "fixed", "module", "instead", "of", "the", "original", "one"], "add_tokens": "const createMDNSServer = require ( \"@alcalzone/mdns-server\" ) ;", "del_tokens": "const createMDNSServer = require ( \"mdns-server\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Implement", "Promise", ".", "any", "method"], "add_tokens": "* @ version 0.0 .11 Promise . any = function ( promises ) { var resPromise = new this ( ) , len = promises . length ; if ( len ) { var i = 0 , error , onFulfilled = function ( val ) { resPromise . fulfill ( val ) ; } , onRejected = function ( _error ) { i || ( error = _error ) ; if ( ++ i === len ) { resPromise . reject ( error ) ; } } ; this . forEach ( promises , onFulfilled , onRejected ) ; } else { resPromise . reject ( Error ( ) ) ; } return resPromise ; } ; resPromise . reject ( Error ( 'timed out' ) ) ;", "del_tokens": "* @ version 0.0 .10 resPromise . reject ( new Error ( 'timed out' ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "new", "method", "for", "business", "systems", "API", "endpoint"], "add_tokens": "/ ** / ** * Retrieves all of the app user ' * @ memberof AppUsersApi . prototype * @ method getBusinessSystems * @ param { string } userId - a user id * @ return { APIResponse } * / getBusinessSystems : smoochMethod ( { params : [ 'userId' ] , path : '/appusers/:userId/businesssystems' , method : 'GET' } ) , if ( ! userId || ! userId . trim ( ) ) { return Promise . reject ( new Error ( 'Must provide a userId.' ) ) ; } // this endpoint only accepts JWT auth with app scope return this . request ( 'DELETE' , url , { } , { allowedAuth : [ 'jwt' ] } ) ; }", "del_tokens": "/ ** if ( ! userId || ! userId . trim ( ) ) { return Promise . reject ( new Error ( 'Must provide a userId.' ) ) ; } // this endpoint only accepts JWT auth with app scope return this . request ( 'DELETE' , url , { } , { allowedAuth : [ 'jwt' ] } ) ; }", "commit_type": "add"}
{"commit_tokens": ["Improve", "error", "message", "for", "disconnected", "write", "attempts"], "add_tokens": "throw new Error ( 'Cannot write when disconnected. ' + 'Check `client.connected` before calling `client.write()`.' )", "del_tokens": "throw new Error ( 'Cannot write when disconnected.' )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "issue", "with", "code", "inside", "attribute", "value"], "add_tokens": "parts . push ( readSimpleToken ( 'ejs-eval' , ejsEndRegex ) )", "del_tokens": "tokens . push ( readSimpleToken ( 'ejs-eval' , ejsEndRegex ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", ".", "initial"], "add_tokens": "import { isArray , isFunction , isPromise , isMap , isWeakMap , mapSet } from '../helpers/types' ; useMap = p . initial && ( isMap ( p . initial ) || isWeakMap ( p . initial ) ) || p . useMap || p . useMap == null && mapSet [ p . type ] , res = p . result = p . initial || ( useMap ? new Map ( ) : Object . create ( null ) ) ;", "del_tokens": "import { isArray , isFunction , isPromise , mapSet } from '../helpers/types' ; useMap = p . useMap || p . useMap == null && mapSet [ p . type ] , res = p . result = useMap ? new Map ( ) : Object . create ( null ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "an", "ANSI", "colored", "prompt", "for", "the", "REPL"], "add_tokens": "'prompt' : '\\033[32m>>>\\033[0m ' ,", "del_tokens": "'prompt' : ' >>> '", "commit_type": "use"}
{"commit_tokens": ["Add", "protocols", "to", "OPENSRC", "-", "44", "verification"], "add_tokens": "id : urn . split ( ':' ) . slice ( - 1 ) [ 0 ] var allowedProtocols = [ 'pbk:ec:secp256r1' , 'pbk:rsa:2048' , 'ble:1\\.0' , 'nfc:1\\.0' , 'sn' ] ; var allowedProtocolsRegExp = new RegExp ( '^' + allowedProtocols . join ( ':[^:]+|^' ) + ':[^:]+' ) ; if ( ! urn . match ( allowedProtocolsRegExp ) || ! urn . match ( / ^([^:]+:)+[^:]+$ / ) ) {", "del_tokens": "id : urn . split ( ':' ) [ urn . split ( ':' ) . length - 1 ] if ( ! urn . match ( / ^([^:]+:)+[^:]+$ / ) ) {", "commit_type": "add"}
{"commit_tokens": ["Moved", "around", "some", "files", "and", "more", "testing"], "add_tokens": "matches : { args : [ 'RegExp' ] , returnType : 'boolean' } , // one hiccup: is this a regular expression literal? esparse does not help with this // we need to check the raw value to find out if ( / ^\\/.+\\/[igm]?$ / . test ( node . raw ) ) { // regular expression. construct it. if ( 'igm' . indexOf ( node . raw . slice ( - 1 ) ) !== - 1 ) { // we have a modifier letter node . value = new RegExp ( node . raw . slice ( 1 , - 2 ) , node . raw . slice ( - 1 ) ) ; } else { node . value = new RegExp ( node . raw . slice ( 1 , - 1 ) ) ; } node . inferredType = 'RegExp' ; } else if ( node . value === undefined ) { } else {", "del_tokens": "if ( node . value === undefined ) { } else if ( node . value !== null ) {", "commit_type": "move"}
{"commit_tokens": ["Added", "more", "complete", "tests", "for", "globals", "to", "the", "noolsParser", "tests", ".", "Fixed", "the", "spacing", "issue", "uncovered", "by", "the", "test", "in", "the", "body", "of", "the", "scope", "generated", "by", "the", "parser", "."], "add_tokens": "body = body . replace ( / ^\\s+|\\s+$ / g , '' ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["made", "error", "handing", "error", "safe"], "add_tokens": "var errorHandled = Symbol ( ) , boundObject = Symbol ( ) , try { if ( ! ( errorHandled in err ) ) { err . type = \"route\" ; err . location = position ; err [ errorHandled ] = true ; } } finally { throw err ; try { if ( ! ( errorHandled in err ) ) { err . type = \"close\" ; err . location = this [ position ] ; err . data = data ; err [ errorHandled ] = true ; } } finally { throw err ;", "del_tokens": "var boundObject = Symbol ( ) , if ( typeof err === \"object\" && ! err . location ) { err . type = \"route\" ; err . location = position ; throw err ; if ( typeof err === \"object\" && ! err . location ) { err . type = \"close\" ; err . location = this [ position ] ; err . data = data ; throw err ;", "commit_type": "make"}
{"commit_tokens": ["Make", "stringify", "()", "put", "spaces", "between", "different", "levels", "of", "sections"], "add_tokens": "lastBlock = null , if ( lastBlock && lastBlock . type === 'section' && lastBlock . level !== block . level ) { newSource += '\\n' } lastBlock = block if ( block . type === 'section' ) { block . children . forEach ( stringify ) }", "del_tokens": "block . children . forEach ( stringify )", "commit_type": "make"}
{"commit_tokens": ["Add", "new", "ssl", "certs", "to", "handle", "upcoming", "expiration"], "add_tokens": "var knownCerts = [ \"instrumental.2018-08-19\" , \"instrumental\" ] ; var certExpiration = certName . split ( \".\" ) [ 1 ] ; certExpiration = certExpiration && new Date ( Date . parse ( certExpiration ) ) ; if ( ! certExpiration || ( new Date ( ) < certExpiration ) ) { log ( \"Loading cert bundle: \" + certName ) ; var certPath = path . join ( certDir , certName + \".ca.pem\" ) ; caChain . push ( fs . readFileSync ( certPath ) ) ; }", "del_tokens": "var knownCerts = [ \"equifax\" , \"geotrust\" , \"rapidssl\" ] ; var certPath = path . join ( certDir , certName + \".ca.pem\" ) ; caChain . push ( fs . readFileSync ( certPath ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "choose", "which", "detection", "strategy", "to", "use", ".", "Added", "onReady", "option", "callback", "to", "be", "called", "when", "all", "elements", "of", "the", "listenTo", "are", "ready", "."], "add_tokens": "var batchUpdater = getOption ( options , \"batchUpdater\" , batchUpdaterMaker ( { reporter : reporter } ) ) ; var detectionStrategy ; var desiredStrategy = getOption ( options , \"strategy\" , \"object\" ) ; var strategyOptions = { } ; if ( desiredStrategy === \"scroll\" ) { detectionStrategy = scrollStrategyMaker ( strategyOptions ) ; } else if ( desiredStrategy === \"object\" ) { detectionStrategy = objectStrategyMaker ( strategyOptions ) ; } else { throw new Error ( \"Invalid strategy name: \" + desiredStrategy ) ; } var elementsReady = 0 ; var onReadyCallback = getOption ( options , \"onReady\" , function noop ( ) { } ) ; elementsReady ++ ; if ( elementsReady === elements . length ) { onReadyCallback ( ) ; } elementsReady ++ ; if ( elementsReady === elements . length ) { onReadyCallback ( ) ; }", "del_tokens": "var batchUpdater = getOption ( options , \"batchUpdater\" , batchUpdaterMaker ( { reporter : reporter } ) ) ; var detectionStrategy = scrollStrategyMaker ( { } ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "types", "and", "internal", "-", "only", "links", "of", "pluralrules", ".", "js"], "add_tokens": "* This file is auto - generated . * @ enum { string }", "del_tokens": "* This file is autogenerated by script : * http : //go/generate_pluralrules.py * using the -- for_closure flag . * enum { string }", "commit_type": "fix"}
{"commit_tokens": ["Adding", "new", "script", "for", "automated", "HRIR", "set", "generation"], "add_tokens": "module . exports = '0.9.3' ;", "del_tokens": "module . exports = '0.9.2' ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "plain", "non", "-", "number", "-", "prefixed", "Material", "colors"], "add_tokens": "\"red\" : \"#F44336\" , \"pink\" : \"#E91E63\" , \"purple\" : \"#9C27B0\" , \"deepPurple\" : \"#673AB7\" , \"indigo\" : \"#3F51B5\" , \"blue\" : \"#2196F3\" , \"lightBlue\" : \"#03A9F4\" , \"cyan\" : \"#00BCD4\" , \"teal\" : \"#009688\" , \"green\" : \"#4CAF50\" , \"lightGreen\" : \"#8BC34A\" , \"lime\" : \"#CDDC39\" , \"yellow\" : \"#FFEB3B\" , \"amber\" : \"#FFC107\" , \"orange\" : \"#FF9800\" , \"deepOrange\" : \"#FF5722\" , \"brown\" : \"#795548\" , \"grey\" : \"#9E9E9E\" , \"blueGrey\" : \"#607D8B\" , \"fuchsia\" : \"#D500F9\" , \"gray\" : \"#AAAAAA\"", "del_tokens": "\"blue\" : \"#2196F3\" , \"lime\" : \"#CDDC39\" , \"teal\" : \"#009688\" , \"green\" : \"#4CAF50\" , \"red\" : \"#F44336\" , \"orange\" : \"#FF9800\" , \"purple\" : \"#9C27B0\" , \"yellow\" : \"#FFEB3B\" , \"gray\" : \"#9E9E9E\" , \"fuchsia\" : \"#D500F9\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "module", "definition", "pattern", "for", "IE8"], "add_tokens": "root [ name ] = had ? prev : undefined ; if ( ! had ) { try { delete root [ name ] ; } catch ( ex ) { } atom . VERSION = '0.2.2' ;", "del_tokens": "delete root [ name ] ; if ( had ) { root [ name ] = prev ; atom . VERSION = '0.2.1' ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "few", "new", "line", "tests"], "add_tokens": "'side by side new line characters' ) ; input = 'One word per line\\njust\\nlike\\nthis' ; t . deepEqual ( format . lines ( input , { width : 80 , filler : '' , ansi : false } ) , [ 'One word per line' , 'just' , 'like' , 'this' ] , 'one word between new line characters' ) ; input = 'Space before \\nnew line' ; t . deepEqual ( format . lines ( input , { width : 80 , filler : '' , ansi : false } ) , [ 'Space before ' , 'new line' ] , 'space before new line'", "del_tokens": "'new line characters'", "commit_type": "add"}
{"commit_tokens": ["Removing", "an", "unnecessary", "done", "and", "adding", "a", "stub", "of"], "add_tokens": "describe ( 'Testing mongoMapper.' , function ( ) {", "del_tokens": "describe ( 'Testing mongoMapper.' , function ( done ) {", "commit_type": "remove"}
{"commit_tokens": ["added", "loop", "and", "reduce", "function"], "add_tokens": "if ( typeof func !== 'function' ) {", "del_tokens": "if ( typeof func !== 'function' ) {", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "the", "history", ".", "js", "for", "older", "browsers", "add", "a", "function", "to", "remove", "functions", "from", "the", "payload", "object", "for", "the", "history", "API"], "add_tokens": "/ ** * Remove functions from an object ( in - place ) * * @ author Jelle De Loecker < jelle @ kipdola . be > * @ since 2013.08 .09 * @ version 2013.08 .09 * / function removeFunctions ( object ) { // Go over every entry in the object for ( var i in object ) { // If the object is a function, remove it! if ( object [ i ] instanceof Function ) { delete object [ i ] ; } else if ( typeof object [ i ] === 'object' ) { // If it's an object, recursively remove those functions removeFunctions ( object [ i ] ) ; } } return object ; } removeFunctions ( payload ) ;", "del_tokens": "for ( var i in payload ) { if ( payload [ i ] instanceof Function ) { delete payload [ i ] ; } }", "commit_type": "upgrade"}
{"commit_tokens": ["change", "default", "formatter", "from", "compact", "to", "stylish", "to", "conform", "to", "eslint", "project", "direction"], "add_tokens": "formatter = 'stylish' ;", "del_tokens": "formatter = 'compact' ;", "commit_type": "change"}
{"commit_tokens": ["allow", "logger", "to", "be", "set"], "add_tokens": "opts . log = opts . log || opts . logger || logger ;", "del_tokens": "opts . log = opts . log || logger ;", "commit_type": "allow"}
{"commit_tokens": ["Changed", "e2e", "serve", "options", "to", "launch", ".", "Wrote", "tests"], "add_tokens": "launch : 'none'", "del_tokens": "noOpen : true", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", "multiple", "dest", "files", "and", "conversion", "to", "placeholders", "if", "output", "to", "sass"], "add_tokens": "dest : [ \"tmp/base64.css\" , \"tmp/base64.sass\" , \"tmp/base64.scss\" ]", "del_tokens": "dest : \"tmp/base64.css\"", "commit_type": "add"}
{"commit_tokens": ["add", "names", "to", "comments", "remove", "setTimeout"], "add_tokens": "this . inquirer . prompt ( opts , function ( answer ) { var val = utils . get ( answer , opts . name ) ; if ( opts . isDefault === true ) { this . answer . setDefault ( val ) ; } if ( opts . save !== false && ! opts . isDefault && val !== opts . default ) { this . answer . set ( val ) ; } cb ( null , utils . set ( { } , opts . name , val ) ) ;", "del_tokens": "setImmediate ( function ( ) { this . inquirer . prompt ( opts , function ( answer ) { var val = utils . get ( answer , opts . name ) ; if ( opts . isDefault === true ) { this . answer . setDefault ( val ) ; } if ( opts . save !== false && ! opts . isDefault && val !== opts . default ) { this . answer . set ( val ) ; } cb ( null , utils . set ( { } , opts . name , val ) ) ; } . bind ( this ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "changemany", "and", "createmany", "events"], "add_tokens": "toArray : function ( val ) { if ( util . isObject ( val ) ) return values ( val ) ; return Array . prototype . slice . call ( val , 0 ) ; } , values : function ( obj ) { return map ( obj , function ( value ) { return value ; } ) ; this . emit ( 'changemany createmany' , util . toArray ( input ) . length ) ; this . emit ( 'changemany' , objOrKey . length ) ;", "del_tokens": "toArray : function ( arr ) { return Array . prototype . slice . call ( arr , 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "pid", "file", "management", "&", "added", "SIGHUP", "event", "hanlder"], "add_tokens": "if ( process . argv [ 1 ] == 'geena' ) { process . argv . splice ( 1 , 1 ) ; } else { process . argv . splice ( 1 , 2 ) ; }", "del_tokens": "//process.argv.splice(1,2); process . argv . splice ( 1 , 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["move", "tests", "to", "inner", "directory"], "add_tokens": "const visit = require ( '../index' ) ;", "del_tokens": "const visit = require ( './index' ) ;", "commit_type": "move"}
{"commit_tokens": ["fix", "bug", "with", "multiple", "loops"], "add_tokens": "var offset = points . length edges . push ( [ offset + j , offset + ( j + 1 ) % loop . length ] )", "del_tokens": "edges . push ( [ j , ( j + 1 ) % loop . length ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "search", "index", "for", "the", "taxonomy", "collection"], "add_tokens": "{ key : { name : 1 } , name : 'byName' } , { key : { name : 'text' } , weights : { name : 1 } , name : 'querySearch' }", "del_tokens": "{ key : { name : 1 } , name : 'byName' }", "commit_type": "add"}
{"commit_tokens": ["Remove", "only", "(", "oops", ")"], "add_tokens": "describe ( 'EventDispatcher' , function ( ) {", "del_tokens": "describe . only ( 'EventDispatcher' , function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["added", "magic", "which", "is", "useful", "stuff", "not", "present", "in", "the", "original", "assembler"], "add_tokens": ". option ( '-m, --magic' , 'enable Magic: this turns on useful features not supported by the original LC2 Assembler' ) . action ( ( file , output , options ) => { var assembler = new Assembler ( cli . debug , options . magic )", "del_tokens": "function writeToStdout ( x ) { process . stdout . write ( x . toString ( ) ) } . action ( ( file , output ) => { var assembler = new Assembler ( cli . debug )", "commit_type": "add"}
{"commit_tokens": ["add", "simple", "test", "case", "for", "prefix", "based", "subs"], "add_tokens": "var pubsub_prefix_sub = require ( './test_pubsub_prefix_sub.js' ) ; exports . testPubsubPrefixSub = pubsub_prefix_sub . testPubsubPrefixSub ;", "del_tokens": "exports . testPubsubEligible = pubsub_eligible . testPubsubEligible ;", "commit_type": "add"}
{"commit_tokens": ["changed", "max", "values", ".", "Reduced", "all", "by", "2", "px", "to", "fix", "the", "breakpoint", "bug"], "add_tokens": "mdx : 767 , lgx : 1023 , xlx : 1279", "del_tokens": "mdx : 769 , lgx : 1025 , xlx : 1281", "commit_type": "change"}
{"commit_tokens": ["Fixed", "require", "s", "that", "are", "returned"], "add_tokens": "require : [ '?^^ngOutlet' , 'ngOutlet' ] , require : 'ngOutlet' , return { require : '?^^ngOutlet' , restrict : 'A' , link : ngLinkDirectiveLinkFn } ;", "del_tokens": "require1 : [ '?^^ngOutlet' , 'ngOutlet' ] , require1 : 'ngOutlet' , return { require1 : '?^^ngOutlet' , restrict : 'A' , link : ngLinkDirectiveLinkFn } ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "issue", "-", "erc721", "-", "token", "example", "."], "add_tokens": "walletInfo = require ( ` ` ) async function issueERC721Property ( ) { issueERC721Property ( )", "del_tokens": "walletInfo = require ( ` ` ) async function createERC721Property ( ) { createERC721Property ( )", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "that", "the", "CachingWriter", "constructor", "is", "called", "."], "add_tokens": "// Call \"super\" (the broccoli-caching-writer constructor) Writer . call ( this , inputTree , this . options ) ;", "del_tokens": "this . inputTree = inputTree ;", "commit_type": "make"}
{"commit_tokens": ["updated", "doc", "and", "config", "examples"], "add_tokens": "enable : true resources : { mongo : { host : \"mongohost\" , port : 10071 , dbname : \"dbname\" , user : \"user\" , password : \"pass\" , enable : true } , nami : { host : \"amihost\" , port : 5048 , username : \"admin\" , secret : \"secret\" , enable : true } , websocket : { enable : true , port : 1028 } , express : { enable : true , port : 1029 }", "del_tokens": "enable : true mongo : { host : \"mongodomain.com\" , port : 1234 , dbname : \"dbname\" , user : \"username\" , password : \"password\" , enable : true } , amiData : { host : \"asteriskdomain.com\" , port : 2134 , username : \"username\" , secret : \"secret\" } , webSocket : { enable : true , port : 1028 } , httpServer : { enable : true , port : 1029", "commit_type": "update"}
{"commit_tokens": ["Added", "getSystemScriptFiles", "to", "distinguish", "files", "that", "are", "required", "for", "triton", "client", "to", "work", "and", "renamed", "getHeadScriptFiles", "to", "getUserScriptFiles", "which", "is", "for", "application", "code", "."], "add_tokens": "renderSystemScripts ( pageObject , res ) , renderUserScripts ( pageObject , res ) , function renderUserScripts ( pageObject , res ) { return renderScripts ( pageObject . getUserScriptFiles ( ) ) ; } function renderSystemScripts ( pageObject , res ) { return renderScripts ( pageObject . getSystemScriptFiles ( ) ) ; } function renderScripts ( scripts , res ) { // right now, the getXXXScriptFiles methods return synchronously, no promises, so we can render // immediately. scripts . forEach ( ( scriptPath ) => {", "del_tokens": "renderScripts ( pageObject , res ) , function renderScripts ( pageObject , res ) { pageObject . getHeadScriptFiles ( ) . forEach ( ( scriptPath ) => {", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "stroke", "configuration", "option", "from", "the", "oceans", "plugin"], "add_tokens": "* Date : 2013 - 12 - 22 T06 : 44 : 19.016 Z", "del_tokens": "* Date : 2013 - 12 - 22 T04 : 25 : 03.422 Z", "commit_type": "remove"}
{"commit_tokens": ["Made", "the", "app", "event", "driven", ".", "Since", "there", "is", "async", "operations", "needed", "to", "load", "the", "app", "we", "shouldn", "t", "do", "anything", "until", "the", "app", "responds", "as", "ready", "."], "add_tokens": "var util = require ( 'util' ) ; var EventEmitter = require ( 'events' ) . EventEmitter ; var app = function ( config ) { db = require ( '../db/database' ) ( config . db ) , util = require ( 'util' ) , self = this ; app . db . init ( app , function ( ) { self . emit ( 'ready' , app ) ; } ) ; } ; util . inherits ( app , EventEmitter ) ; module . exports = app ;", "del_tokens": "var app ; module . exports = app = function app ( config ) { db = require ( '../db/database' ) ( config . db ) ; app . db . init ( app ) ; return app ; } ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "wav", "-", "size", "issue", "chrome", "sync", "issue", "auto", "-", "stop", "recording", "etc", "."], "add_tokens": "function CanvasRecorder ( htmlElement , config ) { config = config || { } ; if ( config . initCallback ) { config . initCallback ( ) ; } whammy . frames = [ ] ; if ( ! config . disableLogs ) { if ( ! config . disableLogs ) { / ** * This method resets currently recorded data . * @ method * @ memberof CanvasRecorder * @ example * recorder . clearRecordedData ( ) ; * / this . clearRecordedData = function ( ) { this . pause ( ) ; whammy . frames = [ ] ; if ( ! config . disableLogs ) { console . debug ( 'Cleared old recorded data.' ) ; } } ;", "del_tokens": "function CanvasRecorder ( htmlElement ) { if ( ! this . disableLogs ) { if ( ! this . disableLogs ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "gnap", "-", "angular", "custom", "files"], "add_tokens": "'copy:gnap-angular_custom_to_build' , 'copy:gnap-angular_deploy_gnap' , 'copy:gnap-angular_deploy' , 'clean:gnap-angular_deploy'", "del_tokens": "'copy:gnap-angular_deploy' / * , 'clean:gnap-angular_deploy' * /", "commit_type": "add"}
{"commit_tokens": ["Fixed", "logout", "permission", "for", "non", "-", "admin"], "add_tokens": "( route [ 2 ] && route [ 2 ] != user . username . toString ( ) && route [ 2 ] != 'logout' ) )", "del_tokens": "( route [ 2 ] && ( route [ 2 ] != user . username . toString ( ) || ( route [ 1 ] == 'users' && route [ 3 ] && route [ 3 ] == 'admin' ) ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "define", "host", "as", "parameter", "and", "set", "the", "default", "as", "[", "::", "]"], "add_tokens": "{ name : 'host' , type : String , default : '::' } , var listener = app . listen ( options . port , options . host , function ( ) {", "del_tokens": "var listener = app . listen ( options . port , function ( ) {", "commit_type": "allow"}
{"commit_tokens": ["Changed", ";", "make", "sure", "to", "clear", "polling", "timeout", "if", "the", "connection", "closes", "."], "add_tokens": "* Clears polling timeout * @ api private HTTPPolling . prototype . clearPollTimeout = function ( ) { return this ; } ; / ** * Performs a write . * * @ api private . * / HTTPPolling . prototype . write = function ( data , close ) { this . clearPollTimeout ( ) ; this . clearPollTimeout ( ) ;", "del_tokens": "* Performs a write . * @ api private . HTTPPolling . prototype . write = function ( data , close ) {", "commit_type": "change"}
{"commit_tokens": ["adds", "events", "interface", "for", "device"], "add_tokens": "device . connect ( ) . on ( 'connect' , handleConnect . bind ( null , device ) ) . on ( 'data' , handleData . bind ( null , device ) ) . on ( 'disconnect' , handleDisconnect . bind ( null , device ) ) ; console . log ( 'Just removed: ' + pnpId ) ; var tmr ; function handleConnect ( device ) { console . log ( 'device connected!' ) ; console . log ( device . getInfo ( ) ) ; tmr = setInterval ( function ( ) { device . write ( '?\\n' ) ; } , 1000 ) ; } function handleData ( device , data ) { console . log ( data ) ; } function handleDisconnect ( device ) { console . log ( 'device disconnected :(' ) ; console . log ( device . getInfo ( ) ) ; clearInterval ( tmr ) ; }", "del_tokens": "console . log ( 'device found: ' + device . pnpId ) ; console . log ( 'Just remoded: ' + pnpId ) ; // Machines() // .search() // .on('validdevice', function (device) { // device // .connect() // .on('connected', function () { // }); // .on('data', function (data) { // console.log(data); // }) // .on('disconnect', function () { // }); // });", "commit_type": "add"}
{"commit_tokens": ["Add", "execWrap", "for", "error", "handling", "rewrite", "to", "use", "named", "remotes"], "add_tokens": "remote : 'git@github.com:robwierzbowski/grunt-version-build.git' , commit : true , connectCommits : false , push : true", "del_tokens": "// remote: 'git@github.com:robwierzbowski/grunt-version-build.git', commit : true", "commit_type": "add"}
{"commit_tokens": ["Remove", "mem_delta", "from", "tracer", "."], "add_tokens": "}", "del_tokens": "nodeCache [ key ] . mem_delta = 0 ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "memory", "stats", "to", "aedes", "bench", "programs"], "add_tokens": "var start_time = new Date ( ) ; var end_time = new Date ( ) ; console . log ( f . name + ':' , ( end_time . getTime ( ) - start_time . getTime ( ) ) + 'ms' ) ; gc ( ) ; var start_mem = process . memoryUsage ( ) ; gc ( ) ; var end_mem = process . memoryUsage ( ) ; console . log ( 'heap:' , ( ( end_mem . heapUsed - start_mem . heapUsed ) / 1024 / 1024 ) . toFixed ( 1 ) + 'MiB' , 'rss:' , ( ( end_mem . rss - start_mem . rss ) / 1024 / 1024 ) . toFixed ( 1 ) + 'MiB' ) ;", "del_tokens": "var start = new Date ( ) ; var end = new Date ( ) ; console . log ( f . name + ':' , end . getTime ( ) - start . getTime ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "update", "value", "on", "animation", ".", "More", "examples", "..."], "add_tokens": "updateValueOnAnimation : false , canvas = config . renderTo . tagName ? config . renderTo : document . getElementById ( config . renderTo ) , config . updateValueOnAnimation ? self . setRawValue ( fromValue ) : self . draw ( ) ; fontSrc = \"url('\" + ( window . CANV_GAUGE_FONTS_PATH || 'fonts' ) + \"/digital-7-mono.\" + ( ie ? 'eot' : 'ttf' ) + \"')\" ,", "del_tokens": "canvas = config . renderTo . tagName ? config . renderTo : document . getElementById ( config . renderTo ) , self . draw ( ) ; fontSrc = \"url('fonts/digital-7-mono.\" + ( ie ? 'eot' : 'ttf' ) + \"')\" ,", "commit_type": "add"}
{"commit_tokens": ["add", "webpack", "-", "dev", "-", "server", "for", "HRM", "test"], "add_tokens": "path : './' ,", "del_tokens": "path : 'build/' ,", "commit_type": "add"}
{"commit_tokens": ["Fixing", "fixed", "nodes", "&", "helpers", "optim"], "add_tokens": "if ( NodeMatrix [ n + NODE_FIXED ] !== 1 ) { if ( NodeMatrix [ n + NODE_FIXED ] !== 1 ) {", "del_tokens": "if ( ! NodeMatrix [ n + NODE_FIXED ] ) { if ( ! NodeMatrix [ n + NODE_FIXED ] ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "the", "user", "field", "not", "setting", "the", "value", "correctly", "for", "multi", "-", "users", "."], "add_tokens": "return [ ] ;", "del_tokens": "return personas ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "path", "for", "node", ".", "TODO", "make", "it", "driven", "off", "of", "BIN", "or", "NODE_PATH"], "add_tokens": "var zipCmd = \"zip -r -T -y '\" + archiveFile + \"' *.app\" ;", "del_tokens": "var zipCmd = \"zip -r \" + archiveFile + \" *.app\" ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "sass", "-", "glob", "to", "sass", "compiler"], "add_tokens": "import { notification_icon_location , plugins } from '../config/shared-vars' ; . pipe ( plugins . sassGlob ( ) ) autoprefixer ( { browsers : [ 'last 2 version' , '> 1%' , 'ie >= 11' ] , grid : true } ) ,", "del_tokens": "import { notification_icon_location } from '../config/shared-vars' ; autoprefixer ( { browsers : [ 'last 2 version' , '> 5%' , 'safari 5' , 'ios 6' , 'android 4' , 'ie >= 9' ] } ) ,", "commit_type": "add"}
{"commit_tokens": ["Fixing", "code", "issues", "in", "gulpfile"], "add_tokens": "deploy = require ( 'gulp-gh-pages' ) , git = require ( 'gulp-git' ) , . filter ( function ( i ) { return i . substr ( 0 , 2 ) !== './' ; } ) . map ( function ( i ) { return chalk . blue ( i . replace ( __dirname , '' ) ) ; } ) ; return gulp . src ( EXAMPLE_FILES . map ( function ( i ) { return EXAMPLE_SRC_PATH + '/' + i ; } ) ) } ; } gulp . watch ( EXAMPLE_FILES . map ( function ( i ) { return EXAMPLE_SRC_PATH + '/' + i ; } ) , [ 'dev:build:example:files' ] ) ;", "del_tokens": "deploy = require ( \"gulp-gh-pages\" ) , git = require ( \"gulp-git\" ) , . filter ( function ( i ) { return i . substr ( 0 , 2 ) !== './' } ) . map ( function ( i ) { return chalk . blue ( i . replace ( __dirname , '' ) ) } ) ; return gulp . src ( EXAMPLE_FILES . map ( function ( i ) { return EXAMPLE_SRC_PATH + '/' + i } ) ) } } ; gulp . watch ( EXAMPLE_FILES . map ( function ( i ) { return EXAMPLE_SRC_PATH + '/' + i } ) , [ 'dev:build:example:files' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "tar", "config", "for", "install", ".", "js"], "add_tokens": "cp . execFile ( 'tar' , [ 'zxf' , path . resolve ( filePath ) ] , { dir : extractedPath } , function ( err ) {", "del_tokens": "cp . execFile ( 'tar' , [ 'zxf' , path . resolve ( filePath ) ] , options , function ( err ) {", "commit_type": "update"}
{"commit_tokens": ["fixed", "error", "handling", "in", "the", "async", "wrapper"], "add_tokens": "Promise . resolve ( value ) . then ( resume ) . catch ( ( error ) => { try { iterator . throw ( error ) } catch ( err ) { reject ( err ) } } )", "del_tokens": "Promise . resolve ( value ) . then ( resume ) . catch ( reject )", "commit_type": "fix"}
{"commit_tokens": ["Improved", "info", "about", "ExtJs", "component", "in", "exploration", "mode", "."], "add_tokens": "rowSep : '= = = = = = =' , getAttributes : function ( compOrEl ) { arr . push ( '\\n' + tiaEJ . ctConsts . rowSep + '\\n' ) ; var propsArr = [ 'entityName' , 'getId()' , 'getIdProperty()' , 'session.$className' , 'store.$className' ] ; tia . u . dumpObj ( record , propsArr , arr , true ) ; var index ; try { index = record . store . indexOfId ( record . getId ( ) ) ; } catch ( e ) { } arr . push ( 'Index in store: ' + index ) ; arr . push ( ( printFieldName ? ( fieldName + ': ' ) : '' ) + '\"' + fieldValue + '\"' ) ;", "del_tokens": "getAttributes : function ( compOrEl ) { arr . push ( ( printFieldName ? ( fieldName + ': ' ) : '' ) + '\"' + fieldValue + '\"' ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "extra", "information", "for", "sonar", "-", "junit", "report"], "add_tokens": "'dirname' : path . dirname ( file ) , 'extension' : path . extname ( file ) , var matchingSpecs = _ . filter ( specs , function ( spec ) { } ) ; return spec . name === matchingSpec . name ; testcase . attr . dirname = matchingSpec . dirname ; testcase . attr . extension = matchingSpec . extension ; testcase . attr . classname = matchingSpec . name . replace ( / \\. / g , '_' ) ;", "del_tokens": "var matchingSpecs = _ . map ( _ . filter ( specs , function ( spec ) { } ) , 'name' ) ; return spec . name === matchingSpec ; testcase . attr . classname = matchingSpec . replace ( / \\. / g , '_' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "tasks", "support", "for", "sauce", "."], "add_tokens": "var tasks = [ ] tasks . push ( { id : \"sauce\" , data : { total : result . total , failed : result . failed , passed : result . passed , runtime : result . runtime , id : result . id } } ) cb ( buildStatus , tasks )", "del_tokens": "cb ( buildStatus )", "commit_type": "add"}
{"commit_tokens": ["moving", "versions", "over", "to", "the", "ngnx", "server", "instead", "of", "here", "."], "add_tokens": "'./test/selenium/specs/start.js' , './test/selenium/specs/**/*.js'", "del_tokens": "'./selenium/specs/start.js' , './selenium/specs/**/*.js'", "commit_type": "move"}
{"commit_tokens": ["Fix", "bug", "cannot", "use", "native", "ES6", "Promise"], "add_tokens": "// Mongoose 4.1.x and up if ( mongoose . Promise . ES6 ) { promise = new mongoose . Promise . ES6 ( resolver )", "del_tokens": "// Mongoose 4.1.x if ( mongoose . PromiseProvider ) { promise = new mongoose . PromiseProvider . get ( ) . ES6 ( resolver )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "keyParser", "method", "on", "cache", "opts"], "add_tokens": "function httpEtagModuleRun ( ) { $provide . decorator ( '$http' , [ '$delegate' , 'httpEtag' , 'polyfills' , function ( $delegate , httpEtag , polyfills ) { cacheKey = httpEtag . _parseCacheKey ( config . etag , config . url , config . params ) ; fn ( cacheValue . data ) ; cacheKey = httpEtag . _parseCacheKey ( config . etag , url , config . params ) ; fn ( cacheValue . data ) ;", "del_tokens": "httpEtagModuleRun . $inject = [ 'httpEtag' , 'polyfills' ] ; function httpEtagModuleRun ( httpEtag , polyfills ) { $provide . decorator ( '$http' , [ '$delegate' , function ( $delegate ) { cacheKey = httpEtag . getCacheKey ( config . url , config . params ) ; fn ( cacheValue . data , cacheKey ) ; cacheKey = httpEtag . getCacheKey ( url , config . params ) ; fn ( cacheValue . data , cacheKey ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "updateCurrentTime", "private", "(", "as", "it", "should", "be", ")", "."], "add_tokens": "setInterval ( player . ima . updateCurrentTime_ , seekCheckInterval ) ; * @ private player . ima . updateCurrentTime_ = function ( ) {", "del_tokens": "setInterval ( player . ima . updateCurrentTime , seekCheckInterval ) ; player . ima . updateCurrentTime = function ( ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "disabled", "class", "in", "<<", "<", ">", ">>"], "add_tokens": "liClass : scope . page - 1 <= 0 ? 'disabled' : '' , liClass : scope . page - 1 <= 0 ? 'disabled' : '' , liClass : scope . page + 1 > pageCount ? 'disabled' : '' , liClass : scope . page + 1 > pageCount ? 'disabled' : '' , } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "loader", ".", "js", "for", "browser", "/", "node", "fileloading", "support"], "add_tokens": "// module.exports = ToolStack;", "del_tokens": "module . exports = ToolStack ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "responding", "to", "ANY", "queries"], "add_tokens": "type = type ? [ type ] : Object . keys ( registry ) return flatten ( type . map ( function ( type ) { if ( ! ( type in registry ) ) return [ ] return registry [ type ] . filter ( function ( record ) { return record . name === name } ) } ) )", "del_tokens": "if ( ! ( type in registry ) ) return [ ] return registry [ type ] . filter ( function ( record ) { return record . name === name } )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "developers", "to", "specify", "a", "custom", "local", "port", "when", "running", "apps", "locally"], "add_tokens": "port : process . env . FH_LOCAL_DB_PORT || 27017 ,", "del_tokens": "port : 27017 ,", "commit_type": "allow"}
{"commit_tokens": ["Make", "stylesheets", "load", "in", "the", "correct", "order", "."], "add_tokens": "alchemy . usePath ( './app' , { less : false } ) ;", "del_tokens": "alchemy . usePath ( './app' ) ;", "commit_type": "make"}
{"commit_tokens": ["move", "text", "code", "into", "separate", "file"], "add_tokens": "var text = require ( './text' ) ; exports . registerFont = text . registerFont ;", "del_tokens": "var opentype = require ( 'opentype.js' ) ; var NAMED_COLORS = require ( './named_colors' ) ; var _fonts = { } ; exports . registerFont = function ( binary , family , weight , style , variant ) { _fonts [ family ] = { binary : binary , family : family , weight : weight , style : style , variant : variant , loaded : false , font : null , load : function ( cb ) { console . log ( \"PureImage loading\" , family , weight , style , variant ) ; if ( this . loaded ) { if ( cb ) cb ( ) ; return ; } var self = this ; opentype . load ( binary , function ( err , font ) { if ( err ) throw new Error ( 'Could not load font: ' + err ) ; self . loaded = true ; self . font = font ; if ( cb ) cb ( ) ; } ) ; } } ; return _fonts [ family ] ; } ; exports . debug_list_of_fonts = _fonts ;", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "to", "find", "license", "name", "from", "license", "urls"], "add_tokens": "var urltoLicense = require ( './urltolicense' ) } else if ( license . url ) { var licensename = urltoLicense ( license . url ) if ( licensename ) return licensename + \" (\" + license . url + \")\" else throw Error ( \"unknown license: \" + JSON . stringify ( license ) ) } else {", "del_tokens": "} else {", "commit_type": "add"}
{"commit_tokens": ["update", "utils", "models", "and", "routes"], "add_tokens": "if ( execute && typeof execute === 'function' ) { execute ( data || { } ) ;", "del_tokens": "if ( typeof ( execute ) === 'function' ) { if ( ! data ) { execute ( ) ; } else { execute ( data ) ; }", "commit_type": "update"}
{"commit_tokens": ["make", "event", "for", "hotkey", ".", "callback", "optional"], "add_tokens": "if ( event ) { var target = event . target || event . srcElement ; // srcElement is IE only var nodeName = target . nodeName . toUpperCase ( ) ; // check if the input has a mousetrap class, and skip checking preventIn if so if ( ( ' ' + target . className + ' ' ) . indexOf ( ' mousetrap ' ) > - 1 ) { shouldExecute = true ; } else { // don't execute callback if the event was fired from inside an element listed in preventIn for ( var i = 0 ; i < preventIn . length ; i ++ ) { if ( preventIn [ i ] === nodeName ) { shouldExecute = false ; break ; }", "del_tokens": "var target = event . target || event . srcElement ; // srcElement is IE only var nodeName = target . nodeName . toUpperCase ( ) ; // check if the input has a mousetrap class, and skip checking preventIn if so if ( ( ' ' + target . className + ' ' ) . indexOf ( ' mousetrap ' ) > - 1 ) { shouldExecute = true ; } else { // don't execute callback if the event was fired from inside an element listed in preventIn for ( var i = 0 ; i < preventIn . length ; i ++ ) { if ( preventIn [ i ] === nodeName ) { shouldExecute = false ; break ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "wrong", "path", "for", "jquery", "in", "requirejs", "config", "template"], "add_tokens": "\" jquery: 'vendor/jquery.min'\" ,", "del_tokens": "\" jquery: 'app/scripts/vendor/jquery.min'\" ,", "commit_type": "fix"}
{"commit_tokens": ["updated", "module", "for", "better", "exporting", "of", "routes"], "add_tokens": "import { RouterModule } from '@angular/router' ; RouterModule , TabsModule //, //UserAdminRouting", "del_tokens": "import { UserAdminRouting } from './user-admin.routing' ; TabsModule , UserAdminRouting", "commit_type": "update"}
{"commit_tokens": ["change", "string", "to", "uncommited", "changes"], "add_tokens": "Studio . openTab ( { key : 'versionControlLocalChanges' , editorComponentKey : 'versionControlLocalChanges' , title : 'Uncommited changes' } )", "del_tokens": "Studio . openTab ( { key : 'versionControlLocalChanges' , editorComponentKey : 'versionControlLocalChanges' , title : 'Local changes' } )", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "case", "-", "sensitive", "filesystems", ":", "sizzle", "-", ">", "Sizzle"], "add_tokens": "var Sizzle = require ( \"./Sizzle\" ) ;", "del_tokens": "var Sizzle = require ( \"./sizzle\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "conversions", "between", "native", "and", "JavaScript", "instruction", "structures"], "add_tokens": "new Buffer ( source . prefix ) . copy ( this . prefix ) ; new Buffer ( source . opcode ) . copy ( this . opcode ) ; this . prefix = source . prefix . buffer . toJSON ( ) ; this . opcode = source . opcode . buffer . toJSON ( ) ;", "del_tokens": "source . prefix . buffer . copy ( this . prefix ) ; source . opcode . buffer . copy ( this . opcode ) ; this . prefix = new Buffer ( 5 ) ; this . opcode = new Buffer ( 3 ) ; source . prefix . buffer . copy ( this . prefix ) ; source . opcode . buffer . copy ( this . opcode ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "most", "problems", "with", "upgrade"], "add_tokens": "entity . redirects = entity . redirects || [ ] ; entity . redirects . push ( entity . permalink . replace ( / \\/$ / , '/index.html' ) ) ; // TODO type checking like below entity . redirects = Array . isArray ( entity . yml . redirects ) && entity . yml . redirects || [ ] ;", "del_tokens": "console . log ( 'root entity.path' , entity . path ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "pantry", "dependency", "and", "examples"], "add_tokens": "This timbit will query Wordpress API and display the results \\ href : '/chocolate/?site=sports.nationalpost.com' , caption : 'Latest Sports news from The National Post' href : '/chocolate/alternate-view?site=sports.nationalpost.com&tag=Hockey&number=5' , caption : 'Latest five posts on Hockey from The National Post' site : { description : 'The Wordpress site to query' , values : [ 'sports.nationalpost.com' , 'blog.windsorstar.com' ] tag : { description : 'Tag to filter by' , required : false , strict : false , values : [ 'Hockey' , 'Detroit' ] } , \"number\" : { description : 'The number of posts to display' , alias : 'rpp' , strict : false , values : [ 3 , 5 , 10 ] name : 'wordpress' , uri : \"http://public-api.wordpress.com/rest/v1/sites/\" + context . site + \"/posts?number=\" + context . number if ( context . tag ) { src . uri += \"&tag=\" + context . tag ; }", "del_tokens": "This timbit will query twitter and display the results \\ href : '/chocolate/?q=winning' , caption : 'Winning - Default View' href : '/chocolate/alternate-view?q=winning&rpp=20' , caption : 'Winning - Alternate View' q : { description : 'Keyword to search for' , values : [ 'Coffee' , 'Timbits' ] rpp : { description : 'Maximum number of tweets to display' , alias : 'max' , type : 'Number' , values : [ 1 , 8 , 16 ] name : 'tweets' , uri : \"http://search.twitter.com/search.json?q=\" + context . q + \"&rpp=\" + context . rpp", "commit_type": "update"}
{"commit_tokens": ["Fixed", "the", "after_prepare", "hook", ":", "now", "it", "runs", "after", "the", "last", "changes"], "add_tokens": "enabled : options [ 'local-development' ] . enabled", "del_tokens": "enabled : options . [ 'local-development' ] . enabled", "commit_type": "fix"}
{"commit_tokens": ["add", "now", "accepts", "as", "many", "args", "as", "needed"], "add_tokens": "import curryN from '../function/curryN' * @ param { ... Number } nums The numbers to add together const add = ( ... nums ) => nums . reduce ( ( total , x ) => total + Number ( x ) , 0 ) export default curryN ( 2 , add )", "del_tokens": "import curry from '../function/curry' * @ param { Number } a The first number to add * @ param { Number } b The second number to add const add = ( a , b ) => Number ( a ) + Number ( b ) export default curry ( add )", "commit_type": "add"}
{"commit_tokens": ["Added", "readStringAsBytes", "for", "BytesIO", "."], "add_tokens": "* LastModified : Aug 3 , 2015 * ostream . write ( stream . readStringAsBytes ( count + 1 ) ) ;", "del_tokens": "* LastModified : Jul 19 , 2015 * ostream . writeString ( stream . readString ( count + 1 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "comb", ".", "define", "and", "comb", ".", "singleton", "docs"], "add_tokens": "* @ name define * @ memberOf comb * * Defines a singleton instance of a Class . See { @ link define } * * * @ name singleton * @ memberOf comb", "del_tokens": "* Defines a singleton instance of a Class * See { @ link define }", "commit_type": "fix"}
{"commit_tokens": ["use", "src", "intead", "of", "lib"], "add_tokens": "/* eslint-env browser */ import Emitter from 'component-emitter' const emit = Emitter . prototype . emit const KEY = '!!storage-emitter-key' const sEmitter = new Emitter ( ) global . addEventListener ( 'storage' , function onStorage ( e ) { if ( e . key !== KEY ) return // ignore other keys sEmitter . listeners ( cmd . event ) . forEach ( ( callback ) => { } catch ( err ) { sEmitter . emit = function ( event , args ) { export default sEmitter", "del_tokens": "var Emitter = require ( 'component-emitter' ) var emit = Emitter . prototype . emit var KEY = '!!storage-emitter-key' var sEmitter = new Emitter ( ) global . addEventListener ( 'storage' , function onStorage ( e ) { if ( e . key != KEY ) return // ignore other keys sEmitter . listeners ( cmd . event ) . forEach ( function ( callback ) { } catch ( err ) { sEmitter . emit = function ( event , args ) { module . exports = sEmitter", "commit_type": "use"}
{"commit_tokens": ["make", "questions", "methods", "consistent", "with", "question", "methods"], "add_tokens": "questions = new Questions ( { debug : true } ) ; beforeEach ( function ( ) { questions = new Questions ( { debug : true } ) ; afterEach ( function ( ) { questions . eraseAll ( ) ; } ) ; } ) ; question . setAnswer ( 'bar' ) ; question . delAnswer ( ) ; questions . set ( 'zzz' ) ; assert ( ! questions . isAnswered ( 'zzz' ) ) ; questions . setAnswer ( 'zzz' , 'yyy' ) ; assert ( questions . isAnswered ( 'zzz' ) ) ;", "del_tokens": "questions = new Questions ( ) ; question . set ( 'bar' ) ; question . del ( ) ; questions . set ( 'foo' ) ; var question = questions . get ( 'foo' ) ; assert ( ! questions . isAnswered ( 'foo' ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "proxy", "support", "for", "external", "requests", "."], "add_tokens": "plugins = require ( './middleware/cordova/plugins' ) , proxy = require ( './middleware/proxy' ) ; // proxy cross-origin requests app . use ( proxy ( options ) ) ;", "del_tokens": "plugins = require ( './middleware/cordova/plugins' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "express", "trust", "proxy", "setting"], "add_tokens": "var properties = module . exports = { // mock express' .get('trust proxy') app : { // getter returning a mock for `req.app` containing // the `.get()` method get : function ( ) { var ctx = this . ctx return { get : function ( key ) { if ( key === 'trust proxy' ) { return ctx . app . proxy } return undefined } } } } }", "del_tokens": "'app' , var properties = module . exports = { }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "some", "bugs", "in", "fragmentation", "reconstruction", "."], "add_tokens": "totalLength += currentFrame . binaryPayload . length ; if ( totalLength > this . maxMessageSize ) { var binaryPayload = new Buffer ( totalLength ) ; currentFrame . binaryPayload . copy ( binaryPayload , bytesCopied ) ; bytesCopied += currentFrame . binaryPayload . length ; binaryData : binaryPayload utf8Data : binaryPayload . toString ( 'utf8' ) this . frameQueue = [ ] ;", "del_tokens": "totalLength += currentFrame . binaryData . length ; if ( totalLenth > this . maxMessageSize ) { var binaryData = new Buffer ( totalLength ) ; currentFrame . binaryData . copy ( binaryData , bytesCopied ) ; bytesCopied += currentFrame . binaryData . length ; this . frameQueue = [ ] ; binaryData : binaryData utf8Data : binaryData . toString ( 'utf8' )", "commit_type": "fix"}
{"commit_tokens": ["Moved", "all", "decode", "logic", "to", "the", "typeConverter"], "add_tokens": "con . execute ( \"select id, big_sample, blob_sample, decimal_sample, list_sample, set_sample, map_sample, text_sample from sampletable1 where id IN (200, 201, 202, 203);\" , null , function ( err , result ) { if ( err ) { test . fail ( err , 'Error selecting' ) ; test . done ( ) ; return ; } 'execute prepared query' : function ( test ) { //TODO: prepare a bunch of queries involving different data types //to check type conversion test . done ( ) ; } ,", "del_tokens": "con . execute ( \"select * from sampletable1 where id IN (200, 201, 202, 203);\" , null , function ( err , result ) {", "commit_type": "move"}
{"commit_tokens": ["allow", "ConversationPage", "and", "MessagesPage", "to", "accept", "custom", "dateTimeFormatter"], "add_tokens": "formatDateTime : props . formatDateTime || ( utcTimestamp => props . dateTimeFormat . formatDateTime ( { } ) ) ,", "del_tokens": "formatDateTime : utcTimestamp => props . dateTimeFormat . formatDateTime ( { } ) ,", "commit_type": "allow"}
{"commit_tokens": ["Implement", "mdl", "-", "grid", "and", "mdl", "-", "cell"], "add_tokens": "import { reflectPropertiesToAttributes , makeShadow } from '../utils' ; class Grid extends HTMLElement { connectedCallback ( ) { this . classList . add ( 'mdl-grid' ) ; } attributeChangedCallback ( attrName , oldVal , newVal ) { this . classList . toggle ( 'mdl-grid--no-spacing' , this . noSpacing ) ; if ( attrName === 'shadow' ) makeShadow ( this , oldVal , newVal ) ; } } export default reflectPropertiesToAttributes ( Grid , [ { propName : 'noSpacing' , propType : Boolean } , { propName : 'shadow' , propType : Number } , ] )", "del_tokens": ". gitkeep", "commit_type": "implement"}
{"commit_tokens": ["fixed", "support", "for", "plain", "objects", "used", "as", "schema", "when", "the", "indexes", "field", "is", "missing"], "add_tokens": "var schemaIndexes = schema . indexes || [ ] ; schemaIndexes . forEach ( ( function ( indexSchema ) { var schemaIndexes = schema . indexes || [ ] ; var newIndexNames = schemaIndexes . map ( ( function ( indexSchema ) { var indexSchema = schemaIndexes . filter ( ( function ( indexSchema ) {", "del_tokens": "schema . indexes . forEach ( ( function ( indexSchema ) { var newIndexNames = schema . indexes . map ( ( function ( indexSchema ) { var indexSchema = schema . indexes . filter ( ( function ( indexSchema ) {", "commit_type": "fix"}
{"commit_tokens": ["Implementing", "model", ".", "sync", "()", "to", "assign", "promise", "resolutions", "to", "objects", "."], "add_tokens": "return extend ( function ModelClassFactory ( name , options ) { } , { sync : function ( dst , promises ) { forEach ( promises , function ( promise , name ) { promise . then ( function ( value ) { dst [ name ] = value ; } ) ; } ) ; } } ) ; this . $model = function ( ) { return owner ; } ;", "del_tokens": "return function ModelClassFactory ( name , options ) { } ; this . $model = function ( ) { return owner ; }", "commit_type": "implement"}
{"commit_tokens": ["Change", "unchanged", "let", "to", "const"], "add_tokens": "const pugNode = Parser . getNodeWithAttributes ( node ) const { nodeName } = node", "del_tokens": "let pugNode = Parser . getNodeWithAttributes ( node ) let { nodeName } = node", "commit_type": "change"}
{"commit_tokens": ["updated", "is_plural", "check", "for", "irregulars"], "add_tokens": "// if it's a known verb //if it's a known irregular singular for ( var i = 0 ; i < pluralize_rules . length ; i ++ ) { if ( str . match ( pluralize_rules [ i ] . reg ) ) { return false } } // if it changes when singularized // 'looks pretty plural' rules", "del_tokens": "//if it's a known verb //if it changes when singularized //'looks pretty plural' rules", "commit_type": "update"}
{"commit_tokens": ["Move", "synopsis", "before", "description", "."], "add_tokens": "'description' ,", "del_tokens": "'description' ,", "commit_type": "move"}
{"commit_tokens": ["Updating", "for", "change", "in", "analysis", "property", "names"], "add_tokens": "console . log ( ` ${ analysis . target } ` ) ; console . warn ( ` ${ analysis . target } ` ) ;", "del_tokens": "console . log ( ` ${ analysis . source } ` ) ; console . warn ( ` ${ analysis . source } ` ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "back", "sprintf", "as", "dependency"], "add_tokens": "* version : 0.2 .19 VERSION = '0.2.19' ,", "del_tokens": "* version : 0.2 .18 VERSION = '0.2.18' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "helmholtz", "misinterpretation", "in", "README", "and", "in", "the", "teoria", ".", "note", ".", "helmholtz", "method"], "add_tokens": "* C , , - f # '' - d - Eb - etc . * Returns the Helmholtz notation form of the note ( fx C , , d ' F# g#' ' this . name . toLowerCase ( ) ; var paddingChar = ( this . octave < 3 ) ? ',' : '\\'' ; var paddingCount = ( this . octave < 2 ) ? 2 - this . octave : this . octave - 3 ; pad ( name + this . accidental . sign , paddingChar , paddingCount ) ; return pad ( name + this . accidental . sign , paddingChar , paddingCount ) ;", "del_tokens": "* , , C - f # '' - d - Eb - etc . * Returns the Helmholtz notation form of the note ( fx , , C d ' F# g#' ' this . name . toLowerCase ( ) ; var padding ; if ( this . octave <= 2 ) { padding = pad ( '' , ',' , 2 - this . octave ) ; return padding + name + this . accidental . sign ; } else { padding = pad ( '' , '\\'' , this . octave - 3 ) ; return name + this . accidental . sign + padding ; }", "commit_type": "fix"}
{"commit_tokens": ["fixing", "some", "more", "issues", "with", "each"], "add_tokens": "return content . indexOf ( attr + '=\"' ) > - 1 ; if ( ! count && ! jsonPath ) {", "del_tokens": "return content . indexOf ( attr ) > - 1 ; if ( ! count ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "telegram", "-", "mt", "-", "node", "dependency"], "add_tokens": "var PublicKey = require ( 'telegram-mt-node' ) . security . PublicKey ;", "del_tokens": "var PublicKey = require ( './crypto-util/public-key' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "starts", "with", "query", "option", "."], "add_tokens": ";", "del_tokens": ";", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "optional", "parameter", "for", "devToolsExtension", ".", "open", "to", "choose", "position", "for", "DevTools", "window"], "add_tokens": "let position = 'devtools-left' ; if ( [ 'panel' , 'left' , 'right' , 'bottom' ] . indexOf ( request . position ) !== - 1 ) position = 'devtools-' + request . position ; openDevToolsWindow ( position ) ;", "del_tokens": "openDevToolsWindow ( ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "validators", "and", "sanitizers", "to", "be", "overwritten"], "add_tokens": "const defaultFn = tryCatch ( options . type , name , method ) ; let chainableMethod = function chainableMethod ( fn ) { let _fn = defaultFn ; if ( arguments . length === 1 && _ . isFunction ( fn ) ) { _fn = tryCatch ( options . type , name , fn ) ; }", "del_tokens": "let _fn = tryCatch ( options . type , name , method ) ; let chainableMethod = function chainableMethod ( ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "tracker", "-", "reannounce", "-", "timer"], "add_tokens": "let lastid = - 1 let main if ( trackers [ lastid ] ) { updateNext ( ) main = setTimeout ( updateAll , 1000 ) } else { lastid = 0 main = setTimeout ( updateAll , 30 * 1000 ) } updateAll ( )", "del_tokens": "let lastid updateNext ( ) if ( lastid ) setTimeout ( updateAll , 1000 ) const main = setInterval ( ( ) => { lastid = 0 updateAll ( ) } , ( 30 + trackers . length ) * 1000 ) //every 30secs + per tracker 1sec", "commit_type": "fix"}
{"commit_tokens": ["Fix", "shallow", "stack", "traces", "when", "trycatch", "()", "isn", "t", "used"], "add_tokens": ", util = require ( 'util' ) , events = require ( 'events' )", "del_tokens": ", util = require ( \"util\" ) , events = require ( \"events\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "log", ".", "skipLevelInfo", "to", "reduce", "log", "space"], "add_tokens": "if ( module . exports . skipLevelInfo && level === LOG_LEVELS . INFO ) level = undefined ; if ( ! module . exports . skipLevelInfo || level !== LOG_LEVELS . INFO ) parts . push ( ` ${ level } ` ) ; // Indicates that level: \"INFO\" property should be skipped in the log. // This is useful to reduce log space skipLevelInfo : false ,", "del_tokens": "parts . push ( ` ${ level } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "relative", "path", "from", "app", "base", "for", "flow", "http", "ssl", "certificates", "."], "add_tokens": "const resolve = require ( 'path' ) . resolve ; if ( ! event . args . ssl || ! event . args . ssl . cert || ! event . args . ssl . key ) { return next ( new Error ( 'Flow-http.listen: A valid ssl config must pe provided.' ) ) ; } ssl : { cert : resolve ( process . env . flow_base , '../' , event . args . ssl . cert ) , key : resolve ( process . env . flow_base , '../' , event . args . ssl . key ) } ,", "del_tokens": "ssl : event . args . ssl ,", "commit_type": "use"}
{"commit_tokens": ["Move", "the", "CLI", "to", "a", "different", "file"], "add_tokens": "import tailwind from '..'", "del_tokens": "import tailwind from './tailwind'", "commit_type": "move"}
{"commit_tokens": ["move", "html", "files", "to", "the", "test", "directory"], "add_tokens": "define ( [ \"gmeassert\" , \"../lib/sha1\" ] , function ( ASSERT ) {", "del_tokens": "define ( [ \"src/gmeassert\" , \"lib/sha1\" ] , function ( ASSERT ) {", "commit_type": "move"}
{"commit_tokens": ["Move", "examples", "to", "root", ";", "make", "them", "self", "-", "contained"], "add_tokens": "const index_js_1 = require ( \"../../dist/index.js\" ) ; const ynab = new index_js_1 . Api ( API_KEY , \"http://localhost:3000/papi/v1\" ) ;", "del_tokens": "const ynabApi = require ( \"../index\" ) ; const ynab = new ynabApi . Api ( API_KEY ) ; //# sourceMappingURL=change-polling.js.map", "commit_type": "move"}
{"commit_tokens": ["Making", "it", "simpler", "to", "check", "for", "curr", "db", "-", ">", "less", "dupe", "code", "."], "add_tokens": "function throwIfNoCurrDB ( ) { if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; } } throwIfNoCurrDB ( ) ; throwIfNoCurrDB ( ) ; throwIfNoCurrDB ( ) ; throwIfNoCurrDB ( ) ; throwIfNoCurrDB ( ) ; throwIfNoCurrDB ( ) ; throwIfNoCurrDB ( ) ;", "del_tokens": "if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; } if ( ! currDatabase ) { throw 'You must call setDatabase() first.' ; } if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; } if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; } if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; } if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; } if ( ! currDatabase ) { throw 'Must setDatabase() first.' ; }", "commit_type": "make"}
{"commit_tokens": ["fix", "missing", "/", "mispelled", "validation", "so", "it", "ignores", "literals"], "add_tokens": "// match any of our literals true, false, int, float, quoted strings, or is property (has dot) var LITERAL_OR_PROP_RE = / ^(true|false|\\-?[0-9\\.]+)$|'|\"|\\. / i ; / ** true if is a literal name * / function isLiteralOrProp ( name ) { // need to match what is in vcon.js, TODO consolidate? return LITERAL_OR_PROP_RE . test ( name ) ; if ( ! isLiteralOrProp ( p ) && ! names [ p ] ) innerAccum . push ( sprintf ( MISSING_INPUTS , p ) ) ; // add error if missing if ( ! isLiteralOrProp ( p ) && ! names [ p ] ) accum . push ( sprintf ( MISSING_INPUTS , p ) ) ; // add error if missing", "del_tokens": "function isProp ( str ) { // true if is a property name (contains a dot) return ( str . indexOf ( '.' ) !== - 1 ) ; if ( ! isProp ( p ) && ! names [ p ] ) innerAccum . push ( sprintf ( MISSING_INPUTS , p ) ) ; // add error if missing if ( ! isProp ( p ) && ! names [ p ] ) accum . push ( sprintf ( MISSING_INPUTS , p ) ) ; // add error if missing", "commit_type": "fix"}
{"commit_tokens": ["Moved", "and", "factorized", "notifyEnd", "()", "of", "transportable", "objects", "also", "into", "makeTransportable", "."], "add_tokens": "console . log ( \"Grain position is out of bounds\" ) ; if ( this . hasOwnProperty ( \"notifyEnd\" ) ) { this . notifyEnd ( ) ; }", "del_tokens": "this . notifyEnd ( ) ; console . log ( \"Position is out of bounds\" ) ; / ** * Notify end to the Transporter object . * @ private * / notifyEnd : { enumerable : false , value : function ( ) { if ( this . transporter ) { console . log ( \"notifyEnd\" , this ) ; this . transporter . onTransportableObjectEnded ( this ) ; } else { throw \"notifyEnd error\" ; } } } ,", "commit_type": "move"}
{"commit_tokens": ["updated", "things", "to", "work", "with", "new", "versions"], "add_tokens": "'script-src' : [ csp . SRC_SELF , csp . SRC_DATA ]", "del_tokens": "'script-src' : [ csp . SRC_SELF , csp . SRC_DATA ]", "commit_type": "update"}
{"commit_tokens": ["fixing", "model", "compiler", "and", "related", "unit", "tests"], "add_tokens": "return new Function ( \"attributes\" , `", "del_tokens": "return new Function ( `", "commit_type": "fix"}
{"commit_tokens": ["fixed", "wrong", "path", "to", "/", "base", "/", "component"], "add_tokens": "$include ( './base/component' ) // component facility", "del_tokens": "$include ( './base/Component' ) // component facility", "commit_type": "fix"}
{"commit_tokens": ["move", "content", "selector", "to", "sites"], "add_tokens": "// extract content based on site definitions var found = sites . findMatch ( uri ) ; if ( found ) { var content = $ ( found . selector ) . html ( ) ; callback ( uri , html , found . selector , content ) ; } else { var def = $ ( 'body' ) . html ( ) || html ; callback ( uri , html , 'body' , def ) ; }", "del_tokens": "for ( var uriMatch in sites . annoLoc ) { if ( uri . match ( uriMatch ) ) { var found = annoLoc [ uriMatch ] ; var content = $ ( found . selector ) . html ( ) ; callback ( uri , html , found . selector , content ) ; return ; } } var def = $ ( 'body' ) . html ( ) || html ; callback ( uri , html , 'body' , def ) ;", "commit_type": "move"}
{"commit_tokens": ["Update", "empty", "visual", "clean", "up", "visual", "-", "scripts", "to", "eliminate", "legacy", "-", "mode", "support"], "add_tokens": "const EXPECTED_TOP_LEVEL = [ 'visual' , 'apiVersion' , 'entry' , 'capabilities' ] name : 1 , capabilities : 1", "del_tokens": "const EXPECTED_TOP_LEVEL = [ 'visual' , 'apiVersion' , 'entry' ] name : 1", "commit_type": "update"}
{"commit_tokens": ["Fix", "another", "bug", "in", "recursive", "dependencies"], "add_tokens": "for ( var k in data . dependencies ) { results [ k ] = data . dependencies [ k ] ; } for ( var k in data [ category ] ) { if ( data . dependencies [ k ] ) { results [ k ] = data . dependencies [ k ] ; } }", "del_tokens": "Object . assign ( results , data . dependencies ) ; Object . assign ( results , data [ category ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "our", "own", "sync", "requests"], "add_tokens": "var syncRequest = require ( 'sync-request' ) ; var res = syncRequest ( 'POST' , web3 . currentProvider . host , { json : { \"jsonrpc\" : \"2.0\" , \"method\" : \"eth_getBlockByNumber\" , \"params\" : [ \"latest\" , false ] , \"id\" : 1 } } ) ; const block = JSON . parse ( res . getBody ( 'utf8' ) ) . result ;", "del_tokens": "const block = web3 . eth . getBlock ( 'latest' ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "an", "option", "to", "skip", "adding", "models", "to", "swagger"], "add_tokens": "function init ( pathToModels , cb , addToSwagger ) { if ( modelSwagger && addToSwagger ) {", "del_tokens": "function init ( pathToModels , cb ) { if ( modelSwagger ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "ngSubmit", "override", "so", "that", "the", "form", "gets", "validated", "before", "it", "is", "submitted"], "add_tokens": "$provide . decorator ( 'ngSubmitDirective' , [ '$parse' , function ( $delegate , $parse , validationManager ) { $delegate [ 0 ] . compile = function ( $element , attr ) { var fn = $parse ( attr [ 'ng-submit' ] ) ; return function ( scope , element ) { element . on ( 'submit' , function ( event ) { scope . $apply ( function ( ) { if ( validationManager . validateForm ( element ) ) { console . log ( 3 ) ; fn ( scope , { $event : event } ) ; } } ) ; } ) ;", "del_tokens": "$provide . decorator ( 'ngFormDirective' , [ function ( $delegate , validationManager ) { var directive = $delegate [ 0 ] , link = directive . link ; directive . compile = function ( ) { return function ( scope , element , attrs , ctrls ) { link . apply ( this , arguments ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", ".", "co", "amazon", "urls"], "add_tokens": "const REGEX_AMAZON_URL = / https?:\\/\\/(.*amazon\\..*\\/.*|.*amzn\\..*\\/.*|.*a\\.co\\/.*) / i", "del_tokens": "const REGEX_AMAZON_URL = / https?:\\/\\/(.*amazon\\..*\\/.*|.*amzn\\.com\\/.*) / i", "commit_type": "add"}
{"commit_tokens": ["Use", "streams", "to", "read", "/", "write", "file", "contents"], "add_tokens": "concat = require ( 'concat-stream' ) , return data . pipe ( res ) ; req . pipe ( concat ( function ( data ) { req . body = data ; deleteObjects ( req , res ) ; } ) ) ;", "del_tokens": "return res . end ( data ) ; deleteObjects ( req , res ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "leading", "newline", "from", "getErrorSource", "."], "add_tokens": "return source + ':' + line + '\\n' + code + '\\n' + if ( source !== null ) { console . error ( ) ; console . error ( source ) ; }", "del_tokens": "return '\\n' + source + ':' + line + '\\n' + code + '\\n' + if ( source !== null ) console . error ( source ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "bunch", "more", "tests"], "add_tokens": "// describe(\".add_col()\", function(){ // }); // describe(\".add_row()\", function(){ // }); // describe(\".drop_col()\", function(){ // }); // describe(\".drop_row()\", function(){ // }); // describe(\".to_obj()\", function(){ // }); // describe(\"to_json()\", function(){ // }); // describe(\".to_csv()\", function(){ // }); // describe(\".to_csvblob()\", function(){ // });", "del_tokens": "describe ( \".add_col()\" , function ( ) { } ) ; describe ( \".add_row()\" , function ( ) { } ) ; describe ( \".drop_col()\" , function ( ) { } ) ; describe ( \".drop_row()\" , function ( ) { } ) ; describe ( \".to_obj()\" , function ( ) { } ) ; describe ( \"to_json()\" , function ( ) { } ) ; describe ( \".to_csv()\" , function ( ) { } ) ; describe ( \".to_csvblob()\" , function ( ) { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "1d<", "-", ">", "2d", "test", "."], "add_tokens": "require ( 'proof' ) ( 2 , function ( equal ) { var hilbert = require ( '../..' ) , res res = hilbert . d2xy ( 16 , 2 ) equal ( res [ 0 ] , 4 ) equal ( res [ 1 ] , 0 )", "del_tokens": "require ( 'proof' ) ( 1 , function ( equal ) { var hilbert = require ( '../..' ) equal ( hilbert . d2xy ( 16 , 2 ) , [ 4 , 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "ability", "to", "define", "custom", "demo", "templates"], "add_tokens": "demoTemplate : multiline . stripIndent ( function ( ) { / * < ! doctype html > < html > < head > < style > svg { width : 50 px ; height : 50 px ; fill : black ! important ; } < / style > < head > < body > { { svg } } { { useBlock } } < / body > < / html > * / }), var demoHTML = options . demoTemplate ;", "del_tokens": "var demoHTML = multiline . stripIndent ( function ( ) { / * < ! doctype html > < html > < head > < style > svg { width : 50 px ; height : 50 px ; fill : black ! important ; } < / style > < head > < body > { { svg } } { { useBlock } } < / body > < / html > * / });", "commit_type": "add"}
{"commit_tokens": ["update", "ouch", ".", "spec", "to", "use", ".", "type", "()", "instead", "of", ".", "an", ".", "object", "and", ".", "a", ".", "function"], "add_tokens": "it ( \"should return a Ouch instance object with Ouch prototype methods\" , function ( done ) { ouch . should . be . type ( \"object\" ) ; ouch . getHandlers . should . be . type ( \"function\" ) ; ouch . pushHandler . should . be . type ( \"function\" ) ; ouch . popHandler . should . be . type ( \"function\" ) ; ouch . clearHandlers . should . be . type ( \"function\" ) ; ouch . handleException . should . be . type ( \"function\" ) ; spyCall . args [ 0 ] . should . be . type ( \"function\" ) ; spyCall . args [ 0 ] . should . be . type ( \"function\" ) ;", "del_tokens": "it . only ( \"should return a Ouch instance object with Ouch prototype methods\" , function ( done ) { ouch . should . be . an . object ; ouch . getHandlers . should . be . a . function ; ouch . pushHandler . should . be . a . function ; ouch . popHandler . should . be . a . function ; ouch . clearHandlers . should . be . a . function ; ouch . handleException . should . be . a . function ; spyCall . args [ 0 ] . should . be . a . function ; spyCall . args [ 0 ] . should . be . a . function ;", "commit_type": "update"}
{"commit_tokens": ["Use", "Ember", ".", "$", "()", "instead", "of", "$", "()"], "add_tokens": "expect ( Ember . $ . trim ( this . $ ( ) . text ( ) ) ) . to . equal ( 'Pretty Color:' ) ; expect ( Ember . $ . trim ( this . $ ( ) . text ( ) ) ) . to . equal ( 'Pretty Color: green' ) ; expect ( Ember . $ . trim ( this . $ ( '.color-name' ) . text ( ) ) ) . to . equal ( 'green' ) ; expect ( Ember . $ . trim ( this . $ ( ) . text ( ) ) ) . to . equal ( 'Pretty Color: green' ) ;", "del_tokens": "expect ( $ . trim ( this . $ ( ) . text ( ) ) ) . to . equal ( 'Pretty Color:' ) ; expect ( $ . trim ( this . $ ( ) . text ( ) ) ) . to . equal ( 'Pretty Color: green' ) ; expect ( $ . trim ( this . $ ( '.color-name' ) . text ( ) ) ) . to . equal ( 'green' ) ; expect ( $ . trim ( this . $ ( ) . text ( ) ) ) . to . equal ( 'Pretty Color: green' ) ;", "commit_type": "use"}
{"commit_tokens": ["use", "git", "submodule", "for", "libsass", "and", "add", "paths", "and", "style", "args", "for", "render"], "add_tokens": "var toString = Object . prototype . toString ; SASS_OUTPUT_STYLE = { nested : 0 , expanded : 1 , compact : 2 , compressed : 3 } ; exports . render = function ( css , callback , options ) { var paths , style ; if ( toString . call ( options ) !== '[object Object]' ) { options = { } ; } paths = options . include_paths || [ ] ; if ( ! ( ( style = options . output_style ) in SASS_OUTPUT_STYLE ) ) { style = 'nested' ; } return binding . render ( css , callback , paths . join ( ':' ) , SASS_OUTPUT_STYLE [ style ] ) ; } ;", "del_tokens": "exports . render = binding . render", "commit_type": "use"}
{"commit_tokens": ["Use", "webtask", "-", "log", "-", "stream", "instead", "of", "event", "-", "source", "-", "stream"], "add_tokens": "var LogStream = require ( 'webtask-log-stream' ) ; return LogStream ( url ) ;", "del_tokens": "var EventSource = require ( 'event-source-stream' ) ; return EventSource ( url , { json : true } ) ; Sandbox . CronJob = CronJob ; Sandbox . Webtask = Webtask ;", "commit_type": "use"}
{"commit_tokens": ["added", "validation", "to", "(", "Worker", ")", "Job#reportStatus"], "add_tokens": "var client = gearmanode . client ( ) ; // by default expects job server on localhost:4730 client . submitJob ( { name : 'reverse' , payload : 'hello world!' } , function ( err , job ) { // by default foreground job with normal priority //client.submitJob({ name: 'reverse', payload: 'luouk k' }, function(err, job) { // by default foreground job with normal priority // simplest sample for README.md - foreground job receiving status update // var client = gearmanode.client(); // client.submitJob({ name: 'sleep', payload: '3' }, function(err, job) { // job.on('status', function(result) { // console.log('STATUS >> ' + util.inspect(result)); // }); // job.on('complete', function() { // console.log(\"RESULT >>> \" + job.response); // client.close(); // }); // })", "del_tokens": "// var client = gearmanode.client(); // by default expects job server on localhost:4730 // client.submitJob({ name: 'reverse', payload: 'hello world!' }, function(err, job) { // by default foreground job with normal priority // //client.submitJob({ name: 'reverse', payload: 'luouk k' }, function(err, job) { // by default foreground job with normal priority // job.on('complete', function() { // console.log(\"RESULT >>> \" + job.response); // client.close(); // }); // }) // simplest sample for README.md - foreground job receiving status update var client = gearmanode . client ( ) ; client . submitJob ( { name : 'sleep' , payload : '3' } , function ( err , job ) { job . on ( 'status' , function ( result ) { console . log ( 'STATUS >> ' + util . inspect ( result ) ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Improved", "handling", "for", "import", ".", "Fixed", "invalid", "character", "."], "add_tokens": "for ( var i = 0 ; i < samples . length ; ++ i ) {", "del_tokens": "for ( var i = 0 ; i < samples . length ; ++ i )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "for", "prod", "bug", "with", "JSON", "parsing"], "add_tokens": "try { val = JSON . parse ( val ) ; } catch ( ex ) { /* eslint no-console:0 */ console . log ( ex ) ; }", "del_tokens": "val = JSON . parse ( val ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "moment", "and", "format", "prop", "for", "last", "active", "method"], "add_tokens": "import moment from 'moment' ; ] ) , format : React . PropTypes . string render ( ) { return < div > { this . props . children } < / div > } , if ( this . props . format ) return moment ( this . state . lastActive ) . format ( this . props . format ) ;", "del_tokens": "] ) render ( ) { return this . props . children ; } ,", "commit_type": "add"}
{"commit_tokens": ["add", "showOtherMonths", "selectOtherMonths", "moveToOtherMonthsOnSelect", "options"], "add_tokens": "//TODO     //TODO      showOtherMonths : true , selectOtherMonths : true , moveToOtherMonthsOnSelect : true , this . silent = false ; // Need to prevent unnecessary rendering var d = this . parsedDate ; if ( date . getMonth ( ) != d . month && this . opts . moveToOtherMonthsOnSelect ) { this . silent = true ; this . date = new Date ( date . getFullYear ( ) , date . getMonth ( ) , 1 ) ; this . silent = false ; this . nav . _render ( ) } if ( this . inited && ! this . silent ) {", "del_tokens": "showOtherMonths : '' , selectOtherMonths : '' , if ( this . inited ) {", "commit_type": "add"}
{"commit_tokens": ["Adds", "and", "removes", "some", "operators"], "add_tokens": "// console.log(\"=== CODE ===\"); // console.log(code);", "del_tokens": "console . log ( \"=== CODE ===\" ) ; console . log ( code ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "further", "unwrapping", "to", "bang", "operator", "."], "add_tokens": "if ( x . lbracket && x . curly && x . blockType != \"object\" ) { console . log ( x ) return true } // if(x.assign) return true", "del_tokens": "if ( x . lbracket && x . curly && this . blockType != \"object\" ) return true if ( x . assign ) return true", "commit_type": "add"}
{"commit_tokens": ["Updating", "options", "passed", "into", "reporter"], "add_tokens": "} , options ) ) ;", "del_tokens": "} , options . reporter ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "ability", "to", "override", "params", "for", "adapter"], "add_tokens": "return me . validateRequestParams ( req , resource , method , serviceInfo . adapterName ) * @ param adapter ServiceFactory . prototype . validateRequestParams = function ( req , resource , method , adapter ) { var methodParams = _ . extend ( { } , params [ method ] , params [ adapter + '.' + method ] ) ;", "del_tokens": "return me . validateRequestParams ( req , resource , method ) ServiceFactory . prototype . validateRequestParams = function ( req , resource , method ) { var methodParams = params [ method ] || { } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "uniqueFontSize", "-", ">", "uniqueFontSizes"], "add_tokens": "\"uniqueFontSizes\" : false ,", "del_tokens": "\"uniqueFontSize\" : false ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "path", "using", "canonical", "path", "."], "add_tokens": ", upath = require ( 'canonical-path' ) server . parent = this ; , path = upath . join ( req . site . path , req . path ) if ( site . parent ) { //console.log(' -- ' + site.parent.path) }", "del_tokens": ", path = ( req . site . path || '' ) + req . path ; if ( '/' != path [ 0 ] ) { path = '/' + path ; }", "commit_type": "make"}
{"commit_tokens": ["fixed", "tooltip", "for", "interactive", "guideline"], "add_tokens": "* AngularJS - nvD3 , v1 .0 .1 ; MIT License ; 10 / 09 / 2015 12 : 36 else if ( key === 'tooltip' ) { if ( options [ key ] === undefined || options [ key ] === null ) { if ( scope . _config . extended ) options [ key ] = { } ; } configure ( chart [ key ] , options [ key ] , chartType ) ; }", "del_tokens": "* AngularJS - nvD3 , v1 .0 .1 ; MIT License ; 09 / 09 / 2015 17 : 27 } else if ( key === 'tooltip' ) { configure ( chart [ key ] , options [ key ] , chartType ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "pump", "in", "place", "of", "pipe", "to", "destroy", "sources", "."], "add_tokens": "var pump = require ( 'pump' ) ; pump ( child . stdout , stream ) ; pump ( child . stderr , stream ) ;", "del_tokens": "child . stdout . pipe ( stream ) ; child . stderr . pipe ( stream ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "absolute", "path", "in", "component", "example", "files"], "add_tokens": "var selected_tag = $ ( this ) . find ( 'option' ) . attr ( 'selected' )", "del_tokens": "var selected_tag = $ ( this ) . find ( ':selected' ) . length ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "date", "runtime", "translation", "add", "Uri", "component", "to", "JavaScript", "runtime"], "add_tokens": "/* JavaScript runtime for core unary and binary operators operators */", "del_tokens": "* Copyright 2015 - 2016 IBM Corporation * /* \"standard library\" (implementation of unary and binary operators) */", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "up", "available", "example", "emitting", "more", "than", "once"], "add_tokens": "for ( var i = 0 , l = not_found . length ; i < l ; i ++ ) { if ( stdout . indexOf ( not_found [ i ] ) >= 0 ) { }", "del_tokens": "console . log ( stdout ) ; not_found . forEach ( function ( nf ) { if ( stdout . indexOf ( nf ) >= 0 ) { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "version", "license", "author", "info"], "add_tokens": "/ * * Dancer . js ( c ) 2012 Jordan Santell * MIT License * http : //github.com/jsantell/dancer.js * * v0 .0 .1 * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "correlation", "id", "to", "rpc", "errors"], "add_tokens": "else { return topic + SEP + 'E' + SEP + type + SEP + message ; }", "del_tokens": "if ( typeof message === 'string' ) { return topic + SEP + 'E' + SEP + type + SEP + message ; }", "commit_type": "add"}
{"commit_tokens": ["allow", "preprocessors", "/", "index", ".", "js", "to", "determine", "order"], "add_tokens": "spawn ( process . execPath , [ shapeindex , '--shape_files' , infile ] )", "del_tokens": "spawn ( shapeindex , [ '--shape_files' , infile ] )", "commit_type": "allow"}
{"commit_tokens": ["fix", "missing", "module", ".", "resolve", "in", "statifier"], "add_tokens": "var appDirectory = join ( module . resolve ( '../apps' ) , appName ) ; var indexHtml = render ( exists ( appSpecific ) ? appSpecific : module . resolve ( 'skins/app.html' ) , {", "del_tokens": "var appDirectory = join ( module . directory , '../' , 'apps' , appName ) ; var indexHtml = render ( exists ( appSpecific ) ? appSpecific : 'skins/app.html' , {", "commit_type": "fix"}
{"commit_tokens": ["Adds", "Traceur", "support", "to", "Component", "Model", "demo", "."], "add_tokens": "try { try { // Feature test for native Component Model subclassing. HTMLElement . call = Function . prototype . call ; HTMLElement . apply = Function . prototype . apply ; new HTMLElement ( ) ; } catch ( featureTestException ) { // Else, hack in \"generic\" element support for constructing HTMLElement. add ( 'HTMLElement' , HTMLElement , function ( ) { return document . createElement ( 'span' ) ; } ) ; } } catch ( e ) { } defineProperty ( proto , 'constructor' , { value : TheClass , writable : true , configurable : true } ) ;", "del_tokens": "try { add ( 'HTMLElement' , HTMLElement , function ( ) { return document . createElement ( 'span' ) ; } ) ; } catch ( e ) { }", "commit_type": "add"}
{"commit_tokens": ["Removing", "backwards", "incompatible", "code", "and", "empty", "tests"], "add_tokens": "const aggregateType = _ . find ( [ 'anyOf' , 'oneOf' ] , _ . partial ( _ . includes , Object . keys ( model ) ) ) } else if ( model . not ) { const baseSchema = retModel . properties [ depName ]", "del_tokens": "const aggregateType = _ . find ( [ 'anyOf' , 'oneOf' ] , _ . partial ( _ . includes , Object . keys ( retModel ) ) ) } else if ( retModel . not ) { const baseSchema = model . properties [ depName ]", "commit_type": "remove"}
{"commit_tokens": ["updating", "bower", ".", "json", "and", "dist", "build"], "add_tokens": "/*! angular-locker v0.6.1 | (c) 2014 @tymondesigns | https://github.com/tymondesigns/angular-locker */", "del_tokens": "/*! angular-locker v0.6.0 | (c) 2014 @tymondesigns | https://github.com/tymondesigns/angular-locker */", "commit_type": "update"}
{"commit_tokens": ["Added", "e", "notation", "for", "complex", "numbers"], "add_tokens": "P [ \"r\" ] = 0 ; for ( var reg = / [+-]?(?:[\\di.]e[+-]?[\\di]+|[\\di.]+) / ig , tmp , tr , i = 0 ; null !== ( tmp = reg . exec ( a ) ) ; i = 1 ) {", "del_tokens": "P [ \"r\" ] = 0 ; for ( var reg = / [+-]?[\\di.]+ / g , tmp , tr , i = 0 ; null !== ( tmp = reg . exec ( a ) ) ; i = 1 ) {", "commit_type": "add"}
{"commit_tokens": ["Removed", "newline", "from", "parsed", "PR", "number"], "add_tokens": "const prNumber = stdout . replace ( '#' , '' ) . replace ( '\\n' , '' )", "del_tokens": "const prNumber = stdout . replace ( '#' , '' )", "commit_type": "remove"}
{"commit_tokens": ["update", "Flyfiles", "to", "remove", "main", "task", "(", "supported", "but", "discouraged", ")"], "add_tokens": "export default async function ( ) {", "del_tokens": "export default async function main ( ) {", "commit_type": "update"}
{"commit_tokens": ["Use", "callback", "to", "return", "result"], "add_tokens": "if ( err || response . statusCode != 200 ) { callback ( err , testResultUrl ) ; } else { callback ( null , testResultUrl ) ; } callback ( new Error ( \"Hypem url is not correct. It should start with 'http://hypem.com/track/'\" , null ) ) ;", "del_tokens": "callback ( testResultUrl ) ; //if (err) { // return testResultUrl; //} else { // return testResultUrl; //} throw new Error ( \"Hypem url is not correct. It should start with 'http://hypem.com/track/'\" ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "typo", "in", "iau82", "polynomial"], "add_tokens": "export const iau82 = [ 24110.54841 , 8640184.812866 , 0.093104 , - 0.0000062 ]", "del_tokens": "export const iau82 = [ 24110.54841 , 8640184.812866 , 0.093104 , 0.0000062 ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "dispatch", "to", "use", "eventData", ".", "type"], "add_tokens": "eventType = eventData . type ;", "del_tokens": "eventType = event . type ;", "commit_type": "fix"}
{"commit_tokens": ["Allowing", "to", "stop", "/", "play", "if", "focused", "element", "is", "interactive"], "add_tokens": "/ ** * Internal stored time . * @ type { ? number } * / this . time = this . ws_ . options . autoslide ; if ( this . time ) { DOM . once ( wsInstance . el , 'ws:init' , this . play . bind ( this ) ) ; document . body . addEventListener ( 'focus' , this . onFocus . bind ( this ) ) ; } } / ** * On focus handler . Will decide if stops / play depending on the focused * element if autoslide is active . * / onFocus ( ) { if ( DOM . isFocusableElement ( ) ) { this . stop ( ) ; } else if ( this . interval_ === null ) { this . play ( ) ; } time = time || this . time ; this . time = time ;", "del_tokens": "DOM . once ( wsInstance . el , 'ws:init' , this . play . bind ( this ) ) ; time = time || this . ws_ . options . autoslide ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "the", "umd", "build", "of", "msgpack"], "add_tokens": "msgpack5 : \"msgpack5\" , \"@aspnet/signalr\" : \"signalR\" ,", "del_tokens": "msgpack5 : \"msgpack5\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "validate", ".", "js", "to", "sdk"], "add_tokens": "Poller = require ( './poller' ) , ServiceError = require ( './error' ) . ServiceError ; Service . prototype . validate = require ( './validate' ) ; Service . prototype . validateScriptInput = function ( data , constraints , options ) { var errors = this . validate ( data , constraints , options ) ; if ( errors ) { return new ServiceError ( errors . join ( ', ' ) ) ; } } ;", "del_tokens": "Poller = require ( './poller' ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "pathFilter", "for", "alt", "browser", "field"], "add_tokens": "var replacements = info [ browser ] ; if ( ! replacements ) { mappedPath = replacements [ relativePath ] ; if ( ! mappedPath && ( relativePath . lastIndexOf ( \".js\" ) === relativePath . length - 3 ) ) { mappedPath = replacements [ relativePath + \".js\" ] ; } return mappedPath ;", "del_tokens": "if ( ! info . browser ) { if ( typeof info . browser ) { mappedPath = info . browser [ relativePath ] ; if ( ! mappedPath && ( relativePath . lastIndexOf ( \".js\" ) === relativePath . length - 3 ) ) { mappedPath = info . browser [ relativePath + \".js\" ] ; } return mappedPath ; }", "commit_type": "fix"}
{"commit_tokens": ["Using", "React", ".", "DOM", "API", "for", "creating", "elements", "."], "add_tokens": "return React . DOM . span ( { 'key' : this . count } , string ) ; return React . DOM . strong ( { 'key' : this . count , 'className' : 'highlight' } , string ) ; return React . DOM . span ( React . __spread ( { } , this . props ) , this . renderElement ( this . props . children ) ) ;", "del_tokens": "return React . createElement ( 'span' , { 'key' : this . count } , string ) ; return React . createElement ( 'strong' , { 'key' : this . count , 'className' : 'highlight' } , string ) ; return React . createElement ( 'span' , React . __spread ( { } , this . props ) , this . renderElement ( this . props . children ) )", "commit_type": "use"}
{"commit_tokens": ["added", "log", "when", "job", "is", "added"], "add_tokens": "return queueAddJob ( )", "del_tokens": "return queueProcess ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "and", "fix", "for", "argument", "-", "passing", "bug", "."], "add_tokens": "} else { }", "del_tokens": "} else", "commit_type": "add"}
{"commit_tokens": ["changed", "my", "mind", "about", ".", "chr", "too"], "add_tokens": "'chr' : function ( ) {", "del_tokens": "'unicode' : function ( ) {", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", ".", "on", "(", "exit", "function", "(", "code", "signal", ")", "{}", ")"], "add_tokens": "var EventEmitter = require ( 'events' ) . EventEmitter ; // for 'close' this . _internalee = new EventEmitter ( ) ; function afterExit ( code , signal ) { self . emit ( 'exit' , code , signal ) ; } ? pty . fork ( file , args , env , cwd , cols , rows , opt . uid , opt . gid , afterExit ) : pty . fork ( file , args , env , cwd , cols , rows , afterExit ) ; self . emit ( 'close' , null ) ; if ( type === 'close' ) { this . _internalee . on ( 'close' , func ) ; return this ; } if ( arguments [ 0 ] === 'close' ) { return this . _internalee . emit . apply ( this . _internalee , arguments ) ; }", "del_tokens": "? pty . fork ( file , args , env , cwd , cols , rows , opt . uid , opt . gid ) : pty . fork ( file , args , env , cwd , cols , rows ) ; self . emit ( 'exit' , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "blocklyDom", "to", "roboAst", "transformation"], "add_tokens": "[ '', ' ='], name : 'value' , [ '', ' ='], [ '', ' ='], [ '', ' ='], name : 'value' , name : 'count' ,", "del_tokens": "[ '!=' , '!=' ] , name : 'color' , [ '!=' , '!=' ] , [ '>=' , '>=' ] , [ '<=' , '<=' ] , name : 'position' , name : 'position' ,", "commit_type": "implement"}
{"commit_tokens": ["allow", "to", "install", "packages", "in", "cwd"], "add_tokens": "await install ( { packages : [ 'buble-loader' ] , cwd : fixture ( 'simple' ) ,", "del_tokens": "await install ( [ 'buble-loader' ] , fixture ( 'simple' ) , {", "commit_type": "allow"}
{"commit_tokens": ["Use", "Shearer", "syllables", "in", "solfege", "to", "account", "for", "extreme", "intervals", "(", "diminished", "second", "augmented", "seventh", "etc"], "add_tokens": "// Adjusted Shearer syllables - Chromatic solfege system 'd2' : 'raw' , 'd3' : 'maw' , 'A3' : 'mai' , 'd6' : 'law' , 'd7' : 'taw' , 'A7' : 'tai' , 'd8' : 'de' , 'P8' : 'do' , 'A8' : 'di' intervalInt = kNotes [ to . name ] . index - kNotes [ from . name ] . index + ( 7 * ( to . octave - from . octave ) ) ; } else if ( semitones < 0 || intervalInt < 0 ) { intervalInt = - intervalInt ;", "del_tokens": "// Moveable do solfege syllables - Sato Method 'A3' : 'ma' , 'A7' : 'to' , 'P8' : 'do' } else if ( semitones < 0 ) { intervalInt = kNotes [ to . name ] . index - kNotes [ from . name ] . index + ( 7 * ( to . octave - from . octave ) ) ; / *return { name : interval . name , quality : quality , direction : ( semitones > 0 ? 'up' : 'down' ) , simple : simpleName } ; * /", "commit_type": "use"}
{"commit_tokens": ["Changed", "the", "variable", "that", "gets", "printed", "out", "in", "the", "message", "when", "when", "using"], "add_tokens": "record ( \"Set ignored flag for: \" + req . body . requestPath , 0 ) ;", "del_tokens": "record ( \"Set ignored flag for: \" + body . requestPath , 0 ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "gateway", "config", "websocket", "api"], "add_tokens": "console . log ( \"gateway online with socket id:\" , check . socketId ) ;", "del_tokens": "console . log ( \"gateway online\" ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "project", "to", "override", "webpack", "config", "when", "running", "the", "dev", "server", "and", "provide", "a", "default", "configuration"], "add_tokens": "const __path = require ( \"path\" ) ; const defaultWebpackConfig = require . resolve ( '../webpack/webpack.config-development' ) ; const projectDir = __path . resolve ( path ) ; if ( ! project . startDevServer ( projectDir , defaultWebpackConfig ) ) {", "del_tokens": "if ( ! project . startDevServer ( path ) ) {", "commit_type": "allow"}
{"commit_tokens": ["removed", "entities", "from", "scope", "analysis"], "add_tokens": "// how does this work with constants that are really var references? // should work when things are not described as well - but this is for testing // but if it refers to something else if ( ! lvar && this . _desc ) { // entities should be able to extract the needed info instead ROOT . entities ( ) . add ( l . namepath ( ) , { namepath : l . namepath ( ) , type : r . typeName ( ) , desc : this . _desc } ) ; } ; Scope . prototype . loc = function ( ) { return this . node ( ) . loc ( ) ; } ; loc : self . loc ( )", "del_tokens": "// p \"assign {l} {r} {l.value}\" desc : self . _desc , loc : self . region ( ) } ; desc . meta = self . _node && self . _node . metadata && self . _node . metadata ( ) ; for ( var i = 0 , ary = iter$ ( self . _annotations ) , len = ary . length , res = [ ] ; i < len ; i ++ ) { res . push ( ary [ i ] . metadata ( ) ) ; desc . entities = res ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "function", "to", "get", "the", "total", "upload", "size"], "add_tokens": "$ . getSize = function ( ) { var totalSize = 0 ; $h . each ( $ . files , function ( file ) { totalSize += file . size ; } ) ; return ( totalSize ) ; } ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "that", "failed", "because", "in", "an", "idCode", "there", "was", "ascii", "code", "127", "(", "that", "corresponds", "to", "delete", "!", ")"], "add_tokens": "diaIDs [ 0 ] . oclID . should . equal ( 'gC`HALiKT@' + String . fromCharCode ( 127 ) + 'RHDRj@' ) ;", "del_tokens": "diaIDs [ 0 ] . oclID . should . equal ( 'gC`HALiKT@RHDRj@' ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "collection", "fetch", "and", "create", "set", "action", "even", "if", "it", "exists", "action", "set", "override", "existing", "actions", "."], "add_tokens": "options . action = 'create' ; options . action = 'fetch' ;", "del_tokens": "options . action = options . action || 'create' ; options . action = options . action || 'fetch' ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "support", "for", "sending", "fragmented", "frames", "."], "add_tokens": "httpServer : server", "del_tokens": "httpServer : server , maxReceivedFrameSize : 6", "commit_type": "add"}
{"commit_tokens": ["fix", "import", "paths", "in", "SettingsPanel"], "add_tokens": "import rcFont from '../../assets/RcFont/RcFont.scss' ; import Header from '../Header' ; import Panel from '../Panel' ; import Line from '../Line' ; import LinkLine from '../LinkLine' ; import IconLine from '../IconLine' ; import Eula from '../Eula' ; import Switch from '../Switch' ;", "del_tokens": "import rcFont from '../../../src/assets/RcFont/RcFont.scss' ; import Header from '../../../src/components/Header' ; import Panel from '../../../src/components/Panel' ; import Line from '../../../src/components/Line' ; import LinkLine from '../../../src/components/LinkLine' ; import IconLine from '../../../src/components/IconLine' ; import Eula from '../../../src/components/Eula' ; import Switch from '../../../src/components/Switch' ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "beginning", "newline", "from", "parsed", "pug"], "add_tokens": "yep ( this . pug . substring ( 1 ) )", "del_tokens": "yep ( this . pug )", "commit_type": "remove"}
{"commit_tokens": ["Add", "quotes", "rule", "and", "test", "coverage", "for", "configuration", "options"], "add_tokens": "var constructorName = \"\" ; if ( constructorName . charAt ( 0 ) === constructorName . charAt ( 0 ) . toLowerCase ( ) ) { context . report ( node , \"A constructor name should start with an uppercase letter.\" ) ;", "del_tokens": "var constructorName = \"\" , inWhiteList = false ; inWhiteList = context . options . some ( function ( validConstructorName ) { return validConstructorName === constructorName ; } ) ; if ( ! inWhiteList ) { if ( constructorName . charAt ( 0 ) === constructorName . charAt ( 0 ) . toLowerCase ( ) ) { context . report ( node , \"A constructor name should start with an uppercase letter.\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Adds", "graph", "-", "util", "for", "deep", "clone", "topological", "sort"], "add_tokens": "'alwaysLoadedAfterModules' : {", "del_tokens": "'dependsOnModules' : {", "commit_type": "add"}
{"commit_tokens": ["Updated", "references", "to", "use", "org", "scope"], "add_tokens": "const couchbackup = require ( '@cloudant/couchbackup' ) ;", "del_tokens": "const couchbackup = require ( 'couchbackup' ) ;", "commit_type": "update"}
{"commit_tokens": ["removed", "useless", "tests", "for", "lancaster"], "add_tokens": "it ( 'should stem and append and recurse' , function ( ) {", "del_tokens": "it ( 'should stem and append' , function ( ) { it ( 'should nest rules' , function ( ) { expect ( 'measurably' . stem ( ) ) . toBe ( 'meas' ) ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Move", "Dropdown", "to", "own", "component"], "add_tokens": "import Dropdown from './dropdown' const NavigationDropdown = ( { items , section } ) => { < Dropdown defaultValue = { defaultValue } className = { classes . dropdown } > < / Dropdown > < NavigationDropdown items = { items } section = { section } / >", "del_tokens": "import { navigate } from 'gatsby' const Dropdown = ( { items , section } ) => { < select defaultValue = { defaultValue } className = { classes . dropdown } onChange = { ( { target } ) => navigate ( target . value ) } > < / select > < Dropdown items = { items } section = { section } / >", "commit_type": "move"}
{"commit_tokens": ["make", "time", "pickers", "a", "little", "bit", "more", "user", "friendly"], "add_tokens": "// this.highlightHour(); //console.log(this.previousSibling.previousSibling.tagName); //this.highlightMeridian();", "del_tokens": "this . highlightHour ( ) ; this . highlightMeridian ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "stop", "functions", "to", "farmer", "consolidated", "some", "code"], "add_tokens": "exports . utils = require ( './lib/utils' ) ; /** {@link Utils} */ exports . reporter = require ( './lib/reporter' ) ;", "del_tokens": "exports . Utils = require ( './lib/utils' ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "dependent", "libraries", "and", "put", "it", "in", "npm"], "add_tokens": "var FR = require ( '../lib/FASTAReader' ) ;", "del_tokens": "var FR = require ( '../FASTAReader' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "media", "queries"], "add_tokens": "var res ; if ( media === '' ) { res = data . rules ; } else { res = { type : 'media' , media : media , rules : data . rules } ; } rules = rules . concat ( res ) ;", "del_tokens": "rules = rules . concat ( data . rules ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "way", "spawn", "env", "were", "set", "-", "to", "my", "liking", ".."], "add_tokens": "//add some extra env params var env = extend ( { } , process . env ) ; if ( exports . config . condorConfig ) { env . CONDOR_CONFIG = exports . config . condorConfig ; if ( exports . config . condorLocation ) { env . PATH = path . join ( exports . config . condorLocation , 'bin' ) + ':' + path . join ( exports . config . condorLocation , 'sbin' ) + ':' + env . PATH ; var p = spawn ( cmd , opts , { env : env } ) ; //, {cwd: __dirname});", "del_tokens": "// Export the condor config, if set if ( exports . config [ 'condorConfig' ] ) { process . env [ 'CONDOR_CONFIG' ] = exports . config [ 'condorConfig' ] ; // Update the PATH, if condorLocation is set if ( exports . config [ 'condorLocation' ] ) { process . env [ 'PATH' ] = path . join ( exports . config [ 'condorLocation' ] , 'bin' ) + ':' + path . join ( exports . config [ 'condorLocation' ] , 'sbin' ) + ':' + process . env [ 'PATH' ] ; var p = spawn ( cmd , opts ) ; //, {cwd: __dirname});", "commit_type": "update"}
{"commit_tokens": ["Add", "String", "()", "behaviour", "to", "replyTo"], "add_tokens": "// replyTo: String(mailData.email), // This is optional and reliant on your form actually collecting a field named `email`", "del_tokens": "replyTo : \"\" + mailData . email ,", "commit_type": "add"}
{"commit_tokens": ["added", "gulp", "jshint", "to", "assist", "with", "code", "quality", "and", "bumping", "releases"], "add_tokens": "while ( ( arr = re . exec ( template ) ) !== null ) { return this . namespace ? util . format ( '%s:%s' , this . namespace . prefix , this . name ) : this . name ; } ;", "del_tokens": "while ( ( arr = re . exec ( template ) ) != null ) { return this . namespace ? util . format ( \"%s:%s\" , this . namespace . prefix , this . name ) : this . name ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "analytics", ".", "js", "reference", "after", "script", "has", "loaded"], "add_tokens": "return window . analytics [ method ] . apply ( analytics , arguments ) ;", "del_tokens": "return analytics [ method ] . apply ( analytics , arguments ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "all", "currently", "supported", "Request", "functionality"], "add_tokens": "this . path = parsedURL . pathname ; this . protocol = ( parsedURL . protocol || window . location . protocol ) . replace ( ':' , '' ) ; if ( ! type ) return false ;", "del_tokens": "this . path = parsedURL . path ; this . protocol = parsedURL . protocol ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "test", "for", "syntax", "errors", "."], "add_tokens": "sources : [ 'package.json' , '*.js' , 'tasks/**/*.js' , 'build/**/*.js' , 'src/**/*.js' , 'spec/**/*.js' , '!spec/**/*.error.js' , '!spec/browser/json2.js' ] , 'spec/browser/json2.js' ,", "del_tokens": "sources : [ 'package.json' , '*.js' , 'tasks/**/*.js' , 'build/**/*.js' , 'src/**/*.js' , 'spec/**/*.js' ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "edges", "sometimes", "passing", "through", "nodes"], "add_tokens": "var xs = values ( xss ) . map ( function ( xs ) { return xs [ u . id ( ) ] ; } ) . sort ( function ( x , y ) { return x - y ; } ) ;", "del_tokens": "var xs = values ( xss ) . map ( function ( xs ) { return xs [ u . id ( ) ] ; } ) . sort ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "an", "issue", "where", "the", "images", "wouldn", "t", "load", "correctly"], "add_tokens": "assetURL : 'https://minicart.paypal-labs.com/build/' ,", "del_tokens": "assetURL : 'https://minicart.paypal-labs.com/' ,", "commit_type": "fix"}
{"commit_tokens": ["Adding", "ability", "to", "lookup", "values", "by", "index", "using", "[]"], "add_tokens": "} else if ( exprData instanceof expression . Bracket ) { value = exprData . value ( scope ) ; if ( exprData . isHelper ) { return value ; } if ( ! ( exprData instanceof expression . Helper ) && ! ( exprData instanceof expression . Call ) && ! ( exprData instanceof expression . Bracket ) ) {", "del_tokens": "if ( ! ( exprData instanceof expression . Helper ) && ! ( exprData instanceof expression . Call ) ) {", "commit_type": "add"}
{"commit_tokens": ["use", "d3", "-", "view", "-", "test"], "add_tokens": "import { render } from 'd3-view-test' ;", "del_tokens": "import render from 'd3-view/test/render' ;", "commit_type": "use"}
{"commit_tokens": ["update", "build", "dependencies", "and", "version", "number", "for", "npm"], "add_tokens": "// Generated by CoffeeScript 1.7.1 //# sourceMappingURL=script.map", "del_tokens": "// Generated by CoffeeScript 1.6.3 / * //@ sourceMappingURL=script.map * /", "commit_type": "update"}
{"commit_tokens": ["added", "precommit", "npm", "-", "script", "and", "updated", ".", "huskyrc", ".", "js"], "add_tokens": "'pre-commit' : 'npm run precommit'", "del_tokens": "'pre-commit' : 'lint-staged'", "commit_type": "add"}
{"commit_tokens": ["Remove", "asc", "<", "--", ">", "desc", "hack"], "add_tokens": "sortAsc = require ( 'sort-asc' ) , sortDesc = require ( 'sort-desc' ) ;", "del_tokens": "// Yes, asc <-> desc happens. That's because sort-asc and sort-desc are // named the opposite of what they do IMO. sortAsc = require ( 'sort-desc' ) , sortDesc = require ( 'sort-asc' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "link", "to", "GitHub", "commit", "details", "by", "default"], "add_tokens": "* Copyright ( c ) 2014 - 2015 Martin Wendt", "del_tokens": "* Copyright ( c ) 2014 Martin Wendt", "commit_type": "add"}
{"commit_tokens": ["Make", "global", "max", "volume", "calculation", "a", "bit", "simpler", "."], "add_tokens": "maxVolume = Math . max ( maxVolume , node . maxVolume || 0 ) ; this . state . maxVolume = maxVolume * 1.5 ;", "del_tokens": "maxVolume = maxVolume + ( node . maxVolume || 0 ) ; this . state . maxVolume = ( maxVolume / ( ( state . nodes . length - 1 ) || 1 ) ) * 1.8 ;", "commit_type": "make"}
{"commit_tokens": ["removed", "unnecessary", "null", "/", "undefined", "checks"], "add_tokens": "* @ returns { * } The value of the property return style . getPropertyValue ( property ) ;", "del_tokens": "* This function solely exists for the check to the style p operty b fore * invoking the expensive function getComputedStyle . if ( ! isDefined ( element . style ) ) { return null ; // not a styled element, e.g. document } * @ returns { * } Returns the value of the property or undefined if style is not thruthy . * This function solely exists for caching reasons . return style ? style . getPropertyValue ( property ) : undefined ; if ( ! style ) { return false ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "global", "data", "handler", "overrides"], "add_tokens": "globalHandleList : function ( fn ) { } ,", "del_tokens": "globalHandleList : function ( ) { } ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "try", "/", "catch", "edge", "cases"], "add_tokens": "catch ( e ) { return __propagate ( _ , e ) ; catch ( e ) { return __propagate ( _ , e ) ; catch ( e ) { return __propagate ( _ , e ) ; catch ( e ) { return __propagate ( _ , e ) ; __propagate ( cb , ex ) ; exports . version = \"0.1.1b2\" ;", "del_tokens": "catch ( __err ) { return _ ( __err ) ; catch ( __err ) { return __propagate ( _ , __err ) ; catch ( __err ) { return __propagate ( _ , __err ) ; catch ( __err ) { return _ ( __err ) ; cb ( ex ) exports . version = \"0.1.1b1\" ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "any", "in", "-", "scope", "node", "modules", "directory", "first", "for", "non", "-", "loader", "module", "resolution"], "add_tokens": "var fs = require ( 'fs' ) / ** * Tries to find a node_modules directory which will be resolved for requires * from the working directory . * / function findWorkingDirNodeModules ( ) { var parts = process . cwd ( ) . split ( path . sep ) while ( parts . length > 0 ) { var target = path . join ( parts . join ( path . sep ) , 'node_modules' ) if ( fs . existsSync ( target ) ) { return target } parts . pop ( ) } } / ** * We need to special - case exclusion to allow the heatpack dummy entry module to * be processed by loaders , as it will be under global node_modules . * / // If there's a node_modules in scope from where the user ran heatpack, we // want to pick up React from it first, so prepend it to the list of // directories to resolve modules from. root : findWorkingDirNodeModules ( ) , fallback : HEATPACK_MODULES , alias : options . alias // Always resolve loaders from heatpack's own dependencies root : HEATPACK_MODULES", "del_tokens": "// We need to special-case loading the heatpack dummy entry module as it will // be under global node_modules. alias : options . alias , fallback : HEATPACK_MODULES // Resolve loaders from heatpack's dependencies modulesDirectories : [ HEATPACK_MODULES ] ,", "commit_type": "use"}
{"commit_tokens": ["Add", "enter", "to", "default", "extend", "/", "retract", "keys"], "add_tokens": "options . keys = options . keys || [ '+' , 'space' , 'enter' ] ;", "del_tokens": "options . keys = options . keys || [ '+' , 'space' ] ;", "commit_type": "add"}
{"commit_tokens": ["Remove", ":", "Left", "over", "console", "statements"], "add_tokens": "", "del_tokens": "console . log ( args ) ; console . log ( type ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "default", "exports", "for", "node", ".", "js"], "add_tokens": "import $C from './core' ; export default $C ; import { IS_NODE } from './consts/hacks' ; if ( IS_NODE ) { module . exports = exports = $C ; }", "del_tokens": "export { default as default } from './core' ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bugs", "noticed", "during", "review"], "add_tokens": "request . input ( paramName , clean [ 0 ] , clean [ 1 ] ) ;", "del_tokens": "request . input ( paramName , param ) ; return request . input ( paramName , clean [ 0 ] , clean [ 1 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "names", "of", "typing", "files"], "add_tokens": "writeFileSync ( path . resolve ( __dirname , 'index.js.flow' ) , sourceFlow , { encoding : 'utf8' } ) writeFileSync ( path . resolve ( __dirname , 'index.d.ts' ) , sourceTs , { encoding : 'utf8' } )", "del_tokens": "writeFileSync ( path . resolve ( __dirname , 'telegram-typings.flow.js' ) , sourceFlow , { encoding : 'utf8' } ) writeFileSync ( path . resolve ( __dirname , 'telegram-typings.d.ts' ) , sourceTs , { encoding : 'utf8' } )", "commit_type": "change"}
{"commit_tokens": ["add", "prototype", "keyword", "to", "Rectangle"], "add_tokens": "PIXI . Rectangle . prototype . contains = function ( x , y )", "del_tokens": "PIXI . Rectangle . contains = function ( x , y )", "commit_type": "add"}
{"commit_tokens": ["Fix", "so", "the", "paths", "will", "be", "properly", "resolved", "and", "working", "when", "the", "git", "directory", "differs", "from", "the", "current", "working", "directory"], "add_tokens": "const tasks = generateTasks ( config , resolvePaths ( files , sgf . cwd ) )", "del_tokens": "const tasks = generateTasks ( config , resolvePaths ( files ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "about", "specify", "the", "config", "file"], "add_tokens": "} , FILE : 'cooking.conf.js'", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["add", "screenshot", "to", "html", "report", "for", "failed", "scenarios"], "add_tokens": "function consoleInfo ( ) { Object . keys ( runtime ) . forEach ( function ( key ) { global . sharedObjectPaths . forEach ( function ( itemPath ) { if ( fs . existsSync ( itemPath ) ) { if ( Object . keys ( allDirs ) . length > 0 ) { // executed after each scenario this . After ( function ( scenario , done ) { if ( scenario . isFailed ( ) ) { // add a screenshot to the error report driver . takeScreenshot ( ) . then ( function ( screenShot ) { scenario . attach ( new Buffer ( screenShot , 'base64' ) , 'image/png' , done ) ; } ) ; // test failed, dont close the browser } else { // if the test passed close the browser to ensure a fresh enviroment for the next scenario driver . quit ( ) ; done ( ) ;", "del_tokens": "function consoleInfo ( ) { Object . keys ( runtime ) . forEach ( function ( key ) { global . sharedObjectPaths . forEach ( function ( itemPath ) { if ( fs . existsSync ( itemPath ) ) { if ( Object . keys ( allDirs ) . length > 0 ) { // close the browser after each scenario to ensure a fresh enviroment for the next scenario this . After ( function ( scenario ) { if ( ! scenario . isFailed ( ) ) { return driver . quit ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "table", "aliases", "in", "joins"], "add_tokens": "return this . wrap ( table ) ;", "del_tokens": "return this . wrapValue ( table ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "mock", "feature", "to", "support", "specifically", "enabled", "mocks", "by", "action", "in", "the", "blueprint", "."], "add_tokens": "//console.log(self.app.models[model]);", "del_tokens": "console . log ( self . app . models [ model ] ) ;", "commit_type": "update"}
{"commit_tokens": ["Updated", "error", "in", "output", "scripts", "which", "caused", "memory", "dumps", "to", "fail", "."], "add_tokens": "callback ( null , csvFile ) ;", "del_tokens": "callback ( csvFile ) ;", "commit_type": "update"}
{"commit_tokens": ["move", "Firmata", ".", "h", "from", "addHeader", "to", "addIncludes"], "add_tokens": "var includes = \"#include <Firmata.h>\" ; includes += \"\\n\\n\" ;", "del_tokens": "header += \"#include <Firmata.h>\" ; header += \"\\n\\n\" ; var includes = \"\" ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "some", "errors", "in", "lib", "/", "array", ".", "js"], "add_tokens": "} } var closestVal = null , if ( closestVal === null || Math . abs ( this [ i ] - goal ) < Math . abs ( closestVal - goal ) ) { closestVal = this [ i ] ; return closestVal ; break ;", "del_tokens": "} ; } ; var closest = null , if ( closest === null || Math . abs ( this [ i ] - goal ) < Math . abs ( closest - goal ) ) { closest = this [ i ] ; return closest ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "basic", "testing", "for", "addEntry", "()"], "add_tokens": "timesheet . addEntry ( { date : now , start : Number ( now . getTime ( ) - 100000 ) , end : now , tags : [ \"demo\" ] , notes : \"This is me, using this software.\" } ) ; // How let's display the revised contents based on // the toString() rendering", "del_tokens": "timesheet . addEntry ( { date : now , start : ( now - 100000 ) , end : now , tags : [ \"demo\" ] , notes : \"This is me, using this software.\" } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "milestone", "generator", "for", "org", "-", "wide", "milestones"], "add_tokens": "var fakeRepo = { name : 'fake-repo' , milestones : { create : function ( ) { return Promise . resolve ( ) ; } , } , this . repoInfo = [ fakeRepo , ] ; // Octokat API will sometimes return array or an iterable object; // this fake needs to simulate both behaviours. this . repoInfo . issues = fakeRepo . issues ; Octokat . prototype . orgs = function ( ) { var self = this ; return { repos : self . repos ( ) , } ; } ; // For the purposes of the fake, it's the same thing. Octokat . prototype . users = Octokat . prototype . orgs ;", "del_tokens": "this . repoInfo = {", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "extra", "test", "."], "add_tokens": "it ( 'parse + character correctly' , function ( ) { var parsed = new Uri ( 'http://example.com?test=a%2Bb' ) expect ( parsed . toString ( ) ) . to . equal ( 'http://example.com/?test=a%2Bb' ) } ) it ( 'parse space character encoded as + correctly' , function ( ) { it ( 'parse + character correctly' , function ( ) {", "del_tokens": "it ( 'parse + character correctly without changing it' , function ( ) { it ( 'parse + character correctly without changing it' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "some", "docs", "and", "included", "License", "in", "index", ".", "js"], "add_tokens": "/ * * Copyright 2013 Research In Motion Limited . * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / // methods to start and stop scanning", "del_tokens": "// Thread methods to start and stop", "commit_type": "update"}
{"commit_tokens": ["changed", "calls", "to", "Connection", ".", "send", "to", "write", "()", "."], "add_tokens": "self . write ( \"AMQP\" + String . fromCharCode ( 1 , 1 , 8 , 0 ) ) ; // in order to allow reconnects, have to clear the // Channel 0 is the control channel. If not zero then deligate to this . write ( c ) ; connection . write ( s ) ; this . write ( b ) ; this . write ( b ) ; this . write ( body ) ; this . write ( String . fromCharCode ( 206 ) ) ; // frameEnd this . write ( b ) ; if ( ! task . reply ) { self . emit ( 'jsonMessage' , json ) ;", "del_tokens": "self . send ( \"AMQP\" + String . fromCharCode ( 1 , 1 , 8 , 0 ) ) ; // in order to allow reconnects, have to clear the // Channel 0 is the control channel. If not zero then deligate to this . send ( c ) ; connection . send ( s ) ; this . send ( b ) ; this . send ( b ) ; this . send ( body ) ; this . send ( String . fromCharCode ( 206 ) ) ; // frameEnd this . send ( b ) ; if ( ! task . reply ) { self . emit ( 'jsonMessage' , json ) ;", "commit_type": "change"}
{"commit_tokens": ["adding", "ability", "to", "pass", "array", "to", "get", "method"], "add_tokens": "} ) ) ; it ( 'should return an object containing the key/value pairs passed in via array' , inject ( function ( ) { locker . put ( function ( ) { return { 'something' : 'some value' , 'anotherThing' : [ 'foo' , 'bar' ] , 'lorem' : true } ; } ) ; var result = locker . get ( [ 'something' , 'anotherThing' ] ) ; expect ( angular . isObject ( result ) ) . toBeTruthy ( ) ; expect ( result . something ) . toEqual ( 'some value' ) ; expect ( result ) . not . toEqual ( jasmine . objectContaining ( { lorem : true } ) ) ; } ) ) ; } ) ;", "del_tokens": "} ) ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "the", "new", "glaze", "work", "with", "basic", "features", "+", "cake", "bake"], "add_tokens": "var QQ = { \"client\" : { } , \"shared\" : { } , \"data\" : { } } ; var requireConfig = { \"namespace\" : \"QQ\" , \"domains\" : [ \"client\" , \"shared\" ] } ; scannable = [ reqStr . match ( DomReg ) [ 1 ] ] ; reqStr = reqStr . split ( '::' ) [ 1 ] ; ( function ( ) { QQ . define ( 'bigthing/sub2.coffee' , 'client' , function ( require , module , exports ) { module . exports = function ( str ) { console . log ( '2100?' , v . isLeapYear ( 2100 ) ) ; } ) ; } ) ( ) ;", "del_tokens": "var QQ = { \"client\" : { } , \"shared\" : { } , \"data\" : { } } ; var requireConfig = { \"namespace\" : \"QQ\" , \"domains\" : [ \"client\" , \"shared\" ] } ; scannable = [ reqStr . match ( DomReq ) [ 1 ] ] ; QQ . define ( 'bigthing/sub2.coffee' , 'client' , function ( require , module , exports ) { module . exports = function ( str ) { console . log ( '2100?' , v . isLeapYear ( 2100 ) ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "fake", "apikey", "and", "replace", "by", "ENV", "var"], "add_tokens": "var apikey = process . env . ote_apikey ;", "del_tokens": "var apikey = 'GJL7RR88hRMRrIRz3R5grAfB' ;", "commit_type": "remove"}
{"commit_tokens": ["remove", "clients", "that", "have", "gone", "away"], "add_tokens": "sender . killFunction = function ( ) { delete oscSenders [ sender . host ] ; } ; // Kill the OSC client if we haven't heard from it in a while. clearTimeout ( sender . killTimeout ) ; sender . killTimeout = setTimeout ( sender . killFunction , 5000 ) ;", "del_tokens": "Client Demonstrate remote configuration -- color is defined in remote server config ClusterState class maintains an AppState for each node Client gets back its own AppState", "commit_type": "remove"}
{"commit_tokens": ["Allow", "safe", "concatenation", "with", "other", "programs"], "add_tokens": "safe , semicolons : true , safe : false result = '' ; if ( safe && stmt . type === Syntax . Program && stmt . body . length === 0 ) { result += '\\n' ; } result += generateComment ( comment ) ; len = stmt . body . length ; result = safe && len > 0 ? '\\n' : '' ; for ( i = 0 ; i < len ; i += 1 ) { fragment = addIndent ( generateStatement ( stmt . body [ i ] , { semicolonOptional : ! safe && i === len - 1 } ) ) ; result = addCommentsToStatement ( stmt , result ) ; } if ( ! safe && newline === '' && result . charAt ( result . length - 1 ) === '\\n' ) { return result . slice ( 0 , - 1 ) ; safe = options . format . safe ;", "del_tokens": "semicolons : true result = generateComment ( comment ) ; result = '' ; for ( i = 0 , len = stmt . body . length ; i < len ; i += 1 ) { fragment = addIndent ( generateStatement ( stmt . body [ i ] , { semicolonOptional : i === len - 1 } ) ) ; return addCommentsToStatement ( stmt , result ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "rollup", "-", "plugin", "-", "alias", "options"], "add_tokens": "format : 'es' , external : [ 'ember' , 'require' ] , 'ember-test-helpers' : './ember-test-helpers/' , format : 'es' , format : 'es' , 'ember-mocha' : './ember-mocha/' ,", "del_tokens": "external : [ 'ember' ] , 'ember-test-helpers/' : './ember-test-helpers/' , 'ember-mocha/' : './ember-mocha/' ,", "commit_type": "fix"}
{"commit_tokens": ["fix", "unicode", "range", "to", "include", "charachters", "161", "and", "higher", "(", "UNICODE", "310", "/", "ISO", "10646", ")"], "add_tokens": "// http://www.w3.org/TR/css3-syntax/#characters // unicode/ISO 10646 characters 161 and higher encoding = '\\u00a1-\\uffff' ,", "del_tokens": "// ascii + unicode encoding = '\\u0080-\\uffff' ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "enabled", "option", "bump", "keyboard", "-", "controls", "."], "add_tokens": "if ( ! this . data . enabled ) { return ; } else if ( ! event . type ) {", "del_tokens": "if ( ! event . type ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "for", "download", "box", "content"], "add_tokens": "var that = this ; return new Model ( that , data ) ; return new Model ( that , d ) ;", "del_tokens": "return new Model ( this , data ) ; return new Model ( this , d ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "an", "errant", "console", ".", "log"], "add_tokens": "function write ( status , data , contentType ) {", "del_tokens": "function write ( status , data , contentType ) { console . log ( data ) ;", "commit_type": "remove"}
{"commit_tokens": ["makes", "default", "generated", "POST", "lambda", "use", "req", ".", "_url", "helper"], "add_tokens": "res ( { location : req . _url ( '/' ) } )", "del_tokens": "res ( { location : ` ` } )", "commit_type": "make"}
{"commit_tokens": ["Fix", "node", "4", "-", "5", "builds"], "add_tokens": "\"use strict\" ; const webpackPromise = function ( config , globalPlugins ) { if ( Array . isArray ( globalPlugins ) ) { globalPlugins . forEach ( p => compiler . apply ( p ) ) ; } async function executeAndGetLogs ( fixture , globalPlugins ) { await webpackPromise ( require ( fixture ) , globalPlugins ) ; let globalPlugins = [ new FriendlyErrorsWebpackPlugin ( ) ] ; const logs = await executeAndGetLogs ( './fixtures/multi-compiler-success/webpack.config' , globalPlugins ) ; let globalPlugins = [ new FriendlyErrorsWebpackPlugin ( ) ] ; const logs = await executeAndGetLogs ( './fixtures/multi-compiler-module-errors/webpack.config' , globalPlugins ) ;", "del_tokens": "const webpackPromise = function ( config , ... globalPlugins ) { globalPlugins . forEach ( p => compiler . apply ( p ) ) ; async function executeAndGetLogs ( fixture , ... globalPlugins ) { await webpackPromise ( require ( fixture ) , ... globalPlugins ) ; const logs = await executeAndGetLogs ( './fixtures/multi-compiler-success/webpack.config' , new FriendlyErrorsWebpackPlugin ( ) ) ; const logs = await executeAndGetLogs ( './fixtures/multi-compiler-module-errors/webpack.config' , new FriendlyErrorsWebpackPlugin ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "shell", "-", "quote", "to", "escape", "pip", "and", "chown", "commands", "inside", "the", "docker", "container"], "add_tokens": "const quote = require ( 'shell-quote' ) . quote ; pipCmd = quote ( pipCmd ) ; chownCmd = quote ( [ 'chown' , '-R' , ` ${ process . getuid ( ) } ${ process . getgid ( ) } ` , '.serverless/requirements' ] ) ;", "del_tokens": "pipCmd = pipCmd . join ( ' ' ) ; chownCmd = ` ${ process . getuid ( ) } ${ process . getgid ( ) } `", "commit_type": "use"}
{"commit_tokens": ["Adding", "entry", "point", "for", "babel"], "add_tokens": "var ERRORS = { rated : 'You have hit the rate limit. Free for non-commercial use for up to 10 requests per minute! To increase your rate limit, please contact api@superevilmegacorp.com' , auth : 'Unauthorized, invalid API key provided.' , unknown : 'Unknown error, please try your request again.' } ; var messages = this . parseErrors ( body . errors ) ; return { error : true , messages : messages } ; } , { key : 'parseErrors' , value : function parseErrors ( errors ) { return errors . map ( function ( err ) { switch ( err . title ) { case 'Unauthorized' : return ERRORS . auth ; default : return ERRORS . unknown ; } } ) ; } return _context . abrupt ( 'return' , { error : true , messages : [ 'NO DATA' ] } ) ; return _context . abrupt ( 'return' , new Error ( parsedBody . messages ) ) ; case 21 :", "del_tokens": "return { error : true , message : body . errors } ; return _context . abrupt ( 'return' , { error : true , message : 'NO DATA' } ) ; return _context . abrupt ( 'return' , new Error ( parsedBody ) ) ; console . log ( 'error' , _context . t0 ) ; case 22 :", "commit_type": "add"}
{"commit_tokens": ["add", "getTemplate", "function", "to", "locals"], "add_tokens": "var config = require ( 'config' ) , glob = require ( 'glob' ) , _ = require ( 'lodash' ) , log = require ( './log' ) , / ** * get full filename w / extension * @ param { string } name e . g . \"entrytext\" * @ return { string } e . g . \" components / entrytext / template . jade \" * / function getTemplate ( name ) { var filePath = 'components/' + name + '/' + config . get ( 'names.template' ) , possibleTemplates = glob . sync ( filePath + '.*' ) ; if ( ! possibleTemplates . length ) { throw new Error ( 'No template files found for ' + filePath ) ; } // return the first template found return possibleTemplates [ 0 ] ; } locals : locals , getTemplate : getTemplate } catch ( e ) { } ; module . exports . getTemplate = getTemplate ; // for testing", "del_tokens": "var log = require ( './log' ) , locals : locals } catch ( e ) { } ;", "commit_type": "add"}
{"commit_tokens": ["add", "run", "-", "android", "/", "ios", "fro", "antm"], "add_tokens": "'version' : [ versionInfo , 'print version' ] , 'run-android' : [ runAndroid , 'builds your app and starts it on a connected Android emulator or device' ] , 'run-ios' : [ runIOS , 'builds your app and starts it on iOS simulator' ] ,", "del_tokens": "'version' : [ versionInfo , 'print version' ] // 'run-android': [runAndroid, 'builds your app and starts it on a connected Android emulator or device'], // 'run-ios': [runIOS, 'builds your app and starts it on iOS simulator'],", "commit_type": "add"}
{"commit_tokens": ["fix", "exception", "when", "call", "mocha", "HTML", "reporter"], "add_tokens": "// 1.4.2 moved reporters to Mocha instead of mocha var mochaInstance = window . Mocha || window . mocha ; var GruntReporter = function ( runner ) { var Klass = function ( ) { } ; Klass . prototype = mochaInstance . reporters . HTML . prototype ; GruntReporter . prototype = new Klass ( ) ;", "del_tokens": "var GruntReporter = function ( runner ) { // 1.4.2 moved reporters to Mocha instead of mocha var mochaInstance = window . Mocha || window . mocha ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "innersvg", "-", "polyfill", ".", "js"], "add_tokens": "\"<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'>\" +", "del_tokens": "\"<svg xmlns='http://www.w3.org/2000/svg'>\" +", "commit_type": "update"}
{"commit_tokens": ["added", "captcha", "support", "to", "signup"], "add_tokens": "remember_me : Joi . string ( ) . description ( \"checkbox on\" ) , accept_terms : Joi . string ( ) . description ( \"checkbox on\" ) ,", "del_tokens": "remember_me : Joi . number ( ) . description ( \"boolean\" ) , accept_terms : Joi . number ( ) . description ( \"boolean\" ) ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "update", "socketid", "since", "npm", "no", "longer", "needs", "to", "pass", "socketid"], "add_tokens": "require ( './lib/updateSocketId' ) ( { uuid : data . uuid , token : data . token , socketid : socket . id . toString ( ) } , function ( auth ) {", "del_tokens": "require ( './lib/updateSocketId' ) ( data , function ( auth ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "clauses", "shielding", "in", "_extension", "()"], "add_tokens": "ext [ prop_name ] = sql [ prop_name ] ; } ) ; [ 'select' , 'insert' , 'update' , 'delete' ] . forEach ( function ( stmt ) { var cls = sql [ stmt ] ; ext [ stmt ] = subclass ( cls ) ; ext [ stmt ] . defineClause = cls . defineClause ; ext [ stmt ] . prototype . clauses = cls . prototype . clauses . slice ( ) ; ext . insertInto = ext . insert ; ext . deleteFrom = ext . delete ;", "del_tokens": "var item = sql [ prop_name ] ; if ( ! ( item instanceof Statement ) ) return ext [ prop_name ] = item ; ext [ prop_name ] = subclass ( item ) ; ext [ prop_name ] . defineClause = item . defineClause ; ext [ prop_name ] . prototype . clauses = item . prototype . clauses . slice ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "SPA", "path", "instead", "of", "relying", "on", "..", "/", "..", "/"], "add_tokens": "const packageJson = require ( path . resolve ( process . cwd ( ) , 'package.json' ) ) ;", "del_tokens": "const packageJson = require ( path . resolve ( __dirname , '..' , '..' , 'package.json' ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "null", "rendering", "in", "components"], "add_tokens": "var node = rquery_getDOMNode ( component ) ; if ( node ) { return node . getAttribute ( 'data-reactid' ) ; } return '' ;", "del_tokens": "return rquery_getDOMNode ( component ) . getAttribute ( 'data-reactid' ) ; console . log ( component ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "to", "reset", "client", "subscriptions", "before", "(", "re", ")", "starting", "them"], "add_tokens": "this . _reset ( ) ; / ** * Prepare to start the subscription . May be called after starting the subscription without * having stopped the subscription using ` ` . This is useful if the connection was disconnected * and we are reconnecting . * / _reset ( ) { this . _isReady = false ; this . _isFailed = false ; this . _initializationError = null ; this . _isStopped = false ; } * * ` ` must be called first . // If we hit this, someone forgot to call `_reset`. if ( this . _isReady ) throw new Error ( ` ${ this . _id } ` ) ; export default Subscription ;", "del_tokens": "this . _isReady = false ; this . _isFailed = false ; this . _isStopped = false ; export default Subscription ;", "commit_type": "make"}
{"commit_tokens": ["Removed", "JS", ".", "Class", "from", "nodes"], "add_tokens": "assert . equal ( $$ . isInstanceOf ( node , __ . SequenceNode ) , true ) ; assert . equal ( $$ . isInstanceOf ( scalar , __ . ScalarNode ) , true ) ;", "del_tokens": "assert . equal ( node . isA ( __ . SequenceNode ) , true ) ; assert . equal ( scalar . isA ( __ . ScalarNode ) , true ) ;", "commit_type": "remove"}
{"commit_tokens": ["make", "angoose", "-", "jquery", "callable", "add", "url", "field", "type"], "add_tokens": "function angoose_jquery_adapater ( ) { angoose_jquery_adapater ( ) ;", "del_tokens": "( function ( ) { } ) ( ) ; // testing functions function $anget ( serviceName ) { return angular . element ( document ) . injector ( ) . get ( serviceName )", "commit_type": "make"}
{"commit_tokens": ["Remove", "local", "d3", "combined", "file", "use", "default", "d3", "package"], "add_tokens": "import * as d3 from 'd3' ;", "del_tokens": "import d3 from './d3' ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "typos", "and", "file", "functions"], "add_tokens": "return this . backupStream ( fs . createWriteStream ( filename ) , opts , callback ) ; return this . restoreStream ( fs . createReadStream ( filename ) , opts , callback ) ;", "del_tokens": "return backup ( fs . creteWriteStream ( fileanme ) , opts , callback ) ; return restore ( fs . createReadStream ( filename ) , opts , callback ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "range", "qualifier", "to", "pass", "arguments", "array"], "add_tokens": "'<input id=\"text-field\" type=\"text\" value=\"2\">' + range : [ 0 , 10 ] textField . value = '-1' textField . value = '11' textField . value = '5'", "del_tokens": "'<input id=\"text-field\" type=\"text\" value=\"pass\">' + values : [ 'pass' ] textField . value = 'fail' textField . value = 'fail again' textField . value = 'pass'", "commit_type": "allow"}
{"commit_tokens": ["Make", "it", "possible", "for", "helpers", "to", "let", "downstream", "helpers", "know", "what", "the", "path", "to", "the", "current", "object", "is"], "add_tokens": "test ( \"functions receive the current path as part of the 'this'\" , function ( ) { template = \"Hello {{#person}}{{show name}}{{/person}}\" object = { person : { name : \"Alan\" } } ; fallback = { show : function ( context ) { return context + \" (from \" + this . __path__ . join ( \"/\" ) + \")\" ; } } shouldCompileTo ( template , [ object , fallback ] , \"Hello Alan (from person)\" ) } ) ; test ( \"block helpers don't mess with the path receive the current path as part of the 'this'\" , function ( ) { template = \"Hello {{#block}}{{#person}}{{#info}}{{show name}}{{/info}}{{/person}}{{/block}}. {{show other/name}}\" object = { person : { info : { name : \"Alan\" } } , other : { name : \"Yehuda\" } } ; fallback = { show : function ( context ) { var ret = context ; if ( this . __path__ ) ret += \" (from \" + this . __path__ . join ( \"/\" ) + \")\" ; return ret ; } , block : function ( context , fn ) { return fn ( this ) ; } } shouldCompileTo ( template , [ object , fallback ] , \"Hello Alan (from person/info). Yehuda\" ) } ) ; } ) ;", "del_tokens": "} )", "commit_type": "make"}
{"commit_tokens": ["Add", "in", "onRowClick", "handler", "as", "prop"], "add_tokens": "onRowClick : React . PropTypes . func , * @ prop { Boolean } fullWidth = true Whether the table takes up full width or not * @ prop { Function } onRowClick Callback for when a row is clicked . * @ prop { Boolean } sortable = true Whether the table can be sorted or not * @ prop { Boolean } striped = false Whether the table is striped columnHighlighting , plugins , columnGroups , onRowClick } = this . props ; onClick = { onRowClick }", "del_tokens": "* @ prop { Boolean } sortable = true Whether the table can be sorted or not * @ prop { Boolean } striped = false Whether the table is striped * @ prop { Boolean } fullWidth = true Whether the table takes up full width or not columnHighlighting , plugins , columnGroups } = this . props ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "fake", "timers", "compatibility", "with", "beforeEach", "/", "afterEach", "cycles"], "add_tokens": "if ( ! disableAutoSandbox ) {", "del_tokens": "if ( ! disableAutoSandbox && typeof test . spy === 'undefined' ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "Promise", "object", "instead", "of", "sync", "request", "in", "Web", "Worker", "plugin", "."], "add_tokens": "function ( pp , Pathfinder , ClipperLib , workerPromise , Logger ) { // Set callbacks for worker promise object. workerPromise . then ( function ( worker ) { this . worker = worker ; } . bind ( this ) , function ( Error ) { Logger . log ( \"navmesh:warn\" , \"Worker error:\" , Error ) ; } . bind ( this ) ) ;", "del_tokens": "function ( pp , Pathfinder , ClipperLib , aStarWorker , Logger ) { if ( aStarWorker ) { this . worker = aStarWorker ; } else { }", "commit_type": "use"}
{"commit_tokens": ["Improving", "developer", "meu", "list", "."], "add_tokens": "function listArray ( stock , language , itemPath ) { list += ' <li><a href=\"' + itemUrl + '\"' + '>' + '[' + menuItem . order + '] ' + menuItem . text + '</a>' ; if ( menuItem . children ) { list += '\\n' ; list += ' <a data-toggle=\"collapse\" href=\"#collapse' + menuItem . id + '\">\\n' ; list += ' <span class=\"glyphicon glyphicon-list\"></span>\\n' ; list += ' </a>\\n' ; list += ' <div class=\"collapse\" id=\"collapse' + menuItem . id + '\">\\n' ; list += ' <ul>\\n' ; list += listArray ( menuItem . children , language , itemPath ) ; list += ' </ul>\\n' ; list += ' </div>\\n' ; } list += ' </li>\\n' ; list += listArray ( menus [ key ] , key , itemPath ) ;", "del_tokens": "function listArray ( stock , language , itemPath , menuPath ) { var itemText = ( menuPath ? menuPath + '  ' : ' ) + '[' + menuItem . order + '] ' + menuItem . text ; list += '<li><a href=\"' + itemUrl + '\"' + '>' + itemText + '</a></li>\\n' ; if ( menuItem . children ) list += listArray ( menuItem . children , language , itemPath , itemText ) ; //list += menus[ key ].list( key, itemPath ); list += listArray ( menus [ key ] , key , itemPath , '' ) ;", "commit_type": "improve"}
{"commit_tokens": ["Use", "new", "getReporter", "method", "of", "jscs", "/", "cli", "-", "config", "module"], "add_tokens": "var Checker = require ( \"jscs\" ) , this . _reporter = null ; this . registerReporter ( options . reporter ) ; this . _reporter = defaultReporter ; return this ; var reporter = jscsConfig . getReporter ( name ) ; if ( reporter . writer ) { this . _reporter = reporter . writer ; return this ; grunt . fatal ( \"Reporter \\\"\" + reporter . path + \"\\\" does not exist\" ) ;", "del_tokens": "var path = require ( \"path\" ) , Checker = require ( \"jscs\" ) , this . _reporter = this . registerReporter ( options . reporter ) ; return defaultReporter ; var module ; try { module = require ( \"jscs/lib/reporters/\" + name ) ; } catch ( _ ) { try { module = require ( path . resolve ( process . cwd ( ) , name ) ) ; } catch ( _ ) { } } if ( module ) { return module ; grunt . fatal ( \"Reporter \\\"\" + name + \"\\\" does not exist\" ) ; // This, is just for the consistency, since we throw in the line above return null ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "a", "custom", "reporter", "to", "be", "specified", "in", "the", "options", "to", "gulp", "-", "flowtype"], "add_tokens": "var stylishReporter = require ( require ( 'jshint-stylish' ) ) . reporter ; // Allow a custom reporter to be passed into the options, otherwise default // to jshint-stylish reporter var reporter = typeof options . reporter === 'undefined' ? stylishReporter : options . reporter . reporter ;", "del_tokens": "var { reporter } = require ( require ( 'jshint-stylish' ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "the", "files", "around", "in", "prep", "for", "new", "Strategy", "."], "add_tokens": "var LegacyStrategy = require ( './legacy-strategy' ) ;", "del_tokens": "var LegacyStrategy = require ( './strategy' ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "problem", "with", "BASE4", "block", "style"], "add_tokens": "var result , i , c , padding , leftdata = 0 ; // bits decoded, but yet to be appended result = [ ] ; for ( i = 0 ; i < data . length ; i ++ ) { if ( 10 === data . charCodeAt ( i ) ) { // new line charcter (\\n) continue ; } if ( ' ' == data [ i ] ) { console . log ( data . charCodeAt ( i ) ) ; } // Fail on illegal characters and whitespace throw new Error ( \"Illegal characters (code=\" + data . charCodeAt ( i ) + \") in position \" + i + \": ordinal not in range(128)\" ) ; result . push ( ( leftdata >> leftbits ) & 0xff ) ;", "del_tokens": "var result , resultLength , idx , i , c , padding , leftdata = 0 , // bits decoded, but yet to be appended dataLength = data . indexOf ( '=' ) ; if ( dataLength < 0 ) { dataLength = data . length ; } // Every four characters is 3 resulting numbers resultLength = ( dataLength >> 2 ) * 3 + Math . floor ( ( dataLength % 4 ) / 1.5 ) ; result = new Array ( resultLength ) ; for ( idx = 0 , i = 0 ; i < data . length ; i ++ ) { // Skip illegal characters and whitespace throw new Error ( \"Illegal characters in position \" + i + \": ordinal not in range(128)\" ) ; result [ idx ++ ] = ( leftdata >> leftbits ) & 0xff ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "case", "to", "check", "parseJSON", "for", "multiple", "fields"], "add_tokens": "} ) ;", "del_tokens": "} )", "commit_type": "add"}
{"commit_tokens": ["using", "Number", ".", "isSafeInteger", "for", "iterable", "size", "(", "+", "fixed", "some", "comments", ")"], "add_tokens": "// Returns the child nodes for each entry in iterable. If we have // Returns the \"n entries\" string for this node, generating and if ( Number . isSafeInteger ( data . size ) ) {", "del_tokens": "// Returns the child nodes for each element in the array. If we have // Returns the \"n Items\" string for this node, generating and if ( typeof data . size !== 'undefined' ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "double", "-", "decoding", "problem", "in", "activity", "host"], "add_tokens": "requestString = fragmentRequestParam ;", "del_tokens": "requestString = decodeURIComponent ( fragmentRequestParam ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "off", "-", "by", "-", "one", "error", "in", "getting", "domains"], "add_tokens": "for ( var i = 0 ; i < res . length ; i += 2 ) {", "del_tokens": "for ( var i = 1 ; i < res . length ; i += 2 ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "elipsis", "for", "long", "text", "that", "overlaps", "the", "arrow", "icon"], "add_tokens": "$select_dropdown . text ( $ ( selector ) . find ( ':selected' ) . text ( ) ) . wrapInner ( '<span></span>' ) ; $select_dropdown . text ( $ ( target ) . text ( ) ) . removeClass ( 'show' ) . wrapInner ( '<span></span>' ) ; ;", "del_tokens": "$select_dropdown . text ( $ ( selector ) . find ( ':selected' ) . text ( ) ) ; $select_dropdown . text ( $ ( target ) . text ( ) ) . removeClass ( 'show' ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "predefined", "global", "var", "in", "place", "of", "this", "."], "add_tokens": "} else { global . sn = sn ;", "del_tokens": "else this . sn = sn ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "with", "special", "names", "and", "disabled", "colors"], "add_tokens": "let _ = require ( 'lodash' ) ; let colors = { app : 'cyan' , attachment : 'green' , addon : 'magenta' , } ; let definedColors = _ . pick ( colors , function ( value ) { return typeof ( chalk [ value ] ) === 'function' ; } ) ; let boundColors = _ . mapValues ( definedColors , function ( value ) { return function ( s ) { return chalk [ value ] ( s ) ; } ; module . exports = Object . assign ( chalk , boundColors ) ;", "del_tokens": "module . exports = Object . assign ( chalk , { app : chalk . cyan , attachment : chalk . green , addon : chalk . magenta ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "node", "-", "hot", "version"], "add_tokens": "plugins : [ '@babel/plugin-proposal-class-properties' , 'babel-plugin-transform-inline-environment-variables' , ] ,", "del_tokens": "plugins : [ '@babel/plugin-proposal-class-properties' ] ,", "commit_type": "fix"}
{"commit_tokens": ["Update", "roadmap", "-", "Enable", "secio"], "add_tokens": "crypto : [ require ( \"zeronet-crypto/secio\" ) ]", "del_tokens": "crypto : [ ]", "commit_type": "update"}
{"commit_tokens": ["Fix", "+", "keep", "same", "format", "between", "dates", "and", "folder", "explorer"], "add_tokens": "if ( ! dirPath || typeof dirPath !== 'string' ) { callback ( \"dirPath must be a string\" ) ; } else { fs . readdir ( dirPath , function ( err , list ) { var dir = [ ] ; list . forEach ( function ( item ) { dir . push ( readNode ( path . join ( dirPath , item ) ) ) ; } ) ; callback ( null , dir ) ; } ) ; } res . status ( 400 ) . end ( ) ; files : logWriter . history . dates [ date ] . map ( function ( item ) { return { name : path . basename ( item ) , path : item } ; } )", "del_tokens": "fs . readdir ( dirPath , function ( err , list ) { var dir = [ ] ; list . forEach ( function ( item ) { dir . push ( readNode ( path . join ( dirPath , item ) ) ) ; } ) ; callback ( null , dir ) ; } ) ; res . status ( 500 ) . end ( ) ; files : logWriter . history . dates [ date ]", "commit_type": "fix"}
{"commit_tokens": ["remove", "date", ".", "valueOf", "in", "favor", "of", "valueOf", "function"], "add_tokens": "import valueOf from '../utils/value-of' ; export default function compute31BitDateHash ( date ) { var _time = valueOf ( date ) ;", "del_tokens": "export default function compute31BitDateHash ( val ) { var _time = val . getTime ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "xunit", "reporter", "to", "handle", "hook", "names", "properly"], "add_tokens": "} while ( temp = temp . originalParent || temp . parent )", "del_tokens": "} while ( temp = temp . parent )", "commit_type": "fix"}
{"commit_tokens": ["Use", "append", "-", "only", "format", "for", "removes", "too"], "add_tokens": ", updatedDocs = [ ] updatedDocs . push ( modifiedDoc ) ; self . persistNewState ( updatedDocs , function ( err ) { , newData = [ ] , removedDocs = [ ] ; removedDocs . push ( { $$deleted : true , _id : d . _id } ) ; self . persistNewState ( removedDocs , function ( err ) {", "del_tokens": ", updatedData = [ ] updatedData . push ( modifiedDoc ) ; self . persistNewState ( updatedData , function ( err ) { , newData = [ ] ; self . persistWholeDatabase ( newData , function ( err ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "when", "webpack", "bundle", "analyze", "shows"], "add_tokens": "if ( WEBPACK_BUNDLE_ANALYZE && IS_PRODUCTION_MODE ) {", "del_tokens": "if ( WEBPACK_BUNDLE_ANALYZE ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "importing", "css", "files", "from", "sass", "/", "scss"], "add_tokens": "var extensionMatcher = / \\.(sass|scss|css)$ / ;", "del_tokens": "var extensionMatcher = / \\.(sass|scss)$ / ;", "commit_type": "fix"}
{"commit_tokens": ["added", "record", "method", "in", "sobject", ".", "js", "to", "access", "each", "entity"], "add_tokens": ", SObject = require ( './sobject' ) this . _sobjects [ type ] || new SObject ( type , this ) ;", "del_tokens": ", SObjectCollection = require ( './sobject' ) this . _sobjects [ type ] || new SObjectCollection ( type , this ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "indexOf", "(", "this", ")"], "add_tokens": "return this . siblings ? this . siblings . indexOf ( this ) : - 1 ;", "del_tokens": "if ( ! this . siblings ) return - 1 ; for ( var i = 0 ; i < this . siblings . length ; i ++ ) { if ( this === this . siblings [ i ] ) { return i ; } }", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "pointerover", "pointerout", "events"], "add_tokens": "const OVER_EVENT_TYPE = 'pointerover' ; const OUT_EVENT_TYPE = 'pointerout' ; this . enableOutEvent = this . options . enable ; this . enableOverEvent = this . options . enable ; if ( eventType === OVER_EVENT_TYPE ) { this . enableOverEvent = enabled ; } if ( eventType === OUT_EVENT_TYPE ) { this . enableOutEvent = enabled ; } this . handleOverEvent ( event ) ; this . handleOutEvent ( event ) ; this . handleLeaveEvent ( event ) ; this . handleMoveEvent ( event ) ; } handleOverEvent ( event ) { if ( this . enableOverEvent ) { if ( event . type === 'mouseover' ) { this . callback ( { type : OVER_EVENT_TYPE , srcEvent : event , pointerType : 'mouse' , target : event . target } ) ; } } } handleOutEvent ( event ) { if ( this . enableOutEvent ) { if ( event . type === 'mouseout' ) { this . callback ( { type : OUT_EVENT_TYPE , srcEvent : event , pointerType : 'mouse' , target : event . target } ) ; } } } handleLeaveEvent ( event ) { } handleMoveEvent ( event ) { // Move events use `which` to track the button being pressed", "del_tokens": "// Move events use `which` to track the button being pressed", "commit_type": "add"}
{"commit_tokens": ["update", "README", "and", "package", ".", "json", "after", "merge", "a", "PR"], "add_tokens": "", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["fixed", "tests", ";", "added", "ability", "to", "npm", "test", ";", "added", "mongoose", "devDep"], "add_tokens": "autoIncrement . initialize ( mongoose . connection ) ; SomeSchema . plugin ( autoIncrement . plugin , 'ai_id' ) ; user . _id . should . eql ( 0 ) ; SomeSchema . plugin ( autoIncrement . plugin , { model : 'ai_another_field' , field : 'sequence' } ) ; SomeSchema . plugin ( autoIncrement . plugin , { model : 'ai_start_at' , startAt : 3 } ) ; SomeSchema . plugin ( autoIncrement . plugin , { model : 'incrementBy' , incrementBy : 5 } ) ; SomeSchema . plugin ( autoIncrement . plugin , { model : 'incrementOnUpdate' , field : 'sequence' , incrementOnUpdate : true } ) ; } ) ;", "del_tokens": "SomeSchema . plugin ( autoIncrement , 'ai_id' ) ; user . _id . should . eql ( 0 ) SomeSchema . plugin ( autoIncrement , { model : 'ai_another_field' , field : 'sequence' } ) ; SomeSchema . plugin ( autoIncrement , { model : 'ai_start_at' , startAt : 3 } ) ; SomeSchema . plugin ( autoIncrement , { model : 'incrementBy' , incrementBy : 5 } ) ; SomeSchema . plugin ( autoIncrement , { model : 'incrementOnUpdate' , field : 'sequence' , incrementOnUpdate : true } ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "level", "6", "for", "deflate", "profiling"], "add_tokens": "pako . deflate ( data , { level : 6 } ) ;", "del_tokens": "pako . deflate ( data , { level : 1 } ) ;", "commit_type": "use"}
{"commit_tokens": ["fixing", "jshit", "error", "/", "suggestion"], "add_tokens": "} catch ( f ) { } } if ( h !== null ) { h . replace ( \"-\" , \"_\" ) ; d . locale = h ; } } return d ; } ( ) ;", "del_tokens": "} catch ( f ) { } } if ( h !== null ) { h . replace ( \"-\" , \"_\" ) ; d . locale = h ; } } return d ; } ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "a", "listing", "using", "a", "matching", "listing", "object"], "add_tokens": "this . waitTimer = setTimeout ( Listings . prototype . processActions . bind ( this ) , this . waitTime ) ; if ( type == 'remove' ) { const match = this . actions [ type ] . some ( ( id ) => id == action ) ; if ( match ) { return ; } } this . wait ( ) ;", "del_tokens": "this . _wait = setTimeout ( Listings . prototype . processActions . bind ( this ) , this . waitTime ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "error", "handling"], "add_tokens": "//Set an event handler for the error events lineReader . on ( 'error' , error => sink ( new Bacon . Error ( error ) ) ) ;", "del_tokens": "//Set an event handler for the error events readStream . on ( 'error' , error => sink ( new Bacon . Error ( error ) ) ) ; lineReader . on ( 'error' , error => sink ( new Bacon . Error ( error ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "Test", "for", "target", "and", "fix", "the", "original", "tests", "to", "include", "target", "."], "add_tokens": "assert . equal ( result , 'My link: <a href=\"http://google.com\" target=\"_self\">http://google.com</a>' ) ; assert . equal ( result , '<a href=\"www.johnotander.com\" target=\"_self\">www.johnotander.com</a>' ) ; test ( 'it should turn a url into a link with a target of \"_blank\"' , function ( assert ) { var result = linkify ( \"My link: http://google.com\" , \"_blank\" ) . toString ( ) . trim ( ) ; assert . equal ( result , 'My link: <a href=\"http://google.com\" target=\"_blank\">http://google.com</a>' ) ; } ) ;", "del_tokens": "assert . equal ( result , 'My link: <a href=\"http://google.com\">http://google.com</a>' ) ; assert . equal ( result , '<a href=\"www.johnotander.com\">www.johnotander.com</a>' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "id", "(", "true", ")", "to", "print", "full", "id"], "add_tokens": "this . __type = name ; definition . Constructor . prototype . id = function ( full ) { return ( full ? this . _type ( ) + \"/\" : \"\" ) + this [ definition . key ] ( ) ;", "del_tokens": "// Store the definition type in the prototype to get to it easily. definition . Constructor . prototype . __type = name ; definition . Constructor . prototype . id = function ( ) { return this [ definition . key ] ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "cheking", "for", "required", "type"], "add_tokens": "} else { // only check this if no invalid type was detected this . _checkTypes ( ) ;", "del_tokens": "this . _checkTypes ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "check", "error", "that", "would", "fail", "if", "number", "was", "set", "to", "0"], "add_tokens": "if ( val == undefined || parseFloat ( val ) != val ) {", "del_tokens": "if ( ! val || parseFloat ( val ) != val ) {", "commit_type": "fix"}
{"commit_tokens": ["change", "mastermind", "public", "facing", "api", "added", "tests"], "add_tokens": "'object' , mastermind . update ( 'genericStoreUpdate' , { mastermind . update ( 'genericStoreUpdate' , { mastermind . update ( 'genericStoreUpdate' , {", "del_tokens": "'function' , mastermind ( 'genericStoreUpdate' , { mastermind ( 'genericStoreUpdate' , { mastermind ( 'genericStoreUpdate' , {", "commit_type": "change"}
{"commit_tokens": ["Add", "debug", "option", "to", "make", "output", "less", "verbose"], "add_tokens": "if ( options . debug ) console . log ( PLUGIN_NAME + '-init: No source content for \"' + source + '\". Loading from file.' ) ; if ( options . debug ) console . warn ( PLUGIN_NAME + '-init: source file not found: ' + absPath ) ; if ( options . debug ) console . log ( PLUGIN_NAME + '-write: No source content for \"' + sourceMap . sources [ i ] + '\". Loading from file.' ) ; if ( options . debug ) console . warn ( PLUGIN_NAME + '-write: source file not found: ' + sourcePath ) ;", "del_tokens": "console . log ( PLUGIN_NAME + '-init: No source content for \"' + source + '\". Loading from file.' ) ; console . warn ( PLUGIN_NAME + '-init: source file not found: ' + absPath ) ; console . log ( PLUGIN_NAME + '-write: No source content for \"' + sourceMap . sources [ i ] + '\". Loading from file.' ) ; console . warn ( PLUGIN_NAME + '-write: source file not found: ' + sourcePath ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "disconnection", "of", "dsp", "inlets"], "add_tokens": "var patch = this ; this . mapEndPoints ( function ( obj ) { patch . tick ( obj ) ; } ) ; var patch = this ; this . audio . play ( function ( ) { return patch . generateFrame ( ) ; } ) ;", "del_tokens": "var me = this ; this . mapEndPoints ( function ( obj ) { me . tick ( obj ) ; } ) ; var me = this ; this . audio . play ( function ( ) { return me . generateFrame ( ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "another", "test", "for", "someting", "I", "want", "to", "work"], "add_tokens": "'for a different target attribute' : common . createTest ( 'attribute' , { \"url\" : [ \"data-bind\" , \"src\" ] } ) , 'for an different target attribute with extra values' : common . createTest ( 'extra-attribute' , { \"url\" : [ \"class\" , \"src\" ] } )", "del_tokens": "'for an overridden destination' : common . createTest ( 'attribute' , { \"url\" : [ \"data-bind\" , \"src\" ] } )", "commit_type": "add"}
{"commit_tokens": ["Add", "perpage", "and", "page", "options"], "add_tokens": "branchPrepend : 'willitmerge-' , page : 0 , perpage : 30 state : 'open' , page : that . options . page , per_page : that . options . perpage", "del_tokens": "branchPrepend : 'willitmerge-' state : 'open'", "commit_type": "add"}
{"commit_tokens": ["Use", "deployInfo", ".", "_checksum", "as", "a", "value", "to", "avoid", "conflicts", "."], "add_tokens": "deployInfo . _checksum = computeChecksum ( JSON . stringify ( deployInfo ) ) ; return deployInfo ; } ) . then ( deployInfo => { return this . getDeployInfo ( appId ) . then ( ( ) => { delete deployInfo . _checksum ; } ) . then ( ( ) => this . setDeployInfo ( appId , deployInfo ) ) return Promise . resolve ( deployInfo ) ;", "del_tokens": "return this . getDeployInfo ( ) . then ( ( ) => this . setDeployInfo ( appId , deployInfo ) ) return new Promise ( ( resolve , reject ) => { resolve ( deployInfo ) ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "the", "attachEvent", "method"], "add_tokens": "action ( arguments , action ) ;", "del_tokens": "action ( arguments , actionManager . context ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "removal", "of", "events", "using", "null", "for", "cb", "arg"], "add_tokens": "const { UiWindow , UiHorizontalBox , UiVerticalBox , UiCheckbox , UiMultilineEntry , UiVerticalSeparator } = require ( '../..' ) ; function logChanges ( ) { } entry . onChanged ( logChanges ) ; const vbox = new UiVerticalBox ( ) ; vbox . padded = true ; const chkLog = new UiCheckbox ( 'log' ) ; chkLog . checked = true ; chkLog . onToggled ( ( ) => { if ( chkLog . checked ) { entry . onChanged ( logChanges ) ; } else { entry . onChanged ( null ) ; } vbox . append ( chkLog , false ) ; vbox . append ( box , true ) ; win . setChild ( vbox ) ;", "del_tokens": "const { UiWindow , UiHorizontalBox , UiMultilineEntry , UiVerticalSeparator } = require ( '../..' ) ; entry . onChanged ( ( ) => { win . setChild ( box ) ;", "commit_type": "implement"}
{"commit_tokens": ["updated", "docs", "and", "bug", "fixes"], "add_tokens": "var schema = this . schema ; if ( schema . hasOwnProperty ( column ) ) { this . __values [ column ] = this . _typeCastValue ( column , value , ignore ) ; } else { this [ column ] = value ; }", "del_tokens": "this . __values [ column ] = this . _typeCastValue ( column , value , ignore ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "consoleStatements", ".", "if", "null", "--", ">", "0"], "add_tokens": "var consoleStatements = content . match ( / (console.*) / g ) ; consoleStatements : consoleStatements != null ? consoleStatements . length : 0", "del_tokens": "consoleStatements : content . match ( / (console.*) / g ) . length", "commit_type": "fix"}
{"commit_tokens": ["Adds", "host", ".", "logMask", "masking", "of", "portions", "of", "command", "from", "console", "and", "log", "file", "."], "add_tokens": "function star ( mask ) { var stars = '' , i , length ; for ( i = 0 , length = mask . length ; i < length ; i += 1 ) { stars += '*' ; } return stars ; } mask = this . logMask , stars , if ( mask ) { stars = star ( mask ) ; while ( command . indexOf ( mask ) !== - 1 ) { command = command . replace ( mask , stars ) ; } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "get", "-", "port", "instead", "of", "getport"], "add_tokens": "var getPort = require ( 'get-port' ) getPort ( { port : 8080 } ) . then ( function ( port ) { . catch ( function ( err ) { state . error = err } )", "del_tokens": "var getPort = require ( 'getport' ) getPort ( 8080 , 9000 , function ( err , port ) { if ( err ) state . error = err", "commit_type": "use"}
{"commit_tokens": ["Use", "babel", "-", "plugin", "-", "transform", "-", "runtime", "instead", "of", "babel", "-", "polyfill"], "add_tokens": "const bluebird = require ( 'bluebird' ) ; global . Promise = bluebird ; list . forEach ( api => bluebird . promisifyAll ( obj [ api ] , { promisifier } ) ) ;", "del_tokens": "import 'babel-polyfill' ; global . Promise = require ( 'bluebird' ) ; list . forEach ( api => Promise . promisifyAll ( obj [ api ] , { promisifier } ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "draft", "3", "to", "4", "convert", "for", "all", "schemas"], "add_tokens": "//Convertion is safe even for Draft4 schemas, so convert everything schema = jsonCompat . v4 ( schema ) ;", "del_tokens": "//FIXME: assert . equal ( schema . $schema || schema [ '' ] , 'http://json-schema.org/draft-03/schema' ) ; schema = jsonCompat . v4 ( schema ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "unmodified", "jquery", "and", "removed", "process", ".", "mixin"], "add_tokens": "var dom = require ( \"../../lib/level1/core\" ) . dom . level1 . core ; var window = { document : new dom . Document ( ) } ;", "del_tokens": "process . mixin ( GLOBAL , require ( \"../../lib/level1/core\" ) . dom . level1 . core ) ; var window = { document : new Document ( ) } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "compatibility", "intent", "name", "string", "for", "Actions", "on", "Google"], "add_tokens": "return [ 'actions.intent.MAIN' ] ; 'actions.intent.MAIN' : 'WELCOME' return [ 'actions.intent.TEXT' ] ;", "del_tokens": "return [ 'assistant.intent.action.MAIN' ] ; 'assistant.intent.action.MAIN' : 'WELCOME' return [ 'assistant.intent.action.TEXT' ] ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "autoCreate", "in", "flow", "control", "sample", "."], "add_tokens": "const topic = pubsub . topic ( topicName ) ; const options = { flowControl : { maxBytes : maxBytes , maxMessages : maxInProgress , } , } ; const subscription = topic . subscription ( subscriptionName , options ) ; subscription . get ( { autoCreate : true ,", "del_tokens": "pubsub . topic ( topicName ) . createSubscription ( subscriptionName , { flowControl : { maxBytes : maxBytes , maxMessages : maxInProgress , } ,", "commit_type": "use"}
{"commit_tokens": ["Remove", "dependency", "on", "objection", ".", "js"], "add_tokens": "const constants = require ( \"../constants\" ) ; if ( value . relation . name === constants . HasOneRelation ) { value . relation . name === constants . BelongsToOneRelation } else if ( value . relation . name === constants . HasManyRelation ) { value . relation . name === constants . ManyToManyRelation", "del_tokens": "const Model = require ( \"objection\" ) . Model ; if ( value . relation . name === Model . HasOneRelation . name ) { value . relation . name === Model . BelongsToOneRelation . name } else if ( value . relation . name === Model . HasManyRelation . name ) { value . relation . name === Model . ManyToManyRelation . name", "commit_type": "remove"}
{"commit_tokens": ["update", "action", "check", "for", "resolutor", "query"], "add_tokens": "if ( actions !== undefined && query instanceof Functor && actions [ query . getId ( ) ] !== undefined ) { if ( actions !== undefined && actions [ headLiteral . getId ( ) ] !== undefined ) {", "del_tokens": "if ( actions !== undefined && query instanceof Functor && actions . indexOf ( query . getId ( ) ) > - 1 ) { if ( actions !== undefined && actions . indexOf ( headLiteral . getId ( ) ) > - 1 ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "minifying", "step", "to", "release"], "add_tokens": "uglify : { progressbar : { options : { sourceMap : true } , files : { 'progressbar.min.js' : [ 'progressbar.js' ] } } } , } , stageMinified : { options : { stdout : true } , command : 'git add progressbar.min.js progressbar.min.js.map' commitMessage : 'Release <%= version %>' grunt . loadNpmTasks ( 'grunt-contrib-uglify' ) ; grunt . registerTask ( 'stageMinified' , function ( ) { grunt . task . run ( [ 'uglify:progressbar' , 'shell:stageMinified' ] ) ; } ) ; grunt . task . run ( [ 'jshint' , 'stageMinified' , 'extRelease:' + arg , 'updateDevVersion' ] ) ;", "del_tokens": "commitMessage : 'Release <%= version %>' , tagMessage : 'Tag <%= version %>' grunt . task . run ( [ 'jshint' , 'extRelease:' + arg , 'updateDevVersion' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "port", "issue", "with", "colon", "uri", "+", "add", "test"], "add_tokens": "uri_parser : / ^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@\\/]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d+|(?=:)))?(:)?)((((?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?) / this . uriParts . isColonUri = ! ! val ; if ( this . port ( ) || ( this . path ( ) && this . path ( ) . substr ( 0 , 1 ) . match ( / [0-9] / ) ) ) {", "del_tokens": "uri_parser : / ^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@\\/]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d+))?(:)?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?) / this . isColonUri = ! ! val ; if ( this . port ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "processData", "mapping", "to", "return", "a", "JSON", "array"], "add_tokens": "console . log ( 'this should be an array' , Array . isArray ( transformData ) ) ; var finalData = data . hits . hits . map ( function ( obj ) { return obj . _source ; return JSON . stringify ( finalData ) ;", "del_tokens": "return data . hits . hits . map ( function ( obj ) { return JSON . stringify ( obj . _source )", "commit_type": "fix"}
{"commit_tokens": ["Add", "resources", "()", "to", "integreat"], "add_tokens": "const resources = integreat . resources ( )", "del_tokens": "const lengthFormat = ( value ) => ( value ) ? value . length : 0 const resources = { adapters : integreat . adapters ( ) , transformers : { } , filters : { } , formatters : Object . assign ( { length : lengthFormat } , integreat . formatters ( ) ) , workers : integreat . workers ( ) , authstrats : integreat . authstrats ( ) }", "commit_type": "add"}
{"commit_tokens": ["Updating", "extent", "option", "name", ".", "Ignoring", "row", "extent", "step", "for", "extent", "option", "."], "add_tokens": "if ( self . hashMode !== 'extent' && currentGeojson . geometry . coordinates [ 0 ] . length >= self . splitAt ) {", "del_tokens": "if ( currentGeojson . geometry . coordinates [ 0 ] . length >= self . splitAt ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "delimiters", "tests", "and", "implementation", "."], "add_tokens": "// Store all partials inside this object, exposed so that it can be // primed. // Store all filters inside this object, exposed so that it can be // primed. // Refresh the compiler and source. this . _refresh ( Combyne . settings . delimiters ) ; } / ** * An internal method used to refresh the compiler and source . * * @ param { Object } delimiters to be used while parsing . * * @ api private * / Combyne . prototype . _refresh = function ( delimiters ) { var grammar = new Grammar ( delimiters ) . escape ( ) ; } ; // Refactor to just use _.defaults implementation. Combyne . prototype . setDelimiters = function ( local ) { var delimiters = { } ; function inherits ( name ) { return local [ name ] || Combyne . settings . delimiters [ name ] ; } delimiters = { START_PROP : inherits ( \"START_PROP\" ) , END_PROP : inherits ( \"END_PROP\" ) , START_EXPR : inherits ( \"START_EXPR\" ) , END_EXPR : inherits ( \"END_EXPR\" ) , COMMENT : inherits ( \"COMMENT\" ) , FILTER : inherits ( \"FILTER\" ) } ; this . _refresh ( delimiters ) ; } ;", "del_tokens": "var grammar = new Grammar ( Combyne . settings . delimiters ) . escape ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "OIDC", "id", "-", "token"], "add_tokens": "const token = _ . get ( userInfo , 'user.token' ) || _ . get ( userInfo , 'user.auth-provider.config.id-token' ) ;", "del_tokens": "const token = _ . get ( userInfo , 'user.token' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "up", "race", "conditions", "in", "the", "shutdown", "where", "process", ".", "exit", "()", "could"], "add_tokens": "if ( sauceAccount ) { sauceAccount . updateJob ( id , { 'passed' : passed } , function ( ) { } ) ; process . exit ( passed ? 0 : 1 ) ; driver . quit ( ) . then ( function ( ) { if ( server ) { util . puts ( 'Shutting down selenium standalone server' ) ; server . stop ( ) ; } } ) . then ( function ( ) { process . exit ( passed ? 0 : 1 ) ; } ) ;", "del_tokens": "if ( sauceAccount ) { sauceAccount . updateJob ( id , { 'passed' : passed } , function ( ) { } ) ; } driver . quit ( ) ; if ( server ) { util . puts ( 'Shutting down selenium standalone server' ) ; server . stop ( ) ; process . exit ( passed ? 0 : 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "last", "part", "of", "contract", "file", "rather", "than", "1st"], "add_tokens": "var contractFileParts = contractFile . split ( '.' ) [ 1 ] , extension = contractFileParts [ contractFileParts . length - 1 ] ;", "del_tokens": "var extension = contractFile . split ( '.' ) [ 1 ] ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "task", "description"], "add_tokens": "grunt . registerTask ( 'default' , 'Default task will lint and test' , [ 'jshint' , 'test' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , 'Default tas will lint and test' , [ 'jshint' , 'test' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "experimental", "onerror", "feature", ";", "add", "docs", "on", "update", "feature"], "add_tokens": "function execFunc ( cmd ) { return function run ( ) {", "del_tokens": "// this feature is experimental and may be subject to removal var onErrors = [ ] . concat ( argv . onerror ) . filter ( Boolean ) onErrors . forEach ( function ( cmd ) { instance . on ( 'bundle-error' , execFunc ( cmd , true ) ) } ) function execFunc ( cmd , isErr ) { return function run ( err ) { if ( isErr && err && err . message ) { p . stdin . write ( err . message . trim ( ) + '\\n' ) p . stdin . end ( ) }", "commit_type": "remove"}
{"commit_tokens": ["Change", "id", "for", "summary", "field"], "add_tokens": "' <input type=\"text\" id=\"inputSummary\" name=\"title\" ng-model=\"ctrl.model.data.summary\" required>\\n' +", "del_tokens": "' <input type=\"text\" id=\"inputTitle\" name=\"title\" ng-model=\"ctrl.model.data.summary\" required>\\n' +", "commit_type": "change"}
{"commit_tokens": ["Add", ".", "send", "()", "method"], "add_tokens": "import { asserter , isBinary } from './utils' ; const socket = this . _websocket = new WebSocket ( url , protocols , options ) ; / ** * Sends a message to the connected client . * @ param { Mixed } message - JSON or a binary interface . * @ return { undefined } * / send ( message ) { const payload = isBinary ( message ) ? message : JSON . stringify ( message ) ; this . _websocket . send ( payload ) ; }", "del_tokens": "import { asserter } from './utils' ; const socket = new WebSocket ( url , protocols , options ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "way", "default", "uri", "querying", "works", ".", "If", "no", "value", "is", "found", "at", "the", "given", "selector", "the", "query", "will", "no", "longer", "attempt", "to", "resolve", "the", "default", "value", "against", "the", "base", "uri"], "add_tokens": "* Finds the URI in the document and resolves the found URI * against the query ' let uri = document . uri ( this . options . selector ) ; if ( uri !== undefined ) return url . resolve ( this . options . base , uri ) ;", "del_tokens": "* Finds the URI in the document . return document . uri ( this . options . selector ) ; } / ** * Given the retrieved URI , this method resolves the found URI * against the query ' * * @ param { string } string The URI retrieved from the document . * @ param { Document } document The document the URI was retrieved from . * @ return { string } The resulting , URI coerced to a string . * / build ( string , document ) { return url . resolve ( this . options . base , string ) ;", "commit_type": "change"}
{"commit_tokens": ["Make", "sure", "that", "error", "controller", "have", "right", "context"], "add_tokens": "response = errorController . get ( 'action_' + errorAction ) . call ( errorController , response ) ;", "del_tokens": "response = errorController . get ( 'action_' + errorAction ) ( response ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "error", "-", "validate", "value", "before", "checking", "hasTrait"], "add_tokens": "if ( 'object' === typeof value && value . hasTrait ( 'Message' ) ) {", "del_tokens": "if ( value . hasTrait ( 'Message' ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "treemap", ".", "round", "."], "add_tokens": "tile = squarify , round = false ; var nodes = layout ( d ) , root = nodes [ 0 ] ; root . x0 = root . y0 = 0 , root . x1 = dx , root . y1 = dy ; if ( round ) visitBefore ( root , roundNode ) ; treemap . round = function ( x ) { return arguments . length ? ( round = ! ! x , treemap ) : round ; } ; function roundNode ( d ) { d . x0 = Math . round ( d . x0 ) ; d . y0 = Math . round ( d . y0 ) ; d . x1 = Math . round ( d . x1 ) ; d . y1 = Math . round ( d . y1 ) ; }", "del_tokens": "tile = squarify ; var nodes = layout ( d ) , root = nodes [ 0 ] ; root . x0 = root . y0 = 0 ; root . x1 = dx , root . y1 = dy ;", "commit_type": "add"}
{"commit_tokens": ["fix", "TypeError", ":", "Illegal", "invocation", "when", "using", "document", ".", "querySelectorAll", "(", "no", "MooTools", "or", "jQuery", "on", "page", ")"], "add_tokens": "var query ; if ( document . querySelectorAll ) query = document . querySelectorAll . bind ( document ) ; if ( ! query && 'undefined' !== typeof $$ ) query = $$ ; if ( ! query && 'undefined' !== typeof jQuery ) query = jQuery ;", "del_tokens": "var query = document . querySelectorAll ; if ( 'undefined' !== typeof $$ ) query = $$ ; if ( 'undefined' !== typeof jQuery ) query = jQuery ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "old", "version", "api", "open", "request"], "add_tokens": "this . dbVersion = parseInt ( this . dbVersion , 10 ) ; openRequest = this . idb . open ( this . dbName , this . dbVersion ) ;", "del_tokens": "if ( this . newVersionAPI ) { this . dbVersion = parseInt ( this . dbVersion , 10 ) ; openRequest = this . idb . open ( this . dbName , this . dbVersion , this . dbDescription ) ; } else { openRequest = this . idb . open ( this . dbName , this . dbDescription ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "new", "browser", "to", "v123", "listing"], "add_tokens": "'Iris' , 'SeaRequin'", "del_tokens": "'Iris'", "commit_type": "add"}
{"commit_tokens": ["Fix", "remove", "of", "branch", "when", "unmerged", "commits"], "add_tokens": "return that . repo . git ( \"branch\" , { D : true } , name ) ;", "del_tokens": "return that . repo . delete_branch ( name ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "cached", "reference", "to", "test", "s", "context"], "add_tokens": "window . srcDoc = this . _srcDoc ; delete this . _srcDoc ; this . _srcDoc = window . srcDoc . noConflict ( ) ;", "del_tokens": "window . srcDoc = window . _srcDoc ; delete window . _srcDoc ; window . _srcDoc = window . srcDoc . noConflict ( ) ;", "commit_type": "move"}
{"commit_tokens": ["removing", "fetch", "example", "until", "it", "works"], "add_tokens": "clicks : 0 , fetched : null", "del_tokens": "clicks : 0", "commit_type": "remove"}
{"commit_tokens": ["removed", "unused", "values", "and", "some", "minor", "updates"], "add_tokens": "// [Website] (http://foxmetrics.com) // [Documentation - JS](http://foxmetrics.com/documentation/apijavascript) appId : null var _fxm = window . _fxm || { } ; window . _fxm = _fxm . events || [ ] ; // user id is required for profile updates, // otherwise its a waste of resources as nothing will get updated if ( userId ) {", "del_tokens": "appId : null , appName : null , cookieDomain : null // fxm - aync script load var _fxm = _fxm || { } ; _fxm . events = _fxm . events || [ ] ; window . _fxm = _fxm . events ; // FoxMetrics allows the user to create/update a profile // however, the user id is a required field if ( typeof ( userId ) !== 'undefined' && userId ) {", "commit_type": "remove"}
{"commit_tokens": ["added", "functionality", "to", "override", "version", "number", "in", "info", "endpoint"], "add_tokens": "\"version\" : process . env . VERSION || packageInfo . version ,", "del_tokens": "\"version\" : packageInfo . version ,", "commit_type": "add"}
{"commit_tokens": ["updating", "collapsible", "component", "s", "DOM", "structure", "/", "logic"], "add_tokens": "toggleTextSelector : '.collapsible-toggle' , collapsibleSelector : '.collapsible-target' , isCollapsedClass : 'is-collapsed' toggleState : function ( isVisible ) { $textEl . text ( self . $el . data ( 'expanded-text' ) ) ; $textEl . text ( self . $el . data ( 'collapsed-text' ) ) ; self . $el . toggleClass ( self . options . isCollapsedClass , ! isVisible ) ; self . toggleState ( $collapsibleEl . is ( ':visible' ) ) ; self . toggleState ( ! isVisible ) ;", "del_tokens": "toggleTextSelector : '.collapsible-toggle-text' , collapsibleSelector : '.collapsible-content' toggleText : function ( isVisible ) { $textEl . text ( self . $el . data ( 'expand-text' ) ) ; $textEl . text ( self . $el . data ( 'collapse-text' ) ) ; self . toggleText ( $collapsibleEl . is ( ':visible' ) ) ; self . toggleText ( ! isVisible ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "obj", ".", "Super", "(", "name", ")", "to", "get", "method", "in", "base", "classes"], "add_tokens": "newclass . prototype . instanceOf = instanceOf ; newclass . prototype . Super = superMethod ; // check whether this obj is an instance of base classes function instanceOf ( baseclass ) { if ( this instanceof baseclass ) return true ; return subOf ( this . constructor , baseclass ) ; } // find method with given name from base classes function superMethod ( methodname ) { var func = null ; var p = this . __proto__ ; if ( ! p ) throw new Error ( 'invalid parameters' ) ; for ( p = p . __proto__ ; ! isEmpty ( p ) ; p = p . __proto__ ) { var method = p [ methodname ] ; if ( typeof method === 'function' ) { func = method ; break ; } } if ( ! func ) throw new Error ( 'super method not found: ' + methodname ) ; return func ; }", "del_tokens": "newclass . prototype . instanceOf = function ( baseclass ) { if ( this instanceof baseclass ) return true ; return subOf ( this . constructor , baseclass ) ; } ; ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "over", "-", "restrictive", "normalisation", "checks", "."], "add_tokens": "check . positiveNumber ( timeToLoad ) verify . number ( start ) ; check . verify . not . negativeNumber ( start ) ; verify . number ( end ) ; check . verify . not . negativeNumber ( end ) ;", "del_tokens": "check . positiveNumber ( timeToLoad ) && check . unemptyString ( data . r ) verify . positiveNumber ( start ) ; verify . positiveNumber ( end ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "ANY", "type", "for", "websql", "from", "facebook", "polyfill"], "add_tokens": "goog . require ( 'ydn.db.utils' ) ; } else if ( goog . isDef ( type ) ) { } else { return ydn . db . utils . encodeKey ( key ) ; } else if ( goog . isDef ( type ) ) { } else { return ydn . db . utils . decodeKey ( /** @type {string} */ ( key ) ) ;", "del_tokens": "} else { } else {", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "dates", "not", "getting", "parsed", "to", "excel", "properly", "."], "add_tokens": "//else if(cell.v instanceof Date) { // cell.t = 'n'; cell.z = XLSX.SSF._table[14]; // cell.v = datenum(cell.v); //}", "del_tokens": "else if ( cell . v instanceof Date ) { cell . t = 'n' ; cell . z = XLSX . SSF . _table [ 14 ] ; cell . v = datenum ( cell . v ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "charset", "conversion"], "add_tokens": "' [-w <path/to/www>]\\n' + ' [-c <charset>]\\n' ) ; if ( args . c ) webtelnetd . setCharset ( args . c ) ;", "del_tokens": "' [-w <path/to/www>]\\n' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "page", "title", "fallback", "just", "in", "case"], "add_tokens": "if ( sectionTitle && title ) {", "del_tokens": "if ( sectionTitle ) {", "commit_type": "add"}
{"commit_tokens": ["using", "jquery", "naming", "notation", "in", "interfaces"], "add_tokens": "/ ** @preserve jQuery animateNumber plugin v0.0.5 numberStep : function ( now , tween ) { handler = defaults . numberStep ; numberStepFactories : { if ( options . numberStep ) { this [ '_animateNumberSetter' ] = options . numberStep ;", "del_tokens": "/ ** @preserve jQuery animateNumber plugin v0.0.4 number_step : function ( now , tween ) { handler = defaults . number_step ; number_step_factories : { if ( options . number_step ) { this [ '_animateNumberSetter' ] = options . number_step ;", "commit_type": "use"}
{"commit_tokens": ["Add", "failing", "indent", "rule", "test", "."], "add_tokens": "' B = 2;' , '' , 'const myArr = [' , ' {' , ' a: 1,' , ' b: 2,' , ' },' , '];' ,", "del_tokens": "' B = 2;'", "commit_type": "add"}
{"commit_tokens": ["Improve", "js", "-", ">", "xml", "conversion"], "add_tokens": "var Request = require ( './request.js' ) ; for ( var i in Request ) { exports [ i ] = Request [ i ] ; }", "del_tokens": "var Request = exports . Request = require ( './request.js' ) . Request ;", "commit_type": "improve"}
{"commit_tokens": ["Using", "the", "Object", "s", "toString"], "add_tokens": "var toString = Object . prototype . toString ;", "del_tokens": "var toString = [ ] . toString ;", "commit_type": "use"}
{"commit_tokens": ["Add", "basename", "and", "dirname", "and", "bubble", "up", "entries"], "add_tokens": ", path = require ( \"path\" ) me . basename = path . basename ( opts . path ) me . dirname = path . dirname ( opts . path ) // if the filter doesn't pass, then just skip over this one. // still have to emit end so that dir-walking can move on. var ret = me . filter ( ) me . emit ( \"stat\" , props ) fst . on ( \"stat\" , function ( p ) { // bubble up fst . on ( \"entry\" , function ( entry ) { me . emit ( \"entry\" , entry ) } ) me . basename = path . basename ( opts . path ) me . dirname = path . dirname ( opts . path ) if ( typeof is === \"function\" ) is = is . call ( st )", "del_tokens": "me . emit ( \"stat\" , props ) var ret = me . filter ( props ) fst . on ( \"props\" , function ( p ) { if ( typeof is === \"function\" ) is = is ( )", "commit_type": "add"}
{"commit_tokens": ["Allow", "stacktrace", "to", "work", "in", "environments", "where", "window", "is", "not", "defined"], "add_tokens": "} else if ( typeof window !== 'undefined' && window . opera && e . stacktrace ) { } else if ( typeof window !== 'undefined' && window . opera && ! ( 'stacktrace' in e ) ) { //Opera 9-", "del_tokens": "} else if ( window . opera && e . stacktrace ) { } else if ( window . opera && ! ( 'stacktrace' in e ) ) { //Opera 9-", "commit_type": "allow"}
{"commit_tokens": ["Allow", "setting", "process", "title", "."], "add_tokens": "watchDir , workerTitle , masterTitle ; serverFile = path . resolve ( path . dirname ( require . main . filename ) , config . server ) ; watchDir = config . watch ? path . resolve ( path . dirname ( require . main . filename ) , config . watch ) : null ; workerTitle = config . workerTitle || 'server-worker' ; process . title = config . serverTitle || 'server-master' ; '--config' , JSON . stringify ( config . app || { } ) , '--title' , workerTitle if ( watchDir ) {", "del_tokens": "watchDir ; serverFile = config . server ; watchDir = path . resolve ( path . dirname ( require . main . filename ) , config . watch ) ; '--config' , JSON . stringify ( config . app || { } ) if ( watchDir !== undefined ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "crash", "and", "light", "bot"], "add_tokens": "promises . push ( this . app . services . DeviceService . findWithFavorites ( userId , { roomId : roomId } ) ) id : 1000 + roomId , //FIXME get proper way to do this images : { 'off' : '/images/widgets/light_off.png' , 'on' : '/images/widgets/light_on.png' }", "del_tokens": "promises . push ( this . app . services . DeviceService . findWithFavorites ( userId , { roomId : roomId } ) ) id : 'group_light_' + roomId , images : { 'off' : '/images/widgets/light_off.png' , 'on' : '/images/widgets/light_on.png' }", "commit_type": "fix"}
{"commit_tokens": ["use", "external", "kinda", "from", "wasm", "-", "json", "-", "toolkit"], "add_tokens": "const { Iterator , json2wasm } = require ( 'wasm-json-toolkit' ) const EXTERNAL_KIND = json2wasm . EXTERNAL_KIND", "del_tokens": "const Iterator = require ( 'wasm-json-toolkit' ) . Iterator const EXTERNAL_KIND = { 'function' : 0 , 'table' : 1 , 'memory' : 2 , 'global' : 3 }", "commit_type": "use"}
{"commit_tokens": ["add", "flattening", "and", "promoting", "of", "styles", "to", "collector"], "add_tokens": "var collector = require ( './collector' ) ; stream : stream , collect : collector . collect ,", "del_tokens": "stream : stream", "commit_type": "add"}
{"commit_tokens": ["add", "abbreviations", "for", "US", "states", "and", "other", "official", "/", "postal", "regions"], "add_tokens": "[ \"United States\" , \"US\" , \"Alaska~AK|Alabama~AL|American Samoa~AS|Arizona~AZ|Arkansas~AR|California~CA|Colorado~CO|Connecticut~CT|Delaware~DE|District of Columbia~DC|Micronesia~FM|Florida~FL|Georgia~GA|Guam~GU|Hawaii~HI|Idaho~ID|Illinois~IL|Indiana~IN|Iowa~IA|Kansas~KS|Kentucky~KY|Louisiana~LA|Maine~ME|Marshall Islands~MH|Maryland~MD|Massachusetts~MA|Michigan~MI|Minnesota~MN|Mississippi~MS|Missouri~MO|Montana~MT|Nebraska~NE|Nevada~NV|New Hampshire~NH|New Jersey~NJ|New Mexico~NM|New York~NY|North Carolina~NC|North Dakota~ND|Northern Mariana Islands~MP|Ohio~OH|Oklahoma~OK|Oregon~OR|Palau~PW|Pennsylvania~PA|Puerto Rico~PR|Rhode Island~RI|South Carolina~SC|South Dakota~SD|Tennessee~TN|Texas~TX|Utah~UT|Vermont~VT|Virgin Islands~VI|Virginia~VA|Washington~WA|West Virginia~WV|Wisconsin~WI|Wyoming~WY|Armed Forces Africa~AE|Armed Forces Americas~AA|Armed Forces Canada~AE|Armed Forces Europe~AE|Armed Forces Middle East~AE|Armed Forces Pacific~AP\" ] ,", "del_tokens": "[ \"United States\" , \"US\" , \"Alaska|Alabama|American Samoa|Arizona|Arkansas|California|Colorado|Connecticut|Delaware|District of Columbia|Micronesia|Florida|Georgia|Guam|Hawaii|Idaho|Illinois|Indiana|Iowa|Kansas|Kentucky|Louisiana|Maine|Marshall Islands|Maryland|Massachusetts|Michigan|Minnesota|Mississippi|Missouri|Montana|Nebraska|Nevada|New Hampshire|New Jersey|New Mexico|New York|North Carolina|North Dakota|Northern Mariana Islands|Ohio|Oklahoma|Oregon|Palau|Pennsylvania|Puerto Rico|Rhode Island|South Carolina|South Dakota|Tennessee|Texas|Utah|Vermont|Virgin Islands|Virginia|Washington|West Virginia|Wisconsin|Wyoming|Armed Forces Africa|Armed Forces Americas|Armed Forces Canada|Armed Forces Europe|Armed Forces Middle East|Armed Forces Pacific\" ] ,", "commit_type": "add"}
{"commit_tokens": ["Removing", "reference", "to", "window", "so", "class", "definition", "does", "not", "fail"], "add_tokens": "static Promise = Promise ;", "del_tokens": "static Promise = window . Promise ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "globalExtras", "and", "extras", "implementation"], "add_tokens": "return cssString ; return cssString ; var cssString = '' ; for ( var key in loader ) { cssString += ( key + '{' + loader [ key ] + '}\\n' ) ; return cssString ;", "del_tokens": "return globalExtras ; return extras ; var loaderStyle = '' ; for ( var rule in loader ) { loaderStyle += ( rule + '{' + loader [ rule ] + '}\\n' ) ; return loaderStyle ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "Google", "bug", "with", "no", "profile", "picture"], "add_tokens": "o . last_name = o . family_name || ( o . name ? o . name . familyName : null ) ; o . first_name = o . given_name || ( o . name ? o . name . givenName : null ) ; o . picture = o . picture || ( o . image ? o . image . url : null ) ;", "del_tokens": "o . last_name = o . family_name || o . name . familyName ; o . first_name = o . given_name || o . name . givenName ; o . picture = o . picture || o . image . url ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "tests", "changed", "imag", "behavior"], "add_tokens": "// Check for augmented vector * Returns the imaginary part of the quaternion as a 3 D vector / array return [ this [ 'x' ] , this [ 'y' ] , this [ 'z' ] ] ; * Gets the actual quaternion as a 4 D vector / array", "del_tokens": "// Check for vector * Returns the imaginary part of the quaternion as a new quaternion with real part zero return new Quaternion ( 0 , this [ 'x' ] , this [ 'y' ] , this [ 'z' ] ) ; * Gets the actual quaternion as an array", "commit_type": "fix"}
{"commit_tokens": ["Add", "putAttachment", "support", "for", "the", "rel", "domain"], "add_tokens": "function putAttachment ( type , obj , attachmentId , attachment , attachmentType ) { var dbDocId = serialize ( type , obj . id ) ; var typeInfo = getTypeInfo ( type ) ; return Promise . resolve ( ) . then ( function ( ) { return db . putAttachment ( dbDocId , attachmentId , obj . rev , attachment , attachmentType ) ; } ) . then ( function ( pouchRes ) { var res = { } ; res [ typeInfo . plural ] = [ extend ( true , obj , { id : deserialize ( pouchRes . id ) , rev : pouchRes . rev } ) ] ; return res ; } ) ; } } , putAttachment : putAttachment", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Allowing", "demos", "to", "run", "properly", "in", "windows"], "add_tokens": "parts = dirname . split ( '/' ) ; // glob always returns '/' as separator", "del_tokens": "parts = dirname . split ( path . sep ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", ":", "sExt", "file", "and", "folder", "creation", "mode"], "add_tokens": "opts . mode = opts . mode || '0777' ; opts . mode = opts . mode || '0777' ; mode = '0777' & ( ~ process . umask ( ) ) ;", "del_tokens": "opts . mode = opts . mode || 777 ; opts . mode = opts . mode || 777 ; mode = 777 & ( ~ process . umask ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "fromJS", "more", "loosely", "detect", "objects", "for", "cross", "-", "frame", "support"], "add_tokens": "// If it's a primitive type, just return the value. Note `==` check // for null, which is intentionally used to match either `null` or // `undefined`. if ( value == null || ( typeof value !== \"object\" ) ) { return value ; } // Otherwise, treat it like an object. We can't reliably detect if // it's a plain object because we might be objects from other JS // contexts so `Object !== Object`. return Immutable . Seq ( value ) . map ( fromJS ) . toMap ( ) ;", "del_tokens": "function isPlainObj ( value ) { return value && ( value . constructor === Object || value . constructor === undefined ) ; } if ( isPlainObj ( value ) ) { return Immutable . Seq ( value ) . map ( fromJS ) . toMap ( ) ; } return value ;", "commit_type": "make"}
{"commit_tokens": ["Added", "npm", "publishing", "protocols", "removed", "post", "install", "script"], "add_tokens": "return Object . keys ( packageJson . dependencies ) ;", "del_tokens": "/* global require, __dirname, module */ const excludeArray = [ 'rollup' , 'rollup-plugin-alias' , 'rollup-plugin-babel' , 'rollup-plugin-uglify' , 'uglify-es' ] ; return Object . keys ( packageJson . dependencies ) . filter ( ( value ) => ! excludeArray . includes ( value ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "speed", "-", "rating", "to", "duration", "classes", "and", "tooltips"], "add_tokens": "const h2 = New ( \"h2\" , { textContent : ( this . autoIt ? \"It \" : \"\" ) + test . title } ) ; addTo ( title ) ( h2 ) ; if ( ! test . pending ) { const duration = this . createDuration ( test . duration , true ) ; duration . title += ` ${ speed === \"okay\" ? \"medium\" : speed } ` ; addTo ( title ) ( duration ) ; } if ( test . duration > thresh / 2 ) return \"okay\" ;", "del_tokens": "addTo ( title ) ( New ( \"h2\" , { textContent : ( this . autoIt ? \"It \" : \"\" ) + test . title } ) , test . pending ? null : this . createDuration ( test . duration , true ) ) ; if ( test . duration > thresh / 2 ) return \"medium\" ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "https", ":", "//", "github", ".", "com", "/", "nikhilmodak", "/", "gulp", "-", "ngdocs", "/", "issues", "/", "15", "initializing", "setup", "variable", "documnetation", "for", "loadDefaults", "option", "https", ":", "//", "github", ".", "com", "/", "nikhilmodak", "/", "gulp", "-", "ngdocs", "/", "pull", "/", "17"], "add_tokens": "var setup = { sections : { } , pages : [ ] , apis : { } } ;", "del_tokens": "var setup ; setup = { sections : { } , pages : [ ] , apis : { } } ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "context", "instead", "of", "describe"], "add_tokens": "context ( 'Test with simple rules' , function ( ) { context ( 'Test with custom rules' , function ( ) { context ( 'Test with rule params' , function ( ) { context ( 'Test with multiple errors' , function ( ) {", "del_tokens": "describe ( 'Test with simple rules' , function ( ) { describe ( 'Test with custom rules' , function ( ) { describe ( 'Test with rule params' , function ( ) { describe ( 'Test with multiple errors' , function ( ) {", "commit_type": "use"}
{"commit_tokens": ["Fixing", "last", "entry", "in", "Chrome", "stack"], "add_tokens": "var stack = ( e . stack + '\\n' ) . replace ( / ^\\S[^\\(]+?[\\n$] / gm , '' ) . stack . pop ( ) ; return stack ;", "del_tokens": "//return e.stack.replace(/^[^\\(]+?[\\n$]/gm, '').replace(/^\\s+at\\s+/gm, '').replace(/^Object.<anonymous>\\s*\\(/gm, '{anonymous}()@').split('\\n'); return e . stack . replace ( / ^\\S[^\\(]+?[\\n$] / gm , '' ) .", "commit_type": "fix"}
{"commit_tokens": ["ADD", ":", "demo", "with", "browser", "detection"], "add_tokens": ". replace ( / w\\s*>= / ig , 'min-width:' ) . replace ( / w\\s*<= / ig , 'max-width:' ) 'return ' + sugar ( node . groupText ) result . cssdom = dom", "del_tokens": ". replace ( / >= / g , 'min-width:' ) . replace ( / <= / g , 'max-width:' ) 'return ' + node . groupText", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "creating", "a", "new", "api", "with", "restifier", ".", "api", "()"], "add_tokens": "// Expose the RestAPI instance restifier . instance = api ;", "del_tokens": "/ ** * Resets the restifier API . You should not use this . * * @ api private * /", "commit_type": "add"}
{"commit_tokens": ["Updated", "$", ".", "template", "to", "use", "a", "string", "instead", "of", "script", "tag", "for", "templates", "."], "add_tokens": "const CHUIVersion = \"0.6beta\" ; const UIExpectedChocolateChipJSVersion = \"1.1.4\" ;", "del_tokens": "const CHUIVersion = \"0.5beta\" ; const UIExpectedChocolateChipJSVersion = \"1.1.3\" ;", "commit_type": "update"}
{"commit_tokens": ["Add", "title", "property", "on", "marker", "component"], "add_tokens": "map , google , position , mapCenter , icon , label , draggable , title title : title ,", "del_tokens": "map , google , position , mapCenter , icon , label , draggable", "commit_type": "add"}
{"commit_tokens": ["Updated", "async", "paths", "to", "know", "which", "function", "to", "post", "-", "process"], "add_tokens": "tests_run ++ ; fs . flock ( file_fd , 'sh' , function ( err , extra ) { // After a change to returning arguments to async callback routines, // check that this API still receives only one argument. if ( extra === undefined ) { tests_ok ++ ; } else { console . log ( ' async flock() callback received more than one argument' ) ; }", "del_tokens": "fs . flock ( file_fd , 'sh' , function ( err ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "command", ".", "is_running", "and", "tunnel", ".", "is_open", "methods"], "add_tokens": "this . status = 'closed' ; } ; this . opened = function ( ) { this . status = 'open' ; this . emit ( 'opened' ) ; } ; this . is_open = function ( ) { return this . status == 'open' ; console . log ( \" -- Closing tunnel!\" ) ; console . log ( \" -- Local socket state: \" + local_socket . readyState ) ; console . log ( \" -- Local tunnel connected to \" + local_port ) ; console . log ( \" -- Remote socket ended.\" ) ; console . log ( \" -- Local socket ended.\" ) ; console . log ( \" -- Remote socket closed.\" ) ; console . log ( \" -- Local socket closed.\" ) ;", "del_tokens": "console . log ( \"Closing tunnel!\" ) ; this . opened = function ( ) { this . status = 'open' ; this . emit ( 'opened' ) ; } ; console . log ( \"Local socket state: \" + local_socket . readyState ) ; console . log ( \"Local tunnel connected to \" + local_port ) ; console . log ( \"Remote socket ended.\" ) ; console . log ( \"Local socket ended.\" ) ; console . log ( \"Remote socket closed.\" ) ; console . log ( \"Local socket closed.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "calling", "methods", "from", "a", "class", "inside", "a", "module"], "add_tokens": "self . class . print ( output ) ; self . class . print ( output ) ;", "del_tokens": "output . print ( self . class ) ; output . print ( self . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "no", "-", "network", "connection", "error", "for", "downloading", "firmware"], "add_tokens": "'writeBinary()' , //'downloadFirmwareVersion(7,0.9416)', //'downloadFirmwareVersion(7,0.9421)', downloadFirmware , // 7", "del_tokens": "//'writeBinary()', 'downloadFirmwareVersion(7,0.9416)' , 'downloadFirmwareVersion(7,0.9421)' ,", "commit_type": "fix"}
{"commit_tokens": ["remove", "deprecated", "PouchDB", ".", "destroy"], "add_tokens": "return db . destroy ( ) ;", "del_tokens": "return Pouch . destroy ( dbName ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "dest", "instead", "of", "jsDest", "for", "compatibility"], "add_tokens": "dest : 'test/tmp/basic.js' , dest : 'test/tmp/nonrelative.js' , dest : 'test/tmp/callback.js' , dest : 'test/tmp/with-css.js' ,", "del_tokens": "jsDest : 'test/tmp/basic.js' , jsDest : 'test/tmp/nonrelative.js' , jsDest : 'test/tmp/callback.js' , jsDest : 'test/tmp/with-css.js' ,", "commit_type": "use"}
{"commit_tokens": ["using", "white", "texture", "as", "default"], "add_tokens": "var WhiteTex = require ( 'gl-white-texture' ) //white texture is akin to \"no texture\" (without switching shaders) this . _defaultTexture = WhiteTex ( gl ) this . _texture = this . _defaultTexture //set default attributes this . reset ( ) texture : { get : function ( ) { return this . _texture } , set : function ( tex ) { this . _texture = tex || this . _defaultTexture } } , this . texture = sprite . texture", "del_tokens": "//default attributes this . reset ( ) if ( sprite . texture ) this . texture = sprite . texture", "commit_type": "use"}
{"commit_tokens": ["Move", "memory", "access", "in", "CPU", "to", "Memory", "class"], "add_tokens": "this . array = opts . array || new Int8Array ( new ArrayBuffer ( this . tryteCount ) ) ; // Int8Array is 8-bit signed -129 to +128, fits 5-trit -121 to +121", "del_tokens": "this . array = opts . array || new Int8Array ( new ArrayBuffer ( this . tryteCount ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "JSLint", "error", "in", "core", ".", "js", ".", "Also", "fixxed", "custom", "corner", "string", "position", "problem", "."], "add_tokens": "target = self . cache . target = $ ( event . target ) ;", "del_tokens": "target = self . cache . target = $ ( event . target )", "commit_type": "fix"}
{"commit_tokens": ["removed", "double", "asignation", "of", "properties", "variable", "removed", "comments"], "add_tokens": "var properties = Object . assign ( { } , _this . localScreenProperties || _defaultScreenProperties , publisherOptions ) ; * @ param { Object } [ publisherOptions ] - Properties for the screen sharing publisher .", "del_tokens": "var properties = _this . localScreenProperties || _defaultScreenProperties ; if ( publisherOptions ) { var properties = Object . assign ( { } , _this . localScreenProperties || _defaultScreenProperties , publisherOptions ) ; } * Accepts custom properties as a parameters * @ param { Object } publisherOptions * @ param null", "commit_type": "remove"}
{"commit_tokens": ["Added", "sub", "subDoc", "update", "functionality"], "add_tokens": "cb ( err , doc , parent ) ; var callback = function ( err , children , parent , lastPath ) { cb = config . callback || cb ; //push the new doc children = _ . extend ( children , data ) ; parent . save ( function ( err , doc ) { if ( doc ) { cb ( err , children ) ; } else { cb ( err ) ; } } ) ; } ; findSubDoc ( config , callback ) ;", "del_tokens": "cb ( err , doc , parent , lastPath ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "source", "option", "of", "make", "to", "be", "an", "object", "of", "arbitrary", "more", "info", "to", "be", "added", "to", "the", "torrent", "s", "info", "object"], "add_tokens": "* @ param options . moreInfo Typically used to generate a different info hash . // add additional moreInfo to info for ( var moreKey in options . moreInfo ) { // only add moreInfo if it doesn't overwrite info if ( ! Object . prototype . hasOwnProperty . call ( info , moreKey ) ) { info [ moreKey ] = options . moreInfo [ moreKey ] ; } }", "del_tokens": "* @ param options . source Typically used to generate a different info hash . if ( options . source ) info . source = options . source ;", "commit_type": "change"}
{"commit_tokens": ["Use", "both", "default", "and", "named", "export", "in", "polyfill"], "add_tokens": "function patch ( what ) { module . exports . patch = patch export default patch", "del_tokens": "export default function patch ( what ) {", "commit_type": "use"}
{"commit_tokens": ["Allow", "sharing", "a", "Chrome", "browser", "instance"], "add_tokens": "if ( state . browser && state . autoClose ) { // Check whether we have a browser already let browser ; if ( options . browser ) { options . log . debug ( 'Using a pre-configured Headless Chrome instance, the `chromeLaunchConfig` option will be ignored' ) ; browser = state . browser = options . browser ; state . autoClose = false ; } else { // Launch a Headless Chrome browser. We use a // state object which is accessible from the // wrapping function options . log . debug ( 'Launching Headless Chrome' ) ; browser = state . browser = await puppeteer . launch ( options . chromeLaunchConfig ) ; state . autoClose = true ; } // Create a page if ( state . autoClose ) { browser . close ( ) ; } browser : null ,", "del_tokens": "if ( state . browser ) { // Launch a Headless Chrome browser and create a page // We use a state object which is accessible from the // wrapping function options . log . debug ( 'Launching Headless Chrome' ) ; const browser = state . browser = await puppeteer . launch ( options . chromeLaunchConfig ) ; browser . close ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Remove", "log", "output", "fix", "display", "of", "array", "types"], "add_tokens": "return this . items . type + \"[]\" ;", "del_tokens": "console . log ( result ) ; return this . items + \"[]\" ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "createTransactions", "and", "bulkCreateTransactions", "to", "gen", "template"], "add_tokens": "import { TransactionsApi } from \"./transactionsApi\" ; this . _transactions = new TransactionsApi ( this . _configuration ) ; Object . defineProperty ( api . prototype , \"deprecated\" , { get : function ( ) { if ( ! this . _deprecated ) { this . _deprecated = new CodeGen . DeprecatedApi ( this . _configuration ) ; } return this . _deprecated ; } , enumerable : true , configurable : true } ) ;", "del_tokens": "this . _transactions = new CodeGen . TransactionsApi ( this . _configuration ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "base", "URL", "for", "pulling", "script", "in", "from", "the", "client", "."], "add_tokens": "/* global jQuery, Zepto, card, baseUrl */ card . require ( baseUrl + '/js/zepto.min.js' , function ( ) {", "del_tokens": "/* global jQuery, Zepto, card */ card . require ( 'http://hashdo.com/js/zepto.min.js' , function ( ) {", "commit_type": "use"}
{"commit_tokens": ["use", "browserstack", "inside", "travis", "ci", "for", "e2e", "tests", "with", "protractor", "(", "8", ")"], "add_tokens": "'browserstack.local' : true , 'browserstack.localIdentifier' : process . env . BROWSERSTACK_LOCAL_IDENTIFIER", "del_tokens": "'browserstack.local' : true", "commit_type": "use"}
{"commit_tokens": ["fix", "broken", "angular", "translate", "attr", "for", "meta", "tags", "in", "template"], "add_tokens": "$document . find ( 'body' ) [ 0 ] . appendChild ( script ) ;", "del_tokens": "$document . find ( 'body' ) . append ( script ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "some", "copyright", "dates", "."], "add_tokens": "* Copyright ( c ) 2014 - 2015 Xcraft < mathieu @ schroetersa . ch >", "del_tokens": "* Copyright ( c ) 2014 Xcraft < mathieu @ schroetersa . ch >", "commit_type": "update"}
{"commit_tokens": ["Add", "desktop", "notifications", "overridable", "in", "the", "same", "way", "as", "other", "components", "(", "although", "it", "s", "not", "a", "react", "component", ")", ".", "Also", "extend", "the", "flux", "dispatcher", "a", "little", "to", "be", "less", "dumb", "about", "dispatching", "while", "something", "else", "is", "already", "dispatching", "."], "add_tokens": "var ComponentBroker = require ( '../../ComponentBroker' ) ; var Notifier = ComponentBroker . get ( 'organisms/Notifier' ) ; logged_in : ! ! ( MatrixClientPeg . get ( ) && MatrixClientPeg . get ( ) . credentials ) , Notifier . stop ( ) ; this . focusComposer = true ; Notifier . start ( ) ;", "del_tokens": "logged_in : ! ! ( MatrixClientPeg . get ( ) && mxCliPeg . get ( ) . credentials ) , this . focusComposer = true ;", "commit_type": "add"}
{"commit_tokens": ["use", "define", "to", "make", "inherited", "methods", "non", "-", "enumerable"], "add_tokens": "utils . define ( receiver , key , provider [ key ] ) ; utils . define ( receiver , key , provider [ key ] ) ;", "del_tokens": "receiver [ key ] = provider [ key ] ; receiver [ key ] = provider [ key ] ;", "commit_type": "use"}
{"commit_tokens": ["make", "private", "property", "non", "-", "enumerable"], "add_tokens": "app . define ( '_wildCardEmitter' , true ) ;", "del_tokens": "app . _wildCardEmitter = true ;", "commit_type": "make"}
{"commit_tokens": ["changed", "directory", "structure", "for", "builds"], "add_tokens": "dest : 'build/d3-view.js' ,", "del_tokens": "dest : 'dist/d3-view.js' ,", "commit_type": "change"}
{"commit_tokens": ["Added", "imagemin", "grunt", "task", "and", "compressed", "all", "images", "in", "demo", "site"], "add_tokens": "imagemin : { demoimages : { // Target options : { // Target options } , files : [ { expand : true , // Enable dynamic expansion cwd : 'demo/img' , // Src matches are relative to this path src : [ '*.{png,jpg,gif}' ] , // Actual patterns to match dest : 'demo/img' // Destination path prefix } ] } , } , grunt . loadNpmTasks ( 'grunt-contrib-imagemin' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'uglify' , 'markdox' , 'imagemin' , 'compress' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'uglify' , 'markdox' , 'compress' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "color", "descriptions", "to", "color", "palette"], "add_tokens": "'<div class=\"col s6\">' , '<span class=\"color-name\"></span>' , '</div>' , '<div class=\"col s6\">' , '<span class=\"color-name\"></span>' , '</div>' , colorNames : options . colorNames ,", "del_tokens": "/ *'<li>', '<div class=\"btn-group\">' , ' <div class=\"note-palette-title\">' + lang . color . background + '</div>' , ' <div>' , ' <button type=\"button\" class=\"note-color-reset btn\" data-event=\"backColor\" data-value=\"inherit\">' , lang . color . transparent , ' </button>' , ' </div>' , ' <div class=\"note-holder\" data-event=\"backColor\"/>' , '</div>' , '<div class=\"btn-group\">' , ' <div class=\"note-palette-title\">' + lang . color . foreground + '</div>' , ' <div>' , ' <button type=\"button\" class=\"note-color-reset btn\" data-event=\"removeFormat\" data-value=\"foreColor\">' , lang . color . resetToDefault , ' </button>' , ' </div>' , ' <div class=\"note-holder\" data-event=\"foreColor\"/>' , '</div>' , '</li>' * /", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "in", "the", "replace", "logic", "for", "the", "webpack", "eval", "code", "that", "was", "trying", "to", "parse", "arguments", "passed", "to", "eval", "that", "were", "not", "string", "literals", "."], "add_tokens": "if ( node . callee . name === 'eval' && node . arguments [ 0 ] . type === 'Literal' && typeof node . arguments [ 0 ] . value === 'string' ) {", "del_tokens": "if ( node . callee . name === 'eval' ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "outdated", "certs", "and", "testing", "w", "/", "SSL", "options"], "add_tokens": "{ host : 'kinesis.us-east-1.amazonaws.com' , method : 'POST' } : { host : 'localhost' , port : port , method : 'POST' , rejectUnauthorized : false }", "del_tokens": "{ host : 'kinesis.us-east-1.amazonaws.com' , method : 'POST' } : { host : 'localhost' , port : port , method : 'POST' } process . env . NODE_TLS_REJECT_UNAUTHORIZED = '0'", "commit_type": "update"}
{"commit_tokens": ["make", "ctx", ".", "getAttribute", "work"], "add_tokens": "getAttribute : function ( id , attr , args ) { if ( ! mCompiled ) throw \"Error\" let entity = null ; try { entity = mObjects [ 'resources' ] [ id ] } catch ( e ) { throw \"No such entity: \" + id } if ( entity . local ) throw \"This entity is private\" if ( ! args ) args = { } args . __proto__ = mObjects [ 'context' ] ; return entity . getAttribute ( attr , mObjects [ 'resources' ] , args )", "del_tokens": "getAttribute : function ( id , args ) { let curObj = this . _get ( id , args ) ; return mObjects [ 'system' ] . getattrs ( curObj , mObjects [ 'system' ] , id ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "timing", "on", "log", "handling"], "add_tokens": "// don't do this before the promises are evaluated // are the driver script won't have a chance to have // set it yet var resolved = { log : requestClauses . log } ;", "del_tokens": "var resolved = { log : requestClauses . log } ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "which", "a", "layer", "s", "mouseover", "and", "mouseout", "events", "might", "cause", "an", "error"], "add_tokens": "duration = duration || 0 ; // Retrieve or create canvas's event cache var eventCache = getEventCache ( $elem [ 0 ] ) ; // Bind one canvas event which handles all layer events of that type $elem . bind ( helperEventName + '.jCanvas' , function ( event ) {", "del_tokens": "$elem . bind ( helperEventName + '.jCanvas' , function ( event ) { var eventCache = getEventCache ( $elem [ 0 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "sftp", "-", "web", ".", "ts", "(", "no", "longer", "needed", "unified", "with", "Node", "-", "based", "client", ")"], "add_tokens": "lib_web : [ 'lib/util-web.ts' , 'lib/promise.ts' , 'lib/util.ts' , 'lib/charsets.ts' , 'lib/fs-api.ts' , 'lib/fs-misc.ts' , 'lib/fs-glob.ts' , 'lib/fs-sources.ts' , 'lib/fs-targets.ts' , 'lib/fs-plus.ts' , 'lib/channel.ts' , 'lib/channel-ws.ts' , 'lib/sftp-enums.ts' , 'lib/sftp-packet.ts' , 'lib/sftp-misc.ts' , 'lib/sftp-client.ts' , 'lib/sftp.ts' ] ,", "del_tokens": "lib_web : [ 'lib/util-web.ts' , 'lib/promise.ts' , 'lib/util.ts' , 'lib/charsets.ts' , 'lib/fs-api.ts' , 'lib/fs-misc.ts' , 'lib/fs-glob.ts' , 'lib/fs-sources.ts' , 'lib/fs-targets.ts' , 'lib/fs-plus.ts' , 'lib/channel.ts' , 'lib/channel-ws.ts' , 'lib/sftp-enums.ts' , 'lib/sftp-packet.ts' , 'lib/sftp-misc.ts' , 'lib/sftp-client.ts' , 'lib/sftp-web.ts' ] ,", "commit_type": "remove"}
{"commit_tokens": ["Fix", "checkbox", "behavior", "when", "truthMap", "is", "not", "defined"], "add_tokens": ", value = config . value , checked = truthMap ? truthMap [ \"true\" ] === value : value ; if ( meta . isHidden ) return null ;", "del_tokens": ", checked = truthMap [ \"true\" ] === config . value ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "indentedSyntax", "not", "being", "a", "boolean", "flag"], "add_tokens": "( ext === 'sass' ? '&indentedSyntax' : '' ) + '!' +", "del_tokens": "( ext === 'sass' ? '&indentedSyntax=sass' : '' ) + '!' +", "commit_type": "fix"}
{"commit_tokens": ["Change", "formatting", "of", "assertion", "violations", "."], "add_tokens": "if ( result . name ) path += \" > \" + result . name ; this . _write ( Style . bold ( \"[\" + path + \"]\" ) ) ; this . _write ( \"Actual: \" + result . actual ) ; this . _write ( \"Expected: \" + result . expected ) ;", "del_tokens": "this . _write ( Style . bold ( path + \" > \" + result . name ) ) ; this . _write ( \" Actual: \" + result . actual ) ; this . _write ( \" Expected: \" + result . expected ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "typo", "in", "matchRoutes", ".", "js"], "add_tokens": "* Match routes against a path", "del_tokens": "* Match rotues against a path", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "args", "are", "handled", "correctly", "by", "run"], "add_tokens": "var args = fixture . content ; if ( Array . isArray ( args [ 0 ] ) ) { file . run . apply ( null , args ) ; } else { file . run ( args ) ; }", "del_tokens": "file . run ( fixture . content ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "atom", "-", "beautify", "for", "all", "the", "code", "for", "some", "consistency"], "add_tokens": "var DisneyAPI = new ( require ( \"wdwjs\" ) ) ( ) ; if ( err ) return console . error ( \"Error fetching Magic Kingdom wait times: \" + err ) ; console . log ( JSON . stringify ( data , null , 2 ) ) ; console . log ( JSON . stringify ( data , null , 2 ) ) ; console . log ( JSON . stringify ( d , null , 2 ) ) ; console . log ( JSON . stringify ( d , null , 2 ) ) ; console . log ( JSON . stringify ( data , null , 2 ) ) ;", "del_tokens": "var DisneyAPI = new ( require ( \"wdwjs\" ) ) ( ) ; if ( err ) return console . error ( \"Error fetching Magic Kingdom wait times: \" + err ) ; console . log ( JSON . stringify ( data , null , 2 ) ) ; console . log ( JSON . stringify ( data , null , 2 ) ) ; console . log ( JSON . stringify ( d , null , 2 ) ) ; console . log ( JSON . stringify ( d , null , 2 ) ) ; console . log ( JSON . stringify ( data , null , 2 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "octal", "and", "hex", "values", "in", "output"], "add_tokens": "var parse = require ( 'acorn/acorn_loose' ) . parse_dammit ; var syntaxTree = parse ( contents , { value : ( node . raw !== undefined ) ? node . raw : node . value ,", "del_tokens": "var acorn = require ( 'acorn' ) ; var syntaxTree = acorn . parse ( contents , { value : node . value ,", "commit_type": "fix"}
{"commit_tokens": ["Adding", "simple", "shuffling", "technique", "to", "cross", "validation", "test"], "add_tokens": "samples = samples . sort ( function ( x , y ) { return Math . random ( ) ; } ) ; for ( var i = 0 ; i < samples . length ; i ++ ) { if ( samples [ i ] [ 0 ] >= 20 ) { outputs . push ( \"20-30\" ) ; } else if ( samples [ i ] [ 0 ] >= 10 ) { outputs . push ( \"10-20\" ) ; } else { outputs . push ( \"0-9\" ) ; } } samples . slice ( 0 , 22 ) , outputs . slice ( 0 , 22 ) , samples . slice ( 22 ) , outputs . slice ( 22 ) ) ; //console.log(curve);", "del_tokens": "outputs . push ( \"0-9\" ) ; outputs . push ( \"10-20\" ) ; outputs . push ( \"20-30\" ) ; samples . slice ( 0 , 18 ) , outputs . slice ( 0 , 18 ) , samples . slice ( 18 ) , outputs . slice ( 18 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "radio", "renderInput", "local", "var", ".", "Use", "extend", "for", "inputAttrs", "instead", "of", "defaults", ".", "inputClass", "is", "no", "longer", "set", "with", "addClass"], "add_tokens": "var $checkbox = testField . renderSingleCheckbox ( { value : 'foo' , display : testOpts . possibleVals . foo } , true , 1 ) ; var $checkbox = testField . renderSingleCheckbox ( { value : 'foo' , display : testOpts . possibleVals . foo } , false , 1 ) ; model : new Backbone . Model ( )", "del_tokens": "var $checkbox = testField . renderSingleCheckbox ( 'foo' , testOpts . possibleVals . foo , true , 1 ) ; var $checkbox = testField . renderSingleCheckbox ( 'foo' , testOpts . possibleVals . foo , false , 1 ) ; model : testModel", "commit_type": "move"}
{"commit_tokens": ["Add", "delimiter", "to", "UdpBroadcastManager", "ID", "."], "add_tokens": "return data . address + ':' + data . port ;", "del_tokens": "return data . address + data . port ;", "commit_type": "add"}
{"commit_tokens": ["Use", "native", "Object", ".", "keys"], "add_tokens": "var PREFIX_REGEX = Object . keys ( PREFIX_MAP ) . sort ( function ( a , b ) { var UNIT_REGEX = Object . keys ( UNIT_MAP ) . sort ( function ( a , b ) {", "del_tokens": "// Utility functions // return object keys function objectKeys ( obj ) { var keys = [ ] ; for ( var key in obj ) { if ( obj . hasOwnProperty ( key ) ) { keys . push ( key ) ; } } return keys ; } var PREFIX_REGEX = objectKeys ( PREFIX_MAP ) . sort ( function ( a , b ) { var UNIT_REGEX = objectKeys ( UNIT_MAP ) . sort ( function ( a , b ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "using", "shortcodes", "inline"], "add_tokens": "var inlineMode = ( options || { } ) . inlineMode || false ; var tokenizers = inlineMode ? parser . inlineTokenizers : parser . blockTokenizers ; var methods = inlineMode ? parser . inlineMethods : parser . blockMethods ; tokenizers . shortcode = shortcodeTokenizer ; methods . splice ( methods . indexOf ( \"html\" ) , 0 , \"shortcode\" ) ;", "del_tokens": "parser . blockTokenizers . shortcode = shortcodeTokenizer ; parser . blockMethods . splice ( parser . blockMethods . indexOf ( \"html\" ) , 0 , \"shortcode\" ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "valid", "-", "url", "instead", "of", "local", "regex"], "add_tokens": "var validUrl = require ( 'valid-url' ) ; } else if ( validUrl . isUri ( arg ) ) {", "del_tokens": "var URL = / ^(?:(?:ht|f)tp(?:s?)\\:\\/\\/|~\\/|\\/)?(?:\\w+:\\w+@)?((?:(?:[-\\w\\d{1-3}]+\\.)+(?:com|org|cat|coop|int|pro|tel|xxx|net|gov|mil|biz|info|mobi|name|aero|jobs|edu|co\\.uk|ac\\.uk|it|fr|tv|museum|asia|local|travel|[a-z]{2})?)|((\\b25[0-5]\\b|\\b[2][0-4][0-9]\\b|\\b[0-1]?[0-9]?[0-9]\\b)(\\.(\\b25[0-5]\\b|\\b[2][0-4][0-9]\\b|\\b[0-1]?[0-9]?[0-9]\\b)){3}))(?::[\\d]{1,5})?(?:(?:(?:\\/(?:[-\\w~!$+|.,=]|%[a-f\\d]{2})+)+|\\/)+|\\?|#)?(?:(?:\\?(?:[-\\w~!$+|.,*:]|%[a-f\\d{2}])+=?(?:[-\\w~!$+|.,*:=]|%[a-f\\d]{2})*)(?:&(?:[-\\w~!$+|.,*:]|%[a-f\\d{2}])+=?(?:[-\\w~!$+|.,*:=]|%[a-f\\d]{2})*)*)*(?:#(?:[-\\w~!$ |\\/.,*:;=]|%[a-f\\d]{2})*)?$ / ; } else if ( URL . test ( arg ) && path . extname ( arg ) . indexOf ( '.css' ) !== - 1 ) { that . urls . push ( arg ) ; } else if ( URL . test ( arg ) ) {", "commit_type": "use"}
{"commit_tokens": ["updated", "the", "user", "-", "agent", "string", "in", "the", "API", "requests"], "add_tokens": "'User-Agent' : 'asthma-forecast-sdk-node@' + packageJson . version", "del_tokens": "'User-Agent' : 'asthma-forecast@' + packageJson . version", "commit_type": "update"}
{"commit_tokens": ["update", "README", "and", "package", ".", "json", "after", "merge", "a", "PR"], "add_tokens": "", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "named", "themes"], "add_tokens": "theme : [ 'THEME' ] , template : [ 'TEMPLATE' ] , t . same ( results . theme , [ 'THEME' ] , 'theme passed through' ) t . same ( results . template , [ 'TEMPLATE' ] , 'template passed through' ) theme : [ 'THEME' ] , template : [ 'TEMPLATE' ] , theme : [ 'THEME' ] , template : [ 'TEMPLATE' ] ,", "del_tokens": "theme : 'THEME' , template : 'TEMPLATE' , t . is ( results . theme , 'THEME' , 'theme passed through' ) t . is ( results . template , 'TEMPLATE' , 'template passed through' ) theme : 'THEME' , template : 'TEMPLATE' , theme : 'THEME' , template : 'TEMPLATE' ,", "commit_type": "add"}
{"commit_tokens": ["Changed", "catch", "parameter", "name", "to", "avoid", "name", "collision", "and", "fixed", "comment", "typo", "."], "add_tokens": "let data = null let error = null } catch ( unusedError ) { data = null // In case somehow data got set to not null, this is more of a failsafe.", "del_tokens": "var data = null var error = null } catch ( error ) { data = null //incase somehow data got set to not null, this is more of a failsafe.", "commit_type": "change"}
{"commit_tokens": ["Added", "bower_components", "to", ".", "gitignore", "."], "add_tokens": "var StaticScraper = require ( './StaticScraper.js' ) , function initScraper ( ScraperType , url ) { var promise = new ScraperPromise ( ) , scraper = new ScraperType ( function ( err , scraper ) { promise . _fire ( err , scraper ) ; if ( url ) { scraper . get ( url ) ; return initScraper ( StaticScraper , url ) ; return initScraper ( StaticScraper , url ) ; StaticScraper : StaticScraper ,", "del_tokens": "var SimpleScraper = require ( './StaticScraper.js' ) , function initScraper ( type , url ) { var promise = new ScraperPromise ( ) ; if ( url ) { type ( url , function ( error , scraper ) { promise . _fire ( error , scraper ) ; } ) ; } else { type ( function ( error , scraper ) { promise . _fire ( error , scraper ) ; return initScraper ( SimpleScraper , url ) ; return initScraper ( DynamicScraper , url ) ; SimpleScraper : SimpleScraper ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "_localAddress", "reference", "typo", "."], "add_tokens": "opts . address = opts . address || this . _localAddress ;", "del_tokens": "opts . address = opts . address || this . localAddress ;", "commit_type": "fix"}
{"commit_tokens": ["added", "ability", "to", "set", "http", "timeout", "value"], "add_tokens": "var timeout = ( params ) ? params . timeout || 10000 : 10000 ; http . getJson ( _createUrl ( params ) , timeout , function handleResponse ( err , data ) {", "del_tokens": "http . getJson ( _createUrl ( params ) , 2000 , function handleResponse ( err , data ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "eq", "primitive"], "add_tokens": "return [ a , '=' , b ] . join ( ' ' ) ;", "del_tokens": "return a + ' = ' + b ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "few", "steps", "to", "make", "sure", "that", "we", "are", "able", "to", "load", "two", "versions", "of", "the", "LJM", "library", ".", "The", ".", "dll", "doesn", "t", "actually", "get", "un", "-", "loaded", "...", "That", "functionality", "is", "hidden", "by", "the", "ffi", "library", "."], "add_tokens": "'include the default version of LJM' : function ( test ) { var ljm_ffi = require ( '../lib/ljm-ffi' ) ; ljm = ljm_ffi . load ( ) ; liblabjack = ljm_ffi . loadSafe ( ) ; ffi_liblabjack = ljm_ffi . loadRaw ( ) ; test . done ( ) ; } , 'Execute LJM_NameToAddress (Sync)' : function ( test ) { var ljmLibraryVersion = ljm . LJM_ReadLibraryConfigS ( 'LJM_LIBRARY_VERSION' , 0 ) ; var expectedData = { 'ljmError' : 0 , 'Parameter' : 'LJM_LIBRARY_VERSION' , 'Value' : ljmLibraryVersion . Value , } ; console . log ( ' - Installed LJM Library Version:' , ljmLibraryVersion . Value ) ; test . deepEqual ( ljmLibraryVersion , expectedData ) ; test . done ( ) ; } , 'unload ljm' : function ( test ) { var ljm_ffi = require ( '../lib/ljm-ffi' ) ; ljm_ffi . unload ( ) ; test . done ( ) ; } , 'Execute LJM_NameToAddress (Sync) -v2' : function ( test ) { console . log ( ' - Secondary LJM Library Version:' , ljmLibraryVersion . Value ) ; 'Execute LJM_NameToAddress (Async) -v2' : function ( test ) {", "del_tokens": "'Execute LJM_NameToAddress (Sync)' : function ( test ) { console . log ( ' - LJM Library Version:' , ljmLibraryVersion . Value ) ; 'Execute LJM_NameToAddress (Async)' : function ( test ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "off", "by", "one", "error", "preventing", "single", "retry"], "add_tokens": "else if ( self . current . retry >= 1 ) { if ( self . current . retry >= 0 ) {", "del_tokens": "else if ( self . current . retry > 1 ) { if ( self . current . retry > 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "compress", "dependency", "and", "refuse", "gzip", "encoding"], "add_tokens": "req = require ( 'request' ) ; \"Accept-Encoding\" : \"none\" ,", "del_tokens": "req = require ( 'request' ) , compress = null ; try { compress = require ( \"compress\" ) ; } catch ( e ) { } \"Accept-Encoding\" : compress ? \"gzip,deflate\" : \"none\" ,", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "minor", "things", "here", "and", "there"], "add_tokens": "fs . writeFile ( dest , content , function ( err ) {", "del_tokens": "fs . writeFile ( destination , content , function ( err ) {", "commit_type": "fix"}
{"commit_tokens": ["Change", "url", "for", "rpc", "methods"], "add_tokens": "var manager = new HttpRPCManager ( app , '/' ) ;", "del_tokens": "var manager = new HttpRPCManager ( app , '/rpc' ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "use", "of", "req", ".", "flash", "in", "test", "env", "+", "reenable", "redis"], "add_tokens": "app . use ( flash ) ;", "del_tokens": "app . use ( flash ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "config", "attr", "to", "data", "-", "ak", "-", "scrolltoggle"], "add_tokens": "if ( this . el_ . hasAttribute ( 'data-ak-scrolltoggle' ) ) { var elConfig = JSON . parse ( this . el_ . getAttribute ( 'data-ak-scrolltoggle' ) ) ;", "del_tokens": "if ( this . el_ . hasAttribute ( 'data-scrolltoggle' ) ) { var elConfig = JSON . parse ( this . el_ . getAttribute ( 'data-scrolltoggle' ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "Node", "4", "&", "5"], "add_tokens": "var db = new sqlite3 . Database ( ':memory:' ) console . log ( db )", "del_tokens": "var db = new sqlite3 . Database ( ':memory:' )", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "only", "in", "test", "case", "!"], "add_tokens": "describe ( 'toDiastereotopicSVG on propane' , function ( ) {", "del_tokens": "describe . only ( 'toDiastereotopicSVG on propane' , function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["fixed", "a", "bug", "where", "comments", "in", "script", "nodes", "could", "lead", "to", "syntax", "errors"], "add_tokens": "content = content . trim ( ) . replace ( / ;$ / , '' ) . replace ( / \\/\\/.*$ / gm , '' ) ; if ( content . trim ( ) ) { resultObject . functions . push ( content ) ; usesMerge = true ; }", "del_tokens": "resultObject . functions . push ( content . trim ( ) . replace ( / ;$ / , '' ) ) ; usesMerge = true ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "browser", "locale", "support", "."], "add_tokens": "Object . defineProperty ( this , 'supportedLocales' , { return filingCabinet . languages ; if ( ! req . session ) req . session = { language : req . locale || config . defaultLocale } ; else if ( ! req . session . language ) req . session . language = req . locale || config . defaultLocale ;", "del_tokens": "Object . defineProperty ( this , 'locale' , { return config . locale ; } , enumerable : true , configurable : false } ) ; Object . defineProperty ( this , 'session' , { get : function ( ) { return config . session ; } , enumerable : true , configurable : false } ) ; Object . defineProperty ( this , 'site' , { get : function ( ) { return config . site ; if ( ! req . session ) { req . session = { language : config . defaultLocale } ; } else if ( ! req . session . language ) { req . session . language = config . defaultLocale ; }", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "mapping", "assigned", "words", "to", "normalized", "slugs"], "add_tokens": "chapter . rawNumber = chapter . number ; // TRICKY: we use the un-normalized slug here so we don't break word assignments let temp = props . tw_assignments [ chapter . rawNumber ] [ frameSlug ] ; slug = slug . replace ( / ^(0+) / , '' ) . trim ( ) ;", "del_tokens": "let temp = props . tw_assignments [ chapter . number ] [ frameSlug ] ; slug = slug . replace ( / ^(0+) / , '' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "hoodi", "app", "install", "/", "start", "routine"], "add_tokens": "// setup modules DB npm . load ( function ( error , npm ) { var password = npm . config . get ( name + \"_admin_pass\" ) ; request ( { url : couch_url + \"/modules\" , method : \"PUT\" , auth : \"admin:\" + password } , function ( error , response , body ) { // boop. request ( { url : couch_url + \"/modules/global_config\" , method : \"PUT\" , auth : \"admin:\" + password , body : \"{}\" } , function ( error , response , body ) { // boom start_workers ( ) ; } ) ; } ) ; } ) ;", "del_tokens": "start_workers ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "way", "of", "reading", "option", "-", "only", "properties"], "add_tokens": "res = [ ] , d , defined = Object . create ( null ) ; res . push ( d = new GoogleObjectProperty ( k , d ) ) ; defined [ d . getName ( ) ] = null ; // now read all properties of the object which name start with 'gopt_' def = Ember . keys ( this ) ; for ( var i = 0 ; i < def . length ; i ++ ) { if ( / ^gopt_ / . test ( def [ i ] ) && ( k = def [ i ] . substr ( 5 ) ) && ! ( k in defined ) ) { res . push ( new GoogleObjectProperty ( def [ i ] , { name : k , optionOnly : true } ) ) ; } }", "del_tokens": "res = [ ] , d ; res . push ( new GoogleObjectProperty ( k , d ) ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "hasPassword", "to", "User", ".", "prototype"], "add_tokens": "User . prototype . hasPassword =", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "socket", "options", "for", "mongo", "connection"], "add_tokens": "var opts = { server : { socketOptions : { keepAlive : 1 , connectTimeoutMS : 30000 } } , replset : { socketOptions : { keepAlive : 1 , connectTimeoutMS : 30000 } } } ;", "del_tokens": "var opts = { } ;", "commit_type": "add"}
{"commit_tokens": ["adding", "option", "to", "fill", "scrollbar", "gap"], "add_tokens": "export interface BodyScrollOptions { reserveScrollBarGap ? : boolean ; } let previousBodyPaddingRight ; const setOverflowHidden = ( options ? : BodyScrollOptions ) => { const reserveScrollBarGap = ! ! options && options . reserveScrollBarGap === true ; const scrollBarGap = window . innerWidth - document . documentElement . clientWidth ; if ( reserveScrollBarGap && scrollBarGap > 0 ) { previousBodyPaddingRight = document . body . style . paddingRight ; document . body . style . paddingRight = ` ${ scrollBarGap } ` ; } if ( previousBodyPaddingRight !== undefined ) { document . body . style . paddingRight = previousBodyPaddingRight ; previousBodyPaddingRight = undefined ; } export const disableBodyScroll = ( targetElement : any , options ? : BodyScrollOptions ) : void => { setOverflowHidden ( options ) ;", "del_tokens": "const setOverflowHidden = ( ) => { export const disableBodyScroll = ( targetElement : any ) : void => { setOverflowHidden ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bugs", "in", "ErrorQueueStore", "and", "deepMatchObject", "()"], "add_tokens": "if ( typeof matchProp === 'object' ) { return ( typeof objProp === 'object' ) ? deepMatchObject ( objProp , matchProp , testFn ) : false ; } else { return testFn ( objProp , matchProp ) ; }", "del_tokens": "return ( typeof matchProp === 'object' ) ? testObjAgainstMatch ( objProp , matchProp , testFn ) : testFn ( objProp , matchProp ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "positioning", "engine", "to", "use", "popper", ".", "js", "instead", "of", "tether"], "add_tokens": "text : [ 'Shepherd is a javascript library for guiding users through your app. It uses <a href=\"https://popper.js.org/\">Popper.js</a>, another open source library, to position all of its steps.' , 'Popper makes sure your steps never end up off screen or cropped by an overflow. Try resizing your browser to see what we mean.' ] , text : 'Including Shepherd is easy! Just include popper.js, shepherd.js, and a Shepherd theme file.' , attachTo : '#hero-including-code left' , attachTo : '#hero-example-code right' ,", "del_tokens": "text : [ 'Shepherd is a javascript library for guiding users through your app. It uses <a href=\"http://github.hubspot.com/tether/\">Tether</a>, another open source library, to position all of its steps.' , 'Tether makes sure your steps never end up off screen or cropped by an overflow. Try resizing your browser to see what we mean.' ] , text : 'Including Shepherd is easy! Just include shepherd.js, and a Shepherd theme file.' , attachTo : '.hero-including bottom' , attachTo : '.hero-example bottom' ,", "commit_type": "update"}
{"commit_tokens": ["fixed", "issue", "with", "calling", "make", "()"], "add_tokens": "return exports . Exchange . make ( a , b , c ) ;", "del_tokens": "return Exchange . make ( a , b , c ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "log", "messages", "configurable", "maxDbSize", "use", "of", "Timer", ".", "unref"], "add_tokens": "var tid = setInterval ( function ( ) { } , config . recoverInterval || 240000 ) tid . unref ( ) if ( fs . existsSync ( getFileNameForDb ( ) ) && fs . statSync ( getFileNameForDb ( ) ) . size >= ( config . maxDbSize || 1024 * 1024 * 50 ) ) { logger . error ( 'checkMaxDbSize: removing old records from NeDB failed: %s' , ( err . msg || err . toString ( ) ) ) logger . info ( 'checkMaxDbSize: maximum reached %d records deleted' , numRemoved || 0 ) logger . error ( 'checkMaxDbSize: Unknown error:' + error , { error : error , dbError : err || '-' , numRemoved : numRemoved || - 1 } )", "del_tokens": "setInterval ( function ( ) { } , config . recoverInterval || 30000 ) if ( fs . existsSync ( getFileNameForDb ( ) ) && fs . statSync ( getFileNameForDb ( ) ) . size >= 1024 * 1024 * 50 ) { logger . error ( 'Removed old records from NeDB because NeDB file grows over maximum failed: %s' , ( err . msg || err . toString ( ) ) ) logger . info ( 'Removed old records from NeDB because NeDB file grows over maximum: %d records removed' , numRemoved || 0 ) logger . error ( 'Unknown error in function checkMaxDbSize ' , { error : error , dbError : err || '-' , numRemoved : numRemoved || - 1 } )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "some", "trailing", "commas", "for", "IE"], "add_tokens": "numSamples : parseInt ( $row . find ( '.num-samples-input' ) . val ( ) ) variations : variations } ( Abba || { } , jQuery , Hash ) ) ;", "del_tokens": "numSamples : parseInt ( $row . find ( '.num-samples-input' ) . val ( ) ) , variations : variations , } ( Abba || { } , jQuery , Hash ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "optimization", "of", "child", "selectors", "with", "multiple", "classes"], "add_tokens": "var partial = current . replace ( names . shift ( ) , '' ) . trim ( ) if ( partial === '>' ) { break }", "del_tokens": "var partial = current . replace ( names . shift ( ) , '' )", "commit_type": "fix"}
{"commit_tokens": ["make", "limited", "links", "arrows", "move", "one", "page", "instead", "of", "chunks"], "add_tokens": "const liClasses = getClassesForLink ( link , vm . currentPage , vm . listOfPages . length - 1 ) function getClassesForLink ( link , currentPage , lastPage ) { if ( link === LEFT_ARROW && currentPage <= 0 ) { liClass . push ( 'disabled' ) } else if ( link === RIGHT_ARROW && currentPage >= lastPage ) { liClass . push ( 'disabled' ) } if ( link === LEFT_ARROW ) { return ( currentPage - 1 ) < 0 ? 0 : currentPage - 1 } else if ( link === RIGHT_ARROW ) { return ( currentPage + 1 > listOfPages . length - 1 ) ? listOfPages . length - 1 : currentPage + 1 } else if ( metaData === 'right-ellipses' ) { } else if ( metaData === 'left-ellipses' ) {", "del_tokens": "const liClasses = getClassesForLink ( link , vm . currentPage ) function getClassesForLink ( link , currentPage ) { if ( link === RIGHT_ARROW || metaData === 'right-ellipses' ) { } else if ( link === LEFT_ARROW || metaData === 'left-ellipses' ) {", "commit_type": "make"}
{"commit_tokens": ["Implement", "and", "document", "transformAuthInfo", "()", "."], "add_tokens": "passport . transformAuthInfo ( info , function ( err , tinfo ) { if ( err ) { return next ( err ) ; } req . authInfo = tinfo ; complete ( ) ; } ) ; } else { complete ( ) ; function complete ( ) { if ( options . successRedirect ) { return res . redirect ( options . successRedirect ) ; } next ( ) ;", "del_tokens": "req . authInfo = info ; if ( options . successRedirect ) { return res . redirect ( options . successRedirect ) ; next ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "return", "to", "all", "Scene", "functions"], "add_tokens": "this . isReady = false ; this . _listenForEvents ( ) ; this . isReady = true ; * @ return { Scene } Itself return this ; * @ return { Scene } Itself * @ return { Scene } Itself return this ; * @ return { Scene } Itself return this ; * @ return { Scene } Itself return this ; * @ return { Scene } Itself return this ; * @ return { Scene } Itself return this ;", "del_tokens": "this . _listenForEvents ( ) ; this . isReady = true ; * @ return { Scene } Itself", "commit_type": "add"}
{"commit_tokens": ["remove", "string", ".", "match", "because", "it", "is", "not", "used", "anymore"], "add_tokens": "module . exports . string = isString ;", "del_tokens": "/ ** * @ param obj * @ param { RegExp } regex * @ param [ ref ] * @ returns { * } * / function isStringMatch ( obj , regex , ref ) { isString ( obj , ref ) ; if ( ! obj . match ( regex ) ) { throwExpectedRegexMatchError ( obj , regex , ref ) ; } return obj ; } module . exports . string = isString ; module . exports . string . match = isStringMatch ;", "commit_type": "remove"}
{"commit_tokens": ["added", "node", "style", "callbacks", "to", "dataset", "actions", "and", "updated", "test", "to", "use", "it"], "add_tokens": "fetchRows : function ( sql , block , cb ) { execute : function ( sql , opts , block , cb ) { return this . _super ( arguments , [ sql , comb . merge ( { type : \"select\" } , opts ) , block ] , cb ) ;", "del_tokens": "fetchRows : function ( sql , block ) { execute : function ( sql , opts , block ) { return this . _super ( arguments , [ sql , comb . merge ( { type : \"select\" } , opts ) , block ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "handling", "for", "frame", "blending", "type"], "add_tokens": "var getFrameBlendingType = require ( './getFrameBlendingType' ) ; blendingMode : getBlendingMode ( baseValues . blendingMode ) , frameBlendingType : getFrameBlendingType ( baseValues . frameBlendingType )", "del_tokens": "blendingMode : getBlendingMode ( baseValues . blendingMode )", "commit_type": "add"}
{"commit_tokens": ["Added", "headers", "and", "query", "string", "separator", "support"], "add_tokens": "function getUrl ( urlStr , q , sep ) { var qObject = querystring . parse ( url . query , sep ) ; url . search = '?' + querystring . stringify ( qObject , sep ) ; var Source = function ( action , url , query , data , cookie , headers , sep ) { this . sep = sep || '&' ; this . headers = headers || { } ; var url = getUrl ( this . url , query , this . sep ) ; data : JSON . stringify ( data ) , headers : this . headers } ;", "del_tokens": "function getUrl ( urlStr , q ) { var qObject = querystring . parse ( url . query ) ; url . search = '?' + querystring . stringify ( qObject ) ; var Source = function ( action , url , query , data , cookie ) { var url = getUrl ( this . url , query ) ; data : JSON . stringify ( data ) }", "commit_type": "add"}
{"commit_tokens": ["use", "timezoneHour", "instead", "of", "rawTime"], "add_tokens": "if ( alarm . get ( 'timezoneHour' ) != null ) { this . timeField . val ( alarm . get ( 'timezoneHour' ) ) ; _this . event . timezoneHour = alarm . get ( 'timezoneHour' ) ; timezoneHour : alarm . get ( 'timezoneHour' ) , if ( alarm . get ( 'timezoneHour' ) != null ) { startRaw = alarm . get ( 'timezoneHour' ) ; if ( event . timezoneHour != null ) { start = event . timezoneHour ;", "del_tokens": "if ( alarm . get ( 'rawTime' ) != null ) { this . timeField . val ( alarm . get ( 'rawTime' ) ) ; _this . event . rawTime = alarm . get ( 'rawTime' ) ; console . log ( alarm ) ; console . log ( prevDateHash ) ; console . log ( this . views ) ; rawTime : alarm . get ( 'rawTime' ) , if ( alarm . get ( 'rawTime' ) != null ) { startRaw = alarm . get ( 'rawTime' ) ; if ( event . rawTime != null ) { start = event . rawTime ;", "commit_type": "use"}
{"commit_tokens": ["Made", "automatic", "download", "of", "missing", "schemas", "opt", "-", "in", "."], "add_tokens": "xmlxsd2js . parseString ( input , { downloadSchemas : true } , function ( err , result ) {", "del_tokens": "xmlxsd2js . parseString ( input , function ( err , result ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "centered", "alignment", ".", "Fix", "invalid", "align", "values"], "add_tokens": "var alignMap = { left : ':--' , right : '--:' , center : ':-:' } ; if ( align ) { border = alignMap [ align . value ] || border ; }", "del_tokens": "var alignMap = { left : ':--' , right : '--:' } ; if ( align ) { border = alignMap [ align . value ] ; }", "commit_type": "add"}
{"commit_tokens": ["updating", "segment", ".", "io", "snippet"], "add_tokens": "environment : 'production' , verbose : true", "del_tokens": "environment : 'production'", "commit_type": "update"}
{"commit_tokens": ["add", "timeout", "custom", "component", "or", "classname"], "add_tokens": "< ReactTransitionGroup transitionName = \"fade\" className = { this . props . className } component = { this . props . component || \"div\" } > setTimeout ( ( ) => Object . assign ( this . page . style , this . props . finalStyle ) ) }", "del_tokens": "< ReactTransitionGroup transitionName = \"fade\" className = { this . props . className } component = { this . props . component || \"div\" } > Object . assign ( this . page . style , this . props . finalStyle ) }", "commit_type": "add"}
{"commit_tokens": ["use", "delete", "instead", "of", "omit", "so", "files", "can", "be", "re", "-", "added", "later"], "add_tokens": "files = utils . union ( [ ] , files , config . files ) ; if ( res . length ) { config [ key ] = res ; return res ; // don't use `omit`, so the key can be re-added // by `update` delete config [ key ] ; return ;", "del_tokens": "if ( res . length === 0 ) { schema . omit ( key ) ; return ; return res ;", "commit_type": "use"}
{"commit_tokens": ["changed", "output", "of", "phonetic", "algorithms", "to", "be", "upper", "case", "while", "there"], "add_tokens": "return token . toUpperCase ( ) ;", "del_tokens": "return token ;", "commit_type": "change"}
{"commit_tokens": ["Adds", "tests", "fixes", "and", "a", "method", "to", "better", "use", "it", "on", "entty", "module", "for", "now", "."], "add_tokens": "mongo . getMongooseModel = getMongooseModel ; throw 'connection error' ; function getMongooseModel ( name ) { var promise = openConnection ( ) . then ( function ( db ) { mongo . db = db ; return mongoose . model ( name ) ; } , function ( db ) { throw 'connection error' ; return db ; } ) . then ( function ( model ) { closeConnection ( ) ; return model ; } ) ; return promise ; }", "del_tokens": "console . log ( 'error error error' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "release", "config", "and", "fix", "build"], "add_tokens": "var chartFiles = new Funnel ( path . join ( this . project . root , 'bower_components' , 'arcgis-cedar/dist/charts/' ) , {", "del_tokens": "var chartFiles = new Funnel ( path . join ( __dirname , 'bower_components' , 'arcgis-cedar/dist/charts/' ) , {", "commit_type": "add"}
{"commit_tokens": ["Move", "code", "to", "src", "folder", "&", "rename", "main"], "add_tokens": "const tangram_carto = require ( '../src/index.js' ) ;", "del_tokens": "const tangram_carto = require ( '../main.js' ) ;", "commit_type": "move"}
{"commit_tokens": ["updated", "pelias", "-", "model", "to", "@missinglink", "s", "model", "PR", "for", "addParent", "/", "removeParent", "and", "3", "parameter", "constructor"], "add_tokens": "var wofDoc = new Document ( 'whosonfirst' , record . place_type , record . id ) ; wofDoc . addParent ( 'locality' , hierarchy_element . name , hierarchy_element . id . toString ( ) ) ; wofDoc . addParent ( 'localadmin' , hierarchy_element . name , hierarchy_element . id . toString ( ) ) ; wofDoc . addParent ( 'county' , hierarchy_element . name , hierarchy_element . id . toString ( ) ) ; wofDoc . addParent ( 'region' , hierarchy_element . name , hierarchy_element . id . toString ( ) , hierarchy_element . abbreviation ) ; } else { wofDoc . addParent ( 'region' , hierarchy_element . name , hierarchy_element . id . toString ( ) ) ; wofDoc . addParent ( 'country' , hierarchy_element . name , hierarchy_element . id . toString ( ) ) ;", "del_tokens": "var wofDoc = new Document ( 'whosonfirst' , record . id ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "typo", "in", "error", "message", "."], "add_tokens": "callback ( 'Error parsing batch:' + batchName + '\\n' ) ;", "del_tokens": "callback ( 'Error parsin batch:' + batchName + '\\n' ) ;", "commit_type": "fix"}
{"commit_tokens": ["update", "the", "index", ".", "html", "file", "to", "use", "a", "new", "image", "so", "it", "doesn", "t", "really", "look", "like", "angular", "sponsors", "docular", ".", "Updated", "some", "properties", "in", "the", "npm", "package", "file", "and", "bumped", "the", "version"], "add_tokens": "groupTitle : 'Angular' , //this is what will show up in the UI for this group groupTitle : 'Docular' , //this is what will show up in the UI for this group title : \"Docular API\" , [ \"baseURL = '\" + baseUrl + \"'; addTag('base', {href: '\" + baseUrl + \"'});\" ]", "del_tokens": "groupTitle : 'Angular Docs' , //this is what will show up in the UI for this group groupTitle : 'Docular Doc Generation' , //this is what will show up in the UI for this group title : \"Docular\" , [ \"addTag('base', {href: '\" + baseUrl + \"'});\" ]", "commit_type": "update"}
{"commit_tokens": ["Adds", "tests", "for", "sensor", ".", "monitoringConfig", "()", "functions", "."], "add_tokens": "sound : \"apnsSound\" , // string if ( configProperty ) return this . _dirty [ configProperty ] || false ; // if the above didn't mark anything because this is a dummy-config, // ensure this still complies with expected behavior if ( Object . keys ( this . _dirty ) . length === 0 ) { this . _dirty . __ALL__ = true ; }", "del_tokens": "sound : \"apnsSoud\" , // string if ( configProperty ) return this . _dirty [ configProperty ] ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "deep", "clone", "of", "actions", "and", "cleaned", "up", "project"], "add_tokens": "cache : { } , packageCache : { } , fullPaths : options . watch", "del_tokens": "cache : { } , packageCache : { } , fullPaths : true", "commit_type": "fix"}
{"commit_tokens": ["fixed", "two", "big", "bugs", "in", "the", "withJoins", "feature", "now", "works", "both", "with", "single", "join", "names", "and", "dot", "notation", "join", "chains"], "add_tokens": "console . error ( snippet . name + ': unknown type for attr attribute of relationship ' + name + ', ignoring' ) ; if ( ! arrays . length ) { join . _dotPath = join . name ; } else { join . _dotPath = arrays . join ( '.' ) + '.' + join . name ; } return ; if ( withJoinName . substr ( 0 , dotPath . length + 1 ) === ( dotPath + '.' ) ) {", "del_tokens": "console . log ( snippet . name + ': unknown type for attr attribute of relationship ' + name + ', ignoring' ) ; join . _dotPath = arrays . join ( '.' ) + '.' + join . name ; if ( withJoinName . substr ( 0 , dotPath + 1 ) === ( dotPath + '.' ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "froala", "/", "knockout", "-", "froala", "/", "issues", "/", "16"], "add_tokens": "function update ( element , value , bindings ) { //if froalaInstance defined, use that for the editor instance var allBindings = unwrap ( bindings ( ) ) ; if ( allBindings . froalaInstance && ko . isWriteableObservable ( allBindings . froalaInstance ) ) { editorInstance = allBindings . froalaInstance ( ) ; }", "del_tokens": "function update ( element , value ) {", "commit_type": "fix"}
{"commit_tokens": ["Adds", "dbid", "property", "mapping", "for", "tag", "manager", "object", "."], "add_tokens": "const roMgrProps = [ \"mac\" , \"radioId\" , \"rev\" , \"wirelessConfig\" , \"online\" , \"selected\" , \"dbid\" ] ;", "del_tokens": "const roMgrProps = [ \"mac\" , \"radioId\" , \"rev\" , \"wirelessConfig\" , \"online\" , \"selected\" ] ;", "commit_type": "add"}
{"commit_tokens": ["add", "datetime", "parser", "in", "toDateTimeLiteral", "function", "in", "order", "to", "specify", "string", "formatted", "datetime"], "add_tokens": "table : \"Opportunity\" , { CloseDate : { $lte : SfDate . TOMORROW } } , { CloseDate : { $gt : SfDate . toDateLiteral ( new Date ( 1288958400000 ) ) } } , { CreatedDate : { $lt : SfDate . toDateTimeLiteral ( '2010-11-02T04:45:04+09:00' ) } } \"SELECT Id FROM Opportunity \" + \"WHERE CloseDate >= LAST_N_DAYS:10 AND CloseDate <= TOMORROW \" + \"AND CloseDate > 2010-11-05 AND CreatedDate < 2010-11-01T19:45:04Z\"", "del_tokens": "table : \"Account\" , { CloseDate : { $lte : SfDate . TOMORROW } } \"SELECT Id FROM Account \" + \"WHERE CloseDate >= LAST_N_DAYS:10 AND CloseDate <= TOMORROW\"", "commit_type": "add"}
{"commit_tokens": ["adding", "simpe", "html", "chat", "code"], "add_tokens": "socket . emit ( 'newMessage' , generateMessage ( 'admin' , 'welcome to chating' ) ) ;", "del_tokens": "socket . emit ( 'newMessage' , generateMessage ( 'admin' , 'welcome to chating' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "maskFile", "option", "allow", "mask", "to", "be", "a", "string", "an", "object", "or", "an", "array", "of", "strings", "and", "objects"], "add_tokens": "mask : \"test/fixtures/mask.json\" mask : \"test/fixtures/mask1.yml\" mask : \"test/fixtures/mask2.yml\" mask : [ \"test/fixtures/mask1.yml\" , \"a nonexisting file to test the error handling\" ] , mask : \"test/fixtures/mask3.yml\" , mask : [ \"test/fixtures/mask1.yml\" , { height : false , amount : true , car : { green : false , blue : true } } , \"a nonexisting file to test the error handling\" ]", "del_tokens": "maskFile : \"test/fixtures/mask.json\" maskFile : \"test/fixtures/mask1.yml\" maskFile : \"test/fixtures/mask2.yml\" maskFile : \"test/fixtures/mask1.yml\" , maskFile : \"test/fixtures/mask3.yml\" , maskFile : \"test/fixtures/mask1.yml\" , mask : { height : false , amount : true , car : { green : false , blue : true } }", "commit_type": "remove"}
{"commit_tokens": ["Added", "chalk", "for", "pretty", "printing"], "add_tokens": "define ( \"kindred-api\" , [ \"module\" , 'request' , 'chalk' ] , factory ) ; factory ( module , require ( 'request' ) , require ( 'chalk' ) ) ; factory ( mod , global . request , global . chalk ) ; } ) ( this , function ( module , request , chalk ) { if ( ! cb ) return console . log ( chalk . red ( \"error: No callback passed in for the method call regarding `\" + chalk . yellow ( reqUrl ) + \"`\" ) ) ; if ( cb ) return cb ( error , body ) ;", "del_tokens": "define ( \"kindred-api\" , [ \"module\" , 'request' ] , factory ) ; factory ( module , require ( 'request' ) ) ; factory ( mod , global . request ) ; } ) ( this , function ( module , request ) { console . log ( reqUrl ) ; if ( cb ) return cb ( error , body ) ; else console . log ( 'ERROR: No callback passed in!' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "incorrect", "OOXML", "types"], "add_tokens": "var slurpModeRegExp = / ^(?:[1-4]\\. |\\s{0,3})[a-z]{4,}(?: [a-z]{4,})+(?:s|\\(s\\))?\\s*:\\s* / i", "del_tokens": "var slurpModeRegExp = / ^[a-z]{4,} [a-z]{4,}(?:s|\\(s\\))?\\s*:\\s* / i", "commit_type": "fix"}
{"commit_tokens": ["fixed", "font", "for", "link_to_diff", "objects"], "add_tokens": "object_value = JSON . stringify ( eval_object , null , 4 ) ;", "del_tokens": "object_value = JSON . stringify ( eval_object , null , 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "CDN", "for", "angular", ".", "min", ".", "js", "and", "angular", "-", "mock", ".", "js"], "add_tokens": "\"https://ajax.googleapis.com/ajax/libs/angularjs/1.4.3/angular.min.js\" , \"https://ajax.googleapis.com/ajax/libs/angularjs/1.4.3/angular-mocks.js\" ,", "del_tokens": "\"http://code.angularjs.org/1.4.3/angular.js\" , \"http://code.angularjs.org/1.4.3/angular-mocks.js\" ,", "commit_type": "use"}
{"commit_tokens": ["Updated", "packages", "and", "unit", "tests"], "add_tokens": "/* eslint-disable no-unused-expressions */ redis ( 'Testing' , { uri : '' , port : 0 } ) . then ( client => { it ( 'should return a client on a connectClient call' , function ( ) { expect ( connectedClient . constructor . name ) . to . be . equal ( 'RedisClient' ) } ) it ( 'should return a promise on a connectClient call' , function ( ) { let client = redis . getClient ( 'default' ) client . connected = false let connectedClient = redis . connectClient ( 'default' )", "del_tokens": "// mockLogger.error = mockLogger.debug = mockLogger.info = mockLogger.warn = console.log redis ( 'Testing' , { uri : '' , port : 0 } ) . then ( client => { it ( 'should returns a promise on a connectClient call' , function ( ) {", "commit_type": "update"}
{"commit_tokens": ["Allow", "join", "to", "join", "at", "end", "of", "stream", "."], "add_tokens": "var interrupt = require ( 'interrupt' ) . createInterrupter ( 'procession' ) } else if ( value == null ) { throw interrupt ( 'endOfStream' )", "del_tokens": "var interrupt = require ( 'interrupt' ) . createInterrupter ( 'conduit' ) if ( value == null ) { throw interrupt ( 'endOfStream' ) }", "commit_type": "allow"}
{"commit_tokens": ["Fix", "regex", "for", "whitespace", "removal"], "add_tokens": "return sql . replace ( / \\s+ / g , \" \" ) ;", "del_tokens": "return sql . replace ( / \\W+ / g , \" \" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "order", "of", "test", "declarations"], "add_tokens": "methods : \"test/methods.js\" , enmasse : \"test/enmasse.js\"", "del_tokens": "enmasse : \"test/enmasse.js\" , methods : \"test/methods.js\"", "commit_type": "change"}
{"commit_tokens": ["Fix", "another", "issue", "parsing", "events"], "add_tokens": "else r += '<span class=\"eventListenerClose\">, </span><span class=\"eventFunctionOpen\">function(</span>'", "del_tokens": "else r += ', <span class=\"eventFunctionOpen\">function(</span>'", "commit_type": "fix"}
{"commit_tokens": ["fixed", "color", "rendering", "of", "colorizer", "reformatted", "test", "output"], "add_tokens": "echo : function ( text , style ) { console . log ( style ? this . colorizer . colorize ( text , style ) : text ) ; 'WARNING' : { fg : 'red' , bold : true } , if ( style . bg && background [ style . bg ] ) { codes . push ( background [ style . bg ] ) ;", "del_tokens": "echo : function ( text ) { console . log ( text ) ; if ( style . bg && foreground [ style . bg ] ) { codes . push ( foreground [ style . bg ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "custom", "style", "for", "audio", "playerq"], "add_tokens": "var playerStyle = \"position: relative; bottom: 20px; left: 10%; width: 80%;\" ; // style used for audio controls var hoverStyle = \"width: 50%; height:75px; position: fixed; left: 25%; bottom: 4px;z-index: 33;\" ; // style used for hover around audio controls if ( config . playerStyle ) playerStyle = config . playerStyle ; if ( config . hoverStyle ) hoverStyle = config . hoverStyle ; divElement . setAttribute ( 'style' , hoverStyle ) ; audioElement . setAttribute ( 'style' , playerStyle ) ;", "del_tokens": "var style = \"width: 50%; height:75px; position: fixed; left: 25%; bottom: 4px;z-index: 33;\" ; // style used for audio controls if ( config . style ) style = config . style ; divElement . setAttribute ( 'style' , style ) ; audioElement . setAttribute ( 'style' , \"position: relative; top: 20px; left: 10%; width: 80%;\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "maxAge", "==", "0"], "add_tokens": "if ( null != opt . maxAge ) { var maxAge = opt . maxAge - 0 ; if ( isNaN ( maxAge ) ) throw new Error ( 'maxAge should be convertable to Number' ) ; pairs . push ( 'Max-Age=' + maxAge ) ; }", "del_tokens": "if ( opt . maxAge ) pairs . push ( 'Max-Age=' + opt . maxAge ) ;", "commit_type": "fix"}
{"commit_tokens": ["create", "db", "only", "after", "chdir"], "add_tokens": "cozyLight . db = new Pouchdb ( 'cozy' ) ;", "del_tokens": "cozyLight . db = new Pouchdb ( 'cozy' ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "passwordless", "test", ".", "Upgrade", "all", "versions", ".", "Add", "yarn", ".", "lock"], "add_tokens": "* check the documentation for details : * the documentation . PostgreStore understands the following options : * valid in terms of time - to - live . If yes , the method provides the * the stored referrer URL if any . * referrer will be null . If the token / uid combination was not found * found , valid will be false and all else null . Otherwise , valid will * be true , referrer will ( if provided when the token was stored ) the } else if ( ! result . rows [ 0 ] . origin ) { callback ( null , true , '' ) ; module . exports = PostgreStore ;", "del_tokens": "* check the documentation for details : * the documentation . PostgreStore understands the following options : * valid in terms of time - to - live . If yes , the method provides the * the stored referrer URL if any . * referrer will be null . If the token / uid combination was not found * found , valid will be false and all else null . Otherwise , valid will * be true , referrer will ( if provided when the token was stored ) the module . exports = PostgreStore ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "test", "after", "moving", "it"], "add_tokens": "var pongular = require ( '../../lib/pongular' ) . pongular ;", "del_tokens": "var pongular = require ( '../lib/pongular' ) . pongular ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "be", "ecmascript", "module"], "add_tokens": "import { _replaceAdjacentItems } from '@writetome51/array-replace-adjacent-items' ; export function replaceAdjacentAt ( index , newValues , array ) { _replaceAdjacentItems ( index , newValues . length , newValues , array ) ;", "del_tokens": "\"use strict\" ; Object . defineProperty ( exports , \"__esModule\" , { value : true } ) ; var error_if_not_array_1 = require ( \"error-if-not-array\" ) ; var array_replace_adjacent_items_1 = require ( \"@writetome51/array-replace-adjacent-items\" ) ; // The number of adjacent items that get replaced equals `newValues.length`. function replaceAdjacentAt ( index , newValues , array ) { error_if_not_array_1 . errorIfNotArray ( newValues ) ; // The other parameters, index and array, are type-checked here: array_replace_adjacent_items_1 . _replaceAdjacentItems ( index , newValues . length , newValues , array ) ; exports . replaceAdjacentAt = replaceAdjacentAt ;", "commit_type": "update"}
{"commit_tokens": ["Changed", "paths", "of", "payment", "providers", "and", "updated", "readme"], "add_tokens": "const paypal = require ( './routes/payments/paypal' ) ; const stripe = require ( './routes/payments/stripe' ) ;", "del_tokens": "const paypal = require ( './routes/paypal' ) ; const stripe = require ( './routes/stripe' ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "Makefile", "that", "aggregates", "and", "minifies", "Playem", "and", "its", "players", "=", ">", "playem", "-", "min", ".", "js", "passes", "the", "Youtube", "tests"], "add_tokens": "function initPlayer ( ) { playem . addPlayer ( window [ pl + \"Player\" ] , defaultPlayerParams ) ; // instanciates player class console . log ( \"Init \" + pl + \" player...\" ) ; if ( window [ pl + \"Player\" ] ) // check that class exists initPlayer ( ) ; else loader . includeJS ( \"../playem-\" + pl . toLowerCase ( ) + \".js\" , initPlayer ) ;", "del_tokens": "if ( window [ pl + \"Player\" ] ) // check that class exists else { console . log ( \"Loading \" + pl + \" player...\" ) ; loader . includeJS ( \"../playem-\" + pl . toLowerCase ( ) + \".js\" , function ( ) { playem . addPlayer ( window [ pl + \"Player\" ] , defaultPlayerParams ) ; // instanciates player class next ( ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "API", "to", "work", "for", "multiple", "CSS", "engines"], "add_tokens": "// Localize CSS router and options var cssRouter = data . cssRouter , cssOptions = data . cssOptions || { } ; // If there is no CSS router if ( ! cssRouter ) { // Create a url router object cssRouter = { } ; // For each css format, generate a router destCssFormats . forEach ( function ( cssFormat ) { var cssPath = destCss [ cssFormat ] ; cssRouter [ cssFormat ] = url . relative . bind ( url , cssPath ) ; } ) ; } router = cssRouter [ cssFormat ] || cssRouter ; options : cssOptions [ cssFormat ] || { }", "del_tokens": "router = data . router || url . relative . bind ( url , cssPath ) ; options : data . cssOptions || { }", "commit_type": "update"}
{"commit_tokens": ["Adds", "Materialized", "Boxed", "and", "Errors", "as", "values", "tests", "."], "add_tokens": "[ \"lists\" , \"to-expired-list\" , \"0\" , \"summary\" ]", "del_tokens": "[ \"lists\" , \"expired-list\" , \"0\" , \"summary\" ]", "commit_type": "add"}
{"commit_tokens": ["improved", "input", "handling", "fewer", "key", "sticking", "issues"], "add_tokens": "if ( typeof window . performance === \"object\" ) { if ( window . performance . now ) { module . exports = function ( ) { return window . performance . now ( ) } } else if ( window . performance . webktiNow ) { module . exports = function ( ) { return window . performance . webkitNow ( ) } }", "del_tokens": "if ( window . performance . now ) { module . exports = function ( ) { return window . performance . now ( ) } } else if ( window . performance . webktiNow ) { module . exports = function ( ) { return window . performance . webkitNow ( ) }", "commit_type": "improve"}
{"commit_tokens": ["Fix", "test", "errors", "due", "to", "order", "of", "promises"], "add_tokens": "module . exports . type . delete . doc . parameters = module . exports . type . read . doc . parameters ;", "del_tokens": "module . exports . delete . doc . arguments = module . exports . read . doc . arguments ;", "commit_type": "fix"}
{"commit_tokens": ["add", "feature", "fix", "bugs", "optimize"], "add_tokens": "let pointer if ( evt . touches && evt . touches [ 0 ] ) { pointer = evt . touches [ 0 ] } else if ( evt . changedTouches && evt . changedTouches [ 0 ] ) { pointer = evt . changedTouches [ 0 ] } else { pointer = evt }", "del_tokens": "let pointer = evt . touches ? evt . touches [ 0 ] : evt touchDetect ( ) { window . addEventListener ( 'touchstart' , function onFirstTouch ( ) { window . USER_IS_TOUCHING = true window . removeEventListener ( 'touchstart' , onFirstTouch , false ) } , false ) } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "first", "(", "dirty", ")", "draft", "of", "filter", "support", "."], "add_tokens": "filters : { } , parsePattern : / \\{\\{\\s*([\\.\\-\\w]*(\\s\\|\\s*[\\-\\w]+)?)\\s*\\}\\} / g return template . replace ( options . parsePattern , function ( match , inner ) { var parts = inner . split ( '|' ) ; var key = mout . string . trim ( parts . shift ( ) ) ; var filterName = mout . string . trim ( parts . shift ( ) ) ; var res = resolveName ( key , content ) ; if ( ! mout . lang . isEmpty ( filterName ) ) { if ( mout . object . has ( options . filters , filterName ) ) { res = options . filters [ filterName ] ( res ) ; } else { grunt . log . error ( 'Unknown filter:' + filterName ) ; } } return res ;", "del_tokens": "parsePattern : / \\{\\{\\s*([\\.\\-\\w]*)\\s*\\}\\} / g return template . replace ( options . parsePattern , function ( match , key ) { return resolveName ( key , content ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "test", "for", "a", "plain", "HTML", "element", "(", "span", ")"], "add_tokens": "'span' : id , var testHead = \"<doctype html><head><title>hello</title></head>\\n\" ; var testFooter = \"<body></body>\" ; var customElement = \"<test-element foo='bar' baz=\\\"booz\\\">\" + \"<foo-bar></foo-bar><span>hello</span></test-element>\" ; var testDoc = testHead + customElement + testFooter ; assert . equal ( n0 . innerHTML , innerHTML ( customElement ) ) ; assert . equal ( n0 . outerHTML , customElement ) ; } , \"span\" : function ( ) { var testElement = '<span>foo</span>' ; var doc = testHead + '<div>' + testElement + '</div>' + testFooter ; var nodes = matcher . matchAll ( doc ) ; var n0 = nodes [ 0 ] ; assert . equal ( n0 . innerHTML , innerHTML ( testElement ) ) ; assert . equal ( n0 . outerHTML , testElement ) ; assert . deepEqual ( n0 . attributes , { } ) ;", "del_tokens": "var testElement = \"<test-element foo='bar' baz=\\\"booz\\\"><foo-bar></foo-bar><span>hello</span></test-element>\" ; var testDoc = \"<doctype html><head><title>hello</title></head>\\n\" + testElement + \"<body></body>\" ; assert . equal ( n0 . innerHTML , innerHTML ( testElement ) ) ; assert . equal ( n0 . outerHTML , testElement ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "logs", "for", "debugging", "purposes"], "add_tokens": "if ( error ) { console . log ( 'ERROR: code: ' + code + ', msg: ' + errorFile [ code ] + ', stack: ' + error ) ; //for debugging purposes source : 'driver' , value : error , code : code , msg : errorFile [ code ] } else { }", "del_tokens": "if ( error ) \"error\" : error , \"code\" : code , \"msg\" : errorFile [ code ] else", "commit_type": "add"}
{"commit_tokens": ["removes", "hashbang", "and", "redirects", "and", "instead", "simply", "serves", "index", ".", "html", "upon", "page", "reload", "in", "html5", "push", "state", "and", "angular", "will", "handle", "the", "rest"], "add_tokens": "path = require ( 'path' ) , / ** * Get file path relative to app root * @ param pPath * / function getFilePathRelativeToAppRoot ( pPath ) { // go to meow-blog directory var projectBaseDirectory = path . resolve ( __dirname , '..' ) ; if ( projectBaseDirectory . indexOf ( 'node_modules' ) !== - 1 ) { // from meow-blog, go up to node_modules, then go to base directory projectBaseDirectory = path . resolve ( projectBaseDirectory , '..' , '..' ) ; } return path . resolve ( projectBaseDirectory , pPath ) ; } setPropertyVal : setPropertyVal , getFilePathRelativeToAppRoot : getFilePathRelativeToAppRoot", "del_tokens": "setPropertyVal : setPropertyVal", "commit_type": "remove"}
{"commit_tokens": ["use", "TypeError", "instead", "of", "plain", "Error"], "add_tokens": "done ( new TypeError ( 'Collection \"' + name + '\" does not exist' ) ) done ( new TypeError ( 'Specify a template or layout for \"' + name + '\" pages' ) ) done ( new TypeError ( 'You should not specify template and layout for \"' + done ( new TypeError ( 'Specify a path for \"' + name + '\" pages' ) )", "del_tokens": "done ( new Error ( 'Collection \"' + name + '\" does not exist' ) ) done ( new Error ( 'Specify a template or layout for \"' + name + '\" pages' ) ) done ( new Error ( 'You should not specify template and layout for \"' + done ( new Error ( 'Specify a path for \"' + name + '\" pages' ) )", "commit_type": "use"}
{"commit_tokens": ["Implement", "--", "invoke", "for", "running", "exact", "tasks", "."], "add_tokens": "tasksToInvoke , tasksToInvoke = grunt . option ( 'invoke' ) ; if ( tasksToInvoke ) { tasksToInvoke = tasksToInvoke . split ( ',' ) ; } if ( tasksToInvoke ) { deploy . invokeTasks ( tasksToInvoke , done ) ; } else if ( args . indexOf ( 'setup' ) !== - 1 ) {", "del_tokens": "if ( args . indexOf ( 'setup' ) !== - 1 ) {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "path", "resolution", "of", "recommended", "Wist", "configuration"], "add_tokens": "? ConfigOps . merge ( { } , ConfigFile . load ( options . baseConfig , this ) )", "del_tokens": "? ConfigOps . merge ( { } , ConfigFile . loadObject ( options . baseConfig , this ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "server", "-", "side", "message", "to", "include", "the", "shell", "namespace", "when", "displaying", "that", "a", "command", "was", "received", "."], "add_tokens": "console . log ( '%s: %s' , shell . namespace , cmdStr ) ;", "del_tokens": "console . log ( 'Received: ' + cmdStr ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "support", "for", "single", "or", "multi", "to", "input"], "add_tokens": "var SingleEvent = require ( \"geval/single\" ) var MultipleEvent = require ( \"geval/multiple\" ) input : input , function input ( names ) { if ( ! names ) { return SingleEvent ( ) } return MultipleEvent ( names ) }", "del_tokens": "input : require ( \"geval/multiple\" ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "a", "few", "more", "tests"], "add_tokens": "var num = this . baseRead ( ) , v = + num ; // Test for wraparound & roundoff if ( v < 0 || 1 + v == v ) { throw new RangeError ( ` ${ num } ` ) ;", "del_tokens": "var num = this . baseRead ( ) ; if ( num != + num ) { throw ` ${ num } ` ;", "commit_type": "add"}
{"commit_tokens": ["Change", "formatting", "of", "the", "module", "string", "for", "better", "readability", "."], "add_tokens": "var module = \"angular.module('\" + options . module + \"')\" + \".run(['gettextCatalog', function (gettextCatalog) {\\n\" + \"/* jshint -W100 */\\n\" + locales . join ( '' ) + \"/* jshint +W100 */\\n\" + \"}]);\" ;", "del_tokens": "var module = \"angular.module('\" + options . module + \"').run(['gettextCatalog', function (gettextCatalog) {\\n/* jshint -W100 */\\n\" + locales . join ( '' ) + \"/* jshint +W100 */\\n}]);\" ;", "commit_type": "change"}
{"commit_tokens": ["Added", "overwriteIfExists", "to", "Entity", ".", "create"], "add_tokens": "'insertOrReplaceEntity' , Entity . create = function ( properties , overwriteIfExists ) { // Use insertOrReplaceEntity if we should overwrite on existence var createMethod = ClassProps . __aux . insertEntity ; if ( overwriteIfExists ) { createMethod = ClassProps . __aux . insertOrReplaceEntity ; } // Create entity return createMethod ( entity )", "del_tokens": "Entity . create = function ( properties ) { return ClassProps . __aux . insertEntity ( entity )", "commit_type": "add"}
{"commit_tokens": ["removed", "weird", "byte", "checking", "now", "it", "s", "obsolete"], "add_tokens": "if ( keyFileStr . match ( / ^[a-f\\d]{64}$ / i ) ) {", "del_tokens": "if ( keyFileStr . match ( / ^[a-z\\d]{64}$ / i ) ) {", "commit_type": "remove"}
{"commit_tokens": ["adding", "changes", "to", "allow", "index", ".", "js", "to", "accept", "an", "array", "of", "addon", "module", "functions", "allowing", "it", "to", "play", "nicely", "with", "webpack", "environments"], "add_tokens": "var additive = addons [ addon ] ; if ( additive instanceof Function ) { additive ( THREE ) ; } else if ( typeof additive === \"string\" ) { require ( \"./addons/\" + additive + \".js\" ) ( THREE ) ; } else { throw new Error ( \"Invalid module type provided\" ) ; } } ) ( this || } ) ;", "del_tokens": "require ( \"./addons/\" + addons [ addon ] + \".js\" ) ( THREE ) ; } ) ( this || } ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "dev", "dependencies", "and", ".", "travis", ".", "yml"], "add_tokens": "* @ version 0.24 .0 - alpha .2 lamb . _version = \"0.24.0-alpha.2\" ;", "del_tokens": "* @ version 0.24 .0 - alpha .1 lamb . _version = \"0.24.0-alpha.1\" ;", "commit_type": "update"}
{"commit_tokens": ["remove", "drawing", "shadow", "one", "out", "of", "2", "frames"], "add_tokens": "var SHADOW_OPACITY = 0.03 ; ctx . globalAlpha = SHADOW_OPACITY ; for ( var i = 0 ; i < pointsX . length ; i ++ ) { if ( drawShadowAtPoint [ i ] ) { ctx . drawImage ( shadow , pointsX [ i ] - DELTA_SHADOW_X * pixelRatio , pointsY [ i ] - DELTA_SHADOW_Y * pixelRatio , SIZE_SHADOW * pixelRatio , SIZE_SHADOW * pixelRatio ) ; ctx . globalAlpha = 1.0 ;", "del_tokens": "var SHADOW_OPACITY = 0.04 ; /** Shoud shadows be drawn at next render (alternates every frame) */ var drawShadow = true ; if ( drawShadow ) { ctx . globalAlpha = SHADOW_OPACITY ; for ( var i = 0 ; i < pointsX . length ; i ++ ) { if ( drawShadowAtPoint [ i ] ) { ctx . drawImage ( shadow , pointsX [ i ] - DELTA_SHADOW_X * pixelRatio , pointsY [ i ] - DELTA_SHADOW_Y * pixelRatio , SIZE_SHADOW * pixelRatio , SIZE_SHADOW * pixelRatio ) ; } ctx . globalAlpha = 1.0 ; drawShadow = ! drawShadow ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "the", "build", "script", "and", "build", "the", "package", "from", "the", "scr", "folder"], "add_tokens": "'vue-native' : path . resolve ( __dirname , '../src/platforms/react-vue' ) ,", "del_tokens": "'react-vue' : path . resolve ( __dirname , '../src/platforms/react-vue' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "debug", "option", "to", "display", "logs", "."], "add_tokens": "exports . debug = false ; if ( exports . debug ) console . log ( '%s: %s' , shell . namespace , cmdStr ) ;", "del_tokens": "console . log ( '%s: %s' , shell . namespace , cmdStr ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "checkpoint", "-", "controls", "and", "checkpoint", "components", "."], "add_tokens": "this . el . setAttribute ( 'velocity' , control . getVelocity ( ) ) ; return ;", "del_tokens": "throw new Error ( 'getVelocity() not currently supported, use getVelocityDelta()' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "it", "so", "perPage", ">", "=", "total", "makes", "numPages", "=", "1"], "add_tokens": "if ( response ) { if ( length ( response ) < response . total ) { $scope . paginated = true ; if ( ( request . to < response . total - 1 && response . total < Infinity ) || ( response . to < response . total - 1 && response . total < request . to ) ) { if ( ! $scope . perPage || length ( response ) < $scope . perPage ) { $scope . perPage = $scope . Math . min ( length ( response ) , $scope . clientLimit ) ; $scope . serverLimit = length ( response ) ; }", "del_tokens": "if ( response && length ( response ) < response . total ) { $scope . paginated = true ; if ( ( request . to < response . total - 1 && response . total < Infinity ) || ( response . to < response . total - 1 && response . total < request . to ) ) { if ( ! $scope . perPage || length ( response ) < $scope . perPage ) { $scope . perPage = $scope . Math . min ( length ( response ) , $scope . clientLimit ) ; $scope . serverLimit = length ( response ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "duplicate", "jquery", "and", "jquery", "-", "ui"], "add_tokens": "var deps = mainBowerFiles ( ) . filter ( function ( it ) { return ! it . match ( / \\/bower_components\\/(jquery|jquery-ui)\\/ / ) ; } ) ;", "del_tokens": "var deps = mainBowerFiles ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "the", "tests", "happy", "again", "(", "56", "passing", ")"], "add_tokens": "* @ returns { Email } the parsed email if ( typeof ( text ) !== \"string\" ) return new Email ( [ ] ) ; text = text . replace ( matches [ 1 ] , matches [ 1 ] . replace ( / \\n / g , ' ' ) ) ; if ( fragment . isQuoted === isQuoted ) return true ; return this . _isQuoteHeader ( line ) || line . length === 0 ; return this . _signatureRegex . test ( esrever . reverse ( text ) ) ; return _ . filter ( this . _quoteHeadersRegex , exp => exp . test ( esrever . reverse ( text ) ) ) . length > 0 ;", "del_tokens": "* @ returns { Email } the parsed email , or null if not parseable if ( typeof ( text ) !== \"string\" ) return null ; text = text . replace ( matches [ 1 ] , matches [ 1 ] . replace ( '\\n' , ' ' ) ) ; if ( fragment . isQuoted === isQuoted ) return true ; return this . _isQuoteHeader ( line ) && fragment . lines . length === 0 ; return this . _signatureRegex . test ( text ) ; return _ . filter ( this . _quoteHeadersRegex , exp => exp . test ( text ) ) . length > 0 ;", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "ability", "for", "types", "and", "instanceOf", "to", "have", "multiple", "values", "separated", "by", "|"], "add_tokens": "docket . title ( ` ` ) ;", "del_tokens": "docket . title ( ` ` ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "polyserve", "support", "unbuilt", "and", "built", "versions", "of", "docs", "now", "both", "work", "."], "add_tokens": "import ( '../../@polymer/iron-component-page/iron-component-page.js' ) ;", "del_tokens": "import ( './dependencies/@polymer/iron-component-page/iron-component-page.js' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "popup", "for", "showing", "pin", "info"], "add_tokens": "{ kind : \"Infobox\" } , var p = this . $ . map . createPushpin ( loc . latitude , loc . longitude , { icon : \"images/poi_search.png\" , height : 48 , width : 48 } ) ; Microsoft . Maps . Events . addHandler ( p , 'click' , enyo . bind ( this , \"openInfobox\" , inItem ) ) ; } , openInfobox : function ( inItem , e ) { var loc = e . target . getLocation ( ) ; var pix = this . $ . map . hasMap ( ) . tryLocationToPixel ( loc , Microsoft . Maps . PixelReference . control ) ; this . $ . infobox . setTitle ( inItem . title ) ; this . $ . infobox . setDetails ( inItem . details ) ; this . $ . infobox . openAt ( pix . y , pix . x + 18 ) ;", "del_tokens": "this . $ . map . createPushpin ( loc . latitude , loc . longitude , { icon : \"images/poi_search.png\" , height : 48 , width : 48 } ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "unneeded", "dependency", "on", "deprecated", "sys", "module"], "add_tokens": "util = require ( 'util' ) ,", "del_tokens": "sys = require ( 'sys' ) ,", "commit_type": "remove"}
{"commit_tokens": ["Use", "rdf", "option", "to", "remove", "dir", "over", "ssh"], "add_tokens": "child = exec ( \"rm -rdf \" + path , {", "del_tokens": "child = exec ( \"rm -rf \" + path , {", "commit_type": "use"}
{"commit_tokens": ["Allow", "website", "updater", "to", "be", "ran", "from", "any", "dir"], "add_tokens": "var fs = require ( 'fs' ) var path = require ( 'path' ) var webRoot = __dirname ; var uppyRoot = path . dirname ( __dirname ) ; var configPath = webRoot + '/_config.yml' var config = fs . readFileSync ( configPath , 'utf-8' ) var version = require ( uppyRoot + '/package.json' ) . version var sizes = { } ; min : uppyRoot + '/dist/uppy.js' , gz : uppyRoot + '/dist/uppy.js' , dev : uppyRoot + '/dist/uppy.js' webRoot + '/themes/uppy/source/js/uppy.js' ,", "del_tokens": "var fs = require ( 'fs' ) var version = require ( '../package.json' ) . version var configPath = '_config.yml' var config = fs . readFileSync ( configPath , 'utf-8' ) var sizes = { } ; min : '../dist/uppy.js' , gz : '../dist/uppy.js' , dev : '../dist/uppy.js' './themes/uppy/source/js/uppy.js' ,", "commit_type": "allow"}
{"commit_tokens": ["Fix", "siteProps", "in", "dev", "HTML", "template"], "add_tokens": "const siteProps = await config . getSiteProps ( { dev : true } ) < HtmlTemplate staticMeta = { { } } Html = { Html } Head = { Head } Body = { Body } siteProps = { siteProps } >", "del_tokens": "< HtmlTemplate staticMeta = { { } } Html = { Html } Head = { Head } Body = { Body } >", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "eudex", "hash", "using", "long"], "add_tokens": "import Long from 'long' ; firstByte = INJECTIVE_PHONES_C1 [ entry - 0xDF ] ; firstByte = new Long ( firstByte ) ; let res = Long . UZERO , n = 0 , while ( n < 8 && b < array . length ) { let x ; if ( ! res . and ( 0xFE ) . equals ( x & 0xFE ) ) { res = res . shiftLeft ( 8 ) ; res = res . or ( x ) ; n ++ ; return res . or ( firstByte . shiftLeft ( 56 ) ) ;", "del_tokens": "firstByte = INJECTIVE_PHONES_C1 [ ( entry - 0xDF ) ] ; let res = 0 , n = 1 , while ( n !== 0 && b < array . length ) { let x = 0 ; if ( ( res & 0xFE ) !== ( x & 0xFE ) ) { res <<= 8 ; res |= x ; n <<= 1 ; return res | ( firstByte << 56 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "lint", "issues", "and", "added", "node", "version", "tests", "to", "travis"], "add_tokens": "const lfs = new Lfs ( { 'basePath' : __dirname + '/test_environment/1' , 'cacheMaxSize' : 1 } ) ;", "del_tokens": "const lfs = new Lfs ( { 'basePath' : __dirname + '/test_environment/1' , 'cacheMaxSize' : 1 } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "tests", "back", "to", "test", "/"], "add_tokens": "const baseSuite = require ( '@raincatcher/example-base/test' ) . default ;", "del_tokens": "const baseSuite = require ( '@raincatcher/example-base/out/test' ) . default ;", "commit_type": "move"}
{"commit_tokens": ["allow", "current", "directory", "to", "be", "chosen", "as", "serve", "-", "dir"], "add_tokens": "const serveDir = program . serveDir ? program . serveDir === '/' ? '' : ` ${ program . serveDir } ` : '' ;", "del_tokens": "const serveDir = program . serveDir ? ` ${ program . serveDir } ` : '' ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "sync", "file", "reading", "."], "add_tokens": "function readChunckAsync ( fd , buffer , start , size ) { function readChunckSync ( fd , buffer , start , size ) { try { return fsbinding . read ( fd , buffer , 0 , size , start ) } catch ( error ) { return error } } var readChunck = options && options . sync ? readChunckSync : readChunckAsync module . exports = reader", "del_tokens": "function readChunck ( fd , buffer , start , size ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "logging", "inside", "the", "tests", "."], "add_tokens": "util . puts ( 'stats: ' + JSON . stringify ( stats ) ) ; var data = JSON . stringify ( state ) ; util . puts ( 'Returning response: ' + data ) ; response . end ( data ) ;", "del_tokens": "util . puts ( 'stats: ' + stats ) ; response . end ( JSON . stringify ( state ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "reserved", "words", "char", "and", "interface"], "add_tokens": "current = { interf : root , path : '' } chr = keypath . charAt ( index ) if ( ! ! ~ interfaces . indexOf ( chr ) ) { current = { interf : chr , path : '' } current . path += chr Object . keys ( sightglass . adapters ) . forEach ( function ( interf ) { if ( ! ~ interfaces . indexOf ( interf ) ) { interfaces . push ( interf ) return this . options . adapters [ key . interf ] || sightglass . adapters [ key . interf ]", "del_tokens": "current = { interface : root , path : '' } char = keypath . charAt ( index ) if ( ! ! ~ interfaces . indexOf ( char ) ) { current = { interface : char , path : '' } current . path += char Object . keys ( sightglass . adapters ) . forEach ( function ( interface ) { if ( ! ~ interfaces . indexOf ( interface ) ) { interfaces . push ( interface ) return this . options . adapters [ key . interface ] || sightglass . adapters [ key . interface ]", "commit_type": "remove"}
{"commit_tokens": ["Fix", "error", "when", "multiplying", "/", "dividing", "unlike", "quantities"], "add_tokens": "it 'should multiply unlike quantities' qty1 = new Qty ( \"2.5 m\" ) qty2 = new Qty ( \"3 N\" ) result = qty1 . mul ( qty2 ) result . scalar . should . be 7.5 qty1 = new Qty ( \"2.5 m^2\" ) qty2 = new Qty ( \"3 kg/m^2\" ) result = qty1 . mul ( qty2 ) result . scalar . should . be 7.5 result . units ( ) . should . be \"kg\" end it 'should divide unlike quantities' qty1 = new Qty ( \"7.5kg\" ) qty2 = new Qty ( \"2.5m^2\" ) result = qty1 . div ( qty2 ) result . scalar . should . be 3 result . units ( ) . should . be \"kg/m^2\" end", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Add", "deps", "to", "libs", "for", "proper", "gh", "-", "paging"], "add_tokens": "} , jquery : { src : [ 'node_modules/jquery/dist/jquery.js' ] , dest : 'libs/jquery.js' } , qunitcss : { src : [ 'node_modules/qunitjs/qunit/qunit.css' ] , dest : 'libs/qunit.css' } , qunitjs : { src : [ 'node_modules/qunitjs/qunit/qunit.js' ] , dest : 'libs/qunit.js' grunt . registerTask ( 'default' , 'concat lint qunit min' ) ; grunt . registerTask ( 'travis' , 'concat lint qunit' ) ;", "del_tokens": "grunt . registerTask ( 'default' , 'lint qunit concat min' ) ; grunt . registerTask ( 'travis' , 'lint qunit' ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "setting", "retry", "and", "backoff", "via", "global", "setup"], "add_tokens": "retry : _gs . retry || 0 , retry_backoff : _gs . retry_backoff || 1000 ,", "del_tokens": "retry : 0 , retry_backoff : 1000 ,", "commit_type": "allow"}
{"commit_tokens": ["fix", "how", "getters", "are", "being", "serialized", "to", "JSON", "(", "check", "if", "the", "getter", "has", "a", "toJSON", "method", "and", "call", "that", "instead", ")"], "add_tokens": "val = self [ attr ] if ( val === undefined ) return ; if ( val && val . toJSON ) { obj [ attr ] = val . toJSON ( ) ; } else { obj [ attr ] = val ; }", "del_tokens": "if ( self [ attr ] ) { obj [ attr ] = self [ attr ] }", "commit_type": "fix"}
{"commit_tokens": ["make", "lots", "of", "gcd", "tests"], "add_tokens": "generateTests ( 'gcd' , 100 , function ( a , b ) {", "del_tokens": "generateTests ( 'gcd' , 20 , function ( a , b ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "the", "TeoriaInterval#octaves", "()", "method"], "add_tokens": "var without , octaves ; if ( this . direction ( ) === 'up' ) { without = sub ( this . coord , mul ( sharp , this . qualityValue ( ) ) ) ; octaves = without [ 0 ] - intervals [ this . base ( ) ] [ 0 ] ; } else { without = sub ( this . coord , mul ( sharp , - this . qualityValue ( ) ) ) ; octaves = - ( without [ 0 ] + intervals [ this . base ( ) ] [ 0 ] ) ; }", "del_tokens": "var without = sub ( this . coord , mul ( sharp , this . qualityValue ( ) ) ) ; var octaves = without [ 0 ] - intervals [ this . base ( ) ] [ 0 ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "to", "delete", "range", "fix", "non", "valid", "keys", "in", "delete", "operation"], "add_tokens": "// 'tests/get.js'", "del_tokens": "'tests/get.js'", "commit_type": "add"}
{"commit_tokens": ["fix", "https", ":", "//", "github", ".", "com", "/", "MathieuLoutre", "/", "grunt", "-", "aws", "-", "s3", "/", "issues", "/", "128"], "add_tokens": "return put_params . includes ( key ) ;", "del_tokens": "return _ . contains ( put_params , key ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "running", "on", "NodeJS"], "add_tokens": "const BODY = process . browser ? document . body : null ; if ( BODY != null ) { if ( nextProps . isOpen ) { BODY . style . overflow = 'hidden' ; } else { BODY . style . overflow = null ; }", "del_tokens": "const BODY = document . body ; if ( nextProps . isOpen ) { BODY . style . overflow = 'hidden' ; } else { BODY . style . overflow = null ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "synchronous", "spawn", "to", "run", "openssl", "for", "CLI", "subcommands"], "add_tokens": "var results = util . generatePrivateKeyAndCsr ( configDir , command . filePrefix , commonOrCsrFileName , verbosity ) var privateKeyFileName = results . privateKeyFileName var csrFileName = results . csrFileName requestProvisionConfig ( hostName , command . port , command . username , command . password , fs . readFileSync ( csrFileName ) , verbosity , function ( config ) { storeProvisionConfig ( config , configDir , command . filePrefix , privateKeyFileName , verbosity )", "del_tokens": "util . generatePrivateKeyAndCsr ( configDir , command . filePrefix , commonOrCsrFileName , verbosity , function ( privateKeyFileName , csrFileName ) { requestProvisionConfig ( hostName , command . port , command . username , command . password , fs . readFileSync ( csrFileName ) , verbosity , function ( config ) { storeProvisionConfig ( config , configDir , command . filePrefix , privateKeyFileName , verbosity ) } )", "commit_type": "use"}
{"commit_tokens": ["Added", "(", "mostly", "pointless", ")", "anonymous", "authentication", "strategy"], "add_tokens": "'strategies' , 'auth.strategies.anonymous'", "del_tokens": "'strategies'", "commit_type": "add"}
{"commit_tokens": ["Make", "work", "with", "eu", "-", "central", "-", "1", "region"], "add_tokens": "signedOpts . headers [ 'Connection' ] = 'keep-alive' ;", "del_tokens": "headers [ 'Connection' ] = 'Keep-Alive' ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "bug", "where", "font", "-", "variant", "-", "caps", ":", "small", "-", "caps", "resulted", "in", "c2sc", "feature"], "add_tokens": "\"small-caps\" : \"\\\"smcp\\\"\" ,", "del_tokens": "\"small-caps\" : \"\\\"c2sc\\\"\" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "failfast", "mode", "."], "add_tokens": "* @ param { Boolean } failfast True to exit after first failure . var executeTest = function ( filePath , failfast , verbosity , callback ) { if ( failfast && failedResult ) { common . printTestsSummary ( dateStart , successes , failures , timeouts ) ; }", "del_tokens": "* @ param { Boolean } failFast True to exit after first failure . var executeTest = function ( filePath , failFast , verbosity , callback ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "basic", "-", "autosize", "-", "textarea", "unit", "test", ":", "minimumRows", "can", "make", "element", "taller", "than", "required", "to", "fit", "content", ".", "Flush", "before", "setting", "minimumRows", "property", "."], "add_tokens": "container . appendChild ( fixture ) ; container . appendChild ( fixtureComp ) ; flush ( function ( ) { } ) ;", "del_tokens": "// BUGBUG - We have to wait for the element's attached callback to be invoked, since // we rely on _initializeWhenRendered to be called prior to our setting the minimumRows // property. Otherwise, the minimumRowsChanged handler does nothing and the tests fail. // Note that on Chrome, attached is called seemingly synchronously after ready, and we could set minimumRows // synchronously after calling container.appendChild. But this will fail on Firefox/Safari. fixture . attachedHook = function ( ) { } ; container . appendChild ( fixture ) ; container . appendChild ( fixtureComp ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "anonymous", "functions", "to", "use", "ES6", "syntax"], "add_tokens": "return headers . map ( ( header , index ) => { var headingAttributes , order , heading ; order = headingAttributes [ 'aria-sort' ] ; return data . map ( ( row ) => { var rowCells = columns . map ( ( column , index ) => {", "del_tokens": "return headers . map ( function ( header , index ) { var sortProps , order , heading ; order = sortProps [ 'aria-sort' ] ; return data . map ( function ( row ) { var rowCells = columns . map ( function ( column , index ) {", "commit_type": "change"}
{"commit_tokens": ["Move", "preventDocumentScrolling", "uber", "flag", "setting", "from", "App", "code", "to", "index", ".", "html"], "add_tokens": "{ name : \"menu\" , classes : \"menu\" , defaultKind : \"onyx.IconButton\" , components : [ { src : \"images/menu-icon-info.png\" , panel : \"info\" , ontap : \"togglePullout\" } , { src : \"images/menu-icon-bookmark.png\" , panel : \"bookmark\" , ontap : \"togglePullout\" } , { src : \"images/menu-icon-mylocation.png\" , ontap : \"findCurrentLocation\" } ] } ,", "del_tokens": "enyo . preventDocumentScrolling = true ; ] } , { name : \"menu\" , classes : \"menu\" , defaultKind : \"onyx.IconButton\" , components : [ { src : \"images/menu-icon-info.png\" , panel : \"info\" , ontap : \"togglePullout\" } , { src : \"images/menu-icon-bookmark.png\" , panel : \"bookmark\" , ontap : \"togglePullout\" } , { src : \"images/menu-icon-mylocation.png\" , ontap : \"findCurrentLocation\" }", "commit_type": "move"}
{"commit_tokens": ["add", "a", "fix", "in", "tests", "to", "avoid", "having", "two", "commits", "in", "same", "time", "(", "ms", ")"], "add_tokens": "const Promise = require ( 'bluebird' ) await jsreport . init ( ) // postpone the commit to avoid having two commits in same ms const old = jsreport . versionControl . commit . bind ( jsreport . versionControl ) jsreport . versionControl . commit = ( ... args ) => Promise . delay ( 3 ) . then ( ( ) => old ( ... args ) )", "del_tokens": "return jsreport . init ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "stability", "around", "possible", "async", "timing", "issues", "and", "response", "tests"], "add_tokens": "var contentTypeJson = { 'Content-Type' : 'application/json;charset=utf-8' } transformResponse : [ function ( data , headers ) { if ( typeof data === 'string' && ( headers ( 'content-type' ) || '' ) . indexOf ( 'json' ) >= 0 ) {", "del_tokens": "var jsonStart = / ^\\s*(\\[|\\{[^\\{]) / , jsonEnd = / [\\}\\]]\\s*$ / , contentTypeJson = { 'Content-Type' : 'application/json;charset=utf-8' } // transform incoming response data transformResponse : [ function ( data ) { // TODO: use Content-Type not regex tests if ( typeof data === 'string' && jsonStart . test ( data ) && jsonEnd . test ( data ) ) { // transform outgoing request data // default headers", "commit_type": "add"}
{"commit_tokens": ["Remove", "next", "-", "bundle", "-", "analyzer", "and", "next", "-", "workers"], "add_tokens": "withSass ( withMdx ( // Currently empty ) )", "del_tokens": "const path = require ( 'path' ) const withBundleAnalyzer = require ( '@zeit/next-bundle-analyzer' ) const withWorkers = require ( '@zeit/next-workers' ) const { BUNDLE_ANALYZE } = process . env withBundleAnalyzer ( withWorkers ( withSass ( withMdx ( // Configuration for next-bundle-analyzer so it can be controlled via // BUNDLE_ANALYZE environment variables. analyzeServer : [ 'server' , 'both' ] . includes ( BUNDLE_ANALYZE ) , analyzeBrowser : [ 'browser' , 'both' ] . includes ( BUNDLE_ANALYZE ) , bundleAnalyzerConfig : { server : { analyzerMode : 'static' , reportFilename : path . resolve ( './bundles/server.html' ) } , browser : { analyzerMode : 'static' , reportFilename : path . resolve ( './bundles/client.html' ) } } ) ) ) )", "commit_type": "remove"}
{"commit_tokens": ["add", "integrity", "option", "for", "webpack", "-", "subresource", "-", "integrity"], "add_tokens": "keepInMemory : false , integrity : false var integrity = compilation . assets [ asset ] . integrity if ( self . options . integrity && integrity ) { typeMap [ typeName + 'Integrity' ] = integrity }", "del_tokens": "keepInMemory : false", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", ":", "log", "works", "on", "the", "global", "directly", "."], "add_tokens": "log ( state , emitter , app , localEmitter )", "del_tokens": "window . choo . log = log ( state , emitter , app , localEmitter )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "dev", "mode", "while", "its", "buggy"], "add_tokens": "userBasePath : this . userBasePath", "del_tokens": "userBasePath : this . userBasePath , devMode : this . devMode ? 'development' : null", "commit_type": "remove"}
{"commit_tokens": ["add", "standard", "+", "fix", "standard", "errors"], "add_tokens": "module . exports = Automata return lattice . map ( function ( cell , index , array ) { var lastEl = lattice . length - 1 cell . right = lattice [ index + 1 ] . state cell . left = lattice [ index - 1 ] . state cell . right = lattice [ index - 1 ] . state cell . left = lattice [ index + 1 ] . state neighbourhoods . forEach ( function ( hood , index ) { // let's convert a number to an 8-bit bae", "del_tokens": "module . exports = Automata ; return lattice . map ( function ( cell , index , array ) { var lastEl = lattice . length - 1 cell . right = lattice [ index + 1 ] . state cell . left = lattice [ index - 1 ] . state cell . right = lattice [ index - 1 ] . state cell . left = lattice [ index + 1 ] . state neighbourhoods . forEach ( function ( hood , index ) { // let's convert a number to an 8-bit bae // let's reverse it, b/c our neighbourhoods are reversed too", "commit_type": "add"}
{"commit_tokens": ["Add", "app", ".", "js", "in", "the", "lint", "checks", "."], "add_tokens": "/*eslint-env node */ 'use strict' ; /*eslint-disable new-cap */ /*eslint-enable new-cap */ } ) ; /*eslint-disable no-unused-vars */ err . status = ( err . status || 500 ) ; /*eslint-enable no-unused-vars */", "del_tokens": "} ) err . status = ( err . status || 500 )", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "texteq", "less", "violent"], "add_tokens": "let children = $elm . contents ( ) , textCounter = 0 , found = false for ( let i = 0 , child ; child = children [ i ] ; i ++ ) { if ( child . type === \"text\" ) { $elm = child found = true textCounter ++ $elm = cheerio . load ( \"\" ) value = value === undefined ? \"\" : value", "del_tokens": "let children = $elm . contents ( ) ; let textCounter = 0 ; let found = false ; for ( let i = 0 ; i < children . length ; i ++ ) { if ( children [ i ] . type === 'text' ) { $elm = children [ i ] ; found = true ; textCounter ++ ; throw Error ( 'Text node as specified in texteq not found' ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "debug", "mode", "in", "VectorLayer"], "add_tokens": "var geometry = this . geometry , layer = geometry . getLayer ( ) ; if ( ! geometry . options [ 'debug' ] && ! layer . options [ 'debug' ] ) {", "del_tokens": "var geometry = this . geometry ; if ( ! geometry . options [ 'debug' ] ) {", "commit_type": "add"}
{"commit_tokens": ["Moved", "if", "check", "to", "right", "location"], "add_tokens": "if ( names . length <= index ) return cb ( new Error ( \"No file unique file found!\" ) )", "del_tokens": "if ( names . length <= index ) return cb ( new Error ( \"No file unique file found!\" ) )", "commit_type": "move"}
{"commit_tokens": ["added", ".", "then", ":", "beers", ":"], "add_tokens": "var EventEmitter = require ( 'events' ) . EventEmitter , MPromise = require ( 'mpromise' ) ; / ** * [ Promises / A + ] ( http : //promises-aplus.github.io/promises-spec/)-compliant `.then`. * * @ api public * / Promise . prototype . then = function ( ) { var p = new MPromise ; this . success ( p . fulfill . bind ( p ) ) ; this . error ( p . reject . bind ( p ) ) ; return p . then . apply ( p , arguments ) ; } ;", "del_tokens": "var EventEmitter = require ( 'events' ) . EventEmitter ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "Steam", "API", "key", "can", "now", "be", "set", "globally", "in", "Steam", ".", "key", "(", "as", "well", "was"], "add_tokens": "* @ param { String } ( optional ) key A Steam API key // If optional key was not given if ( typeof ( key ) === \"function\" ) { callback = key ; key = undefined ; } / ** * Helper method to get a value by searching for it by priority * * First checking the options object passed in to the method call * then the instance object properties * or finally the global Steam object * / // else if ( Steam [ key ] !== undefined ) { return Steam [ key ] ; } // All we need to get started, we will build and attach the rest later (down below)", "del_tokens": "* @ param { String } key A Steam API key // Helper method to get a value by first checking the options object, or else the instance variable // All we need to get started, we will build and attach the rest at run-time", "commit_type": "add"}
{"commit_tokens": ["Fix", "extraction", "of", "zips", "given", "by", "relative", "paths"], "add_tokens": "zip : \"./app/native/res/zip/test_single-file-no-folder.zip\" , destination : \"./tmp\" ,", "del_tokens": "zip : \"app/native/res/zip/test_single-file-no-folder.zip\" , destination : \"tmp\" ,", "commit_type": "fix"}
{"commit_tokens": ["update", "observations", "to", "be", "pushed", "into", "result"], "add_tokens": "let _lastStepActions = [ ] ; let _lastStepObservations = [ ] ; let activeObservations = [ ] ; let theta = { $T : _currentTime } ; activeObservations . push ( action . substitute ( theta ) ) ; _lastStepActions = activeActions ; return _lastStepActions . map ( action => action . toString ( ) ) ; } ; this . getLastStepObservations = function getLastStepObservations ( ) { return _lastStepObservations . map ( action => action . toString ( ) ) ; fluents : this . getActiveFluents ( ) , actions : this . getLastStepActions ( ) , observations : this . getLastStepObservations ( )", "del_tokens": "let lastStepActions = [ ] ; lastStepActions = activeActions ; return lastStepActions . map ( action => action . toString ( ) ) ; activeFluents : this . getActiveFluents ( ) , actions : this . getLastStepActions ( )", "commit_type": "update"}
{"commit_tokens": ["Remove", "options", ".", "classes", "."], "add_tokens": "child . position . setX ( child . styles . marginBounds . min . x * - 1 ) child . position . setY ( position - child . styles . marginBounds . max . y ) child . position . setX ( position - child . styles . marginBounds . min . x ) child . position . setY ( child . styles . marginBounds . max . y * - 1 )", "del_tokens": "_workingBox3_1 . scale ( child . scale ) child . position . setX ( _workingVector3_1 . x / - 2 ) child . position . setY ( position - _workingVector3_1 . y / 2 - _workingVector3_2 . y ) child . position . setX ( position + _workingVector3_1 . x / 2 - _workingVector3_2 . x ) child . position . setY ( _workingVector3_1 . y / - 2 )", "commit_type": "remove"}
{"commit_tokens": ["Allow", "to", "retrieve", "the", "wrapped", "instance", "as", "react", "-", "redux", "does"], "add_tokens": "import invariant from 'invariant' composeTheme : COMPOSE_DEEPLY , withRef : false export default ( componentName , localTheme , options = { } ) => ( ThemedComponent ) => { const { composeTheme : optionComposeTheme , withRef : optionWithRef } = { ... DEFAULT_OPTIONS , ... options } getWrappedInstance ( ) { invariant ( optionWithRef , 'To access the wrapped instance, you need to specify ' + '{ withRef: true } as the third argument of the themr() call.' ) return this . refs . wrappedInstance } let renderedElement if ( optionWithRef ) { renderedElement = React . createElement ( ThemedComponent , { ... rest , ref : 'wrappedInstance' , theme : composeTheme ? this . getTheme ( ) : this . getThemeNotComposed ( ) } ) } else { renderedElement = React . createElement ( ThemedComponent , { ... rest , theme : composeTheme ? this . getTheme ( ) : this . getThemeNotComposed ( ) } ) } return renderedElement", "del_tokens": "composeTheme : COMPOSE_DEEPLY export default ( componentName , localTheme , options = DEFAULT_OPTIONS ) => ( ThemedComponent ) => { const { composeTheme : optionComposeTheme } = options return React . createElement ( ThemedComponent , { ... rest , theme : composeTheme ? this . getTheme ( ) : this . getThemeNotComposed ( ) } )", "commit_type": "allow"}
{"commit_tokens": ["Added", "an", "option", "to", "show", "the", "Punch", "version", "on", "CLI"], "add_tokens": "version : function ( ) { var package_meta = require ( \"../package.json\" ) ; console . log ( 'Punch version ' + package_meta . version ) ; } , console . log ( ' setup - create directory strucutre for Punch. (punch setup PATH)' ) ; console . log ( ' version - show Punch version. (shortcut `punch v`)' ) ; var commands = [ \"setup\" , \"server\" , \"generate\" , \"help\" , \"version\" ] ; var short_codes = { \"s\" : \"server\" , \"g\" : \"generate\" , \"h\" : \"help\" , \"v\" : \"version\" } ;", "del_tokens": "console . log ( ' setup - create directory strucutre for Punch (punch setup PATH)' ) ; var commands = [ \"setup\" , \"server\" , \"generate\" , \"help\" ] ; var short_codes = { \"s\" : \"server\" , \"g\" : \"generate\" , \"h\" : \"help\" } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "the", "..", "syntax"], "add_tokens": "var scope = null ; if ( typeof min === 'string' && min . match ( / ^\\d+\\.{2}\\d+$ / ) ) { step = max ; scope = min . split ( '..' ) ; min = + scope [ 0 ] ; max = + scope [ 1 ] ; } , min = this . min ( ) , isFloat = typeof min === 'float' while ( min <= max ) { min += step ; while ( ( min += step ) <= max ) {", "del_tokens": ", min = this . min ( ) - step while ( ( min = min + step ) <= max ) { while ( ( min = min + step ) <= max ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "checking", "just", "the", "tops", "of", "the", "elements", "for", "the", "inviewclassadder", "."], "add_tokens": "* @ param { Boolean } opt_fromTop Whether to check if only the tops and bottoms * of the elements are in view , and to skip checking the sides . var InViewClassAdder = function ( selector , className , opt_offset , opt_delay , opt_fromTop ) { this . fromTop = opt_fromTop || false ; fromTop : false , if ( ui . isElementInView ( el , this . offset , this . fromTop ) ) { var fromTop = config . fromTop || InViewClassAdder . DefaultConfig . fromTop ; var classAdder = new InViewClassAdder ( selector , className , offset , delay , fromTop ) ;", "del_tokens": "var InViewClassAdder = function ( selector , className , opt_offset , opt_delay ) { if ( ui . isElementInView ( el , this . offset ) ) { var classAdder = new InViewClassAdder ( selector , className , offset , delay ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "few", "more", "tests", "for", "single", "argument", "class", "definition", "and", "making", "Properties", "getter", "/", "setter", "function", "more", "readable", "."], "add_tokens": "subject [ this . _getterName ( name , value ) ] = function ( ) { return this [ name ] ; } ; subject [ this . _setterName ( name ) ] = function ( value ) { this [ name ] = value ; } ;", "del_tokens": "subject [ this . _getterName ( name , value ) ] = function ( ) { return this [ name ] ; } ; subject [ this . _setterName ( name ) ] = function ( value ) { this [ name ] = value ; } ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "features", "for", "new", "Traceur"], "add_tokens": "* * * * * * In order to support async functions ( ` ` / ` ` ) do : * * ` ` *", "del_tokens": "* * * * * * * In order to support block scope ( ` ` ) do : * ` ` *", "commit_type": "update"}
{"commit_tokens": ["Added", "gradients", ".", "Changed", "plugin", "architecture", "."], "add_tokens": "Savage . plugin ( function ( Savage , Element , Paper , glob ) { mmin = Math . min ; setproto . attr = function ( value ) { this . items [ i ] . attr ( value ) ; Savage . set = function ( ) { } ) ;", "del_tokens": "( function ( ) { mmin = Math . min , g = eve ( \"savage.globals\" ) [ 0 ] ; setproto . attr = function ( name , value ) { this . items [ i ] . attr ( name , value ) ; g . savage . set = function ( ) { } ) ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "unit", "test", "for", "LibraryStatement", "UsingStatement", "lib", "method", "calls"], "add_tokens": "const contractNameMatch = source . match ( / (?:contract)\\s([^\\s]*)\\s*{ / )", "del_tokens": "const contractNameMatch = source . match ( / (?:contract|library)\\s([^\\s]*)\\s*{ / )", "commit_type": "add"}
{"commit_tokens": ["Update", "leapjs", "plugins", "with", "sendImmediateFrame"], "add_tokens": "* LeapJS - Plugins Extra - v0 .1 .6 - 2014 - 05 - 14", "del_tokens": "* LeapJS - Plugins Extra - v0 .1 .6 - 2014 - 05 - 12", "commit_type": "update"}
{"commit_tokens": ["add", "normalize", "setting", "to", "speakers"], "add_tokens": "// Post gain compensation value. var POST_GAIN_DB = 0 ;", "del_tokens": "// Post gain compensation value, empirically determined. var POST_GAIN_DB = 30 ;", "commit_type": "add"}
{"commit_tokens": ["added", "some", "tests", "and", "npm", "run", "cover", "command"], "add_tokens": "describe ( 'List Secure Value' , function ( ) {", "del_tokens": "describe . only ( 'List Secure Value' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "socket", ".", "destroy", "()", "to", "statsd", ".", "close", "()", "when", "using", "TCP"], "add_tokens": "if ( this . protocol === 'tcp' ) { this . socket . destroy ( ) ; } else { this . socket . close ( ) ; }", "del_tokens": "this . socket . close ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "blur", "attr", "for", "editable", "form"], "add_tokens": "[ '$rootScope' , '$parse' , 'editableFormController' , 'editableOptions' , function ( $rootScope , $parse , editableFormController , editableOptions ) { / ** * Action when form losses focus . Values : ` ` . * Default is ` ` . * * @ var { string | attribute } blur * @ memberOf editable - form * / eForm . _blur = attrs . blur || editableOptions . blurForm ; // click - mark form as clicked to exclude in document click handler elem . bind ( 'click' , function ( e ) { // ignore right/middle button click if ( e . which !== 1 ) { return ; } if ( eForm . $visible ) { eForm . _clicked = true ; } } ) ;", "del_tokens": "[ '$rootScope' , '$parse' , 'editableFormController' , function ( $rootScope , $parse , editableFormController ) { / * Maybe it 's better attach editable controller to form' s controller not in pre ( ) but in controller itself . This allows to use ng - init already in < form > tag, otherwise we can't (in FF). * /", "commit_type": "add"}
{"commit_tokens": ["Allow", "tempOutputDir", "to", "have", "a", "custom", "basename"], "add_tokens": "const os = require ( 'os' ) const outputDir = module . exports . tempOutputDir ( installerOptions . dest ) module . exports . tempOutputDir = function tempOutputDir ( customDir ) { return customDir ? path . join ( os . tmpdir ( ) , customDir ) : temp . path ( { prefix : 'electron-installer-debian-' } )", "del_tokens": "const outputDir = installerOptions . dest || module . exports . tempOutputDir ( ) module . exports . tempOutputDir = function tempOutputDir ( ) { return temp . path ( { prefix : 'electron-installer-debian-' } )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "Ui", "*", "Box", "::", "padded", "not", "implemented", "as", "property"], "add_tokens": "get padded ( ) { set padded ( value ) {", "del_tokens": "getPadded ( ) { setPadded ( value ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "missing", "variable", "declarations"], "add_tokens": "let curieMajor = id . getCurieMajor ( ) ; let className = null ; let curie = id . getCurie ( ) . toString ( ) ; let key = curie . toString ( ) ; let className = this . messages [ key ] ;", "del_tokens": "curieMajor = id . getCurieMajor ( ) ; curie = id . getCurie ( ) . toString ( ) ; key = curie . toString ( ) ; className = this . messages [ key ] ;", "commit_type": "add"}
{"commit_tokens": ["make", "demo", "page", "a", "bit", "nicer"], "add_tokens": "return gulp . src ( paths . sassLib )", "del_tokens": "sassThemes : 'examples/**/*.scss' , return gulp . src ( paths . sassThemes ) gulp . watch ( paths . sassThemes , [ 'compileSass' ] ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "problem", "accessing", "the", "query", "result", "when", "it", "is", "empty"], "add_tokens": "const isSelect = ! recordSet . length || ( recordSet [ 0 ] && recordSet [ 0 ] . rowCount === undefined ) ;", "del_tokens": "const isSelect = recordSet [ 0 ] && recordSet [ 0 ] . rowCount === undefined ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "action", "-", "input", "to", "a", "regular", "dependency", ".", "Move", "static", "assets", "into", "folder", "at", "the", "root", "for", "easy", "integration", "in", "potassium", "-", "samples", "."], "add_tokens": "\"/static/potassium-es/models/Controller.obj\" ,", "del_tokens": "\"./js/potassium/input/models/Controller.obj\" ,", "commit_type": "move"}
{"commit_tokens": ["added", "support", "for", "configuration", "options"], "add_tokens": "options = $ember . get ( this , 'options' ) || { } , socket = $io . connect ( server , options ) ;", "del_tokens": "socket = $io . connect ( server ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "SVG", "cleanup", "removing", "inline", "styles"], "add_tokens": "if ( options . cleanup && key === 'style' ) { value = null ; } $elem . attr ( key , value ) ;", "del_tokens": "$elem . attr ( key , value ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "attribute", "more", "consistent", "to", "the", "directive", "name"], "add_tokens": "mdtRow : '=' $scope . $watch ( 'mdtRow' , function ( mdtRow ) { if ( typeof mdtRow === 'object' ) { _ . each ( mdtRow [ 'data' ] , function ( row ) { rowId = row [ mdtRow [ 'table-row-id-key' ] ] ; _ . each ( mdtRow [ 'column-keys' ] , function ( columnKey ) {", "del_tokens": "mdDataTableRow : '=' $scope . $watch ( 'mdDataTableRow' , function ( mdDataTableRow ) { if ( typeof mdDataTableRow === 'object' ) { _ . each ( mdDataTableRow [ 'data' ] , function ( row ) { rowId = row [ mdDataTableRow [ 'table-row-id-key' ] ] ; _ . each ( mdDataTableRow [ 'column-keys' ] , function ( columnKey ) {", "commit_type": "make"}
{"commit_tokens": ["make", "wrap", "a", "completely", "private", "method"], "add_tokens": "this [ action . replace ( / onE / , '_e' ) ] = wrap ( this [ action ] , this ) ; function wrap ( func , scene ) {", "del_tokens": "this [ action . replace ( / onE / , '_e' ) ] = Miso . Scene . __wrap ( this [ action ] , this ) ; Miso . Scene . __wrap = function ( func , scene ) {", "commit_type": "make"}
{"commit_tokens": ["improve", "whitespace", "handling", "in", "li", "and", "anchors"], "add_tokens": "var href = attribs . href ; if ( ! name && ! href ) return ; if ( name && ! href ) { this . output = this . output . replace ( / (?!\\w)\\s+$ / , '' ) ;", "del_tokens": "if ( name && ! attribs . href ) { this . output = this . output . replace ( / \\s+$ / , '' ) ;", "commit_type": "improve"}
{"commit_tokens": ["Created", "light", "sidebar", "and", "added", "new", "skin", "mixins"], "add_tokens": "* @ version 2.1 .0 / * ControlSidebar * === === === === == * Control the all of the control sidebar transitions * * @ type Object * @ usage $ . Admin . controlSidebar . activate ( options ) * / $ . AdminLTE . controlSidebar = { //Default settings defaults : { toggleBtnSelector : \"[data-toggle='control-sidebar']\" , selector : \".control-sidebar\" , slide : false , animationSpeed : 300 } , //Initiate the object activate : function ( options ) { var settings = $ . extend ( { } , options , this . defaults ) ; } , //Close the control sidebar close : function ( ) { } , //Open the control sidebar open : function ( ) { } , //If the slide option is set, this //function is used to open the sidebar slideIn : function ( ) { } , //The complement funtion to slideIn slideOut : function ( ) { } } ;", "del_tokens": "* @ version 2.0 .5", "commit_type": "create"}
{"commit_tokens": ["fix", "tests", "after", "removing", "+", "1s", "from", "proportion", "calc"], "add_tokens": "expect ( + arabidopsis . results ( ) . proportion . toPrecision ( 3 ) ) . toEqual ( 0.00149 ) ; expect ( + taxonomy . globalResultSetStats ( ) . maxProportion . toPrecision ( 3 ) ) . toEqual ( 0.00249 ) ;", "del_tokens": "expect ( + arabidopsis . results ( ) . proportion . toPrecision ( 3 ) ) . toEqual ( 0.00151 ) ; expect ( + taxonomy . globalResultSetStats ( ) . maxProportion . toPrecision ( 3 ) ) . toEqual ( 0.00262 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "issue", "for", "ES6", "style", "iteration", "on", "MIDI", "inputs"], "add_tokens": "var it = iface . inputs [ \"values\" ] ( ) ;", "del_tokens": "var it = iface . outputs [ \"values\" ] ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "linters", "detect", "the", "falls", "-", "through", "comment"], "add_tokens": "/* falls through */", "del_tokens": "/* falls through */", "commit_type": "make"}
{"commit_tokens": ["Add", "@fileoverview", "to", "decoratelayer", ".", "js"], "add_tokens": "/ ** * @ fileoverview Provides a function that adds properties ( using * ` ` ) to the layer , making it possible to control layer * properties with ngModel . * * Example : * < input type = \"checkbox\" ngModel = \"layer.visible\" / > * /", "del_tokens": "* This service provides a function that adds properties ( using * ` ` ) to the layer , making it possible to * control layer properties with ngModel . * * Example : * < input type = \"checkbox\" ngModel = \"layer.visible\" / > *", "commit_type": "add"}
{"commit_tokens": ["Fix", "bugs", "with", "channel", "close", "/", "cancel"], "add_tokens": "remotePeer , correlationId , peerConnection . getLocalDescription ( ) , * this . cancel = function ( ) { } ; this . close = function ( ) { rtcDataChannel = null ; module . exports = Channel ;", "del_tokens": "remotePeer , correlationId , peerConnection . getLocalDescription ( ) , * this . destroy = function ( ) { if ( rtcDataChannel ) { rtcDataChannel . close ( ) ; rtcDataChannel . onmessage = null ; // etc.. rtcDataChannel = null ; } module . exports = Channel ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "force", "-", "flag", "to", "JSON", "response", "middleware", "to", "treat", "all", "responses", "as", "JSON"], "add_tokens": "module . exports = opts => ( { const contentType = response . headers [ 'content-type' ] || '' const shouldDecode = ( opts && opts . force ) || contentType . indexOf ( 'application/json' ) !== - 1 if ( ! response . body || ! contentType || ! shouldDecode ) {", "del_tokens": "module . exports = ( ) => ( { const contentType = response . headers [ 'content-type' ] if ( ! response . body || ! contentType || contentType . indexOf ( 'application/json' ) === - 1 ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "complete", "word", "as", "parameters"], "add_tokens": "utils . addMethod ( assert , 'deepEqualExcluding' , function ( actual , expected , props , message ) { new Assertion ( actual , message ) . excluding ( props ) . to . deep . equal ( expected ) utils . addMethod ( assert , 'deepEqualExcludingEvery' , function ( actual , expected , props , message ) { new Assertion ( actual , message ) . excludingEvery ( props ) . to . deep . equal ( expected )", "del_tokens": "utils . addMethod ( assert , 'deepEqualExcluding' , function ( act , exp , props , msg ) { new Assertion ( act , msg ) . excluding ( props ) . to . deep . equal ( exp ) utils . addMethod ( assert , 'deepEqualExcludingEvery' , function ( act , exp , props , msg ) { new Assertion ( act , msg ) . excludingEvery ( props ) . to . deep . equal ( exp )", "commit_type": "use"}
{"commit_tokens": ["Add", "options", "for", "the", "npm", "client"], "add_tokens": "npm . load ( opts . npm || { } , function ( er ) {", "del_tokens": "npm . load ( { } , function ( er ) {", "commit_type": "add"}
{"commit_tokens": ["added", "minimal", "REPL", "for", "query", "stats", "etc"], "add_tokens": "memory = false , queryRowCallback , dfltCompleteCallback ; queryRowCallback = options . rowCallback ; dfltCompleteCallback = options . completeCallback ; if ( ! rowCallback ) rowCallback = queryRowCallback ; if ( ! completeCallback ) completeCallback = dfltCompleteCallback ; if ( ! callback ) { callback = dfltCompleteCallback ; } SimpleNodeDb . createREPL = function ( opts ) { 'use strict' ; if ( typeof opts === 'string' ) { opts = { path : opts } ; } if ( ! opts ) opts = { } ; if ( ! opts . log ) opts . log = require ( 'simple-node-logger' ) . createLogger ( ) ; if ( ! opts . rowCallback ) { opts . rowCallback = function ( key , value ) { opts . log . info ( key , ':' , value ) ; return db . parseModel ( value ) ; } ; } if ( ! opts . completeCallback ) { opts . completeCallback = function ( err , result ) { if ( err ) throw err ; opts . log . info ( result ) ; } ; } var db = new SimpleNodeDb ( opts ) ; return db ; } ;", "del_tokens": "memory = false ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "some", "PLOS", "articles", "to", "the", "game", "."], "add_tokens": "console . error ( \"Node not yet supported within section: \" + type ) ; // throw new ImporterError(\"Node not yet supported within section: \" + type); console . error ( \"Not yet supported on paragraph level: \" + type ) ; // throw new ImporterError(\"Not yet supported on paragraph level: \" + type);", "del_tokens": "throw new ImporterError ( \"Node not yet supported within section: \" + type ) ; throw new ImporterError ( \"Not yet supported on paragraph level: \" + type ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "closure", "in", "async", "delay", "management"], "add_tokens": "function delayEnd ( func , self ) { if ( func ) func ( ) ; remove ( self ) ; } this . parent . delay ( null , ms ) ; return setTimeout ( delayEnd , ms , func , this ) ;", "del_tokens": "var self = this ; this . parent . delay ( function ( ) { } , ms ) ; return setTimeout ( function ( ) { func ( ) ; remove ( self ) ; } , ms ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "the", "methods", "translate", "and", "translateIn", "to", "the", "$i18n", "instance", "object", "to", "keep", "api", "consistent"], "add_tokens": "translate : translate , translateIn : translateInLanguage , // register the translation function on the vue instance directly // register the specific language translation function on the vue instance directly", "del_tokens": "// register the translation function on the vue instance // register the specific language translation function on the vue instance", "commit_type": "add"}
{"commit_tokens": ["Allow", "custom", "options", "to", "be", "passed", "to", "the", "Jade", "compiler"], "add_tokens": "content = jade . render ( content , options . jade ) ; jade : { pretty : true } ,", "del_tokens": "content = jade . render ( content , { pretty : true } ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "a", "couple", "more", "bugs", "including", "a", "bad", "closure", ".", "All", "tests", "pass", "."], "add_tokens": "var add_method = function ( method ) { for ( var i = 0 ; i < methods . length ; i ++ ) { add_method ( methods [ i ] ) } if ( typeof method === 'function' ) { } else if ( typeof route === 'function' ) { route = undefined if ( route )", "del_tokens": "for ( var i = 0 ; i < methods . length ; i ++ ) { var method = methods [ i ] if ( typeof method == 'function' ) { } else if ( typeof route == 'function' ) { route = method method = undefined if ( route ) { }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "missing", "uses", "of", "_", ".", "isEqual", "without", "checking", "if", "custom", "compare", "is", "set", "first", "."], "add_tokens": "attrs , dataType , silent , unset , currentVal , initial , hasChanged , isEqual ; isEqual = this . _getCompareForType ( def . type ) ; hasChanged = ! isEqual ( currentVal , newVal ) ; if ( ! isEqual ( previous [ attr ] , newVal ) ) { var def , isEqual ; def = this . _definition [ attr ] ; isEqual = this . _getCompareForType ( def && def . type ) ; if ( isEqual ( old [ attr ] , ( val = diff [ attr ] ) ) ) continue ; // Determine which comparison algorithm to use for comparing a property _getCompareForType : function ( type ) { var dataType = this . _dataTypes [ type ] ; if ( dataType && dataType . compare ) return dataType . compare ; return _ . isEqual ; } ,", "del_tokens": "attrs , dataType , silent , unset , currentVal , initial , hasChanged ; if ( dataType && dataType . compare ) { hasChanged = ! dataType . compare ( currentVal , newVal ) ; } else { hasChanged = ! _ . isEqual ( currentVal , newVal ) ; } if ( ! _ . isEqual ( previous [ attr ] , newVal ) ) { if ( _ . isEqual ( old [ attr ] , ( val = diff [ attr ] ) ) ) continue ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "to", "normalizing", "excludedFiles", "and", "only", "testing", "end", "of", "filename", "for", "match"], "add_tokens": "// If not passed, check if file is marked for manual exclusion. Else, fail it. var exclude = _ ( excludedFiles ) . some ( function ( o ) { return o . test ( name ) ; } ) ; var result = pass ? \"PASS\" : ( exclude ? \"SKIP\" : \"FAIL\" ) ; // Get the array of excludedFiles, normalize and prepare them // Users should be able to define it in the command-line as an array or include it in the test file. excludedFiles = _ ( excludedFiles ) . map ( function ( o ) { return new RegExp ( path . normalize ( o ) + '$' ) ; } ) . value ( ) ; // Get the custom thresholds for files, normalize and prepare the file names", "del_tokens": "//If not passed, check if file is marked for manual exclusion. Else, fail it. var result = pass ? \"PASS\" : ( excludedFiles . indexOf ( name ) === - 1 /*File not found*/ ? \"FAIL\" : \"SKIP\" ) ; //Get the array of excludedFiles //Users should be able to define it in the command-line as an array or include it in the test file. // Get the custom thresholds for files, normalizing the file names", "commit_type": "change"}
{"commit_tokens": ["add", "new", "exitNow", "actions", "different", "from", "exit", "to", "force", "process", "to", "kill", "itself", "with", "appropriate", "return", "code"], "add_tokens": "} ; actions . stop ( endProcess ) ; } , / ** * Manage properly exit of the process when SIGINT signal is triggered . * It asks to every plugin to end properly . * / exitNow : function ( ) { var killProcess = function ( err ) { LOGGER . info ( 'Killing process.' ) ; var handles_c = process . _getActiveHandles ( ) . length ; var requests_c = process . _getActiveRequests ( ) . length ; if ( handles_c + requests_c > 0 ) { LOGGER . info ( 'Has remaining open handles..' ) ; LOGGER . info ( '_getActiveHandles ' + handles_c ) ; LOGGER . info ( '_getActiveRequests ' + requests_c ) ; } process . exit ( err ? 1 : 0 ) ; actions . exit ( killProcess ) ;", "del_tokens": "else if ( process . _getActiveHandles ( ) . length || process . _getActiveRequests ( ) . length ) { process . exit ( err ? 1 : 0 ) ; } actions . stop ( endProcess ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "some", "tests", "to", "mocha"], "add_tokens": "grunt . registerTask ( 'pre-check' , [ 'deps-ok' , 'nice-package' , 'complexity' ] ) ;", "del_tokens": "jshint : { options : { jshintrc : '.jshintrc' , reporter : require ( 'jshint-stylish' ) } , default : { src : [ \"index.js\" , \"test/test.js\" ] } } , jsonlint : { all : { src : [ '*.json' ] } } , grunt . registerTask ( 'pre-check' , [ 'deps-ok' , 'jsonlint' , 'jshint' , 'nice-package' , 'complexity' ] ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "JPEG", "and", "PNG", "support", "for", "SVGGraphics", ".", "toDataURL"], "add_tokens": "var dataURL = 'data:image/svg+xml;charset=utf-8,' + serializedSVG ; console . log ( type , options ) ; // use canvas to export var img = new Image ( ) ; img . src = dataURL ; // sync mode var imageLoaded = function ( ) { return img . width > 0 && img . height > 0 ; } ; // wait until image loaded while ( ! imageLoaded ( ) ) { } var canvas = document . createElement ( 'canvas' ) ; canvas . width = svgCanvas . width ; canvas . height = svgCanvas . height ; var ctx = canvas . getContext ( '2d' ) ; ctx . drawImage ( img , 0 , 0 ) ; return canvas . toDataURL ( type , options ) ; return dataURL ;", "del_tokens": "return 'data:image/svg+xml;charset=utf-8,' + serializedSVG ;", "commit_type": "add"}
{"commit_tokens": ["Added", "better", "minification", "obfuscation", "and", "better", "parsing"], "add_tokens": "\"use strict\" ; , child = require ( './lib/child' ) } ; child . closure ( 'js' , content , { } , fn ) ;", "del_tokens": "} var fields = { output_format : 'text' , compilation_level : aggressive ? 'ADVANCED_OPTIMIZATIONS' : 'SIMPLE_OPTIMIZATIONS' , js_code : content , output_info : 'compiled_code' } ; // request request . post ( { url : 'http://closure-compiler.appspot.com/compile' , body : Object . keys ( fields ) . map ( function map ( key ) { return encodeURIComponent ( key ) + '=' + encodeURIComponent ( fields [ key ] ) ; } ) . join ( '&' ) } , function complete ( err , response , data ) { if ( err ) return fn ( err , content ) ; if ( response . statusCode !== 200 ) return fn ( new Error ( 'invalid status' ) , content ) ; fn ( null , data ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "docs", "for", "income", "()", "and", "renamed", "some", "vars"], "add_tokens": "* @ return { Void } - Listing info is passed through callbacks / ** * Generate estimate income for a particular hosting * @ param { Number , String } hosting - Hosting ID * @ param { Object } options - Search options , similar to options for . availability ( ) * @ param { Function } successCallback - Callback to invoke when successfully calculating est income * @ param { Function } failureCallback - Failure callback to invoke * @ return { Void } - Estimate income is passed onto callbacks * / var estIncome ; availability ( hosting , options , function success ( err , res , availabilityInfo ) { estIncome = availabilityInfo . calendar_months . map ( function ( thisMonth ) { avgPrice = daysWithPrice . length ? daysWithPrice . reduce ( _sumPrice , 0 ) / daysWithPrice . length : 0 ; successCallback ( estIncome ) ; // Expose public methods", "del_tokens": "* @ return { [ Void ] } - Listing info is passed through callbacks var monthsIncome ; availability ( hosting , options , function success ( err , res , info ) { monthsIncome = info . calendar_months . map ( function ( thisMonth ) { avgPrice = daysWithPrice . reduce ( _sumPrice , 0 ) / daysWithPrice . length ; successCallback ( monthsIncome ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "babel", "(", "__esModule", "would", "throw", ")", "+", "tests"], "add_tokens": "const RESERVED_PROPS = [ 'inspect' , '__esModule' return RESERVED_PROPS . includes ( name )", "del_tokens": "const RESERVED_METHODS = [ 'inspect' return RESERVED_METHODS . includes ( name )", "commit_type": "add"}
{"commit_tokens": ["added", "has", "range", "to", "filter", "on", "array", "content"], "add_tokens": "] , tags : [ 'old' , 'smart' ] ] , tags : [ 'young' , 'dull' ] ] , tags : [ 'young' ] ] , tags : [ 'young' , 'smart' ] ] , tags : [ 'old' , 'dull' ] let query3 = Query . from ( { tags : { $has : 'dull' } } ) ; let result3 = data . filter ( query3 . predicate ) ; expect ( result3 ) . to . have . length ( 2 ) ; expect ( result3 ) . to . deep . equal ( data . filter ( item => item . tags . includes ( 'dull' ) ) ) ;", "del_tokens": "] ] ] ] ]", "commit_type": "add"}
{"commit_tokens": ["updated", "meta", "-", "data", "from", "schema", "changes"], "add_tokens": "\"display_name\" : \"Taxon closure (labels)\" , \"display_name\" : \"Taxon closure (labels)\" , \"display_name\" : \"Taxon label\" , \"display_name\" : \"Taxon closure (labels)\" , \"display_name\" : \"Is-a/Part-of closure\" , \"display_name\" : \"Taxon closure (labels)\" , \"display_name\" : \"Is-a/Part-of closure\" , \"display_name\" : \"Taxon label\" , \"display_name\" : \"Taxon closure (labels)\" , \"display_name\" : \"Is-a/Part-of closure\" , \"display_name\" : \"Is-a/Part-of closure (labels)\" , \"display_name\" : \"Is-a/Part-of closure (labels)\" , \"display_name\" : \"Taxon closure (labels)\" , \"display_name\" : \"Is-a/Part-of closure\" , \"display_name\" : \"Is-a/Part-of closure\" , \"display_name\" : \"Is-a/Part-of closure\" ,", "del_tokens": "\"display_name\" : \"Taxon label closure\" , \"display_name\" : \"Taxon label closure\" , \"display_name\" : \"Taxon\" , \"display_name\" : \"Taxon label closure\" , \"display_name\" : \"isa/partof closure (ids)\" , \"display_name\" : \"Taxon label closure\" , \"display_name\" : \"isa/partof closure (ids)\" , \"display_name\" : \"Taxon\" , \"display_name\" : \"Taxon label closure\" , \"display_name\" : \"isa/partof closure\" , \"display_name\" : \"isa/partof label closure\" , \"display_name\" : \"isa/partof label closure\" , \"display_name\" : \"Taxon label closure\" , \"display_name\" : \"isa/partof closure\" , \"display_name\" : \"isa/partof closure (ids)\" , \"display_name\" : \"isa/partof closure (ids)\" ,", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "to", "live", "reload", "SVG", "images"], "add_tokens": "if ( path . match ( / \\.(jpe?g|png|gif|svg)$ / i ) ) {", "del_tokens": "if ( path . match ( / \\.(jpe?g|png|gif)$ / i ) ) {", "commit_type": "add"}
{"commit_tokens": ["Implement", "migratable", ".", "describe", "()"], "add_tokens": "if ( ! connectionObject ) return cb ( Errors . InvalidConnection ) ; if ( ! collection ) return cb ( Errors . CollectionNotRegistered ) ; collection . describeTable ( cb ) ;", "del_tokens": "cb ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "back", "nuclearComponent", "and", "provideReactor", "for", "backwards", "compat"], "add_tokens": "import provideReactor from './src/provideReactor' import nuclearComponent from './src/nuclearComponent' export { provideReactor , nuclearComponent ,", "del_tokens": "export default {", "commit_type": "add"}
{"commit_tokens": ["move", "deep", ".", "store", ".", "Object", "to", "deep", ".", "Object"], "add_tokens": "* @ class deep . Object deep . Object = deep . Classes ( deep . Store , // console.log(\"deep.Object.post : \", object, id); return deep . errors . Conflict ( \"deep.Object.post : An object has the same id before post : please put in place : object : \" , object ) ; } , deep . store . fullSheet ) ; return deep . Object ;", "del_tokens": "* @ class deep . store . Object deep . store . Object = deep . compose . Classes ( deep . Store , // console.log(\"deep.store.Object.post : \", object, id); return deep . errors . Conflict ( \"deep.store.Object.post : An object has the same id before post : please put in place : object : \" , object ) ; } ) ; deep . Object = deep . store . Object . create = function ( protocol , root , schema , options ) { return new deep . store . Object ( protocol , root , schema , options ) ; } ; deep . sheet ( deep . store . Object . prototype , deep . store . fullSheet ) ; return deep . store . Object ;", "commit_type": "move"}
{"commit_tokens": ["change", "serveral", "var", "namings", "and", "add", "comments"], "add_tokens": "var Query = module . exports = function ( conn , config , locator ) { if ( _ . isString ( config ) ) { // if query config is string, it is given in SOQL. this . _soql = config ; this . _config = config ; if ( locator && locator . indexOf ( \"/\" ) >= 0 ) { // if locator given in url for next records this . _config . limit = limit ; this . _config . offset = offset ; this . _config . sort = sort ; Query . prototype . _maxFetch = 10000 ; Query . prototype . _autoFetch = false ; var soql = self . _soql = self . _soql || SOQLBuilder . createSOQL ( self . _config ) ;", "del_tokens": "var Query = module . exports = function ( conn , query , locator ) { if ( _ . isString ( query ) ) { // if query is string, it is given in SOQL. this . _soql = query ; this . _query = query ; if ( locator && locator . indexOf ( \"/\" ) >= 0 ) { this . _query . limit = limit ; this . _query . offset = offset ; this . _query . sort = sort ; var soql = self . _soql = self . _soql || SOQLBuilder . createSOQL ( self . _query ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "license", "to", "MIT", "only", ";", "Added", "grunt", "tools", "for", "bump", "and", "build", "."], "add_tokens": "* https : //github.com/mar10/fancytree/ * Released under the MIT license * https : //github.com/mar10/fancytree/wiki/LicenseInfo * @ version DEVELOPMENT * @ date DEVELOPMENT * / * version : \"2.0.0-22\" , /** @type {String} */ buildType : \"develop\" ,", "del_tokens": "* Dual licensed under the MIT or GPL Version 2 licenses . * http : //code.google.com/p/fancytree/wiki/LicenseInfo * A current version and some documentation is available at * https : //github.com/mar10/fancytree/ * * @ summary jQuery UI tree widget * @ description Dynamic tree view control , with support for lazy loading of branches . * @ file jquery . fancytree . js * @ version 2.0 * @ author Martin Wendt * @ license MIT or GPL v2 * * $Version : $ $Revision : $ @ depends : jquery . js @ depends : jquery . ui . widget . js @ depends : jquery . ui . core . js @ depends : jquery . cookie . js ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * / * version : \"2.0.0pre\" ,", "commit_type": "change"}
{"commit_tokens": ["Add", "reference", "implementation", "of", "sprite", "loader"], "add_tokens": "const SpriteLoaderPlugin = require ( \"svg-sprite-loader/plugin\" ) ; sprite : { extract : true } , // Options for svg-sprite-loader const fileLoaderOptions = rule . use ( \"file-loader\" ) . get ( \"options\" ) ; // Get the file loader options options . external = { ... fileLoaderOptions , ... options . external } ; // Make sure we save the file loader options options . sprite = { spriteFilename : fileLoaderOptions . name , ... options . sprite } ; // Use file loader options for sprite name config . plugin ( \"sprite\" ) . use ( SpriteLoaderPlugin ) ;", "del_tokens": "sprite : { } , // Options for svg-sprite-loader options . external = { ... rule . use ( \"file-loader\" ) . get ( \"options\" ) , ... options . external } ; // Make sure we save the file loader options", "commit_type": "add"}
{"commit_tokens": ["allow", "unset", "operations", "without", "data"], "add_tokens": "removers = require ( './enums' ) . removers ;", "del_tokens": "removers = [ 'unset' ] ;", "commit_type": "allow"}
{"commit_tokens": ["Adding", "close", "ability", "on", "service"], "add_tokens": "/ ** * Close the service . * * @ param { Function } callback - The callback . * / close ( ) { this . client . close ( ) ; } return callback ( error , this ) ; * @ param { Function } callback - The callback . * @ param { Object } options - The options . * @ param { Function } callback - The callback function .", "del_tokens": "callback ( error , this ) ; * @ param { function } callback - The callback . * @ param { function } callback - The callback function .", "commit_type": "add"}
{"commit_tokens": ["Using", "safe", "AcFun", "parse", "method", "."], "add_tokens": "cmt . appendChild ( document . createTextNode ( data . text ) ) ; cmt . innerText = data . text ;", "del_tokens": "/ ** Remove 'else' block if you do not trust 3 rd party sources or parsers . Note : The AcfunFormat is NOT safe , please do NOT use unchecked sources in AcFun Mode ! ! ** / if ( data . raw != true ) { cmt . appendChild ( document . createTextNode ( data . text ) ) ; cmt . innerText = data . text ; } else { cmt . innerHTML = data . text ; //This is for compat with ACFun. Assume text is safe. }", "commit_type": "use"}
{"commit_tokens": ["added", "passportjs", "support", "and", "apiKey", "support"], "add_tokens": "username => User . findOne ( { $or : [ { username } , { \"emails.email\" : { $in : [ username ] } } ] } ) . exec ( ) ; / ** * Returns a user if it finds one , otherwise returns null if a user is not found . * @ param { String } masterApiKey - The unique user name to find * @ param { Function } done - The user if found , otherwise returns undefined * @ returns { Promise } resolved user if found , otherwise resolves undefined * / exports . findUserByMasterApiKey = masterApiKey => User . findOne ( { $or : [ { masterApiKey } , { \"masterApiKey\" : { $in : [ masterApiKey ] } } ] } ) . exec ( ) ;", "del_tokens": "username => User . findOne ( { $or : [ { username } , { \"emails.email\" : { $in : [ username ] } } ] } ) . exec ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "custom", "schema", "validation", "formats"], "add_tokens": "// Email format const emailRegex = / ^([\\w-.]+)@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.)|(([\\w-]+\\.)+))([a-zA-Z]{2,4}|[0-9]{1,3})(\\]?)$ / ; ajv . addFormat ( 'emailAddress' , emailRegex ) ; // Amount format const amountRegex = / ^[1-9]\\d*(\\.\\d+)?$ / ; ajv . addFormat ( 'amount' , amountRegex ) ; const result = ajv . validate ( schema , json ) ; return { result , errors : ajv . errors } ;", "del_tokens": "return ajv . validate ( schema , json ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "harInput", "instead", "of", "filtered", "harFile"], "add_tokens": "//var HARFile = require('./fixtures/HARFile.json'); var rawResource = require ( './fixtures/raw.json' ) ; function getInput ( ) { var resources = [ '/addyn.js?redirect=5&gzip=true' , '/addyn.js?gzip=true' , '/addyn.js' , '/bg.jpg' , '/logo.png' ] ; return resources . map ( function ( url ) { var entry = hoek . clone ( rawResource ) ; url = host + url ; entry . request . url = url ; entry . startReply . url = url ; entry . endReply . url = url ; return entry ; } ) ; harInput : { resources : getInput ( ) } assert . isObject ( harvested . harInput ) ; assert . isNumber ( tips . possibleCompressWithOnlyScriptGzip , 'possibleCompressWithOnlyScriptGzip should be a number' ) ;", "del_tokens": "var HARFile = require ( './fixtures/HARFile.json' ) ; function getHARfile ( ) { var har = hoek . clone ( HARFile ) ; har . log . entries . forEach ( function ( entry ) { entry . request . url = host + entry . request . url ; } ) ; return har ; HARFile : getHARfile ( ) assert . isObject ( harvested . HARFile ) ; assert . isNumber ( tips . possibleCompressWithOnlyScriptGzip , 'possibleCompressWithOnlyScriptGzip should be a number' ) ; //console.log(harvested.rawFileDataSummary)", "commit_type": "use"}
{"commit_tokens": ["add", "opacity", "and", "alpha", "to", "be", "reflected", "on", "frame", "for", "both", "os"], "add_tokens": "var props = [ 'left' , 'top' , 'width' , 'height' , 'title' , 'state' , 'topmost' , 'showChrome' , 'resizable' , 'opacity' , 'alpha' ] ;", "del_tokens": "var props = [ 'left' , 'top' , 'width' , 'height' , 'title' , 'state' , 'topmost' , 'showChrome' , 'resizable' ] ; process . platform !== 'linux' && props . push ( 'alpha' ) ; process . platform !== 'win32' && props . push ( 'opacity' ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "of", "text", "node", "inserting"], "add_tokens": ": ( typeof move . item === 'object' ) ? move . item . render ( ) : document . createTextNode ( move . item )", "del_tokens": ": move . item . render ( )", "commit_type": "fix"}
{"commit_tokens": ["Added", "IE", "definition", "of", "%"], "add_tokens": "define ( 'escape(FILTER)[0]' , 'IE' ) , define ( null , 'ATOB' ) ,", "del_tokens": "define ( null , 'ATOB' )", "commit_type": "add"}
{"commit_tokens": ["improved", "Chatter", "added", "mode", "button", "need", "to", "make", "it", "work"], "add_tokens": "'ID' , 'Type' , 'Admin' , 'Stage' , 'Level' , 'Paused' , 'Last Error' // clientObj.sid || 'N/A',", "del_tokens": "'ID' , 'SID' , 'Type' , 'Admin' , 'Stage' , 'Level' , 'Paused' , 'Last Error' clientObj . sid || 'N/A' ,", "commit_type": "improve"}
{"commit_tokens": ["Added", "support", "for", "frozen", "trees", "and", "automatically", "freeze", "generated", "trees"], "add_tokens": "\"use strict\" expect ( baseState . aProp ) . toBe ( \"hi\" )", "del_tokens": "debugger expect ( baseState . aProp ) . toBe ( 'hi' ) describe ( \"readme example\" , ( ) => { it ( \"works\" , ( ) => { const baseState = [ { todo : \"Learn typescript\" , done : true } , { todo : \"Try immer\" , done : false } ] const nextState = immer ( baseState , state => { state . push ( { todo : \"Tweet about it\" } ) state [ 1 ] . done = true } ) // the new item is only added to the next state, // base state is unmodified expect ( baseState . length ) . toBe ( 2 ) expect ( nextState . length ) . toBe ( 3 ) // same for the changed 'done' prop expect ( baseState [ 1 ] . done ) . toBe ( false ) expect ( nextState [ 1 ] . done ) . toBe ( true ) // unchanged data is structurally shared expect ( nextState [ 0 ] ) . toBe ( baseState [ 0 ] ) // changed data not (dh) expect ( nextState [ 1 ] ) . not . toBe ( baseState [ 1 ] ) } ) } )", "commit_type": "add"}
{"commit_tokens": ["changed", "npm", "module", "phantomjs", "to", "phantomjs", "-", "prebuild"], "add_tokens": "phantomjs = require ( 'phantomjs-prebuilt' ) ,", "del_tokens": "phantomjs = require ( 'phantomjs' ) ,", "commit_type": "change"}
{"commit_tokens": ["Using", "somewhat", "more", "consistent", "version", "of", "flatten", "."], "add_tokens": "var idx = - 1 , len = list ? list . length : 0 , result = [ ] , push = result . push , val ; while ( ++ idx < len ) { val = list [ idx ] ; push . apply ( result , isArray ( val ) ? flatten ( val ) : [ val ] ) ; } return result ;", "del_tokens": "var h = head ( list ) , t = tail ( list ) ; return isEmpty ( list ) ? EMPTY : ( isAtom ( h ) ) ? prepend ( h , flatten ( t ) ) : merge ( flatten ( h ) , flatten ( t ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "beep", "-", "on", "-", "error", "an", "opt", "-", "in", "feature"], "add_tokens": "var beepOnError = ! ! process . env . GULP_BEEPONERROR ; if ( beepOnError && process . stdout && process . stdout . isTTY ) {", "del_tokens": "if ( process && process . stdout && process . stdout . isTTY ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "error", "on", "fresh", "repo", "existing", "remote", "branch"], "add_tokens": "execWrap ( 'git add -A .' ) ; execWrap ( 'git commit -m \"' + message + '\"' ) ; gitReset ( ) ;", "del_tokens": "execWrap ( 'git add -A . && git commit -m \"' + message + '\"' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "JSHint", "warnings", "in", "inspiration", "syntax", "file", "."], "add_tokens": "/* global db, select, update, Model, Manager, hasMany, belongsTo, w, f, User */ function dontRun ( ) { /* jshint unused:false */ qs = User . where ( '...' ) ; console . log ( query + transaction ) ; } if ( dontRun ) { }", "del_tokens": "/* global db, select, update, Model, Manager, hasMany, belongsTo, w, f */ ( function ( ) { 'use strict' ; var qs = User . where ( '...' ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "built", "-", "in", "JSON", ".", "parse"], "add_tokens": ", data : hash . data ? JSON . parse ( hash . data ) : { }", "del_tokens": ", data : hash . data ? ( new Function ( 'return' + hash . data ) ) ( ) : { }", "commit_type": "use"}
{"commit_tokens": ["Changed", "to", "gulp", "-", "protractor", "to", "handle", "errors", "better"], "add_tokens": "var protractor = require ( \"gulp-protractor\" ) . protractor ; gulp . task ( 'test-e2e' , [ 'serve-e2e' ] , function ( ) { return gulp . src ( [ './test/e2e/**/*.js' ] ) . pipe ( protractor ( { configFile : './protractor.conf.js' } ) ) . on ( 'error' , function ( e ) { browserSync . exit ( ) ; throw e ; } ) . on ( 'end' , function ( e ) { browserSync . exit ( ) ; } ) ;", "del_tokens": "var child_process = require ( 'child_process' ) ; gulp . task ( 'test-e2e' , [ 'serve-e2e' ] , function ( done ) { var protractor = path . resolve ( 'node_modules/.bin/protractor' ) ; child_process . spawn ( protractor , [ './protractor.conf.js' ] , { stdio : 'inherit' } ) . once ( 'close' , function ( code ) { browserSync . exit ( ) ; done ( ) ; } ) ;", "commit_type": "change"}
{"commit_tokens": ["updated", "readme", "for", "accesstoken", "doc"], "add_tokens": "auth = 'Bearer ' + auth . accessToken ;", "del_tokens": "auth = 'Bearer ' + auth . access_token ;", "commit_type": "update"}
{"commit_tokens": ["Added", "the", "#once", "method", "and", "options", "for", "#on"], "add_tokens": "assert . equal ( count , 0 ) ; count = 0 ; } ) ; it ( 'binding a function with \"once\" set to true should work only once' , function ( ) { e . once ( 'myEvent' , callback ) ; e . emit ( 'myEvent' ) ; assert . equal ( count , 1 ) ; e . emit ( 'myEvent' ) ; assert . equal ( count , 1 ) ; count = 0 ; it ( 'giving unrecognized parameters should throw an error' , function ( ) { var count = 0 , callback = function ( ) { count ++ ; } , e = new emitter ( ) ; assert . throws ( function ( ) { e . on ( 'myEvent' , callback , { blabla : 42 } ) } ) ; } ) ;", "del_tokens": "assert . strictEqual ( count , 3 ) ;", "commit_type": "add"}
{"commit_tokens": ["USe", "plugin", "-", "error", "to", "log", "instead", "gutil", ".", "log"], "add_tokens": "const PluginError = require ( 'plugin-error' ) ;", "del_tokens": "const gutil = require ( 'gulp-util' ) ; const PluginError = gutil . PluginError ;", "commit_type": "use"}
{"commit_tokens": ["added", "rate", "limits", "to", "socket", "message", "api"], "add_tokens": "// if(err || saved === 0) { if ( err ) {", "del_tokens": "if ( err || saved === 0 ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "FirefoxSymbolBugWorkaround", "after", "append", "too", ":", "only", "on", "Firefox"], "add_tokens": "if ( this . isFirefox ) { FirefoxSymbolBugWorkaround ( this . svg ) ; }", "del_tokens": "FirefoxSymbolBugWorkaround ( this . svg ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "defect", "causing", "autohost", "and", "autohost", "auth", "providers", "to", "load", "their", "own", "instances", "of", "passport", "by", "introducing", "initPassport", "on", "auth", "provider", "API", "."], "add_tokens": "bearerAuth , useSession ; initPassport : function ( passport ) { basicAuth = passport . authenticate ( 'basic' , { session : useSession } ) ; bearerAuth = passport . authenticate ( 'bearer' , { session : useSession } ) ; } , useSession = ! ( config == undefined ? false : config . noSession ) ;", "del_tokens": "bearerAuth ; var useSession = ! ( config == undefined ? false : config . noSession ) ; basicAuth = passport . authenticate ( 'basic' , { session : useSession } ) ; bearerAuth = passport . authenticate ( 'bearer' , { session : useSession } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "default", "value", "to", "datab", ".", "data", "constructor", "if", "no", "arg", "supplied"], "add_tokens": "* args : arr - a matrix ( 2 d - array ) with column headers if ( typeof ( matrix ) == \"undefined\" ) var matrix = [ [ ] ] ;", "del_tokens": "* args : arr - a matrix ( 2 d - array )", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "to", "the", "error", "description", "in", "case", "it", "is", "global"], "add_tokens": "var globalResponses = yamlJson . responses ; var responses = { } ; for ( var oneResponse in globalResponses ) { responses [ oneResponse . toLowerCase ( ) ] = { \"description\" : globalResponses [ oneResponse ] . description } ; } if ( ! isNaN ( code ) && code !== 200 && apiPath [ route ] [ oneMethod ] . responses [ errorCode ] . description ) { else { if ( ! isNaN ( code ) && code !== 200 ) { all_errors [ code ] = responses [ apiPath [ route ] [ oneMethod ] . responses [ errorCode ] [ '$ref' ] . split ( \"/\" ) [ 2 ] ] . description ; } }", "del_tokens": "if ( ! isNaN ( code ) && code !== 200 ) {", "commit_type": "add"}
{"commit_tokens": ["add", "HTTP", "error", "code", "for", "backward", "compat"], "add_tokens": "UNKNOWN : 0 , HTTP : 8000 0 : 'Unknown Error' , 8000 : 'Http Error'", "del_tokens": "UNKNOWN : 0 0 : 'Unknown Error' // TODO: ... common error classes", "commit_type": "add"}
{"commit_tokens": ["Use", ".", "exec", "()", "instead", "of", ".", "matchAll", "()", "when", "searching", "for", "GLIBC"], "add_tokens": "const glibcPattern = / \\bGLIBC_([0-9.]+)\\b / g ; let maxVersion = null ; let match ; while ( match = glibcPattern . exec ( output ) ) { const thisVersion = version . parse ( match [ 1 ] ) ; if ( ! maxVersion || version . greater ( thisVersion , maxVersion ) ) { maxVersion = thisVersion ; } return maxVersion ;", "del_tokens": "const glibcPattern = / \\bGLIBC_([0-9.]+)\\b / gm ; const versions = output . matchAll ( glibcPattern ) . map ( match => version . parse ( match [ 1 ] ) ) ; if ( versions . length > 0 ) { return versions . reduce ( version . max ) ; } else { return null ;", "commit_type": "use"}
{"commit_tokens": ["Update", "meyda", "-", "wa", ".", "js"], "add_tokens": "self . setSource ( options . source ) ; this . spn = self . audioContext . createScriptProcessor ( self . bufferSize , 1 , 1 ) ; this . spn . connect ( self . audioContext . destination ) ; this . spn . onaudioprocess = function ( e ) {", "del_tokens": "self . setSource ( options . source ) ; self . spn = self . audioContext . createScriptProcessor ( self . bufferSize , 1 , 1 ) ; self . spn . connect ( self . audioContext . destination ) ; self . spn . onaudioprocess = function ( e ) {", "commit_type": "update"}
{"commit_tokens": ["Improve", "cross", "-", "origin", "checking"], "add_tokens": "if ( options . checkImageOrigin && isCrossOriginURL ( url ) ) { crossOrigin = ' crossOrigin' ; // crossOrigin=\"anonymous\" if ( ! $this . prop ( 'crossOrigin' ) ) { // Only when there was not a \"crossOrigin\" property", "del_tokens": "if ( options . checkImageOrigin ) { if ( isCrossOriginURL ( url ) ) { crossOrigin = ' crossOrigin' ; // crossOrigin=\"anonymous\"", "commit_type": "improve"}
{"commit_tokens": ["Add", "skip", "to", "progressions", ".", "js"], "add_tokens": "* / function skip ( roman_numeral , skipi ) { if ( skipi == null ) { skipi = 1 ; } var i = numerals . indexOf ( roman_numeral ) + skipi ; console . log ( i ) return numerals [ i % 7 ] ; } exports . tuple_to_string = tuple_to_string ; exports . skip = skip ;", "del_tokens": "def skip ( roman_numeral , skip = 1 ) : \"\" \" { { { >>> progressions . skip ( \"I\" ) 'II' >>> progressions . skip ( \"VII\" ) 'I' >>> progressions . skip ( \"I\" , 2 ) 'III' } } } \"\" \" i = numerals . index ( roman_numeral ) + skip return numerals [ i % 7 ] * / exports . tuple_to_string = tuple_to_string ;", "commit_type": "add"}
{"commit_tokens": ["add", "a", "deprecation", "jsdoc", "to", "the", "ParseError", "object"], "add_tokens": "/ ** * @ deprecated since Kuzzle 1.4 .1 , BadRequestError should be used instead * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "unlink", "."], "add_tokens": "var _unlink = decorate ( process . binding ( \"fs\" ) . unlink )", "del_tokens": "var _unlink = decorate ( process . binding ( \"fs\" ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "format", "/", "aap", ":", "Impl", "code", "parsing"], "add_tokens": "this . code = [ new MBR . Code ( value , 0 , 0x1AB ) ]", "del_tokens": "// TODO: Parse out code", "commit_type": "update"}
{"commit_tokens": ["Add", "default", "flexShrink", "for", "Avatar"], "add_tokens": "< Avatar name = { profile . name } / >", "del_tokens": "< Avatar name = { profile . name } flexShrink = { 0 } / >", "commit_type": "add"}
{"commit_tokens": ["updating", "path", "to", "match", "gh", "-", "pages", "branch", "commit"], "add_tokens": "wrench . copyDirSyncRecursive ( './sdk/docs' , '../gh-pages/sdk/docs' ) ;", "del_tokens": "wrench . copyDirSyncRecursive ( './sdk/docs' , '../gh-pages/sdk' ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "placeholder", "image", "bump", "version"], "add_tokens": "version : '0.4.5' ,", "del_tokens": "version : '0.4.4' ,", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "MultiPoint", "coordinates", "encapsulated", "in", "parentheses"], "add_tokens": "var newCoordsFormat = _ . substring ( _ . indexOf ( '(' ) + 1 , _ . length - 1 ) . replace ( / \\( / g , '' ) . replace ( / \\) / g , '' ) ; _ = 'MULTIPOINT (' + newCoordsFormat + ')' ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "feature", "to", "send", "event", "parameters", "to", "api", ".", "ai", "nlp", "provider"], "add_tokens": "let eventParam = { let eventOpts = { } ; if ( eventData . params ) { eventParam . data = eventData . params ; } let request = this . apiai . apiaiService . eventRequest ( eventParam , eventOpts ) ; if ( eventData . params ) { response . eventParams = eventData . params ; }", "del_tokens": "let requestOpts = { if ( eventData . params ) { requestOpts . data = eventData . params ; } let request = this . apiai . apiaiService . eventRequest ( requestOpts , { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "option", "to", "provide", "your", "own", "mpv", "binary", "file", "in", "case", "that", "mpv", "is", "not", "in", "/", "usr", "/", "local", "/", "bin", ":", "/", "usr", "/", "bin", ":", "/", "bin", ":", "/", "usr", "/", "sbin", ":", "/", "sbin"], "add_tokens": "\"time_update\" : 1 , \"binary\" : null // default Arguments // user the user provied binary if ( options . binary ) { this . mpvPlayer = spawn ( options . binary , defaultArgs ) ; } // use the binary found (or not) in $PATH else { this . mpvPlayer = spawn ( 'mpv' , defaultArgs ) ; } // restart the mpv instance if ( options . binary ) { this . mpvPlayer = spawn ( options . binary , defaultArgs ) ; } else { this . mpvPlayer = spawn ( 'mpv' , defaultArgs ) ; } console . log ( error ) ; } // add all the other modules using lodash", "del_tokens": "\"time_update\" : 1 // default Arguments this . mpvPlayer = spawn ( 'mpv' , defaultArgs ) ; this . mpvPlayer = spawn ( 'mpv' , defaultArgs ) ; console . log ( error ) ; } // add all the other modules using lodash", "commit_type": "add"}
{"commit_tokens": ["Allow", "encoding", "arrays", "/", "buffers", "to", "XDR", "string", "type"], "add_tokens": "import isArray from \"lodash/isArray\" ; return result . buffer ( ) ; } readString ( io ) { return this . read ( io ) . toString ( 'utf8' ) ; let buffer ; if ( isString ( value ) ) { buffer = Buffer . from ( value , 'utf8' ) ; } else { buffer = Buffer . from ( value ) ; let buffer ; if ( isString ( value ) ) { buffer = Buffer . from ( value , 'utf8' ) ; } else if ( isArray ( value ) || Buffer . isBuffer ( value ) ) { buffer = Buffer . from ( value ) ; } else {", "del_tokens": "return result . buffer ( ) . toString ( 'utf8' ) ; if ( ! isString ( value ) ) { throw new Error ( ` ${ value } ` ) ; let buffer = Buffer . from ( value , 'utf8' ) ; if ( ! isString ( value ) ) { let buffer = Buffer . from ( value , 'utf8' ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "tree", "walker", "(", "does", "not", "recurse", "yet", ")"], "add_tokens": "console . log ( \"loading: \" + hash ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "relative", "paths", "in", "includes", ".", "still", "limited"], "add_tokens": "function buildPathFromRelativePath ( cdir , fdir ) { var dir = cdir . split ( '\\\\' ) ; dir . pop ( ) ; fdir . split ( '\\\\' ) . map ( function ( e ) { ( e === '..' ) ? dir . pop ( ) : ( e !== '.' && e !== '' ) ? dir . push ( e ) : void 0 ; } ) ; return dir . join ( '\\\\' ) ; } fpath = \"\" , fpath = buildPathFromRelativePath ( file . path , filename ) ; if ( wrapFiles [ fpath ] ) { processClip ( wrapFiles [ fpath ] ) ; topWrap = wrapFiles [ fpath ] . content ; filename = buildPathFromRelativePath ( file . path , filename ) ; wrapFiles [ f . path ] = f ; insertFiles [ f . path ] = f ;", "del_tokens": "if ( wrapFiles [ filename ] ) { processClip ( wrapFiles [ filename ] ) ; topWrap = wrapFiles [ filename ] . content ; wrapFiles [ f . name ] = f ; insertFiles [ f . name ] = f ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "pre", "-", "installed", "dependencies", "so", "you", "can", "use", "with", "either", "BLE", "or", "Bluetooth", "Classic"], "add_tokens": "\"It looks like you want to connect to a BB-8 or Ollie\" , \"but did not install noble.\" , \"To install it run this command:\" , \"'npm install noble'\" , \"or for more information go to https://github.com/sandeepmistry/noble\"", "del_tokens": "\"It looks like noble didn't install properly.\" , \"For more information, please go to:\" , \"https://github.com/sandeepmistry/noble\"", "commit_type": "remove"}
{"commit_tokens": ["Allow", "string", "id", "for", "element"], "add_tokens": "function setElement ( element , data , opts , callback ) { if ( typeof element === \"string\" ) { element = document . getElementById ( element ) ; } fetchDataSource ( element , data , opts || { } , callback ) ; } setElement ( element , dataSource , opts , processLineData ) ; setElement ( element , dataSource , opts , processColumnData ) ; setElement ( element , dataSource , opts , processPieData ) ;", "del_tokens": "fetchDataSource ( element , dataSource , opts || { } , processLineData ) ; fetchDataSource ( element , dataSource , opts || { } , processColumnData ) ; fetchDataSource ( element , dataSource , opts || { } , processPieData ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "check", "for", "non", "null", "datum"], "add_tokens": "if ( datum && datum . features ) {", "del_tokens": "if ( datum . features ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "trigger", "an", "event", "when", "an", "image", "is", "loaded"], "add_tokens": "var cornerstone = ( function ( $ , cornerstone ) { // broadcast an image loaded event once the image is loaded // This is based on the idea here: http://stackoverflow.com/questions/3279809/global-custom-events-in-jquery imagePromise . then ( function ( image ) { $ ( cornerstone ) . trigger ( 'cornerstoneImageLoaded' , image ) ; } ) ; } ( $ , cornerstone ) ) ;", "del_tokens": "var cornerstone = ( function ( cornerstone ) { } ( cornerstone ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "redux", "-", "api", "-", "middleware", "since", "it", "breaks", "the", "node", "resolving"], "add_tokens": "export default [ thunk ] ;", "del_tokens": "import { apiMiddleware } from 'redux-api-middleware' ; export default [ thunk , apiMiddleware ] ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "tests", "for", "QUnit", "2"], "add_tokens": "assert . expect ( 3 ) ;", "del_tokens": "QUnit . expect ( 3 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "regex", "for", "rewriting", "requires", "based", "on", "the", "package", "lib"], "add_tokens": "var escapeRegExpPattern = / [-\\[\\]\\/\\{\\}\\(\\)\\*\\+\\?\\.\\\\\\^\\$\\|] / g ; function escapeRegExp ( str ) { return str . replace ( escapeRegExpPattern , \"\\\\$&\" ) ; } , tmpVar , regex tmpVar = path . normalize ( pkg . moduleRoot + '/' + leaf . filepath ) . substring ( 0 , pkg . moduleRoot . length ) ; if ( tmpVar === pkg . moduleRoot ) { regex = new RegExp ( '(^|\\/)' + escapeRegExp ( path . normalize ( pkg . lib ) + '/' ) ) ; modulepath = pkg . name + '/' + leaf . filepath . replace ( regex , function ( $ ) { return $ [ 0 ] ; } ) ; } else { modulepath = pkg . name + '/' + leaf . filepath ; }", "del_tokens": "// TODO be a little more robust with lib removal // lib/blah -> blah // XXX hilib/blah -> hiblah // XXX lib/ -> (assume pkg.name) modulepath = pkg . name + '/' + leaf . filepath . replace ( path . normalize ( pkg . lib ) + '/' , '' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "quicksort", "example", ".", "Several", "minor", "new", "Ramda", "functions", "still", "need", "documentation", "and", "tests", "."], "add_tokens": "var clone = R . clone = function ( list ) { R . lt = _ ( function ( a , b ) { return a < b ; } ) ; R . lte = _ ( function ( a , b ) { return a <= b ; } ) ; R . gt = _ ( function ( a , b ) { return a > b ; } ) ; R . gte = _ ( function ( a , b ) { return a >= b ; } ) ;", "del_tokens": "var clone = function ( list ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "various", "issues", "with", "different", "color", "formats"], "add_tokens": "* Decoding of chunk data after scaling * Phase 3 * @ method postDecode postDecode : function ( image , strict ) { outputStream = new BufferedStream ( image , false ) ; // use same buffer outputStream . writeOffset = 0 ; for ( i = 0 , len = image . length ; i < len ; i += 4 ) { imageStream . skip ( 3 ) ; // Skip the next three bytes outputStream . writeUInt8 ( 255 ) ;", "del_tokens": "* Decoding of chunk data before scaling * Phase 2 * @ method decode decode : function ( image , strict ) { //TODO: May be give an option for using these suggested colors? outputStream = new BufferedStream ( null , null , image . length * 4 ) ; for ( i = 0 , len = image . length ; i < len ; i ++ ) { color . alpha = color . alpha || 255 ; // Opaque by default outputStream . writeUInt8 ( color . alpha ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "build", "errors", "after", "merge", "with", "docs", "branch"], "add_tokens": "input : opts . entry , name : config . fullname , sourcemap : true , sourcemapFile : dest ,", "del_tokens": "entry : opts . entry , moduleName : config . fullname , sourceMap : true , sourceMapFile : dest ,", "commit_type": "fix"}
{"commit_tokens": ["Made", "it", "so", "the", "same", "fact", "is", "asserted", "with", "a", "new", "recency"], "add_tokens": "var f = this . retract ( fact ) ; return this . assert ( f ) ; f = this . __assertFact ( f ) ; f = this . __retractFact ( f ) ; return wmFact ; return wmFact ;", "del_tokens": "this . retract ( fact ) ; return this . assert ( fact ) ; this . __assertFact ( f ) ; this . __retractFact ( f ) ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "referencing", "to", "a", "separate", "content", "file", ";", "Allow", "defining", "markdown", "options"], "add_tokens": "gutil . log ( 'Using configuration in ' , configFile ) ; target = require ( configFile ) ; target . configFile = configFile ; var marked = require ( 'marked' ) ; marked . setOptions ( target . markdown ) ; . pipe ( markdown ( target . markdown ) ) if ( input . contentFromFile ) { input . content = fs . readFileSync ( input . contentFromFile ) . toString ( ) ; if ( ! input . content ) { throw new gutil . PluginError ( 'menu' , 'Invalid contentFromFile reference ' + input . contentFromFile ) ; } else { input . content = marked ( input . content ) ; } }", "del_tokens": "target = require ( './' + configFile ) ; target . configFile = './' + configFile ; gutil . log ( 'Using configuration in ' , target . configFile ) ; . pipe ( markdown ( { } ) ) //delete input.content;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "out", "of", "buffer", "s", "boundary", "error", "for", "ND", "Command", "with", "data"], "add_tokens": "if ( reader . buf . length > reader . tell ( ) ) { frame . remoteParent16 = reader . nextString ( 2 , 'hex' ) ; frame . deviceType = reader . nextUInt8 ( ) ; frame . sourceEvent = reader . nextUInt8 ( ) ; frame . digiProfileID = reader . nextString ( 2 , 'hex' ) ; frame . digiManufacturerID = reader . nextString ( 2 , 'hex' ) ; }", "del_tokens": "frame . remoteParent16 = reader . nextString ( 2 , 'hex' ) ; frame . deviceType = reader . nextUInt8 ( ) ; frame . sourceEvent = reader . nextUInt8 ( ) ; frame . digiProfileID = reader . nextString ( 2 , 'hex' ) ; frame . digiManufacturerID = reader . nextString ( 2 , 'hex' ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "reload", "port", "&", "notify", "port", "options", "to", "the", "monitor", "cli"], "add_tokens": ". usage ( 'Usage: $0 monitor [--help|-h] [--reload-port|-rp] [--hostname|-hn] [--show-notification|-n] <bundle-path>' ) . alias ( 'a' , 'hostname' ) . describe ( 'a' , 'hostname' ) . alias ( 'r' , 'reload-port' ) . describe ( 'r' , 'Reloading port that listens new WebSocket clients (browsers)' ) . alias ( 'y' , 'notify-port' ) . describe ( 'y' , 'Notification HTTP port (see \"listen\" command) that triggers reloading event' ) require ( '../lib/server/monitor' ) ( monitor . _ [ 1 ] , { displayNotification : ! ! monitor . n , port : monitor . r , notifyPort : monitor . y , hostname : monitor . a } )", "del_tokens": ". usage ( 'Usage: $0 monitor [--help|-h] [--show-notification|-n] <bundle-path>' ) require ( '../lib/server/monitor' ) ( monitor . _ [ 1 ] , { displayNotification : ! ! monitor . n } )", "commit_type": "add"}
{"commit_tokens": ["adds", "a", "DataSource#feed", "method", "with", "pending", "test", "for", "now"], "add_tokens": "describe . skip ( '.feed' , function ( ) { it ( 'should return a successful response' , function ( ) { return NS1 . DataSource . find ( data_source_obj . id ) . then ( ( data_source ) => { return data_source . feed ( { \"test_name\" : { \"default\" : null , \"required\" : true , \"validator\" : \"text\" , \"shortdesc\" : \"Test Name\" , \"type\" : \"text\" , \"desc\" : \"The name of the test in Monitor.us that corresponds to this feed\" } } ) . then ( ( response ) => { expect ( response ) . to . eq ( '' ) } ) } ) } ) } )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "use", "of", "promise", "factory", "."], "add_tokens": "var EyesUtils = require ( 'eyes.utils' ) , PromiseFactory = EyesUtils . PromiseFactory ; ViewportSize . setPromiseFactory ( PromiseFactory ) ; * @ constructor EyesBase . call ( this , PromiseFactory , serverUrl || EyesBase . DEFAULT_EYES_SERVER , isDisabled ) ; return 'eyes-protractor/0.0.22' ;", "del_tokens": "PromiseFactory = EyesSDK . EyesPromiseFactory , var EyesUtils = require ( 'eyes.utils' ) ; * * C ' * EyesBase . call ( this , serverUrl || EyesBase . DEFAULT_EYES_SERVER , isDisabled ) ; return 'eyes-protractor/0.0.20' ;", "commit_type": "update"}
{"commit_tokens": ["add", "selected", "rows", "callback", "feature"], "add_tokens": "} , { name : 'Selected rows callback' , codepen : 'OMvbMj' 'exampleApp11' , 'exampleApp12'", "del_tokens": "'exampleApp11'", "commit_type": "add"}
{"commit_tokens": ["Adding", "form", "validation", "on", "model", "update"], "add_tokens": "onSubmit , mapValues ( validators , ( validator , field ) => { if ( onSubmit && ! ! valid ) { componentDidUpdate ( prevProps ) { const { validators , model , dispatch } = this . props ; mapValues ( validators , ( validator , field ) => { const fieldModel = [ model , field ] . join ( '.' ) ; const value = _get ( this . props , fieldModel ) ; if ( value === _get ( prevProps , fieldModel ) ) return ; const validity = validate ( validator , value ) ; dispatch ( actions . setValidity ( fieldModel , validate ( validator , value ) ) ) ; } ) ; }", "del_tokens": "onSubmit = identity , Object . keys ( validators ) . forEach ( ( field ) => { const validator = validators [ field ] ; if ( ! valid ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "OS", "differences", "in", "Watcher"], "add_tokens": "* Version 0.1 .1 Nathan @ master - technology . com var cmd = 'adb shell ps | grep ' + projectData . nativescript . id ; if ( os . type ( ) === \"Windows_NT\" ) { cmd = 'adb shell ps ^| grep ' + projectData . nativescript . id ; } cp . exec ( cmd , function ( err , stdout ) {", "del_tokens": "* Version 0.1 .0 Nathan @ master - technology . com cp . exec ( 'adb shell ps ^| grep ' + projectData . nativescript . id , function ( err , stdout ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "TopicNotAvailableError", "context"], "add_tokens": "availableTopics : this . availableTopics ,", "del_tokens": "availableTopics : this . availaleTopics ,", "commit_type": "fix"}
{"commit_tokens": ["removed", "floorFilter", "and", "replaced", "with", "example", "page", "splitting", "logic", "specific", "only", "to", "examples", ".", "js"], "add_tokens": "var splitIndex = Math . floor ( appConfig . examplePages . length / 2 ) ; $scope . examplePageColumns = { left : appConfig . examplePages . slice ( 0 , splitIndex ) , right : appConfig . examplePages . slice ( splitIndex ) } ;", "del_tokens": "$scope . examplePages = appConfig . examplePages ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "browser", "-", "locale", "to", "determine", "current", "browser", "language"], "add_tokens": "import browserLocale from 'browser-locale' ; / ** * Gets the current browser ' * See browser - locale ( https : //github.com/maxogden/browser-locale) for more info. * * @ return { string } Current browser language * / // Ignore error as we may have more exports in the future // eslint-disable-next-line import/prefer-default-export export function getBrowserLang ( ) { return browserLocale ( ) ;", "del_tokens": "export function getLang ( ) { // this is just for testing, as changing the navigator.language wasn't possible // return 'fr'; return navigator . languages ? navigator . languages [ 0 ] : ( navigator . language || navigator . userLanguage ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "gulpfile", ".", "js", "and", "bower", ".", "json"], "add_tokens": "reloadOnRestart : false , open : \"local\" , online : false", "del_tokens": "reloadOnRestart : false", "commit_type": "update"}
{"commit_tokens": ["Adding", "real", "-", "time", "to", "canonical", "order", "list", "fixes", "issues", "with", "sorting"], "add_tokens": "\"data/worker\" , \"real-time\" ,", "del_tokens": "\"data/worker\" ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "specify", "base", "branch", "to", "filter", "pull", "requests", "-", "master", "by", "default"], "add_tokens": ". option ( '-b, --base-branch <name>' , '[optional] specify the base branch name - master by default' ) const base = program . baseBranch || 'master' ; return await github . pullRequests . getAll ( { base , owner , page , per_page : 100 , repo , state : 'closed' } ) ;", "del_tokens": "return await github . pullRequests . getAll ( { owner , page , per_page : 100 , repo , state : 'closed' } ) ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "column", "-", "to", "-", "object", "to", "steps"], "add_tokens": "var isNullable = require ( '../util/is-nullable' ) ;", "del_tokens": "var isNullable = require ( './is-nullable' ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "race", "condition", "if", "model", "had", ">", "1", "many", "to", "many", "associations", "to", "save"], "add_tokens": "* Model . save ( ) will still need to be called to actually make the association to persist * @ return { undefined } nothing to return", "del_tokens": "const Promise = require ( 'bluebird' ) ; * @ return { Promise [ null ] } a promise resolving to null if relationship was updated successfully return new Promise ( ( resolve , reject ) => { recordToUpdate . save ( ( err ) => { if ( err ) { return reject ( err ) ; } return resolve ( null ) ; } ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "more", "codeacy", "flagged", "issues"], "add_tokens": "// The node has received an input as part of a flow, need to determine // what the request is for, and based on that if the required fields //have been provided. // These are var functions that have been initialised here, so that // they are available for the instance of this node to use. // Tried to make these protoypes, but couldn't get them to be // If a translation is requested, then the model id will have been // built by the calling function based on source, target and domain. } ) ; var doTrain = function ( msg , model_id , filetype ) { params . base_model_id = model_id ; function ( err ) { if ( domain !== 'news' ) {", "del_tokens": "// The node has received an input as part of a flow, need to determine what the request // is for, and based on that if the required fields have been provided. // These are var functions that have been initialised here, so that they are available for the // instance of this node to use. Tried to make these protoypes, but couldn't get them to be // If a translation is requested, then the model id will have been built by the calling // function based on source, target and domain. } ) ; var doTrain = function ( msg , model_id ) { params . base_model_id = basemodel ; function ( err , model ) { if ( domain != \"news\" ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "better", "handling", "of", "errors", "and", "lint", "messages"], "add_tokens": "* @ version 0.3 .2", "del_tokens": "* @ version 0.2 .0", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "port", "number", "to", "the", "utils", ".", "js", "file", "so", "that", "it", "gets", "printed", "."], "add_tokens": "data = ljm . LJM_OpenS ( 'LJM_dtT7' , 'LJM_ctUDP' , 'LJM_idANY' , 0 ) ;", "del_tokens": "data = ljm . LJM_OpenS ( 'LJM_dtT7' , 'LJM_ctEthernet' , 'LJM_idANY' , 0 ) ; // console.log('openAllData', openAllData); // console.log('openAllData', openAllData);", "commit_type": "add"}
{"commit_tokens": ["fix", "painting", "problem", "padding", "+", "border_size", "box", "model"], "add_tokens": "pkg . getTopParent = function ( c ) { function getTop ( ) { return 0 ; } , function getLeft ( ) { return 0 ; } , function getBottom ( ) { return 0 ; } , function getRight ( ) { return 0 ; } ,", "del_tokens": "pkg . getTop = function ( c ) { function getTop ( ) { return 0 ; } , function getLeft ( ) { return 0 ; } , function getBottom ( ) { return 0 ; } , function getRight ( ) { return 0 ; } ,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "promise", "-", "control", "-", "flow"], "add_tokens": "const flow = require ( './flow.js' ) setTimeout ( ( ) => resolve ( callback ( ) ) , ms || 0 )", "del_tokens": "const flow = require ( 'promise-control-flow' ) if ( ! ms ) { return resolve ( callback ( ) ) } setTimeout ( ( ) => resolve ( callback ( ) ) , ms )", "commit_type": "remove"}
{"commit_tokens": ["Improve", "Bucket#toString", "and", "its", "tests"], "add_tokens": "Bucket . prototype . toString = function ( ) { var res = '<( ' ; res += this . _store [ i ] . id . toString ( true ) + ' ' ; if ( this . length < this . _capacity ) res += ':' + ( this . _capacity - this . length ) + ': ' ; res += ')>' ; Object . defineProperty ( Bucket . prototype , 'length' , { module . exports = Bucket ;", "del_tokens": "Bucket . prototype . toString = function ( indent ) { if ( typeof indent === 'undefined' ) indent = 0 ; var res = 'Bucket (' + this . size + '/' + this . _capacity + ')\\n' ; res += new Array ( indent ) . join ( ' ' ) + this . _store [ i ] . id . toString ( ) + '\\n' ; Object . defineProperty ( Bucket . prototype , 'size' , { module . exports = Bucket", "commit_type": "improve"}
{"commit_tokens": ["Use", "dates", ".", "eq", "instead", "of", "comparing", "date", ".", "getTime", "()"], "add_tokens": "let padding = range . findIndex ( x => dates . eq ( x , start , 'day' ) ) ;", "del_tokens": "let padding = range . findIndex ( x => x . getTime ( ) === start . getTime ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "summary", "option", "for", "concise", "console", "output"], "add_tokens": "if ( ! argv . summary ) { console . log ( ` ${ index } ${ expected [ index ] } ${ predicted [ index ] } ` ) ; } ( correct / predicted . length ) *", "del_tokens": "console . log ( ` ${ index } ${ expected [ index ] } ${ predicted [ index ] } ` ) ; correct / predicted . length *", "commit_type": "add"}
{"commit_tokens": ["update", "log", "info", "add", "file", "path"], "add_tokens": "delete config . __source ; if ( section . __source ) { console . log ( \"Settings \" + JSON . stringify ( settings , null ) + \" of \" + section . __source + \" being merged into \" + this . settings [ key ] . __source ) ; } else { console . log ( \"section for \" + settings + \" was merged\" ) ; }", "del_tokens": "console . log ( settings + \" has been specified multiple times.\" ) ; console . log ( \"Merging config:\" ) ; console . log ( section ) ; console . log ( \"to:\" ) ; console . log ( this . settings [ key ] ) ;", "commit_type": "update"}
{"commit_tokens": ["Update", "addRouterParams", "to", "include", "match", ".", "params", "for", "v4"], "add_tokens": "Object . assign ( result , props . params , props . match && props . match . params ) ;", "del_tokens": "Object . assign ( result , props . params ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "helloworld", ".", "js", "to", "bootstrap", "devs"], "add_tokens": "message : \"Congrats, your Cisco Spark bot is up and running\" , tip : \"Don't forget to create WebHooks to start receiving events from Cisco Spark: https://developer.ciscospark.com/endpoint-webhooks-post.html\" , commands : Object . keys ( self . router . commands )", "del_tokens": "message : \"Congrats, your Cisco Spark webhook is up and running\" , commands : Object . keys ( self . router . commands ) , tip : \"Register your bot as a WebHook to start receiving events: https://developer.ciscospark.com/endpoint-webhooks-post.html\"", "commit_type": "add"}
{"commit_tokens": ["use", "nodeChildren", "option", "when", "determining", "relationship"], "add_tokens": "buildHierarchy ( $chart , opts . ajaxURL ? data : attachRel ( data , '00' , opts ) , 0 , opts ) ; buildHierarchy ( $chart , opts . ajaxURL ? data : attachRel ( data , '00' , opts ) , 0 , opts ) ; function attachRel ( data , flags , opts ) { var children = data [ opts . nodeChildren ] data . relationship = flags + ( children && children . length > 0 ? 1 : 0 ) ; if ( children ) { children . forEach ( function ( item ) { attachRel ( item , '1' + ( children . length > 1 ? 1 : 0 ) , opts ) ;", "del_tokens": "buildHierarchy ( $chart , opts . ajaxURL ? data : attachRel ( data , '00' ) , 0 , opts ) ; buildHierarchy ( $chart , opts . ajaxURL ? data : attachRel ( data , '00' ) , 0 , opts ) ; function attachRel ( data , flags ) { data . relationship = flags + ( data . children ? 1 : 0 ) ; if ( data . children ) { data . children . forEach ( function ( item ) { attachRel ( item , '1' + ( data . children . length > 1 ? 1 : 0 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "sdcClients", ".", "setLogLevel", "()"], "add_tokens": "var log = require ( 'restify' ) . log ; CAPI : CAPI , / ** * Sets the log level . * * @ param { String } the level . Can be one of these : * \"trace\" \"debug\" \"info\" \"warn\" \"error\" \"fatal\" \"off\" * / setLogLevel : function ( level ) { // Set uppercase var upper = level . replace ( / \\b(.)(.*) / , function ( m , first , rest ) { return first . toUpperCase ( ) + rest . toLowerCase ( ) ; } ) ; var l = log . Level [ upper ] ; if ( ! l ) { throw new Error ( \"Unknown log level. Try one of these \" + JSON . stringify ( log . Level ) ) ; } log . level ( l ) ; }", "del_tokens": "CAPI : CAPI", "commit_type": "add"}
{"commit_tokens": ["Fix", "path", "for", "require", "call", "."], "add_tokens": "var packageInfo = require ( '../../package.json' ) ,", "del_tokens": "var packageInfo = require ( '../package.json' ) ,", "commit_type": "fix"}
{"commit_tokens": ["add", "token", "support", "+", "docs"], "add_tokens": "keystone . set ( 'resty auth type' , restyStone . AUTH_TYPE . SESSION ) ; // keep KeystoneJS cookie based session for auth (use in dev only!)", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["update", "gulp", "file", "and", "read", "me"], "add_tokens": "} ) ;", "del_tokens": "var tsc = require ( 'gulp-tsc' ) ; var paths = { src : 'src/**/*.ts' , dest : 'lib/' } ; var tscopts = { out : 'index.js' , module : 'commonjs' , declaration : true , sourcemap : true } ; gulp . task ( 'compile' , function ( ) { return gulp . src ( paths . src ) . pipe ( tsc ( tscopts ) ) . pipe ( gulp . dest ( paths . dest ) ) ; } ) ; } ) ; gulp . task ( 'default' , [ 'compile' ] ) ;", "commit_type": "update"}
{"commit_tokens": ["Updated", "all", "related", "files", "for", "KVO", "update"], "add_tokens": "if ( this . observers === undefined ) { if ( this . observers [ key ] === undefined ) {", "del_tokens": "if ( this . observers === null ) { if ( this . observers [ key ] === null ) {", "commit_type": "update"}
{"commit_tokens": ["changed", "tests", "to", "not", "use", "proxyquire"], "add_tokens": "const checkSystem = require ( './checkSystem' ) ; checkSystem ( './notarealpackage.json' ) . then ( ( result ) => { let mf = new MockFile ( 'testPackage.json' , { foo : 'bar' } ) ; checkSystem ( mf . path ) . then ( ( result ) => { t . equal ( result . status , - 1 ) ; mf . delete ( ) ; mf = undefined ; t . end ( ) ; } ) ; t . test ( 'passes when engines key exists' , ( t ) => { let mf = new MockFile ( 'testPackage2.json' , { engines : { node : '5.10.1' } } ) ; t . equal ( result . status , 0 ) ;", "del_tokens": "const proxyquire = require ( 'proxyquire' ) ; function setupChecker ( mocks ) { return proxyquire ( './checkSystem' , mocks ) ; } const checkSystem = setupChecker ( { fs : { accessSync : ( ) => { throw 'File not found!' ; } } } ) ; checkSystem ( ) . then ( ( result ) => { const checkSystem = setupChecker ( { fs : { accessSync : ( ) => 0 } let mf = new MockFile ( './testPackage.json' , { } ) ; t . equal ( result . status , - 1 ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "issue", "with", "overlay", "not", "staying", "synced", "with", "canvas"], "add_tokens": "overlay . style . top = ( ( canvas . getBoundingClientRect ( ) . top + window . scrollY ) / SCALE ) + 'px' ; overlay . style . marginTop = ( ( ( ( overlayHeight - viewport . height ) / SCALE ) / 2 ) * - 1 ) + 'px' ; scale = parseFloat ( scale , 10 ) ; rotate = parseInt ( rotate , 10 ) ;", "del_tokens": "overlay . style . top = ( parseInt ( getComputedStyle ( overlay ) . top , 10 ) / SCALE ) + 'px' ; overlay . style . marginTop = ( ( ( overlayHeight - viewport . height ) / 2 ) * - 1 ) + 'px' ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "get", "/", "set", "/", "save", "/", "load", "transforms", "and", "filled", "in", "comments"], "add_tokens": "ezobjects . createObject ( { className : 'DatabaseRecord' , { name : 'id' , type : 'number' , setTransform : x => parseInt ( x ) } ezobjects . createObject ( { className : 'Person' , { name : 'checkingBalance' , type : 'number' , setTransform : x => parseFloat ( x ) } ,", "del_tokens": "ezobjects ( { name : 'DatabaseRecord' , { name : 'id' , type : 'int' } ezobjects ( { name : 'Person' , { name : 'checkingBalance' , type : 'float' } ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "template", "processing", "setting"], "add_tokens": "/ ** * Are template files watched ? * * @ type { Boolean } * / let areTemplateFilesWatched = false ; if ( ! areTemplateFilesWatched ) { // Watch or Hot mode if ( process . argv . includes ( '--watch' ) || process . argv . includes ( '--hot' ) ) { if ( Config . tpl . hasOwnProperty ( template ) ) { watchFile ( template , processTemplates ) ; } }", "del_tokens": "switch ( true ) { // Watch mode case process . argv . includes ( '--watch' ) : // Watch manifest file watchFile ( Mix . manifest . path ( ) , processTemplates ) ; // Watch or Hot mode (no break, falls through) case process . argv . includes ( '--hot' ) : watchFile ( template , processTemplates ) ; break ; // Default default : break ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "handling", "childProcess", ".", "exec", "callback"], "add_tokens": "process . nextTick ( function ( ) { cb ( null , 'stdout' , 'stderr' ) } ) ;", "del_tokens": "process . nextTick ( cb ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "use", "of", ".", "every", "."], "add_tokens": "var allVerified = true ; for ( var i = 0 ; i < results . length ; i ++ ) { if ( ! results [ i ] . verified ) { allVerified = false ; break ; } } signatureMap . verified = allVerified ;", "del_tokens": "signatureMap . verified = results . every ( r => r . verified ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "which", "setting", "the", "cornerRadius", "property", "with", "$", ".", "jCanvas", "would", "not", "work"], "add_tokens": "cornerRadius : 0 , if ( params . cornerRadius ) {", "del_tokens": "cornerRadius : 3 , if ( args . cornerRadius > 0 || params . rounded === true ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "boolean", "and", "case", "attributes", "handling", "in", "custom", "tags"], "add_tokens": "jsCode += ` \\n \\t ${ jsEscape ( makeCamelCase ( attribute . name ) ) } ` if ( attribute . quote === '' && attribute . value === '' ) { // Pseudo-boolean attribute } / ** * Turn dashed notation to camel case . * Example : 'ejs-html' to 'ejsHtml' * @ param { string } name * @ returns { string } * / function makeCamelCase ( name ) { return name . replace ( / -([a-z]) / g , ( _ , letter ) => letter . toUpperCase ( ) )", "del_tokens": "jsCode += ` \\n \\t ${ jsEscape ( attribute . name ) } ` if ( attribute . quote === '' ) {", "commit_type": "fix"}
{"commit_tokens": ["moved", "route", "-", "named", "members", "into", "routes", "namespace", "member"], "add_tokens": "assert . strictEqual ( router . routes [ route ] , null ) ; assert . strictEqual ( router . routes [ route ] , null ) ; assert . strictEqual ( JSON . stringify ( router . routes . notfound ) , '{\"path\":\"/does/not/exist\"}' ) ;", "del_tokens": "assert . strictEqual ( router [ route ] , null ) ; assert . strictEqual ( router [ route ] , null ) ; assert . strictEqual ( JSON . stringify ( router . notfound ) , '{\"path\":\"/does/not/exist\"}' ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "displayHover", "to", "return", "a", "promise", "instead", "of", "a", "promise", "value", "."], "add_tokens": "return browser . wait ( function ( ) {", "del_tokens": "browser . wait ( function ( ) {", "commit_type": "change"}
{"commit_tokens": ["Allow", "configuration", "of", "minimum", "energy", "threshold"], "add_tokens": "Layout . ForceDirected = function ( graph , stiffness , repulsion , damping , minEnergyThreshold ) { this . minEnergyThreshold = minEnergyThreshold || 0.01 ; //threshold used to determine render stop if ( t . _stop || t . totalEnergy ( ) < t . minEnergyThreshold ) {", "del_tokens": "Layout . ForceDirected = function ( graph , stiffness , repulsion , damping ) { if ( t . _stop || t . totalEnergy ( ) < 0.01 ) {", "commit_type": "allow"}
{"commit_tokens": ["Remove", "old", "build", "code", "for", "benchmarks", "."], "add_tokens": "options : { build : { build : { grunt . registerTask ( 'default' , [ 'build' ] ) ;", "del_tokens": "options : { build : { } , benchmark : { loose : \"all\" , options : { blacklist : [ 'es3.memberExpressionLiterals' , 'es3.propertyLiterals' , 'regenerator' , //es6.generators 'es6.properties.shorthand' ] , optional : [ 'spec.undefinedToVoid' , 'minification.constantFolding' , 'minification.propertyLiterals' ] } , files : [ { expand : true , cwd : './benchmark/src/' , src : './**/*.js' , dest : './benchmark/build/' } ] build : { } , benchmark : { src : [ './benchmark/build' ] grunt . registerTask ( 'build-benchmark' , [ 'clean:benchmark' , 'babel:benchmark' ] ) ; grunt . registerTask ( 'default' , [ 'build' , 'build-benchmark' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "undeclared", "variable", "use", "and", "immediate", "function", "call", "wrapping", "."], "add_tokens": "var now = ( new Date ( ) ) . getTime ( ) ; var iterator = ( function ( args ) { return function ( element ) { this . queue . forEach ( iterator ) ;", "del_tokens": "now = ( new Date ( ) ) . getTime ( ) ; this . queue . forEach ( function ( args ) { return function ( element , index , array ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "where", "instructions", "had", "multiple", "tabs"], "add_tokens": "s = s . replace ( / \\s+ / gi , ' ' )", "del_tokens": "while ( s . indexOf ( '\\t' ) >= 0 ) s = s . replace ( '\\t' , ' ' )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "to", "get", "worm", "supergroups", "working", "."], "add_tokens": "if ( sg && tier . superGroups [ sg ] ) { // workaround case where group and supergroup IDs match.", "del_tokens": "if ( sg ) {", "commit_type": "fix"}
{"commit_tokens": ["removed", "mustache", "as", "a", "local", "dependency"], "add_tokens": "var mustache = require ( 'mustache' ) ;", "del_tokens": "var mustache = require ( './lib/Mustache/mustache.js' ) ;", "commit_type": "remove"}
{"commit_tokens": ["implementing", "replace", "(", "not", "working", "well", "for", "space", ")"], "add_tokens": "if ( ! letterRegex . test ( key . name ) ) return false ; if ( handled ) return ;", "del_tokens": "// TODO: space not working if ( ! letterRegex . test ( key . name ) ) return false ; // && key.name !== 'space') return false; if ( ! handled ) original_ttyWrite ( code , key ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "normalisation", "of", "zeroed", "events", "."], "add_tokens": "if ( check . number ( start ) && check . number ( end ) ) {", "del_tokens": "if ( start && end ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "get", "+", "create", "read", "stream"], "add_tokens": "var Stream = require ( \"stream\" ) , ReadableStream = Stream . Readable , PassThroughStream = Stream . PassThrough ; var adapter = module . exports = { createReadStream : function createReadStream ( url , filePath , options ) { var outStream = new PassThroughStream ( ) ; adapter . getFileStream ( url , filePath , options ) . then ( function __handleStream ( stream ) { stream . pipe ( outStream ) ; } ) . catch ( function __handleReadError ( err ) { outStream . emit ( \"error\" , err ) ; } ) ; return outStream ; } , getFileStream : function getFileStream ( url , filePath , options ) { options = options || { headers : { } } ; return fetch ( url + filePath , { method : \"GET\" , headers : deepmerge ( { // todo range } , options . headers ) } ) . then ( responseHandlers . handleResponseCode ) . then ( function ( res ) { return res . body ; } ) ; } ,", "del_tokens": "module . exports = {", "commit_type": "add"}
{"commit_tokens": ["allow", "path", "joining", "in", "static", "files"], "add_tokens": "path = require ( 'path' ) , if ( typeof ( script_url ) == 'string' && ! ~ script_url . indexOf ( '//' ) ) script_url = path . join ( self . admin_root , script_url ) ; if ( typeof ( style_url ) == 'string' && ! ~ style_url . indexOf ( '://' ) ) style_url = path . join ( self . admin_root , style_url ) ;", "del_tokens": "if ( ! ~ script_url . indexOf ( '//' ) ) script_url = self . admin_root + script_url ; if ( ! ~ style_url . indexOf ( '://' ) ) style_url = self . admin_root + style_url ;", "commit_type": "allow"}
{"commit_tokens": ["Removed", "min", "from", "grunt", "watch", "task", "."], "add_tokens": "tasks : 'lint:grunt lint:tests concat lint:dist'", "del_tokens": "tasks : 'lint:grunt lint:tests concat lint:dist min'", "commit_type": "remove"}
{"commit_tokens": ["Updated", "test", "suite", "to", "uncompressed", "output"], "add_tokens": "var rfs = function ( file ) { tests . forEach ( function ( test , i ) { uncss ( rfs ( 'index.html' ) , { csspath : 'tests' } , function ( output ) { describe ( 'uncss' , function ( ) { var check = function ( done ) { setTimeout ( function ( ) { before ( function ( done ) { it ( 'should not be an empty string' , function ( ) { expect ( rawcss ) . not . to . equal ( false ) ; } ) ; tests . forEach ( function ( test ) { it ( 'should handle ' + test . split ( '.' ) [ 0 ] , function ( ) { } ) ;", "del_tokens": "var rfs = function ( file ) { tests . forEach ( function ( test , i ) { uncss ( rfs ( 'index.html' ) , { compress : true , raw : input } , function ( output ) { describe ( 'uncss' , function ( ) { var check = function ( done ) { setTimeout ( function ( ) { before ( function ( done ) { tests . forEach ( function ( test ) { it ( 'should handle ' + test . split ( '.' ) [ 0 ] , function ( ) { } ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "setter", "back", "in", "its", "more", "intuitive", "and", "good", "practice"], "add_tokens": "this . setDefaults = function ( newDefaults ) { angular . extend ( defaults , newDefaults ) ; getDefaults : function ( ) { return defaults ; }", "del_tokens": "this . getDefaults = function ( ) { return defaults ; return this ;", "commit_type": "add"}
{"commit_tokens": ["add", "an", "argument", "to", "switch", "over", "protocols"], "add_tokens": "this . broadcast = new Broadcast ( options . foglet . options . rps , this . vector , this . protocol ) ;", "del_tokens": "this . broadcast = new Broadcast ( options . foglet . options . spray , this . vector , this . protocol ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "handling", "of", "missing", "option", "arguments"], "add_tokens": "return lines // yargs passes [undefined] when insufficient arguments are given . filter ( function ( line ) { return line !== null && line !== undefined ; } ) . map ( parseHeader ) defaultDescription : swaggerSpecValidator . DEFAULT_URL , nargs : 1", "del_tokens": "return lines . map ( parseHeader ) defaultDescription : swaggerSpecValidator . DEFAULT_URL", "commit_type": "fix"}
{"commit_tokens": ["Change", "basic", "to", "simple", ";", "bug", "fixes", "on", "advanced", "strategy"], "add_tokens": "const playerOptions = { hitSoft17 : true , numberOfDecks : 1 , strategyComplexity : \"advanced\" } ;", "del_tokens": "function RunTest ( testName , playerCards , dealerCard , handCount , dealerCheckedBlackjack , options , expectedResult ) { const result = lib . GetRecommendedPlayerAction ( playerCards , dealerCard , handCount , dealerCheckedBlackjack , options ) ; if ( result == expectedResult ) { console . log ( \"SUCCESS: \" + testName + \" returned \" + result ) ; succeeded ++ ; } else { console . log ( \"FAIL: \" + testName + \" returned \" + result + \" rather than \" + expectedResult ) ; failed ++ ; } } const playerOptions = { hitSoft17 : true , numberOfDecks : 1 , strategyComplexity : \"basic\" } ;", "commit_type": "change"}
{"commit_tokens": ["Allow", "browser", "history", "type", "prop", "on", "Router"], "add_tokens": "import createMemoryHistory from 'history/createMemoryHistory' import createHashHistory from 'history/createHashHistory' return class GetRouteProps extends Component { if ( this . unmounting ) { return } componentWillUnmount ( ) { this . unmounting = true } return class GetSiteProps extends Component { if ( this . unmounting ) { return } componentWillUnmount ( ) { this . unmounting = true } static defaultProps = { type : 'browser' , } const { history , type , ... rest } = this . props resolvedHistory = history || global . __reactStaticRouterHistory if ( ! resolvedHistory ) { if ( type === 'memory' ) { resolvedHistory = createMemoryHistory ( ) } else if ( type === 'hash' ) { console . log ( 'hash!' ) resolvedHistory = createHashHistory ( ) } else { resolvedHistory = createBrowserHistory ( ) } }", "del_tokens": "return class AsyncPropsComponent extends Component { return class AsyncPropsComponent extends Component { const { history , ... rest } = this . props resolvedHistory = history || global . __reactStaticRouterHistory || createBrowserHistory ( )", "commit_type": "allow"}
{"commit_tokens": ["Move", "init", "command", "in", "prime", ".", "js"], "add_tokens": "parser . usage ( 'Usage: prime <command>' ) ;", "del_tokens": "parser . usage ( 'Usage: prime <command>' ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "emitter", "and", "replication", "manager"], "add_tokens": "var ThaliEmitter = require ( '../../thali/thaliemitter' ) ;", "del_tokens": "var ThaliEmitter = require ( '../../lib/thaliemitter' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "footer", "that", "adapts", "to", "page", "height"], "add_tokens": "var PageCtrl = function ( $rootScope , $scope , $routeParams , $http , $sce , $filter , $timeout ) { // Wait after the digest so that $timeout ( function ( ) { $scope . $emit ( \"ass-page-data-applied\" ) } , 0 ) ;", "del_tokens": "var PageCtrl = function ( $rootScope , $scope , $routeParams , $http , $sce , $filter ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "message", "=", "to", "the", "data", "so", "that", "the", "signature", "is", "generated", "correctly"], "add_tokens": "publicKey : null , // Leave as null if not using project auth var message = \"message=\" + base64_encode ( JSON . stringify ( data ) ) ;", "del_tokens": "publicKey : null , // Leave as null if not using project auth var message = base64_encode ( JSON . stringify ( data ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "tasks", "instance", "don", "t", "extend", "args", "in", "processArgv"], "add_tokens": "return app ; * base . runApps ( apps , function ( err ) { this . emit ( toPlural ( method ( 'run' ) ) , apps , this ) ; this . emit ( 'prebuild' , name , tasks , instance ) ;", "del_tokens": "utils . extend ( args , args . options ) ; * foo . runApps ( apps , function ( err ) { instance . emit ( 'prebuild' , name , tasks , instance ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "password", "matching", "validation", "to", "return", "the", "correct", "status", "code", "."], "add_tokens": "return callback ( null , [ 'Passwords must match.' ] , 400 ) ;", "del_tokens": "return callback ( null , [ 'Passwords must match.' ] , 409 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "issue", "where", "firestore", "could", "not", "be", "loaded", "alongside", "firebase", ".", "js"], "add_tokens": "module . exports = [ multiExport ] ;", "del_tokens": "const singleExport = Object . assign ( { } , baseConfig , { entry : { firebase : resolve ( __dirname , 'index.js' ) } , output : Object . assign ( { } , baseConfig . output , { library : 'firebase' , libraryTarget : 'window' } ) } ) ; module . exports = [ singleExport , multiExport ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "code", "comments", "and", "reorganize"], "add_tokens": "// Create JSON with metadata about the serve to serve at the root path. // Create two hash-based routers, one for POSTs and a separate one for GETs. // Request route handler functions // Serve service metadata at root. // Helper Functions function respond401 ( response ) { response . statusCode = 401 response . setHeader ( 'WWW-Authenticate' , 'Basic realm=\"Common Form\"' ) response . end ( ) } function respond500 ( request , response , error ) { request . log . error ( error ) response . statusCode = 500 response . end ( ) } function respond400 ( response , message ) { response . statusCode = 400 response . end ( message || '' ) } // Wrap a request handler function to check authoriztion. // Authentication // Path of a plain text files with valid publisher names and passwords. // Parse \"Authorization: Basic $base64\" headers.", "del_tokens": "function respond401 ( response ) { response . statusCode = 401 response . setHeader ( 'WWW-Authenticate' , 'Basic realm=\"Common Form\"' ) response . end ( ) } function respond500 ( request , response , error ) { request . log . error ( error ) response . statusCode = 500 response . end ( ) } function respond400 ( response , message ) { response . statusCode = 400 response . end ( message || '' ) }", "commit_type": "add"}
{"commit_tokens": ["Use", "options", "object", "with", "parameters", "in", "Transaction", "constructor", "."], "add_tokens": "this . chainID = options . chainID ; this . from = account . fromAddress ( options . from ) ; this . to = account . fromAddress ( options . to ) ; this . value = utils . toBigNumber ( options . value ) ; this . nonce = options . nonce ; this . data = parsePayload ( options . payload ) ; this . gasPrice = utils . toBigNumber ( options . gasPrice ) ; this . gasLimit = utils . toBigNumber ( options . gasLimit ) ;", "del_tokens": "this . chainID = chainID ; this . from = account . fromAddress ( from ) ; this . to = account . fromAddress ( to ) ; this . value = utils . toBigNumber ( value ) ; this . nonce = nonce ; this . data = parsePayload ( payload ) ; this . gasPrice = utils . toBigNumber ( gasPrice ) ; this . gasLimit = utils . toBigNumber ( gasLimit ) ;", "commit_type": "use"}
{"commit_tokens": ["allow", "specification", "of", "multiple", "offset", "for", "each", "partition"], "add_tokens": "console . log ( \" kafka-topics topic-name [[group-id] offset [offset2 ...]]\" ) console . log ( \" multiple offset will be cycled for each partition in topic\" ) ; var setTo ; if ( args . length > 3 ) { setTo = args . slice ( 2 ) . map ( function ( i ) { return parseInt ( i ) } ) ; if ( ! setTo . some ( isNaN ) ) return setGroupId ( topic , offset , setTo , partitions , groupId , mins , maxs , data ) ; } else { setTo = parseInt ( args [ 2 ] ) ; if ( ! isNaN ( setTo ) ) return setGroupId ( topic , offset , setTo , partitions , groupId , mins , maxs , data ) ; } var payloads = partitions . map ( function ( partition , index ) { var value = Array . isArray ( setTo ) ? setTo [ index % setTo . length ] : setTo ;", "del_tokens": "console . log ( \" kafka-topics topic-name [[group-id] offset]\" ) var setTo = parseInt ( args [ 2 ] ) ; if ( ! isNaN ( setTo ) ) return setGroupId ( topic , offset , setTo , partitions , groupId , mins , maxs , data ) ; var payloads = partitions . map ( function ( partition ) { var value = setTo ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "String", ".", "prototype", ".", "trim", "()", "in", "favour", "of", "RegExp", "to", "trim", "a", "value"], "add_tokens": "//@see https://github.com/oncletom/tld.js/issues/95 value = String ( value ) . trim ( ) . toLowerCase ( ) ;", "del_tokens": "function ltrim ( value ) { return String ( value ) . replace ( / ^\\s+ / g , '' ) ; } value = ltrim ( value ) . toLowerCase ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "decrypt", "more", "asynchronous", ".", "If", "no", "key", "then", "don", "t", "encrypt", "."], "add_tokens": "if ( f === undefined ) encrypt = this . key && this . key . length ; Crypt . prototype . maybe_decrypt = function ( data , f , get_key ) if ( get_key ) { get_key ( function ( err , key ) { if ( err ) { f ( err ) ; } else { new Crypt ( key ) . decrypt ( data . data , f ) ; } } ) ; } else { this . decrypt ( data . data , f ) ; }", "del_tokens": "if ( arguments . length === 2 ) encrypt = ! ! key ; Crypt . prototype . maybe_decrypt = function ( data , f ) this . decrypt ( data . data , f ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "version", "to", "always", "return", "current", "date", "when", "not", "set"], "add_tokens": "return new Date ( ) . toLocaleString ( ) ;", "del_tokens": "if ( this . strategy === 'all' || ! hash ) { Object . defineProperty ( this , 'version' , { value : new Date ( ) . toLocaleString ( ) , writable : false , enumerable : true , configurable : true } ) ; } else { return hash ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "cursor", "finding", "in", "code", "blocks"], "add_tokens": "render . code_block = ( node , options ) => { let code = wrap ( node , options , \"code\" )", "del_tokens": "render . code_block = node => { let code = elt ( \"code\" , node . textContent )", "commit_type": "fix"}
{"commit_tokens": ["Added", "info", "window", "panning", "based", "on", "map", "edge", "offsets", "."], "add_tokens": "", "del_tokens": "infowindow . open ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "install", "multiple", "targets", "with", "one", "command"], "add_tokens": "// lock ? - without version arg, locks current version, with version arg triggers install name@version (updating other packages appropiately)", "del_tokens": "// lock ?", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "reactor", ".", "createChangeObserver", "()"], "add_tokens": "describe ( '#createChangeObserver' , ( ) => { it ( \"should create a ChangeObserver object\" , ( ) => { var mockFn = jest . genMockFn ( ) var changeObserver = reactor . createChangeObserver ( ) changeObserver . onChange ( 'ExperimentCore.experiments' , mockFn ) var experiments = [ exp1 , exp2 , exp3 ] reactor . cycle ( { type : 'addExperiments' , payload : { data : experiments } } ) var expected = reactor . get ( 'ExperimentCore.experiments' ) expect ( mockFn . mock . calls [ 0 ] [ 0 ] ) . toEqual ( expected ) } ) } )", "del_tokens": "var update = require ( '../src/immutable-helpers' ) . update", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "with", "interpolators", "and", "items", "prop", "length"], "add_tokens": "const { items , firstItem , autoplay } = nextProps ; if ( items . length !== this . props . items . length ) { nextState . interpolators = this . _initInterpolators ( nextProps ) ; setTimeout ( ( ) => { this . snapToItem ( firstItem , false , false ) ; } , 0 ) ; if ( autoplay ) { this . startAutoplay ( ) ; } } _initInterpolators ( props = this . props ) { const { items , firstItem } = props ; return interpolators ;", "del_tokens": "_initInterpolators ( ) { const { items , firstItem } = this . props ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "hash", "rules", "do", "not", "work"], "add_tokens": "'^' + ( isHashRouter ( path ) ? '\\/' : '' ) + path . replace ( / \\* / g , '(.*)' ) + '$'", "del_tokens": "'^' + path . replace ( / \\* / g , '(.*)' ) + ( isHashRouter ( path ) ? '(#*)(.*)$' : '$' )", "commit_type": "fix"}
{"commit_tokens": ["Added", "and", "using", "utils", ".", "ui", ".", "openBrowserConsole", "()", "for", "easier", "debugging", "of", "failing", "tests"], "add_tokens": "await utils . ui . openBrowserConsole ( driver ) ;", "del_tokens": "// install the addon (note: returns addon id)", "commit_type": "add"}
{"commit_tokens": ["Fix", "associations", ":", "type", "-", "collection", "include", "-", "index"], "add_tokens": "if ( rec [ via ] === record [ pk ] ) filtered . push ( rec [ assoc . collection ] ) ; if ( rec [ via ] === record [ pk ] ) filtered . push ( rec [ assocPk ] ) ;", "del_tokens": "if ( rec [ via ] === record . id ) filtered . push ( rec [ assoc . collection ] ) ; if ( rec [ via ] === record . id ) filtered . push ( rec . id ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "char", "token", "parsers", ":", "octal", "and", "unicode", "escapes"], "add_tokens": "check = C . check , oneOf = pos . oneOf , // TODO this needs to parse based on java.util.regex.Pattern.compile // can I just reuse unicode escape? // no, because `\\u` is okay (but parsed by _char_simple) _char_unicode = node ( 'unicode' , [ 'open' , literal ( 'u' ) ] , [ 'first' , _hex ] , [ 'rest' , cut ( '3 hex characters' , quantity ( 3 , _hex ) ) ] ) , [ 'first' , _0_7 ] , [ 'rest' , cut ( '0-2 octal characters' , check ( function ( cs ) { return ( cs . length <= 2 ) ; } , many0 ( _0_7 ) ) ) ] ) ,", "del_tokens": "oneOf = pos . oneOf , // can I just reuse unicode escape? see spec.md _char_unicode = _unicode_escape , // not sure what errors this is responsible for _octal_check = function ( ds ) { if ( ds . length > 3 ) { return cut ( 'octal escape: too long' , zero ) ; } else if ( parseInt ( ds , 8 ) > 255 ) { // not sure if this error check belongs in this phase // maybe it should be split into a later phase // because the current phase is still about parsing return cut ( 'octal escape: too large' , zero ) ; } return pure ( ds ) ; } , [ 'digits' , cut ( 'digits' , bind ( many1 ( _0_7 ) , _octal_check ) ) ] ) ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "structure", "with", "mocha", "+", "karma"], "add_tokens": "{ type : this . props . type || \"button\" ,", "del_tokens": "{ type : \"button\" ,", "commit_type": "add"}
{"commit_tokens": ["fixing", "html", "directive", "regex", "to", "ignore", "html", "filter", "place"], "add_tokens": "HtmlDirective : '<[^>]*translate[^}>]*>([^<]*)<\\/[^>]*>' ,", "del_tokens": "HtmlDirective : '<[^>]*translate[^{>]*>([^<]*)<\\/[^>]*>' ,", "commit_type": "fix"}
{"commit_tokens": ["added", "examples", "for", "passing", "tasks", "in", "json"], "add_tokens": "var util = require ( 'util' ) ; var result = JSON . parse ( task . toString ( ) , function ( key , value ) { if ( ! ( 'at' in result ) ) { util . log ( 'JSON array missing mandatory keys' ) ; return { } ; } return result ;", "del_tokens": "return JSON . parse ( task . toString ( ) , function ( key , value ) {", "commit_type": "add"}
{"commit_tokens": ["add", "nice", "transition", "to", "basic", "list", "screen", "example"], "add_tokens": "import _ from 'lodash' ; import * as Animatable from 'react-native-animatable' ; animation = \"fadeIn\" easing = \"ease-out-expo\" duration = { 1000 } useNativeDriver < Animatable . Image source = { { uri : row . mediaUrl } } style = { styles . image } animation = \"fadeInLeft\" easing = \"ease-out-expo\" duration = { 600 } delay = { _ . sample ( [ 20 , 80 , 120 , 170 ] ) } useNativeDriver / >", "del_tokens": "< Image source = { { uri : row . mediaUrl } } style = { styles . image } / > // return ( // <BasicList.Item {...props}/> // );", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "exception", "thrown", "when", "object", "is", "undefined"], "add_tokens": "// it(\"should throw an exception if called without an object\", function(){ // expect(function(){ Sugarless() }).toThrow(); // }); describe ( \"some more nice things\" , function ( ) { it ( \"works with the strict mode\" , function ( ) { \"use strict\" ; var strict_func = function ( ) { return \"strict mode\" } expect ( Sugarless ( { } ) ( strict_func ) ) . toEqual ( \"strict mode\" ) ; } ) ;", "del_tokens": "it ( \"should throw an exception if called without an object\" , function ( ) { expect ( function ( ) { Sugarless ( ) } ) . toThrow ( ) ; } ) ; describe ( \"some nice things\" , function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "back", "-", "compat", "safe", "loading", "of", "mem", "-", "store", "by", "entity"], "add_tokens": "var MemStore = require ( 'seneca-mem-store' ) var opts = { mem_store : true } var seneca = this var extend = seneca . util . deepextend opts = extend ( opts , options ) // Ensures legacy versions of seneca that load mem-store do not // crash the system. Seneca 2.x and lower loads mem-store by default. if ( ! seneca . options ( ) . default_plugins [ 'mem-store' ] & opts . mem_store ) { seneca . use ( MemStore ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "CLI", "support", "for", "cache", "method"], "add_tokens": "var config = new Config ( ) args = getCLIArguments ( args ) config . port = args . port || config . port config . folder = args . folder || config . folder config . cacheControl = args . cache || config . cacheControl return config } function getCLIArguments ( args ) { return o . describe ( 'port' , 'listens on this port. Default: ' + Config . DEFAULT_PORT ) . describe ( 'folder' , 'serves content from this folder. Default: ' + Config . DEFAULT_FOLDER ) . describe ( 'cache' , 'caching method used. Default: ' + Config . DEFAULT_CACHE_CONTROL ) . alias ( 'p' , 'port' ) . alias ( 'f' , 'folder' ) . argv", "del_tokens": "return o . default ( 'port' , Config . DEFAULT_PORT ) . default ( 'folder' , Config . DEFAULT_FOLDER ) . alias ( 'p' , 'port' ) . alias ( 'f' , 'folder' ) . argv", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "contentFor", "hook", "idemponent"], "add_tokens": "if ( config . environment !== 'test' && type === 'body-footer' && ! config . _emberBasicDropdownContentForInvoked ) { config . _emberBasicDropdownContentForInvoked = true ;", "del_tokens": "if ( config . environment !== 'test' && type === 'body-footer' ) {", "commit_type": "make"}
{"commit_tokens": ["add", "support", "for", "cedar", "s", "transform", "property"], "add_tokens": "return this . addBowerPackageToProject ( 'arcgis-cedar' , '^0.8.0' ) ;", "del_tokens": "return this . addBowerPackageToProject ( 'arcgis-cedar' , '^0.6.1' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "default", "reduce", "declarations", "config", "for", "global"], "add_tokens": "if ( ! hasReadReduceDeclarations && optionsIn !== null ) { if ( optionsIn [ 'reduceConfig' ] === undefined || optionsIn [ 'reduceConfig' ] === null ) { //default process settings var default_reduce_declarations_config = { \"declaration_names\" : [ \"font\" , \"margin\" , \"padding\" , \"list-style\" , \"outline\" , \"border\" , \"border-top\" , \"border-right\" , \"border-bottom\" , \"border-left\" , \"border-radius\" , \"border-color\" , \"border-top-color\" , \"border-right-color\" , \"border-bottom-color\" , \"border-left-color\" , \"color\" , \"background-color\" , \"font-color\" , \"outline-color\" , \"box-shadow\" , \"text-shadow\" , \"float\" , \"font-family\" , \"font-size\" , \"font-weight\" , \"font-style\" , \"font-variant\" , \"font-stretch\" ] } ; optionsIn [ 'reduceConfig' ] = default_reduce_declarations_config ; readReduceDeclarations ( optionsIn [ 'reduceConfig' ] ) ; } } else { readReduceDeclarations ( ) ; } if ( ! hasReadReduceDeclarations && optionsIn !== null ) { if ( optionsIn [ 'reduceConfig' ] === undefined || optionsIn [ 'reduceConfig' ] === null ) { readReduceDeclarations ( optionsIn [ 'reduceConfig' ] ) ; } else { readReduceDeclarations ( ) ;", "del_tokens": "readReduceDeclarations ( ) ; if ( ! hasReadReduceDeclarations ) { if ( optionsIn [ 'reduceConfig' ] === undefined ) { readReduceDeclarations ( optionsIn [ 'reduceConfig' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "default", "module", "minifier", "to", "the", "offline", "one"], "add_tokens": "defaultValue : \"ESPRIMA\"", "del_tokens": "defaultValue : \"WHITESPACE_ONLY\"", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "auto", "-", "scaling", "of", "width", "and", "height"], "add_tokens": "if ( outWidth < 1 && outHeight < 1 ) { callback ( \"Width and/or height required\" ) ; return ; } sharp . resize ( options . inFile , options . inBuffer , output , outWidth , outHeight , canvas , sharpen , progessive , sequentialRead , callback ) ; \"use strict\" ; } ;", "del_tokens": "sharp . resize ( options . inFile , options . inBuffer , output , width , height , canvas , sharpen , progessive , sequentialRead , callback ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "encoding", "issue", "in", "node", "4", "."], "add_tokens": "return fs . createReadStream ( path ) . pipe ( new Decoder ( opts ) ) ;", "del_tokens": "return fs . createReadStream ( path , 'binary' ) . pipe ( new Decoder ( opts ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "input", "buffer", "parsing", "word"], "add_tokens": "exports . tick = function ( ) { // ' } exports . paren = function ( ) { // ( } exports . paren . immediate = true ; exports . colon = function ( ) { // : } exports . char = function ( ) { } exports . constant = function ( ) { } exports . create = function ( ) { } exports . postpone = function ( ) { } exports . variable = function ( ) { } exports . bracketTick = function ( ) { // ['] } exports . bracketChar = function ( ) { } console . log ( 'chunk: [' , chunk ) ; // do { console . log ( name , start , i ) ; // fn = that[name]; // if (fn) { // fn.call(that); // } else { // that.DS.push(Number(name)); // } // } while (i < (chunk.length - 2)) console . log ( ']' ) ;", "del_tokens": "do { fn = that [ name ] ; if ( fn ) { fn . call ( that ) ; } else { that . DS . push ( Number ( name ) ) ; } } while ( i < ( chunk . length - 2 ) ) exports . bracketTick = function ( ) { // [] }", "commit_type": "add"}
{"commit_tokens": ["Improved", "JSHint", "config", "in", "build", "environment"], "add_tokens": "components : 'src/**/*.js' // change this from 'localhost' to '*' to access the server from outside", "del_tokens": "component : 'src/backbone.select.js' // change this to '*' to access the server from outside", "commit_type": "improve"}
{"commit_tokens": ["change", "doc", "of", "batch", "function"], "add_tokens": "* Batch operations in the search engine", "del_tokens": "* Util function mapping db ops batch input to search batch input", "commit_type": "change"}
{"commit_tokens": ["fixed", "middleware", "bug", "where", "failed", "middleware", "would", "still", "call", "resolver"], "add_tokens": "if ( error ) { clearTimeout ( timeout ) ; return reject ( error ) ; } else if ( ! hooks . length ) { if ( error ) { clearTimeout ( timeout ) ; return reject ( error ) ; } else if ( ! hooks . length ) {", "del_tokens": "if ( error ) return reject ( error ) ; if ( ! hooks . length ) { if ( error ) return reject ( error ) ; if ( ! hooks . length ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ReactJS", "js", "error", "when", "option", "is", "not", "passed", "in"], "add_tokens": "phoneRegionCode = ( nextProps . options || { } ) . phoneRegionCode , ( options || { } ) . initValue = value ; value = pps . maxLength > 0 ? Util . headStr ( value , pps . maxLength ) : value ; // no options, normal input if ( blocksLength === 0 ) { return value ; }", "del_tokens": "phoneRegionCode = nextProps . options . phoneRegionCode , options . initValue = value ; value = Util . headStr ( value , pps . maxLength ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "controller", "to", "handle", "custom", "queries"], "add_tokens": "var query = ( req . controllerData && req . controllerData . model_query ) ? req . controllerData . model_query : options . query || { } ,", "del_tokens": "var query = options . query || { } ,", "commit_type": "update"}
{"commit_tokens": ["Use", "$templateRequest", "to", "handle", "template", "caching", "automatically"], "add_tokens": "module . factory ( 'ModalService' , [ '$document' , '$compile' , '$controller' , '$http' , '$rootScope' , '$q' , '$templateRequest' , function ( $document , $compile , $controller , $http , $rootScope , $q , $templateRequest ) { $templateRequest ( templateUrl , true ) . then ( function ( template ) { deferred . resolve ( template ) ; } , function ( error ) {", "del_tokens": "module . factory ( 'ModalService' , [ '$document' , '$compile' , '$controller' , '$http' , '$rootScope' , '$q' , '$templateCache' , function ( $document , $compile , $controller , $http , $rootScope , $q , $templateCache ) { // Get the template, using the $templateCache. $http . get ( templateUrl , { cache : $templateCache } ) . then ( function ( result ) { deferred . resolve ( result . data ) ; } , function ( error ) {", "commit_type": "use"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "variable", "name", "replacement", ".", "It", "didn", "t", "work", "when", "the", "same", "variable", "was", "encountered", "more", "than", "once", "in", "a", "query", "."], "add_tokens": "var reg = new RegExp ( \"\\\\\" + variable , \"g\" ) ; q = q . replace ( reg , value ) ; var reg = new RegExp ( \"\\\\\" + variable , \"g\" ) ; q = q . replace ( reg , value ) ;", "del_tokens": "q = q . replace ( variable , value ) ; q = q . replace ( variable , value ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "aspect", "ratio", "argument", "for", "perspective", "matrix", "."], "add_tokens": "var width = this . _width ; var height = this . _height ; var hfov = convertFov . vtoh ( vfov , width , height ) ; var aspect = width / height ; mat4 . perspective ( p , vfov , aspect , - 1 , 1 ) ;", "del_tokens": "var hfov = convertFov . vtoh ( vfov , this . _width , this . _height ) ; mat4 . perspective ( p , vfov , hfov / vfov , - 1 , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "ways", "to", "get", "formBuilder", "instance"], "add_tokens": "import assert from 'fl-assert' ; const jsonStateToRestore = xdiv . dataset . restoreState ; if ( jsonStateToRestore ) { try { const stateToRestore = JSON . parse ( jsonStateToRestore ) ; coordinator . importState ( stateToRestore ) ; } catch ( e ) { assert . warn ( e ) ; } } const loadEvent = new CustomEvent ( 'formBuilderLoaded' , { detail : { instance : coordinator , } , } ) ; xdiv . dispatchEvent ( loadEvent ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "force", "flag", "to", "delete", "command"], "add_tokens": "function run ( forceFlag ) { if ( forceFlag ) { deleteBackendProject ( ) } else { inquirer . prompt ( [ { type : 'confirm' , name : 'deleteBackend' , message : 'delete backend project ' + _projectInfo . BackendProjectName , default : false } ] ) . then ( function ( answers ) { if ( answers . deleteBackend ) { deleteBackendProject ( ) } } ) }", "del_tokens": "function run ( ) { inquirer . prompt ( [ { type : 'confirm' , name : 'deleteBackend' , message : 'delete backend project ' + _projectInfo . BackendProjectName , default : false } ] ) . then ( function ( answers ) { if ( answers . deleteBackend ) { deleteBackendProject ( ) } } )", "commit_type": "add"}
{"commit_tokens": ["Improve", "support", "for", "extended", "members"], "add_tokens": "// TODO: this whole sequence is terrible d . safe = true ; var found = false ; // sorted push for ( var z = 0 ; z < paninoArray [ a ] . list [ srcId ] . children . length ; z ++ ) { var currId = paninoArray [ a ] . list [ srcId ] . children [ z ] . id ; if ( currId > d . id ) { paninoArray [ a ] . list [ srcId ] . children . splice ( z , 0 , d ) ; found = true ; break ; } } if ( ! found ) { //console.log(d.id) paninoArray [ a ] . list [ srcId ] . children . push ( d ) ; } // why do I have to do this? why can't I just do paninoArray[p].tree.children[d.id] ?", "del_tokens": "paninoArray [ a ] . list [ srcId ] . children . push ( d ) ; // why do I have to do this? why can't I just do aninoArray[p].tree.children[d.id] ?", "commit_type": "improve"}
{"commit_tokens": ["Added", "support", "for", "larger", "resolution", "displays"], "add_tokens": "tap_pixel_range : 5 , end_y = ( e . originalEvent . targetTouches ) ? e . originalEvent . changedTouches [ 0 ] . pageY : e . pageY ; diff_x = ( start_pos . x - end_x ) , diff_y = ( start_pos . y - end_y ) ; if ( origTarget == e . target && started && ( ( new Date ( ) . getTime ( ) - start_time ) < settings . taphold_threshold ) && ( ( start_pos . x == end_x && start_pos . y == end_y ) || ( diff_x >= - ( settings . tap_pixel_range ) && diff_x <= settings . tap_pixel_range && diff_y >= - ( settings . tap_pixel_range ) && diff_y <= settings . tap_pixel_range ) ) ) {", "del_tokens": "end_y = ( e . originalEvent . targetTouches ) ? e . originalEvent . changedTouches [ 0 ] . pageY : e . pageY ; if ( origTarget == e . target && started && ( ( new Date ( ) . getTime ( ) - start_time ) < settings . taphold_threshold ) && ( start_pos . x == end_x && start_pos . y == end_y ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bulk", "string", "offset", "cache"], "add_tokens": "parser . bigStrSize = offsetEnd + 2", "del_tokens": "parser . bigStrSize = length + 2", "commit_type": "fix"}
{"commit_tokens": ["Updated", "buildDeploymentRecord", "()", "kubernetes", "driver"], "add_tokens": "let envs = [ ] ; podSpec . containers [ 0 ] . env . forEach ( ( oneEnv ) => { if ( oneEnv . value ) { envs . push ( oneEnv . name + '=' + oneEnv . value ) } else { //automatically generated values are delected here, actual values are not included if ( oneEnv . valueFrom && oneEnv . valueFrom . fieldRef && oneEnv . valueFrom . fieldRef . fieldPath ) { envs . push ( oneEnv . name + '=' + oneEnv . valueFrom . fieldRef . fieldPath ) ; } else { envs . push ( oneEnv . name + '=' + JSON . stringify ( oneEnv . valueFrom , null , 0 ) ) ; } } } ) ;", "del_tokens": "return podSpec . containers [ 0 ] . env ;", "commit_type": "update"}
{"commit_tokens": ["Move", "localize", "and", "mixin", "into", "their", "own", "npm", "package"], "add_tokens": "var I18N = require ( './lib' ) , i18n = new I18N ( ) ; $this : i18n , I18N : I18N", "del_tokens": "var i18n = require ( './lib' ) , mixin = require ( './lib/mixin' ) , localize = require ( './lib/localize' ) ; mixin : mixin , localize : localize , I18N : i18n . I18N", "commit_type": "move"}
{"commit_tokens": ["add", "kad", "-", "telemetry", "support"], "add_tokens": "var telemetry = require ( 'kad-telemetry' ) this . telemetryStorage = options . telemetryStorage var TelemetryTransport = telemetry . TransportDecorator ( MMTransport ) var transport = new TelemetryTransport ( this . contact , { messaging : this . messaging , telemetry : { storage : this . telemetryStorage } } ) //var transport = new MMTransport(this.contact, {messaging: this.messaging}) transport . before ( 'serialize' , crypto . sign . bind ( null , this . keypair ) ) transport . before ( 'receive' , crypto . verify ) var TelemetryRouter = telemetry . RouterDecorator ( kademlia . Router ) var router = new TelemetryRouter ( { transport : transport , logger : kademliaLogger } ) logger : kademliaLogger , router : router //TODO: Use getContactsByNodeId //TODO: When result is null, use lookup() => (err,'VALUE',value) (err, 'NODE' shortlist)", "del_tokens": "// var telemetry = require('kad-telemetry') // var TelemetryTransport = telemetry.TransportDecorator(MMTransport) // var pathToTelemetryData = null // var transport = new TelemetryTransport(contact, {messaging: this.messaging, telemetry: {filename: pathToTelemetryData}}) var transport = new MMTransport ( this . contact , { messaging : this . messaging } ) transport . before ( 'serialize' , crypto . sign . bind ( null , this . keypair ) ) transport . before ( 'receive' , crypto . verify ) // var TelemetryRouter = telemetry.RouterDecorator(kademlia.Router) // var router = new TelemetryRouter({ // transport: transport // }) logger : kademliaLogger", "commit_type": "add"}
{"commit_tokens": ["fixed", "AMD", "module", "definition", "added", "a", "minified", "version"], "add_tokens": "if ( typeof exports !== \"undefined\" ) { // Server if ( typeof module !== \"undefined\" && module . exports ) { exports = module . exports = Stapes ; } exports . Stapes = Stapes ; } else if ( typeof define === \"function\" && define . amd ) { // AMD define ( function ( ) { return Stapes ; } ) ; // Global scope", "del_tokens": "if ( typeof module !== \"undefined\" && module . exports ) { module . exports = Stapes ; } else if ( typeof define !== \"undefined\" ) { define ( Stapes ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "api", "method", "for", "listing", "events"], "add_tokens": "needed : [ ] , defaults : { } var args = _ . extend ( { } , method . options . defaults , req . query , req . body ) ;", "del_tokens": "needed : [ ] var args = _ . extend ( { } , req . query , req . body ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "bugs", "in", "HTTP", "dialect"], "add_tokens": ", _baseURL = function ( id ) { return '/api/v2/:jobType' + ( id ? '/:id' : '' ) + '/?$' } if ( ! ~ self . _allowedJobTypes . indexOf ( req . params . jobType ) ) jobType : req . params . jobType , id : req . body . id this . server . get ( _baseURL ( ) , function ( q , r ) { r . end ( 'test' ) } ) this . server . post ( _baseURL ( ) , httpRequest . call ( this , 'push' ) ) this . server . del ( _baseURL ( true ) , httpRequest . call ( this , 'remove' ) ) console . log ( _baseURL ( true ) )", "del_tokens": ", _baseURL = '/api/v1/:jobType/:id/?$' if ( ! self . _allowedJobTypes . indexOf ( req . params . jobType ) ) id : req . params . id , jobType : req . params . jobType this . server . get ( _baseURL , function ( q , r ) { r . end ( 'test' ) } ) this . server . post ( _baseURL , httpRequest . call ( this , 'push' ) ) this . server . del ( _baseURL , httpRequest . call ( this , 'remove' ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "post", "params", "support", "to", "_oauthservices", "parseParameters", "."], "add_tokens": "// GET variables // POST variables if ( body ) { for ( var key in body ) { result [ key ] = body [ key ] ; } }", "del_tokens": "//TODO: Figure out how to use post params....", "commit_type": "add"}
{"commit_tokens": ["Fix", "valid", "()", "function", "fname", "variable", "references"], "add_tokens": "fName = path . join ( dbLocation , dbName + '.json' ) fName = path . join ( userData , dbName + '.json' )", "del_tokens": "var fName = path . join ( dbLocation , dbName + '.json' ) fname = path . join ( userData , dbName + '.json' )", "commit_type": "fix"}
{"commit_tokens": ["removed", "auto", "generation", "of", "sub", "keys", "in", "collate", "plugin"], "add_tokens": "//if (gen_html) // _addOutputFile(data_name+'.'+value, as+'-'+value, true, context, fileInfo); // add output file (eg categories-some-category.html)", "del_tokens": "if ( gen_html ) _addOutputFile ( data_name + '.' + value , as + '-' + value , true , context , fileInfo ) ; // add output file (eg categories-some-category.html)", "commit_type": "remove"}
{"commit_tokens": ["fix", "a", "small", "redeclaration", "complaint"], "add_tokens": "var data ; data = { } ; data = '' ; data = '<event>\\n' ;", "del_tokens": "var data = { } ; var data = '' ; var data = '<event>\\n' ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "const", "for", "a", "couple", "more", "variable", "declarations", "."], "add_tokens": "const libsignal = require ( \"@throneless/libsignal-protocol\" ) ; const ProvisionMessage = require ( \"./protobufs.js\" ) . lookupType (", "del_tokens": "var libsignal = require ( \"@throneless/libsignal-protocol\" ) ; var ProvisionMessage = require ( \"./protobufs.js\" ) . lookupType (", "commit_type": "use"}
{"commit_tokens": ["add", "css", "routing", "and", "move", "markup", "to", "html", ";", "close", "window", "when", "navigating", "back", "to", "loading", "screen"], "add_tokens": "// construct UI document . body . classList . add ( 'loading' ) ; document . body . classList . remove ( 'loading' ) ; location . hash = 'enter-passphrase' ;", "del_tokens": "// run UI rootElement . innerHTML = ` < input type = \"text\" name = \"passphrase\" > < button > Confirm < / button > < span id = \"error\" > < / span > ` ; // TODO show loading animation // TODO stop loading animation", "commit_type": "add"}
{"commit_tokens": ["Add", "beforeinitialize", "and", "beforedestroy", "events", "."], "add_tokens": "// Hook for plugins so that functionality // can be triggered before Fruit Machine // object initialization. FruitMachine . trigger ( 'beforeinitialize' ) ; // Hook for plugins so that functionality // can be triggered before Fruit Machine // object destruction. FruitMachine . trigger ( 'beforedestroy' ) ; } ( this ) ) ;", "del_tokens": "} ( this ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "tutorial", "on", "making", "an", "OADA", "-", "schema"], "add_tokens": "description : 'time is a data type which holds a reading of...time...' , properties : { } ,", "del_tokens": "description : 'time is a data type which holds a reading of...time...' ,", "commit_type": "add"}
{"commit_tokens": ["moved", "directive", "reduction", "to", "its", "own", "function"], "add_tokens": "query Query ( $skip : Boolean ! ) @ test ( value : \"queryOp\" ) { id @ test ( value : \"idField\" ) @ remove ( if : true ) remove : true , // randomBoolean(),", "del_tokens": "query Query ( $skip : Boolean ! , $remove : Boolean ! ) @ test ( value : \"queryOp\" ) { id @ remove ( if : $remove ) @ test ( value : \"idField\" ) remove : false , // randomBoolean(),", "commit_type": "move"}
{"commit_tokens": ["Added", "$rawData", "binding", "context", "for", "the", "sake", "of", "completeness", "(", "Currently", "$data", "==", "$rawData", ")", "."], "add_tokens": "$data : data , $rawData : data $rawData : item , throw new Error ( 'Expression evaluator needs at least 4 arguments.' ) ;", "del_tokens": "$data : data throw new Error ( 'Expression evaluator needs at least 4 arguments.' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removes", "extra", "export", ";", "formatting"], "add_tokens": "spaced ( word ( \"export\" ) . then ( Expr ) ) . map ( ast . Module ) . or ( Script )", "del_tokens": "P . alt ( spaced ( word ( \"export\" ) . then ( Expr ) ) . map ( ast . Module ) , Script ) ; Script : Script ,", "commit_type": "remove"}
{"commit_tokens": ["Add", "UIntVar", "/", "IntVar", "types", "and", "their", "corresponding", "conversion", "serializing", "/", "deserializing", "logics"], "add_tokens": "let force_size = true ; force_size = false ; // NOTE: In case that the highest bit is 1 ( the size is not efficient to represent the value ) let _result = buffer ; if ( ! force_size ) { let real_len = size - 1 ; while ( ( real_len > 0 ) && ( ( buffer [ real_len ] & 0xFF ) === 0 ) ) { real_len -- ; } if ( ( buffer [ real_len ] & 0x80 ) !== 0 ) { real_len ++ ; } _result = ( real_len === size ) ? buffer : buffer . slice ( 0 , real_len + 1 ) ; } BitwiseTwoComplimentLE ( _result ) ; return _result ;", "del_tokens": "BitwiseTwoComplimentLE ( buffer ) ; return buffer ;", "commit_type": "add"}
{"commit_tokens": ["added", "ability", "to", "specify", "arg", "value", "for", "js", "commands"], "add_tokens": "} ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "event", "emitters", "to", "emit", "events", "whenever", "a", "page", "is", "processed"], "add_tokens": "var complete_callback = function ( err , text_pages ) { } var processor = pdf ( pdf_path , options , complete_callback ) ; processor . on ( 'complete' , function ( data ) { data . should . have . property ( 'text_pages' ) ; data . should . have . property ( 'pdf_path' ) ; data . text_pages . length . should . eql ( 2 , 'wrong number of pages after extracting from mulitpage searchable pdf with name: ' + file_name ) ; page_event_fired . should . be . true ; var page_event_fired = false ; processor . on ( 'page' , function ( data ) { page_event_fired = true ; data . should . have . property ( 'index' ) ; data . should . have . property ( 'pdf_path' ) ; data . should . have . property ( 'text' ) ; data . pdf_path . should . eql ( pdf_path ) ; data . text . length . should . above ( 0 ) ; } ) ;", "del_tokens": "pdf ( pdf_path , options , function ( err , text_pages ) {", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "initialize", "identify", "and", "track"], "add_tokens": "// A list of providers that have been initialized. providers : [ ] , var initializedProviders = [ ] ; availableProviders [ key ] . initialize ( providers [ key ] ) ; initializedProviders . push ( availableProviders [ key ] ) ; // `event` - the name of the event. // `test` - the name of the test. // `variation` - the name of the variation the user saw. ab : function ( test , variation ) { provider . ab ( test , variation ) ; initialize : function ( settings ) { initialize : function ( settings ) {", "del_tokens": "// A place to store providers that have been initialized. providers : { } , var initializedProviders = { } ; initializedProviders [ key ] = availableProviders [ key ] ; initializedProviders [ key ] . init ( providers [ key ] ) ; // `eventName` - the name of the event. // `testName` - the name of the test. // `variationName` - the name of the variation the user saw. ab : function ( testName , variationName ) { provider . ab ( testName , variationName ) ; init : function ( settings ) { init : function ( settings ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "external", "db", "adapters"], "add_tokens": "let adapter if ( process . env . DB_ADAPTER ) { adapter = require ( 'micro-analytics-adapter-' + process . env . DB_ADAPTER ) } else { adapter = require ( './flat-file-adapter' ) }", "del_tokens": "const adapter = require ( './flat-file-adapter' ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "matreshka", "-", "magic", ".", "js"], "add_tokens": "var commentMatreshka = '/*\\n\\tMatreshka v<%= pkg.version %> (<%= grunt.template.today(\"yyyy-mm-dd\") %>)\\n\\tJavaScript Framework by Andrey Gubanov\\n\\tReleased under the MIT license\\n\\tMore info: http://matreshka.io\\n*/\\n' , commentMagic = '/*\\n\\tMatreshka Magic v<%= pkg.version %> (<%= grunt.template.today(\"yyyy-mm-dd\") %>), the part of Matreshka project \\n\\tJavaScript Framework by Andrey Gubanov\\n\\tReleased under the MIT license\\n\\tMore info: http://matreshka.io/#magic\\n*/\\n' ; matreshka : { start : commentMatreshka , } , matreshka_magic : { options : { baseUrl : 'src' , name : \"matreshka-magic\" , out : \"matreshka-magic.js\" , optimize : \"none\" , preserveLicenseComments : false , paths : { matreshka_dir : '' } , wrap : { start : commentMagic , end : ' \\ if ( typeof define === \"function\" && define . amd ) { \\ define ( [ \"matreshka-magic\" ] , function ( magic ) { \\ magic . version = \"<%= pkg.version %>\" ; \\ return magic ; \\ } ) ; \\ } else { \\ magic . version = \"<%= pkg.version %>\" ; \\ if ( typeof exports == \"object\" ) module . exports = magic ; \\ } ' } } matreshka : { options : { sourceMapName : 'matreshka.min.map' , banner : commentMatreshka } , } , matreshka_magic : { options : { sourceMapName : 'matreshka-magic.min.map' , banner : commentMagic } , src : 'matreshka-magic.js' , dest : 'matreshka-magic.min.js'", "del_tokens": "var comment = '/*\\n\\tMatreshka v<%= pkg.version %> (<%= grunt.template.today(\"yyyy-mm-dd\") %>)\\n\\tJavaScript Framework by Andrey Gubanov\\n\\tReleased under the MIT license\\n\\tMore info: http://matreshka.io\\n*/\\n' compile : { start : comment , banner : comment , sourceMapName : 'matreshka.min.map' , build : {", "commit_type": "add"}
{"commit_tokens": ["Fix", "data", "drift", "in", "directions", "e2e", "tests", "."], "add_tokens": "var stringMatching = jasmine . stringMatching ; end_address : stringMatching ( / Parramatta NSW / )", "del_tokens": "end_address : 'Parramatta NSW, Australia'", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "Rake", "task", "for", "releasing", "."], "add_tokens": "var glm = require ( \"../../dist/gl-matrix\" ) ;", "del_tokens": "var glm = require ( \"../../lib/gl-matrix\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "away", "from", "exporting", "a", "class", "and", "split", "methods", "into", "separate", "files"], "add_tokens": "const args = require ( '../lib' ) ;", "del_tokens": "const args = require ( '../' ) ;", "commit_type": "move"}
{"commit_tokens": ["use", "cwd", "instead", "of", "__dirname", "for", "resolving", "plugin", "paths"], "add_tokens": "theGenerator . start ( options ) . done ( try { theGenerator . loadAllPluginsInDirectory ( f ) ; } catch ( e ) { logger . log ( \"init\" , \"app\" , \"Error processing plugin directory '\" + f + \"'\" , e ) ; console . error ( \"Error processing plugin directory %s\\n\" , f , e ) ; }", "del_tokens": "theGenerator . start ( options ) . then ( theGenerator . loadAllPluginsInDirectory ( f ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "some", "bugs", "and", "test", "complete"], "add_tokens": "import { generateFiles , generateFilesFromTemplate , generateFilesFromCustom , } from './files' import { generateQuestions , getTemplatesList , getConfig , getTemplate , } from './utils' import { questions } from './questions' async function startTemplateGenerator ( ) { const requiredAnswers = await inquirer . prompt ( [ questions . name , questions . path , ] ) return await startTemplateGenerator ( ) return await startTemplateGenerator ( ) Logger . error ( e . message )", "del_tokens": "import { generateFiles , generateFilesFromTemplate , generateFilesFromCustom } from './files' import { generateQuestions , getTemplatesList , getConfig , getTemplate } from './utils' import questions from './questions' async function startTemplateGenarator ( ) { const requiredAnswers = await inquirer . prompt ( [ questions . name , questions . path ] ) return await startTemplateGenarator ( ) return await startTemplateGenarator ( ) Logger . error ( e )", "commit_type": "fix"}
{"commit_tokens": ["updated", "import", "042", "payment", "addr"], "add_tokens": "for ( var address in artifact . payment . addresses ) {", "del_tokens": "for ( var address of artifact . payment . addresses ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "node", "error", "parser"], "add_tokens": ". pipe ( replace ( 'require(\\'source-map/lib/source-map/source-map-consumer\\')' , 'null' ) ) // needed for node until source maps dependency is fixed . pipe ( replace ( 'require(\\'source-map/lib/source-map/source-map-consumer\\')' , 'null' ) ) // needed for node until source maps dependency is fixed", "del_tokens": ". pipe ( replace ( 'require(\\'source-map/lib/source-map/source-map-consumer\\')' , '{}' ) ) // needed for node until source maps dependency is fixed . pipe ( replace ( 'require(\\'source-map/lib/source-map/source-map-consumer\\')' , '{}' ) ) // needed for node until source maps dependency is fixed", "commit_type": "add"}
{"commit_tokens": ["Updated", "jake", "-", "deploy", "-", "test", "-", "app", "to", "fetch", "/", "install", "plugins", "rather", "than", "calling", "add"], "add_tokens": "fetchPlugin = \"cordova/plugin fetch %s\" , installPlugin = \"cordova/plugin install %s\" , var cmd = util . format ( fetchPlugin , path . join ( pluginsPath , plugin ) ) ; task . andThen ( utils . execCommandWithJWorkflow ( cmd , { cwd : projectPath } ) ) ; } ) ; plugins . forEach ( function ( plugin ) { var cmd = util . format ( installPlugin , plugin ) ;", "del_tokens": "addPlugin = \"cordova/plugin add %s\" , var cmd = util . format ( addPlugin , path . join ( pluginsPath , plugin ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", ":", "Require", "classes", "used", "as", "entry", "command", "handlers", "when", "used", "not", "during", "registration", "."], "add_tokens": "this . commands [ name ] = handler ; return ;", "del_tokens": "switch ( typeof handler ) { case 'string' : var m = this . O . requireChain ( handler ) ; if ( typeof m === 'function' ) { this . on ( name , m ) ; return ; } if ( m . O && m . O . type === 'class' ) { this . commands [ name ] = onClass ( m . O . ctor ) ; return ; } break ; case 'function' : if ( handler . prototype . O && handler . prototype . O . type === 'class' ) { this . commands [ name ] = onClass ( handler ) ; return ; } this . commands [ name ] = handler ; return ; } break ;", "commit_type": "change"}
{"commit_tokens": ["added", "safeguard", "on", "creating", "new", "objectStore"], "add_tokens": "db . objectStoreNames . contains ( storeName ) ? null : db . createObjectStore ( storeName , { keyPath : 'id' } )", "del_tokens": "db . createObjectStore ( storeName , { keyPath : 'id' } )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "https", ":", "//", "github", ".", "com", "/", "jhipster", "/", "generator", "-", "jhipster", "/", "issues", "/", "4147"], "add_tokens": "//relationship.otherEntityField = _.lowerFirst(splitField.otherEntityField); relationship . relationshipType = 'one-to-many' ; otherSplitField = extractField ( relatedRelationship . injectedFieldInFrom ) ; relationship . otherEntityRelationshipName = _ . lowerFirst ( otherSplitField . relationshipName ) ;", "del_tokens": "relationship . otherEntityField = _ . lowerFirst ( splitField . otherEntityField ) ;", "commit_type": "fix"}
{"commit_tokens": ["Created", "the", "methods", "for", "plan", "and", "payment", "method"], "add_tokens": "const Actions = require ( './actions.js' ) ; const Analysis = require ( './analysis.js' ) ; const Buckets = require ( './buckets.js' ) ; const Dashboards = require ( './dashboards.js' ) ; const Devices = require ( './devices.js' ) ; const Notifications = require ( './notifications.js' ) ; const Middlewares = require ( './middlewares.js' ) ; const Tags = require ( './tags.js' ) ; const PaymentMethods = require ( './paymentMethods' ) ; const Plan = require ( './plan' ) ; get paymentMethods ( ) { return new PaymentMethods ( this . token ) ; } get plan ( ) { return new Plan ( this . token ) ; }", "del_tokens": "const Actions = require ( './actions.js' ) ; const Analysis = require ( './analysis.js' ) ; const Buckets = require ( './buckets.js' ) ; const Dashboards = require ( './dashboards.js' ) ; const Devices = require ( './devices.js' ) ; const Notifications = require ( './notifications.js' ) ; const Middlewares = require ( './middlewares.js' ) ; const Tags = require ( './tags.js' ) ;", "commit_type": "create"}
{"commit_tokens": ["Make", "the", "multi", "-", "ton", "backwards", "compatible", "with", "the", "original", "FruitMachine", "convenience", "method", "."], "add_tokens": "function LazyView ( options ) { return new View ( options ) ; } LazyView . Model = Model ; LazyView . View = View ; LazyView . define = define ( store , View ) ; LazyView . store = store ; LazyView . util = utils ; return LazyView ;", "del_tokens": "return { Model : Model , View : View , define : define ( store , View ) , store : store , util : utils , } ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "x", "-", "forwarded", "-", "for", "header", "to", "support", "lists", "with", "spaces", "around", "the"], "add_tokens": "ips = ( headers [ proxies [ i ] . ip ] || '' ) . replace ( / \\s*,\\s* / , ',' ) . split ( ',' ) ;", "del_tokens": "ips = ( headers [ proxies [ i ] . ip ] || '' ) . split ( ',' ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "group", "label", "children", "bug"], "add_tokens": "const _boxSize = Symbol ( 'boxSize' ) delete this . subject [ _boxSize ] delete this . subject [ _boxSize ] delete this . subject [ _boxSize ] if ( this [ _boxSize ] ) { return this [ _boxSize ] this [ _boxSize ] = size", "del_tokens": "textboxSize : '' , this . set ( 'textboxSize' , '' ) @ attr set textboxSize ( val ) { this . set ( 'textboxSize' , val ) } this . set ( 'textboxSize' , '' ) this . set ( 'textboxSize' , '' ) const boxSize = this . attr ( 'textboxSize' ) if ( boxSize ) { return boxSize this . attr ( 'textboxSize' , size )", "commit_type": "fix"}
{"commit_tokens": ["Added", "defaultValue", "helper", "for", "properties", ".", "---", ">", "defaultValue", ".", "NOW"], "add_tokens": "const defaultValues = require ( './helpers/defaultValues' ) ; let value = schema . paths [ k ] . hasOwnProperty ( 'default' ) ? schema . paths [ k ] . default : null ; if ( ( { } ) . hasOwnProperty . call ( defaultValues . __map__ , value ) ) { / ** * If default value is in the gstore . defaultValue map * then execute the handler for that shortcut * / value = defaultValues . __handler__ ( value ) ; } else if ( value === null && schema . paths [ k ] . hasOwnProperty ( 'values' ) ) { value = schema . paths [ k ] . values [ 0 ] ; entityData [ k ] = value ;", "del_tokens": "entityData [ k ] = schema . paths [ k ] . hasOwnProperty ( 'default' ) ? schema . paths [ k ] . default : null ; if ( entityData [ k ] === null && schema . paths [ k ] . hasOwnProperty ( 'values' ) ) { entityData [ k ] = schema . paths [ k ] . values [ 0 ] ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "fixing", "multiple", "wrong", "version", "numbers", "in", "the", "same", "line"], "add_tokens": "* versionUpdater v3 .12 .45 let versionsToReplace = [ ] ; let replacedInFile = false ; versionsToReplace . push ( currentMatch ) ; // handle version numbers update replacedInFile = true ; // handle replacement of wrong version numbers if ( versionsToReplace . length > 0 ) { replacedInFile = true ; console . log ( versionsToReplace ) ; versionsToReplace . forEach ( function ( toReplace ) { occurencies ++ ; lines [ i ] = operations [ fileType ] ( lines [ i ] , toReplace . replace ( / ^v / , '' ) ) ; if ( STOP ) { return ; } } ) ; if ( STOP ) { break ; } } if ( replacedInFile ) { fileOccurencies ++ ; }", "del_tokens": "* versionUpdater v3 .12 .26 versionToReplace = match [ 1 ] ; fileOccurencies ++ ;", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "a", "custom", "HTML", "page"], "add_tokens": "app . set ( \"duo html\" , null ) ; html ( app . get ( \"duo html\" ) , function ( err , template ) { if ( err ) return next ( err ) ; res . send ( template ( { title : app . get ( \"duo title\" ) , body : body || null , css : app . get ( \"duo css\" ) , js : app . get ( \"duo js\" ) } ) ) ; } ) ;", "del_tokens": "res . send ( html ( { title : app . get ( \"duo title\" ) , body : body || null , css : app . get ( \"duo css\" ) , js : app . get ( \"duo js\" ) } ) ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "filling", "w", "/", "o", "consuming", "data"], "add_tokens": "if ( cfg . consumeData !== false ) { delete data [ key ] ; }", "del_tokens": "delete data [ key ] ;", "commit_type": "allow"}
{"commit_tokens": ["Allowing", "for", "user", "folders", "to", "edit"], "add_tokens": "imap_utils = require ( './utils' ) ) , deepExtend = require ( 'deep-extend' ) ; me . folders = deepExtend ( ( me . user && me . user . folders ) || { } , this . options . folders ) ; IMAPConnection . prototype . onAuthenticated = function ( notification ) { this . indexFolders ( ) ; } ;", "del_tokens": "imap_utils = require ( './utils' ) ) ; me . folders = extend ( { } , this . options . folders ) ;", "commit_type": "allow"}
{"commit_tokens": ["allow", "static", "pug", "import", "to", "access", "options", "as", "locals", "to", "mimic", "pug", ".", "render", "behavior", "."], "add_tokens": "import { render , compileClientWithDependenciesTracked } from 'pug' const is_static = matchStaticPattern ( id ) let opts if ( is_static ) { opts = clone ( config ) } else { opts = cloneProps ( config , PUGPROPS ) } const output = [ ] if ( is_static ) { const static_opts = assign ( { } , config . locals , opts ) body = JSON . stringify ( render ( code , static_opts ) ) + ';'", "del_tokens": "import { compile , compileClientWithDependenciesTracked } from 'pug' const opts = cloneProps ( config , PUGPROPS ) const output = [ ] if ( matchStaticPattern ( id ) ) { const locals = config . locals fn = compile ( code , opts ) body = JSON . stringify ( fn ( locals ) ) + ';'", "commit_type": "allow"}
{"commit_tokens": ["Fix", "diamond", "symbol", "on", "Windows"], "add_tokens": "` wa rrior.s c ore}` . p a dEnd(s c reenWidth, ' '),", "del_tokens": "` wa rrior.s c ore}` . p a dEnd(s c reenWidth, ' '),", "commit_type": "fix"}
{"commit_tokens": ["add", "switch", "to", "disable", "morgan"], "add_tokens": "var morgan = morgan ( 'combined' ) ; app . use ( function ( q , r , n ) { if ( program . noExpressLog !== true ) { morgan ( q , r , n ) ; } } ) ;", "del_tokens": "app . use ( morgan ( 'combined' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "possibility", "to", "denormalize", "multiple", "viewmodels", "in", "same", "collection", "with", "intelligent", "queries", "in", "an", "async", "way"], "add_tokens": "var eventViewBuilderMap = [ ] ; // [{ event: evt, viewBuilders: [] }] eventViewBuilderMap . push ( { event : evt , viewBuilders : viewBuilders } ) ; _ . each ( viewBuilders , function ( vb ) { async . eachSeries ( eventViewBuilderMap , function ( item , callback ) { async . each ( item . viewBuilders , function ( vb , callback ) { vb . denormalize ( item . event , callback ) ;", "del_tokens": "var viewBuilderMap = { } ; var groupedEvents = { } ; _ . each ( viewBuilders , function ( vb ) { viewBuilderMap [ vb . workerId ] = vb ; groupedEvents [ vb . workerId ] = groupedEvents [ vb . workerId ] || [ ] ; groupedEvents [ vb . workerId ] . push ( evt ) ; async . each ( _ . values ( viewBuilderMap ) , function ( vb , callback ) { if ( ! groupedEvents [ vb . workerId ] || groupedEvents [ vb . workerId ] . length === 0 ) { return callback ( null ) ; } async . eachSeries ( groupedEvents [ vb . workerId ] , function ( e , callback ) { vb . denormalize ( e , callback ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "tests", "with", "the", "new", "organization", "and", "policy", "token", "formatting"], "add_tokens": "'dist/ng-image-upload-template-in.js' ,", "del_tokens": "'dist/ng-image-upload.js' ,", "commit_type": "update"}
{"commit_tokens": ["Adding", "a", "patch", "to", "catch", "all", "uncaughtExceptions", "thrown", "."], "add_tokens": "} ; module . exports . patch_global = function patch_global ( options ) { var client = new Client ( options ) ; process . on ( 'uncaughtException' , function ( err ) { client . create_from_exception ( err , { } , function ( result ) { var util = require ( 'util' ) ; util . log ( 'uncaughtException: ' + client . get_ident ( result ) ) ; } ) ; } ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "$noty", ".", "data", "instead", "of", "base", ".", "options"], "add_tokens": "$noty . removeClass ( $noty . data ( 'noty_options' ) . type ) ; type = $noty . data ( 'noty_options' ) . cssPrefix + type ; $noty . data ( 'noty_options' ) . type = type ; $noty . addClass ( type ) ;", "del_tokens": "$noty . removeClass ( base . options . type ) ; base . options . type = base . options . cssPrefix + type ; $noty . addClass ( base . options . type ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "an", "async", "problem", "with", "the", "spriting"], "add_tokens": "images += '<img src=\"data:image/png;base64,' + image . data + '\"/>\\n' ;", "del_tokens": "images += '<img src=\"data:image/png;base64,' + image + '\"/>\\n' ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "/", "query", "expects", "an", "array", "."], "add_tokens": "var all , allCached , allPromise , clearCache , count , destroy , destroyPromise , exports , get , getCached , getPromise , items , itemsById , methods , queryMethods , queryResource , resource , save , savePromise , updateMasterList , version , _version ; queryMethods = { query : { method : 'POST' , params : { } , isArray : true } } ; queryResource = $resource ( '/api/' + resourceName + '/query' , { } , queryMethods ) ; var cacheable , options , r ; r = resource ; if ( params . query != null ) { r = queryResource ; } return r . query ( options , function ( results ) { ;", "del_tokens": "var all , allCached , allPromise , clearCache , count , destroy , destroyPromise , exports , get , getCached , getPromise , items , itemsById , methods , resource , save , savePromise , updateMasterList , version , _version ; var cacheable , options ; return resource . query ( options , function ( results ) { ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "default", "current", "directory", "."], "add_tokens": "process . stdout . write ( \"Unknown action\\r\\n\" . red ) ; ask ( \"Where are your config files? (relative to \" + path . resolve ( path . normalize ( process . cwd ( ) ) ) + \") \" , function ( relativePath ) {", "del_tokens": "process . stdout . write ( \"Unknown action\" ) ; ask ( \"Where are your config files? (relative to \" + path . resolve ( path . normalize ( \".\" ) ) + \") \" , function ( relativePath ) {", "commit_type": "change"}
{"commit_tokens": ["Remove", "line", "breaks", "from", "summary"], "add_tokens": "json = preProcess ( json ) ; fs . writeFile ( __dirname + '/../README.md' , readme ) ; function preProcess ( json ) { // Filter out private API json = json . filter ( function ( item ) { return item . ctx && item . isPrivate === false ; } ) ; // Remove line breaks json . forEach ( function ( item ) { if ( item . description . summary ) { item . description . summary = item . description . summary . replace ( / <br \\/> / g , ' ' ) ; } } ) ; return json ; }", "del_tokens": "json = json . filter ( function ( item ) { return item . ctx && item . isPrivate === false ; } ) ; fs . writeFile ( __dirname + '/../README.md' , readme ) ;", "commit_type": "remove"}
{"commit_tokens": ["make", "container", "and", "prototype", "methods", "read", "-", "only", "to", "avoid", "issues", "with", "improper", "usage"], "add_tokens": "const container = this . options . container ; if ( container instanceof HTMLElement ) { const style = window . getComputedStyle ( container ) ; if ( style . position === 'static' ) { container . style . position = 'relative' ; } } container . addEventListener ( 'scroll' , this . _scroll ) ;", "del_tokens": "this . options . container . addEventListener ( 'scroll' , this . _scroll ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "namespace", "updated", "Settings", ".", "ts"], "add_tokens": "src : [ 'src/@init.ts' , 'src/td/Application.ts' , 'src/~bootstrap.ts' ] ,", "del_tokens": "src : [ 'src/**/*.ts' ] ,", "commit_type": "change"}
{"commit_tokens": ["Use", "Object", ".", "create", "(", "null", ")", "for", "Headers", "internal", "map"], "add_tokens": "this [ MAP ] = Object . create ( null ) ; for ( let name in this [ MAP ] ) { } return ! ! this [ MAP ] [ sanitizeName ( name ) ] ;", "del_tokens": "this [ MAP ] = { } ; Object . getOwnPropertyNames ( this [ MAP ] ) . forEach ( name => { } ) ; return this [ MAP ] . hasOwnProperty ( sanitizeName ( name ) ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "toggle", "for", "prevent", "default", "behaviour"], "add_tokens": "/** @private @type {boolean} */ zCanvas . prototype . _disposed = false ; /** @private @type {boolean} */ zCanvas . prototype . _animate = false ; /** @private @type {boolean} */ zCanvas . prototype . _smoothing = true ; /** @private @type {boolean} */ zCanvas . prototype . _preventDefaults = false ; / ** * whether or not all events captured by the zCanvas can * bubble down in the document , when true , DOM events that * have interacted with the zCanvas will stop their propagation * and prevent their default behaviour * * @ public * @ param { boolean } value * / zCanvas . prototype . preventEventBubbling = function ( value ) { this . _preventDefaults = value ; } ; if ( this . _preventDefaults ) { aEvent . stopPropagation ( ) ; aEvent . preventDefault ( ) ; }", "del_tokens": "/** @private @type {boolean} */ zCanvas . prototype . _disposed = false ; /** @private @type {boolean} */ zCanvas . prototype . _animate = false ; /** @private @type {boolean} */ zCanvas . prototype . _smoothing = true ; * aEvent . stopPropagation ( ) ; aEvent . preventDefault ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "hl", ".", "method", "param"], "add_tokens": "* @ param { String } [ params . method ] - Specifies the highlighting implementation to use , acceptables values are unified , original , fastVector , and postings if ( ! _ . isUndefined ( params . method ) ) { self . params . push ( 'hl.method=' + params . method ) ; } module . exports = Query ;", "del_tokens": "module . exports = Query ;", "commit_type": "add"}
{"commit_tokens": ["Upgraded", "to", "new", "kwaai", "-", "mongo"], "add_tokens": "kwaaiCrud . getByQuery ( { collection : \"test collection\" , query : { select : \"name\" } , rawQuery : { select : { name : 1 , description : 1 } , find : { name : \"testDistinct\" } } } , function ( err , val ) { if ( err ) { console . error ( err ) } console . log ( val ) } ) return ;", "del_tokens": "kwaaiCrud . getByQuery ( { collection : \"test collection\" , query : { select : \"name\" } , rawQuery : { select : { name : 1 , description : 1 } } } , function ( err , val ) { if ( err ) { console . error ( err ) } console . log ( val ) } )", "commit_type": "upgrade"}
{"commit_tokens": ["Remove", "automatic", "viaContentsApi", "fallback", "from", "viaTreesApi"], "add_tokens": "files . truncated = contents . truncated ;", "del_tokens": "if ( contents . truncated ) { return viaContentsApi ( repo , dir , token ) ; }", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "with", "multiple", "expectations", "of", "the", "same", "name", ".", "updated", "readme"], "add_tokens": "this . _expectations = { } ; this . _unnamedExpectationCount = 0 ; this . _expectations = { } ; Object . keys ( that . _expectations ) . forEach ( function ( name ) { that . _expectations [ name ] . bind ( that ) ( res ) ; that . _expectations = { } ; name = \"Expectation \" + this . _unnamedExpectationCount ++ ; this . _expectations [ name ] = fnTest ;", "del_tokens": "this . _expectations = [ ] ; that . _expectations . forEach ( function ( expectation ) { expectation . fnTest . bind ( that ) ( res ) ; var name = expectation . name || ( \"Unnamed Expectation \" + unnamedExpectationCount ++ ) ; that . _expectations = [ ] ; name = '' ; this . _expectations . push ( { name : name , fnTest : fnTest } ) ;", "commit_type": "fix"}
{"commit_tokens": ["update", "levelgraph", "example", "with", "new", "version", "of", "sparql", "-", "engine"], "add_tokens": "const { HashMapDataset , Graph , PlanBuilder } = require ( '../dist/api' )", "del_tokens": "const { HashMapDataset , Graph , PlanBuilder } = require ( 'sparql-engine' )", "commit_type": "update"}
{"commit_tokens": ["update", "npm", "fix", "hang", "on", "getch"], "add_tokens": "process . stdin . pause ( ) ;", "del_tokens": "process . stdin . resume ( ) ;", "commit_type": "update"}
{"commit_tokens": ["move", "the", "pumpapp", "to", "something", "else"], "add_tokens": "params . schema = api . getSchema ( ) ;", "del_tokens": "params . schema = PumpAPI . getSchema ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "Express", "params", "sometimes", "coming", "in", "blank"], "add_tokens": "params [ routeKey . name ] = req . params [ routeKey . name ] ;", "del_tokens": "params [ routeKey . name ] = req . route . params [ routeKey . name ] ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "states", "data", "from", "data", "directory"], "add_tokens": "var STATES_DATA = require ( __dirname + '/statesData.js' ) ;", "del_tokens": "var STATES_DATA = require ( __dirname + '/data/statesData.js' ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "trees", "immutable", "and", "stringify", "without", "loc", "."], "add_tokens": "elements . push ( new NullTree ( ) ) ;", "del_tokens": "elements . push ( NullTree . Instance ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "throttled", "-", "queue", "-", "spec", "fake", "timer", "."], "add_tokens": "// This simplistic fake is suitable for injecting into the ThrottledQueue. // The queue only has one pending timeout at a time. setTimeout ( function ( ) { theTime += 0.5 * PERIOD ; } , 10 ) ; setTimeout ( function ( ) { theTime += 2 * PERIOD ; } , 10 ) ;", "del_tokens": "fakeSetTimeout ( function ( ) { } , 0.5 * PERIOD ) ; fakeSetTimeout ( function ( ) { } , 2 * PERIOD ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "Date", "as", "internal", "date", "format"], "add_tokens": "let type = attrDef . type if ( ! type && / (cre|upd)atedAt / . test ( key ) ) { type = 'date' } const attr = new Attribute ( key , type , attrDef . path , attrDef . defaultValue )", "del_tokens": "const attr = new Attribute ( key , attrDef . type , attrDef . path , attrDef . defaultValue )", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "with", "popup", "-", "grid", "sharing", "model", "instance", "."], "add_tokens": "requireAuthentication : '=?' , $scope . requireAuthentication = angular . isUndefined ( $scope . requireAuthentication ) ? true : $scope . requireAuthentication ; model . editPopup = function ( template , size ) { var data = { } ; angular . forEach ( model , function ( value , key ) { if ( key [ 0 ] === '$' ) return ; data [ key ] = value ; } ) ; var clone = new TubularModel ( $scope , data , $scope . dataService ) ; tubularPopupService . openDialog ( template , clone , $scope , size ) ;", "del_tokens": "requireAuthentication : '@?' , $scope . requireAuthentication = $scope . requireAuthentication || true ; model . editPopup = function ( template , size ) { tubularPopupService . openDialog ( template , model , $scope , size ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "hooks", ":", "isNodeDraggable", "isNodeDroppable"], "add_tokens": "let isNodeDroppable if ( info . store . isNodeDroppable ) { isNodeDroppable = info . store . isNodeDroppable } else { isNodeDroppable = ( node , nodeVm , store ) => { if ( node . hasOwnProperty ( 'droppable' ) ) { return node . droppable } else { return true } } branch . _droppable = isNodeDroppable ( branch , branch . _vm , branch . _vm . store ) item . _droppable = isNodeDroppable ( item , item . _vm , item . _vm . store )", "del_tokens": "if ( branch . hasOwnProperty ( 'droppable' ) ) { branch . _droppable = branch . droppable } else if ( ! branch . hasOwnProperty ( '_droppable' ) ) { branch . _droppable = true item . _droppable = item . hasOwnProperty ( 'droppable' ) ? item . droppable : parent . _droppable", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "basename", "like", "icon2", "."], "add_tokens": "basename = _ . replace ( basename , options . retinaInfix + '2x' , '' ) ; basename = _ . replace ( basename , options . retinaInfix + '3x' , '' ) ;", "del_tokens": "// Get the base name of file. // Example1: demo.png/demo@2x.png/demo_2x.png ==> demo // Example2: demo.new.png/demo.new@2x.png ==> demo.new // Note: 'extname' should like `.png`(also as default) function getBaseName ( filepath , extname , retina ) { extname = extname || '.png' ; retina = retina || false ; var basename = path . basename ( filepath , extname ) ; if ( retina ) { basename = _ . trimEnd ( basename , '@2x' ) ; basename = _ . trimEnd ( basename , '@3x' ) ; basename = _ . trimEnd ( basename , '_2x' ) ; basename = _ . trimEnd ( basename , '_3x' ) ; } return basename ; } basename = _ . trimEnd ( basename , '@2x' ) ; basename = _ . trimEnd ( basename , '@3x' ) ; basename = _ . trimEnd ( basename , '_2x' ) ; basename = _ . trimEnd ( basename , '_3x' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "manual", "trigger", "passthrough", "with", "auto", "show"], "add_tokens": "if ( this . settings . show && this . settings . trigger !== 'manual' ) {", "del_tokens": "if ( this . settings . show ) {", "commit_type": "allow"}
{"commit_tokens": ["remove", "\\", "before", "#", "in", "character", "lists", "(", "meaningless", "escape", "error", "with", "u", "flag", ")"], "add_tokens": "if ( ctx . list ) { return true ; }", "del_tokens": "if ( ctx . list ) { return true ; }", "commit_type": "remove"}
{"commit_tokens": ["made", "change", "to", "more", "functional", "approach", "with", "taskCollection"], "add_tokens": "let collection = TaskCollection ( ) ;", "del_tokens": "/ ** * These two functions manage the access . update of a global task collection * variable * / exports . globalTaskCollection = undefined ; exports . getTaskCollection = function ( ) { return taskCollection ; } exports . setTaskCollectioni = function ( tc ) { taskCollection = tc ; } globalTaskCollection = TC . TaskCollection ( ) ; let collection = TC . getInstance ( ) ; collection = TC . getInstance ( ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "queue", "of", "next", "check", "by", "checkLazyElements", "-", ">", "triggerEvent"], "add_tokens": "waitingMode = 1 ;", "del_tokens": "waitingMode = 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "nav", "JS", "to", "remove", "other", "dropdowns", "when", "tabbing", "BACKWARDS"], "add_tokens": "// Unfocus all other focussed parent items $parentLi . removeClass ( \"focused\" ) ; $ ( this ) . closest ( $parentLi ) . addClass ( \"focused\" ) ;", "del_tokens": "$ ( this ) . closest ( $parentLi ) . addClass ( \"focused\" ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "the", "body", "click", "undefined", "error"], "add_tokens": "if ( pop && pop . _opened ) {", "del_tokens": "if ( pop . _opened ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "activity", "feed", "filters"], "add_tokens": "\"PLAYED_WITH\" , \"LAUNCHED_GAME_FIRST_TIME\" , \"PROFILE_ABOUT_ME\" , \"CONTENT_SHARE\" , \"STORE_PROMO\" , \"IN_GAME_POST\"", "del_tokens": "\"STORE_PROMO\" , \"CONTENT_SHARE\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "|version|", "option", "to", "be", "a", "function"], "add_tokens": "var defaultOptions = { version : function version ( ) { return new Date ( ) . toLocaleString ( ) ; } , } ; } , { key : 'version' , get : function get ( ) { var version = this . options . version ; return typeof version === 'function' ? version ( ) : version + '' ; }", "del_tokens": "var defaultOptions = Object . defineProperties ( { } , { version : { get : function get ( ) { return new Date ( ) . toLocaleString ( ) ; } , configurable : true , enumerable : true } } ) ; this . version = this . options . version + '' ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "indexes", "templates", "imports", "and", "exports"], "add_tokens": "return ` ${ COMPONENT_NAME } ${ COMPONENT_NAME } . js '", "del_tokens": "return ` ${ COMPONENT_NAME } . js ' const $ { COMPONENT_NAME } = template", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "enable", "or", "disable", "touch", "zoom"], "add_tokens": "options . map . zoom . enabled && options . map . zoom . touch && $self . on ( \"touchstart\" , function ( e ) { options . map . zoom . enabled && options . map . zoom . touch && $self . on ( \"touchmove\" , function ( e ) { $ ( \"body\" ) . on ( \"mouseup\" + ( options . touch ? \" touchend\" : \"\" ) , function ( e ) { $container . on ( \"mousedown\" + ( options . touch ? \" touchstart\" : \"\" ) , function ( e ) { } ) . on ( \"mousemove\" + ( options . touch ? \" touchmove\" : \"\" ) , function ( e ) { , touch : true", "del_tokens": "options . map . zoom . enabled && $self . on ( \"touchstart\" , function ( e ) { options . map . zoom . enabled && $self . on ( \"touchmove\" , function ( e ) { $ ( \"body\" ) . on ( \"mouseup touchend\" , function ( e ) { $container . on ( \"mousedown touchstart\" , function ( e ) { } ) . on ( \"mousemove touchmove\" , function ( e ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "mkdir", "to", "mkdirp", "for", "recursive", "directory", "creation", "(", "aligns", "with", "S3", "api", ")", "when", "createBucket", "is", "invoked", "."], "add_tokens": "fs . mkdirp ( bucketPath , 502 , function ( err ) {", "del_tokens": "fs . mkdir ( bucketPath , 502 , function ( err ) {", "commit_type": "change"}
{"commit_tokens": ["Fixed", "strange", "stack", "issue", "."], "add_tokens": "this . fn += \"arg = \" + param + \";\" ; this . fn += \"stack.push(context);\" ; this . fn += \"out = out + Handlebars.handleBlock(lookup, wrappedContext, arg, \" + fnId + \", \" + fnId + \"Not);\"", "del_tokens": "this . fn += \"stack.push(context);\" ; this . fn += \"out = out + Handlebars.handleBlock(lookup, wrappedContext, \" + param + \", \" + fnId + \", \" + fnId + \"Not);\"", "commit_type": "fix"}
{"commit_tokens": ["allow", "the", "length", "to", "be", "specified", "as", "a", "second", "argument"], "add_tokens": "* The returned constructor ' * TypedArray API . function ArrayType ( data , length ) { return new ArrayType ( data , length ) this . length = null == length ? data . length : length this . length = null == length ? data . length / item_size : length", "del_tokens": "function ArrayType ( data ) { return new ArrayType ( _length ) this . length = data . length this . length = data . length / item_size", "commit_type": "allow"}
{"commit_tokens": ["add", "paging", "to", "both", "queries", "and", "scan", ".", "Allow", "for", "streaming", "query", "items"], "add_tokens": "var _ = require ( 'underscore' ) ; if ( ! cb && _ . isFunction ( opts ) ) { cb = opts ; opts = { } ; } if ( ! opts ) opts = { } ; if ( opts . limit ) { params . Limit = opts . limit ; } return dynamoRequest ( { query : params , pages : opts . pages , func : function ( query , callback ) { if ( resp . Items ) { } var result = { count : resp . Count , items : resp . Items } ; if ( resp . LastEvaluatedKey ) { result . last = resp . LastEvaluatedKey ; } callback ( null , result ) ;", "del_tokens": "if ( ! cb ) { cb = opts ; opts = { } ; } return dynamoRequest ( { query : params , func : function ( query , callback ) { if ( resp . Items ) callback ( null , { count : resp . Count , items : resp . Items } ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "conn", "and", "load", "views"], "add_tokens": "var conn = process . env . COUCH || 'http://localhost:5984' ;", "del_tokens": "var conn = require ( '../conn' ) ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "string", "enum", "pattern", "when", "initializing", "Compressor", "/", "Decompressor"], "add_tokens": "function Decompressor ( type ) { var initial_table = ( type === 'REQUEST' ) ? CompressionContext . initialRequestTable : CompressionContext . initialResponseTable ; function Compressor ( type ) { var initial_table = ( type === 'REQUEST' ) ? CompressionContext . initialRequestTable : CompressionContext . initialResponseTable ;", "del_tokens": "function Decompressor ( request ) { var initial_table = request ? CompressionContext . initialRequestTable : CompressionContext . initialResponseTable ; function Compressor ( request ) { var initial_table = request ? CompressionContext . initialRequestTable : CompressionContext . initialResponseTable ;", "commit_type": "change"}
{"commit_tokens": ["Use", "extend", "module", "so", "we", "get", "a", "copy", "of", "the", "fixture", "file", "."], "add_tokens": "var fs = require ( 'fs' ) , extend = require ( 'extend' ) , path = require ( 'path' ) , nock = require ( 'nock' ) ; // use extend so we get a copy of the fixture file fixtureFile = extend ( true , { } , require ( filePathJson ) ) ;", "del_tokens": "var fs = require ( 'fs' ) , path = require ( 'path' ) , nock = require ( 'nock' ) ; fixtureFile = require ( filePathJson ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "warning", "for", "excluded", "components", "."], "add_tokens": "var testExclude = _ . find ( config . get ( 'exclude' ) , function ( pattern ) { return path . join ( config . get ( 'bower-directory' ) , component ) . match ( pattern ) ; } ) if ( dep . main . length === 0 && testExclude == undefined ) {", "del_tokens": "if ( dep . main . length === 0 ) {", "commit_type": "remove"}
{"commit_tokens": ["Remove", "ready", "method", "/", "callback"], "add_tokens": "for ( var namespace in config ) { console . log ( namespace ) ; var ns = io . of ( namespace ) ; nodevent ( ns , config [ namespace ] ) ;", "del_tokens": "for ( var namespace in config ) { nodevent ( io . of ( namespace ) , config [ namespace ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["adding", "image", "tests", "and", "removing", "console", ".", "log", "from", "ellipse", "tests"], "add_tokens": "// Exit // Enter images . enter ( ) . append ( \"image\" ) ; // Update", "del_tokens": "images . enter ( ) . append ( \"image\" ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "perf", ".", "js", "work", "again"], "add_tokens": "// console.time('100 naive searches 1%'); // var result; // for (var j = 0; j < 100; j++) { // result = []; // for (i = 0; i < N; i++) { // if (tree._intersects(bboxes10[j], data[i])) { // result.push(data[i]); // } // } // } // console.timeEnd('100 naive searches 1%');", "del_tokens": "console . time ( '100 naive searches 1%' ) ; var result ; for ( var j = 0 ; j < 100 ; j ++ ) { result = [ ] ; for ( i = 0 ; i < N ; i ++ ) { if ( tree . _intersects ( bboxes10 [ j ] , data [ i ] ) ) { result . push ( data [ i ] ) ; } } } console . timeEnd ( '100 naive searches 1%' ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "compiler", "output", "filesystem", "for", "stats", "."], "add_tokens": "compiler . plugin ( 'after-emit' , function ( compilation , done ) { var fs = compiler . outputFileSystem ; var data = JSON . stringify ( compilation . getStats ( ) . toJson ( options ) ) ; fs . mkdirp ( path . dirname ( output ) , function ( err ) { if ( err ) { done ( err ) ; } else { fs . writeFile ( output , data , done ) ; } } ) ;", "del_tokens": "var fs = require ( 'fs' ) ; var mkdirp = require ( 'mkdirp' ) ; compiler . plugin ( 'done' , function ( stats ) { mkdirp . sync ( path . dirname ( output ) ) ; fs . writeFileSync ( output , JSON . stringify ( stats . toJson ( options ) ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "number", "of", "position", "elements", "instead", "of", "hard", "coded", "#"], "add_tokens": "keyframes : parsedDae . keyframes , numElements : parsedDae . vertexPositionIndices . length", "del_tokens": "keyframes : parsedDae . keyframes", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "for", "reloadApplication", "condition"], "add_tokens": "pm2 . gracefulReload ( targetName ,", "del_tokens": "spawnAsExec ( targetApp . prehook , execOptions ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "route", "info", "on", "every", "error", "request"], "add_tokens": "_getRouteInfo : function ( ) { } , expect ( a ) . toBe ( '{ data: { __request_route__: undefined } }' ) ; _getRouteInfo : function ( ) { } , _getRouteInfo : function ( ) { } ,", "del_tokens": "expect ( a ) . toBe ( '{}' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "control", "about", "object", "caching", "in", "container", "."], "add_tokens": "if ( ! cfg . hasOwnProperty ( \"forceCreate\" ) && cfg . forceCreate !== true ) { // buffer the service this . services [ name ] = service ; }", "del_tokens": "// buffer the service this . services [ name ] = service ;", "commit_type": "add"}
{"commit_tokens": ["adds", "support", "for", "ignoring", "symlinks"], "add_tokens": "/* deps: mocha */ describe ( 'glob pattern' , function ( ) { } ) ; describe ( 'path' , function ( ) { it ( 'should return an array of directories:' , function ( ) { console . time ( 'mocha' ) ; resolveUp ( 'mocha' ) . should . should . be . an . array ; console . timeEnd ( 'mocha' ) ; } ) ; it ( 'should return an array of directories:' , function ( ) { console . time ( 'nosymlinks' ) ; resolveUp ( 'mocha' , { nosymlinks : true } ) . should . should . be . an . array ; console . timeEnd ( 'nosymlinks' ) ; } ) ; } ) ; describe ( 'errors' , function ( ) {", "del_tokens": "/* deps:mocha */ describe ( 'resolve-up' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Updating", "handshake", "error", "handling", "to", "conform", "to", "draft", "-", "09"], "add_tokens": "426 : \"Upgrade Required\" , this . reject ( 400 , \"Client must provide a value for Sec-WebSocket-Key.\" ) ; this . reject ( 400 , \"Client must provide a value for Sec-WebSocket-Version.\" ) ; this . reject ( 426 , \"Unsupported websocket client version.\" , { \"Sec-WebSocket-Version\" : \"8\" } ) ; reject : function ( status , reason , extraHeaders ) { status = 403 ; if ( extraHeaders ) { for ( var key in extraHeaders ) { var sanitizedValue = extraHeaders [ key ] . toString ( ) . replace ( headerSanitizeRegExp , '' ) ; var sanitizedKey = key . replace ( headerSanitizeRegExp , '' ) ; response += ( key + \": \" + sanitizedValue + \"\\r\\n\" ) ; } }", "del_tokens": "reject : function ( status , reason ) { status = 400 ;", "commit_type": "update"}
{"commit_tokens": ["Make", "tree", "-", "building", "from", "the", "syntax", "nodes", "lazy", "."], "add_tokens": "/ *! knockout-secure-binding - v0.2.0 - 2014-1-31 member_op = this . op === operators [ '.' ] ; this . nodes = nodes ; if ( ! this . root ) { this . root = this . build_tree ( this . nodes ) ; }", "del_tokens": "/ *! knockout-secure-binding - v0.1.0 - 2014-1-31 member_op = this . op === operators [ '.' ] || this . op === operators [ '[]' ] ;", "commit_type": "make"}
{"commit_tokens": ["Add", "version", "check", "for", "global", "proxy"], "add_tokens": "const semvar = require ( 'semver' ) ; const proxiedGlobal = ( ( semvar . satisfies ( process . versions . node + '>=8.3.0' ) ) ? true : false ) ; if ( config . includeGlobals && ! proxiedGlobal ) Object . assign ( sandbox , global ) ; parent : settings . get ( 'parent' ) . parent || settings . get ( 'parent' ) sandbox . require = sandbox . module . require = requireLike ( config . filename ) ; return proxiedGlobal ? createProxy ( sandbox ) : sandbox ;", "del_tokens": "if ( config . includeGlobals ) Object . assign ( sandbox , global , { require : requireLike ( config . filename ) } ) ; parent : settings . get ( 'parent' ) . parent || settings . get ( 'parent' ) , require : sandbox . require || requireLike ( config . filename ) return createProxy ( sandbox ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "test", "for", "EasyStar", ".", "Update", "thrown", "error", "message", "."], "add_tokens": "throw \"You can't set a path without first calling setGrid() on EasyStar.\" ; }", "del_tokens": "throw \"You can't set a path without first calling setCollisionGrid on the EasyStar.js\" ; }", "commit_type": "add"}
{"commit_tokens": ["Moved", "props", "into", "design", "-", "tokens"], "add_tokens": "const configGlob = './design-tokens/**/*.config.json' ; transformGroup : 'scss' , buildPath : 'dist/tokens/web/' , format : 'scss/variables' format : 'json' format : 'css/variables' } , { destination : ` ${ themeName } ` , format : 'javascript/module'", "del_tokens": "const configGlob = './design-properties/**/*.config.json' ; transformGroup : \"scss\" , buildPath : \"dist/tokens/web/\" , format : \"scss/variables\" format : \"json\" format : \"css/variables\"", "commit_type": "move"}
{"commit_tokens": ["Allow", "selection", "of", "tests", "when", "creating", "a", "test", "session"], "add_tokens": "runTestSession : runTestSession , tests : [ ] init ( ) ; function init ( ) { $http . get ( '/api/tests' ) . then ( function success ( res ) { $scope . vm . tests = res . data ; } , function error ( res ) { console . log ( res . data ) ; } ) ; } var tests = $scope . vm . tests . filter ( function ( t ) { return t . selected ; } ) ; if ( ! tests . length ) { return ; } $http . post ( '/api/session' , { tests : tests } )", "del_tokens": "runTestSession : runTestSession $http . post ( '/api/session' )", "commit_type": "allow"}
{"commit_tokens": ["updated", "esriMap", "to", "do", "unshift", "instead", "of", "push", "on", "layerInfos", ";"], "add_tokens": "this . layerInfos . unshift ( lyrInfo ) ;", "del_tokens": "this . layerInfos . push ( lyrInfo ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "user", "sign", "in", "bug"], "add_tokens": "var pass = req . body . password ; if ( bcrypt . compareSync ( pass , user . password ) ) {", "del_tokens": "if ( bcrypt . compareSync ( req . body . password , user . password ) ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "basic", "tests", "remove", "unused", "folder", "make", "linux", "out", "dir", "behave", "like", "other", "OSes"], "add_tokens": "var finalDir = path . join ( opts . out || process . cwd ( ) , opts . name + '-linux' )", "del_tokens": "var finalDir = opts . out || path . join ( process . cwd ( ) , opts . name + '-linux' )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "local", "server", "for", "testing", "requester", "instead", "of", "mocking"], "add_tokens": "var clientRequest , that ; clientRequest = this . getRequest ( rqstOptions , function ( response ) { clientRequest . end ( ) ;", "del_tokens": "var request , that ; request = this . getRequest ( rqstOptions , function ( response ) { request . end ( ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "support", "for", "page", "objects"], "add_tokens": ". option ( '-p, --pageObjects <path>' , 'path to page objects. defaults to ./page-objects' , './page-objects' ) // store browserName globally (used within world.js to build driver) // used within world.js to import page objects global . pageObjects = path . resolve ( program . pageObjects ) ; // add cucumber world as first required script (this sets up the globals) // add path to import step definitions", "del_tokens": ". option ( '-p, --pageObjects <path>' , 'path to page objects' ) // store browserName globally (used within world.js) // add cucumber world as first required script (this sets up the gloals) // add cucumber world as first required script (this sets up the gloals)", "commit_type": "add"}
{"commit_tokens": ["Add", "optional", "replace", "override", "to", "parser"], "add_tokens": "* @ param { String } html - The HTML . * @ param { Object } [ options ] - The additional options . * @ param { Function } [ options . replace ] - The replace method . function htmlToReact ( html , options ) { return domToReact ( htmlToDOM ( html ) , options ) ;", "del_tokens": "* @ param { String } html - The HTML . function htmlToReact ( html ) { return domToReact ( htmlToDOM ( html ) ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "unquote", "and", "unquote", "-", "splicing", "from", "AST", ":", "expand", "them", "to", "lists", "instead"], "add_tokens": "'syntax-quote' : _leaf . bind ( null , 'syntax-quote' ) , 'eval' : _leaf . bind ( null , 'eval' ) ,", "del_tokens": "'syntax-quote' : _leaf . bind ( null , 'syntax-quote' ) , 'unquote' : _leaf . bind ( null , 'unquote' ) , 'unquote-splicing' : _leaf . bind ( null , 'unquote-splicing' ) , 'eval' : _leaf . bind ( null , 'eval' ) ,", "commit_type": "remove"}
{"commit_tokens": ["adding", "variables", "to", "style", "guide"], "add_tokens": "this . pushIntoGroup ( \"variables\" ) ;", "del_tokens": "// this.pushIntoGroup( \"variables\" );", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "cut", "function", "updated", "paste", "function"], "add_tokens": "init ( '<p><label>Text: <input type=\"text\" value=\"booooooob\" /></label></p>' ) ; elt . firstChild . firstChild . lastChild . selectionEnd = 8 ; describe ( \"cutting with the mouse the selected text inside an input[type=text]\" , function ( ) { before ( function ( ) { init ( '<p><label>Text: <input type=\"text\" value=\"booooooob\" /></label></p>' ) ; elt . firstChild . firstChild . lastChild . selectionStart = 1 ; elt . firstChild . firstChild . lastChild . selectionEnd = 8 ; } ) ; after ( uninit ) ; it ( \"should return the cutted content\" , function ( ) { assert . equal ( mouse . cut ( elt . firstChild . firstChild . lastChild ) , 'ooooooo' ) ; } ) ; it ( \"should change it's value\" , function ( ) { assert . equal ( elt . firstChild . firstChild . lastChild . value , 'bb' ) ; } ) ; } ) ;", "del_tokens": "init ( '<p><label>Text: <input type=\"text\" value=\"bob\" /></label></p>' ) ; elt . firstChild . firstChild . lastChild . selectionEnd = 2 ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "the", "reusing", "of", "data", "by", "copying", "it", "before", "testing", "on", "it"], "add_tokens": "var fse = require ( 'fs-extra' ) ; grunt . registerTask ( 'test' , function ( ) { fse . copySync ( 'fixtures/' , 'data/' , { clobber : true } ) ; grunt . task . run ( [ 'lint' , 'unit' ] ) ; } ) ;", "del_tokens": "grunt . registerTask ( 'test' , [ 'lint' , 'unit' ] ) ;", "commit_type": "allow"}
{"commit_tokens": ["Remove", "all", "error", "listeners", "."], "add_tokens": "stream . removeAllListeners ( 'error' ) ;", "del_tokens": "if ( process . env . NODE_ENV === 'test' ) { stream . setMaxListeners ( 1024 ) ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "umd", "support", "and", "move", "the", "source", "to", "the", "src", "directory"], "add_tokens": "src : [ 'src/rzslider.less' ] , 'src/rzslider.js'", "del_tokens": "src : [ 'rzslider.less' ] , 'rzslider.js'", "commit_type": "add"}
{"commit_tokens": ["Added", "indexOf", "polyFill", "from", "Mozilla", "a", "Polyfill", "for", "indexOf"], "add_tokens": "Dated : 2016 - 08 - 09 * /", "del_tokens": "Dated : 2016 - 07 - 30 * /", "commit_type": "add"}
{"commit_tokens": ["allow", "consuming", "from", "queue", "before", "calling", "attach"], "add_tokens": "c . consume ( ) ;", "del_tokens": "c . on ( 'attached' , function ( ) { // wait for messages c . consume ( ) ; } ) ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "div", "positioning", "for", "animations"], "add_tokens": "this . render ( ) ; this . render ( ) ; let $ = component . $ ( ) ; equal ( $ . prop ( 'class' ) , 'ember-view pop-over' ) ; equal ( $ . prop ( 'class' ) , 'ember-view pop-over orient-above' ) ; equal ( $ . prop ( 'class' ) , \"ember-view pop-over orient-below pointer-center\" ) ; equal ( $ . prop ( 'class' ) , \"ember-view pop-over pointer-left\" ) ; equal ( $ . prop ( 'class' ) , \"ember-view pop-over\" ) ;", "del_tokens": "const hasClass = function ( element , classNames ) { let $el = $ ( element ) ; let classList = Ember . A ( $ . trim ( $el . prop ( 'class' ) ) . split ( / \\s+ / ) ) . map ( function ( className ) { return $ . trim ( className ) ; } ) . join ( ' ' ) ; equal ( classList , classNames ) ; } ; this . append ( ) ; this . append ( ) ; let $ = component . $ ( '.pop-over' ) ; hasClass ( $ , 'pop-over' ) ; hasClass ( $ , 'pop-over orient-above' ) ; hasClass ( $ , \"pop-over orient-below pointer-center\" ) ; hasClass ( $ , \"pop-over pointer-left\" ) ; hasClass ( $ , \"pop-over\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "attempt", "()", "in", "index", ".", "js", "for", "retryable", "errors", "and", "cancellation", "."], "add_tokens": "googleMaps = require ( '../../lib/index' ) . init ( apiKey ) ; } , ( err , response ) => { expect ( err ) . toBe ( null ) ; expect ( response . json . results ) . toEqual ( done ( ) ; } ) ; it ( 'reverse geocodes the coordinates for the Sydney Opera House' , ( done ) => { } , ( err , response ) => { expect ( err ) . toBe ( null ) ; expect ( response . json . results ) . toEqual ( done ( ) ; } ) ;", "del_tokens": "var fetch = require ( 'node-fetch' ) ; fetch . Promise = require ( 'q' ) . Promise ; googleMaps = require ( '../lib/index' ) . init ( apiKey , fetch ) ; } ) . then ( ( response ) => response . json ( ) ) . then ( ( json ) => { expect ( json . results ) . toEqual ( } ) . then ( done , fail ) ; xit ( 'reverse geocodes the coordinates for the Sydney Opera House' , ( done ) => { } ) . then ( ( response ) => response . json ( ) ) . then ( ( json ) => { expect ( json . results ) . toEqual ( } ) . then ( done , fail ) ;", "commit_type": "use"}
{"commit_tokens": ["Change", "google", "storage", "endpoint", "to", "us", "https"], "add_tokens": "const googleStorageEndpoint = ` ` ;", "del_tokens": "const googleStorageEndpoint = ` ` ;", "commit_type": "change"}
{"commit_tokens": ["Add", "update", "route", "based", "on", "release", "channel"], "add_tokens": "this . router . get ( '/update/channel/:channel/:platform/:version/RELEASES' , this . onUpdateWin ) ; var channel = req . params . channel || '*' ; channel : channel var gitFilePath = ( channel === '*' ? '../../../../' : '../../../../../../' ) ; entry . filename = urljoin ( fullUrl , gitFilePath , '/download/' + entry . semver + '/' + entry . filename ) ;", "del_tokens": "channel : '*' entry . filename = urljoin ( fullUrl , '/../../../../' , '/download/' + entry . semver + '/' + entry . filename ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "fat", "arrow", "test", "on", "throws", "as", "it", "caused", "issues", "with", "assert"], "add_tokens": "function ( err ) { function ( err ) { function ( err ) {", "del_tokens": "( err ) => { ( err ) => { ( err ) => {", "commit_type": "remove"}
{"commit_tokens": ["use", "Lb", "()", "to", "mark", "open", "tag", "and", "Le", "for", "close", "one", "(", "L", ")", "azy", "(", "b", ")", "egin", "/", "(", "L", ")", "azy", "(", "e", ")", "nd"], "add_tokens": "window . Lb = function ( tag , inner ) { window . Le = function ( ) { document . write ( '</div ' ) ; } ;", "del_tokens": "window . Z = function ( tag , inner ) {", "commit_type": "use"}
{"commit_tokens": ["Allow", "reloading", "same", "file", "without", "specifying", "file", "path", "."], "add_tokens": "function Reader ( buf , filePath ) { filePath = buf ; this . filePath = filePath ; r = new Reader ( buf , file ) ; if ( typeof file === 'function' || typeof file === 'undefined' ) { cb = file ; file = this . filePath ; } if ( ! file ) { setImmediate ( function ( ) { cb ( new Error ( 'No file to load' ) ) ; } ) ; return ; } if ( ! file ) { file = this . filePath ; } if ( ! file ) { throw new Error ( 'No file to load' ) ; }", "del_tokens": "function Reader ( buf ) { r = new Reader ( buf ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "test", "case", "for", "cache", "logic"], "add_tokens": "if ( ! helper . isString ( key ) ) { if ( ! options . key ) { options . key = key ; }", "del_tokens": "if ( helper . isNumber ( key ) ) { options . key = key ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "text", "-", "indent", "and", "only", "for", "tests", "."], "add_tokens": "describe ( 'global/dialog' , ( ) => {", "del_tokens": "describe . only ( 'global/dialog' , ( ) => {", "commit_type": "remove"}
{"commit_tokens": ["Added", "new", "test", "for", "media", "query", "error"], "add_tokens": "console . log ( \"Loading \" , files ) ; console . log ( 'mapReadFiles Error: could not find: ' + process . cwd ( ) + filename ) ;", "del_tokens": "console . log ( 'mapReadFiles Error: could not find: ' + filename ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "compability", "for", "IE", "(", "input", "size", "issue", ")"], "add_tokens": "this . $input = $ ( '<input type=\"text\" placeholder=\"' + this . placeholderText + '\"/>' ) . appendTo ( this . $container ) ; this . $input . get ( 0 ) . style . setProperty ( 'width' , this . inputSize < 3 ? 3 : this . inputSize + 'em' , 'important' ) ; // to override bootstrap width !important $input . get ( 0 ) . style . setProperty ( 'width' , Math . max ( this . inputSize < 3 ? 3 : this . inputSize , $input . val ( ) . length ) + 'em' , 'important' ) ;", "del_tokens": "this . $input = $ ( '<input size=\"' + this . inputSize + '\" type=\"text\" placeholder=\"' + this . placeholderText + '\"/>' ) . appendTo ( this . $container ) ; $input . attr ( 'size' , Math . max ( this . inputSize , $input . val ( ) . length ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "try", "/", "catch", "on", "heapdump", "require"], "add_tokens": "try { var heapdump = require ( 'heapdump' ) ; var cwd = process . cwd ( ) ; console . error ( 'SIGUSR2 received! Writing snapshot.' ) ; process . chdir ( '/tmp' ) ; heapdump . writeSnapshot ( ) ; process . chdir ( cwd ) ; } catch ( e ) { self . _logger . log ( 'warn/service-runner/worker' , 'Worker ' + process . pid + ' received SIGUSR2, but heapdump is not installed' ) ; }", "del_tokens": "var heapdump = require ( 'heapdump' ) ; var cwd = process . cwd ( ) ; console . error ( 'SIGUSR2 received! Writing snapshot.' ) ; process . chdir ( '/tmp' ) ; heapdump . writeSnapshot ( ) ; process . chdir ( cwd ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "http", "etagCache", "function", "value", "to", "any", "supported", "type"], "add_tokens": "// Evaluate function first etagValue = etagValue ( httpConfig ) etagValueType = typeof etagValue } if ( etagValueType === 'object' ) {", "del_tokens": "etagCacheConfig = etagValue ( httpConfig ) } else if ( etagValueType === 'object' ) {", "commit_type": "allow"}
{"commit_tokens": ["Adding", "better", "error", "handling", "for", "google", "login", "."], "add_tokens": "helpers . render ( req . app . get ( 'stormpathGoogleLoginFailedView' ) , res ) ; helpers . render ( req . app . get ( 'stormpathGoogleLoginFailedView' ) , res ) ;", "del_tokens": "res . send ( 400 ) ; res . send ( 400 ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "failing", "code", "related", "attr", "tests"], "add_tokens": "assert . equal ( '<p class=\"tj\"></p>' , render ( 'p(class: name)' , { locals : { name : 'tj' } } ) ) ; assert . equal ( '<p class=\"default\"></p>' , render ( 'p(class: name || \"default\")' , { locals : { name : null } } ) ) ;", "del_tokens": "// assert.equal('', render('p(class: \"name\")', { locals: { name: 'tj' }}));", "commit_type": "add"}
{"commit_tokens": ["change", "test", "documents", "to", "draft", "-", "06"], "add_tokens": "'$schema' : ' http : //json-schema.org/draft-06/schema#', '$schema' : ' http : //json-schema.org/draft-06/schema#', '$schema' : ' http : //json-schema.org/draft-06/schema#', '$schema' : ' http : //json-schema.org/draft-06/schema#', '$schema' : ' http : //json-schema.org/draft-06/schema#', '$schema' : ' http : //json-schema.org/draft-06/schema#', '$schema' : ' http : //json-schema.org/draft-06/schema#',", "del_tokens": "'$schema' : ' http : //json-schema.org/draft-04/schema#', '$schema' : ' http : //json-schema.org/draft-04/schema#', '$schema' : ' http : //json-schema.org/draft-04/schema#', '$schema' : ' http : //json-schema.org/draft-04/schema#', '$schema' : ' http : //json-schema.org/draft-04/schema#', '$schema' : ' http : //json-schema.org/draft-04/schema#', '$schema' : ' http : //json-schema.org/draft-04/schema#',", "commit_type": "change"}
{"commit_tokens": ["add", "shadows", "screen", "to", "example", "project"], "add_tokens": "{ title : 'Shadows (iOS)' , tags : 'shadow' , screen : 'example.style.ShadowsScreen' }", "del_tokens": "{ title : 'Shadows (iOS)' , tags : 'shadow' , screen : 'example.ShadowsScreen' }", "commit_type": "add"}
{"commit_tokens": ["Add", "JSHint", "\\", "o", "/", "(", "&", "so", "fix", "Gruntfile", "error", ")"], "add_tokens": "grunt . loadNpmTasks ( 'grunt-contrib-jshint' ) ; grunt . loadNpmTasks ( 'grunt-jekyll' ) ; grunt . loadNpmTasks ( 'grunt-webfont' ) ; grunt . loadNpmTasks ( 'grunt-contrib-livereload' ) ; jshint : happyPlan . grunt . jshint , 'http_fonts_path = \"' + happyPlan . baseUrl + happyPlan . build . assets . fonts . replace ( happyPlan . build . path , '' ) + '\"' 'http_fonts_path = \"' + happyPlan . baseUrl + happyPlan . build . assets . fonts . replace ( happyPlan . build . path , '' ) + '\"'", "del_tokens": "grunt . loadNpmTasks ( 'grunt-contrib-livereload' ) ; grunt . loadNpmTasks ( 'grunt-jekyll' ) ; grunt . loadNpmTasks ( 'grunt-webfont' ) ; 'http_fonts_path = \"' + happyPlan . baseUrl + happyPlan . build . assets . fonts . replace ( happyPlan . build . path , '' ) + '\"' , 'http_fonts_path = \"' + happyPlan . baseUrl + happyPlan . build . assets . fonts . replace ( happyPlan . build . path , '' ) + '\"' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "runner", "config", "default", "port"], "add_tokens": "this . _port = 61616 ;", "del_tokens": "this . _hostname = 61616 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "mocha", "-", "setup", "helper", "file"], "add_tokens": "files : [ 'README.md' , 'LICENSE' , 'mocha-setup.js' ]", "del_tokens": "files : [ 'README.md' , 'LICENSE' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "hang", "on", "seek", "after", "adaptation", "."], "add_tokens": "// saner and fixes \"dead-zone\" issues such as #15 and #26. If seeking // within the buffered range, we avoid clearing so that we don't // re-download content. var time = this . video_ . currentTime ; var index = this . segmentIndex_ . findReferenceIndex ( time ) ; if ( ! this . sbm_ . isBuffered ( time ) || ! this . sbm_ . isInserted ( index ) ) {", "del_tokens": "// saner and fixes \"dead-zone\" issues such as #15. If seeking within // the buffered range, we avoid clearing so that we don't re-download // content. if ( ! this . sbm_ . isBuffered ( this . video_ . currentTime ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "two", "console", ".", "log", "()", "calls", "."], "add_tokens": "// console.log(\"FAILED with HTTP status code %d\", response.statusCode); // console.log('FAILED outside of HTTP: ' + e.message);", "del_tokens": "console . log ( \"FAILED with HTTP status code %d\" , response . statusCode ) ; console . log ( 'FAILED outside of HTTP: ' + e . message ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "logging", "labels", "and", "colors", "."], "add_tokens": "var logger = getLogger ( \"api\" ) ; var logger = getLogger ( \"models\" ) ; return rootLogger ;", "del_tokens": "var logger = getLogger ( ) ; var logger = getLogger ( ) ; var logger = logUtil . bindHelper ( rootLogger , '' ) ; return logger ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "retrieving", "stack", "frame", "in", "logErrorAndLine", "()"], "add_tokens": "console . log ( ' ' + exports . getLine ( true ) )", "del_tokens": "console . log ( ' ' + exports . getLine ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Move", "all", "error", "messages", "to", "single", "enum"], "add_tokens": "/ ** * List of error messages . * Please keep it in alphabetical order . * @ enum { string } * / var ErrorMessage = { HYPHEN_IS_NOT_SUPPORTED_IN_ARRAY_CONTEXT : 'Implementation does not support \"-\" token for arrays.' , INVALID_DOCUMENT : 'JSON document is not valid.' , INVALID_DOCUMENT_TYPE : 'JSON document must be a string.' , INVALID_POINTER : 'Pointer is not valid.' , NON_NUMBER_TOKEN_IN_ARRAY_CONTEXT : 'Non-number tokens cannot be used in array context.' , TOKEN_WITH_LEADING_ZERO_IN_ARRAY_CONTEXT : 'Token with leading zero cannot be used in array context.' } ; throw getError ( ErrorMessage . INVALID_DOCUMENT_TYPE ) ; throw getError ( ErrorMessage . INVALID_POINTER ) ; throw getError ( ErrorMessage . INVALID_DOCUMENT ) ; throw getError ( ErrorMessage . HYPHEN_IS_NOT_SUPPORTED_IN_ARRAY_CONTEXT ) ; throw getError ( ErrorMessage . NON_NUMBER_TOKEN_IN_ARRAY_CONTEXT ) ; throw getError ( ErrorMessage . TOKEN_WITH_LEADING_ZERO_IN_ARRAY_CONTEXT ) ;", "del_tokens": "throw getError ( 'JSON document must be a string.' ) ; throw getError ( 'Pointer is not valid.' ) ; throw getError ( 'JSON document is not valid.' ) ; throw getError ( 'Implementation does not support \"-\" token for arrays.' ) ; throw getError ( 'Non-number tokens cannot be used in array context.' ) ; throw getError ( 'Token with leading zero cannot be used in array context.' ) ;", "commit_type": "move"}
{"commit_tokens": ["fixing", "the", "csv", "-", "to", "-", "ping", "script", "if", "you", "have", "a", "lot", "of", "pings"], "add_tokens": "// Space out the calls by 500ms each setTimeout ( createMonitor . bind ( null , monitorBody ) , 500 * i ) ; function createMonitor ( monitorBody ) { synthetics . createMonitor ( monitorBody , program . dest , function createCB ( error , response , body ) { if ( ! error && response . statusCode == 201 ) { console . log ( 'Created:' , response . headers . location ) ; } else { if ( error ) { console . error ( 'error:' , error ) ; } else { console . error ( 'bad status code:' , response . statusCode ) ; console . error ( body ) ; } } } ) ; }", "del_tokens": "synthetics . createMonitor ( monitorBody , program . dest , function createCB ( error , response , body ) { if ( ! error && response . statusCode == 201 ) { console . log ( 'Created:' , response . headers . location ) ; } else { if ( error ) { console . error ( 'error:' , error ) ; } else { console . error ( 'bad status code:' , response . statusCode ) ; console . error ( body ) ; } } } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "breaking", "flash", "middleware", "."], "add_tokens": "if ( req . session === undefined ) {", "del_tokens": "if ( req . sessions === undefined ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "pid", "to", "startup", "log", "statement"], "add_tokens": "'Anvil Connect pid %s is running on port %s' , process . pid , server . settings . port", "del_tokens": "'Anvil Connect is running on port ' + server . settings . port", "commit_type": "add"}
{"commit_tokens": ["Use", "_", ".", "reduce", "instead", "Object", ".", "entries", "for", "node", "6", "support", "."], "add_tokens": "const fields = _ . reduce ( projection , ( memo , value , key ) => { if ( key !== '_id' && value !== undefined && ! value ) { if ( value || ( key === '_id' && value === undefined && includeIdDefault ) ) { memo . push ( key ) ; return memo ; } , [ ] ) ;", "del_tokens": "const fields = [ ] ; for ( const [ field , value ] of Object . entries ( projection ) ) { if ( field !== '_id' && value !== undefined && ! value ) { if ( value || ( field === '_id' && value === undefined && includeIdDefault ) ) { fields . push ( field ) ; }", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "ifnot", "binding", "(", "inline", "and", "containerless", ")", "."], "add_tokens": "if ( binding === 'ifnot' ) { binding = 'if' ; if ( ( match = stmt . match ( syntaxRegex . ifnot ) ) ) { }", "del_tokens": "/ *if (binding === 'ifnot') { * / / *if ((match = stmt.match(syntaxRegex.ifnot))) { } * /", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "that", "Async", "function", "times", "out"], "add_tokens": "if ( promise && _ . isFunction ( promise . then ) ) { // Returning non-Promise values would be meaningless for lambda. // But inherit the behavior of the original handler. return promise ;", "del_tokens": "if ( promise && _ . isFunction ( promise . then ) && ! callback ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "cyclic", "import", "issue", "(", "GroupedData", "<", "-", ">", "DataFrame", ")"], "add_tokens": "// run-time require is ugly workaround for issues with import cycle. var DataFrame = require ( './DataFrame' ) ; return new DataFrame ( this . jvm_obj . count ( ) ) ;", "del_tokens": "return this . jvm_obj . count ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "skull", ".", "babylon", "from", "project", "."], "add_tokens": "const googleStorageEndpoint = ` ` ; < ArcRotateCamera target = { [ 0 , 0 , 0 ] } < Mesh path = { googleStorageEndpoint } fileName = { 'skull.babylon' }", "del_tokens": "import skullMesh from \"../meshes/skull.babylon\" ; < ArcRotateCamera target = { [ 0 , 0 , 0 ] } < Mesh path = { skullMesh . split ( \"/\" ) [ 1 ] + \"/\" } fileName = { skullMesh . split ( \"/\" ) [ 2 ] }", "commit_type": "remove"}
{"commit_tokens": ["added", "api", "key", "test", "expectation", "to", "all", "providers"], "add_tokens": "'Google Analytics' : 'x' expect ( analytics . providers [ 0 ] . settings . trackingId ) . to . equal ( 'x' ) ;", "del_tokens": "'Google Analytics' : 'UA-XXXXXXX-X'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "and", "removed", "push", "from", "task"], "add_tokens": "'shell:github-pages-commit'", "del_tokens": "'shell:github-pages-commit' , 'shell:github-pages-push'", "commit_type": "fix"}
{"commit_tokens": ["fix", "toRegExpAction", "of", "eventListener", "action"], "add_tokens": "return new RegExp ( '(^|\\\\s)(' + list . join ( '|' ) + ')($|\\\\s|\\\\.)' ) ;", "del_tokens": "return new RegExp ( '^(' + list . join ( '|' ) + ')\\\\.?' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "required", "toggle", "in", "FormComponent"], "add_tokens": "if ( isRequired ) { els . forEach ( function ( el ) { el . setAttribute ( 'required' , true ) ; } ) ; } else { els . forEach ( function ( el ) { el . removeAttribute ( 'required' ) ; } ) ; } return true ;", "del_tokens": "[ ] . forEach . call ( els , function ( el ) { el . setAttribute ( 'required' , true ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "base64", "add", "a", "trim", "on", "files", "encrypto", "."], "add_tokens": "shield : { } , base64 : { options : { log : true , base64 : true , encodingLevelStart : 10 , encodingLevelEnd : 15 , notEncode : [ 'css' , 'js' , 'img' , 'view' , 'config' , 'index.php' ] , } , files : [ { src : [ '**' ] , dest : 'tmp/app' , cwd : 'test/fixtures/app' } ] grunt . registerTask ( 'test_shield' , [ 'php_shield:shield' , 'nodeunit' ] ) ; grunt . registerTask ( 'test_base64' , [ 'php_shield:base64' , 'nodeunit' ] ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'test_base64' ] ) ;", "del_tokens": "crypto : { log : true , base64 : true , encodingLevelStart : 2 , encodingLevelEnd : 5 , notEncode : [ 'css' , 'js' , 'img' , 'view' , 'config' , 'index.php' ] , grunt . registerTask ( 'test' , [ 'php_shield' , 'nodeunit' ] ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'test' ] ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "topic", "support", "and", "connect", "method"], "add_tokens": "* @ property { string } topic this . connection = false ; this . topics = backendConfig . topics ; / ** * Sets the connection flag . * / connect ( ) { this . connection = true ; } requeue : requeue . bind ( null , this , record . id ) , topic : record . topic * @ param { string } topic sendMessage ( message , callback , topic ) { finalMessage . topic = topic ;", "del_tokens": "requeue : requeue . bind ( null , this , record . id ) sendMessage ( message , callback ) {", "commit_type": "add"}
{"commit_tokens": ["Improving", "loading", "of", "non", "-", "marker", "sublayers", "."], "add_tokens": "if ( ! ( 'options' in layer ) || ! ( 'icon' in layer . options ) ) { for ( var i in this . _staticLayers ) { map . addLayer ( this . _staticLayers [ i ] ) ; }", "del_tokens": "if ( ! '_icon' in layer ) {", "commit_type": "improve"}
{"commit_tokens": ["Use", "can", "-", "simple", "-", "map", "for", "scope", "references"], "add_tokens": "var SimpleMap = require ( \"can-simple-map\" ) ; var ReferenceMap = SimpleMap . extend ( { } ) ; return oldIsMapLike . call ( this , obj ) ;", "del_tokens": "var Construct = require ( \"can-construct\" ) ; var canBatch = require ( \"can-event/batch/batch\" ) ; var canEvent = require ( \"can-event\" ) ; var assign = require ( \"can-util/js/assign/assign\" ) ; var ObserveInfo = require ( \"can-observe-info\" ) ; var ReferenceMap = Construct . extend ( \"ReferenceMap\" , { setup : function ( ) { this . _data = { } ; } , attr : function ( prop , value ) { if ( arguments . length > 1 ) { var old = this . _data [ prop ] ; this . _data [ prop ] = value ; canBatch . trigger . call ( this , prop , [ old ] ) ; } else { if ( prop !== \"constructor\" ) { ObserveInfo . observe ( this , prop ) ; return this . _data [ prop ] ; } else { return this . constructor ; } } } } ) ; assign ( ReferenceMap . prototype , canEvent ) ; } else { return oldIsMapLike . call ( this , obj ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "pointer", "events", "on", "dimmed", "areas"], "add_tokens": "gulp . task ( 'css:docs' , function ( ) { gulp . src ( './docs/welcome/sass/*.sass' ) . pipe ( sass ( ) ) . pipe ( prefixer ( ) ) . pipe ( gulp . dest ( './docs/welcome/css' ) ) ; } ) ; gulp . task ( 'build' , [ 'js' , 'css' , 'eager' ] ) ; gulp . task ( 'default' , [ 'build' ] ) ;", "del_tokens": "gulp . task ( 'build' , [ 'js' , 'css' , 'eager' ] ) gulp . task ( 'default' , [ 'build' ] )", "commit_type": "remove"}
{"commit_tokens": ["Add", "default", "radius", "to", "arc"], "add_tokens": "* @ param { Number } [ radius = 0 ] - Distance from center to outer edge constructor ( positionDefinition , radius = 0 , startAngle = 0 , endAngle = 0.5 , options ) {", "del_tokens": "* @ param { Number } radius - Distance from center to outer edge constructor ( positionDefinition , radius , startAngle = 0 , endAngle = 0.5 , options ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "formatting", "of", "<reply", ">", "tag", "in", "triggers"], "add_tokens": "let value = self . formatMessage ( history [ type ] [ i - 1 ] , type === \"reply\" ) ; regexp = regexp . replace ( new RegExp ( ` ${ type } ${ i } ` , \"g\" ) , value ) ;", "del_tokens": "regexp = regexp . replace ( new RegExp ( ` ${ type } ${ i } ` , \"g\" ) , history [ type ] [ i - 1 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "two", "-", "way", "binding", "for", "text", "boxes"], "add_tokens": "return ! $scope . $root . $$phase ; template : '<section><datalist id=\"numbers\"><option ng-repeat=\"index in iter(max)\">{{index}}</option></datalist><input list=\"numbers\" type=\"range\" ng-change=\"_which = 0\" ng-model=\"_model[0]\" min=\"{{_values.min}}\" max=\"{{_values.max}}\" step=\"{{_step}}\" /><input type=\"range\" ng-change=\"_which = 1\" ng-model=\"_model[1]\" min=\"{{_values.min}}\" max=\"{{_values.max}}\" step=\"{{_step}}\" /></section>' , * @ property _values * @ type { Object } scope . _values = { min : scope . min || 0 , max : scope . max || 100 } ; // Listen for any changes to the original model. scope . $watch ( 'model' , function alteredValues ( ) { scope . _model = [ scope . model . from , scope . model . to ] ; } , true ) ;", "del_tokens": "return ! ! $scope . $root . $$phase ; template : '<section><datalist id=\"numbers\"><option ng-repeat=\"index in iter(max)\">{{index}}</option></datalist><input list=\"numbers\" type=\"range\" ng-change=\"_which = 0\" ng-model=\"_model[0]\" min=\"{{_min}}\" max=\"{{_max}}\" step=\"{{_step}}\" /><input type=\"range\" ng-change=\"_which = 1\" ng-model=\"_model[1]\" min=\"{{_min}}\" max=\"{{_max}}\" step=\"{{_step}}\" /></section>' , * @ property _min * @ type { Number } * @ private * / scope . _min = scope . min || 0 ; / ** * @ property _max * @ type { Number } scope . _max = scope . max || 100 ; scope . $watch ( 'min' , function alteredMin ( ) { scope . _min = scope . min ; } ) ; scope . $watch ( 'max' , function alteredMax ( ) { scope . _max = scope . max ; _reevaluateInputs ( ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "tests", "to", "specify", "additional", "globals"], "add_tokens": "var context = extend ( { require : require , module : module , exports : module . exports , assert : assert } , config . context || { } ) ; var contextKeys = Object . keys ( context ) ; var contextValues = contextKeys . map ( function ( key ) { return context [ key ] ; } ) ; var fn = new Function ( contextKeys , code ) ; fn . apply ( { } , contextValues ) ;", "del_tokens": "var fn = new Function ( 'require' , 'module' , 'exports' , 'assert' , code ) ; fn ( require , module , module . exports , assert ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "raw", "row", "not", "included", "on", "the", "row", "object"], "add_tokens": "var headerRow = new Row ( inputHeaders ) ; row = new Row ( rawRow ) ; constructor ( raw ) { this . raw = raw || { } ;", "del_tokens": "var headerRow = new Row ( ) ; headerRow . raw = inputHeaders ; row = new Row ( ) ; constructor ( ) { this . raw = { } ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "up", "zoom", "out", "not", "always", "removing", "child", "clusters", "."], "add_tokens": "if ( depthToStartAt === 0 ) { this . _recursivelyRemoveChildrenFromMap ( bounds , depthToAnimateIn ) ; //TODO: previousBounds, not bounds if ( this . _isSingleParent ( ) && depthToAnimateIn === 1 ) { //If we are the same as our parent, don't do an animation, just immediately appear this . _recursivelyRemoveChildrenFromMap ( depthToAnimateIn ) ; //Immediately remove our children as we are replacing them console . log ( 'skipping' ) ; if ( depth === 0 ) {", "del_tokens": "if ( depthToStartAt == 0 ) { this . _recursivelyRemoveChildrenFromMap ( depthToAnimateIn ) ; if ( this . _isSingleParent ( ) && depthToAnimateIn == 1 ) { //If we are the same as our parent, don't do an animation, just immediately appear this . _recursivelyRemoveChildrenFromMap ( depthToAnimateIn ) ; //Immediately if ( depth === 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "defining", "routing", "rule", "when", "connecting"], "add_tokens": "this . _routingRule = 'identity' ; connectWithPassword ( identifier , password , routingRule ) { this . _routingRule = routingRule || this . _routingRule ; connectWithKey ( identifier , key , routingRule ) { this . _routingRule = routingRule || this . _routingRule ; routingRule : this . _routingRule", "del_tokens": "connectWithPassword ( identifier , password ) { connectWithKey ( identifier , key ) { routingRule : 'identity'", "commit_type": "allow"}
{"commit_tokens": ["Allow", "post", "-", "transforms", "on", "the", "bundle", "stream"], "add_tokens": "var concat = require ( 'concat-stream' ) ; var pipes = options . pipes || function ( x ) { return x ; } ; var output = pipes ( b . bundle ( options ) ) ; output . on ( 'error' , reject ) ; output . pipe ( concat ( { encoding : 'string' } , resolve ) ) ;", "del_tokens": "function once ( func ) { var called = false ; return function ( ) { if ( called ) { return ; } called = true ; func . apply ( this , arguments ) ; } ; } b . bundle ( options , once ( function ( err , result ) { if ( err ) { reject ( err ) ; } else { resolve ( result ) ; } } ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "disabled", "state", "to", "button", "and", "always", "show", "all", "buttons", "even", "if", "disabled"], "add_tokens": "< LogMonitorButton theme = { theme } onClick = { : : this . handleRollback } enabled = { computedStates . length } > Revert < / LogMonitorButton > < LogMonitorButton theme = { theme } onClick = { : : this . handleSweep } enabled = { Object . keys ( skippedActions ) . some ( key => skippedActions [ key ] ) } > Sweep < / LogMonitorButton > < LogMonitorButton theme = { theme } onClick = { : : this . handleCommit } enabled = { computedStates . length > 1 } > Commit < / LogMonitorButton >", "del_tokens": "{ computedStates . length > 1 && < LogMonitorButton theme = { theme } onClick = { : : this . handleRollback } > Revert < / LogMonitorButton > } { Object . keys ( skippedActions ) . some ( key => skippedActions [ key ] ) && < LogMonitorButton theme = { theme } onClick = { : : this . handleSweep } > Sweep < / LogMonitorButton > } { computedStates . length > 1 && < LogMonitorButton theme = { theme } onClick = { : : this . handleCommit } > Commit < / LogMonitorButton > }", "commit_type": "add"}
{"commit_tokens": ["moved", "monochrome", "to", "color", "dictionary"], "add_tokens": "} } , monochrome : { hueRange : [ 0 , 0 ] , sMin : 0 , vMin : 0", "del_tokens": "} if ( options . hue === 'monochrome' ) { return 0 ; // The H value has no effect on the appearance of a grey } ; console . log ( 'dark color requested!!!' ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "new", "enum", "for", "flag_color", ";", "improve", "update", "txn", "example"], "add_tokens": "transaction . memo = \"Updated memo\" ; transaction", "del_tokens": "let updateTransaction = ynab . utils . convertTransactionToSaveTransaction ( transaction ) ; updateTransaction . memo = \"Updated memo\" ; transaction : updateTransaction", "commit_type": "use"}
{"commit_tokens": ["make", "sure", "uris", "can", "come", "from", "redis"], "add_tokens": "{ CACHE_ENABLED } = require ( './constants' ) , { isUri } = require ( 'clayutils' ) ; . then ( val => { try { return JSON . parse ( val ) ; } catch ( e ) { return val ; } } ) // Always parse on the way out to match Postgres . catch ( ( ) => { return postgres . get ( key ) ; } ) ;", "del_tokens": "{ CACHE_ENABLED } = require ( './constants' ) ; . then ( JSON . parse ) // Always parse on the way out to match Mongo . catch ( ( ) => postgres . get ( key ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "test", "of", "delay", "option"], "add_tokens": "var DEFAULT_HOST = '0.0.0.0:28987' ; // test utility for get request the server var get = function ( path , cb ) { exec ( 'curl ' + DEFAULT_HOST + path , function ( error , stdout , stderr ) { cb ( stdout . toString ( ) ) ; } ) ; } ; get ( '/hello' , function ( responseText ) { expect ( responseText ) . to . equal ( 'Hello, world!' ) ; it ( 'registers a delayed response for a path if delay option is specified' , function ( done ) { stubbatti . register ( 'get' , '/delay' , 'delayed response' , { delay : 1000 } ) ; var startTime = new Date ( ) . getTime ( ) ; stubbatti . start ( function ( ) { get ( '/delay' , function ( responseText ) { expect ( responseText ) . to . equal ( 'delayed response' ) ; var endTime = new Date ( ) . getTime ( ) ; var error = Math . abs ( startTime + 1000 - endTime ) ; expect ( error ) . to . be . below ( 100 ) ; done ( ) ; } ) ; } ) ; } ) ;", "del_tokens": "exec ( 'curl 0.0.0.0:28987/hello' , function ( err , stdout , stderr ) { expect ( stdout ) . to . equal ( 'Hello, world!' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "extra", "test", "for", "propertyless", "event", "to", "gosquared", "and", "got", "it", "passing"], "add_tokens": "analytics . track ( event ) ; // GoSquared adds the event name to the properties hash. var augmentedProperties = { gs_evt_name : event } ; expect ( spy ) . to . have . been . calledWith ( [ event , sinon . match ( augmentedProperties ) ] ) ; spy . restore ( ) ; // GoSquared adds the event name to the properties hash. augmentedProperties = _ . extend ( properties , { gs_evt_name : event } ) ;", "del_tokens": "var augmentedProperties = _ . extend ( properties , { gs_evt_name : event } ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "HTTP", "use", "promises", "and", "add", "HTTP", "tests"], "add_tokens": "init : function ( isSplunk ) { this . _super ( isSplunk ) ; } , makeRequest : function ( url , message , callback ) { data : message . body || \"\" ,", "del_tokens": "request : function ( url , message , callback ) { data : message . body ,", "commit_type": "make"}
{"commit_tokens": ["Make", "the", "$location", "properties", "actually", "functions", "."], "add_tokens": "return function ( ) { if ( request ) { return code ( ) ; } else { return undefined ; } } ; return function ( ) { if ( request ) { if ( ! requestUrlParts ) { requestUrlParts = url . parse ( request . url , true ) ; } return code ( requestUrlParts ) ; else { return undefined ; } } ;", "del_tokens": "if ( request ) { return code ( ) ; } else { return undefined ; } if ( request ) { if ( ! requestUrlParts ) { requestUrlParts = url . parse ( request . url , true ) ; return code ( requestUrlParts ) ; } else { return undefined ; }", "commit_type": "make"}
{"commit_tokens": ["fixing", "out", "of", "place", "comma"], "add_tokens": "'margin-right' : me . margin . right + 'px'", "del_tokens": "'margin-right' : me . margin . right + 'px' ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "variable", "name", "."], "add_tokens": "return ( global !== undefined && global . location !== undefined && global . location . protocol !== undefined", "del_tokens": "return ( global !== undefined && global . locaion !== undefined && global . location . protocol !== undefined", "commit_type": "fix"}
{"commit_tokens": ["Use", "ES5", "Syntax", "node", "CI", "node4", "tests", "continued"], "add_tokens": "const expect = require ( \"chai\" ) . expect ;", "del_tokens": "const { expect } = require ( \"chai\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "documentation", "for", "the", "new", "hide", "property", "on", "fields"], "add_tokens": "formId : '=formId' , index : '=index' , var templateUrl = $scope . options . templateUrl || getTemplateUrl ( $scope . options . type ) ; if ( typeof $scope . options . default !== 'undefined' ) { $templateCache . put ( 'directives/formly-form.html' , '<form class=formly role=form><formly-field ng-repeat=\"field in fields\" options=field form-value=result[field.key||$index] class=formly-field form-id=options.uniqueFormId index=$index ng-hide=field.hide></formly-field><button type=submit ng-hide=options.hideSubmit>{{options.submitCopy || \"Submit\"}}</button></form>' ) ;", "del_tokens": "formId : '@formId' , index : '@index' , var templateUrl = getTemplateUrl ( $scope . options . type ) ; if ( $scope . options . default ) { formId : '@formId' , controller : [ '$scope' , '$element' , function formController ( $scope , $element ) { } ] , $templateCache . put ( 'directives/formly-form.html' , '<form class=formly role=form><formly-field ng-repeat=\"field in fields\" options=field form-value=result[field.key||$index] class=formly-field form-id={{options.uniqueFormId}} index={{$index}}></formly-field><button type=submit ng-hide=options.hideSubmit>{{options.submitCopy || \"Submit\"}}</button></form>' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "Array", ".", "prototype", ".", "find", "polyfill"], "add_tokens": "// (form)(control/widget) import { FormControl , Checkbox } from 'react-bootstrap' ; // YBZSAAS-461 // IE11Array.prototype.find() import 'core-js/fn/array/find' ;", "del_tokens": "// (form)(control/widget) import { FormControl , Checkbox } from 'react-bootstrap' ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "latitude", "parsing", "in", "nodeview"], "add_tokens": "function createNodesView ( pb , pg ) { function get ( i ) { return { lat : 0.000000001 * ( pb . lat_offset . toNumber ( ) + ( pb . granularity * pg . dense . lat [ i ] . toNumber ( ) ) ) } ; } length : length , get : get function extendPrimitiveGroup ( pb , pg ) { pg . nodesView = createNodesView ( pb , pg ) ; extendPrimitiveGroup ( data , data . primitivegroup [ i ] ) ;", "del_tokens": "function createNodesView ( pg ) { length : length function extendPrimitiveGroup ( pg ) { pg . nodesView = createNodesView ( pg ) ; extendPrimitiveGroup ( data . primitivegroup [ i ] ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "for", "CSS", "class", "applier", "more", "range", "/", "selection", "wrapper", "work"], "add_tokens": "features : { domRangeProperties : domRangeProperties , domRangeMethods : domRangeMethods } , api . features . rangesAreTextRanges = rangesAreTextRanges ; return true ; return false ; return true ; return false ; var endNode = range . endContainer , endOffset = range . endOffset ; return range . endContainer !== endNode || range . endOffset !== endOffset ; var startNode = range . startContainer , startOffset = range . endOffset ; return range . startContainer !== startNode || range . startOffset !== startOffset ; return false ; return true ; return false ; return true ; api . rangesIntersect = rangesIntersect ; return sel . anchorNode === null ? 0 : 1 ;", "del_tokens": "features : { } , api . rangesAreTextRanges = rangesAreTextRanges ; return 1 ;", "commit_type": "fix"}
{"commit_tokens": ["add", "request", "test", "and", "response", "test"], "add_tokens": "return gulp . src ( [ 'test/index.js' , 'test/context/*' , 'test/request/*' , 'test/response/*' ] , { read : false } ) . pipe ( mocha ( ) ) ;", "del_tokens": "return gulp . src ( [ 'test/index.js' , 'test/context/*' ] , { read : false } ) . pipe ( mocha ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "all", "pre", "and", "post", "api", "logic", "."], "add_tokens": "self . caches = [ ] ; self . caches . push ( cache ) ; self . caches . push ( self . cacheModuleConfig [ i ] . cache ) ; if ( self . caches . length < 1 ) { throw new exception ( 'NoCacheException' , 'No caches were succesfully initialized.' ) ;", "del_tokens": "self . preApi = [ ] ; self . postApi = [ ] ; if ( cacheConfig . postApi && self . postApi . length > 0 ) { continue ; } var preOrPostApi = ( ! cacheConfig . postApi ) ? 'preApi' : 'postApi' ; self [ preOrPostApi ] . push ( cache ) ; var preOrPostApi = ( ! cacheConfig . postApi ) ? 'preApi' : 'postApi' ; self [ preOrPostApi ] . push ( self . cacheModuleConfig [ i ] . cache ) ; if ( self . preApi . length < 1 ) { throw new exception ( 'NoCacheException' , 'No pre-api caches were succesfully initialized.' ) ;", "commit_type": "remove"}
{"commit_tokens": ["make", "remote", "template", "instantiations", "monkey", "-", "patch", "the", "root", "element"], "add_tokens": "if ( template ) { entity . addEventListener ( 'loaded' , function ( ) { var templateChild = entity . firstChild ; templateChild . addEventListener ( 'templaterendered' , function ( ) { var cloned = templateChild . firstChild ; // mirror the attributes Array . prototype . slice . call ( cloned . attributes ) . forEach ( function ( attr ) { entity . setAttribute ( attr . nodeName , attr . nodeValue ) ; } ) ; // take the children for ( var child = cloned . firstChild ; child ; child = cloned . firstChild ) { cloned . removeChild ( child ) ; entity . appendChild ( child ) ; } cloned . pause ( ) ; templateChild . pause ( ) ; setTimeout ( function ( ) { try { templateChild . removeChild ( cloned ) ; } catch ( e ) { } try { entity . removeChild ( templateChild ) ; } catch ( e ) { } // delete? } ) ; } ) ; } ) ; } //showLocalTemplate: entityData.showTemplate, //showRemoteTemplate: entityData.showTemplate, //entity.setAttribute('networked-share', networkData); module . exports = NetworkEntities ;", "del_tokens": "module . exports = NetworkEntities ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "recursive", "creation", "of", "less", "files", "on", "init"], "add_tokens": "lessWatchCompilerUtilsModule . walk ( f , options , callback , initCallback ) ;", "del_tokens": "lessWatchCompilerUtilsModule . walk ( f , options , callback ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "create", "dir", "and", "file", "bug"], "add_tokens": "var fsx = require ( 'fs-extra' ) ; var genDefaultCompareConfig = function ( ) { fsx . ensureFileSync ( paths . compareConfigFileName ) ; fsx . writeFileSync ( paths . compareConfigFileName , JSON . stringify ( configDefault , null , 2 ) ) ;", "del_tokens": "var fs = require ( 'fs' ) ; var genDefaultCompareConfig = function ( cb ) { fs . writeFile ( paths . compareConfigFileName , JSON . stringify ( configDefault , null , 2 ) , function ( err ) { if ( err ) { console . log ( 'error: while genDefaultCompareConfig();' ) } if ( typeof cb == 'object' ) cb ( ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "Seq", ".", "UUID", "as", "a", "custom", "type"], "add_tokens": "const storeInit = require ( './lib/sqlStore' ) , typesInit = require ( './lib/customTypes' ) ; typesInit ( thorin ) ;", "del_tokens": "const storeInit = require ( './lib/sqlStore' ) ; require ( './lib/customTypes' ) ;", "commit_type": "add"}
{"commit_tokens": ["Create", "ui", "-", "currency", "directive", "to", "extend", "angular", "currency", "filter"], "add_tokens": "'modules/directives/date/test/*.js' , 'modules/directives/currency/src/*.js' , 'modules/directives/currency/test/*.js'", "del_tokens": "'modules/directives/date/test/*.js'", "commit_type": "create"}
{"commit_tokens": ["fix", "annotations", "for", "google", "closure"], "add_tokens": "* @ param { ( Array . < string > | string ) = } dependencies array of module names * @ param { ( string | function ( ) | Object ) = } factory * @ type { Object } new loaderError ( 'Unexpected factory type for ' new loaderError ( 'mod with no factory detected in a module file' ) ; new loaderError ( 'Invalid module path: ' + path ) ;", "del_tokens": "* @ param { ( Array . < string > ) = } dependencies array of module names * @ param { ( string | function | Object ) = } factory * @ type { object } loaderError ( 'Unexpected factory type for ' loaderError ( 'mod with no factory detected in a module file' ) ; loaderError ( 'Invalid module path: ' + path ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "JavaScript", "Standard", "Style", ";", "Add", "test", "for", "malformed", "HHMMSS", "time", "in", "stop_times"], "add_tokens": "if ( arrival === null ) { console . warn ( 'No valid arrival time: ' + stopTimeRow . arrival_time ) return result } if ( departure === null ) { console . warn ( 'No valid departure time: ' + stopTimeRow . departure_time ) return result result . push ( obj ) return result } , [ ] )", "del_tokens": "if ( arrival === null || departure === null ) { return result ; result . push ( obj ) ; return result ; } , [ ] ) ;", "commit_type": "use"}
{"commit_tokens": ["Updating", "webpack", "config", "to", "rearragne", "license", "text"], "add_tokens": "const fs = require ( 'fs' ) ; const licenseBanner = fs . readFileSync ( 'src/LICENSE' , 'utf8' ) ; const webpack = require ( 'webpack' ) ; compress : true , output : { comments : false , } , } ) , new webpack . BannerPlugin ( { banner : licenseBanner , raw : true , } ) ,", "del_tokens": "sourceMap : true , } )", "commit_type": "update"}
{"commit_tokens": ["add", "Index", ".", "create", "()", "stub"], "add_tokens": "var DEFAULT_STATIC_FALLBACK_INDEX = '/ipfs/QmPxLM631zJQ12tUDWs55LkGqqroFZKHeLjAZ2XwL9Miu3' ; Index . create = function create ( ) { // TODO: make it work with js-ipfs && IPFSStorage this . storage = new merkleBtree . RAMStorage ( ) ; this . identitiesBySearchKey = new merkleBtree . MerkleBTree ( this . storage , IPFS_INDEX_WIDTH ) ; this . messagesByTimestamp = new merkleBtree . MerkleBTree ( this . storage , IPFS_INDEX_WIDTH ) ; return true ; } ;", "del_tokens": "var DEFAULT_STATIC_FALLBACK_INDEX = '/ipns/Qmbb1DRwd75rZk5TotTXJYzDSJL6BaNT1DAQ6VbKcKLhbs' ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "adding", "/", "editing", "/", "deleting", "employee", "photos"], "add_tokens": "photo = require ( './handlers/employees/{username}/photos/{photoType}' ) , photo . init ( server , function ( ) { projects . init ( server , function ( ) { } ) ; } ) ; server . get ( '/employees/{username}/photos/{photoType}' , photo . get ) ; server . put ( '/employees/{username}/photos/{photoType}' , photo . put ) ; server . delete ( '/employees/{username}/photos/{photoType}' , photo . delete ) ;", "del_tokens": "projects . init ( server , function ( ) { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "add", "links", "between", "couples", "of", "lat", "long", "or", "x", "y", "coordinates"], "add_tokens": "if ( typeof options . links [ id ] . between [ 0 ] == 'string' ) { p1 = options . plots [ options . links [ id ] . between [ 0 ] ] ; } else { p1 = options . links [ id ] . between [ 0 ] ; } if ( typeof options . links [ id ] . between [ 1 ] == 'string' ) { p2 = options . plots [ options . links [ id ] . between [ 1 ] ] ; } else { p2 = options . links [ id ] . between [ 1 ] ; }", "del_tokens": "p1 = options . plots [ options . links [ id ] . between [ 0 ] ] ; p2 = options . plots [ options . links [ id ] . between [ 1 ] ] ;", "commit_type": "allow"}
{"commit_tokens": ["added", "[", "send", "]", "and", "pd", ".", "receive", "()"], "add_tokens": "/** send a message from inside the graph to a named receiver outside the graph **/ this . receive = function ( name , callback ) { pd . addlistener ( name , { \"message\" : function ( d , val ) { callback ( val ) ; } } ) ; } /** send a bang to all receive objects named \"test\" **/ // listen out for messages from the ether with the name of our argument // ordinary message sender \"send\" : { \"outletTypes\" : [ \"message\" ] , \"init\" : function ( ) { if ( this . args . length >= 6 ) { this . id = this . args [ 5 ] ; } else { //TODO:cause lack of arg to create 2nd inlet this . pd . log ( \"error: must provide a name\" ) ; } } , \"message\" : function ( inletnum , val ) { if ( inletnum == 0 ) { this . pd . send ( this . id , val ) ; } } , } , PdObjects . s = PdObjects . send ;", "del_tokens": "// listen out for messages from the either with the name of our argument", "commit_type": "add"}
{"commit_tokens": ["added", "shim", "for", "rbush", "and", "box2d"], "add_tokens": "if ( ! ( a0 <= b1 && b0 <= a1 ) ) {", "del_tokens": "if ( a [ 0 ] <= b [ 1 ] && b [ 0 ] <= a [ 1 ] ) {", "commit_type": "add"}
{"commit_tokens": ["update", "minor", "-", "update", "comments", "and", "constant"], "add_tokens": "mnomonic = require ( './utils/mnemonic' ) ; / ** * Generate a keystore object based on given passphrase and private key along * with other params like salt , iv and key derivation * @ param { String } password [ A passphrase entered to create keystore object ] * @ param { String } privateKey [ A 64 bytes Hex String ] * @ param { String } salt [ A 32 bytes Hex String ] * @ param { String } iv [ A 16 bytes Hex String ] * @ param { Object } option [ An object contains kdf method and params ] * / throw new Error ( 'message authentication code mismatch' ) ;", "del_tokens": "mnomonic = require ( './utils/mnemonic' ) , ADDRESS_LENGTH = 40 ; //20 bytes return new Error ( 'message authentication code mismatch' ) ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "error", "handling", "and", "loggin", "in", "store"], "add_tokens": "lib = require ( './lib' ) , log = require ( './log' ) ; log . out ( 'Sending message:' , fmsg ) ; log . out ( 'Received message at:' , this . processID , 'from:' , channel , message ) ; log . error ( 'Store error:' , err . stack ) ; try { this . client . end ( ) ; this . pub . end ( ) ; this . sub . end ( ) ; } catch ( ex ) { log . error ( 'Unable to close store client connections.' ) ; }", "del_tokens": "lib = require ( './lib' ) ; console . log ( '--- SENDING MESSAGE:' , fmsg ) ; console . log ( 'RECEIVED MESSAGE at:' , this . processID , 'from:' , channel , message ) ; console . log ( '\\n\\n--- STORE ERROR ---' , err , err . stack , '\\n\\n' ) ; this . pub . end ( ) ; this . sub . end ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "new", "files", "to", "concat"], "add_tokens": "'src/geometries/*.js' , 'src/bodies/*.js' ,", "del_tokens": "'src/objects/*.js' ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "some", "collections", "were", "not", "showing", "in", "sidebar", "list"], "add_tokens": "var skipped_dbs = [ \"null\" , \"admin\" , \"local\" ] ; if ( skipped_dbs . indexOf ( value . name ) === - 1 ) { var temp_db = mongojs ( mongo_db . db ( value . name ) ) ; temp_db . getCollectionNames ( function ( err , collections ) { callback ( ) ; } ) ; } else { }", "del_tokens": "var temp_db = mongojs ( mongo_db . db ( value . name ) ) ; temp_db . getCollectionNames ( function ( err , collections ) { // remove system.indexes var index = collections . indexOf ( \"system.indexes\" ) ; collections . splice ( index , 1 ) ; if ( value . name != \"local\" ) { } } ) ; // remove system.indexes var index = collections . indexOf ( \"system.indexes\" ) ; collections . splice ( index , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "docs", "router", "test", "name"], "add_tokens": "describe ( 'DocsRouter' , function ( ) {", "del_tokens": "describe ( 'docs.router' , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "regression", "in", "log_to_console", "option"], "add_tokens": "addOptions ( tracerImp ) { tracerImp . addOption ( 'xhr_instrumentation' , { type : 'bool' , defaultValue : false } ) ; tracerImp . addOption ( 'xhr_url_inclusion_patterns' , { type : 'array' , defaultValue : [ / .* / ] } ) ; tracerImp . addOption ( 'xhr_url_exclusion_patterns' , { type : 'array' , defaultValue : [ ] } ) ; }", "del_tokens": "tracerImp . addOption ( 'xhr_instrumentation' , { type : 'bool' , defaultValue : false } ) ; tracerImp . addOption ( 'xhr_url_inclusion_patterns' , { type : 'array' , defaultValue : [ / .* / ] } ) ; tracerImp . addOption ( 'xhr_url_exclusion_patterns' , { type : 'array' , defaultValue : [ ] } ) ;", "commit_type": "fix"}
{"commit_tokens": ["adds", "current", "directory", "variable", "to", "link", "synonyms", ".", "txt"], "add_tokens": "var path = require ( \"path\" ) ; var moduleDir = path . dirname ( process . mainModule . filename ) \"synonyms_path\" : moduleDir + \"/analysis/synonyms.txt\"", "del_tokens": "\"synonyms_path\" : \"analysis/synonyms.txt\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "+", "improve", "Error", "messages"], "add_tokens": "var commandStr = args [ 0 ] + ( Array . isArray ( args [ 1 ] ) ? ( ' ' + args [ 1 ] . join ( ' ' ) ) : '' ) ; err . message += ' `' + commandStr + '` (exited with error code ' + err . code + ')' ; message : '`' + commandStr + '` failed with code ' + code", "del_tokens": "err . message += args [ 0 ] + ' (exited with error code ' + err . code + ')' ; message : '\"' + commandStr + '\" failed with code ' + code", "commit_type": "fix"}
{"commit_tokens": ["Use", "latest", "version", "of", "application", "insights"], "add_tokens": "var _applicationinsightsWeb = require ( '@microsoft/applicationinsights-web' ) ; Vue . appInsights = new _applicationinsightsWeb . ApplicationInsights ( { config : appInsightConfig } ) ; appInsights . loadAppInsights ( ) ; if ( typeof options . onAfterScriptLoaded === 'function' ) { options . onAfterScriptLoaded ( ) ; Vue . appInsights . flush ( ) ;", "del_tokens": "var _applicationinsightsJs = require ( 'applicationinsights-js' ) ; Vue . appInsights = _applicationinsightsJs . AppInsights ; Vue . appInsights . downloadAndSetup ( appInsightConfig ) ; if ( typeof ( options . onAfterScriptLoaded ) === 'function' ) { options . onAfterScriptLoaded ( )", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "consume", "expression", ".", "setup", "directly", "from", "new", "object"], "add_tokens": "if ( expression . setup ) { expression . setup ( ed , {", "del_tokens": "// make config'ed setup method available if ( expression . setup ) { var configSetup = expression . setup ; delete expression . setup ; } if ( configSetup ) { configSetup ( ed , {", "commit_type": "change"}
{"commit_tokens": ["fix", "another", "issue", "with", "using", "module", "as", "a", "free", "variable"], "add_tokens": "// Will hold the `module` variable name if necessary. var moduleBaseName = null // Holds the `module.exports` variable name. // If `module` is used as a free variable we need to turn it into an object with an `.exports` // property, to deal with situations like: // // var a = module; // a.exports = 'hello' // // Not too common, but it happens if ( moduleList . length > 0 ) { moduleBaseName = moduleExportsName moduleExportsName += '.exports' } node . update ( moduleBaseName ) } else if ( moduleBaseName ) { source . prepend ( 'var ' + moduleBaseName + ' = { exports: {} };\\n' ) . append ( '\\n' + moduleBaseName + ' = ' + moduleExportsName ) moduleExportsName = moduleBaseName", "del_tokens": "node . update ( '({exports:' + moduleExportsName + '})' )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "discovery", "of", "coroutine", "shim"], "add_tokens": "fs . statSync ( require . resolve ( './src/fibers' ) ) . mtime ) {", "del_tokens": "fs . statSync ( __dirname + '/src/fibers.node' ) . mtime ) {", "commit_type": "improve"}
{"commit_tokens": ["fixes", "code", "context", "line", "number"], "add_tokens": "var val = '' ; var res = utils . codeContext ( lines [ i ] , lineno + i ) ; val = lines [ i ] ; lineno += i + 1 ;", "del_tokens": "var codeContext = require ( 'parse-code-context' ) ; var res = codeContext ( lines [ i ] , lineno + i ) ; lineno += i ; var val = ctx . original || '' ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "SyncPromise", "to", "a", "separate", "file"], "add_tokens": "const SyncPromise = require ( './lib/sync-promise' ) ;", "del_tokens": "// eslint-disable-next-line no-undef let SyncPromise ; // Import a synchronous version of Yaku which can be used for flowing streams // (to avoid missing events, as discussed in README.md) without converting all // instances of yaku to synchronous (in case other modules are using it). /* eslint-disable global-require */ ( function requireYakuSync ( ) { const yakuPath = require . resolve ( 'yaku' ) ; const yakuCached = require . cache [ yakuPath ] ; delete require . cache [ yakuPath ] ; SyncPromise = require ( 'yaku' ) ; SyncPromise . nextTick = function thisTick ( fn ) { fn ( ) ; } ; if ( yakuCached ) { require . cache [ yakuPath ] = yakuCached ; } else { delete require . cache [ yakuPath ] ; } } ( ) ) ; /* eslint-enable global-require */", "commit_type": "move"}
{"commit_tokens": ["move", "regexp", "flag", "into", "the", "creation", "of", "the", "regexp", "object", "and", "remove", "it", "from", "the", "test", "method", "."], "add_tokens": "* Version 0.5 .5 - built Wed Mar 12 2014 19 : 12 : 04 if ( ! new RegExp ( this . regexp , this . flag ) . test ( value ) )", "del_tokens": "* Version 0.5 .5 - built Tue Mar 11 2014 12 : 52 : 08 if ( ! new RegExp ( this . regexp ) . test ( value , this . flag ) )", "commit_type": "move"}
{"commit_tokens": ["Fix", "ackDeadline", "configuration", "for", "subscription"], "add_tokens": "* ackDeadlineSeconds : 90", "del_tokens": "* ackDeadline : 90000 // 90 seconds", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "to", "check", "borders", "when", "calculating", "height"], "add_tokens": "* @ param { Boolean } options . useBorders - Consider borders when calculating fold heights this . useBorders = undefined === options . useBorders ? \"auto\" : options . useBorders ; let scrollHeight = fold . el . scrollHeight ;", "del_tokens": "let scrollHeight = fold . totalHeight ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "objects", "with", "a", "toJSON", "method"], "add_tokens": "if ( response . toJSON ) { response = response . toJSON ( ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "occurrence", "freq", "to", "determine", "caching"], "add_tokens": "this . cacheFreq = opts . cacheFreq || 15 ; this . cacheHistogram ( idxi32 ) ; // console.log(this.i32idx); RgbQuant . prototype . cacheHistogram = function cacheHistogram ( idxi32 ) { var x = 0 ; for ( var i = 0 , i32 = idxi32 [ i ] ; i < idxi32 . length && this . histogram [ i32 ] >= this . cacheFreq ; i32 = idxi32 [ i ++ ] ) { this . i32idx [ i32 ] = this . nearestIndex ( i32 ) ; x ++ ; } console . log ( x ) ;", "del_tokens": "this . cacheLimit = opts . cacheLimit || 2e5 ; for ( var i = 0 ; i < idxi32 . length ; i ++ ) this . cacheColor ( idxi32 [ i ] , this . nearestIndex ( idxi32 [ i ] ) ) ; var numCached = 0 ; RgbQuant . prototype . cacheColor = function cacheColor ( i32 , idx ) { if ( numCached == this . cacheLimit || this . i32idx [ i32 ] ) return ; this . i32idx [ i32 ] = idx ; numCached ++ ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "in", "no", "-", "change", "form", "with", "entity", "creating", "question"], "add_tokens": "this . model . on ( \"change\" , this . handleChange ) ;", "del_tokens": "this . formView . on ( 'change' , this . handleChange ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "context", "functions", "non", "-", "enumerable"], "add_tokens": "if ( c . hasOwnProperty ( '_stopped' ) ) return ; // Already done? function _flw_stop ( reason , cb ) { } Object . defineProperty ( c , '_stop' , { enumerable : false , configurable : false , writable : false , value : _flw_stop , } ) ; function _flw_store ( key , cb ) { } Object . defineProperty ( c , '_store' , { enumerable : false , configurable : false , value : _flw_store , } ) ; function _flw_clean ( ) { } Object . defineProperty ( c , '_clean' , { enumerable : false , configurable : false , value : _flw_clean , } ) ; Object . defineProperty ( c , '_flw_store' , { enumerable : false , configurable : false , writable : false , value : _flw_store , } ) ;", "del_tokens": "if ( c . _stopped ) return ; // Already done? c . _stop = function _flw_stop ( reason , cb ) { } ; c . _store = function _flw_store ( key , cb ) { } ; c . _clean = function _flw_clean ( ) { } ; c . _flw_store = c . _store ;", "commit_type": "make"}
{"commit_tokens": ["Use", "events", "to", "communicate", "with", "extensions", "Socket", ".", "IO", "to", "communicate", "with", "clients"], "add_tokens": "var util = require ( 'util' ) ; var events = require ( 'events' ) ; events . EventEmitter . call ( this ) ; socket . on ( 'destroyVariable' , function ( data , cb ) { cb ( self . destroy ( data . bundleName , data . variableName ) ) ; } ) ; util . inherits ( Bundles , events . EventEmitter ) ; this . emitToAll ( 'variableDeclared' , { this . emitToAll ( 'variableDestroyed' , { this . emitToAll ( 'variableAssigned' , { SyncedVariables . prototype . emitToAll = function ( eventName , data ) { // Emit to clients using Socket.IO io . emit ( eventName , data ) ; // Emit to extensions using EventEmitter this . emit ( eventName , data ) ; } ;", "del_tokens": "io . emit ( 'variableDeclared' , { io . emit ( 'variableDestroyed' , { io . emit ( 'variableAssigned' , {", "commit_type": "use"}
{"commit_tokens": ["Changed", "tabs", "to", "spaces", "to", "look", "better"], "add_tokens": "location : 'New York, NY' , checkin : '06/03/2015' , checkout : '06/06/2015' console . log ( body ) ; } ) ;", "del_tokens": "location : 'New York, NY' , checkin : '06/03/2015' , checkout : '06/06/2015' console . log ( body ) ; } ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "a", "few", "small", "bugs"], "add_tokens": "usingWebAudio = false ; self . pause ( id ) . play ( activeNode . _sprite , id ) ; if ( ! obj . _loaded ) { if ( typeof define === 'function' && define . amd ) {", "del_tokens": "self . pause ( id ) . play ( node . _sprite , id ) ; if ( ! self . _loaded ) { if ( typeof define == 'function' && define . amd ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "repo", "to", "not", "break", "on", "resolve"], "add_tokens": "self . repo . open ( path . resolve && path . resolve ( dir ) || dir , function ( ) { self . repo . open ( path . resolve && path . resolve ( dir ) || dir ) ; self . repo . init ( path . resolve && path . resolve ( dir ) || dir , is_bare , function ( ) {", "del_tokens": "self . repo . open ( path . resolve ( dir ) , function ( ) { self . repo . open ( path . resolve ( dir ) ) ; self . repo . init ( path . resolve ( dir ) , is_bare , function ( ) {", "commit_type": "update"}
{"commit_tokens": ["Fixed", "Editor", "with", "workers", "."], "add_tokens": "var res = sns . string . evaluateWithoutCache ( ` elmserver = Regex . replace \"\" \"<link[^>]*href=\" / server - elm - style . css \"[^>]*>\" \"\" ( | > Regex . replace \"const defaultServerContent = .*;\\\\\\\\s*const useDefaultServerContent = false;\" ( \\\\ _ - > \"\" \" const useDefaultServerContent = true ; \"\" \"", "del_tokens": "var res = sns . string . evaluate ( ` elmserver = Regex . replace \"\" \"<link rel=\" stylesheet \" type = \"text/css\" href = \"/server-elm-style.css\" > \"\" \" ( | > Regex . replace \"const defaultServerContent = .*;\" ( \\\\ _ - > \"\" \"const defaultServerContent = @(jsCode.stringOf elmserver);\" \"\" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "path", ".", "resolve", "instead", "of", "path", "concatenation"], "add_tokens": "var configPath = this . options && this . options . config ; if ( ! grunt . file . isPathAbsolute ( configPath ) ) { configPath = path . resolve ( process . cwd ( ) , configPath ) ; if ( grunt . file . exists ( configPath ) ) { return grunt . file . readJSON ( configPath ) ;", "del_tokens": "var path = this . options && this . options . config ; if ( ! grunt . file . isPathAbsolute ( path ) ) { // Prepend the cwd, as jscs does via CLI path = process . cwd ( ) + \"/\" + path ; if ( grunt . file . exists ( path ) ) { return grunt . file . readJSON ( path ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "Error", ".", "captureStackTrace", "(", "10%", "faster", ")"], "add_tokens": "var obj , stack obj = { } Error . captureStackTrace ( obj ) stack = obj . stack . substr ( 16 )", "del_tokens": "var stack = new Error ( ) . stack . substr ( 6 )", "commit_type": "use"}
{"commit_tokens": ["Add", "inverse", "variant", "to", "ContextBox", "component"], "add_tokens": ". to . contain ( 'positioned--top' ) describe ( 'when a placement is provided' , function ( ) { const placement = 'bottom' placement . to . contain ( 'positioned--' + placement )", "del_tokens": ". to . contain ( 'positioned--above' ) it ( 'should animate' , function ( ) { testbed . render ( ) expect ( testbed . dom . node . className ) . to . contain ( 'with-animation' ) } ) describe ( 'when animation is disabled' , function ( ) { it ( 'should not animate' , function ( ) { testbed . render ( { withAnimation : false } ) expect ( testbed . dom . node . className ) . to . not . contain ( 'with-animation' ) } ) } ) describe ( 'when a position is provided' , function ( ) { const positioned = 'below' it ( 'should animate to that position' , function ( ) { testbed . render ( { positioned } ) expect ( testbed . dom . node . className ) . to . contain ( 'positioned--' + positioned ) } ) positioned . to . contain ( 'positioned--' + positioned )", "commit_type": "add"}
{"commit_tokens": ["changed", "unrecognized", "characters", "to", "be", "non", "-", "greedy"], "add_tokens": "s = \".+\" ;", "del_tokens": "s = \".*\" ;", "commit_type": "change"}
{"commit_tokens": ["remove", "lib", ".", "d", ".", "ts", "loading"], "add_tokens": "'!node_modules/**/lib*.ts'", "del_tokens": "'!src/typescript/lib*.ts'", "commit_type": "remove"}
{"commit_tokens": ["Added", ":", "jQuery", "manifest", "file"], "add_tokens": "* noty - jQuery Notification Plugin v2 .1 .2", "del_tokens": "* noty - jQuery Notification Plugin v2 .1 .1", "commit_type": "add"}
{"commit_tokens": ["Updated", "NIB", "to", "the", "latest", "version"], "add_tokens": "exports . version = '0.0.10' ;", "del_tokens": "exports . version = '0.0.9' ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "decoding", "/", "protos", "/", "tests"], "add_tokens": "var from = proto . source + \".\" + ( proto . sourceDevice == null ? 0 : proto . sourceDevice ) ; return decryptWhisperMessage ( from , getString ( proto . message ) ) ; var from = proto . source + \".\" + ( proto . sourceDevice == null ? 0 : proto . sourceDevice ) ; return initSessionFromPreKeyWhisperMessage ( from , preKeyProto ) . then ( function ( sessions ) { return decryptWhisperMessage ( from , getString ( preKeyProto . message ) , sessions [ 0 ] ) . then ( function ( result ) {", "del_tokens": "return decryptWhisperMessage ( proto . source + \".\" + proto . sourceDevice , getString ( proto . message ) ) ; //XXX: proto.sourceDevice == jsNumber??? (and above) return initSessionFromPreKeyWhisperMessage ( proto . source + \".\" + proto . sourceDevice , preKeyProto ) . then ( function ( sessions ) { return decryptWhisperMessage ( proto . source , getString ( preKeyProto . message ) , sessions [ 0 ] ) . then ( function ( result ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "backslash", "before", "digit", "when", "searching", "for", "0<unit", ">", "to", "be", "replaced", "by", "0"], "add_tokens": "content = content . replace ( / (^|[^.0-9\\\\])(?:0?\\.)?0(?:ex|ch|r?em|vw|vh|vmin|vmax|cm|mm|in|pt|pc|px|deg|g?rad|turn|m?s|k?Hz|dpi|dpcm|dppx|%) / gi , \"$10\" ) ;", "del_tokens": "content = content . replace ( / (^|[^.0-9])(?:0?\\.)?0(?:ex|ch|r?em|vw|vh|vmin|vmax|cm|mm|in|pt|pc|px|deg|g?rad|turn|m?s|k?Hz|dpi|dpcm|dppx|%) / gi , \"$10\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "object", "/", "setHidden", "and", "setHiddenConst"], "add_tokens": "const NameSpace = require ( 'es6lib/namespace' ) . NameSpace ; / ** * Set 'value' as unenumerable but configurable and writable property 'key' of 'object' . * @ return { object } The value that was set . * / const setHidden = exports . setHidden = function setHidden ( object , key , value ) { Object . defineProperty ( object , key , { value : value , configurable : true , writable : true , } ) ; return value ; } ; / ** * Set 'value' as unenumerable , unconfigurable and unwritable property 'key' of 'object' . * @ return { object } The value that was set . * / const setHiddenConst = exports . setHiddenConst = function setHiddenConst ( object , key , value ) { Object . defineProperty ( object , key , { value : value , } ) ; return value ; } ;", "del_tokens": "const NameSpace = reqire ( 'es6lib/namespace' ) . NameSpace ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "perf", "tests", ".", "Need", "to", "get", "better", "perf", "in", "chrome", "."], "add_tokens": "import polyfill from '../../src/host/polyfill' ;", "del_tokens": "import polyfill from '../../src/polyfill' ;", "commit_type": "fix"}
{"commit_tokens": ["use", "custom", "fill", "method", "for", "txs", "with", "from", "accounts", "."], "add_tokens": "// if (from) { // return from.fill(tx, callback); // } if ( from && account !== from ) { continue ; } if ( from ) { var err = new Error ( 'Not enough funds' ) ; err . minBalance = total ; return callback ( err ) ; }", "del_tokens": "if ( from ) { return from . fill ( tx , callback ) ; } // if (from && account !== from) { // continue; // } // if (from) { // var err = new Error('Not enough funds'); // err.minBalance = total; // return callback(err); // }", "commit_type": "use"}
{"commit_tokens": ["Fix", "tests", "failing", "under", "phantomjs", "."], "add_tokens": "//Set to empty-string if undefined or null, but not if 0, false, etc if ( value === null || value === undefined ) { value = '' ; }", "del_tokens": "if ( value === undefined ) { value = '' ; }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "rendering", "of", "checkbox", "field"], "add_tokens": "html += f . value ? ' value=\"' + f . value + '\"' : '' ; exports . checkbox = function ( opt ) { var opt = opt || { } ; var w = { } ; w . classes = opt . classes || [ ] ; w . toHTML = function ( name , f ) { var f = f || { } ; var html = '<input type=\"checkbox\"' ; html += attrs ( { name : name , id : f . id , classes : w . classes } ) ; html += f . value ? ' checked=\"checked\"' : '' ; return html + ' />' ; } return w ; } ;", "del_tokens": "if ( f . value ) { html += ' value=\"' + f . value + '\"' ; } exports . checkbox = input ( 'checkbox' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "getDestFileName", "and", "fix", "argument"], "add_tokens": "var preprocessorsToApply = preprocessorsForFile ( preprocessors , fileName )", "del_tokens": "var preprocessorsToApply = preprocessorsForFile ( preprocessors , relativePath )", "commit_type": "add"}
{"commit_tokens": ["Fix", "product", "js", "in", "current", "state"], "add_tokens": "// eslint-disable-next-line no-new onVariantSelected : updateVariantSelection , function updateVariantSelection ( variant ) {", "del_tokens": "onVariantSelected : self . updateVarientSelection , function updateVarientSelection ( variant ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "spacing", "between", "month", "names"], "add_tokens": "months : [ 'Janeiro' , 'Fevereiro' , 'Maro', Abril', Maio', Junho', Julho', Agosto', Setembro', Outubro', Novembro', Dezembro'] ,", "del_tokens": "months : [ 'Janeiro' , 'Fevereiro' , 'Maro', ' Abril', ' Maio', ' Junho', Julho', ' Agosto', ' Setembro', ' Outubro', ' Novembro', ' Dezembro'] ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "my", "name", "and", "bump", "version"], "add_tokens": "* @ author Jesse Farmer < jesse @ 20 bits . com > * @ version 1.0 .3", "del_tokens": "* @ version 1.0 .2", "commit_type": "add"}
{"commit_tokens": ["removing", "hard", "dependency", "to", "lodash", "updating", "authors", "and", "bumping", "version", "in", "package", ".", "json"], "add_tokens": "} ;", "del_tokens": "} ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "catdown", "-", "core", "and", "added", "default", "textarea", "element", "."], "add_tokens": "opts = opts || { } ; // Pull textarea from opts or create and append a new one. // \"Unwrap\" in case a jQuery (or any $ style) object is provided. this . $textarea = opts . textarea !== null ? utils . unwrapElement ( opts . textarea ) : document . body . appendChild ( document . createElement ( \"textarea\" ) ) ;", "del_tokens": "// Pull textarea from opts. Unwrap if it's a jQuery object. this . $textarea = utils . unwrapElement ( opts . textarea || document . createElement ( \"textarea\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "some", "comments", "fixed", "an", "issue", "with", "nested", "blocks"], "add_tokens": "t . is ( tag . attributes . me . value , 'Welt!' , 'Attribute correctly applied' ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Pebble", "when", "resolving", "DNS", "HTTP", "requests", "and", "challenges", "during", "tests"], "add_tokens": "const uuid = require ( 'uuid/v4' ) ; const acme = require ( './../' ) ; describe ( 'client' , ( ) => { const testContact = ` ${ uuid ( ) } ` ; const data = { contact : [ testContact ] } ; const account = await testClient . updateAccount ( data ) ; assert . isArray ( account . contact ) ; assert . include ( account . contact , testContact ) ;", "del_tokens": "const acme = require ( './../src' ) ; describe ( ` ${ directoryUrl } ` , ( ) => { const account = await testClient . updateAccount ( { } ) ;", "commit_type": "use"}
{"commit_tokens": ["use", "default", "for", "alias", "when", "this", ".", "env", "doesn", "t", "exist"], "add_tokens": "var alias = this . env ? this . env . alias : 'default' ; debug ( 'extending \"%s\" with \"%s\"' , alias , name ) ;", "del_tokens": "debug ( 'extending \"%s\" with \"%s\"' , this . env . alias , name ) ;", "commit_type": "use"}
{"commit_tokens": ["Making", "new", "stream", "test", "cases", "pass", "."], "add_tokens": "var frame ; while ( frame = this . upstream . _queue . shift ( ) ) { this . upstream . emit ( 'sending' , frame ) ; this . _log . debug ( { frame : frame } , 'Sending frame' ) ; this . upstream . push ( frame ) ; }", "del_tokens": "var upstream = this . upstream , log = this . _log ; this . upstream . _queue . forEach ( function ( frame ) { upstream . emit ( 'sending' , frame ) ; log . debug ( { frame : frame } , 'Sending frame' ) ; upstream . push ( frame ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "--", "verbose", "option", "which", "forwards", "stdout", "/", "err"], "add_tokens": "test ( 'test works - verbose' , function ( t ) { var cmds = fixtureTestCommands ( 'test-works-verbose.sh' ) ; exec ( cmds , shouldWork . bind ( null , t ) ) ; t . plan ( 1 ) ; } ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "separator", "support", "to", "the", "checkbox", "prompt"], "add_tokens": "new inquirer . Separator ( \"The usual:\" ) , name : \"Mushroom\" new inquirer . Separator ( \"The extras:\" ) , name : \"Pineapple\" } , { name : \"Extra cheese\"", "del_tokens": "name : \"Pineapple\" name : \"Mushroom\"", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "23", ":", "remove", "file", "BOM", "before", "combo"], "add_tokens": "fileContent = fs . readFileSync ( mod . path ) ; // fix issue 23: remove file BOM before combo. if ( / ^\\uFEFF / . test ( fileContent ) ) { fileContent = fileContent . toString ( ) . replace ( / ^\\uFEFF / , '' ) ; } var modContent = iconv . decode ( fileContent , mod . charset ) ;", "del_tokens": "modContent = iconv . decode ( fs . readFileSync ( mod . path ) , mod . charset ) ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "passing", "private", "key", "through", "config", "option", "serviceAccountPrivateKey"], "add_tokens": "options . serviceAccountPrivateKey ,", "del_tokens": "undefined ,", "commit_type": "allow"}
{"commit_tokens": ["fix", "snap", "-", "drag", "bug", "for", "touch", "events"], "add_tokens": "document . addEventListener ( 'touchend' , this . _touchEnd , false ) ;", "del_tokens": "console . log ( '_onSliderTouchStart' ) ; console . log ( '_onSliderTouchStart' ) ; document . addEventListener ( 'touchend' , this . _onTouchEnd , false ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "docs", "css", "to", "inject", "athena", "s", "header", "comment", "block"], "add_tokens": "function buildCSS ( src , filename , dest , applyHeader , doBrowserSync ) { doBrowserSync = doBrowserSync || false ; . pipe ( gulpif ( doBrowserSync , browserSync . stream ( ) ) ) ; return buildCSS ( config . src . scssPath + '/framework.scss' , 'framework.min.css' , config . dist . cssPath , true , true ) ; return buildCSS ( config . docs . scssPath + '/style.scss' , 'style.min.css' , config . docs . cssPath , true , false ) ;", "del_tokens": "function buildCSS ( src , filename , dest , applyHeader ) { . pipe ( browserSync . stream ( ) ) ; return buildCSS ( config . src . scssPath + '/framework.scss' , 'framework.min.css' , config . dist . cssPath , true ) ; gulp . src ( config . docs . scssPath + '/style.scss' ) . pipe ( sass ( ) . on ( 'error' , sass . logError ) ) . pipe ( cleanCSS ( ) ) . pipe ( autoprefixer ( { // Supported browsers added in package.json (\"browserslist\") cascade : false } ) ) . pipe ( rename ( 'style.min.css' ) ) . pipe ( gulp . dest ( config . docs . cssPath ) ) ;", "commit_type": "update"}
{"commit_tokens": ["changed", "consumer", "to", "kafkaesque", "in", "produce", ".", "js", "and", "fix", "the", "required", "package", "name"], "add_tokens": "var reinterval = require ( 'reinterval' ) ; _heartbeatInterval = reinterval ( function heartbeat ( ) {", "del_tokens": "var reInterval = require ( 'reInterval' ) ; _heartbeatInterval = reInterval ( function heartbeat ( ) {", "commit_type": "change"}
{"commit_tokens": ["Make", "error", "-", "less", "default", "behaviour"], "add_tokens": "var getClientX = require ( 'get-client-xy' ) . x ; var getClientY = require ( 'get-client-xy' ) . y ; var x = getClientX ( e ) - offsets . left ; var y = getClientY ( e ) - offsets . top ; var picker = self . getClosestPicker ( x , y ) ; if ( self . instant ) { for ( var i = self . pickers . length ; i -- ; ) { if ( self . pickers [ i ] !== picker ) { self . pickers [ i ] . dragstate = 'idle' ; / * * /", "del_tokens": "var x = e . clientX - offsets . left ; var y = e . clientY - offsets . top ; var picker = slidy . getClosestPicker ( x , y ) ; if ( slidy . instant ) { for ( var i = slidy . pickers . length ; i -- ; ) { if ( slidy . pickers [ i ] !== picker ) { slidy . pickers [ i ] . dragstate = 'idle' ;", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "mechanism", "to", "colorize", "text", "by", "sending", "a", "second", "parameter", "to", "Player", ".", "send", "denoting", "what", "type", "of", "message", "it", "is", "."], "add_tokens": "execute : function ( string ) { target . send ( this . name + \" tells you: \" + params . join ( ' ' ) , 'tell' ) ;", "del_tokens": "execute : function ( ) { target . send ( this . name + \" tells you: \" + params . join ( ' ' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "examples", "with", "shift", "behaviour", "and", "new", "repl", "example"], "add_tokens": "var fps = 1 ; // how many frames per second do you want to try?", "del_tokens": "var fps = 20 ; // how many frames per second do you want to try?", "commit_type": "update"}
{"commit_tokens": ["Updated", "the", "version", "inside", "the", "library"], "add_tokens": "version : '3.9.7' ,", "del_tokens": "version : '3.9.2' ,", "commit_type": "update"}
{"commit_tokens": ["Removing", "pagination", "params", "check", "moved", "to", "back4app", "-", "rest"], "add_tokens": "skip = params . skip ; limit = params . limit ;", "del_tokens": "params = params || { } ; // cleaning the parameter skip = params . skip !== undefined ? params . skip : Adapter . DEFAULT_SKIP ; limit = params . limit === undefined ? Adapter . DEFAULT_LIMIT : params . limit > Adapter . MAX_LIMIT ? Adapter . MAX_LIMIT : params . limit ; sort = params . sort !== undefined ? params . sort : { _id : 1 } ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "length", "key", "from", "output"], "add_tokens": "var flatten = { } var qResult = { }", "del_tokens": "var flatten = { length : 0 } ; current . length ++ ; flatten . length ++ ; var qResult = { length : 0 } , i ; qResult . length ++ ; qResult . length ++ ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "connection", ".", "request", "to", "work", "with", "UTF", "-", "8", "data"], "add_tokens": "\"Content-Type\" : \"application/json; charset=utf-8\" options . headers [ \"Content-Length\" ] = Buffer . byteLength ( jsonBody ) ;", "del_tokens": "\"Content-Type\" : \"application/json\" options . headers [ \"Content-Length\" ] = jsonBody . length ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "for", "messenger", "codes"], "add_tokens": "Broadcast = require ( './broadcast-api' ) , MessengerCode = require ( './messenger-code-api' ) ; this . MessengerCode = new MessengerCode ( this . GraphRequest ) ;", "del_tokens": "Broadcast = require ( './broadcast-api' ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "custom", "app", "-", "starting", "commands"], "add_tokens": "return supertest ( proxyquire ( path . join ( config . cwd , config . cmd || 'app' ) , { } ) ) ;", "del_tokens": "return supertest ( proxyquire ( path . join ( config . cwd , 'app' ) , { } ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "the", "List", "formatter", "to", "formatters"], "add_tokens": "var Formatter = require ( './mini/formatters/list' ) ;", "del_tokens": "var Formatter = require ( './mini/formatter' ) ;", "commit_type": "move"}
{"commit_tokens": ["Moving", "builder", "code", "to", "a", "separated", "file"], "add_tokens": "var buildAsPromise = require ( './build' ) ; return buildAsPromise ( options . pathToApp ) ;", "del_tokens": "return tools . buildAsPromise ( options . pathToApp ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "missing", "test", "for", "event", "triggered", "by", "autoSelect", "when", "creating", "a", "collection"], "add_tokens": "var selectOneEventCounter ; var SelfObservingCollection = Collection . extend ( { initialize : function ( models ) { Collection . prototype . initialize . call ( this , models ) ; this . listenTo ( this , \"select:one\" , function ( ) { selectOneEventCounter ++ ; } ) } } ) ; selectOneEventCounter = 0 ; collection = new SelfObservingCollection ( models ) ; it ( 'no select:one event is triggered in the collection' , function ( ) { // In Backbone.Select, adding models to a collection during instantiation is treated like a // reset. The collection doesn't fire selection-related events. The autoSelect mechanism should // behave the same way and not fire a collection event during instantiation. expect ( selectOneEventCounter ) . to . equal ( 0 ) ; } ) ;", "del_tokens": "collection = new Collection ( models ) ; // NB Events: // // A select:one event is not triggered on the collection. For one, it can't be done because // initialize is run before the models are added to the collection. Also, it is pointless. // External listeners can't be attached while the collection is being created.", "commit_type": "add"}
{"commit_tokens": ["create", "demo", "db", "converte", "to", "sqlweb"], "add_tokens": "'test/cases/create/*.js' ,", "del_tokens": "'test/scripts/dbhelper.js' ,", "commit_type": "create"}
{"commit_tokens": ["Changed", "implied", "url", "class", "limiter", "to", "h", "-", "item"], "add_tokens": "//not with class: include or item or h-item && domUtils . hasAttributeValueByPrefix ( dom , node , 'class' , 'h-item' ) === false ) {", "del_tokens": "//not with class: include or item or h-* (get h-item with prefix exclude) && domUtils . hasAttributeValueByPrefix ( dom , node , 'class' , 'h-' ) === false ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "the", "create", "hook", "to", "the", "index", ".", "js", "virtualize", "function", "."], "add_tokens": "export default function ( el , options ) { return virtualizeString ( el , options ) ; return virtualizeNode ( el , options ) ;", "del_tokens": "export default function ( el ) { return virtualizeString ( el ) ; return virtualizeNode ( el ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "valueOf", "()", "to", "get", "the", "reference", "the", "object", "."], "add_tokens": "return new Assertion ( Object ( this ) . valueOf ( ) ) ;", "del_tokens": "return new Assertion ( this ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "decoding", "bug", "of", "short", "int"], "add_tokens": "var value = ( upper << 8 ) + lower ; if ( value & 0x8000 ) { value = - ( ( value - 1 ) ^ 0xFFFF ) ; } return value", "del_tokens": "return ( upper << 8 ) + lower ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "passing", "args", "as", "json", "obj", "to", "array", "expecting", "exec", "()"], "add_tokens": "var args = decodeURIComponent ( input [ 0 ] ) ; return JNEXT . invoke ( self . m_id , \"extractFile \" + callbackId + ' ' + args ) ;", "del_tokens": "console . log ( input ) ; return JNEXT . invoke ( self . m_id , \"extractFile \" + callbackId + \" \" + JSON . stringify ( input ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typos", "in", "README", "added", "example", "use", "on", "the", "web", "bumped", "version", "."], "add_tokens": "+ \" sprinter <command> <cmd-options> --repos=org/repo,org2/repo2\\n\" . yellow + \" sprinter <command> <cmd-options> --repos=./path/to/repo/file\\n\\n\" . yellow console . log ( 'sprinter createMilestones \"Sprint 43\" \"April 16, 2014\" --repos=rhyolight/highlinker,rhyolight/chesster' . yellow ) ; if ( err ) { return console . error ( err ) ; }", "del_tokens": "+ \" sprinter <command> <cmd-options> --repo=org/repo,org2/repo2\\n\" . yellow + \" sprinter <command> <cmd-options> --repo=./path/to/repo/file\\n\\n\" . yellow console . log ( 'sprinter createMilestones \"Sprint 43\" \"April 16, 2014\" --repo=rhyolight/highlinker,rhyolight/chesster' . yellow ) ; // TODO: handle errors.", "commit_type": "fix"}
{"commit_tokens": ["update", "/", "simplify", "example", ".", "js"], "add_tokens": "var ZabbixSender = require ( 'node-zabbix-sender' ) ; var Sender = new ZabbixSender ( { host : 'zabbix.example.com' } ) ;", "del_tokens": "var ZabbixSender = require ( './index.js' ) ; var Sender = new ZabbixSender ( { host : '10.121.202.100' } ) ; //var Sender = new ZabbixSender({host: 'zabbix.example.com'});", "commit_type": "update"}
{"commit_tokens": ["Fix", "stamp", "/", "privatize", "without", "any", "methods", "present"], "add_tokens": "var newObject = { } ; privates . set ( newObject , this ) ; if ( ! methods ) { return newObject ; }", "del_tokens": "var newObject = { } ; privates . set ( newObject , this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "RA", "-", "T411", "detection", "and", "fixed", "double", "-", "association", "bug"], "add_tokens": "if ( ! identifiers [ id ] . url ) { if ( device . identifier . type === \"EUI-64\" ) { // RA-T411 device . url = \"http://reelyactive.com/metadata/ra-t411.json\" ; return }", "del_tokens": "if ( ! id . url ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "readme", "and", "yargs", "with", "new", "wizard", "options"], "add_tokens": "} , 'w' : { alias : 'wizard' , boolean : true , describe : 'Run a wizard to guide you through renaming files' describe : 'Print all rename operations to be completed and confirm before proceeding'", "del_tokens": "describe : 'Print all rename operations completed'", "commit_type": "update"}
{"commit_tokens": ["Fix", "logging", "error", "for", "group", "retrieval", "."], "add_tokens": "groups = _ . uniq ( _ . sortBy ( groups , function ( group ) { return ( group . cn || group . dn ) ; } ) , true , function ( group ) { callback ( err , groups ) ;", "del_tokens": "var groups = _ . uniq ( groups , function ( group ) { callback ( err , results ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "bug", "with", "tag", "and", "kungFig", ".", "load", "()"], "add_tokens": "if ( config instanceof kungFig . TagContainer ) { config = config . children ; } else if ( config instanceof kungFig . Tag ) { config = config . content ; } config [ key ] = this . expand ( config [ key ] , { cwd : options . cwd , root : options . root , fileObjectMap : options . fileObjectMap } ) ;", "del_tokens": "config [ key ] = this . expand ( config [ key ] , { cwd : options . cwd , root : options . root , fileObjectMap : options . fileObjectMap } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "export", "of", "suffix", "config", "when", "parsing", "bsconfig"], "add_tokens": "/*:: type Options = { moduleDir: BsModuleFormat | 'js', inSource: boolean, suffix: string } */ const bsSuffix = bsconfig . suffix const suffix = typeof bsSuffix === 'string' ? bsSuffix : '.js' const options /*: Options */ = { moduleDir , inSource , suffix } const bsSuffix = bsconfig . suffix", "del_tokens": "/*:: type Options = { moduleDir: BsModuleFormat | 'js', inSource: boolean } */ const options /*: Options */ = { moduleDir , inSource } const bsSuffix = bsconfig . suffix || '.js'", "commit_type": "add"}
{"commit_tokens": ["Add", "fallback", "for", "utils", ".", "rpad"], "add_tokens": "var utils = require ( 'ethereumjs-util' ) ; // FIXME: remove this once ethereumjs-util has this feature // (there's a pull request in progress: // https://github.com/ethereum/ethereumjs-util/pull/8) if ( utils . rpad === undefined ) { utils . rpad = function ( msg , length ) { msg = utils . toBuffer ( msg ) if ( msg . length < length ) { var buf = utils . zeros ( length ) msg . copy ( buf ) return buf } return msg . slice ( - length ) } }", "del_tokens": "const utils = require ( 'ethereumjs-util' ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "mongodb", "driver", "2", ".", "x", "support"], "add_tokens": "mongoVersion = require ( 'mongodb/package.json' ) . version , isNew = mongoVersion . indexOf ( '1.' ) !== 0 , ObjectID = isNew ? mongo . ObjectID : mongo . BSONPure . ObjectID ; server = new mongo . ReplSet ( servers ) ; self . store = new self . db . collection ( options . collectionName ) ;", "del_tokens": "ObjectID = mongo . BSONPure . ObjectID ; server = new mongo . ReplSetServers ( servers ) ; self . store = new mongo . Collection ( client , options . collectionName ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "cursor", "clone", "method", "and", "ability", "to", "take", "a", "cursor", "factory", "on", "pr", "cursor", "creation"], "add_tokens": "// Setup the docs as an array ops = Array . isArray ( ops ) ? ops : [ ops ] ; // Execute write // Setup the docs as an array ops = Array . isArray ( ops ) ? ops : [ ops ] ; // Execute write // Setup the docs as an array ops = Array . isArray ( ops ) ? ops : [ ops ] ; // Execute write var FinalCursor = cursorOptions . cursorFactory || Cursor ; return new FinalCursor ( bson , ns , cmd , cursorOptions , self , options ) ;", "del_tokens": "return new Cursor ( bson , ns , cmd , cursorOptions , self , options ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "JSON", "to", "globals", "ignore", "in", "config", "/", "jshint", ".", "js"], "add_tokens": "require : true , JSON : true", "del_tokens": "require : true", "commit_type": "add"}
{"commit_tokens": ["fix", "rollback", "-", "no", "end", "transaction", "necessary"], "add_tokens": "{ sql : 'ROLLBACK;' , args : [ ] }", "del_tokens": "{ sql : 'ROLLBACK;' , args : [ ] } , { sql : 'END;' , args : [ ] }", "commit_type": "fix"}
{"commit_tokens": ["Added", "removing", "url", "parentheses", "if", "possible", "."], "add_tokens": "'urls' : cssContext ( { 'keep urls without parentheses unchanged' : 'a{background:url(/images/blank.png) 0 0 no-repeat}' , 'strip single parentheses' : [ \"a{background:url('/images/blank.png') 0 0 no-repeat}\" , \"a{background:url(/images/blank.png) 0 0 no-repeat}\" ] , 'strip double parentheses' : [ 'a{background:url(\"/images/blank.png\") 0 0 no-repeat}' , 'a{background:url(/images/blank.png) 0 0 no-repeat}' ] , 'strip more' : [ 'a{background:url(\"/images/blank.png\") 0 0 no-repeat}a{}a{background:url(\"/images/blank.png\") 0 0 no-repeat}' , 'a{background:url(/images/blank.png) 0 0 no-repeat}a{}a{background:url(/images/blank.png) 0 0 no-repeat}' ] , 'not strip comments if spaces inside' : [ 'a{background:url(\"/images/long image name.png\") 0 0 no-repeat}a{}a{background:url(\"/images/no-spaces.png\") 0 0 no-repeat}' , 'a{background:url(\"/images/long image name.png\") 0 0 no-repeat}a{}a{background:url(/images/no-spaces.png) 0 0 no-repeat}' ] } ) , 'a{filter:progid:DXImageTransform.Microsoft.Chroma(color=#919191)}' , 'a{filter:chroma(color=#919191)}'", "del_tokens": "'a{filter:progid:DXImageTransform.Microsoft.Chroma(color=#919191)}' , 'a{filter:chroma(color=#919191)}'", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "limit", "env", "output"], "add_tokens": "var trace = require ( 'debug' ) ( 'slcenv' ) ; var selector = options . _ ; // the argv, stripped of the flags (both -- and -) var env = { } , versions : process . versions , } ; try { env = selectProperties ( selector , env ) ; //XXX argv--> includes options? } catch ( er ) { return loader . error ( er . message ) ; } console . log ( env ) ; function selectProperties ( properties , obj ) { var select = properties . shift ( ) ; if ( ! select ) { return obj ; } if ( obj [ select ] === undefined ) { throw Error ( 'No such property: ' + select ) ; } // Hm, js object literals can't include key names specified as variables? var r = { } ; r [ select ] = selectProperties ( properties , obj [ select ] ) ; return r ; } trace ( 'links' , links , 'resolves to' , resolved ) ; trace ( 'recur' , seen , next ) ; trace ( 'readlink failed' , er ) ;", "del_tokens": "console . log ( { } / * , versions : process . versions , * / } ) ; debug ( 'links' , links , 'resolves to' , resolved ) ; debug ( 'recur' , seen , next ) ; debug ( 'readlink failed' , er ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "missing", "pagination", "when", "data", "changed", "."], "add_tokens": "let page , sizePerPage ; if ( this . store . isChangedPage ( ) ) { sizePerPage = this . refs . pagination . getSizePerPage ( ) ; page = this . refs . pagination . getCurrentPage ( ) ; } else { sizePerPage = this . props . options . sizePerPage || Const . SIZE_PER_PAGE_LIST [ 0 ] ; page = this . props . options . page || 1 ; } result = this . store . page ( page , sizePerPage ) . get ( ) ;", "del_tokens": "result = this . store . page ( this . props . options . page || 1 , this . props . options . sizePerPage || Const . SIZE_PER_PAGE_LIST [ 0 ] ) . get ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "benchmarks", "for", "different", "remarkable", "modes"], "add_tokens": "var md = new Remarkable ( { linkify : true , typographer : true } ) ;", "del_tokens": "var md = new Remarkable ( 'commonmark' / * { xhtml : true , breaks : false , langPrefix : 'language-' } * / ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", "with", "fake", "node_module", "directory"], "add_tokens": "var twitterlib = require ( 'twitterlib' ) ;", "del_tokens": "var twitterlib = require ( '../twitterlib' ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "pop", "confirm", "to", "index", ".", "js"], "add_tokens": "import fixURL from './src/tool/fixurl' ; import ffanPopConfirm from './src/components/popconfirm' ; ffanPopConfirm as PopConfirm ,", "del_tokens": "import fixURL from './src/tool/fixurl'", "commit_type": "add"}
{"commit_tokens": ["remove", "a", "property", "from", "the", "object", "if", "it", "s", "new", "value", "is", "set", "to", "undefined"], "add_tokens": "if ( value === undefined ) { if ( this . propertyInfo . obj !== undefined ) { delete this . propertyInfo . obj [ this . propertyInfo . last ] } } else { if ( this . propertyInfo . obj === undefined ) { // create the path if it doesn't exist createProperty ( this ) } this . propertyInfo . obj [ this . propertyInfo . last ] = value }", "del_tokens": "if ( this . propertyInfo . obj === undefined ) { // create the path if it doesn't exist createProperty ( this ) } this . propertyInfo . obj [ this . propertyInfo . last ] = value", "commit_type": "remove"}
{"commit_tokens": ["Add", "allowEmpty", "option", "to", "prevent", "errors", "when", "linking", "roots", "."], "add_tokens": "if ( fs . existsSync ( inputPath ) ) { this . _copy ( inputPath , this . destPath ) ; } else if ( this . allowEmpty ) { mkdirp . sync ( this . destPath ) ; }", "del_tokens": "this . _copy ( inputPath , this . destPath ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "the", "allowNull", "validator", "."], "add_tokens": "if ( typeof obj === 'undefined' || obj === null ) { if ( obj === null ) { if ( schema . allowNull === true || ( options || { } ) . allowNull === true ) return finalize ( obj , fn ) ; return fn ( new ValidationError ( keyPath , schema . _nonFormalizedSchema , 'noNull' , ( schema . errors || { } ) . allowNull || 'Cannot be null.' ) ) ; }", "del_tokens": "if ( typeof obj === 'undefined' ) {", "commit_type": "implement"}
{"commit_tokens": ["Moved", "utilities", "to", "js", "-", "bali", "-", "virtual", "-", "machine", "project", "."], "add_tokens": "var types = require ( '../syntax/NodeTypes' ) ;", "del_tokens": "var types = require ( '../nodes/NodeTypes' ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "arguments", "to", "ga", ".", "js", ":", "value", "and", "noninteraction"], "add_tokens": "properties . label , properties . value , properties . noninteraction", "del_tokens": "properties . label", "commit_type": "add"}
{"commit_tokens": ["Added", "another", "test", "for", "checking", "modified", "times", "when", "updating", "an", "object"], "add_tokens": "var DISPLAY_NAME = 'S3rver'", "del_tokens": "var DISPLAY_NAME = 'NodeFakeS3'", "commit_type": "add"}
{"commit_tokens": ["remove", "assumption", "of", "entry", ".", "year"], "add_tokens": "if ( entry . year ) entry . year = parseInt ( entry . year . split ( \"-\" ) [ 0 ] ) ; // first year for series", "del_tokens": "entry . year = parseInt ( entry . year . split ( \"-\" ) [ 0 ] ) ; // first year for series", "commit_type": "remove"}
{"commit_tokens": ["Added", "tests", "for", "the", "KeepAlive", "class", "and", "performed", "minor", "fixes"], "add_tokens": "import RequestMonitor from \"./RequestMonitor\" if ( this [ FIELDS . terminated ] ) {", "del_tokens": "if ( terminated ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "CSS", "-", "module", "functionality", "to", "bundle", "mode", "."], "add_tokens": "import { fromObject } from \"interlock/lib/util/ast\" ; const exportObjTmpl = getTemplate ( \"export-object\" , node => t . program ( [ node ] ) ) ; * @ param { Object } moduleClassnameMaps Mapping of filename to friendly / module * classname maps . function replaceCssModules ( bundles , cssBundles , originBundleCssBundleMap , moduleClassnameMaps ) { const exportValue = moduleClassnameMaps && moduleClassnameMaps [ module . path ] ? fromObject ( assign ( { } , moduleClassnameMaps [ module . path ] , { _path : cssBundle . dest } ) ) : t . stringLiteral ( cssBundle . dest ) ; ast : exportObjTmpl ( { EXPORT_VALUE : exportValue } ) export default function generateCssBundles ( bundles , moduleClassnameMaps ) { . then ( cssBundles => replaceCssModules ( bundles , cssBundles , originBundleCssBundleMap , moduleClassnameMaps ) ) ;", "del_tokens": "const returnObjTemplate = getTemplate ( \"return-object\" , node => t . program ( [ node ] ) ) ; function replaceCssModules ( bundles , cssBundles , originBundleCssBundleMap ) { ast : returnObjTemplate ( { OBJ : t . stringLiteral ( cssBundle . dest ) } ) export default function generateCssBundles ( bundles ) { . then ( cssBundles => replaceCssModules ( bundles , cssBundles , originBundleCssBundleMap ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "pattern", "-", "lab", "config", "file", "path"], "add_tokens": "fs . readFileSync ( config . configFile , 'utf8' ) const plRoot = path . join ( config . configFile , '../..' ) ; const watchedExtensions = config . watchedExtensions . join ( ',' ) ; const src = config . extraWatches ? [ ] . concat ( plGlob , config . extraWatches )", "del_tokens": "fs . readFileSync ( config . patternLab . configFile , 'utf8' ) const plRoot = path . join ( config . patternLab . configFile , '../..' ) ; const watchedExtensions = config . patternLab . watchedExtensions . join ( ',' ) ; const src = config . patternLab . extraWatches ? [ ] . concat ( plGlob , config . patternLab . extraWatches )", "commit_type": "fix"}
{"commit_tokens": ["added", "history", "API", "state", "serialization"], "add_tokens": "var CAMEL_TO_UNDERSCORE = { for ( var camelCase in CAMEL_TO_UNDERSCORE ) { var underscore = CAMEL_TO_UNDERSCORE [ camelCase ] ; for ( var camelCase in CAMEL_TO_UNDERSCORE ) { var underscore = CAMEL_TO_UNDERSCORE [ camelCase ] ; / ** * Generates a URL to reflect this scene . * / SceneInfo . prototype . getCurrentUrl = function ( ) { var url = location . protocol + '//' + location . host + location . pathname + '?' ; for ( var camelCase in CAMEL_TO_UNDERSCORE ) { var underscore = CAMEL_TO_UNDERSCORE [ camelCase ] ; var value = this [ camelCase ] ; if ( value !== undefined ) { url += underscore + '=' + value + '&' ; } } // Chop off the trailing ampersand. return url . substring ( 0 , url . length - 1 ) ; } ;", "del_tokens": "var camelToUnderscore = { for ( var camelCase in camelToUnderscore ) { var underscore = camelToUnderscore [ camelCase ] ; for ( var camelCase in camelToUnderscore ) { var underscore = camelToUnderscore [ camelCase ] ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "a", "problem", "with", "the", "file", "paths", "for", "sentry", "file", "uploads"], "add_tokens": "var url = require ( 'url' ) ; var IGNORE_DOMAIN = '~' ; var sentryFilePath = IGNORE_DOMAIN + IGNORE_PATH + fileName ; var releaseEndpoint = makeUrl ( projectSlug , orgSlug ) ; var uploadEndpoint = releaseEndpoint + releaseVersion + '/files/' ;", "del_tokens": "var IGNORE_DOMAIN = '~/' ; var sentryFilePath = IGNORE_DOMAIN + IGNORE_PATH + fileName ; var releaseEndpoint = makeUrl ( projectSlug , orgSlug ) ; var uploadEndpoint = releaseEndpoint + releaseVersion + '/files/' ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "GNaP", "logo", "and", "favicon"], "add_tokens": "for ( var n in from ) {", "del_tokens": "for ( n in from ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "underscore", "for", "map", "for", "oldIE"], "add_tokens": "var _ = require ( 'underscore' ) ; var IoCBinding = require ( './IoCBinding.js' ) ; var deps = _ . map ( depNames , function ( d ) { return _this . make ( d ) ; } ) ;", "del_tokens": "var IoCBinding = require ( './IoCBinding.js' ) ; var deps = depNames . map ( function ( d ) { return _this . make ( d ) ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["use", "define", "in", "namespace", ".", "js"], "add_tokens": "( function ( exports ) { 'use strict' ; const moduleName = 'es6lib/namespace' ; if ( typeof module !== 'undefined' ) { module . exports = exports ; } else if ( typeof define === 'function' ) { define ( moduleName , exports ) ; } else if ( typeof window !== 'undefined' && typeof module === 'undefined' ) { window [ moduleName ] = exports ; } return exports ; } ) ( { } ) ;", "del_tokens": "'use strict' ;", "commit_type": "use"}
{"commit_tokens": ["Make", "filter", "function", "date", "more", "robust"], "add_tokens": "const isDatish = ( value ) => typeof value === 'object' && value !== null && ! Array . isArray ( value ) && typeof value . getTime === 'function' && typeof value . toISOString === 'function' if ( typeof value === 'string' || typeof value === 'number' ) { if ( isDatish ( value ) && ! Number . isNaN ( value . getTime ( ) ) ) {", "del_tokens": "if ( typeof value === 'string' ) { if ( value instanceof Date && ! Number . isNaN ( value . getTime ( ) ) ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "editing", "pages"], "add_tokens": "usage : '[title] [-a | --after MM-DD-YYYY] [-b | --before MM-DD-YYYY] [-c | --category CATEGORY] [-d | --draft | --drafts] [-f | --folder FOLDER] [-g | --gui] [-p | --page | --pages] [-t | --tag | --tags TAG]' , { name : '-c, --category, --categories' , desc : 'Category to filter on.' } , { name : '-d, --draft, --drafts' , desc : 'Only consider drafts' } , { name : '-p, --page, --pages' , desc : 'Edit pages instead of posts' } , { name : '-t, --tag, --tags' , desc : 'Tag to filter on.' } ,", "del_tokens": "usage : '[title] [-f | --folder] [-g | --gui]' , { name : '-c, --category' , desc : 'Category to filter on.' } , { name : '-d, --draft' , desc : 'Only consider drafts' } , { name : '-t, --tag' , desc : 'Tag to filter on.' } ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "stripped", "html", "on", "dropdown", "clear"], "add_tokens": "* semantic - ui - angular - jquery - 0.2 .4 * watcher : function ( scope , expression , func , context , force , equals ) scope . $watch ( expression , function ( updated ) if ( expression != 'model' || ! angular . equals ( currentValue , updated ) ) set : function ( value ) if ( scope [ expression ] != value || force ) scope . $evalAsync ( function ( ) update : function ( ) scope . $evalAsync ( function ( ) if ( value === null ) { } else if ( value === false ) { element . dropdown ( 'reset' ) ; }", "del_tokens": "* semantic - ui - angular - jquery - 0.2 .3 * watcher : function ( scope , expression , func , context , force , equals ) scope . $watch ( expression , function ( updated ) if ( expression != 'model' || ! angular . equals ( currentValue , updated ) ) set : function ( value ) if ( scope [ expression ] != value || force ) scope . $evalAsync ( function ( ) update : function ( ) scope . $evalAsync ( function ( ) if ( value == null ) { }", "commit_type": "fix"}
{"commit_tokens": ["Improve", "touch", "experience", "on", "IE10"], "add_tokens": "setTimeout ( function ( ) { el . _gesture . stop ( ) ; } , 0 ) ; return ;", "del_tokens": "el . _gesture . stop ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "alpha", "support", "in", "particle", "system"], "add_tokens": "this . alpha = 1 ; return this ; } , setCurrentAlpha : function ( gameTime ) { var a ; if ( this . config . alpha . length > 1 ) { var len = this . config . alpha . length ; var index = Math . floor ( ( gameTime - this . initTime ) / this . timeAlpha ) ; if ( index > len - 1 ) index = len - 1 ; a = this . config . alpha [ index ] ; if ( index < len - 1 ) { var t = this . timeAlpha * ( index + 1 ) ; t = this . timeAlpha - ( t - ( gameTime - this . initTime ) ) ; var leftTime = this . timeColor - t ; a += ( this . config . alpha [ index + 1 ] - this . config . alpha [ index ] ) * this . easing ( ( this . timeAlpha - leftTime ) / this . timeAlpha ) ; } } else { a = this . config . alpha [ 0 ] ; } this . alpha = a ; this . setCurrentAlpha ( gameTime ) ;", "del_tokens": "//console.log('???', index, t1); //console.log(this.tint, r,g,b, index, gameTime);", "commit_type": "add"}
{"commit_tokens": ["Allow", "injection", "of", "alternate", "cached", "instances", "with", "different", "opts"], "add_tokens": "app . use ( mw . $ . domainWrap || mw . req . domainWrap ( ) ) app . use ( mw . $ . notFound || mw . res . notFound ( ) ) app . use ( mw . $ . error || mw . res . error ( ) )", "del_tokens": "app . use ( mw . req . domainWrap ( ) ) app . use ( mw . res . notFound ( ) ) app . use ( mw . res . error ( ) )", "commit_type": "allow"}
{"commit_tokens": ["Adds", "custom", "radios", "/", "checkboxes", "stuff"], "add_tokens": "gulp . src ( [ 'bower_components/jquery/dist/jquery.min.js' , './src/js/**/*.js' ] ) gulp . watch ( [ './src/less/**/*.less' ] , [ 'css' ] ) ; gulp . watch ( [ './src/js/**/*.js' ] , [ 'js' ] ) ;", "del_tokens": "gulp . src ( './src/js/**/*.js' ) gulp . watch ( [ './src/less/**/*.less' , './src/js/**/*.js' ] , [ 'css' , 'js' ] ) ; gulp . watch ( [ './playground/**/*.less' ] , [ 'playground' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "not", "setting", "connected", "flag", "correctly", "events", "associated", "with", "responses", "will", "no", "longer", "emit", "a", "namiEvent", "event"], "add_tokens": "if ( event . event . indexOf ( 'Complete' ) !== - 1 || ( ( typeof ( event . eventlist ) !== 'undefined' ) && event . eventlist . indexOf ( 'Complete' ) !== - 1 ) || event . event . indexOf ( 'DBGetResponse' ) !== - 1 ) { this . callbacks [ event . actionid ] ( this . responses [ event . actionid ] ) ; } this . socket . on ( 'connect' , function ( ) { self . onConnect ( ) ; } ) ;", "del_tokens": "} if ( event . event . indexOf ( 'Complete' ) !== - 1 || ( ( typeof ( event . eventlist ) !== 'undefined' ) && event . eventlist . indexOf ( 'Complete' ) !== - 1 ) || event . event . indexOf ( 'DBGetResponse' ) !== - 1 ) { this . callbacks [ event . actionid ] ( this . responses [ event . actionid ] ) ; this . socket . on ( 'connect' , this . onConnect ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "documentation", "iinaccuracies", "in", "api", ".", "js"], "add_tokens": "* \"1000000\" , * \"2000000\" * \"1000000\" , * \"2000000\" , * \"1000000\" , * \"2000000\" , * \"1000000\" , * \"2000000\" , * \"1000000\" , * \"2000000\" * \"1000000\" , * \"2000000\" ,", "del_tokens": "* \"gasPrice\" : \"1000000\" , * \"gasLimit\" : \"2000000\" * \"gasPrice\" : \"1000000\" , * \"gasLimit\" : \"2000000\" , * \"gasPrice\" : \"1000000\" , * \"gasLimit\" : \"2000000\" , * \"gasPrice\" : \"1000000\" , * \"gasLimit\" : \"2000000\" , * \"gasPrice\" : \"1000000\" , * \"gasLimit\" : \"2000000\" * \"gasPrice\" : \"1000000\" , * \"gasLimit\" : \"2000000\" ,", "commit_type": "fix"}
{"commit_tokens": ["fixed", "path", "for", "length", "validation"], "add_tokens": "var results = func . validate ( { childArray : [ [ [ 1 , { field : 2 } , 2 ] ] ] } )", "del_tokens": "var results = func . validate ( { childArray : [ [ [ 1 ] ] ] } )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "crypto", "-", "Better", "debug"], "add_tokens": "ordered [ key ] = ( ( typeof unordered [ key ] == \"object\" ) && ! Array . isArray ( unordered [ key ] ) ) ? OrderObject ( unordered [ key ] ) : unordered [ key ] function JSONBlock ( data ) { //python json dump style return JSON . stringify ( OrderObject ( data ) , null , 1 ) . replace ( / \\n / g , \"\" ) . replace ( / + / g , \" \" ) . replace ( / ([\\{\\[]) / g , \"$1\" ) . replace ( / ([\\}\\]]) / g , \"$1\" ) if ( vss < signs_required )", "del_tokens": "ordered [ key ] = typeof unordered [ key ] == \"object\" ? OrderObject ( unordered [ key ] ) : unordered [ key ] function JSONBlock ( data ) { //zeronet sign's json in this format return JSON . stringify ( OrderObject ( data ) ) delete data . signs_required delete data . signers_sign if ( vss < signs_required ) { //console.log(addr, real, signs[addr], VerifySig(addr, real, signs[addr])) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "that", "webfont", "should", "be", "declared", "with", "var", "and", "add", "@constructor", "annotations", "to", "remove", "compiler", "warnings", "caused", "by", "that", "change"], "add_tokens": "var webfont = { } ;", "del_tokens": "webfont = { } ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "eslint", "and", "babel", "support", "with", "ES6"], "add_tokens": "const chai = require ( 'chai' ) ; const expect = chai . expect ; 'I want to be told the sum of two numbers' , ( ) => { Scenario ( 'Add two numbers' , ( ) => { let number1 ; let number2 ; let sum ; Given ( 'I have entered 50 into the calculator' , ( ) => { number1 = 50 ; } ) ; And ( 'I have entered 70 into the calculator' , ( ) => { number2 = 70 ; } ) ; When ( 'I press add' , ( ) => { sum = number1 + number2 ; } ) ; Then ( 'the result should be 120 on the screen' , ( ) => { expect ( sum ) . to . equal ( 120 ) ; } ) ;", "del_tokens": "var chai = require ( 'chai' ) ; var expect = chai . expect ; 'I want to be told the sum of two numbers' , function ( ) { Scenario ( 'Add two numbers' , function ( ) { Given ( 'I have entered 50 into the calculator' , function ( ) { this . number1 = 50 ; } ) ; And ( 'I have entered 70 into the calculator' , function ( ) { this . number2 = 70 ; } ) ; When ( 'I press add' , function ( ) { this . sum = this . number1 + this . number2 ; } ) ; Then ( 'the result should be 120 on the screen' , function ( ) { expect ( this . sum ) . to . equal ( 120 ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "the", "var", "name", "in", "JS", "bindings"], "add_tokens": "getContext : function ( id ) { return new L20n . Context ( this . xul [ id ] , this . cache ) hasContext : function ( id ) { return this . xul [ id ] ? true : false ; createContext : function ( id ) { this . xul [ id ] = { 'l20n' : { } , 'data' : { } } ; return new L20n . Context ( this . xul [ id ] , this . cache ) ;", "del_tokens": "getContext : function ( path ) { return new L20n . Context ( this . xul [ path ] , this . cache ) hasContext : function ( path ) { return this . xul [ path ] ? true : false ; createContext : function ( path , testPath ) { this . xul [ path ] = { 'l20n' : { } , 'data' : { } } ; return new L20n . Context ( this . xul [ path ] , this . cache ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "decay", "to", "tailer", "interval"], "add_tokens": "let resultPromise = Promise . resolve ( ) ; resultPromise = this . fetchSafe ( byteRangeStart , byteRangeEnd ) ; return resultPromise ;", "del_tokens": "this . fetchSafe ( byteRangeStart , byteRangeEnd ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "adapters", "to", "be", "added", "externally"], "add_tokens": "exports . registerBidAdapter = function ( bidAdaptor , bidderCode ) { } ; this . registerBidAdapter ( RubiconAdapter ( ) , 'rubicon' ) ; this . registerBidAdapter ( AppNexusAdapter ( ) , 'appnexus' ) ; this . registerBidAdapter ( OpenxAdapter ( ) , 'openx' ) ; this . registerBidAdapter ( PubmaticAdapter ( ) , 'pubmatic' ) ; this . registerBidAdapter ( CriteoAdapter ( ) , 'criteo' ) ; this . registerBidAdapter ( YieldbotAdapter ( ) , 'yieldbot' ) ; this . registerBidAdapter ( Casale ( ) , 'casale' ) ;", "del_tokens": "function registerBidAdapter ( bidAdaptor , bidderCode ) { } registerBidAdapter ( RubiconAdapter ( ) , 'rubicon' ) ; registerBidAdapter ( AppNexusAdapter ( ) , 'appnexus' ) ; registerBidAdapter ( OpenxAdapter ( ) , 'openx' ) ; registerBidAdapter ( PubmaticAdapter ( ) , 'pubmatic' ) ; registerBidAdapter ( CriteoAdapter ( ) , 'criteo' ) ; registerBidAdapter ( YieldbotAdapter ( ) , 'yieldbot' ) ; registerBidAdapter ( Casale ( ) , 'casale' ) ;", "commit_type": "allow"}
{"commit_tokens": ["allow", "empty", "json", "reports", "instead", "of", "failing"], "add_tokens": "files . map ( file => { // Cucumber json can be empty, it's likely being created by another process (#47) const data = fs . readFileSync ( file ) . toString ( ) || \"[]\" ; JSON . parse ( data ) . map ( json => { if ( options . metadata && ! json . metadata ) { json . metadata = options . metadata ; } else { json = Object . assign ( { \"metadata\" : { \"browser\" : { \"name\" : \"not known\" , \"version\" : \"not known\" } , \"device\" : \"not known\" , \"platform\" : { \"name\" : \"not known\" , \"version\" : \"not known\" } } , json ) ; } jsonOutput . push ( json ) } ) ; } ) ;", "del_tokens": "files . map ( file => jsonFile . readFileSync ( file ) . map ( json => { if ( options . metadata && ! json . metadata ) { json . metadata = options . metadata ; } else { json = Object . assign ( { \"metadata\" : { \"browser\" : { \"name\" : \"not known\" , \"version\" : \"not known\" } , \"device\" : \"not known\" , \"platform\" : { \"name\" : \"not known\" , \"version\" : \"not known\" } } , json ) ; } jsonOutput . push ( json ) } ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "tests", "to", "check", "built", "asset"], "add_tokens": "// THIS MUST BE FIRST. It loads the babel/polyfill require ( './require-test' ) ;", "del_tokens": "require ( 'babel/polyfill' ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "possibility", "to", "push", "taskbulks", "added", "test"], "add_tokens": "if ( data . constructor !== Array ) { data = [ data ] ; } _forEach ( data , function ( task ) { q . tasks . push ( { data : task , callback : typeof callback === 'function' ? callback : null } ) ; if ( q . saturated && q . tasks . length == concurrency ) { q . saturated ( ) ; } async . nextTick ( q . process ) ; } ) ;", "del_tokens": "q . tasks . push ( { data : data , callback : typeof callback === 'function' ? callback : null } ) ; if ( q . saturated && q . tasks . length == concurrency ) q . saturated ( ) ; async . nextTick ( q . process ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "retry", "for", "the", "examples", "hook", ".", "Fix", "mongodb", "cleaning"], "add_tokens": "done ( ) ; done ( ) ;", "del_tokens": "done ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "folling", "update", "to", "npm", "-", "check", "v5"], "add_tokens": "results = results . get ( 'packages' ) ; message : 'Out of date packages: \\n' + results . map ( function ( p ) { return moduleInfo ( p ) ; } ) . join ( '\\n' ) ( 0 , _gulpUtil . log ) ( 'All packages are up to dates :)' ) ; / ** * get descriptive module info * @ param { [ type ] } module [ description ] * @ return { [ type ] } [ description ] * / function moduleInfo ( module ) { return '\\t' + module . moduleName + ' (installed: ' + module . installed + ', latest: ' + module . latest + ')' ; } * / module . exports = exports [ 'default' ] ;", "del_tokens": "message : 'Out of date packages: ' + results . map ( function ( p ) { return p . moduleName ; } ) ( 0 , _gulpUtil . log ) ( 'All packages are up to date :)' ) ; module . exports = exports [ 'default' ] ; * /", "commit_type": "fix"}
{"commit_tokens": ["Fix", "when", "element", "do", "not", "have", ".", "getAttribute"], "add_tokens": "if ( el . getAttribute && typeof el . getAttribute ( 'xlink:href' ) === 'string' ) {", "del_tokens": "if ( typeof el . getAttribute ( 'xlink:href' ) === 'string' ) {", "commit_type": "fix"}
{"commit_tokens": ["update", "the", "template", "of", "app"], "add_tokens": "module . exports = function l10ns ( cmd , options , done ) { if ( _ . isFunction ( options ) ) { done = options ; options = { } ; } if ( ! _ . isFunction ( done ) ) { done = function ( ) { } ; } // Run update translation l10ns ( 'update' , function ( err , time ) { // Run compile translation l10ns ( 'compile' , function ( err , time ) { // console.log(`rum command l10ns ${cmd}...`.gray);", "del_tokens": "module . exports = function runL10ns ( cmd , options , done ) { console . log ( ` ${ cmd } ` . gray ) ; var time = process . hrtime ( ) ; var time = process . hrtime ( ) ; var p = spawn ( l10nsBin , [ 'update' ] , l10nsOptions ) ; p . on ( 'close' , ( code ) => { p = spawn ( l10nsBin , [ 'compile' ] , l10nsOptions ) ; p . on ( 'close' , ( code ) => {", "commit_type": "update"}
{"commit_tokens": ["Implement", "action", "handling", "in", "the", "Store", "and", "add", "tests"], "add_tokens": "var utils = require ( './utils' ) / ** * @ param { string } actionType * @ param { object } payload * / dispatch ( actionType , payload ) { this . dispatchStream . write ( { type : actionType , payload : payload } ) } store = new store ( )", "del_tokens": "store = new Store ( )", "commit_type": "implement"}
{"commit_tokens": ["Using", "a", "more", "reliable", "isBrowser", "func"], "add_tokens": "return ! ( Object . prototype . toString . call ( global . process ) === '[object process]' ) ;", "del_tokens": "return ! ( Object . prototype . toString . call ( typeof process !== 'undefined' ? process : 0 ) === '[object process]' ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "data", "into", "a", "separate", "file", "."], "add_tokens": "// You can put your own text in a file `hubot-encourage-data.json` in // your hubot project. It should be a copy of data.json from this // project. const Path = require ( \"path\" ) ; let data = require ( '../data' ) ; try { // Attempt to load data from app directory. data = require ( Path . join ( process . cwd ( ) , \"hubot-encourage-data\" ) ) ; } catch ( e ) { if ( e . code !== \"MODULE_NOT_FOUND\" ) { throw e ; } } msg . send ( capitalize ( msg . random ( data . remarks ) . replace ( \"%\" , name ) ) ) ; msg . send ( msg . random ( data . allinclusive ) ) ;", "del_tokens": "// None const remarks = [ \"Great job, %!\" , \"Way to go, %!\" , \"% is amazing, and everyone should be happy this amazing person is around.\" , \"I wish I was more like %.\" , \"% is good at like, 10 times more things than I am.\" , \"%, you are an incredibly sensitive person who inspires joyous feelings in all those around you.\" , \"%, you are crazy, but in a good way.\" , \"% has a phenomenal attitude.\" , \"% is a great part of the team!\" , \"I admire %'s strength and perseverance.\" , \"% is a problem-solver and cooperative teammate.\" , \"% is the wind beneath my wings.\" , \"% has a great reputation.\" ] ; const allinclusive = [ \"Great job today, everyone!\" , \"Go team!\" , \"Super duper, gang!\" , \"If I could afford it, I would buy you all lunch!\" , \"What a great group of individuals there are in here. I'm proud to be chatting with you.\" , \"You all are capable of accomplishing whatever you set your mind to.\" , \"I love this team's different way of looking at things!\" ] ; msg . send ( capitalize ( msg . random ( remarks ) . replace ( \"%\" , name ) ) ) ; msg . send ( msg . random ( allinclusive ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "same", "-", "path", "limitation", "for", "IE6", "/", "7"], "add_tokens": "var storage , storageOwner , storageContainer ; // Since #userData storage applies only to specific paths, we need to // somehow link our data to a specific path. We choose /favicon.ico // as a pretty safe option, since all browsers already make a request to // this URL anyway and being a 404 will not hurt us here. We wrap an // iframe pointing to the favicon in an ActiveXObject(htmlfile) object // (see: http://msdn.microsoft.com/en-us/library/aa752574(v=VS.85).aspx) // since the iframe access rules appear to allow direct access and // manipulation of the document element, even for a 404 page. This // document can be used instead of the current document (which would // have been limited to the current path) to perform #userData storage. try { storageContainer = new ActiveXObject ( 'htmlfile' ) ; storageContainer . open ( ) ; storageContainer . write ( '<s' + 'cript>document.w=window</s' + 'cript><iframe src=\"/favicon.ico\"></frame>' ) ; storageContainer . close ( ) ; storageOwner = storageContainer . w . frames [ 0 ] . document ; storage = storageOwner . createElement ( 'div' ) ; } catch ( e ) { // somehow ActiveXObject instantiation failed (perhaps some special // security settings or otherwse), fall back to per-path storage storage = doc . createElement ( 'div' ) ; storageOwner = doc . body ; } storageOwner . appendChild ( storage ) storageOwner . removeChild ( storage )", "del_tokens": "var storage = doc . createElement ( 'div' ) doc . body . appendChild ( storage ) doc . body . removeChild ( storage )", "commit_type": "remove"}
{"commit_tokens": ["Update", "the", "seng", "-", "boilerplate", "version"], "add_tokens": "library : \"VueTransitionComponent\"", "del_tokens": "library : \"VueTransition\"", "commit_type": "update"}
{"commit_tokens": ["Added", "more", "syntax", "and", "working", "examples", ";"], "add_tokens": "memcached . increment ( \"hello\" , 1 , function ( err , result ) {", "del_tokens": "memcached . increment ( \"hello\" , function ( err , result ) {", "commit_type": "add"}
{"commit_tokens": ["added", "check", "for", "multiple", "callback", "invocation", "&", "tests", "for", "it", ";", "beautified", "Function", ".", "prototype", ".", "sync", "()"], "add_tokens": "// Wrong asynchronous which calls callback twice function asyncFunctionCallbackTwice ( a , b , callback ) { process . nextTick ( function ( ) { callback ( null , a + b ) ; callback ( null , a - b ) ; } ) } // test asynchronous which calls callback twice (should not be called twice) var result = asyncFunctionCallbackTwice . sync ( null , 2 , 3 ) ; assert . equal ( result , 2 + 3 ) ;", "del_tokens": "// test on throws exception", "commit_type": "add"}
{"commit_tokens": ["Adding", "output", "format", "aliases", "url", "=", "uri"], "add_tokens": "case 'datauristring' : case 'datauristrlng' : return 'data:application/pdf;base64,' + base64_encode_with_native_fallback ( buildDocument ( ) ) case 'datauri' : case 'dataurl' : document . location . href = 'data:application/pdf;base64,' + base64_encode_with_native_fallback ( buildDocument ( ) ) ; break ;", "del_tokens": "case 'datauristring' : return 'data:application/pdf;base64,' + base64_encode_with_native_fallback ( buildDocument ( ) ) case 'datauri' : document . location . href = 'data:application/pdf;base64,' + base64_encode_with_native_fallback ( buildDocument ( ) ) ; break ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", ".", "Emit", "error", "on", "serve", ".", "Removed", "serve", "and", "dependencies", "."], "add_tokens": ". then ( ( ) => BbPromise . reject ( new this . serverless . classes . Error ( 'serve has been removed. Use serverless-offline instead.' ) ) ) ,", "del_tokens": "const serve = require ( './lib/serve' ) ; serve , options : { port : { usage : 'The local server port' , shortcut : 'p' , } , } , . then ( this . validate ) . then ( this . serve ) ,", "commit_type": "update"}
{"commit_tokens": ["update", "the", "changelog", "renderer", "so", "it", "only", "adds", "a", "changelog", "if", "there", "is", "content", "defined"], "add_tokens": "var itemArr = entity . selectAll ( 'item' ) var items = Promise . all ( itemArr . map ( function ( itemEntity ) { // Only add a changelog if there is content to display if ( itemArr . length > 0 || description || extra ) { return page . create ( 'div' ) . class ( 'qm-changelog' ) . add ( page . create ( 'div' ) . class ( 'qm-changelog-head' ) . add ( title ) ) . add ( page . create ( 'div' ) . class ( 'qm-changelog-body' ) . add ( description ) . add ( items ) . add ( extra ) ) }", "del_tokens": "var items = Promise . all ( entity . selectAll ( 'item' ) . map ( function ( itemEntity ) { return page . create ( 'div' ) . class ( 'qm-changelog' ) . add ( page . create ( 'div' ) . class ( 'qm-changelog-head' ) . add ( title ) ) . add ( page . create ( 'div' ) . class ( 'qm-changelog-body' ) . add ( description ) . add ( items ) . add ( extra ) )", "commit_type": "update"}
{"commit_tokens": ["fix", "umd", "builds", "with", "exposed", "modules"], "add_tokens": "function flatten ( rows , opts , stream ) { var isEntryModule = rows [ i ] . entry && rows [ i ] . hasExports && opts . standalone // Need this for: // https://github.com/browserify/browserify/blob/0305b703b226878f3acb5b8f2ff9451c87cd3991/test/debug_standalone.js#L44-L64 var isStandaloneModule = opts . standalone && rows [ i ] . id === stream . standaloneModule if ( isEntryModule || isStandaloneModule ) { stream . push ( flatten ( rows , opts || { } , stream ) )", "del_tokens": "function flatten ( rows , opts ) { if ( rows [ i ] . entry && rows [ i ] . hasExports && opts . standalone ) { stream . push ( flatten ( rows , opts || { } ) )", "commit_type": "fix"}
{"commit_tokens": ["added", "pre", "nav", "hook", "for", "the", "client"], "add_tokens": "this . beforeNavigate ( routeName , function ( cancel ) { if ( cancel ) { return LAZO . app . trigger ( 'route:canceled' ) ; } if ( routeName . match ( / ^(?:(ht|f)tp(s?)\\:\\/\\/)? / ) [ 0 ] . length ) { return window . location = routeName ; } LAZO . router . navigate ( routeName , { trigger : true } ) ; } ) ; beforeNavigate : function ( path , callback ) { callback ( false ) ; } ,", "del_tokens": "if ( routeName . match ( / ^(?:(ht|f)tp(s?)\\:\\/\\/)? / ) [ 0 ] . length ) { return window . location = routeName ; } LAZO . router . navigate ( routeName , { trigger : true } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "keydown", "event", "to", "window", "inview", "check", "events"], "add_tokens": ". merge ( signalFromEvent ( window , 'checkInView click ready wheel mousewheel DomMouseScroll MozMousePixelScroll resize scroll touchmove mouseup keydown' ) )", "del_tokens": ". merge ( signalFromEvent ( window , 'checkInView click ready wheel mousewheel DomMouseScroll MozMousePixelScroll resize scroll touchmove mouseup' ) )", "commit_type": "add"}
{"commit_tokens": ["fix", "false", "width", "and", "height", "from", "canvas", "elements"], "add_tokens": "* Origami . js 0.5 .0 * Date : 2016 - 09 - 18 T17 : 57 Z width : el . offsetWidth , height : el . offsetHeight ,", "del_tokens": "* Origami . js 0.4 .7 * Date : 2016 - 09 - 15 T04 : 31 Z width : el . width , height : el . height ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "eson", ".", "seconds", "()", "."], "add_tokens": "var eson ; module . exports = eson = require ( 'eson' ) ; / ** * Similar to ` ` but convert to seconds . * / eson . seconds = function ( key , val ) { var m , n , type ; m = / ^(\\d+) *(seconds?|s|minutes?|m|hours?|h|days?|d)$ / . exec ( val ) ; if ( ! m ) { return ; } n = ~ ~ m [ 1 ] ; type = m [ 2 ] ; switch ( type ) { case 'days' : case 'day' : case 'd' : return n * 86400 ; case 'hours' : case 'hour' : case 'h' : return n * 3600 ; case 'minutes' : case 'minute' : case 'm' : return n * 60 ; case 'seconds' : case 'second' : case 's' : return n ; } } ;", "del_tokens": "module . exports = require ( 'eson' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "to", "message", "and", "server!"], "add_tokens": "var constants = require ( '../lib/constants.js' ) ; it ( 'should understand JRC_MESSAGE' , function ( ) { message . command . should . equal ( constants . MESSAGE ) ;", "del_tokens": "it ( 'should understand JRC_NORMAL' , function ( ) { message . command . should . equal ( 'E' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "textformat", "block", "and", "add", "test", "case"], "add_tokens": "if ( style == 'email' ) { var paragraphs = content . split ( / [\\r\\n]{2} / ) ; for ( var i = 0 ; i < paragraphs . length ; ++ i ) { if ( ! p ) { if ( indent_first > 0 ) { if ( indent > 0 ) { p = p . replace ( / ^ / mg , indentStr ) ;", "del_tokens": "if ( style == 'email' ) { var paragraphs = content . split ( '\\n' ) ; for ( var i = 0 ; i < paragraphs . length ; ++ i ) { if ( ! p ) { if ( indent_first ) { if ( indent ) { p = p . replace ( / ^ / mg , indentStr ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "in", "controllers", ".", "js", "placeholder", "code"], "add_tokens": "MyCtrl2 . $inject = [ ] ;", "del_tokens": "MyCtrl1 . $inject = [ ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "to", "tell", "the", "server", "the", "browser", "time", "zone"], "add_tokens": "var browser_timezone = '' ; try { if ( $ . type ( window . jstz ) == 'object' && $ . type ( jstz . determine ) == 'function' ) { browser_timezone = jstz . determine ( ) . name ( ) ; if ( $ . type ( browser_timezone ) !== 'string' ) { browser_timezone = '' ; } } } catch ( e ) { } var params = { from : self . options . position . start . getTime ( ) , to : self . options . position . end . getTime ( ) } ; if ( browser_timezone . length ) { params . browser_timezone = browser_timezone ; } url : buildEventsUrl ( self . options . events_url , params ) ,", "del_tokens": "url : buildEventsUrl ( self . options . events_url , { from : self . options . position . start . getTime ( ) , to : self . options . position . end . getTime ( ) } ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "event", "to", "create", "default", "folders"], "add_tokens": "var mkdirp = require ( 'mkdirp' ) ; function createDefaultFolders ( next ) { we . events . emit ( 'we:create:default:folders' , we ) ; next ( ) ; } , we . log . info ( 'We.js bootstrap done' ) ;", "del_tokens": "we . log . info ( 'All loaded, starting the app' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "pipe", "to", "transform", "ability"], "add_tokens": "'modules:pipe' : { src : '../test/_fixtures/modules' , pipe : { '.concat' : { src : '**/*.js' , file : 'main.js' , } , '.uglify' : { file : { extname : '.min.js' } } } } , 'modules:uglify' : { src : '../test/_fixtures/modules' , '.uglify' : { src : '**/*.js' , file : { extname : '.min.js' } } } , markups : { src : '../test/_fixtures/modules/**/*.html' , flatten : true } , createGulpTasks ( gulp , taskConfigs , config ) ;", "del_tokens": "markups : { src : '*.html' } , createGulpTasks ( taskConfigs , config ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "dry", "-", "run", "imports", "on", "unowned", "archives"], "add_tokens": "if ( ! dstArchive . owner && ! dryRun ) {", "del_tokens": "if ( ! dstArchive . owner ) {", "commit_type": "allow"}
{"commit_tokens": ["Allow", "for", "empty", "strings", "in", "accessors", "and", "arguments", "."], "add_tokens": "accessExp = / ^\\.?([^\\.\\[]+)|\\[((-?\\d+)|('|\")(|.*?[^\\\\])\\4)\\] / , argumentsExp = / ^(,|^)\\s*?((true|false|(-?\\d+))|('|\")(|.*?([^\\\\]|\\5))\\5) / ;", "del_tokens": "accessExp = / ^\\.?([^\\.\\[]+)|\\[((-?\\d+)|('|\")(.*?[^\\\\])\\4)\\] / , argumentsExp = / ^(,|^)\\s*?((true|false|(-?\\d+))|('|\")(.*?([^\\\\]|\\5))\\5) / ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "path", ".", "resolve", "for", "getting", "the", "root", "directory"], "add_tokens": "const memoryBase = path . resolve ( path . join ( ` ${ this . baseUrl } ` , '/expressvue/bundles' , memoryParsed . dir ) ) ; // add C: for memory file system for windows machines context . script = path . join ( '/' , path . relative ( path . resolve ( '/' ) , bundlePath . memory . filename . client ) ) ; // strip drive letter for windows systems context . script = path . join ( '/' , path . relative ( path . resolve ( '/' ) , bundle . clientBundlePath ) ) ; // strip drive letter for windows systems const fullFileName = path . resolve ( bundleFileName ) ; // add C: for memory file system for windows machines", "del_tokens": "const memoryBase = path . join ( path . sep === '/' ? '/' : 'C:\\\\' , ` ${ this . baseUrl } ` , memoryParsed . dir ) ; context . script = path . sep === '/' ? bundlePath . memory . filename . client : bundlePath . memory . filename . client . replace ( / ^C: / , '' ) ; // strip C: for windows systems context . script = path . sep === '/' ? bundle . clientBundlePath : bundle . clientBundlePath . replace ( / ^C: / , '' ) ; // strip C: for windows systems const fullFileName = path . sep === '/' ? bundleFileName : path . join ( 'C:\\\\' , bundleFileName ) ; // add C: for memory file system for windows machines", "commit_type": "use"}
{"commit_tokens": ["add", "test", "for", "multi", "file"], "add_tokens": "id && ( ids [ id ] = 1 ) ; callback ( ) ;", "del_tokens": "if ( id && ids [ id ] ) { return ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "bottom", "option", "that", "if", "set", "to", "a", "number", "other", "than", "the", "default", "-", "1", "will", "fix", "the", "element", "to", "whatever", "the", "bottom", "number", "is", ".", "The", "flow", "is", "the", "same", "as", "for", "top", "elements", ".", "The", "item", "will", "still", "move", "left", "to", "right", "with", "page", "resize", "and", "horizontal", "scroll", "."], "add_tokens": "if ( base . options . bottom != - 1 ) { setFixed ( ) ; } 'top' : base . options . bottom == - 1 ? base . options . marginTop : '' , 'bottom' : base . options . bottom == - 1 ? '' : base . options . bottom function setLeft ( x ) { setLeft ( x ) ; if ( base . options . bottom != - 1 ) { setLeft ( x ) ; } else { // Set the target element to unfixed, placing it where it was // before. setUnfixed ( ) ; } if ( base . options . bottom != - 1 ) { setFixed ( ) ; } limit : 0 , bottom : - 1", "del_tokens": "'top' : base . options . marginTop function setleft ( x ) { setleft ( x ) ; // Set the target element to unfixed, placing it where it was // before. setUnfixed ( ) ; limit : 0", "commit_type": "add"}
{"commit_tokens": ["Fix", "fullscreenchange", "event", "handling", "for", "IE11"], "add_tokens": "// 'fullscreenchange webkitfullscreenchange mozfullscreenchange MSFullscreenChange' var FULLSCREENCHANGE_EVENT = [ '' , ' webkit' , ' moz' , ' ' ] . join ( 'fullscreenchange' ) + // @NOTE: IE 11 uses upper-camel-case for this, which is apparently necessary 'MSFullscreenChange' ;", "del_tokens": "// 'webkitfullscreenchange mozfullscreenchange msfullscreenchange fullscreenchange' var FULLSCREENCHANGE_EVENT = [ 'webkit' , ' moz' , ' ms' , ' ' , '' ] . join ( 'fullscreenchange' ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "logSuccess", "option", "and", "bumped", "up", "version"], "add_tokens": "if ( config . logSuccess ) { gutil . log ( 'Beautifying' , file . relative ) ; }", "del_tokens": "if ( config . logSuccess ) gutil . log ( 'Beautifying' , file . relative ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "failing", "tests", "and", "added", "test", "for", "adding", "/", "removing", "from", "lib", "search", "paths", "."], "add_tokens": "if ( file . path == filePath || file . path == ( '\"' + filePath + '\"' ) ) {", "del_tokens": "if ( file . path == filePath ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "undocumented", "support", "for", "next", "()", "on", "the", "handler", "returned"], "add_tokens": "const GCLOUD_TYPE = 'gcloud' ; // Google Cloud, Express and others fn(req, res) * Errors issued by the service handler and passed on to error handler . * Returns a handler with either function ( req , res ) signature // return handler function with fn(req, res) signature return ( req , res ) => { const done = err => err && setImmediate ( errorHandler , err , req , res ) ; * it will handle the error if the Promise is rejected .", "del_tokens": "const GCLOUD_TYPE = 'gcloud' ; // Google Cloud, Express and others fn(req, res[, next]) * Errors issued by the service handler and passed on to error handler , or next ( ) . * Returns a handler with either function ( req , res , next ) signature // return handler function with fn(req, res, next) signature return ( req , res , next ) => { const done = next && ( err => setImmediate ( next , err ) ) || ( err => err && setImmediate ( errorHandler , err , req , res ) ) ; * the next ( ) callback will be called after the promise is resolved * and will contain the error if the Promise is rejected .", "commit_type": "remove"}
{"commit_tokens": ["Improve", "the", "browserify", "compatibility", "for", "the", "client", "code"], "add_tokens": "} ( typeof module !== 'undefined' ? module . exports : window ) ) ;", "del_tokens": "} ( typeof window !== 'undefined' ? window : module . exports ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["remove", "Firefox", "-", "specific", "fields", "in", "Source", "type"], "add_tokens": "url : t . union ( [ t . String , t . Nil ] )", "del_tokens": "url : t . union ( [ t . String , t . Nil ] ) , // Internal for Firefox for now actor : t . maybe ( t . String )", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "an", "error", "in", "condition", ".", "Caught", "by", "@bleathem", "."], "add_tokens": "if ( ! isNaN ( fullDateAfterSeconds ) ) { var fullDateAfterMillis = fullDateAfterSeconds * 1000 ; if ( ( distanceMillis >= 0 && fullDateAfterMillis <= distanceMillis ) || ( distanceMillis < 0 && fullDateAfterMillis >= distanceMillis ) ) { if ( format ) { return $filter ( 'date' ) ( fromTime , format , timezone ) ; }", "del_tokens": "if ( ! isNaN ( fullDateAfterSeconds ) && ( ( distanceMillis >= 0 && ( fullDateAfterSeconds * 1000 ) <= distanceMillis ) || ( fullDateAfterSeconds * 1000 ) >= distanceMillis ) ) { if ( format ) { return $filter ( 'date' ) ( fromTime , format , timezone ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "remote", "-", "user", "token"], "add_tokens": "var auth = require ( 'basic-auth' ) exports . format ( 'default' , ':remote-addr - :remote-user [:date] \":method :url HTTP/:http-version\" :status :res[content-length] \":referrer\" \":user-agent\"' ) ; exports . format ( 'short' , ':remote-addr :remote-user :method :url HTTP/:http-version :status :res[content-length] - :response-time ms' ) ; / ** * remote user * / exports . token ( 'remote-user' , function ( req ) { var creds = auth ( req ) var user = ( creds && creds . name ) || '-' return user ; } )", "del_tokens": "exports . format ( 'default' , ':remote-addr - - [:date] \":method :url HTTP/:http-version\" :status :res[content-length] \":referrer\" \":user-agent\"' ) ; exports . format ( 'short' , ':remote-addr - :method :url HTTP/:http-version :status :res[content-length] - :response-time ms' ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "sample", "config", "comments", "to", "make", "whitelist", "behavior", "slightly", "more", "clear", "."], "add_tokens": "metricFiltersInclude : [ / .* / ] //OPTIONAL (array of regex) any metrics NOT matching at least one of these filters will be dropped", "del_tokens": "metricFiltersInclude : [ / .* / ] //OPTIONAL (array of regex) any metrics NOT matching these filters will be dropped", "commit_type": "change"}
{"commit_tokens": ["add", "german", "language", "file", "and", "integrated", "translation", "method"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "client", "close", "call", "so", "that", "Mocha", "can", "finish", "the", "test", "run", "and", "move", "on", "to", "type", "checking"], "add_tokens": "const transport = new RSocketWebSocketClient ( { deferred . resolve ( broker . toObject ( ) ) ; client . close ( ) ; expect ( broker . brokerid ) . to . not . equal ( undefined ) ;", "del_tokens": "const transport = new RSocketWebSocketClient ( { deferred . resolve ( ) ; deferred . resolve ( broker ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "change", "for", "dist", "dir"], "add_tokens": "class ShapeUtils { //# sourceMappingURL=ShapeUtils.js.map", "del_tokens": "export class ShapeUtils { //# sourceMappingURL=ShapeUtils.js.map", "commit_type": "add"}
{"commit_tokens": ["Added", "loader", "for", "scripts", "trying", "to", "get", "output", "of", "test", "scripts", "working"], "add_tokens": "footer : \"\\\";\\n//@ sourceURL=feta.js\"", "del_tokens": "footer : \"\\\";\"", "commit_type": "add"}
{"commit_tokens": ["add", "code", "coverage", "to", "unit", "tests"], "add_tokens": "grunt . registerTask ( 'ci' , [ 'clean' , 'jshint:jslint' , 'jshint:checkstyle' , 'bgShell:coverage' , 'bgShell:cobertura' , 'jasmine_node' ] ) ;", "del_tokens": "grunt . registerTask ( 'ci' , [ 'clean' , 'jshint:jslint' , 'jshint:checkstyle' , 'bgShell:coverage' , 'bgShell:cobertura' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "vertical", "scrolling", "of", "labels"], "add_tokens": "jQuery ( '#labels' ) . css ( 'top' , - ( jQuery ( window ) . scrollTop ( ) ) ) ;", "del_tokens": "jQuery ( '#labels' ) . css ( 'top' , '-' + jQuery ( window ) . scrollTop ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "in", "engines", "and", "async"], "add_tokens": "async = require ( 'async' ) , Zip = require ( 'node-zip' ) , engines = { } ; // In series async . waterfall ( [ function create ] , cb ) ;", "del_tokens": "icomoonPath = require . resolve ( 'icomoon-phantomjs' ) , Zip = require ( 'node-zip' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "continuation", "to", "render", "()", "view", "for", "actions", "returning", "Promises", "."], "add_tokens": "* @ param { Router } router express . Router instance * @ param { String } name controller name path with prefix / const info = new RouteInfo ( ctr , name , prop , ctr [ prop ] ) / ** * Ignore result when action method receives the res parameter . * It means that the action method takes the responsibility of * sending the response via res object . * / if ( info . argsNames . includes ( 'res' ) ) { if ( ctx != undefined && ctx != null ) throw Error ( 'connect-controller: You are both receiving argument res and returning a result!!! Please remove res or return undefined!!!' ) return // Action method must send response via res !!! } / ** * For async action methods * / if ( ctx instanceof Promise ) { ctx . then ( content => res . render ( info . view , content ) ) . catch ( err => next ( err ) ) } else { // Sync action methods }", "del_tokens": "const info = new RouteInfo ( ctr , prop , ctr [ prop ] ) if ( ! info . argsNames . includes ( 'res' ) )", "commit_type": "add"}
{"commit_tokens": ["update", "angular", "example", "from", "angular", "5", "to", "angular", "6"], "add_tokens": "frameworks : [ 'jasmine' , '@angular-devkit/build-angular' ] , require ( '@angular-devkit/build-angular/plugins/karma' ) dir : require ( 'path' ) . join ( __dirname , 'coverage' ) ,", "del_tokens": "frameworks : [ 'jasmine' , '@angular/cli' ] , require ( '@angular/cli/plugins/karma' ) angularCli : { environment : 'dev' } ,", "commit_type": "update"}
{"commit_tokens": ["fixed", "version", "undefined", "bug", "in", "footer", ".", "ejs"], "add_tokens": "return VERSION ;", "del_tokens": "return conf . version ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "ignore", "property", "to", "bower"], "add_tokens": "external . version = \"2.2.2\" ;", "del_tokens": "external . version = \"2.2.1\" ;", "commit_type": "add"}
{"commit_tokens": ["updated", "expired", "view", "to", "compare", "dates"], "add_tokens": "console . log ( cloudq + '/_design/queued/_view/name?limit=1' ) ; request ( cloudq + '/_design/queued/_view/name?limit=1' , { json : true , body : JSON . stringify ( { keys : [ queue ] } ) } , function ( e , r , b ) { console . log ( r . request . body . toString ( ) ) ;", "del_tokens": "request ( cloudq + '/_design/queued/_view/name?limit=1' , { json : { startkey : [ queue , 1 ] } } , function ( e , r , b ) {", "commit_type": "update"}
{"commit_tokens": ["add", "basic", "support", "for", "alpha", "ordered", "list", "types"], "add_tokens": "// Return different functions for different OL types var typeFunctions = { 1 : function ( start , i ) { return i + 1 + start } , a : function ( start , i ) { return String . fromCharCode ( i + start + 97 ) } , A : function ( start , i ) { return String . fromCharCode ( i + start + 65 ) } } ; // Determine type var olType = elem . attribs . type || '1' // Use different function depending on type var index = typeFunctions [ olType ] ( start , i ) ; var prefix = ( olType === '1' ) ? ' ' + index + '. ' + _s . repeat ( ' ' , spacing ) : index + '. ' ;", "del_tokens": "var index = i + 1 + start ; var prefix = ' ' + index + '. ' + _s . repeat ( ' ' , spacing ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "filter", "for", "velocityCount", "in", "foreach"], "add_tokens": "variable : [ ast . to , 'velocityCount' ] ,", "del_tokens": "variable : [ ast . to ] ,", "commit_type": "add"}
{"commit_tokens": ["added", "possibility", "to", "chain", "from", "statements"], "add_tokens": "if ( from . skipFromStatement ) { result . push ( ',' ) ; } else { result . push ( 'FROM' ) ; } var hasFrom = false ; node . skipFromStatement = hasFrom ; hasFrom = true ;", "del_tokens": "result . push ( 'FROM' ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "missing", "props", "to", "field", "view", "models"], "add_tokens": "value : { type : 'string' , value : '' } , inline : 'htmlbool' ,", "del_tokens": "value : 'string' ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "string", "and", "boolean", "values", "being", "animated", "would", "not", "be", "updated", "properly", ".", "Also", "added", "a", "boolean", "for", "isInitialized"], "add_tokens": "var duration ; var delay ; var ease ; duration = aniDef . duration ; delay = aniDef . delay ; ease = aniDef . ease ; duration : duration / overallDuration , delay : delay / overallDuration , ease : ease , } else if ( typeof stateDef [ pathPart ] === 'string' || typeof stateDef [ pathPart ] === 'boolean' ) { if ( time * overallDuration < duration + delay ) {", "del_tokens": "duration : aniDef . duration / overallDuration , delay : aniDef . delay / overallDuration , ease : aniDef . ease , } else if ( typeof stateDef [ pathPart ] === 'string' ) { if ( time < 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "auto", "-", "refresh", "clearing", "room", "bold"], "add_tokens": "// Clear current selection of clients. this . clearSelectedClients ( ) ; this . clientsField . placeholder = 'Choose a room and ' + // Needed when the refresh button is pressed. if ( roomObj . id === node . game . roomInUse ) elem . click ( ) ; ClientList . prototype . clearSelectedClients = function ( ) { this . clientsField . value = '' ; } ;", "del_tokens": "this . clientsField . placeholder = 'Select a room and ' +", "commit_type": "fix"}
{"commit_tokens": ["Add", "karma", "test", "for", "CI", "test"], "add_tokens": "// Check the below cookies setting manually.", "del_tokens": "it ( 'should return false if the cookie is disabled' , function ( ) { expect ( Cookie . isEnabled ( ) ) . to . equal ( false ) ; } ) ; it ( 'should set secure when option is true' , function ( ) { Cookie . set ( 'someKey' , 'someValue' , { secure : true } ) ; expect ( Cookie . get ( 'someKey' ) ) . to . equal ( null ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "/", "help", "for", "good", "measure", ".", "Fix", "some", "styles", "."], "add_tokens": "this . helpOpen = ko . observable ( false ) ; return _ . include ( [ \":\" , \"/\" ] , input . charAt ( 0 ) ) ; switch ( cmd . toLowerCase ( ) ) { case \"help\" : this . helpOpen ( ! this . helpOpen ( ) ) ; break ;", "del_tokens": "$inputBox . focus ( ) ; return _ . include ( [ \":\" , \"/\" ] , input . charAt ( 0 ) ) switch ( cmd ) {", "commit_type": "add"}
{"commit_tokens": ["use", "cryptographically", "secure", "random", "function"], "add_tokens": "var mathRandom = require ( 'math-random' ) ; module . exports . isCrypto = ! ! mathRandom . cryptographic ; res += mask . charAt ( parseInt ( mathRandom ( ) * mask . length , 10 ) ) ;", "del_tokens": "res += mask . charAt ( parseInt ( Math . random ( ) * mask . length , 10 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "pluralisation", "of", "collection", "names"], "add_tokens": "const pluralize = require ( 'pluralize' ) return pluralize ( name . replace ( / [^a-z0-9] / g , '' ) , 1 )", "del_tokens": "return name . replace ( / [^a-z0-9] / g , '' )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "issues", "that", "came", "up", "in", "review"], "add_tokens": "this . highlighted_ = highlighted ; this . showLineNumbers_ = showLineNumbers ; var showLineNumbers , highlighted ; if ( writer . currentLine_ . length > 0 ) { __proto__ : ParseTreeVisitor . prototype , if ( tree != null && tree == this . highlighted_ ) { if ( tree != null && tree . location != null && tree . location . start != null && this . showLineNumbers_ ) { if ( tree != null && tree == this . highlighted_ ) { while ( this . currentLine_ . length < 80 ) { if ( this . currentLine_ . length == 0 ) {", "del_tokens": "this . HIGHLIGHTED = highlighted ; this . SHOW_LINE_NUMBERS = showLineNumbers ; if ( writer . currentLine_ . length ( ) > 0 ) { __proto__ : ParseTreeVisitor , if ( tree != null && tree == this . HIGHLIGHTED ) { if ( tree != null && tree . location != null && tree . location . start != null && this . SHOW_LINE_NUMBERS ) { if ( tree != null && tree == this . HIGHLIGHTED ) { while ( this . currentLine_ . length ( ) < 80 ) { if ( this . currentLine_ . length ( ) == 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "index", ".", "md", "files", "as", "index", "pages"], "add_tokens": "const indexRE = / \\b(index|readme)\\.md$ / i", "del_tokens": "const indexRE = / \\breadme\\.md$ / i", "commit_type": "allow"}
{"commit_tokens": ["Use", "input", "nodes", "and", "edges", "for", "attributes"], "add_tokens": "function initOrder ( g , nodeMap ) { var rank = nodeMap [ u ] . rank ; if ( nodeMap [ u ] . rank === 0 ) { return function ( g , orderIters , nodeMap , dummyMap ) { var allMap = { } ; mergeAttributes ( nodeMap , allMap ) ; mergeAttributes ( dummyMap , allMap ) ; var layering = initOrder ( g , allMap ) ;", "del_tokens": "function initOrder ( g , ranks ) { var rank = ranks [ u ] ; if ( ranks [ u ] === 0 ) { return function ( g , orderIters , ranks ) { var layering = initOrder ( g , ranks ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "bobtail", "-", "dev", "/", "bobtail", "-", "rx", "/", "issues", "/", "13"], "add_tokens": "function mkSetQueue ( elems ) { let ret = new Set ( elems ) ; ret . pop = ( ) => { const first = ret . keys ( ) . next ( ) . value ; ret . delete ( first ) ; return first ; } ; ret . extend = ( elems ) => { for ( let e of elems ) { ret . add ( e ) ; } } ; return ret ; } let cur ; let cells = mkSetQueue ( allDownstream ( ... Array . from ( downstreamCells ) || [ ] ) ) ; this . _shield = true ; while ( cells . size ) { try { cur = cells . pop ( ) ; cur . refresh ( ) ; cells . extend ( cur . onSet . downstreamCells ) ; } finally { cur . _shield = false ; } this . _shield = false ;", "del_tokens": "this . _shield = true ; let cells = allDownstream ( ... Array . from ( downstreamCells ) || [ ] ) ; try { return cells . forEach ( c => c . refresh ( ) ) ; } finally { cells . forEach ( c => c . _shield = false ) ; this . _shield = false ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "touch", "timer", "interval", "to", "be", "in", "seconds"], "add_tokens": "} , ( ttl / 3 ) * 1000 ) ;", "del_tokens": "} , ttl / 3 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "in", "minifyMapping", "and", "add", "tests"], "add_tokens": "if ( newMapping . fromScheme ) { newMapping . fromScheme = _ . pick ( newMapping . fromScheme , [ \"uri\" , \"notation\" ] ) } if ( newMapping . toScheme ) { newMapping . toScheme = _ . pick ( newMapping . toScheme , [ \"uri\" , \"notation\" ] ) }", "del_tokens": "newMapping . fromScheme = _ . pick ( newMapping . fromScheme , [ \"uri\" , \"notation\" ] ) newMapping . toScheme = _ . pick ( newMapping . toScheme , [ \"uri\" , \"notation\" ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "flat", "properties", "in", "Key", "transform", "."], "add_tokens": "* @ param { boolean } params . flat - A boolean flag indicating if the field names * should be treated as flat property names , side - stepping nested field * lookups normally indicated by dot or bracket notation . return ( this . value && ! _ . modified ( ) ) ? this . value : key ( _ . fields , _ . flat ) ;", "del_tokens": "return ( this . value && ! _ . modified ( ) ) ? this . value : key ( _ . fields ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "options", ".", "page"], "add_tokens": "all : [ 'example/test/**/!(test2|testBail|testPage).html' ] , } , // Test page options testPage : { src : [ 'example/test/testPage.html' ] , options : { page : { settings : { userAgent : 'grunt-mocha-agent' } } } grunt . task . registerTask ( 'testPage' , [ 'mocha:testPage' ] ) ; 'testPage' , 'testBail' ,", "del_tokens": "all : [ 'example/test/**/!(test2|testBail).html' ] , 'testBail'", "commit_type": "add"}
{"commit_tokens": ["Fixing", "broken", "flattenDeps", "and", "adding", "error", "for", "nested", "evaluations"], "add_tokens": "var isEvaluating = false ; if ( isEvaluating === true ) { isEvaluating = false throw new Error ( \"Evaluate may not be called within a Getters computeFn\" ) } isEvaluating = true var returnValue = getter . computeFn . apply ( null , values ) isEvaluating = false return returnValue", "del_tokens": "return getter . computeFn . apply ( null , values )", "commit_type": "fix"}
{"commit_tokens": ["fix", "formdata", "support", "when", "you", "are", "trying", "to", "wrap", "the", "request"], "add_tokens": "// don't allow cloning a used body // check that body is a stream and not form-data object // note: we can't clone the form-data object without having it as a dependency if ( bodyStream ( body ) && typeof body . getBoundary !== 'function' ) {", "del_tokens": "if ( bodyStream ( body ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "ES2015", "+", "strict", "mode"], "add_tokens": "'use strict' const npmWhich = require ( 'npm-which' ) ( process . cwd ( ) ) const binPath = 'npm' const args = [ 'run' , '-s' , binName , '--' ] . concat ( paths )", "del_tokens": "var npmWhich = require ( 'npm-which' ) ( process . cwd ( ) ) var binPath = 'npm' var args = [ 'run' , '-s' , binName , '--' ] . concat ( paths )", "commit_type": "use"}
{"commit_tokens": ["Use", "flexible", "peerDeps", "and", "update", "example", "to", "use", "jest", "-", "webpack", "as", "an", "installed", "package"], "add_tokens": "var JestWebpackPlugin = require ( 'jest-webpack/Plugin' ) ; loader : 'jest-webpack/ManualMockLoader'", "del_tokens": "var JestWebpackPlugin = require ( '../Plugin' ) ; resolveLoader : { alias : { 'manual-mock' : path . join ( __dirname , '../ManualMockLoader.js' ) } } , loader : 'manual-mock'", "commit_type": "use"}
{"commit_tokens": ["Fix", "trace", ".", "Annotation", ".", "string", "and", "added", "a", "test", "for", "it", ".", "It", "is", "not", "a", "timestamp"], "add_tokens": "Annotation . string = function ( name , value ) { return new Annotation ( name , value , 'string' ) ;", "del_tokens": "Annotation . string = function ( timestamp ) { return Annotation . timestamp ( zipkinCore_types . SERVER_RECV , timestamp ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "options", "to", "fetch", "callback", "so", "the", "TTLs", "can", "be", "set", "from", "inside", "the", "fetch", "()", "callable", "."], "add_tokens": "* Fetches a key from the data provider , the via the provided fetch callable when this object was created . * this . fetcher ( key , function ( err , value , fetcherOptions ) { if ( fetcherOptions ) { var staleTtl = fetcherOptions . staleTtl , expiresTtl = fetcherOptions . expiresTtl ; if ( staleTtl !== undefined ) { options . staleTtl = staleTtl ; } if ( expiresTtl !== undefined ) { options . expiresTtl = expiresTtl ; } }", "del_tokens": "* Fetches a key from the data provider this . fetcher ( key , function ( err , value ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "Windows", "bug", "in", "new", "react", "-", "native", "link", "script", ".", "Android", "scheduler", "bug", ".", "When", "app", "is", "terminated", "&", "restarted", "during", "a", "scheduled", "ON", "period", "tracking", "-", "service", "does", "not", "restart", "."], "add_tokens": "const moduleName = ( process . platform === 'win32' ) ? moduleDirectory . split ( '\\\\' ) . pop ( ) : moduleDirectory . split ( '/' ) . pop ( ) ;", "del_tokens": "const moduleName = moduleDirectory . split ( '/' ) . pop ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "mock", "test", "for", "auth", "header"], "add_tokens": "if ( username ) { baseOptions . headers . Authorization = typeof username === \"object\" ? authTools . generateTokenAuthHeader ( username ) : authTools . generateBasicAuthHeader ( username , password ) ;", "del_tokens": "if ( username && username . length > 0 ) { baseOptions . headers . Authorization = authTools . generateBasicAuthHeader ( username , password ) ; } if ( username && username . token_type ) { baseOptions . headers . Authorization = authTools . generateTokenAuthHeader ( username ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "maybe", "generators", "for", "taking", "first", "last", "find", "and", "elementAt", "from", "iterable", "into", "a", "maybe"], "add_tokens": "const MaybeGenerators = require ( \"./maybe/generators\" ) ; const _Maybe = require ( \"./maybe\" ) ; const Maybe = Object . assign ( { } , _Maybe , MaybeGenerators ) ; exports . Maybe = Maybe ;", "del_tokens": "const Maybe = require ( \"./maybe\" ) ; exports . Maybe = Maybe ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "some", "options", "input", "types", "."], "add_tokens": "item ( chalk . yellow ( \"WARNING: \" + o ) , useBullet ) ;", "del_tokens": "item ( chalk . yellow ( o ) , useBullet ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "error", "passing", "options", "to", "browser", "websocket", "constructor"], "add_tokens": "var opts = ( process . title === 'browser' ) ? this . options . protocol : this . options this . ws = new WebSocketPoly ( server , opts )", "del_tokens": "this . ws = new WebSocketPoly ( server , this . options )", "commit_type": "fix"}
{"commit_tokens": ["added", "path", "check", "for", "windows"], "add_tokens": "// Windows path adjustment if ( process . platform === 'win32' ) { preset = preset . replace ( / \\\\ / g , \"\\\\\\\\\" ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "effects", "part", "of", "the", "core"], "add_tokens": "module . exports = require ( './src/core/effects' )", "del_tokens": "module . exports = require ( 'hooter/effects' )", "commit_type": "make"}
{"commit_tokens": ["added", "assurance", "for", "userTenant", ".", "pin"], "add_tokens": "if ( userTenant && userTenant . pin && userTenant . pin . allowed )", "del_tokens": "if ( userTenant . pin && userTenant . pin . allowed )", "commit_type": "add"}
{"commit_tokens": ["fix", "use", "of", "deprecated", "Buffer"], "add_tokens": "this . secretBuffer = Buffer . alloc ( this . secret . length , this . secret , this . ENC ) ;", "del_tokens": "this . secretBuffer = new Buffer ( this . secret , this . ENC ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "marker", "events", "from", "callbacks", "to", "rootScope", "broadcasts"], "add_tokens": "// Set up marker event broadcasting var markerEvents = [ 'click' , 'dblclick' , 'mousedown' , 'mouseover' , 'mouseout' , 'contextmenu' , 'dragstart' , 'drag' , 'dragend' , 'move' , 'remove' , 'popupopen' , 'popupclose' ] ; for ( var i = 0 ; i < markerEvents . length ; i ++ ) { var eventName = markerEvents [ i ] ; marker . on ( eventName , function ( e ) { var broadcastName = 'leafletDirectiveMarker.' + this . eventName ; $rootScope . $apply ( function ( ) { $rootScope . $broadcast ( broadcastName , { markerName : scope_watch_name . replace ( 'markers.' , '' ) , leafletEvent : e } ) ; } ) ; } , { eventName : eventName , scope_watch_name : scope_watch_name } ) ;", "del_tokens": "// Set up marker events // Pass original marker name with the event data for easier reference var eventData = { name : scope_watch_name . replace ( 'markers.' , '' ) } ; if ( typeof ( marker_data . events ) == 'object' ) { for ( var bind_to in marker_data . events ) { marker . on ( bind_to , marker_data . events [ bind_to ] , eventData ) ; }", "commit_type": "change"}
{"commit_tokens": ["adding", "preDrop", "before", "tables", "drops", "and", "postBuild", "after", "tables", "sync"], "add_tokens": "var _ = require ( 'lodash' ) ; * Drop schemas tables . If it exists , it calls ` ` beforehand var knex = this . knex ; return Promise . map ( schemas || [ ] , function ( schema ) { return ( schema . preDrop || _ . noop ) ( knex ) ; } ) . then ( function ( ) { // Reduce force sequential execution. return Promise . reduce ( resolver . resolve ( ) . reverse ( ) , dropSchema . bind ( this ) , [ ] ) ; } . bind ( this ) ) ;", "del_tokens": "* Drop schemas tables . // Reduce force sequential execution. return Promise . reduce ( resolver . resolve ( ) . reverse ( ) , dropSchema . bind ( this ) , [ ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "exclusive", "flag", "make", "logging", "example", "match", "README", "."], "add_tokens": "if ( opts [ key ] === undefined ) {", "del_tokens": "if ( ! opts [ key ] ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "exception", "not", "printed", "when", "debugging"], "add_tokens": "// Ensure error is printed synchronously and not truncated if ( process . stderr . _handle && process . stderr . _handle . setBlocking ) { process . stderr . _handle . setBlocking ( true ) ; } console . error ( ) ; console . error ( source ) ; console . error ( error . stack ) ;", "del_tokens": "fs . writeSync ( 2 , \"\\n\" + source + \"\\n\" ) ; fs . writeSync ( 2 , error . stack + \"\\n\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "pixelRatio", "considerations", "for", "multi", "-", "res"], "add_tokens": "var devicePixelRatio = window . devicePixelRatio || 1 ; var lastAllowedImage = 0 ; var testWidth ; for ( var j = 0 , image ; j < imageSizes . length ; j ++ ) { image = imageSizes [ j ] ; if ( typeof image === 'string' ) { image = imageSizes [ j ] = { url : image } ; } if ( image . pixelRatio && image . pixelRatio != devicePixelRatio ) { // We disallowed choosing this image for current device pixel ratio, // So skip this one. continue ; } // Mark this one as the last one we investigated // which does not violate device pixel ratio rules. // We may choose this one later if there's no match. lastAllowedImage = j ; // For most images, we match the specified width against element width, // And enforcing a limit depending on the \"pixelRatio\" property if specified. // But if a pixelRatio=\"auto\", then we consider the width as the physical width of the image, // And match it while considering the device's pixel ratio. testWidth = containerWidth ; if ( image . pixelRatio === 'auto' ) { containerWidth *= devicePixelRatio ; if ( image . width >= testWidth ) { return imageSizes [ Math . min ( j , lastAllowedImage ) ] ;", "del_tokens": "for ( var j = 0 ; j < imageSizes . length ; j ++ ) { if ( typeof imageSizes [ j ] === 'string' ) { imageSizes [ j ] = { url : imageSizes [ j ] } ; if ( imageSizes [ j ] . width > containerWidth ) { return imageSizes [ j - 1 ] ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "integration", "tests", "with", "new", "log", "text"], "add_tokens": "logData . should . include ( 'Markdown passed linting' ) ; logData . should . include ( 'Markdown passed linting' ) ; logData . should . include ( 'Markdown passed linting' ) ;", "del_tokens": "logData . should . include ( 'Markdown passed linting.' ) ; logData . should . include ( 'Markdown passed linting.' ) ; logData . should . include ( 'Markdown passed linting.' ) ;", "commit_type": "update"}
{"commit_tokens": ["moved", "libraries", "to", "resources", "to", "that", "they", "can", "be", "shared", "with", "packages", "consuming", "this", "one", "."], "add_tokens": "const testdata = path . join ( __dirname , '..' , 'resources' , 'libraries' ) ;", "del_tokens": "const testdata = path . join ( __dirname , 'data' ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "ability", "to", "publish", "to", "npm"], "add_tokens": "gutil . log ( 'Published' , '\\'' + chalk . magenta ( version ) + '\\'' , 'to \\'' + chalk . cyan ( 'github' ) + '\\'' ) ; / ** * Publish the current codebase to npm . * * @ return { Bluebird promise } - Resolves or rejects ( with nothing ) based on the status of the ` ` commands . * / function publishToNpm ( ) { return new Promise ( function ( resolve , reject ) { spork ( 'npm' , [ 'publish' ] , { exit : false , quiet : true } ) . on ( 'exit:code' , function ( code ) { if ( code === 0 ) { if ( ! options . quiet ) { gutil . log ( 'Published to \\'' + chalk . cyan ( 'npm' ) + '\\'' ) ; } resolve ( ) ; } else { reject ( 'failed to publish to npm' ) ; } } ) ; } ) ;", "del_tokens": "logPublished ( version , 'github' ) ; function publishToNpm ( version ) { console . log ( chalk . bold . yellow ( '[WARN]:' ) , 'npm not yet supported. skipping.' ) ; //logPublished(version, 'npm'); return Promise . resolve ( 'Skipped' ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "name", "to", "gladius", "-", "forge", "."], "add_tokens": "gladius = require ( 'gladius-forge' ) , gladius . config ( gulp , { gladius . setupTasks ( { var $ = gladius . getPlugins ( ) ; gladius . setupWatchers ( function ( gulp ) { gladius . setupMain ( {", "del_tokens": "gulpBoilerplate = require ( 'es6-gulp-boilerplate' ) , gulpBoilerplate . config ( gulp , { gulpBoilerplate . setupTasks ( { var $ = gulpBoilerplate . getPlugins ( ) ; gulpBoilerplate . setupWatchers ( function ( gulp ) { gulpBoilerplate . setupMain ( {", "commit_type": "change"}
{"commit_tokens": ["Change", "input", "text", "when", "keying", "through", "menu", "items"], "add_tokens": "const { activeIndex , selected , text } = this . state ; activeIndex = { activeIndex }", "del_tokens": "const { selected , text } = this . state ;", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "TypeError", "when", "none", "of", "the", "unmarshaling", "commands", "can", "handle", "the"], "add_tokens": "throw new TypeError ( 'Marshaling error: encountered ' + ( ( item ) ? ( 'unexpected item ' + item ) : 'empty value' ) ) ; if ( _ . isUndefined ( unmarshaledItem ) ) { throw new TypeError ( 'Unmarshal error: encountered unexpected item ' + item ) ; }", "del_tokens": "throw new TypeError ( 'Marshaling error: encountered ' + ( ( item ) ? ( 'unexpected type ' + item ) : 'empty value' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "setMaxPage", "issue", "leading", "to", "test", "failure"], "add_tokens": "var maxPage = this . getMaxPage ( results ) ;", "del_tokens": "var totalResults ; var maxPage = this . getMaxPage ( ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "dependency", "checkr", "after", "consumer", "creation"], "add_tokens": "async init ( configuration ) { await this . _producer . init ( configuration , logger ) await this . _chosenConsumer . init ( configuration , logger ) ; await this . _dependencyChecker . init ( chosenConsumer , configuration , logger ) ;", "del_tokens": "init ( configuration ) { this . _dependencyChecker . init ( chosenConsumer , configuration , logger ) ; return this . _producer . init ( configuration , logger ) . then ( ( ) => { return this . _chosenConsumer . init ( configuration , logger ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Esperanto", "s", "absolutePaths", "option", "to", "remove", "rewrite", "relative", "imports", "."], "add_tokens": "define ( 'inner/first' , [ 'exports' , 'something' ] , function ( exports , Something ) {", "del_tokens": "define ( 'inner/first' , [ 'exports' , '../something' ] , function ( exports , Something ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "shift", "+", "click", "deletion"], "add_tokens": "cornerstone . updateImage ( eventData . element ) ;", "del_tokens": "cornerstone . updateImage ( element ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "registration", "server", "crash", "."], "add_tokens": "return res . serverError ( err ) ;", "del_tokens": "res . serverError ( err ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "null", "settlement"], "add_tokens": "* A class for creating a _hubii nahmii_ DriipSettlement , which is used for settlement with driip . throw new Error ( 'Current challenge proposal has not expired yet!' ) ; throw new Error ( 'Current challenge proposal is disqualified!' ) ; throw new Error ( 'The settlement can not be replayed!' ) ;", "del_tokens": "* A class for creating a _hubii nahmii_ DriipSettlement , which is used for settlement or challenge related operations . throw new Error ( 'Current challenge is not expired yet!' ) ; throw new Error ( 'Current challenge status is in disqualified, can not settle the driip!' ) ; throw new Error ( 'The settlement is already done before, not allowed to be settled more than once!' ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "is2", "/", "is3", "convenience", "methods", "to", "determine", "if", "an", "input", "is", "a", "known", "ISO", "2", "or", "3", "code", "instead", "of", "having", "to", "interrogate", "return", "value", "of", "list", "()"], "add_tokens": "/ ** * Return true if input is a known ISO 3166 - 1 alpha - 2 code , false otherwise * * @ param { String } alpha2 * @ return { Boolean } * / var is2 = function is2 ( code ) { return ISOCodes . some ( function ( row ) { return row . alpha2 === code } ) } / ** * Return true if input is a known ISO 3166 - 1 alpha - 3 code , false otherwise * * @ param { String } alpha3 * @ return { Boolean } * / var is3 = function is3 ( code ) { return ISOCodes . some ( function ( row ) { return row . alpha3 === code } ) } list : list , is2 : is2 , is3 : is3", "del_tokens": "list : list", "commit_type": "add"}
{"commit_tokens": ["fixed", "Column", "Width", "function", "."], "add_tokens": "thisCol . setWidth ( w ) ; column . prototype . setWidth = setWidth ; function setWidth ( w ) { this . width = w ; this . customWidth = 1 ; }", "del_tokens": "this . width = w ; this . customWidth = 1 ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "list", "param", "-", "list", "-", "format", "to", "render", "nested", "properties", "(", "options", ".", "one", ".", "two", "etc", ")", "to", "the", "correct", "depth"], "add_tokens": "description : \"", "del_tokens": "description : \"list, table\"", "commit_type": "update"}
{"commit_tokens": ["used", "hex", "chars", "rather", "than", "octals"], "add_tokens": "ERROR = \"\\x1B[1;31mERROR\\x1B[0m\" , FAILURE = \"\\x1B[0;31mFAILURE\\x1B[0m\" , OK = \"\\x1B[0;32mOK\\x1B[0m\" ,", "del_tokens": "ERROR = \"\\033[1;31mERROR\\033[0m\" , FAILURE = \"\\033[0;31mFAILURE\\033[0m\" , OK = \"\\033[0;32mOK\\033[0m\" ,", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "optional", "image", "file", "size", "limit", "restriction", "on", "inlineImages", "option"], "add_tokens": "// If inlineImages is not an object but evaluates to true // create object with default options if ( options . inlineImages && typeof options . inlineImages !== 'object' ) { options . inlineImages = { options : { limit : 0 } } ; } // Read the file in and convert it if its an image // If a size limit given skip if file larger than limit if ( options . inlineImages . options . limit > 0 ) { var stat = fs . statSync ( localImagePath ) ; if ( stat . size > options . inlineImages . options . limit ) { continue ; } }", "del_tokens": "// Read the file in and convert it if its an image", "commit_type": "add"}
{"commit_tokens": ["Remove", "docs", "fix", "mapItems", "bug", "when", "data", "is", "null"], "add_tokens": "if ( data instanceof Array ) { return data . map ( function ( item ) { return fn ( item ) ; } ) ; } return data === null ? null : fn ( data ) ;", "del_tokens": "return data instanceof Array ? data . map ( function ( item ) { return fn ( item ) ; } ) : fn ( data ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "settings", "module", "instead", "of", "harcoded", "version"], "add_tokens": "var settings = require ( './settings' ) ; var DATABASE = settings . get ( 'DATABASE' ) ; var sequelize = exports . sequelize = new Sequelize ( DATABASE [ 'NAME' ] , DATABASE [ 'USER' ] , DATABASE [ 'PASSWORD' ] , { host : DATABASE [ 'HOST' ] , port : DATABASE [ 'PORT' ] , dialect : DATABASE [ 'ENGINE' ] , storage : DATABASE [ 'NAME' ] ,", "del_tokens": "var settings = require ( process . env [ 'CAPTAINJS_SETTINGS' ] || process . cwd ( ) + '/settings.js' ) ; var sequelize = exports . sequelize = new Sequelize ( settings . DATABASE [ 'NAME' ] , settings . DATABASE [ 'USER' ] , settings . DATABASE [ 'PASSWORD' ] , { host : settings . DATABASE [ 'HOST' ] , port : settings . DATABASE [ 'PORT' ] , dialect : settings . DATABASE [ 'ENGINE' ] , storage : settings . DATABASE [ 'NAME' ] ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "preventing", "more", "than", "32", "implementations", "being", "added", "to", "a", "morphic", "method"], "add_tokens": "// eliminate this - // make a negative bitset first, then unset the bits with xor, that way // we're not falling into the issue where we're \"and\"ing with different // sized bitsets var cantBeBitSet = new bitset ( ) . setRange ( 0 , this . calls . length ) . xor ( this . stackHits [ question ] ) ; currentGuess = currentGuess . and ( cantBeBitSet ) ;", "del_tokens": "// eliminate this currentGuess = currentGuess . and ( this . stackHits [ question ] . clone ( ) . not ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "eval", "from", "option", "parser"], "add_tokens": "/* global ngMap */ /* global google */ scope . google = google ; var options = parser . getOptions ( filtered , scope ) ; var infoWindow = new google . maps . InfoWindow ( options ) ; if ( eventName ) { google . maps . event . addListener ( infoWindow , eventName , events [ eventName ] ) ; } var matches = contents . match ( / \\[\\[[^\\]]+\\]\\] / g ) ; } ; // return", "del_tokens": "var options = parser . getOptions ( filtered ) ; infoWindow = new google . maps . InfoWindow ( options ) ; google . maps . event . addListener ( infoWindow , eventName , events [ eventname ] ) ; var matches = contents . match ( / \\[\\[[^\\]]+\\]\\] / g ) } // return", "commit_type": "remove"}
{"commit_tokens": ["updated", "to", "support", "windows", "versions"], "add_tokens": "var version ; // Supports two different version outputs: `Meteor x.x.x.x` or // `WINDOWS-PREVIEW@x.x.x.x`. Split on the correct char and trim any // extra whitespace. if ( versionText . indexOf ( '@' ) >= 0 ) { version = versionText . split ( '@' ) [ 1 ] . trim ( ) ; } else { version = versionText . split ( ' ' ) [ 1 ] . trim ( ) ; } context . isWindows = versionText . toLowerCase ( ) . indexOf ( 'windows' ) >= 0 ; // Default to `meteor` if running on Windows. && fs . existsSync ( smartJsonPath ) && ! context . isWindows ) {", "del_tokens": "// Split on space and take the second element because the version output is // `Meteor x.x.x.x`. var version = versionText . split ( ' ' ) [ 1 ] . trim ( ) ; && fs . existsSync ( smartJsonPath ) ) {", "commit_type": "update"}
{"commit_tokens": ["Implement", "math", "metamethods", "and", "fix", "rawget", "/", "rawset"], "add_tokens": "tab [ newKey = key + 1 ] !== undefined ) { tonumber : function ( val , base ) { return [ runtime . tonumber ( val , base ) ] ; } , tostring : function ( val ) { return [ runtime . tostring ( val ) ] ; } ,", "del_tokens": "tab . hasOwnProperty ( newKey = key + 1 ) ) { tonumber : function ( ) { throw new Error ( \"TODO: Implement tonumber\" ) ; } , tostring : function ( ) { throw new Error ( \"TODO: Implement tostring\" ) ; } ,", "commit_type": "implement"}
{"commit_tokens": ["Updated", "writeMany", "(", "string", ")"], "add_tokens": "var dataOffset = 0 ; aValues . writeDoubleLE ( values [ i ] , dataOffset ) ; dataOffset += ARCH_DOUBLE_NUM_BYTES ; var dataOffset = 0 ; aValues . writeDoubleLE ( values [ i ] , dataOffset ) ; dataOffset += ARCH_DOUBLE_NUM_BYTES ; var offsetP = 0 ; ref . writePointer ( aNames , offsetP , buf ) ; offsetP += ARCH_POINTER_SIZE ; var offsetP = 0 ; ref . writePointer ( aNames , offsetP , buf ) ; offsetP += ARCH_POINTER_SIZE ;", "del_tokens": "aValues . writeDoubleLE ( values [ i ] , offset ) ; aValues . writeDoubleLE ( values [ i ] , offset ) ; ref . writePointer ( aNames , offsetD , buf ) ; offsetD += ARCH_POINTER_SIZE ; ref . writePointer ( aNames , offsetD , buf ) ; offsetD += ARCH_POINTER_SIZE ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "bug", "when", "passing", "undefined", "as", "optional", "callback"], "add_tokens": "if ( len > 0 && ! Array . isArray ( args [ len - 1 ] ) ) {", "del_tokens": "if ( len > 0 && typeof args [ len - 1 ] === 'function' ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "command", "-", "line", "interface", "for", "one", "-", "off", "builds"], "add_tokens": "} , function ( ) { generator . regenerate ( ) } ) if ( ! generator . outputTmpDir ) { throw new Error ( 'Expected generator.outputTmpDir to be set' ) return generator . outputTmpDir", "del_tokens": "} , generator . regenerate . bind ( generator ) ) if ( ! generator . outputDir ) { throw new Error ( 'Expected generator.outputDir to be set' ) return generator . outputDir", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "prefix", "in", "xmi", "serialization", "."], "add_tokens": "function processElement ( root ) { if ( value !== undefined && value !== 'false' ) { isAbstract = feature . get ( 'eType' ) . get ( 'abstract' ) , prefix ; prefix = ref . eClass . eContainer . get ( 'nsPrefix' ) ; docRoot += ' xsi:type=\"' + ( prefix ? prefix + ':' : '' ) + ref . eClass . get ( 'name' ) + '\"' ;", "del_tokens": "// ------- function processElement ( root ) { if ( value !== false && value !== 'false' ) { isAbstract = feature . get ( 'eType' ) . get ( 'abstract' ) ; docRoot += ' xsi:type=\"' + ref . eClass . get ( 'name' ) + '\"' ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "automatically", "commit", "bump", "to", "master"], "add_tokens": ". version ( '1.0.4' ) . option ( '-c, --commit' , 'commit the version bump and push it to master' ) . option ( '-q, --quiet' , 'output nothing (suppress STDOUT and STDERR)' ) publish ( program . args [ 0 ] , { dest : program . dest , commit : program . commit , quiet : program . quiet } )", "del_tokens": ". version ( '1.0.0' ) . option ( '-q, --quiet' , 'output nothing (suppress STDOUT and STDERR)' ) publish ( program . args [ 0 ] , { dest : program . dest , quiet : program . quiet } )", "commit_type": "add"}
{"commit_tokens": ["Change", "fs", ".", "mkdir", "to", "fs", ".", "mkdirSync"], "add_tokens": "fs . mkdirSync ( linuxPath ) ;", "del_tokens": "fs . mkdir ( linuxPath ) ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "grunt", "files", "-", "update", "doc"], "add_tokens": "* Copyright ( c ) 2013 Markus Lima", "del_tokens": "* Copyright ( c ) 2012 Markus Lima // Add event click propagation to the file input for Mozilla only if ( $ . browser . mozilla ) { $this . parent ( ) . children ( 'label[for=' + name + ']' ) . click ( function ( ) { $this . click ( ) ; } ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "tests", "for", "asset", "resolver"], "add_tokens": ". then ( assets => { expect ( assets ) . to . be . an ( 'object' ) ; expect ( assets ) . to . eql ( data . results [ 0 ] ) ; it ( 'creates a map of resolved theme assets' , ( ) => { . then ( assets => { expect ( assets ) . to . be . an ( 'object' ) ; expect ( assets ) . to . eql ( data . results [ 1 ] ) ; } ) ; } ) ; it ( 'omits missing files from listing' , ( ) => { return resolver . resolveThemedAssets ( data . artifacts [ 0 ] , data . themes [ 1 ] , data . assets ) . then ( assets => { expect ( assets ) . to . be . an ( 'object' ) ; expect ( assets ) . to . eql ( data . results [ 2 ] ) ;", "del_tokens": ". then ( artifacts => { expect ( artifacts ) . to . be . an ( 'object' ) ; it ( 'creates a map of resolved assets' , ( ) => { . then ( artifacts => { expect ( artifacts ) . to . be . an ( 'object' ) ;", "commit_type": "add"}
{"commit_tokens": ["Created", "a", "new", "test", "schema", "to", "test", "references", "to", "hashes", "within", "a", "file"], "add_tokens": "var schema = jsonSchemaLib . readSync ( path . rel ( 'schemas/external-refs-multiple/vehicle.json' ) ) ; instance . readSync ( path . rel ( 'schemas/external-refs-single/person.json' ) ) ; expect ( callCounter ) . to . equal ( 6 ) ;", "del_tokens": "var schema = jsonSchemaLib . readSync ( path . rel ( 'schemas/external-refs-simple/vehicle.json' ) ) ; instance . readSync ( path . rel ( 'schemas/external-refs-simple/vehicle.json' ) ) ; expect ( callCounter ) . to . equal ( 24 ) ;", "commit_type": "create"}
{"commit_tokens": ["Change", "to", "export", "mesh", "-", "buffer", ".", "js", "createVoxelMesh", "()"], "add_tokens": "var createAOMesh = require ( \"./mesh.js\" )", "del_tokens": "var createAOMesh = require ( \"voxel-mesher\" )", "commit_type": "change"}
{"commit_tokens": ["Updated", "readme", "with", "error", "handling", "instructions", "."], "add_tokens": "* myPoller . promise . then ( null , null , callback ) ; * myPoller . promise . then ( null , null , callback ) ;", "del_tokens": "* myPoller . promise . then ( successCallback , errorCallback , notifyCallback ) ; * myPoller . promise . then ( successCallback , errorCallback , notifyCallback ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "exit", "vs", ".", "close", "error", "in", "help", ".", "t", ".", "js", "."], "add_tokens": "help . on ( ( / ^v0.(\\d+) / . exec ( process . version ) || [ ] ) [ 1 ] < 8 ? 'exit' : 'close' , function ( code ) {", "del_tokens": "help . on ( 'close' , function ( code ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "dash", "for", "--", "config", "option"], "add_tokens": "case '--config' :", "del_tokens": "case '-config' :", "commit_type": "add"}
{"commit_tokens": ["Improved", "test", "for", "whether", "something", "is", "a", "promise", "."], "add_tokens": "this . addType ( function ( v ) { return v && typeof v . then == 'function' && Promise . resolve ( v ) == v ; } , PromiseSubject ) ;", "del_tokens": "this . addType ( function ( v ) { return v instanceof Promise ; } , PromiseSubject ) ;", "commit_type": "improve"}
{"commit_tokens": ["add", ".", "handler", "and", ".", "handlers", "un", "-", "nest", "code"], "add_tokens": "it ( 'should not accept non-functions' , function ( ) { assert . throws ( function ( ) { } ) ; assert . throws ( function ( ) { } ) ; assert . throws ( function ( ) { } ) ; assert . throws ( function ( ) { } ) ;", "del_tokens": "it ( 'should not accept non-functions' , function ( cb ) { try { cb ( new Error ( 'expected an error' ) ) ; } catch ( err ) { assert ( / expected callback to be a function.*string / . test ( err . message ) ) ; } try { cb ( new Error ( 'expected an error' ) ) ; } catch ( err ) { assert ( / expected callback to be a function.*number / . test ( err . message ) ) ; } try { cb ( new Error ( 'expected an error' ) ) ; } catch ( err ) { assert ( / expected callback to be a function.*null / . test ( err . message ) ) ; } try { cb ( new Error ( 'expected an error' ) ) ; } catch ( err ) { assert ( / expected callback to be a function.*date / . test ( err . message ) ) ; } cb ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "undescore", "/", "camielization", "and", "indexes"], "add_tokens": "return comb . isString ( c ) ? c : this . literal ( c ) . replace ( / \\W / g , \"\" )", "del_tokens": "return comb . isString ( c ) ? c : this . literal ( c ) . replace ( / \\W / g , \"_\" )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "default", "setting", "and", "logic", "to", "allow", "a", "single", "slide", "to", "display", "in", "a", "slideshow", "."], "add_tokens": "allowOneSlide : true , //{NEW} Boolean: Whether or not to allow a slider comprised of a single slide if ( ( $slides . length === 1 && options . allowOneSlide === true ) || $slides . length === 0 ) {", "del_tokens": "if ( ( $slides . length === 1 && options . allowOneSlide !== true ) || $slides . length === 0 ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "status", "-", "code", "only", "response"], "add_tokens": "return amqp . publishAndWait ( getRoute ( ROUTE_NAME ) , message , { timeout : getTimeout ( ROUTE_NAME ) } ) . then ( reply => { if ( reply . requiresActivation ) { res . send ( 202 ) ; } else { res . statusCode = 201 ; res . meta = { jwt : reply . jwt } ; return { type : 'user' , id : reply . user . username , attributes : reply . user . metadata , } ; } } ) ;", "del_tokens": "return amqp . publishAndWait ( getRoute ( ROUTE_NAME ) , message , { timeout : getTimeout ( ROUTE_NAME ) } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "decoding", "and", "encoding", "tests", "."], "add_tokens": "// TODO: Add `decodeBuffers` option to coerce buffers into binary strings. throw new AvscError ( 'truncated buffer' ) ; throw new AvscError ( 'invalid object' ) ; if ( ! tap . isValid ( ) ) { // back on the field so that JSON serialization works as expected. // Having the second default in function has the added benefit that it body += ' if (typeof obj != \\'object\\') { return false; }\\n' ; body += ' ' ; * @ param arr { Array } The array . *", "del_tokens": "throw new Error ( 'truncated buffer' ) ; throw new Error ( 'invalid object' ) ; if ( ! tap . isValid ) { // back on the field to ensure `toJSON` will work appropriately. // Having the second default in an option has the added benefit that it // Default reader (used when the writer schema is the same). body += 'if (typeof obj != \\'object\\') { return false; }\\n' ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Shower", "2", ".", "x", "plugin"], "add_tokens": "return 'Shower 1.x' ; return typeof shower === 'object' && typeof shower . modules === 'undefined' ;", "del_tokens": "return 'Shower' ; return typeof shower === 'object' ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "accessing", "stack", "property"], "add_tokens": "this . name = 'CompositeError' ; Error . captureStackTrace ( this , this . constructor ) ; return this . originalStackDescriptor . get ? this . originalStackDescriptor . get . call ( this ) : this . originalStackDescriptor . value ;", "del_tokens": "Error . captureStackTrace ( this , this . constructor ) ; this . name = 'CompositeError' ; return this . originalStackDescriptor . get . call ( this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "streaming", "test", "fix", "serializer", "chunking", "."], "add_tokens": "_callback = callback ; _nextField ( ) ; _nextValue ( ) ; return _serialize ( buffer , 0 , buffer . length ) ;", "del_tokens": "_nextField ( ) _nextValue ( ) _outgoing = null ; _serialize ( buffer , 0 , buffer . length ) ;", "commit_type": "add"}
{"commit_tokens": ["improved", "inventory", ".", "unEquip", "tests"], "add_tokens": "describe ( 'unEqip' , function ( ) { var helmet = { slot : 'head' } ; var attributes = { equipped : { head : helmet , emptySlot : null } , inventory : [ ] } ; it ( 'removes item from given slot and pushes it to inventory' , function ( ) { } ) ; it ( 'does not changes anything when working with empty slot' , function ( ) { var inventoryLength = attributes . inventory . length ; inventory . unEquip ( attributes , 'emptySlot' ) ; assert . lengthOf ( attributes . inventory , inventoryLength ) ; assert . isNull ( attributes . equipped . emptySlot ) ; } ) ; it ( 'throws specific error with incorrect slot' , function ( ) {", "del_tokens": "describe ( 'uneqip' , function ( ) { it ( 'removes item from given slot and pushes it to inventory' , function ( ) { var helmet = { slot : 'head' } ; var attributes = { equipped : { head : helmet } , inventory : [ ] } ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "support", "for", "raw", "template", "and", "template", "caching", "updated", "tests"], "add_tokens": "// Returns a promise which gets the template, either // from the template parameter or via a request to the // template url parameter. var getTemplate = function ( template , templateUrl ) { var deferred = $q . defer ( ) ; if ( template ) { deferred . resolve ( template ) ; } else if ( templateUrl ) { $http ( { method : 'GET' , url : templateUrl , cache : true } ) . then ( function ( result ) { deferred . resolve ( result . data ) ; } ) . catch ( function ( error ) { deferred . reject ( error ) ; } ) ; } else { deferred . reject ( \"No template or templateUrl has been specified.\" ) ; } return deferred . promise ; } ; getTemplate ( options . template , options . templateUrl ) . then ( function ( template ) { var modalHtml = template ; } ) . catch ( function ( error ) { deferred . reject ( error ) ;", "del_tokens": "var templateUrl = options . templateUrl ; if ( ! templateUrl ) { deferred . reject ( \"No templateUrl has been specified.\" ) ; return deferred . promise ; } $http . get ( templateUrl ) . then ( function ( result ) { // Create the complete modal html. Wrapped in a div which is what we remove. var modalHtml = result . data ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "react", "-", "hot", "plugin", "from", "babel", "setter", "make", "dev", "-", "server", "use", "webpack", "/", "hot", "/", "only", "-", "dev", "-", "server"], "add_tokens": "loaders : [ 'babel?cacheDirectory' ]", "del_tokens": "loaders : [ 'babel?cacheDirectory&plugins[]=react-hot-loader/babel' ]", "commit_type": "remove"}
{"commit_tokens": ["Added", "fix", "for", "polymer", "issue", "1276"], "add_tokens": "const urlPattern = / url\\(.*\\) / gi ; function fixSVGIssue ( styleSheetData ) { // Workaround for polymer issue: https://github.com/Polymer/polymer/issues/1276 return styleSheetData . replace ( urlPattern , function replacer ( match ) { return match . replace ( / ' / g , '%27' ) ; } ) ; } context . parsedStylesheets . push ( fixSVGIssue ( data ) ) ;", "del_tokens": "context . parsedStylesheets . push ( data ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "noResolve", "instead", "of", "deprecated", "noExternalResolve"], "add_tokens": "noResolve : false", "del_tokens": "noExternalResolve : false", "commit_type": "use"}
{"commit_tokens": ["Use", ".", "triggerHandler", "(", "click", ")", "instead", "of", ".", "click", "()"], "add_tokens": "if ( ! rows . length ) return ; angular . element ( rows [ scope . $select . activeIdx ] ) . triggerHandler ( 'click' ) ;", "del_tokens": "if ( ! rows . length ) return ; // In case its empty if ( window . jQuery ) { // Firefox 3.6 does not support element.click() // See HTMLElement.click https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement.click $ ( rows [ scope . $select . activeIdx ] ) . click ( ) ; } else { rows [ scope . $select . activeIdx ] . click ( ) ; }", "commit_type": "use"}
{"commit_tokens": ["updated", "examples", ".", "added", "range_exists", "."], "add_tokens": "ns : argv . namespace , set : argv . set ,", "del_tokens": "ns : env . namespace , set : env . set ,", "commit_type": "update"}
{"commit_tokens": ["Fix", "missing", "headers", "in", "Windows", "8", "Proxy"], "add_tokens": "var origin = protocol + url . host . replace ( \":\" + url . port , \"\" ) ; // Windows 8 (IE10) append :80 or :443 to url.host", "del_tokens": "var origin = protocol + url . host ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "where", "the", "strict", "mode", "was", "not", "detected", "when", "a", "comment", "was", "before", "strict", "mode", ";"], "add_tokens": "var multiLineComment = / ^\\s*\\/\\*.*?\\*\\/ / ; var singleLineComment = / ^\\s*\\/\\/.*?[\\r\\n] / ; var strictMode = / ^\\s*(?:\"use strict\"|'use strict')[ \\t]*(?:[\\r\\n]|;) / ; var singleLine ; var multiLine ; while ( ( singleLine = singleLineComment . test ( src ) ) || ( multiLine = multiLineComment . test ( src ) ) ) { if ( singleLine ) { src = src . replace ( singleLineComment , \"\" ) ; } if ( multiLine ) { src = src . replace ( multiLineComment , \"\" ) ; } } return strictMode . test ( src ) ; module . exports = detectStrictMode ;", "del_tokens": "return ( / ^\\s*(?:\"use strict\"|'use strict')[ \\t]*(?:[\\r\\n]|;) / g ) . test ( src ) ; module . exports = detectStrictMode ;", "commit_type": "fix"}
{"commit_tokens": ["added", "inheritance", "Client", "Worker", "-", ">", "ServerMate"], "add_tokens": "// static logger JobServer . logger = winston . loggers . get ( 'JobServer' ) ;", "del_tokens": "// static logger if ( JobServer . logger === undefined ) { JobServer . logger = winston . loggers . get ( 'JobServer' ) ; } // static register of all job servers", "commit_type": "add"}
{"commit_tokens": ["Allow", "global", "interfaces", "setting", "."], "add_tokens": "// bind to interfaces defined in group, if not defined // bind to interfaces defined globally, if not defined // bind to all interfaces var interfacesToAssign = domainInput . interfaces || config . interfaces || [ null ] ;", "del_tokens": "var interfacesToAssign = domainInput . interfaces || [ null ] ;", "commit_type": "allow"}
{"commit_tokens": ["allow", "old", "and", "new", "F_OK", "mode"], "add_tokens": "var fsMode = ( fs . constants && fs . constants . F_OK ) || fs . F_OK ; fs . access ( outputFile , fsMode , function ( err ) {", "del_tokens": "fs . access ( outputFile , fs . constants . F_OK , function ( err ) {", "commit_type": "allow"}
{"commit_tokens": ["fix", "incorrect", "computation", "of", "starting", "day"], "add_tokens": "event . start_day = ( event . start_day + 6 ) % 7 ;", "del_tokens": "event . start_day = event . start_day - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["make", ".", "8", "and", ".", "1", "versions", "passed"], "add_tokens": "&& ! number . toString ( ) . match ( / \\. / ) ; return email . toString ( ) . match ( this . match ) ; return md5 && md5 . toString ( ) . match ( this . match ) ; return uuid && uuid . toString ( ) . match ( this . match ) ;", "del_tokens": "&& ! ` ${ number } ` . match ( / \\. / ) ; return ` ${ email } ` . match ( this . match ) ; return md5 && ` ${ md5 } ` . match ( this . match ) ; return uuid && ` ${ uuid } ` . match ( this . match ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "no", "cancel", "button", "on", "Android", "alert"], "add_tokens": "options . unshift ( { text : cancelText , onPress : ( ) => resolve ( null ) , style : 'cancel' } )", "del_tokens": "options . push ( { text : cancelText , onPress : ( ) => resolve ( null ) , style : 'cancel' } )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "Travis", "-", "CI", "support", "."], "add_tokens": "grunt . registerTask ( 'test' , [ 'jshint' , 'nodeunit' ] ) ; grunt . registerTask ( 'default' , [ 'test' ] ) ;", "del_tokens": "// Default task. grunt . registerTask ( 'default' , [ 'jshint' , 'nodeunit' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "helpful", "message", "when", "filesystem", "path", "is", "used", "in", "browser"], "add_tokens": "if ( typeof fs . readdir !== 'function' ) { throw new Error ( 'filesystem paths do not work in the browser' ) } throw new Error ( 'invalid input type' )", "del_tokens": "throw new Error ( 'invalid input type in array' )", "commit_type": "add"}
{"commit_tokens": ["use", "path", ".", "resolve", "and", "not", "path", ".", "join"], "add_tokens": "basePath : \"./node_modules\"", "del_tokens": "basePath : __dirname", "commit_type": "use"}
{"commit_tokens": ["Fix", "blending", "of", "semitransparent", "textures", "."], "add_tokens": "// The texture must be premultiplied by alpha to ensure correct blending of // semitransparent textures. For details, see: // http://www.realtimerendering.com/blog/gpus-prefer-premultiplication/ gl . pixelStorei ( gl . UNPACK_PREMULTIPLY_ALPHA_WEBGL , true ) ; gl . pixelStorei ( gl . UNPACK_PREMULTIPLY_ALPHA_WEBGL , true ) ;", "del_tokens": "// Create a new texture and paint it.", "commit_type": "fix"}
{"commit_tokens": ["fixes", "the", "build", "system", "and", "leaves", "it", "like", "this", "for", "now", "."], "add_tokens": "var pkg = require ( './package.json' ) ; var banner = [ '/**' , ' * <%= pkg.name %> - <%= pkg.description %>' , ' * @link <%= pkg.homepage %>' , ' * @license <%= pkg.license %>' , ' */' , '' ] . join ( '\\n' ) ; . pipe ( plugins . header ( banner , { pkg : pkg } ) )", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Add", "basic", "kernel", "boot", "test"], "add_tokens": "var prepareConfig = require ( '../helpers/prepare-config' ) ; var Kernel = require ( '../../lib/kernel' ) ; var config = prepareConfig ( require ( '../data/basic-config' ) ) ; new Kernel ( config , function ( err ) {", "del_tokens": "var config = require ( '../data/basic-config' ) ; var kernel = require ( '../../lib/kernel' ) ; config . test = true ; kernel . boot ( config , function ( err ) { / * it ( 'should fail to load a bad config' , function ( done ) { var config = require ( '../data/broken-config' ) ; var kernel = require ( '../../lib/kernel' ) ; config . test = true ; kernel . boot ( config , function ( err ) { assert ( err ) ; done ( ) ; } ) ; } ) ; * /", "commit_type": "add"}
{"commit_tokens": ["Used", "__dirname", "instead", "of", "process", ".", "cwd"], "add_tokens": "iconBox : fs . readFileSync ( __dirname + \"/../tmpl/icon-box.html\" , \"utf-8\" ) , html : fs . readFileSync ( __dirname + \"/../tmpl/preview.html\" , \"utf-8\" )", "del_tokens": "iconBox : fs . readFileSync ( process . cwd ( ) + \"/tmpl/icon-box.html\" , \"utf-8\" ) , html : fs . readFileSync ( process . cwd ( ) + \"/tmpl/preview.html\" , \"utf-8\" )", "commit_type": "use"}
{"commit_tokens": ["Add", "initial", "livereactload", "server", "implementation"], "add_tokens": "var plugin = require ( './lib/browserify/plugin' ) , listen = require ( './lib/server/listen' ) ;", "del_tokens": "var plugin = require ( './lib/browserify/plugin' ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "n3", "example", "with", "join", "ordering", "example"], "add_tokens": "// Format a triple pattern according to N3 API: // SPARQL variables must be replaced by `null` values function formatTriplePattern ( triple ) { let subject = null let predicate = null let object = null if ( ! triple . subject . startsWith ( '?' ) ) { subject = triple . subject } if ( ! triple . predicate . startsWith ( '?' ) ) { predicate = triple . predicate } if ( ! triple . object . startsWith ( '?' ) ) { object = triple . object } return { subject , predicate , object } } const { subject , predicate , object } = formatTriplePattern ( triple ) estimateCardinality ( triple ) { const { subject , predicate , object } = formatTriplePattern ( triple ) return Promise . resolve ( this . _store . countTriples ( subject , predicate , object ) ) }", "del_tokens": "let subject = null let predicate = null let object = null if ( ! triple . subject . startsWith ( '?' ) ) { subject = triple . subject } if ( ! triple . predicate . startsWith ( '?' ) ) { predicate = triple . predicate } if ( ! triple . object . startsWith ( '?' ) ) { object = triple . object }", "commit_type": "update"}
{"commit_tokens": ["allow", "people", "to", "name", "their", "host"], "add_tokens": "'name' : settings . d . name ,", "del_tokens": "'name' : \"David's Computer (pi)\" ,", "commit_type": "allow"}
{"commit_tokens": ["Fix", "bug", "that", "causes", "always", "overwriting", "header", "labels", "with", "the", "default", "c", "+", "i"], "add_tokens": "if ( typeof ( sniffResult . labels [ i ] ) != \"string\" ) { return transformed . length ? transformed : opts . labelFn ( i + 1 ) ;", "del_tokens": "if ( typeof ( sniffResult . labels [ i ] != \"string\" ) ) { return transformed . length ? transformed : opts . labelFn ( i + 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["change", "request", "timeout", "to", "5sec"], "add_tokens": "requestTimeout : 5 * 1000 ,", "del_tokens": "requestTimeout : 15 * 1000 ,", "commit_type": "change"}
{"commit_tokens": ["added", "resolvedProperties", "to", "treat", "property", "concats", "independently", ".", "updated", "tests", "."], "add_tokens": "schema . resolved = true ; if ( ! schema . resolvedProperties ) { resolveProperties ( schema ) ; schema . resolvedProperties = true ; }", "del_tokens": "schema . resolved = true ; logger . debug ( \"Resolved schema $refs\" , schema ) ; resolveProperties ( schema ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "unification", "tot", "the", "initialisation", "functions", "of", "headcorner"], "add_tokens": "new_fs = rule . fs . unify ( fs_with_feature_B , grammar . type_lattice ) ;", "del_tokens": "new_fs = rule . fs . unify ( that . data . fs . features [ B ] , grammar . type_lattice ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "date", "parsing", "issues"], "add_tokens": "if ( parameters [ 'VALUE' ] === 'DATE' ) return _types [ 'DATE' ] . parse ( value ) ; var utc = value . length > 15 ? value [ 15 ] === 'Z' : false ; if ( utc ) return new Date ( Date . UTC . apply ( null , d ) ) ; else return new Date ( d [ 0 ] , d [ 1 ] - 1 , d [ 2 ] , d [ 3 ] , d [ 4 ] , d [ 5 ] ) ;", "del_tokens": "return new Date ( d [ 0 ] , d [ 1 ] - 1 , d [ 2 ] , d [ 3 ] , d [ 4 ] , d [ 5 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "a", "very", "naive", "though", "handy", "CellView", ">>", "getStrokeBBox", "()", "method", "and", "use", "it", "to", "for", "source", "/", "target", "bbox", "when", "linking"], "add_tokens": "var magnetEl = this . paper . $ ( this . _makeSelector ( source ) ) [ 0 ] ; var cellView = this . paper . findView ( magnetEl ) ; this . _sourceBbox = cellView . getStrokeBBox ( source . selector ? magnetEl : undefined ) ; var magnetEl = this . paper . $ ( this . _makeSelector ( target ) ) [ 0 ] ; var cellView = this . paper . findView ( magnetEl ) ; this . _targetBbox = cellView . getStrokeBBox ( target . selector ? magnetEl : undefined ) ;", "del_tokens": "this . _sourceBbox = V ( this . paper . $ ( this . _makeSelector ( source ) ) [ 0 ] ) . bbox ( false , this . paper . viewport ) ; this . _targetBbox = V ( this . paper . $ ( this . _makeSelector ( target ) ) [ 0 ] ) . bbox ( false , this . paper . viewport ) ;", "commit_type": "implement"}
{"commit_tokens": ["Made", "failing", "test", "and", "converted", "jquery", "deffered", "to", "promises"], "add_tokens": "module . exports = connect . behavior ( \"data/url\" , function ( baseConnect ) { let res = this . url [ reqOptions . prop ] ( params ) ; return ( res instanceof Promise ) ? res : new Promise ( ( resolve , reject ) => res . then ( resolve ) . fail ( reject ) ) ;", "del_tokens": "module . exports = connect . behavior ( \"data/url\" , function ( baseConnect ) { return this . url [ reqOptions . prop ] ( params ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "problem", "with", "UTF", "-", "8", "Byte", "order", "marks"], "add_tokens": "// Remove BOM (Byte Mark Order) if ( contents . charCodeAt ( 0 ) === 65279 ) contents = contents . substring ( 1 ) ; flow . string = flow . strings . join ( '\\r\\n' ) ;", "del_tokens": "flow . string = flow . strings . join ( '\\n' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "a", "valid", "Postgres", "engine", "with", "minimal", "test", "cases", "."], "add_tokens": "MySQLEngine = require ( './MySQLEngine' ) , PostgresEngine = require ( './PostgresEngine' ) ; * @ param { String } type the database type , i . e . 'mysql' , 'postgres' . * @ param { Object } [ options ] connection options . * @ param { String } options . database the name of the database . if ( / mysql / i . test ( type ) ) { if ( / postgres / i . test ( type ) ) { engine = new PostgresEngine ( options ) ; return new Database ( engine ) ;", "del_tokens": "MySQLEngine = require ( './mysql/Engine' ) ; // type constants exports . MYSQL = 'MYSQL' ; exports . POSTGRES = 'POSTGRES' ; * @ param { String } type the database type , i . e . 'MYSQL' , 'POSTGRES' . * @ param { Object } options connection options . * @ param { String } options . database the name of the database , a . k . a . the schema . if ( type === this . MYSQL ) { if ( type === this . POSTGRES ) { throw new Error ( 'Postgres database not yet supported' ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "lint", "for", "all", "other", "packages"], "add_tokens": "expect ( node ) . toBeA ( Node ) ; }", "del_tokens": "} // eslint-disable-line", "commit_type": "fix"}
{"commit_tokens": ["Changed", "how", "errors", "are", "silenced", "."], "add_tokens": "var includeErrorCode = true ; try { if ( ! exception . initFailure . deviceHints . discovered ) { includeErrorCode = false ; } } catch ( err ) { } // if(errorCodesToReport.indexOf(exception.errorCode) >= 0) { if ( includeErrorCode ) {", "del_tokens": "if ( errorCodesToReport . indexOf ( exception . errorCode ) >= 0 ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "few", "tests", "."], "add_tokens": "var index = longReader . call ( this ) ; var reader = readers [ index ] ; if ( reader === undefined ) { throw new AvscError ( 'invalid union index: %s' , index ) ; } return reader . call ( this ) ;", "del_tokens": "return readers [ longReader . call ( this ) ] . call ( this ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "Array", ".", "isArray", "instead", "of", "instanceof", "Array"], "add_tokens": "return Array . isArray ( raw_data ) ? raw_data : [ raw_data ] ;", "del_tokens": "if ( raw_data instanceof Array ) return raw_data ; else return [ raw_data ] ;", "commit_type": "use"}
{"commit_tokens": ["added", "exec", "event", "and", "loading", "of", "routes", "for", "router"], "add_tokens": "_childrenInitialized : function ( ) { this . callBase ( ) ; for ( var c = 0 ; c < this . $configurations . length ; c ++ ) { var config = this . $configurations [ c ] ; if ( config . className == \"js.conf.Route\" ) { this . addRoute ( config . $ ) ; } } } , if ( route . onexec ) { route . fn = this . $rootScope [ route . onexec ] ; } if ( route . regex && ! ( route . regex instanceof RegExp ) ) { // build regex from string route . regex = new RegExp ( route . regex ) ; } route . fn . apply ( this . $rootScope , params ) ;", "del_tokens": "route . fn . apply ( this , params ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "to", "use", "balanced", "folder", "structure", "with", "mine", "and", "community", "at", "the", "same", "depth", "."], "add_tokens": "const mine = 'mine' ; return path . join ( this . particleFolder ( ) , libraries ) ; } communityLibrariesFolder ( ) { return path . join ( this . librariesFolder ( ) , community ) ; return path . join ( this . librariesFolder ( ) , mine ) ; return path . join ( this . particleFolder ( ) , projects ) ; } communityProjectsFolder ( ) { return path . join ( this . projectsFolder ( ) , community ) ; return path . join ( this . projectsFolder ( ) , mine ) ;", "del_tokens": "return path . join ( this . myLibrariesFolder ( ) , community ) ; return path . join ( this . particleFolder ( ) , libraries ) ; return path . join ( this . myProjectsFolder ( ) , community ) ; return path . join ( this . particleFolder ( ) , projects ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "docco", "docs", "changed", "doc", "to", "docs"], "add_tokens": "var path = require ( 'path' ) , git = require ( '../' ) ; self . repo . open ( path . normalize ( path ) , function ( ) {", "del_tokens": "var git = require ( '../' ) ; self . repo . open ( path , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "js", "-", "extensions", "build", "wtf"], "add_tokens": "var builder = require ( '@jenkins-cd/js-builder' ) ; builder . lint ( 'none' ) ;", "del_tokens": "require ( '@jenkins-cd/js-builder' ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "new", "framework", "for", "tests"], "add_tokens": "b . uuid . should . be . exactly ( a . first ( 'child' ) ) ; a . uuid . should . be . exactly ( items [ 0 ] ) ;", "del_tokens": "b . should . be . exactly ( a . first ( 'child' ) ) ; a . should . be . exactly ( items [ 0 ] ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "throw", "on", "invalid", "dep", "type", "(", "non", "string", ")", ".", "Add", "option", "to", "callback", "with", "error", "on", "invalid", "dep", "type"], "add_tokens": "ESCM : { title : \"SCM\" , list : [ ] } , EDEPTYPE : { title : \"Non-strng dependency\" , list : [ ] } ESCM : argv . errorSCM , EDEPTYPE : argv . errorDepType", "del_tokens": "ESCM : { title : \"SCM\" , list : [ ] } ESCM : argv . errorSCM", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "_events", "for", "array", "binders"], "add_tokens": "childBinder . _events = [ ] ; var removeMethodNames = [ 'pop' , 'shift' , 'splice' ] , insertMethodNames = [ 'push' , 'unshift' ] , sortingMethodNames = [ 'reverse' , 'sort' ] ; } else if ( sortingMethodNames . indexOf ( action ) !== - 1 ) {", "del_tokens": "var removeMethodNames = [ 'pop' , 'shift' , 'splice' ] , insertMethodNames = [ 'push' , 'unshift' ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "check", "for", "ownership", "in", "ENS"], "add_tokens": "var dotEth = web3 . sha3 ( '0000000000000000000000000000000000000000000000000000000000000000' + web3 . sha3 ( 'eth' ) . slice ( 2 ) , { encoding : 'hex' } ) ; var nameDotEth = web3 . sha3 ( dotEth + web3 . sha3 ( 'name' ) . slice ( 2 ) , { encoding : 'hex' } ) ; dotEth , } , // Check the owner is set in ENS function ( done ) { ens . owner ( nameDotEth , function ( err , owner ) { assert . equal ( err , null , err ) ; assert . equal ( owner , accounts [ 1 ] ) ; done ( ) ; } ) ;", "del_tokens": "web3 . sha3 ( '0000000000000000000000000000000000000000000000000000000000000000' + web3 . sha3 ( 'eth' ) . slice ( 2 ) , { encoding : 'hex' } ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "exports", "UTF8", "encode", "/", "decode"], "add_tokens": "const { ExtractBuffer , UTF8Encode , UTF8Decode } = require ( './lib/misc' ) ; ExtractBuffer , UTF8Encode , UTF8Decode", "del_tokens": "const { ExtractBuffer } = require ( './lib/misc' ) ; ExtractBuffer", "commit_type": "add"}
{"commit_tokens": ["Updated", "docs", "and", "lib", "."], "add_tokens": "o . buildDate = /*date*/ \"Thu, 18 Jul 2013 18:22:12 GMT\" ; // injected by build process", "del_tokens": "o . buildDate = /*date*/ \"Wed, 17 Jul 2013 17:39:18 GMT\" ; // injected by build process", "commit_type": "update"}
{"commit_tokens": ["fixed", "the", "glob", "patterns", "for", "test", "specs"], "add_tokens": "'test/specs/*/*.spec.js' ,", "del_tokens": "'test/specs/*.js' ,", "commit_type": "fix"}
{"commit_tokens": ["Uses", "this", "to", "search", "for", "modules", "to", "unpack", "."], "add_tokens": "// Unpacks all modules in black. Utils go in `target` or the global obj function unpack_all ( kind , global ) { keys ( this ) . forEach ( function ( module ) { module = root [ this ] , this , global || top , module ) } , this )", "del_tokens": "// Unpacks all modules in source. Utils go in `target` or the global obj function unpack_all ( kind , source , target ) { keys ( root ) . forEach ( function ( module ) { module = root [ module ] , source , target || top , module ) } )", "commit_type": "use"}
{"commit_tokens": ["added", "few", "development", "changes", ";"], "add_tokens": "var dotenv = require ( 'dotenv-safe' ) . config ( { path : process . env . ENV_FILE , example : '../../config/development/dev.env.sample' } ) ;", "del_tokens": "const Dotenv = require ( 'dotenv-webpack' ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "tests", "platform", "independent", "and", "fix", "code", "style"], "add_tokens": "var path = require ( 'path' ) ; var read = function ( ) { var filepath = path . join . apply ( this , Array . prototype . slice . call ( arguments ) ) ; return grunt . util . normalizelf ( grunt . file . read ( filepath ) ) ; } ; path . join ( 'deep' , 'directory' , 'location' , 'source_map.js.map' ) , files . forEach ( function ( file ) { var actual = read ( 'tmp' , file ) ; var expected = read ( 'test' , 'fixtures' , 'expected' , file ) ;", "del_tokens": "var tmp = 'tmp/' , fixtures = 'test/fixtures/expected/' ; 'deep/directory/location/source_map.js.map' , files . forEach ( function ( file ) { var actual = grunt . file . read ( tmp + file ) ; var expected = grunt . file . read ( fixtures + file ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "mapping", "to", "avoid", "infinite", "loop"], "add_tokens": "// map contain self link as key and a list of linkNames which were already fetched var map = { } ; var self = data . _links . self . href ; if ( ! map [ self ] ) { map [ self ] = [ ] ; } if ( map [ self ] . indexOf ( linkName ) < 0 && ( fetchLinkNames == config . fetchAllKey || ( fetchLinkNames instanceof Array && fetchLinkNames . indexOf ( linkName ) >= 0 ) ) ) { map [ self ] . push ( linkName ) ;", "del_tokens": "if ( fetchLinkNames == config . fetchAllKey || ( fetchLinkNames instanceof Array && fetchLinkNames . indexOf ( linkName ) >= 0 ) ) {", "commit_type": "add"}
{"commit_tokens": ["add", "iscroll", "to", "monaca", "-", "scroller"], "add_tokens": "setTimeout ( function ( ) { var wrapper = element . find ( '.scroller-wrapper' ) . get ( 0 ) ; var iScroll = new IScroll ( wrapper , { momentum : true , bounceLock : true , bounce : true } ) ; } , 0 ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "include", "only", "vector", "sources", "in", "inspect", "style", "."], "add_tokens": "if ( source . type === \"vector\" || source . type === \"geojson\" ) {", "del_tokens": "if ( source . type !== 'raster' ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "caching", "for", "specified", "file", "extensions"], "add_tokens": "* Deletes matching data when an extension is given or all data when no extension is given . * @ param { string } extension - Related extension which should be deleted . const _flush = function ( extension ) { cache . forEach ( ( value , key ) => { // Delete entry directly when no caching information available if ( value . cache == null ) { cache . delete ( key ) return true } // Look for matching extensions in the current entry let matches = value . cache . filter ( ( value ) => value === extension ) // Delete entry when a match was found if ( matches . length > 0 ) cache . delete ( key ) } )", "del_tokens": "* Flush the cache and all of the stored data . const _flush = function ( ) { cache . clear ( )", "commit_type": "add"}
{"commit_tokens": ["implement", "start", "of", "a", "basic", "streaming", "converter"], "add_tokens": "var through = require ( 'through' ) ; var converter = require ( '../lib/index.js' ) ( ) ; test ( 'single' , function ( t ) { t . plan ( 2 ) ; var stream = readable . pipe ( parser . stream ( ) ) . pipe ( converter ) ; stream . pipe ( through ( function ( fc ) { t . equals ( fc . type , \"FeatureCollection\" ) ; t . equals ( fc . features . length , 8 ) ; } ) ) ;", "del_tokens": "var converter = require ( '../index.js' ) ; test ( 'polygon' , function ( t ) { t . plan ( 1 ) ; readable . pipe ( parser ) . pipe ( converter ) ; parser . parse ( readable , function ( error , parsed ) { t . equals ( parsed . length , 39 ) ; } ) ;", "commit_type": "implement"}
{"commit_tokens": ["Use", "etag", "to", "generate", "ETag", "header"], "add_tokens": "var etag = require ( 'etag' ) var val = etag ( stat ) debug ( 'etag %s' , val ) res . setHeader ( 'ETag' , val )", "del_tokens": "var etag = utils . etag ( path , stat ) ; debug ( 'etag %s' , etag ) ; res . setHeader ( 'ETag' , etag ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "to", "set", "custom", "error", "message", "for", "missing", "runtime", "parameters", "."], "add_tokens": "options = _ . extend ( { required : true , message : 'Unknown parameter \"' + name + '\"; give it to the Scenario object at construction or from the command line with the -p, --params option' } , options ) ; throw new Error ( options . message ) ;", "del_tokens": "options = _ . extend ( { required : true } , options ) ; throw new Error ( 'Unknown parameter \"' + name + '\"; give it to the Scenario object at construction or from the command line with the -p, --params option' ) ;", "commit_type": "allow"}
{"commit_tokens": ["removed", "contributing", ".", "md", "cleaned", "up", "junk", "in", "root", ".", "rebuilt", "readme", "."], "add_tokens": "jshintrc : 'tasks/.jshintrc'", "del_tokens": "jshintrc : '.jshintrc'", "commit_type": "remove"}
{"commit_tokens": ["Add", "pause", "duration", "option", "before", "slide", "is", "exported"], "add_tokens": "} , pause : { default : 1000 , help : \"Duration in milliseconds before the next slide is exported\" // FIXME: PhantomJS is emitting this event for both pages and frames } , opts . pause ) ; // TODO: support a more advanced \"fragment to pause\" mapping for special use cases like GIF animations // TODO: add a plugin optional function to wait until a particular condition instead of a pause", "del_tokens": "} , 1000 ) ; // TODO: add a function per backend to wait until a particular condition instead of a timeout", "commit_type": "add"}
{"commit_tokens": ["Fixing", "wrong", "source", "method", "name", ".", "Improved", "docs", "."], "add_tokens": "/ ** * @ module source * / / ** * Interface for Source objects . * @ interface Source * / / ** * The main method to retrieve the data from the source . * @ method * @ name Source # fetch * @ param { number } offset The offset to read from in the source * @ param { number } length The requested number of bytes * / * @ returns The constructed source * @ returns The constructed source * @ returns The constructed source / ** * Creates a new source using the node filesystem API . * @ param { string } path The path to the file in the local filesystem . * @ returns The constructed source * / / ** * Create a new source from a given file / blob . * @ param { Blob } file The file or blob to read from . * @ returns The constructed source * / async fetch ( offset , length ) {", "del_tokens": "async read ( offset , length ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "I", "broke", "while", "linting"], "add_tokens": "Binder . prototype . createTopology = function Binder$createTopology ( route ) { return route . pattern . createTopology ( this . _topology , route . serviceDomainName , route . appName , route . name ) ; return self . createTopology ( publishingRoute ) return self . createTopology ( consumingRoute ) ;", "del_tokens": "Binder . prototype . assertTopology = function Binder$assertTopology ( route ) { return route . pattern . assertTopology ( this . _topology , route . serviceDomainName , route . appName , route . name ) ; return self . assertTopology ( publishingRoute ) return self . assertTopology ( consumingRoute ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "option", "to", "provide", "function", "for", "name", "generation"], "add_tokens": "_this . uiStateName = typeof config . name === 'function' ? config . name ( props ) : ( 0 , _ . generateName ) ( config . name ) ;", "del_tokens": "_this . uiStateName = config . persist ? config . name : ( 0 , _ . generateName ) ( config . name ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "links", "to", "source", "code", "to", "sample", "frontend"], "add_tokens": "< h4 > What is happening here? < / h4 > < h4 > Pants down. Show me the sources! < / h4 > < p > < span > Check out the < / span > < a href = \"https://github.com/flux-capacitor/flux-capacitor/tree/master/sample/frontend\" rel = \"nofollow\" > Frontend < / a > < span > and < / span > < a href = \"https://github.com/flux-capacitor/flux-capacitor/tree/master/sample/server\" rel = \"nofollow\" > Server < / a > < span > sources. < / span > < / p >", "del_tokens": "< h5 > What is happening here? < / h5 >", "commit_type": "add"}
{"commit_tokens": ["Fix", "major", "bug", "with", "indexing", "."], "add_tokens": "output . features . push ( normalized . features [ j ] ) ;", "del_tokens": "output . features . push ( normalized . features [ i ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "module", "export", "for", "node"], "add_tokens": "module . exports = function ( { types : t } ) {", "del_tokens": "export default function ( { types : t } ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "where", "the", "unreferenced", "files", "would", "still", "be", "in", "the", "manifest"], "add_tokens": "const initialExtraneous = this . __props . extraneous || { } ; const extraneous = initialExtraneous ;", "del_tokens": "const extraneous = this . __props . extraneous || { } ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "running", "callback", "in", "next", "tick"], "add_tokens": "setTimeout ( callback , 0 ) ;", "del_tokens": "setTimeout ( function ( ) { this . callback ( ) ; } , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "tests", "to", "text", "method"], "add_tokens": "* Date : 2016 - 02 - 07 T19 : 06 Z", "del_tokens": "* Date : 2016 - 02 - 07 T18 : 53 Z", "commit_type": "add"}
{"commit_tokens": ["Adding", "the", "Sorensen", "index", "alias"], "add_tokens": "import sorensen , { index as sorensenIndex , similarity as sorensenSimilarity , distance as sorensenDistance } from '../../src/distances/sorensen' ; it ( 'should compute the Dice index & aliases correctly.' , function ( ) { it ( 'Sorensen index should be the same as Dice.' , function ( ) { const compared = [ 'healed' , 'sealed' ] ; assert . strictEqual ( dice ( ... compared ) , sorensen ( ... compared ) ) ; assert . strictEqual ( index ( ... compared ) , sorensenIndex ( ... compared ) ) ; assert . strictEqual ( similarity ( ... compared ) , sorensenSimilarity ( ... compared ) ) ; assert . strictEqual ( distance ( ... compared ) , sorensenDistance ( ... compared ) ) ; } ) ;", "del_tokens": "it ( 'should compute the dice index & aliases correctly.' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "mapSettings", "description", "in", "options", ".", "md", "to", "highlight", "that", "zoom", "can", "be", "set", "to", "0", "for", "automatic", "centering", "and", "zooming", "fixed", "close", "directiosn", "bug", "where", "close", "icon", "couldn", "t", "be", "clicked", "more", "than", "two", "times"], "add_tokens": "/ *! jQuery Google Maps Store Locator - v2.0.8 - 2015-07-13 // Close directions $ ( document ) . on ( 'click.' + pluginName , '.' + _this . settings . locationList + ' .bh-sl-close-icon' , function ( ) { _this . closeDirections ( ) ; } ) ;", "del_tokens": "/ *! jQuery Google Maps Store Locator - v2.0.8 - 2015-05-23 } ) ; // Close directions $ ( document ) . on ( 'click.' + pluginName , '.' + _this . settings . locationList + ' .bh-sl-close-icon' , function ( ) { _this . closeDirections ( ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "documentation", "for", "manual", "tests"], "add_tokens": "var accelerometer_tests = '<div id=\"getAcceleration\"></div>' + 'Expected result: Will update the status box with X, Y, and Z values when pressed. Status will read \"Stopped\"' + '<p/> <div id=\"watchAcceleration\"></div>' + 'Expected result: When pressed, will start a watch on the accelerometer and update X,Y,Z values when movement is sensed. Status will read \"Running\"' + '<p/> <div id=\"clearAcceleration\"></div>' + 'Expected result: Will clear the accelerometer watch, so X,Y,Z values will no longer be updated. Status will read \"Stopped\"' ; accelerometer_tests ; } , 'getAcceleration' ) ; } , 'watchAcceleration' ) ; } , 'clearAcceleration' ) ;", "del_tokens": "'<div id=\"actions\"></div>' ; } , 'actions' ) ; } , 'actions' ) ; } , 'actions' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "relative", "url", "support", "."], "add_tokens": "console . log ( '\\t- ' + file . replace ( staticDir , '' ) . replace ( / ^\\/ / , '' ) ) ; var filePath = file . replace ( pagesDir , '' ) . replace ( / ^\\/ / , '' ) ; filePath , console . log ( '\\t- ' + filePath ) ;", "del_tokens": "console . log ( '\\t- ' + file . replace ( staticDir , '' ) ) ; console . log ( '\\t- ' + file . replace ( pagesDir , '' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", ";", "add", "disconnect", "check", "to", "Socket#disconnect", "."], "add_tokens": "if ( ! this . disconnected ) { this . log . info ( 'booting client' ) ; this . store . disconnect ( this . id , true ) ; }", "del_tokens": "this . packet ( { type : 'disconnect' } ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "Default", "Parameter", "Value"], "add_tokens": "if ( ! fnParams [ 0 ] ) { return ; } var spec ; if ( fnParams [ 0 ] . type === 'ObjectPattern' ) { spec = fnParams [ 0 ] ; } else if ( fnParams [ 0 ] . type === 'AssignmentPattern' ) { spec = fnParams [ 0 ] . left ; } else {", "del_tokens": "if ( ! fnParams [ 0 ] || fnParams [ 0 ] . type !== 'ObjectPattern' ) { var spec = fnParams [ 0 ] ;", "commit_type": "add"}
{"commit_tokens": ["changed", "how", "dates", "are", "formatted", "to", "deal", "with", "encoding", "issue", "in", "IE", "browsers", "."], "add_tokens": "// dealing with encoding issue in IE browsers. resolveValue = ( value . _d . getMonth ( ) + 1 ) + '/' + value . _d . getDate ( ) + '/' + value . _d . getFullYear ( ) ;", "del_tokens": "resolveValue = value . _d . toLocaleDateString ( ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "error", "code", "in", "README", "and", "the", "example"], "add_tokens": "if ( err . code === 'ER_LOCK_DEADLOCK' ) {", "del_tokens": "if ( err . code === 'DEADLOCK' ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "100%", "and", "one", "node", "tree", "display"], "add_tokens": "//console.log(id, bundle); if ( commonParent . children . length === 0 ) { newChildren . push ( commonParent ) ; } else { newChildren = newChildren . concat ( commonParent . children ) ; }", "del_tokens": "newChildren = newChildren . concat ( commonParent . children ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "documentation", "and", "test", "for", "wrap", "s", "exportAll", "feature", "."], "add_tokens": "// Wrap code in a common js wrapper. topLevel = topLevel . wrap_commonjs ( options . wrap , options . exportAll ) ;", "del_tokens": "// Wrap code in a common js wrapper. topLevel = topLevel . wrap_commonjs ( options . wrap , options . export_all ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "some", "test", "cases", "to", "make", "tests", "pass", ".", "The", "issues", "are", "still", "sorta", "present", ".", "The", "errors", "are", "just", "thrown", "by", "ffi", "instead", "of", "the", "type", "code", "."], "add_tokens": "} else if ( type . indexOf ( '*' ) >= 0 ) { // {'start': 256, 'end': 0, 'err': true}, // {'start': -1, 'end': 256, 'err': true}, userStr . length ,", "del_tokens": "} else { { 'start' : 256 , 'end' : 0 , 'err' : true } , { 'start' : - 1 , 'end' : 256 , 'err' : true } , userStr . length + 1 ,", "commit_type": "remove"}
{"commit_tokens": ["fixed", "faulty", "error", "-", "handling", "in", "async", "tests", "where", "failures", "were", "being", "treated", "as", "errors"], "add_tokens": "test . error = new jarvis . Framework . Error ( err , \"fail\" ) ;", "del_tokens": "test . error = self . handleError ( err , test ) ; test . expectedError = jarvis . globalExpectedError ;", "commit_type": "fix"}
{"commit_tokens": ["add", "i18n", ".", "js", "and", "day", "names", "rendering"], "add_tokens": "gulp . src ( [ 'js/datepicker/datepicker.js' , 'js/datepicker/i18n.js' , 'js/datepicker/cell.js' , 'js/datepicker/body.js' ] )", "del_tokens": "gulp . src ( [ 'js/datepicker/datepicker.js' , 'js/datepicker/cell.js' , 'js/datepicker/body.js' ] )", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "security", "group", "for", "access", "to", "the", "endpoints"], "add_tokens": "Ref : 'LambdaEndpointSecurityGroup' , const securitygroup = { Type : 'AWS::EC2::SecurityGroup' , Properties : { GroupDescription : 'Lambda access to VPC endpoints' , VpcId : { Ref : 'VPC' , } , SecurityGroupIngress : [ { SourceSecurityGroupId : { Ref : 'LambdaExecutionSecurityGroup' , } , IpProtocol : 'tcp' , FromPort : 443 , ToPort : 443 , } , ] , Tags : [ { Key : 'STAGE' , Value : this . provider . getStage ( ) , } , { Key : 'Name' , Value : { 'Fn::Join' : [ '-' , [ { Ref : 'AWS::StackName' , } , 'lambda-endpoint' , ] , ] , } , } , ] , } , } ; resources . LambdaEndpointSecurityGroup = securitygroup ;", "del_tokens": "Ref : 'LambdaExecutionSecurityGroup' ,", "commit_type": "create"}
{"commit_tokens": ["made", "logo", "inline", "with", "flag"], "add_tokens": "this . maxSize = 3 ;", "del_tokens": "this . maxSize = 5 ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "side", "calculation", "precedence", "bug"], "add_tokens": "var side = d + ( flip ? 3 : 0 ) var tex_id = voxelTexture ( val & VOXEL_MASK , side , this . voxelSideTextureIDs )", "del_tokens": "var side = d + flip ? 3 : 0 var tex_id = voxelTexture ( val & VOXEL_MASK , d + flip ? 3 : 0 , this . voxelSideTextureIDs )", "commit_type": "fix"}
{"commit_tokens": ["add", "the", "autoplay", "argument", "sent", "to", "renderer"], "add_tokens": "subtitlesRenderer = new Renderer ( 'playerCaptions' , captionsURL , mediaPlayer , autoStart ) ;", "del_tokens": "subtitlesRenderer = new Renderer ( 'playerCaptions' , captionsURL , mediaPlayer , container , autoStart ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "namespace", "capability", "and", "adjust", "get", "and", "all", "methods", "return", "data"], "add_tokens": "var query = null ; if ( namespace ) { query = datastore . createQuery ( namespace , kind ) ; } else { query = datastore . createQuery ( kind ) ; }", "del_tokens": "var query = datastore . createQuery ( kind ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "skipped", "to", "the", "failure", "epilogue"], "add_tokens": "if ( stats . skipped ) { this . writer . write ( Colors . wrap ( Colors . cyan , ' %d %s skipped' ) , stats . skipped , pluralize ( stats . skipped ) ) } this . writer . write ( Colors . wrap ( Colors . cyan , ' ' ) + Colors . wrap ( Colors . cyan , ' %d %s skipped' ) , stats . skipped , pluralize ( stats . skipped ) )", "del_tokens": "+ Colors . wrap ( Colors . intenseBlack , ':' ) format = Colors . wrap ( Colors . cyan , ' ' ) + Colors . wrap ( Colors . cyan , ' %d %s skipped' ) this . writer . write ( format , stats . skipped , pluralize ( stats . skipped ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "allow", "javascript", "XHR", "middleware", "."], "add_tokens": "[ 'access_logger' , 'transaction_id' , 'body_size_limiter' , 'allow_javascript_xhr' ] . forEach ( function ( module ) {", "del_tokens": "[ 'access_logger' , 'transaction_id' , 'body_size_limiter' ] . forEach ( function ( module ) {", "commit_type": "add"}
{"commit_tokens": ["add", "legacy", "webpack", "support", "and", "fixes"], "add_tokens": "var Pusher = require ( 'pusher-js' ) ;", "del_tokens": "var Pusher = require ( 'pusher-js/dist/web/pusher.js' ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "with", "new", "lodash", "methods"], "add_tokens": "'dist/probe.min.js' : 'src/probe.js'", "del_tokens": "'build/probe.min.js' : 'src/probe.js'", "commit_type": "update"}
{"commit_tokens": ["added", "missing", "semicolons", "and", "check", "for", "callback", "being", "a", "function", "before", "calling", "it"], "add_tokens": "//Call EventEmmiter _contructor_ debug ( \"Forwarding frontend message '%s', with data %j\" , message . event , message . data ) ; if ( message . event !== undefined ) { if ( typeof callback === 'function' ) { callback ( ) ; } return ;", "del_tokens": "//Call EventEmmiter _contructor_ if ( message . event != undefined ) { debug ( \"message received: %s\" , JSON . stringify ( message ) ) ; callback ( ) ; return", "commit_type": "add"}
{"commit_tokens": ["Remove", "unneeded", "process", "dep", "."], "add_tokens": "var browser = typeof window !== 'undefined' ; var raf = browser && require ( 'raf-component' ) ; return browser ? raf ( fn ) : setImmediate ( fn ) ; return browser ? raf . cancel ( id ) : clearImmediate ( id ) ;", "del_tokens": "var raf = process . browser && require ( 'raf-component' ) ; return process . browser ? raf ( fn ) : setImmediate ( fn ) ; return process . browser ? raf . cancel ( id ) : clearImmediate ( id ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updating", "server", "to", "only", "write", "pid", "if", "it", "successfully", "listens"], "add_tokens": "http . createServer ( app ) . listen ( 8000 , function ( ) { fs . writeFileSync ( pidFile , process . pid , 'utf-8' ) ; } ) ;", "del_tokens": "http . createServer ( app ) . listen ( 8000 ) ; fs . writeFileSync ( pidFile , process . pid , 'utf-8' ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "the", "ability", "to", "number", "in", "descending", "order", "."], "add_tokens": "let descendingOrder = false ; if ( str . substr ( r [ 0 ] + r [ 1 ] + 1 , 1 ) === '-' ) { descendingOrder = true ; } const matches = str . substr ( r [ 0 ] + r [ 1 ] + 1 + Number ( descendingOrder ) ) . match ( / ^(\\d+) / ) ; offsetLength = matches [ 1 ] . length + 1 + Number ( descendingOrder ) ; } else { offsetLength = 2 ; + ( typeof value === 'function' ? value ( str . substr ( r [ 0 ] , r [ 1 ] ) , offset , descendingOrder ) : value )", "del_tokens": "const matches = str . substr ( r [ 0 ] + r [ 1 ] + 1 ) . match ( / ^(\\d+) / ) ; offsetLength = matches [ 1 ] . length + 1 ; + ( typeof value === 'function' ? value ( str . substr ( r [ 0 ] , r [ 1 ] ) , offset ) : value )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "drag", "and", "drop", "on", "Firefox", ".", "Blocks", "now", "tied", "to", "instances", "."], "add_tokens": ". bind ( 'dragleave' , halt ) . bind ( 'mouseout' , function ( ev ) { $ ( this ) . removeClass ( 'active' ) ; } ) . bind ( 'dragover' , function ( ev ) { ev . preventDefault ( ) ; } ) ; ev . originalEvent . dataTransfer . setData ( 'Text' , item . parent ( ) . attr ( 'id' ) ) ; this . instance . marker . hide ( ) ; \"data-instance\" : this . instance . ID , . bind ( 'drag' , this . instance . marker . show ) ;", "del_tokens": ". bind ( 'mouseout' , function ( ev ) { $ ( this ) . removeClass ( 'active' ) ; } ) ; ev . originalEvent . dataTransfer . setData ( 'Text' , item . parent ( ) . attr ( 'id' ) ) ; . dropArea ( ) . bind ( 'drag' , this . instance . marker . show ) . bind ( 'dragleave' , function ( ) { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "test", "for", "prefixed", "AudioContext"], "add_tokens": "if ( isBrowser && ! AudioContext ) throw new Error ( 'This browser doesn\\'t seem to support web audio API' )", "del_tokens": "if ( isBrowser && ! AudioContext ) { if ( window . webkitAudioContext ) console . error ( 'This browser uses a prefixed version of web audio API' ) else console . error ( 'This browser doesn\\'t seem to support web audio API' ) }", "commit_type": "remove"}
{"commit_tokens": ["Use", "feathers", "-", "errors", "error", "converter"], "add_tokens": "reject ( errors . convert ( JSON . parse ( err . responseText ) ) ) ;", "del_tokens": "const error = JSON . parse ( err . responseText ) ; const FeathersError = errors [ error . name ] ; if ( FeathersError ) { return reject ( new FeathersError ( error . message , error . data ) ) ; } throw error ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "options", ".", "macPlist", "(", "String", "=", ">", "string", ")"], "add_tokens": "if ( typeof self . options . macPlist === 'string' ) {", "del_tokens": "if ( typeof self . options . macPlist === 'String' ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "eslint", "crash", "when", "using", "object", "spread", "inside", "prop", "definition"], "add_tokens": "* Checks if the passed prop has a default value . find ( p => p . key && p . key . name === 'default' )", "del_tokens": "* Checks if the passed prop has a defualt value . find ( p => p . key . name === 'default' )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "default", "fps", "to", "20"], "add_tokens": "fps : 20", "del_tokens": "fps : 16", "commit_type": "change"}
{"commit_tokens": ["use", "strict", "on", "entire", "code"], "add_tokens": "\"use strict\" ;", "del_tokens": "\"use strict\" ;", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "ISO", "week", "duration"], "add_tokens": "const isoDuration = / ^P(?:(?:(\\d+)Y)?(?:(\\d+)M)?(?:(\\d+)D)?(?:T(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?)?|(\\d+)W)$ / ; const [ , yearStr , monthStr , dayStr , hourStr , minuteStr , secondStr , weekStr ] = match ; week : parseInt ( weekStr ) ,", "del_tokens": "const isoDuration = / ^P(?:(\\d+)Y)?(?:(\\d+)M)?(?:(\\d+)D)?(?:T(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?)?$ / ; const [ , yearStr , monthStr , dayStr , hourStr , minuteStr , secondStr ] = match ;", "commit_type": "add"}
{"commit_tokens": ["fix", "mistyped", "option", "name", "extenstion", "-", ">", "extension"], "add_tokens": "// check for mistyped 'extenstion' option name if ( this . data . extenstion && ! this . data . extension ) { this . data . extension = this . data . extenstion ; console . warn ( 'Warning: use deprecated (mistyped) option `extenstion`, please use `extension` instead.' . yellow ) ; } var extension = this . data . extension || 'html' ;", "del_tokens": "var extension = this . data . extenstion || 'html' ;", "commit_type": "fix"}
{"commit_tokens": ["add", "basic", "finder", "query", "methods", "and", "helper", "methods"], "add_tokens": "BasicFinder = require ( './finders/basic' ) , Helpers = require ( './finders/helpers' ) ; BasicFinder , Helpers", "del_tokens": "BasicFinder = require ( './finders/basic' ) ; BasicFinder", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "turn", "and", "rad", "units"], "add_tokens": "return / ([\\+\\-]?[0-9#\\.]+)(%|px|pt|em|rem|in|cm|mm|ex|pc|vw|vh|deg|rad|turn)? / . exec ( val ) [ 2 ] ;", "del_tokens": "return / ([\\+\\-]?[0-9|auto|#\\.]+)(%|px|pt|em|rem|in|cm|mm|ex|pc|vw|vh|deg)? / . exec ( val ) [ 2 ] ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "AddError", "()", "to", "handle", "errors", "with", "no", "prefixes", "."], "add_tokens": "if ( message != null ) { if ( MathJax && MathJax . ElementJax ) { var n = MathJax . ElementJax . ID + 1 ; if ( prefix !== \"\" ) { prefix += \" (\" + n + \"): \" } } message = prefix + message ; } else { message = prefix ; }", "del_tokens": "var n = MathJax . ElementJax . ID + 1 ; if ( prefix !== \"\" ) { prefix += \" (\" + n + \"): \" } message = prefix + message ;", "commit_type": "fix"}
{"commit_tokens": ["added", ";", "output", "validation", "support"], "add_tokens": "yield validateInput ( prop , this . request , spec . validate ) ; if ( spec . validate . output ) { yield validateOutput ( spec ) ; } * Creates an input validation thunk for the given function validateInput ( prop , request , validate ) { / ** * Creates an output validation thunk for response body . * * @ param { Object } spec * @ api private * / function validateOutput ( spec ) { return function ( cb ) { debug ( 'validating output' ) ; var ctx = this ; Joi . validate ( ctx . body , spec . validate . output , function ( err , val ) { if ( err ) { err . status = 500 ; return cb ( err ) ; } // update our request w/ the casted values ctx . body = val ; cb ( ) ; } ) ; } }", "del_tokens": "yield validate ( prop , this . request , spec . validate ) ; * Creates a validation thunk for the given function validate ( prop , request , validate ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "ReferenceError", "in", "clone"], "add_tokens": "args . push ( val instanceof adt . __Base__ ? val . clone ( ) : val ) ;", "del_tokens": "args . push ( n instanceof adt . __Base__ ? val . clone ( ) : val ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "streaming", "tests", "and", "start", "of", "streaming", "API"], "add_tokens": ", es = require ( 'event-stream' ) if ( options && options . sort ) { if ( callback === undefined ) { return es . readArray ( cursor . all ( ) ) } else { callback ( null , cursor . all ( ) ) } return findByQuery ( query , options , callback )", "del_tokens": "if ( typeof callback !== 'function' ) { throw new Error ( 'callback must be a function' ) } if ( options . sort ) { callback ( null , cursor . all ( ) ) findByQuery ( query , options , callback )", "commit_type": "add"}
{"commit_tokens": ["added", "JSDoc", "comments", "to", "some", "src", "files"], "add_tokens": "const S = { } ; require ( './src/evaluate' ) . loadTo ( S ) ; require ( './src/parsers' ) . loadTo ( S ) ; require ( './src/prim/types' ) . loadTo ( S ) ; require ( './src/prim/equals' ) . loadTo ( S ) ; require ( './src/prim/ops' ) . loadTo ( S ) ; require ( './src/prim/logical' ) . loadTo ( S ) ; require ( './src/prim/lambda' ) . loadTo ( S ) ; require ( './src/lib_utils' ) . loadTo ( S ) ; require ( './src/async' ) . loadTo ( S ) ; module . exports = S ;", "del_tokens": "const s = { } ; require ( './src/evaluate' ) . loadTo ( s ) ; require ( './src/parsers' ) . loadTo ( s ) ; require ( './src/prim/types' ) . loadTo ( s ) ; require ( './src/prim/equals' ) . loadTo ( s ) ; require ( './src/prim/ops' ) . loadTo ( s ) ; require ( './src/prim/logical' ) . loadTo ( s ) ; require ( './src/prim/lambda' ) . loadTo ( s ) ; require ( './src/lib_utils' ) . loadTo ( s ) ; require ( './src/async' ) . loadTo ( s ) ; module . exports = s ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "not", "working", "single", "test", "runs", "."], "add_tokens": "result . module = modules . reverse ( ) . join ( ' / ' ) ;", "del_tokens": "modules . reverse ( ) ; result . module = modules . length ? modules . join ( ' / ' ) : '' ; result . fullName = result . fullName ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "check", "to", "confirm", "that", "vedoeStream", ".", "getVideoTracks", "is", "a", "function"], "add_tokens": "var checker = typeof videoStream . getVideoTracks === 'function' ; if ( videoStream . getVideoTracks && checker ) { // ENSURE THIS IS CHECKED FIRST BEFORE THE FALLBACK // videoStream.stop()", "del_tokens": "if ( videoStream . getVideoTracks ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "index", "option", "for", "getPageNumberUrl", "."], "add_tokens": "* @ param { Boolean } options . index First page will be ` ` if true . export function getPageNumberUrl ( urlPrefix , pageNumber , { index } = { } ) { if ( index ) { return ` ${ urlPrefix } ` ; } else { return urlPrefix ; } * @ param { Boolean } options . index Add ` ` to the first pages s urce p th. export function paginate ( documents , { sourcePathPrefix , urlPrefix , documentsPerPage , layout , index , extra = { } } = { } ) { let sourcePath = getPageNumberUrl ( sourcePathPrefix , pageNumber , { index } ) ;", "del_tokens": "export function getPageNumberUrl ( urlPrefix , pageNumber ) { return urlPrefix ; export function paginate ( documents , { sourcePathPrefix , urlPrefix , documentsPerPage , layout , extra = { } } = { } ) { let sourcePath = getPageNumberUrl ( sourcePathPrefix , pageNumber ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "set", "expire", "in", "years", "on", "certificate"], "add_tokens": "var printKeyCred = function ( keycred ) { } , function ( err , params ) { expireInYears : { description : 'Number of years until expiration (default is 1)' } } , function ( err , certparams ) { } , function ( err , fileparams ) {", "del_tokens": "var printKeyCred = function ( keycred ) { } , function ( err , params ) { } , function ( err , certparams ) { } , function ( err , fileparams ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "query", "accessor", "&", "documentation", "."], "add_tokens": "/ ** * Access to a query object that is tied to this database . * * @ name Database # query * @ since 1.0 * @ public * @ type { Query } * @ readonly * / Database . defineAccessor ( 'query' ) ; Database . reopen ( /** @lends Database# */ { * Shortcut for ` ` . * @ see { @ link Database # query } * @ see { @ link Query # select }", "del_tokens": "Database . reopen ( /** @lends Database# */ { * Documentation forthcoming .", "commit_type": "add"}
{"commit_tokens": ["Added", "initial", "set", "of", "icons", "used", "by", "resale", "tooltips", "."], "add_tokens": "font : 'src/main/font/*' , icons : 'src/main/svg/icon-*.svg' var stream = gulp . src ( [ src . icons ] )", "del_tokens": "font : 'src/main/font/*' var stream = gulp . src ( src . svg )", "commit_type": "add"}
{"commit_tokens": ["removed", "surrogate", "for", "testing", "if", "middleware", "provider", "can", "be", "executed"], "add_tokens": ". runAll ( moduleMeta )", "del_tokens": "function canExecuteProvider ( provider ) { return provider . match && provider . match . test ( moduleMeta . name ) ; } . runAll ( moduleMeta , canExecuteProvider )", "commit_type": "remove"}
{"commit_tokens": ["Added", "release", "commit", "/", "push"], "add_tokens": "if ( ! this . _callbacks [ methodName ] ) { this . _callbacks [ methodName ] = [ ] ; } this . _callbacks [ methodName ] . push ( callback ) ; var callbacks = this . _callbacks [ methodName ] ; if ( ! callbacks || ! callbacks . length ) { var response = callbacks . shift ( ) . apply ( null , arguments ) ;", "del_tokens": "this . _callbacks [ methodName ] = callback ; if ( typeof this . _callbacks [ methodName ] !== 'function' ) { var response = this . _callbacks [ methodName ] . apply ( null , arguments ) ; // Make sure subsequent calls are handled delete this . _callbacks [ methodName ] ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "convenience", "method", "."], "add_tokens": "self . port = parseInt ( opts . port , 10 ) ; if ( ! _ . isNumber ( self . port ) ) {", "del_tokens": "if ( ! _ . isNumber ( opts . port ) ) { self . port = opts . port ;", "commit_type": "add"}
{"commit_tokens": ["Add", "github", "link", "for", "doc"], "add_tokens": "import styles from './header.module.scss' ; < a href = { githubLink } target = \"_blank\" className = { styles . githubLink } / >", "del_tokens": "import styles from './header.scss' ; < a href = { githubLink } target = \"_blank\" className = \"githubLink\" / >", "commit_type": "add"}
{"commit_tokens": ["Adds", "frame", "count", "to", "result", "object", "if", "it", "s", "an", "animation", "."], "add_tokens": "if ( result . type === ANIMATION ) { result . frames = frames ; }", "del_tokens": "if ( result . type === ANIMATION )", "commit_type": "add"}
{"commit_tokens": ["Updated", "benchmark", "&", "readme", "to", "reflect", "latest", "changes"], "add_tokens": "dir = \"/Users/felix/Downloads/finalrun-input/\" var ret = getReadableContent . process ( file ) ; console . log ( \"skipped\" , skipped ) ;", "del_tokens": "dir = \"/path/to/files/\" var ret = getReadableContent . process ( file , 0 , { } ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "a", "check", "for", "pool", "id", "since", "it", "can", "come", "from", "two", "places"], "add_tokens": "var id = this . id || this . pool_id return ngin . Standings . create ( { pool_id : id } ) . fetch ( callback )", "del_tokens": "return ngin . Standings . create ( { pool_id : this . id } ) . fetch ( callback )", "commit_type": "add"}
{"commit_tokens": ["change", "default", "ports", "to", "be", "sequential"], "add_tokens": "port : 8080 , cfg . couch . port = 8081 ;", "del_tokens": "port : 6001 , cfg . couch . port = 6004 ;", "commit_type": "change"}
{"commit_tokens": ["Add", "new", "intervals", "to", "charts"], "add_tokens": "if ( interval == \"daily\" || interval . indexOf ( \"day\" ) != - 1 ) { else if ( interval == \"weekly\" || interval . indexOf ( \"week\" ) != - 1 ) { else if ( interval == \"hourly\" || interval . indexOf ( \"hours\" ) != - 1 ) { else if ( interval == \"monthly\" || interval . indexOf ( \"month\" ) != - 1 ) { else if ( interval == \"minutely\" || interval . indexOf ( \"minute\" ) != - 1 ) {", "del_tokens": "if ( interval == \"daily\" ) { else if ( interval == \"weekly\" ) { else if ( interval == \"hourly\" ) { else if ( interval == \"monthly\" ) { else if ( interval == \"minutely\" ) {", "commit_type": "add"}
{"commit_tokens": ["update", "webpack", "config", "to", "build", "dist"], "add_tokens": "const path = require ( 'path' ) ; const webpack = require ( 'webpack' ) ; const ENV = process . env . NODE_ENV ; const BUILD_FOLDER = path . resolve ( process . env . BUILD_FOLDER ) ; const ROOT_FOLDER = path . resolve ( __dirname ) ; const SOURCE_FOLDER = path . join ( ROOT_FOLDER , 'src' ) ; 'otplib.ga' : SOURCE_FOLDER + '/authenticator.js' , filename : '[name].min.js'", "del_tokens": "let path = require ( 'path' ) ; let webpack = require ( 'webpack' ) ; var ENV = process . env . NODE_ENV ; let ROOT_FOLDER = path . resolve ( __dirname ) ; let SOURCE_FOLDER = path . join ( ROOT_FOLDER , 'src' ) ; let BUILD_FOLDER = path . join ( ROOT_FOLDER , 'site/public' ) ; 'otplib.ga' : SOURCE_FOLDER + '/authenticator.js' , filename : '[name].js'", "commit_type": "update"}
{"commit_tokens": ["remove", "clone", "option", "in", "downloadGitRepo"], "add_tokens": "downloadGitRepo ( repo , tempDirPath , function ( err ) {", "del_tokens": "downloadGitRepo ( repo , tempDirPath , { clone : true } , function ( err ) {", "commit_type": "remove"}
{"commit_tokens": ["Adds", "a", "specific", "ROUTER", "file", "test"], "add_tokens": "describe ( \"middleware\" , function ( ) { var port = 9967 before ( function ( done ) { express ( ) . use ( yonder ( __dirname + \"/examples/ROUTER\" ) ) . listen ( port , function ( ) { done ( ) } ) } ) it ( \"should obey redirect\" , function ( done ) { request . get ( \"http://localhost:\" + port + \"/privacy\" , { followRedirect : false } , function ( e , r , b ) { r . statusCode . should . eql ( 301 ) r . headers . should . have . property ( \"location\" , \"/privacy-policy\" ) done ( ) } ) } ) it ( \"should obey remote redirect\" , function ( done ) { request . get ( \"http://localhost:\" + port + \"/blog\" , { followRedirect : false } , function ( e , r , b ) { r . statusCode . should . eql ( 302 ) r . headers . should . have . property ( \"location\" , \"http://medium.com/surge-sh\" ) done ( ) } ) } ) } ) var port = 9968 } )", "del_tokens": "var port = 9967 } )", "commit_type": "add"}
{"commit_tokens": ["changed", "twitter", ".", "js", "watson", ".", "js", "and", "app", ".", "js", "to", "reflect", "name", "change", "to", "personify", "and", "accept", "one", "object", "for", "authentication"], "add_tokens": "var Personify = require ( 'personify' ) ; var P = new Personify ( { watsonConfig : { service_url : \"https://gateway.watsonplatform.net/systemu/service/\" , service_username : \"12312a68-fdff-4064-9928-eb088a960815\" , service_password : \"KUwy0neR5kpV\" } , twitterConfig : { consumer_key : 'nnnMzv63aJKbQgzF77vQLXCm0' , consumer_secret : 'BAG1XL3PHUVw6AsW7K0dRcIv6qkITkWARmZL9Bb8nOKfTkbTpo' , access_token : '35398491-9KTshSy7QNiKh0Ia71AeZ6D1XMg6teKJWAwp6YNNE' , access_token_secret : 'ivIGOcV4OHxW9lRrW7pevEcxwtk2RDGzVSW6IdOqz9R0D' } P . user ( 'fr332th1nk' , function ( data , err ) { console . log ( 'TTTTTTTTTTTTTTTTTT ' , data , 'TTTTTTTTTTTTTTTTTT' ) ; } ) ; // W.searchGeo(function(data, err){ // console.log(data, err); // }, '#nike', 'NY');", "del_tokens": "var Watson = require ( 'watson' ) ; var W = new Watson ( { service_url : \"https://gateway.watsonplatform.net/systemu/service/\" , service_username : \"12312a68-fdff-4064-9928-eb088a960815\" , service_password : \"KUwy0neR5kpV\" } , { consumer_key : 'nnnMzv63aJKbQgzF77vQLXCm0' , consumer_secret : 'BAG1XL3PHUVw6AsW7K0dRcIv6qkITkWARmZL9Bb8nOKfTkbTpo' , access_token : '35398491-9KTshSy7QNiKh0Ia71AeZ6D1XMg6teKJWAwp6YNNE' , access_token_secret : 'ivIGOcV4OHxW9lRrW7pevEcxwtk2RDGzVSW6IdOqz9R0D' // W.user('fr332th1nk', function(data, err){ // console.log('TTTTTTTTTTTTTTTTTT ' , data , 'TTTTTTTTTTTTTTTTTT'); // }); W . searchGeo ( function ( data , err ) { console . log ( data , err ) ; } , '#nike' , 'NY' ) ;", "commit_type": "change"}
{"commit_tokens": ["Upgrade", "to", "latest", "Webpack", "and", "fix", "some", "issues"], "add_tokens": "const HappyPack = require ( \"happypack\" ) ; rules : [ test : / \\.jsx?$ / , loader : \"happypack/loader?id=babel\" } ) , // Use HappyPack to speed up Babel build times // significantly new HappyPack ( { id : \"babel\" , loaders : [ ` ${ require . resolve ( \"./fixRequireIssues\" ) } ` ] extensions : [ ` ${ platform } ` , \".js\" ] const configs = PLATFORMS . map ( platform => { delete config . platform ; // @todo solve performance when returning many return configs [ PLATFORMS . indexOf ( options . platform ) ] ;", "del_tokens": "loaders : [ test : / \\.js?$ / , loader : \"babel-loader?cacheDirectory=true\" , extensions : [ \"\" , ` ${ platform } ` , \".js\" ] return PLATFORMS . map ( platform => {", "commit_type": "upgrade"}
{"commit_tokens": ["Change", "@tour", "step", "instance", "to", "@shepherd"], "add_tokens": "function Step ( shepherd , options ) { this . shepherd = shepherd ; action : this . shepherd . next return _this . shepherd . advance ( ) ; return _this . shepherd . advance ( ) ; return _this . shepherd . show ( page ) ;", "del_tokens": "function Step ( tour , options ) { this . tour = tour ; action : this . tour . next return _this . tour . advance ( ) ; return _this . tour . advance ( ) ; return _this . tour . show ( page ) ;", "commit_type": "change"}
{"commit_tokens": ["allowing", "nulls", "to", "be", "dispatched", "as", "a", "valid", "payload"], "add_tokens": "if ( ! ! actionOrValue && actionOrValue . useFailType ) { if ( typeof actionOrValue === 'undefined' ) { // ignore empty action", "del_tokens": "if ( actionOrValue . useFailType ) { if ( act ) { // ignore empty action", "commit_type": "allow"}
{"commit_tokens": ["Remove", "unnecessary", "try", "-", "catch", "block"], "add_tokens": "// no cookies if ( ! cookies ) { return next ( ) ; req . cookies = cookie . parse ( cookies , options ) ; // parse signed cookies if ( secret ) { req . signedCookies = parse . signedCookies ( req . cookies , secret ) ; req . signedCookies = parse . JSONCookies ( req . signedCookies ) ; } // parse JSON cookies req . cookies = parse . JSONCookies ( req . cookies ) ;", "del_tokens": "if ( cookies ) { try { req . cookies = cookie . parse ( cookies , options ) ; if ( secret ) { req . signedCookies = parse . signedCookies ( req . cookies , secret ) ; req . signedCookies = parse . JSONCookies ( req . signedCookies ) ; } req . cookies = parse . JSONCookies ( req . cookies ) ; } catch ( err ) { err . status = 400 ; return next ( err ) ; }", "commit_type": "remove"}
{"commit_tokens": ["make", "require", "()", "for", "template", "engine", "more", "visible"], "add_tokens": "} return ProjectInitCommand . templateEngine ( ) . template ( content ) ( data ) ; static templateEngine ( ) { return require ( 'underscore' ) ; }", "del_tokens": "} return require ( 'underscore' ) . template ( content ) ( data ) ;", "commit_type": "make"}
{"commit_tokens": ["remove", "redis", "cacher", "middleware", "declaration"], "add_tokens": "return this . get ( cacheKey ) . then ( content => { if ( content != null ) { // Found in the cache! Don't call handler, return with the context ctx . cachedResult = true ; return content ; } // Call the handler return handler ( ctx ) . then ( result => { // Save the response to the cache this . set ( cacheKey , result ) ; return result ; } ) ;", "del_tokens": "const content = this . get ( cacheKey ) ; if ( content != null ) { // Found in the cache! Don't call handler, return with the context ctx . cachedResult = true ; return content ; } // Call the handler return handler ( ctx ) . then ( result => { // Save the response to the cache this . set ( cacheKey , result ) ; return result ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "more", "detail", "to", "the", "watcher", "test"], "add_tokens": "var count = 0 ; count ++ ; if ( count > 1 ) throw new Error ( \"Count mismatch: \" + count ) ; setTimeout ( function ( ) { watcher . removeListener ( \"change\" , listen ) ; writable . end ( ) ; } , 1000 ) ; } ) ; writable . on ( \"close\" , function ( ) { watcher . on ( \"change\" , function ( event , filename ) { watcher . close ( ) ; done ( ) ; fs . unlinkSync ( base + vpath ) ;", "del_tokens": "watcher . removeListener ( \"change\" , listen ) ; writable . on ( \"close\" , function ( ) { watcher . on ( \"change\" , function ( event , filename ) { watcher . close ( ) ; done ( ) ; } ) ; fs . unlinkSync ( base + vpath ) ; writable . end ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "export", "to", "travis", "config"], "add_tokens": "} ; exports . config = config ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Add", "specs", "for", "error", "cases"], "add_tokens": "it ( 'should throw when no ui-select-choices found' , function ( ) { expect ( function ( ) { compileTemplate ( ' \\ < ui-select-match > < / ui-select-match > \\ < / ui-select > ' ) ; } ) . toThrow ( new Error ( '[ui.select:transcluded] Expected 1 .ui-select-choices but got \\'0\\'.' ) ) ; } ) ; it ( 'should throw when no repeat attribute is provided to ui-select-choices' , function ( ) { expect ( function ( ) { compileTemplate ( ' \\ < ui-select-choices > < / ui-select-choices > \\ < / ui-select > ' ) ; } ) . toThrow ( new Error ( '[ui.select:repeat] Expected \\'repeat\\' expression.' ) ) ; } ) ; it ( 'should throw when no ui-select-match found' , function ( ) { expect ( function ( ) { compileTemplate ( ' \\ < ui-select-choices repeat = \"item in items\" > < / ui-select-choices > \\ < / ui-select > ' ) ; } ) . toThrow ( new Error ( '[ui.select:transcluded] Expected 1 .ui-select-match but got \\'0\\'.' ) ) ; } ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "unique", "id", "for", "multiple", "layers"], "add_tokens": "c . id = 'webgl-leaflet-' + L . Util . stamp ( this ) ; } ;", "del_tokens": "c . id = 'webgl-leaflet' ; } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "multiple", "image", "scales"], "add_tokens": "const webpack = require ( \"webpack\" ) ; const path = require ( \"path\" ) ; const fs = require ( \"fs\" ) ;", "del_tokens": "const webpack = require ( 'webpack' ) ; const path = require ( 'path' ) ; const fs = require ( 'fs' ) ; const chalk = require ( 'chalk' ) ; const dedent = require ( 'dedent' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "CSS", "modules", "functionality", "to", "insert", "mode", "."], "add_tokens": "import { fromObject } from \"interlock/lib/util/ast\" ; export default function generateStyleLoaders ( bundles , compiledModules , moduleClassnameMaps ) { RULES : t . stringLiteral ( escape ( module . ast . toString ( ) ) ) , EXPORT_VALUE : moduleClassnameMaps && moduleClassnameMaps [ module . path ] ? fromObject ( moduleClassnameMaps [ module . path ] ) : t . identifier ( \"stylesheet\" )", "del_tokens": "export default function generateStyleLoaders ( bundles , compiledModules ) { RULES : t . stringLiteral ( escape ( module . ast . toString ( ) ) ) // TODO: If in CSS-module mode, make sure that the style-loader // template will export an object that maps written // class names to unique/generated class names.", "commit_type": "add"}
{"commit_tokens": ["Use", "circular", "()", "when", "calling", "stringify", "()", "."], "add_tokens": "record = JSON . stringify ( record , circular ( ) ) ;", "del_tokens": "record = JSON . stringify ( record ) ;", "commit_type": "use"}
{"commit_tokens": ["change", "task", "name", "in", "grunt", "file"], "add_tokens": "src : {", "del_tokens": "ngTranslate : {", "commit_type": "change"}
{"commit_tokens": ["Updated", "lint", "script", "to", "no", "longer", "lint", "mirage", "files"], "add_tokens": "chalk . gray ( '\\nLinting complete!' )", "del_tokens": "chalk . gray ( '\\nlinting complete!' )", "commit_type": "update"}
{"commit_tokens": ["move", "out", "classes", "move", "in", "configs", "expose", "new", "functions"], "add_tokens": "import Webpack from './classes/Webpack' ; module . exports = class UniversalApp { this . config = props ; this . webpack = new Webpack ( { } , this ) ; this . logger . info ( '[Universal App] - Creating instance..' ) / ** * Starts the engine * / this . server . start ( ) ; / ** * Adds routes to the route config * @ param { array } routes [ route , route2 , routefolder , routefolder3 ] * / addRoutes ( routes ) { this . server . addRoutes ( route ) } / ** * Adds a route file or folder to the route config * @ param { string } route path / to / route . js * / addRoute ( route ) { this . server . addRoute ( route ) }", "del_tokens": "class UniversalApp { this . config = new Config ( { } , this ) ; this . server . start ( ) export default new UniversalApp ( )", "commit_type": "move"}
{"commit_tokens": ["Added", "a", "checkStatus", "method", "to", "the", "data", "manager"], "add_tokens": "return mediator . request ( 'sync:manage' , [ datasetId , { } , { } , { } ] )", "del_tokens": "return mediator . request ( 'sync:manage' , datasetId )", "commit_type": "add"}
{"commit_tokens": ["Changed", "API", "to", "support", "transform", "of", "JSX"], "add_tokens": "function ExtendedComponent ( dispatcher , props ) { props . stores . forEach ( function ( store ) { componentStores . push ( store ) ; props . storesDidUpdate ( ) ;", "del_tokens": "function ExtendedComponent ( dispatcher , stores , props ) { props . stores . forEach ( function ( storeName ) { componentStores . push ( typeof storeName === 'string' ? stores [ storeName ] : storeName ) ; if ( props . getInitialState ) { this . getInitialState = function ( ) { return props . getInitialState . apply ( this , componentStores ) ; } ; } props . storesDidUpdate . apply ( this , componentStores ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "issue", "in", "IE", "with", "messaging", "between", "several", "instances", "with", "the", "same", "name"], "add_tokens": "this . latestEventData = undefined && transport . latestEventData !== event . data transport . latestEventData = event . data //fix previous IE double event handling this . latestEventData = undefined", "del_tokens": "var latestEventData && latestEventData !== event . data latestEventData = event . data //fix previous IE double event handling", "commit_type": "fix"}
{"commit_tokens": ["fix", "IE8", "issue", "with", "toString"], "add_tokens": "this . info = \"[Component: #\" + this . pathInfo + \"]\" ; // debug info log . error ( this . info + \" Invalid component reference\" ) ; this . info = \"[Component attribute element: @\" + this . name + \"]\" ; log . error ( this . info + \" Element not supported by its parent component\" ) ; log . error ( this . info + \" Controller property is mandatory for component elements\" ) ; log . error ( this . info + \" Invalid component element type: \" + eltDef . type ) ; log . error ( this . info + \" Attribute elements cannot be used outside components\" ) ;", "del_tokens": "log . error ( this + \" Invalid component reference\" ) ; } , / ** * Helper function used to give contextual error information * @ return { String } - e . g . \"[Component: #foo.bar]\" * / toString : function ( ) { return \"[Component: #\" + this . pathInfo + \"]\" ; log . error ( this + \" Element not supported by its parent component\" ) ; log . error ( this + \" Controller property is mandatory for component elements\" ) ; log . error ( this + \" Invalid component element type: \" + eltDef . type ) ; log . error ( this + \" Attribute elements cannot be used outside components\" ) ; } , / ** * Helper function used to give contextual error information * @ return { String } - e . g . \"[Component attribute element: @body]\" * / toString : function ( ) { return \"[Component attribute element: @\" + this . name + \"]\" ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "new", "records", "module", "version", "."], "add_tokens": "if ( ! keyPropDesc . isScalar ( ) || ( keyPropDesc . scalarValueType === 'object' ) ) for ( let refTarget of propDesc . refTargets ) {", "del_tokens": "if ( ! keyPropDesc . isScalar ( ) || keyPropDesc . isPolymorph ( ) || ( keyPropDesc . scalarValueType === 'object' ) ) for ( let refTarget of propDesc . subtypes ) {", "commit_type": "use"}
{"commit_tokens": ["remove", "AMD", "support", "from", "terraformer"], "add_tokens": "exports = module . exports = factory ( require ( 'terraformer' ) ) ; if ( ! root . Terraformer ) { throw new Error ( \"Terraformer.ArcGIS requires the core Terraformer library. https://github.com/esri/Terraformer\" ) ; root . Terraformer . ArcGIS = factory ( root . Terraformer ) ; } ( this , function ( Terraformer ) {", "del_tokens": "exports = module . exports = factory ( ) ; } // AMD. if ( typeof define === 'function' && define . amd ) { define ( [ \"terraformer/terraformer\" ] , factory ) ; if ( typeof root . Terraformer === \"undefined\" ) { root . Terraformer = { } ; root . Terraformer . ArcGIS = factory ( ) ; } ( this , function ( ) { var Terraformer ; // Local Reference To Browser Global if ( typeof this . navigator === \"object\" ) { Terraformer = this . Terraformer ; } // Setup Node Dependencies if ( typeof module === 'object' && typeof module . exports === 'object' ) { Terraformer = require ( 'terraformer' ) ; } // Setup AMD Dependencies if ( arguments [ 0 ] && typeof define === 'function' && define . amd ) { Terraformer = arguments [ 0 ] ; }", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "default", "data", "for", "-", "c", "and", "-", "d", "flag", "(", "documentation", ")", "and", "version", "bumping"], "add_tokens": ". version ( '0.0.5' )", "del_tokens": ". version ( '0.0.4' )", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "components", "to", "theme", "generator"], "add_tokens": "// Copy the dotfiles. const dotfileBuilder = gulp . src ( path . join ( deckRoot , '.*' ) , srcOpts ) . pipe ( gulp . dest ( newThemeDest ) ) ; // Copy the hooks directory. const hookBuilder = gulp . src ( path . join ( deckRoot , 'hooks' , '**' , '*' ) ) . pipe ( gulp . dest ( path . join ( newThemeDest , 'hooks' ) ) ) ; // Copy the package.json. const packageJsonBuilder = gulp . src ( path . join ( deckRoot , 'package.json' ) ) . pipe ( gulp . dest ( newThemeDest ) ) ; return merge ( assetsBuilder , coreFileBuilder , dotfileBuilder , hookBuilder , packageJsonBuilder ) ;", "del_tokens": "return merge ( assetsBuilder , coreFileBuilder ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "babel", "-", "istanbul", "-", "instrumenter"], "add_tokens": "var Instrumenter = require ( 'istanbul' ) . Instrumenter ; esModules : true ,", "del_tokens": "var Instrumenter = require ( './babel-istanbul-instrumenter' ) ; babel : this . _babelOptions ,", "commit_type": "remove"}
{"commit_tokens": ["Fix", "longstanding", "(", "?", ")", "attachment", "bug"], "add_tokens": "for ( var i = 0 ; i < decrypted . attachments . length ; i ++ ) promises [ i ] = handleAttachment ( decrypted . attachments [ i ] ) ;", "del_tokens": "for ( var i = 0 ; i < decrypted . message . attachments . length ; i ++ ) promises [ i ] = handleAttachment ( decrypted . message . attachments [ i ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "IPv4", "-", "mapped", "IPv6", "addresses"], "add_tokens": "var GROUPS = 8 if ( net . isIPv4 ( groups [ groups . length - 1 ] ) ) { GROUPS = 7 } holes = GROUPS - ( groups . length - 2 ) // ::1 => ['', '', 1] for ( i = 0 ; i < ( GROUPS - holes ) ; ++ i ) { holes = GROUPS - groups . length - 1", "del_tokens": "holes = 8 - ( groups . length - 2 ) // ::1 => ['', '', 1] for ( i = 0 ; i < ( 8 - holes ) ; ++ i ) { holes = 8 - groups . length - 1", "commit_type": "fix"}
{"commit_tokens": ["Add", "skate", "build", "for", "named", "slots"], "add_tokens": "export function polyfill ( elem ) { export function slot ( opts ) { coerce : function ( val ) { 'default' : function ( ) {", "del_tokens": "function polyfill ( elem ) { function slot ( opts ) { coerce : function ( val ) { 'default' : function ( ) {", "commit_type": "add"}
{"commit_tokens": ["added", "support", "with", "propsData", "with", "deprecating", "data", "related", "to", "https", ":", "//", "github", ".", "com", "/", "express", "-", "vue", "/", "vue", "-", "pronto", "/", "issues", "/", "66"], "add_tokens": "this . propsData = options . propsData || { } ; / ** * @ param { Object } oldPropsData * @ param { Object } newPropsData * @ returns { Function } * / FixPropsData ( oldPropsData , newPropsData ) { return Object . assign ( { } , oldPropsData , this . propsData , newPropsData ) ; } * @ param { Object } vueOptions MakeVueClass ( filePath , data , vueOptions = { } ) { if ( vueOptions . propsData && ( cachedBundle . bundle . propsData || cachedBundle . bundle . props ) ) { cachedBundle . bundle . propsData = this . FixPropsData ( cachedBundle . bundle . propsData || { } , vueOptions . propsData ) ; } //Insert propsData if ( vueOptions . propsData && ( bundle . propsData || bundle . props ) ) { bundle . propsData = this . FixPropsData ( bundle . propsData || { } , vueOptions . propsData ) ; } this . MakeVueClass ( filePath , data , vueOptions ) this . MakeVueClass ( filePath , data , vueOptions )", "del_tokens": "MakeVueClass ( filePath , data ) { this . MakeVueClass ( filePath , data ) this . MakeVueClass ( filePath , data )", "commit_type": "add"}
{"commit_tokens": ["use", "query", "-", "string", "package"], "add_tokens": "import queryString from 'query-string' ; const qs = queryString . stringify ( Object . assign ( { s : size } , options ) ) ; if ( qs ) { url += '?' + qs ; }", "del_tokens": "function queryString ( options ) { const str = _ . map ( options , ( val , key ) => key + '=' + encodeURIComponent ( val ) ) . join ( '&' ) ; return str . length > 0 ? '?' + str : str ; } url += queryString ( Object . assign ( { s : size } , options ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "registerStore", "method", "with", "deprecation", "warning"], "add_tokens": "* @ deprecated * @ param { String } id * @ param { Store } store * / registerStore ( id , store ) { console . warn ( 'Deprecation warning: `registerStore` will no longer be supported in 1.1, use `registerStores` instead' ) var stores = { } stores [ id ] = store this . registerStores ( stores ) } / ** * @ param { Store [ ] } stores", "del_tokens": "* @ param { Array . < string , Store > } stores", "commit_type": "add"}
{"commit_tokens": ["Allow", "consumers", "to", "access", "history", "object", "on", "the", "client", "side"], "add_tokens": "var createHistory = require ( 'history' ) . createHistory ; var history ; var location ; history = createHistory ( ) ; location = _window . location . pathname + _window . location . search + _window . location . hash ; history : history return callback && callback ( props , history ) ;", "del_tokens": "var routerHistory = require ( 'history' ) ; var windowLocation = window . location ; var location = windowLocation . pathname + windowLocation . search + windowLocation . hash ; history : routerHistory . createHistory ( ) return callback && callback ( props , router ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "csslinting", "during", "tests", "to", "assert", "that", "generated", "css", "files", "are", "compliant"], "add_tokens": "} , csslint : { options : { import : false } , src : [ 'test/**/*.css' ] grunt . loadNpmTasks ( 'grunt-contrib-csslint' ) ; grunt . registerTask ( 'default' , [ 'clean' , 'jshint' , 'nodeunit' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'clean' , 'jshint' , 'nodeunit' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "Yahoo", "me", "/", "friends"], "add_tokens": "\"me/friends\" : 'http://query.yahooapis.com/v1/yql?q=select%20*%20from%20social.contacts%20where%20guid=me&format=json' } , // Can't get ID's // It might be better to loop through the social.relationshipd table with has unique ID's of users. \"me/friends\" : function ( o ) { var contact , field ; o . data = o . query . results . contact ; for ( var i = 0 ; i < o . data . length ; i ++ ) { contact = o . data [ i ] ; o . data [ i ] . id = null ; for ( var j = 0 ; j < contact . fields . length ; j ++ ) { field = contact . fields [ j ] ; if ( field . type === 'email' ) { o . data [ i ] . email = field . value ; } if ( field . type === 'name' ) { o . data [ i ] . first_name = field . value . givenName ; o . data [ i ] . last_name = field . value . familyName ; o . data [ i ] . name = field . value . givenName + ' ' + field . value . familyName ; } if ( field . type === 'yahooid' ) { o . data [ i ] . id = field . value ; } } } return o ;", "del_tokens": "\"me/friends\" : 'http://query.yahooapis.com/v1/public/yql?q=select%20*%20from%20social.profile%20where%20guid%20in%20(select%20guid%20from%20social.connections%20where%20owner_guid%3Dme)&format=json'", "commit_type": "add"}
{"commit_tokens": ["Update", "all", "dev", "dependencies", "and", "grunt", "file", "to", "be", "compatible", "with", "grunt", "-", "continue"], "add_tokens": "grunt . registerTask ( 'dev' , [ 'build' , 'continue:on' , 'mocha:fail' , 'continue:off' , 'mocha:pass' ] ) ; grunt . registerTask ( 'test' , [ 'build' , 'pass' , 'continue:on' , 'fail' , 'continue:off' ] ) ;", "del_tokens": "grunt . registerTask ( 'dev' , [ 'build' , 'continueOn' , 'mocha:fail' , 'continueOff' , 'mocha:pass' ] ) ; grunt . registerTask ( 'test' , [ 'build' , 'pass' , 'continueOn' , 'fail' , 'continueOff' ] ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "breaking", "upstream", "arraytools", "change"], "add_tokens": "var at = require ( 'arraytools' ) } throw new Error ( spec . colormap + * map x axis point from 0 - > 1 to 0 - > n return result", "del_tokens": "var at = require ( 'arraytools' ) ( ) } throw new Error ( spec . colormap + * map x axis point from 0 - > 1 to 0 - > n return result", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "changes", "to", "scripter"], "add_tokens": "function ButtonObject ( ) { } ; var invoke = function ( method , params ) { var create = function ( obj_class , obj_name , serialized ) { self . postMessage ( JSON . stringify ( { \"action\" : \"AssignObject\" , \"name\" : obj_name , \"class\" : obj_class , \"serialized\" : serialized } ) ) ; } ; invoke ( \"alert\" , [ msg ] ) ; } ; this . createButton = function ( data ) { var button = new ButtonObject ( data ) ; create ( \"button\" , \"ButttonObject\" , \"{}\" ) ; return button ;", "del_tokens": "this . invoke = function ( method , params ) { this . invoke ( \"alert\" , [ msg ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "session", ".", "storage", "format"], "add_tokens": "if ( session . userAddress && session . storage && session . storage . davToken && session . cryptoPwdForRead ) { //coming back session . storage = { userAddress : session . userAddress , davUrl : davUrl , storageType : 'http://unhosted.org/spec/dav/0.1' } window . location = session . storage . davUrl", "del_tokens": "if ( session . userAddress && session . davUrl && session . davToken && session . cryptoPwdForRead ) { //coming back session . davUrl = davUrl session . storageType = 'http://unhosted.org/spec/dav/0.1' window . location = session . davUrl", "commit_type": "fix"}
{"commit_tokens": ["adding", "testing", "file", "and", "updated", "some", "functions"], "add_tokens": "var currDate = moment ( this . firstPaymentDate ( loan . closingDate ) ) ; var tempDate , tempDay , balloonPeriod , balloonAmount , payment , balance ; interestRate = interestRate / 100 ;", "del_tokens": "var currDate = loan . firstPaymentDate && ! _ . isEmpty ( loan . firstPaymentDate ) && firstPaymentDate . constructor === Date ? moment ( firstPaymentDate ) : moment ( ) ; var tempDate , tempDay , balloonPeriod , balloonAmount , payment , balance ; var interestRate = interestRate / 100 ; loan . interestRate", "commit_type": "add"}
{"commit_tokens": ["Fix", "event", "target", "focusing", "issue"], "add_tokens": "//target to dragstart off ( self . dragTarget , 'focus' + self . _ns ) ; self . dragTarget = null ; self . currentHandles = q . all ( self . handle ) ; //abort drag if target being focused self . dragTarget = e . target ; on ( self . dragTarget , 'focus' + self . _ns , function ( ) { self . state = 'idle' ; off ( self . dragTarget , 'focus' + self . _ns ) ; self . dragTarget = null ; } ) ; if ( doc . activeElement === e . target ) { return ; } // e.preventDefault();", "del_tokens": "self . currentHandles = q . all ( self . handle ) ; //bind start drag to each handle if ( doc . activeElement === e . target ) return ; e . preventDefault ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "custom", "runtime", "image"], "add_tokens": "image , if ( image || env || memory ) { if ( image ) { container . image = image ; } description . image ,", "del_tokens": "if ( env || memory ) {", "commit_type": "add"}
{"commit_tokens": ["added", "a", "negative", "db", "test", "for", "method", "none", "."], "add_tokens": "var result , error ; } , function ( reason ) { error = reason ; expect ( error ) . toBe ( undefined ) ; describe ( \"Return data from a query must match the request type\" , function ( ) { it ( \"method 'none' must throw an error when there was data returned\" , function ( ) { var result , error ; db . none ( \"select 123\" ) . then ( function ( data ) { result = data ; } , function ( reason ) { result = null ; error = reason ; } ) ; waitsFor ( function ( ) { return result !== undefined ; } , \"Query timed out\" , 5000 ) ; runs ( function ( ) { expect ( result ) . toBe ( null ) ; expect ( error ) . toBe ( \"No return data was expected from query: select 123\" ) ; } ) ; } ) ; } ) ;", "del_tokens": "var result ; } , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "return", "to", "try", "/", "catch", "blocks", "that", "end", "a", "function"], "add_tokens": "} else if ( nodeList [ lastIndex ] . type === 'TryStatement' ) { nodeList [ lastIndex ] = addReturnStatementsToTryCatch ( nodeList [ lastIndex ] ) ; if ( ! hasReturnStatement ) { node . body = lastReturnStatement ( node . body ) ; } return node ; } function addReturnStatementsToTryCatch ( node ) { node . block = addReturnStatementToBlock ( node . block ) ; if ( node . handler ) { node . handler . body = addReturnStatementToBlock ( node . handler . body ) ;", "del_tokens": "if ( hasReturnStatement ) { return node ; node . body = lastReturnStatement ( node . body ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "Font", "Alignment", "when", "applied", "directly", "to", "a", "Cell"], "add_tokens": "Alignment : { cellRange : that , Vertical : formatter . font . alignment . vertical , Horizontal : formatter . font . alignment . horizontal } vertical : function ( val ) { horizontal : function ( val ) { tmpStyle . Font . Alignment . Horizontal ( val ) ;", "del_tokens": "Alignment : formatter . font . alignment Vertical : function ( val ) { Horizontal : function ( ) { tmpStyle . Alignment . Horizontal ( val ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "systemStatus", "()", "to", "see", "if", "binance", "is", "down"], "add_tokens": "publicRequest ( wapi + 'v3/systemStatus.html' , { } , callback ) ; } ,", "del_tokens": "publicRequest ( wapi + 'v3/systemStatus.html' , { } , callback ) ; } ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "cache", "permission", "while", "unpacking"], "add_tokens": "var isWin = / ^win / . test ( process . platform ) ; umask : ( isWin ? false : 0 ) ,", "del_tokens": "umask : 0 ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "json", "and", "semicolon", "errors"], "add_tokens": "next ( ) ; next ( ) ; next ( ) ;", "del_tokens": "next ( ) next ( ) next ( )", "commit_type": "fix"}
{"commit_tokens": ["moved", "public", "part", "to", "public", "-", "server", "-", ">", "min", "dependencies"], "add_tokens": "var HiddenServer = require ( '../index' ) ; obj . response = \"are you sure about: \" + obj . command ;", "del_tokens": "var HiddenServer = require ( '../index' ) ( 'hidden' ) ; obj . response = Math . random ( ) ; obj . add = \"plus\" ; obj . sub = \"subtrahieren\" ; obj . command = obj . command + \"What?\" ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "bug", "for", "assigning", "vs", "cloning", "cards"], "add_tokens": "let eCard = this . card . clone ( ) ; eCard = cardConstraints [ cardConstraints . length - 1 ] . card . clone ( ) ;", "del_tokens": "let eCard = this . card ; eCard = cardConstraints [ cardConstraints . length - 1 ] . card ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "host", "/", "port", "configuration"], "add_tokens": "this . host = options . host || 'localhost' ; this . httpPort = options . httpPort || '8500' ; options . protocol = 'http:' ; options . hostname = this . host ; options . port = this . httpPort ; options . path = '/v1' + options . path ;", "del_tokens": "var parseUrl = require ( 'url' ) . parse ; this . url = parseUrl ( options . url || 'http://localhost:8500/v1' ) ; // url options . protocol = this . url . protocol ; options . hostname = this . url . hostname ; if ( this . url . port ) options . port = this . url . port ; options . path = this . url . path + options . path ;", "commit_type": "use"}
{"commit_tokens": ["fixes", "failures", "from", "newer", "nodes", "/", "npms"], "add_tokens": "var spawn = require ( 'child_process' ) . spawn let p = spawn ( 'npm' , [ 'ci' , '--ignore-scripts' ] , { cwd : lock , shell : true , } ) p . on ( 'close' , function win ( ) { } ) p . on ( 'error' , function fail ( err ) { callback ( err )", "del_tokens": "var Installer = require ( 'cipm' ) let installer = new Installer ( { prefix : lock } ) installer . run ( ) . then ( function _success ( ) { } ) . catch ( function _fail ( err ) { // log any cipm failures but continue anyhow console . log ( chalk . red ( pathToCode ) ) console . log ( chalk . red ( err ) ) callback ( )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "syntax", "checking", "for", "quick_replies"], "add_tokens": "} if ( [ 'text' , 'location' ] . indexOf ( options . content_type ) == - 1 ) { let error = ' required when \"content_type\" is \"text\"' ; console . error ( '\"title\"' + error ) ; } else if ( ! options . payload ) { console . error ( '\"payload\"' + error ) ; return ;", "del_tokens": "} else if ( [ 'text' , 'location' ] . indexOf ( options . content_type ) == - 1 ) { console . error ( '\"title\" required when \"content_type\" is \"text\"' ) ; return ; } if ( ! options . payload ) { console . error ( '\"payload\" required when \"content_type\" is \"text\"' ) ; return ;", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "for", "mappingCSV"], "add_tokens": "to : { memberSet : [ { notation : [ \"a'c\" ] , prefLabel : { en : \"0\" } } , { notation : [ \"b\\\" d\\\"\" ] , prefLabel : { en : \"1 and some\" } } ] } , optionsNone : \"\\\"0\\\",\\\"a'c\\\",\\\"b\\\"\\\" d\\\"\\\"\\\",\\\"\\\"\\n\" , optionsAllColumns : \"\\\"\\\",\\\"0\\\",\\\"'\\\",\\\"\\\",\\\"a'c\\\",\\\"0\\\",\\\"b\\\"\\\" d\\\"\\\"\\\",\\\"1 and some\\\",\\\"\\\",\\\"someone\\\"\\n\" , optionsOther : \"'0';'a''c';'b\\\" d\\\"';''\\n\" , optionsNone : \"\\\"fromNotation\\\",\\\"toNotation\\\",\\\"toNotation2\\\",\\\"type\\\"\\n\\\"0\\\",\\\"a'c\\\",\\\"\\\",\\\"broad\\\"\\n\\\"0\\\",\\\"a'c\\\",\\\"b\\\"\\\" d\\\"\\\"\\\",\\\"\\\"\\n\" , optionsAllColumns : \"\\\"fromScheme\\\",\\\"fromNotation\\\",\\\"fromLabel\\\",\\\"toScheme\\\",\\\"toNotation\\\",\\\"toLabel\\\",\\\"toNotation2\\\",\\\"toLabel2\\\",\\\"type\\\",\\\"creator\\\"\\n\\\"A\\\",\\\"0\\\",\\\"'\\\",\\\"B\\\",\\\"a'c\\\",\\\"0\\\",\\\"\\\",\\\"\\\",\\\"broad\\\",\\\"\\\"\\n\\\"\\\",\\\"0\\\",\\\"'\\\",\\\"\\\",\\\"a'c\\\",\\\"0\\\",\\\"b\\\"\\\" d\\\"\\\"\\\",\\\"1 and some\\\",\\\"\\\",\\\"someone\\\"\\n\" , optionsOther : \"'fromNotation';'toNotation';'toNotation2';'type'\\n'0';'a''c';'';'broad'\\n'0';'a''c';'b\\\" d\\\"';''\\n\" ,", "del_tokens": "to : { memberSet : [ { notation : [ \"a'c\" ] , prefLabel : { en : \"0\" } } , { notation : [ \"b\\\"d\\\"\" ] , prefLabel : { en : \"1\" } } ] } , optionsNone : \"\\\"0\\\",\\\"a'c\\\",\\\"b\\\"\\\"d\\\"\\\"\\\",\\\"\\\"\\n\" , optionsAllColumns : \"\\\"\\\",\\\"0\\\",\\\"'\\\",\\\"\\\",\\\"a'c\\\",\\\"0\\\",\\\"b\\\"\\\"d\\\"\\\"\\\",\\\"1\\\",\\\"\\\",\\\"someone\\\"\\n\" , optionsOther : \"'0';'a''c';'b\\\"d\\\"';''\\n\" , optionsNone : \"\\\"fromNotation\\\",\\\"toNotation\\\",\\\"toNotation2\\\",\\\"type\\\"\\n\\\"0\\\",\\\"a'c\\\",\\\"\\\",\\\"broad\\\"\\n\\\"0\\\",\\\"a'c\\\",\\\"b\\\"\\\"d\\\"\\\"\\\",\\\"\\\"\\n\" , optionsAllColumns : \"\\\"fromScheme\\\",\\\"fromNotation\\\",\\\"fromLabel\\\",\\\"toScheme\\\",\\\"toNotation\\\",\\\"toLabel\\\",\\\"toNotation2\\\",\\\"toLabel2\\\",\\\"type\\\",\\\"creator\\\"\\n\\\"A\\\",\\\"0\\\",\\\"'\\\",\\\"B\\\",\\\"a'c\\\",\\\"0\\\",\\\"\\\",\\\"\\\",\\\"broad\\\",\\\"\\\"\\n\\\"\\\",\\\"0\\\",\\\"'\\\",\\\"\\\",\\\"a'c\\\",\\\"0\\\",\\\"b\\\"\\\"d\\\"\\\"\\\",\\\"1\\\",\\\"\\\",\\\"someone\\\"\\n\" , optionsOther : \"'fromNotation';'toNotation';'toNotation2';'type'\\n'0';'a''c';'';'broad'\\n'0';'a''c';'b\\\"d\\\"';''\\n\" ,", "commit_type": "add"}
{"commit_tokens": ["Added", "attr", "(", "key", "value", ")", "for", "masochists"], "add_tokens": "elproto . attr = function ( params , value ) { var el = this , node = el . node ; return el ; if ( arguments . length > 1 ) { var json = { } ; json [ params ] = value ; params = json ; } else { return arrayFirstValue ( eve ( \"savage.util.getattr.\" + params , el ) ) ; } eve ( \"savage.util.attr.\" + att , el , params [ att ] ) ; return el ; * Creates clone of the element and inserts it after the element . = ( Element ) the clone", "del_tokens": "elproto . attr = function ( params ) { var node = this . node ; return this ; return arrayFirstValue ( eve ( \"savage.util.getattr.\" + params , this ) ) ; eve ( \"savage.util.attr.\" + att , this , params [ att ] ) ; return this ; * Creates ` ` element linked to the current element . = ( Element ) ` ` element", "commit_type": "add"}
{"commit_tokens": ["adding", "ability", "to", "add", "roots", "to", "common", "js", "project", "plus", "a", "fix", "to", "how", "projects", "are", "created"], "add_tokens": "CommonJsProject . prototype . addRoot = function ( root ) { this . roots . push ( root ) ; } ; if ( ! isDirectory ( obj . root ) ) { obj . project = new CommonJsProject ( [ obj . root ] ) ;", "del_tokens": "if ( ! isFile ( obj . root ) ) { obj . project = new CommonJsProject ( { unknown : obj . root } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "deleting", "arrow", "function", "exports"], "add_tokens": "node . right . type === 'AssignmentExpression' || // Don't output a statement containing only `void () => {}` node . right . type === 'ArrowFunctionExpression' ) {", "del_tokens": "node . right . type === 'AssignmentExpression' ) {", "commit_type": "fix"}
{"commit_tokens": ["remove", "stuff", "that", "should", "not", "be", "in", "git", "+", "remove", "log", "message"], "add_tokens": "import { webComponentBaseClass } from '../../dist/webComponentBaseClass.js' ;", "del_tokens": "import { webComponentBaseClass } from '../../src/webComponentBaseClass.js' ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "alignment", "in", "activity", "output"], "add_tokens": "_ . padRight ( deployment . action , 9 ) + \" \" + // longest action name is downscale", "del_tokens": "_ . padRight ( deployment . action , 8 ) + \" \" +", "commit_type": "fix"}
{"commit_tokens": ["fix", "empty", "req", "body", "and", "broken", "bitbucket"], "add_tokens": "if ( req . method !== 'POST' ) { res . end ( ) ; return ; } res . end ( ) ; var source = ipaddr . parse ( req . ip ) ; if ( ! source . match ( configured ) ) { if ( ! tmp . push ) {", "del_tokens": "res . end ( ) ; if ( req . method !== 'POST' ) return ; if ( ! tmp . match ( configured ) ) { if ( ! body . push ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "react", "-", "native", "env", "issue"], "add_tokens": "return this . __onComplete ( _XHR ) , _defer . promise ;", "del_tokens": "return this . __onComplete ( _XHR ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "safeguard", "to", "prefer", "-", "compact"], "add_tokens": "return ( func && func . type === 'Identifier' && func . name === 'Boolean' ) ||", "del_tokens": "return ( func . type === 'Identifier' && func . name === 'Boolean' ) ||", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "extra", "parameter", "for", "array", "of", "fields"], "add_tokens": "modelFields += '\\t\\'' + field . name + '\\' : ' + ( field . array ? '[' : '' ) + ( allowedFieldsTypes [ field . type ] ) . name + ( field . array ? ']' : '' ) ;", "del_tokens": "modelFields += '\\t\\'' + field . name + '\\' : ' + ( allowedFieldsTypes [ field . type ] ) . name ;", "commit_type": "add"}
{"commit_tokens": ["added", "fix", "for", "when", "snowplow", "is", "not", "defined"], "add_tokens": "var sp = typeof snowplow === 'undefined' ? noop : snowplow ; if ( data . u ) sp ( 'setUserId' , data . u ) ; sp ( 'trackUnstructEvent' , { } ; function noop ( event , data ) { console . info ( 'snowplow' , event , data ) ; }", "del_tokens": "if ( data . u ) snowplow ( 'setUserId' , data . u ) ; snowplow ( 'trackUnstructEvent' , { } ;", "commit_type": "add"}
{"commit_tokens": ["added", "stoponerror", "and", "stoponwarning", "options"], "add_tokens": "var merge = require ( 'merge' ) ; var hasError = false , hasWarning = false ; options = merge ( { disabledIds : [ ] , stoponwarning : false , stoponerror : false } , options ) ; var isError = ( lint . id [ 0 ] === 'E' ) , isWarning = ( lint . id [ 0 ] === 'W' ) , lintId = ( isError ) ? chalk . bgRed . white ( lint . id ) : chalk . bgYellow . white ( lint . id ) , if ( isError ) { hasError = true ; } if ( isWarning ) { hasWarning = true ; } if ( ( hasWarning && options . stoponwarning ) || ( hasError && options . stoponerror ) ) {", "del_tokens": "options = options || { disabledIds : [ ] } ; var hasError = false ; var lintId = ( lint . id [ 0 ] === 'E' ) ? chalk . bgRed . white ( lint . id ) : chalk . bgYellow . white ( lint . id ) , hasError = true ; if ( hasError ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "css_property_names_extra", "to", "lib", "and", "add", "fallback", "for", "not", "implemented", "properties"], "add_tokens": "var allExtraProperties = require ( './allExtraProperties' ) ; var getBasicPropertyDescriptor = require ( './utils/getBasicPropertyDescriptor' ) ; var declaration = getBasicPropertyDescriptor ( property ) ; Object . defineProperty ( CSSStyleDeclaration . prototype , property , declaration ) ; Object . defineProperty ( CSSStyleDeclaration . prototype , dashedToCamelCase ( property ) , declaration ) ; } } ) ; allExtraProperties . forEach ( function ( property ) { if ( ! implementedProperties . has ( property ) ) { var declaration = getBasicPropertyDescriptor ( property ) ;", "del_tokens": "var declaration = { set : function ( v ) { this . _setProperty ( property , v ) ; } , get : function ( ) { return this . getPropertyValue ( property ) ; } , enumerable : true , configurable : true , } ;", "commit_type": "move"}
{"commit_tokens": ["Added", "test", "case", ";", "prevented", "elementType", "from", "being", "inherited", "by", "children", "(", "this", "makes", "no", "sense", ")"], "add_tokens": "delete options . elementType ; /// element type is not inherited by child, but elementFactory is. TODO: document module . exports = Options ;", "del_tokens": "module . exports = Options ;", "commit_type": "add"}
{"commit_tokens": ["Added", "SDK", "version", "and", "variant", "in", "HTTP", "headers"], "add_tokens": "/* globals VERSION */ 'Authorization' : that . getAuthorizationHeader ( ) , 'X-sdk-variant' : 'javascript' , 'X-sdk-version' : VERSION", "del_tokens": "Authorization : that . getAuthorizationHeader ( )", "commit_type": "add"}
{"commit_tokens": ["add", "a", "simplified", "syntax", "for", "defining", "overrides", "on", "components", "alone"], "add_tokens": "function getTag ( tag , overrides ) { const override = get ( overrides , tag ) ; return typeof override === 'function' ? override : get ( overrides , ` ${ tag } ` , tag ) ; } return React . createElement ( getTag ( tag , options . overrides ) , { ... overrideProps , ... props , className : cx ( props && props . className , overrideProps . className ) || undefined , } , ... children ) ;", "del_tokens": "return React . createElement ( get ( options . overrides , ` ${ tag } ` , tag ) , { ... overrideProps , ... props , className : cx ( props && props . className , overrideProps . className ) || undefined , } , ... children ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "mock", "nested", "services", "like", "DynamoDB", ".", "DocumentClient", "though", "care", "must", "be", "taken", "when", "mocking", "a", "nested", "service", "and", "its", "parent", "."], "add_tokens": "var traverse = require ( 'traverse' ) ; / ** * Save the real constructor so we can invoke it later on . * Uses traverse for easy access to nested services ( dot - separated ) * / services [ service ] . Constructor = traverse ( _AWS ) . get ( service . split ( '.' ) ) ; var nestedServices = service . split ( '.' ) ; var method = nestedServices . pop ( ) ; var object = traverse ( _AWS ) . get ( nestedServices ) ; var serviceStub = sinon . stub ( object , method , function ( args ) {", "del_tokens": "// Save the real constructor so we can invoke it later on. services [ service ] . Constructor = _AWS [ service ] ; var serviceStub = sinon . stub ( _AWS , service , function ( args ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "only", "one", "compilation", "mode", ":", "Advanced"], "add_tokens": "function compile ( ) { compilation_level : 'ADVANCED_OPTIMIZATIONS' , js_output_file : 'erste.js' gulp . task ( 'compile' , compile ) ; gulp . task ( 'watch' , ( ) => watch ( './src/**/*.js' , compile ) ) ; gulp . task ( 'default' , [ 'clean' , 'compile' ] ) ;", "del_tokens": "function compile ( advanced = false ) { const compilationLevel = advanced ? 'ADVANCED_OPTIMIZATIONS' : 'SIMPLE_OPTIMIZATIONS' ; const outputFile = advanced ? 'erste.min.js' : 'erste.js' ; compilation_level : compilationLevel , js_output_file : outputFile if ( ! advanced ) options . formatting = 'PRETTY_PRINT' ; gulp . task ( 'compile:simple' , compile . bind ( null , false ) ) ; gulp . task ( 'compile:advanced' , compile . bind ( null , true ) ) ; gulp . task ( 'watch:simple' , ( ) => watch ( './src/**/*.js' , ( ) => compile ( false ) ) ) ; gulp . task ( 'watch:advanced' , ( ) => watch ( './src/**/*.js' , ( ) => compile ( ) ) ) ; gulp . task ( 'default' , [ 'clean' , 'compile:simple' , 'compile:advanced' ] ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "closing", "tooltip", "when", "interacting", "with", "a", "select", "inside"], "add_tokens": "if ( ( this . options . touchDevices ) && ( touchDevice ) && ( ( this . options . trigger == 'click' ) || ( this . options . trigger == 'hover' ) ) ) { if ( this . options . interactive ) { if ( keepAlive ) { tooltipster . mouseleave ( function ( e ) { if ( e . target . tagName !== 'SELECT' && e . target . tagName !== 'OPTION' ) { object . hideTooltip ( ) ; }", "del_tokens": "if ( ( this . options . touchDevices == true ) && ( touchDevice ) && ( ( this . options . trigger == 'click' ) || ( this . options . trigger == 'hover' ) ) ) { if ( this . options . interactive == true ) { if ( keepAlive == true ) { tooltipster . mouseleave ( function ( ) { object . hideTooltip ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "projector", "with", "default", "projection"], "add_tokens": "this . _projection = projector . util . cleanProjString ( options . projection || \"EPSG:4326\" ) ;", "del_tokens": "this . _projection = projector . util . cleanProjString ( options . projection ) || \"EPSG:4326\" ; //\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs\";", "commit_type": "fix"}
{"commit_tokens": ["adding", "ping", "and", "remove", "subscription"], "add_tokens": "let create = function ( change , data ) { } let destroy = function ( data ) { return data . cursor . close ( ) } this . subscriptionSetup ( info , create , destroy ) unsubscribe : { type : 'Boolean' , args : { subscriber : 'String' } , resolve ( source , args , context , info ) { return this . subscriptionRemove ( args ) } } ,", "del_tokens": "this . subscriptionSetup ( info , function ( change , data ) { } )", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "improvements", "and", "documentation"], "add_tokens": "* Function for getting the width in meters dynamically by zoom / ** * Function for getting the cap statically * * @ param { object } c3ss compiled carto css * @ returns { string } with cap value Ex : round * / / ** * Function for getting the join statically * * @ param { object } c3ss compiled carto css * @ returns { string } with join value Ex : round * / / ** * Function for getting the blend statically * * @ param { object } c3ss compiled carto css * @ returns { string } with blending value Ex : \"multiply\" * / const getBlending = R . compose ( / ** * Function for getting dash value statically * * @ param { object } c3ss compiled carto css * @ returns { string } with dash value Ex : [ 2 , 1 ] * / blend : getBlending ( c3ss ) ,", "del_tokens": "* Function for get the width in meters dynamically by zoom const getBlend = R . compose ( blend : getBlend ( c3ss ) ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "detox", "-", "server", "crashes", "after", "stressful", "tests", "."], "add_tokens": "const json = JSON . stringify ( { } ) + '\\n ' _ws . send ( json ) ;", "del_tokens": "_ws . send ( JSON . stringify ( { } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "packing", "methods", "onto", "config"], "add_tokens": "const { packEncryptedText , unpackEncryptedText } = require ( \"../../dist/base/packing.js\" ) ; describe ( \"packEncryptedText\" , function ( ) { const output = packEncryptedText ( { describe ( \"unpackEncryptedText\" , function ( ) { this . packed = packEncryptedText ( { const unpacked = unpackEncryptedText ( this . packed ) ;", "del_tokens": "const { packEncryptedContent , unpackEncryptedContent } = require ( \"../../dist/base/packing.js\" ) ; describe ( \"packEncryptedContent\" , function ( ) { const output = packEncryptedContent ( { describe ( \"unpackEncryptedContent\" , function ( ) { this . packed = packEncryptedContent ( { const unpacked = unpackEncryptedContent ( this . packed ) ;", "commit_type": "move"}
{"commit_tokens": ["Move", "to", "a", "saner", "class", "hierarchy", "for", "nodes"], "add_tokens": "export { $fromJSON , $node , $text , nodeTypes , NodeType , findConnection , compareMarkup } from \"./node\"", "del_tokens": "export { $node , $text , Node , Span , nodeTypes , NodeType , findConnection } from \"./node\"", "commit_type": "move"}
{"commit_tokens": ["fix", "seconds", "lost", "in", "datetime"], "add_tokens": "for ( var i = 0 ; i < 60 ; i ++ ) minutes . push ( formatNumber ( i ) ) ;", "del_tokens": "for ( var i = 0 ; i < 59 ; i ++ ) minutes . push ( formatNumber ( i ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "unqualified", "function", "calls", "received", "wrong", "this", "object", "."], "add_tokens": "var oldCalleePath = path . get ( \"callee\" ) ; var newCallee = self . explodeExpression ( oldCalleePath ) ; // If the callee was not previously a MemberExpression, then the // CallExpression was \"unqualified,\" meaning its `this` object should // be the global object. If the exploded expression has become a // MemberExpression, then we need to force it to be unqualified by // using the (0, object.property)(...) trick; otherwise, it will // receive the object of the MemberExpression as its `this` object. if ( ! n . MemberExpression . check ( oldCalleePath . node ) && n . MemberExpression . check ( newCallee ) ) { newCallee = b . sequenceExpression ( [ b . literal ( 0 ) , newCallee ] ) ; } newCallee ,", "del_tokens": "self . explodeExpression ( path . get ( \"callee\" ) ) ,", "commit_type": "fix"}
{"commit_tokens": ["Updated", ":", "event", "handler", "function", "props"], "add_tokens": "onBeforeNavigation : React . PropTypes . func , onNavigation : React . PropTypes . func onBeforeNavigation : emptyFunction , onNavigation : emptyFunction this . props . onBeforeNavigation ( path ) ; this . replaceState ( { prefix : this . state . prefix , this . props . onNavigation . apply ( this , arguments ) ; } . bind ( this ) ) ;", "del_tokens": "eventHandler : React . PropTypes . oneOfType ( [ React . PropTypes . func , React . PropTypes . shape ( { emit : React . PropTypes . func } ) ] ) eventHandler : emptyFunction var handler = this . props . eventHandler ; ( handler . emit || handler ) . call ( handler , events . start , path ) ; var self = this ; self . replaceState ( { prefix : self . state . prefix , var handler = self . props . eventHandler ; ( handler . emit || handler ) . call ( handler , events . success , path ) ; } ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "step", "value", "on", "the", "ticks"], "add_tokens": "files : [ 'dist/*' , 'demo/*' ] ,", "del_tokens": "files : [ 'dist/*' ] ,", "commit_type": "add"}
{"commit_tokens": ["Moved", "grid", "drawing", "to", "TimelineView"], "add_tokens": "vp . draw ( ctx , viewLWorld , viewRWorld , canvasH ) ;", "del_tokens": "if ( vp . gridEnabled ) { var x = vp . gridTimebase ; ctx . beginPath ( ) ; while ( x < viewRWorld ) { if ( x >= viewLWorld ) { // Do conversion to viewspace here rather than on // x to avoid precision issues. var vx = vp . xWorldToView ( x ) ; ctx . moveTo ( vx , 0 ) ; ctx . lineTo ( vx , canvasH ) ; } x += vp . gridStep ; } ctx . strokeStyle = 'rgba(255,0,0,0.25)' ; ctx . stroke ( ) ; }", "commit_type": "move"}
{"commit_tokens": ["Adds", "class", "support", "to", "columns"], "add_tokens": "rowHTML += '<td' ; if ( column . class ) rowHTML += ' class=\"' + column . class + '\"' ; rowHTML += '>' + row [ column . property ] + '</td>' ;", "del_tokens": "rowHTML += '<td>' + row [ column . property ] + '</td>' ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "sorting", "of", "unsorted", "maps"], "add_tokens": "debug ( 'ElementFactory.createElement' , props , options ) ; if ( ! options . sorted ) { debug ( \"sorting\" ) map = Array . from ( map ) . sort ( ( a , b ) => utils . compare ( a , b , options ) ) ; } debug ( \"merge\" , element_options ) ;", "del_tokens": "//debug('ElementFactory.createElement', props, options); if ( ! options . sorted ) map = Array . from ( map ) . sort ( ( a , b ) => ( a , b , options ) ) ; debug ( \"merge\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "hmac", "(", "bcrypt", ")", "to", "pbkdf2", "for", "password", "encoding"], "add_tokens": "app . use ( middleware . authenticate ( ) ) ; console . log ( 'Listening at http://%s:%d' , settings . HOST , settings . PORT ) ;", "del_tokens": "app . use ( middleware . authenticate ( ) ) console . log ( 'Listening at http://localhost:8080' ) ;", "commit_type": "change"}
{"commit_tokens": ["removing", "defaultValue", "prop", "from", "being", "passed", "down", "to", "actual", "component"], "add_tokens": "let cleanedProps = { ... props } ; delete cleanedProps . defaultValue ;", "del_tokens": "const cleanedProps = { ... props } ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "filepath", "for", "Windows", "OS"], "add_tokens": "var prefix = requirePath . substring ( 0 , requirePath . indexOf ( 'red.js' ) ) ; context = require ( prefix + \"runtime/nodes/context\" ) ; comms = require ( prefix + \"api/editor/comms\" ) ; credentials = require ( prefix + \"runtime/nodes/credentials\" ) ;", "del_tokens": "var prefix = requirePath . substring ( 0 , requirePath . indexOf ( '/red.js' ) ) ; context = require ( prefix + \"/runtime/nodes/context\" ) ; comms = require ( prefix + \"/api/editor/comms\" ) ; credentials = require ( prefix + \"/runtime/nodes/credentials\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "test", "for", "writeable", "streams"], "add_tokens": "rimraf = require ( \"rimraf\" ) . sync , waitOn = require ( \"wait-on\" ) ; function waitOnFile ( filename ) { return new Promise ( function ( resolve , reject ) { waitOn ( { resources : [ filename ] , interval : 50 , timeout : 500 , window : 0 } , function ( err ) { if ( err ) { return reject ( err ) ; } return resolve ( ) ; } ) ; } ) ; } // stupid stream needs time to close probably.. waitOnFile ( TARGET_FILE ) . then ( resolve , reject ) ;", "del_tokens": "rimraf = require ( \"rimraf\" ) . sync ; // stupid stream needs time to close probably..  setTimeout ( resolve , 150 ) ;", "commit_type": "improve"}
{"commit_tokens": ["changed", "target", "name", "in", "the", "qa", "target"], "add_tokens": "grunt . registerTask ( 'qa' , [ 'jshint' ] ) ;", "del_tokens": "grunt . registerTask ( 'qa' , [ 'lint' ] ) ;", "commit_type": "change"}
{"commit_tokens": ["Using", "TimeUnit", "nearly", "everywhere", "already", ".", "Only", "configuration", "remains", "to", "be", "adjusted"], "add_tokens": "if ( this . timers [ i ] . dueTime . isLongerThan ( timer . dueTime ) ) {", "del_tokens": "if ( Math . round ( this . timers [ i ] . dueTime . toMilliseconds ( ) ) > Math . round ( timer . dueTime . toMilliseconds ( ) ) ) {", "commit_type": "use"}
{"commit_tokens": ["Remove", "underbar", "from", "_padding", "."], "add_tokens": "patternIndex , _context = definition . context || this , padding , _callback ; padding = null ; padding = field . padding if ( field . endianness == \"x\" && padding == null ) { if ( padding != null ) { value = padding ; padding = pattern [ patternIndex ] . padding padding = null ;", "del_tokens": "patternIndex , _context = definition . context || this , _padding , _callback ; _padding = null ; _padding = field . padding if ( field . endianness == \"x\" && _padding == null ) { if ( _padding != null ) { value = _padding ; _padding = pattern [ patternIndex ] . padding _padding = null ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "filecompiler", "to", "write", ".", "traceur", ".", "js"], "add_tokens": "var path = require ( 'path' ) ; filename = path . join ( path . dirname ( process . argv [ 1 ] ) , filename ) ; if ( result . errors . hadError ( ) ) { console . log ( 'Compilation of ' + filename + ' failed.' ) ; filename = path . basename ( filename , 'js' ) + '.traceur.js' ; fs . writeFileSync ( filename + '.traceur' , new Buffer ( result . result ) ) ;", "del_tokens": "if ( result . errors . length > 0 ) { console . warn ( 'Traceur compilation errors' , result . errors ) ; fs . writeFileSync ( filename , new Buffer ( result . result ) ) ; console . log ( 'WARNING: files are modified in place.' ) ;", "commit_type": "change"}
{"commit_tokens": ["Change", "TeoriaNote#valueName", "to", "TeoriaNote#durationName", "and", "finished", "the", "documentation", "of", "the", "TeoriaNote", "object"], "add_tokens": "durationName : function ( ) {", "del_tokens": "valueName : function ( ) {", "commit_type": "change"}
{"commit_tokens": ["fixed", "cpu", "-", "load", "example"], "add_tokens": "var used = 0 ; used += cpu . times . irq ; used += cpu . times . nice ; used += cpu . times . sys ; used += cpu . times . user ; used : used var idleDiff = currentCpuInfo . idle - cpuInfo . idle ; var usedDiff = currentCpuInfo . used - cpuInfo . used ; var usage = ( usedDiff / ( usedDiff + idleDiff ) ) * 100 ; return usage ; blinkt . setPixel ( i , red , green , blue ) ; } , 100 ) ;", "del_tokens": "var irq = 0 ; var nice = 0 ; var sys = 0 ; var user = 0 ; irq += cpu . times . irq ; nice += cpu . times . nice ; sys += cpu . times . sys ; user += cpu . times . user ; total : idle + irq + nice + sys + user var idle = currentCpuInfo . idle - cpuInfo . idle ; var total = currentCpuInfo . total - cpuInfo . total ; var usage = idle / total ; return 1 - usage ; } , 1000 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "with", "&numsort", "or", "&lexsort", "of", "undefined", "value", "(", "updated", "web", ")"], "add_tokens": "var indices = list . map ( function ( _val , n ) { return n } )", "del_tokens": "var indices = listExpansion . value . map ( function ( _val , n ) { return n } )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "options", "to", "be", "passed", "to", "simplesmtp"], "add_tokens": "init : function ( port , smtpOptions ) { smtpServer = smtp . createServer ( smtpOptions ) ;", "del_tokens": "init : function ( port ) { smtpServer = smtp . createServer ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["use", "git", "reset", "--", "hard", "to", "refresh", "git", "repo"], "add_tokens": "exports . resetHard . bind ( null , repo , 'origin/master' )", "del_tokens": "exports . merge . bind ( null , repo , 'origin/master' )", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "required", "argument", "error"], "add_tokens": "var assume = false ; assume = true ; if ( assume ) { throw new Error ( 'A required argument is missing' ) ; } else { throw new Error ( 'Required argument \"' + ( arg instanceof Object ? arg . join ( '/' ) : arg ) + '\" is missing' ) ; }", "del_tokens": "throw new Error ( 'Required argument \"' + ( arg instanceof Object ? arg . join ( '/' ) : arg ) + '\" is missing' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "components", "icons", "title", "with", "parameters", "and", "hover", "color"], "add_tokens": "for ( let componentName in ICONS ) { if ( child . components && child . components [ componentName ] ) { let properties = child . getAttribute ( componentName ) ; const titles = Object . keys ( properties ) . sort ( ) . map ( property => { return ' - ' + property + ': ' + properties [ property ] ; } ) ; let componentTitle = componentName + ( titles . length ? '\\n' + titles . join ( '\\n' ) : '' ) ; extra += ' <i class=\"component fa ' + ICONS [ componentName ] + '\" title=\"' + componentTitle + '\"></i>' ;", "del_tokens": "for ( let icon in ICONS ) { if ( child . components && child . components [ icon ] ) { extra += ' <i class=\"fa ' + ICONS [ icon ] + '\"></i>' ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "setting", "time", "for", "when", "inventory", "updated"], "add_tokens": "if ( this . _lastInventoryUpdate === null ) { this . _lastInventoryUpdate = time ; } else if ( body . fallback . available === false && time . unix ( ) !== this . _lastInvoryUpdentate . unix ( ) ) {", "del_tokens": "if ( body . fallback . available === false && ( this . _lastInventoryUpdate === null || time . unix ( ) !== this . _lastInventoryUpdate . unix ( ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "test", "for", "null", "object"], "add_tokens": "} else if ( ( typeof obj === 'object' ) && ( obj !== null ) ) { } else if ( ( typeof obj === 'object' ) && ( obj !== null ) ) {", "del_tokens": "} else if ( typeof obj === 'object' ) { } else if ( typeof obj === 'object' ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "descriptive", "comments", "regarding", "option", ".", "limit", "."], "add_tokens": "// Handling for limit queries; limit arrives as options \"limit\", \"resultRecordCount\", \"count\" or \"maxFeatures // options.limit is incremented by one in normalizeOptions.js; so if filtered.length === options.limit, we know // the original limit option has been exceeded // Now slice off the last feature, so that our feature array length is consistent with origin option", "del_tokens": "// Handling for limit queries", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "for", "youtube", "destroy", "method", "in", "beforeDestroy"], "add_tokens": "if ( this . player !== null && this . player . destroy ) {", "del_tokens": "if ( this . player !== null ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "test", "mode", "config", "."], "add_tokens": "* 1. ` `", "del_tokens": "* 1. [ ` ` ] ( test . js . html )", "commit_type": "remove"}
{"commit_tokens": ["add", "tests", "to", "new", "functions", "in", "broker"], "add_tokens": "this . data = data ;", "del_tokens": "if ( data ) this . data = data ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "non", "-", "standard", "extension", "getTimezoneAbbr", "()", ".", "Thanks", "@clintandrewhall!"], "add_tokens": "// Returns the timezone offset from GMT the Date instance currently is in, // in minutes. Also, left of GMT is positive, right of GMT is negative. // NON-STANDARD: Returns the abbreviation (e.g. EST, EDT) for the specified time zone. this . getTimezoneAbbr = function getTimezoneAbbr ( ) { return tz . tzname [ zoneInfo . isDaylightSavings ? 1 : 0 ] ; } // NON-STANDARD: I don't think we can implement this before 'setTimezone()' // called, so until it is, throw an Error on the Date instance. function getTimezoneAbbr ( ) { throw new Error ( 'You must call \"setTimezone(tz)\" before \"getTimezoneAbbr()\" may be called' ) ; } Date . prototype . getTimezoneAbbr = getTimezoneAbbr ;", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["moves", "jshint", "options", "to", "external", "file"], "add_tokens": "] ) . pipe ( jshint ( ) )", "del_tokens": "] ) . pipe ( jshint ( { 'node' : true , 'browser' : true , 'es5' : false , 'esnext' : true , 'bitwise' : false , 'camelcase' : false , 'curly' : true , 'eqeqeq' : true , 'immed' : true , 'latedef' : true , 'newcap' : true , 'noarg' : true , 'quotmark' : 'single' , 'regexp' : true , 'undef' : true , 'unused' : true , 'strict' : true , 'expr' : true , // stops complaints about 'to.be.true' etc in chai 'predef' : [ 'Modernizr' , 'ga' , 'describe' , 'it' , 'expect' , 'beforeEach' , 'afterEach' ] } ) )", "commit_type": "move"}
{"commit_tokens": ["Changed", "call", "to", "only", "expect", "and", "return", "binary", "headers", "when", "key", "ends", "with", "-", "bin"], "add_tokens": "'key1-bin' : [ new Buffer ( 'value1' ) ] , 'key2-bin' : [ new Buffer ( 'value2' ) ]", "del_tokens": "'key1' : [ new Buffer ( 'value1' ) ] , 'key2' : [ new Buffer ( 'value2' ) ]", "commit_type": "change"}
{"commit_tokens": ["Add", "webkit", "prefix", "for", "clip", "-", "path", "and", "only", "check", "for", "webkit", "-", "prefix", "and", "prefix", "-", "free", "clip", "-", "path", "support", "."], "add_tokens": "const clipPath = ( value ) => ( { WebkitClipPath : value , clipPath : value } ) transition : 'clip-path 550ms cubic-bezier(0.4, 0.0, 0.2, 1), -webkit-clip-path 550ms cubic-bezier(0.4, 0.0, 0.2, 1)' , ... clipPath ( props . on ? 'polygon(0% 0%, 0% 0%, 0% 0%)' : 'polygon(0% 200%, 0% 0%, 200% 0%)' ) , transition : 'clip-path 550ms cubic-bezier(0.4, 0.0, 0.2, 1), -webkit-clip-path 550ms cubic-bezier(0.4, 0.0, 0.2, 1)' , ... clipPath ( props . on ? 'polygon(100% -100%, 100% 100%, -100% 100%)' : 'polygon(100% 100%, 100% 100%, 100% 100%)' ) ,", "del_tokens": "transition : 'clip-path 550ms cubic-bezier(0.4, 0.0, 0.2, 1)' , clipPath : props . on ? 'polygon(0% 0%, 0% 0%, 0% 0%)' : 'polygon(0% 200%, 0% 0%, 200% 0%)' , transition : 'clip-path 550ms cubic-bezier(0.4, 0.0, 0.2, 1)' , clipPath : props . on ? 'polygon(100% -100%, 100% 100%, -100% 100%)' : 'polygon(100% 100%, 100% 100%, 100% 100%)' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "recognizing", "position", "on", "the", "Kenwood", "D700"], "add_tokens": "return ( first == \"`\" || first == \"'\" ) ;", "del_tokens": "return first == \"`\" ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "inverses", "of", "steps", "test", "them"], "add_tokens": "if ( same ( set [ i ] , style ) ) return true if ( set [ i ] . type == type ) return set [ i ]", "del_tokens": "if ( same ( set [ i ] , style ) ) return set [ i ] if ( set [ i ] . type == type ) return true", "commit_type": "add"}
{"commit_tokens": ["removed", "other", "es6", "test", "issue"], "add_tokens": "it ( 'should correctly deserialize using strict and non-strict mode using nodeDoc' , function ( done ) {", "del_tokens": "it ( 'should correctly deserialize using strict and non-strict mode using nodeDoc' , ( done ) => {", "commit_type": "remove"}
{"commit_tokens": ["fixed", "the", "bug", "of", "button", "positioning", "and", "the", "bug", "of", "image", "toolbar", "positioning"], "add_tokens": "left = $p . position ( ) . left - parseInt ( $buttons . find ( '.medium-insert-buttons-addons' ) . css ( 'left' ) , 10 ) - parseInt ( $buttons . find ( '.medium-insert-buttons-addons a:first' ) . css ( 'margin-left' ) , 10 ) ; left : left , top : $current . position ( ) . top + parseInt ( $current . css ( 'margin-top' ) , 10 ) if ( $current . closest ( '.medium-insert-image-active' ) . length === 1 ) { $buttons . offset ( { top : $current . offset ( ) . top } ) ; }", "del_tokens": "left = $p . offset ( ) . left - parseInt ( $buttons . find ( '.medium-insert-buttons-addons' ) . css ( 'left' ) , 10 ) - parseInt ( $buttons . find ( '.medium-insert-buttons-addons a:first' ) . css ( 'margin-left' ) , 10 ) ; left : left < 0 ? $p . offset ( ) . left : left , top : $current . offset ( ) . top", "commit_type": "fix"}
{"commit_tokens": ["change", "serveral", "var", "namings", "and", "add", "comments"], "add_tokens": "var Query = module . exports = function ( conn , config , locator ) { if ( _ . isString ( config ) ) { // if query config is string, it is given in SOQL. this . _soql = config ; this . _config = config ; if ( locator && locator . indexOf ( \"/\" ) >= 0 ) { // if locator given in url for next records this . _config . limit = limit ; this . _config . offset = offset ; this . _config . sort = sort ; Query . prototype . _maxFetch = 10000 ; Query . prototype . _autoFetch = false ; var soql = self . _soql = self . _soql || SOQLBuilder . createSOQL ( self . _config ) ;", "del_tokens": "var Query = module . exports = function ( conn , query , locator ) { if ( _ . isString ( query ) ) { // if query is string, it is given in SOQL. this . _soql = query ; this . _query = query ; if ( locator && locator . indexOf ( \"/\" ) >= 0 ) { this . _query . limit = limit ; this . _query . offset = offset ; this . _query . sort = sort ; var soql = self . _soql = self . _soql || SOQLBuilder . createSOQL ( self . _query ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "color", "options", "to", "webpack", "commands"], "add_tokens": "shell . exec ( 'cd node_modules/enclave && webpack --color && webpack-dev-server --colors --port ' + JSON . parse ( userSettings . port ) )", "del_tokens": "shell . exec ( 'cd node_modules/enclave && webpack && webpack-dev-server --port ' + JSON . parse ( userSettings . port ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "ability", "to", "set", "classNames", "outside", "of", "the", "attributes", "object"], "add_tokens": "defaultClasses . concat ( this . props . className . split ( ' ' ) )", "del_tokens": "defaultClasses . concat ( this . props . className . split ( ' ' ) )", "commit_type": "remove"}
{"commit_tokens": ["update", "fast", "-", "animation", "-", "frame"], "add_tokens": "var _requestAnimationFrame = void 0 , _cancelAnimationFrame = void 0 ; _cancelAnimationFrame = function _cancelAnimationFrame ( id ) { return clearTimeout ( id ) ; } ; _cancelAnimationFrame = cancelAnimationFrame ; if ( ! steps . length && timerId ) { _cancelAnimationFrame ( timerId ) ; timerId = null ; }", "del_tokens": "var _requestAnimationFrame = void 0 ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "old", "references", "to", "alignLinkTypes"], "add_tokens": "orderLinks ( G ) orderLinks ( G )", "del_tokens": "var alignLinkTypes = false orderLinks ( G , { alignLinkTypes : alignLinkTypes } ) orderLinks ( G , { alignLinkTypes : alignLinkTypes , firstRun : true } ) sankey . alignLinkTypes = function ( x ) { if ( ! arguments . length ) return alignLinkTypes alignLinkTypes = ! ! x return sankey }", "commit_type": "remove"}
{"commit_tokens": ["Create", "and", "Update", "written", ".", "Bugs", "remain"], "add_tokens": "reserved . _self = reserved . _nodeType = reserved . _db =", "del_tokens": "reserved . self = reserved . nodeType = reserved . db =", "commit_type": "create"}
{"commit_tokens": ["add", "bulk", "action", "checkboxes", "to", "all", "states"], "add_tokens": "lastPage : _ . last ( pages )", "del_tokens": "lastPage : _ . last ( pages ) , statesWithBulkActions : [ 'completed' , 'failed' ]", "commit_type": "add"}
{"commit_tokens": ["Add", "timestamp", "and", "extra", "information", "to", "local", "changes", "during", "conflict", "resolution"], "add_tokens": "queue . push ( this . _addObviousInforation ( feedQueue [ 0 ] . s , feedQueue [ 0 ] . k , key . replace ( / .*\\. / , '' ) , item ) ) ; } . bind ( this ) ,", "del_tokens": "queue . push ( item ) ; } ,", "commit_type": "add"}
{"commit_tokens": ["make", "istanbul", "cover", "only", "source", "(", "not", "tests", ")"], "add_tokens": "package : path . join ( __dirname , './test/package.json' )", "del_tokens": "package : path . join ( __dirname , './test-package.json' )", "commit_type": "make"}
{"commit_tokens": ["adding", "more", "browser", "versions", "for", "testing", "incl", "safari"], "add_tokens": "browserName : \"firefox\" , platform : \"WIN7\" } , { platform : \"WIN7\" } , { browserName : \"chrome\" , version : \"26\" , platform : \"WIN7\" , platform : \"WIN7\" , } , { browserName : \"internet explorer\" , platform : \"XP\" , version : \"8\" } , { browserName : \"safari\" , platform : \"OS X 10.9\" , version : \"7\" } , { browserName : \"safari\" , platform : \"OS X 10.8\" , version : \"6\" maxRetries : 3 ,", "del_tokens": "platform : \"VISTA\" , platform : \"VISTA\" ,", "commit_type": "add"}
{"commit_tokens": ["added", "apis", "for", "cssStyles", "and", "html", "functions"], "add_tokens": "* @ pCSSFiles_a -   css     , *   ", "del_tokens": "* @ pCSSFiles_a -   css     , *   ", "commit_type": "add"}
{"commit_tokens": ["add", "use", "strict", "to", "generated", "code"], "add_tokens": "module . exports = { convertTemplateToReact : convertTemplateToReact , convertFile : convertFile , _test : { } } ;", "del_tokens": "module . exports . convertTemplateToReact = convertTemplateToReact ; module . exports . convertFile = convertFile ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "timezone", "correction", "code", "."], "add_tokens": "return this . getComponents ( 'STANDARD' ) [ 0 ] . getPropertyValue ( 'TZOFFSETTO' ) ;", "del_tokens": "return this . getComponents ( 'STANDARD' ) . getPropertyValue ( 'TZOFFSETTO' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "---", "to", "deliniate", "the", "beginning", "of", "YAML", "metadata"], "add_tokens": "// Find last YAML file delimiter in the comment, if present var start = 0 ; for ( var i = node . comments . length - 1 ; i >= 0 ; i -- ) { var line = node . comments [ i ] ; if ( line . trim ( ) == '---' ) { start = i ; break ; } } // start metadata at the last YAML delimiter or at the beginning of the comment var commentString = node . comments . slice ( start , node . comments . length ) . join ( \"\\n\" ) ;", "del_tokens": "var commentString = node . comments . join ( \"\\n\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "async", "support", "for", "loading", "and", "for", "rendering"], "add_tokens": "output += ') {\\nvar $c = new $_w();\\n' ; // output += ') {\\n'; var internals = internalsUsed . length ? 'var ' + internalsUsed . map ( function ( item ) { } ) . join ( ',\\n' ) + ';\\n\\n' : '' ; var code = 'function(vmc){return function($L,$p,$i) {var $v=vmc?new vmc($p):null; var $h=$L.helpers; var $_w=$i.$W;\\nvar $c = new $_w();\\n' + internals + compiled + '\\nreturn $c.getOutput();\\n}\\n}' ;", "del_tokens": "output += ') {\\nvar $c = new Chunk();\\n' var internals = 'var ' + internalsUsed . map ( function ( item ) { } ) . join ( ',\\n' ) + ';\\n\\n' ; var code = 'function(vmc){return function($L,Chunk,$p,$i) {var $v=vmc?new vmc($p):null; var $h=$L.helpers;\\nvar $c = new Chunk();\\n' + internals + compiled + '\\nreturn $c.getOutput();\\n}\\n}' ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "coknsole", "logs", "and", "warnings"], "add_tokens": "// console.log('StaticQuery result', config, tableOfContents, allMarkdown);", "del_tokens": "console . log ( 'StaticQuery result' , config , tableOfContents , allMarkdown ) ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "formatUrl", "()", "to", "alter", "req", "opt"], "add_tokens": "return this . formatUrl ( urlParts , opt ) ;", "del_tokens": "return this . formatUrl ( urlParts ) ;", "commit_type": "allow"}
{"commit_tokens": ["use", "model", "name", "instead", "of", "collection", "name"], "add_tokens": "'cloneable' : typeof ( MongooseAdmin . singleton . models [ req . params . modelName ] . options . cloneable ) != 'undefined' ,", "del_tokens": "'cloneable' : typeof ( MongooseAdmin . singleton . models [ req . params . modelName ] . options . cloneable ) == 'string' ,", "commit_type": "use"}
{"commit_tokens": ["adds", "test", "for", "file", "object"], "add_tokens": "function toFile ( file , dest ) { if ( dest ) file . dest = dest ; it ( 'should normalize a file object:' , function ( ) { var config = normalize ( toFile ( path . resolve ( 'a/b/c.js' ) , 'dist/' ) ) ; assert ( Array . isArray ( config . files ) ) ; assert ( config . files [ 0 ] . src [ 0 ] === path . resolve ( 'a/b/c.js' ) ) ; assert ( config . files [ 0 ] . dest === 'dist/' ) ;", "del_tokens": "function toFile ( file ) { it . only ( 'should normalize a file object:' , function ( ) { var file = toFile ( path . resolve ( 'a/b/c.js' ) ) ; console . log ( normalize ( file ) ) ; // assert(Array.isArray(foo.files)); // assert(foo.files[0].src[0] === '*.js'); // assert(foo.files[0].dest === 'foo/'); // assert(bar.files[0].src[0] === '*.js'); // assert(bar.files[0].dest === 'foo/'); // assert(foo.files[1].src[0] === '*.md'); // assert(foo.files[1].dest === 'bar/');", "commit_type": "add"}
{"commit_tokens": ["change", "command", "name", "to", "command", "for", "interface", "tweak"], "add_tokens": "console . error ( util . format ( ' heroku %s:%s # %s' , command . topic , command . command , command . shortHelp ) ) ; return command . topic === c [ 0 ] && command . command === c [ 1 ] ;", "del_tokens": "console . error ( util . format ( ' heroku %s:%s # %s' , command . topic , command . name , command . shortHelp ) ) ; return command . topic === c [ 0 ] && command . name === c [ 1 ] ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "an", "object", "that", "does", "not", "exist", "in", "Bug"], "add_tokens": "if ( typeof options === 'object' && options != null ) {", "del_tokens": "if ( typeof options === 'object' && object != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "indent", "to", "command", "options"], "add_tokens": "` ${ printName ( option ) } \\t ${ chalk . gray ( printDescription ( option ) ) } ` ,", "del_tokens": "` ${ printName ( option ) } \\t ${ chalk . gray ( printDescription ( option ) ) } ` ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "internal", "settings", "from", "request", "payload"], "add_tokens": "case 'projectRoot' : case 'stripProjectRoot' : case 'addWildcardPrefix' : {", "del_tokens": "case 'projectRoot' : {", "commit_type": "remove"}
{"commit_tokens": ["Added", "failing", "disconnection", "event", "test"], "add_tokens": "var port = ++ ports , io = sio . listen ( port ) , sid ; io . configure ( function ( ) { io . set ( 'close timeout' , .2 ) ; } ) ; io . sockets . on ( 'connection' , function ( socket ) { socket . id . should . eql ( sid ) ; socket . on ( 'disconnect' , function ( ) { console . log ( 'disconnected' ) ; io . server . close ( ) ; done ( ) ; } ) ; } ) ; handshake ( port , function ( sessid ) { sid = sessid ; get ( '/socket.io/{protocol}/xhr-polling/' + sid , port ) ; } ) ;", "del_tokens": "io . set ( 'polling duration' , .2 ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "leveldb", "prefix", "as", "pouchdb", "is", "host", "aware"], "add_tokens": ", app = module . exports = express ( ) , Pouch = module . exports . Pouch = require ( 'pouchdb' ) ; Pouch ( name , function ( err , db ) { Pouch . destroy ( name , function ( err , info ) { Pouch ( name , function ( err , db ) {", "del_tokens": ", Pouch = require ( 'pouchdb' ) , protocol = 'leveldb://' , app = module . exports = express ( ) ; module . exports . Pouch = Pouch ; Pouch ( protocol + name , function ( err , db ) { Pouch . destroy ( protocol + name , function ( err , info ) { Pouch ( protocol + name , function ( err , db ) {", "commit_type": "remove"}
{"commit_tokens": ["removing", "some", "checks", "these", "bugs", "need", "to", "be", "addressed"], "add_tokens": "return ( $ . isTag ( elem ) ) ; if ( selector === undefined ) return $ ( children ) ; else if ( _ . isNumber ( selector ) ) return $ ( children [ selector ] ) ;", "del_tokens": "return $ . isTag ( elem ) ; if ( ! selector ) return $ ( children ) ; // remove depth for ( var i = 0 ; i < children . length ; i ++ ) delete children . children ;", "commit_type": "remove"}
{"commit_tokens": ["moved", "edge", "removal", "perf", "test"], "add_tokens": ". run ( { 'async' : true } ) ;", "del_tokens": ". run ( { 'async' : true } ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "save", "object", "property", "with", "azuretable"], "add_tokens": "entity [ property ] = eg . String ( JSON . stringify ( entity [ property ] ) ) ;", "del_tokens": "entity [ property ] = JSON . stringify ( entity [ property ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "tests", "at", "least", "locally"], "add_tokens": "plugins : [ require ( 'postcss-cssnext' ) ] ,", "del_tokens": "plugins : [ require ( 'postcss-cssnext' ) , require ( 'postcss-css-variables' ) , require ( 'postcss-custom-media' ) , require ( 'postcss-nested' ) ]", "commit_type": "fix"}
{"commit_tokens": ["added", "nicer", "name", "to", "olark", "chat", "identifies"], "add_tokens": "snippet : 'Zeus (zeus@segment.io)' snippet : 'Zeus (zeus@segment.io)'", "del_tokens": "analytics . identify ( userId , traits ) ; analytics . identify ( userId , traits ) ; snippet : 'Zeus' snippet : 'Zeus'", "commit_type": "add"}
{"commit_tokens": ["Added", "retryMethod", "test", "to", "retry", ".", "js", "tests", "100%", "coverage", "incoming", "."], "add_tokens": "", "del_tokens": "/ * * /", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "toString", "according", "to", "HTML", "5", "draft"], "add_tokens": "s . test ( \"HTML 5 toString test\" , function ( t ) { var div = doc . createElement ( \"div\" ) ; div . innerHTML = 'one<script type=\"text/javascript\">var x = 1;</script>two' ; doc . body . appendChild ( div ) ; var sel = selectionCreator ( win ) ; sel . removeAllRanges ( ) ; var range = rangeCreator ( doc ) ; range . selectNodeContents ( div ) ; sel . addRange ( range ) ; var rangeText = range . toString ( ) ; var selText = sel . toString ( ) ; doc . body . removeChild ( div ) ; t . assertEquals ( rangeText , \"onevar x = 1;two\" ) ; t . assertEquals ( selText , \"onevar x = 1;two\" ) ; } ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "AerospikeStore#close", "()", "method"], "add_tokens": "store . close ( )", "del_tokens": "store . client . close ( )", "commit_type": "use"}
{"commit_tokens": ["Make", "a", "couple", "slight", "code", "style", "updates"], "add_tokens": "empty = val === false || val == null || ! val . length , empty = val === false || val == null || ! val . length ;", "del_tokens": "empty = val === false || val == null || val . length === 0 , empty = val === false || val == null || val . length === 0 ;", "commit_type": "make"}
{"commit_tokens": ["updated", "readme", "added", "optional", "options", "and", "made", "program", "more", "robust"], "add_tokens": "if ( grunt . file . exists ( '.ftpauth' ) ) return JSON . parse ( grunt . file . read ( '.ftpauth' ) ) [ authKey ] ; else if ( options . username && options . password ) { return { username : options . username , password : options . password } ; } else { return { username : null , password : null } ; // Will Force the User to Use Anonymous Login }", "del_tokens": "return JSON . parse ( grunt . file . read ( '.ftpauth' ) ) [ authKey ] ;", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "OsmAnd", "."], "add_tokens": "'maps-me' : ' mapsme : //', osmand : 'https://osmand.net/' , osmand : 'OsmAnd' , 'maps-me' : require ( './images/maps-me.png' ) , osmand : require ( './images/osmand.png' ) ,", "del_tokens": "'maps-me' : 'mapsme://' 'maps-me' : require ( './images/maps-me.png' )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "that", "swapped", "default", "list", "style", "types", "..."], "add_tokens": "} else { type = 'disc'", "del_tokens": "type = 'disc' } else {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "SphereDrawnItemFactory", "and", "example", "Sphere"], "add_tokens": "drawnItem = cellGroup . data . drawnItems [ item . key ] ; delete cellGroup . data . drawnItems [ item . key ] ; delete this . cellGroupsMap [ groupKey ] ; drawnItem = this . drawnItemFactory . getDrawnItem ( item ) ; //Prepare the map of drawn items by id cellGroup . data . drawnItems = { } ; //Map the drawn items by id so they can be removed if ( ! ! item . key ) { cellGroup . data . drawnItems [ item . key ] = drawnItem ; } //some item types include pieces drawn below the grid (let the game logic ensure they are the only item in the cell) if ( ! ! drawnItem . belowGridItem ) { cellGroup . belowGridGroup . addChild ( drawnItem . belowGridItem ) ; } drawnItem . nextDrawnItem = cellGroup ;", "del_tokens": "drawnItem = cellGroup [ item . key ] ; delete cellGroup [ item . key ] ; delete cellGroupsMap [ groupKey ] ; drawnItem = this . drawnItemFactory . getDrawnItemForCellItem ( item ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "message", "connection", "module", "with", "examples", "."], "add_tokens": "function debug ( message ) { //console.log(message) } var closed = Q . defer ( ) ; return Q . when ( result , null , function ( reason ) { closed . resolve ( ) ; return Q . reject ( reason ) ; } ) ; } , \"closed\" : closed . promise , \"close\" : function ( reason ) { var end = { \"head\" : Q . reject ( reason ) } ; end . tail = end ; ends . resolve ( end ) ; return closed . promise ; debug ( message ) ;", "del_tokens": "//console.log(message);", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "silly", "typo", "actually", "run", "tests", "before", "pushing"], "add_tokens": "if ( path . isAbsolute ( tpl ) ) {", "del_tokens": "if ( path . isAbsolut ( tpl ) ) {", "commit_type": "fix"}
{"commit_tokens": ["improve", "postgres", "compatibility", "add", "additional", "types", "change", "hasDuplicateValues", "to", "work", "with", "p", "-", "sql"], "add_tokens": ". select ( column ) . havingRaw ( ` ${ column } ` )", "del_tokens": ". count ( column + ' as hasSameValues' ) . having ( 'hasSameValues' , '>' , 1 )", "commit_type": "improve"}
{"commit_tokens": ["Use", "TEST_URL", "to", "set", "the", "site", "to", "test"], "add_tokens": "var baseTestUrl = system . env . TEST_URL ;", "del_tokens": "var baseTestUrl = 'http://localhost:8675' ;", "commit_type": "use"}
{"commit_tokens": ["add", "a", "flow", "after", "upload", "file", "success"], "add_tokens": "owner . request ( 'after-send-file' , [ file , ret , headers ] , function ( ) { file . setStatus ( Status . COMPLETE ) ; owner . trigger ( 'uploadComplete' , file ) ; tr . destroy ( ) ; } ) . fail ( function ( reason ) { tr . trigger ( 'error' , reason ) ; } ) ;", "del_tokens": "file . setStatus ( Status . COMPLETE ) ; owner . trigger ( 'uploadComplete' , file ) ; tr . destroy ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "misplaced", "comments", "-", "the", "leftovers", "from", "static", "feature", "implementation", "."], "add_tokens": "// We might end up having two different stampit modules loaded and used in conjunction. // These || operators ensure that old stamps could be combined with the current version stamps. * @ return { Function } factory . static Add properties to the stamp ( not objects ! ) . Chainable .", "del_tokens": "// We might end up having two different stampit modules loaded and used in conjunction. // These || operators ensure that old stamps could be combined with the current version stamps. * @ return { Function } factory . static Add properties to the stamp ( not objects ! ) . Chainable .", "commit_type": "move"}
{"commit_tokens": ["improve", "doc", "&", "dev", "dependencies"], "add_tokens": "const APP_FILES = [ path . join ( __dirname , \"lib\" , \"**\" , \"*.js\" ) ] ; gulp . task ( \"istanbul\" , gulp . series ( \"eslint\" , ( ) => { } ) ) ; gulp . task ( \"mocha\" , gulp . series ( \"istanbul\" , ( ) => { } ) ) ; gulp . task ( \"coveralls\" , gulp . series ( \"mocha\" , ( ) => { } ) ) ; gulp . task ( \"tests\" , gulp . series ( ISTRAVIS ? \"coveralls\" : \"mocha\" ) ) ; gulp . task ( \"default\" , gulp . series ( \"mocha\" ) ) ;", "del_tokens": "const APP_FILES = [ path . join ( __dirname , \"lib\" , \"*.js\" ) ] ; gulp . task ( \"istanbul\" , [ \"eslint\" ] , ( ) => { } ) ; gulp . task ( \"mocha\" , [ \"istanbul\" ] , ( ) => { } ) ; gulp . task ( \"coveralls\" , [ \"mocha\" ] , ( ) => { } ) ; gulp . task ( \"tests\" , [ ISTRAVIS ? \"coveralls\" : \"mocha\" ] ) ; gulp . task ( \"default\" , [ \"mocha\" ] ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "initial", "movement", "without", "mod"], "add_tokens": "var Draggy = require ( 'draggy' ) ; /** Create test case */ // draggy.on('threshold', paintThreshold); // draggy.on('dragstart', renderHelpers); // draggy.on('drag', renderHelpers); // draggy.on('dragend', clear); // draggy.on('idle', clear); // draggy.on('track', renderDirection);", "del_tokens": "window . WeakMap = require ( 'weak-map' ) ; var Draggy = require ( '../index' ) ; /**simple polyfill*/ if ( ! document . contains ) { Node . prototype . contains = function contains ( node ) { if ( ! ( 0 in arguments ) ) { throw new TypeError ( '1 argument is required' ) ; } do { if ( this === node ) { return true ; } } while ( node = node && node . parentNode ) ; return false ; } ; } draggy . on ( 'threshold' , paintThreshold ) ; draggy . on ( 'dragstart' , renderHelpers ) ; draggy . on ( 'drag' , renderHelpers ) ; draggy . on ( 'dragend' , clear ) ; draggy . on ( 'idle' , clear ) ; draggy . on ( 'track' , renderDirection ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "arrow", "key", "navigation", ".", "Relative", "to", "the", "scale", "level", "."], "add_tokens": "return d / this . _scale ; return d * this . _scale ; var delta = function ( ) { // Make key moves relative to scale. return 50 / that . _scale ; // same as toSpaceDistance } ; that . moveBy ( 0 , - delta ( ) ) ; that . moveBy ( 0 , delta ( ) ) ; that . moveBy ( - delta ( ) , 0 ) ; that . moveBy ( delta ( ) , 0 ) ;", "del_tokens": "return d / this . _scale ; // dummy return d * this . _scale ; // dummy that . moveBy ( 0 , - 50 ) ; that . moveBy ( 0 , + 50 ) ; that . moveBy ( - 50 , 0 ) ; that . moveBy ( + 50 , 0 ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "fh", "-", "run", "-", "array", "to", "take", "string", "or", "array", "again"], "add_tokens": "var cmds = grunt . config . get ( test_type ) ; cmd = typeof cmds === 'string' ? cmds : cmds . join ( ' && ' ) ;", "del_tokens": "var cmdsString = grunt . config . get ( test_type ) ; var cmdArray = cmdsString . split ( ',' ) ; cmd = cmdArray . join ( ' && ' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "bug", "where", "Picture", "tab", "is", "broken", "after", "min"], "add_tokens": "return [ '$scope' , 'Pictures' , function ( $scope , Pictures ) { } ] ;", "del_tokens": "return function ( $scope , Pictures ) { } ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "keyboard", "navigation", "after", "click", "event"], "add_tokens": "var window = require ( 'global/window' ) ; 'click' , finder . clickEvent . bind ( null , container , cfg , emitter ) ) ; var x = window . pageXOffset ; var y = window . pageYOffset ; // fix for #14: we need to keep the focus on a live DOM element, such as the // container, in order for keydown events to get fired value . container . focus ( ) ; window . scrollTo ( x , y ) ; * @ param { element } container finder . clickEvent = function clickEvent ( container , cfg , emitter , event ) { container : container , container : value . container ,", "del_tokens": "'click' , finder . clickEvent . bind ( null , cfg , emitter ) ) ; finder . clickEvent = function clickEvent ( cfg , emitter , event ) {", "commit_type": "fix"}
{"commit_tokens": ["update", "scene", "to", "support", "components"], "add_tokens": "_extends ( { ref : this . attachEvents } , this . props ) ,", "del_tokens": "{ ref : this . attachEvents } ,", "commit_type": "update"}
{"commit_tokens": ["Improve", "filtering", "use", "of", "backbone", ".", "paginator", "API"], "add_tokens": "'backbone.paginator' : 'bower_components/backbone.paginator/lib/backbone.paginator.min' ,", "del_tokens": "'backbone.paginator' : 'bower_components/backbone.paginator/lib/backbone.paginator' ,", "commit_type": "improve"}
{"commit_tokens": ["Updating", "partial", "scoring", "based", "on", "feedback", "from", "more", "real", "use", "case"], "add_tokens": "return ( 1 / depth ) * 0.8 + Math . min ( 1 , score / depth ) * 0.2 ;", "del_tokens": "const diff = Math . abs ( score - tokens ) ; if ( tokens === 0 ) { // Special case for no tokens, low effort first return 1 / score ; } else if ( score > tokens ) { let result = 0.95 ; if ( diff > 0 ) { result += ( diff / Math . max ( diff , depth - tokens ) ) * 0.05 ; } return result ; } else { return ( score / tokens ) * 0.95 ; }", "commit_type": "update"}
{"commit_tokens": ["Made", "port", "configurable", "via", "command", "line", "and", "devServer", "config"], "add_tokens": "await startDevServer ( { config } )", "del_tokens": "findAvailablePort , // Find an available port to serve on. const port = await findAvailablePort ( 3000 ) await startDevServer ( { config , port } )", "commit_type": "make"}
{"commit_tokens": ["Moving", "to", "fs", "as", "a", "last", "resort", "and", "still", "getting", "trolled", ";", "_", ";"], "add_tokens": "require ( 'fs' ) . writeFileSync ( 'a.png' , this . result , 'binary' ) ; getPixels ( 'a.png' , function ( err , actualPixels ) { that . actualPixels = actualPixels ; cb ( err ) ; // var buff = new Buffer(this.result, 'binary'); // // Repurposed from https://github.com/mikolalysenko/get-pixels/blob/2ac98645119244d6e52afcef5fe52cc9300fb27b/node-pixels.js // var that = this; // pngparse.parse(buff, function(err, img_data) { // if(err) { // cb(err); // return; // } // that.actualPixels = ndarray(new Uint8Array(img_data.data), // [img_data.height|0, img_data.width|0, 4], // [4*img_data.width|0, 4, 1], // 0); // cb(); // });", "del_tokens": "var buff = new Buffer ( this . result , 'binary' ) ; // Repurposed from https://github.com/mikolalysenko/get-pixels/blob/2ac98645119244d6e52afcef5fe52cc9300fb27b/node-pixels.js pngparse . parse ( buff , function ( err , img_data ) { if ( err ) { cb ( err ) ; return ; } that . actualPixels = ndarray ( new Uint8Array ( img_data . data ) , [ img_data . height | 0 , img_data . width | 0 , 4 ] , [ 4 * img_data . width | 0 , 4 , 1 ] , 0 ) ; cb ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "more", "tests", "set", "default", "model", "data"], "add_tokens": "/** @private @const TYPE_PROP {string} - Name of the type property when the model is converted into POJO */ /** @private @const DEFAULT_TYPE {string} - Type of the default model */ /** @private @const RESERVED_KEYS {Array<string>} - List of property names that shouldn't be used in the model */", "del_tokens": "/** @const TYPE_PROP {string} - Name of the type property when the model is converted into POJO */ /** @const DEFAULT_TYPE {string} - Type of the default model */ /** @const RESERVED_KEYS {Array<string>} - List of property names that shouldn't be used in the model */", "commit_type": "add"}
{"commit_tokens": ["Make", "TokenizerInput", "state", "consistent", "with", "TypeaheadInput"], "add_tokens": "isFocused : false , { 'focus' : this . state . isFocused } this . setState ( { isFocused : false } ) ; this . setState ( { isFocused : true } ) ;", "del_tokens": "focused : false , { 'focus' : this . state . focused } this . setState ( { focused : false } ) ; this . setState ( { focused : true } ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "fallback", "to", "app", ".", "import", "if", "this", ".", "import", "is", "not", "available"], "add_tokens": "// In nested addons, app.bowerDirectory might not be available // In ember-cli < 2.7, this.import is not available, so fall back to use app.import var importShim = typeof this . import !== 'undefined' ? this : app ; importShim . import ( bowerDirectory + '/gettext.js/dist/gettext.min.js' , {", "del_tokens": "this . import ( bowerDirectory + '/gettext.js/dist/gettext.min.js' , {", "commit_type": "add"}
{"commit_tokens": ["Add", "match", "property", "to", "string", "type"], "add_tokens": "( { min , max , match } = { } , value ) => { if ( match && ! match . test ( value ) ) { throw new Error ( ` ` ) }", "del_tokens": "( { min , max } = { } , value ) => {", "commit_type": "add"}
{"commit_tokens": ["Added", "jsdoc", "in", "the", "source", ".", "Gulp", "tasks", "to", "clean", "and", "document", "."], "add_tokens": "const gulp = require ( 'gulp' ) ; const babel = require ( 'gulp-babel' ) ; const del = require ( 'del' ) ; const jsdoc = require ( 'gulp-jsdoc' ) ; src : 'src/**/*.js' , out : 'lib' , docSrc : 'lib/*.js' , docOut : 'docs' gulp . task ( 'clean' , function ( ) { return del ( [ Loc . out , Loc . docOut ] ) ; } ) ; gulp . task ( 'js' , [ 'clean' ] , function ( ) { gulp . task ( 'document' , [ 'clean' , 'js' ] , function ( ) { return gulp . src ( Loc . docSrc ) . pipe ( jsdoc ( Loc . docOut ) ) } ) ; gulp . task ( 'default' , [ 'js' , 'document' ] ) ;", "del_tokens": "const gulp = require ( 'gulp' ) ; const babel = require ( 'gulp-babel' ) ; src : [ 'src/**/*.js' ] , out : 'lib' gulp . task ( 'js' , function ( ) { gulp . task ( 'default' , [ 'js' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "deprecated", "use", "of", "lookupFactory"], "add_tokens": "function initialize ( registry , application ) { application . register ( 'service:segment' , segment , { singleton : true } ) ; } function instanceInitialize ( container ) { var config = container . lookupFactory ( 'config:environment' ) ; var segment = container . lookup ( 'service:segment' ) ; segment . set ( 'config' , config ) ; segment . trackPageView ( ) ; export { initialize , instanceInitialize } ;", "del_tokens": "export function initialize ( container , application ) { var config = container . lookupFactory ( 'config:environment' ) ; application . register ( 'service:segment' , segment . extend ( { config : config } ) , { singleton : true } ) ; container . lookup ( 'service:segment' ) . trackPageView ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "dead", "code", "export", "findClass", "function", "register", "namespaced", "classes"], "add_tokens": "* @ version 1.0 .5 var context = exports . Classes ; if ( constructor . namespace ) { context = fromPath ( exports . Classes , constructor . namespace ) ; if ( ! context ) { context = { } ; setPath ( exports . Classes , constructor . namespace . split ( '.' ) , context ) ; } } context [ name ] = constructor ; * @ version 1.0 .5 } else if ( value . name ) { constructor = constructor [ value . name ] ; * @ version 1.0 .5 exports . registerDrier = registerDrier ; exports . findClass = findClass ;", "del_tokens": "* @ version 1.0 .0 exports . Classes [ name ] = constructor ; * @ version 1.0 .0 * @ version 1.0 .4 return undry_paths . get ( current ) . undried ; exports . registerDrier = registerDrier ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "interactive", "shell", "check", "when", "opening", "browser", "on", "start"], "add_tokens": "openBrowser ( protocol + '://' + host + ':' + port + '/' ) ;", "del_tokens": "if ( isInteractive ) { openBrowser ( protocol + '://' + host + ':' + port + '/' ) ; }", "commit_type": "remove"}
{"commit_tokens": ["added", "getNth", "and", "override", "getEnd"], "add_tokens": "GedUtil = require ( './util.js' ) , // We must have start and end. error if both aren't set if ( ! startString || ! endString ) { throw new Error ( 'Recurring must have a start and end' ) ; } Recurring . prototype . getEnd = function ( ) { if ( this . count ) { return this . getNth ( this . count ) ; } else { return Infinity ; } } Recurring . prototype . getNth = function ( multiplier ) { var duration = GedUtil . multiplyDuration ( this . duration , multiplier ) ; return GedUtil . addDuration ( this . start , duration ) ; }", "del_tokens": "// TODO we must have start and end. error if both aren't set", "commit_type": "add"}
{"commit_tokens": ["Added", "integration", "test", "(", "needs", "configuration", "customization", "etc", ")"], "add_tokens": "'X-Imbo-Imageidentifier' : catMd5 , 'X-Imbo-Imageidentifier' : catMd5 ,", "del_tokens": "after ( function ( ) { errServer . close ( ) ; stcServer . close ( ) ; } ) ; 'X-Imbo-Image-Identifier' : catMd5 , 'X-Imbo-Image-Identifier' : catMd5 ,", "commit_type": "add"}
{"commit_tokens": ["allow", "for", "multiple", "indexes", "and", "custom", "stopwords"], "add_tokens": "// we now have no use for the \"default\" index so delete it delete config . indexes . default ; var stopWordFilter = lunr . stopWordFilter ; // add any stopwords if ( typeof config . indexes [ index ] . stopWords !== 'undefined' ) { for ( var i in config . indexes [ index ] . stopWords ) { stopWordFilter . stopWords . add ( config . indexes [ index ] . stopWords [ i ] ) ; } } idx . pipeline . add ( stopWordFilter , lunr . stemmer ) ;", "del_tokens": "if ( index == 'default' ) { continue ; } //console.log(err); if ( index == 'default' ) { continue ; } //console.log(err); idx . pipeline . add ( lunr . stopWordFilter , lunr . stemmer ) ; // finally save all the initializations we just did if ( index == 'default' ) { return ; } if ( index == 'default' ) { continue ; }", "commit_type": "allow"}
{"commit_tokens": ["Remove", "url", "param", "from", "catch", "promises"], "add_tokens": "/*! qwest 1.7.0 (https://github.com/pyrsmk/qwest) */ // Late status code verification to allow data when, per example, a 409 is returned // --- https://stackoverflow.com/questions/10046972/msie-returns-status-code-of-1223-for-ajax-request if ( 'status' in xhr && ! / ^2|1223 / . test ( xhr . status ) ) { throw xhr . status + ' (' + xhr . statusText + ')' ; } p = func . call ( xhr , p ) ; func . call ( xhr , e , response ) ; func . call ( xhr , response ) ; func . call ( xhr , e , null ) ;", "del_tokens": "/*! qwest 1.6.1 (https://github.com/pyrsmk/qwest) */ // Verify status code // --- https://stackoverflow.com/questions/10046972/msie-returns-status-code-of-1223-for-ajax-request if ( 'status' in xhr && ! / ^2|1223 / . test ( xhr . status ) ) { throw xhr . status + ' (' + xhr . statusText + ')' ; } p = func . call ( xhr , p ) ; func . call ( xhr , e , url ) ; func . call ( xhr ) ; func . call ( xhr , e , url ) ;", "commit_type": "remove"}
{"commit_tokens": ["use", "async", ".", "map", "()", "instead", "to", "keep", "return", "values"], "add_tokens": "async . map ( tasks , function ( task , itemDone ) { asyncDone ( function ( taskDone ) { return task . run ( gulp , config , stream , taskDone ) ; } , itemDone ) ;", "del_tokens": "async . each ( tasks , function ( task , done ) { asyncDone ( function ( done ) { return task . run ( gulp , config , stream , done ) ; } , done ) ;", "commit_type": "use"}
{"commit_tokens": ["Removing", "lame", "vows", "tests", "."], "add_tokens": "if ( event === 'rename' ) { return ; } watcher . checkFile ( fPath , options . strict , function _checkFile ( err , result ) { watcher . checkFile ( fPath , options . strict , function _checkFile ( err , result ) { watcher . checkFile ( fPath , options . strict , function _checkFile ( err , result ) { options . strict = typeof options . strict === 'undefined' ? false : options . strict", "del_tokens": "if ( event !== 'rename' ) { return ; } watcher . checkFile ( fPath , function _checkFile ( err , result ) { watcher . checkFile ( fPath , function _checkFile ( err , result ) { watcher . checkFile ( fPath , function _checkFile ( err , result ) {", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "mddataset", "related", "code", "."], "add_tokens": "if ( this . hasMoreCells ( ) ) { return this . _cellNodes . item ( index ) ;", "del_tokens": "if ( this . _cellOrd === this . _ord && this . hasMoreCells ( ) ) { this . _cellNodes . item ( index ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "couple", "of", "bugs", ":", "attributeSchema", "and", "empty", "strings", ".", "Implemented", "onUpdate", "."], "add_tokens": "_attributeSchema : function ( attributeSchema ) { if ( _ . isString ( attributeSchema ) ) attributeSchema = this . _schema ( ) [ attributeSchema ] ; _attributeSchema : function ( attributeSchema ) { return this . model . prototype . _attributeSchema . call ( this , attributeSchema ) ;", "del_tokens": "_attributeSchema : function ( name ) { var attributeSchema = this . _schema ( ) [ name ] ; _attributeSchema : function ( name ) { return this . model . prototype . _attributeSchema . call ( this , name ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "crosshair", "into", "plugin", "."], "add_tokens": "'../js/plugins/hit.js' , '../js/plugins/crosshair.js' ,", "del_tokens": "'../js/plugins/hit.js' ,", "commit_type": "move"}
{"commit_tokens": ["fixed", "comments", "and", "lodash", "import"], "add_tokens": "const { assignIn } = require ( 'lodash' ) ; * Holds a list of factory methods to create different document types . * Creates and adds a a factory method for a type of document .", "del_tokens": "// lodash imports const _ = require ( 'lodash' ) ; const assignIn = _ . assignIn ; * Holds a list of factory methods to create different types of documents . * Creates and adds a new document subtype class to the factory .", "commit_type": "fix"}
{"commit_tokens": ["add", "2", "type", "Array", ".", "isArray", "test", "for", "zip", "return", "value"], "add_tokens": "t . true ( Array . isArray ( zip ( [ 'a' , 'b' ] , [ 1 , 2 ] , [ true , false ] ) ) , 'zip returns an Array' ) ; t . true ( Array . isArray ( zip ( [ 'a' ] , [ 1 , 2 ] , [ true , false ] ) ) , 'zip returns an Array' ) ;", "del_tokens": "//t.equal(zip(args..), 'Expected');", "commit_type": "add"}
{"commit_tokens": ["Add", "i386", "and", "amd64", "to", "platforms", "detection"], "add_tokens": "if ( name . indexOf ( '32' ) >= 0 || name . indexOf ( 'ia32' ) >= 0 || name . indexOf ( 'i386' ) >= 0 ) suffix = '32' ; if ( name . indexOf ( '64' ) >= 0 || name . indexOf ( 'x64' ) >= 0 || name . indexOf ( 'amd64' ) >= 0 ) suffix = '64' ;", "del_tokens": "if ( name . indexOf ( '32' ) >= 0 || name . indexOf ( 'ia32' ) >= 0 ) suffix = '32' ; if ( name . indexOf ( '64' ) >= 0 || name . indexOf ( 'x64' ) >= 0 ) suffix = '64' ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "build", "process", "to", "build", "both", "minified", "and", "normal"], "add_tokens": "function _build ( file , entries , isMin ) { . pipe ( gulpif ( isMin , buffer ( ) ) ) . pipe ( gulpif ( isMin , sourcemaps . init ( ) ) ) . pipe ( gulpif ( isMin , streamify ( uglify ( { . pipe ( gulpif ( isMin , sourcemaps . write ( './' ) ) ) gulp . task ( 'build' , [ 'build:normal' , 'build:min' ] ) ; gulp . task ( 'build:min' , function ( ) { return _build ( 'state-router.min.js' , './src/index.js' , true ) ; } ) ; gulp . task ( 'build:normal' , function ( ) { return _build ( 'state-router.js' , './src/index.js' ) ;", "del_tokens": "var _isProduction = process . env . NODE_ENV === 'production' ; function _build ( file , entries ) { . pipe ( gulpif ( _isProduction , buffer ( ) ) ) . pipe ( gulpif ( _isProduction , sourcemaps . init ( ) ) ) . pipe ( gulpif ( _isProduction , streamify ( uglify ( { . pipe ( gulpif ( _isProduction , sourcemaps . write ( './' ) ) ) gulp . task ( 'build' , function ( ) { return _build ( _isProduction ? 'state-router.min.js' : 'state-router.js' , './src/index.js' ) ;", "commit_type": "update"}
{"commit_tokens": ["Improved", "the", "mock", "device", "to", "return", "test", "analog", "input", "values", "(", "via", "random"], "add_tokens": "'DEVICE_NAME_DEFAULT' : 'TEST_DEVICE' , 'WIFI_VERSION' : 3.12 , 'BOOTLOADER_VERSION' : 0.9400 , 'FIRMWARE_VERSION' : 1.0144 } ; / ** * Analog input generation code : ** / var randomAnalogReading = function ( min , max ) { return Math . random ( ) * ( max - min ) + min ; } ; var analogInputRanges = { } ; this . getAINReading = function ( channelNum ) { var resultRange = 10 ; if ( analogInputRanges [ channelNum ] ) { resultRange = analogInputRanges [ channelNum ] ; } return randomAnalogReading ( resultRange , resultRange * - 1 ) ; var getChannelNum = new RegExp ( \"[0-9]{1,}\" ) ; var isAnalogInput = new RegExp ( \"^AIN[0-9]{1,}$\" ) ; } else { var channelNum ; if ( isAnalogInput . test ( address ) ) { channelNum = getChannelNum . exec ( address ) [ 0 ] ; result = self . getAINReading ( channelNum ) ; }", "del_tokens": "'DEVICE_NAME_DEFAULT' : 'TEST_DEVICE'", "commit_type": "improve"}
{"commit_tokens": ["added", "possibility", "for", "basic", "http", "authentification", ".", "updated", "test"], "add_tokens": "/ ** * Function defining a Bamboo instance * * @ param { String } host hostname . By default \"http://hostname.com:8085\" * @ param { String | null } username optional param for base HTTP authentification . Username * @ param { String | null } password optional param for base HTTP authentification . Password * @ constructor * / function Bamboo ( host , username , password ) { host = host || \"http://localhost:8085\" ; if ( username && password ) { var protocol = host . match ( / (^|\\s)(https?:\\/\\/) / i ) ; if ( _ . isArray ( protocol ) ) { protocol = _ . first ( protocol ) ; var url = host . substr ( protocol . length ) ; host = protocol + username + \":\" + password + \"@\" + url ; } }", "del_tokens": "/ * * Function defining a Bamboo instance * * @ param { String } hostname . E . g . \"http://hostname.com:8085\" * / function Bamboo ( host ) {", "commit_type": "add"}
{"commit_tokens": ["added", "gamma", "calculation", "and", "gamma", "tests"], "add_tokens": "* See { @ link http : //en.wikipedia.org/wiki/Black%E2%80%93Scholes_model#The_Greeks|Wikipedia} / ** * Calculates the gamma of a call and put option . * * @ private * @ param { Number } s Current price of the underlying * @ param { Number } k Strike price * @ param { Number } t Time to experiation in years * @ param { Number } v Volatility as a decimal * @ param { Number } r Anual risk - free interest rate as a decimal * @ returns { Number } The gamma of the option * / function getGamma ( s , k , t , v , r ) { var w = bs . getW ( s , k , t , v , r ) ; return ( isFinite ( w ) ) ? ( _stdNormDensity ( w ) / ( s * v * Math . sqrt ( t ) ) ) : 0 ; } getVega : getVega , getGamma : getGamma", "del_tokens": "getVega : getVega", "commit_type": "add"}
{"commit_tokens": ["Adding", "fix", "for", "sessions", "+", "verification", "."], "add_tokens": "req . app . get ( 'stormpathClient' ) . getAccount ( account . href , function ( err , acc ) { if ( err ) { res . send ( 500 ) ; } else { req . session . user = acc ; res . locals . user = acc ; req . user = acc ; helpers . render ( req . app . get ( 'stormpathAccountVerificationCompleteView' ) , res ) ; } } ) ;", "del_tokens": "req . session . user = account ; res . locals . user = account ; req . user = account ; helpers . render ( req . app . get ( 'stormpathAccountVerificationCompleteView' ) , res ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "issues", "with", "sequences"], "add_tokens": "var sliceSequence = ____SuperProtoOfIndexedSequence . slice . call ( this , begin , end , maintainIndices ) ; if ( ! maintainIndices && sliceSequence !== this ) { sliceSequence . toVector = function ( ) { return sequence . setBounds ( return sliceSequence ;", "del_tokens": "var sliced = ____SuperProtoOfIndexedSequence . slice . call ( this , begin , end , maintainIndices ) ; if ( ! maintainIndices && sliced !== this ) { sliced . toVector = function ( ) { return sequence . setBounds ( return sliced ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "protocol", "from", "script", "URLS", "-", "fixes", "https", ":", "//", "github", ".", "com", "/", "shakyShane", "/", "grunt", "-", "browser", "-", "sync", "/", "issues", "/", "5"], "add_tokens": "var expectedMatch1 = \"<script src='//0.0.0.0:\" + ports [ 0 ] + messages . socketIoScript + \"'></script>\" ; var expectedMatch2 = \"<script src='//0.0.0.0:\" + ports [ 1 ] + messages . clientScript + \"'></script>\" ;", "del_tokens": "var expectedMatch1 = \"<script src='http://0.0.0.0:\" + ports [ 0 ] + messages . socketIoScript + \"'></script>\" ; var expectedMatch2 = \"<script src='http://0.0.0.0:\" + ports [ 1 ] + messages . clientScript + \"'></script>\" ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "overriding", "default", "scope", "of", "ServiceWorker"], "add_tokens": "* - ` ` ( Object ) An object containing registration options for ServiceWorkerContainer . register ( ) . 'service-worker-url' : 'upup.sw.min.js' , 'registration-options' : { scope : './' } _serviceWorker . register ( _settings [ 'service-worker-url' ] , _settings [ 'registration-options' ] ) . then ( function ( registration ) { [ 'content' , 'content-url' , 'assets' , 'service-worker-url' , 'cache-version' , 'registration-options' ] . forEach ( function ( settingName ) {", "del_tokens": "'service-worker-url' : 'upup.sw.min.js' _serviceWorker . register ( _settings [ 'service-worker-url' ] , { scope : './' } ) . then ( function ( registration ) { [ 'content' , 'content-url' , 'assets' , 'service-worker-url' , 'cache-version' ] . forEach ( function ( settingName ) {", "commit_type": "allow"}
{"commit_tokens": ["added", "optional", "params", "to", "the", "signin", "endpoint"], "add_tokens": "password : Joi . string ( ) . required ( ) . description ( ACCESS_TOKEN_DESCR ) , //optional remember_me : Joi . string ( ) . description ( \"checkbox on\" ) , accept_terms : Joi . string ( ) . description ( \"checkbox on\" ) , \"g-recaptcha-response\" : Joi . string ( ) . default ( \"\" )", "del_tokens": "password : Joi . string ( ) . required ( ) . description ( ACCESS_TOKEN_DESCR )", "commit_type": "add"}
{"commit_tokens": ["Removed", "bad", "Sentence#toStringCtx", "()", "in", "favor", "of", "a", "specific", "Sentence#toStringKFG", "()", "for", "Kung", "-", "Fig", "KFG", "purpose"], "add_tokens": "Sentence . prototype . toStringKFG = function toStringKFG ( data , thisCtx ) data || ( this . indirection && this . indirection . data ) ,", "del_tokens": "Sentence . prototype . toStringCtx = function toStringCtx ( thisCtx ) arguments . length === 1 && this . indirection && this . indirection . data ? [ this . indirection . data ] : Array . prototype . slice . call ( arguments , 1 ) ,", "commit_type": "remove"}
{"commit_tokens": ["remove", "custom", "event", "listener", "before", "destroying", "components"], "add_tokens": "// databaseProvider: 'wilddog', // siteId: 'wd2168973289ifdmcg' // // locale: 'en' const wildfireConfig = { databaseProvider : 'firebase' , databaseConfig : { apiKey : 'AIzaSyB39UJBnIUYAQxu3zKkpyzjTZDDfHt7lzc' , authDomain : 'wild-fire-ee770.firebaseapp.com' , databaseURL : 'https://wild-fire-ee770.firebaseio.com' , projectId : 'wild-fire-ee770' , storageBucket : 'wild-fire-ee770.appspot.com' , messagingSenderId : '655484997793' } , pageURL : 'http://chengkang.me/wildfire' , pageTitle : 'Wildfire Demo' , locale : 'zh-CN' }", "del_tokens": "const wildfireConfig = { databaseProvider : 'wilddog' , databaseConfig : { siteId : 'wd2168973289ifdmcg' } , pageURL : 'http://chengkang.me/wildfire' , pageTitle : 'Wildfire Demo' , // locale: 'en' locale : 'zh-CN' } // databaseProvider: 'firebase', // apiKey: 'AIzaSyB39UJBnIUYAQxu3zKkpyzjTZDDfHt7lzc', // authDomain: 'wild-fire-ee770.firebaseapp.com', // databaseURL: 'https://wild-fire-ee770.firebaseio.com', // projectId: 'wild-fire-ee770', // storageBucket: 'wild-fire-ee770.appspot.com', // messagingSenderId: '655484997793'", "commit_type": "remove"}
{"commit_tokens": ["improve", "(", "events", ")", ":", "lint", "and", "minor", "doc", "change"], "add_tokens": "} * @ param { Function } [ callback ] . . .", "del_tokens": "} ; * @ param { Function } callback . . .", "commit_type": "improve"}
{"commit_tokens": ["Changed", "description", "of", "a", "certain", "test", ".", "Added", "extra", "keyword", "in", "the", "package", ".", "json", "file", "."], "add_tokens": "it ( 'Should just store the string value of the expression if it could not be processed ' , function ( done ) {", "del_tokens": "it ( 'Should just store the expression as is if the expression could not be processed ' , function ( done ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "samples", "to", "method", "s", "comments"], "add_tokens": "* Copyright 2011 Andrey A.I .  Sit ik <an r ey@sit n ik.ru> , * sponsored by Evil Martians . // if ( Visibility.hidden() ) { // Statistics.userOpenPageInBackgroundTab(); // } // // if ( 'prerender' == Visibility.state() ) { // Statistics.pageIsPrerended(); // } // // Dont use `Visibility.state()` to detect, is page visible, because // visibility states can extend in next API versions. // Use more simpler and general `Visibility.hidden()` for this cases. // // Visibility.change(function(e, state) { // if ( Visibility.hidden() ) { // Statistics.tabGoToBackground(); // } // }) // // // Visibility.onVisible(function() { // Notification.animateNotice(\"Hello\"); // }) // // Visibility.notPrerender(function() { // Statistics.countVisitor(); // }) // Visibility.every(60 * 1000, 5 * 60 * 1000, function() { // checkNewMails(); // }) // // Visibility.every(1000, function() { // updateCountdown(); // }) // // could use Chronos syntax sugar in interval arguments: // // Visibility.every('second', function() { // updateCountdown(); // }) // Visibility.every('1 minute', '5 minutes', function() { // checkNewMails(); // }) // // slideshow = Visibility.every(5 * 1000, function() { // changeSlide(); // }) // $('.stopSlideshow').click(function() { // Visibility.stop(slideshow); // })", "del_tokens": "* Copyright 2011 Andrey A.I .  Sit ik <an r ey@sit n ik.ru> . // could use Chronos syntax sugar in interval arguments.", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "require", "()", "call", "that", "doesn", "t", "work", "in", "jsdoc3", "/", "rhino"], "add_tokens": "en : JSON . parse ( fs . readFileSync ( path . join ( __dirname , '../res/en.json' ) , 'utf8' ) )", "del_tokens": "en : require ( '../res/en.json' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "websocket", "support", "-", "slow", "API", "calls", "fallback", "to", "websockets", ".", "Best", "balance", "of", "http", "and", "websocket", "from", "a", "server", "resource", "perspective", "(", "only", "uses", "websocket", "when", "necessary", ")", "."], "add_tokens": "if ( config && typeof ( config ) === 'function' ) { if ( ! callback ) callback = function ( ) { } ; var host = 'http://localhost' var url = host + '/rootapipath/' + command ; console . log ( 'success calling ' + command ) ; if ( data && data . slowMode ) { console . log ( command + ' is running in slow mode' ) ; //switch to slowmode, initiate socket.io var socket = io . connect ( host ) ; socket . emit ( 'callbackPlease' , data . uuid ) ; socket . on ( 'response' , function ( data ) { //got the callback from websocket! console . log ( 'Got slowmode callback from ' + command ) ; callback ( null , data ) ; socket . disconnect ( ) ; } ) ; } else { //respond now callback ( null , data ) ; }", "del_tokens": "if ( typeof ( config ) === 'function' ) { var url = 'http://localhost/rootapipath/' + command ; console . log ( 'success' ) ; callback ( null , data ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "helpers", ".", "hashmap", "modify"], "add_tokens": "add : function ( key , value , validator , force ) { if ( ! validator ) validator = validatorDefault ; if ( ! helper . HashMaps . exists . call ( this , key ) || ! validator ( value ) ) return false ; this [ key ] = value ;", "del_tokens": "add : function ( key , value , validator ) { if ( ! helper . HashMaps . exists . call ( this , key ) ) return false ; helper . HashMaps . add ( key , value , validator )", "commit_type": "fix"}
{"commit_tokens": ["improved", "performance", "in", "core", "logic", "of", "getters", "and", "setters"], "add_tokens": "getter : null , setter : null , return specialProps . getter ? specialProps . getter . call ( object ) : specialProps . value ; specialProps . setter ? specialProps . setter . call ( object , v ) : magic . set ( object , key , v , { fromSetter : true } ) ;", "del_tokens": "getter : function ( ) { return specialProps . value ; } , setter : function ( v ) { magic . set ( object , key , v , { fromSetter : true } ) ; } , return specialProps . getter . call ( object ) ; specialProps . setter . call ( object , v ) ;", "commit_type": "improve"}
{"commit_tokens": ["Remove", "test", "that", "fails", "on", "travis"], "add_tokens": "// Fails on travis // log: function (test) { // var self = this; // self.gitsync.sync(self.origin, 'MyBranch', self.target, function (err) { // self.gitsync.log(self.target, {}, function (err, commits) { // console.log(commits); // test.ok(!err, JSON.stringify(err)); // test.equals(commits.length, 4); // test.done(); // }); // }); // },", "del_tokens": "log : function ( test ) { var self = this ; self . gitsync . sync ( self . origin , 'MyBranch' , self . target , function ( err ) { self . gitsync . log ( self . target , { } , function ( err , commits ) { console . log ( commits ) ; test . ok ( ! err , JSON . stringify ( err ) ) ; test . equals ( commits . length , 4 ) ; test . done ( ) ; } ) ; } ) ; } ,", "commit_type": "remove"}
{"commit_tokens": ["Add", "numbers", "up", "to", "99"], "add_tokens": "var makiAvailable = fs . readdirSync ( makiRenders ) . reduce ( function ( mem , file ) { mem [ file . replace ( '.png' , '' ) ] = true ; return mem ; } , { } ) ; if ( ! options . symbol || ( options . symbol && options . symbol . length === 1 ) || ( options . symbol . length === 2 && ! isNaN ( parseInt ( options . symbol ) ) ) ) { if ( ! makiAvailable [ symbol ] ) { return callback ( new Error ( 'Marker \"' + JSON . stringify ( options ) + '\" is invalid because the symbol is not found.' ) ) ; }", "del_tokens": "if ( ! options . symbol || ( options . symbol && options . symbol . length === 1 ) ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "responseData", "as", "well", "after", "response", "OK"], "add_tokens": "var responseData = res . body ; / * * Handling superagent issue setting body to null , see more here : * https : //github.com/visionmedia/superagent/pull/638 * /", "del_tokens": "var responseData = res . body ; / * * Handling superagent issue setting body to null , see more here : * https : //github.com/visionmedia/superagent/pull/638 * /", "commit_type": "move"}
{"commit_tokens": ["Added", "the", "gfycat", "/", ":", "gfyId", "/", "related", "endpoint"], "add_tokens": "/ ** * Get gifs that are related to a gif . * / getRelatedContent ( { gfyId , count , cursor , from } , callback ) { if ( typeof gfyId === 'undefined' || gfyId === null || gfyId . length === 0 ) { return this . handleError ( 'invalid gfyId' , callback ) ; } let queryParams = { } ; if ( count ) queryParams . count = count ; if ( cursor ) queryParams . cursor = cursor ; if ( from ) queryParams . from = from ; let options = { path : ` ${ gfyId } ` , method : 'GET' , query : queryParams } return this . _request ( options , callback ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["update", "the", "webpack", "config", "to", "use", "a", "template", "loader", "to", "include", "the", "html", "and", "styles"], "add_tokens": "return ` ${ name } ${ value } ` ; const closingTag = tagName === 'script' ? '</script>' : '' ; return ` ${ tagName } ${ attributes . join ( ' ' ) } ${ closingTag } ` ;", "del_tokens": "return name + '=\"' + value + '\"' ; return '<' + tagName + ' ' + attributes . join ( ' ' ) + '>' ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "less", "-", "loader", "generator", "to", "work", "with", "less", "mixins"], "add_tokens": "loader : ExtractTextPlugin . extract ( 'style-loader' , 'css-loader!postcss-loader!less-loader' ) ,", "del_tokens": "loader : ExtractTextPlugin . extract ( 'style-loader' , 'css-loader!less-loader!postcss-loader' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Move", "snapshot", "to", "addon", "namespace", "."], "add_tokens": "return '<!DOCTYPE html>' ; let doctype = \"<!DOCTYPE \" + doctypeNode . name + ( doctypeNode . publicId ? ' PUBLIC \"' + doctypeNode . publicId + '\"' : '' ) + ( ! doctypeNode . publicId && doctypeNode . systemId ? ' SYSTEM' : '' ) + ( doctypeNode . systemId ? ' \"' + doctypeNode . systemId + '\"' : '' ) + '>' ; export function percySnapshot ( name ) {", "del_tokens": "return '<!DOCTYPE html>' let doctype = \"<!DOCTYPE \" + doctypeNode . name + ( doctypeNode . publicId ? ' PUBLIC \"' + doctypeNode . publicId + '\"' : '' ) + ( ! doctypeNode . publicId && doctypeNode . systemId ? ' SYSTEM' : '' ) + ( doctypeNode . systemId ? ' \"' + doctypeNode . systemId + '\"' : '' ) + '>' ; export default function ( name ) {", "commit_type": "move"}
{"commit_tokens": ["Move", "log", "before", "potentially", "exiting", "from", "function"], "add_tokens": "console . log ( chalk . green ( '\\nFiles uploaded successfully!\\n' ) ) ;", "del_tokens": "console . log ( chalk . green ( '\\nFiles uploaded successfully!\\n' ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Adding", "option", "to", "disable", "invocation", "so", "nesting", "module", ".", "export", "is", "not", "necessary", "."], "add_tokens": "if ( self . options . invoke !== false ) { if ( ! notAsync ) { mod = mod . call ( script , instance , function ( ) { self . __log ( 'Loaded *.' + map . join ( '.' ) ) ; next ( ) ; } ) ; } else if ( typeof mod === 'function' ) { mod = mod . call ( script , instance ) ; }", "del_tokens": "if ( ! notAsync ) { mod = mod . call ( script , instance , function ( ) { self . __log ( 'Loaded *.' + map . join ( '.' ) ) ; next ( ) ; } ) ; } else if ( typeof mod === 'function' ) { mod = mod . call ( script , instance ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "active", "user", "issue", "and", "updating", "deps"], "add_tokens": "return userService . findMe ? userService . findMe ( ) . then ( setUserLocal ) : { } ;", "del_tokens": "return userService . findMe ( ) . then ( setUserLocal ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "mesage", "for", "empty", "dashboard"], "add_tokens": "define ( 'hr/args' , [ ] , function ( ) { return { \"revision\" : 1381093933403 , \"baseUrl\" : \"/\" } ; } ) ;", "del_tokens": "define ( 'hr/args' , [ ] , function ( ) { return { \"revision\" : 1381089928919 , \"baseUrl\" : \"/\" } ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "caused", "by", "a", "careless", "re", "-", "throw", "when", "the", "log", "write", "-", "stream", "sends", "an", "error"], "add_tokens": "// Discard log file on errors and get a new one: logFile . on ( 'error' , err => { const filePath = helpers . buildLogFilePath ( fileName , devMode , logsBasePath ) ; const newLogFile = helpers . createLogFile ( fileName , devMode , logsBasePath ) ; worker . process . stdout . pipe ( newLogFile ) ; worker . process . stderr . pipe ( newLogFile ) ; // Logging takes place after the reset of the log-file, because there was an error with the old one: log . error ( 'Error on write stream \"%s\". %s' , filePath , err ) ; log . info ( 'Discarded it and opened a new one...' ) ; } ) ;", "del_tokens": "stream . on ( 'error' , err => { console . log ( 'Error opening write stream \"%s\". %s' , filePath , err ) ; throw err ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "typo", "in", "test"], "add_tokens": "ip . should . be . a ( 'string' ) ;", "del_tokens": "ip . shoud . be . a ( 'string' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "helper", "functions", "to", "fs"], "add_tokens": "export function createDir ( dir ) { fs . mkdirSync ( dir ) } write ( filename , json ) } export function write ( filename , data ) { fs . writeFileSync ( filename , data ) } export function copy ( source , target ) { fs . createReadStream ( source ) . pipe ( fs . createWriteStream ( target ) ) createDir , writeJson , write ,", "del_tokens": "fs . writeFileSync ( filename , json ) writeJson", "commit_type": "add"}
{"commit_tokens": ["fixing", "linter", "issue", "and", "a", "potential", "vulnerability"], "add_tokens": "const _baseClass = baseClass == null ? Model : baseClass ; if ( _baseClass !== Model && ! ( _baseClass . prototype instanceof Model ) ) { eval ( ` ${ modelName } extends _baseClass { if ( ! ptnKeyword . test ( key ) ) { errors . push ( new TypeError ( ` ${ key } ` ) ) ; } else { attributes [ key ] = schema [ key ] ; }", "del_tokens": "if ( baseClass == null ) { baseClass = Model ; } else if ( baseClass !== Model && ! ( baseClass . prototype instanceof Model ) ) { eval ( ` ${ modelName } extends baseClass { attributes [ key ] = schema [ key ] ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "logging", "calls", "changed", "evt", "handler", "names", "."], "add_tokens": "this . wss . on ( \"open\" , ( ) => { } ) ; this . wss . on ( \"error\" , e => { reject ( e ) ; } ) ; this . wss . on ( \"connection\" , conn => { u . log ( conn ) ; } ) ;", "del_tokens": "this . wss . onopen = ( ) => { } ; this . wss . onerror = e => { reject ( e ) ; } ; this . wss . onconnection = conn => { } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "icon", "prefix", "option", "for", "when", "using", "default", "controls"], "add_tokens": "gulp . watch ( paths . plyr . src . sprite , [ \"sprite\" ] ) ; gulp . watch ( paths . docs . src . templates , [ \"js\" ] ) ;", "del_tokens": "gulp . watch ( paths . plyr . src . sprite , \"sprite\" ) ; gulp . watch ( paths . docs . src . templates , \"js\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "convert", "script", "to", "match", "the", "new", "vue", "-", "skeleton", "structure"], "add_tokens": "command : 'sg settings -t ./build-tools/template,./node_modules/vue-transition-component/template' ,", "del_tokens": "command : 'sg settings -t ./template,./node_modules/vue-transition-component/template' ,", "commit_type": "update"}
{"commit_tokens": ["Added", "modified", "place", "wikidata", "comparator"], "add_tokens": "'added_place' : require ( './comparators/added_place' ) , 'modified_place_wikidata' : require ( './comparators/modified-place-wikidata' )", "del_tokens": "'added_place' : require ( './comparators/added_place' )", "commit_type": "add"}
{"commit_tokens": ["Make", "npm", "start", "an", "alias", "for", "packager", ".", "sh", "don", "t", "silently", "no", "-", "op", "on", "Windows"], "add_tokens": "var runPackager = require ( './run-packager.js' ) ; ' android: generates an Android project for your app' , ' run-android: builds your app and starts it on a connected Android emulator or device' runPackager ( false ) ; case 'help' : printUsage ( ) ; break ;", "del_tokens": "// var runPackager_DEPRECATED = require('./run-packager.js'); ' android: generates an Android project for your app' server ( args , config ) . done ( ) ; // runPackager_DEPRECATED();", "commit_type": "make"}
{"commit_tokens": ["added", "documentation", "in", "getCustomCallbacks", "=", ">", "createdCallback", "for", "why", "return", "on", "first", "instantiating"], "add_tokens": "ComponentClass . create = function ( $create_vars = { } ) { // return if native instantiating (with new) of custom element. // See CustomElement.register => .create(). What we want is to pass arguments // through .create() (see tests view.spec.js) therefore // we have to do that manually (see CustomElement.register .create() => createdCallback)", "del_tokens": "ComponentClass . create = function ( $create_vars ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "enterprise", "mode", "is", "always", "true"], "add_tokens": "const enterprise = process . env . NEO4J_ENTERPRISE === 'true' ;", "del_tokens": "const enterprise = ! ! process . env . NEO4J_ENTERPRISE ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "element", "text", "name", "and", "attributes", "from", "node", "to", "element", "itself"], "add_tokens": "xml . on ( 'updateElement: item' , function ( item ) { xml . on ( 'text: item > description' , function ( element ) { element . $text = element . $text", "del_tokens": "xml . on ( 'updateElement: item' , function ( node ) { var item = node . element ; xml . on ( 'text: item > description' , function ( node ) { node . text = node . text", "commit_type": "move"}
{"commit_tokens": ["Fix", "incorrect", "page", "size", "calculation", "on", "print"], "add_tokens": "var position = boxInstance . getProp ( self , \"position\" ) ; adapt . base . setCSSProperty ( boxContainer , \"position\" , position ? position . name : \"absolute\" ) ;", "del_tokens": "adapt . base . setCSSProperty ( boxContainer , \"position\" , \"absolute\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "postcss", "-", "selector", "-", "parser", "to", "handle", "all", "cases", "with", "the", "&", "selector"], "add_tokens": "var selectorParser = require ( 'postcss-selector-parser' ) ; // special case for the '&' selector, resolves to scope var processor = selectorParser ( function ( selectors ) { var hasNestingSelector = false ; selectors . walkNesting ( function ( selector ) { hasNestingSelector = true ; selector . replaceWith ( selectorParser . string ( { value : scope } ) ) ; } ) ; if ( ! hasNestingSelector ) { selectors . first . prepend ( selectorParser . string ( { value : scope + ' ' } ) ) ; } } ) ; return processor . processSync ( selector ) ;", "del_tokens": "// special case for a top level '&' selector, resolves to scope if ( selector === '&' ) { return scope ; } return scope + ' ' + selector ;", "commit_type": "use"}
{"commit_tokens": ["Use", "only", "one", "version", "of", "Edge", "in", "the", "test", "suite"], "add_tokens": "browserName : 'MicrosoftEdge' // SauceLabs-CI fails when multiple instances of Edge are running at the same time. / *SL_EDGE_13: { } , * /", "del_tokens": "browserName : 'MicrosoftEdge' , version : '14.14393' SL_EDGE_13 : { } ,", "commit_type": "use"}
{"commit_tokens": ["use", "lib", ".", "each", "to", "iterate", "in", "compileFor"], "add_tokens": "lib . each ( lookups , function ( lookup ) { lookup . target . value == 'loop' && lookup . val instanceof nodes . Literal ) { } ) ;", "del_tokens": "for ( var i = 0 , lookup ; lookup = lookups [ i ++ ] ; ) { lookup . target . value == 'loop' && lookup . val instanceof nodes . Literal ) { }", "commit_type": "use"}
{"commit_tokens": ["Added", "user", "to", "deploy", "system"], "add_tokens": "var deploySystem = function ( user , systemId , revisionId , out , cb ) { user : user ,", "del_tokens": "var deploySystem = function ( systemId , revisionId , out , cb ) {", "commit_type": "add"}
{"commit_tokens": ["add", "indentWithTabs", "option", "fix", "indentation", "model", "to", "allow", "this"], "add_tokens": "if ( ! stream . column ( ) ) { state . indented = stream . indentation ( ) ; if ( stream . eatSpace ( ) ) return null ;", "del_tokens": "var atStart = stream . column ( ) == 0 , spaces = stream . eatSpace ( ) ; if ( atStart ) { state . indented = spaces ; if ( spaces ) return null ;", "commit_type": "add"}
{"commit_tokens": ["Made", "auto", "alias", "expansions", "clearer"], "add_tokens": "sql . aliasExpansions = function aliasExpansions ( abbrs ) {", "del_tokens": "sql . setAbbrs = function setAbbrs ( abbrs ) {", "commit_type": "make"}
{"commit_tokens": ["add", "a", "much", "-", "requested", "buffer", "()", "method", "for", "convenience"], "add_tokens": "return this . _decode ( ) . then ( function ( buffer ) { return JSON . parse ( buffer . toString ( ) ) ; return this . _decode ( ) . then ( function ( buffer ) { return buffer . toString ( ) ; } ) ; } ; / ** * Decode response as buffer * * @ return Promise * / Body . prototype . buffer = function ( ) { // turn raw buffers into a single utf-8 buffer ) ;", "del_tokens": "return this . _decode ( ) . then ( function ( text ) { return JSON . parse ( text ) ; // turn raw buffers into utf-8 string ) . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "error", "in", "cases", "when", "scrollContainer", "()", "returns", "null", "or", "undefined"], "add_tokens": "var locked = $scrollContainer . length > 0 ; useAbsolutePositioning = locked ;", "del_tokens": "useAbsolutePositioning = opts . scrollContainer ( $table ) . length ; var locked = $scrollContainer . length > 0 ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "tags", "in", "conditional", "comments", "to", "be", "parsed"], "add_tokens": ", RE_COMMENT = / (<!--[^[i][\\S\\s]+?--\\s?>) / gm ;", "del_tokens": ", RE_COMMENT = / (<!--[\\S\\s]+?--\\s?>) / gm ;", "commit_type": "allow"}
{"commit_tokens": ["remove", "ipaddr", ".", "js", "depdendency"], "add_tokens": "const ipv6Normalize = require ( \"ipv6-normalize\" ) ; return cidrTools . normalize ( cls . fromBigInteger ( number ) . address ) ; cidrTools . normalize = ( cidr ) => { const cidrVersion = isCidr ( cidr ) ; if ( cidrVersion === 4 ) { return cidr ; } else if ( cidrVersion === 6 ) { const [ ip , prefix ] = cidr . split ( \"/\" ) ; return ` ${ ipv6Normalize ( ip ) } ${ prefix } ` ; } const ipVersion = net . isIP ( cidr ) ; if ( ipVersion === 4 ) { return cidr ; } else if ( ipVersion === 6 ) { return ipv6Normalize ( cidr ) ; throw new Error ( ` ${ cidr } ` ) ;", "del_tokens": "const ipaddr = require ( \"ipaddr.js\" ) ; return ipaddr . parse ( cls . fromBigInteger ( number ) . address ) . toString ( ) ; cidrTools . normalize = cidr => { if ( isCidr ( cidr ) ) { return ipaddr . parseCIDR ( cidr ) . toString ( ) ; } else if ( net . isIP ( cidr ) ) { return ipaddr . parse ( cidr ) . toString ( ) ; } else { throw new Error ( ` ${ cidr } ` ) ;", "commit_type": "remove"}
{"commit_tokens": ["Made", "most", "of", "the", "cloud", "component", "now", "works", "for", "all", "interaction", "with", "database", "next", "is", "to", "finish", "the", "update", "functions", "which", "gathers", "content", "from", "the", "API", ":", "s"], "add_tokens": "module . exports = { getRoutes : function ( client ) { functions . content ( req , res , client ) ; } }", "del_tokens": "module . exports = ( function ( ) { functions . content ( req , res ) ; } ) ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "collection", "references", "to", "Promises", "."], "add_tokens": "* @ param { Collection } collection function Promise ( col , type ) { this . col = col ;", "del_tokens": "function Promise ( type ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "cert", "URL", "validation", "to", "sns", "response", "handling"], "add_tokens": "exports . parseSNSResponse = parseSNSResponse ; var defaultHostPattern = / ^sns\\.[a-zA-Z0-9\\-]{3,}\\.amazonaws\\.com(\\.cn)?$ / ; return callback ( error . missingParameter ( 'Missing parameter on SNS response: ' + required [ i ] ) ) ; return callback ( error . invalidSignatureVersion ( 'Unknown SNS Signature version: ' + response . SignatureVersion ) ) ; var parsed = URL . parse ( response . SigningCertURL ) ; if ( parsed . protocol !== 'https:' || parsed . path . substr ( - 4 ) !== '.pem' || ! defaultHostPattern . test ( parsed . host ) ) { return callback ( error . invalidCertificateDomain ( 'The certificate is located on an invalid domain.' ) ) ; }", "del_tokens": "return callback ( err . missingParameter ( 'Missing parameter on SNS response: ' + required [ i ] ) ) ; return callback ( err . invalidSignatureVersion ( 'Unknown SNS Signature version: ' + response . SignatureVersion ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "dependency", "on", "fs", "module"], "add_tokens": "if ( ! grunt . file . exists ( sourceDir ) ) { if ( ! grunt . file . exists ( config . privateKey ) ) {", "del_tokens": "var fs = require ( 'fs' ) ; var existsSync = fs . existsSync ; if ( ! existsSync ( sourceDir ) ) { if ( ! existsSync ( config . privateKey ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "enter", "/", "leave", "events"], "add_tokens": "$scope . $apply ( function ( ) { ctrl . onEnter ( locals ) ; } ) ; $scope . $apply ( function ( ) { ctrl . onLeave ( locals ) ; } ) ;", "del_tokens": "ctrl . onEnter ( locals ) ; ctrl . onLeave ( locals ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "minitest", ".", "js", "and", "a", "basic", "test", "example"], "add_tokens": "var Splunk = require ( '../splunk/splunk.js' ) ; var NodeHttp = require ( '../utils/node_http' ) . NodeHttp ; var __bind = require ( '../utils/utils' ) . bind ; var Class = require ( '../lib/jquery.class' ) . Class ; var Async = require ( '../utils/async' ) ; var minitest = require ( '../external/minitest' ) ; var assert = require ( 'assert' ) ;", "del_tokens": "var Splunk = require ( '../splunk/splunk.js' ) , NodeHttp = require ( '../utils/node_http' ) . NodeHttp , __bind = require ( '../utils/utils' ) . bind ; Class = require ( '../lib/jquery.class' ) . Class , Async = require ( '../utils/async' ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "un", "-", "needed", "undef", "check"], "add_tokens": "for ( var header in headers ) { downloader . setRequestHeader ( header , headers [ header ] ) ;", "del_tokens": "if ( headers ) { for ( var header in headers ) { downloader . setRequestHeader ( header , headers [ header ] ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "not", "-", "image", "images", "getting", "in", "the", "way"], "add_tokens": "if ( info . hasImageContents && info . srcURL && info . srcURL . length > 1 ) {", "del_tokens": "if ( info . hasImageContents ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "cleanup", "and", "updated", "test", "tools"], "add_tokens": "const BbPromise = require ( 'bluebird' ) ; chai . use ( require ( 'chai-as-promised' ) ) ; let sandbox ; let module ; sandbox = sinon . sandbox . create ( ) ; sandbox . usingPromise ( BbPromise ) ; webpackMock = makeWebpackMock ( sandbox ) ; mockery . enable ( { warnOnUnregistered : false } ) ; log : sandbox . stub ( ) , consoleLog : sandbox . stub ( ) afterEach ( ( ) => { // This will reset the mocks too sandbox . restore ( ) ; } ) ; expect ( utilsMock . purgeCache ) . to . have . not . been . called ;", "del_tokens": "let module ; mockery . enable ( { warnOnUnregistered : false } ) ; webpackMock = makeWebpackMock ( ) ; log : sinon . spy ( ) , consoleLog : sinon . spy ( ) , webpackMock . _resetSpies ( ) ; utilsMock . _resetSpies ( ) ; expect ( utilsMock . purgeCache ) . to . have . callCount ( 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "status", ":", "standard", "from", "browsers", ".", "ts", "as", "it", "s", "the", "default"], "add_tokens": "if ( mdnEntry . status === 'standard' ) { return { syntax : mdnEntry . syntax } }", "del_tokens": "standard : 's' ,", "commit_type": "remove"}
{"commit_tokens": ["Added", "some", "documentation", "fixes", "added", "readme"], "add_tokens": "* @ memberof ApplicationConfig * @ memberof ApplicationConfig * @ memberof ApplicationConfig * @ returns { string } sdkType", "del_tokens": "* @ memberof ApplicationConfig * @ memberof ApplicationConfig", "commit_type": "add"}
{"commit_tokens": ["move", "webpack", "config", "into", "build"], "add_tokens": "entry : path . resolve ( __dirname , 'dev-entry.js' ) , path : path . resolve ( __dirname , '../dist' ) ,", "del_tokens": "entry : path . resolve ( __dirname , 'build/dev-entry.js' ) , path : path . resolve ( __dirname , 'dist' ) ,", "commit_type": "move"}
{"commit_tokens": ["Add", "skipping", "of", "tests", "and", "test", "groups", "."], "add_tokens": "test ( \"assert\" , ( ) => assert . isDefined ( assert ) ) . skip ( ) ,", "del_tokens": "test ( \"assert\" , ( ) => assert . isDefined ( assert ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "requirement", "to", "wait", "for", "promise", "to", "manipulate", "local", "models"], "add_tokens": "// Wait for initial data to load to check if data was merged. // By adding this new TODO, we now should have two in the list. return testIfInDOM ( todo , document . querySelectorAll ( \".todoView\" ) [ 1 ] ) ; return document . querySelectorAll ( \".todoView\" ) . length == 3 ; return _scope . todos . length == 4 ; if ( snapshot . val ( ) . length == 3 ) {", "del_tokens": "if ( _scope != null ) return false ; casper . thenEvaluate ( function ( ) { // Clean up Firebase to start fresh test. var fbRef = new Firebase ( _url ) ; fbRef . set ( null , function ( err ) { window . __flag = true ; } ) ; } ) ; casper . waitFor ( function ( ) { return this . getGlobal ( \"__flag\" ) === true ; } ) ; return testIfInDOM ( todo , document . querySelector ( \".todoView\" ) ) ; return document . querySelectorAll ( \".todoView\" ) . length == 2 ; return _scope . todos . length == 3 ; if ( snapshot . val ( ) . length == 2 ) {", "commit_type": "remove"}
{"commit_tokens": ["Made", "message", "properties", "enumerable", "(", "they", "are", "now", "shown", "by", "console", ".", "log", ")", "."], "add_tokens": "Object . defineProperty ( this , 'type' , { writable : false , value : type , enumerable : true } ) ; Object . defineProperty ( this , f , { writable : false , value : eventInitDict [ f ] , enumerable : true } ) ;", "del_tokens": "Object . defineProperty ( this , 'type' , { writable : false , value : type } ) ; Object . defineProperty ( this , f , { writable : false , value : eventInitDict [ f ] } ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "superficial", "flag", "aggregate", "checking"], "add_tokens": "var c = 1 , f = node . flag var r = visitRec ( node . left , node ) c += r [ 0 ] f = f || r [ 1 ] var r = visitRec ( node . right , node ) c += r [ 0 ] f = f || r [ 1 ] t . equals ( f , node . flagAggregate , \"checking flagAggregate\" ) return [ c , f ] t . equals ( n [ 0 ] , list . length , \"checking total count\" ) t . equals ( n [ 1 ] , list . some ( function ( v ) { v . flag } ) , \"checking flag\" )", "del_tokens": "var c = 1 c += visitRec ( node . left , node ) c += visitRec ( node . right , node ) return c t . equals ( n , list . length , \"checking total count\" )", "commit_type": "add"}
{"commit_tokens": ["use", "url", ".", "resolve", "to", "compose", "url"], "add_tokens": "path : url . resolve ( p . pathname , \"login\" ) path : url . resolve ( p . pathname , \"login\" ) , console . log ( \" serer.pathname =\" , server . pathname , path_string ) ; path : url . resolve ( server . pathname , path_string ) , console . log ( \"options =\" , options ) ; console . log ( \" text = \" , txt ) ;", "del_tokens": "path : path . join ( p . pathname , \"login\" ) path : path . join ( p . pathname , \"login\" ) , path : path . join ( server . pathname , path_string ) ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "passing", "absolute", "path", "to", "hux", "cmd"], "add_tokens": "return glob . sync ( path . join ( path . resolve ( path1 ) , consts . HUXLEYFILE_NAME ) ) ;", "del_tokens": "return glob . sync ( path . join ( process . cwd ( ) , path1 , consts . HUXLEYFILE_NAME ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "gulp", "tasks", "and", "added", "additional", "config", "for", "production", "compiling"], "add_tokens": "gulp . task ( 'gh-build-pages' , function ( ) { process . chdir ( './_docs' ) ; process . env . JEKYLL_ENV = 'production' ; const jekyll = childProc . spawnSync ( 'jekyll' , [ 'build' , '--config=_config.yml,_config_prod.yml' ] ) ; 'config-gh-pages' , 'components-gh-pages' , 'scss-gh-pages' , 'js-gh-pages' , 'gh-build-pages' process . chdir ( './_docs' ) ; '--drafts'", "del_tokens": "gulp . task ( 'move-gh-pages' , function ( ) { return gulp . src ( config . docs . rootPath + '/_site/**/*' ) . pipe ( gulp . dest ( config . docs . deployPath ) ) ; 'config-gh-pages' , 'components-gh-pages' , 'scss-gh-pages' , 'js-gh-pages' , 'move-gh-pages' process . chdir ( './docs' ) ; '--drafts' , '--baseurl=/Athena-Framework'", "commit_type": "update"}
{"commit_tokens": ["Fix", "minor", "typo", "in", "docs"], "add_tokens": "// Maximum age of the cache, in milliseconds", "del_tokens": "// Maximum age of the cache, in seconds", "commit_type": "fix"}
{"commit_tokens": ["Remove", "copy", "tnd", "concat", "task", "from", "Gruntfile", "and", "package", "file", "."], "add_tokens": "tasks : [ 'jshint' , 'uglify' ] grunt . registerTask ( 'default' , [ 'jshint' , 'uglify' ] ) ;", "del_tokens": "copy : { main : { expand : true , src : 'sticky-sidebar.js' , dest : 'docs/js' } , } , tasks : [ 'jshint' , 'uglify' , 'copy' ] grunt . loadNpmTasks ( 'grunt-contrib-concat' ) ; grunt . loadNpmTasks ( 'grunt-contrib-copy' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'uglify' , 'copy' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "a", "rear", "-", "error", "issue", "with", "stack", "trace", "being", "captured", "before", "message"], "add_tokens": "function RearError ( message , props ) { Error . captureStackTrace ( this , this . constructor ) ;", "del_tokens": "function RearError ( message , props ) { Error . captureStackTrace ( this , this . constructor ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "conversion", "between", "bd09ll", "and", "wgs84"], "add_tokens": "wgs84_bd09ll : function ( wgsLon , wgsLat ) { var c = this . wgs84_gcj02 ( wgsLon , wgsLat ) ; return this . gcj02_bd09ll ( c [ 0 ] , c [ 1 ] ) ; } , bd09ll_wgs84 : function ( wgsLon , wgsLat ) { var c = this . bd09ll_gcj02 ( wgsLon , wgsLat ) ; return this . gcj02_wgs84 ( c [ 0 ] , c [ 1 ] ) ; } , } ) ( ) ;", "del_tokens": "} ) ( ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "support", "for", "radio", "stack", "modules", "(", "e", ".", "g", ".", "SoftDevice", "on", "Gen", "3", ")"], "add_tokens": "'c' , 'a'", "del_tokens": "'c'", "commit_type": "add"}
{"commit_tokens": ["Added", ".", "travel", ".", "yml", "back", "in"], "add_tokens": "src : 'lib/**/*.js' , tests : 'test/**/*.js' pkg : grunt . file . readJSON ( 'package.json' ) , jshint : { all : [ 'Gruntfile.js' , files . src , files . tests ] } , mochacov : { test : { src : [ files . tests ] } , // Run with the spec testrunner coverage : { src : [ files . tests ] , options : { coveralls : { serviceName : 'travis-ci' , repoToken : process . env . COVERALLS_REPO_TOKEN } } } , options : { reporter : 'spec' , ignoreLeaks : false , files : [ files . tests ] } } , watch : { tests : { files : _ . toArray ( files ) , tasks : [ 'test' ] } } // Load third-party modules grunt . loadNpmTasks ( 'grunt-contrib-jshint' ) ; grunt . loadNpmTasks ( 'grunt-contrib-watch' ) ; grunt . loadNpmTasks ( 'grunt-mocha-cov' ) ; // Tasks // grunt.registerTask('travis', [ 'jshint', 'mochacov:test', 'mochacov:coverage' ]); grunt . registerTask ( 'travis' , [ 'mochacov:test' ] ) ; grunt . registerTask ( 'test' , [ 'jshint:all' , 'mochacov:test' ] ) ; // Default task (runs when running `grunt` without arguments) grunt . registerTask ( 'default' , [ 'test' ] ) ;", "del_tokens": "src : 'lib/**/*.js' pkg : grunt . file . readJSON ( 'package.json' )", "commit_type": "add"}
{"commit_tokens": ["Fix", "init", "of", "sandbox", "requests"], "add_tokens": "this . requests = this . server . requests ;", "del_tokens": "this . requests = this . sandbox . useFakeXMLHttpRequest ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "excluding", "NaN", "values"], "add_tokens": "NaNValues = false , value = cleanDeep ( value , { NaNValues , cleanKeys , cleanValues , emptyArrays , emptyObjects , emptyStrings , nullValues , undefinedValues } ) ; // Exclude NaN values. if ( NaNValues && Number . isNaN ( value ) ) { return ; } } ;", "del_tokens": "value = cleanDeep ( value , { cleanKeys , cleanValues , emptyArrays , emptyObjects , emptyStrings , nullValues , undefinedValues } ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "bulkload", "test", "for", "create", "/", "update", "/", "delete"], "add_tokens": "} , function ( err , results ) { results = _ . map ( results , function ( ret ) { return { id : ret . Id || null , success : ret . Success === \"true\" , errors : ret . Error ? [ ret . Error ] : [ ] } ; } ) ; self . emit ( 'response' , results ) ; callback ( err , results ) ;", "del_tokens": "} , function ( err , res ) { self . emit ( 'response' , res ) ; callback ( err , res ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "withActive", "with", "Modals", ":", "sparkles", ":"], "add_tokens": "C_ACTIVE : {", "del_tokens": "COMPONENTRY_ACTIVE : {", "commit_type": "use"}
{"commit_tokens": ["add", "production", "flag", "set", "node_env", "by", "default"], "add_tokens": "const minimist = require ( 'minimist' ) ; // get cmd args const argv = minimist ( process . argv . slice ( 2 ) ) ; if ( argv . production || argv . prod ) { set ( 'NODE_ENV' , 'production' ) ; } set ( 'NODE_ENV' , 'development' ) ; set ( 'DEV' , / development / . test ( get ( 'NODE_ENV' ) ) ) ; set ( 'PROD' , / production / . test ( get ( 'NODE_ENV' ) ) ) ;", "del_tokens": "set ( 'DEV' , / development|undefined / . test ( get ( 'NODE_ENV' ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "conga", ".", "Update", "README"], "add_tokens": "types : [ \"MonoSynth\" , \"Kick\" , \"Snare\" , \"Hat\" , \"Cowbell\" , \"Conga\" ] ,", "del_tokens": "types : [ \"MonoSynth\" , \"Kick\" , \"Snare\" , \"Cowbell\" ] ,", "commit_type": "add"}
{"commit_tokens": ["Add", "forgiveness", "on", "both", "sides", "of", "expected", "span", "durations", "on", "tests"], "add_tokens": "var FORGIVENESS = 0.2 ; assert ( duration > SERVER_WAIT * ( 1 - FORGIVENESS ) ) ; assert ( duration < SERVER_WAIT * ( 1 + FORGIVENESS ) ) ;", "del_tokens": "var FORGIVENESS = 1.2 ; assert ( duration > SERVER_WAIT ) ; assert ( duration < SERVER_WAIT * FORGIVENESS ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "set", "of", "tests", "for", "case1"], "add_tokens": "var tagContent = 'router2-content' ; var containers = document . querySelectorAll ( tagContent ) ; var matched = document . querySelector ( ` ${ tagContent } ${ hash } ` ) ;", "del_tokens": "var containers = document . querySelectorAll ( 'router2-content' ) ; var matched = document . querySelector ( ` ${ hash } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["improve", "debug", "speed", "and", "reliability", "using", "webpack", "-", "dev", "-", "middleware"], "add_tokens": "]", "del_tokens": "] , devtool : '#source-map'", "commit_type": "improve"}
{"commit_tokens": ["Fix", "bugs", "and", "add", "connectable", "support"], "add_tokens": "hashPairs . unshift ( keyName + ':' + popStack ( stack ) ) ; hashTypes . unshift ( keyName + ':' + popStack ( stack ) ) ; args . unshift ( popStack ( stack ) ) ; types . unshift ( popStack ( stack ) ) ;", "del_tokens": "hashPairs . push ( keyName + ':' + popStack ( stack ) ) ; hashTypes . push ( keyName + ':' + popStack ( stack ) ) ; args . push ( popStack ( stack ) ) ; types . push ( popStack ( stack ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "drive", "to", "allow", "blind", "following", "of", "last", "command", "."], "add_tokens": "if ( this . driveStepsRemaining < 0 ) { // go on the last command blindly } else if ( this . driveStepsRemaining > 1 ) { // decrement the drive chain callback ( ) ; callback ( ) ; this . driveStepsRemaining = 0 ;", "del_tokens": "if ( this . driveStepsRemaining > 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "new", "internal", "type", "-", "error"], "add_tokens": "[ 'buffer' , 'binary' ] , 'error' } , function ( value ) { /* error */ if ( value === null || value === undefined ) { return value ; } else if ( value instanceof Error || / Error$ / . test ( value . name ) || typeof value . message !== 'undefined' ) { return { name : value . name || 'Error' , message : value . message } ; } else if ( typeof value === 'string' ) { return { name : 'Error' , message : value } } else { throw new Error ( 'Invalid error: ' + value ) ; }", "del_tokens": "[ 'buffer' , 'binary' ]", "commit_type": "add"}
{"commit_tokens": ["fix", "getting", "CSS", "style", "keys"], "add_tokens": "const { decamelize } = require ( '../utils/strUtils' ) return decamelize ( key ) + ':' + value", "del_tokens": "return key + ':' + value", "commit_type": "fix"}
{"commit_tokens": ["removed", "meta", "module", "coercion", "in", "fetch", "method", "to", "prevent", "breaking", "object", "references", "being", "passed", "around"], "add_tokens": "Module . Meta . validate ( moduleMeta ) ; moduleMeta . deps = moduleMeta . deps || [ ] ;", "del_tokens": "moduleMeta = new Module . Meta ( moduleMeta ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "TypeError", "message", "from", "Chrome"], "add_tokens": "throw new TypeError ( 'Cannot convert undefined or null to object' ) ;", "del_tokens": "throw new TypeError ( 'expected an object' ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "(", "not", "yet", "finished", ")", "up", "and", "down", "method"], "add_tokens": "} ) . sort ( function ( a , b ) { if ( a . file > b . file ) { return 1 ; } else if ( a . file < b . file ) { return - 1 ; } else { return 0 ; } return this . pending ( ) . bind ( this ) . map ( function ( migration ) { return migration . file ; } ) . then ( function ( migrationFiles ) { return this . execute ( { migrations : migrationFiles , method : 'up' } ) ; } ) ; return this . executed ( ) . bind ( this ) . map ( function ( migration ) { return migration . file } ) . then ( function ( migrationFiles ) { return this . execute ( { migrations : [ migrationFiles [ 0 ] ] , method : 'down' } ) ; } ) ;", "del_tokens": "return this . storage . up ( ) ; return this . storage . down ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "deepGet", "empty", "string", "value"], "add_tokens": "if ( ! current [ parts [ i ] ] && current [ parts [ i ] ] !== false && current [ parts [ i ] ] !== 0 && current [ parts [ i ] ] !== '' ) return undefined ;", "del_tokens": "if ( ! current [ parts [ i ] ] && current [ parts [ i ] ] !== false && current [ parts [ i ] ] !== 0 ) return undefined ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "clustering", "/", "inverted", "-", "index"], "add_tokens": "* @ param { number } radius - Maximum radius of each cluster . radius = options . radius ; if ( typeof radius !== 'number' || radius < 0 ) throw new Error ( 'talisman/clustering/vp-tree: `radius` option should be a number >= 0.' ) ; const neighbors = tree . neighborsInRange ( radius , item ) ;", "del_tokens": "* @ param { number } range - Maximum range of each cluster . range = options . range ; if ( typeof range !== 'number' || range < 0 ) throw new Error ( 'talisman/clustering/vp-tree: `range` option should be a number >= 0.' ) ; const neighbors = tree . neighborsInRange ( range , item ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "use", "of", "point", "-", "cluster"], "add_tokens": "let N = 1e5 // size: Array(pos.length).fill(100).map(x => Math.random() * 5 + 5), size : 5 , // color: Array(pos.length).fill(0).map(() => colors[Math.floor(Math.random() * colors.length)]), color : 'rgba(0, 0, 255, .5)' ,", "del_tokens": "let N = 10001 size : Array ( pos . length ) . fill ( 100 ) . map ( x => Math . random ( ) * 5 + 5 ) , // size: 10, color : Array ( pos . length ) . fill ( 0 ) . map ( ( ) => colors [ Math . floor ( Math . random ( ) * colors . length ) ] ) , // color: 'rgba(0, 0, 255, .5)',", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "aspect", "ratio", "setting"], "add_tokens": "'cropAspectRatio' : '1.0' , // Convert the crop ratio to a float this . _options . cropAspectRatio = parseFloat ( this . _options . cropAspectRatio ) // Set the preview URL this . setAssetProp ( 'previewURL' , dataURI )", "del_tokens": "'cropAspectRatio' : 1.0 ,", "commit_type": "fix"}
{"commit_tokens": ["Created", "kelvin", "writer", "and", "associated", "length", "writers", "."], "add_tokens": "// mxfEvents.on('metadata', function (preface) { // console.log('*** METADATA ***\\n'); // console.log(util.inspect(preface, { depth : null })); // }); mxfEvents . once ( 'picture0' , function ( data ) { fs . writeFile ( 'frame0.h264' , data . value , console . error ) ; // var soundCount = 0; // // mxfEvents.on('sound0', function (data) { // console.log(`*** SOUND ${soundCount++} ***\\n`); // console.log(util.inspect(data, { depth : null })); // });", "del_tokens": "mxfEvents . on ( 'metadata' , function ( preface ) { console . log ( '*** METADATA ***\\n' ) ; console . log ( util . inspect ( preface , { depth : null } ) ) ; } ) ; mxfEvents . on ( 'picture0' , function ( data ) { var soundCount = 0 ; mxfEvents . on ( 'sound0' , function ( data ) { console . log ( ` ${ soundCount ++ } \\n ` ) ; console . log ( util . inspect ( data , { depth : null } ) ) ; } ) ;", "commit_type": "create"}
{"commit_tokens": ["Added", "a", "TypeError", "exception", "if", "a", "value", "going", "through", "the", "marshaler", "is", "not", "a", "marshalable", "value", "such", "as", "an", "empty", "string", "or", "an", "unknown", "class", "instance", "."], "add_tokens": "if ( _ . isUndefined ( result ) ) { throw new TypeError ( 'Marshaling error: encountered ' + ( ( item ) ? ( 'unexpected type ' + item ) : 'empty value' ) ) ; } return _ . assign ( marshaledItem , result ) ;", "del_tokens": "_ . assign ( marshaledItem , result ) ; return marshaledItem ;", "commit_type": "add"}
{"commit_tokens": ["implementing", "the", "allowHalfOpen", "option", "and", "destroy", "method"], "add_tokens": "sio . on ( 'disconnect' , this . _ondisconnect . bind ( this ) ) ; if ( stream . socket || stream . destroyed ) { Socket . prototype . _ondisconnect = function ( ) { var stream ; for ( var id in this . streams ) { stream = this . streams [ id ] ; // Close streams when the underlaying // socket.io connection is closed (regardless why) stream . emit ( 'close' ) ; stream . emit ( 'error' , new Error ( 'Connection aborted' ) ) ; } } ; Socket . prototype . cleanup = function ( id ) { delete this . streams [ id ] ; } ;", "del_tokens": "if ( stream . socket ) { // Utility functions var cleanup = function ( ) { delete this . streams [ id ] ; } . bind ( this ) ; // TODO: clean up the stream when finished to use it too. // add a listener to clean up. stream . on ( 'error' , cleanup ) ; // Close streams when the underlaying // socket.io connection is closed (regardless why) sio . once ( 'disconnect' , function ( ) { stream . emit ( 'end' ) ; stream . emit ( 'close' ) ; cleanup ( ) ; } ) ; // TODO: clean up the stream when finished to use it too. // add a listener to clean up. stream . on ( 'error' , function ( ) { delete this . streams [ id ] ; } . bind ( this ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "sourcemap", "when", "concat", "with", "sdtin"], "add_tokens": ". then ( ( stdin ) => [ { content : stdin } ] ) ;", "del_tokens": ". then ( ( stdin ) => [ { file : '-' , content : stdin } ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "supports", "for", "circular", "dependencies"], "add_tokens": "function getAllParents ( chunkGroup , parents , visitedGroups ) { if ( visitedGroups . includes ( chunkGroup ) ) return ; visitedGroups . push ( chunkGroup ) ; chunkGroup . getParents ( ) . forEach ( parentGroup => { parents . push ( parentGroup . chunks . filter ( chunk => ! parents . includes ( chunk ) ) ) ; getAllParents ( parentGroup , parents , visitedGroups ) ; } ) ; compilation . hooks . afterOptimizeChunks . tap ( 'Capture chunks' , ( chunks , chunkGroups ) => { this . chunkGroups = chunkGroups ; // Sort the chunks based on the graph depth (place leafs first, root of the tree // latest) // Get a list of all chunks that are parent of the currentChunk. A parent is // a chunk that has to be loaded before currentChunk can be loaded. let parents = [ ] Array . from ( currentChunk . groupsIterable ) . forEach ( group => getAllParents ( group , parents , [ ] ) ) ; parents = flatten ( parents ) . filter ( parent => parent != currentChunk ) ;", "del_tokens": "function getAllParents ( chunkGroup ) { return chunkGroup . getParents ( ) . map ( parentGroup => [ ... parentGroup . chunks , ... getAllParents ( parentGroup ) , ] ) ; compilation . hooks . afterOptimizeChunkAssets . tap ( 'Capture chunks' , ( chunks ) => { const parents = flatten ( Array . from ( currentChunk . groupsIterable ) . map ( getAllParents ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "send", "-", "to", "-", "owners", "example"], "add_tokens": "const WALLET1 = ` ` const WALLET2 = ` ` // Inspect utility used for debugging. const util = require ( \"util\" ) util . inspect . defaultOptions = { showHidden : true , colors : true , depth : 1 } const wallet1 = await openWallet ( WALLET1 ) const WHC = wallet1 . tokenBalance . find ( token => token . propertyid === 1 ) const WHCBalance = Number ( WHC . balance ) if ( WHCBalance < 1.0 ) { console . log ( ` Wallet 1 does not have a WHC token needed to run the test . Exiting . ` ) process . exit ( 0 ) } const BCHBalance = wallet1 . bchBalance walletInfo . bchBalance = balance [ 0 ]", "del_tokens": "const wallet1 = await openWallet ( ` ` ) walletInfo . bchBalance = balance", "commit_type": "update"}
{"commit_tokens": ["Use", "the", "unmount", "function", "as", "intended", "."], "add_tokens": "ReactDOM . unmountComponentAtNode ( node )", "del_tokens": "ReactDOM . unmountComponentAtNode ( node . firstElementChild )", "commit_type": "use"}
{"commit_tokens": ["Allow", "query", "-", "param", "hashes", "in", "chunk", "names"], "add_tokens": ". filter ( name => path . extname ( name ) . split ( '?' ) [ 0 ] === ` ${ extension } ` )", "del_tokens": ". filter ( name => path . extname ( name ) === ` ${ extension } ` )", "commit_type": "allow"}
{"commit_tokens": ["Add", "tests", "for", "other", "filter", "convenience", "methods", "clean", "up", "filter", ".", "js"], "add_tokens": "return this . filter ( 's' , searchString ) ; return this . filter ( 'name' , slug ) ;", "del_tokens": "this . _filters . s = searchString ; return this ; this . _filters . name = slug ; return this ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "with", "creating", "some", "listings"], "add_tokens": "// TODO: Don't clear the actions queue, but remove listings removed in the request // TODO: Don't clear the actions queue, but remove listings made in the request self . emit ( 'actions' , self . actions . create , self . actions . remove ) ;", "del_tokens": "self . emit ( 'actions' , self . actions . create , self . actions . remove ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "a", "forgotten", "read", "of", "a", "nonexistent", "parameter", "."], "add_tokens": "* headers : { & lt ; name 1 & gt ; : & lt ; value 1 & gt ; ... & lt ; name n & gt ; : & lt ; value n & gt ; } } < / li > * headers : { & lt ; name 1 & gt ; : & lt ; value 1 & gt ; ... & lt ; name n & gt ; : & lt ; value n & gt ; } } < / li >", "del_tokens": "* headers : { & lt ; name 1 & gt ; : & lt ; value 1 & gt ; ... & lt ; name n & gt ; : & lt ; value n & gt ; } , sessionId : & lt ; session id & gt ; } < / li > * headers : { & lt ; name 1 & gt ; : & lt ; value 1 & gt ; ... & lt ; name n & gt ; : & lt ; value n & gt ; } , sessionId : & lt ; session id & gt ; } < / li >", "commit_type": "remove"}
{"commit_tokens": ["Updating", "examples", "/", "echo", ".", "js", "and", "adding", "NPM", "information", "to", "package", ".", "json"], "add_tokens": "var xmpp = require ( \"../lib/xmpp\" ) ;", "del_tokens": "var xmpp = require ( \"../xmpp\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Implement", "event", "filtering", "in", "the", "REPL"], "add_tokens": "var override = function ( filter ) { // remove all the listeners (just one actually) anyway chrome . removeAllListeners ( eventName ) ; // a filter will always enable/update the listener if ( ! filter && registeredEvents [ eventName ] ) { // use the filter (or true) as a status token var statusToken = ( filter ? filter . toString ( ) : true ) ; status [ eventName ] = registeredEvents [ eventName ] = statusToken ; if ( filter ) { message = filter ( message ) ; }", "del_tokens": "var override = function ( ) { if ( registeredEvents [ eventName ] ) { chrome . removeAllListeners ( eventName ) ; status [ eventName ] = registeredEvents [ eventName ] = true ;", "commit_type": "implement"}
{"commit_tokens": ["fix", "annoying", "json", "parse", "error", "from", "simple", "-", "get"], "add_tokens": "this . timeout ( 20000 ) ; if ( err ) { cb ( err ) ; return ; } assert . strictEqual ( data . toString ( ) , '' ) ;", "del_tokens": "this . timeout ( 5000 ) ; if ( err ) return cb ( err ) ; assert . strictEqual ( data , '' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moving", "all", "resticted", "field", "stuff", "from", "api", "handler", "to", "schema", "toJSON", "methods"], "add_tokens": "//use __ prefix to stop special query params being included in filter Model . find ( filter , '-__v' ) . populate ( populations ) . sort ( '-createdAt' ) . exec ( function ( err , results ) {", "del_tokens": "//don't send these fields to client var defaultRestrictedFields = [ '__v' ] ; //TODO: remove restricted fields, move to schemas var restrictedFields = { sites : [ ] , pages : [ ] , parts : [ ] , templates : [ ] , users : [ ] , media : [ 'path' ] } ; //create addtional restricted fields var restricted = restrictedFields [ apiType ] . concat ( defaultRestrictedFields ) . map ( function ( field ) { return '-' + field ; } ) . join ( ' ' ) ; Model . find ( filter , restricted ) . populate ( populations ) . sort ( '-createdAt' ) . exec ( function ( err , results ) {", "commit_type": "move"}
{"commit_tokens": ["add", "working", "example", "of", "amp", "-", "install", "-", "serviceworker"], "add_tokens": "const swPrecache = require ( 'sw-precache' ) ; gulp . task ( 'compile:sw-precache' , [ 'copy:images' , 'copy:videos' , 'compile:example' ] , function ( ) { swPrecache . write ( path . join ( paths . dist . dir , 'sw.js' ) , { staticFileGlobs : [ path . join ( paths . dist . dir , 'LICENSE.txt' ) , path . join ( paths . dist . img , 'gist.png' ) , path . join ( paths . dist . img , 'abe_preview.png' ) , path . join ( paths . dist . favicons , '*.png' ) , path . join ( paths . dist . dir , 'components/amp-install-serviceworker/*.html' ) ] , stripPrefix : 'dist' , verbose : true } ) ; } ) ; 'compile:example' , 'compile:sw-precache' ] ) ;", "del_tokens": "'compile:example' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "class", "k", "-", "ButtonIcon", "--", "verticalArrow"], "add_tokens": "< div className = { classNames ( \"k-ExternalRichLink__element\" , \"k-ExternalRichLink__element--animate\" ) } > < span className = { classNames ( \"k-ButtonIcon\" , \"k-ButtonIcon--default\" , \"k-ButtonIcon--withoutHover\" , \"k-ButtonIcon--tiny\" , \"k-ButtonIcon--verticalArrow\" ) } >", "del_tokens": "< div className = \" k - ExternalRichLink__element -- animate \" > < span className = \" k - ButtonIcon -- default k - ButtonIcon -- withoutHover k - ButtonIcon -- tiny \" >", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "gulp", "build", "task", "to", "also", "copy", "the", "new", "lib", "to", "the", "example", "folders"], "add_tokens": "/ ** * ocLazyLoad - Load modules on demand ( lazy load ) with angularJS * @ version v0 .2 .0 * @ link https : //github.com/ocombe/ocLazyLoad * @ license MIT * @ author Olivier Combe < olivier . combe @ gmail . com > * / var self = this , config = null , moduleCache = [ ] , deferred = $q . defer ( ) , moduleName , errText ; self . setModuleConfig ( requireEntry ) ; }", "del_tokens": "var self = this , config = null , moduleCache = [ ] , deferred = $q . defer ( ) , moduleName , errText ; self . setModuleConfig ( requireEntry ) ; }", "commit_type": "update"}
{"commit_tokens": ["removing", ".", "only", "from", "test"], "add_tokens": "it ( 'should sync the path property if changed during rendering' , function ( done ) {", "del_tokens": "it . only ( 'should sync the path property if changed during rendering' , function ( done ) {", "commit_type": "remove"}
{"commit_tokens": ["move", "relative", "-", "to", "-", "homedir", "code", "to", "own", "npm", "package"], "add_tokens": "const relative_to_homedir = require ( '@brillout/relative-to-homedir' ) ; console . log ( green_checkmark ( ) + ' ' + description + ' found at ' + relative_to_homedir ( file_path ) ) ;", "del_tokens": "const { path_relative_to_homedir } = require ( '@reframe/utils/path_relative_to_homedir' ) ; console . log ( green_checkmark ( ) + ' ' + description + ' found at ' + path_relative_to_homedir ( file_path ) ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "some", "logs", "for", "debugging"], "add_tokens": "asyncTasks . push ( function ( callback ) { callback ( 'error in open image' ) ; console . log ( 'prop : ' , prop ) ; console . log ( 'msg.params[prop] : ' , msg . params [ prop ] ) ; console . log ( 'info.path : ' , info . path ) ; console . log ( 'list_params[prop] : ' , list_params [ prop ] ) ; console . log ( 'before cb()' ) ; //cb(null,\"file \" + prop + \" ready\"); // IIIII callback ( ) ; console . log ( error , results ) ; console . log ( 'in parallel end' ) ; console . log ( params ) ; console . log ( list_params ) ; console . log ( params ) ; console . log ( list_params ) ;", "del_tokens": "asyncTasks . push ( function ( cb ) { cb ( 'error in open image' ) ; cb ( null , \"file \" + prop + \" ready\" ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "new", "multiplex", "-", "templates"], "add_tokens": "} , layoutFile = 'layouts/' + layout + '/' + config . get ( 'names.template' ) + '.nunjucks' ; // hardcoded until layouts are in components res . send ( multiplex . render ( layoutFile , data ) ) ;", "del_tokens": "_ = require ( 'lodash' ) , } ; res . send ( multiplex . render ( layout , data , 'layout' ) ) ;", "commit_type": "use"}
{"commit_tokens": ["using", "sha1", "for", "filename", "in", "the", "cache"], "add_tokens": "var util = require ( 'util' ) , spawn = require ( 'child_process' ) . spawn , fs = require ( 'fs' ) , crypto = require ( 'crypto' ) , Cache = require ( './cache' ) , Funnel = require ( './funnel' ) , tts = { var sha1 = crypto . createHash ( 'sha1' ) ; sha1 . update ( voice + '_' + this . format + '_' + text ) ; var hex = sha1 . digest ( 'hex' ) ; var filename = this . cachePath + '/' + hex + this . format ;", "del_tokens": "var util = require ( 'util' ) , spawn = require ( 'child_process' ) . spawn , fs = require ( 'fs' ) , Cache = require ( './cache' ) , Funnel = require ( './funnel' ) , tts = { var filename = voice + '_' + this . format + '_' + text ; filename = this . cachePath + '/' + filename . replace ( / [^a-zA-Z0-9] / g , '_' ) + this . format ;", "commit_type": "use"}
{"commit_tokens": ["Use", "prefix", "for", "storage", "key"], "add_tokens": "\"utils/storage\" , ] , function ( $ , storage , analytic , _state , exercise , progress , sidebar ) { // Initialize storage storage . setBaseKey ( state . githubId ) ;", "del_tokens": "] , function ( $ , analytic , _state , exercise , progress , sidebar ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "linking", "of", "tests", "in", "and", "filtering", "of", "tests", "through", "query", "params"], "add_tokens": "this . header = this . el . appendChild ( createDom ( \"div\" , { className : \"header\" } , createDom ( \"h1\" , { } , createDom ( \"a\" , { href : \"?\" } , \"It\" ) ) ) ) ; createDom ( \"a\" , { href : \"?filter=\" + encodeURIComponent ( action . get ( \"fullName\" ) ) } , action . description ) createDom ( \"a\" , { href : \"?filter=\" + encodeURIComponent ( action . get ( \"fullName\" ) ) } , format ( \" %s, (%dms)\" , action . description , summary . duration ) )", "del_tokens": "this . header = this . el . appendChild ( createDom ( \"div\" , { className : \"header\" } , createDom ( \"h1\" , { } , \"It\" ) ) ) ; action . description format ( \" %s, (%dms)\" , action . description , summary . duration )", "commit_type": "add"}
{"commit_tokens": ["Add", "webpack", "json", "-", "loader", "to", "support", "requiring", "/", "exporting", "json", "file", "natively", "through", "webpack", "."], "add_tokens": "{ test : / \\.html$ / , loader : 'html' } , { test : / \\.json$ / , loader : 'json-loader' }", "del_tokens": "{ test : / \\.html$ / , loader : 'html' }", "commit_type": "add"}
{"commit_tokens": ["Move", "configuration", "to", "the", "lib", "directory"], "add_tokens": "const config = require ( './lib/configuration' ) ;", "del_tokens": "const config = require ( './configuration' ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "option", "to", "select", "a", "digest", "mode", "for", "cryptographic", "hashes"], "add_tokens": "function createPbkdf2Hash ( salt , secret , digest = 'sha256' ) { if ( ! crypto . getHashes ( ) . includes ( digest ) ) { throw new Error ( ` ${ digest } ` ) ; } return crypto . pbkdf2Sync ( secret , salt , 1000 , 64 , digest ) . toString ( 'base64' ) ; function createShaHash ( str , digest = 'sha256' ) { if ( ! crypto . getHashes ( ) . includes ( digest ) ) { throw new Error ( ` ${ digest } ` ) ; } return crypto . createHash ( digest ) . update ( str , 'base64' ) . digest ( 'base64' ) ;", "del_tokens": "function createPbkdf2Hash ( salt , secret ) { return crypto . pbkdf2Sync ( secret , salt , 1000 , 64 , 'sha512' ) . toString ( 'base64' ) ; function createShaHash ( str ) { return crypto . createHash ( 'sha512' ) . update ( str , 'base64' ) . digest ( 'base64' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "flash", "to", "req", "mock"], "add_tokens": "'body' , 'flash'", "del_tokens": "'body'", "commit_type": "add"}
{"commit_tokens": ["Added", "public", "method", "to", "retrieve", "access", "token", "from", "refresh", "token", "."], "add_tokens": "/ ** * Retrieves access token using refresh token * @ param { function = } callback callback * / OAuth2Client . prototype . getAccessToken = function ( callback ) { var that = this ; if ( ! this . credentials . refresh_token ) { throw new Error ( 'No refresh token is set' ) ; } this . refreshToken_ ( this . credentials . refresh_token , function ( err , result ) { if ( err ) { callback ( err , null ) ; } else { var tokens = result ; tokens . refresh_token = that . credentials . refresh_token ; that . credentials = tokens ; callback ( null , that . credentials ) ; } } ) ; } ; if ( ! credentials . access_token && ! credentials . refresh_token ) { throw new Error ( 'No access or refresh token is set.' ) ;", "del_tokens": "if ( ! credentials . access_token ) { throw new Error ( 'No access token is set.' ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "wrap", "(", "Farr", ")", "issue", "on", "IE"], "add_tokens": "$ . clone ( $ . create ( 'char_group' , 'hanzi cjk' ) ) $ . clone ( $ . create ( 'char' , 'hanzi cjk' ) ) $ . clone ( $ . create ( 'word' ) ) $ . clone ( $ . create ( 'char' , 'punct' ) ) $ . clone ( $ . create ( 'char' , 'alphabet latin' ) ) $ . clone ( $ . create ( 'char' , 'alphabet ellinika greek' ) ) $ . clone ( $ . create ( 'char' , 'alphabet kirillica cyrillic' ) )", "del_tokens": "$ . create ( 'char_group' , 'hanzi cjk' ) $ . create ( 'char' , 'hanzi cjk' ) $ . create ( 'word' ) $ . create ( 'char' , 'punct' ) $ . create ( 'char' , 'alphabet latin' ) $ . create ( 'char' , 'alphabet ellinika greek' ) $ . create ( 'char' , 'alphabet kirillica cyrillic' )", "commit_type": "fix"}
{"commit_tokens": ["Change", "multi", "-", "task", "name", "for", "benchmark"], "add_tokens": "all : {", "del_tokens": "singleTest : {", "commit_type": "change"}
{"commit_tokens": ["Added", "logic", "to", "ignore", "save", "if", "user", "isn", "t", "logged", "in", ";", "also", "added", "logic", "to", "mark", "record", "with", "modifiedBy", "field", "."], "add_tokens": "session = this . get ( 'session' ) ; if ( ! session || ! session . isAuthenticated ) { return new Ember . RSVP . Promise ( function ( resolve , reject ) { Ember . run ( null , reject , \"ERROR you must be logged in to save\" ) ; } ) ; } var sessionVars = session . store . restore ( ) ; this . set ( 'modifiedBy' , sessionVars . name ) ; this . _super ( ) . then ( function ( results ) { this . rollback ( ) ; this . reload ( ) . then ( function ( record ) { } . bind ( this ) ) ; } . bind ( this ) ) ;", "del_tokens": "self = this ; self . _super ( ) . then ( function ( results ) { self . rollback ( ) ; self . reload ( ) . then ( function ( record ) { } ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "DHT", "for", "finding", "instances", "to", "replicate", "with", "use", "internal", "log", "system"], "add_tokens": "var hat = require ( \"hat\" ) ; module . dbId = argv [ \"db-identifier\" ] ; module . dbId = ( module . dbId && module . dbId . length == 40 && parseInt ( module . dbId , 16 ) ) ? module . dbId : hat ( 160 , 16 ) ; db . listenReplications ( module . dbId ) ; // start our replication server db . findReplications ( module . dbId ) ; // replicate to other instances / * * /", "del_tokens": "db . listenReplications ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Improving", "get", "method", "for", "widgets"], "add_tokens": "return ( node && node . __widget ) || null ;", "del_tokens": "return node . __widget || null ;", "commit_type": "improve"}
{"commit_tokens": ["Use", "the", "linked", "-", "list", "implementation", "from", "utils"], "add_tokens": "var LinkedList = require ( 'chip-utils/linked-list' ) ; LinkedList . makeNode ( this ) ;", "del_tokens": "this . prev = null ; this . next = null ;", "commit_type": "use"}
{"commit_tokens": ["Use", "api", ".", "commonform", ".", "org", "publication", "API"], "add_tokens": "var getPublication = require ( 'commonform-get-publication' ) // Regular expression for references to publications. var PUBLICATION = / ^([a-z]+)\\/([a-z-]+)@([0-9eucd]+)$ / } else if ( PUBLICATION . test ( directive ) ) { var match = PUBLICATION . exec ( directive ) getPublication ( function ( error , publication ) { getForm ( publication . digest , e ( callback , function ( form ) {", "del_tokens": "var getProject = require ( 'commonform-get-project' ) // Regular expression for references to projects. var PROJECT = / ^([a-z]+)\\/([a-z-]+)@([0-9eucd]+)$ / } else if ( PROJECT . test ( directive ) ) { var match = PROJECT . exec ( directive ) getProject ( function ( error , project ) { getForm ( project . form , e ( callback , function ( form ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "RectilinearView", "documentation", "."], "add_tokens": "* @ classdesc A view implementing a rectilinear projection for 360  mages.", "del_tokens": "* @ classdesc A view implementiong a rectilinear projection for 360  mages.", "commit_type": "fix"}
{"commit_tokens": ["Improved", "supported", "field", "rules", "adding", "square", "for", "options", "[]", "."], "add_tokens": "FIELDS_REGEXP = / (\\w+:(?:[\\w.|\\+]|(?:,(?!\\s)|(?:\\[[\"\\w,\\s]+\\]))|(?:\\[.*?\\])|(?:,\\s*\\w*?\\]))+) / g ;", "del_tokens": "FIELDS_REGEXP = / (\\w+:(?:[\\w.|\\[\\]\\+]|(?:,(?!\\s))|(?:,\\s*\\w*?\\]))+) / g ;", "commit_type": "improve"}
{"commit_tokens": ["Allow", "for", "LDAPJS", "options", "to", "be", "passed", "through", "to", "the", "internal", "client", "wrapper", "."], "add_tokens": "* @ param { String } url The url to use when creating the LDAP client . * @ param { object } opts The optional LDAP client options . function createClient ( url , opts ) { url = url || this . url || ( this . opts || { } ) . url || ( opts || { } ) . url ; var opts = getLdapOpts ( _ . defaults ( { } , { url : url } , opts , this . opts ) ) ; var client = createClient . call ( self , null , opts ) ; var referralClient = createClient . call ( self , referralUrl , opts ) ;", "del_tokens": "* @ param { String } [ url ] The url to use when creating the LDAP client . function createClient ( url ) { url = url || this . url || ( this . opts || { } ) . url ; var opts = _ . defaults ( { } , { url : url } , this . opts ) ; var client = createClient . call ( self ) ; var referralClient = createClient . call ( self , referralUrl ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "initial", "scene", "for", "devices", ".", "Update", "packages", "."], "add_tokens": "< View style = { { backgroundColor : borderColor , height : 1 } } / > backgroundColor : 'white' ,", "del_tokens": "< View style = { { backgroundColor : borderColor , height : 1 , flex : 1 } } / >", "commit_type": "add"}
{"commit_tokens": ["Added", "getData", "method", "to", "session", "behavior", "."], "add_tokens": "var errors = require ( 'feathers-errors' ) ; return new Promise ( function ( resolve , reject ) { . then ( function ( payload ) { return resolve ( new Session ( payload ) ) ; } ) getData ( ) { return new Promise ( function ( resolve , reject ) { app . authentication . getJWT ( ) . then ( function ( data ) { if ( data ) { return resolve ( data ) ; } reject ( new errors . NotAuthenticated ( 'Not Authenticated' ) ) ; } ) ; } ) ; } ,", "del_tokens": "return new Promise ( ( resolve , reject ) => { . then ( payload => resolve ( new Session ( payload ) ) )", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "test", "variable", "assigned", "to", "app", "so", "that", "it", "does", "not", "override", "the", "previous", "test", "case"], "add_tokens": "app . __utest_regctrl_result = {", "del_tokens": "app . __utest_ctrl_result = {", "commit_type": "update"}
{"commit_tokens": ["Fixing", "missing", "semi", "-", "colon"], "add_tokens": "setTemplateUrl ( name , templateUrl ) ;", "del_tokens": "setTemplateUrl ( name , templateUrl )", "commit_type": "fix"}
{"commit_tokens": ["Make", "request", ".", "js", "a", "peerDependency"], "add_tokens": "let request ; if ( typeof request === 'undefined' ) { request = require ( 'request' ) ; }", "del_tokens": "const request = require ( 'request' ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "day", "-", "based", "key", "for", "day", "cells"], "add_tokens": "{ week . map ( day => this . renderDay ( month , day ) ) } renderDay ( month , day ) { let key = ` ${ day . getFullYear ( ) } ${ day . getMonth ( ) } ${ day . getDate ( ) } ` ; return < div key = { ` ${ key } ` } className = { className } / > ; < div key = { key } className = { className }", "del_tokens": "{ week . map ( ( day , j ) => this . renderDay ( month , day , j ) ) } renderDay ( month , day , i ) { return < div key = { ` ${ i } ` } className = { className } / > ; < div key = { i } className = { className }", "commit_type": "use"}
{"commit_tokens": ["Add", "watch", "to", "package", ".", "json"], "add_tokens": "'test' : 'Executes the karma testsuite.' , 'watch' : 'Automatically rebuild /dist whenever /src files change.'", "del_tokens": "'test' : 'Executes the karma testsuite.'", "commit_type": "add"}
{"commit_tokens": ["Fixing", "java", "path", "issue", "and", "apk", "-", "utils", "functional", "test", "."], "add_tokens": "const sep = path . sep ; let java = ` ${ getJavaHome ( ) } ${ sep } ${ sep } ` ;", "del_tokens": "let java = getJavaHome ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["makes", "uglify", "remove", "some", "more", "comments", "at", "the", "beginning", "of", "the", "file"], "add_tokens": "* $dom library ( v0 .9 .1 b ) copyright 2009 , Keith Clark ; // empty statement to make uglify remove the following comments", "del_tokens": "* @ preserve $dom library ( v0 .9 .1 b ) copyright 2009 , Keith Clark", "commit_type": "make"}
{"commit_tokens": ["Fix", "issue", "with", "html", ".", "replace", "mangling", "$&"], "add_tokens": "html = html . replace ( source . context , function ( ) { return content ; } ) ; }", "del_tokens": "html = html . replace ( source . context , content ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Create", "and", "test", "declaration", "-", "semicolon", "-", "space", "-", "before"], "add_tokens": "tr . ok ( \"a::before { content: \\\";a\\\"; }\" ) tr . ok ( \"a::before { content: \\\"; a\\\"; }\" ) tr . ok ( \"a::before { content: \\\";a\\\"; }\" ) tr . ok ( \"a::before { content: \\\"; a\\\"; }\" )", "del_tokens": "tr . ok ( \"a::before { content: \\\":a\\\"; }\" ) tr . ok ( \"a::before { content: \\\": a\\\"; }\" ) tr . ok ( \"a::before { content: \\\":a\\\"; }\" ) tr . ok ( \"a::before { content: \\\": a\\\"; }\" )", "commit_type": "create"}
{"commit_tokens": ["Add", "deepRequired", "support", "for", "Collections"], "add_tokens": "isRequired : function ( property , group , deepRequired ) { if ( deepRequired ) { if ( 'Collection' === constraint . __class__ ) { constraint = constraint . constraint ; // ensure constraint of collection gets the same deepRequired option constraint . options . deepRequired = deepRequired ; } if ( constraint instanceof Constraint ) { for ( var node in constraint . nodes ) { if ( constraint . isRequired ( node , group , deepRequired ) ) { return true ; } var isRequired = this . isRequired ( property , group , this . options . deepRequired ) ; if ( object instanceof Assert || ( _isArray ( object ) && object [ 0 ] instanceof Assert ) ) {", "del_tokens": "isRequired : function ( property , group ) { if ( constraint instanceof Constraint && this . options . deepRequired ) { for ( var node in constraint . nodes ) { if ( constraint . isRequired ( node , group ) ) { return true ; var isRequired = this . isRequired ( property , group ) ; if ( object instanceof Assert || ( _isArray ( object ) && object [ 0 ] instanceof Assert ) ) {", "commit_type": "add"}
{"commit_tokens": ["Allow", "creating", "of", "service", "when", "plugin", "enabled"], "add_tokens": "if ( _ . isEmpty ( currentRolePolicies ) && _ . has ( currentTemplate , 'Resources.IamPolicyLambdaExecution' ) ) { if ( _ . isEmpty ( stageRolePolicies ) && _ . has ( stageStack , 'Resources.IamPolicyLambdaExecution' ) ) { if ( stageRolePolicies . length !== 1 ) {", "del_tokens": "if ( _ . isEmpty ( currentRolePolicies . length ) && _ . has ( currentTemplate , 'Resources.IamPolicyLambdaExecution' ) ) { if ( _ . isEmpty ( stageRolePolicies . length ) && _ . has ( stageStack , 'Resources.IamPolicyLambdaExecution' ) ) { if ( stageRolePolicies . length !== 1 || currentRolePolicies . length !== 1 ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "functionality", "to", "get", "tokens", "by", "consumer", "including", "expired", "tokens", ".", "Added", "functionality", "to", "not", "delete", "expired", "tokens", "instead", "archive", "them", ".", "We", "are", "archiving", "them", "so", "we", "don", "t", "search", "them", "on", "every", "db", "call", "."], "add_tokens": "s . get = function ( _token , options ) { return tokenDao . get ( tokenId , options ) s . getTokensByConsumer = function ( id , options ) { return tokenDao . getTokensByConsumer ( id , options ) ; } ;", "del_tokens": "s . get = function ( _token ) { return tokenDao . get ( tokenId )", "commit_type": "add"}
{"commit_tokens": ["Added", "debug", "to", "utils", ".", "status"], "add_tokens": "case 'debug' : msg = '\\x1B[36mDEBUG\\x1B[0m: ' + msg ; break ; [ 'info' , 'error' , 'fatal' , 'ok' , 'debug' , 'bold' ] . forEach ( function ( type ) {", "del_tokens": "[ 'info' , 'error' , 'fatal' , 'ok' , 'bold' ] . forEach ( function ( type ) {", "commit_type": "add"}
{"commit_tokens": ["added", "types", "and", "readme", "for", "useGregorianParser"], "add_tokens": "describe ( \"use gregorian calendar parser in 'fa' locale\" , function ( ) {", "del_tokens": "describe ( \"use gregorian parser in 'fa' locale\" , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "bunch", "of", "tests", "for", "view", "behavior", "including", "tests", "for", "remove", "and", "destroy"], "add_tokens": "this . mutateChildViews ( function ( view ) { // remove from parent if found if ( this . get ( 'parentView' ) ) { this . removeFromParent ( ) ; } //Do generic destroy. It takes care of mixins and sets isDestroyed to YES. sc_super ( ) ; return this ; // done with cleanup", "del_tokens": "this . $ ( ) . remove ( ) ; this . _destroy ( ) ; // core destroy method // remove from parent if found if ( this . get ( 'parentView' ) ) { this . removeFromParent ( ) ; } //Do generic destroy. It takes care of mixins and sets isDestroyed to YES. sc_super ( ) ; return this ; // done with cleanup } , _destroy : function ( ) { childView . mutateChildViews ( function ( view ) { return this ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "indent", "rule", "to", "allow", "static", "offsets", "for", "variables"], "add_tokens": "'];' message : 'Expected indentation of 7 spaces but found 6.' , type : 'Identifier' , message : 'Expected indentation of 3 spaces but found 2.' , type : 'Identifier' , message : 'Expected indentation of 3 spaces but found 0.' , type : 'Identifier' , message : 'Expected indentation of 0 spaces but found 3.' , type : 'Keyword' , message : 'Expected indentation of 3 spaces but found 6.' , type : 'Keyword' , message : 'Expected indentation of 0 spaces but found 3.' , type : 'Keyword' , message : 'Expected indentation of 3 spaces but found 6.' , type : 'Identifier' , message : 'Expected indentation of 6 spaces but found 3.' , type : 'Identifier' , message : 'Expected indentation of 6 spaces but found 4.' , type : 'Identifier' ,", "del_tokens": "'];' , message : 'Expected indentation of 7 space characters but found 6.' , type : 'VariableDeclarator' , message : 'Expected indentation of 3 space characters but found 2.' , type : 'ExpressionStatement' , message : 'Expected indentation of 3 space characters but found 0.' , type : 'ExpressionStatement' , message : 'Expected indentation of 0 space characters but found 3.' , type : 'SwitchCase' , message : 'Expected indentation of 3 space characters but found 6.' , type : 'BreakStatement' , message : 'Expected indentation of 0 space characters but found 3.' , type : 'SwitchCase' , message : 'Expected indentation of 3 space characters but found 6.' , type : 'ExpressionStatement' , message : 'Expected indentation of 6 space characters but found 3.' , type : 'VariableDeclarator' , message : 'Expected indentation of 6 space characters but found 4.' , type : 'VariableDeclarator' ,", "commit_type": "fix"}
{"commit_tokens": ["Using", "twitter", "-", "text", "module", "to", "auto", "link", "comment", "content"], "add_tokens": "import twitter from 'twitter-text' ; child . innerHTML = twitter . autoLink ( twitter . htmlEscape ( comment . content ) ) ;", "del_tokens": "child . appendChild ( document . createTextNode ( comment . content ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "docs", "for", "restifier", "global"], "add_tokens": "* The main function . Wraps { RestAPI # setup } . * * @ global * @ see RestAPI # setup * * @ global * @ see RestAPI * * @ returns RestAPI A new RestAPI . restifier . api = function ( ) { * Represents a RESTful API powered by Restifier . * * @ class", "del_tokens": "/ ** * @ alias restifier . api * / * @ alias RestAPI . setup restifier . api = function ( cb ) { * @ alias restifier . api", "commit_type": "add"}
{"commit_tokens": ["added", "compile", "script", "for", "bgs", ".", "updated", "script", "for", "cpp"], "add_tokens": "\" stateLevel_{{stateLevel}} = {{stateName}};\" , \" if ( {{&guard}} ) {\" , \" changeState = 1;\" , \" // TRANSITION::{{prevState.name}}->{{finalState.name}}\" , \"{{> setState}}\" , \" // start state timer (@ next states period)\" , \" hardware_set_soft_timer({{#convertPeriod}}{{&timerPeriod}}{{/convertPeriod}},state_timer_handle,0);\" , \" // execute the transition function\" , \"{{&transitionFunc}}\" , \" } // END::TRANSITION::{{prevState.name}}->{{finalState.name}}\\n\" \"{{#getPrefix}}\" , \"{{#transitions}}\" , \"{{> transition}}\" , // check all transitions \"{{/transitions}}\" , \"{{#State_list}}\" , \"{{> execute}}\" , // execute all substates (transitions and functions) \"{{/State_list}}\" , \"{{#execute}}\" , // only add the following if execute is true \"{{&function}}\" , // run the state function \"}\" , \"{{/getPrefix}}\" , // takes a scope with: root(state), getPrefix(function), and execute(bool) \"{{#execute}}\" , // only add the following if execute is true", "del_tokens": "\"stateLevel_{{stateLevel}} = {{stateName}};\" , \"if ( {{&guard}} ) {\" , \" changeState = 1;\" , \" // TRANSITION::{{prevState.name}}->{{finalState.name}}\" , \" {{> setState}}\" , \" // start state timer (@ next states period)\" , \" hardware_set_soft_timer( {{timerPeriod}}, state_timer_handle, 0);\" , \" // execute the transition function\" , \" {{&transitionFunc}}\" , \"}\" \" {{#transitions}}\" , // if there are any transitions out of this state \" {{> transition}}\" , \" {{/transitions}}\" , \" {{#State_list}}\" , \" {{> execute}}\" , // recurse here \" {{/State_list}}\" , \"{{#execute}}\" , // only add the following if execute is true \" {{&function}}\" , \"}\" // takes a scope with: root, prefix, and execute \"{{#execute}}\" ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "crash", "on", "receiving", "a", "QUIT"], "add_tokens": "if ( statechanges . utilityFunctions . isNicknameInUserlist ( nickname , channel . userlist ) ) { statechanges . utilityFunctions . setActiveWindow ( state , { serverIdx : serverIdx , channelIdx : channelIdx - 1 } ) ; statechanges . utilityFunctions . setActiveWindow ( state , { serverIdx : serverIdx } ) ; // TODO: implement when query windows can be closed", "del_tokens": "if ( this . isNicknameInUserlist ( nickname , channel . userlist ) ) { this . setActiveWindow ( state , { serverIdx : serverIdx , channelIdx : channelIdx - 1 } ) ; this . setActiveWindow ( state , { serverIdx : serverIdx } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "interval", ".", "invert", "and", "ability", "to", "transpose", "down"], "add_tokens": "Note . prototype . transpose = function ( int , down ) { // Transposing down is the same as transposing up by inverted interval if ( down ) return this . transpose ( int . invert ( ) ) ;", "del_tokens": "Note . prototype . transpose = function ( int ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "merge", "module", "in", "place", "of", "builting", "merge", "function"], "add_tokens": "var merge = require ( 'merge' ) ; var options = merge ( true , this . options ) ;", "del_tokens": "var options = merge ( { } , this . options ) ; function merge ( obj1 , obj2 ) { var key ; obj1 = obj1 || } ; obj2 = obj2 || } ; for ( key in obj2 ) { if ( obj2 . hasOwnProperty ( key ) ) { obj1 [ key ] = obj2 [ key ] ; } } return obj1 ; }", "commit_type": "use"}
{"commit_tokens": ["Make", "check", "API", "more", "robust", "."], "add_tokens": "app . get ( '/check/:id/stats/:type/:page?' , function ( req , res , next ) { check . getStatsForPeriod ( req . params . type , req . params . page , function ( err , stats ) { if ( err ) return next ( err ) ; app . get ( '/check/:id/events' , function ( req , res , next ) {", "del_tokens": "app . get ( '/check/:id/stats/:type/:page?' , function ( req , res ) { check . getStatsForPeriod ( req . params . type , req . params . page , function ( stats ) { app . get ( '/check/:id/events' , function ( req , res ) {", "commit_type": "make"}
{"commit_tokens": ["added", "removing", "of", "JobServer", "event", "listeners"], "add_tokens": "var eventNames ; eventNames = [ 'end' , 'close' , 'timeout' , 'drain' ] ; eventNames . forEach ( function ( name ) { var i , eventNames ; // remove listeners from socket eventNames = [ 'connect' , 'data' , 'error' , 'end' , 'close' , 'timeout' , 'drain' ] ; for ( i = 0 ; i < eventNames . length ; i ++ ) { this . socket . removeAllListeners ( eventNames [ i ] ) ; }", "del_tokens": "var evNames = [ 'end' , 'close' , 'timeout' , 'drain' ] ; evNames . forEach ( function ( name ) { var i ;", "commit_type": "add"}
{"commit_tokens": ["added", "Scaler", "Clip", "Power", "operators"], "add_tokens": "import Clip from './Clip' ; import Multiplier from './Multiplier' ; import Scale from './Scale' ; Clip , Multiplier ,", "del_tokens": "import Scaler from './Scaler' ; Scaler ,", "commit_type": "add"}
{"commit_tokens": ["Add", "unorm", "polyfill", "and", "decompose", "the", "filename", "modifications"], "add_tokens": "var latinize = require ( 'latinize' ) , unorm = require ( 'unorm' ) ; var normalizedFileName = file . name . replace ( / \\s+ / g , \"_\" ) . normalize ( ) ; var fileName = latinize ( normalizedFileName ) ; var normalizedFileName = file . name . replace ( / \\s+ / g , \"_\" ) . normalize ( ) ; var fileName = latinize ( normalizedFileName ) ;", "del_tokens": "var latinize = require ( 'latinize' ) ; var fileName = latinize ( file . name . replace ( / \\s+ / g , \"_\" ) . normalize ( ) ) ; var fileName = latinize ( file . name . replace ( / \\s+ / g , \"_\" ) . normalize ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "small", "issues", "with", "expiry", "time", "calculation", "and", "missing", "pieces", "of", "header", "."], "add_tokens": "var expires = getDate ( new Date ( now . getTime ( ) + ( 1000 * 600 ) ) ) ; return \"<wsse:Security xmlns:wsse=\\\"http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd\\\" xmlns:wsu=\\\"http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd\\\" soap:mustUnderstand=\\\"1\\\">\" + \"</wsu:Timestamp>\" +", "del_tokens": "var expires = getDate ( new Date ( now . getMilliseconds ( ) + ( 1000 * 600 ) ) ) ; return \"<wsse:Security xmlns:wsse=\\\"http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd\\\" soap:mustUnderstand=\\\"1\\\">\" + \"</wsu:Timestamp>\"", "commit_type": "fix"}
{"commit_tokens": ["use", "defineProperty", "-", ">", "enumerable", "=", "false"], "add_tokens": "} } Object . defineProperty ( Array . prototype , \"qsort\" , { value : function ( l , r , func ) { module . exports ( this , l , r , func ) ; return this ; } , enumerable : false } ) ;", "del_tokens": "} ; } ; Array . prototype . qsort = function ( l , r , func ) { module . exports ( this , l , r , func ) ; return this ; } ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "path", "to", "materialize", "sass", "to", "make", "it", "absolute", "."], "add_tokens": "outputStyle : 'expanded' , includePaths : [ path . join ( __dirname , 'node_modules' ) ]", "del_tokens": "import livereload from 'gulp-livereload' ; import rename from 'gulp-rename' ; import webserver from 'gulp-webserver' ; outputStyle : 'expanded'", "commit_type": "fix"}
{"commit_tokens": ["Add", "utils", ":", "declarationValueIndex", "whitespaceChecker", "and", "their", "req", "-", "s"], "add_tokens": "export { default as configurationError } from \"./configurationError\" export { default as declarationValueIndex } from \"./declarationValueIndex\" export { default as isSingleLineString } from \"./isSingleLineString\" export { default as isWhitespace } from \"./isWhitespace\" export { default as parseSelector } from \"./parseSelector\" export { default as whitespaceChecker } from \"./whitespaceChecker\"", "del_tokens": "export { default as parseSelector } from \"./parseSelector\"", "commit_type": "add"}
{"commit_tokens": ["Improve", "documentation", "for", "--", "fingerprinting", "-", "map", "option"], "add_tokens": "description : 'Path to the fingerprint-map file. Set to false to deactivate fingerprinting' ,", "del_tokens": "description : 'Path to the fingerprint-map file' ,", "commit_type": "improve"}
{"commit_tokens": ["add", "a", "bit", "of", "documentation", "and", "correctly", "set", "results", ".", "object", "when", "res", "!", "=", "true"], "add_tokens": "// takes an existing comparator function and returns a new comparator function that runs the // existing comparator with an empty object results object. if that existing comparator execution // evaluates to true the results it produced are included as part of the larger result set. // this is done to include results from comparisons made within sub-objects at the expected level of // nesting within the final results object. if ( res ) { // if we are comparing a sub-object assign results to the given prop, // if we are comparing the root assign all props to results if ( prop !== undefined ) { existingResult [ prop ] = options . result ; } else { assign ( existingResult , options . result ) ; } options . result = existingResult ;", "del_tokens": "if ( res && prop !== undefined ) { existingResult [ prop ] = options . result ; options . result = existingResult ;", "commit_type": "add"}
{"commit_tokens": ["Add", "vector", "addition", "implementation", "and", "test"], "add_tokens": "if ( ! arrA [ 0 ] . length ) { // The arrays are vectors. for ( var i = 0 ; i < arrA . length ; i ++ ) { result [ i ] = arrA [ i ] + arrB [ i ] ; } } else { for ( var i = 0 ; i < arrA . length ; i ++ ) { result [ i ] = new Array ( arrA [ i ] . length ) ; for ( var j = 0 ; j < arrA [ i ] . length ; j ++ ) { result [ i ] [ j ] = arrA [ i ] [ j ] + arrB [ i ] [ j ] ; }", "del_tokens": "for ( var i = 0 ; i < arrA . length ; i ++ ) { result [ i ] = new Array ( arrA [ i ] . length ) ; for ( var j = 0 ; j < arrA [ i ] . length ; j ++ ) { result [ i ] [ j ] = arrA [ i ] [ j ] + arrB [ i ] [ j ] ;", "commit_type": "add"}
{"commit_tokens": ["Added", "min", ".", "js", "for", "production", "build"], "add_tokens": "filename : 'FluxThis.js' ,", "del_tokens": "var filename = 'FluxThis' + ( process . env . NODE_ENV === 'production' ? '.min' : '' ) + '.js' ; filename : filename ,", "commit_type": "add"}
{"commit_tokens": ["remove", "back", "label", "from", "navigation"], "add_tokens": "// overrideBackPress: row.overrideBackPress, backButtonTitle : '' ,", "del_tokens": "overrideBackPress : row . overrideBackPress ,", "commit_type": "remove"}
{"commit_tokens": ["Add", "Visible", ".", "support", "()", "to", "check", "browser", "support"], "add_tokens": "name = this . _prefixes [ i ] + 'VisibilityState' ; } , // Return true if browser support Page Visibility API. support : function ( ) { return ( 'undefined' != typeof ( this . _prefix ( ) ) ) ;", "del_tokens": "name = this . _prefixes [ i ] + 'VisibilityState'", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "make", "sure", "dx", "and", "dy", "are", "defined", "locally"], "add_tokens": "/ * var dx = ( this . pos . x + ( this . width >> 1 ) ) - ( o . pos . x + ( o . width >> 1 ) ) ; var dy = ( this . pos . y + ( this . height >> 1 ) ) - ( o . pos . y + ( o . height >> 1 ) ) ;", "del_tokens": "/ * dx = ( this . pos . x + ( this . width >> 1 ) ) - ( o . pos . x + ( o . width >> 1 ) ) ; dy = ( this . pos . y + ( this . height >> 1 ) ) - ( o . pos . y + ( o . height >> 1 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "destroy", "method", "to", "abort", "live", "stream", "of", "chat", "messages", "."], "add_tokens": "const Abortable = require ( 'pull-abortable' ) ; const aborter = Abortable ( ) ; aborter , getChatboxElement : getChatboxElement , / ** * Ends the live message feed arriving into the chat . Does not remove the * DOM element * / destroy : ( ) => { aborter . abort ( ) }", "del_tokens": "getChatboxElement : getChatboxElement", "commit_type": "add"}
{"commit_tokens": ["updated", "binaries", "and", "updated", "dispatch", "bin", "to", "point", "to", "dispatch", ".", "js"], "add_tokens": "require ( 'child_process' ) . execSync ( 'dotnet ' + __dirname + '/netcoreapp2.0/Dispatch.dll ' + args , { stdio : [ 0 , 1 , 2 ] } ) ;", "del_tokens": "require ( 'child_process' ) . execSync ( 'dotnet ' + __dirname + '\\\\netcoreapp2.0\\\\dispatch.dll ' + args , { stdio : [ 0 , 1 , 2 ] } ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "--", "keep", "-", "colons", "opt"], "add_tokens": "this . options . semicolon = options . keepColons ? ':' : '' ;", "del_tokens": "this . options . semicolon = '' ;", "commit_type": "add"}
{"commit_tokens": ["Use", "native", "promises", "instead", "of", "bluebird"], "add_tokens": "return Promise . reject ( new Error ( 'Must specify a template to load' ) ) ; return Promise . resolve ( templateName ) ; return Promise . resolve ( _self . cache [ templateName ] ) ; return Promise . reject ( new Error ( 'Must define a sourceLoader' ) ) ; promise = Promise . resolve ( null ) ;", "del_tokens": "var Bluebird = require ( 'bluebird' ) ; return Bluebird . reject ( new Error ( 'Must specify a template to load' ) ) ; return Bluebird . resolve ( templateName ) ; return Bluebird . resolve ( _self . cache [ templateName ] ) ; return Bluebird . reject ( new Error ( 'Must define a sourceLoader' ) ) ; promise = Bluebird . resolve ( null ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "inline", "=", "true", "condition"], "add_tokens": "// <([a-zA-Z]+)\\b[^>]*?\\s(?:inline [^>]*?|inline|inline=([\\'\\\"]).*?\\2[^>]*?)>(?:<\\/\\1\\s?>)? return new RegExp ( '<([a-zA-Z]+)\\\\b[^>]*?\\\\s(?:' + attribute + ' [^>]*?|' + attribute + '|' + attribute + '=([\\\\\\'\\\\\\\"])true\\\\2[^>]*?)>(?:<\\\\/\\\\1\\\\s?>)?' , 'gm' ) ;", "del_tokens": "// <([a-zA-Z]+)\\b[^>]*?\\s(?:inline [^>]*?|inline)>(?:<\\/\\1\\s?>)? return new RegExp ( '<([a-zA-Z]+)\\\\b[^>]*?\\\\s(?:' + attribute + ' [^>]*?|' + attribute + ')>(?:<\\\\/\\\\1\\\\s?>)?' , 'gm' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "path", "in", "expand", "that", "I", "hit", "."], "add_tokens": "if ( ! meta . children || ! meta . children . spec || kvp . value . spec === null ) {", "del_tokens": "if ( ! meta . children || ! meta . children . spec ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", ":", "date", "format", "and", "timezoning", ".", "Updated", "tests", "."], "add_tokens": "var alarm , data , date , dueDate , formatter , time , _ref1 , dueDate = Date . create ( dueDate ) ; formatter = \"{Dow} {Mon} {dd} {yyyy} {HH}:{mm}:00\" ; dueDate = dueDate . format ( formatter ) ; console . log ( dueDate ) ;", "del_tokens": "var alarm , data , date , dueDate , time , _ref1 , dueDate = Date . utc . create ( dueDate ) ; dueDate = dueDate . toISOString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "module", ".", "export", "both", "export", "factory", "&", "class"], "add_tokens": "if ( ! ( this instanceof Medea ) ) return new Medea ( options ) ; module . exports = Medea ;", "del_tokens": "module . exports = function ( options ) { return new Medea ( options ) ; } ;", "commit_type": "make"}
{"commit_tokens": ["Add", "check", "for", "null", "and", "undefined", "."], "add_tokens": "if ( value == null ) {", "del_tokens": "if ( ! value ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "ghc", "-", "pkg", "for", "getting", "the", "Haskell", "package", "version"], "add_tokens": "const haskellPackageVersion = this . runStackOutput ( [ 'exec' , '--' , 'ghc-pkg' , 'field' , PACKAGE_NAME , 'version' , '--simple-output' ] ) ;", "del_tokens": "const haskellPackageVersions = this . runStackOutput ( [ 'list-dependencies' , '--depth' , '1' ] ) . split ( '\\n' ) . reduce ( ( packageDict , str ) => { let [ packageName , version ] = str . split ( ' ' ) ; packageDict [ packageName ] = version ; return packageDict ; } , { } ) ; const haskellPackageVersion = haskellPackageVersions [ PACKAGE_NAME ] ;", "commit_type": "use"}
{"commit_tokens": ["adding", "dispatcher", "until", "flux", "official", "in", "NPM", "registry"], "add_tokens": "SuperAgent : require ( 'superagent' ) , Dispatcher : require ( './lib/dispatcher' )", "del_tokens": "SuperAgent : require ( 'superagent' ) // Dispatcher: require('./lib/dispatcher')", "commit_type": "add"}
{"commit_tokens": ["Added", "try", "/", "catch", "to", "bin", "/", "index", ".", "js", "and", "fixed", "shell", "pipes"], "add_tokens": "if ( args . h || args . help || ( process . argv . length <= 2 && process . stdin . isTTY ) ) { '[files] [options] .. or' , '[options] -- [files]' try { if ( render ) { outputStream . write ( script . render ( ) + '\\n' ) ; } else { outputStream . write ( beforeCompile + script . compile ( ) + afterCompile + '\\n' ) ; } catch ( ex ) { console . log ( ex . toString ( ) ) ; if ( ! buffer ) { if ( len === 0 ) { console . error ( 'Error: No input files' ) ; process . exit ( 1 ) ; } else { process . exit ( ) ; }", "del_tokens": "if ( args . h || args . help || process . argv . length <= 2 ) { '[options] [files]' if ( render ) { outputStream . write ( script . render ( ) + '\\n' ) ; else { outputStream . write ( beforeCompile + script . compile ( ) + afterCompile + '\\n' ) ; if ( len === 0 ) { console . error ( 'Error: No input files' ) ; process . exit ( 1 ) ; } else { process . exit ( ) ;", "commit_type": "add"}
{"commit_tokens": ["makes", "it", "so", "props", "don", "t", "have", "to", "be", "passed"], "add_tokens": "offsetProp = offsetProp || \"offset\" ; limitProp = limitProp || \"limit\" ; offsetProp , limitProp , startIndexProperty = startIndexProperty || \"start\" ; endIndexProperty = endIndexProperty || \"end\" ; startIndexProperty , endIndexProperty ,", "del_tokens": "offsetProp || \"offset\" , limitProp || \"limit\" , startIndexProperty || \"start\" , endIndexProperty || \"end\" ,", "commit_type": "make"}
{"commit_tokens": ["Fix", "double", "didMount", "bug", "."], "add_tokens": "this . willUnmount = sinon . spy ( this , 'willUnmount' ) ; } ) ; QUnit . test ( \"Only call didMount once for childs and grandchilds when setProps is called during mounting process.\" , function ( assert ) { var childComp = comp . refs . child ; var grandChildComp = childComp . refs . child ; assert . equal ( childComp . didMount . callCount , 1 , \"Child's didMount should have been called only once.\" ) ; assert . equal ( grandChildComp . didMount . callCount , 1 , \"Grandchild's didMount should have been called only once.\" ) ; comp . empty ( ) ; assert . equal ( childComp . willUnmount . callCount , 1 , \"Child's willUnmount should have been called once.\" ) ; assert . equal ( grandChildComp . willUnmount . callCount , 1 , \"Grandchild's willUnmount should have been called once.\" ) ; // TODO: can/should we somehow dispose the references to childComp and grandChildComp now?", "del_tokens": "} ) ; QUnit . test ( \"Only call didMount once.\" , function ( assert ) { assert . equal ( comp . refs . child . didMount . callCount , 1 , \"Child's didMount should have been called only once.\" ) ; assert . equal ( comp . refs . child . refs . child . didMount . callCount , 1 , \"Grandchild's didMount should have been called only once.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "isWhitelisted", "function", "in", "createOpts"], "add_tokens": "if ( len >= 1 && ! opts . run && ! isWhitelisted ( opts ) ) { whitelist : utils . whitelist , esc : utils . fileKeys function isWhitelisted ( argv ) { var keys = utils . whitelist ; for ( var key in argv ) { if ( ~ keys . indexOf ( key ) ) return true ; } return false ; } this . use ( plugins . store ( this . _name . toLowerCase ( ) ) ) ;", "del_tokens": "var pkg = config . get ( 'pkg' ) ; if ( len >= 1 && ! opts . run ) { var fileKeys = [ 'base' , 'basename' , 'cwd' , 'dir' , 'dirname' , 'ext' , 'extname' , 'f' , 'file' , 'filename' , 'path' , 'root' , 'stem' ] ; whitelist : [ 'emit' ] . concat ( fileKeys ) , esc : fileKeys this . use ( plugins . store ( this . _name ) ) ;", "commit_type": "use"}
{"commit_tokens": ["change", "markdown", "default", "route", "and", "use", "a", "regexp", "for", "markdown", "files"], "add_tokens": "var ext = / .m(ar)?k?d(own)?$ / ; return val . match ( ext ) ; if ( path . extname ( filePath ) . match ( ext ) ) { * Try to display the index . md page . displayPage ( path . join ( cli . root , 'index.md' ) , res ) ;", "del_tokens": "var ext = '.md' ; return val . indexOf ( ext ) != - 1 ; if ( path . extname ( filePath ) === ext ) { * Try to display the index . mkd page . displayPage ( path . join ( cli . root , 'index.mkd' ) , res ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "test", "description", "[", "ci", "skip", "]"], "add_tokens": "test ( 'inner and outer local and global classes are all present' , async function ( assert ) {", "del_tokens": "test ( 'no classees ' , async function ( assert ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "label", "issue", "on", "crossfilter"], "add_tokens": "label : label", "del_tokens": "label : match . get ( groupBy )", "commit_type": "fix"}
{"commit_tokens": ["Moved", "appended", "newline", "from", "tests", "to", "formatter", "."], "add_tokens": "var formatted = language . formatDocument ( tree ) ; var formatted = language . formatDocument ( tree ) ; var formatted = language . formatDocument ( tree ) ; var formatted = language . formatDocument ( tree ) ;", "del_tokens": "var formatted = language . formatDocument ( tree ) + '\\n' ; var formatted = language . formatDocument ( tree ) + '\\n' ; var formatted = language . formatDocument ( tree ) + '\\n' ; var formatted = language . formatDocument ( tree ) + '\\n' ;", "commit_type": "move"}
{"commit_tokens": ["Added", "semantic", "if", "as", "option", "."], "add_tokens": "semanticIf : false , if ( value === undefined || value === false || string === 'false' ) { return true ; } if ( options . semanticIf === true ) { return mout . array . indexOf ( [ 'no' , 'off' ] , string ) !== - 1 ; } if ( mout . lang . isArray ( options . semanticIf ) ) { return mout . array . indexOf ( options . semanticIf , string ) !== - 1 ; } if ( mout . lang . isFunction ( options . semanticIf ) ) { return options . semanticIf ( value ) ; } return false ;", "del_tokens": "var untrues = [ \"false\" , \"no\" ] ; return ( value === undefined || value === false || untrues . indexOf ( string ) !== - 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "--", "errors", "option", "for", "printing", "messages", "as", "errors"], "add_tokens": "ruleId : rule_id , fatal : options . errors", "del_tokens": "ruleId : rule_id", "commit_type": "add"}
{"commit_tokens": ["Fixed", "lint", "issue", "with", "wp", ".", "js"], "add_tokens": "const defaults = { username : '' , password : '' } ;", "del_tokens": "const defaults = { username : '' , password : '' } ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "slice", "instead", "new", "TypedArray", "better", "performance"], "add_tokens": "// http://www.cosy.sbg.ac.at/~held/projects/triang/triang.html // Z Order Hash ? this . points = exterior ; // Don't konw why, but use slice is more faster than new Float32Array(this.points). this . points = this . points . slice ( ) ; hole = hole . slice ( ) ; for ( var i = 0 ; i < nGrids ; i ++ ) { this . _pointsTypes = [ ] ;", "del_tokens": "// @author pissang(https://github.com/pissang) this . points = new Float32Array ( exterior ) ; hole = new Float32Array ( hole ) ; var len = this . _grids . length ; for ( var i = 0 ; i < len ; i ++ ) { this . _grids [ i ] . length = 0 ; } for ( ; i < nGrids ; i ++ ) { this . _pointsTypes = new Uint8Array ( n ) ;", "commit_type": "use"}
{"commit_tokens": ["Using", "coverall", "and", "remove", "localy", "jscoverage"], "add_tokens": "require ( './spec.js' ) ( require ( '../chain.js' ) , chai . assert )", "del_tokens": "global . Chain = require ( '../chain.js' ) global . assert = chai . assert require ( './spec.js' )", "commit_type": "use"}
{"commit_tokens": ["added", "support", "listening", "non", "-", "UI", "events", "on", "domnodes"], "add_tokens": "REGEXP_EMITTER = / ^(\\w|-|#)+$ / ,", "del_tokens": "REGEXP_EMITTER = / ^(\\w|-)+$ / ,", "commit_type": "add"}
{"commit_tokens": ["Update", "less", "-", "watch", "-", "compiler", ".", "js"], "add_tokens": "var command = 'lessc -x ' + file . replace ( / \\s+ / g , '\\\\ ' ) + ' ' + argvs [ 1 ] + '/' + filename . replace ( / \\s+ / g , '\\\\ ' ) + '.css' ;", "del_tokens": "var command = 'lessc --yui-compress ' + file . replace ( / \\s+ / g , '\\\\ ' ) + ' ' + argvs [ 1 ] + '/' + filename . replace ( / \\s+ / g , '\\\\ ' ) + '.css' ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "passing", "string", "instead", "of", "options", "object"], "add_tokens": "const options = typeof opts === 'string' ? { url : opts } : objectAssign ( { } , opts )", "del_tokens": "const options = objectAssign ( { } , opts )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "redis", "client", "creation", "when", "doing", "a", "sync", ".", "connect", "()"], "add_tokens": "var redisUrl = 'redis://' + api . redisHost + ':' + api . redisPort ;", "del_tokens": "var redisUrl = api . redisHost + ':' + api . redisPort ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "NPC", "selling", "Mists", "Stone"], "add_tokens": "67007 : { type : 'pristine-fractal-relic' , quantity : 1 , cost : 5 , npcs : [ { name : 'BUY-2046 PFR' , position : 'Mistlock Observatory' } ] } ,", "del_tokens": "67007 : { type : 'pristine-fractal-relic' , quantity : 1 , cost : 5 , npcs : [ { name : 'BUY-4373' , position : 'Mistlock Observatory' } ] } ,", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "issue", "with", "DOFF", "part", "of", "header", "&", "vs", ".", "|", "caused", "it", "to", "be", "clobbered", "."], "add_tokens": "var doffHeader = ( ( this . frameType & 0xFF ) << 16 ) | ( this . _getTypeSpecificHeader ( ) & 0xFFFF ) ;", "del_tokens": "* 00 00 00 39 // size == 0x39 * 02 00 00 00 // DOFF == 2 * 00 81 00 00 * 00 00 00 00 * 00 10 c0 25 * 0 a 40 40 70 * 00 00 02 00 * 60 00 0 a 83 * 00 00 00 00 * 00 00 03 e8 * a1 05 65 6 e * 2 d 55 53 a1 * 05 65 6 e 2 d * 55 53 40 40 * 40 * var doffHeader = ( ( this . frameType & 0xFF ) << 16 ) & ( this . _getTypeSpecificHeader ( ) & 0xFFFF ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "webpack", ".", "config", ".", "js", "for", "bundling", "and", "minification"], "add_tokens": "const webpack = require ( 'webpack' ) ; if ( process . env . NODE_ENV === \"production\" ) { var file_name_suffix = \".umd.bundle.min.js\" ; } else { var file_name_suffix = \".umd.bundle.js\" ; } entry : { \"apollo-client\" : \"./src/apollo-client.js\" , \"subscription-transport-ws\" : \"./src/subscription-transport-ws.js\" , //onlinedemo: \"./src/onlinedemo.js\", - need a new endpoint so skip filename : \"[name]\" + file_name_suffix , } , plugins : [ new webpack . DefinePlugin ( { 'process.env' : { 'NODE_ENV' : JSON . stringify ( process . env . NODE_ENV ) } } ) , ]", "del_tokens": "entry : { demo : \"./src/demo.js\" , umd : \"./src/createUMD.js\" filename : \"[name].bundle.js\" , }", "commit_type": "update"}
{"commit_tokens": ["Use", "promised", "-", "mongo", "fork", "fix", "eslint", "bump", "version"], "add_tokens": "const result = await collection . findAndModify ( {", "del_tokens": "let result = await collection . findAndModify ( {", "commit_type": "use"}
{"commit_tokens": ["Moving", "to", "variables", "but", "basically", "out", "of", "time", "=", "("], "add_tokens": "return { name : name , value : map [ name ] . toString ( 16 ) , // TODO: This will be part of json2fontcss as well? fonts : { // TODO: Work on this ;_; // Should be auto-generated without an explicit list } } ;", "del_tokens": "return { name : name , value : map [ name ] . toString ( 16 ) } ;", "commit_type": "move"}
{"commit_tokens": ["Added", "limitations", "emailInfo", "and", "wallet", "properties"], "add_tokens": "this . emailInfo = { \"address\" : body . email_address , \"validated\" : body . email_is_validated } ; this . emit ( 'accountLimitations' , body . bis_limited_account , body . bis_community_banned , body . bis_locked_account , body . bis_limited_account_allowed_to_invite_friends ) ; this . limitations = { \"limited\" : body . bis_limited_account , \"communityBanned\" : body . bis_community_banned , \"locked\" : body . bis_locked_account , \"canInviteFriends\" : body . bis_limited_account_allowed_to_invite_friends } ; this . wallet = { \"hasWallet\" : body . has_wallet , \"currency\" : body . currency , \"balance\" : body . balance } ;", "del_tokens": "this . emit ( 'accountLimitations' , body . bis_limited_account , body . bis_community_banned , body . bis_locked_account , body . b_is_limited_account_allowed_to_invite_friends ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "logs", "for", "displaying", "instead", "of"], "add_tokens": "function registerIfNeeded ( imageName , containerId , containerName ) { log && log . info ( 'Registering container %s for target %s' , containerName , target . src ) ; registerIfNeeded ( container . Image , container . Id , container . Names [ 0 ] . replace ( \"/\" , \"\" ) ) ; log && log . info ( 'Container %s changed to status %s' , evt . Actor . Attributes . name , evt . status ) ; registerIfNeeded ( evt . from , evt . id , evt . Actor . Attributes . name ) ; log && log . info ( 'Un-registering container %s for target %s' , evt . Actor . Attributes . name , target . src ) ; registerIfNeeded ( imageName , containerId , containerId ) ;", "del_tokens": "function registerIfNeeded ( imageName , containerId ) { log && log . info ( 'Registering container %s for target %s' , containerId , target . src ) ; registerIfNeeded ( container . Image , container . Id , container . Names ) ; log && log . info ( 'Container %s changed to status %s' , evt . id , evt . status ) ; registerIfNeeded ( evt . from , evt . id ) ; log && log . info ( 'Un-registering container %s for target %s' , evt . id , target . src ) ; registerIfNeeded ( imageName , containerId ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "Mark", "comment", "to", "Mark", "pragma", "."], "add_tokens": "var div = Mark . parse ( \"{div {span class:'bold'} {br} 'text' {!--pragma--} }\" ) ;", "del_tokens": "var div = Mark . parse ( \"{div {span class:'bold'} {br} 'text' {{pragma}} }\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "entry", "point", "and", "add", "source", "maps"], "add_tokens": "webpackDevServer , . command ( webpackDevServer ) // Enable source map on stack traces. if ( process . env . DEBUG ) { let { install } = require ( 'source-map-support' ) install ( ) }", "del_tokens": "serve , . command ( serve )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "config", "in", "comments", "as", "well", ".", "Removed", "commented", "code", "."], "add_tokens": "* \"*.js\" : \"eslint\" * without adding", "del_tokens": "* \"eslint\" : \"*.js\" * without having", "commit_type": "update"}
{"commit_tokens": ["Fix", "sizeby", "too", "big", "for", "track", "rm", "timeline", "call"], "add_tokens": "sizeByClinicalAttribute ( track , $ ( this ) . prop ( \"innerHTML\" ) , 2 , itemHeight ) ; sizeByClinicalAttribute ( track , attr , 2 , itemHeight ) ;", "del_tokens": "timeline ( ) ; sizeByClinicalAttribute ( track , $ ( this ) . prop ( \"innerHTML\" ) , 2 , itemHeight + 2 ) ; sizeByClinicalAttribute ( track , attr , 2 , itemHeight + 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "initialize", "anti", "-", "pattern", "from", "dzitilesource", "constructor", "."], "add_tokens": "if ( this . displayRects ) { } } ; $ . extend ( $ . DziTileSource . prototype , $ . TileSource . prototype , {", "del_tokens": "this . initialize ( ) ; } ; $ . extend ( $ . DziTileSource . prototype , $ . TileSource . prototype , { initialize : function ( ) { if ( ! this . displayRects ) { return ; } } ,", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "of", "hprose", "Service"], "add_tokens": "* LastModified : Sep 23 , 2015 * var result = invoke ( name , args , context ) ; if ( Future . isPromise ( result ) ) { return result . catch ( function ( e ) { return sendError ( e , context ) ; } ) ; } return result ;", "del_tokens": "* LastModified : Sep 11 , 2015 * return invoke ( name , args , context ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "users", "to", "provide", "extern", "module", "definitions", "."], "add_tokens": "* @ return { ! http . Server }", "del_tokens": "* @ return { http . Server }", "commit_type": "allow"}
{"commit_tokens": ["Added", "menu", "support", "to", "macOS"], "add_tokens": "const Menu = Electron . Menu ; if ( process . platform === 'darwin' ) { Menu . setApplicationMenu ( Menu . buildFromTemplate ( this . setup . menu ) ) ; } else { this . object . setMenu ( this . setup . menu ) ; }", "del_tokens": "this . object . setMenu ( this . setup . menu ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "getInfo", "method", "for", "Android", "."], "add_tokens": "GET_INFO : 'jsGetInfo' * Get information about the current version like current release version , app build version and so on . * The \"data\" property of the callback will contain all the information . getInfo : function ( callback ) { callNativeMethod ( pluginNativeMethod . GET_INFO , null , callback ) ;", "del_tokens": "GET_CURRENT_VERSION : 'jsGetCurrentVersion' * Get the name of the current version . * The \"data\" property of the callback will contain the name of the current version . getCurrentVersion : function ( callback ) { callNativeMethod ( pluginNativeMethod . GET_CURRENT_VERSION , null , callback ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "generated", "fallback", "image", "on", "obs_about_image_url"], "add_tokens": "var visualize = require ( 'visualize-buffer' ) obs_about_image_url : ( id ) => get ( id ) . imageUrl var fallbackImageUrl = genImage ( id ) image : Value ( genImage ( id ) ) } ) obs . imageUrl = computed ( obs . image , ( image ) => { var obj = msgs . link ( image , 'blob' ) if ( obj ) { return api . blob_url ( obj . link ) } else { return fallbackImageUrl } function genImage ( id ) { return visualize ( new Buffer ( id . substring ( 1 ) , 'base64' ) , 256 ) . src }", "del_tokens": "obs_about_image_url : ( id ) => { return computed ( get ( id ) . image , ( image ) => { var obj = msgs . link ( image , 'blob' ) if ( obj ) { return api . blob_url ( obj . link ) } } ) } image : Value ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "zoom", "out", "when", "click", "outside", "index", "slides"], "add_tokens": "const obj = this ; div . addEventListener ( 'click' , ( ) => obj . toggleZoom ( ) ) ;", "del_tokens": "div . addEventListener ( 'click' , this . ws_ . toggleZoom ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "it", ".", "skip", "()"], "add_tokens": "'uncaughtException' , 'skip' ] ;", "del_tokens": "'uncaughtException' ] ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "ability", "to", "set", "defaults", "for", "subsequent", "serve", "calls"], "add_tokens": "describe ( 'General' , function ( ) { } ) ; describe ( 'Use default options' , function ( ) { var server , postProcess , app = createFn ( ) ; setup ( ) ; before ( function ( done ) { erm . defaults ( { version : '/custom' } ) ; erm . serve ( app , setup . customerModel , { lowercase : true , restify : app . isRestify } ) ; server = app . listen ( testPort , done ) ; } ) ; after ( function ( done ) { erm . defaults ( null ) ; if ( app . close ) { return app . close ( done ) ; } server . close ( done ) ; } ) ; it ( '200 GET custom/customers' , function ( done ) { request . get ( { url : util . format ( '%s/api/custom/customers' , testUrl ) , json : true } , function ( err , res , body ) { assert . equal ( res . statusCode , 200 , 'Wrong status code' ) ; done ( ) ; } ) ; } ) ;", "del_tokens": "describe . only ( 'General' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["improved", "process", "management", "for", "exits", "and", "selenium", "now", "uses", "freeport"], "add_tokens": "var path = require ( 'path' ) , freeport = require ( 'freeport' ) , async = require ( 'async' ) , cp = require ( 'child_process' ) ; // XXX rule of 3. both phantom and selenium have this code. If we use it a 3rd time with // ChromeDriver, this code should be generalized var killPhantomAndDie = function ( ) { if ( ! ! phantomProcess && ! phantomProcess . killed ) { phantomProcess . kill ( 'SIGTERM' ) ; phantomProcess . killed = true ; } process . exit ( ) ; } ; process . on ( 'SIGTERM' , killPhantomAndDie ) ; process . on ( 'exit' , killPhantomAndDie ) ;", "del_tokens": "var path = require ( 'path' ) , freeport = require ( 'freeport' ) , async = require ( 'async' ) , cp = require ( 'child_process' ) ; process . on ( 'exit' , function ( ) { phantomProcess . kill ( ) ; } ) ;", "commit_type": "improve"}
{"commit_tokens": ["add", "require", "account", "activation", "event"], "add_tokens": "showRequireActivationMessage : function ( ) { this . set ( 'model.showRequireActivation' , true ) ; } , if ( data && data . messages ) { if ( data . messages [ 0 ] . extraData && data . messages [ 0 ] . extraData . requireActivation ) { self . send ( 'showRequireActivationMessage' ) ; } self . set ( 'messages' , data . messages ) ;", "del_tokens": "if ( data . responseJSON && data . responseJSON . messages ) { self . set ( 'messages' , data . responseJSON . messages ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "shippable", "to", "travis", "setup", "coveralls", "and", "change", "badges"], "add_tokens": "reporters : [ 'lcov' ]", "del_tokens": "reporters : [ 'lcov' , 'json' , 'cobertura' ]", "commit_type": "change"}
{"commit_tokens": ["added", "test", "for", "regex", "match"], "add_tokens": "} ) ; asyncTest ( \"regex match\" , function ( ) { var message = \"changeme\" ; var router = Router ( { '/initiative\\\\/([a-z0-9-]+)\\\\/([a-z0-9-]+)' : function ( one , two ) { message = \"awesome\" ; } } ) . init ( ) ; window . location . hash = \"/initiative/hi/there\" ; setTimeout ( function ( ) { equals ( message , \"awesome\" , \"basic route should have changed variable\" ) ; start ( ) ; } , 20 ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "cached", "url", "builder", "resets", "if", "the", "url", "changes", "values"], "add_tokens": "var previousUrl ; if ( ! RailsResource . config . urlBuilder || RailsResource . config . url !== previousUrl ) { previousUrl = RailsResource . config . url ;", "del_tokens": "if ( ! RailsResource . config . urlBuilder ) {", "commit_type": "make"}
{"commit_tokens": ["fixed", "deepextend", "when", "types", "mismatch"], "add_tokens": "// entry = single entry, from map:[] else { newvals . push ( val ) }", "del_tokens": "else newvals . push ( val )", "commit_type": "fix"}
{"commit_tokens": ["Added", "pixelRatio", "support", "to", "WindowImplBrowser"], "add_tokens": "canvas . width = width * pixelRatio ; canvas . height = height * pixelRatio ; canvas . style . width = width + 'px' ; canvas . style . height = height + 'px' ; this . width = width * pixelRatio ; this . height = height * pixelRatio ;", "del_tokens": "//canvas.width = width * pixelRatio; //canvas.height = height * pixelRatio; //canvas.style.width = width + 'px'; //canvas.style.height = height + 'px'; canvas . width = width ; canvas . height = height ; //this.width = width * pixelRatio; //this.height = height * pixelRatio; this . width = width ; this . height = height ;", "commit_type": "add"}
{"commit_tokens": ["changed", "default", "image", "path", "to", "correspond", "to", "shorter", "/", "images", "instead", "of", "/", "Scripts", "/", "images"], "add_tokens": "REST : '/images/zoomin_rest.png' , GROUP : '/images/zoomin_grouphover.png' , HOVER : '/images/zoomin_hover.png' , DOWN : '/images/zoomin_pressed.png' REST : '/images/zoomout_rest.png' , GROUP : '/images/zoomout_grouphover.png' , HOVER : '/images/zoomout_hover.png' , DOWN : '/images/zoomout_pressed.png' REST : '/images/home_rest.png' , GROUP : '/images/home_grouphover.png' , HOVER : '/images/home_hover.png' , DOWN : '/images/home_pressed.png' REST : '/images/fullpage_rest.png' , GROUP : '/images/fullpage_grouphover.png' , HOVER : '/images/fullpage_hover.png' , DOWN : '/images/fullpage_pressed.png'", "del_tokens": "REST : '/Scripts/images/zoomin_rest.png' , GROUP : '/Scripts/images/zoomin_grouphover.png' , HOVER : '/Scripts/images/zoomin_hover.png' , DOWN : '/Scripts/images/zoomin_pressed.png' REST : '/Scripts/images/zoomout_rest.png' , GROUP : '/Scripts/images/zoomout_grouphover.png' , HOVER : '/Scripts/images/zoomout_hover.png' , DOWN : '/Scripts/images/zoomout_pressed.png' REST : '/Scripts/images/home_rest.png' , GROUP : '/Scripts/images/home_grouphover.png' , HOVER : '/Scripts/images/home_hover.png' , DOWN : '/Scripts/images/home_pressed.png' REST : '/Scripts/images/fullpage_rest.png' , GROUP : '/Scripts/images/fullpage_grouphover.png' , HOVER : '/Scripts/images/fullpage_hover.png' , DOWN : '/Scripts/images/fullpage_pressed.png'", "commit_type": "change"}
{"commit_tokens": ["Updating", "tests", "adding", "example", "spec", "output"], "add_tokens": ", default : function ( ) { return 100 } require ( 'fs' ) . writeFileSync ( __dirname + '/example/spec.json' , JSON . stringify ( specs , null , 2 ) )", "del_tokens": ", default : 100", "commit_type": "update"}
{"commit_tokens": ["Add", "full", "metadata", "to", "imdFind", "callback"], "add_tokens": "// Named queue, means that we're not working on one name more than once at a time } , function ( err , imdb_id , match , full ) { cb ( null , imdb_id , match , full ) provider ( task . q , function ( err , id , match , res ) { return cb ( null , id , { match : n } , res )", "del_tokens": "// Named queue, means that we're not working on one name more than once at a tim } , function ( err , imdb_id , match ) { cb ( null , imdb_id , match ) provider ( task . q , function ( err , id ) { return cb ( null , id , { match : n } )", "commit_type": "add"}
{"commit_tokens": ["fixed", "idents", "everywhere", "added", "prologue", "to", "fix", "nested", "closures"], "add_tokens": "_globals . core . Object . prototype . children = [ ]", "del_tokens": "_globals . core . Item . prototype . children = [ ]", "commit_type": "fix"}
{"commit_tokens": ["added", "more", "prompt", "questions", "and", "simplified", "usage"], "add_tokens": "var prompts = [ { name : 'appName' , message : 'What is your app\\'s name?' } , { name : 'devName' , message : 'What is your name?' } , { name : 'devEmail' , message : 'What is your email?' } , { name : 'devGitHubUrl' , message : 'What is your github url?' } , { name : 'projGitHubUrl' , message : 'What is your projects github url?' } , console . log ( 'Damir :' + props ) ; this . devName = this . props . devName ; this . devEmail = this . props . devEmail ; this . devGitHubUrl = this . props . devGitHubUrl ; this . projGitHubUrl = this . props . projGitHubUrl ; var templateContext = { appName : this . appName , devName : this . devName , devEmail : this . devEmail , devGitHubUrl : this . devGitHubUrl , projGitHubUrl : this . projGitHubUrl , } ; templateContext templateContext templateContext", "del_tokens": "var prompts = [ { name : 'appName' , message : 'What is your app\\'s name?' } , { appName : this . appName } { appName : this . appName } { appName : this . appName }", "commit_type": "add"}
{"commit_tokens": ["Added", "file", "name", "on", "error", "in", "loadTest", "for", "Plask"], "add_tokens": "return callback ( 'File doesn\\'t exist ' + '\"' + path + '\"' , null ) ;", "del_tokens": "return callback ( 'File doesn\\t exist' , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "and", "documentation", "for", "Istanbul", "."], "add_tokens": "R : typeof reporter === 'string' ? reporter : 'nyan' , istanbul : true", "del_tokens": "R : typeof reporter === 'string' ? reporter : 'nyan'", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "jedfoster", "/", "Readmore", ".", "js", "/", "issues", "/", "73"], "add_tokens": "maxHeight = ( parseInt ( current . css ( 'max-height' ) . replace ( / [^-\\d\\.] / g , '' ) , 10 ) > current . data ( 'max-height' ) ) ? parseInt ( current . css ( 'max-height' ) . replace ( / [^-\\d\\.] / g , '' ) , 10 ) : current . data ( 'max-height' ) ,", "del_tokens": "maxHeight = ( current . css ( 'max-height' ) . replace ( / [^-\\d\\.] / g , '' ) > current . data ( 'max-height' ) ) ? current . css ( 'max-height' ) . replace ( / [^-\\d\\.] / g , '' ) : current . data ( 'max-height' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "forEach", "instead", "of", "unclear", "reduce"], "add_tokens": ", forEach = require ( 'es5-ext/object/for-each' ) var start = '' , end = '' ; forEach ( fn . _cliColorData , function ( mod ) { end = '\\x1b[' + mod [ 1 ] + 'm' + end ; start += '\\x1b[' + mod [ 0 ] + 'm' ; } , null , true ) ; return start + join . call ( arguments , ' ' ) + end ;", "del_tokens": ", reduce = require ( 'es5-ext/object/reduce' ) var close = '' ; return reduce ( fn . _cliColorData , function ( str , mod ) { close = '\\x1b[' + mod [ 1 ] + 'm' + close ; return str + '\\x1b[' + mod [ 0 ] + 'm' ; } , '' , true ) + join . call ( arguments , ' ' ) + close ;", "commit_type": "use"}
{"commit_tokens": ["add", "code", "coverage", "to", "unit", "tests"], "add_tokens": "bgShell : { coverage : { cmd : 'node node_modules/istanbul/lib/cli.js cover --dir build/coverage node_modules/grunt-jasmine-node/node_modules/jasmine-node/bin/jasmine-node test' } , cobertura : { cmd : 'node node_modules/istanbul/lib/cli.js report --root build/coverage --dir build/coverage/cobertura cobertura' } } , open : { file : { path : 'build/coverage/lcov-report/index.html' } grunt . loadNpmTasks ( 'grunt-bg-shell' ) ; grunt . loadNpmTasks ( 'grunt-open' ) ; // Register tasks. grunt . registerTask ( 'test' , [ 'clean:build' , 'jshint:test' , 'jasmine_node' ] ) ; grunt . registerTask ( 'cover' , [ 'clean:build' , 'jshint:test' , 'bgShell:coverage' , 'open' ] ) ; grunt . registerTask ( 'ci' , [ 'clean:build' , 'jshint:jslint' , 'jshint:checkstyle' , 'bgShell:coverage' , 'bgShell:cobertura' ] ) ; grunt . registerTask ( 'default' , [ 'test' , 'concat' , 'uglify' ] ) ;", "del_tokens": "watch : { files : '<%= jshint.files %>' , tasks : [ 'jshint:files' ] grunt . loadNpmTasks ( 'grunt-contrib-watch' ) ; grunt . registerTask ( 'default' , [ 'clean' , 'jshint:test' , 'jasmine_node' , 'concat' , 'uglify' ] ) ; grunt . registerTask ( 'test' , [ 'clean' , 'jshint:test' , 'jasmine_node' ] ) ; grunt . registerTask ( 'ci' , [ 'clean' , 'jshint:jslint' , 'jshint:checkstyle' , 'jasmine_node' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "when", "multiple", "inquirer", "process", "where", "fired", "(", "module", "required", "at", "multiple", "place", "by", "different", "submodules", "-", "inception", ")"], "add_tokens": "this . rl . close ( ) ; this . rl = null ; process . stdout . write ( \"\\033[?25h\" ) ; // show cursor", "del_tokens": "this . rl . pause ( ) ; process . stdout . write ( \"\\033[?25h\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "regexp", "to", "detect", "url", "this", "fix", "using", "state", "params", "in", "futureState"], "add_tokens": "[ '$stateProvider' , '$urlRouterProvider' , '$urlMatcherFactory' function _futureStateProvider ( $stateProvider , $urlRouterProvider , $urlMatcherFactory ) { futureUrlPrefixes [ futureState . urlPrefix ] . regexp = $urlMatcherFactory . compile ( futureState . urlPrefix ) . regexp ; for ( var future in futureUrlPrefixes ) { if ( futureUrlPrefixes [ future ] . regexp . test ( options . url ) ) { return futureUrlPrefixes [ future ] ; } }", "del_tokens": "[ '$stateProvider' , '$urlRouterProvider' , function _futureStateProvider ( $stateProvider , $urlRouterProvider ) { var urlComponents = options . url . split ( / \\/ / ) ; while ( urlComponents . length ) { var urlPrefix = urlComponents . join ( \"/\" ) ; if ( futureUrlPrefixes [ urlPrefix ] ) return futureUrlPrefixes [ urlPrefix ] ; urlComponents . pop ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "metalsmith", "-", "assets", "-", "improved"], "add_tokens": "const metalsmithAssets = require ( 'metalsmith-assets-improved' ) // Construct the options for metalsmith-assets-improved. src : files [ filename ] . src || files [ filename ] . source , dest : files [ filename ] . dest || files [ filename ] . destination || path . join ( path . dirname ( filename ) , '.' ) if ( files [ filename ] . replace ) { data . replace = files [ filename ] . replace } // Replace the .asset file. // Engage the plugin.", "del_tokens": "const metalsmithAssets = require ( 'metalsmith-assets' ) source : files [ filename ] . source , destination : files [ filename ] . destination || path . join ( path . dirname ( filename ) , '.' )", "commit_type": "update"}
{"commit_tokens": ["Fix", "the", "mirror", "case", "in", "https", ":", "//", "github", ".", "com", "/", "schteppe", "/", "poly", "-", "decomp", ".", "js", "/", "issues", "/", "8"], "add_tokens": "function indexDistance ( i , j , max ) { var diff = Math . abs ( j - i ) % max ; // This is either the distance or max - distance var distance = diff > max / 2 ? max - diff : diff ; return distance ; } if ( d < closestDist && ( indexDistance ( i , j , poly . length ) <= 2 || polygonCanSee ( poly , i , j ) ) ) {", "del_tokens": "if ( d < closestDist && ( Math . abs ( i - j ) <= 2 || polygonCanSee ( poly , i , j ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "rule", "prefer", "-", "compact"], "add_tokens": "unwrap : require ( './lib/rules/unwrap' ) , 'prefer-compact' : ( './lib/rules/prefer-compact' ) unwrap : 0 , 'prefer-compact' : 1", "del_tokens": "unwrap : require ( './lib/rules/unwrap' ) unwrap : 0", "commit_type": "add"}
{"commit_tokens": ["changed", "api", "to", "be", "just", "one", "function", "exported"], "add_tokens": "module . exports = log ;", "del_tokens": "module . exports = { log : log } ;", "commit_type": "change"}
{"commit_tokens": ["removed", "null", "method", "Drawer", ".", "prototype", ".", "idle"], "add_tokens": "}", "del_tokens": "} else { viewer . drawer . idle ( ) ; } idle : function ( ) { } ,", "commit_type": "remove"}
{"commit_tokens": ["added", "support", "for", "options", ".", "urls"], "add_tokens": "request = require ( 'request' ) , // If we have a warning from Phantom, we just report it // (no need to exit the process) console . error ( error ) ; callback ( buffer ) ;", "del_tokens": "console . log ( error ) ; process . exit ( 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "string", "and", "added", "text", "plain", "handling", "just", "in", "cause"], "add_tokens": "if ( data . type && ( data . type === 'text/html' || data . type === 'text/plain' ) ) {", "del_tokens": "if ( data . type && data . type === 'text/html' ) {", "commit_type": "add"}
{"commit_tokens": ["add", "route", ".", "callOptions", "to", "upload", "action", "calling"], "add_tokens": "promises . push ( ctx . call ( action . action , file , _ . defaultsDeep ( opts . callOptions , { meta : { } } ) ) ) ;", "del_tokens": "promises . push ( ctx . call ( action . action , file , { meta : { } } ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "databytes", "to", "a", "value", "config"], "add_tokens": "var databytes = config . get ( 'databytes' , 'value' ) ; // TODO: need to test for this later response . push ( \"SIZE \" + databytes ) ;", "del_tokens": "var databytes = config . get ( 'databytes' ) ; response . push ( \"SIZE \" + databytes [ 0 ] ) ;", "commit_type": "move"}
{"commit_tokens": ["Implemented", "console", ".", "time", "and", "console", ".", "timeEnd", "."], "add_tokens": "console . log = ( /** @param {...*} args */ function ( args ) { } ) ; // Linking console.dir and console.dirxml to the console.log method if // missing. Hopefully the browser already logs objects and DOM nodes as a // tree. // Implement console.time and console.timeEnd if one of them is missing if ( ! console [ \"time\" ] || ! console [ \"timeEnd\" ] ) { var timers = { } ; console [ \"time\" ] = function ( id ) { timers [ id ] = new Date ( ) . getTime ( ) ; } ; console [ \"timeEnd\" ] = function ( id ) { var start = timers [ id ] ; if ( start ) { console . log ( id + \": \" + ( new Date ( ) . getTime ( ) - start ) + \"ms\" ) ; delete timers [ id ] ; } } ; } if ( ! console [ \"trace\" ] ) console [ \"trace\" ] = function ( ) { } ;", "del_tokens": "console . log = function ( ) { } ; // Linking console.dir and console.dirxml to the console.log method in the // hope that the browser already logs objects and DOM nodes as a tree. if ( ! console [ \"trace\" ] ) console [ \"trace\" ] = function ( ) { } ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "plain", "and", "start", "of", "gssapi"], "add_tokens": "// Auth mechanisms , MongoCR : require ( './lib/auth/mongocr' ) , X509 : require ( './lib/auth/x509' ) , Plain : require ( './lib/auth/plain' )", "del_tokens": ", MongoCR : require ( './lib/auth/mongocr' ) , X509 : require ( './lib/auth/x509' )", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "pub", "-", "sub", "samples"], "add_tokens": "function listAllTopics ( ) { // [START pubsub_publisher_batched_settings] function publishBatchedMessages ( topicName , data , maxMessages , maxWaitTime ) { // Instantiates a client const pubsub = PubSub ( ) ; // References an existing topic, e.g. \"my-topic\" const topic = pubsub . topic ( topicName ) ; // Create a publisher for the topic (with additional batching configuration) const publisher = topic . publisher ( { batching : { maxMessages : maxMessages , maxMilliseconds : maxWaitTime } } ) ; // Publishes the message as a string, e.g. \"Hello, world!\" or JSON.stringify(someObject) const dataBuffer = Buffer . from ( data ) ; return publisher . publish ( dataBuffer ) . then ( ( results ) => { const messageId = results [ 0 ] ; console . log ( ` ${ messageId } ` ) ; return messageId ; } ) ; } // [END pubsub_publisher_batched_settings] listAllTopics ) . command ( ` ` , ` ` , { maxWaitTime : { alias : 'w' , type : 'number' , default : 10 } , maxMessages : { alias : 'm' , type : 'number' , default : 10 } } , ( opts ) => { publishBatchedMessages ( opts . topicName , opts . message , opts . maxMessages , opts . maxWaitTime ) ; } . example ( ` ` ) . example ( ` ` )", "del_tokens": "function listTopics ( ) { listTopics", "commit_type": "add"}
{"commit_tokens": ["Adds", "Array#length", "and", "#@", "props", "."], "add_tokens": "this . prop ( 'native' , { get : function ( ) { return this . __elements__ ; } } ) ; this . prop ( 'length' , { get : function ( ) { return this . __elements__ . length ; } } ) ; this . prop ( '@' , { get : function ( ) { return this ; } } ) ; if ( n !== added . length ) { this . didChange ( 'length' ) ; } this . didChange ( '@' ) ;", "del_tokens": "Object . defineProperties ( this . prototype , { // Public: Returns the current length of the array. length : { get : function ( ) { return this . __elements__ . length ; } } , // Public: Returns the backing native array. native : { get : function ( ) { return this . __elements__ ; } } } ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Jenkins", "to", "build", "npm", "package"], "add_tokens": "// TODO: Add headless karma testing // gulp.task('package', gulp.series('clean', 'lint', 'test:run', 'dist:build')); gulp . task ( 'package' , gulp . series ( 'clean' , 'dist:build' ) ) ;", "del_tokens": "gulp . task ( 'package' , gulp . series ( 'clean' , 'lint' , 'test:run' , 'dist:build' ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "according", "to", "PR", "comments"], "add_tokens": "conf . worker_heartbeat_timeout = conf . worker_heartbeat_timeout || 1000 ; if ( ! lastBeat || ( ! lastBeat . killed && new Date ( ) - lastBeat . time > self . config . worker_heartbeat_timeout ) ) { } , self . config . worker_heartbeat_timeout / 2 + 1 ) ; ServiceRunner . prototype . _workerHeartBeat = function ( ) { } , this . config . worker_heartbeat_timeout / 5 ) ; self . _workerHeartBeat ( ) ;", "del_tokens": "conf . timeout = conf . timeout || 1000 ; if ( ! lastBeat || ( ! lastBeat . killed && new Date ( ) - lastBeat . time > self . config . timeout ) ) { } , self . config . timeout ) ; ServiceRunner . prototype . _runHeartBeat = function ( ) { } , this . config . timeout / 3 ) ; self . _runHeartBeat ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "syntax", "error", "in", "regular", "expressions", "."], "add_tokens": "this . _interpret_time_remove_unwantedCharacters = / [^\\\\h;m,.\\-:\\/\\d]+ / gi ; this . _interpret_time_remove_separatorCharacters = / [\\\\h;m,.\\-:\\/\\s] / ;", "del_tokens": "this . _interpret_time_remove_unwantedCharacters = / [^\\\\h;m,.\\-:/\\d]+ / gi ; this . _interpret_time_remove_separatorCharacters = / [\\\\h;m,.\\-:/\\s] / ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "bodyParser", ".", "json", "to", "remove", "deprecation", "warnings"], "add_tokens": "var bodyParser = require ( 'body-parser' ) . json ( )", "del_tokens": "var bodyParser = require ( 'body-parser' ) ( )", "commit_type": "use"}
{"commit_tokens": ["Fix", "detection", "of", "mobile", "devices"], "add_tokens": "isDesktop = ! ! ( ! browser . mobile && ! browser . tablet ) ,", "del_tokens": "isDesktop = ! ! ( ! browser . mobile || ! browser . tablet ) ,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "2", "sec", "pause", "in", "E2E", "test"], "add_tokens": "resolve ( ) ; resolve ( ) ;", "del_tokens": "// this is called without steps parameter in order to execute all steps // in sequence, just continue setTimeout ( resolve , 2000 ) ; // this is called without steps parameter in order to execute all steps // in sequence, just continue setTimeout ( resolve , 2000 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "export", "functionality", "to", "grid"], "add_tokens": "this . remoteExportHandler = this . remoteExportHandler . bind ( this ) ; perPage : 8 , isExportButtonEnabled : true remoteExportHandler ( filters ) { // This is where Ajax requests are sent and then the rows in the state of this component should be updated to update the grid this . setState ( { filters } , ( ) => { this . exportProducts ( ) ; } ) ; } exportProducts ( ) { this . setState ( { isExportButtonEnabled : false } ) ; let url = 'http://localhost/simple-cart/web/app_dev.php/api/products?' ; if ( this . state . sort ) { url += '&sortBy=' + this . state . sort . column + '&sortDir=' + this . state . sort . direction ; } jQuery . ajax ( { url : url , crossDomain : true , complete : ( ) => { this . setState ( { isExportButtonEnabled : true } ) } } ) ; } remoteExportHandler = { this . remoteExportHandler } isExportButtonEnabled = { this . state . isExportButtonEnabled }", "del_tokens": "perPage : 8", "commit_type": "add"}
{"commit_tokens": ["adding", "render", "and", "reposition", "test", "while", "scrolling"], "add_tokens": "Ember . instrument ( 'updateContext' , this , function ( ) { if ( context !== newContext ) { set ( this , 'context' , newContext ) ; Ember . instrument ( 'updateContext.render' , this , function ( ) { } , this ) ; console . log ( 'render' ) ; } else { Ember . instrument ( 'updateContext.reposition' , this , function ( ) { } , this ) ; console . log ( 'repositions' ) ; } } , this ) ;", "del_tokens": "if ( context !== newContext ) { set ( this , 'context' , newContext ) ; }", "commit_type": "add"}
{"commit_tokens": ["adds", "missing", "test", "and", "removes", "unused", "dependencies"], "add_tokens": "import { GeneralPropTypes , createClassName , generalClassNames } from '../utils' ; 'full' : props . isFullscreen ... GeneralPropTypes , isTiny : PropTypes . bool , isSmall : PropTypes . bool , isLarge : PropTypes . bool , isFullscreen : PropTypes . bool", "del_tokens": "import { CloseButton } from './close-button' ; import { GeneralPropTypes , createClassName , generalClassNames , removeProps , objectValues } from '../utils' ; 'full' : props . isFull ... GeneralPropTypes", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "PropTypes", "import", "from", "react", "-", "native"], "add_tokens": "var reactModules = [ 'react' , 'react/addons' , 'react-native' ] ;", "del_tokens": "var reactModules = [ 'react' , 'react/addons' ] ;", "commit_type": "add"}
{"commit_tokens": ["add", "place", "holder", "for", "painters", "builders", "and", "feeders"], "add_tokens": "// set the plugin name visualData. / ** * set the default options . * The default options will help understand : * - how this plugin is designed * - how to customize the plugin * / // Analyzers // ======================== dataAnalyzer : null , // TODO: group rules will be part of analyzer. // Builders // ======================= dashboardBuilder : null , // Feeders // ======================= summaryFeeder : null , insightsFeeder : null , // Painters // ======================== chartPainter : null", "del_tokens": "// set the plugin name bilevelSunburst. // set the default options. insightsFeeder : null", "commit_type": "add"}
{"commit_tokens": ["Fix", "hard", "-", "coded", "values", "in", "isVoidFunction", "method"], "add_tokens": "&& ( parentContext . ruleIndex === Parser . rule . functionDeclaration || parentContext . ruleIndex === Parser . rule . anonymousFunctionDeclaration ) ; } ;", "del_tokens": "&& ( parentContext . ruleIndex === 23 || parentContext . ruleIndex === 24 ) ; } ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "second", "argument", "[", "name", "]", "of", "setter", "methods"], "add_tokens": "fnByModule [ id ] = b . functionDeclaration ( b . identifier ( id ) , [ b . identifier ( 'm' ) ] , b . blockStatement ( [ ] ) ) ;", "del_tokens": "fnByModule [ id ] = b . functionDeclaration ( b . identifier ( id ) , [ b . identifier ( 'm' ) , b . identifier ( 'name' ) ] , b . blockStatement ( [ ] ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "timezone", "issue", "with", "test"], "add_tokens": "if ( x . toString ) { return x . toString ( ) ; }", "del_tokens": "if ( x . toString ) { return x . toString ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "for", "offset", "start", "."], "add_tokens": "request ( opts . start ) ;", "del_tokens": "request ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "formFor", "Compatibile", "to", "the", "Serialization"], "add_tokens": "} ) : model . put ( this . id , this , function ( err , res ) {", "del_tokens": "} ) : model . put ( this , function ( err , res ) {", "commit_type": "make"}
{"commit_tokens": ["Update", "to", "mocha", "add", "travis", "yml"], "add_tokens": "try { stat = fs . lstatSync ( filepath ) ; } catch ( e ) { throw e ; } try { files = fs . readdirSync ( filepath ) ; } catch ( e ) { throw e ; } try { rm ( path . join ( filepath , file ) ) ; } catch ( e ) { throw e ; } try { fs . rmdirSync ( filepath ) ; } catch ( e ) { throw e ; } throw new Error ( 'Unrecognized file.' ) ; } it ( 'correctly caches files' , function ( ) { } ) ;", "del_tokens": "try { stat = fs . lstatSync ( filepath ) ; } catch ( e ) { throw e } ; try { files = fs . readdirSync ( filepath ) ; } catch ( e ) { throw e } ; try { rm ( path . join ( filepath , file ) ) ; } catch ( e ) { throw e } ; try { fs . rmdirSync ( filepath ) ; } catch ( e ) { throw e } ; throw new Error ( 'Unrecognized file.' ) } ; tests [ 'cache' ] = function ( ) { } ;", "commit_type": "update"}
{"commit_tokens": ["Add", "Config", "class", "for", "environment", "-", "specific", "configuration"], "add_tokens": "App : require ( './app' ) , Config : require ( './config' )", "del_tokens": "App : require ( './app' )", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "test", "pass", "."], "add_tokens": "res . end ( ) var es = new EventSource ( server . url ) es . reconnectInterval = 0 var errored = false if ( errored ) return errored = true", "del_tokens": "res . end ( ) ; var es = new EventSource ( server . url ) ; es . reconnectInterval = 0 ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "setEncoding", "call", "of", "stdout", ".", "README", "updated"], "add_tokens": "process . stdout . write ( text + '\\n' , 'utf-8' ) ;", "del_tokens": "process . stdout . setEncoding ( 'utf8' ) ; process . stdout . write ( text + '\\n' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", ":", "end", "position"], "add_tokens": "throw new Error ( '[' + id + ']: No such rname.' ) ; return idx2pos ( unit . length - 2 , idlen ( unit ) , unit . linelen ) ; var read = fs . readSync ( fd , endIdx - startIdx , startIdx ) ; * @ param number idx : character index ( leftside ) prelen = prelen || 0 ; idx = Number ( idx ) ; return Math . max ( 0 , idx - prelen - Math . floor ( ( idx - prelen ) / ( linelen + 1 ) ) ) + 1 ;", "del_tokens": "throw '[' + id + ']: No such rname.' ; return idx2pos ( unit . length - 1 , idlen ( unit ) , unit . linelen ) ; var read = fs . readSync ( fd , endIdx - startIdx , startIdx ) ; * @ param number idx : character index prelen = prelen || 0 ; return Math . max ( 0 , Number ( idx ) + 1 - prelen - Math . floor ( ( Number ( idx ) + 1 - prelen ) / ( linelen + 1 ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "new", "functionality", ";", "Return", "final", "options", "Object", "for", "sync", "methods"], "add_tokens": "let action = NodeCipher . Actions . ENCRYPT ; this . _parseCipherRequest ( action , options , ( err , opts ) => { return callback . call ( scope , err , opts ) ; let action = NodeCipher . Actions . DECRYPT ; this . _parseCipherRequest ( action , options , ( err , opts ) => { return callback . call ( scope , err , opts ) ; * @ returns { Object } return this . _encryptSync . apply ( this , arguments ) ; * @ returns { Object } return this . _decryptSync . apply ( this , arguments ) ;", "del_tokens": "this . _parseCipherRequest ( NodeCipher . Actions . ENCRYPT , options , err => { return callback . call ( scope , err ) ; this . _parseCipherRequest ( NodeCipher . Actions . DECRYPT , options , err => { return callback . call ( scope , err ) ; this . _encryptSync . apply ( this , arguments ) ; this . _decryptSync . apply ( this , arguments ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "bindingsparser", "for", "old", "webkit", "-", "based", "browsers", "(", "eg", "Konqueror", ")"], "add_tokens": "var i , previous , textContent , childNode , body ; try { if ( previous ) { previous . insertAdjacentHTML ( 'afterend' , textContent ) ; } else { node . insertAdjacentHTML ( 'afterbegin' , textContent ) ; } } catch ( e ) { // in case user uses very old webkit-based browser body = document . body ; if ( previous ) { body . appendChild ( previous ) ; previous . insertAdjacentHTML ( 'afterend' , textContent ) ; body . removeChild ( previous ) ; } else { body . appendChild ( node ) ; node . insertAdjacentHTML ( 'afterbegin' , textContent ) ; body . removeChild ( node ) ; }", "del_tokens": "var i , previous , textContent , childNode ; if ( previous ) { previous . insertAdjacentHTML ( 'afterend' , textContent ) ; } else { node . insertAdjacentHTML ( 'afterbegin' , textContent ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "readme", "note", "about", "withTransport"], "add_tokens": "headers : { ... _options . headers , ... HEADERS } ,", "del_tokens": "headers : { ... _options . headers , ... HEADERS } ,", "commit_type": "add"}
{"commit_tokens": ["add", "function", "to", "calculate", "interest", "allocated", "for", "a", "payment"], "add_tokens": ". then ( finance . interestAllocationForPayment ) //console.error(err);", "del_tokens": "console . error ( err ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "default", "options", ".", "emitError", "was", "missing", ".", "Also", "supply", "full", "failure", "information", "to", "the", "exception"], "add_tokens": "Array . prototype . push . apply ( allFailures , failures ) ; return this . emit ( 'error' , new PluginError ( 'gulp-tslint' , 'Failed to lint: ' + allFailures . map ( function ( failure ) { return proseErrorFormat ( failure ) ;", "del_tokens": "allFailures . push ( failures ) ; return this . emit ( 'error' , new PluginError ( 'gulp-tslint' , 'Failed to lint: ' + errorFiles . map ( function ( file ) { return path . basename ( file . path ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "interpolation", "for", "the", "ListItem", "keys"], "add_tokens": "var key = ` ${ parentIndex } ${ childIndex } ` ;", "del_tokens": "var key = parentIndex + '.' + childIndex ;", "commit_type": "use"}
{"commit_tokens": ["Add", "banner", "to", "the", "usage"], "add_tokens": "import { CTRINE } from './banner' Yargs . usage ( CTRINE ) . command ( build )", "del_tokens": "Yargs . command ( build )", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "/", "sendMessage", ".", "js", "export", "function", "name"], "add_tokens": "module . exports = function runSendMessageMethodTestSuite ( ) {", "del_tokens": "module . exports = function runSendAllMethodTestSuite ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "whitespace", "between", "tag", "and", "template"], "add_tokens": "const templateRegEx = / i18n\\s*`[^`]*` / g", "del_tokens": "const templateRegEx = / i18n`[^`]*` / g", "commit_type": "allow"}
{"commit_tokens": ["Implement", "complex", "data", "updates", "for", "nested", "views", "."], "add_tokens": "result . pass = a . innerHTML == b . innerHTML ; result . message = 'Expected \"' + a . innerHTML + '\" not to be equals \"' + b . innerHTML + '\".' ; result . message = 'Expected \"' + a . innerHTML + '\" to be equals \"' + b . innerHTML + '\".' ;", "del_tokens": "result . pass = a . toString ( ) == b . toString ( ) ; result . message = 'Expected \"' + a . toString ( ) + '\" not to be equals \"' + b . toString ( ) + '\".' ; result . message = 'Expected \"' + a . toString ( ) + '\" to be equals \"' + b . toString ( ) + '\".' ;", "commit_type": "implement"}
{"commit_tokens": ["allow", "the", "command", "site", "to", "intercept", "errors", "before", "they", "are", "thrown"], "add_tokens": "error ( error ) { throw error ; } . then ( ( _directory ) => { directory = _directory ; . then ( ( _filesystem ) => { filesystem = _filesystem ; return this . canCreateInDirectory ( site , filesystem , directory ) ; } ) . then ( create => { if ( create ) { project = site . notifyCreatingProject ( directory , project ) || project ; return project . then ( ( ) => site . notifyProjectCreated ( directory ) ) ; } else { return site . notifyProjectNotCreated ( directory ) ; } } ) . catch ( error => { site . error ( error ) ; } ) ; } }", "del_tokens": ". then ( ( _directory ) => { directory = _directory ; . then ( ( _filesystem ) => { filesystem = _filesystem ; return this . canCreateInDirectory ( site , filesystem , directory ) ; } ) . then ( create => { if ( create ) { project = site . notifyCreatingProject ( directory , project ) || project ; return project . then ( ( ) => site . notifyProjectCreated ( directory ) ) ; } else { return site . notifyProjectNotCreated ( directory ) ; } } ) ; } }", "commit_type": "allow"}
{"commit_tokens": ["making", "tests", "that", "aren", "t", "implemented", "yet", "fail", "and", "added", "a", "couple", "of", "callback", "tests", ".", "@brianr", "@sbezboro"], "add_tokens": "return this . _log ( level || args . level || this . options . level || 'debug' , var endpoint = this . options . endpoint || 'https://api.rollbar.com/api/1/item/' ; return endpoint + path ; Util . merge ( this . options , options ) ; Util . merge ( scopedNotifier . options , options ) ;", "del_tokens": "return this . _log ( args . level || this . options . level || 'debug' , return this . options . endpoint + path ; this . options = Util . copy ( options ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "stuff", "to", "the", "client", "side", "log", "reactor"], "add_tokens": "var cls = require ( 'continuation-local-storage' ) ; var session = cls . getNamespace ( 'appSession' ) ; if ( session && session . active ) { var caller = session . get ( 'caller' ) ; if ( caller && caller . user ) { logData . userId = caller . user . _id ; logData . username = caller . user . username ; } logData . app = session . get ( 'app' ) ; logData . lang = session . get ( 'lang' ) ; logData . url = session . get ( 'url' ) ; logData . visitorId = session . get ( 'visitorId' ) ; } _ . isString ( logData ) ? errorClient . captureMessage ( logData , { extra : logData } ) : logData . msg ? errorClient . captureMessage ( logData . msg , { extra : logData } ) : errorClient . captureMessage ( JSON . stringify ( logData ) , { extra : logData } ) ;", "del_tokens": "errorClient . captureMessage ( logData , { extra : logData } ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bugs", "remove", "duplicate", "code"], "add_tokens": "const functions_1 = require ( \"./functions\" ) ; functions_1 . route ( meta [ method ] . route , Class , method ) ; functions_1 . upload ( ... meta [ method ] . upload ) ( Class . prototype , method ) ; if ( meta [ method ] . requireAuth ) functions_1 . requireAuth ( Class . prototype , method ) ; functions_1 . event ( meta [ method ] . event , Class , method ) ; if ( meta [ method ] . requireAuth ) functions_1 . requireAuth ( Class . prototype , method ) ;", "del_tokens": "const RouteMap_1 = require ( \"./RouteMap\" ) ; const EventMap_1 = require ( \"./EventMap\" ) ; RouteMap_1 . RouteMap [ meta [ method ] . route ] = { Class , method } ; Class . UploadFields [ method ] = meta [ method ] . upload ; if ( meta [ method ] . requireAuth && ! Class . RequireAuth . includes ( method ) ) Class . RequireAuth . push ( method ) ; EventMap_1 . EventMap [ meta [ method ] . event ] = { Class , method } ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "css", "min", "and", "expanded", "in", "dist", "via", "gulp"], "add_tokens": ". pipe ( gulp . dest ( paths . dist ) ) . pipe ( $ . csso ( ) ) . pipe ( $ . rename ( 'ng-datepicker.min.css' ) )", "del_tokens": ". pipe ( $ . csso ( ) )", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "dependency", "on", "Object", ".", "assign", "()", "and", "changed", "some", "sass", "to", "handle", "max", "width", "and", "max", "height", "differently", "."], "add_tokens": "// Copy keys from the source into the target function copyKeys ( target , source ) { if ( target && source ) { Object . keys ( source ) . forEach ( ( key ) => { target [ key ] = source [ key ] ; } ) ; } } const copy = { } ; copyKeys ( copy , _defaultOptions ) ; copyKeys ( copy , opts ) ; const objCopy = { } ; copyKeys ( objCopy , obj ) ; copyKeys ( objCopy , copy [ key ] ) ; copy [ key ] = objCopy ;", "del_tokens": "const copy = Object . assign ( { } , _defaultOptions , opts ) ; copy [ key ] = Object . assign ( { } , obj , copy [ key ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "unncessary", "check", "as", "minPeakDistance", "is", "always", "available"], "add_tokens": "if ( typeof config . minPeakHeight !== 'number' || config . minPeakHeight === NaN ) { throw new TypeError ( 'config.minPeakHeight should be a numeric value. Was: ' + String ( config . minPeakHeight ) ) ; this . filters . push ( function minHeightFilter ( item ) { return item >= config . minPeakHeight ; } ) ;", "del_tokens": "if ( config . hasOwnProperty ( 'minPeakHeight' ) ) { if ( typeof config . minPeakHeight !== 'number' || config . minPeakHeight === NaN ) { throw new TypeError ( 'config.minPeakHeight should be a numeric value. Was: ' + config . minPeakHeight ) ; } this . filters . push ( function minHeightFilter ( item ) { return item >= config . minPeakHeight ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Removed", "home", "rolled", "flakey", "caching", "mechanism", "in", "favour", "of", "leaving", "it", "to", "the", "consumer", "to", "cache", "if", "required", ".", "More", "unix", "style", "approach", ".", "Removed", "events", "-", "if", "you", "want", "to", "know", "when", "versions", "change", "listen", "to", "the", "registry", "changes", "feed", ".", "Simplified", "code", "and", "switched", "coding", "style", "."], "add_tokens": "var semver = require ( \"semver\" ) , SemVer = semver . SemVer , Range = semver . Range version = new SemVer ( version , loose ) range = new Range ( range , loose ) return false var comparators = range . set [ i ] var high = null var low = null high = high || comparator low = low || comparator high = comparator low = comparator } ) return false return false return false return true }", "del_tokens": "var semver = require ( 'semver' ) ; var SemVer = semver . SemVer ; var Range = semver . Range ; * version = new SemVer ( version , loose ) ; range = new Range ( range , loose ) ; return false ; var comparators = range . set [ i ] ; var high = null ; var low = null ; high = high || comparator ; low = low || comparator ; high = comparator ; low = comparator ; } ) ; return false ; return false ; return false ; return true ; } ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "test", "for", "Knockout", "s", "text", "binding"], "add_tokens": "// equivalent to with(context){with(context.$data){...}}", "del_tokens": "// equivalent to with(context){with(context.$data){...}}", "commit_type": "add"}
{"commit_tokens": ["upgrade", "styler", "version", "to", "fix", "warning", "log", "of", "non", "standard", "property", "name"], "add_tokens": "{ line : 1 , column : 1 , reason : 'WARNING: `x` is not a standard property name (may not be supported)' } , { line : 1 , column : 1 , reason : 'WARNING: `y` is not a standard property name (may not be supported)' } { line : 1 , column : 109 , reason : 'WARNING: `x` is not a standard property name (may not be supported)' } , { line : 1 , column : 109 , reason : 'WARNING: `y` is not a standard property name (may not be supported)' } , { line : 1 , column : 109 , reason : 'WARNING: `z` is not a standard property name (may not be supported)' } log : [ { line : 1 , column : 12 , reason : 'WARNING: `-webkit-transform` is not a standard property name (may not be supported)' } ]", "del_tokens": "{ line : 1 , column : 1 , reason : 'WARNING: `x` is not a standard property name' } , { line : 1 , column : 1 , reason : 'WARNING: `y` is not a standard property name' } { line : 1 , column : 109 , reason : 'WARNING: `x` is not a standard property name' } , { line : 1 , column : 109 , reason : 'WARNING: `y` is not a standard property name' } , { line : 1 , column : 109 , reason : 'WARNING: `z` is not a standard property name' } log : [ { line : 1 , column : 12 , reason : 'WARNING: `-webkit-transform` is not a standard property name' } ]", "commit_type": "upgrade"}
{"commit_tokens": ["add", "validator", "for", "webstorm", "executable", "."], "add_tokens": "/ ** * Utility to validate the executable path that will be used to open WebStorm * @ returns { boolean } * / WebStorm . prototype . validateExecutable = function ( ) { var executable = WebStorm . prototype . executable ( ) ; var isValid = false ; if ( executable !== null ) { isValid = io . existsFileSync ( executable ) ; } return isValid ; } ; * When generating the . idea project WebStorm will remove any plain text files specified * on first open if they do not exist . * The user preferences directory for WebStorm on the current platform .", "del_tokens": "* webStorm will remove any plain text files specified on first open * if they do not exists . * * The user preferences directory for webstorm on the current platform", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "babel", "plugin", "for", "Vue", "in", "React"], "add_tokens": "import wrapReactElement from './wrapReactElement' export { React , Vue , wrapReactElement }", "del_tokens": "export { React , Vue }", "commit_type": "add"}
{"commit_tokens": ["Fix", "certain", "references", "not", "being", "regenerated", "correctly", "because", "key", "iteration", "happens", "out", "-", "of", "-", "order"], "add_tokens": "* @ version 1.0 .3 // Because we always regenerate parsed objects first // (JSON-dry parsing goes from string  object  regenerated object) // keys of regular objects can appear out-of-order, so we need to parse them if ( temp && temp instanceof String ) { // Unset the String as a valid result retrieve [ current ] = null ; // Regenerate the string again // (We have to create a new instance, because it's already been \"seen\") temp = retrieve [ current ] = regenerate ( root , new String ( temp ) , seen , retrieve , undry_paths , old ) ; } * @ version 1.0 .2 * @ param { Boolean } force If a piece of the path doesn '", "del_tokens": "* @ version 1.0 .0 * @ version 1.0 .0 * @ param { Boolean } force", "commit_type": "fix"}
{"commit_tokens": ["remove", "local", "storage", "on", "logout"], "add_tokens": "// local storage var uxid = Login . getId ( ) ; if ( uxid ) { window . localStorage . removeItem ( uxid ) ; } // local vars Login . error = null ; // notify any listeners", "del_tokens": "Login . error = null ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "new", "key", "type", "for", "entities", "useful", "to", "allow", "empty", "keys"], "add_tokens": "entry . type == 'encodedstring' || entry . type == 'keystring' , \"PartitionKey must be a string\" ) ; entry . type == 'encodedstring' || entry . type == 'keystring' , \"RowKey must be a string\" ) ; // Register `keystring` as a type, to workaround Azure Table Storage // limitations, such as no control characters and no /\\#?% and non-empty keys // Note in particular % is undocumented and doesn't work. // See: http://msdn.microsoft.com/en-us/library/azure/dd179338.aspx Entity . registerDataType ( 'keystring' , { serialize : function ( d ) { assert . equal ( typeof ( d ) , 'string' , \"Type string must be a string\" ) ; // 1. URL encode // 2. URL encode all tilde (replace ~ with %7E) // 3. Replace % with tilde for Azure compatibility // 4. Prepend '~' to avoid empty keys return '~' + encodeURIComponent ( d ) . replace ( / ~ / g , '%7E' ) . replace ( / % / g , '~' ) ; } , deserialize : function ( r ) { assert . equal ( typeof ( r ) , 'string' , \"Type string must be a string\" ) ; assert ( r [ 0 ] , '~' , \"keystring types should have ~ as first character\" ) ; // 1. Removed tilde prefixed (used to avoid empty keys) // 2. Replace tilde with % to get URL encoded string // 3. URL decode (this handle step 1 and 2 from encoding process) return decodeURIComponent ( r . slice ( 1 ) . replace ( / ~ / g , '%' ) ) ; } } ) ;", "del_tokens": "entry . type == 'encodedstring' , \"PartitionKey must be a string\" ) ; entry . type == 'encodedstring' , \"RowKey must be a string\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "ipad", "retina", "table", "with", "issue"], "add_tokens": "w += getOffsetWidth ( $fthCells . get ( i ) ) ;", "del_tokens": "w += $fthCells . get ( i ) . offsetWidth ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "enableMobileResize", "method", "browser", "test", "updated", "readme"], "add_tokens": "if ( screen . width > 1023 || this . mobile ) { addEvent . call ( this , handlerFunc ) ; } resizilla . enableMobileResize = function ( ) { root . mobile = true ; }", "del_tokens": "addEvent . call ( this , handlerFunc ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "correct", "function", "for", "finOneBy", "*", "queries"], "add_tokens": "if ( method === 'findOneBy*' || method === 'findOneBy*In' ) return self . findOne ( options , cb ) ;", "del_tokens": "if ( method === 'findOneBy*' || method === 'findOneBy*In' ) return self . find ( options , cb ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "#getPathToKey", "and", "exposed", "#valueFromPath"], "add_tokens": "it ( 'Should return a value to a path' , function ( ) { var paths = jsd . getPathToKey ( complex , / hello / ) ; var value = jsd . valueFromPath ( complex , paths [ 0 ] ) ; expect ( value ) . to . equal ( \"it is me you're looking for\" ) ; } ) ; it ( 'Should return a path to a key' , function ( ) { var paths = jsd . getPathToKey ( complex , / hello / ) ; expect ( paths . length ) . to . equal ( 1 ) ; expect ( paths [ 0 ] ) . to . equal ( 'articles.1.hello' ) ; } ) ;", "del_tokens": "it ( 'Should reject keys that aren\\'t strings or RegExps' , function ( ) { try { var articles = jsd . getValuesByKeyName ( complex , { } ) ; } catch ( e ) { expect ( e . message ) . to . equal ( 'Key must be either a string or a RegExp' ) ; } } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "stock_server", ".", "js0"], "add_tokens": "module . exports = stockServer ;", "del_tokens": "exports . module = stockServer ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "assertions", "from", "playback", "and", "plotter"], "add_tokens": "// console.assert(hand[prop]); // console.assert(!isNaN(elapsedTime)); // console.assert(nameOrHash); // console.assert(key); // console.assert(nameOrHash[key]); // console.assert(data[key]); // console.assert(!isNaN(this.timeSinceLastFrame));", "del_tokens": "console . assert ( hand [ prop ] ) ; console . assert ( ! isNaN ( elapsedTime ) ) ; console . assert ( nameOrHash ) ; console . assert ( key ) ; console . assert ( nameOrHash [ key ] ) ; console . assert ( data [ key ] ) ; console . assert ( ! isNaN ( this . timeSinceLastFrame ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "exception", "when", "validating", "an", "object", "Collection"], "add_tokens": "] , strings : [ { } ] items : [ new Assert ( ) . Collection ( new Assert ( ) . Email ( ) ) , new Assert ( ) . Count ( 2 ) ] , strings : [ new Assert ( ) . Collection ( new Assert ( ) . IsString ( ) ) ] expect ( result . strings [ 0 ] ) . to . have . key ( '0' ) ; expect ( result . strings [ 0 ] [ 0 ] ) . to . be . a ( Violation ) ; expect ( result . strings [ 0 ] [ 0 ] . assert . __class__ ) . to . be ( 'IsString' ) ;", "del_tokens": "] items : [ new Assert ( ) . Collection ( new Assert ( ) . Email ( ) ) , new Assert ( ) . Count ( 2 ) ]", "commit_type": "fix"}
{"commit_tokens": ["Update", "examples", "around", "luigi", "config"], "add_tokens": "* - customIdpProvider ( if you provide a class to Luigi . config . auth . customIdpProvider )", "del_tokens": "* - customIdpProvider ( if you provide a class to LuigiConfig . auth . customIdpProvider )", "commit_type": "update"}
{"commit_tokens": ["added", "single", "page", "file", "data", "to", "electronic", "text", "extraction", "origin"], "add_tokens": "var inspect = require ( 'eyes' ) . inspector ( ) ; var single_page_pdf_file_paths = [ ] ; return var file_path = file . file_path single_page_pdf_file_paths . push ( file . file_path ) ; self . emit ( 'complete' , { text_pages : text_pages , pdf_path : pdf_path , single_page_pdf_file_paths : single_page_pdf_file_paths } ) ;", "del_tokens": "return self . emit ( 'complete' , { text_pages : text_pages , pdf_path : pdf_path } ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "current", "section", "highlighted", "instead", "of", "previous"], "add_tokens": "if ( heading . offsetTop > top + options . headingsOffset + 1 ) {", "del_tokens": "if ( heading . offsetTop > top + options . headingsOffset ) {", "commit_type": "make"}
{"commit_tokens": ["add", "isCapped", "()", "to", "collection", ".", "js"], "add_tokens": "query . skip = self . _skip || 0", "del_tokens": "query . skip = self . _skip", "commit_type": "add"}
{"commit_tokens": ["Fix", "field", "edit", "in", "some", "situations"], "add_tokens": "if ( ! t . valueElement ) { if ( ! t . valueElement ) { } t . valueElement = null ;", "del_tokens": "if ( ! t . valueChanged ( ) || ! t . valueElement ) { clearTimeout ( t . mouseOutTimer ) ; if ( ! $ ( \".feedit .fevalueelement\" ) . is ( \":focus\" ) ) clearTimeout ( t . mouseOutTimer ) ; if ( ! $ ( \".feedit .fevalueelement\" ) . is ( \":focus\" ) )", "commit_type": "fix"}
{"commit_tokens": ["use", "console", ".", "log", "()", "instead", "of", "console", ".", "error", "()"], "add_tokens": "console . log ( indent + ( result . message || \"\" ) ) ; console . log ( indent + ( i + 1 ) + \". \" + result . stackTrace [ i ] ) ; console . log ( new Array ( depth ) . join ( \" \" ) + ( endTime - test . startTime ) + \"ms \" + testObj . assertions + \" assertion\" + ( testObj . assertions !== 1 ? \"s\" : \"\" ) ) ; console . log ( new Array ( depth ) . join ( \" \" ) + \"-----------------------------------\" ) ;", "del_tokens": "console . error ( indent + ( result . message || \"\" ) ) ; console . error ( indent + ( i + 1 ) + \". \" + result . stackTrace [ i ] ) ; if ( test === undefined ) { console . dir ( tests ) ; } console . log ( Array ( depth ) . join ( \" \" ) + ( endTime - test . startTime ) + \"ms \" + testObj . assertions + \" assertion\" + ( testObj . assertions !== 1 ? \"s\" : \"\" ) ) ; console . log ( Array ( depth ) . join ( \" \" ) + \"-----------------------------------\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "cache", "expiry", "logic", "."], "add_tokens": "return Date . now ( ) - new Date ( fs . statSync ( path ) . mtime ) . getTime ( ) > expiresIn ;", "del_tokens": "return new Date ( fs . statSync ( path ) . mtime ) . getTime ( ) - expiresIn < 0 ;", "commit_type": "fix"}
{"commit_tokens": ["making", "swig", "-", "stub", "do", "stuff"], "add_tokens": "prettyjson = require ( 'prettyjson' ) , stubs = require ( './lib/stubs' ) ; if ( ! response ) { swig . log ( ) ; swig . log . error ( 'swig-stub' , 'Allllllrighty then, thanks for playing.' ) ; return ; return gulp . src ( path . join ( __dirname , 'templates' , data . type , '/**/*' ) ) . pipe ( stubs ( swig ) ) . pipe ( gulp . dest ( path . join ( swig . target . path , 'web-' + data . name ) ) ) ; . on ( 'exit' , function exit ( ) { // ask about installing swig, npm } ) ;", "del_tokens": "prettyjson = require ( 'prettyjson' ) ; ; if ( response ) { swig . log ( 'THUMBS UP BRO' )", "commit_type": "make"}
{"commit_tokens": ["Upgrade", "to", "latest", "version", "of", "libphonenumber", ".", "Many", "fixes", "but", "supports", "some", "brazilian", "formats", "previously", "not", "supported"], "add_tokens": "* Copyright ( C ) 2011 The Libphonenumber Authors . // Region code for global networks (e.g. +800 numbers). UN001 : '001' , AE : 'AE' , AQ : 'AQ' , BB : 'BB' , BR : 'BR' , BY : 'BY' , CH : 'CH' , CX : 'CX' , HU : 'HU' , SE : 'SE' ,", "del_tokens": "* Copyright ( C ) 2011 The Libphonenumber Authors", "commit_type": "upgrade"}
{"commit_tokens": ["add", "browserify", "-", "shim", "for", "spell", "-", "checker"], "add_tokens": "var rename = require ( \"gulp-rename\" ) ; . pipe ( gulp . dest ( \"./debug/\" ) ) ; . pipe ( concat ( \"simplemde.css\" ) ) . pipe ( gulp . dest ( \"./debug/\" ) ) . pipe ( rename ( \"simplemde.min.css\" ) )", "del_tokens": ". pipe ( gulp . dest ( \"./dist/\" ) ) ; . pipe ( concat ( \"simplemde.min.css\" ) )", "commit_type": "add"}
{"commit_tokens": ["Improve", "symmetry", "of", "packString", "()", "and", "unpackString", "()"], "add_tokens": "return packed [ 0 ] === TYPE_STRING ? unpack ( packed ) : JSON . stringify ( unpack ( packed ) ) ;", "del_tokens": "return JSON . stringify ( unpack ( packed ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["add", "timestamp", "to", "promise", ".", "log"], "add_tokens": "const av = [ ( new Date ( ) ) . toISOString ( ) , ] ;", "del_tokens": "const av = [ ] ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "non", "-", "existent", "field"], "add_tokens": "var _ = require ( 'lodash' ) ; if ( ! _ . has ( body , prop ) ) {", "del_tokens": "if ( ! body . hasOwnProperty ( prop ) ) {", "commit_type": "add"}
{"commit_tokens": ["Improve", "tokenizer", "and", "change", "line", "number", "styling"], "add_tokens": "line : 'gloss__line' , lineNum : 'gloss__line--' , line : 'test__line' , lineNum : 'test__line--' , test ( 'should accept a String as a tokenizer' , function ( t ) { test ( 'should accept a RegExp as a tokenizer' , function ( t ) { var leipzig = Leipzig ( { tokenizers : / test / } ) ; t . deepEqual ( leipzig . tokenizers , / test / ) ; t . end ( ) ; } ) ;", "del_tokens": "line : 'gloss__line--' , line : 'test__line--' , test ( 'should accept a string as a tokenizer' , function ( t ) {", "commit_type": "improve"}
{"commit_tokens": ["upgrade", "to", "postcss", "v4", ".", "x"], "add_tokens": "if ( source . input && source . input . file ) { message = source . input . file if ( ( source . input && source . input . file ) || source . start ) { if ( source . input && source . input . file ) { err . fileName = source . input . file", "del_tokens": "if ( source . file ) { message = source . file if ( source . file || source . start ) { if ( source . file ) { err . fileName = source . file", "commit_type": "upgrade"}
{"commit_tokens": ["Use", "postcss", "-", "modules", "-", "local", "-", "by", "-", "default"], "add_tokens": "import background from './css/background.css' ; import zIndex from './css/zIndex.css' ; background , word , zIndex", "del_tokens": "word", "commit_type": "use"}
{"commit_tokens": ["Fix", "import", "issues", "related", "to", "PhantomJS", "."], "add_tokens": "} ) ( window ? window : this ) ;", "del_tokens": "} ) ( this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "chaining", "setters", "on", "NumberFormatter", "and", "use", "that", "in", "the", "demo", "."], "add_tokens": "this . _alwaysShowsDecimalSeparator = alwaysShowsDecimalSeparator ; return this ; this . _decimalSeparator = decimalSeparator ; return this ; return this ; return this ; this . _negativePrefix = prefix ; return this ; this . _negativeSuffix = prefix ; return this ; this . _positivePrefix = prefix ; return this ; this . _positiveSuffix = prefix ; return this ; this . _roundingMode = roundingMode ; return this ;", "del_tokens": "return this . _alwaysShowsDecimalSeparator = alwaysShowsDecimalSeparator ; return this . _decimalSeparator = decimalSeparator ; return null ; return null ; return this . _negativePrefix = prefix ; return this . _negativeSuffix = prefix ; return this . _positivePrefix = prefix ; return this . _positiveSuffix = prefix ; return this . _roundingMode = roundingMode ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "demo", "into", "its", "own", "directory", "use", "a", "proper", "JS", "file"], "add_tokens": "exports . expressionType = function ( ast , start , end ) { var found = walk . findNodeAt ( ast , start , end , \"Expression\" , scopePasser , cx . topScope ) ;", "del_tokens": "exports . expressionType = function ( ast , exprEnd ) { var found = walk . findNodeAt ( ast , null , exprEnd , \"Expression\" , scopePasser , cx . topScope ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "upload", "button", "text", "option", "so", "that", "you", "are", "not", "required", "anymore", "to", "change", "the", "entire", "template", "for", "it", "."], "add_tokens": "uploadButtonText : 'Upload a file' , '<div class=\"qq-upload-button\">{uploadButtonText}</div>' + qq . extend ( this . _options , o ) ; // overwrite the upload button text if any this . _options . template = this . _options . template . replace ( / \\{uploadButtonText\\} / g , this . _options . uploadButtonText ) ;", "del_tokens": "'<div class=\"qq-upload-button\">Upload a file</div>' + qq . extend ( this . _options , o ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "dischargeTime", "to", "easily", "show", "the", "power", "state", "change", "in", "seconds"], "add_tokens": "if ( deviceStates [ dev ] . dischargeAt ) { self . devices [ index ] . dischargeAt = deviceStates [ dev ] . dischargeAt ; self . devices [ index ] . dischargeTime = Math . round ( ( Date . now ( ) - deviceStates [ dev ] . dischargeAt . getTime ( ) ) / 1000 ) ; }", "del_tokens": "if ( deviceStates [ dev ] . dischargeAt ) self . devices [ index ] . dischargeAt = deviceStates [ dev ] . dischargeAt ;", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "g", "--", "grep", "<pattern", ">", "support"], "add_tokens": "} ; } ; } ; } ;", "del_tokens": "} } } }", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "bugs", "in", "searcher", "and", "tests"], "add_tokens": "cancel : function ( callback ) { this . job . cancel ( callback ) ;", "del_tokens": "cancel : function ( ) { this . job . cancel ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "callback", "support", "on", "array", "load"], "add_tokens": "var from = options . from ; var to = options . to ; var label = options . label ; var callback = options . callback ; vulpejs . utils . execute ( callback , $rootScope . vulpejs ) ;", "del_tokens": "var from = options . from , to = options . to , label = options . label ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "size", "issue", "with", "linked", "list", "and", "added", "alternative", "method", "for", "appending", "to", "sll", "for", "efficiency"], "add_tokens": "exports . Needle = Needle ; // temporary for client side testing //window.Needle = Needle;", "del_tokens": "exports . Needle = Needle ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "full", "support", "for", "algolia"], "add_tokens": "const indexName = process . env . GATSBY_ALGOLIA_INDEX_NAME ; indexName : indexName ,", "del_tokens": "indexName : 'wix' ,", "commit_type": "add"}
{"commit_tokens": ["Added", "debug", "statements", "throughout", "code", "for", "troubleshooting", "and", "bumped", "minor", "version"], "add_tokens": "debug ( 'starting connection' ) ; debug ( 'got host list, connecting to hosts' ) ; debug ( 'connecting to all hosts' ) ; debug ( 'flushing client write buffer' ) ;", "del_tokens": "debug ( 'Connecting...' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "preventing", "supervisor", "from", "work", "if", "node", "were", "run", "without", "extname", "on", "target", "script"], "add_tokens": "currentProcessFileName : $memoized ( $property ( function ( ) { var file = process . argv [ 1 ] return file + ( path . extname ( file ) || '.js' ) } ) ) ,", "del_tokens": "currentProcessFileName : $property ( process . argv [ 1 ] ) ,", "commit_type": "fix"}
{"commit_tokens": ["Adding", "some", "testing", "for", "createFromText", "and", "the", "reading", "the", "passthrough", "res", ".", "sentry", "object", "."], "add_tokens": "} , client = new raven . Client ( options ) ; client . createFromText ( 'Testing!!!' , function ( result ) { } ) ; raven . patchGlobal ( options ) ; function handle_request ( req , res ) { throw new Error ( 'broke' ) ; } connect ( function connect ( req , res ) { handle_request ( req , res ) ; } , raven_middleware ( client ) , function ( err , req , res , next ) { res . statusCode = 500 ; res . end ( JSON . stringify ( res . sentry ) ) ; } ) . listen ( 3000 ) ; //ffdasfsd.fdasfd;", "del_tokens": "} ; raven . patch_global ( options ) ; connect ( function ( req , res ) { idontexist [ 'what' ] ; } , raven_middleware ( options ) ) . listen ( 3000 ) ; ffdasfsd . fdasfd ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "config", "arg", "handling", "."], "add_tokens": "config = JSON . parse ( bag . cli . lookupFile ( args . config || '.repoman.json' ) ) ; var config = JSON . parse ( bag . cli . lookupFile ( args . config || '.repoman.json' ) ) ,", "del_tokens": "config = JSON . parse ( bag . cli . lookupFile ( args . parent . configFile || '.repoman.json' ) ) ; var config = JSON . parse ( bag . cli . lookupFile ( args . parent . configFile || '.repoman.json' ) ) ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "toggle", "function", "set", "inlineStyleOverride", "."], "add_tokens": "import { stateToHTML } from 'draft-js-export-html' ; import { Editor , convertToRaw , RichUtils } from 'draft-js' ; toggleTextTransform = transform => { const newEditorState = styles . textTransform . toggle ( this . state . editorState , transform ) ; < div style = { { flex : '1 0 25%' } } onMouseDown = { e => e . preventDefault ( ) } >", "del_tokens": "import { Editor , convertToRaw , RichUtils } from 'draft-js' ; import { stateToHTML } from 'draft-js-export-html' ; toggleTextTransform = color => { const newEditorState = styles . textTransform . toggle ( this . state . editorState , color ) ; < div style = { { flex : '1 0 25%' } } >", "commit_type": "make"}
{"commit_tokens": ["Remove", "old", "stuff", "add", "artifact", "listing", "generation"], "add_tokens": "* } ] ; const artifactCollector = require ( './lib/artifact_collector' ) ; const artifactsListing = require ( './lib/artifacts_listing' ) ; artifactsListing ,", "del_tokens": "* ] ; const artifactCollector = require ( './lib/artifact_collector_core' ) ; const stylesheetCollector = require ( './lib/stylesheet_collector' ) ; stylesheetCollector ,", "commit_type": "remove"}
{"commit_tokens": ["added", "the", "total", "number", "of", "files", "to", "fsinfo", "output", "as", "well", "as", "file", "-", "not", "-", "found", "message"], "add_tokens": "logStatus ( 'NodeMCU' , 'Free Disk Space: ' + meta . remaining + ' KB | Total: ' + meta . total + ' KB | ' + files . length + ' Files' ) ; // files found ? if ( files . length == 0 ) { logStatus ( 'NodeMCU' , 'No Files found - do you have created the file-system ?' ) ; } else { logStatus ( 'NodeMCU' , 'Files stored into Flash (SPIFFS)' ) ; // print fileinfo files . forEach ( function ( file ) { logStatus ( '' , '\\t |- ' + file . name + ' (' + file . size + ' Bytes)' ) ; } ) ; }", "del_tokens": "logStatus ( 'NodeMCU' , 'Free Disk Space: ' + meta . remaining + ' KB | Total: ' + meta . total + ' KB' ) ; logStatus ( 'NodeMCU' , 'Files stored into Flash (SPIFFS)' ) ; // print fileinfo files . forEach ( function ( file ) { logStatus ( '' , '\\t |- ' + file . name + ' (' + file . size + ' Bytes)' ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "new", "option", "enableRestartRunningInstances", "to", "restart", "instances", "after", "file", "upload", "."], "add_tokens": "const TaskOptions = require ( './core/taskOptions' ) . TaskOptions ; const RestartAllRunningInstancesRequest = require ( './api/restartAllRunningInstancesRequest' ) . RestartAllRunningInstancesRequest ; * @ type { ! TaskOptions } var options = this . options ( new TaskOptions ( ) ) ; requestSender = new RequestSender ( options . host , options . port ) ; } ) . then ( function ( ) { var promise = Promise . resolve ( ) ; if ( options . enableRestartRunningInstances ) { promise = requestSender . sendRequest ( new RestartAllRunningInstancesRequest ( ) ) . then ( function ( ) { grunt . log . ok ( 'All instances restarted.' ) ; } ) ; } return promise ; } ) . then ( function finish ( ) { done ( ) ;", "del_tokens": "* @ type { { files : { src : [ ] } , srcMerge : string , dest : string } } var config = this . data ; requestSender = new RequestSender ( config . host , config . port ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "can", "terminate", "before", "terminating"], "add_tokens": "console . log ( 'Test runner started -- http://localhost:' + options . port + '/' ) ; if ( worker ) { worker . terminate ( ) ; worker = null ; }", "del_tokens": "console . log ( 'Test runner started: http://localhost:' + options . port + '/' ) ; worker . terminate ( ) ; worker = null ;", "commit_type": "make"}
{"commit_tokens": ["make", "utils", ".", "once", "protect", "recursive", "functions"], "add_tokens": "result = func . apply ( this , arguments ) ;", "del_tokens": "result = func . apply ( this , arguments ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "the", "broken", "test", "case"], "add_tokens": "const RocketChatClient = require ( \"../lib/rocketChat\" ) . RocketChatClient ;", "del_tokens": "const RocketChatClient = require ( \"../lib/rocketchat\" ) . RocketChatClient ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "live", "move", "updating", "handling", "."], "add_tokens": "ply : situation . ply , if ( chessGround && ( data . ply > config . ply ) ) { config . ply = data . ply ; chessGround . move ( data . orig , data . dest ) ;", "del_tokens": "console . dir ( chessGround ) ; if ( chessGround && data . fen !== chessGround . state . fen ) { chessGround . move ( data . orig , data . dest ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "full", "stop", "with", "--"], "add_tokens": "default : { stream : true } , '--' : true", "del_tokens": "default : { stream : true }", "commit_type": "add"}
{"commit_tokens": ["Added", "options", "for", "distribution", "alignment", "range"], "add_tokens": "guidelines : [ \"gridSpacing\" , \"guidelinesStackOrder\" , \"guidelinesTolerance\" , \"guidelinesStyle\" , \"distributionGuidelines\" , \"range\" ] ,", "del_tokens": "guidelines : [ \"gridSpacing\" , \"guidelinesStackOrder\" , \"guidelinesTolerance\" , \"guidelinesStyle\" , \"distributionGuidelines\" ] ,", "commit_type": "add"}
{"commit_tokens": ["update", "local", "database", "config", "to", "load", "from", "local", ".", "js"], "add_tokens": "var log = require ( '../log' ) ( ) ; storage : path . resolve ( projectFolder , 'files/sqlite/dev.sqlite' ) , // by default log to info logging : log . info storage : path . resolve ( projectFolder , 'files/sqlite/test.sqlite' ) , // by default log to info logging : log . info } , dbFileConfigs = require ( path . resolve ( projectFolder , 'config' , 'local.js' ) ) . database ;", "del_tokens": "storage : path . resolve ( projectFolder , 'files/sqlite/dev.sqlite' ) storage : path . resolve ( projectFolder , 'files/sqlite/test.sqlite' ) } dbFileConfigs = require ( path . resolve ( projectFolder , 'configs' , 'database.js' ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Moved", "the", "module", "meta", "validation", "to", "the", "fetch", "step", "to", "fail", "a", "bit", "earlier", ".", "A", "bad", "module", "meta", "will", "no", "longer", "fail", "in", "the", "loader", "pipeline"], "add_tokens": "this . pipeline = new Pipeline ( [ metaTransform , metaDependencies ] ) ;", "del_tokens": "metaValidation = require ( './meta/validation' ) , this . pipeline = new Pipeline ( [ metaValidation , metaTransform , metaDependencies ] ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "calculating", "rounded", "to", "step", "value", "add", "negative", "values", "example"], "add_tokens": "const stepDecimalsMultiplier = Math . pow ( 10 , this . stepDecimals ) ; this . stepDecimals = calculateDecimals ( this . config . step ) ;", "del_tokens": "const stepDecimalsMultiplier = Math . pow ( 10 , this . stepRatioDecimals ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "reductions", "array", "builder", "function"], "add_tokens": "} , // Returns an array of each intermediate stage of a call to // a `reduce`-like function. reductions : function ( array , fun , init ) { var ret = [ ] ; var acc = init ; _ . each ( array , function ( v , k ) { acc = fun ( acc , array [ k ] ) ; ret . push ( acc ) ; } ) ; return ret ; }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["removed", "volume", "option", "added", "system", "notifications", "added", "option", "to", "turn", "sound", "off"], "add_tokens": "* Copyright ( c ) 2014 - 2015 Dominik Wilkowski * Licensed under the GNU GPLv2 license . test1 : { options : { } , } , // deviate from defaults test2 : { options : { sound : 'bloom' , //differten build in sound randomize : true , //randomize build in sounds custom : './sounds/nudge.mp3' , //run your own notifications : true , } , } , test3 : { options : { sound : 'bloom' , //differten build in sound randomize : [ //randomize below sounds './sounds/hollow.mp3' , './sounds/realization.mp3' , ] , custom : './sounds/nudge.mp3' , //run your own notifications : true , } , } , test4 : { sound : false , //turn sound off notifications : true , //------------------------------------------------------------------------------------------------------------------------------------------------------------ //------------------------------------------------------------------------------------------------------------------------------------------------------------", "del_tokens": "* Copyright ( c ) 2014 Dominik Wilkowski * Licensed under the MIT license . wakeme : { // sound: 'bloom', //differten build in sound // randomize: true, //randomize build in sounds // randomize: [ // './sounds/hollow.mp3', // './sounds/realization.mp3', // ], // custom: './sounds/nudge.mp3', //run your own // volume: 7, //---------------------------------------------------------------------------------------------------------------------------------------------------------- //----------------------------------------------------------------------------------------------------------------------------------------------------------", "commit_type": "remove"}
{"commit_tokens": ["fixing", "toNumber", "overflow", "+", "faster", "toString", "implementation"], "add_tokens": "return ( this . _high * 65536 ) + this . _low return this . toNumber ( ) . toString ( radix || 10 )", "del_tokens": "return ( this . _high << 16 ) | this . _low radix = radix || 10 var radixUint = radixCache [ radix ] || new UINT32 ( radix ) if ( ! this . gt ( radixUint ) ) return this . toNumber ( ) . toString ( radix ) var self = this . clone ( ) var res = new Array ( 32 ) for ( var i = 31 ; i >= 0 ; i -- ) { self . div ( radixUint ) res [ i ] = self . remainder . toNumber ( ) . toString ( radix ) if ( ! self . gt ( radixUint ) ) break } res [ i - 1 ] = self . toNumber ( ) . toString ( radix ) return res . join ( '' )", "commit_type": "fix"}
{"commit_tokens": ["removing", "first", "path", "character", "check"], "add_tokens": "// if (c && '/' !== c && '.' !== c) return next(layerError);", "del_tokens": "if ( c && '/' !== c && '.' !== c ) return next ( layerError ) ;", "commit_type": "remove"}
{"commit_tokens": ["make", "nonegate", "option", "more", "specific"], "add_tokens": "if ( parsed === '' && isNegated && this . options . nonegate !== true ) {", "del_tokens": "if ( parsed === '' && isNegated && ! this . options . nonegate ) {", "commit_type": "make"}
{"commit_tokens": ["fix", "missing", "replace", "attribute", "key"], "add_tokens": "else if ( typeof branch [ 1 ] === 'function' ) setReplaceAttribute ( branch , boundNode ) else console . warn ( // eslint-disable-line 'A change function was not defined on the key \"' + key + '\".' ) adjacentNodes . push ( [ key , boundNode ] ) setReplaceAttribute ( branch , boundNode ) function setReplaceAttribute ( branch , boundNode ) { Object . defineProperty ( branch , replaceAttributeKey , { value : ~ replaceValue . indexOf ( boundNode . nodeName ) ? ~ replaceChecked . indexOf ( boundNode . type ) ? 'checked' : 'value' : 'textContent' } ) }", "del_tokens": "else if ( typeof branch [ 1 ] !== 'function' ) console . warn ( // eslint-disable-line 'A change function was not defined on the key \"' + key + '\".' ) else adjacentNodes . push ( [ key , boundNode ] ) Object . defineProperty ( branch , replaceAttributeKey , { value : ~ replaceValue . indexOf ( boundNode . nodeName ) ? ~ replaceChecked . indexOf ( boundNode . type ) ? 'checked' : 'value' : 'textContent' } )", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "status", "bar", "to", "drag", "and", "drop", "dump", "that", "shows", "errors", "and", "warnings", "that", "happen", "while", "parsing"], "add_tokens": "throw \"DICM prefix not found at location 132\" ;", "del_tokens": "throw \"DICM prefix not found at location 132 in this byteStream\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "iOS", "platform", "to", "cordova", "after", "hooks", "are", "copied", "so", "that", "it", "will", "add", "the", "default", "plugins", "in", "the", "hooks"], "add_tokens": "var cordovaCommand = 'cordova create app ' + reverseDomain + ' ' + nameOfApp ; copyHooks , runCommand ( 'cd app; cordova platforms add ios' , 'Adding ios platform to cordova...' )", "del_tokens": "var cordovaCommand = 'cordova create app ' + reverseDomain + ' ' + nameOfApp + '; cd app; ' + 'cordova platforms add ios' ; copyHooks", "commit_type": "add"}
{"commit_tokens": ["Added", "tolerence", "parameter", "to", "fuzzy", "string", "matcher"], "add_tokens": "* @ param number tolerence The tolerence when comparing using levenshtein , defaults to 10 function fuzzyStringCompare ( a , b , tolerence ) { if ( tolerence == undefined && levenshtein ( as , bs ) < 10 ) return true ; if ( tolerence && levenshtein ( as , bs ) <= tolerence ) return true ;", "del_tokens": "function fuzzyStringCompare ( a , b ) { if ( levenshtein ( as , bs ) < 10 ) return true ; } / ** * Returns true if the string 'looks' numeric * e . g . '1st' , '23rd' * @ param string string The string to examine * @ return boolean True if the string appears to be numeric * / function isDecendentNumeric ( a ) { return / ^[0-9]+(st|nd|rd|th)$ / . test ( a ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "column", "titles"], "add_tokens": "data . buffer . push ( \"\\n <th><div class=\\\"table-tree__th-inner\\\" data-label=\\\"column-title\\\">\" ) ;", "del_tokens": "data . buffer . push ( \"\\n <th><div class=\\\"table-tree__th-inner\\\">\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "last", "test", "to", "pass", "green"], "add_tokens": "function matchHash ( parent , hash , params ) { var _params = params || [ ] ; _params . forEach ( ( item , i ) => { container . setAttribute ( ` ${ i + 1 } ` , item ) ; } ) ; if ( i > 0 && item ) { _params . push ( item ) ; container . setAttribute ( ` ${ _params . length } ` , item ) ; _hash = next_hash [ next_hash . length - 1 ] ; matchHash ( container , _hash , _params ) ;", "del_tokens": "function matchHash ( parent , hash ) { if ( i === 0 ) { } else if ( item ) { container . setAttribute ( ` ${ i } ` , item ) ; } if ( i > 0 ) { if ( next_hash [ 1 ] === item ) { next_hash = [ ... next_hash . slice ( 0 , 1 ) , ... next_hash . slice ( 2 ) ] ; } _hash = next_hash [ 1 ] ; matchHash ( container , _hash ) ;", "commit_type": "make"}
{"commit_tokens": ["updating", "devserver", "to", "use", "Config"], "add_tokens": ", Config = require ( '../lib/model/Config.js' ) var config = new Config ( this . options ( ) ) , options = this . target ? config . getServer ( this . target ) : config . getOptions ( )", "del_tokens": ", loadCompleteOptions = require ( '../lib/commands/loadCompleteOptionsCmd.js' ) var options = loadCompleteOptions ( this . options ( ) )", "commit_type": "update"}
{"commit_tokens": ["Fixed", "append", "-", ">", "push", "bug"], "add_tokens": "node . value . push ( this . composeNode ( node , index ) ) ;", "del_tokens": "node . value . append ( this . composeNode ( node , index ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "mocha", "-", "phantomjs", "test", "suite"], "add_tokens": "describe ( 'chai-immutable' , function ( ) {", "del_tokens": "var typeEnv ; typeEnv = 'Node.js' ; else typeEnv = 'PhantomJS' ; describe ( 'chai-immutable (' + typeEnv + ')' , function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "some", "missing", "use", "strict", "and", "remove", "unnecessary", "comments"], "add_tokens": "'use strict' ;", "del_tokens": "// // Created by davimacedo on 22/10/15. //", "commit_type": "add"}
{"commit_tokens": ["fixed", "access", "to", "the", "read", "-", "write", "indexes"], "add_tokens": "* Deletes all records matching the provided filter . * let nativeIndex = this [ FIELDS . objectStore ] . index ( indexName )", "del_tokens": "let nativeIndex = this [ FIELDS . storage ] . index ( indexName )", "commit_type": "fix"}
{"commit_tokens": ["added", "resize", "event", "and", "width", "/", "height"], "add_tokens": "var shell = require ( \"../shell\" ) ( )", "del_tokens": "var shell = require ( \"../shell\" ) ( { pointerLock : true } )", "commit_type": "add"}
{"commit_tokens": ["Add", "editing", "prop", "to", "fields"], "add_tokens": "const { fields , definitions , onInputChange , entityPathArray , editing } = props ; return < FieldComponent { ... options } { ... field } editing = { editing } name = { propertyName } onChange = { onChange } value = { value } metadata = { definitions [ propertyName ] } / > ;", "del_tokens": "const { fields , definitions , onInputChange , entityPathArray } = props ; return < FieldComponent { ... options } { ... field } name = { propertyName } onChange = { onChange } value = { value } metadata = { definitions [ propertyName ] } / > ;", "commit_type": "add"}
{"commit_tokens": ["update", "message", "parsers", "to", "support", "async", "parsing"], "add_tokens": "var noop = utils . noop ;", "del_tokens": "// --- Client Helpers --- function noop ( ) { }", "commit_type": "update"}
{"commit_tokens": ["added", "sum", "to", "all", "metrics", "and", "mean", "to", "the", "total", "-", "also", "changed", "the", "way", "we", "calculate", "these", "metrics", "by", "using", "a", "cumulative", "sum", "as", "it", "is", "more", "efficient", "for", "multiple", "percentile", "thresholds"], "add_tokens": "var cumulativeValues = [ min ] ; for ( var i = 1 ; i < count ; i ++ ) { cumulativeValues . push ( values [ i ] + cumulativeValues [ i - 1 ] ) ; } var sum = min ; maxAtThreshold = values [ numInThreshold - 1 ] ; sum = cumulativeValues [ numInThreshold - 1 ] ; message += 'stats.timers.' + key + '.sum_' + clean_pct + ' ' + sum + ' ' + ts + \"\\n\" ; sum = cumulativeValues [ count - 1 ] ; mean = sum / count ; message += 'stats.timers.' + key + '.sum ' + sum + ' ' + ts + \"\\n\" ; message += 'stats.timers.' + key + '.mean ' + mean + ' ' + ts + \"\\n\" ;", "del_tokens": "var pctValues = values . slice ( 0 , numInThreshold ) ; maxAtThreshold = pctValues [ numInThreshold - 1 ] ; // average the remaining timings var sum = 0 ; for ( var i = 0 ; i < numInThreshold ; i ++ ) { sum += pctValues [ i ] ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "lint", "issues", ":", "remove", "most", "usages", "of", "findDOMNode", "."], "add_tokens": "_el : ? HTMLElement ; _elSetter = ( el : ? HTMLElement ) => { this . _el = el ; } ; const el = this . _el ; /*:: if (!el) throw new Error(); */ const el = this . _el ; /*:: if (!el) throw new Error(); */ ref = { this . _elSetter }", "del_tokens": "import { findDOMNode } from 'react-dom' ; const el = findDOMNode ( this ) ; /*:: if (!(el instanceof HTMLElement)) throw new Error(); */ const el = findDOMNode ( this ) ; /*:: if (!(el instanceof HTMLElement)) throw new Error(); */", "commit_type": "fix"}
{"commit_tokens": ["Added", "packaging", "info", "w", "/", "uglify", "automation", "and", "restructured", "directories"], "add_tokens": "* ( a ) Wil Neeley * ( c ) Code may be freely distributed under the MIT license . } ) ( jQuery , window , document ) ;", "del_tokens": "* ( a ) Wil Neeley , Trestle Media , LLC . * Code may be freely distributed under the MIT license . } ) ( jQuery , window , document ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "callback", "as", "part", "of", "argument", "list"], "add_tokens": "if ( ! ( this instanceof SendMessage ) ) return new SendMessage ( clientId , clientSecret , callback )", "del_tokens": "if ( ! ( this instanceof SendMessage ) ) return new SendMessage ( clientId , clientSecret )", "commit_type": "add"}
{"commit_tokens": ["add", "jBone", ".", "makeArray", "handle", "caseses", "with", "array", "like", "objects", "in", "jBone", "()"], "add_tokens": "var getType = { } ; return el && getType . toString . call ( el ) === \"[object Function]\" ; } , isArray = function ( el ) { return Array . isArray ( el ) ; // Return element wrapped by jBone return jBone . makeArray ( element , this ) ;", "del_tokens": "return typeof el === \"function\" ; // Return element wrapped by jBone if ( element ) { element = Array . isArray ( element ) ? element : [ element ] ; return jBone . merge ( this , element ) ; } return this ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "gjslint", "error", "-", "Line", "too", "long"], "add_tokens": "if ( isNaN ( token ) || String ( token ) . length != alterations [ a ] . length ) {", "del_tokens": "if ( isNaN ( token ) || String ( token ) . length != alterations [ a ] . length ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "old", "docs", "area", "event", "naming", "and", "enums"], "add_tokens": "UiAreaMouseEvent , UiAreaKeyEvent , Point , UiAreaKeyEvent , UiAreaMouseEvent , brushType : DrawBrush . type , modifierKeys : UiAreaKeyEvent . modifierKeys , extKeys : UiAreaKeyEvent . extKeys libui . Area . init ( UiAreaMouseEvent , UiAreaKeyEvent , AreaDrawParams , AreaDrawContext ,", "del_tokens": "AreaMouseEvent , AreaKeyEvent , brushType : DrawBrush . type libui . Area . init ( AreaMouseEvent , AreaKeyEvent , AreaDrawParams , AreaDrawContext ,", "commit_type": "use"}
{"commit_tokens": ["Added", "slug", "to", "the", "resource", "name", "properties", "mostly", "for", "blog", "APIs"], "add_tokens": "var nameProperties = [ 'id' , 'key' , 'slug' , 'code' , 'number' , 'num' , 'nbr' , 'username' , 'name' ] ;", "del_tokens": "var nameProperties = [ 'id' , 'key' , 'code' , 'number' , 'num' , 'nbr' , 'username' , 'name' ] ;", "commit_type": "add"}
{"commit_tokens": ["added", "globalMetricPrefix", "option", "to", "use", "a", "single", "prefix", "for", "all", "statsD", "metric", "types"], "add_tokens": "/ ** * Global metric prefix option will override any other configured metric prefixes * / if ( config . globalMetricPrefix ) { options . customMetricPrefix . gauges = options . customMetricPrefix . counters = options . customMetricPrefix . timers = options . customMetricPrefix . sets = config . globalMetricPrefix ; } else if ( config . customMetricPrefix ) {", "del_tokens": "if ( config . customMetricPrefix ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "textContent", "for", "cross", "-", "browser", "compatibility", "."], "add_tokens": "var text = ( 'innerText' in target ) ? 'innerText' : 'textContent' ; target [ text ] += ' [click!]' ; target [ text ] = target [ text ] . replace ( / \\[click!\\] / g , '' ) ;", "del_tokens": "target . innerText += ' [click!]' ; target . innerText = target . innerText . replace ( / \\[click!\\] / g , '' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", ".", "delete", "method", "from", "BaseModel"], "add_tokens": "destroy : function ( options ) {", "del_tokens": "destroy : function ( ) { return this . _delete . apply ( this , arguments ) ; } , // really delete from db, useful for tests in case destroy is overridden delete : function ( ) { return this . _delete . apply ( this , arguments ) ; } , _delete : function ( options ) {", "commit_type": "remove"}
{"commit_tokens": ["fix", "bad", "performance", "on", "certain", "inputs"], "add_tokens": "var x = Math . floor ( hilbertMax * ( this . data [ 5 * i + 1 ] - this . _minX ) / width ) ; var y = Math . floor ( hilbertMax * ( this . data [ 5 * i + 2 ] - this . _minY ) / height ) ;", "del_tokens": "var x = Math . floor ( hilbertMax * this . data [ 5 * i + 1 ] / width ) ; var y = Math . floor ( hilbertMax * this . data [ 5 * i + 2 ] / height ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "the", "overly", "complicated", "ajaxorg", "github", "shit", "-", "replace", "with", "like", "15", "lines", "of", "code"], "add_tokens": "repo = new Repo ( repo ) . getData ( function ( err ) { err || repo . spook ( ) ; } ) ;", "del_tokens": "repo = new Repo ( repo ) . getData ( function ( err ) { err || repo . spook ( next ) ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "return", "statement", "if", "expression", "is", "not", "exists"], "add_tokens": "return b . returnStatement ( node . expression ? mapExpression ( node . expression , meta ) : null ) ;", "del_tokens": "return b . returnStatement ( mapExpression ( node . expression , meta ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "full", "lowercase", "version", "for", "UUIDs", "passing", "between", "react", "-", "native", "module", "and", "js", "on", "iOS", "."], "add_tokens": "import { fullUUID } from './Utils' ; if ( characteristic . deviceUUID !== deviceIdentifier || characteristic . serviceUUID !== fullUUID ( serviceUUID ) || characteristic . uuid !== fullUUID ( characteristicUUID ) ) return", "del_tokens": "if ( characteristic . deviceUUID . toUpperCase ( ) !== deviceIdentifier . toUpperCase ( ) || characteristic . serviceUUID . toUpperCase ( ) !== serviceUUID . toUpperCase ( ) || characteristic . uuid . toUpperCase ( ) !== characteristicUUID . toUpperCase ( ) ) return", "commit_type": "implement"}
{"commit_tokens": ["Changed", "boolean", "compare", "to", "an", "options", "dic", "(", "object", ")", "updated", "unit", "test", "to", "match", "other", "test", "patternes", "and", "remove", "spyOn"], "add_tokens": "function set ( path , value , options = { } ) { // If using options.compare = true. JSON.strigify compare the two sets of data. if ( options . compare ) {", "del_tokens": "function set ( path , value , compare ) { // If using compare = true. JSON.strigify compare the two sets of data. if ( compare ) {", "commit_type": "change"}
{"commit_tokens": ["make", "sure", "to", "give", "method", "names", "actual", "names", "."], "add_tokens": "Paginator = Class ( /* @lends module:tastypie/paginator.Paginator.prototype */ { , page : function page ( ) { , next : function next ( limit , offset , count ) { , previous : function previous ( limit , offset , count ) { , count : function count ( ) { , slice : function slice ( limit , offset ) { , limit : function limit ( ) {", "del_tokens": "Paginator = Class ( /* @lends module .THING.prototype */ { , page : function ( ) { , next : function ( limit , offset , count ) { , previous : function ( limit , offset , count ) { , count : function ( ) { , slice : function ( limit , offset ) { , limit : function ( ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "removing", "reset", "-", "min", ".", "css", "temporary", "file", "on", "Windows", "."], "add_tokens": "var isWindows = process . platform == 'win32' ; var lineBreak = isWindows ? / \\r\\n / g : / \\n / g ; if ( isWindows ) exec ( 'del /q /f reset-min.css' ) ; else exec ( 'rm reset-min.css' ) ;", "del_tokens": "var isWindows = process . platform == 'win32' , lineBreak = isWindows ? / \\r\\n / g : / \\n / g ; exec ( 'rm reset-min.css' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "mode", "for", "running", "only", "one", "dyno", ":", "Procfile", "-", "free"], "add_tokens": "define ( 'hr/args' , [ ] , function ( ) { return { \"map\" : { \"apiKey\" : \"AIzaSyAAeM47baWKdmKoqWeIuK5bQCxtur6mWm0\" } , \"revision\" : 1381999800489 , \"baseUrl\" : \"/\" } ; } ) ;", "del_tokens": "define ( 'hr/args' , [ ] , function ( ) { return { \"map\" : { \"apiKey\" : \"AIzaSyAAeM47baWKdmKoqWeIuK5bQCxtur6mWm0\" } , \"revision\" : 1381960476963 , \"baseUrl\" : \"/\" } ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "scrollContainer", "option", "to", "allow", "devs", "to", "observe", "within", "scrolling", "containers", "."], "add_tokens": "let previousAmountScrolled = 0 ; let customScrollContainer = false ; if ( customScrollContainer ) { return Math . max ( customScrollContainer . scrollHeight , customScrollContainer . offsetHeight , body . scrollHeight , body . offsetHeight , html . clientHeight , html . scrollHeight , html . offsetHeight ) ; } else { return Math . max ( body . scrollHeight , body . offsetHeight , html . clientHeight , html . scrollHeight , html . offsetHeight ) ; } let amountScrolled = 0 ; if ( customScrollContainer ) { amountScrolled = customScrollContainer . scrollTop ; } else { amountScrolled = window . pageYOffset ; } if ( amountScrolled > previousAmountScrolled ) direction = 'down' ; else if ( amountScrolled < previousAmountScrolled ) direction = 'up' ; previousAmountScrolled = amountScrolled ; once = false , scrollContainer = false customScrollContainer = scrollContainer ;", "del_tokens": "let previousYOffset = 0 ; return Math . max ( body . scrollHeight , body . offsetHeight , html . clientHeight , html . scrollHeight , html . offsetHeight ) ; if ( window . pageYOffset > previousYOffset ) direction = 'down' ; else if ( window . pageYOffset < previousYOffset ) direction = 'up' ; previousYOffset = window . pageYOffset ; once = false", "commit_type": "add"}
{"commit_tokens": ["Adds", "transition", "from", "setupController", "to", "the", "setup", "hook"], "add_tokens": "setupController ( controller , model , transition ) { tryInvoke ( controller , 'setup' , [ event , transition ] ) ; sendEvent ( controller , 'setup' , [ event , transition ] ) ;", "del_tokens": "setupController ( controller ) { tryInvoke ( controller , 'setup' , [ event ] ) ; sendEvent ( controller , 'setup' , [ event ] ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "failing", "test", "for", "nested", "propstrings"], "add_tokens": "return template ( this . _convertRe ( str ) , ctx ) ; / ** * ## . _convertRe * * Convert propstring delimiters into valid Lo - Dash template * delimiters . * * @ param { String } ` ` * @ return { String } * / Route . prototype . _convertRe = function ( str ) { // convert `{a}` to es6 valid templates: `${a}` var brace = / \\{([^\\}]*(?:\\.[^\\}]*)*)\\} / g ; // convert `:a` to es6 valid templates: `${a}` var props = / :([^\\\\\\/:${}]+) / g ; return str . replace ( brace , '<%= $1 %>' ) . replace ( props , '<%= $1 %>' ) . replace ( '$' , '' ) ; } ;", "del_tokens": "// convert `{a}` to es6 valid templates: `${a}` var brace = / \\{([^\\}]*(?:\\.[^\\}]*)*)\\} / g ; // convert `:a` to es6 valid templates: `${a}` var props = / :([^\\\\\\/:${}]+) / g ; var route = str . replace ( brace , '${$1}' ) . replace ( props , '${$1}' ) . replace ( '$$' , '$' ) ; return template ( route , ctx ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "zoomed", "-", "in", "svg", "with", "pt", "units"], "add_tokens": "Version 2.4 .0 + chxnl", "del_tokens": "Version 2.4 .0 + chxk7", "commit_type": "fix"}
{"commit_tokens": ["move", "existing", "style", "block", "check", "outside", "ajax"], "add_tokens": "var existingStyle = window . document . querySelector ( 'style[data-href$=\"' + grunticon . href + '\"]' ) ; var ref = grunticon . getCSS ( grunticon . href ) ; callback = callback || function ( ) { } ; if ( existingStyle ) { // NOTE this will do nothing at all if the embeds are already there // and the embed attribute has been removed. The only purpose for this // is if the markup has been \"rerendered\" in the page after the // initial embed at which point the embed attributes should exist and // the existing embeds should be gone grunticon . embedIcons ( grunticon . getIcons ( existingStyle ) ) ; callback ( ) ; } else if ( ref ) { ajaxGet ( grunticon . href , function ( ) { } ) ; }", "del_tokens": "ajaxGet ( grunticon . href , function ( ) { // check to see if we've already created a style block for this href var existingStyle = window . document . querySelector ( 'style[data-href$=\"' + grunticon . href + '\"]' ) ; var ref = grunticon . getCSS ( grunticon . href ) ; if ( existingStyle ) { // NOTE this will do nothing at all if the embeds are already there // and the embed attribute has been removed. The only purpose for this // is if the markup has been \"rerendered\" in the page after the // initial embed at which point the embed attributes should exist and // the existing embeds should be gone grunticon . embedIcons ( grunticon . getIcons ( existingStyle ) ) ; } else { } // only call the callback if the href gets something out of the DOM // TODO this functions should probably throw an exception when the href // is now found in the page if ( ( existingStyle || ref ) && typeof callback === \"function\" ) { } } ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "an", "transfer", "effect", "that", "shows", "where", "opened", "tabs", "will", "go"], "add_tokens": "define ( [ 'jquery' , 'knockout' , './MainModel' , 'amplify' , 'cms/transfer-effect' , './ko-bindings/cms-tab' , './ko-bindings/moment' , 'bootstrap/button' , 'bootstrap/transition' , 'bootstrap/collapse' , 'bootstrap/dropdown' , 'bootstrap-notify' ] , function ( $ , ko , Main , amplify , transferEffect ) { amplify . subscribe ( 'cms.tabs.open' , function ( tab , e ) { if ( e && e . currentTarget ) { var options = { from : e . currentTarget , to : '.tabs-container .dropdown-toggle' , duration : 650 , easing : 'swing' } ; transferEffect ( options ) ; } } ) ;", "del_tokens": "define ( [ 'jquery' , 'knockout' , './MainModel' , './ko-bindings/cms-tab' , './ko-bindings/moment' , 'bootstrap/button' , 'bootstrap/transition' , 'bootstrap/collapse' , 'bootstrap/dropdown' , 'bootstrap-notify' ] , function ( $ , ko , Main ) {", "commit_type": "add"}
{"commit_tokens": ["add", "warning", "for", "duplicate", "bid", "provider"], "add_tokens": "this . totalBidProviders = 0 ; AuctionMediator . prototype . checkBids_ = function ( ) { if ( this . bidCount === this . totalBidProviders ) { if ( this . bidProviders [ bidProvider . name ] ) { Event . publish ( Event . EVENT_TYPE . WARN , 'Warning: bid provider ' + bidProvider . name + ' is already added' ) ; } else { this . totalBidProviders ++ ; this . bidProviders [ bidProvider . name ] = bidProvider ; }", "del_tokens": "AuctionMediator . prototype . checkBids_ = function ( /*data*/ ) { if ( this . bidCount === Object . keys ( this . bidProviders ) . length ) { this . bidProviders [ bidProvider . name ] = bidProvider ;", "commit_type": "add"}
{"commit_tokens": ["adding", "documentation", "on", "formats", "and", "custom", "formatting"], "add_tokens": "results . push ( format . log ( result . msg ) )", "del_tokens": "results . push ( result . msg )", "commit_type": "add"}
{"commit_tokens": ["updated", "docs", "[", "ci", "skip", "]"], "add_tokens": "/ ** * Promise resolver * * @ param { Object } [ Promise | Object | Function ] * @ param { Function } [ resolver ] - Resolver function ( resolve , reject , progress , timeout ) * @ return { Object } Promise * @ api public * / / ** * Check if promise is pending * * @ return { Boolean } - Returns true if pending or else false * / / ** * Check if promise is fulfilled * * @ return { Boolean } - Returns true if pending or else false * / / ** * Check if promise is rejeced * * @ return { Boolean } - Returns true if pending or else false * / / ** * Check if promise has resolved * * @ return { Boolean } - Returns true if pending or else false * / / ** * Get value if promise has been fulfilled * * @ return { Boolean } - Returns true if pending or else false * / / ** * Get reason if promise has rejected * * @ return { Boolean } - Returns true if pending or else false * /", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Fix", "when", "queue", "is", "disabled"], "add_tokens": "return func ( ) ;", "del_tokens": "return promise ( func ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "helper", "methods", ";", "remove", "extra", "logic"], "add_tokens": "return ! ! ( this . _isPartlyConnected ( ) && this . channel ) } _isPartlyConnected ( ) : boolean { return ! ! ( this . connection ) if ( ! this . _isConnected ( ) ) { if ( opts . type === 'topic' && ! opts . routingKey ) { if ( ! this . _isConnected ( ) ) { return Promise . reject ( new Error ( 'you must .connect() before consuming' ) ) // XXX(bryan): is this valid? should I not be checking _this_.consuming? if ( ! this . _isPartlyConnected ( ) ) { return Promise . reject ( new Error ( 'not connected. cannot disconnect.' ) )", "del_tokens": "return ! ! ( this . connection && this . channel ) if ( ! this . channel ) { if ( ! opts . exchange || ! opts . type || ! opts . handler ) { return Promise . reject ( new Error ( 'exchange and handler are required' ) ) } if ( ! opts . type === 'topic' && ! opts . routingKey ) { if ( ! this . channel ) { throw new Error ( 'you must .connect() before consuming' ) if ( ! this . connection ) { throw new Error ( 'not connected. cannot disconnect.' )", "commit_type": "add"}
{"commit_tokens": ["Removed", "object", ".", "toArray", "()", "and", "object", ".", "isArray", "()", "."], "add_tokens": "if ( Array . isArray ( this ) )", "del_tokens": "if ( this . isArray ( ) ) / ** * Find out if the object is an array . * / newObject . isArray = function ( ) { return Array . isArray ( this ) ; } ; / ** * Return an array with the property values . * If already an array , returns the unmodified array . * / newObject . toArray = function ( ) { if ( this . isArray ( ) ) { return this ; } var result = [ ] ; this . forEach ( function ( value ) { result . push ( value ) ; } ) ; return result ; } ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "tokenization", "of", "the", "input"], "add_tokens": "return _ . filter ( html . split ( / ({{.+?}}(?!})|[{}\\(\\)\\[\\]#\\*`=:;,<>\"'\\/]|\\s+) / ) ) ;", "del_tokens": "return _ . filter ( html . split ( / ({{.+?}}(?!})|[{}\\(\\)=:;,<>\"'\\[\\]\\/]|\\s+) / ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "cache", "update", "animate", "event", "names"], "add_tokens": "node . dispatchEvent ( new Event ( 'animatestart' + direction ) ) ; node . dispatchEvent ( new Event ( 'animateend' + direction ) ) ; this . clonedFrom [ '__animationDuration' + direction ] = milliseconds ;", "del_tokens": "node . dispatchEvent ( new Event ( 'animatestart' ) ) ; node . dispatchEvent ( new Event ( 'animateend' ) ) ; this . clonedFrom . __animationDuration__ = milliseconds ;", "commit_type": "fix"}
{"commit_tokens": ["add", "callback", "option", "to", "train", "()"], "add_tokens": "var assert = require ( \"should\" ) , describe ( 'train() options' , function ( ) { it ( 'training callback called with training stats' , function ( done ) { var iters = 100 ; var period = 20 ; var target = iters / 20 ; var calls = 0 ; var net = new brain . NeuralNetwork ( ) ; net . train ( data , { iterations : iters , callback : function ( stats ) { assert . ok ( stats . iterations % period == 0 ) ; calls ++ ; if ( calls == target ) { done ( ) ; } } , callbackPeriod : 20 } ) ; } ) ;", "del_tokens": "var assert = require ( 'should' ) , describe ( 'thresholds' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["add", "filter", ":", "//", "https|hide"], "add_tokens": "Weinre : rules . weinre && rules . weinre . raw , Filter : rules . filter && rules . filter . raw", "del_tokens": "Weinre : rules . weinre && rules . weinre . raw", "commit_type": "add"}
{"commit_tokens": ["Updated", "Readme", "for", "the", "new", "Plugin", "structure"], "add_tokens": "new sassLintPlugin ( { failOnWarning : true } ) ,", "del_tokens": "new sassLintPlugin ( { configFile : '.sass-lint.yml' } ) ,", "commit_type": "update"}
{"commit_tokens": ["fix", "stray", "commas", "when", "exports", "are", "removed", "from", "object", "literals"], "add_tokens": "return } else if ( node . type === 'Property' ) { // We may have to also overwrite a comma here, eg in `module.exports = {a, b, c}` // where `a` and `b` are unused. Else we would end up with `{,, c}`. const match = string . original . slice ( node . end ) . match ( / ^\\s*, / ) if ( match ) { string . overwrite ( node . start , node . end + match [ 0 ] . length , ` ${ safeComment ( node . getSource ( ) ) } ` ) return } node . edit . update ( ` ${ safeComment ( node . getSource ( ) ) } ` )", "del_tokens": "} else { node . edit . update ( ` ${ safeComment ( node . getSource ( ) ) } ` )", "commit_type": "fix"}
{"commit_tokens": ["Added", "helper", "routines", "for", "assertions"], "add_tokens": "utils : require ( './utils' ) , / ** * Helper methods that can be used when evaluating assertions . * / assertionHelper : require ( './assertion-helper' )", "del_tokens": "utils : require ( './utils' )", "commit_type": "add"}
{"commit_tokens": ["make", "schema", "swagger", "-", "compliant"], "add_tokens": "// value: joi.any().when('op', { is: ['add', 'replace', 'test'], otherwise: joi.forbidden()}), // from: joi.string().when('op', { is: ['copy', 'move'], otherwise: joi.forbidden()}) value : joi . any ( ) , from : joi . string ( )", "del_tokens": "value : joi . any ( ) . when ( 'op' , { is : [ 'add' , 'replace' , 'test' ] , otherwise : joi . forbidden ( ) } ) , from : joi . string ( ) . when ( 'op' , { is : [ 'copy' , 'move' ] , otherwise : joi . forbidden ( ) } )", "commit_type": "make"}
{"commit_tokens": ["Fix", "JSHint", "warnings", "and", "improve", "code", "style"], "add_tokens": ". parse ( process . argv ) ;", "del_tokens": ". parse ( process . argv )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "the", "last", "of", "the", "independent", "babelrc", "files"], "add_tokens": "let output = hook . call ( this , result ) ;", "del_tokens": "let output = this : : hook ( result ) ;", "commit_type": "remove"}
{"commit_tokens": ["allow", "dynamical", "definition", "of", "columns"], "add_tokens": "'use strict' ; table . addColumn ( config . columns [ i ] ) ; } return table ; } ; Table . prototype . addColumn = function ( col ) { if ( ! ( col instanceof Column ) ) { col . table = this ; this . columns . push ( col ) ;", "del_tokens": "'use strict' ; var col = config . columns [ i ] ; col . table = table ; table . addColumn ( col ) ; return table ; } ; Table . prototype . addColumn = function ( col ) { this . columns . push ( col ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "open", "and", "close", "parentheses", "conversion"], "add_tokens": "output : 'a!%40%23%24%25%5E*%28%29_%2B-%3D%7B%7D%7C%5B%5D%5C%22%27%3C%3E%3F%2C%3A%3B.mp4'", "del_tokens": "output : 'a!%40%23%24%25%5E*()_%2B-%3D%7B%7D%7C%5B%5D%5C%22%27%3C%3E%3F%2C%3A%3B.mp4'", "commit_type": "fix"}
{"commit_tokens": ["implement", "a", "size", "helper", "on", "graph", "+", "using", "shards", "factory", "now", "to", "create", "a", "point", "instance"], "add_tokens": "/ ** * Calculate the number of nodes * / graph . prototype . size = function ( ) { var size = 0 ; for ( var i = 0 ; i < this . shards . length ; i ++ ) { if ( this . shards [ i ] ) { size += this . shards [ i ] . length ; } } return size ; } ; var uuid = this . uuid ( ) ; var shard = this . shard ( uuid ) ; result = shard . factory ( uuid ) ; } else { result . uuid = uuid ; shard . attach ( result ) ;", "del_tokens": "var point = require ( './point' ) ; result = new point ( this ) ; var uuid = this . uuid ( ) ; this . shard ( uuid ) . push ( uuid , result ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "activity", "parsing", "regex", "in", "API10"], "add_tokens": "/ mFocusedApp.+Record\\{.*\\s([^\\s\\/\\}]+)\\/([^\\s\\/\\}]+)(\\s[^\\s\\/\\}]+)*\\} / ) ;", "del_tokens": "/ mFocusedApp.+ActivityRecord\\{.*\\s([^\\s\\/\\}]+)\\/([^\\s\\/\\}]+)(\\s[^\\s\\/\\}]+)*\\} / ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "path", "type", "for", "Options"], "add_tokens": "var InvalidInputError = require ( './error/invalid-input' ) , path = require ( 'path' ) ; case 'path' : // A path that may be relative or absolute. We should parse this into an absolute path if ( path . isAbsolute ( value ) ) { return path . normalize ( value ) ; } return path . resolve ( process . cwd ( ) , value ) ;", "del_tokens": "var InvalidInputError = require ( './error/invalid-input' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "MIME", "type", "in", "static", "file", "serving"], "add_tokens": "var mime = require ( 'mime' ) ; var mimeObject = opts . mime || mime ; res . header ( \"Content-Type\" , mimeObject . lookup ( filePath ) ) ;", "del_tokens": "res . contentType ( filePath ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "batch", "cb", "invocation", "out", "of", "posthook", "try", "/", "catch"], "add_tokens": "cb ( )", "del_tokens": "cb ( )", "commit_type": "move"}
{"commit_tokens": ["Add", "examples", "and", "test", "methods"], "add_tokens": "const metronome = { } metronome . test = function ( ) { console . log ( 'Working...' ) } module . exports = metronome", "del_tokens": "import web3 from 'web3' export default web3", "commit_type": "add"}
{"commit_tokens": ["Remove", "Short", "description", "of", "image"], "add_tokens": "_replaceSelection ( cm , stat . image , '![](http://' , ')' ) ;", "del_tokens": "_replaceSelection ( cm , stat . image , '![Short description of image](http://' , ')' ) ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "clickableIcons", "override", "to", "use", "!!", "instead"], "add_tokens": "clickableIcons : ! ! this . props . clickableIcons ,", "del_tokens": "clickableIcons : this . props . clickableIcons || false ,", "commit_type": "change"}
{"commit_tokens": ["removed", "remaining", "psuedo", "-", "private", "properties", "from", "spring", ".", "js"], "add_tokens": "this . currentValue = ( this . currentTime >= this . targetTime ) ? this . targetValue : this . startValue + ( this . targetValue - this . startValue ) * transform ( this . springStiffness , ( this . currentTime - this . startTime ) / ( this . targetTime - this . startTime ) ) ;", "del_tokens": "this . currentValue = ( this . currentTime >= this . targetTime ) ? this . targetValue : this . startValue + ( this . targetValue - this . startValue ) * transform ( this . springStiffness , ( this . currentTime - this . startTime ) / ( this . targetTime - this . startTime ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "issue", "with", "iframes", "w", "/", "o", "allowfullscreen", "attrs"], "add_tokens": "var shouldPushElement = true ; // When BigScreen.request is called specifically, the element requested // is already pushed onto the stack. If the video element belongs to an // element on the stack, don't push it on here. if ( elements . length > 0 ) { for ( var i = 0 , length = elements . length ; i < length ; i ++ ) { var video = _getVideo ( elements [ i ] . element ) ; if ( video === event . srcElement ) { shouldPushElement = false ; break ; } } } if ( shouldPushElement ) { elements . push ( { element : event . srcElement , enter : emptyFunction , exit : emptyFunction , error : emptyFunction } ) ; }", "del_tokens": "elements . push ( { element : event . srcElement , enter : emptyFunction , exit : emptyFunction , error : emptyFunction } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "non", "-", "proxy", "test", "(", "broken", "by", "fda2296", ")", "."], "add_tokens": "vows . describe ( 'livestyle server in non-proxy mode' ) . addBatch ( { socket . emit ( 'watch' , [ '/styles.css' ] ) ; assert . deepEqual ( changedFileNames , [ '/styles.css' ] ) ;", "del_tokens": "vows . describe ( 'foo' ) . addBatch ( { socket . emit ( 'watch' , [ 'styles.css' ] , '/' ) ; assert . deepEqual ( changedFileNames , [ 'styles.css' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "index", "use", "100vw", "etc", "for", "canvas"], "add_tokens": "var gl = twgl . getWebGLContext ( document . getElementById ( \"canvas\" ) , {", "del_tokens": "var gl = twgl . getWebGLContext ( document . createElement ( \"canvas\" ) , { document . getElementById ( \"canvas\" ) . appendChild ( gl . canvas ) ;", "commit_type": "make"}
{"commit_tokens": ["updated", "the", "demo", "chat", "bus", ".", "io", "session", "stuff"], "add_tokens": "var session = require ( 'bus.io-session' ) ( ) ; app . use ( expressSession ( session . config ) ) ; bus . use ( session ) ;", "del_tokens": "var connectRedis = require ( 'connect-redis' ) ( expressSession ) ; var cookieParser = require ( 'cookie-parser' ) ; var config = { session : { secret : 'secret' , key : 'bus.io' , store : new connectRedis ( ) } } ; var session = require ( 'bus.io-session' ) ; app . use ( cookieParser ( ) ) ; app . use ( expressSession ( config . session ) ) ; bus . use ( session ( config . session ) ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "the", "change", "in", "run", "API", "on", "second", "call"], "add_tokens": "ctx . run = function ( life , automata , currentYear ) { assert . ok ( life , 'olivaw: need to provide number of years to run a generation' ) if ( ! currentYear ) currentYear = 0 if ( currentYear < life ) ctx . run ( life , automaton , ++ currentYear )", "del_tokens": "ctx . run = function ( life , automata , currentLife ) { assert . ok ( life , 'olivaw: need to provide number' ) assert . equal ( typeof life , 'number' , 'olivaw: life needs to be a number' ) if ( ! currentLife ) currentLife = 0 if ( currentLife < life ) ctx . run ( automaton , life , ++ currentLife )", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "few", "types", "for", "object", "transform", "values"], "add_tokens": "additionalProperties : { type : [ 'string' , 'boolean' , 'number' ] } ,", "del_tokens": "additionalProperties : { type : 'string' } ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "grunt", "and", "jshint", "use", "make", "and", "eslint"], "add_tokens": "( function ( ) { var i while ( ordinalizeTokens . length ) { i = ordinalizeTokens . pop ( ) formatTokenFunctions [ 'j' + i + 'o' ] = ordinalizeToken ( formatTokenFunctions [ 'j' + i ] , i ) } while ( paddedTokens . length ) { i = paddedTokens . pop ( ) formatTokenFunctions [ 'j' + i + i ] = padToken ( formatTokenFunctions [ 'j' + i ] , 2 ) } formatTokenFunctions . jDDDD = padToken ( formatTokenFunctions . jDDD , 3 ) } ( ) ) else if ( '' . __proto__ ) return object . __proto__", "del_tokens": "'use strict' ; , i while ( ordinalizeTokens . length ) { i = ordinalizeTokens . pop ( ) formatTokenFunctions [ 'j' + i + 'o' ] = ordinalizeToken ( formatTokenFunctions [ 'j' + i ] , i ) } while ( paddedTokens . length ) { i = paddedTokens . pop ( ) formatTokenFunctions [ 'j' + i + i ] = padToken ( formatTokenFunctions [ 'j' + i ] , 2 ) } formatTokenFunctions . jDDDD = padToken ( formatTokenFunctions . jDDD , 3 ) else if ( '' . __proto__ ) // jshint ignore:line return object . __proto__ // jshint ignore:line", "commit_type": "remove"}
{"commit_tokens": ["add", "remote", "cluster", "benchmark", "test"], "add_tokens": "broker . start ( ) . then ( ( ) => console . log ( ` ${ broker . nodeID } ` ) ) ;", "del_tokens": "broker . start ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "attributeValueRegex", "and", "better", "syntax", "error", "message"], "add_tokens": "* The token types on the resulting array may have one of the types : ejs - eval , ejs - escaped , ejs - raw", "del_tokens": "* The token types on the resulting array may have one of the following types : * ejs - eval , ejs - escaped , ejs - raw and ?? ?", "commit_type": "fix"}
{"commit_tokens": ["Allow", "bounce", "for", "animation", "easing"], "add_tokens": "const BOUNCE_IN = 'cubic-bezier(0.175, 0.885, 0.32, 1.275)' ; const BOUNCE_OUT = 'cubic-bezier(0.68, -0.275, 0.825, 0.115)' ; if ( easing === 'bounce-in' ) easing = BOUNCE_IN ; if ( easing === 'bounce-out' ) easing = BOUNCE_OUT ; return transition ( $el , { transform : [ transform + ' scale(0.5)' , transform + ' scale(1)' ] } , duration , _delay , 'bounce-in' ) ; animation = transition ( $el , { transform : [ transform + ' scale(1)' , transform + ' scale(0.5)' ] } , duration , delay , 'bounce-out' ) ;", "del_tokens": "const from = transform + ' scale(0.5)' ; const to = transform + ' scale(1)' ; const easing = 'cubic-bezier(0.175, 0.885, 0.32, 1.275)' ; return transition ( $el , { transform : [ from , to ] } , duration , _delay , easing ) ; const from = transform + ' scale(1)' ; const to = transform + ' scale(0.5)' ; const easing = 'cubic-bezier(0.68, -0.275, 0.825, 0.115)' ; animation = transition ( $el , { transform : [ from , to ] } , duration , delay , easing ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "multiple", "refresh", "problem", "when", "refreshed", "before", "first", "response"], "add_tokens": "vows . describe ( \"connection\" ) . addBatch ( { var self = this ; redirectUri : config . redirectUri , logLevel : config . logLevel } ) ; browser . visit ( conn . oauth2 . getAuthorizationUrl ( ) , function ( ) { browser . wait ( 1500 , self . callback ) ;", "del_tokens": "vows . describe ( \"salesforce\" ) . addBatch ( { redirectUri : config . redirectUri browser . visit ( conn . oauth2 . getAuthorizationUrl ( ) , this . callback ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", ":", "wrong", "source", "map", "path", "for", "sources", "in", "subdirs"], "add_tokens": "path : path . join ( file . base , destPath , file . relative ) + '.map' , comment = '\\n//# sourceMappingURL=' + path . join ( path . relative ( path . dirname ( file . path ) , file . base ) , destPath , file . relative ) + '.map' ;", "del_tokens": "path : path . join ( path . dirname ( file . path ) , destPath , path . basename ( file . path ) ) + '.map' , comment = '\\n//# sourceMappingURL=' + path . join ( destPath , path . basename ( file . path ) ) + '.map' ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "problem", "when", "validating", "a", "part", "of", "the", "settings"], "add_tokens": "export function validate ( config , metaConfig = { } , toValidate = true ) { validateMightThrow ( config , metaConfig . validations ) ; console . log ( config [ group ] , ( metaConfig . validations [ group ] ) ) ; validateMightThrow ( config [ group ] , metaConfig . validations && metaConfig . validations [ group ] ) ; * @ param { object } validations - the meta configuration object that has information about how to validate export function validateMightThrow ( config , validations ) { if ( ! validations ) { const validateKeys = Object . keys ( validations ) ; const validator = validations [ validateKey ] ; ... validator", "del_tokens": "export function validate ( config , metaConfig , toValidate = true ) { validateMightThrow ( config , metaConfig ) ; validateMightThrow ( config [ group ] , metaConfig [ group ] ) ; * @ param { object } metaConfig - the meta configuration object that has information about how to validate export function validateMightThrow ( config , metaConfig ) { if ( ! metaConfig || ! metaConfig . validations ) { const validateKeys = Object . keys ( metaConfig . validations ) ; const validator = metaConfig . validations [ validateKey ] ; validations : { ... validator }", "commit_type": "fix"}
{"commit_tokens": ["allow", "users", "to", "download", "an", "event", "as", "an", "ical", "file"], "add_tokens": "EventModal . prototype . exportDateFormat = '{year}-{MM}-{dd}-{HH}-{mm}' ; end : this . model . getEndDateObject ( ) . format ( this . inputDateTimeFormat ) , exportdate : this . model . getStartDateObject ( ) . format ( this . exportDateFormat ) buf . push ( '</span>&nbsp;<a' ) ; buf . push ( attrs ( { 'href' : ( \"events/\" + ( id ) + \"/\" + ( exportdate ) + \".ics\" ) } , { \"href\" : true } ) ) ; buf . push ( '> <i class=\"fa fa-download fa-1\"></i></a><button class=\"close\">&times;</button></div><div class=\"modal-body\"><form id=\"basic\" class=\"form-inline\"><div class=\"row-fluid\"><div class=\"control-group span12\"><label for=\"basic-summary\" class=\"control-label\">' ) ;", "del_tokens": "end : this . model . getEndDateObject ( ) . format ( this . inputDateTimeFormat ) buf . push ( '</span><button class=\"close\">&times;</button></div><div class=\"modal-body\"><form id=\"basic\" class=\"form-inline\"><div class=\"row-fluid\"><div class=\"control-group span12\"><label for=\"basic-summary\" class=\"control-label\">' ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "general", "case", "-", "insensitivity", "in", "datarow", "test"], "add_tokens": "} , setCaseSensitivity : TerminalNode . setCaseSensitivity", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Fixed", "getViewportCollisions", "()", "math", "."], "add_tokens": "if ( coords . left < scrollLeft || coords . right + elementWidth > scrollLeft + windowWidth ) { if ( coords . left + elementWidth > scrollLeft + windowWidth || coords . right < scrollLeft ) {", "del_tokens": "if ( coords . left < scrollLeft || ( coords . right && coords . right - elementWidth < scrollLeft ) ) { if ( coords . left + elementWidth > scrollLeft + windowWidth || ( coords . right && coords . right > scrollLeft + windowWidth ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "configmap", "to", "create", "testing", "bundle"], "add_tokens": "testBundleExternalName : process . env . HELM_BROKER_TEST_BUNDLE_EXTERNAL_NAME ? process . env . HELM_BROKER_TEST_BUNDLE_EXTERNAL_NAME : 'testing' , testBundleMinimalName : process . env . HELM_BROKER_TEST_BUNDLE_MINIMAL_NAME ? process . env . HELM_BROKER_TEST_BUNDLE_MINIMAL_NAME : 'minimal' , testBundleFullName : process . env . HELM_BROKER_TEST_BUNDLE_FULL_NAME ? process . env . HELM_BROKER_TEST_BUNDLE_FULL_NAME : 'full' ,", "del_tokens": "testBundleExternalName : 'testing' ,", "commit_type": "use"}
{"commit_tokens": ["Implement", "MonadIO", ".", "fromPromise", "()", ".", "Correct", "the", "naming", "of", "promiseof"], "add_tokens": "MonadIO . fromPromise = function ( p ) { var m = new MonadIODef ( function ( ) { return MonadIO . doM ( function * ( ) { return yield p ; } ) ; } ) ; return m ; } ; MonadIO . promiseof = function ( ref ) {", "del_tokens": "MonadIO . asof = function ( ref ) {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "missing", "semicolon", "in", "cucumber", "support", "code"], "add_tokens": "} ;", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["remove", "content", "-", "type", "header", "when", "using", "form", "data"], "add_tokens": "delete fetchOptions . headers [ 'Content-Type' ] ;", "del_tokens": "Object . assign ( fetchOptions . headers , { 'Content-Type' : 'multipart/form-data' } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "a", "path", "traversal", "issue", "when", "using", "root"], "add_tokens": "root = normalize ( root + sep ) parts = path . substr ( root . length ) . split ( sep )", "del_tokens": "root = normalize ( root ) parts = path . substr ( root . length + 1 ) . split ( sep )", "commit_type": "fix"}
{"commit_tokens": ["adding", "connected", "to", "redux", "+", "middleware"], "add_tokens": "blacklist : [ 'login' , 'search' , 'nav' ] , // reducer keys that you do NOT want stored to persistence here", "del_tokens": "blacklist : [ 'login' , 'search' ] , // reducer keys that you do NOT want stored to persistence here", "commit_type": "add"}
{"commit_tokens": ["Fix", "adding", "printouts", "at", "end", "of", "section"], "add_tokens": "var parent = Reveal . getSlide ( storage [ 1 ] . data [ i ] . slide . h , storage [ 1 ] . data [ i ] . slide . v ) . parentElement ; addPrintout ( parent , nextSlide [ i ] , imgCanvas , patImg ) ; addPrintout ( parent , nextSlide [ i ] , imgCanvas , patImg ) ; function addPrintout ( parent , nextSlide , imgCanvas , patImg ) { if ( nextSlide != null ) { parent . insertBefore ( newSlide , nextSlide ) ; } else { parent . append ( newSlide ) ; }", "del_tokens": "addPrintout ( nextSlide [ i ] , imgCanvas , patImg ) ; addPrintout ( nextSlide [ i ] , imgCanvas , patImg ) ; function addPrintout ( nextSlide , imgCanvas , patImg ) { nextSlide . parentElement . insertBefore ( newSlide , nextSlide ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "jQuery", "adapter", "and", "client", "shell", "to", "offer", "more", "flexibility", ".", "Also", "updated", "README", "to", "reflect", "API", "changes", "."], "add_tokens": "storedContext = { } , storedContext = result . context ; self . execute = function ( cmdStr ) { var context = { } ; switch ( arguments . length ) { case 2 : resultCallback = arguments [ 1 ] ; context = storedContext ; break ; case 3 : context = arguments [ 1 ] ; resultCallback = arguments [ 2 ] ; break ; } socket . emit ( 'execute' , cmdStr , storedContext ) ;", "del_tokens": "context = { } , context = result . context ; self . execute = function ( cmdStr , callback ) { resultCallback = callback ; socket . emit ( 'execute' , cmdStr , context ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "behaviour", "of", "date", "predicate", "."], "add_tokens": "* Returns ` ` something is a valid date , return Object . prototype . toString . call ( data ) === '[object Date]' && ! isNaN ( data . getTime ( ) ) ;", "del_tokens": "* Returns ` ` something is a date , return Object . prototype . toString . call ( data ) === '[object Date]' ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "validation", "to", "test", "priority", "option", "and", "updated", "README", "and", "test", "fixture", "."], "add_tokens": "param : 'number' , info : 'change test priority (0-9) [enforced by API key, otherwise 5]' , valid : / ^\\d$ /", "del_tokens": "param : 'string' , info : 'change test priority'", "commit_type": "add"}
{"commit_tokens": ["Made", "_", ".", "walk", "available", "as", "a", "function", "in", "case", "others", "would", "like", "to", "use", "it", "as", "a", "building", "block", "."], "add_tokens": "_ . walk = walk ; _ . extend ( walk , { } ) ;", "del_tokens": "_ . walk = { } ;", "commit_type": "make"}
{"commit_tokens": ["add", "incomplete", "vfs", ".", "js", "component"], "add_tokens": "'/lib/runtime/0.1.0/platform.js' , '/system/vfs.js' ,", "del_tokens": "'/lib/platform.js' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "auto", "-", "load", "with", "resize"], "add_tokens": "[ \"nav$n1\" , \"Commits\" , [ \"ul$2\" ] ] , [ \"nav$n2\" , \"Files\" , [ \"ul$3\" ] ] , window . addEventListener ( \"resize\" , function ( ) { var evt = new window . Event ( 'scroll' ) ; $ . n1 . dispatchEvent ( evt ) ; $ . n2 . dispatchEvent ( evt ) ; } , false ) ;", "del_tokens": "[ \"nav\" , \"Commits\" , [ \"ul$2\" ] ] , [ \"nav\" , \"Files\" , [ \"ul$3\" ] ] ,", "commit_type": "fix"}
{"commit_tokens": ["Update", "ws", "-", "fallback", ".", "js"], "add_tokens": "module . exports = WebSocket || MozWebSocket || window . WebSocket || window . MozWebSocket", "del_tokens": "module . exports = window . WebSocket || window . MozWebSocket", "commit_type": "update"}
{"commit_tokens": ["Removed", "use", "of", "reserved", "words", "."], "add_tokens": "'byte' : function ( s , i , j ) { 'char' : function ( ) { var intValue = Math . floor ( x ) , mantissa = x - intValue ; return [ intValue , mantissa ] ;", "del_tokens": "byte : function ( s , i , j ) { char : function ( ) { var int = Math . floor ( x ) , mantissa = x - int ; return [ int , mantissa ] ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "README", ".", "md", "and", "clarified", "comments", "."], "add_tokens": "* @ param { String } mapId - mapId of the top - level object in the resultSet * @ param { String } [ columnPrefix ] - prefix that should be applied to the column names of the top - level object * @ param { boolean } [ isRequired ] - is it required to have a mapped object as a return value ? Default is true .", "del_tokens": "* @ param { String } mapId - mapId of the top - level objects in the resultSet * @ param { String } [ columnPrefix ] - prefix that should be applied to the column names of the top - level objects * @ param { boolean } [ isRequired ] - is a mapped object required to be returned , default is true", "commit_type": "update"}
{"commit_tokens": ["Fix", "to", "avoid", "creating", "a", "phantom", "object", "landroid", "-", "s", ".", "0undefined", "and", "some", "small", "changes", "."], "add_tokens": "\"e-mail\" : { \"en\" : \"email\" , \"de\" : \"E-Mail\" , \"ru\" : \" \"}, \"de\" : \"Beim Speichern von Einstellungen wird der Adapter sofort neu gestartet.\" ,", "del_tokens": "\"e-mail\" : { \"en\" : \"email\" , \"de\" : \"E-mail\" , \"ru\" : \" \"}, \"de\" : \"Beim Speichern von Einstellungen der Adapter wird sofort neu gestartet.\" ,", "commit_type": "fix"}
{"commit_tokens": ["Move", "files", "around", "to", "better", "conform", "to", "CommonJS", "updates", "to", "package", ".", "json"], "add_tokens": "var XMLHttpRequest = require ( \"xmlhttprequest\" ) . XMLHttpRequest ;", "del_tokens": "var XMLHttpRequest = require ( \"./XMLHttpRequest\" ) . XMLHttpRequest ;", "commit_type": "move"}
{"commit_tokens": ["Uses", "document", ".", "querySelector", "directly", "rather", "than", "wrapping", "it", "."], "add_tokens": "var querySelector = document . querySelector . bind ( document ) ;", "del_tokens": "var querySelector = function ( selector ) { return document . querySelector ( selector ) ; } ;", "commit_type": "use"}
{"commit_tokens": ["allow", "for", "lower", "case", "headings"], "add_tokens": "var heading = fn ( elem . children , options ) ; if ( options . uppercaseHeadings ) { heading = heading . toUpperCase ( ) ; } return heading + '\\n' ;", "del_tokens": "return fn ( elem . children , options ) . toUpperCase ( ) + '\\n' ;", "commit_type": "allow"}
{"commit_tokens": ["Removed", "width", "and", "height", "parameters", "from", "snapZoom", "function"], "add_tokens": "snapZoom ( options ) this . plugins [ 'snap-zoom' ] = new SnapZoom ( this , options )", "del_tokens": "snapZoom ( width , height , options ) this . plugins [ 'snap-zoom' ] = new SnapZoom ( this , width , height , options )", "commit_type": "remove"}
{"commit_tokens": ["Remove", "deleted", "ORDER", "constant", "from", "test", "file", "."], "add_tokens": "import { UPDATE , DELETE , CREATE } from '../constants' ;", "del_tokens": "import { UPDATE , DELETE , CREATE , ORDER } from '../constants' ;", "commit_type": "remove"}
{"commit_tokens": ["moved", "docs", "to", "https", ":", "//", "github", ".", "com", "/", "finom", "/", "matreshka_docs"], "add_tokens": "Matreshka v0 .3 .2 ( 2015 - 03 - 17 )", "del_tokens": "Matreshka v0 .3 .2 ( 2015 - 03 - 16 )", "commit_type": "move"}
{"commit_tokens": ["Fixed", "the", "formattiong", "on", "text", "that", "the", "error", "in", "throwError", "used"], "add_tokens": "export function throwError ( name , message , value , type = 'field' ) { value = value || '[Nothing]' ; ` ${ value } ` +", "del_tokens": "export function throwError ( name , message , value = '[Nothing]' , type = 'field' ) { message = message && message + '\\n' ; ` ${ value } ` +", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "configurable", "time", "since", "process", "start"], "add_tokens": "var TypeUtils = require ( \"./detail/TypeUtils\" ) ; that . setupTime ( that . config . timeSinceStartup ) ; Zurvan . prototype . setupTime = function ( timeSinceStartup ) { var startupTimeInNanoseconds = 0 ; if ( TypeUtils . isNumber ( timeSinceStartup ) ) { startupTimeInNanoseconds = timeSinceStartup * 1e9 ; } else if ( timeSinceStartup !== undefined ) { startupTimeInNanoseconds = timeSinceStartup [ 0 ] * 1e9 + timeSinceStartup [ 1 ] ; } this . currentTime = { milliseconds : Math . floor ( startupTimeInNanoseconds / 1e6 ) , nanoseconds : startupTimeInNanoseconds % 1e6 } ; this . targetTime = { milliseconds : this . currentTime . milliseconds , nanoseconds : this . currentTime . nanoseconds } ; } ;", "del_tokens": "that . currentTime = { milliseconds : 0 , nanoseconds : 0 } ; that . targetTime = { milliseconds : 0 , nanoseconds : 0 } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "wrong", "requires", "in", "flow", "tests"], "add_tokens": "console . log ( order ) ; } ) ; require ( '../../lib/async_testing' ) . run ( __filename , process . ARGV ) ;", "del_tokens": "console . log ( order ) ; } ) ; require ( '../lib/async_testing' ) . run ( __filename , process . ARGV ) ;", "commit_type": "fix"}
{"commit_tokens": ["change", "global", "output", "object", "name", "to", "skylarkjs"], "add_tokens": "if ( relative [ 0 ] !== \".\" ) { return relative ; } var skylarkjs = require ( \"skylark-utils/main\" ) ; exports = skylarkjs ; globals . skylarkjs = skylarkjs ;", "del_tokens": "// Set up Backbone appropriately for the environment. Start with AMD. var skylark = require ( \"skylark-utils\" ) ; exports = skylark ; globals . skylark = skylark ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "tests", "for", "scroll", "-", "item", "and", "cover", "the", "file"], "add_tokens": "describe ( 'RectCache mixin' , function ( ) {", "del_tokens": "describe ( 'RectCache' , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["adds", "client", "-", "side", "cors", "handling"], "add_tokens": "filePath = \"https://data.cityofnewyork.us/api/views/3h6b-pt5u/rows.csv\" / > ,", "del_tokens": "filePath = \"http://spatialkeydocs.s3.amazonaws.com/FL_insurance_sample.csv\" / > ,", "commit_type": "add"}
{"commit_tokens": ["Update", "resize", "-", "test", "-", "element", ".", "html", "to", "new", "Polymer", "syntax", ".", "All", "but", "2", "tests", "completing", "now", "."], "add_tokens": "test ( 'ignore changes in element\\'s own attributes' , function ( done ) {", "del_tokens": "test ( \"ignore changes in element's own attributes\" , function ( done ) {", "commit_type": "update"}
{"commit_tokens": ["Removed", "hasSubTypes", "and", "replaced", "with", "simplerer", "logic", "in", "Ecore", ".", "XMI", "."], "add_tokens": "var aType = node . attributes [ 'xsi:type' ] ; if ( aType ) { eClass = resourceSet . getEObject ( getClassURIFromPrefix ( aType ) ) ; if ( ! isResource ) {", "del_tokens": "hasSubTypes : function ( ) { return this . get ( 'abstract' ) || this . get ( 'eAllSubTypes' ) ; } , var EClass_hasSubTypes = new EObject ( ) ; EClass_hasSubTypes . values = { name : 'hasSubTypes' , lowerBound : 0 , upperBound : - 1 , derived : true , containment : false , _ : EClass . values . hasSubTypes } ; . add ( EClass_hasSubTypes ) // hasSubTypes EClass_hasSubTypes . eClass = EReference ; EClass_hasSubTypes . values . eType = EClass ; if ( eType . get ( 'hasSubTypes' ) ) { var aType = node . attributes [ 'xsi:type' ] ; if ( aType ) { eClass = resourceSet . getEObject ( getClassURIFromPrefix ( aType ) ) ; } else { eClass = eType ; } if ( ! isResource && root . eContainingFeature . get ( 'eType' ) . get ( 'hasSubTypes' ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Use", "window", ".", "getComputedStyle", "()", "to", "set", "color", "and", "background", "color", "of", "input", "wrapper", "."], "add_tokens": "var wrapper = document . createElement ( 'i' ) ; wrapper . className = el . className + ' waves-input-wrapper' ; el . className = 'waves-button-input' ; // Apply element color and background color to wrapper var elementStyle = window . getComputedStyle ( el , null ) ; var color = elementStyle . color ; var backgroundColor = elementStyle . backgroundColor ; wrapper . setAttribute ( 'style' , 'color:' + color + ';background:' + backgroundColor ) ; el . setAttribute ( 'style' , 'background-color:rgba(0,0,0,0);' ) ;", "del_tokens": "var wrapper = document . createElement ( 'i' ) ; wrapper . className = el . className + ' waves-input-wrapper' ; var elementStyle = el . getAttribute ( 'style' ) ; if ( ! elementStyle ) { elementStyle = '' ; } wrapper . setAttribute ( 'style' , elementStyle ) ; el . className = 'waves-button-input' ; el . removeAttribute ( 'style' ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "w", "/", "virtual", "base", "module", "&", "finish", "tests"], "add_tokens": "this . maybeAddVirtualBaseModule ( projectOptions ) ; / ** * If needed , adds a virtual base module that all root modules depend on . * @ param { ! Object } projectOptions * / ModuleManager . prototype . maybeAddVirtualBaseModule = function ( projectOptions ) { projectOptions . jsModules [ VIRTUAL_BASE_MODULE ] = { alwaysLoadedAfterModules : [ ] , dontCompileInputFiles : [ ] , nonClosureNamespacedInputFiles : [ ] , closureRootNamespaces : [ ] } ;", "del_tokens": "this . maybeAddVirtualBaseModule ( ) ; /** If needed, adds a virtual base module that all root modules depend on. */ ModuleManager . prototype . maybeAddVirtualBaseModule = function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "reduce", "and", "reduceRight", "to", "flows", "module", "+", "added", "thisObj", "arg", "to", "existing", "methods"], "add_tokens": "/*** Generated by streamline --lines-mark 0.1.9 - DO NOT EDIT ***/ function __cb ( _ , fn ) { var ctx = __global . __context ; return function ( err , result ) { __global . __context = ctx ; if ( err ) return _ ( err ) ; return fn ( null , result ) ; } } function __trap ( err ) { if ( err ) { if ( __global . __context && __global . __context . errorHandler ) __global . __context . errorHandler ( err ) ; else console . error ( \"UNCAUGHT EXCEPTION: \" + err . message + \"\\n\" + err . stack ) ; } }", "del_tokens": "/*** Generated by streamline --lines-mark 0.1.8 - DO NOT EDIT ***/ function __cb ( _ , fn ) { var ctx = __global . __context ; return function ( err , result ) { __global . __context = ctx ; if ( err ) return _ ( err ) ; return fn ( null , result ) ; } } function __trap ( err ) { if ( err ) { if ( __global . __context && __global . __context . errorHandler ) __global . __context . errorHandler ( err ) ; else console . error ( \"UNCAUGHT EXCEPTION: \" + err . message + \"\\n\" + err . stack ) ; } }", "commit_type": "add"}
{"commit_tokens": ["Added", "responseSchema", "class", "name", "support"], "add_tokens": "// If the responseSchema is a joi object, response className can be set as an option: // Example: route.responseSchema = Joi.object({foo:Joi.string()}).options({className:\"MyResponseClass\"}); var responseClassName = route . responseSchema && route . responseSchema . _settings ? route . responseSchema . _settings . className || route . responseSchema . _settings . typeName : undefined ; var responseProperty = internals . validatorToProperty ( responseClassName || op . nickname + '_response' , route . responseSchema , swagger . models ) ;", "del_tokens": "var responseProperty = internals . validatorToProperty ( op . nickname + '_response' , route . responseSchema , swagger . models ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "options", "to", "not", "include", "<title", ">", "and", "<desc", ">", "."], "add_tokens": "} , noTitleElement : { options : { includeTitleElement : false } , files : { 'tmp/no_title_element.svg' : [ 'test/fixtures/codepen.svg' ] } } , noDescElement : { options : { preserveDescElement : false } , files : { 'tmp/no_desc_element.svg' : [ 'test/fixtures/codepen.svg' ] }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "to", "upload", "a", "release", "asset"], "add_tokens": "} ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Fix", "Gandalf", "s", "review", "comments", "."], "add_tokens": "if ( ! origChild ) { continue ; } var id = element . getAttribute ( 'id' ) ; if ( id ) { return '*[@id=\"' + id + '\"]' ;", "del_tokens": "if ( element . id !== '' ) { return '*[@id=\"' + element . id + '\"]' ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", ".", "keys", "to", "match", "on", "iterable", "collections", "as", "well", "(", "such", "as", "List", ")"], "add_tokens": "if ( Immutable . Iterable . isIterable ( obj ) ) {", "del_tokens": "if ( Immutable . Iterable . isKeyed ( obj ) ) {", "commit_type": "allow"}
{"commit_tokens": ["moving", "auth", "and", "the", "private", "weakmap", "to", "it", "s", "own", "module"], "add_tokens": "const privates = require ( './private-map' ) ; const authenticate = require ( './auth' ) ;", "del_tokens": "const privates = new WeakMap ( ) ; function authenticate ( client , settings ) { return new Promise ( ( resolve , reject ) => { let req = { url : client . baseUrl + '/realms/master/protocol/openid-connect/token' , form : settings } , jsonParsedBody ; request . post ( req , ( err , resp , body ) => { if ( err ) { return reject ( err ) ; } jsonParsedBody = JSON . parse ( body ) ; privates . get ( client ) . accessToken = jsonParsedBody . access_token ; return resolve ( client ) ; } ) ; } ) ; }", "commit_type": "move"}
{"commit_tokens": ["Fix", "sendDelete", "call", "to", "provide", "empty", "data", "so", "header", "is", "correct"], "add_tokens": "return this . sendDelete ( httpEndPoint + '/projection/' + name + '?deleteStateStream=' + stateStream + '&deleteCheckpointStream' + checkpointStream + '&deleteEmittedStreams=' + deleteEmittedStreams , '' , userCredentials , HTTP_OK ) ;", "del_tokens": "return this . sendDelete ( httpEndPoint + '/projection/' + name + '?deleteStateStream=' + stateStream + '&deleteCheckpointStream' + checkpointStream + '&deleteEmittedStreams=' + deleteEmittedStreams , userCredentials , HTTP_OK ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "extended", "replacements", "using", "dynamic", "data", "."], "add_tokens": "} else if ( typeof userConfig === 'object' ) { var utilExtensions = / %f|%e / g ; var uniqueExtensions = { } ; var result ; var isNull ; if ( typeof item . src !== 'undefined' ) { isNull = item . src === null ; while ( result = utilExtensions . exec ( tpl ) ) { var type = result [ 0 ] ; var unique = { } ; if ( uniqueExtensions [ type ] ) continue ; unique . regex = new RegExp ( result [ 0 ] , \"g\" ) ; unique . value = null ; uniqueExtensions [ type ] = unique ; } tpl : tpl , uni : uniqueExtensions , isNull : isNull", "del_tokens": "} if ( typeof userConfig === 'object' ) { if ( item . src ) { tpl : tpl", "commit_type": "add"}
{"commit_tokens": ["Updated", "docs", "and", "index", ".", "html"], "add_tokens": "// ## [Github Repo](https://github.com/Raynos/contract)", "del_tokens": "// # [Github Repo](https://github.com/Raynos/contract)", "commit_type": "update"}
{"commit_tokens": ["fixed", "a", "couple", "lint", "warnings"], "add_tokens": "} ; var host ; host = url . hostname ; host = \"localhost\" ; var syncProc = spawn ( process . argv [ 0 ] , [ \"-e\" , execString ] ) ;", "del_tokens": "var client ; return ; } var host = url . hostname ; var host = \"localhost\" ; syncProc = spawn ( process . argv [ 0 ] , [ \"-e\" , execString ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "living", "characters", "and", "perspective", "-", "based", "text", "."], "add_tokens": "guid : '' , this . guid = String . uniqueID ( ) ; if ( target && player . guid == target . guid ) { } else if ( player . guid == my . guid ) { } else if ( player . guid != my . guid ) { player . send ( messages [ 2 ] , style ) ;", "del_tokens": "if ( target && player . name == target . name ) { } else if ( player . name != me ) { player . send ( messages [ 2 ] , style ) ; } else if ( player . name == me ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "module", "s", "version"], "add_tokens": "exports . version = '0.1.0' ;", "del_tokens": "exports . version = '0.0.23' ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "lint", "violations", "in", "tests"], "add_tokens": "code2 . display = 'Another name for the code.' ; code2 . code = '6789' ; } ) ; . withBasedOn ( base . identifier )", "del_tokens": "code2 . display = 'Another name for the code.' code2 . code = '6789' } )", "commit_type": "fix"}
{"commit_tokens": ["use", "Template", "in", "place", "of", "Program"], "add_tokens": "peg$startRuleFunctions = { Template : peg$parseTemplate } , peg$startRuleFunction = peg$parseTemplate , type : 'Template' , function peg$parseTemplate ( ) {", "del_tokens": "peg$startRuleFunctions = { Program : peg$parseProgram } , peg$startRuleFunction = peg$parseProgram , type : 'Program' , function peg$parseProgram ( ) {", "commit_type": "use"}
{"commit_tokens": ["Improve", "media", "queries", "and", "mobile", "-", "first", "support", "for", "grid", "."], "add_tokens": "tasks : [ 'stylus:server' ] options : { compress : false } , server : { } , dist : { options : { compress : true , } , files : { 'gridlayout.min.css' : 'src/gridlayout.styl' } 'stylus:server' ,", "del_tokens": "tasks : [ 'stylus' ] all : { 'stylus' ,", "commit_type": "improve"}
{"commit_tokens": ["allow", "populate", "to", "store", "population", "in", "a", "differently", "named", "variable"], "add_tokens": "Name . prototype . populate = function ( obj , value ) { var n = this . name ; l = n . length ; / * * TODO : make this a configurable Tyranid option as to how populated entries should be named * * 1. organizationId - > organization * 2. organization - > organization$ * 3. organization - > organization * * TODO : should we mark populated values as enumerable : false ? * / if ( n . substring ( l - 2 ) === 'Id' ) { n = n . substring ( 0 , l - 2 ) ; } else { n += '$' ; } obj [ n ] = value ; } ; name . populate ( doc , linkDoc ) ;", "del_tokens": "name . set ( doc , linkDoc ) ;", "commit_type": "allow"}
{"commit_tokens": ["use", "findOrCreate", "with", "Permission", "fixture"], "add_tokens": "{ } , { } , { } return Promise . all ( _ . map ( permissions , function ( permission ) { return Permission . findOrCreate ( permission , permission ) ; } ) ) ;", "del_tokens": "Permission . create ( { } ) , Permission . create ( { } ) , Permission . create ( { } ) , return Promise . all ( permissions ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "the", "way", "row", "slices", "and", "put", "better", "docs"], "add_tokens": "* @ param { Number } start Required . An integer that specifies where to start the selection ( The first columns has an index of 0 ) . You can also use negative numbers to select from the end of the row * @ param { Number } end Optional . An integer that specifies where to end the selection . If omitted , slice ( ) selects all elements from the start position and to the end of the row", "del_tokens": "* @ param { Number } start The starting index for the columns slice * @ param { Number } end The ending index for the columns slice end = end || this . length - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "filtering", "in", "collection", "data", "bindings"], "add_tokens": "this . trigger ( 'change:' + changedAttr , { model : this , changedAttributes : changed } ) ; this . trigger ( 'change' , { model : this , changedAttributes : changed } ) ;", "del_tokens": "this . trigger ( 'change:' + changedAttr , { changedAttributes : changed } ) ; this . trigger ( 'change' , { changedAttributes : changed } ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "key", "button", "on", "root", "view"], "add_tokens": "setupAddKeyButton ( ) ; setupAddKeyButton ( ) ; } function setupAddKeyButton ( ) {", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "autocontext", "and", "usage", "thereof", ".", "Other", "stuff", "."], "add_tokens": "if ( build . autocontext ) { // Add some stuff to the global context. if ( build . buildvar ) context [ build . buildvar ] = build ; context [ 't' ] = build . translate ; context [ 'tn' ] = build . translateNumeric ; }", "del_tokens": "// TODO: Route views and errors after finding out what files exist with glob. if ( build . buildvar ) context [ build . buildvar ] = build ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "internal", "properties", "init"], "add_tokens": "prop ( this , '__requiredAssets__' , [ ] , { writable : true } ) ; prop ( this , '__dependencyPaths__' , [ ] , { writable : true } ) ; return this . __dependencyPaths__ . slice ( ) ; return this . __requiredAssets__ . slice ( ) ;", "del_tokens": "if ( ! this . __dependencyPaths__ ) { prop ( this , '__dependencyPaths__' , [ ] , { writable : true } ) ; } return this . __dependencyPaths__ ; if ( ! this . __requiredAssets__ ) { prop ( this , '__requiredAssets__' , [ ] , { writable : true } ) ; } return this . __requiredAssets__ ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "users", "to", "pass", "object", "literals", "as", "argument", "to", "addRow", "so", "it", "works", "like", "collection", ".", "add"], "add_tokens": "models = this . collection . add ( models ) ;", "del_tokens": "this . collection . add ( models ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "bug", "with", "import", "of", "options"], "add_tokens": "this . _opts = Object . assign ( { populateGlobalWithMain : true , } , this . _pkg . repl , this . _constructorOpts ) ; let ignoreFiles = { __tests__ : true , } ; if ( basename . endsWith ( '.test.js' ) ) { return true ; }", "del_tokens": "this . _opts = Object . assign ( { populateGlobalWithMain : true , } , this . _pkg , this . _constructorOpts ) ; let ignoreFiles = { } ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "README", ";", "Fixed", "resemble", "tests", ";", "Set", "default", "timeout", "to", "10s"], "add_tokens": "timeout : 10000 grunt . registerTask ( 'travis' , [ 'jshint' , 'mochacov:unit' , 'mochacov:coveralls' ] ) ;", "del_tokens": "timeout : 5000 grunt . registerTask ( 'travis' , [ 'jshint' , 'mochacov:coveralls' ] ) ;", "commit_type": "update"}
{"commit_tokens": ["Updated", "with", "small", "changes", "to", "where", "the", "cache", "is", "located", "and", "an", "inital", "version", "of", "a", "cache", "prep", "script", "."], "add_tokens": "// Support plugin adds in two VS features and two bug fixes: Task Runner Explorer event bindings and res/native var cordovaCache = process . env [ \"CORDOVA_CACHE\" ] || ( process . platform == \"darwin\" ? path . join ( process . env [ \"HOME\" ] , \".cordova-cache\" ) : path . join ( process . env [ \"APPDATA\" ] , \"cordova-cache\" ) ) , process . env [ \"CORDOVA_HOME\" ] = path . join ( cordovaCache , \"_cordova\" ) ; // Set platforms to cache in cache locaiton to avoid unexpected results process . env [ \"PLUGMAN_HOME\" ] = path . join ( cordovaCache , \"_plugman\" ) ; // Set plugin cache in cache locaiton to avoid unexpected results", "del_tokens": "// Support plugin adds in two VS features: Task Runner Explorer event bindings and res/native var cordovaCache = process . env [ \"CORDOVA_CACHE\" ] || path . resolve ( \"_cordova\" ) , process . env [ \"CORDOVA_HOME\" ] = cordovaCache ; // Set platforms to cache in cache locaiton to avoid unexpected results", "commit_type": "update"}
{"commit_tokens": ["Added", "remote", "CLI", "option", "defaults", "to", "origin"], "add_tokens": "var remote = opts . remote || 'origin' ; var remoteBranch = opts . branch ; . then ( pushDirToRemote . bind ( null , remote , remoteBranch ) ) function pushDirToRemote ( remote , remoteBranch ) { 'git push ' + remote + ' HEAD:' + remoteBranch + ' --force' ,", "del_tokens": "var remote = opts . branch ; . then ( pushDirToRemote . bind ( null , remote ) ) function pushDirToRemote ( remote ) { 'git push origin HEAD:' + remote + ' --force' ,", "commit_type": "add"}
{"commit_tokens": ["Move", "node", "drawing", "before", "layout"], "add_tokens": "var e2 = g . addEdge ( rootEdge . attrs . edgeId , root , e . head ( ) , e . attrs ) ;", "del_tokens": "var e2 = g . addEdge ( rootEdge . id ( ) , root , e . head ( ) , e . attrs ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "quick", "hack", "of", "a", "client", "-", "side", "version"], "add_tokens": "* Copyright ( c ) 2012 TJ Holowaychuk < tj @ vision - media . ca >", "del_tokens": "* Copyright ( c ) 2011 TJ Holowaychuk < tj @ vision - media . ca >", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "shutting", "down", "the", "server", "/", "cluster", "programmatically"], "add_tokens": "var server = app . listen ( this . port ) ; return server ;", "del_tokens": "app . listen ( this . port ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "title", "references", "in", "currentStep", "attribute", "to", "account", "for", "wz", "-", "step", "addition"], "add_tokens": "var stepTitle = $scope . selectedStep . title || $scope . selectedStep . wzTitle ; if ( $scope . selectedStep && stepTitle !== $scope . currentStep ) { $scope . currentStep = step . title || step . wzTitle ;", "del_tokens": "if ( $scope . selectedStep && $scope . selectedStep . title !== $scope . currentStep ) { $scope . currentStep = step . title ;", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "comments", "to", "helpers", "file"], "add_tokens": "// YAML Front Matter exports . FrontMatter = require ( './frontMatter' ) . FrontMatter ; // Markdown exports . Markdown = require ( './markdown' ) . Markdown ; // Template Engines // Extensions Map", "del_tokens": "exports . FrontMatter = require ( './frontMatter' ) . FrontMatter ; exports . Markdown = require ( './markdown' ) . Markdown ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "tag", "line", "and", "bumping", "version"], "add_tokens": "grunt . registerMultiTask ( 'i18n_linter' , 'Grunt plugin to highlight unused or missing translations' , function ( ) {", "del_tokens": "grunt . registerMultiTask ( 'i18n_linter' , 'Grunt plugin to loop through templates to validate the use of translations' , function ( ) {", "commit_type": "update"}
{"commit_tokens": ["added", "spport", "for", "naver", "map"], "add_tokens": "import { askAppChoice , checkOptions , checkNaverMapOptions } from './utils' ; * naverCallerName : string | undefined case 'navermap' : checkNaverMapOptions ( options ) url = ` ${ prefixes . navermap } ${ lat } ${ lng } ${ options . naverCallerName } ` ; if ( useSourceDestiny ) { url = ` ${ prefixes . navermap } ${ sourceLat } ${ sourceLng } ${ lat } ${ lng } ${ options . naverCallerName } ` ; }", "del_tokens": "import { askAppChoice , checkOptions } from './utils' ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "updating", "/", "inserting", "a", "null", "value", "."], "add_tokens": "if ( typeof value !== 'undefined' ) { if ( value && typeof value === 'object' && typeof value . raw === 'string' ) {", "del_tokens": "if ( isDefined ( value ) ) { if ( typeof value === 'object' && typeof value . raw === 'string' ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "proxy", "in", "more", "places", "in", "IE9", "."], "add_tokens": "// IE versions prior to 10 don't support CORS, so always use the proxy. this . _alwaysUseProxy = ( FeatureDetection . isInternetExplorer ( ) && FeatureDetection . internetExplorerVersion ( ) [ 0 ] < 10 ) ; if ( layer . proxy || this . _alwaysUseProxy ) { var proxy ; if ( layer . proxy || this . _alwaysUseProxy ) { // if (layer.proxy || this._alwaysUseProxy) { // proxy = new Cesium.DefaultProxy('/proxy/'); // server = proxy.getURL(server); // if (layerName !== 'REST') { // server += '%3f'; // } // } if ( description . proxy || this . _alwaysUseProxy ) {", "del_tokens": "// IE versions prior to 10 don't support CORS, so always use the proxy. if ( layer . proxy || ( FeatureDetection . isInternetExplorer ( ) && FeatureDetection . internetExplorerVersion ( ) [ 0 ] < 10 ) ) { var proxy ; if ( layer . proxy ) { // if (layer.proxy) { // proxy = new Cesium.DefaultProxy('/proxy/'); // server = proxy.getURL(server); // if (layerName !== 'REST') { // server += '%3f'; // } // } if ( description . proxy ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "option", "to", "configure", "cookie", "settings", "."], "add_tokens": "res . cookie ( 'remember_me' , token , { path : '/' , httpOnly : true , maxAge : 604800000 } ) ;", "del_tokens": "res . cookie ( 'remember_me' , token , { maxAge : 900000 , httpOnly : true } ) ;", "commit_type": "add"}
{"commit_tokens": ["added", ";", ".", "end", "()"], "add_tokens": "this . ended = false ; if ( retPromise . ended ) throw err ; / ** * Signifies that this promise was the last in a chain of ` ` : if a handler passed to the call to ` ` which produced this promise throws , the exception will go uncaught . * * #### Example : * * var p = new Promise ; * p . then ( function ( ) { throw new Error ( 'shucks' ) } ) ; * setTimeout ( function ( ) { * p . fulfill ( ) ; * // error was caught and swallowed by the promise returned from * // p.then(). we either have to always register handlers on * // the returned promises or we can do the following... * } , 10 ) ; * * // this time we use .end() which prevents catching thrown errors * var p = new Promise ; * var p2 = p . then ( function ( ) { throw new Error ( 'shucks' ) } ) . end ( ) ; // <-- * setTimeout ( function ( ) { * p . fulfill ( ) ; // throws \"shucks\" * } , 10 ) ; * / Promise . prototype . end = function ( ) { this . ended = true ; }", "del_tokens": "// TODO maybe refactor out this wrapped fn?", "commit_type": "add"}
{"commit_tokens": ["Improve", "spec", "descriptions", "for", "request", "options"], "add_tokens": "it ( 'POSTs to url.parse in request options' , ( ) => { it ( 'POSTs to URL path in request options with default host' , ( ) => { it ( 'POSTs to http://online.swagger.io in request options' , ( ) => { it ( 'returns Error for unsupported protocol in request options' , ( ) => {", "del_tokens": "it ( 'POSTs to URL from caller options' , ( ) => { it ( 'POSTs to URL path from caller options with default host' , ( ) => { it ( 'POSTs to http://online.swagger.io from caller options' , ( ) => { it ( 'returns Error for unsupported protocol' , ( ) => {", "commit_type": "improve"}
{"commit_tokens": ["add", "better", "defaults", "to", "blockchain", "config"], "add_tokens": "bootNodes : config . bootnodes || [ ] , geth_extra_opts : config . geth_extra_opts || [ ] ,", "del_tokens": "bootNodes : config . bootnodes , geth_extra_opts : config . geth_extra_opts ,", "commit_type": "add"}
{"commit_tokens": ["add", "setBehindPage", "and", "setAbovePage", "to", "monaca", "-", "sliding", "-", "menu", ".", "js"], "add_tokens": "scope . monaca . setAbovePage = function ( page ) { if ( page ) { scope . pages . above = page ; } else { throw new Error ( 'cannot set undefined page' ) ; } } scope . monaca . setBehindPage = function ( page ) { if ( page ) { scope . pages . behind = page ; } else { throw new Error ( 'cannot set undefined page' ) ; } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["improve", "Class", "add", "concurrent", "/", "forOn"], "add_tokens": "( noop ? describe : xdescribe ) ( '\"noop\" should' , ( ) => {", "del_tokens": "xdescribe ( '\"noop\" should' , ( ) => {", "commit_type": "improve"}
{"commit_tokens": ["removing", "undefined", "as", "classname", "and", "giving", "checkbox", "an", "inline", "label"], "add_tokens": "meta , noOuterLabel className = { ` ${ getIntentClass ( this . props ) || \"\" } ${ className || \"\" } ` } ! noOuterLabel && ( hideDropAfterUpload && value . length ? \" tg-hide-drop-target\" : \"\" ) function generateField ( component , opts ) { const compWithDefaultVal = withAbstractWrapper ( component , opts ) ; export const withAbstractWrapper = ( ComponentToWrap , opts = { } ) => { < AbstractInput { ... { ... opts , ... props } } > export const CheckboxField = generateField ( renderBlueprintCheckbox , { noOuterLabel : true } ) ;", "del_tokens": "meta className = { ` ${ getIntentClass ( this . props ) } ${ className } ` } ( hideDropAfterUpload && value . length && \" tg-hide-drop-target\" ) function generateField ( component ) { const compWithDefaultVal = withAbstractWrapper ( component ) ; export const withAbstractWrapper = ComponentToWrap => { < AbstractInput { ... props } > export const CheckboxField = generateField ( renderBlueprintCheckbox ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "method", "to", "get", "tonic"], "add_tokens": "var plusIntervalInKey = require ( './plus-interval-in-key.js' ) var Pitch = require ( 'nmusic' ) . Pitch * @ param { string } [ key = 'C major' ] - the key in which to apply the generic interval . Must * be a valid pitch string and mode name seperated by whitespace such as 'Bb major' . key = key || 'C major' var tonic = Pitch ( key . split ( / \\s+ / ) [ 0 ] ) . pitchClass ( ) / ** * the tonic note of this key * @ returns { string } a pitch class string * / this . tonic = function ( ) { return tonic } // special case if construcion is empty -- return only pitch classes if ( ! construction ) { return initialScaleDegrees . map ( plusIntervalInKey ( key , ) ) } return grammarGraph . choices ( ) . map ( )", "del_tokens": "* @ param { Key } key - the key of this guide return grammarGraph . choices ( )", "commit_type": "add"}
{"commit_tokens": ["Use", "os", ".", "homedir", "to", "get", "home", "dir", "in", "tests"], "add_tokens": "var os = require ( 'os' ) ; var global_config_path = process . env . CORDOVA_HOME || path . join ( os . homedir ( ) , '.cordova' ) ;", "del_tokens": "var global_config_path = process . env . CORDOVA_HOME ; if ( ! global_config_path ) { var HOME = process . env [ ( process . platform . slice ( 0 , 3 ) === 'win' ) ? 'USERPROFILE' : 'HOME' ] ; global_config_path = path . join ( HOME , '.cordova' ) ; }", "commit_type": "use"}
{"commit_tokens": ["Fix", "calculation", "of", "default", "view", "width", "on", "launch"], "add_tokens": "/ ** * @ export * * @ return { number } Gives the device width . * / static get WIDTH ( ) { if ( ! View . width_ ) { var bodyStyle = window . getComputedStyle ( document . body , null ) ; var width = parseInt ( bodyStyle && bodyStyle . width || 0 , 10 ) ; View . width_ = width ; return View . width_ ; } else { return View . width_ ; } }", "del_tokens": "var bodyStyle = window . getComputedStyle ( document . body , null ) ; / ** * @ export * * @ type { number } Gives the device width . * / View . WIDTH = parseInt ( bodyStyle && bodyStyle . width || 0 , 10 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "number", "and", "string", "vars", "in", "debugger"], "add_tokens": "type_icon = '<span class=\"fa-stack fa-1x\" style=\"width: 1em;height: 1em;line-height: 1em;\"><i class=\"fa fa-square fa-stack-2x\" style=\"font-size: 1.2em;\"></i><strong class=\"fa-stack-1x text-primary\" style=\"color: white;font-size: 70%;\">ab</strong></span>' ; type_icon = '<span class=\"fa-stack fa-1x\" style=\"width: 1em;height: 1em;line-height: 1em;\"><i class=\"fa fa-square fa-stack-2x\" style=\"font-size: 1.2em;\"></i><strong class=\"fa-stack-1x text-primary\" style=\"color: white;font-size: 60%;\">01</strong></span>' ;", "del_tokens": "type_icon = '<i class=\"fa fa-font\" aria-hidden=\"true\"></i>' ; type_icon = '<i class=\"fa fa-superscript\" aria-hidden=\"true\"></i>' ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "assignment", "of", "the", "name", "into", "the", "node", "function"], "add_tokens": "name : related || '' ,", "del_tokens": "opts . name = related || '' ; name : opts . name || '' ,", "commit_type": "move"}
{"commit_tokens": ["add", "support", "for", "main", "config", "file"], "add_tokens": "result += className + \"Abi = \" + abi + \";\" ; result += className + \"Contract = web3.eth.contract(\" + className + \"Abi);\" ; result += className + \" = \" + className + \"Contract.at('\" + contractAddress + \"');\" ;", "del_tokens": "result += \"var \" + className + \"Abi = \" + abi + \";\" ; result += \"var \" + className + \"Contract = web3.eth.contract(\" + className + \"Abi);\" ; result += \"var \" + className + \" = \" + className + \"Contract.at('\" + contractAddress + \"');\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "$", ".", "each", "()", "to", "use", "jQuery", "arguments", "ordering"], "add_tokens": "$ . each ( SITES , function ( sideId , site ) {", "del_tokens": "$ . each ( SITES , function ( site , sideId ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "req", ".", "user", "support", "and", "session", "handling"], "add_tokens": "var db = require ( 'riak-js' ) . getClient ( ) ; app . use ( express . cookieParser ( ) ) ; app . use ( function ( req , res , next ) { req . user = null ; if ( ! req . cookies . token ) { return next ( ) ; } db . get ( 'tokens' , req . cookies . token , function ( err , user ) { if ( ! err && user ) { req . user = user ; next ( ) ; } else if ( err && err . statusCode === 404 ) { next ( ) ; } else { next ( err ) ; } } ) ; } ) app . use ( function ( err , req , res , next ) { } else if ( err . syscall ) { res . json ( 500 , { error : 'An unexcepted error occured' } ) ;", "del_tokens": "app . use ( function ( err , req , res , next ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "jam", "remove", "command", "for", "repositories", "list"], "add_tokens": "exports . reportUnused ( settings , cfg , opt , function ( err , packages ) { exports . reportUnused = function ( settings , cfg , opt , callback ) { install . repoSource ( settings . repositories , cfg )", "del_tokens": "exports . reportUnused ( cfg , opt , function ( err , packages ) { exports . reportUnused = function ( cfg , opt , callback ) { install . repoSource ( opt . repositories , cfg )", "commit_type": "fix"}
{"commit_tokens": ["removed", "sylvster", "&", "simplified", "naive", "bayes"], "add_tokens": "return this . getClassifications ( observation ) [ 0 ] . name ;", "del_tokens": "return this . getClassifications ( $V ( observation ) ) [ 0 ] . name ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "char", "helper", "throw", "an", "error", "if", "not", "given", "a", "string"], "add_tokens": "if ( arguments . length !== 2 || typeof charset !== 'string' ) {", "del_tokens": "if ( arguments . length !== 2 ) {", "commit_type": "make"}
{"commit_tokens": ["improved", "the", "comments", "in", "the", "root", "files"], "add_tokens": "* and execution of different types of queries . * * @ class Scope * Constructs a Scope given a document to act as the context * for all queries . * Returns the Document used by this scope . * Executes a given Query within the context of this scope . * @ param { Query } query The query to execute . * @ return { Promise < any > } The result of the query . * be returned instead . * @ return { Scope } The created Scope .", "del_tokens": "* and execution of different query types . * Constructs a Scope given a document to act as the root . * Returns the inner Document used in this scope . * Executes a given query within the context of this scope . * @ param { Query } query The query to execute . * @ return { Promise < * > } The result of the query . * be returned . * @ return { Scope } The created Scope .", "commit_type": "improve"}
{"commit_tokens": ["fixed", "and", "tested", "npm", "package"], "add_tokens": "args = resolveArguments ( process . argv ) , wru = require ( path . join ( __dirname , 'wru.console.js' ) ) , if ( args . length ) { args . forEach ( function ( fileName ) { require ( path . join ( CWD , fileName ) ) ; } ) ; } else { console . log ( '' ) ; console . log ( 'Usage:' ) ; console . log ( 'wru ~/path/with/test.js ~/more?if/necessary.js' ) ; console . log ( '' ) ; process . exit ( ) ; }", "del_tokens": "wru = require ( path . join ( CWD , 'node' , 'wru.console.js' ) ) , resolveArguments ( process . argv ) . forEach ( function ( fileName ) { require ( path . join ( CWD , fileName ) ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "library", "to", "support", "the", "enhanced", "link", "attribution", "ability", "of", "Google", "Analytics", "."], "add_tokens": "// apiKey : 'UA-XXXXXXX-X', // enhancedLinkAttribution : true // _Last updated: October 25th, 2012_ if ( settings . enhancedLinkAttribution === true ) { var pluginUrl = ( ( 'https:' == document . location . protocol ) ? 'https://ssl.' : 'http://www.' ) + 'google-analytics.com/plugins/ga/inpage_linkid.js' ; _gaq . push ( [ '_require' , 'inpage_linkid' , pluginUrl ] ) ; }", "del_tokens": "// apiKey : 'UA-XXXXXXX-X' // _Last updated: September 27th, 2012_", "commit_type": "update"}
{"commit_tokens": ["Fixing", "a", "side", "-", "menu", "bug", "."], "add_tokens": "menuStock . add ( text , order , contentPath , hidden , umbel ) ;", "del_tokens": "// Omit hidden item. var path = contentPath ; var length = path . length ; if ( length >= 6 && path . substr ( - 6 ) === '/index' ) { // Cut down closing index. var end = length > 6 ? 6 : 5 ; path = path . substr ( 0 , length - end ) ; } // Store menu item. menuStock . add ( text , order , path , hidden , umbel ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "our", "onExit", "handler", "when", "disabling", "gauge"], "add_tokens": "this . _cleanupOnExit = options . cleanupOnExit == null || options . cleanupOnExit this . _removeOnExit = null if ( this . _cleanupOnExit ) { this . _removeOnExit = onExit ( callWith ( this , this . disable ) ) } if ( this . _removeOnExit ) this . _removeOnExit ( )", "del_tokens": "if ( options . cleanupOnExit == null || options . cleanupOnExit ) { onExit ( callWith ( this , this . disable ) ) }", "commit_type": "remove"}
{"commit_tokens": ["Updated", "method", "for", "setting", "docker", "image", "name", "based", "on", "feedback", "from", "PR", "."], "add_tokens": "const image = this . custom ( ) . dockerImage || ` ${ runtime } ` ;", "del_tokens": "let image = ` ${ runtime } ` if ( this . custom ( ) . dockerImage != null ) { image = this . custom ( ) . dockerImage }", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "Keen", "IO"], "add_tokens": "// Configure the Keen object with your Project ID and API Key. // Use Keen IO global properties to include user ID and traits on every event sent to Keen IO. // Each track invocation will add a single event to Keen.", "del_tokens": "// Configure the Keen object with your Project ID and API Key // use Keen IO global properties to include user ID and traits on every event sent to Keen IO // each track invocation will add a single event to Keen", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "keyfile", "data", "buffers"], "add_tokens": "var path = require ( \"path\" ) , fs = require ( \"fs\" ) ; } , loadsFromContentWithKeyfileData : function ( test ) { var keyFileData = fs . readFileSync ( binFilePath ) ; var tds = new TextDatasource ( this . contentFromKeyfile ) ; tds . load ( new Credentials ( { keyfile : keyFileData } ) ) . then ( function ( archive ) { test . ok ( archive instanceof Archive , \"Should return an archive\" ) ; test . strictEqual ( archive . getGroups ( ) [ 0 ] . getTitle ( ) , \"main\" , \"Should contain correct group\" ) ; test . done ( ) ; } ) . catch ( function ( err ) { console . error ( err ) ; } ) ;", "del_tokens": "var path = require ( \"path\" ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "soajs", ".", "controller", "from", "devDependency", "and", "test", "cases", "."], "add_tokens": "uri : 'http://localhost:4099/' + apiName ,", "del_tokens": "uri : 'http://localhost:4000/mytest/' + apiName ,", "commit_type": "remove"}
{"commit_tokens": ["added", "orderedDependencies", "for", "future", "parallel", "processing"], "add_tokens": "if ( ! svgElement ) return ; checkFitToScreen . checked = false ; if ( processed . model ) { processed . measurement = makerjs . measure . modelExtents ( processed . model ) ; if ( ! MakerJsPlayground . viewScale || checkFitToScreen . checked ) { fitOnScreen ( ) ; } else if ( MakerJsPlayground . renderUnits != processed . model . units ) { fitNatural ( ) ; } function processResult ( html , result , orderedDependencies ) {", "del_tokens": "checkFitToScreen . checked = false ; processed . measurement = makerjs . measure . modelExtents ( processed . model ) ; if ( ! MakerJsPlayground . viewScale || checkFitToScreen . checked ) { fitOnScreen ( ) ; } else if ( MakerJsPlayground . renderUnits != processed . model . units ) { fitNatural ( ) ; function processResult ( html , result ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "url", "in", "redis", "-", "probe", "-", "test", ".", "js", "header"], "add_tokens": "* http : //www.apache.org/licenses/LICENSE-2.0", "del_tokens": "* redis : //www.apache.org/licenses/LICENSE-2.0", "commit_type": "fix"}
{"commit_tokens": ["Use", "raw", "data", "instead", "of", "formatted"], "add_tokens": "// console.log('\\033[2J')", "del_tokens": "console . log ( '\\033[2J' )", "commit_type": "use"}
{"commit_tokens": ["use", "posix", "-", "character", "-", "classes", "module"], "add_tokens": "var posix = require ( 'posix-character-classes' ) ; var val = posix [ node . inner ] ;", "del_tokens": "var utils = require ( './utils' ) ; var val = utils . POSIX [ node . inner ] ;", "commit_type": "use"}
{"commit_tokens": ["added", "basic", "auth", "express", "mw"], "add_tokens": "var basic = require ( 'basic-auth' ) ; / ** * Simple basic auth middleware for use with Express 4. x . * * @ example * app . use ( '/api-requiring-auth' , utils . basicAuth ( [ { user : 'username' , pass : 'password' } ] ) ) ; * * @ param { string } username Expected username * @ param { string } password Expected password * @ returns { function } Express 4 middleware requiring the given credentials * / function basicAuth ( users ) { return function ( req , res , next ) { var user = basic ( req ) ; if ( ! user || users . filter ( function ( item ) { return item . user == user && item . pass == pass ; } ) . length == 0 ) { res . set ( 'WWW-Authenticate' , 'Basic realm=Authorization Required' ) ; return res . send ( 401 ) ; } next ( ) ; } ; } ; getTicket : getTicket , basicAuth : basicAuth", "del_tokens": "getTicket : getTicket", "commit_type": "add"}
{"commit_tokens": ["adds", "options", "to", "a", "connection"], "add_tokens": "root . pageData ( connection . options . name , set , promise ) ;", "del_tokens": "root . pageData ( connection . name , set , promise ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "shortMessage", "calibration", "status", "attribute"], "add_tokens": "'message' : 'Device Calibration is Bad' , 'shortMessage' : 'Bad' , 'message' : 'Device Calibration is Good' , 'shortMessage' : 'Good' , calibrationStatus . shortMessage = 'Good' ;", "del_tokens": "'message' : 'Device Calibration is Bad' 'message' : 'Device Calibration is Good'", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "add", "id", "property", "in", "RadioListView", "renderInput"], "add_tokens": "if ( self . addId ) { extend ( attributes , { name : id , id : ( id + '-' + i ) } ) ; } if ( modelVal === this . checkedVal ) { this . $el . addClass ( this . className || ( 'fieldset fieldset-' + this . fieldSetName ) ) ; this . $el . addClass ( this . className || ( 'fieldset fieldset-' + this . fieldSetName ) ) ;", "del_tokens": "if ( this . addId ) { extend ( attributes , { name : id , id : ( id + '-' + i ) } ) ; } if ( modelVal === true || modelVal === this . checkedVal ) { className : 'fieldset' , this . $el . addClass ( 'fieldset-' + this . fieldSetName ) ; className : 'fieldset' , this . $el . addClass ( 'fieldset-' + this . fieldSetName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Ui2", "server", "version", "and", "hash", "checks"], "add_tokens": "const UI2_VER = \"v0.0.9\" ; const SERVER_DOWNLOAD_SHA512 = \"e02f621db00d610791d9b7e29740933ce6874ed3f56eaac51122714d3ccab596190773e30f0d8003b7d3dd57ef8f5cc562e08617202beef39cd479ccf35746dc\" ; const SERVER_TEST_DOWNLOAD_SHA512 = \"8be1f72c292a113f5473428dffeb442b68576de092dacd0277331d692e2f143f0ffe46446e946e20ef07142086ff61e510d9011085c7b77aff2ef2bd5e1f8a67\" ;", "del_tokens": "const UI2_VER = \"v0.0.8\" ; const SERVER_DOWNLOAD_SHA512 = \"187bcd2a62b4ba169aed6bfec32a03f11ca9bd6e254254a6fc8b980f31e50d0c7aba653636f48d7c873de58ba6084d5fa992493d34d939998498386e0ecd6be3\" ; const SERVER_TEST_DOWNLOAD_SHA512 = \"66f27145f33009f6ccc0a85760522a107c4e48f0fd79dcebca75e5eb342b9aaf93226f9c2d2c57a2c82323e1a9e17617af864565bafb24bca8f6bcbfbe34b511\" ;", "commit_type": "update"}
{"commit_tokens": ["fix", "wrong", "regexp", "end", "match", "when", "/", "in", "brackets", "[]"], "add_tokens": "var px = / ^\\$(?:\\[(?:\\d+|\"(?:[^\\\\\"\\u0000-\\u001f]|\\\\([\\\\\"/bfnrt]|u[0-9a-zA-Z]{4}))*\")\\])*$ / ; [ / ^\\$(?:\\[(?:\\d+|\"(?:[^\\\\\"\\u0000-\\u001f]|\\\\([\\\\\"/bfnrt]|u[0-9a-zA-Z]{4}))*\")\\])*$ / ] ; function fn ( ) { / ^\\$(?:\\[(?:\\d+|\"(?:[^\\\\\"\\u0000-\\u001f]|\\\\([\\\\\"/bfnrt]|u[0-9a-zA-Z]{4}))*\")\\])*$ / }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Use", "accept", "hdr", "for", "wikidatasparql"], "add_tokens": "// Only keep the \"query\" parameter urlParts . query = { query : urlParts . query . query } ; opt . headers = vg . util . extend ( opt . headers || { } , { 'Accept' : 'application/sparql-results+json' } ) ;", "del_tokens": "urlParts . query = { format : 'json' , query : urlParts . query . query } ;", "commit_type": "use"}
{"commit_tokens": ["added", "regex", "replacement", "for", "[", "and", "]", "in", "normalizeQueryString", "function", "so", "it", "can", "handle", "cases", "where", "param", "keys", "are", "like", "?param", "[", "0", "]", "[", "key", "]", "=", "..."], "add_tokens": "queryString += encodeURIComponent ( params [ i ] ) . replace ( / %5B / g , '[' ) . replace ( / %5D / g , ']' ) ;", "del_tokens": "queryString += encodeURIComponent ( params [ i ] ) . replace ( '%5B' , '[' ) . replace ( '%5D' , ']' ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "unused", "values", "to", "be", "defined", "in", "configuration", "files"], "add_tokens": "* if ( ! ( key in a ) ) { continue ; }", "del_tokens": "*", "commit_type": "allow"}
{"commit_tokens": ["Add", "a", "new", "preact", "-", "router", "/", "match", "entry", "which", "exports", "<Match", ">", "and", "<Link", ">", "components", "both", "of", "which", "respond", "to", "URL", "changes", ".", "Match", "expects", "a", "function", "as", "its", "only", "child", "which", "is", "invokes", "in", "response", "to", "all", "routing", "/", "rendering", "with", "{", "Boolean", "matches", "String", "path", "String", "url", "}", ".", "Link", "works", "just", "like", "the", "built", "-", "in", "Link", "component", "but", "accepts", "an", "activeClassName", "=", "xx", "prop", "which", "is", "a", "class", "attribute", "value", "to", "merge", "when", "the", "link", "s", "path", "(", "or", "href", ")", "is", "matches", "the", "current", "URL", "."], "add_tokens": "const subscribers = [ ] ; for ( let i = subscribers . length ; i -- ; ) { subscribers [ i ] ( url ) ; } Router . subscribers = subscribers ; Router . getCurrentUrl = getCurrentUrl ; export { subscribers , getCurrentUrl , route , Router , Route , Link } ;", "del_tokens": "export { route , Router , Route , Link } ;", "commit_type": "add"}
{"commit_tokens": ["remove", "console", ".", "log", "leftovers"], "add_tokens": "this . socket . once ( 'connect' , function ( ) {", "del_tokens": "this . socket . once ( 'connect' , function ( ) { console . log ( \"on connect event\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "some", "integration", "tests", "to", "check", "attribute", "/", "where", "clause", "stuff"], "add_tokens": "if ( ! PermissionService . checkWhereClause ( body , permissions ) ) { return res . badRequest ( { error : 'Can\\'t create this object, because of failing where clause' } ) ;", "del_tokens": "if ( ! PermissionService . checkWhereClause ( body , permissions , body ) ) { return res . badRequest ( { error : 'Can\\'t create this object, because of failing where clause or attribute permissions' } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "&", "update", "(", "two", ")", "speechbubble", "(", "s", ")", "demo"], "add_tokens": "// entry: __dirname + '/src/index.tsx', // set in package.json", "del_tokens": "entry : __dirname + '/src/index.tsx' ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "schema", "discovery"], "add_tokens": "this . query ( \"SHOW TABLES in `\" + this . __databaseName + \"`;\" , function ( err , tableNames ) {", "del_tokens": "this . query ( \"SHOW TABLES in \" + this . __databaseName + \";\" , function ( err , tableNames ) {", "commit_type": "fix"}
{"commit_tokens": ["fixing", "up", "demo", "and", "tests", ";", "cleaning", "up", "code"], "add_tokens": "// setup our a WebGL canvas var gl = createContext ( 'webgl' , { antialias : true } ) // Create a new shader // pixel data or image var useTexture = false if ( useTexture ) { var uri = require ( 'baboon-image-uri' ) loadImage ( uri , function ( err , img ) { if ( err ) throw err setupTexture ( img , [ img . width , img . height ] ) } ) } else { setupTexture ( [ ] , [ 2 , 2 ] ) } function setupTexture ( img , size ) { tex = createTexture ( gl , img , size , { }", "del_tokens": "var gl = createContext ( 'webgl' ) // we can hard-code some defaults here // loadImage(require('baboon-image-uri'), function (err, img) { // if (err) throw err var img = [ ] tex = createTexture ( gl , img , [ 2 , 2 ] , { // })", "commit_type": "fix"}
{"commit_tokens": ["Add", "integration", "test", "to", "travis"], "add_tokens": "try { // Hack to use symbolink link to the repo for integration tests requireArg = path . join ( process . cwd ( ) , 'node_modules' , pluginIdentifier ) ; require . resolve ( requireArg ) ; } catch ( e ) { requireArg = false ; lager . log . warn ( 'Lager could not find the plugin \"' + pluginIdentifier + '\"' ) ; }", "del_tokens": "requireArg = false ; lager . log . warn ( 'Lager could not find the plugin \"' + pluginIdentifier + '\"' ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "https", ":", "true", "to", "both", "serve", "task"], "add_tokens": "} , https : true } , https : true", "del_tokens": "} }", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "checkForIntent", "argument", "in", "openTooltip", "."], "add_tokens": "checkForIntent ( ) ;", "del_tokens": "checkForIntent ( element ) ;", "commit_type": "remove"}
{"commit_tokens": ["use", "proper", "variable", "for", "setting", "value", "on", "target"], "add_tokens": "endPath . target = isArray ? value [ i ] : value", "del_tokens": "endPath . target = i ? value [ i ] : value", "commit_type": "use"}
{"commit_tokens": ["Adding", "redis", "and", "apiclient", "adapters"], "add_tokens": "* not init ( ) method or if the current adapter is apiclient if ( adapter && adapter !== 'apiclient' ) {", "del_tokens": "* not init ( ) method or if the current adapter is restapi if ( adapter && adapter !== 'restapi' ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "loader", "class", "to", "properly", "check", "the", "current", "working", "directory", "lib", "first", "."], "add_tokens": "//setup current working directory path var cwdClassPath = process . cwd ( ) + '/' + options . setup . classDir + '/' + className + '/' + options . setup . classFile ; if ( fs . existsSync ( cwdClassPath ) ) { //use the cwd class if it exists there classPath = cwdClassPath ; } else if ( fs . existsSync ( classPath ) ) {", "del_tokens": "if ( fs . existsSync ( classPath ) ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "interceptor", "for", "response", "to", "test"], "add_tokens": "setGlobalRequestInterceptor : sinon . spy ( ) , setGlobalResponseInterceptor : sinon . spy ( )", "del_tokens": "setGlobalRequestInterceptor : sinon . spy ( )", "commit_type": "add"}
{"commit_tokens": ["made", "find", "method", "more", "generic"], "add_tokens": "return data_util . coerceNumber (", "del_tokens": "return data_util . convertValue (", "commit_type": "make"}
{"commit_tokens": ["Updated", "host", "to", "look", "for", "empty", "string", "in", "hostname", "instead", "of", "host"], "add_tokens": "var host = ( window . location . hostname !== '' ) ? window . location . hostname : '127.0.0.1' ;", "del_tokens": "var host = ( window . location . host !== '' ) ? window . location . hostname : '127.0.0.1' ;", "commit_type": "update"}
{"commit_tokens": ["Implement", "simpler", "LogDistanceModel", "which", "outperforms", "the", "DeflateDistanceModel", "."], "add_tokens": "* Encodes distances starting at 0 ( for deflate compatibility , subtract * one from distance to encode ) . * Uses ~ 32 - entry model to predict ln2 ( distance ) ( more - or - less ) and then // lengthBitsModelFactory will be called with arguments 2, 4, 8, 16, etc // and must return an appropriate model or coder.", "del_tokens": "* Encodes 16 - bit distances 1 - 0x10000 * Uses 32 - entry model to predict ln2 ( distance ) ( more - or - less ) and then // ModelFunction will be called with arguments 2, 4, 8, 16, etc // and must return a constructor function", "commit_type": "implement"}
{"commit_tokens": ["fix", "bug", "with", "combinations", "result"], "add_tokens": "return last . toArray ( ) . map ( x => [ x ] ) ;", "del_tokens": "return last . map ( x => [ x ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "package", "name", "to", "lower", "case"], "add_tokens": "var FinTSClient = require ( \"../\" ) ; // require(\"open-fin-ts-js-client\");", "del_tokens": "var FinTSClient = require ( \"../\" ) ; // require(\"Open-Fin-TS-JS-Client\");", "commit_type": "change"}
{"commit_tokens": ["Make", "sure", "beforeScroll", "fires", "before", "calculating", "scroll", "target"], "add_tokens": "/ *! Smooth Scroll - v1.4.7 - 2012-10-29 var version = '1.4.7' , if ( typeof options === 'number' ) { // beforeScroll callback function must fire before calculating offset scrollTargetOffset = ( typeof options === 'number' ) ? options : px || ( $ ( opts . scrollTarget ) [ offPos ] ( ) && $ ( opts . scrollTarget ) [ offPos ] ( ) [ opts . direction ] ) || 0 ; aniProps [ scrollDir ] = scrollTargetOffset + scrollerOffset + opts . offset ;", "del_tokens": "/ *! Smooth Scroll - v1.4.6 - 2012-08-23 var version = '1.4.6' , if ( typeof options === 'number' ) { scrollTargetOffset = px || ( $ ( opts . scrollTarget ) [ offPos ] ( ) && $ ( opts . scrollTarget ) [ offPos ] ( ) [ opts . direction ] ) || 0 ; aniProps [ scrollDir ] = scrollTargetOffset + scrollerOffset + opts . offset ;", "commit_type": "make"}
{"commit_tokens": ["changing", "assert", ".", "throws", "contract"], "add_tokens": "throw e ;", "del_tokens": "throw new AssertionError ( { message : message_opt || \"throws failed\" , expected : Error_opt , actual : e } ) ;", "commit_type": "change"}
{"commit_tokens": ["Upgrade", "percy", "-", "client", "and", "fix", "timeout", "bugs", "improve", "error", "logging", "."], "add_tokens": "console . warn ( '\\n[percy] ERROR: API call failed, Percy has been disabled for this build.' ) console . log ( '\\n[percy] Build created:' , percyBuildData . attributes [ 'web-url' ] ) ; promise . then ( function ( response ) { console . log ( '\\n[percy] Uploaded new build resource: ' + resource . resourceUrl ) ; } , handlePercyFailure ) ; } , handlePercyFailure ) ; // Attempt to make our logging come last, giving time for test output to finish. var url = percyBuildData . attributes [ 'web-url' ] ; process . nextTick ( function ( ) { console . log ( '[percy] Visual diffs are now processing:' , url ) ; } ) ;", "del_tokens": "console . warn ( '\\n[percy] ERROR: Failed to create build, skipping.' ) promise . then ( function ( response ) { console . log ( '\\n[percy] Uploaded new build resource: ' + resource . resourceUrl ) ; } , function ( error ) { handlePercyFailure ( error ) ; } ) ; } ) ; // Attempt to make our logging come last, give 200ms for test output to finish. var url = percyBuildData . attributes [ 'web-url' ] ; setTimeout ( function ( ) { console . log ( '[percy] Visual diffs are now processing:' , url ) ; } , 200 ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "transaction", "dictionary", "to", "replace", "the", "object", "current", "state", "vars", "."], "add_tokens": "var MAX_TRANSACTIONS = 64 ; // maximum transaction to wait for // update transaction id modbus . _transactionId = data . readUInt16BE ( 0 ) // get next transaction id var transactionsId = ( this . _transactionId + 1 ) % MAX_TRANSACTIONS ; buffer . writeUInt16BE ( transactionsId , 0 ) ;", "del_tokens": "buffer . writeUInt16BE ( 1 , 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "jstd", "code", "for", "non", "trivial", "assertions"], "add_tokens": "var asserts = require ( './asserts' ) ; JsTestDriver . prototype . $assertEquals = function ( message , expected , actual ) { JsTestDriver . prototype . assertEquals = function ( /*message, expected, actual*/ ) { asserts . assertEquals . apply ( null , arguments ) ; } ;", "del_tokens": "JsTestDriver . prototype . assertEquals = function ( message , expected , actual ) {", "commit_type": "use"}
{"commit_tokens": ["Create", "terminal", "before", "cpu", "after", "memory"], "add_tokens": "const term = Triterm ( { addressTryteSize : VIDEO_TRYTE_ADDRESS_SIZE , tritmap : memory . array . subarray ( memory . map . video . start , memory . map . video . end ) } ) ;", "del_tokens": "const term = Triterm ( { addressTryteSize : VIDEO_TRYTE_ADDRESS_SIZE , tritmap : cpu . memory . array . subarray ( cpu . memory . map . video . start , cpu . memory . map . video . end ) } ) ;", "commit_type": "create"}
{"commit_tokens": ["added", "info", "on", "HRTF", "set"], "add_tokens": "This is from - https : //github.com/google/spatial-media/tree/master/support/hrtfs/cube", "del_tokens": "NOTES === == sampling rate : 48 kHz bit depth : 16 length : 512 samples normalization : - 3.76 dBFS peak tapering : half - hann ( 128 samples ) subject : gorzel @ microphones : Audio Technica BMC - 10 ( open ear canal ) loudspeakers : Equator D5 venue : Interactive Media Lab , TFTV , University of York , UK remarks : Low frequencies re - modelled below 500 Hz . // TODO: why these are different from the coefs above?", "commit_type": "add"}
{"commit_tokens": ["Add", "time", "unit", "to", "return", "comments", "."], "add_tokens": "* @ return The maximal backoff delay , in milliseconds . * @ return The initial backoff delay , in milliseconds .", "del_tokens": "* @ return The maximal backoff delay . * @ return The initial backoff delay .", "commit_type": "add"}
{"commit_tokens": ["added", "indexing", "of", "versification", "and", "chunks", "markers"], "add_tokens": "jest . unmock ( '../lib/container' ) ; describe ( 'Container' , ( ) => { it ( 'should do stuff' , ( ) => { } ) ; } ) ;", "del_tokens": "// TODO: begin writing tests for container module", "commit_type": "add"}
{"commit_tokens": ["added", "conditions", "to", "verify", "flex", "default", "values"], "add_tokens": "var myShorthandSetter = shorthandSetter ( 'flex' , shorthand_for ) ; set : function ( v ) { var normalizedValue = String ( v ) . trim ( ) . toLowerCase ( ) ; if ( normalizedValue === 'none' ) { myShorthandSetter . call ( this , '0 0 auto' ) ; return ; } if ( normalizedValue === 'initial' ) { myShorthandSetter . call ( this , '0 1 auto' ) ; return ; } if ( normalizedValue === 'auto' ) { this . removeProperty ( 'flex-grow' ) ; this . removeProperty ( 'flex-shrink' ) ; this . setProperty ( 'flex-basis' , normalizedValue ) ; return ; } myShorthandSetter . call ( this , v ) } ,", "del_tokens": "set : shorthandSetter ( 'flex' , shorthand_for ) ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "setting", "env", "for", "binaries"], "add_tokens": "export function runBinary ( targetBinary : string , args : string [ ] , env : any ) { env ,", "del_tokens": "export function runBinary ( targetBinary : string , args : string [ ] ) {", "commit_type": "allow"}
{"commit_tokens": ["Remove", "jar", "completely", "if", "unused"], "add_tokens": "opt . jar = null ; var jar = opt && opt . jar ; opt . jar = jar ; cache . add ( options . cache , 'XCSRF' , getHash ( { jar : jar } ) , opt . headers [ 'X-CSRF-TOKEN' ] ) ;", "del_tokens": "cache . add ( options . cache , 'XCSRF' , getHash ( { jar : opt . jar } ) , opt . headers [ 'X-CSRF-TOKEN' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "script", "to", "check", "mandatory", "plugins", "ensure", "that", "this", "is", "run", "when", "creating", "an", "index"], "add_tokens": "var child_process = require ( 'child_process' ) ; var cli = require ( './cli' ) ; // check mandatory plugins are installed before continuing try { child_process . execSync ( 'node ./scripts/check_plugins.js' ) ; } catch ( e ) { console . error ( \"please install mandatory plugins before continuing.\\n\" ) ; process . exit ( 1 ) ; } cli . header ( \"create index\" ) ; if ( err ) { console . error ( err . message || err , '\\n' ) ; process . exit ( 1 ) ; } console . log ( '[put mapping]' , '\\t' , indexName , res , '\\n' ) ;", "del_tokens": "console . log ( '[put mapping]' , '\\t' , indexName , err || '\\t' , res ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "freeze", "/", "zero", "descriptions"], "add_tokens": ". description ( 'Sets all UFO outputs to zero. Does not alter the flag (see \"on\"/\"off\" commands).' ) . description ( 'Stops whatever builtin/custom is playing. Output will remain on; use \"zero\" to stop and turn off output simultaneously.' )", "del_tokens": ". description ( 'Sets all UFO outputs to zero.' ) . description ( 'Stops whatever builtin/custom is playing.' )", "commit_type": "improve"}
{"commit_tokens": ["Made", "zooming", "a", "bit", "more", "robust", "."], "add_tokens": "var tagLine = \"...I can see the lights in the distance.\" ; var zoomBase = 100 ; var zoomExpt = 30 ; // Now gets clobbered. zoomExpt = 250 / Math . log ( MAX_VIEW_SIZE / zoomBase ) ;", "del_tokens": "var tagLine = \"...just some gills and some wings and a few extra thumbs.\" ; var zoomBase = 50 ; var zoomExpt = 30 ;", "commit_type": "make"}
{"commit_tokens": ["Added", "special", "code", "to", "handle", "file", "type", "input", "field"], "add_tokens": "var type = control . type . toLowerCase ( ) ; if ( type === 'checkbox' ) { } else if ( type === 'file' ) { result = control . files ; var type = self . elements [ i ] . type . toLowerCase ( ) ; if ( type === 'checkbox' ) { } else if ( type === 'file' ) { // No input value from model here", "del_tokens": "if ( control . type . toUpperCase ( ) === 'CHECKBOX' ) { if ( self . elements [ i ] . type . toUpperCase ( ) === 'CHECKBOX' ) {", "commit_type": "add"}
{"commit_tokens": ["Updating", "generator", "to", "work", "with", "the", "ne", "emo", "-", "gen", "api"], "add_tokens": "return this . generator . build ( this . gruntOptions . components , this . gruntOptions . views ) ;", "del_tokens": "return this . generator . scrape ( this . gruntOptions . components ) ; } . bind ( this ) ) . then ( function ( components ) { var total = this . getComponentsTotal ( components ) ; this . grunt . log . writeln ( 'Documented ' + total + ' component(s)' ) ; return this . generator . build ( components , this . gruntOptions . views ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "detective", "module", "and", "parse", "self"], "add_tokens": "throw error ;", "del_tokens": "const { r , g , b , w , c , m , y , k } = [ [ 'r' , 1 ] , [ 'g' , 2 ] , [ 'b' , 4 ] , [ 'w' , 7 ] , [ 'c' , 6 ] , [ 'm' , 5 ] , [ 'y' , 3 ] , [ 'k' , 0 ] ] . reduce ( ( cols , col ) => ( { ... cols , [ col [ 0 ] ] : f => ` \\x1b ${ col [ 1 ] } ${ f } \\x1b ` } ) , { } ) ; throw err ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", ":", "loading", "gets", "stuck", "after", "getting", "first", "asset", "from", "cache"], "add_tokens": "next ( ) ;", "del_tokens": "next ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "syntax", "errors", "in", "tile"], "add_tokens": "//msa.addPlugin(new ZoomBar(msa,1,5), \"0_zoombar\");", "del_tokens": "msa . addPlugin ( new ZoomBar ( msa , 1 , 5 ) , \"0_zoombar\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "some", "tests", ".", "Become", "more", "opinionated", "."], "add_tokens": "// Dates // Arrays (assumed to be lists) // Numbers if ( / \\d+ / . test ( x ) ) { return x . toString ( ) ; } // Assume all other objects must be collections of some kind", "del_tokens": "if ( x . toString ) { return x . toString ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Updated", "dependencies", "to", "fix", "grunt", "bug"], "add_tokens": "browserifyOptions : { browserifyOptions : { debug : true ,", "del_tokens": "bundleOptions : { debug : true , bundleOptions : {", "commit_type": "update"}
{"commit_tokens": ["Added", "legend", ".", "labelBoxOpacity", "option", ".", "Added", "check", "for", "bars", "exiting", "to", "label", "box", "drawing", "."], "add_tokens": "// @TODO remove requirement on bars opacityValue = ( s . bars ? s . bars . fillOpacity : legend . labelBoxOpacity ) , opacity = 'opacity:' + opacityValue + ';filter:alpha(opacity=' + opacityValue * 100 + ');' , color = 'background-color:' + ( ( s . bars && s . bars . show && s . bars . fillColor && s . bars . fill ) ? s . bars . fillColor : s . color ) + ';' ; '<div style=\"width:' , boxWidth , 'px;height:' , boxHeight , 'px;' , 'opacity:.4;' , color , '\"></div>' , // Background", "del_tokens": "opacity = 'opacity:' + s . bars . fillOpacity + ';filter:alpha(opacity=' + s . bars . fillOpacity * 100 + ');' , color = 'background-color:' + ( ( s . bars . show && s . bars . fillColor && s . bars . fill ) ? s . bars . fillColor : s . color ) + ';' ; '<div style=\"width:' , boxWidth , 'px;height:' , boxHeight , 'px;' , opacity , color , '\"></div>' , // Background", "commit_type": "add"}
{"commit_tokens": ["Add", "validation", "rules", "for", "stellar", "addresses"], "add_tokens": "function err ( errorMessage ) { return err ( 'MEMO_ID only accepts a positive integer.' ) ; return err ( ` MEMO_ID is an unsigned 64 - bit integer and the max valid return err ( ` ${ memoTextBytes } ` ) ; return err ( ` ${ type } ` ) ; } , address ( input , type ) { if ( input === '' ) { return RESULT_EMPTY ; } // Regex covers 99% of the use cases. // - Allows any character in user part except * and , as specified in Stellar docs // - Includes all valid addresses and a few invalid ones too such as fake TLD or misuse of hyphens or excessive length if ( ! input . match ( / ^[^\\*\\,]+\\*([\\-a-zA-Z0-9]+\\.)*([a-zA-Z0-9]{2,}){1}$ / ) ) { return err ( 'Stellar federation address is improperly formatted.' ) ; } return RESULT_VALID ; } ,", "del_tokens": "function result ( errorMessage ) { return result ( 'MEMO_ID only accepts a positive integer.' ) ; return result ( ` MEMO_ID is an unsigned 64 - bit integer and the max valid return result ( ` ${ memoTextBytes } ` ) ; return result ( ` ${ type } ` ) ; }", "commit_type": "add"}
{"commit_tokens": ["adding", "chat", "version", "to", "api"], "add_tokens": "} , / ** * String of current version of the chat widget . * @ memberof IBMChat * @ example * IBMChat . version * / version : process . env . CHAT_VERSION", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Use", "build", "dir", "for", "testing"], "add_tokens": "const createWebDAVClient = require ( \"../../build/index.js\" ) ;", "del_tokens": "const createWebDAVClient = require ( \"../../source/index.js\" ) ;", "commit_type": "use"}
{"commit_tokens": ["made", "queue", "processing", "a", "tad", "faster"], "add_tokens": "_oldSetTimeout ( _process , 10 ) ; // \"1\" might be fine too but I want to give the browser at least a moment", "del_tokens": "_oldSetTimeout ( _process , 16 ) ; // \"1\" might be fine too but I want to give the browser at least a moment", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "user", "triggers"], "add_tokens": "exports . NullLogHandler = EyesSDK . NullLogHandler ; var eyesBase = EyesSDK . EyesBase ; exports . FailureReport = eyesBase . FailureReport ; exports . MatchLevel = eyesBase . MatchLevel ;", "del_tokens": "exports . NullLogHandler = EyesSDK . NullLogHandler ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "x", "-", "forwarded", "-", "for", "parsing", "to", "pull", "out", "the", "first", "ip", "only", "."], "add_tokens": "this . remoteAddress = request . headers [ 'x-forwarded-for' ] . split ( ', ' ) [ 0 ] ;", "del_tokens": "this . remoteAddress = request . headers [ 'x-forwarded-for' ] ;", "commit_type": "update"}
{"commit_tokens": ["Use", "module", ".", "parent", ".", "require", "to", "pull", "in", "plugins"], "add_tokens": "var plugin = module . parent . require ( name ) ;", "del_tokens": "var plugin = require ( require . resolve ( name ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "regression", "with", "trailing", "comments", "for", "methods"], "add_tokens": "o ( 'DEF_EMPTY' , function ( ) { return [ ] ; } )", "del_tokens": "o ( 'DEF_BODY TERMINATOR' , function ( ) { return [ ] ; } )", "commit_type": "fix"}
{"commit_tokens": ["adds", "targetTouches", "and", "changedTouches", "to", "touchevents", "touch"], "add_tokens": "const touches = createTouch ( element , options ) ; Object . assign ( props , touches ) ;", "del_tokens": "const { touches } = createTouch ( element , options ) ; props . touches = touches ;", "commit_type": "add"}
{"commit_tokens": ["add", "jshint", "to", "deps", "and", "grunt", "task", ".", "Badge", "for", "Travis", "CI", ".", "More", "example", "targets", "."], "add_tokens": "* NOTICE : Most of this code is from grunt - contrib - less * but it has been modified to concat the LESS * files first , then compile them into a CSS * file . This allows for \"requiring\" LESS files * CSS files instead of building one big CSS file . grunt . log . ok ( 'File ' + singleDestFile . cyan + ' created.' + ' ok ' . green ) ;", "del_tokens": "* Most of this code is from grunt - contrib - less * but it has been modified to concat the less * files first , then compile them into a css * file . This allows for requiring less files * css files instead of building 1 big css file . grunt . log . ok ( 'File ' + singleDestFile . magenta + ' created.' + ' ok ' . green ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "npm", "-", "shrinkwrap", "diff", "when", "file", "not", "at", "repository", "root", "."], "add_tokens": "exec ( 'git show ' + sha + ':./npm-shrinkwrap.json' , {", "del_tokens": "exec ( 'git show ' + sha + ':npm-shrinkwrap.json' , {", "commit_type": "fix"}
{"commit_tokens": ["add", "trailing", "characters", "so", "ie", "doesn", "t", "fuck", "up"], "add_tokens": "( params . wspath || '/?wait1' ) ;", "del_tokens": "( params . wspath || '/' ) ;", "commit_type": "add"}
{"commit_tokens": ["using", "csi", "-", "sequences", "instead", "of", "direct", "calls", "for", "tests", "."], "add_tokens": "switch ( n || 0 ) { switch ( n || 0 ) {", "del_tokens": "switch ( n || 'toEnd' ) { case 'toEnd' : case 'toBegin' : case 'entire' : switch ( n || 'toEnd' ) { case 'toEnd' : case 'toBegin' : case 'entire' :", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "fix", "unitless", "style", "declarations", "coalescing", "to", "px", "in", "stylesheet", "declarations", "with", "objects", "."], "add_tokens": "var _unitlessValues = __webpack_require__ ( 23 ) ; var _unitlessValues2 = _interopRequireDefault ( _unitlessValues ) ; __webpack_require__ ( 24 ) ; _utils2 [ \"default\" ] . forIn ( style , function ( value , property ) { if ( _utils2 [ \"default\" ] . isNumber ( value ) && _unitlessValues2 [ \"default\" ] . indexOf ( property ) === - 1 ) { style [ property ] = value + \"px\" ; } } ) ; /***/ function ( module , exports ) { \"use strict\" ; Object . defineProperty ( exports , \"__esModule\" , { value : true } ) ; exports [ \"default\" ] = [ \"columnCount\" , \"columns\" , \"counterIncrement\" , \"counterReset\" , \"flexGrow\" , \"flexShrink\" , \"fontWeight\" , \"lineHeight\" , \"opacity\" , \"order\" , \"pitchRange\" , \"richness\" , \"stress\" , \"volume\" , \"zIndex\" ] ; module . exports = exports [ \"default\" ] ; /***/ } , /* 24 */ exports = module . exports = __webpack_require__ ( 25 ) ( ) ; /* 25 */", "del_tokens": "__webpack_require__ ( 23 ) ; exports = module . exports = __webpack_require__ ( 24 ) ( ) ; /* 24 */", "commit_type": "update"}
{"commit_tokens": ["Fix", "client", "-", "side", "previously", "introduced", "bug"], "add_tokens": "if ( ! pluralFunc && typeof module !== 'undefined' && module . exports ) {", "del_tokens": "if ( ! pluralFunc && module . exports ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "to", "using", "a", "single", "primitive", "component", "for", "Graphics", "primitives"], "add_tokens": ". attach ( new hitagi . components . Primitive ( { type : 'rectangle' , . attach ( new hitagi . components . Primitive ( { radius : params . radius , type : 'circle'", "del_tokens": ". attach ( new hitagi . components . Rectangle ( { . attach ( new hitagi . components . Circle ( { radius : params . radius", "commit_type": "change"}
{"commit_tokens": ["add", "rule", "collection", "-", "return"], "add_tokens": "var collectionMethods = expandAliases ( property . concat ( [ 'reduce' , 'reduceRight' ] ) ) ; WRAPPER_METHODS : WRAPPER_METHODS , collectionMethods : collectionMethods", "del_tokens": "WRAPPER_METHODS : WRAPPER_METHODS", "commit_type": "add"}
{"commit_tokens": ["Updating", "sample", "app", "to", "reflect", "latest", "changes"], "add_tokens": "var sync = ContentSync . sync ( { src : url , id : 'myapps/myapp' , type : 'replace' , copyCordovaAssets : false , headers : false } ) ; switch ( progress . status ) { case 1 : document . getElementById ( 'status' ) . innerHTML = \"Downloading...\" ; break ; case 2 : document . getElementById ( 'status' ) . innerHTML = \"Extracting...\" ; break ; case 3 : document . getElementById ( 'status' ) . innerHTML = \"Complete!\" ; break ; default : document . getElementById ( 'status' ) . innerHTML = \"\" ; } } if ( progress . progress ) { var progressBar = document . getElementById ( 'progressbar' ) . children [ 0 ] ; progressBar . style . width = progress . progress + '%' ;", "del_tokens": "var sync = ContentSync . sync ( { src : url , id : 'myapps/myapp' , type : 'replace' } ) ; document . getElementById ( 'status' ) . innerHTML = ( progress . status == \"Downloading\" ? \"Downloading...\" : \"Extracting...\" ) ; } else { document . getElementById ( 'status' ) . innerHTML = \"\" ; var progressBar = document . getElementById ( 'progressbar' ) . children [ 0 ] ; progressBar . style . width = progress . progress + '%' ; setProgress ( { progress : 100 } )", "commit_type": "update"}
{"commit_tokens": ["Improve", "noval", "(", "0", ")"], "add_tokens": "Object . defineProperty ( requiem , 'version' , { value : '0.12.2' , writable : false } ) ; } else if ( typeof value === 'string' ) { if ( value === '' ) { return true ; } else { return false ; }", "del_tokens": "Object . defineProperty ( requiem , 'version' , { value : '0.12.1' , writable : false } ) ;", "commit_type": "improve"}
{"commit_tokens": ["add", "ig", "flags", "to", "regex", "constructor", "to", "improve", "filtering"], "add_tokens": "filterRegExp = new RegExp ( filterFor , 'ig' ) ;", "del_tokens": "filterRegExp = new RegExp ( filterFor ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "compare", "function", "for", "the", "route", "sort"], "add_tokens": "if ( route1 . path < route2 . path ) return - 1 ; if ( route1 . path > route2 . path ) return 1 ; return 0 ;", "del_tokens": "return route1 . path > route2 . path ;", "commit_type": "update"}
{"commit_tokens": ["Use", "more", "specific", "error", "for", "unknown", "views", "."], "add_tokens": "throw JuttleErrors . syntaxError ( 'RT-INVALID-VIEW' , { sink : sink . name , location : sink . location } ) ;", "del_tokens": "throw JuttleErrors . syntaxError ( 'RT-UNDEFINED' , { name : sink . name , location : sink . location } ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "CORS", "support", "back", "to", "loadImage"], "add_tokens": "function loadImageBrowser ( opts , callback ) { var crossOrigin = null var url = opts if ( url . url ) { crossOrigin = url . crossOrigin url = url . url } img . crossOrigin = crossOrigin", "del_tokens": "function loadImageBrowser ( url , callback , crossOrigin ) { img . crossOrigin = 'anonymous'", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "the", "ExtractTextPlugin", "configs"], "add_tokens": "loader : ExtractTextPlugin . extract ( { notExtractLoader : 'style-loader' , loader : 'css-loader!postcss-loader' } ) ,", "del_tokens": "loader : ExtractTextPlugin . extract ( 'style-loader' , 'css-loader!postcss-loader' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "to", "disable", "heartbeat", "intervals", "in", "polling", "transports", "."], "add_tokens": "HTTPPolling . prototype . setHeartbeatInterval = function ( ) { return this ;", "del_tokens": "HTTPPolling . prototype . setHeartbeatTimeout = function ( ) { return ; } ; / ** * Removes the heartbeat timeouts for polling . * / HTTPPolling . prototype . clearHeartbeatTimeout = function ( ) { return ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "<content", ">", "inlining", "."], "add_tokens": "return posthtml ( [ function ( tree ) { return tree ; } ] . concat ( options . plugins ) ) . use ( function ( tree ) {", "del_tokens": "return posthtml ( options . plugins ) . use ( function ( tree ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "size", "to", "file", "stats"], "add_tokens": "\"type\" : infos . type , \"size\" : infos . size", "del_tokens": "\"type\" : infos . type", "commit_type": "add"}
{"commit_tokens": ["update", "disabledColor", "prop", "checking", "to", "string"], "add_tokens": "disabledColor : _propTypes2 . default . string , } ;", "del_tokens": "disabledColor : _propTypes2 . default . bool , } ;", "commit_type": "update"}
{"commit_tokens": ["changed", "if", "syntax", "and", "removed", "template", "strings"], "add_tokens": "if ( ! session [ newAttribute ] ) { session [ newAttribute ] = currentItem . withSessionAttributes [ newAttribute ] ;", "del_tokens": "if ( typeof session [ ` ${ newAttribute } ` ] === \"undefined\" ) { session [ ` ${ newAttribute } ` ] = currentItem . withSessionAttributes [ ` ${ newAttribute } ` ] ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "some", "helper", "code", "bugs"], "add_tokens": "if ( typeof options . common == 'undefined' ) options . common = true ; if ( hs . options . client ) { if ( hs . options . common ) { if ( hs . options . client ) {", "del_tokens": "if ( typeof options . common == 'undefined' ) options . common = false ; if ( hs . client ) { if ( hs . common ) { if ( hs . client ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "initialConfig", "and", "add", "methods", "for", "hostname", "and", "global", "-", "settings"], "add_tokens": ". then ( function ( ) { return q ( ) ;", "del_tokens": ". then ( function ( response ) { return q ( response ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "resource", "constructor", "when", "creating", "linked", "/", "embedded", "resource"], "add_tokens": "return extractAndUpdateResources ( data , links , this ) ; * @ param { Resource } self function extractAndUpdateResources ( data , links , self ) { resources = resources . concat ( extractAndUpdateResources ( embedded , { } , self ) ) ; var resource = self . $context . get ( links . self . href , self . constructor ) ;", "del_tokens": "return extractAndUpdateResources ( data , links , this . $context ) ; * @ param { ResourceContext } context function extractAndUpdateResources ( data , links , context ) { resources = resources . concat ( extractAndUpdateResources ( embedded , { } , context ) ) ; var resource = context . get ( links . self . href , HalResource ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "some", "test", "files", "&", "fixed", "the", "ljm_functions", ".", "js", "file", "for", "the", "OpenAll", "function", "."], "add_tokens": "{ 'ErrorHandle' : 'int*' } ,", "del_tokens": "{ 'ErrorHandle' : 'a-int*' } ,", "commit_type": "add"}
{"commit_tokens": ["adding", "synthetics", "get", "monitor", "call"], "add_tokens": "var syntheticsId = 0 ; it ( 'gets the list of all monitors' , function ( done ) { syntheticsId = body . monitors [ 0 ] . id ; quickAssert ( error , response ) ; done ( ) ; } ) } ) ; it ( 'gets a single monitor' , function ( done ) { synthetics . getMonitor ( syntheticsId , function ( error , response , body ) {", "del_tokens": "it ( 'calls the synthetics api' , function ( done ) {", "commit_type": "add"}
{"commit_tokens": ["move", "some", "parser", "code", "around", "--", "out", "of", "index", "into", "libraries"], "add_tokens": "var fullparser = require ( './lib/parser/full' ) , var parsed = fullparser . fullParse ( input ) ;", "del_tokens": "var parser = require ( './lib/parser/structure' ) , fullparser = require ( './lib/parser/full' ) , var parsed = parser . parse ( input ) ; //console.log(Array.isArray(parsed)); if ( ! parsed . status ) { parsed = parsed . map ( fullparser . parseTokensInTree ) ; }", "commit_type": "move"}
{"commit_tokens": ["Fix", "Field", "with", "enum", "/", "maximum", "/", "minimum", "constraints"], "add_tokens": "const cast = lodash . bind ( this . castValue , this , lodash , false )", "del_tokens": "const cast = lodash . partial ( this . castValue , lodash , false )", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "simple", "timing", "to", "pullstream", "and", "write", "tty", "friendly", "output"], "add_tokens": "this . __layerStarts = { } ; str += '\\r\\n' ; if ( json . status == 'Downloading' ) { if ( this . __layerStarts [ json . id ] === undefined ) { this . __layerStarts [ json . id ] = new Date ( ) ; } } else if ( json . status == 'Download complete' ) { if ( this . __layerStarts [ json . id ] !== undefined ) { var s = Math . abs ( new Date ( ) - this . __layerStarts [ json . id ] ) / 1000 ; this . push ( json . id + ' - Downloaded in ' + s + ' seconds\\r\\n' ) ; } } this . push ( json . status + '\\r\\n' ) ;", "del_tokens": "str += '\\n' ; this . push ( json . status + '\\n' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "add", "disabled", "option"], "add_tokens": "this . buildComponentSpecificConfiguration ( ) ; // Create placeholder this . addOption ( 'Select an option' ) ; this . html . options [ 0 ] . disabled = true ; this . html . options [ 0 ] . selected = true ; buildComponentSpecificConfiguration ( ) { this . html . configOptions = { } ; const disabledOptionWrapper = document . createElement ( 'label' ) ; const disabledOption = document . createElement ( 'input' ) ; disabledOption . type = 'checkbox' ; disabledOptionWrapper . appendChild ( disabledOption ) ; disabledOptionWrapper . appendChild ( document . createTextNode ( 'Disabled' ) ) ; this . html . configOptions . disabledOption = disabledOption ; this . html . componentSpecificConfiguration . appendChild ( disabledOptionWrapper ) ; } / ** * Fetches component specific options and clears component - specific fields * @ method getComponentSpecificOptions * @ return { Array } * / getComponentSpecificOptions ( ) { // Fetch data const disabledOption = this . html . configOptions . disabledOption . checked ; // Reset fields this . html . configOptions . disabledOption . checked = false ; return [ disabledOption ] ; } addOption ( text , disabled = false ) { if ( disabled ) { newOption . setAttribute ( 'disabled' , true ) ; }", "del_tokens": "addOption ( text ) {", "commit_type": "add"}
{"commit_tokens": ["add", ".", "min", "to", "file", "name", "when", "minified", "option", "is", "set", "to", "true"], "add_tokens": "var command = 'lessc' + sourceMap + minifiedFlag + ' ' + file . replace ( / \\s+ / g , '\\\\ ' ) + ' ' + lessWatchCompilerUtilsModule . config . outputFolder + '/' + filename . replace ( / \\s+ / g , '\\\\ ' ) + ( lessWatchCompilerUtilsModule . config . minified ? '.min' : '' ) + '.css' ; } ) ;", "del_tokens": "var command = 'lessc' + sourceMap + minifiedFlag + ' ' + file . replace ( / \\s+ / g , '\\\\ ' ) + ' ' + lessWatchCompilerUtilsModule . config . outputFolder + '/' + filename . replace ( / \\s+ / g , '\\\\ ' ) + '.css' ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "need", "for", "iCheck", "CSS", "dependency", "."], "add_tokens": "checkboxClass : 'icheckbox_ghost'", "del_tokens": "checkboxClass : 'icheckbox_square-grey'", "commit_type": "remove"}
{"commit_tokens": ["Add", "the", "ability", "to", "enter", "a", "range", "of", "date", "."], "add_tokens": "dates = utils . parseDate ( date ) ,", "del_tokens": "dates = ( Array . isArray ( date ) ) ? date : [ date ] ,", "commit_type": "add"}
{"commit_tokens": ["Implemented", "startAdvertise", "on", "Android", "."], "add_tokens": "* @ param { ArrayBufferView } data - Required for responses to read requests . May be set to null for write requests . * @ param { ArrayBufferView } data - The characteristic ' * Fails if advertise is running . In that case , call stopAdvertise first . * @ property { Object } serviceData - Map of string to ArrayBufferView . Each string is a service UUID . The accompanying ArrayBufferView is data associated with the service . * @ property { Object } manufacturerData - Map of int to ArrayBufferView . Each int is a manufacturer id . The accompanying ArrayBufferView is data associated with the manufacturer .", "del_tokens": "* @ param { ArrayBuffer } data - Required for responses to read requests . May be set to null for write requests . * @ param { ArrayBuffer } data - The characteristic ' * @ property { Object } serviceData - Map of string to ArrayBuffer . Each string is a service UUID . The accompanying ArrayBuffer is data associated with the service . * @ property { Object } manufacturerData - Map of int to ArrayBuffer . Each int is a manufacturer id . The accompanying ArrayBuffer is data associated with the manufacturer .", "commit_type": "implement"}
{"commit_tokens": ["Fix", "service", "registration", "info", "call", "in", "service", "example"], "add_tokens": "var info = new dxl . ServiceRegistrationInfo ( client , 'myService' )", "del_tokens": "var info = new dxl . ServiceRegistrationInfo ( 'myService' )", "commit_type": "fix"}
{"commit_tokens": ["Use", "streams", "instead", "of", "through2"], "add_tokens": "const fixturePath2 = 'test/fixtures/valid-functions-copy.php' ; const testFile2 = new Vinyl ( { path : fixturePath2 , contents : fs . readFileSync ( fixturePath2 ) } ) ; es . readArray ( [ testFile , testFile2 ] )", "del_tokens": "es . readArray ( [ testFile ] )", "commit_type": "use"}
{"commit_tokens": ["use", "_resolved", "instead", "of", "_from", "for", "git", "repos"], "add_tokens": "if ( dependency . _resolved && dependency . _resolved . indexOf ( expectedVersion ) < 0 ) { fail ( packageJson , dependencyName , dependencyPath , expectedVersion , dependency . _resolved )", "del_tokens": "if ( dependency . _from && dependency . _from . indexOf ( expectedVersion ) < 0 ) { fail ( packageJson , dependencyName , dependencyPath , expectedVersion , dependency . _from )", "commit_type": "use"}
{"commit_tokens": ["Adds", "the", "Succss", ".", "options", "user", "setting", "merged", "with", "options", "fixes", "the", "tmpDir", "cleaning"], "add_tokens": "Succss . pages = { }", "del_tokens": "Succss . webpages = { }", "commit_type": "add"}
{"commit_tokens": ["Use", "finish", "event", "instead", "of", "end", "event", "when", "listening", "for", "marko", "template", "writer", "to", "finish"], "add_tokens": ". on ( 'finish' , function ( ) { . on ( 'error' , done ) . end ( ) ;", "del_tokens": ". on ( 'end' , function ( ) { . on ( 'error' , done ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "lazy", "command", "creation", "in", "batch", "result"], "add_tokens": "const batchRes = maybeMap ( result , x => this . exec ( x ) ) ;", "del_tokens": "const batchRes = maybeMap ( result , x => x . exec && this . exec ( x ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bluebirdisms", "in", "tests", "."], "add_tokens": "return execPromise ( fn ) . then ( function ( value ) { console . error = origError console . log = origLog process . exit = origExit return value } , function ( reason ) { console . error = origError console . log = origLog process . exit = origExit throw reason } ) return exec ( spy ) . then ( function ( value ) { process . argv = origArgv return value } , function ( reason ) { process . argv = origArgv throw reason } ) . then ( function ( ) {", "del_tokens": "return execPromise ( fn ) . finally ( function ( ) { console . error = origError console . log = origLog process . exit = origExit } ) return exec ( spy ) . finally ( function ( ) { process . argv = origArgv } ) . then ( function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "messages", "in", "orderer", "-", "chain", "-", "tests", ".", "js"], "add_tokens": "/ TypeError: Parameter \"url\" must be a string, not undefined / ,", "del_tokens": "/ TypeError: Parameter 'url' must be a string / ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "few", "errors", "disable", "logging", "by", "default"], "add_tokens": "if ( options . log === true ) { } else if ( typeof options . log === 'object' ) { } else { this . log = function ( ) { } var self = this ; var self = this ; var self = this ;", "del_tokens": "if ( ! options . log ) { } else {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "use", "~", "alias", "for", "src", "/", "directory", "in", "imports"], "add_tokens": "const srcDir = path . join ( config . projectDir , 'src' ) ; srcDir , alias : { '~' : srcDir , } , if ( ! request . startsWith ( '.' ) && ! request . startsWith ( '~' ) && ! path . isAbsolute ( request ) ) { const resolvePaths = [ srcDir ] . concat ( require . resolve . paths ( relPath ) ) ; '~' : srcDir , include : [ srcDir ] , template : path . join ( srcDir , 'index.html' ) ,", "del_tokens": "path . join ( config . projectDir , 'src' ) , if ( ! request . startsWith ( '.' ) && ! path . isAbsolute ( request ) ) { const resolvePaths = [ path . join ( config . projectDir , 'src' ) ] . concat ( require . resolve . paths ( relPath ) ) ; vue$ : 'vue/dist/vue.esm.js' , // BUG: do we need it? // '@': 'src', include : [ path . join ( config . projectDir , 'src' ) ] , template : path . join ( config . projectDir , 'src' , 'index.html' ) ,", "commit_type": "allow"}
{"commit_tokens": ["Added", "logic", "to", "pull", "in", "configs", "from", "server", "."], "add_tokens": "var remoteDB = document . location . protocol + '//' + document . location . host + '/db/config' ; PouchDB . replicate ( remoteDB , 'config' , { } , function ( err ) { console . log ( \"On ERROR callback:\" ) ; console . dir ( err ) ; application . advanceReadiness ( ) ;", "del_tokens": "PouchDB . replicate ( document . location . href + '/db/config' , 'config' , {", "commit_type": "add"}
{"commit_tokens": ["Use", "lodash", "optimization", "plugins", "for", "webpack", "and", "babel"], "add_tokens": "multiple && find ( selected , o => isEqual ( o , option ) )", "del_tokens": "multiple && find ( selected , option )", "commit_type": "use"}
{"commit_tokens": ["Added", "and", "tested", "grunt", "-", "reloadr", "some", "serious", "issues", "needs", "to", "be", "fixed", "on", "dependency", "before", "launch"], "add_tokens": "src : [ '!<%= basepath %><%= app.build.min.dest %>*.js' , '<%= basepath %>css/dist/style.css' , '<%= basepath %>**/*.html' , '!node_modules/**/*.js' ] //grunt.registerTask('default', ['reloadr', 'watch']); grunt . registerTask ( 'default' , [ 'reloadr' , 'watch' ] ) ;", "del_tokens": "// DO NOT REMOVE // DO NOT REMOVE main : [ '<%= basepath %>**/*.html' , '<%= basepath %>**/*.css' , '<%= basepath %>**/*.js' , // DO NOT REMOVE '!node_modules/**/*.js' ] grunt . registerTask ( 'default' , [ 'watch' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "localfs", "test", "for", "watcher"], "add_tokens": "watcher . on ( \"change\" , function listen ( event , filename ) { watcher . removeListener ( \"change\" , listen ) ; watcher . on ( \"change\" , function ( event , filename ) { watcher . close ( ) ; done ( ) ; } ) ; writable . end ( ) ;", "del_tokens": "watcher . on ( \"change\" , function ( event , filename ) { watcher . close ( ) ; writable . end ( ) ; done ( ) ;", "commit_type": "update"}
{"commit_tokens": ["change", "svgicon", "-", "viewer", "dist"], "add_tokens": "path . join ( __dirname , '../dist/index.html' ) ,", "del_tokens": "path . join ( __dirname , '../assets/index.html' ) ,", "commit_type": "change"}
{"commit_tokens": ["Changed", "check", "method", "to", "checked", "and", "changed", "the", "param", "checked", "to", "value"], "add_tokens": "rquery . prototype . checked = function ( value ) { if ( value !== undefined ) { node . checked = value ;", "del_tokens": "rquery . prototype . check = function ( checked ) { if ( checked !== undefined ) { node . checked = checked ;", "commit_type": "change"}
{"commit_tokens": ["Added", "knowledge", "of", "extension", "to", "export", "modules", ".", "Need", "this", "to", "create", "the", "write", "extensions", "for", "output", "files"], "add_tokens": "} buffer += data ; var ext = exportYaml . getExtension ( options . format ) ; if ( ext ) file . extname = ext ;", "del_tokens": "} buffer += data ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "tiny", "typo", "in", "comments"], "add_tokens": "// check for browser codec support", "del_tokens": "// chek for browser codec support", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "-", "bug", "in", "Functions"], "add_tokens": "return F . broadcast ( df ) ;", "del_tokens": "return F . broadcast ( dataframe ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "extra", "debugging", "for", "common", "issues"], "add_tokens": "* @ param ctrlName function addEventHandlers ( scope , ctrlName , handlers ) { // if it is not a function, throw error b/c dev likely made a mistake if ( ! angular . isFunction ( scope [ name ] ) ) { throw new Error ( ctrlName + ' has uiEventHandler ' + name + ' that does not return a function' ) ; }", "del_tokens": "function addEventHandlers ( scope , handlers ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "feature", "of", "simulating", "blocking", "calls"], "add_tokens": "this . dueTime = currentTime . milliseconds + callDelay ; this . dueTime = currentTime . milliseconds + this . callDelay ; var timer = new TimerType ( callback , this . timerRepository , this . timeServer . currentTime , callDelay ) ;", "del_tokens": "this . dueTime = currentTime + callDelay ; this . timerRepository . clearTimer ( this . uid ) ; this . dueTime += this . callDelay ; var timer = new TimerType ( callback , this . timerRepository , this . timeServer . currentTime . milliseconds , callDelay ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "fundametly", "how", "haunt", "works", "-", "to", "be", "more", "a", "module", "less", "a", "bot", ".", "update", "readme", "to", "reflect", "this", "change"], "add_tokens": "var path = require ( 'path' ) ; failure : hogan . compile ( fs . readFileSync ( path . join ( __dirname , '../views/issues/failure.mustache' ) , 'utf-8' ) ) , warning : hogan . compile ( fs . readFileSync ( path . join ( __dirname , '../views/issues/warning.mustache' ) , 'utf-8' ) )", "del_tokens": "failure : hogan . compile ( fs . readFileSync ( './views/issues/failure.mustache' , 'utf-8' ) ) , warning : hogan . compile ( fs . readFileSync ( './views/issues/warning.mustache' , 'utf-8' ) )", "commit_type": "change"}
{"commit_tokens": ["Add", "tests", "for", "async", "cache", "mechanism", "."], "add_tokens": "import { render , setCacheStrategy , Promise } from \"../src\" ; import { useDefaultCacheStrategy } from \"../src/sequence/cache\" ; const runAllTests = ( ) => { } ; describe ( \"naive caching\" , ( ) => { runAllTests ( ) ; } ) ; describe ( \"async caching\" , ( ) => { beforeEach ( ( ) => { const asyncCache = Object . create ( null ) ; setCacheStrategy ( { get : key => Promise . resolve ( asyncCache [ key ] && JSON . parse ( asyncCache [ key ] ) || null ) , set : ( key , val ) => { asyncCache [ key ] = JSON . stringify ( val ) ; return Promise . resolve ( ) ; } } ) ; } ) ; afterEach ( ( ) => { useDefaultCacheStrategy ( ) ; } ) ; runAllTests ( ) ;", "del_tokens": "import { render } from \"../src\" ; describe ( \"caching\" , ( ) => {", "commit_type": "add"}
{"commit_tokens": ["Add", "trigger", "prop", "to", "PopoverMenu"], "add_tokens": "import safeCloneElement from '../../util/safeCloneElement' < PopoverMenu defaultShow trigger = { < Button > < / Button > / ** * the trigger button * / trigger : PropTypes . node , / ** * text to display inside the trigger button * / label : PropTypes . node , const trigger = this . props . trigger || < Button > { label } < / Button > { safeCloneElement ( trigger , { ... trigger . props , role : 'button' , tabIndex : 0 , ref : ( c ) => { this . _trigger = c } , 'aria-haspopup' : true , id : this . labelId } ) }", "del_tokens": "< PopoverMenu defaultShow label = { < div > < / div > label : PropTypes . node . isRequired , < Button { ... pickProps ( this . props , Button . propTypes ) } ref = { ( c ) => { this . _trigger = c } } aria - haspopup id = { this . labelId } > { label } < / Button >", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "where", "two", "consecutive", "slashes", "would", "be", "replaced", "with", "an", "empty", "string", "rather", "than", "a", "single", "slash", "which", "is", "what", "s", "expected"], "add_tokens": ". replace ( doubleSlashRegex , '/' )", "del_tokens": ". replace ( doubleSlashRegex , '' )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "formatting", "according", "to", ".", "editorconfig"], "add_tokens": "unsubscribe ( ) ; self . registered . splice ( self . registered . indexOf ( listenable ) , 1 ) ;", "del_tokens": "unsubscribe ( ) ; self . registered . splice ( self . registered . indexOf ( listenable ) , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "get", "all", "keybindings"], "add_tokens": "* @ param { [ string ] } [ combo ] the key the Hotkey is bound to . Returns all key bindings if no key is passed if ( ! combo ) { return scope . hotkeys ; }", "del_tokens": "* @ param { [ string ] } combo the key the Hotkey is bound to", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "custom", "identity", "function", "in", "array", "merge", "."], "add_tokens": "* | ` ` | ` ` | Function to compare collection elements to see if they are the 'same' . * | ` ` | ` ` | Function to compare objects to see if they are the 'same' . collectionElementFactory : false , collectionElementIdentity : ( a , b ) => a === b , identity : ( a , b ) => a === b options . identity = this . collectionElementIdentity ;", "del_tokens": "collectionElementFactory : false", "commit_type": "add"}
{"commit_tokens": ["Fix", "errors", "setting", "cookies", "to", "be", "non", "-", "fatal"], "add_tokens": "onHeaders ( res , function setHeaders ( ) { if ( sess === undefined ) { return ; } try { if ( sess === false ) { // remove cookies . set ( name , '' , opts ) ; } else if ( ! json && ! sess . length ) { // do nothing if new and not populated } else if ( sess . changed ( json ) ) { // save sess . save ( ) ; } } catch ( e ) { debug ( 'error saving session %s' , e . message ) ;", "del_tokens": "onHeaders ( res , function ( ) { if ( undefined === sess ) { } else if ( false === sess ) { // remove cookies . set ( name , '' , opts ) ; } else if ( ! json && ! sess . length ) { // do nothing if new and not populated } else if ( sess . changed ( json ) ) { // save sess . save ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "postcss", "inlined", "plugin", "config", "work", "with", "webpack", "2"], "add_tokens": "return ( context ) => Object . assign ( { module : { loaders : [ { test : context . fileType ( 'text/css' ) , exclude : Array . isArray ( exclude ) ? exclude : [ exclude ] , loaders : [ 'style-loader' , 'css-loader' , 'postcss-loader?' + JSON . stringify ( postcssOptions ) ] } ] } } , plugins ? createPostcssPluginsConfig ( context . webpack , plugins ) : { } ) } function createPostcssPluginsConfig ( webpack , plugins ) { const isWebpack2 = typeof webpack . validateSchema !== 'undefined' if ( isWebpack2 ) { return { plugins : [ new webpack . LoaderOptionsPlugin ( { options : { postcss : plugins } } ) } else { return { postcss : plugins } }", "del_tokens": "return ( context ) => Object . assign ( { module : { loaders : [ { test : context . fileType ( 'text/css' ) , exclude : Array . isArray ( exclude ) ? exclude : [ exclude ] , loaders : [ 'style-loader' , 'css-loader' , 'postcss-loader?' + JSON . stringify ( postcssOptions ) ] } } , plugins ? { postcss : plugins } : { } )", "commit_type": "make"}
{"commit_tokens": ["Updated", "tests", "for", "WebGME", "update"], "add_tokens": "var TEST_FIXTURE_DIR = 'webgme/test/_globals' ; if ( test ) { // If they are generating test file test . content = test . content . replace ( '../../../globals' , TEST_FIXTURE_DIR ) ; }", "del_tokens": "test . content = test . content . replace ( '../../../_globals' , 'webgme/test/_globals' ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "Travis", "conf", "(", "hopefully", "...", ")"], "add_tokens": "local : { } , travis : { configFile : 'karma.conf.js' , singleRun : true , browsers : [ 'Firefox' , 'PhantomJS' ] 'karma:local' ] ) ; grunt . registerTask ( 'travis' , [ 'dist' , 'karma:travis'", "del_tokens": "lib : { 'karma'", "commit_type": "fix"}
{"commit_tokens": ["add", "bower", "for", "frontend", "packages"], "add_tokens": "const bower = require ( 'gulp-bower' ) ; scripts : 'dist/scripts' , scripts : 'src/scripts/*.js' gulp . watch ( [ paths . dist . html , paths . dist . scripts ] , function ( file ) { gulp . task ( 'copy:scripts' , 'copy scripts' , function ( ) { return gulp . src ( paths . scripts ) . pipe ( cache ( 'scripts' ) ) . pipe ( gulp . dest ( paths . dist . scripts ) ) ; } ) ; gulp . watch ( paths . scripts , [ 'copy:scripts' ] ) ; gulp . task ( 'bower' , function ( ) { return bower ( ) } ) ; 'bower' , 'copy:scripts' ,", "del_tokens": "gulp . watch ( [ paths . dist . html ] , function ( file ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "errors", ".", "json", "files", "separately", "for", "each", "emitter", "test", "suite"], "add_tokens": "var errors = require ( './fixtures/errors' ) ;", "del_tokens": "var errors = require ( '../fixtures/errors' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "more", "generic", "props", "to", "conversationListItem", ":", "titleStyle", "subtitleStyle", ".."], "add_tokens": "titleStyle : row . isNew ? { fontWeight : '500' } : undefined ,", "del_tokens": "isNew : row . isNew ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "assignation", "issue", "on", "false"], "add_tokens": "_ . forEach ( attr , ( v , k ) => { this [ k ] = v } )", "del_tokens": "_ . forEach ( attr , ( v , k ) => this [ k ] = v )", "commit_type": "fix"}
{"commit_tokens": ["updates", "@themost", "/", "xml", "reference"], "add_tokens": "var RandomUtils = require ( '@themost/common/utils' ) . RandomUtils ;", "del_tokens": "var RandomUtils = require ( '@themost/common/utils' ) . PathUtils ;", "commit_type": "update"}
{"commit_tokens": ["Move", "fs", "stuff", "out", "of", "module"], "add_tokens": "var fs = require ( 'fs' ) ; var modules = _ . keys ( scanFile ( String ( fs . readFileSync ( env ) ) ) ) ;", "del_tokens": "var modules = _ . keys ( scanFile ( env ) ) ;", "commit_type": "move"}
{"commit_tokens": ["updating", "documentation", "and", "fixing", "shortcut", "flag", "generator"], "add_tokens": "description : 'execute a command (ex. --execute [ ls -l ./ ])' , description : 'spawn an evented command (captures stdout and stderr as streams, as well as an exit code) (ex. --execute [ ls -l ./ ])' , program . option ( '--somethingElse' ) ; console . log ( '\\n Minimarg Example CLI Program ' + 'v1.0.0' ) ; console . log ( ' Usage: node example/example.js [options]\\n' ) ; var little_one = spawn ( arr [ 0 ] , arr . slice ( 1 ) , { stdio : \"inherit\" } ) ; }", "del_tokens": "description : 'execute a command' , description : 'spawn an evented command (captures stdout and stderr as streams, as well as an exit code)' , console . log ( '\\n Minimarg Test Case ' + 'v1.0.0' ) ; console . log ( ' Usage: node test/test.js [options]\\n' ) ; var little_one = spawn ( arr [ 0 ] , arr . slice ( 1 ) , { stdio : \"inherit\" } ) ; }", "commit_type": "update"}
{"commit_tokens": ["fix", "moving", "file", "to", "history"], "add_tokens": "const moduleid = dataManager . moduleid ; const target = getTargetFilename ( event . filepath , dest ) ; function getTargetFilename ( filepath , target ) { return path . join ( target , ` ${ date } ${ filename } ` ) ;", "del_tokens": "const moduleid = dataManager . moduleid ; const target = getTargetFilename ( event . filepath ) ; function getTargetFilename ( filepath ) { return path . join ( dirname , ` ${ date } ${ filename } ` ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "extra", "script", "output", "moved", "errors", "to", "stderr"], "add_tokens": "console . error ( 'missing module' , module ) ; console . error ( 'missing script source' , module ) ;", "del_tokens": "console . log ( 'missing module' , module ) ; console . log ( 'missing script source' , module ) ; console . log ( newScript ) ;", "commit_type": "remove"}
{"commit_tokens": ["Removed", "reserved", "keys", ".", "No", "longer", "necessary", "."], "add_tokens": "if ( everyType . indexOf ( underlyingType ) < 0 ) { throw new TypeError ( \"Underlying type does not exist. Typo?\" ) ; } else { aliasTypes [ newTypeName ] = underlyingType ; }", "del_tokens": "var reservedKeys = [ '__arr' , '__arrend' , '__obj' , '__objend' ] ; if ( reservedKeys . indexOf ( newTypeName ) > - 1 || reservedKeys . indexOf ( underlyingType ) > - 1 ) { throw new TypeError ( \"Cannot use reserved keys as a type alias or underlying type\" ) ; } else if ( everyType . indexOf ( underlyingType ) < 0 ) { throw new TypeError ( \"Underlying type does not exist. Typo?\" ) ; } else { aliasTypes [ newTypeName ] = underlyingType ; }", "commit_type": "remove"}
{"commit_tokens": ["use", "base", "-", "is", "-", "enabled", "plugin", "for", "isEnabled", "method"], "add_tokens": "this . initDefaults ( ) ; Verbalize . prototype . initDefaults = function ( ) { this . addMode ( 'verbose' ) ; this . addMode ( 'not' , { mode : 'toggle' } ) ; } ; this . use ( colors ( this . options ) ) ; this . use ( styles ( this . options ) ) ; this . use ( utils . isEnabled ( this . options ) ) ; this . use ( handler ( this . options ) ) ;", "del_tokens": "var isEnabled = require ( './plugins/is-enabled' ) ; this . use ( colors ( ) ) ; this . use ( styles ( ) ) ; this . use ( isEnabled ( ) ) ; this . use ( handler ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "another", "error", "in", "the", "spec", "tests", "for", "utimes"], "add_tokens": "var complete = false ; var that = this ; that . fs . mkdir ( '/testdir' , function ( error ) { that . fs . utimes ( '/testdir' , atime , mtime , function ( error ) {", "del_tokens": "var complete = false //Note: required as the filesystem somehow gets removed from the Jasmine object var fs = this . fs ; fs . mkdir ( '/testdir' , function ( error ) { fs . utimes ( '/testdir' , atime , mtime , function ( error ) { delete fs ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "nested", "else", "statements", "properly"], "add_tokens": "nestedConditionals = matches [ i ] . match ( / [\\s|\\S]<!-- IF[\\s\\S]*ENDIF[\\s\\S]*-->[\\s|\\S] / ) , match = matches [ i ] . replace ( statement , '' ) . replace ( / [\\s|\\S]<!-- IF[\\s\\S]*ENDIF[\\s\\S]*-->[\\s|\\S] / , '<!-- NESTED -->' ) ,", "del_tokens": "nestedConditionals = matches [ i ] . match ( / \\s<!-- IF[\\s\\S]*ENDIF[\\s\\S]*-->\\s / ) , match = matches [ i ] . replace ( statement , '' ) . replace ( / <!-- IF[\\s\\S]*ENDIF[\\s\\S]*--> / , '<!-- NESTED -->' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Random", "interface", "to", "matrix", "+", "add", "next", "gaussian"], "add_tokens": "/// <p> /// <p> /// http://www.apache.org/licenses/LICENSE-2.0 /// <p> /// <p> /// <p> /// http://www.apache.org/licenses/LICENSE-2.0 /// <p>", "del_tokens": "/// /// /// http://www.apache.org/licenses/LICENSE-2.0 /// /// /// /// http://www.apache.org/licenses/LICENSE-2.0 ///", "commit_type": "fix"}
{"commit_tokens": ["remove", "unimplemented", "timeout", "stuff", "so", "that", "it", "isn", "t", "confusing"], "add_tokens": "\"l\" : 49495 \"l\" : \"loggerport\"", "del_tokens": "\"l\" : 49495 , \"t\" : 500 \"t\" : \"time before timeout in milliseconds\" , \"l\" : \"loggerport\" , \"t\" : \"timeout\" options . timeout = argv . timeout ; / * var enablePlugins = argv . use ? argv . use . split ( \" \" ) : false ; var disablePlugins = argv . nuse ? argv . nuse . split ( \" \" ) : [ ] ; var activePlugins = theGenerator . loadPlugins ( enablePlugins , disablePlugins ) ; logger . log ( \"init\" , \"app\" , \"loaded plugins\" , activePlugins ) ; * /", "commit_type": "remove"}
{"commit_tokens": ["add", "failing", "provider", "test", "(", "thanks", "@wayofspark", ")"], "add_tokens": "// provider, provider $get myMod . provider ( \"foo\" , function ( $scope ) {", "del_tokens": "// provider $get myMod . provider ( \"foo\" , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["updating", "gruntfile", "to", "reflect", "dest", "changes"], "add_tokens": "'test/actual/' : [ 'test/files/extend.hbs' ] 'test/actual/yaml/' : [ 'test/yaml/*.hbs' ]", "del_tokens": "'test/actual' : [ 'test/files/extend.hbs' ] 'test/actual/yaml' : [ 'test/yaml/*.hbs' ]", "commit_type": "update"}
{"commit_tokens": ["Add", ".", "jpg", "to", "icon", "types"], "add_tokens": "var iconFileExtensions = [ \".png\" , \".gif\" , \".svg\" , \".ico\" , \".jpg\" ] ;", "del_tokens": "var iconFileExtensions = [ \".png\" , \".gif\" , \".svg\" , \".ico\" ] ;", "commit_type": "add"}
{"commit_tokens": ["fix", "^", "/", "regexp", "and", "last", "/"], "add_tokens": "var routePath = conf . prefix ; if ( ! / \\/$ / . test ( conf . prefix ) && ctrl . ctrlName ) { routePath += '/' ; routePath += ctrl . ctrlName + route . path ; this . route ( route . method , name , routePath || '/' , ctrl [ handler ] , handler ) ; conf . prefix = / ^\\^?\\\\?\\/ / . test ( prefix . source ) ? prefix . source : '/' + prefix . source ;", "del_tokens": "if ( ! / \\/$ / . test ( conf . prefix ) ) { conf . prefix += '/' ; var routePath = conf . prefix + ctrl . ctrlName + route . path ; this . route ( route . method , name , routePath , ctrl [ handler ] , handler ) ; conf . prefix = / ^\\/ / . test ( prefix . source ) ? prefix . source : '/' + prefix . source ;", "commit_type": "fix"}
{"commit_tokens": ["add", "logs", "to", "middleware", "requests"], "add_tokens": "entries = entries || [ ]", "del_tokens": "// if (entries.length === 0) { // return bail('no entry files specified!') // } function bail ( msg ) { process . nextTick ( function ( ) { emitter . emit ( 'error' , new Error ( msg ) ) } ) return emitter }", "commit_type": "add"}
{"commit_tokens": ["Move", "addButtonVisible", "saveButtonVisible", "&", "clearButtonEnabled", "to", "functions", "and", "amend", "unit", "tests", "accordingly"], "add_tokens": "// todo: could be cleverer about clearing in case some graphs haven't changed $scope . addButtonVisible = function ( ) { return $scope . selectedMetric != \"\" ; } ; $scope . saveButtonVisible = function ( ) { return $scope . selectedMetricId != \"0\" ; } ; $scope . clearButtonEnabled = function ( ) { return $scope . addButtonVisible ( ) || $scope . saveButtonVisible ( ) ; } ; $scope . selectedMetricId = \"0\" ;", "del_tokens": "// todo: ould be cleverer about clearing in case some graphs haven't changed $scope . clearButtonEnabled = false ; $scope . addButtonVisible = false ; $scope . saveButtonVisible = false ; $scope . addButtonVisible = valid ; $scope . clearButtonEnabled = valid ; $scope . saveButtonVisible = ! valid ; $scope . addButtonVisible = false ; $scope . saveButtonVisible = true ; $scope . clearButtonEnabled = true ; $scope . addButtonVisible = false ; $scope . saveButtonVisible = false ; $scope . clearButtonEnabled = false ; $scope . clearButtonEnabled = true ; $scope . saveButtonVisible = true ; $scope . addButtonVisible = false ; $scope . selectedMetricId = \"\" ;", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "ES6", "class", "instances", "passed", "to", "defineAll", "."], "add_tokens": "if ( ! obj ) { return this ; } function checkSkipProperty ( prop , name ) { return ( typeof prop !== 'function' || name . substr ( 0 , 1 ) === '_' || ( methodNames && methodNames . indexOf ( name ) == - 1 ) ) ; } if ( ! obj . hasOwnProperty ( i ) || checkSkipProperty ( obj [ i ] , i ) ) { var systemStuff = Object . getOwnPropertyNames ( { } . constructor . prototype ) ; Object . getOwnPropertyNames ( obj . constructor . prototype ) . forEach ( function ( i ) { if ( systemStuff . indexOf ( i ) > - 1 || obj . hasOwnProperty ( i ) || checkSkipProperty ( obj [ i ] , i ) ) { return ; } this . define ( i , obj [ i ] ) ; } . bind ( this ) ) ;", "del_tokens": "if ( ! obj ) return this ; if ( typeof obj [ i ] !== 'function' || i . substr ( 0 , 1 ) === '_' || ( methodNames && methodNames . indexOf ( i ) == - 1 ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "regression", "which", "caused", "gradients", "with", "more", "than", "3", "colors", "to", "fail"], "add_tokens": "percent = Math . round ( ( 100 / ( stops - 1 ) ) * ( i - 1 ) ) / 100 ;", "del_tokens": "percent = Math . round ( ( stops - 1 ) * ( i - 1 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "base", "instead", "of", "use", "lib"], "add_tokens": "require ( 'base-plugins' , 'plugins' ) ; require ( 'isobject' , 'isObject' ) ; require ( 'is-scaffold' ) ;", "del_tokens": "/ ** * Module dependencies * / require ( 'is-scaffold' ) ; / ** * Restore ` ` * /", "commit_type": "use"}
{"commit_tokens": ["Update", "mac", "-", "address", "dependency", "and", "use", "the", "new", "LENGTH", "constant", "when", "working", "with", "MAC", "values", "."], "add_tokens": "bytes += mac . LENGTH ;", "del_tokens": "bytes += 6 ;", "commit_type": "update"}
{"commit_tokens": ["Added", "xlink", "namespace", "to", "defs", "template"], "add_tokens": "defs : '<svg{:styles:} xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs>{:shapes:}</defs></svg>'", "del_tokens": "defs : '<svg{:styles:} xmlns=\"http://www.w3.org/2000/svg\"><defs>{:shapes:}</defs></svg>'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "CellTracGTS", "AndroidID", "to", "MMSI", "mapping"], "add_tokens": "if ( isNaN ( devid ) ) devid = parseInt ( query . id , 16 ) / 1000 ;", "del_tokens": "if ( isNaN ( devid ) ) devid = parseInt ( query . id , 16 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "partial", "args", "to", "invoker"], "add_tokens": "L . meth = L . walterWhite = L . invoker = function ( method /*, args*/ ) { var pargs = _ . rest ( arguments ) ; return targetMethod . apply ( target , L . cat ( pargs , _ . rest ( arguments ) ) ) ;", "del_tokens": "L . meth = L . walterWhite = L . invoker = function ( method ) { return targetMethod . apply ( target , _ . rest ( arguments ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "debug", "and", "enable", "option"], "add_tokens": "var debug = options . debug ; debug ( err ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "custom", "PostCSS", "options"], "add_tokens": "* @ param { PostCSSPlugin [ ] } [ plugins ] Will read ` ` file if not supplied . * @ param { RegExp | Function | string } [ options . exclude ] Directories to exclude . * @ param { string } [ options . parser ] Package name of custom PostCSS parser to use . * @ param { string } [ options . stringifier ] Package name of custom PostCSS stringifier to use . * @ param { string } [ options . syntax ] Package name of custom PostCSS parser / stringifier to use . // https://github.com/postcss/postcss-loader#options const postcssOptions = Object . assign ( { } , options . parser && { parser : options . parser } , options . stringifier && { stringifier : options . stringifier } , options . syntax && { syntax : options . syntax } ) loaders : [ 'style-loader' , 'css-loader' , 'postcss-loader?' + JSON . stringify ( postcssOptions ) ]", "del_tokens": "* @ param { PostCSSPlugin [ ] } [ plugins ] Will read ` ` file if not supplied . * @ param { RegExp , Function , string } [ options . exclude ] Directories to exclude . loaders : [ 'style-loader' , 'css-loader' , 'postcss-loader' ]", "commit_type": "add"}
{"commit_tokens": ["add", "async", "func", "call", "caching", "management", "class"], "add_tokens": "Query = require ( './query' ) , Cache = require ( './cache' ) ; conn . _cache . enableCaching ( this , \"describe\" , { key : \"describe.\" + this . type } ) ;", "del_tokens": "Query = require ( './query' ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "model", "use", "the", "same", "connection", "when", "invoked", "in", "transactions"], "add_tokens": "if ( name === undefined ) return this ; / ** * get relation data * @ param { Array | Object } data * / // make model use the same connection when invoked in transactions model . db ( this . model . db ( ) ) ; // change the default key & fKey", "del_tokens": "if ( name === undefined ) { return this ; } // change default key & fKey", "commit_type": "use"}
{"commit_tokens": ["updates", "to", "fix", "var", "instantiation", "bugs"], "add_tokens": "if ( cfg . hasOwnProperty ( \"recordStores\" ) && cfg . recordStores !== undefined ) { lrsCfg = { } , contextCfg . contextActivities = { } ;", "del_tokens": "if ( cfg . hasOwnProperty ( \"recordStores\" ) && cfg . recordStores . length > 0 ) { lrsCfg ,", "commit_type": "update"}
{"commit_tokens": ["allow", "editor", "to", "limp", "along", "a", "bit", "more", "for", "testing", "before", "converting", "it", "to", "use", "the", "new", "shared", "class_expression", "library"], "add_tokens": "if ( t == 'class' ) { if ( type [ 'union' ] ) { } else if ( type [ 'intersection' ] ) { var f_set = in_type [ t ] || [ ] ; this . _category = in_type [ 'property' ] [ 'id' ] ; this . _property_id = in_type [ 'property' ] [ 'id' ] ; in_type [ 'property' ] [ 'label' ] || this . _property_id ; var f_type = in_type [ 'svf' ] ;", "del_tokens": "if ( t == 'Class' ) { if ( type [ 'unionOf' ] ) { } else if ( type [ 'intersectionOf' ] ) { var f_set = in_type [ t + 'Of' ] || [ ] ; this . _category = in_type [ 'onProperty' ] [ 'id' ] ; this . _property_id = in_type [ 'onProperty' ] [ 'id' ] ; in_type [ 'onProperty' ] [ 'label' ] || this . _property_id ; var f_type = in_type [ 'someValuesFrom' ] ;", "commit_type": "allow"}
{"commit_tokens": ["use", "define", "in", "namespace", ".", "js"], "add_tokens": "( function ( exports ) { 'use strict' ; const moduleName = 'es6lib/namespace' ; if ( typeof module !== 'undefined' ) { module . exports = exports ; } else if ( typeof define === 'function' ) { define ( moduleName , exports ) ; } else if ( typeof window !== 'undefined' && typeof module === 'undefined' ) { window [ moduleName ] = exports ; } return exports ; } ) ( { } ) ;", "del_tokens": "'use strict' ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "empty", "partitionKey", "and", "rowKey"], "add_tokens": "assert ( partitionKey !== undefined && partitionKey !== null , \"PartitionKey is required\" ) ; assert ( rowKey !== undefined && rowKey !== null , \"RowKey is required\" ) ;", "del_tokens": "assert ( partitionKey , \"PartitionKey is required\" ) ; assert ( partitionKey , \"RowKey is required\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "automatic", "API", "port", "selection"], "add_tokens": "options . apiHostname = options . apiHostname || 'mandrillapp.com' ; options . apiPort = options . apiPort || ( options . apiSecure ? 443 : 80 ) ;", "del_tokens": "options . apiHostname = options . apiHostname || 'mandrillapp.com' ; options . apiPort = options . apiPort || ( options . apiSecure ? 443 : 80 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "getUrl", "function", "signature", "not", "matching", "its", "use", "in", "getRequest"], "add_tokens": "let demoUrl = utils . getUrl ( opts ) ;", "del_tokens": "let demoUrl = utils . getUrl ( opts . version , opts . project ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "login", "fields", "check", "email", "first"], "add_tokens": "// IMPORTANT: must check for email first if ( args . email ) { q . email = args . email valid = true } else if ( args . nick ) { var login = loginent . make$ ( seneca . util . argprops ( // DEPRECATED - do this in seneca-auth", "del_tokens": "if ( args . nick ) { else { q . email = args . email valid = true } var login = loginent . make$ ( seneca . util . deepextend ( // DEPRECATED", "commit_type": "fix"}
{"commit_tokens": ["fixed", "badges", "fixed", "module", "loading"], "add_tokens": "var mockServer = require ( '../../' ) ,", "del_tokens": "var mockServer = require ( '../../mockserver-client' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Updated", "code", "comments", "on", "el", ".", "eventID", "()", "."], "add_tokens": "* @ param obj { object } The element whose listener called this function . * @ returns { string } The id of the element that triggered the event .", "del_tokens": "* @ param obj { object } The element / object that triggered the event .", "commit_type": "update"}
{"commit_tokens": ["Use", "localhost", "not", "sbisbee", ".", "cloudant", ".", "com", "."], "add_tokens": "url : 'http://admin:passwd@localhost:5984/sag' , host : 'localhost' ,", "del_tokens": "url : 'http://admin:passwd@sbisbee.cloudant.com:5984/sag' , host : 'sbisbee.cloudant.com' ,", "commit_type": "use"}
{"commit_tokens": ["Use", "istanbul", "API", "instead", "of", "shell", ".", "exec", "b", "/", "c", "incompatible", "w", "/", "npm", "install", "--", "save", "-", "dev", "solcover"], "add_tokens": "const istanbul = require ( 'istanbul' ) ; const istanbulCollector = new istanbul . Collector ( ) ; const istanbulReporter = new istanbul . Reporter ( ) ; // 1. Generate file path reference for coverage report istanbulCollector . add ( coverage . coverage ) ; istanbulReporter . addAll ( [ 'lcov' , 'html' ] ) ; istanbulReporter . write ( istanbulCollector , false , ( ) => { log ( 'Istanbul coverage reports generated' ) ; } ) ;", "del_tokens": "// 1. Generate reference to its real path (this identifies it in the reports) const istanbul = ` ${ modulesDir } ${ silence } ` ; shell . exec ( istanbul ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "an", "example", "for", "increasing", "skipLevel", "to", "mkread", ".", "js"], "add_tokens": "var nodes = getCandidateSiblings ( ) ; ret . textLength = 0 ; for ( var i = 0 , j = nodes . length ; i < j ; i ++ ) ret . textLength += nodes [ i ] . info . textLength ; if ( type === \"text\" ) ret . text = getText ( nodes ) ; else ret . html = getCleanedContent ( getInnerHTML ( nodes ) ) ;", "del_tokens": "//else if(window && window.alert) window.alert(msg); else if ( type === \"text\" ) ret . text = getInnerText ( topCandidate ) ; else { var nodes = getCandidateSiblings ( ) ; ret . textLength = 0 ; for ( var i = 0 , j = nodes . length ; i < j ; i ++ ) ret . textLength += nodes [ i ] . info . textLength ; ret . html = getCleanedContent ( getInnerHTML ( nodes ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "webpack", "3"], "add_tokens": "const uploadFiles = ( compilation , callback ) => { } ; // For webpack >= 4 if ( compiler . hooks ) { compiler . hooks . afterEmit . tapAsync ( 'QiniuWebpackPlugin' , uploadFiles ) ; } // For webpack < 4 else { compiler . plugin ( 'after-emit' , uploadFiles ) ; }", "del_tokens": "compiler . hooks . afterEmit . tapAsync ( 'QiniuWebpackPlugin' , ( compilation , callback ) => { } ) ;", "commit_type": "add"}
{"commit_tokens": ["removing", "unnecessary", "assert", "from", "run", "sku", "graph", "job"], "add_tokens": "self . nodeId ) ;", "del_tokens": "self . nodeId ) . then ( function ( message ) { assert . uuid ( message ) ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "tests", "loading", "Sequelize", "twice"], "add_tokens": "Sequelize = Support . Sequelize ,", "del_tokens": "Sequelize = require ( 'sequelize' ) , require ( '../lib/' ) ( Sequelize ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "dnd", "date", "merge", "when", "moving", "an", "event", "to", "a", "date", "cell"], "add_tokens": "const nextStart = type === 'dateCellWrapper'", "del_tokens": "const nextStart = type === 'dateWrapper'", "commit_type": "fix"}
{"commit_tokens": ["fixed", "circular", "object", "reference", "in", "field", "binding"], "add_tokens": "b . fields = { } ; Object . keys ( f . fields ) . forEach ( function ( k ) { b . fields [ k ] . validate ( b , function ( err , bound_field ) {", "del_tokens": "b . fields = f . fields ; Object . keys ( b . fields ) . forEach ( function ( k ) { f . fields [ k ] . validate ( b , function ( err , bound_field ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "real", "unique", "id", "when", "adding", "an", "entity"], "add_tokens": "var shortid = require ( 'shortid' ) ; data . id = shortid . generate ( ) ;", "del_tokens": "data . id = String ( Date . now ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "change", "error", "logs", "to", "tessel", ".", "logs", ".", "error"], "add_tokens": ", tessel = require ( 'tessel' ) tessel . logs . error ( err ) ; . catch ( function ( err ) { if ( err instanceof Error ) { throw err ; } ; tessel . logs . error ( err ) ;", "del_tokens": "console . error ( err ) ; . catch ( function ( error ) { console . error ( error ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "String", ".", "prototype", ".", "repeat", "ES6", "dependency", "."], "add_tokens": "return new Array ( Math . max ( this . path . length , 0 ) * 2 + 1 ) . join ( \" \" ) ;", "del_tokens": "return \" \" . repeat ( Math . max ( this . path . length , 0 ) * 2 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "spaces", "at", "end", "of", "line"], "add_tokens": "] ,", "del_tokens": "] ,", "commit_type": "remove"}
{"commit_tokens": ["fixed", "closing", "bracket", "for", "url", "not", "showing"], "add_tokens": "return \"url(\" + ( this . value . toCSS ? this . value . toCSS ( ) : this . value ) + \")\" ;", "del_tokens": "return \"url(\" + ( this . value . toCSS ? this . value . toCSS ( ) : this . value + \")\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "render", "(", "force", ")"], "add_tokens": "DT . debug ( \"nodeRender(\" + ! ! force + \", \" + ! ! deep + \")\" , node . toString ( ) ) ; node . ul = null ; case \"minExpandLevel\" : case \"nolink\" : this . tree . render ( true , false ) ; // force, not-deep return true ; if ( opts . disabled ) { return true ; }", "del_tokens": "// DT.debug(\"nodeRender\", node.toString()); case \"disabled\" : // handle enable/disable break ; case \"keyboard\" : break ; this . tree . render ( true , true ) ; return false ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "in", "interpolation", ".", "Len5"], "add_tokens": "3 * ( this . h + this . j ) ,", "del_tokens": "3 * ( this . h + this . k ) ,", "commit_type": "fix"}
{"commit_tokens": ["updated", "clean", "to", "delete", "anywhere"], "add_tokens": "] , { force : true } , cb ) ;", "del_tokens": "] , cb ) ;", "commit_type": "update"}
{"commit_tokens": ["use", "x", "-", "prefix", "for", "custom", "swagger", "spec", "fields", "added", "test", "for", "discriminator", "maps"], "add_tokens": "var apiToServe = _ . cloneDeep ( specs [ specName ] ) ; //clone it since we'll be modifying the host var polyMorphicValidationErrors = swaggerUtil . validateIndividualObjects ( swaggerDoc , parm [ 'x-map' ] , req . body ) ; mapPath = 'responses.%s.x-map' ,", "del_tokens": "var apiToServe = _ . cloneDeep ( prettySpec [ specName ] ) ; //clone it since we'll be modifying the host var polyMorphicValidationErrors = swaggerUtil . validateIndividualObjects ( swaggerDoc , parm . map , req . body ) ; mapPath = 'responses.%s.map' ,", "commit_type": "use"}
{"commit_tokens": ["Add", "econtent", "test", "and", "small", "cleanups", "."], "add_tokens": "return _ . flatten ( _ . union ( eOperations || [ ] , _ . map ( superTypes || [ ] , function ( s ) { return eAllOperations ( s ) ; } ) ) ) ; var eModel = this . eResource ( ) ; return ( eModel ? eModel . get ( 'uri' ) : '' ) + '#' + this . fragment ( ) ;", "del_tokens": "var all = _ . flatten ( _ . union ( eOperations || [ ] , _ . map ( superTypes || [ ] , function ( s ) { return eAllOperations ( s ) ; } ) ) ) ; return all ; options = arguments [ 2 ] ; var featureName ; var eModel = this . eResource ( ) , current = this ; return eModel . get ( 'uri' ) + '#' + this . fragment ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "?", "from", "flow", "when", "default", "value", "is", "set"], "add_tokens": "// Remove ? if default value is set var type = funcNode . jsdoc . params [ i ] . type . replace ( / ^\\? / , '' ) ; param . left . source ( ) + \": \" + type + ' = ' + param . right . source ( )", "del_tokens": "console . log ( funcNode . jsdoc . params [ i ] . type ) ; param . left . source ( ) + \": \" + funcNode . jsdoc . params [ i ] . type + ' = ' + param . right . source ( )", "commit_type": "remove"}
{"commit_tokens": ["Implement", "maxDataSize", "and", "error", "handling"], "add_tokens": "this . maxDataSize = undefined ; combinedStream . maxDataSize = options . maxDataSize ; stream = DelayedStream . create ( stream , this . maxDataSize ) ; this . _register ( stream ) ; this . _register ( stream ) ; stream . on ( 'end' , this . _getNext . bind ( this ) ) CombinedStream . prototype . _register = function ( stream ) { var self = this ; stream . on ( 'error' , function ( err ) { self . _reset ( ) ; self . emit ( 'error' , err ) ; } ) ; } ; this . _reset ( ) ; this . emit ( 'end' ) ; } ; CombinedStream . prototype . destroy = function ( ) { this . _reset ( ) ; this . emit ( 'close' ) ; } ; CombinedStream . prototype . _reset = function ( ) {", "del_tokens": "stream = DelayedStream . create ( stream ) ; stream . on ( 'end' , function ( ) { this . _getNext ( ) ; } . bind ( this ) ) ; this . emit ( 'end' ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "file", "plugin", "to", "module", ".", "js", "and", "to", "testing"], "add_tokens": "'ngCordova.plugins.statusbar' , 'ngCordova.plugins.file'", "del_tokens": "'ngCordova.plugins.statusbar'", "commit_type": "add"}
{"commit_tokens": ["move", "params", "handling", "in", "function", ";", "remove", "global", "parent", ";", "allow", "null", "params"], "add_tokens": "function prepareParams ( options , types , parent ) { var params = Params . normalize ( options . params , types ) ; if ( parent ) { for ( var key in parent . params ) { if ( params [ key ] ) continue ; params [ key ] = parent . params [ key ] ; } } return params ; } var params = prepareParams ( options , types , parent ) ;", "del_tokens": "parent = parent || { } ; var params = options . params || { } ; params = Params . normalize ( params , types ) ; for ( var key in parent . params ) { if ( params [ key ] ) continue ; params [ key ] = parent . params [ key ] ; }", "commit_type": "move"}
{"commit_tokens": ["Add", "origin", "strings", "to", "function", "and", "object", "types"], "add_tokens": "if ( type . types ) for ( var i = 0 ; i < type . types . length && ! def ; ++ i ) def = type . types [ i ] . originNode ; else def = type . originNode ;", "del_tokens": "if ( type . types ) for ( var i = 0 ; i < type . types . length && ! def ; ++ i ) def = type . types [ i ] . origin ; else def = type . origin ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "getting", "language", "&", "Don", "t", "use", "the", "cmnd", "for", "exporting", "because", "it", "blocks", "vbole"], "add_tokens": "{ type : 'keys' , command : '%' + that . app . menuKey ( 'file' ) + '{DOWN}' + that . app . menuKey ( 'export' ) } , { type : 'sleep' , command : 900 } ,", "del_tokens": "{ type : 'caos' , command : 'inst,sys: cmnd 32863,endm' } , { type : 'sleep' , command : 500 } ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "bender", "-", "scoped", "assert", "bindings", "."], "add_tokens": "bender . assert . areSame ( html_beautify ( expected , this . _config ) , html_beautify ( actual , this . _config ) , msg ) ; bender . assert . areSame ( js_beautify ( expected , this . _config ) , js_beautify ( actual , this . _config ) , msg ) ;", "del_tokens": "assert . areSame ( html_beautify ( expected , this . _config ) , html_beautify ( actual , this . _config ) , msg ) ; assert . areSame ( js_beautify ( expected , this . _config ) , js_beautify ( actual , this . _config ) , msg ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "null", "exception", "when", "converting", "profileImageUrl"], "add_tokens": "profileImageURL : user . getPhotoUrl ( ) ? user . getPhotoUrl ( ) . toString ( ) : null profileImageURL : user . getPhotoUrl ( ) ? user . getPhotoUrl ( ) . toString ( ) : null", "del_tokens": "profileImageURL : user . getPhotoUrl ( ) . toString ( ) profileImageURL : user . getPhotoUrl ( ) . toString ( )", "commit_type": "fix"}
{"commit_tokens": ["adding", "frictionFactor", "and", "minVelocityToKeepDecelerating", "to", "the", "optionsso", "that", "they", "can", "be", "controlled", "without", "being", "tied", "to", "the", "library"], "add_tokens": "penetrationAcceleration : 0.08 , /** This configures scrolling friction **/ frictionFactor : 0.95 , /** This configures the minimum velocity that is needed to keep on decelerating **/ minVelocityToKeepDecelerating : 0.1 , var minVelocityToKeepDecelerating = self . options . snapping ? 4 : self . options . minVelocityToKeepDecelerating ; var frictionFactor = self . options . frictionFactor ;", "del_tokens": "penetrationAcceleration : 0.08 var minVelocityToKeepDecelerating = self . options . snapping ? 4 : 0.1 ; var frictionFactor = 0.95 ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "the", "configuration", "files", "to", "a", "dedicated", "folder"], "add_tokens": "out : join ( __dirname , '../doc/api' )", "del_tokens": "out : join ( __dirname , 'api' )", "commit_type": "move"}
{"commit_tokens": ["fixing", "bug", "with", "mutating", "cache"], "add_tokens": "var gotCreated = false ; var gotUpdated = false ; gotCreated = true ; gotUpdated = true ; } if ( gotCreated ) { triggerLifecycle ( elementCache . element , props , 'created' ) ; } else if ( gotUpdated ) { triggerLifecycle ( elementCache . element , props , 'updated' ) ; if ( shouldRecycleElement ( element , props , tag ) === false ) { if ( newVersion === 0 ) { triggerLifecycle ( element , props , 'created' ) ; } if ( newVersion > 0 ) { triggerLifecycle ( element , props , 'updated' ) ; } try { parentElement . appendChild ( newElement ) ; } catch ( e ) { console . error ( e ) ; } return ! isTextNode ( oldElement ) && oldElement . id === \"\" && ! nodeTypeDiffers ( oldElement , tag ) ;", "del_tokens": "if ( newVersion === 0 ) { triggerLifecycle ( newElement , props , 'created' ) ; } if ( newVersion > 0 ) { triggerLifecycle ( newElement , props , 'updated' ) ; } if ( shouldRecycleElement ( element , props , tag ) ) { parentElement . appendChild ( newElement ) ; return oldElement . id === \"\" && nodeTypeDiffers ( oldElement , tag ) ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "sure", "the", "code", "passes", "jsHint"], "add_tokens": "//If the currently matched option is visible if ( self . listItems . eq ( currentOption ) . is ( \":visible\" ) ) { self . selectBox . trigger ( \"change\" ) ; } //Hides the first option in the dropdown list //Shows the first option in the dropdown list //Shows the first option in the dropdown list //Hides the first option in the dropdown list", "del_tokens": "//If the currently matched option is not visible, then do not allow it to be selected as an option if ( ! self . listItems . eq ( currentOption ) . is ( \":visible\" ) ) { } //If the currently matched option is visible else { self . selectBox . trigger ( \"change\" ) ; } //Hides the first option in the dropdown list //Shows the first option in the dropdown list //Shows the first option in the dropdown list //Hides the first option in the dropdown list", "commit_type": "make"}
{"commit_tokens": ["remove", "ru", "for", "front", "app"], "add_tokens": "const supportedLanguage = [ 'en' , 'fr' ] let lang = req . acceptsLanguages ( 'en' , 'en-US' , 'en-UK' , 'fr' , 'fr-FR' )", "del_tokens": "const supportedLanguage = [ 'en' , 'fr' , 'ru' ] let lang = req . acceptsLanguages ( 'en' , 'en-US' , 'en-UK' , 'fr' , 'fr-FR' , 'ru' , 'ru-RU' )", "commit_type": "remove"}
{"commit_tokens": ["Add", "callback", "to", ".", "end", "()", "method"], "add_tokens": "* @ param { Function } cb Squeak . prototype . end = function ( cb ) { if ( cb ) { cb ( ) ; }", "del_tokens": "Squeak . prototype . end = function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "method", "to", "modify", "result", "before", "and", "after", "format", "and", "fixing", "formatResults", "method", "."], "add_tokens": "var config = collections [ collectionName ] . config ; if ( _ . isFunction ( config . beforeFormat ) ) { config . beforeFormat ( result ) ; } if ( _ . isFunction ( config . afterFormat ) ) { config . afterFormat ( result ) ; } formatResult ( result , collectionName ) ; } , beforeFormat : null , afterFormat : null methods : _ . extend ( { } , collection . defaults . methods , c . methods ) , beforeFormat : c . beforeFormat , afterFormat : c . afterFormat", "del_tokens": "formatResult ( results , collectionName ) ; } methods : _ . extend ( { } , collection . defaults . methods , c . methods )", "commit_type": "add"}
{"commit_tokens": ["remove", "envelope", "logic", "from", "req", "/", "res"], "add_tokens": "var id = msg . pop ( ) ; args . push ( id ) ; sock . write ( self . pack ( args ) ) ;", "del_tokens": "var envelopes = [ ] ; for ( var i = 0 ; i < msg . length ; ++ i ) { if ( '\\u0000' === String ( msg [ i ] ) ) { envelopes = msg . splice ( 0 , ++ i ) ; } } sock . write ( self . pack ( envelopes . concat ( args ) ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["update", "various", "deps", "remove", "ejson", "dep"], "add_tokens": "\"plugins\" : [ \"es5\" ] , \"extends\" : [ \"eslint:recommended\" , \"plugin:es5/no-es2015\" ] ,", "del_tokens": "\"extends\" : \"eslint:recommended\" , \"func-style\" : [ \"error\" , \"declaration\" ] , \"no-undefined\" : \"error\" ,", "commit_type": "update"}
{"commit_tokens": ["use", "the", "right", "constructor", "for", "sync", "scheduler"], "add_tokens": "var syncSchedulerModule = require ( './sync-scheduler' ) ; var syncLockModule = require ( './lock' ) ; //TODO: remove redisClient. We probably don't need it anymore var syncLock = null ; syncStorage = storageModule ( ) ; syncLock = syncLockModule ( ) ; var SyncScheduler = syncSchedulerModule ( syncLock , syncStorage , metricsClient ) . SyncScheduler ; syncScheduler = new SyncScheduler ( syncQueue ) ;", "del_tokens": "var SyncScheduler = require ( './sync-scheduler' ) . SyncScheduler ; var datasetClientsCacheKey = 'sync:datasetClients' ; syncStorage = storageModule ( redisClient ) ; syncScheduler = new SyncScheduler ( redisClient , datasetClientsCacheKey ) ;", "commit_type": "use"}
{"commit_tokens": ["removed", "minutes", ".", "io", "from", "dummy", "data", ".", "Fixes", "https", ":", "//", "github", ".", "com", "/", "hoodiehq", "/", "my", "-", "first", "-", "hoodie", "/", "issues", "/", "6"], "add_tokens": "name : \"appName (not implemented yet)\"", "del_tokens": "name : \"minutes.io\"", "commit_type": "remove"}
{"commit_tokens": ["Added", "/", "element", "/", "_id_", "/", "name", "and", "/", "element", "/", "_id_", "/", "attribute", "/", "_attribute", "-", "name_", "GET", "commands"], "add_tokens": "DISPLAYED : \"displayed\" , ATTRIBUTE_DIR : \"/attribute/\" , NAME : \"name\" } else if ( req . urlParsed . path . indexOf ( _const . ATTRIBUTE_DIR ) != - 1 && req . method === \"GET\" ) { _getAttributeCommand ( req , res ) ; return ; } else if ( req . urlParsed . file === _const . NAME && req . method === \"GET\" ) { _getNameCommand ( req , res ) ; return ; _getNameCommand = function ( req , res ) { var result = _session . getCurrentWindow ( ) . evaluate ( require ( \"./webdriver_atoms.js\" ) . get ( \"execute_script\" ) , \"return arguments[0].tagName;\" , [ _getJSON ( ) ] ) ; // N.B. must convert value to a lowercase string as per WebDriver JSONWireProtocol spec if ( result . status === 0 ) result . value = result . value . toLowerCase ( ) ; res . respondBasedOnResult ( _session , req , result ) ; } , _getAttributeCommand = function ( req , res ) { var attributeValueAtom = require ( \"./webdriver_atoms.js\" ) . get ( \"get_attribute_value\" ) ; var attributeName = req . urlParsed . file ; var response = _session . getCurrentWindow ( ) . evaluate ( attributeValueAtom , _getJSON ( ) , attributeName ) ; res . respondBasedOnResult ( _session , req , response ) ; } ,", "del_tokens": "DISPLAYED : \"displayed\"", "commit_type": "add"}
{"commit_tokens": ["changed", "default", "server", "port", "to", "3001"], "add_tokens": "var compareReportURL = 'http://localhost:3001/compare/' ;", "del_tokens": "var compareReportURL = 'http://localhost:3000/compare/' ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "node", "boundaries", "for", "unexpected", "regular", "expressions"], "add_tokens": "if ( ! forceRegexp ) tokStart = tokPos ; else tokPos = tokStart + 1 ;", "del_tokens": "tokStart = tokPos ;", "commit_type": "fix"}
{"commit_tokens": ["added", "out", "of", "bound", "error"], "add_tokens": "var staticProps = require ( 'static-props' ) var pkg = require ( './package.json' ) / ** * Prepend package name to error message * / function msg ( str ) { return pkg . name + ': ' + str } var error = { } staticProps ( error ) ( { outOfBoundIndex : msg ( 'Index exceeds its bound' ) } ) * Maps multidimensional array indices to monodimensional array index console . log ( arguments ) // Check that indices fit inside dimensions shape. for ( var i = 0 ; i < dimensions . length ; i ++ ) { if ( indices [ i ] > dimensions [ i ] ) { throw new TypeError ( error . outOfBoundIndex ) } } var index = indices [ len ] // i_n console . log ( 'factor' , factor ) index += factor * indices [ len - 1 ] // i_n + i_(n-1) * d_n console . log ( 'index' , index ) staticProps ( multiDimArrayIndex ) ( { error : error } )", "del_tokens": "* maps multidimensional array indices to monodimensional array index var index = indices [ len ] index += factor * indices [ len - 1 ]", "commit_type": "add"}
{"commit_tokens": ["Move", "file", "name", "/", "extension", "logic", "into", "Preprocessor", "base", "class"], "add_tokens": "var path = require ( 'path' ) Preprocessor . prototype . getDestFileName = function ( fileName ) { var extension = path . extname ( fileName ) . replace ( / ^\\. / , '' ) if ( ( this . extensions || [ ] ) . indexOf ( extension ) !== - 1 ) { return fileName . slice ( 0 , - extension . length ) + this . targetExtension } return null } CopyPreprocessor . prototype . getDestFileName = function ( fileName ) { return fileName } CoffeeScriptPreprocessor . prototype . extensions = [ 'coffee' ] CoffeeScriptPreprocessor . prototype . targetExtension = 'js' ES6TemplatePreprocessor . prototype . compileFunction = '' ES6TemplatePreprocessor . prototype . extensions = [ ] // set when instantiating ES6TemplatePreprocessor . prototype . targetExtension = 'js' ES6TranspilerPreprocessor . prototype . targetExtension = 'js'", "del_tokens": "CopyPreprocessor . extensions = [ ] CopyPreprocessor . targetExtension = null CoffeeScriptPreprocessor . prototype . extensions = [ 'coffee' ] CoffeeScriptPreprocessor . prototype . targetExtension = 'js' ES6TemplatePreprocessor . prototype . compileFunction = '' ES6TemplatePreprocessor . prototype . extensions = [ ] // set when instantiating ES6TemplatePreprocessor . prototype . targetExtension = 'js'", "commit_type": "move"}
{"commit_tokens": ["improve", "wildcards", "in", "testacular", "configs"], "add_tokens": "'test/e2e/**/*.js'", "del_tokens": "'test/e2e/scenarios.js'", "commit_type": "improve"}
{"commit_tokens": ["remove", "PRE_SLEEP", "and", "NOOP", "in", "each", "REQ", "and", "RES"], "add_tokens": "//this._preSleep(jobServer); callback = callback || function ( ) { } ; var timer = setTimeout ( function ( ) { callback ( new Error ( \"RESET_ABILITIES timeout!\" ) ) ; } , 10000 ) ; / ** * Sends to the servers to grab jobs . * * @ access public * / Worker . prototype . grabJob = function ( numberOfJob ) { var i = 0 , j = 0 ; numberOfJob = numberOfJob ? numberOfJob : 1 ; for ( i = 0 ; i < numberOfJob ; i ++ ) { for ( j = 0 ; i < this . jobServers . length ; i ++ ) { this . jobServers [ i ] . send ( protocol . encodePacket ( protocol . PACKET_TYPES . GRAB_JOB ) ) ; } } } jobServer . send ( protocol . encodePacket ( protocol . PACKET_TYPES . GRAB_JOB ) ) ;", "del_tokens": "this . _preSleep ( jobServer ) ; var timer = setTimeout ( function ( ) { callback ( new Error ( \"RESET_ABILITIES timeout!\" ) ) ; } , 5000 ) ; this . clientOrWorker . _preSleep ( jobServer ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "issue", "s", "giving", "a", "SyntaxError", "."], "add_tokens": "forgetToInstall ( dependencies ) modules . map ( formatGroup ) relativeModulesNotFound ( relativeModules )", "del_tokens": "forgetToInstall ( dependencies ) , modules . map ( formatGroup ) , relativeModulesNotFound ( relativeModules ) ,", "commit_type": "fix"}
{"commit_tokens": ["fix", "html", "comment", "issues", "."], "add_tokens": "} ;", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["add", "a", "how", "to", "use", "private", "messages", "tip", "in", "the", "compose", "box"], "add_tokens": "placeholder : ` \\n \\n \\n \\n `", "del_tokens": "placeholder : 'Write a private message'", "commit_type": "add"}
{"commit_tokens": ["use", "flags", "w", "&", "filter", "output", "istanbul", "s", "log"], "add_tokens": "if ( ist && ! outstream ) { var s = / string / i . test ( typeof outstream ) ? fs . createWriteStream ( outstream , { flags : 'w' } ) : outstream ;", "del_tokens": "if ( ist ) { var s = / string / i . test ( typeof outstream ) ? fs . createWriteStream ( outstream , { flags : 'a' } ) : outstream ;", "commit_type": "use"}
{"commit_tokens": ["added", "allowedEnvironments", "support", "at", "group", "level"], "add_tokens": "let mergedInfo = { \"allowedPackages\" : { } , \"allowedEnvironments\" : { } } ; if ( group . config ) { if ( group . config . allowedPackages ) { mergedInfo . allowedPackages = group . config . allowedPackages ; } if ( group . config . allowedEnvironments ) { mergedInfo . allowedEnvironments = group . config . allowedEnvironments ; } urac . groupsConfig = mergedInfo ; }", "del_tokens": "let mergedInfo = { \"allowedPackages\" : { } } ; if ( group . config && group . config . allowedPackages ) mergedInfo . allowedPackages = group . config . allowedPackages ; urac . groupsConfig = mergedInfo ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ";", "Off", "-", "by", "-", "one", "error", "in", "lorem", ".", "js", "."], "add_tokens": "for ( sentenceCount ; sentenceCount > 0 ; sentenceCount -- ) { for ( paragraphCount ; paragraphCount > 0 ; paragraphCount -- ) {", "del_tokens": "for ( sentenceCount ; sentenceCount >= 0 ; sentenceCount -- ) { for ( paragraphCount ; paragraphCount >= 0 ; paragraphCount -- ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "travis", "config", "for", "building", "docs"], "add_tokens": "/ ** * @ class * / * @ function * @ return { { } } / ** * @ return { Object } * /", "del_tokens": "* @ return { * }", "commit_type": "add"}
{"commit_tokens": ["Update", "src", "and", "dist", "in", "gulp"], "add_tokens": "var src = 'sass/' ; var dest = 'css/' ; return sass ( src + 'ubuntu-styles.scss' , { style : 'expanded' } )", "del_tokens": "var src = 'sass' ; var dest = 'css/responsive/latest/' ; return gulp . src ( src + '/responsive/latest/ubuntu-styles.scss' ) . pipe ( sass ( { style : 'expanded' } ) )", "commit_type": "update"}
{"commit_tokens": ["added", "define", "and", "cond", "as", "lisp", "keywords"], "add_tokens": "[ PR . PR_KEYWORD , / ^(?:block|c[ad]+r|catch|con[ds]|def(?:ine|un)|do|eq|eql|equal|equalp|eval-when|flet|format|go|if|labels|lambda|let|load-time-value|locally|macrolet|multiple-value-call|nil|progn|progv|quote|require|return-from|setq|symbol-macrolet|t|tagbody|the|throw|unwind)\\b / , null ] ,", "del_tokens": "[ PR . PR_KEYWORD , / ^(?:block|c[ad]+r|catch|cons|defun|do|eq|eql|equal|equalp|eval-when|flet|format|go|if|labels|lambda|let|load-time-value|locally|macrolet|multiple-value-call|nil|progn|progv|quote|require|return-from|setq|symbol-macrolet|t|tagbody|the|throw|unwind)\\b / , null ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "browserify", "pack", "pipeline", "replacement"], "add_tokens": "// Replace the 'pack' sub-pipeline with the new browser-pack instance bfy . pipeline . get ( 'pack' ) . splice ( 0 , 1 , bfy . _bpack ) ;", "del_tokens": "// Replace the 'pack' pipeline step with the new browser-pack instance bfy . pipeline . splice ( 'pack' , 1 , bfy . _bpack ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "View", "All", "for", "each", "subsection", "in", "menus", "and", "generate", "required", "files"], "add_tokens": "this . name = subdir . replace ( / [\\/\\\\] / g , '-' ) + '-' + this . fileName ; //this is the unique name with the subDir this . flatPatternPath = subdir . replace ( / [\\/\\\\] / g , '-' ) ;", "del_tokens": "this . name = ( subdir . replace ( / [\\/\\\\] / g , '-' ) + '-' + this . fileName ) . replace ( / \\\\ / g , '-' ) ; //this is the unique name with the subDir this . flatPatternPath = subdir . replace ( / \\/ / g , '-' ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "speed", ":", "use", "id||_id||title", "as", "the", "hash"], "add_tokens": "// var simhash = require('simhash')(); // return id|id_str|title return obj . id || obj . _id || obj . title || hashToNum ( JSON . stringify ( obj ) ) ; // return hashToNum(obj); // b[i].hash = f(typeof a[i] === \"string\"? a[i]: JSON.stringify(a[i])); b [ i ] . hash = f ( typeof a [ i ] === \"string\" ? a [ i ] : a [ i ] ) ;", "del_tokens": "return hashToNum ( obj ) ; b [ i ] . hash = f ( typeof a [ i ] === \"string\" ? a [ i ] : JSON . stringify ( a [ i ] ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "parsing", "with", "multiple", "properties"], "add_tokens": "if ( propNode . childNodes && propNode . childNodes . length > 0 && propNode . childNodes [ 0 ] . nodeType === 1 ) {", "del_tokens": "if ( ! content && propNode . hasChildNodes ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "when", "the", "auth", "is", "not", "working"], "add_tokens": "function ( err , response ) { err = err || responseAsError ( response ) ; if ( err ) { // reset cookie jar and do the login again jar = request . jar ( ) ; checkLogin ( next ) ; } else { next ( ) ; } } , if ( CARELINK_EU ) { refreshTokenEu ( function ( ) { getConnectData ( response , next , retryCount + 1 ) ; } ) ; } else { getConnectData ( response , next , retryCount + 1 ) ; } let expire = new Date ( Date . parse ( _ . get ( getCookie ( CARELINKEU_TOKENEXPIRE_COOKIE ) , 'value' , '2999-01-01' ) ) ) ; if ( expire < new Date ( Date . now ( ) - 10 * 1000 * 60 ) ) {", "del_tokens": "checkResponseThen ( next ) getConnectData ( response , next , retryCount + 1 ) ; let expire = new Date ( Date . parse ( _ . get ( getCookie ( CARELINKEU_TOKENEXPIRE_COOKIE ) , 'value' , '1970-01-01' ) ) ) ; if ( expire < new Date ( Date . now ( ) - 5 * 1000 * 60 ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "groupbuddy", "event"], "add_tokens": "name : 'groupbuddy event' , input : [ 'test@muc.5apps.com' , 'greg' , 'online' , 'hey, wazzup?' ] , handler : 'groupbuddy' , status : 'hey, wazzup?' ,", "del_tokens": "name : 'presence-4' , input : '<presence to=\"hermes@5apps.com/hyperchannel\" from=\"test@muc.5apps.com/greg\" xmlns:stream=\"http://etherx.jabber.org/streams\"><c ver=\"d2rgtMP0QRwWPU4dGU5DEFz5ZmM=\" hash=\"sha-1\" node=\"http://conversations.im\" xmlns=\"http://jabber.org/protocol/caps\"/><x xmlns=\"http://jabber.org/protocol/muc#user\"><item role=\"moderator\" affiliation=\"owner\"/></x></presence>' , status : null ,", "commit_type": "add"}
{"commit_tokens": ["add", "event", "to", "callback", "in", "case", "no", "api", "is", "supported"], "add_tokens": "} else cb ( event ) ;", "del_tokens": "} else cb ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "lambda", "testing", "adjust", "lambda", "handling", "."], "add_tokens": "* * s = t . render ( { foo : function ( ) { return false ; } } ) ; is ( s , \"This template BOO contains an inverted section.\" , \"inverted sections with false returning method in context work\" ) ; is ( s , '&#39;X' , 'Apostrophe is escaped.' ) ; is ( s , 'Here is some stuff!\\n1\\n2\\n3\\n4\\n' , 'Partials with implicit iterators work.' ) ; is ( s , 'Here is some stuff!\\n1\\n2\\n3\\n4\\n' , 'Partials with arrays work.' ) ; testNewLineBetweenDelimiterChanges ( ) ;", "del_tokens": "* * is ( s , '&#39;X' , 'Apostrophe is escaped.' ) ; is ( s , 'Here is some stuff!\\n1\\n2\\n3\\n4\\n' , 'Partials with implicit iterators work.' ) ; is ( s , 'Here is some stuff!\\n1\\n2\\n3\\n4\\n' , 'Partials with arrays work.' ) ; testNewLineBetweenDelimiterChanges ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "imports", "if", "several", "scripts", "are", "defined", "in", "a", "single", "HTML", "page"], "add_tokens": "// Maps the name of imported modules to the module object $B . imported = { __main__ : { __class__ : $B . $ModuleDict , __name__ : '__main__' } }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["move", "error", "messages", "logging", "responsibility", "from", "resume", ".", "js", "to", "test", ".", "js"], "add_tokens": "callback ( true , { errorMessage : 'Cannot export. There are errors in the resume.json schema format.\\nTry using The JSONLInt Validator at: http://jsonlint.com/' } ) ;", "del_tokens": "// makes the schemas output human readable from the console //check if there are schcema errors // now run throught them callback ( true ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "support", "for", "feature", "flags"], "add_tokens": "events : ReactFunc , features : ReactObj self . features = context . features . context ( self . __onus_onStoreChange ) ;", "del_tokens": "events : ReactFunc", "commit_type": "add"}
{"commit_tokens": ["remove", "classname$", ";", "using", "set", "for", "new", "object", "construction"], "add_tokens": "if ( modelClass instanceof angoose ( ) . Service ) var _id = invocation . instance && invocation . instance . _id ; if ( _id ) modelClass . findById ( _id , mongoCallback ) ; else mongoCallback ( false , new modelClass ( ) ) ;", "del_tokens": "if ( modelClass instanceof angoose ( ) . Service || ! invocation . instance . _id ) var _id = invocation . instance . _id ; modelClass . findById ( _id , mongoCallback ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "issues", "in", "test", "related", "to", "cross", "platform", "development"], "add_tokens": "var frames = inspector . getFrames ( ) ; var lines = inspector . getFrames ( ) [ 0 ] . getFileLines ( 8 , 1 ) ; lines [ 0 ] . replace ( / (\\n|\\r)+$ / , \"\" ) ; // remove EOL character to prevent cross platform issues lines . should . containEql ( \"/** do not move this comment from this location - used for testing**/\" ) ; var lines = inspector . getFrames ( ) [ 0 ] . getFileContents ( ) ; lines [ 0 ] . replace ( / (\\n|\\r)+$ / , \"\" ) ; lines . should . containEql ( fs . readFileSync ( __filename , \"utf-8\" ) ) ;", "del_tokens": "inspector . getFrames ( ) [ 0 ] . getFileLines ( 8 , 1 ) . should . containEql ( \"/** do not move this comment from this location - used for testing**/\" ) ; inspector . getFrames ( ) [ 0 ] . getFileContents ( ) . should . containEql ( fs . readFileSync ( __filename , \"utf-8\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "date", "picker", "for", "editing", "rows", "."], "add_tokens": "} , { label : 'Another Date' , id : 'category_date' , filter : { enabled : true , type : 'date' , options : { // Optional format : \"YYYY/MM/DD\" , // Optional fromMonth : new Date ( new Date ( 30 , 0 ) . getFullYear ( ) , 0 ) , // Optional toMonth : new Date ( new Date ( ) . getFullYear ( ) + 2 , 11 ) // Optional } } value : '1992/05/27' , editing : { enabled : true , type : 'date' , options : { format : \"YYYY/MM/DD\" , // Optional fromMonth : new Date ( new Date ( 30 , 0 ) . getFullYear ( ) , 0 ) , // Optional toMonth : new Date ( new Date ( ) . getFullYear ( ) + 2 , 11 ) // Optional } } } , { id : 'category_date' , value : '2009/05/27' , editing : { enabled : true , type : 'date' , options : { format : \"YYYY/MM/DD\" , // Optional fromMonth : new Date ( new Date ( 30 , 0 ) . getFullYear ( ) , 0 ) , // Optional toMonth : new Date ( new Date ( ) . getFullYear ( ) + 2 , 11 ) // Optional } }", "del_tokens": "value : '1992/05/27'", "commit_type": "add"}
{"commit_tokens": ["add", "optins", "in", "the", "Stream", "function"], "add_tokens": "function app ( options ) { // override default options if ( ! app . child && typeof options === 'object' ) { _ . merge ( app . options , options ) ; }", "del_tokens": "function app ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "properly", "parsing", "filters"], "add_tokens": "parsedFilterData . isRegex = input [ beginIndex ] === '/' && input [ input . length - 1 ] === '/' && beginIndex !== input . length - 1 ; beginIndex += 2 ; beginIndex ++ ;", "del_tokens": "parsedFilterData . isRegex = input [ beginIndex ] === '/' ;", "commit_type": "add"}
{"commit_tokens": ["changed", "binding", "syntax", "to", "use", ":", "instead", "of", "."], "add_tokens": "b . inline ( 'Factor_bind' , b . seq ( b . bind ( b . app ( 'Iter' ) , 'x' ) , b . prim ( ':' ) , b . bind ( b . app ( 'ident' ) , 'n' ) ) ) ; b . setRuleDescription ( undefined ) ; b . define ( 'Prop' , b . seq ( b . bind ( b . alt ( b . app ( 'name' ) , b . app ( 'string' ) ) , 'n' ) , b . prim ( ':' ) , b . bind ( b . app ( 'Base' ) , 'p' ) ) ) ;", "del_tokens": "b . inline ( 'Factor_bind' , b . seq ( b . bind ( b . app ( 'Iter' ) , 'x' ) , b . prim ( '.' ) , b . bind ( b . app ( 'ident' ) , 'n' ) ) ) ; b . setRuleDescription ( undefined ) ; b . define ( 'Prop' , b . seq ( b . bind ( b . alt ( b . app ( 'name' ) , b . app ( 'string' ) ) , 'n' ) , b . prim ( ':' ) , b . bind ( b . app ( 'Factor' ) , 'p' ) ) ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "url", "column", "to", "uri", "table", "and", "refactor", "onConflictPut", "to", "insert", "to", "multiple", "columns", "at", "once"], "add_tokens": ". then ( ( ) => client . raw ( 'CREATE TABLE IF NOT EXISTS ?? ( id TEXT PRIMARY KEY NOT NULL, data TEXT NOT NULL, url TEXT NOT NULL );' , [ 'uris' ] ) )", "del_tokens": ". then ( ( ) => client . raw ( 'CREATE TABLE IF NOT EXISTS ?? ( id TEXT PRIMARY KEY NOT NULL, data TEXT NOT NULL );' , [ 'uris' ] ) )", "commit_type": "add"}
{"commit_tokens": ["adding", "the", "ability", "to", "set", "a", "name", "map", "and", "a", "custom", "extension"], "add_tokens": "'extension' : 'json' , 'nameMap' : { } , var name = module ; if ( options . nameMap . hasOwnProperty ( module ) ) { name = options . nameMap [ module ] ; } var fp = options . dest + name + '.' + options . extension ;", "del_tokens": "var fp = options . dest + module + '.json' ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "additional", "test", "failures", "found", "in", "main", "engine", ".", "io", "test", "suite"], "add_tokens": "} else if ( packet . data && ( packet . data . buffer || packet . data ) instanceof ArrayBuffer ) { var data = packet . data . buffer || packet . data ; if ( ! Buffer . isBuffer ( packet . data ) ) {", "del_tokens": "} else if ( packet . data && packet . data . buffer instanceof ArrayBuffer ) { var data = packet . data . buffer ; if ( packet . data . buffer instanceof ArrayBuffer ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "comma", "separated", "values", "for", "flags"], "add_tokens": "else if ( typeof arg === 'string' ) return arg . split ( ',' ) ;", "del_tokens": "else if ( typeof arg === 'string' ) return [ arg ] ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "amazon", "payments", "to", "support", "simple", "SNS", "/", "IPN", "message", "parsing"], "add_tokens": "badToken : 'bad_token' , missingParameter : 'missing_parameter' , invalidSignatureVersion : 'invalid_signature_version' , signatureMismatch : 'signature_mismatch' exports . missingParameter = makeError ( errorTypes . missingParameter ) ; exports . invalidSignatureVersion = makeError ( errorTypes . invalidSignatureVersion ) ; exports . signatureMismatch = makeError ( errorTypes . signatureMismatch ) ;", "del_tokens": "badToken : 'bad_token'", "commit_type": "update"}
{"commit_tokens": ["add", "array", ".", "split", "update", "readme", "&", "tests"], "add_tokens": "const { create } = require ( '../../' ) . object ; describe ( 'object.create' , ( ) => { it ( 'should export a function' , ( ) => { describe ( 'called without constructor' , ( ) => { it ( 'should correctly return enumerable properties' , ( ) => { describe ( 'called with constructor' , ( ) => { it ( 'should correctly return constructed enumerable properties' , ( ) => {", "del_tokens": "import create from 'lib/object/create' ; describe ( 'object/create' , function ( ) { it ( 'should export a function' , function ( ) { describe ( 'called without constructor' , function ( ) { it ( 'should correctly return enumerable properties' , function ( ) { describe ( 'called with constructor' , function ( ) { it ( 'should correctly return constructed enumerable properties' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "AppleScriptApi", "reworked", "WebHelperApi", "added", "WebApi"], "add_tokens": "const SpotifyWebHelper = require ( \"./spotifyWebHelper\" ) ; const SpotifyWebApi = require ( \"./spotifyWebApi\" ) ; const SpotifyAppleScriptApi = require ( \"./SpotifyAppleScriptApi\" ) ; SpotifyWebApi , SpotifyAppleScriptApi", "del_tokens": "const SpotifyWebHelper = require ( \"./spotifyWebHelper\" ) ; // WebApi to be included soon", "commit_type": "add"}
{"commit_tokens": ["added", "testing", "for", "installing", "a", "package"], "add_tokens": "let koa = require ( 'koa' ) ; let gzip = require ( 'koa-gzip' ) ; let r = require ( 'koa-route' ) ; let logger = require ( 'koa-logger' ) ; let parse = require ( 'co-body' ) ; let packages = require ( './lib/packages' ) ; let tarballs = require ( './lib/tarballs' ) ; let config = require ( './lib/config' ) ; let user = require ( './lib/user' ) ; let app = koa ( ) ; this . body = auth ; this . status = 401 ; this . body = { error : \"invalid credentials\" } ;", "del_tokens": "let koa = require ( 'koa' ) ; let gzip = require ( 'koa-gzip' ) ; let r = require ( 'koa-route' ) ; let logger = require ( 'koa-logger' ) ; let parse = require ( 'co-body' ) ; let packages = require ( './lib/packages' ) ; let tarballs = require ( './lib/tarballs' ) ; let config = require ( './lib/config' ) ; let user = require ( './lib/user' ) ; let app = koa ( ) ; this . body = auth ; this . body = { error : \"invalid credentials\" } ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "ffi", "required", "version", "number"], "add_tokens": "printInfo ( execStr ) ; printInfo ( err ) ;", "del_tokens": "console . log ( execStr ) ; console . log ( err ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "a", "bunch", "of", "bugs"], "add_tokens": "var Promise = require ( 'pouchdb/extras/promise' ) ;", "del_tokens": "var Promise ; /* istanbul ignore next */ if ( typeof window !== 'undefined' && window . PouchDB ) { Promise = window . PouchDB . utils . Promise ; } else { Promise = typeof global . Promise === 'function' ? global . Promise : require ( 'lie' ) ; }", "commit_type": "fix"}
{"commit_tokens": ["update", "README", "(", "info", "about", "changing", "the", "scope", "of", "middleware", "at", "runtime", ")"], "add_tokens": "let scope = self ; const hookMethod = currentHook . displayName || urrentHook. n ame; / ** * If there is a __scopeHook function on the object * we call it to get the scope wanted for the hook * / scope = getScope ( self , name , args , hookMethod ) ; function getScope ( self , hookName , args , hookMethod ) { typeof self . __scopeHook ( hookName , args , hookMethod ) !== 'undefined' ? self . __scopeHook ( hookName , args , hookMethod ) : self ;", "del_tokens": "let scope ; / ** * If there is a __scopeHook function on the object * we call it to get the scope wanted for the hook * / scope = getScope ( self , name , args ) ; function getScope ( self , hookName , args ) { typeof self . __scopeHook ( hookName , args ) !== 'undefined' ? self . __scopeHook ( hookName , args ) : self ;", "commit_type": "update"}
{"commit_tokens": ["remove", "listenable", "in", "store", ".", "registered", "after", "unsubscribe", "()"], "add_tokens": "var unsubscribe = listenable . listen ( callback , this ) ; var self = this ; return function ( ) { unsubscribe ( ) ; self . registered . splice ( self . registered . indexOf ( listenable ) , 1 ) ; } ;", "del_tokens": "return listenable . listen ( callback , this ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "default", "mode", "for", "pre", "and", "post", "script"], "add_tokens": "mode : parseInt ( '755' , 8 )", "del_tokens": "mode : '0755'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "no", "-", "restricted", "-", "syntax", "rule", "violations"], "add_tokens": "config = { } ; Object . keys ( window . __karma__ . files ) . forEach ( function ( file ) { } ) ;", "del_tokens": "config = { } , file ; for ( file in window . __karma__ . files ) { }", "commit_type": "fix"}
{"commit_tokens": ["add", "package", ".", "json", "unknown", "error", "handling", "-", "emit", "event"], "add_tokens": ") ) ; // this line must be immediately after express.bodyParser()!", "del_tokens": "} ) ) ; // this line must be immediately after express.bodyParser()!", "commit_type": "add"}
{"commit_tokens": ["updates", "on", "PostController", "to", "populate", "related", "post", "data"], "add_tokens": "type : 'text' , type : 'text'", "del_tokens": "type : 'string' , type : 'string'", "commit_type": "update"}
{"commit_tokens": ["Improve", "formatting", "of", "large", "objects", "when", "used", "as", "a", "card", "body"], "add_tokens": "return $ ( Data , null , inspect ( body , { depth : null } ) ) ;", "del_tokens": "return $ ( Data , null , inspect ( body ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Removing", "hardcoded", "persona", "audience", "."], "add_tokens": ". factory ( '_koastPersona' , [ '$http' , '$q' , '$interval' , '$location' , '$log' , function ( $http , $q , $interval , $location , $log ) { var audience = $location . absUrl ( ) . split ( '/' ) . slice ( 0 , 3 ) . join ( '/' ) + '/' ; audience : audience $log . info ( 'audience:' , audience ) ;", "del_tokens": ". factory ( '_koastPersona' , [ '$http' , '$q' , '$interval' , '$log' , function ( $http , $q , $interval , $log ) { audience : 'http://localhost:3000/'", "commit_type": "remove"}
{"commit_tokens": ["Made", "sure", "that", "$", ".", "event", ".", "handle", "()", "always", "has", "some", "form", "of", "an", "event", "object", "."], "add_tokens": "if ( ! event && ! window . event ) { return null ; } var returnValue = true , handlers = [ ] ;", "del_tokens": "var returnValue = true ; var handlers = [ ] ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "form", "and", "json", "parsing", "options", "to", "be", "configured", "."], "add_tokens": "opts = spec . validate . jsonOptions || { } ; if ( typeof opts . limit === 'undefined' ) { opts . limit = spec . validate . maxBody ; } opts = spec . validate . formOptions || { } ; if ( typeof opts . limit === 'undefined' ) { opts . limit = spec . validate . maxBody ; } opts = spec . validate . multipartOptions || { } ; if ( typeof opts . autoFields === 'undefined' ) { opts . autoFields = true ; }", "del_tokens": "opts = { limit : spec . validate . maxBody } ; opts = { limit : spec . validate . maxBody } ; opts = spec . validate . multipartOptions || { } ; // TODO document this opts . autoFields = true ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "bad", "err", "/", "error", "naming"], "add_tokens": "return callback ( error . signatureMismatch ( 'Signature mismatch, unverified response' ) ) ;", "del_tokens": "return callback ( err . signatureMismatch ( 'Signature mismatch, unverified response' ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "http#req", "param", "followAllRedirects", ":", "true", "to", "follow", "non", "-", "GET", "redirection", "."], "add_tokens": "* GET redirection is handled by default by request module . * Non - GET redirection is handled by params followAllRedirects : true . var params = { url : url , followAllRedirects : true } ,", "del_tokens": "var params = { url : url } ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "disabled", "option", "for", "choices"], "add_tokens": "selected : v && v . selected , disabled : v && v . disabled if ( this . value [ this . cursor ] . disabled ) { this . bell ( ) ; } else { this . done = true ; this . aborted = false ; this . fire ( ) ; this . render ( ) ; this . out . write ( '\\n' ) ; this . close ( ) ; }", "del_tokens": "selected : v && v . selected this . done = true ; this . aborted = false ; this . fire ( ) ; this . render ( ) ; this . out . write ( '\\n' ) ; this . close ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "meta", "stuff", ".", "grunt", "package", "etc", "."], "add_tokens": "/ *! * Smooth Scroll - v1 .4 .10 - 2013 - 02 - 20 * https : //github.com/kswedberg/jquery-smooth-scroll * Copyright ( c ) 2013 Karl Swedberg * Licensed MIT ( / blob / master / LICENSE - MIT ) * / var version = '1.4.10' ,", "del_tokens": "/ *! Smooth Scroll - v1.4.9 - 2013-01-21 * https : //github.com/kswedberg/jquery-smooth-scroll * Copyright ( c ) 2013 Karl Swedberg ; Licensed MIT * / var version = '1.4.9' ,", "commit_type": "update"}
{"commit_tokens": ["updated", "package", ".", "json", "(", "removed", "scripts", "{}", ")"], "add_tokens": "* Version : 0.0 .8 , build : 748", "del_tokens": "* Version : 0.0 .7 , build : 747", "commit_type": "update"}
{"commit_tokens": ["improve", "isKeyNotFound", "and", "fix", "spelling", "in", "comment"], "add_tokens": "if ( err . code && err . code === errors . keyNotFound ) { else if ( err . message && err . message === 'key not found' ) { else if ( err . message && err . message . indexOf ( 'key does not exist' ) >= 0 ) { else if ( err . message && err . message . indexOf ( 'key not found' ) >= 0 ) { * A simplified get for our use . } ;", "del_tokens": "if ( err . message && err . message === 'key not found' ) { else if ( err . message && err . message . indexOf ( 'key does not exist' ) >= 0 ) { else if ( err . message && err . message . indexOf ( 'key not found' ) >= 0 ) { else if ( err . code && err . code === errors . keyNotFound ) { * A simplified get for out use . } ;", "commit_type": "improve"}
{"commit_tokens": ["Changed", "name", "of", "method", "to", "be", "more", "correct"], "add_tokens": "exports . portIsAvailable = function ( port , callback ) {", "del_tokens": "exports . portIsOpen = function ( port , callback ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "commandline", "parsing", "for", "flags", "that", "require", "no", "args"], "add_tokens": "boolean : [ 'r' , 'replace' , 'L' , 'identities' , 'd' , 'dependencies' , 'v' , 'verifyTwice' , 'f' , 'without-fairplay' , 'w' , 'without-watchapp' ]", "del_tokens": "boolean : [ 'replace' , 'identities' ]", "commit_type": "fix"}
{"commit_tokens": ["Make", "stylesheet", "handling", "a", "bit", "more", "normative", "."], "add_tokens": "for ( var i = 0 ; i < stylesheets . length ; i ++ ) requireStylesheet ( stylesheets [ i ] ) ; var stylesheetLoadStatus = { } ; if ( window . FLATTENED ) return ; if ( stylesheetLoadStatus [ dependentStylesheetName ] ) return ; stylesheetLoadStatus [ dependentStylesheetName ] = true ; var localPath = dependentStylesheetName . replace ( / \\. / g , '/' ) + '.css' ; var stylesheetPath = moduleBasePath + '/' + localPath ; var linkEl = document . createElement ( 'link' ) ; linkEl . setAttribute ( 'rel' , 'stylesheet' ) ; linkEl . setAttribute ( 'href' , stylesheetPath ) ; base . doc . head . appendChild ( linkEl ) ;", "del_tokens": "for ( var i = 0 ; i < stylesheets . length ; i ++ ) { var stylesheetName = stylesheets [ i ] ; var localPath = stylesheetName . replace ( / \\. / g , '/' ) + '.css' ; var stylesheetPath = moduleBasePath + '/' + localPath ; var linkEl = document . createElement ( 'link' ) ; linkEl . setAttribute ( 'rel' , 'stylesheet' ) ; linkEl . setAttribute ( 'href' , stylesheetPath ) ; base . doc . head . appendChild ( linkEl ) ; } // This is a nop. By the time we've gotten to executing this statement, // the stylesheet should already be loaded.", "commit_type": "make"}
{"commit_tokens": ["Removed", "trailing", "comma", "in", "header", "-", "from", "-", "rpc", "dict"], "add_tokens": "nonce : blockParams . nonce", "del_tokens": "nonce : blockParams . nonce ,", "commit_type": "remove"}
{"commit_tokens": ["Adding", "config", ".", "paypalURL", "property", "to", "allow", "access", "to", "sandbox", "and", "beta", "-", "sandbox", "domains"], "add_tokens": "/ ** * The URL of the paypal website * / paypalURL : 'https://www.paypal.com/cgi-bin/webscr' , self . UI . cart . action = config . paypalURL ;", "del_tokens": "self . UI . cart . action = 'https://www.paypal.com/cgi-bin/webscr' ;", "commit_type": "add"}
{"commit_tokens": ["fix", "Path", ".", "join", "for", "datadir", "and", "path"], "add_tokens": "datadir : nodePath . join ( __dirname , '..' , 'Sia' ) , path : nodePath . join ( __dirname , '..' , 'Sia' , process . platform === 'win32' ? 'siad.exe' : 'siad' )", "del_tokens": "datadir : nodePath . join ( __dirname , '../Sia' ) , path : nodePath . join ( __dirname , '../Sia/' , process . platform === 'win32' ? 'siad.exe' : 'siad' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "meaningful", "errors", "when", "Polly", "throws", ";", "Add", "tests"], "add_tokens": "let pollyError ; done && done ( ) ; // If we caught instance of the polly error, we will save it for the // reference and continue with the tests to print the error at the end // of the spec where it's more visible if ( error . name === 'PollyError' ) { pollyError = error ; done && done ( ) ; } else if ( done ) { // Otherwise let's just fail spec/throw error, there is nothing // special we can do in that case done . fail ( error ) ; } else { throw error ; } // We want to throw polly error here so it's shown as the last one in the // list of possible errors that happend during the test run if ( pollyError ) { pollyError . message = pollyError . message . replace ( / \\.$ / , '' ) + \". Check `setupPolly` method and make sure it's configured correctly.\" ; throw pollyError ; } done && done ( ) ; if ( done ) { done . fail ( error ) ; } else { throw error ; }", "del_tokens": "// If something went wrong while trying to create new polly // instance (e.g., wrong polly config was passed) let's fail // the test with an error done && done . fail ( error ) ; return ; done && done ( ) ; done && done . fail ( error ) ; return ; done && done ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "encryptAuthKey", "and", "decryptAuthKey", "in", "auth", "module"], "add_tokens": "exports . encryptAuthKey = encryptAuthKey ; exports . decryptAuthKey = decryptAuthKey ; require ( 'requirish' ) . _ ( module ) ; var utility = require ( 'lib/utility' ) ; var security = require ( 'lib/security' ) ; var AuthKey = exports . AuthKey ; } // Encrypt authKey with the given password function encryptAuthKey ( authKey , password ) { var plainKey = Buffer . concat ( [ authKey . id , authKey . value ] ) ; var passwordHash = utility . createSHAHash ( new Buffer ( password ) , 'sha512' ) ; var aesKey = passwordHash . slice ( 0 , 32 ) ; var aesIv = passwordHash . slice ( 32 , 64 ) ; return security . cipher . aesEncrypt ( plainKey , aesKey , aesIv ) . slice ( 0 ) ; } // Decrypt authKey with the given password function decryptAuthKey ( buffer , password ) { var passwordHash = utility . createSHAHash ( new Buffer ( password ) , 'sha512' ) ; var aesKey = passwordHash . slice ( 0 , 32 ) ; var aesIv = passwordHash . slice ( 32 , 64 ) ; var decrypted = security . cipher . aesDecrypt ( buffer , aesKey , aesIv ) ; return new AuthKey ( decrypted . slice ( 0 , 8 ) , decrypted . slice ( 8 , 264 ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "dangerous", "markdown", "component", "."], "add_tokens": "import DangerousMarkdown from '../../DangerousMarkdown' ; < DangerousMarkdown > { ` ${ wrapper . alternate } ` } < / DangerousMarkdown > < DangerousMarkdown > { ` ${ wrapper . name } ` } < / DangerousMarkdown > < DangerousMarkdown > { wrapper . example } < / DangerousMarkdown >", "del_tokens": "import dangerousMd from '../../../scripts/markdownRenderer.babel' ; < div dangerouslySetInnerHTML = { { __html : dangerousMd ( ` ${ wrapper . alternate } ` ) } } / > < div dangerouslySetInnerHTML = { { __html : dangerousMd ( ` ${ wrapper . name } ` ) } } / > < div dangerouslySetInnerHTML = { { __html : dangerousMd ( wrapper . example ) } } / >", "commit_type": "add"}
{"commit_tokens": ["moving", "require", ".", "config", "to", "another", "location", "adding", "jshint", "file", "modified", "modules", "to", "be", "AMD", "compatible"], "add_tokens": "define ( function ( require ) { return ( function ( global ) { kd3 = function ( ) { return require ( 'kd3' ) ; } ; global . kd3 = kd3 ; } ( this ) ) ; } ) ;", "del_tokens": "( function ( global ) { kd3 = function ( ) { //do something } ; global . kd3 = kd3 ; } ( this ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Create", "output", "directory", "if", "needed", "clear", "test", "project", "output", "before", "each", "test", "update", "expected", "output", "bundle"], "add_tokens": "const BUILD_PATH = path . resolve ( options . output ) ; if ( ! fs . existsSync ( BUILD_PATH ) ) { fs . mkdirSync ( BUILD_PATH ) ; }", "del_tokens": "const BUILD_PATH = path . resolve ( options . output ) ;", "commit_type": "create"}
{"commit_tokens": ["update", "bind", "and", "bindAll", "method", ";"], "add_tokens": "bind : function ( func , context ) { bindAll : function ( object , ctx ) { ctx = ctx || object ; object [ name ] = util . bind ( func , ctx ) ;", "del_tokens": "bind : function ( context , func ) { bindAll : function ( object ) { object [ name ] = util . bind ( func , object ) ;", "commit_type": "update"}
{"commit_tokens": ["Adds", "missing", "ExecutionPolicy", "option", "for", "powershell"], "add_tokens": "return spawn ( 'Powershell' , [ '-ExecutionPolicy' , 'RemoteSigned' , '-File' , ApplyPlatformConfigScript , ROOT ] ) ;", "del_tokens": "return spawn ( 'Powershell' , [ '-File' , ApplyPlatformConfigScript , ROOT ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "related", "to", "tear", "-", "down", "tests"], "add_tokens": "//assert_true(e.newURL.includes(hash)); //assert_true(e.newURL.includes(hash));", "del_tokens": "assert_true ( e . newURL . includes ( hash ) ) ; assert_true ( e . newURL . includes ( hash ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "generators", "to", "have", "proper", "state", "execution", "and", "transition", "functions", "in", "the", "timer", "and", "IRQ", "handler", ".", "Made", "sure", "the", "comments", "allow", "the", "code", "to", "be", "readable", ".", "Updated", "seed", "with", "some", "edits", "to", "the", "model", "."], "add_tokens": "\"script.bgs.ejs\" : \"import \\\"constants.bgs\\\"\\nimport \\\"globals.bgs\\\"\\n# Import user libraries here (if any)\\n<%\\nif (model.Library_list) {\\n model.Library_list.map(function(library) {\\n-%>\\nimport \\\"<%- library.name %>.bgs\\\"\\n<%\\n });\\n}\\n-%>\\n\\n# The timer handles all the state function code and state transition\\n# code\\nevent hardware_soft_timer(handle)\\n changeState = 0\\n # Generated code to execute state transitions and state functions\\n<%\\nif (model.State_list) {\\n model.State_list.map(function(state) {\\n-%>\\n<%- state.timerFunc %>\\n<%\\n });\\n}\\n-%>\\nend\\n\\n# The interrupt routine handles all conversion from input interrupts\\n# to state variables for state transitions\\nevent hardware_io_port_status(timestamp, port, irq, state_io)\\n # user code to handle the interrupts and convert them to state\\n # variables\\n<%- model.hardware_io_port_status %>\\n\\n changeState = 0\\n # Generated code to perform needed state transitions\\n<%\\nif (model.State_list) {\\n model.State_list.map(function(state) {\\n-%>\\n<%- state.irqFunc %>\\n<%\\n });\\n}\\n-%>\\nend\\n<%\\nif (model.Event_list) {\\n model.Event_list.map(function(event) {\\n-%>\\n\\n<%- event.function %>\\n<%\\n });\\n}\\n-%>\\n\"", "del_tokens": "\"script.bgs.ejs\" : \"import \\\"constants.bgs\\\"\\nimport \\\"globals.bgs\\\"\\n# Import user libraries here (if any)\\n<%\\nif (model.Library_list) {\\n model.Library_list.map(function(library) {\\n-%>\\nimport \\\"<%- library.name %>.bgs\\\"\\n<%\\n });\\n}\\n-%>\\n\\n# The timer handles all the state function code and state transition\\n# code\\nevent hardware_soft_timer(handle)\\n # Generated code to perform state transitions\\n # Generated code to execute state functions\\n changeState = 0\\n<%\\nif (model.State_list) {\\n model.State_list.map(function(state) {\\n-%>\\n<%- state.stateFunc %>\\n<%\\n });\\n}\\n-%>\\nend\\n\\n# The interrupt routine handles all conversion from input interrupts\\n# to state variables for state transitions\\nevent hardware_io_port_status(timestamp, port, irq, state_io)\\n # user code to handle the interrupts and convert them to state\\n # variables\\n<%- model.hardware_io_port_status %>\\n\\n # Generated code to perform needed state transitions\\nend\\n<%\\nif (model.Event_list) {\\n model.Event_list.map(function(event) {\\n-%>\\n\\n<%- event.function %>\\n<%\\n });\\n}\\n-%>\\n\"", "commit_type": "update"}
{"commit_tokens": ["Added", "query", "Parameter", "to", "pass", "all", "mongoose", "Query", "options", "with", "URL"], "add_tokens": "'$and' , '$or' , 'query' ] , //H+ exposes OR, AND and WHERE methods //H+ exposes Query AND, OR and WHERE methods if ( queryOptions . current . query ) { query . where ( JSON . parse ( queryOptions . current . query , jsonQueryParser ) ) ; } //TODO - as introduction of QUERY param obsoletes need of $and, $or query . and ( JSON . parse ( queryOptions . current . $and , jsonQueryParser ) ) ; query . or ( JSON . parse ( queryOptions . current . $or , jsonQueryParser ) ) ; function jsonQueryParser ( key , value ) {", "del_tokens": "'$and' , '$or' ] , //H+ exposes query OR and AND methods //H+ exposes Query AND, OR methods //TODO - add support for more logical operators supported by Mongoose query . and ( JSON . parse ( queryOptions . current . $and , JSONReviewer ) ) ; query . or ( JSON . parse ( queryOptions . current . $or , JSONReviewer ) ) ; function JSONReviewer ( key , value ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "updateObjWith", "to", "utils", ".", "js"], "add_tokens": "var utils = require ( './utils' ) data = utils . updateObjWith ( data , updateWith )", "del_tokens": "/ ** * Merge second object into first one . * * @ param { Object } obj * @ param { Object } upd * @ returns { Object } * / function updateObjWith ( obj , upd ) { for ( var key in upd ) { obj [ key ] = upd [ key ] } return obj } data = updateObjWith ( data , updateWith ) module . exports . updateObjWith = updateObjWith", "commit_type": "move"}
{"commit_tokens": ["Use", "react", "-", "create", "-", "class", "for", "es5", "compat"], "add_tokens": "assign = require ( 'lodash.assign' ) , createClass = require ( 'create-react-class' ) ; var component = createClass ( { displayName : 'Localized(' + componentName + ')' , componentDidMount : function ( ) { } , componentWillUnmount : function ( ) { } , render : function ( ) { } ) ;", "del_tokens": "assign = require ( 'lodash.assign' ) ; class component extends React . Component { componentDidMount ( ) { } componentWillUnmount ( ) { } render ( ) { } component . displayName = 'Localized(' + componentName + ')'", "commit_type": "use"}
{"commit_tokens": ["Add", "remote", "event", "listener", "support"], "add_tokens": "t . expectToBeBuffer ( actual [ 0 ] , bytes ) ; t . expectToBeBuffer ( actual [ 0 ] , bytes ) ; t . expectToBeBuffer ( actual [ 1 ] , bytes ) ; t . expectToBeBuffer ( actual [ 0 ] , bytes ) ; t . expectToBeBuffer ( actual [ 1 ] , bytes ) ;", "del_tokens": "t . assertBuffer ( actual [ 0 ] , bytes ) ; t . assertBuffer ( actual [ 0 ] , bytes ) ; t . assertBuffer ( actual [ 1 ] , bytes ) ; t . assertBuffer ( actual [ 0 ] , bytes ) ; t . assertBuffer ( actual [ 1 ] , bytes ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "db", "permissions", "for", "tests", "to", "work", "locally", "and", "with", "travis"], "add_tokens": "var dbUsername = process . env . DB_USER || 'postgres' ; var dbPassword = process . env . DB_PW || null ; var sequelize = new Sequelize ( 'sequelize_slugify_test' , dbUsername , dbPassword , { host : 'localhost' , dialect : 'postgres' , logging : false } ) ;", "del_tokens": "var sequelize = new Sequelize ( 'postgres://jarrod:jarrod@localhost:5432/sequelize_slugify_test' , { logging : false } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "animation", "to", "notes", "(", "using", "react", "-", "move", "-", "flip", ")"], "add_tokens": "setTimeout ( ( ) => { this . title . focus ( ) } , 1000 ) // small delay for the animation to complete < div className = 'Note' > < / div >", "del_tokens": "this . title . focus ( ) < li className = 'Note' > < / li >", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Matrix", ".", "has", "and", "removed", "log"], "add_tokens": "return Boolean ( row in matrix && column in matrix [ row ] ) ;", "del_tokens": "return Boolean ( matrix [ row ] && matrix [ row ] [ column ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "absolute", "path", "for", "chcp"], "add_tokens": "const SYSTEM32_DIR = path . join ( WINDOWS_DIR , 'System32' ) ; const CHCP_COM = path . join ( SYSTEM32_DIR , 'chcp.com' ) ; const POWERSHELL_DIR = path . join ( SYSTEM32_DIR , 'WindowsPowerShell\\\\v1.0' ) ; $cp = ( $ { CHCP_COM } | Select - String '\\\\d+' ) . Matches . Value ; $ { CHCP_COM } 65001 ; $ { CHCP_COM } $cp ;", "del_tokens": "const POWERSHELL_DIR = path . join ( WINDOWS_DIR , 'System32\\\\WindowsPowerShell\\\\v1.0' ) ; $cp = ( chcp | Select - String '\\\\d+' ) . Matches . Value ; chcp 65001 ; chcp $cp ;", "commit_type": "use"}
{"commit_tokens": ["Use", "Handlebars", "s", "escapeExpression", "when", "stringifying", "JSON"], "add_tokens": "const Handlebars = require ( 'handlebars' ) ; const replacer = ( key , value ) => _ . isString ( value ) ? Handlebars . Utils . escapeExpression ( value ) : value ; const args = [ obj , replacer ] ; args . push ( 2 ) ; return new Handlebars . SafeString ( JSON . stringify ( ... args ) ) ;", "del_tokens": "const Handlerbars = require ( 'handlebars' ) ; var d ; d = JSON . stringify ( obj , null , 2 ) ; } else { d = JSON . stringify ( obj ) ; return new Handlerbars . SafeString ( d ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "csslint", "and", "less", "parser", "in", "pre", "-", "commit", "hook"], "add_tokens": "var lines = [ ] , isInBlock = false ; isInBlock = false ; if ( isInBlock ) { isInBlock = true ; } } ) ; return lines . join ( \"\\n\" ) . replace ( / \\{\\$(\\w+\\.)*\\w+\\} / g , \"{}\" ) ; } , extractStyles : function ( src ) { var lines = [ ] , isInBlock = false ; src . replace ( / \\r / g , \"\" ) . split ( \"\\n\" ) . forEach ( function ( l ) { // we're at the end of the style tag if ( l . indexOf ( \"</style\" ) > - 1 ) { lines [ lines . length ] = \"\" ; isInBlock = false ; return ; } if ( isInBlock ) { lines [ lines . length ] = l ; } else { lines [ lines . length ] = \"\" ; } if ( l . indexOf ( \"<style\" ) > - 1 ) { isInBlock = true ;", "del_tokens": "var lines = [ ] , isInScript = false ; isInScript = false ; if ( isInScript ) { isInScript = true ;", "commit_type": "use"}
{"commit_tokens": ["add", "not", "equals", "built", "in", "functor"], "add_tokens": "'!=/2' : ( v1 , v2 ) => { assertIsValue ( v1 ) ; assertIsValue ( v2 ) ; return v1 . evaluate ( ) != v2 . evaluate ( ) ; } ,", "del_tokens": "console . log ( 'HELLLO' )", "commit_type": "add"}
{"commit_tokens": ["Updated", "NPM", "package", "name", "to", "currentscript"], "add_tokens": "* v0 .1 .6", "del_tokens": "* v0 .1 .5", "commit_type": "update"}
{"commit_tokens": ["Update", "default", "values", "less", "concurrency"], "add_tokens": "var config = require ( \"../config/configuration.js\" ) ; var spawner = require ( 'sspawn' ) ( server , { port : config . port , workers : config . workers } ) ;", "del_tokens": "var configuration = require ( \"../config/configuration.js\" ) ; var spawner = require ( 'sspawn' ) ( server , { port : configuration . port } ) ;", "commit_type": "update"}
{"commit_tokens": ["removed", "arialinter", "from", "doNotUseElementB", "rule", "replaced", "by", "specific", "rule"], "add_tokens": "var uri = '<!doctype html><html><head><title>test hola</title></head><body style=\"background-color: white;\"> <h1 style=\"color: black;\">hola mundo</h1> <b>asdf</b> </body> </html>' , rule = RuleRegistry . getRule ( 'doNotUseElementB' ) ; jsdom . env ( uri , [ 'http://code.jquery.com/jquery.js' ] , function ( err , window ) { test . notEqual ( rule . applyRule ( window ) , true , 'Should fail because it has b element' ) ;", "del_tokens": "var uri = '<!doctype html><html><head><title>test hola</title></head><body style=\"background-color: white;\"> <h1 style=\"color: black;\">hola mundo</h1> <b>asdf</b> </body> </html>' ; AriaLinter . initialize ( uri , function ( ) { test . equal ( AriaLinter . evaluate ( ) , false , 'Should fail because it has b element' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Move", "validateFloat", "to", "separate", "module"], "add_tokens": "var util = require ( '../util' ) ; this . model . _dx = app . crossfilter . dimension ( function ( d ) { return util . validateFloat ( d [ key ] ) ; } ) ;", "del_tokens": "this . model . _dx = app . crossfilter . dimension ( function ( d ) { return + d [ key ] ; } ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "initial", "indentation", "to", "jsbeautify"], "add_tokens": "function update ( repoId , repoPath , dest , addHeader , patch ) { if ( patch ) { content = patch ( content ) ; } function patchHTMLFormatter ( content ) { return content . replace ( 'this.indent_level = 0;' , 'this.indent_level = (options.indent_level === undefined) ? 0 : parseInt(options.indent_level, 10);' ) ; } update ( 'beautify-web/js-beautify' , 'js/lib/beautify-html.js' , './src/beautify/beautify-html.js' , true , patchHTMLFormatter ) ;", "del_tokens": "function update ( repoId , repoPath , dest , addHeader ) { update ( 'beautify-web/js-beautify' , 'js/lib/beautify-html.js' , './src/beautify/beautify-html.js' , true ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "hooks", "for", "deep", "cloning", "and", "equality"], "add_tokens": "args [ i ] = val instanceof adt . __Base__ ? val . clone ( ) : adt . nativeClone ( val ) ; throw new Error ( 'Field index out of range: ' + field ) ; throw new Error ( 'Field name does not exist: ' + field ) ; } else if ( ! adt . nativeEquals ( vala , valb ) ) return false ; // Cloning for native JS types just returns a reference. adt . nativeClone = function ( x ) { return x ; } ; // Equality for native JS types is just strict comparison. adt . nativeEquals = function ( a , b ) { return a === b ; } ;", "del_tokens": "args [ i ] = val instanceof adt . __Base__ ? val . clone ( ) : val ; throw new Error ( 'Field index out of range' ) ; throw new Error ( 'Field name does not exist' ) ; } else if ( vala !== valb ) return false ;", "commit_type": "add"}
{"commit_tokens": ["Added", "comments", ".", "Removed", "console", "."], "add_tokens": "var ErrorsObj ; var defaultValidationOpts ; var processValidateOpts ; // Gets properties from the map's define property. // Default Map for errors object. Useful to add instance helpers // Default validation options to extend passed options from // Processes validation options, creates computes from functions and adds listeners // Loop through each validation option // create compute and add it to computes array // build the map for the final validations object // Using the computes array, create necessary listeners // Build validation options from defaults and processed options // Validate item", "del_tokens": "var ErrorsObj ; var defaultValidationOpts ; var processValidateOpts ; // create compute", "commit_type": "add"}
{"commit_tokens": ["Improve", "testing", "of", "end", "event"], "add_tokens": "// streamCompare may read from either stream first and the 'end' event // does not fire until read() is called after EOF, so we emit directly // for first stream. Then streamCompare must read from the second. process . nextTick ( function ( ) { stream1 . emit ( 'end' ) ; stream2 . end ( ) ; } ) ; stream2 . once ( 'end' , function ( ) { process . nextTick ( function ( ) { stream1 . emit ( 'end' ) ; } ) ; } ) ;", "del_tokens": "stream1 . end ( ) ; stream2 . end ( ) ; stream1 . emit ( 'end' ) ;", "commit_type": "improve"}
{"commit_tokens": ["Changed", "log", "levels", "to", "make", "debugging", "easier"], "add_tokens": "log . debug ( 'larvitrouter: loadPaths() - Application path: ' + res . path ) ; log . debug ( 'larvitrouter: loadPaths() - Module path: ' + res . dependencies [ module ] . path ) ; log . silly ( 'larvitrouter: fileExists() - pathToResolve, \"' + pathToResolve + '\", starts with \"/\", only check aboslute path' ) ; log . silly ( 'larvitrouter: fileExists() - pathToResolve, \"' + pathToResolve + '\", is relative, look in all the paths' ) ; log . silly ( 'larvitrouter: fileExists() - Checking for ' + testPath ) ; log . silly ( 'larvitrouter: fileExists() - Found ' + testPath + ' in cache' ) ; log . silly ( 'larvitrouter: fileExists() - ' + testPath + ' does not exist' ) ;", "del_tokens": "log . verbose ( 'larvitrouter: loadPaths() - Application path: ' + res . path ) ; log . verbose ( 'larvitrouter: loadPaths() - Module path: ' + res . dependencies [ module ] . path ) ; log . debug ( 'larvitrouter: fileExists() - pathToResolve starts with \"/\", only check aboslute path' ) ; log . debug ( 'larvitrouter: fileExists() - pathToResolve is relative, look in all the paths' ) ; log . debug ( 'larvitrouter: fileExists() - Checking for ' + testPath ) ; log . debug ( 'larvitrouter: fileExists() - Found ' + testPath + ' in cache' ) ; log . debug ( 'larvitrouter: fileExists() - ' + testPath + ' does not exist' ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "browser", "proxy", "path", "generation", "when", "calling", "a", "base", "level", "method"], "add_tokens": "var isBase = parentPath . length === 0 ; path = parentPath . join ( '/' ) + ( isBase ? '' : '/' ) + key ;", "del_tokens": "path = parentPath . join ( '/' ) + '/' + key ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "node", "-", "sass", "dependency"], "add_tokens": "gulp . task ( 'build-demo' , [ 'compile-components' ] , function ( ) { 'compile-components' ] , function ( ) {", "del_tokens": "// ===========================================================// // ======================== Styles ===========================// // ===========================================================// / ** * To complie * . scss files into * css , run * ` ` * / gulp . task ( 'compile-scss' , shell . task ( [ path . normalize ( './node_modules/.bin/node-sass ' ) + path . normalize ( 'demo/client/scss/main.scss ' ) + path . normalize ( 'demo/client/css/main.css' ) ] ) ) ; gulp . task ( 'build-demo' , [ 'compile-components' , 'compile-scss' ] , function ( ) { 'compile-components' , 'compile-scss' ] , function ( ) { gulp . watch ( './demo/client/scss/*.scss' , [ 'compile-scss' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "Visible", ".", "hidden", "()", "as", "proxy", "to", "document", ".", "hidden", "with", "vendor", "prefix"], "add_tokens": "\"use strict\" ; } , // Return true if page now isn't visible to user. // It is just proxy to document.hidden, but use vendor prefix. hidden : function ( ) { if ( ! this . support ( ) ) { return false ; } return this . _prop ( 'hidden' ) ; } ;", "del_tokens": "\"use strict\" }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "exclude", "option"], "add_tokens": "tag : timestamp , exclude : [ ] var command = \"tar -czvf ./deploy.tgz\" ; if ( options . exclude . length ) { options . exclude . forEach ( function ( exclusion ) { command += ' --exclude=' + exclusion ; } ) ; } command += \" --exclude=deploy.tgz --ignore-failed-read --directory=\" + options . local_path + \" .\" ; command += \" --directory=\" + options . local_path + \" .\" ;", "del_tokens": "tag : timestamp var command ; command = \"tar -czvf ./deploy.tgz --ignore-failed-read --directory=\" + options . local_path + \" . --exclude=deploy.tgz\" ; command = \"tar -czvf ./deploy.tgz --directory=\" + options . local_path + \" .\" ;", "commit_type": "add"}
{"commit_tokens": ["Create", "clean", ":", "docs", "task", "to", "run", "before", "starting", "docs", "task"], "add_tokens": "gulp . task ( 'clean:docs' , function ( ) { return del ( [ 'dist/docs/**/*' ] ) ; } ) ; gulp . task ( 'docs' , [ 'clean:docs' ] , function ( ) {", "del_tokens": "gulp . task ( 'docs' , function ( ) {", "commit_type": "create"}
{"commit_tokens": ["Moved", "some", "status", "messages", "to", "debug"], "add_tokens": "self . status ( 'Running ' + worker_count + ' workers..' , 'debug' ) ; //Tell each worker to load the job - send `i` so that the worker self . status ( 'Running 1 worker..' , 'debug' ) ;", "del_tokens": "self . status ( 'Running ' + worker_count + ' workers..' ) ; //Tell each worker to load the job - send i so that the worker self . status ( 'Running 1 worker..' ) ;", "commit_type": "move"}
{"commit_tokens": ["fixing", "bug", "in", "mozuhosted", "mode"], "add_tokens": "var cmps ; if ( ! process . env . mozuHosted ) { assert ( context . appKey , \"No application key in context!\" ) ; cmps = [ context . appKey ] ; } else { cmps = [ 'mozuHosted' ] ; } var ticket = claimsCaches [ claimtype ] [ generateCacheKey ( claimtype , context ) ] ;", "del_tokens": "assert ( context . appKey , \"No application key in context!\" ) ; var cmps = [ context . appKey ] ; var ticket = claimsCaches [ claimtype ] [ generateCacheKey ( claimtype , context ) ] ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "APIs", "functions", ":", "filter", "()", "map", "()", "reduce", "()", "every", "()", "some", "()", "."], "add_tokens": "div = Mark . parse ( '{div \"text\" {br} \"more\" {b \"bold\"} {!-- comment --}}' ) ; assert . deepEqual ( div . filter ( n => typeof n === 'string' ) , [ \"text\" , \"more\" ] , \"Mark filter API\" ) ; // map assert . deepEqual ( div . map ( n => typeof n ) , [ \"string\" , \"object\" , \"string\" , \"object\" , \"object\" ] , \"Mark map API\" ) ; // reduce assert . equal ( div . reduce ( ( result , n , i ) => result + ( i ? ', ' : '' ) + ( typeof n ) , 'type: ' ) , \"type: string, object, string, object, object\" , \"Mark reduce API\" ) ; // every assert . equal ( div . every ( n => typeof n != 'number' ) , true , \"Mark every API\" ) ; assert . equal ( div . every ( n => typeof n != 'object' ) , false , \"Mark every API\" ) ; // some assert . equal ( div . some ( n => n . constructor && n . constructor . name == 'b' ) , true , \"Mark some API\" ) ; assert . equal ( div . some ( n => n . constructor && n . constructor . name == 'div' ) , false , \"Mark some API\" ) ;", "del_tokens": "//div = Mark.parse('{div \"text\" {br} \"more\" {b \"bold\"} {!-- comment --}}'); //div.length = 5; //assert.equal(div.filter(function (n) { console.log('n', n); return typeof n === 'string'; }), [\"text\", \"more\"], \"Mark filter API\");", "commit_type": "add"}
{"commit_tokens": ["Remove", "underbar", "from", "_named", "."], "add_tokens": "bytesRead = 0 , skipping , repeat , step , named , index , arrayed , named = named || ! ! field . name ; if ( named ) {", "del_tokens": "bytesRead = 0 , skipping , repeat , step , _named , index , arrayed , _named = _named || ! ! field . name ; if ( _named ) {", "commit_type": "remove"}
{"commit_tokens": ["updated", "watson", "twitter", "and", "app"], "add_tokens": "//Returns a collection of the most recent Tweets and retweets posted by the authenticating user and the users they follow. The home timeline is central to how most users interact with the Twitter service. Watson . prototype . userHome = function ( params , callback ) { var getdata = function ( err , data , response ) { for ( var i = 0 ; i < data . length ; i ++ ) { twitterData += data [ i ] . text ; } watsonModule . watson ( watsonConfig , twitterData , callback ) ; } ; if ( params ) { T . get ( 'statuses/home_timeline' , params , getData ( err , data , response ) ; } else { T . get ( 'statuses/home_timeline' , getData ( err , data , response ) ; } } ; // function(err, data, response) { //for search tweets // for(var i = 0; i < data.statuses.length; i++) { // // accumulate the data (each tweet as a text) received from twitter // twitterData += data.statuses[i].text; // }", "del_tokens": "//console.log(twitterData); //console.log(data.statuses.length) // for(var i = 0; i < data.statuses.length; i++) { // // accumulate the data (each tweet as a text) received from twitter // twitterData += data.statuses[i].text; // } // console.log('TTTTTTTTTTTTTTTTTTTTTT ' + twitterData + ' TTTTTTTTTTTTTTTTTTTTTT') //watsonModule.watson(watsonConfig, twitterData); // function(err, data, response) {", "commit_type": "update"}
{"commit_tokens": ["Use", "namespaces", "internally", "everywhere", "."], "add_tokens": "console . error ( '' + err ) ;", "del_tokens": "console . error ( err ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "example", "for", "dantil", ".", "deleteModuleCache", "()"], "add_tokens": "* Deletes modules from cache , forcing them to be reloaded at next ` ` call . Without removing a module from cache , subsequent ` ` calls to the same module will not enable changes to its file ( s ) . * This is useful for debugging code on a server without restarting the server . * @ example * // Load module * var myModule = require ( './myModule.js' ) * * // Remove module from cache * dannyUtil . deleteModuleCache ( './myModule.js' ) * * // Load module again, enabling changes to './myModule.js' * myModule = require ( './myModule.js' )", "del_tokens": "* Deletes modules from cache , forcing them to be reloaded at next ` ` call . * Useful for debugging code on a server without restarting the server .", "commit_type": "add"}
{"commit_tokens": ["Add", "source", "as", "a", "separate", "command"], "add_tokens": "'echo \"hello world\"\\nalias foo bar\\n' . to ( 'a.sh' ) ; cd . . ` . to ( 'b.sh' ) ; $ . rm ( '-f' , [ 'a.sh' , 'b.sh' , 'nonreadable.txt' ] ) ; cash . source ( 'b.sh' ) ; cash . source ( 'b.sh' ) ; console . log ( cash . cat ( 'a.sh' ) ) ; cash . source ( 'a.sh' ) ;", "del_tokens": "` ` . to ( 'a.sh' ) ; 'echo \"hello world\"\\nalias foo bar\\n' . to ( 'b.sh' ) ; cd . . ` . to ( 'c.sh' ) ; ` ` . to ( 'd.sh' ) ; $ . rm ( '-f' , [ 'a.sh' , 'b.sh' , 'c.sh' , 'd.sh' , 'nonreadable.txt' ] ) ; cash . source ( 'c.sh' ) ; cash . source ( 'c.sh' ) ; console . log ( cash . cat ( 'b.sh' ) ) ; cash . source ( 'b.sh' ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "embedding", "nested", "Schema", "vs", "an", "object", "(", "latter", "allowed", "in", "newest", "mongoose", "only", ")"], "add_tokens": "* The schema for an embedded friendship . ( Treated as an object for compat * with embedding schemas ) var Friendship = { }", "del_tokens": "* The schema for an embedded friendship var Friendship = new mongoose . Schema ( { } )", "commit_type": "fix"}
{"commit_tokens": ["added", "---", "operator", "to", "finish", "async", "calls"], "add_tokens": "if ( this . __break ) return true if ( this . next . text == \"---\" ) { var text = this . next . myText ( ) ; this . next . replaceWith ( text . replace ( \"---\" , \" \" ) ) this . next . __break = true }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "references", "to", "scoped", "property", "methods", "and", "adjust", "some", "of", "the", "AS", "objects"], "add_tokens": "this . connection . disconnect ( ) ; '@type' : 'presence' , '@type' : 'presence' , status : '' , presence : state '@type' : 'presence' , '@type' : 'presence' , presence : 'notauthorized' this . scope . debug ( 'received buddy presence update: ' + from + ' - ' + state ) ; '@type' : 'presence' , '@type' : 'presence' , status : statusText , presence : state this . scope . client . remove ( this . credentials . actor [ '@id' ] ) ;", "del_tokens": "client . disconnect ( ) ; '@type' : 'update' , statusText : '' , state : 'offline' '@type' : 'update' , state : 'notauthorized' this . scope . debug ( 'received buddy state update: ' + from + ' - ' + state ) ; '@type' : 'update' , content : statusText , state : state session . clientManager . remove ( this . credentials . actor [ '@id' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "reading", "GDAL", "metadata", "in", "Firefox", "."], "add_tokens": "var string = this . fileDirectory . GDAL_METADATA ; var xmlDom = globals . parseXml ( string . substring ( 0 , string . length - 1 ) ) ;", "del_tokens": "var xmlDom = globals . parseXml ( this . fileDirectory . GDAL_METADATA ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "dependencies", "for", "TODO", "example"], "add_tokens": "// An example Backbone application that uses a Firebase adapter to persist // Backbone models. Based on a project by Jrme Gravel-Niquet (http://jgn.me/).", "del_tokens": "// An example Backbone application contributed by // [Jrme Gravel-Niquet](http://jgn.me/). This demo uses a simple // Firebase adapter to persist Backbone models.", "commit_type": "update"}
{"commit_tokens": ["Improve", "setRange", "and", "fix", "a", "few", "Vector", "bugs"], "add_tokens": "return ( begin === 0 || ( length != null && begin <= - length ) ) &&", "del_tokens": "return ( begin <= 0 || ( length != null && begin <= - length ) ) &&", "commit_type": "improve"}
{"commit_tokens": ["fixed", "bug", "with", "saving", "result", "css", "file"], "add_tokens": "if ( lExt === '.css' ) { /* if it's css and last file */ lAllCSS += pFinalCode ; if ( lMoreProcessing_f . img || lMoreProcessing_f === true ) lMinIMg_b = true ; }", "del_tokens": "else if ( lExt === '.css' ) { /* if it's css and last file */ lAllCSS += pFinalCode ; if ( lMoreProcessing_f . img || lMoreProcessing_f === true ) lMinIMg_b = true ; }", "commit_type": "fix"}
{"commit_tokens": ["Updated", "code", "snippets", "of", "tab", "for", "scroll", "attribute", "related", "changes", "."], "add_tokens": "< script type = \"text/javascript\" language = \"javascript\" src = \"http://propeller.in/components/tab/js/tab-scrollable.js\" > < / script >", "del_tokens": "< script type = \"text/javascript\" language = \"javascript\" src = \"http://propeller.in/components/tab/js/tab-scrollable.js\" > < / script > < script type = \"text/javascript\" > $ ( document ) . ready ( function ( ) { $ ( '.pmd-tabs' ) . pmdTab ( ) ; } ) ; < / script >", "commit_type": "update"}
{"commit_tokens": ["Updated", "kerberos", "dependency", "and", "module", "version"], "add_tokens": "} else if ( r && typeof r == 'object' && r . result [ '$err' ] ) { } else if ( r && typeof r == 'object' && r . result [ 'errmsg' ] ) {", "del_tokens": "} else if ( r . result [ '$err' ] ) { } else if ( r . result [ 'errmsg' ] ) {", "commit_type": "update"}
{"commit_tokens": ["add", "test", "for", "admin", "routing"], "add_tokens": "// launch httpd for Admin UI", "del_tokens": "// launch httpd for Admin UI on $PORT + 1 // admin panel!", "commit_type": "add"}
{"commit_tokens": ["removing", "lodash", "from", "console", "wrapper"], "add_tokens": "throw new Error ( rest . find ( e => e instanceof Error ) || rest [ 0 ] ) ;", "del_tokens": "import _ from 'lodash' ; throw new Error ( _ . find ( rest , ( e ) => e instanceof Error ) || _ . head ( rest ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Using", "xtend", "to", "decrease", "the", "code", "complexity", "because", "of", "the", "options"], "add_tokens": "var extend = require ( \"xtend\" ) ; // Resolve the options opts = extend ( { // Setting the default coverage file generated by istanbul cobertura report. istanbulReportFile : \"./coverage/cobertura-coverage.xml\" , // The default location for the destination being the coverage directory from istanbul. destinationDir : null , // The shields host to be used for retrieving the badge. https://github.com/badges/shields shieldsHost : process . env . SHIELDS_HOST || \"https://img.shields.io\" , // The name of the badge file to be generated badgeFileName : \"coverage\" , // The thresholds to be used to give colors to the badge. thresholds : defaultThresholds } , opts ) ;", "del_tokens": "opts = opts || { } ; // Setting the default coverage file generated by istanbul cobertura report. opts . istanbulReportFile = opts . istanbulReportFile || \"./coverage/cobertura-coverage.xml\" ; // The default location for the destination being the coverage directory from istanbul. opts . destinationDir = opts . destinationDir || null ; // The shields host to be used for retrieving the badge. https://github.com/badges/shields opts . shieldsHost = opts . shieldsHost || process . env . SHIELDS_HOST || \"https://img.shields.io\" //if (!opts.destinationDir) { // throw Error(\"The option 'destinationDir' must be provided\"); //} // The name of the badge file to be generated opts . badgeFileName = opts . badgeFileName || \"coverage\" ; // The thresholds to be used to give colors to the badge. opts . thresholds = opts . thresholds || defaultThresholds ; opts . thresholds . excellent = opts . thresholds . excellent || defaultThresholds . excellent ; opts . thresholds . good = opts . thresholds . good || defaultThresholds . good ;", "commit_type": "use"}
{"commit_tokens": ["Add", ".", "match", "()", "for", "just", "matching", "and", "returning", "routes"], "add_tokens": "var routington = require ( 'routington' ) var assert = require ( 'assert' ) var router = routington ( ) emit . match = match var node = router . define ( path ) [ 0 ] // match and call a route var matched = match ( path ) if ( matched ) matched . node . cb ( path , matched . param ) } // match and return route // str -> obj function match ( path ) { return router . match ( path ) || router . match ( dft )", "del_tokens": "const routington = require ( 'routington' ) const assert = require ( 'assert' ) const router = routington ( ) const node = router . define ( path ) [ 0 ] // match a route const match = router . match ( path ) || router . match ( dft ) match . node . cb ( path , match ? match . param : { } )", "commit_type": "add"}
{"commit_tokens": ["Adding", "content", "about", "registering", "partials", "in", "README", ".", "md"], "add_tokens": "// Registering partials", "del_tokens": "// Registering custom partials if present", "commit_type": "add"}
{"commit_tokens": ["move", "dsl", "-", "fstr", "to", "dslfs", "and", "make", "react", "fn", "just", "the", "core", "not", "dsl"], "add_tokens": "module . exports = core ; module . exports . dslfs = require ( './lib/dslfs.js' ) ;", "del_tokens": "var dsl = require ( './lib/dsl-fstr.js' ) ; module . exports = dsl ;", "commit_type": "move"}
{"commit_tokens": ["added", "runnerId", "to", "context", "so", "strider", "-", "git", "can", "select", "ssh", "git", "clone", "implementation", "based", "on", "runner", "e", ".", "g", ".", "docker", "runner"], "add_tokens": "project : this . project , runnerId : this . config . branchConfig . runner . id", "del_tokens": "project : this . project", "commit_type": "add"}
{"commit_tokens": ["Allow", "skipping", "examples", "for", "hosted", "build"], "add_tokens": "const config = require ( './config' ) ; if ( filename . indexOf ( 'index.html' ) !== - 1 && filename . indexOf ( '.swp' ) === - 1 && config . skip . indexOf ( filename . split ( path . sep ) [ 0 ] ) === - 1 ) { const id = filename . split ( path . sep ) [ 0 ] ; if ( config . skip . indexOf ( id ) !== - 1 ) { delete files [ filename ] ; }", "del_tokens": "if ( filename . indexOf ( 'index.html' ) !== - 1 && filename . indexOf ( '.swp' ) === - 1 ) { const id = filename . split ( path . sep ) [ 0 ] ;", "commit_type": "allow"}
{"commit_tokens": ["Allow", "class", "name", "overriding", "for", "filter", "and", "page", "size"], "add_tokens": "className : PropTypes . string , className = 'col-md-6' , className = { className }", "del_tokens": "className = \"col-md-6\"", "commit_type": "allow"}
{"commit_tokens": ["Add", "debug", "output", "buttons", "to", "demo"], "add_tokens": "if ( source !== targetWindow || data . status !== 'ok' || data . result !== 'pong' || data . id !== 1 || ( targetOrigin !== '*' && origin !== targetOrigin ) ) return ; window . removeEventListener ( 'message' , connectedListener ) ; reject ( new Error ( 'Connection timeout' ) ) ; } , 10 * 1000 ) ; console . debug ( 'RpcClient REQUEST' , command , args ) ; console . debug ( 'RpcClient RECEIVE' , data ) ; } else { console . warn ( 'Unknown RPC response:' , data ) ;", "del_tokens": "} else { console . log ( 'Received:' , origin , data ) ; if ( source !== targetWindow || data . status !== 'ok' || data . result !== 'pong' || data . id !== 1 || ( targetOrigin !== '*' && origin !== targetOrigin ) ) return ; reject ( new Error ( 'Connection timeout' ) ) ; } , 30 * 1000 ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "order", "of", "parameters", "of", "findIndex", "()", "and", "findLastIndex", "()"], "add_tokens": "* Returns index of first element for which function findIndex : curry ( function ( fn , arr ) { arr . some ( ( x , i ) => { } ) , * Returns index of last element for which function findLastIndex : curry ( function ( fn , arr ) { } ) ,", "del_tokens": "* Returns index of first element for which function findIndex : function ( arr , fn ) { arr . some ( ( x , i ) => { } , * Returns index of last element for which function findLastIndex : function ( arr , fn ) { } ,", "commit_type": "change"}
{"commit_tokens": ["added", "missing", "propertyId", "while", "reading", "values"], "add_tokens": "sql += ' JOIN properties `p` ON p.`index_id` = `d' + property . dimensions . length + '`.`property_index_id`' ;", "del_tokens": "sql += ' JOIN properties `p` ON p.`index_id` = d.`property_index_id`' ;", "commit_type": "add"}
{"commit_tokens": ["Use", "sourceURL", "to", "preserve", "paths", "at", "least", "until", "we", "have", "source", "maps"], "add_tokens": "function JavaScriptConcatenatorCompiler ( options ) { for ( var key in options ) { if ( options . hasOwnProperty ( key ) ) { this [ key ] = options [ key ] } } } var self = this if ( ! self . useSourceURL ) { appJs . write ( fileContents + '\\n' ) } else { // Should pull out copyright comment headers var evalExpression = \"eval('\" + jsStringEscape ( fileContents ) + \"//# sourceURL=\" + jsStringEscape ( fileInfo . relativePath ) + \"');\\n\" appJs . write ( evalExpression ) } JavaScriptConcatenatorCompiler . prototype . useSourceURL = true", "del_tokens": "function JavaScriptConcatenatorCompiler ( ) { } // Wrap in eval for sourceURL? appJs . write ( fileContents + '\\n' )", "commit_type": "use"}
{"commit_tokens": ["Add", "replacer", "test", "+", "fix", "parsing", "escaped", "safe", "chars"], "add_tokens": "} else if ( value [ 0 ] == '\\\\' && value [ 1 ] == 'x' && value [ 2 ] == '7' && value [ 3 ] == 'e' ) {", "del_tokens": "} else if ( value [ 0 ] == '\\\\' && value [ 1 ] == 'x' && value [ 2 ] == 'e' && value [ 3 ] == '7' ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "importing", "in", "addons", "/", "engines"], "add_tokens": "// Fix for loading it in addons/engines if ( typeof app . import !== 'function' && app . app ) { app = app . app ; } app . import ( app . bowerDirectory + '/gettext.js/dist/gettext.min.js' , {", "del_tokens": "app . import ( app . bowerDirectory + '/gettext.js/dist/gettext.min.js' , {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "crash", "on", "uninstall", "if", "target", "file", "doesn", "t", "exist", "."], "add_tokens": "deleteFile ( destinationPath ) ; deleteFile ( destinationPath ) ; } function deleteFile ( destinationPath ) { if ( fs . existsSync ( destinationPath ) ) { console . log ( \"Deleting file: \" + destinationPath ) ; fs . unlink ( destinationPath ) ; }", "del_tokens": "console . log ( \"Deleting file: \" + destinationPath ) ; fs . unlink ( destinationPath ) ; console . log ( \"Deleting file: \" + destinationPath ) ; fs . unlink ( destinationPath ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "max_buffer", "to", "specify", "the", "maximum", "amount", "of", "data", "on", "stdout"], "add_tokens": "zip_deploy : false , max_buffer : 200 * 1024 var execOptions = { maxBuffer : options . max_buffer } ; childProcessExec ( cmd , execOptions , function ( err , stdout , stderr ) {", "del_tokens": "zip_deploy : false childProcessExec ( cmd , function ( err , stdout , stderr ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "comment", "for", "ngAMD", ".", "route"], "add_tokens": "* Helper function to generate angular 's $routeProvider.route. ' config ' * * Populate the resolve attribute using either 'controllerUrl' or 'controller' . If 'controllerUrl' * is passed , it will attempt to load the passed Url using requirejs and remove the attribute from * the result . Otherwise , it will attempt to populate resolve by loading what ' * 'controller' . If neither is passed , resolve is not populated . * * This function works as a pass - through , meaning what ever is passed in as config will be returned , * except for 'controllerUrl' attribute .", "del_tokens": "* Return route for given controller and set the resolver to instantiate defined controller . * controller_path is needed to allow requirejs to find the code for controller . If the path * to controller is defined in require . config , it can then be omitted . * @ param : { string } templateURL : Path to the html template * @ param : { string } controller : Name of the controller to use * @ param : { string } controller_path : Path to the controller to be loaded that requirejs will understand . * If not provided , will attempt to load using @ controller", "commit_type": "update"}
{"commit_tokens": ["Updating", "sync", "controller", "to", "update", "search", "index"], "add_tokens": "constructor ( server , config , documentRepository , searchProvider ) { this . _searchProvider = searchProvider ; this . _searchProvider . indexAdd ( newDoc ) ; this . _searchProvider . indexUpdate ( newDoc ) ;", "del_tokens": "constructor ( server , config , documentRepository ) {", "commit_type": "update"}
{"commit_tokens": ["improved", "docs", "for", "steal", "-", "tools"], "add_tokens": "* Adding \"+cjs\" to a [ steal - tools . export . output ] name will mixin * default [ steal - tools . export . output ] and [ steal - tools . transform . options ] * You can overwrite or alter the behavior of these default values by adding a value in * the [ steal - tools . export . output ] . * The behavior for overwriting [ steal - tools . export . output ] values is * documented in the default value API pages .", "del_tokens": "* Adding \"+cjs\" to a [ steal - tools . exporter . output ] name will mixin * default [ steal - tools . exporter . output ] and [ steal - tools . pluginify . options ] * You can overwrite or alter the behavior of these default values by adding a value in the [ steal - tools . exporter . output ] . * The behavior for overwriting [ steal - tools . exporter . output ] values is documented in the default value API pages .", "commit_type": "improve"}
{"commit_tokens": ["Fix", "issue", "with", "Print", "grid"], "add_tokens": "requestMethod : $scope . requestMethod || 'POST' ,", "del_tokens": "requestMethod : $scope . requestMethod ,", "commit_type": "fix"}
{"commit_tokens": ["added", "update", "method", "to", "global", "api"], "add_tokens": "* AngularJS - nvD3 , v0 .1 .0 ; MIT License ; 08 / 06 / 2014 17 : 19 // Update chart layout (for example if container is resized) update : function ( ) { scope . chart . update ( ) ; } ,", "del_tokens": "* AngularJS - nvD3 , v0 .0 .9 ; MIT License ; 07 / 24 / 2014 12 : 59", "commit_type": "add"}
{"commit_tokens": ["Add", "custom", "build", "info", "to", "vendor", "dependencies"], "add_tokens": "2017 - 05 - 13 Custom build by Erik Koopmans , featuring latest bugfixes and features Released under MIT License", "del_tokens": "Released under License", "commit_type": "add"}
{"commit_tokens": ["Added", "implementation", "of", "HTMLCollection", "for", "Element", ".", "getElementsByTagName"], "add_tokens": "* @ param tagName * / value : function getElementsByTagName ( tagName ) { return this . documentElement . getElementsByTagName ( tagName ) ; return this . documentElement . getElementsByClassName ( className ) ;", "del_tokens": "* @ param tagName * @ param _array * / value : function getElementsByTagName ( tagName , _array ) { return this . documentElement . getElementsByTagName ( tagName , _array ) ; throw new Error ( 'Not implemented' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "getEntryPoint", "when", "no", "bundleMain", "present", "in", "package", ".", "json"], "add_tokens": "entryModule = exports . getPackageMain ( appDir ) ; // Strip leading dir name and return just the submodule. return entryModule . replace ( / ^[^\\\\\\/]+[\\\\\\/] / , \"./\" ) ;", "del_tokens": "entryModule = path . join ( appDir , exports . getPackageMain ( appDir ) ) ; return \"./\" + entryModule ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "for", "block", ".", "validateTransactions", "and", "validateDifficulty", "some", "extra", "test", "data"], "add_tokens": "t . equal ( dif . toString ( ) , test . currentDifficulty . toString ( ) , 'test canonicalDifficulty()' ) t . assert ( block . header . validateDifficulty ( parentBlock ) , 'test validateDifficulty()' )", "del_tokens": "t . equal ( dif . toString ( ) , test . currentDifficulty . toString ( ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "start", "/", "stop", "methods", "to", "profile", "and", "template", "services"], "add_tokens": "'Services.Configuration' , 'Q' function profileServiceFactory ( FileLoader , configuration , Q ) { } ProfileService . prototype . start = function start ( ) { return this . load ( ) ; } ; ProfileService . prototype . stop = function stop ( ) { return Q . resolve ( ) ; } ;", "del_tokens": "'Services.Configuration' function profileServiceFactory ( FileLoader , configuration ) { this . load ( ) . done ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Use", "ISO", "8601", "format", "for", "date", "-", "picker"], "add_tokens": "danjuriqi : new Date ( '2017-02-14' ) . toISOString ( ) ,", "del_tokens": "danjuriqi : '2017-02-14' ,", "commit_type": "use"}
{"commit_tokens": ["Add", "new", "method", "get", "to", "get", "random", "range"], "add_tokens": "range = range . concat ( this [ i ] . set ( 0 , this [ i ] . length ) ) ; if ( Number ( count ) ) { range = range . slice ( 0 , Number ( count ) ) ;", "del_tokens": "range . concat ( this [ i ] . set ( 0 , this [ i ] . length ) ) ; if ( count ) { range = range . slice ( 0 , count ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "specifying", "release", "tag", "names"], "add_tokens": ". option ( '-f, --future-release <version>' , '[optional] specify the next release version' ) . option ( '-t, --future-release-tag <name>' , '[optional] specify the next release tag name if it is different from the release version' ) const futureReleaseTag = program . futureReleaseTag || futureRelease ; html_url : ` ${ owner } ${ repo } ${ futureReleaseTag } ` ,", "del_tokens": ". option ( '-f, --future-release <version>' , '[optional] specify the next release tag' ) html_url : ` ${ owner } ${ repo } ${ futureRelease } ` ,", "commit_type": "allow"}
{"commit_tokens": ["Add", "new", "function", "to", "add", "unique", "value", "to", "array"], "add_tokens": "// Adds an element to an array // Checks to see if it exists function addToArray ( arr , selector ) { if ( ! arrayHasValue ( arr , selector ) ) arr . push ( selector ) ; } return function ( css ) { if ( ! hasContent ) addToArray ( contentAwaiting , selector ) ; else addToArray ( contentPresent , selector ) ;", "del_tokens": "return function ( css , result ) { if ( ! arrayHasValue ( contentPresent , selector ) ) if ( ! hasContent ) contentAwaiting . push ( selector ) ; else contentPresent . push ( selector ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "memory", "leak", "and", "upgrade", "to", "express", "4"], "add_tokens": ", path = require ( 'path' ) , morgan = require ( 'morgan' ) ; app . use ( morgan ( 'dev' ) ) ; app . use ( express . static ( path . join ( __dirname , 'public' ) ) ) ; app . use ( '/db' , require ( '../../' ) ) ;", "del_tokens": ", path = require ( 'path' ) ; app . configure ( function ( ) { app . use ( express . favicon ( ) ) ; app . use ( express . logger ( 'dev' ) ) ; app . use ( express . static ( path . join ( __dirname , 'public' ) ) ) ; app . use ( '/db' , require ( '../../' ) ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "work", "w", "/", "o", "relative", "deps"], "add_tokens": "const createScatter = require ( 'regl-scatter2d/scatter' )", "del_tokens": "const createScatter = require ( '../regl-scatter2d/scatter' )", "commit_type": "make"}
{"commit_tokens": ["Move", "renderToContext", "step", "outside", "of", "createGeometry", "to", "reduce", "duplication", "of", "effort", "in", "renderers", "."], "add_tokens": "var mapRenderContext = this . renderToContext ( geoJson , projection ) ; var geometry = this . createGeometry ( mapRenderContext , isCCW ) ; createGeometry : function createGeometry ( mapRenderContext ) { createGeometry : function createGeometry ( mapRenderContext , isCCW ) { createGeometry : function createGeometry ( mapRenderContext , isCCW ) {", "del_tokens": "var geometry = this . createGeometry ( geoJson , projection , isCCW ) ; createGeometry : function createGeometry ( geoJson , projection ) { var mapRenderContext = this . renderToContext ( geoJson , projection ) ; createGeometry : function createGeometry ( geoJson , projection , isCCW ) { var mapRenderContext = this . renderToContext ( geoJson , projection ) ; createGeometry : function createGeometry ( geoJson , projection , isCCW ) { var mapRenderContext = this . renderToContext ( geoJson , projection ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "account", "and", "transaction", "method"], "add_tokens": "var tx = Transaction . fromProto ( data ) ; console . log ( tx . toString ( ) ) ; var pubkey = Transaction . recover ( tx . hash , tx . sign ) ; var formAddr = Account . fromPubKey ( pubkey ) ; console . log ( \"recover address:\" , formAddr . getAddressString ( ) ) ; if ( formAddr . getAddressString ( ) != tx . from . getAddressString ( ) ) { throw new Error ( \"transaction recover faild.\" ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["remove", "entire", "config", "extend", "per", "get"], "add_tokens": "var safeCloneInto = { value : null } ; var safeCloneFrom = { value : null } ; return safe ( configObject ) ; return safe ( getPath ( configObject , keyPath ) ) ; function configuredGet ( keyPath ) { if ( ! keyPath ) { function safe ( value ) { safeCloneInto . value = null ; safeCloneFrom . value = value ; return deepExtend ( safeCloneInto , safeCloneFrom ) . value ; }", "del_tokens": "var clonedObject = deepExtend ( { } , configObject ) ; return clonedObject ; return getPath ( clonedObject , keyPath ) ; function configuredGet ( keyPath ) { if ( ! keyPath ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "build", "number", "and", "test", "name"], "add_tokens": "verbose : true , build : process . env . TRAVIS_BUILD_NUMBER || process . env . BUILD_NUMBER , testName : \"element-resize-detector\"", "del_tokens": "verbose : true", "commit_type": "add"}
{"commit_tokens": ["Make", "additional", "and", "optional", "cached", "only", "for", "updateStrategy"], "add_tokens": "this . assets = assets ; if ( this . strategy !== 'changed' && caches !== 'all' && ( caches . additional . length || caches . optional . length ) ) { compilation . errors . push ( new Error ( 'OfflinePlugin: Cache sections `additional` and `optional` could be used ' + 'only when `updateStrategy` option is set to `changed`' ) ) ; this . caches = { } ; return ; }", "del_tokens": "this . assets = assets ;", "commit_type": "make"}
{"commit_tokens": ["adding", "some", "error", "log", "messages"], "add_tokens": "console . error ( \"Mirage: Your Ember app tried to \" + verb + \" '\" + path + \"', but there was no route defined to handle this request.\" ) ;", "del_tokens": "console . error ( \"Your Ember app tried to \" + verb + \" '\" + path + \"', but there was no Pretender route defined to handle this request.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "different", "multer", "storage", "engines"], "add_tokens": "// config Enum for when multer.storage property matches, // we set to multe.storage config to multer.memoryStorage() var MULTER_MEMORY_STORAGE = 'multerMemoryStorage' ; var multerConfig = handleMulterConfig ( config . get ( 'multer' ) , logger , serviceLoader ) ; _upload = multer ( multerConfig ) ; // Checks the multer config if the storage property is set to either the // memoryStorage enum or the name of a custom multerService implementing // a multer storage engine. function handleMulterConfig ( multerConfig , logger , serviceLoader ) { // Special handling of storage var storageString = _ . get ( multerConfig , 'storage' ) ; if ( storageString ) { var multerStorage ; if ( storageString === MULTER_MEMORY_STORAGE ) { // simple memory storage logger . debug ( 'loading simple multer memoryStorage' ) ; multerStorage = multer . memoryStorage ( ) ; } else { // otherwise try and load the service for custom multer storage engine logger . debug ( 'loading custom multer storage service' ) ; var multerService = serviceLoader . get ( storageString ) ; if ( ! multerService ) { logger . warn ( 'Multer config \"storage\" property must either be \"' + MULTER_MEMORY_STORAGE + '\"' ) ; logger . warn ( 'or the name of a service that returns a multer storage engine' ) ; } else { multerStorage = multerService . storage ; } } _ . set ( multerConfig , 'storage' , multerStorage ) ; } return multerConfig ; } }", "del_tokens": "_upload = multer ( config . get ( 'multer' ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["fix", "generators", "to", "be", "accurate"], "add_tokens": "await system . spawn ( ` ${ debugFlag } ` , { stdio : 'inherit' } )", "del_tokens": "await system . spawn ( ` ${ debugFlag } ` , { stdio : 'inherit' } )", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "ensure", "values", "are", "saved", "correctly"], "add_tokens": "if ( this . isAnswered ( opts . locale ) && opts . force !== true ) { if ( typeof opts . default === 'undefined' || opts . default === null ) { var val = utils . get ( answer , opts . name ) ; this . setDefault ( val ) ; if ( opts . save !== false && ! opts . isDefault && val !== opts . default ) { this . set ( val ) ; cb ( null , utils . set ( { } , opts . name , val ) ) ;", "del_tokens": "if ( this . isAnswered ( opts . locale ) && ! opts . force === true ) { if ( ! opts . default ) { this . setDefault ( answer ) ; if ( opts . save !== false ) { this . set ( answer ) ; cb ( null , utils . toAnswer ( opts . name , answer ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "imported", "schema"], "add_tokens": "var types = this . wsdl . definitions . types ; self . _invoke ( method , args , location , function ( error , result , raw ) { callback ( error , result , raw ) ; assert . ok ( ! style || style == 'rpc' , 'invalid message definition for document style binding' ) ; assert . ok ( ! style || style == 'document' , 'invalid message definition for rpc style binding' ) ; xml = \"<soap:Envelope \" + callback ( null , obj [ output . $name ] , body ) ; callback ( error , null , body ) ;", "del_tokens": "self . _invoke ( method , args , location , function ( error , result ) { callback ( error , result ) ; assert . ok ( style == 'rpc' , 'invalid message definition for document style binding' ) ; assert . ok ( style == 'document' , 'invalid message definition for rpc style binding' ) ; xml = \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\" + \"<soap:Envelope \" + callback ( null , obj [ output . $name ] ) ; callback ( error ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "tus", "implementation", "according", "to", "@Acconut"], "add_tokens": "var self = this ; self . setProgress ( percentage , current , total ) ; console . log ( ` ${ upload . file . name } ${ upload . url } ` ) ;", "del_tokens": "this . setProgress ( percentage , current , total ) ; console . log ( 'Download %s from %s' , upload . file . name , upload . url ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "storing", "of", "Object", ".", "create", "(", "null", ")", "data", "in", "Firestore"], "add_tokens": "( Object . getPrototypeOf ( input ) === Object . prototype || Object . getPrototypeOf ( input ) === null )", "del_tokens": "Object . getPrototypeOf ( input ) === Object . prototype", "commit_type": "allow"}
{"commit_tokens": ["adding", "updateHorse", "registerIHOHorse", "closeIHOHorse", "and", "updateHorseTrainingFee", "transactions"], "add_tokens": "case \"chargeHorseMonthlyTrainingFee\" :", "del_tokens": "case \"chargeHorseMonthlyTrainingFee\" :", "commit_type": "add"}
{"commit_tokens": ["update", "tests", "to", "new", "structure"], "add_tokens": "const Collection = require ( process . env . TEST_MIN ? '../dist/linq.commonjs.min' : '../dist/linq.commonjs' )", "del_tokens": "const Collection = require ( process . env . TEST_MIN ? '../dist/linq.min' : '../dist/linq' )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "matching", "exception", "rules"], "add_tokens": "filters : [ ] , exceptionFilters : [ ] , let newline = '\\n' ; while ( startPos <= input . length ) { endPos = input . indexOf ( newline , startPos ) ; if ( endPos === - 1 ) { newline = '\\r' ; endPos = input . indexOf ( newline , startPos ) ; } if ( parsedFilterData . isException ) { parserData . exceptionFilters . push ( parsedFilterData ) ; } else { parserData . filters . push ( parsedFilterData ) ; } export function matches ( parserData , input ) { if ( parserData . exceptionFilters . some ( ( parsedFilterData ) => matchesFilter ( parsedFilterData , input ) ) ) { return false ; } return parserData . filters . some ( ( parsedFilterData ) => matchesFilter ( parsedFilterData , input ) ) ; }", "del_tokens": "parsedFilters : [ ] , while ( startPos !== input . length ) { endPos = input . indexOf ( '\\n' , startPos ) ; parserData . parsedFilters . push ( parsedFilterData ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "cleaning", "of", "peer", "dependencies"], "add_tokens": "return [ '(*/|**/node_modules/**/)(' + targets . join ( '|' ) + ')' ] ;", "del_tokens": "var directDeps = targets . map ( function ( pattern ) { return '*/' + pattern ; } ) , indirectDeps = targets . map ( function ( pattern ) { return '**/node_modules/*/' + pattern ; } ) ; return directDeps . concat ( indirectDeps ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "copy", "function", "from", "gulpfile"], "add_tokens": "module . exports = { result = plugin ( _this ) ;", "del_tokens": "module . exports = result = plugin . extendConfiguration ( _this ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "props", ".", "onChangeText", "to", "maintain", "similar", "API"], "add_tokens": "this . props . onChangeText && this . props . onChangeText ( value ) ; //should maintain similar API to core TextInput component", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "correct", "global", "scope", "when", "inside", "WebWorker"], "add_tokens": "} ( typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : this ) ) ;", "del_tokens": "} ( typeof window !== 'undefined' ? window : this ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Upgrade", ":", "Update", "glob", "-", "stream", "dependency"], "add_tokens": "var expectedPath = path . join ( __dirname , './fixtures/wow/' ) ;", "del_tokens": "var expectedPath = path . join ( __dirname , './fixtures/wow' ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["added", "schema", "extend", "and", "tests", ".", "more", "tests", "to", "come"], "add_tokens": "* @ param name * @ param db * @ param config var BaseProto = Model . prototype ; var Base = Model ; InstanceModel . prototype = Object . create ( BaseProto ) ; InstanceModel . __proto__ = Base ; InstanceModel . prototype . __proto__ = BaseProto ; var hookFn = q [ i ] . hook ; var args = q [ i ] . args ;", "del_tokens": "* InstanceModel . prototype = Object . create ( Model . prototype ) ; InstanceModel . __proto__ = Model ; InstanceModel . prototype . __proto__ = Model . prototype ; var hookFn = q [ i ] [ 0 ] ; var args = q [ i ] [ 1 ] ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "recursive", "fn", "in", "merkle", "patricia", "tree", "proof"], "add_tokens": "it ( 'Valid Merkle Patricia tree with nested node exclusive' , function ( ) { var data = require ( './common_data/valid-merkle-patricia-tree-nested-exclusive.json' ) ; var element = Exonum . merklePatriciaProof ( data . root_hash , data . proof , data . searched_key ) ; expect ( element ) . to . equal ( null ) ; } ) ; it ( 'Valid Merkle Patricia tree with nested node inclusive' , function ( ) { var data = require ( './common_data/valid-merkle-patricia-tree-nested-inclusive.json' ) ; var element = Exonum . merklePatriciaProof ( data . root_hash , data . proof , data . searched_key ) ; expect ( element ) . to . deep . equal ( [ 36 , 49 , 15 , 31 , 163 , 171 , 247 , 217 ] ) ; } ) ;", "del_tokens": "// it('Valid Merkle Patricia tree with nested node exclusive', function() { // var data = require('./common_data/valid-merkle-patricia-tree-nested-exclusive.json'); // var element = Exonum.merklePatriciaProof( // data.root_hash, // data.proof, // data.searched_key // ); // expect(element).to.equal(null); // }); // // it('Valid Merkle Patricia tree with nested node inclusive', function() { // var data = require('./common_data/valid-merkle-patricia-tree-nested-inclusive.json'); // var element = Exonum.merklePatriciaProof( // data.root_hash, // data.proof, // data.searched_key // ); // expect(element).to.deep.equal([36, 49, 15, 31, 163, 171, 247, 217]); // });", "commit_type": "fix"}
{"commit_tokens": ["fixed", "some", "minor", "bugs", "in", "printStatus"], "add_tokens": "if ( ! ( testcase in parseResults . testcases . testcaseTable ) ) { cleanResultsStatus ( ) ; if ( criteria in criteriaAnalysis . specs [ spec ] . manual ) { mergedResults . specs [ spec ] [ criteria ] . manual = true ; } const _resultsFolder = ( resultsFolder && resultsFolder !== 'undefined' ) ? ` ${ resultsFolder } ` : '' ; console . log ( \"Spec Criteria Results:\\n\" ) ;", "del_tokens": "cleanResultsStatus ( ) ; if ( ! ( testcase in mergedResults . testcases ) ) { const _resultsFolder = ` ${ resultsFolder } ` ; console . log ( \"Spec Results:\\n\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "of", "multiple", "attributes", "in", "order", "by", "config", "in", "provider"], "add_tokens": "* Defines the attributes used to order the results . * It can be an attribute name or a list of attribute names . * It can be a boolean value or a list of boolean to match the resultOrderByAttribute . * If size of isResultOrderAscending < size of resultOrderByAttribute last value is used .", "del_tokens": "* Defines the attribute used to order the results .", "commit_type": "add"}
{"commit_tokens": ["Make", "title", "and", "toc", "optional"], "add_tokens": "title : [ 't' , 'Page title' , 'string' ] , toc : [ 'l' , 'Table of contents' , 'boolean' , false ] title : options . title , toc : options . toc", "del_tokens": "title : [ 't' , 'Page title' , 'string' , 'Locations' ] title : options . title", "commit_type": "make"}
{"commit_tokens": ["add", "unit", "test", "for", "loading", "of", "settings", "file"], "add_tokens": ". done ( function ( status , data ) {", "del_tokens": ". done ( function ( data ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "context", "introspection", "API", "to", "Wrappers"], "add_tokens": "const context = { name : 'foo' } ; it ( 'is instrospectable through context API' , ( ) => { const SimpleComponent = React . createClass ( { contextTypes : { name : React . PropTypes . string , } , render ( ) { return < div > { this . context . name } < / div > ; } , } ) ; const wrapper = mount ( < SimpleComponent / > , { context } ) ; expect ( wrapper . context ( ) . name ) . to . equal ( context . name ) ; expect ( wrapper . context ( 'name' ) ) . to . equal ( context . name ) ; } ) ;", "del_tokens": "const context = { name : 'foo' } ; const context = { name : 'foo' } ;", "commit_type": "add"}
{"commit_tokens": ["fix", "use", "of", "no", "-", "longer", "-", "existing", "variable", "in", "cursorCoords"], "add_tokens": "var local = localCoords ( start ? sel . from : sel . to ) , off = eltOffset ( lineWrap ) ;", "del_tokens": "var local = localCoords ( start ? sel . from : sel . to ) , off = eltOffset ( space ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "closure", "object", "to", "be", "passed", "through", "the", "renderer", "."], "add_tokens": "* @ param { Object } ctx An object to be passed to all of the rendering functions var outputTextBlock = function ( block , ctx , callback ) { formats [ block . format ] ( block , ctx , callback ) ; section : function ( input , ctx , callback ) { outputTextBlock ( item , ctx , function ( err , val ) {", "del_tokens": "var outputTextBlock = function ( block , callback ) { formats [ block . format ] ( block , callback ) ; section : function ( input , callback ) { outputTextBlock ( item , function ( err , val ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "core", "-", "interfaces", "for", "binary", "data"], "add_tokens": "const { UInt8 , UInt16 , UInt32 , Int8 , Int16 , Int32 , UInt64 , Int64 , UInt128 , Int128 , ObjectId , Binary , Binarized , BinarizedInt } = BesonType ;", "del_tokens": "const { UInt8 , UInt16 , UInt32 , Int8 , Int16 , Int32 , UInt64 , Int64 , UInt128 , Int128 , ObjectId , Binary } = BesonType ;", "commit_type": "add"}
{"commit_tokens": ["Update", "seed", "and", "plugin", "UMLStateMachine", "-", ">", "UMLStateDiagram", "."], "add_tokens": "self . core . getAttribute ( self . getMetaType ( self . activeNode ) , 'name' ) !== 'UMLStateDiagram' ) { callback ( new Error ( 'Active node is not a \"UMLStateDiagram\".' ) , self . result ) ;", "del_tokens": "self . core . getAttribute ( self . getMetaType ( self . activeNode ) , 'name' ) !== 'UMLStateMachine' ) { callback ( new Error ( 'Active node is not a \"UMLStateMachine\".' ) , self . result ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "CORS", "param", "to", "prevent", "browsers", "from", "logging", "cors", "errors", "in", "the", "console", "when", "dispatching", "events", "."], "add_tokens": "// add param for cors headers to be sent by the log endpoint url += '?wxhr=true' ; url += '&' + toQueryString ( params ) ;", "del_tokens": "url += '?' + toQueryString ( params ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "and", "fixes", "for", "db", ".", "del", "()"], "add_tokens": "return db . del ( type ) . commit ( ) ; } ) . then ( function ( ) { return nopg . start ( PGCONFIG ) . typeExists ( \"DeleteTypeTestsxWH8QiBYc\" ) ;", "del_tokens": "return db . del ( type ) . commit ( ) . typeExists ( \"DeleteTypeTestsxWH8QiBYc\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "working", "out", "last", "file"], "add_tokens": "( i === pFiles_a . length - 1 ) ? true : false ) ) ;", "del_tokens": "( i === pFiles_a . length ) ? true : false ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "optional", "parameters", "paging", "author", "description", "time"], "add_tokens": "mode : 'landscape' , paging : true , time : true", "del_tokens": "mode : 'landscape'", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "report", "and", "notify", "methods"], "add_tokens": "fixture . setErrors ( errors = collection ) ; } , report : function ( test ) { hooker . hook ( grunt . log , \"writeln\" , { pre : function ( message ) { test . ok ( message . length , \"Reporter report something\" ) ; test . done ( ) ; return hooker . preempt ( ) ; } , once : true } ) ; fixture . report ( ) ; } , notify : function ( test ) { hooker . hook ( grunt . log , \"error\" , { pre : function ( message ) { test . ok ( message , \"1 code style errors found!\" ) ; test . done ( ) ; return hooker . preempt ( ) ; } , once : true } ) ; fixture . notify ( ) ;", "del_tokens": "errors = collection ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "angularjs", "call", "to", "$anchorScroll", "for", "scrolling", "to", "the", "top", "of", "the", "page", "(", "$window", ".", "scrollTo", "(", "0", "0", ")", "does", "the", "same", "thing", "without", "requiring", "explicit", "anchors", ")"], "add_tokens": ". controller ( 'MainNavController' , function ( $scope , $location , $window ) { $window . scrollTo ( 0 , 0 ) ;", "del_tokens": ". controller ( 'MainNavController' , function ( $scope , $location , $anchorScroll ) { $location . hash ( 'top' ) ; $anchorScroll ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "ok", ".", "views", "dependency", "to", "ok", ".", "dollarview"], "add_tokens": "define ( 'ok.dollarview' , [ 'ok' , 'ok.views' , 'jquery' ] , factory ) ; require ( 'ok.views' ) ;", "del_tokens": "define ( 'ok.dollarview' , [ 'ok' , 'jquery' ] , factory ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "clear", "to", "beginning", "of", "test", ".", "js"], "add_tokens": "function Clear ( Callback ) { MCP9808 . ClearConfigurationRegister ( function ( ) { MCP9808 . SetResolution ( 0x00 , function ( ) { MCP9808 . SetUpperTemperature ( 0 , function ( ) { MCP9808 . SetLowerTemperature ( 0 , function ( ) { MCP9808 . SetCriticalTemperature ( 0 , function ( ) { Callback ( ) ; } ) ; } ) ; } ) ; } ) ; } ) ; } Clear ( function ( ) { TestWritableBits ( function ( ) TestSetCommands ( function ( ) TestTemperature ( function ( ) { //done } ) ;", "del_tokens": "TestWritableBits ( function ( ) { TestSetCommands ( function ( ) TestTemperature ( function ( ) //done", "commit_type": "add"}
{"commit_tokens": ["added", "get", "drawing", "()", "to", "return", "the", "bitmap", "from", "the", "drawing", "on", "android"], "add_tokens": "var color = require ( \"color\" ) ; _super . apply ( this , arguments ) ; this . _android . setPenColor ( new color . Color ( this . penColor ) . android ) ; Object . defineProperty ( SignaturePad . prototype , \"drawing\" , { get : function ( ) { // check if empty first if ( ! this . _android . isEmpty ( ) ) console . log ( 'has drawing' ) ; return this . _android . getTransparentSignatureBitmap ( ) ; } , enumerable : true , configurable : true } ) ;", "del_tokens": "_super . call ( this ) ; if ( ! this . _androidViewId ) { this . _androidViewId = android . view . View . generateViewId ( ) ; } this . _android . setId ( this . _androidViewId ) ; this . _android . setPenColor ( this . penColor . android ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "port", "and", "fixed", "readme"], "add_tokens": "port : self . port , method : 'GET' , port : self . port body : JSON . stringify ( figure ) , port : self . port", "del_tokens": "method : 'GET' body : JSON . stringify ( figure )", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "dependencies", "and", "shrunk", "the", "lodash", "requirement", "down", "to", "be", "lodash", ".", "isempty", "only"], "add_tokens": ", _isEmpty = require ( 'lodash.isempty' ) if ( _isEmpty ( winstonConf ) ) { if ( _isEmpty ( winstonConf ) ) {", "del_tokens": ", _ = require ( 'lodash' ) if ( _ . isEmpty ( winstonConf ) ) { if ( _ . isEmpty ( winstonConf ) ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "source", "images", "copy", "to", "output"], "add_tokens": "this . copyImageAToOutput = options . copyImageAToOutput || false ; this . copyImageBToOutput = options . copyImageBToOutput || false ; if ( self . copyImageAToOutput ) { self . imageA . getImage ( ) . bitblt ( self . imageOutput . getImage ( ) , 0 , 0 , self . imageA . getWidth ( ) , self . imageA . getHeight ( ) , 0 , 0 ) ; } else if ( self . copyImageBToOutput ) { self . imageB . getImage ( ) . bitblt ( self . imageOutput . getImage ( ) , 0 , 0 , self . imageB . getWidth ( ) , self . imageB . getHeight ( ) , 0 , 0 ) ; } PerceptualDiff . version = \"1.3.8\" ;", "del_tokens": "PerceptualDiff . version = \"1.3.7\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "latest", "versions", "of", "node", "to", "tests"], "add_tokens": "options = lodash . omit ( options , [ 'logger' , 'handler' ] ) ; options = lodash . defaults ( options , { includeTags : false , includeData : true , mergeData : false , skipUndefined : true ,", "del_tokens": "options = lodash . defaults ( lodash . omit ( options , [ 'logger' , 'handler' ] ) , { includeTags : false , includeData : true , mergeData : false , skipUndefined : true ,", "commit_type": "add"}
{"commit_tokens": ["Updated", "flow", "removed", "create", "-", "context", "attempted", "to", "fix", "typing"], "add_tokens": "export type PointMap < T > = { | [ row : number ] : { | | } | } ; const EMPTY : PointMap < any > = ( { } : any); return pairs . reduce ( ( acc , [ point , value ] ) => set ( point , value , acc ) , EMPTY ) ;", "del_tokens": "export type PointMap < T > = { [ row : number ] : { } } ; return pairs . reduce ( ( acc , [ point , value ] ) => set ( point , value , acc ) , { } ) ;", "commit_type": "update"}
{"commit_tokens": ["Updated", "bencode", ".", "js", ":", "Sped", "up", "decode", ".", "find", "()", "a", "little"], "add_tokens": "find : function ( chr ) { var d = this . data while ( i < c ) { if ( d [ i ] === chr ) i ++", "del_tokens": "find : function ( needle ) { for ( ; i < c ; i ++ ) { if ( this . data [ i ] === needle ) { }", "commit_type": "update"}
{"commit_tokens": ["Added", "tests", "for", "valid", "attributes"], "add_tokens": "return common . createTest ( 'test-5' , map ) ; return common . createTest ( 'test-6' , map ) ; ) , '(13) attributes can contain valid characters' : ( function ( ) { var map = Plates . Map ( ) ; map . where ( 'href' ) . is ( 'aA1-_:/&#1235; ' ) . insert ( 'test' ) ; return common . createTest ( 'test-13' , map ) ; } ( )", "del_tokens": "return common . createTest ( 'test-5' , map ) ; return common . createTest ( 'test-6' , map ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "an", "anonymous", "module", "declaration", "for", "AMD", "."], "add_tokens": "define ( function ( ) { return Promise ; } ) ;", "del_tokens": "define ( \"Promise\" , [ ] , function ( ) { return Promise ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["Improve", "performance", "of", "contains", "()"], "add_tokens": "* @ param { number } [ position ] The position at which to start looking . export default function contains ( string , query , position ) { const s = string ; const q = query ; const p = position ; return ( p === undefined ? s . indexOf ( q ) : s . indexOf ( q , p ) ) !== - 1 ;", "del_tokens": "* @ param { number } [ position = 0 ] The position at which to start looking . export default function contains ( string , query , position = 0 ) { return string . indexOf ( query , position ) !== - 1 ;", "commit_type": "improve"}
{"commit_tokens": ["Use", "renderable", "instead", "of", "renderFunc"], "add_tokens": "exports . renderable = require ( 'raptor-renderer' ) . renderable ;", "del_tokens": "exports . renderFunc = require ( 'raptor-renderer' ) . renderFunc ;", "commit_type": "use"}
{"commit_tokens": ["fix", "windows", "phone", "missing", "ua"], "add_tokens": "var isWindows = / win / i . test ( 'navigator' in window && 'appVersion' in window . navigator && window . navigator . appVersion . toLowerCase ( ) || '' )", "del_tokens": "var isWindows = / win / i . test ( 'navigator' in window && 'appVersion' in navigator && navigator . appVersion . toLowerCase ( ) || '' )", "commit_type": "fix"}
{"commit_tokens": ["moved", "lib", "to", "jslib", "refactoring", "python", "code", "initial", "CLI", "added", "initial", "templates", "for", "CLI"], "add_tokens": "async run ( edit /*: MappedVariable*/ , args /*: Object*/ , step /*: StepObject*/ ) /*: Promise<any>*/ { async is_enabled ( args /*: Object*/ , step /*: StepObject*/ ) /*: Promise<boolean>*/ { return true } async is_visible ( args /*: Object*/ , step /*: StepObject*/ ) /*: Promise<boolean>*/ { return true }", "del_tokens": "async run ( edit /*: MappedVariable*/ , args /*: Object*/ , step /*: StepObject*/ ) /*: Promise<any>*/ {", "commit_type": "move"}
{"commit_tokens": ["Allow", "cancelling", "of", "attempts", "."], "add_tokens": "var cancelled = false ; process . nextTick ( ( ) => { if ( cancelled ) return ; doSomething ( ( err , result ) => { return { cancel : ( ) => { cancelled = true ; process . nextTick ( ( ) => { callback ( new Error ( 'cancelled' ) , null ) ; } ) ; } } ;", "del_tokens": "doSomething ( ( err , result ) => { process . nextTick ( ( ) => {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "incorrect", "domain", "record", "route", "."], "add_tokens": "var url = util . safeUrl ( 'domains' , args . identifier , 'records' ) ; var url = util . safeUrl ( 'domains' , domainName , 'records' , id ) ; var url = util . safeUrl ( 'domains' , domainName , 'records' ) ; var url = util . safeUrl ( 'domains' , domainName , 'records' , id ) ; var url = util . safeUrl ( 'domains' , domainName , 'records' , id ) ;", "del_tokens": "var url = util . safeUrl ( 'domains' , args . identifier , 'domain_records' ) ; var url = util . safeUrl ( 'domains' , domainName , 'domain_records' , id ) ; var url = util . safeUrl ( 'domains' , domainName , 'domain_records' ) ; var url = util . safeUrl ( 'domains' , domainName , 'domain_records' , id ) ; var url = util . safeUrl ( 'domains' , domainName , 'domain_records' , id ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "border", "settings", "to", "javascript", "and", "include", "conditionals", "for", "sass", "."], "add_tokens": "position : 'top' length : '50px' borderRadius : '10px' , border : 'black dotted 20px' borderRadius : '0' , border : 'red solid' borderRadius : '30pt' , border : 'none'", "del_tokens": "position : 'top' , wrapperClass : 'info-one' , pointer : { enabled : true , length : '1em' , } , backgroundColor : 'rgba(125, 125, 125, 1)' , contentPadding : '3em' , border : '2px solid black' , borderRadius : '0.25em' , fontColor : 'rgba(255,255,255,1)' , font : 'italic 40px Serif' length : '25 ' borderRadius : '10px' borderRadius : '0' borderRadius : '30pt'", "commit_type": "add"}
{"commit_tokens": ["fix", "missing", "-", "support", "test", ";", "reformat", "features", "data"], "add_tokens": "/ * * / missing = function ( browserRequest ) {", "del_tokens": "missing = function ( browserRequest , cb ) { if ( cb == null ) { cb = function ( ) { } ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "output", "results", "to", "JSON", "file", "to", "consumption", "from", "other", "tasks", "/", "CI", "servers"], "add_tokens": "requests : '' , // takes the data returned by wpt.getTestResults and compares //save the file before failing or passing var output = options . output ; if ( typeof output !== 'undefined' ) { grunt . log . ok ( 'Writing file: ' + output ) ; grunt . file . write ( output , JSON . stringify ( data ) ) ; } processData ( response ) ; status = 'Test ' + err . error . testId + ' has timed out. You can still view the results online at ' +", "del_tokens": "requests : '' , // takes the data returned by wpt.getTestResults and compares processData ( response ) ; status = 'Test ' + err . error . testId + ' has timed out. You can still view the results online at ' +", "commit_type": "add"}
{"commit_tokens": ["Made", "isSettingup", "variable", "private", "to", "executing", "context"], "add_tokens": "let isSettingUp = false ;", "del_tokens": "let isSettingUp = false ;", "commit_type": "make"}
{"commit_tokens": ["Added", ".", "gitignore", "when", "init", "edited", "the", "content", "of", "package", ".", "json"], "add_tokens": "name : 'hexo' , version : '0.0.1' , 'node' : '>0.6.0' , 'npm' : \">1.1.0\" function ( next ) { file . write ( target + '/.gitignore' , '.DS_Store\\nnode_modules' , next ) ; } ,", "del_tokens": "'node' : '>0.6.0'", "commit_type": "add"}
{"commit_tokens": ["removing", "makeFromFactory", "()", "from", "this", "release"], "add_tokens": "function Factory ( name , model , attributes ) { this . _isFactory = true ; var factory = factories [ name ] , resolved ; // resolve \"eager\" properties first and leave lazy ones for a second pass var resolved = resolve ( factory . attributes ) ; // pass already resolved attributes as context to the second pass resolved = resolve ( factory . attributes , resolved ) ; // apply overrides helpers . each ( overrides , function ( value , key ) { resolved [ key ] = value ; } ) ; return new factory . model ( resolved ) ;", "del_tokens": "var Factory = function ( name , model , attributes ) { var modelFromFactory = function ( factory , overrides ) { // resolve \"eager\" properties first and leave lazy ones for a second pass var resolved = resolve ( factory . attributes ) ; // pass already resolved attributes as context to the second pass resolved = resolve ( factory . attributes , resolved ) ; // apply overrides helpers . each ( overrides , function ( value , key ) { resolved [ key ] = value ; } ) ; return new factory . model ( resolved ) ; } ; var factory = factories [ name ] ; return modelFromFactory ( factory , overrides ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "event", "infos", "for", "event", "public", "page"], "add_tokens": "var Event , MailHandler , User , VCalendar , mails , moment , time ; moment = require ( 'moment' ) ; var date , dateFormat , key , visitor , _ref , dateFormat = 'MMMM Do YYYY, h:mm a' ; date = moment ( req . event . start ) . format ( dateFormat ) ; date : date ,", "del_tokens": "var Event , MailHandler , User , VCalendar , mails , time ; var key , visitor , _ref ,", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "way", "parameters", "are", "passed", "to", "qlik", "advanced", "functions"], "add_tokens": "grunt . task . run ( 'jscs' , 'simplemocha:all' , 'mocha_istanbul:coverage' , 'jsdoc2md:multipleOutputfiles' , 'bump:patch' , 'shell:publish' , 'coveralls:default' ) ;", "del_tokens": "grunt . task . run ( 'jscs' , 'simplemocha:all' , 'mocha_istanbul:coverage' , 'coveralls:default' , 'jsdoc2md:multipleOutputfiles' , 'bump-only:patch' , 'shell:publish' ) ;", "commit_type": "update"}
{"commit_tokens": ["added", ":", "cdp", ".", "ui", ".", "smoothscroll"], "add_tokens": "// dev-func release  enalbe  'dev-func' : { '%% dev_functions_enabled %%' : 'enable' , // 1 } , 'server' : { '%% target_server %%' : 'prod|dev|stg|qa' , // 21.  } , 'runtime-context' : { '%% runtime_context %%' : false , // false .  } , '%% build_setting %%' : true , // true  '%% dev_functions_enabled %%' : true ,", "del_tokens": "'%% build_setting %%' : true ,", "commit_type": "add"}
{"commit_tokens": ["improve", "wrong", "usage", "error", "message", "for", "missing", "@reframe", "/", "run"], "add_tokens": "const runPath = require . resolve ( '@reframe/run' , { paths : [ projectRootDir ] } ) ; runPath , \"Package `@reframe/run` is missing.\" , \"You need to install it: `npm install @reframe/run`.\" , \"Project in question: `\" + projectRootDir + \"`.\" , require ( runPath ) ;", "del_tokens": "const reframePackageLocation = require . resolve ( '@reframe/run' , { paths : [ projectRootDir ] } ) ; reframePackageLocation , \"Couldn't find the npm package `@reframe/run`.\" , \"It is required to run reframe.\" , \"TODO Include it `@reframe/run` included in the `package.json` of the project at ``?\" require ( reframePackageLocation ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "test", "for", "source", "maps"], "add_tokens": "let contents = prepareContents ( element . children ) , firstContent = true if ( ! firstContent ) { builder . add ( ',' ) } else { firstContent = false }", "del_tokens": "let contents = prepareContents ( element . children ) builder . add ( ',' )", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "variable", "name", "and", "remove", "console", ".", "log"], "add_tokens": "ipAddress = clientIp ;", "del_tokens": "ipAdress = clientIp ; console . log ( ipAddress ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "exception", "handler", "when", "working", "with", "SVG", "transformation", "matrixes", "(", "IE9", "throws", "Unexpected", "call", "to", "method", "or", "property", "access", "in", "odd", "cases", ")", "in", "Vectorizer"], "add_tokens": "try { var globalPoint = p . matrixTransform ( svg . getScreenCTM ( ) . inverse ( ) ) ; var globalToLocalMatrix = this . node . getTransformToElement ( svg ) . inverse ( ) ; } catch ( e ) { // IE9 throws an exception in odd cases. (`Unexpected call to method or property access`) // We have to make do with the original coordianates. return p ; }", "del_tokens": "var globalPoint = p . matrixTransform ( svg . getScreenCTM ( ) . inverse ( ) ) ; var globalToLocalMatrix = this . node . getTransformToElement ( svg ) . inverse ( ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "comments", "per", "@milroc", "s", "request"], "add_tokens": "// basic.addition // basic.subtraction // basic.product // basic.factorial // basic.gcd // basic.lcm", "del_tokens": "// numbers.addition // numbers.subtraction // numbers.product // numbers.factorial // numbers.gcd // numbers.lcm", "commit_type": "update"}
{"commit_tokens": ["Changed", "removeClass", "call", "to", "remove", "all", "classes", "."], "add_tokens": "tipElement . removeClass ( ) ;", "del_tokens": "tipElement . removeClass ( options . placement ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "some", "refactoring", "issues", "and", "optimized", "the", "frequency", "algorithm"], "add_tokens": "for ( var x = 0 , start = new TeoriaNote ( chord . root ) , xLength = CHORDS [ chord . type ] . length ; x < xLength ; x ++ ) { originalFq = concertPitch * Math . pow ( 2 , ( key - 49 ) / 12 ) ; return { note : new TeoriaNote ( name + ( octave + 1 ) ) , cents : cents } ; return new TeoriaNote ( note + ( octave || '' ) ) ;", "del_tokens": "for ( var x = 0 , start = new teoria . note ( chord . root ) , xLength = CHORDS [ chord . type ] . length ; x < xLength ; x ++ ) { originalFq = concertPitch * Math . pow ( Math . pow ( 2 , 1 / 12 ) , key - 49 ) ; return { note : new teoria . note ( name + ( octave + 1 ) ) , cents : cents } ; return new teoria . note ( note + ( octave || '' ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "no", "defaults", "on", "sync", "get"], "add_tokens": "return defaults ( this . _readFileSync ( ) . global , this . _options . globalDefaults ) ;", "del_tokens": "return this . _readFileSync ( ) . global ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "an", "error", "property", "to", "query", "arrays", "."], "add_tokens": "var array = [ ] , promise = Promise . resolve ( ) , isBusy = false , error , queued ; error : { get : function ( ) { return error ; } , enumerable : false } , error = undefined ; function ( e ) { error = e ; throw e ; // error - This is set to the error object that the mapper rejects its promise with. It is // cleared whenever the mapper later resolves its promise.", "del_tokens": "var array = [ ] , promise = Promise . resolve ( ) , isBusy = false , queued ; function ( error ) { throw error ;", "commit_type": "add"}
{"commit_tokens": ["Add", "dropping", "to", "group", "."], "add_tokens": "allWorkersStarted : function ( config ) {", "del_tokens": "initMaster : function ( config ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "create", "-", "error", "dependency"], "add_tokens": "equal ( err . get ( 'emailFail' ) . toString ( ) , 'Errors with emailFail: The emailFail must be a valid email address.' ) ;", "del_tokens": "equal ( err . get ( 'emailFail' ) . toString ( ) , [ 'Errors with emailFail: The emailFail must be a valid email address. ' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "scroll", "/", "drag", "movement", "of", "timeline", "X", "axis"], "add_tokens": "translateX = 0 , tickFormat = { format : function ( d ) { var format = d3 . time . format ( \"%I %p\" ) ; return format ( d ) ; } , zoom . translate ( [ translateX , 0 ] ) ; zoom . event ( gParent ) ; } ; timeline . translate = function ( x ) { if ( ! arguments . length ) return translateX ; translateX = x ; return timeline ; } ;", "del_tokens": "tickFormat = { format : function ( d ) { var format = d3 . time . format ( \"%I %p\" ) ; return format ( d ) } , }", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "way", "getTemplateString", "works"], "add_tokens": "templatesDir : path . join ( process . cwd ( ) , \"src\" , \"layouts\" ) , / ** * Find and return the template string to be compiled * * Note : this can be overridden by passing a 'getTemplateString' * function to the Pagemaki constructor , esp for testing * * @ param { [ type ] } name [ description ] * @ return { [ type ] } [ description ] * / Pagemaki . prototype . getTemplateString = function ( name ) { return fs . readFileSync ( path . join ( this . config . templatesDir , name + \".html\" ) ) . toString ( ) ; } var getTemplateString = ( this . config . getTemplateString || this . getTemplateString ) . bind ( this ) ; this . templates [ name ] = this . config . templateCompile ( getTemplateString ( name ) . trim ( ) ) ;", "del_tokens": "getTemplateString : function ( name ) { return fs . readFileSync ( path . join ( __dirname , \"..\" , \"src\" , \"layouts\" , name + \".html\" ) ) . toString ( ) ; } , this . templates [ name ] = this . config . templateCompile ( this . config . getTemplateString ( name ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "run", "-", "all", "-", "the", "-", "things", "bin", "interface"], "add_tokens": "count || process . kill ( process . pid ) ;", "del_tokens": "count || process . kill ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "eventPicker", "(", "option", ".", "empty", ")", "for", "execute", "picker", "with", "empty", "Notes"], "add_tokens": "function EventPicker ( self , picker , action , treat , path , empty ) { this . _empty = empty ; if ( this . wait > 0 || ( ! this . _empty && this . note . Empty ( ) ) ) { * @ param { external : Boolean } [ option . empty ] execute event when nodelist is empty return picker [ treat ] = new EventPicker ( this , picker , action , treat , option . path , option . empty ) ;", "del_tokens": "function EventPicker ( self , picker , action , treat , path ) { if ( this . wait > 0 || this . note . Empty ( ) ) { return picker [ treat ] = new EventPicker ( this , picker , action , treat , option . path ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "benchmark", "/", "index", ".", "js", "to", "benchmark", ".", "js"], "add_tokens": "stemmer = require ( './' ) ;", "del_tokens": "stemmer = require ( '..' ) ;", "commit_type": "move"}
{"commit_tokens": ["fixed", "resource", "inline", "option", "bug"], "add_tokens": "var _ = require ( 'underscore' ) var opts = _ . extend ( { } , tagObj ) result = transform ( file , tpl , opts ) ? Tag . inline ( file , tpl , opts )", "del_tokens": "result = transform ( file , tpl , tagObj ) ? Tag . inline ( file , tpl , tagObj )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "fieldname", "to", "be", "set", "with", "extensions", "rather", "than", "just", "options"], "add_tokens": "fieldName : options . fieldName || this . fieldName || options . schemaKey ,", "del_tokens": "fieldName : options . fieldName || options . schemaKey ,", "commit_type": "allow"}
{"commit_tokens": ["Use", "gsap", "fixture", "in", "groups"], "add_tokens": "import config from '../src/config/config' const configGsap = { ... config . gsap } describe ( 'groups' , ( ) => { config . gsap . autoInjectUrl = 'test/fixtures/gsap.js' config . gsap = { ... configGsap }", "del_tokens": "describe ( 'groups' , ( ) => {", "commit_type": "use"}
{"commit_tokens": ["Updating", "publish", "plugin", "renaming", "addCreatedAndModified", "."], "add_tokens": ", util = require ( 'util' ) var Blog = mongoose . model ( 'BlogPost' , BlogPost ) vows . describe ( 'Add create and modified' ) . addBatch ( { 'when this plugin registered by default' : { 'it should create created and modified attribute' : function ( topic ) { assert . equal ( util . isDate ( topic . created ) , true ) assert . equal ( util . isDate ( topic . modified ) , true )", "del_tokens": "console . log ( 'registering the plugin...' ) var Blog = mongoose . model ( 'BlogPost' , BlogPost ) vows . describe ( 'Add createAt and modifiedAt' ) . addBatch ( { 'when this plugin registered by default' : { 'it should not be stored in collection' : function ( topic ) { console . log ( topic )", "commit_type": "update"}
{"commit_tokens": ["make", "name", "in", "a", "higher", "scope", "for", "performance", ".", "if", "metricPrefix", "ends", "with", "a", "dot", "just", "use", "that", "dot", "."], "add_tokens": "var k , v , name , vps ; name = format_metric_name ( k ) ; vps = metrics . counter_rates [ k ] ; name = format_metric_name ( k ) ; name = format_metric_name ( k ) ; name = format_metric_name ( k ) ; if ( metricPrefix !== \"\" && metricPrefix !== \".\" ) { if ( metricPrefix . endsWith ( \".\" ) ) { return [ metricPrefix , metric ] . join ( \"\" ) ; } else { return [ metricPrefix , metric ] . join ( \".\" ) ; }", "del_tokens": "var k , v ; var name = format_metric_name ( k ) ; var vps = metrics . counter_rates [ k ] ; var name = format_metric_name ( k ) ; var name = format_metric_name ( k ) ; var name = format_metric_name ( k ) ; if ( metricPrefix != \"\" && metricPrefix != \".\" ) { return [ metricPrefix , metric ] . join ( \".\" ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "sample", "converting", "float32", "PCM", "into", "MP3"], "add_tokens": "module . exports = require ( '../build/Release/bindings.node' ) ;", "del_tokens": "module . exports = require ( 'bindings' ) ( 'bindings' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "synchronization", "of", "sequenceable", "objects", "in", "progress", "."], "add_tokens": "setNextTime : {", "del_tokens": "setNextEventTime : {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "big", "big", "error", "in", "matching", "class", "selectors"], "add_tokens": "if ( ! _hasClass ( elm , classNames [ c ] ) ) { return _false ; }", "del_tokens": "if ( _hasClass ( elm , classNames [ c ] ) ) { return _false ; }", "commit_type": "fix"}
{"commit_tokens": ["make", "this", "also", "a", "command"], "add_tokens": "var opts = { } var args = process . argv . slice ( 2 ) . filter ( function ( e ) { if ( / ^--online / . test ( e ) ) return ! ( opts . online = true ) return true } ) resolve ( args , opts , function ( err , tree ) {", "del_tokens": "resolve ( process . argv . slice ( 2 ) , { } , function ( err , tree ) {", "commit_type": "make"}
{"commit_tokens": ["Allow", "NOT_", "prefix", "for", "capabilities"], "add_tokens": "PLATFORM_APLITE : { PLATFORM_BASALT : { PLATFORM_CHALK : { PLATFORM_DIORITE : { PLATFORM_EMERY : { minFwMajor : 0 , minFwMinor : 0 * @ param { Array < string > } [ capabilities ] var notRegex = / ^NOT_ / ; var result = [ ] ; var mapping = module . exports . capabilityMap [ capability . replace ( notRegex , '' ) ] ; result . push ( ! ! capability . match ( notRegex ) ) ; } else { result . push ( ! capability . match ( notRegex ) ) ; return result . indexOf ( false ) === - 1 ;", "del_tokens": "APLITE : { BASALT : { CHALK : { DIORITE : { EMERY : { minFwMajor : 3 , minFwMinor : 4 * @ param { Array } [ capabilities ] var mapping = module . exports . capabilityMap [ capability ] ; return false ; return true ;", "commit_type": "allow"}
{"commit_tokens": ["move", "it", "to", "use", "IPFS", "Repo"], "add_tokens": "var IPFSRepo = require ( 'ipfs-repo' ) var repo = new IPFSRepo ( require ( './index.js' ) . repoPath ) var blockService = new BlockService ( repo ) repo . datastore . exists ( block1 . key ( ) . toString ( 'hex' ) , function ( err , exists ) {", "del_tokens": "var fs = require ( 'fs-blob-store' ) var util = require ( '../util' ) var datastore = fs ( 'blocks' ) t . is ( util . isAbstractBlobStore ( datastore ) , true , 'datastore is an abstact-blob-store' ) var blockService = new BlockService ( datastore ) datastore . exists ( block1 . key ( ) . toString ( 'hex' ) , function ( err , exists ) {", "commit_type": "move"}
{"commit_tokens": ["Add", "tests", "for", "from", "web", "to", "node"], "add_tokens": "show : false describe ( \"from web to node\" , function ( ) { it ( \"decrypts AES-CBC from web\" , async function ( ) { const encrypted = await nightmare . evaluate ( function ( raw , done ) { const { createSession } = window . iocane ; createSession ( ) . use ( \"cbc\" ) . encrypt ( raw , \"sample-pass\" ) . then ( output => done ( null , output ) ) . catch ( done ) ; } , TEXT ) ; const decrypted = await createSession ( ) . decrypt ( encrypted , \"sample-pass\" ) ; expect ( decrypted ) . to . equal ( TEXT ) ; } ) ; it ( \"decrypts AES-GCM from web\" , async function ( ) { const encrypted = await nightmare . evaluate ( function ( raw , done ) { const { createSession } = window . iocane ; createSession ( ) . use ( \"gcm\" ) . encrypt ( raw , \"sample-pass\" ) . then ( output => done ( null , output ) ) . catch ( done ) ; } , TEXT ) ; const decrypted = await createSession ( ) . decrypt ( encrypted , \"sample-pass\" ) ; expect ( decrypted ) . to . equal ( TEXT ) ; } ) ; } ) ;", "del_tokens": "show : true // webPreferences: { // preload: path.resolve(__dirname, \"../../web/index.js\") // }", "commit_type": "add"}
{"commit_tokens": ["removed", "componentDef", "argument", "from", "entitySets", "."], "add_tokens": "createEntitySet : function ( options , callback ) { // options.componentDefs = this.getComponentDefs( components ); var result = odgn . entity . EntitySet . create ( this . storage , this , options ) ; return result . reload ( function ( err , pEntitySet ) { self . trigger ( 'entity_set:create' , pEntitySet ) ; return callback ( null , pEntitySet ) ;", "del_tokens": "createEntitySet : function ( components , options , callback ) { var storage = this . memoryStorage ; var result = odgn . entity . EntitySet . create ( storage , this , options ) ; var componentDefs = this . getComponentDefs ( components ) ; result . _componentDefIds = _ . map ( componentDefs , function ( componentDef ) { log . debug ( 'mapped in ' + componentDef . defId + ' for ' + componentDef . schema . id ) ; return componentDef . defId ; } ) ; return result . reload ( function ( err ) { self . trigger ( 'entity_set:create' , result ) ; return callback ( null , result ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "build", "since", "there", "is", "a", "known", "issue", "of", "running", "tests", "in", "Chrome", "on", "Travis", "."], "add_tokens": "singleRun : true , browsers : [ 'PhantomJS' ]", "del_tokens": "singleRun : true", "commit_type": "fix"}
{"commit_tokens": ["Added", "help", "to", "the", "command", "line", "app", "."], "add_tokens": "this . verbose = verbose !== undefined ? verbose : false ;", "del_tokens": "this . verbose = verbose ;", "commit_type": "add"}
{"commit_tokens": ["fix", "parser", "doesn", "t", "exist", "error"], "add_tokens": "if ( parser ) { parser . close ( ) ; }", "del_tokens": "parser . close ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "lower", "limit", "for", "harvesting"], "add_tokens": "for ( let timeOffset = this . forecast . lowerLimit ; timeOffset <= this . forecast . upperLimit ; timeOffset += this . forecast . interval ) {", "del_tokens": "for ( let timeOffset = 0 ; timeOffset <= this . forecast . limit ; timeOffset += this . forecast . interval ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "work", "with", "live", "-", "reload"], "add_tokens": "var configDependencies = [ '@loader' , 'npm-extension' , 'module' ] . concat ( configDeps . call ( loader , pkg ) ) ; return \"define(\" + JSON . stringify ( configDependencies ) + \", function(loader, npmExtension, module){\\n\" + var setupLiveReload = function ( ) { var hasLiveReload = ! ! loader . _liveMap ; if ( hasLiveReload ) { loader . import ( \"live-reload\" , { name : module . id } ) . then ( function ( reload ) { reload . dispose ( function ( ) { // Remove state created by the config. delete loader . npm ; delete loader . npmPaths ; } ) ; } ) ; } } ; delete pkg . system . configDependencies ; setupLiveReload ( ) ;", "del_tokens": "var configDependencies = [ '@loader' , 'npm-extension' ] . concat ( configDeps . call ( loader , pkg ) ) ; return \"define(\" + JSON . stringify ( configDependencies ) + \", function(loader, npmExtension){\\n\" +", "commit_type": "make"}
{"commit_tokens": ["add", "React", ".", "mixins", ".", "getState", "/", "React", ".", "mixins", ".", "setState", "methods"], "add_tokens": "function setState ( state , context ) { if ( context . isMounted ( ) ) { context . setState ( state ) ; } else if ( context . state ) { for ( var name in state ) { context . state [ name ] = state [ name ] ; } } else { // if we aren't mounted, we will get an exception if we try to set the state // so keep a placeholder state until we're mounted // this is mainly useful if setModel is called on getInitialState var _state = context . __temporary_state || { } ; for ( var name in state ) { _state [ name ] = state [ name ] ; } context . __temporary_state = _state ; } } function getState ( key , context ) { var state = context . state , initState = context . __temporary_state ; return ( state && state [ key ] ) || ( initState && initState [ key ] ) ; } } , componentWillMount : function ( ) { // not directly related to this mixin but all of these mixins have this as a dependency // if setState was called before the component was mounted, the actual component state was // not set because it might not exist. Convert the pretend state to the real thing // (but don't trigger a render) var _state = this . __temporary_state ; if ( _state ) { for ( var key in _state ) { this . state [ key ] = _state [ key ] ; } delete this . __temporary_state ; } React . mixins . setState = setState ; React . mixins . getState = getState ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "new", "functions"], "add_tokens": "if ( L === undefined ) { throw new Error ( 'Please enter a desired reordering array.' ) ; } else if ( L . length !== M . length ) { } if ( L === undefined ) { throw new Error ( 'Please enter a desired reordering array.' ) ; } else if ( L . length !== M [ 0 ] . length ) {", "del_tokens": "if ( L . length !== M . length ) { } if ( L . length !== M [ 0 ] . length ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "amon", "tests", "to", "use", "bootsrapped", "admin", "user", "in", "ufd"], "add_tokens": "var AMON = sdcClients . AMON ; amon = new AMON ( {", "del_tokens": "var Amon = sdcClients . Amon ; amon = new Amon ( {", "commit_type": "fix"}
{"commit_tokens": ["allow", "for", "both", "HTTPS", "and", "HTTP", "protocol"], "add_tokens": "newScript . src = document . location . protocol + '//completion.amazon.com/search/complete?search-alias=aps&client=amazon-search-ui&mkt=1&q=' + prefix + '&callback=AmazonAutocomplete.AmazonJSONPCallbackHandler_' + this . _id ; } ) ( window , document ) ;", "del_tokens": "newScript . src = 'http://completion.amazon.com/search/complete?search-alias=aps&client=amazon-search-ui&mkt=1&q=' + prefix + '&callback=AmazonAutocomplete.AmazonJSONPCallbackHandler_' + this . _id ; } ) ( window , document ) ;", "commit_type": "allow"}
{"commit_tokens": ["update", "all", "strings", "to", "use", "single", "quotes", "for", "consistency"], "add_tokens": "var Inspector = require ( '../../../exception/Inspector' ) ; var frame = require ( '../../../exception/frame' ) ; var inspector = new Inspector ( new Error ( 'Sample exception message foo' ) ) ; describe ( '#getFileLines()' , function ( ) { it ( 'should return content of specified line numbers of the stack frame file source' , function ( done ) { inspector . getFrames ( ) [ 0 ] . getFileLines ( 8 , 1 ) . should . containEql ( '/** do not move this comment from this location - used for testing**/' ) ; describe ( '#getFileContents()' , function ( ) { it ( 'should returns the full contents of the file for the frame' , function ( done ) { it ( 'should get comments set to frame by addComment method' , function ( done ) { } ) ;", "del_tokens": "var Inspector = require ( \"../../../exception/Inspector\" ) ; var frame = require ( \"../../../exception/frame\" ) ; var inspector = new Inspector ( new Error ( \"Sample exception message foo\" ) ) ; describe ( \"#getFileLines()\" , function ( ) { it ( \"should return content of specified line numbers of the stack frame file source\" , function ( done ) { inspector . getFrames ( ) [ 0 ] . getFileLines ( 8 , 1 ) . should . containEql ( \"/** do not move this comment from this location - used for testing**/\" ) ; describe ( \"#getFileContents()\" , function ( ) { it ( \"should returns the full contents of the file for the frame\" , function ( done ) { it ( \"should get comments set to frame by addComment method\" , function ( done ) { } ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "custom", "ratio", "/", "width", "/", "height", "in", "fromDataURL"], "add_tokens": "SignaturePad . prototype . fromDataURL = function ( dataUrl , options = { } ) { const ratio = options . ratio || window . devicePixelRatio || 1 ; const width = options . width || ( this . _canvas . width / ratio ) ; const height = options . height || ( this . _canvas . height / ratio ) ;", "del_tokens": "SignaturePad . prototype . fromDataURL = function ( dataUrl ) { const ratio = window . devicePixelRatio || 1 ; const width = this . _canvas . width / ratio ; const height = this . _canvas . height / ratio ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "smooth", "scroll", "hash", "change"], "add_tokens": "// Don't prevent default or hash doesn't change. // e.preventDefault()", "del_tokens": "e . preventDefault ( )", "commit_type": "fix"}
{"commit_tokens": ["update", "the", "jpeg", "-", "js", "version"], "add_tokens": "var img1 = PImage . decodeJPEG ( fs . readFileSync ( \"tests/images/rock.jpg\" ) ) ;", "del_tokens": "var img1 = PImage . decodeJPEG ( fs . readFileSync ( \"tests/images/cat.jpg\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "form", "updates", "for", "pristine", "and", "dirty", "fields"], "add_tokens": "return ( 0 , _get2 . default ) ( state , [ 'fields' , model + '.' + field ] , ( 0 , _get2 . default ) ( state , [ 'fields' , field ] , initialFieldState ) ) ; var initialFormState = _extends ( { } , initialFieldState , { } ) ;", "del_tokens": "var result = ( 0 , _get2 . default ) ( state , [ 'fields' , model + '.' + field ] , ( 0 , _get2 . default ) ( state , [ 'fields' , field ] , initialFieldState ) ) ; return result ; var initialFormState = { } ; var form = ( 0 , _cloneDeep2 . default ) ( state ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "with", "a", "last", "line", "in", "html", "output", "being", "trimmed", "."], "add_tokens": "for ( var i = 1 , linesLen = ( cov . source . length + 1 ) ; i < linesLen ; i ++ ) {", "del_tokens": "for ( var i = 1 ; i < cov . source . length ; i ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["updating", "parsing", "of", "custom", "columns", "."], "add_tokens": "var xml = '<response><cases count=\"7\"><case ixBug=\"16006\" operations=\"edit,assign,resolve,email,remind\"><sTitle><![CDATA[AQ toolkit API: bar chart shown and selected for text]]></sTitle><sFixFor><![CDATA[whenever]]></sFixFor><sStatus><![CDATA[ Active ]]></sStatus><sFooBar><![CDATA[FOO FOO FOO]]></sFooBar></case></cases></response>' , fogbugz . search ( '16227' , [ 'sFoo' ] ) fixFor : \"whenever\" , fooBar : 'FOO FOO FOO' , _raw : { '$' : { ixBug : '16006' , operations : 'edit,assign,resolve,email,remind' } , sTitle : [ 'AQ toolkit API: bar chart shown and selected for text' ] , sFixFor : [ 'whenever' ] , sStatus : [ ' Active ' ] , sFooBar : [ 'FOO FOO FOO' ] }", "del_tokens": "var xml = '<response><cases count=\"7\"><case ixBug=\"16006\" operations=\"edit,assign,resolve,email,remind\"><sTitle><![CDATA[AQ toolkit API: bar chart shown and selected for text]]></sTitle><sFixFor><![CDATA[whenever]]></sFixFor><sStatus><![CDATA[ Active ]]></sStatus></case></cases></response>' , fogbugz . search ( '16227' ) fixFor : \"whenever\"", "commit_type": "update"}
{"commit_tokens": ["Add", "and", "refactor", "and", "to", "use", "it"], "add_tokens": "/* global document */ var DropdownMenu = require ( \"./DropdownMenu\" ) [ \"default\" ] ; propTypes : { dropup : React . PropTypes . bool , right : React . PropTypes . bool getInitialState : function ( ) { open : false handleClick : function ( ) { handleClickOutside : function ( ) { 'open' : this . state . open , 'dropup' : this . props . dropup DropdownMenu ( { ref : \"menu\" , right : this . props . right } ,", "del_tokens": "getInitialState : function ( ) { return { open : false } ; getDefaultProps : function ( ) { options : [ ] handleClick : function ( e ) { this . toggle ( false ) ; handleClickOutside : function ( e ) { delete this . _clickedInside ; } , killClick : function ( e ) { // e.stopPropagation() doesn't prevent `handleClickOutside` from being called this . _clickedInside = true ; 'open' : this . state . open React . DOM . ul ( { className : \"dropdown-menu\" , role : \"menu\" , ref : \"menu\" , onClick : this . killClick } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "SVG", "and", "Flexbox", "checking", "support", "."], "add_tokens": "/* Helper.js v1.6.0 */ jQuery . fn . checkSVG = function ( ) { if ( document . createElementNS ( \"http://www.w3.org/2000/svg\" , 'svg' ) . createSVGRect !== undefined ) return jQuery ( this ) . removeClass ( 'no-svg' ) ; else return jQuery ( this ) . addClass ( 'no-flex' ) ; } ; jQuery . fn . checkFlexbox = function ( ) { if ( ( 'flexWrap' in document . documentElement . style ) || ( 'WebkitFlexWrap' in document . documentElement . style ) || ( 'msFlexWrap' in document . documentElement . style ) ) return jQuery ( this ) . removeClass ( 'no-flex' ) ; else return jQuery ( this ) . addClass ( 'no-flex' ) ; } ;", "del_tokens": "/* Helper.js v1.5.2 */", "commit_type": "add"}
{"commit_tokens": ["Fixed", "https", ":", "//", "github", ".", "com", "/", "feathers", "-", "plus", "/", "feathers", "-", "authentication", "-", "management", "/", "issues", "/", "151"], "add_tokens": "await notifier ( options . notifier , 'sendResetPwd' , user2 , notifierOptions ) ;", "del_tokens": "notifier ( options . notifier , 'sendResetPwd' , user2 , notifierOptions ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "texture", "loading", "to", "be", "async"], "add_tokens": "const load = require ( 'load-asset' ) ; const sketch = ( async ( { canvas , width , height , pixelRatio , update } ) => { // Generate the image and wait for load to finish before // moving forward with rendering. const image = await load ( 'assets/baboon.jpg' ) ; // Once the image is loaded, we can update the output // settings to match it update ( { dimensions : settings . dimensions } ) ; sprite . fill = new Two . Texture ( image ) ; } ) ;", "del_tokens": "const sketch = ( { canvas , width , height , pixelRatio } ) => { sprite . fill = new Two . Texture ( 'assets/baboon.jpg' ) ; } ;", "commit_type": "update"}
{"commit_tokens": ["Use", "eslint", "-", "config", "-", "airbnb", "-", "base", "rules", "."], "add_tokens": "const hid = require ( '../' ) ; const Device = hid . device ; const keyboard = hid . parser . keyboard ; const HONEYWELL = 3118 ; const VOYAGER_1450G = 3233 ; const scanner = new Device ( { parser : keyboard , scanner . on ( 'data' , ( data ) => { console . log ( data ) ; // easily consumed data format!", "del_tokens": "var hid = require ( '../' ) ; var HONEYWELL = 3118 ; var VOYAGER_1450G = 3233 ; var scanner = new hid . device ( { parser : hid . parser . keyboard scanner . on ( \"data\" , function ( dat ) { console . log ( dat ) ; // easily consumed data format!", "commit_type": "use"}
{"commit_tokens": ["Add", "some", "steering", "behaviors", "."], "add_tokens": "// Remove first entry, which is current position. return path . slice ( 1 ) ;", "del_tokens": "return path ;", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "added", "fields", "updated", "readme"], "add_tokens": "fields = { } ; for ( var key in fields ) { data [ '@fields' ] [ key ] = fields [ key ] ; } if ( config . fields && typeof config . fields === 'object' ) { for ( var key in config . fields ) { if ( typeof config . fields [ key ] !== 'function' ) { fields [ key ] = config . fields [ key ] ; } } }", "del_tokens": "instance = 'myAWSinstance' , source = 'myApp' , environment = 'dev' ; instance : instance , source : source , environment : environment , instance = ( config . instance !== undefined ) ? config . instance : instance ; source = ( config . source !== undefined ) ? config . source : source ; environment = ( config . environment !== undefined ) ? config . environment : environment ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "facets", "and", "facet", "tests"], "add_tokens": "if ( data [ key ] . facetValues [ q [ 'facets' ] [ i ] ] ) { for ( var j = 0 ; j < data [ key ] . facetValues [ facetCat ] . length ; j ++ ) { var thisFacetValue = data [ key ] . facetValues [ facetCat ] [ j ] ;", "del_tokens": "if ( hit . facetValues [ q [ 'facets' ] [ i ] ] ) { for ( var j = 0 ; j < hit . facetValues [ facetCat ] . length ; j ++ ) { var thisFacetValue = hit . facetValues [ facetCat ] [ j ] ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "log", "from", "test", "bootstrap", "config"], "add_tokens": "port : 9800", "del_tokens": "port : 9800 , log : { level : 'silly' }", "commit_type": "remove"}
{"commit_tokens": ["Use", "JSTHROW", "*", "macros", "and", "fix", "coding", "style"], "add_tokens": "if ( err ) { throw err ; } if ( im . width ( ) < 1 || im . height ( ) < 1 ) { throw new Error ( 'Image has no size' ) ; }", "del_tokens": "console . log ( 'plop' ) ; if ( err ) { throw err ; } if ( im . width ( ) < 1 || im . height ( ) < 1 ) { throw new Error ( 'Image has no size' ) ; }", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "4", "parameter", "easing", "functions", "."], "add_tokens": "var art = emitter . particleImages [ 0 ] instanceof PIXI . Texture ? [ emitter . particleImages [ 0 ] ] : emitter . particleImages [ 0 ] ; * The velocity of the particle . Speed may change , but the angle also { if ( this . ease . length == 4 ) { //the t, b, c, d parameters that some tween libraries use //(time, initial value, end value, duration) lerp = this . ease ( lerp , 0 , 1 , 1 ) ; } else { //the simplified version that we like that takes //one parameter, time from 0-1. TweenJS eases provide this usage. lerp = this . ease ( lerp ) ; } }", "del_tokens": "var art = emitter . particleImages [ 0 ] instanceof PIXI . Texture ? [ emitter . particleImages [ 0 ] ] : emitter . particleImages [ 0 ] ; * The velocity of the particle . Speed may change , but the angle also lerp = this . ease ( lerp ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "title", "and", "path", "parsing", "for", "chapters", "&", "articles"], "add_tokens": "// Parses an Article or Chapter title // supports extracting links function parseTitle ( src ) { // Check if it's a link var matches = marked . InlineLexer . rules . link . exec ( src ) ; // Not a link, return plain text if ( ! matches ) { return { title : src , path : null , } ; } return { title : matches [ 1 ] , path : matches [ 2 ] , } ; } return parseTitle ( _ . first ( nodes ) . text ) ; chapter : parseTitle ( _ . first ( nodes ) . text ) ,", "del_tokens": "return _ . first ( nodes ) . text ; chapter : _ . first ( nodes ) . text ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "regression", "where", "preventing", "recursion", "also", "prevented", "requiredAs", "list", "from", "growing"], "add_tokens": "// prevent super recursion if ( dependencyList [ modulename ] ) { next ( ) ; return ; } dependencyList [ modulename ] = true ;", "del_tokens": "// prevent super recursion if ( dependencyList [ modulename ] ) { next ( ) ; return ; } dependencyList [ modulename ] = true ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "allow", "lambdas", "to", "return", "triple", "-", "staches", "and", "have", "those", "correctly", "interpreted", ".", "Added", "a", "test", "case", "exercising", "this", "behavior", "."], "add_tokens": "this . b ( this . ct ( coerceToString ( result . call ( cx ) ) , cx , partials ) ) ; return null ;", "del_tokens": "return this . ct ( coerceToString ( result . call ( cx ) ) , cx , partials ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "exception", "when", "trying", "to", "read", "statusCode", "from", "undefined", "response"], "add_tokens": "request ( { uri : 'https://www.googleapis.com/oauth2/v1/certs' } , function ( err , response , body ) { if ( err || ! response || response . statusCode != 200 ) {", "del_tokens": "request ( { uri : 'https://www.googleapis.com/oauth2/v1/certs' } , function ( err , response , body ) { if ( err && response . statusCode !== 200 ) {", "commit_type": "fix"}
{"commit_tokens": ["changed", "sync", "array", "to", "component", "array", "in", "network", "component", "schema"], "add_tokens": "opts . entity = '<a-entity id=\"test-entity\" network=\"networkId:network1;owner:owner1;components:position,rotation\" position=\"1 2 3\" rotation=\"4 3 2 1;\" template=\"src:#template1;\"></a-entity>' ;", "del_tokens": "opts . entity = '<a-entity id=\"test-entity\" network=\"networkId:network1;owner:owner1;sync:position,rotation\" position=\"1 2 3\" rotation=\"4 3 2 1;\"></a-entity>' ; // scale: { x: 1, y: 1, z: 1 }, // visible: true", "commit_type": "change"}
{"commit_tokens": ["add", "time", "to", "onSelect", "date", "argument", "add", "timepicker", "tests"], "add_tokens": "dates = new Date ( parsedSelected . year , parsedSelected . month , parsedSelected . date , parsedSelected . hours , parsedSelected . minutes ) ; return new Date ( parsedSelected . year , parsedSelected . month , parsedSelected . date , parsedSelected . hours , parsedSelected . minutes ) ;", "del_tokens": "dates = new Date ( parsedSelected . year , parsedSelected . month , parsedSelected . date ) ; return new Date ( parsedDate . year , parsedDate . month , parsedDate . date )", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "angular", "integration", "."], "add_tokens": "$ExceptionlessClient . createUnhandledException ( new Error ( \"[\" + rejection . status + \"] \" + rejection . config . url ) , 'errorHttpInterceptor' ) . setProperty ( 'request' , rejection . config ) if ( arguments [ 0 ] && arguments [ 0 ] . length > 0 ) { $ExceptionlessClient . submitLog ( null , arguments [ 0 ] , logLevel ) ; } //# sourceMappingURL=angular.js.map", "del_tokens": "$ExceptionlessClient . createUnhandledException ( new Error ( 'HTTP response error' ) , 'errorHttpInterceptor' ) . setProperty ( 'status' , rejection . status ) . setProperty ( 'config' , rejection . config ) $ExceptionlessClient . submitLog ( null , arguments [ 0 ] , logLevel ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "grunt", "watch", "task", "for", "tests"], "add_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'karma:unit' ] ) ; grunt . registerTask ( 'watch' , [ 'karma:watch' ] ) ; } , watch : { options : testConfig ( 'test/karma.conf.js' ) , singleRun : false , autoWatch : true", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'karma' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Allowed", "--", "appId", "and", "--", "versionId", "args", "as", "overrides", "to", "the", ".", "luisrc"], "add_tokens": "params = Object . assign ( ( dataModel || { } ) , { appId , versionId } , params ) ;", "del_tokens": "params = Object . assign ( ( dataModel || { } ) , params , { appId , versionId } ) ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "map", "+", "join", "over", "reduce", "for", "better", "performance"], "add_tokens": "return _ . map ( this . components , function ( component ) { return component . getDOMNode ( ) . innerText || component . getDOMNode ( ) . textContent ; } ) . join ( '' ) ;", "del_tokens": "return _ . reduce ( this . components , function ( memo , comp ) { return memo += comp . getDOMNode ( ) . innerText || comp . getDOMNode ( ) . textContent ; } , '' )", "commit_type": "use"}
{"commit_tokens": ["use", "existing", "path", "if", "path", "isn", "t", "specified", "when", "updating", "a", "named", "route"], "add_tokens": "var path = undefined , funcs ; path : route . path if ( ! found ) { if ( typeof route . path === 'undefined' ) def . path = name } if ( typeof def . path === 'undefined' ) def . path = prop ; //use name as path", "del_tokens": "path : name , var path = '' , funcs ; path = name ; //use varname as path path : route . path || name if ( ! found )", "commit_type": "use"}
{"commit_tokens": ["changed", "layout", "to", "authorize", "more", "than", "one", "model"], "add_tokens": "poller = require ( './lib/poller' ) ; // models var Target = require ( './models/target' ) . Target ; Target . remove ( { } , function ( err ) { t = new Target ( ) ; t = new Target ( ) ; Target . find ( { } , function ( err , docs ) {", "del_tokens": "poller = require ( './lib/poller' ) , schema = require ( './lib/schema' ) ; schema . Target . remove ( { } , function ( err ) { t = new schema . Target ( ) ; t = new schema . Target ( ) ; schema . Target . find ( { } , function ( err , docs ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "test", "for", "travis", "ci", "(", "cannot", "use", "sudo", "to", "launch", "node", ")"], "add_tokens": "const port = process . env . PORT || /* istanbul ignore next: impossible to test */ 443 /* istanbul ignore else: useless to test */ if ( port === 443 || process . env . HTTP_PORT ) } ) . listen ( process . env . HTTP_PORT || /* istanbul ignore next: impossible to test */ 80 ) /* istanbul ignore else: useless to test */ /* istanbul ignore if: impossible to test */", "del_tokens": "const port = process . env . PORT || 443 /* istanbul ignore else */ // useless to test if ( port === 443 ) } ) . listen ( 80 ) /* istanbul ignore else */ // useless to test /* istanbul ignore if */ // impossible to test", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Empty", "adSlot", "Object", "Caused", "by", "Ad", "Blocker"], "add_tokens": "if ( adSlot && adSlot . hasOwnProperty ( \"getServices\" ) ) {", "del_tokens": "if ( adSlot ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "tests", ".", "Become", "more", "opinionated", "."], "add_tokens": "// Dates // Arrays (assumed to be lists) // Numbers if ( / \\d+ / . test ( x ) ) { return x . toString ( ) ; } // Assume all other objects must be collections of some kind", "del_tokens": "if ( x . toString ) { return x . toString ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fixing", "bug", "where", "inline", "style", "were", "being", "removed", "erroneously"], "add_tokens": "* F2 v0 .12 .4", "del_tokens": "* F2 v0 .12 .3", "commit_type": "fix"}
{"commit_tokens": ["Change", "some", "QuerySet", "method", "names", "and", "functionality", ".", "Breaking", "changes", ".", "Make", "orderBy", "work"], "add_tokens": "/ ** * Returns a reference to the plain JS object in the store . * Make sure to not mutate this . * * @ return { Object } a reference to the plain JS object in the store * / get ref ( ) { return this . getClass ( ) . accessId ( this . getId ( ) ) ; } if ( this [ key ] !== null ) {", "del_tokens": "if ( this [ key ] !== null ) {", "commit_type": "change"}
{"commit_tokens": ["Fixing", "the", "issue", "of", "copying", "folders", "failing", "due", "to", "last", "update"], "add_tokens": "if ( file . indexOf ( \".mustache\" ) > 0 && ( file . indexOf ( \".mustache\" ) - ( file . length - \".mustache\" . length ) === 0 ) ) {", "del_tokens": "if ( file . indexOf ( \".mustache\" ) - ( file . length - \".mustache\" . length ) === 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["remove", "search", "from", "user", "store"], "add_tokens": "return async ( dispatch , getState ) => { const { currentUserId } = getState ( ) . entities . users ; dispatch ( { type : UsersTypes . SEARCH_PROFILES_REQUEST } , getState ) ; const profiles = { } ; let search ; try { search = await Client . searchProfiles ( term , options || { } ) ; search . forEach ( ( p ) => { if ( p . id !== currentUserId ) { profiles [ p . id ] = p ; } } ) ; } catch ( error ) { forceLogoutIfNecessary ( error , dispatch ) ; dispatch ( batchActions ( [ { type : UsersTypes . SEARCH_PROFILES_FAILURE , error } , getLogErrorAction ( error ) ] ) , getState ) ; return null ; } dispatch ( batchActions ( [ { type : UsersTypes . RECEIVED_PROFILES , data : profiles } , { type : UsersTypes . SEARCH_PROFILES_SUCCESS } ] ) , getState ) ; return profiles ; } ;", "del_tokens": "return bindClientFunc ( Client . searchProfiles , UsersTypes . SEARCH_PROFILES_REQUEST , [ UsersTypes . RECEIVED_SEARCH_PROFILES , UsersTypes . SEARCH_PROFILES_SUCCESS ] , UsersTypes . SEARCH_PROFILES_FAILURE , term , options || { } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "with", "updateDevVersion", "task"], "add_tokens": "grunt . task . run ( [ 'shell:updateDevVersion' ] ) ; grunt . task . run ( [ 'jshint' , 'extRelease:' + arg , 'updateDevVersion' ] ) ;", "del_tokens": "grunt . task . run ( [ 'shell:commitDevVersion' ] ) ; grunt . task . run ( [ 'jshint' , 'extRelease:' + arg , 'shell:updateDevVersion' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "instrument", ".", "js", "to", "follow", "convention", "of", "jalangi", ".", "js", "et", "al", "and", "name", "smap", "files", "foo_jalangi_", ".", "json", "(", "to", "prevent", "overwriting", "foo", ".", "json", "files", ")", "."], "add_tokens": "fs . writeFileSync ( path . join ( copyDir , instname ) . replace ( / .js$ / , \"_jalangi_.json\" ) , instResult . sourceMapString , \"utf8\" ) ; fs . writeFileSync ( this . instScriptName . replace ( / .js$ / , \"_jalangi_.json\" ) , instResult . sourceMapString , \"utf8\" ) ;", "del_tokens": "fs . writeFileSync ( path . join ( copyDir , instname ) . replace ( / .js$ / , \".json\" ) , instResult . sourceMapString , \"utf8\" ) ; fs . writeFileSync ( this . instScriptName . replace ( / .js$ / , \".json\" ) , instResult . sourceMapString , \"utf8\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Move", "some", "stuff", "to", "model", "and", "controller", "classes"], "add_tokens": "Activity [ verb . toUpperCase ( ) . replace ( '-' , '_' ) ] = verb ; Activity . schema = { pkey : 'id' , fields : [ 'actor' , 'content' , 'generator' , 'icon' , 'id' , 'object' , 'published' , 'provider' , 'target' , 'title' , 'url' , 'updated' , 'verb' ] , indices : [ 'actor.id' , 'object.id' ] } ;", "del_tokens": "Activity [ verb . toUpperCase ( ) ] = verb ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "npm", "package", "to", "work", "right"], "add_tokens": "console . dir ( WebApp ) ; var child = WebApp ( \"http://127.0.0.1:\" + PORT + \"/index.html\" ) ; child . stdout . pipe ( process . stdout ) ; child . stderr . pipe ( process . stderr ) ; console . dir ( WebApp ) ; setTimeout ( function ( ) { } , 1000 ) ;", "del_tokens": "WebApp ( \"http://127.0.0.1:\" + PORT + \"/index.html\" , function ( err ) { if ( err ) throw err ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "an", "issue", "with", "Signal", ".", "fromEvent"], "add_tokens": "import { always , apply , empty , head , tail } from 'fkit' target . addEventListener ( type , emit . next , useCapture ) target . removeEventListener ( 'type' , emit . next , useCapture )", "del_tokens": "import { always , apply , compose , empty , get , head , tail } from 'fkit' const handler = compose ( emit . next , get ( 'detail' ) ) target . addEventListener ( type , handler , useCapture ) target . removeEventListener ( 'type' , handler , useCapture )", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "for", "_", ".", "isIndexed", "and", "fixed", "a", "misnamed", "arg", "bug"], "add_tokens": "isIndexed : function ( x ) { return _ . isArray ( x ) || _ . isString ( x ) || _ . isArguments ( x ) ; } ,", "del_tokens": "isIndexed : function ( x ) { return _ . isArray ( data ) || _ . isString ( data ) || _ . isArguments ( x ) ; } ,", "commit_type": "add"}
{"commit_tokens": ["fix", "broken", "watchPosition", "/", "clearWatch"], "add_tokens": "watchPosition : function ( successCallback , errorCallback , options ) { clearWatch : function ( successCallback , errorCallback , options ) {", "del_tokens": "watchPosition : function ( success , error , args ) { clearWatch : function ( success , error , args ) {", "commit_type": "fix"}
{"commit_tokens": ["Moving", "test", "-", "harness", "out", "of", "app", "and", "into", "plugin"], "add_tokens": "/ * * * Licensed to the Apache Software Foundation ( ASF ) under one * or more contributor license agreements . See the NOTICE file * distributed with this work for additional information * regarding copyright ownership . The ASF licenses this file * to you under the Apache License , Version 2.0 ( the * \"License\" ) ; you may not use this file except in compliance * with the License . You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * \"AS IS\" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . * * / / * * /", "del_tokens": "( function ( ) { var exports = window ; } ( ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "hasSibling", "and", "hasTile", "check", "9x", "faster"], "add_tokens": "function hasSiblings ( tile , tiles ) { for ( var i = 0 ; i < siblings . length ; i ++ ) { if ( ! hasTile ( tiles , siblings [ i ] ) ) return false ; } return true ; for ( var i = 0 ; i < tiles . length ; i ++ ) { if ( tilesEqual ( tiles [ i ] , tile ) ) return true ; } return false ; } ;", "del_tokens": "function hasSiblings ( tile , tiles ) { var hasAll = true ; siblings . forEach ( function ( sibling ) { if ( ! hasTile ( tiles , sibling ) ) { hasAll = false ; } } ) ; return hasAll ; var tileFound = false ; tiles . forEach ( function ( t ) { if ( tilesEqual ( t , tile ) ) { tileFound = true ; } } ) ; return tileFound ; } ;", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "simple", "(", "file", "[", "0", "]", "==", ".", ")", "test", "instead", "of", "a", "full", "regexp", "to", "ignore", "hidden", "files"], "add_tokens": "if ( file [ 0 ] == '.' ) { return ; } //ignore files starting with \".\" if ( file [ 0 ] == '.' ) { return ; } //ignore files starting with \".\"", "del_tokens": "if ( / ^\\. / . test ( file ) ) { return ; } //ignore files starting with \".\" if ( / ^\\. / . test ( file ) ) { return ; } //ignore files starting with \".\"", "commit_type": "use"}
{"commit_tokens": ["add", "test", "for", "closing", "an", "opening", "connection"], "add_tokens": "self . _queue . push ( function ( db ) {", "del_tokens": "self . queue . push ( function ( db ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "remaining", "connectionInfo", "usage", "in", "crypto", ".", "js"], "add_tokens": "var signId = nacl . util . decodeBase64 ( contact . nodeInfo . signId )", "del_tokens": "var signId = nacl . util . decodeBase64 ( contact . connectionInfo . signId )", "commit_type": "fix"}
{"commit_tokens": ["remove", "log", "and", "reformat", "file"], "add_tokens": "// console.log('instrument/actions.js triggering', type, 'on element: ', element.tagName, 'classname:', element.className);", "del_tokens": "console . log ( 'instrument/actions.js triggering' , type , 'on element: ' , element . tagName , 'classname:' , element . className ) ;", "commit_type": "remove"}
{"commit_tokens": ["Removed", "second", "plugin", "version", "in", "file", "header", "."], "add_tokens": "jQuery Wookmark plugin", "del_tokens": "jQuery Wookmark plugin 1.0 .2", "commit_type": "remove"}
{"commit_tokens": ["fix", "cursor", "screwiness", "on", "empty", "lines"], "add_tokens": "var empty = ! html . html ; if ( ! empty && pos === sfrom && sfrom === sto ) html . push ( \"<span class=\\\"CodeMirror-cursor\\\">\\u200b</span>\" ) ; if ( sel === 1 && sto == null ) html . push ( \"<span class=\\\"CodeMirror-selected\\\"> </span>\" ) ; else if ( empty ) addPiece ( \" \" , \"\" ) ;", "del_tokens": "if ( pos === sfrom && sfrom === sto ) html . push ( \"<span class=\\\"CodeMirror-cursor\\\">\\u200b</span>\" ) ; else if ( sel === 1 && sto == null ) html . push ( \"<span class=\\\"CodeMirror-selected\\\"> </span>\" ) ; else if ( ! html . length ) addPiece ( \" \" , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "connReady", "event", "to", "connStatus"], "add_tokens": "case \"connStatus\" : const response = msg . data || { } ; const statusCode = response . status ; switch ( statusCode ) { case 200 : connStatus [ msg . conn ] . ready = true ; break ; case 401 : // authorization error, need to log in connStatus [ msg . conn ] . ready = false ; connStatus [ msg . conn ] . user = null ; connStatus [ msg . conn ] . anonymous = true ; break ; default : console . warn ( \"Invalid connection response status: \" + JSON . stringify ( response ) ) ; break ; } break ; break ; break ; break ; break ; break ; break ; return ; user : settings . user , anonymous : settings . anonymous", "del_tokens": "case \"connReady\" : connStatus [ msg . conn ] . ready = true ; return ; return ; return ; return ; return ; return ; user : connSettings . user , anonymous : connSettings . anonymous", "commit_type": "change"}
{"commit_tokens": ["update", "example", "+", "add", "Bindings", ".", "toString", "()"], "add_tokens": "const { Transform } = require ( 'stream' ) // An utility class used to convert LevelGraph bindings // into a format undestood by sparql-engine class FormatterStream extends Transform { constructor ( ) { super ( { objectMode : true } ) } _transform ( item , encoding , callback ) { // Transform LevelGraph objects into set of mappings // using BindingBase.fromObject this . push ( BindingBase . fromObject ( item ) ) callback ( ) } } // Transform the Stream returned by LevelGraph into an Stream of Bindings return new FormatterStream ( this . _db . searchStream ( bgp ) ) iterator . subscribe ( bindings => { console . log ( 'Find solutions:' , bindings . toObject ( ) ) } , err => { console . error ( 'error' , err ) } , ( ) => {", "del_tokens": "const { AsyncIterator } = require ( 'asynciterator' ) // Transform the Stream returned by LevelGraph into an AsyncIterator return AsyncIterator . wrap ( this . _db . searchStream ( bgp ) ) . map ( item => { // Transform LevelGraph objects into set of mappings // using BindingBase.fromObject return BindingBase . fromObject ( item ) } ) iterator . on ( 'data' , console . log ) iterator . on ( 'error' , console . error ) iterator . on ( 'end' , ( ) => {", "commit_type": "update"}
{"commit_tokens": ["fixed", "error", "when", "undefined", "value", "is", "first", "property", "in", "object"], "add_tokens": "let first = true ; if ( ! first ) { } else { first = false ;", "del_tokens": "if ( i ) {", "commit_type": "fix"}
{"commit_tokens": ["using", "a", "mixin", "function", "for", "dealing", "with", "an", "array", "of", "objects"], "add_tokens": "Action . prototype . field = mixin . arrayPropProto ( \"fields\" , Field ) ;", "del_tokens": "Action . prototype . field = function ( name , type , val ) { if ( ! this . _fields ) { this . _fields = [ ] ; } this . _fields . push ( new Field ( name , type , val ) ) ; return this ; } ;", "commit_type": "use"}
{"commit_tokens": ["update", "jssdk", "to", "avoid", "duplicate", "function"], "add_tokens": "$fh . _handleFhAuthResponse = function ( endurl , res , success , fail ) { $fh . _handleFhAuthResponse ( endurl , res , success , fail ) ;", "del_tokens": "$fh . _handleAuthResponse = function ( endurl , res , success , fail ) { $fh . _handleAuthResponse ( endurl , res , success , fail ) ;", "commit_type": "update"}
{"commit_tokens": ["removed", "use", "of", "..", "/", "support", "/", "should", "for", "now"], "add_tokens": ", should = require ( 'should' )", "del_tokens": ", should = require ( '../support/should' )", "commit_type": "remove"}
{"commit_tokens": ["Updated", "testing", "fs", "failure", "+", "beautifying", "code"], "add_tokens": "username = require ( 'username' ) ; if ( error . code !== 'ENOENT' ) { callback ( error ) ; return ; } if ( error . code !== 'ENOENT' ) { callback ( error ) ; return ; } callback ( error , null ) ;", "del_tokens": "username = require ( 'username' ) ; callback ( error ) ; return ; callback ( error ) ; return ; } else if ( error . code === 'ENOENT' ) { callback ( null , false ) ; callback ( error ? error : 'The .autostart.json is not a file' , null ) ;", "commit_type": "update"}
{"commit_tokens": ["Allowing", "empty", "vars", "data", "."], "add_tokens": "if ( typeof this . varsData !== 'string' ) { if ( typeof this . themeData !== 'string' ) {", "del_tokens": "if ( ! this . varsData ) { if ( ! this . themeData ) {", "commit_type": "allow"}
{"commit_tokens": ["Created", ".", "toggle", "()", "to", "show", "and", "hide", "elements"], "add_tokens": "else if ( typeof define === 'function' && define . amd )", "del_tokens": "else if ( typeof define === 'function' && define . amd )", "commit_type": "create"}
{"commit_tokens": ["Add", "iam", "plugin", "extension", "addRole"], "add_tokens": ". catch ( e => { if ( e . code === 'ENOENT' && path . basename ( e . path ) === 'roles' ) { return Promise . resolve ( [ ] ) ; } return Promise . reject ( e ) ; } ) addRole : loadRole ,", "del_tokens": "} ) . catch ( e => { if ( e . code === 'ENOENT' && path . basename ( e . path ) === 'roles' ) { return Promise . resolve ( [ ] ) ; } return Promise . reject ( e ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "Casper", ".", "repeat", "()", "method", "for", "easy", "definition", "of", "repeated", "steps"], "add_tokens": "var step = self . steps [ self . step ] ; if ( ! self . loadInProgress && typeof ( step ) === \"function\" ) { step ( self ) ; if ( typeof ( step ) !== \"function\" ) { * casper . evaluate ( function ( ) { / ** * Repeats a step a given number of times . * * @ param Number times Number of times to repeat step * @ aram function step The step closure * @ return Casper * @ see Casper # then * / repeat : function ( times , step ) { for ( var i = 0 ; i < times ; i ++ ) { this . then ( step ) ; } return this ; } ,", "del_tokens": "if ( ! self . loadInProgress && typeof ( self . steps [ self . step ] ) === \"function\" ) { self . steps [ self . step ] ( self ) ; if ( typeof ( self . steps [ self . step ] ) !== \"function\" ) { * navigator . evaluate ( function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "script", "and", "~script"], "add_tokens": "// Check for script context if ( contextParams [ 'script' ] !== undefined ) { if ( ! contextParams [ 'script' ] && filterDataContainsOption ( parsedFilterData , 'script' ) ) { return false ; } else if ( contextParams [ 'script' ] && filterDataContainsOption ( parsedFilterData , '~script' ) ) { return false ; } } if ( inputHostIsThirdParty || ! contextParams [ 'third-party' ] ) { return false ; }", "del_tokens": "return ! inputHostIsThirdParty && contextParams [ 'third-party' ] ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "not", "adding", "a", "parameter", "by", "using", "null", "as", "value"], "add_tokens": "if ( value !== undefined && value !== null ) {", "del_tokens": "if ( value !== undefined ) {", "commit_type": "add"}
{"commit_tokens": ["adding", "third", "parameter", "to", "action", "function"], "add_tokens": "flag . action ( err , value , program ) ; command . action ( err , remaining_args , program ) ;", "del_tokens": "flag . action ( err , value ) ; command . action ( err , remaining_args ) ;", "commit_type": "add"}
{"commit_tokens": ["updating", "code", "to", "use", "new", "protobuff", "version", "."], "add_tokens": "callback ( ) ;", "del_tokens": "callback ( null , _root ) ;", "commit_type": "update"}
{"commit_tokens": ["make", "sunrise", "/", "set", "a", "bit", "more", "precise"], "add_tokens": "[ - 0.833 , 'sunrise' , 'sunset' ] , [ - 0.3 , 'sunriseEnd' , 'sunsetStart' ] , [ - 6 , 'dawn' , 'dusk' ] , [ - 12 , 'nauticalDawn' , 'nauticalDusk' ] , [ - 18 , 'nightEnd' , 'night' ] , [ 6 , 'goldenHourEnd' , 'goldenHour' ]", "del_tokens": "[ - 0.83 , 'sunrise' , 'sunset' ] , [ - 0.3 , 'sunriseEnd' , 'sunsetStart' ] , [ - 6 , 'dawn' , 'dusk' ] , [ - 12 , 'nauticalDawn' , 'nauticalDusk' ] , [ - 18 , 'nightEnd' , 'night' ] , [ 6 , 'goldenHourEnd' , 'goldenHour' ]", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "on", "basic", "login", "functionality"], "add_tokens": "replace : true , if ( token && token . access_token && config . profile ) { Profile . get ( ) . success ( function ( response ) { scope . profile = response } ) } scope . show = 'logged-in' ; scope . show = 'logged-out' ;", "del_tokens": "replace : false , if ( token && token . access_token && config . profile ) scope . profile = Profile . get ( ) ; scope . show = 'logged-out' ; scope . show = 'logged-in' ;", "commit_type": "add"}
{"commit_tokens": ["make", "escape_html", "independent", "settings", "for", "global", "and", "each", "instance"], "add_tokens": "if ( escape_html ) escape_html = this . escape_html ; jSmart . prototype . escape_html = false ;", "del_tokens": "if ( jSmart . prototype . escape_html ) jSmart . prototype . escape_html = false ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "printing", "bug", "involving", "old", "rngCat", "code"], "add_tokens": "var printVec = this . s ( [ headRange , tailRange ] ) . _toPrintVector ( ) ;", "del_tokens": "var printVec = this . s ( jd . rngCat ( headRange , tailRange ) ) . _toPrintVector ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "monitoring", "script", "command", "line", "arguments", "and", "their", "descriptions"], "add_tokens": ". usage ( 'Usage: $0 monitor [--help|-h] [--notify-port|-p <port>] [--target-hostname|-t <hostname>] [--reload-port|-r <port>] [--show-notification|-n] <bundle-path>' ) . alias ( 't' , 'target-hostname' ) . describe ( 't' , 'Hostname of the WebSocket clients where reloading events will be sent (default: localhost)' ) . alias ( 'p' , 'notify-port' ) . describe ( 'p' , 'Notification HTTP port (see \"listen\" command) that triggers reloading event' ) require ( '../lib/server/monitor' ) ( monitor . _ [ 1 ] , { displayNotification : ! ! monitor . n , hostname : monitor . t , port : monitor . r , notifyPort : monitor . p } )", "del_tokens": ". usage ( 'Usage: $0 monitor [--help|-h] [--reload-port|-rp] [--hostname|-hn] [--show-notification|-n] <bundle-path>' ) . alias ( 'a' , 'hostname' ) . describe ( 'a' , 'hostname' ) . alias ( 'y' , 'notify-port' ) . describe ( 'y' , 'Notification HTTP port (see \"listen\" command) that triggers reloading event' ) require ( '../lib/server/monitor' ) ( monitor . _ [ 1 ] , { displayNotification : ! ! monitor . n , port : monitor . r , notifyPort : monitor . y , hostname : monitor . a } )", "commit_type": "fix"}
{"commit_tokens": ["using", "_", ".", "mapValues", "instead", "of", "reduce", "."], "add_tokens": "return _ . mapValues ( item . M , unmarshal ) ;", "del_tokens": "return _ . reduce ( item . M , function ( result , value , key ) { result [ key ] = unmarshal ( value ) ; return result ; } , { } ) ;", "commit_type": "use"}
{"commit_tokens": ["changed", "to", "contrib", "-", "connect"], "add_tokens": "connect : { port : 4000 , base : 'src' , keepalive : true } , grunt . loadNpmTasks ( 'grunt-contrib-connect' ) ; grunt . registerTask ( 'dev' , [ 'connect:dev'", "del_tokens": "nodemon : { file : 'server.js' , env : { PORT : 4000 } } grunt . loadNpmTasks ( 'grunt-nodemon' ) ; grunt . registerTask ( 'default' , [ 'nodemon'", "commit_type": "change"}
{"commit_tokens": ["Add", "Base#precompile", "()", "method", "to", "batch", "-", "compilations"], "add_tokens": "* manifest . compile ( \"app.js\" , function ( err , data ) { * // ... * } ) ;", "del_tokens": "* manifest . compile ( \"app.js\" , function ( err , data ) { * // ... * } ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "in", "relative", "position", "angle"], "add_tokens": "const [ sinr, osr] = b se.s i ncos(c 1 .r a - c .r a )", "del_tokens": "const [ sinr, osr] = b se.s i ncos(c 2 .r a - c .r a )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "test", "so", "it", "expects", "&", "verifies", "cstring"], "add_tokens": "assert . equalBuffers ( stream . packets [ 0 ] , [ 0x51 , 0 , 0 , 0 , 6 , 33 , 0 ] )", "del_tokens": "assert . equalBuffers ( stream . packets [ 0 ] , [ 0x51 , 0 , 0 , 0 , 5 , 33 ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "create", "method"], "add_tokens": "it ( 'should create pointer with correct props' , function ( done ) { var shard = { index : 1 , hash : 'fjla93fs9-23892-2sdl@#ds-932049203' , size : 1 , tree : [ 'tree1' , 'tree2' ] , challenges : [ 'challenge1' , 'challenge2' ] } ; Pointer . create ( shard , function ( err , pointer ) { expect ( err ) . to . not . be . an . instanceOf ( Error ) ; expect ( pointer . index ) . to . equal ( shard . index ) ; expect ( pointer . index ) . to . be . a ( 'number' ) ; expect ( pointer . hash ) . to . equal ( shard . hash ) ; expect ( pointer . hash ) . to . be . a ( 'string' ) ; expect ( pointer . size ) . to . equal ( shard . size ) ; expect ( pointer . size ) . to . be . a ( 'number' ) ; expect ( pointer . tree ) . to . be . an ( 'array' ) ; expect ( pointer . challenges ) . to . be . an ( 'array' ) ; done ( ) ; } ) ; } ) ; } ) ;", "del_tokens": "// const storj = require('storj-lib'); } )", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "browsers", "to", "local", "karma", "grunt", "task"], "add_tokens": "browsers : [ \"Chrome\" , \"Safari\" , \"Firefox\" ] , //\"CHROME_LATEST_2\": [\"SL_CHROME_LATEST_LINUX\"], //\"FIREFOX_LATEST_2\": [\"SL_FIREFOX_LATEST_LINUX\"],", "del_tokens": "browsers : [ \"Chrome\" ] , \"CHROME_LATEST_2\" : [ \"SL_CHROME_LATEST_LINUX\" ] , \"FIREFOX_LATEST_2\" : [ \"SL_FIREFOX_LATEST_LINUX\" ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "initial", "test", "index", "."], "add_tokens": "//require(\"./exporter_test\");", "del_tokens": "// require(\"./exporter_test\");", "commit_type": "fix"}
{"commit_tokens": ["add", "uniqueID", "to", "Glide", "instance"], "add_tokens": "this . uniqueID = parseInt ( Math . random ( ) * 1000 ) ; } ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "project", "name", "in", "compiled", "file", "header"], "add_tokens": "* LeapJS - Plugins Extra - v0 .1 .0 - 2014 - 02 - 07", "del_tokens": "* LeapJS - Plugins # { project } - v0 .1 .0 - 2014 - 02 - 07", "commit_type": "fix"}
{"commit_tokens": ["add", "activate", "and", "deactivate", "hooks", "for", "targets"], "add_tokens": "isActive : function ( key , value ) { // Set if ( arguments . length > 1 ) { if ( value ) { if ( activators . contains ( 'focus' ) ) { set ( this , 'focused' , true ) ; } else if ( activators . contains ( 'hover' ) ) { set ( this , 'hovered' , true ) ; } else if ( activators . contains ( 'click' ) ) { set ( this , 'active' , true ) ; } } else { set ( this , 'focused' , false ) ; set ( this , 'hovered' , false ) ; set ( this , 'active' , false ) ; } return value ; } // Get", "del_tokens": "isActive : function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "scoped", "variables", "in", "ES5", "getters", "when", "possible"], "add_tokens": "var onPress ; heading . setAttribute ( \"aria-selected\" , _open ) ; heading . setAttribute ( \"aria-expanded\" , _open ) ; content . setAttribute ( \"aria-hidden\" , ! _open ) ; heading . removeEventListener ( pressEvent , onPress ) ; THIS . ariaEnabled = false ; heading . addEventListener ( pressEvent , onPress ) ; heading . addEventListener ( pressEvent , onPress = function ( e ) {", "del_tokens": "heading . setAttribute ( \"aria-selected\" , this . _open ) ; heading . setAttribute ( \"aria-expanded\" , this . _open ) ; content . setAttribute ( \"aria-hidden\" , ! this . _open ) ; heading . removeEventListener ( pressEvent , this . onPress ) ; this . ariaEnabled = false ; heading . addEventListener ( pressEvent , this . onPress ) ; heading . addEventListener ( pressEvent , this . onPress = function ( e ) {", "commit_type": "use"}
{"commit_tokens": ["Used", "all", "the", "public", "ducks", "."], "add_tokens": "_ . isObject ( value ) && _ . isFunction ( value . traverseSchema ) && _ . isFunction ( value . normalizeSchema ) && _ . isFunction ( value . getData ) && _ . isFunction ( value . traverse ) && _ . isFunction ( value . transform ) && _ . isFunction ( value . transformAsync ) && _ . isFunction ( value . validate ) && _ . isFunction ( value . normalize ) && _ . isFunction ( value . serialize ) && _ . isFunction ( value . createValidateFn ) && _ . isFunction ( value . createNormalizeFn ) && _ . isFunction ( value . getSchemaType ) && _ . isFunction ( value . getSubschemaData )", "del_tokens": "_ . isObject ( value ) && _ . isFunction ( value . traverseSchema ) && _ . isFunction ( value . normalizeSchema ) && _ . isFunction ( value . getData ) && _ . isFunction ( value . traverse ) && _ . isFunction ( value . transform ) && _ . isFunction ( value . transformAsync ) && _ . isFunction ( value . validate ) && _ . isFunction ( value . normalize ) && _ . isFunction ( value . serialize ) && _ . isFunction ( value . getSchemaType ) && _ . isFunction ( value . getSubschemaData )", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "correct", "build", "folder", "when", "deleting", "assets", "in", "watch", "mode"], "add_tokens": "rimraf ( path . join ( createAndGetBuildFolder ( ) , 'css' ) , ( ) => {", "del_tokens": "rimraf ( path . join ( dataPath , 'build/css' ) , ( ) => {", "commit_type": "use"}
{"commit_tokens": ["Updated", "lib", "/", "blockdevice", ":", "zero", "buffer", "in", ".", "read", "()"], "add_tokens": "read : function ( position , length , buffer , callback ) { buffer . fill ( 0 ) this . fd , buffer , 0 , length , position ,", "del_tokens": "read : function ( offset , length , buffer , callback ) { this . fd , buffer , 0 , length , offset ,", "commit_type": "update"}
{"commit_tokens": ["added", "more", "examples", "and", "fixed", "some", "existing", "ones"], "add_tokens": "\" 'path' : \\\"/somePath\\\",\\n\" + \" 'queryStringParameters' : {\\n\" + \" 'userId' : request.queryStringParameters && request.queryStringParameters['userId']\\n\" + \" },\\n\" + \" 'headers' : {\\n\" + \" 'Host' : [ \\\"localhost:1081\\\" ]\\n\" + \" },\\n\" + \" 'body': JSON.stringify({'name': 'value'})\\n\" + \"};\" , \" 'path' : \\\"/somePath\\\",\\n\" + \" 'cookies' : {\\n\" + \" 'SessionId' : request.cookies && request.cookies['SessionId']\\n\" + \" },\\n\" + \" 'headers' : {\\n\" + \" 'Host' : [ \\\"localhost:1081\\\" ]\\n\" + \" },\\n\" + \" 'keepAlive' : true,\\n\" + \" 'secure' : true,\\n\" + \" 'body' : \\\"some_body\\\"\\n\" + \"};\" , \" 'path' : \\\"/somePath\\\",\\n\" + \" 'queryStringParameters' : {\\n\" + \" 'userId' : [ \\\"$!request.queryStringParameters['userId'][0]\\\" ]\\n\" + \" },\\n\" + \" 'cookies' : {\\n\" + \" 'SessionId' : \\\"$!request.cookies['SessionId']\\\"\\n\" + \" },\\n\" + \" 'headers' : {\\n\" + \" 'Host' : [ \\\"localhost:1081\\\" ]\\n\" + \" },\\n\" + \" 'body': \\\"{'name': 'value'}\\\"\\n\" + \"}\" ,", "del_tokens": "\" 'path' : \\\"/somePath\\\",\\n\" + \" 'queryStringParameters' : {\\n\" + \" 'userId' : request.queryStringParameters && request.queryStringParameters['userId']\\n\" + \" },\\n\" + \" 'headers' : {\\n\" + \" 'Host' : [ \\\"localhost:1081\\\" ]\\n\" + \" },\\n\" + \" 'body': JSON.stringify({'name': 'value'})\\n\" + \"};\" , \" 'path' : \\\"/somePath\\\",\\n\" + \" 'cookies' : {\\n\" + \" 'SessionId' : request.cookies && request.cookies['SessionId']\\n\" + \" },\\n\" + \" 'headers' : {\\n\" + \" 'Host' : [ \\\"localhost:1081\\\" ]\\n\" + \" },\\n\" + \" 'keepAlive' : true,\\n\" + \" 'secure' : true,\\n\" + \" 'body' : \\\"some_body\\\"\\n\" + \"};\" , \" 'path' : \\\"/somePath\\\",\\n\" + \" 'queryStringParameters' : {\\n\" + \" 'userId' : [ \\\"$!request.queryStringParameters['userId'][0]\\\" ]\\n\" + \" },\\n\" + \" 'cookies' : {\\n\" + \" 'SessionId' : \\\"$!request.cookies['SessionId']\\\"\\n\" + \" },\\n\" + \" 'headers' : {\\n\" + \" 'Host' : [ \\\"localhost:1081\\\" ]\\n\" + \" },\\n\" + \" 'body': \\\"{'name': 'value'}\\\"\\n\" + \"}\" ,", "commit_type": "add"}
{"commit_tokens": ["add", "websocket", "support", "to", "MemoryUsage", "sample", "widget"], "add_tokens": "filename : 'MemoryUsage.js'", "del_tokens": "filename : 'bundle.js' ,", "commit_type": "add"}
{"commit_tokens": ["added", "gc", "support", "for", "desperate", "cases"], "add_tokens": "if ( ! ( 'gc' in window ) ) { window . gc = function ( ) { } } gc ( ) ;", "del_tokens": "//gc();", "commit_type": "add"}
{"commit_tokens": ["remove", "karma", "-", "happen", "from", "karma", ".", "conf", ".", "js"], "add_tokens": "'karma-sinon-ie'", "del_tokens": "'karma-sinon-ie' , 'karma-happen'", "commit_type": "remove"}
{"commit_tokens": ["moved", "chronology", "into", "its", "own", "folder"], "add_tokens": "var tokenizer = require ( '../whitespace_tokenizer' ) ; text = text . replace ( / ['\"\\.,] / , '' ) ; text = text . replace ( / \\-(\\d{4})\\b / , ' tzminus\\1' ) ;", "del_tokens": "var tokenizer = require ( './whitespace_tokenizer' ) ; //text = text.replace(/[\\'\\\"\\.,]/, ''); //text = text.replace(/ \\-(\\d{4})\\b/, ' tzminus\\1');", "commit_type": "move"}
{"commit_tokens": ["added", "t", "-", "content", "fixed", "README", ".", "md", "formatting"], "add_tokens": "if ( result !== target ) target . parentElement . replaceChild ( result , target ) ; \"t-content\" : ( value , scope , actions , render , { raw , resolved , element } = { } ) => { console . log ( raw , element ) ; element = element . cloneNode ( element , true ) ; element . removeAttribute ( \"t-content\" ) ; element . innerHTML = tlx . escape ( value ) ; return element ; } ,", "del_tokens": "if ( result !== target ) target . parentElement . replaceNode ( result , target ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "update", "listener", "on", "unmount", "also"], "add_tokens": "Riot . js Elmoed Adaptor - Tested with riot v 3.4 .3", "del_tokens": "Riot . js Elmoed Adaptor", "commit_type": "remove"}
{"commit_tokens": ["update", "msearch", "query", "architecture", "implementaion"], "add_tokens": "if ( boolQuery && query . length ) { } else { query = boolQuery ; if ( boolQuery && query . length ) { } else { query = boolQuery ; if ( boolQuery && query . length ) { } else { query = boolQuery ; if ( Array . isArray ( query ) && query . length ) { if ( query && Object . keys ( query ) . length ) { return query ; }", "del_tokens": "if ( boolQuery ) { if ( boolQuery ) { if ( boolQuery ) { if ( query && query . length ) {", "commit_type": "update"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "was", "causing", "only", "the", "first", "table", "to", "be", "persisted", ".", "Clarified", "the", "text", "of", "one", "of", "the", "errors", "thrown", ".", "Added", "a", "Clear", "button", "to", "the", "persistence1", "example", "script", "."], "add_tokens": "if ( words . shift ( ) . toUpperCase ( ) !== \"INTO\" ) throw \"Unintelligible query. Expected 'INTO'\" ; var rows = [ ] ; self . api . delete ( \"jSQL_data_schema\" , function ( ) { self . api . insert ( \"jSQL_data_schema\" , rows , callback ) ; } ) ;", "del_tokens": "if ( words . shift ( ) . toUpperCase ( ) !== \"INTO\" ) throw \"Unintelligible query. Expected 'TABLE'\" ; var rows = [ ] ; self . api . delete ( \"jSQL_data_schema\" , function ( ) { self . api . insert ( \"jSQL_data_schema\" , rows , callback ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "remote", "onto", "the", "fetch", "."], "add_tokens": "execWrap ( 'git fetch ' + remoteName ) ;", "del_tokens": "execWrap ( 'git fetch' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "in", "cancelAll", "uploadHandler", "method"], "add_tokens": "maxConnections : 999 , this . _cancel ( this . _queue [ i ] ) ; this . _options . onCancel ( id , this . getName ( id ) ) ;", "del_tokens": "maxConnections : 0 , this . _cancel ( id ) ; this . _options . onCancel ( id , this . getName ( id ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "hook", "for", "after", "table", "render", "."], "add_tokens": "function onAfterTableComplete ( ) { console . log ( 'Table render complete.' ) ; } mode : \"checkbox\" , sortOrder : \"desc\" , //default sort order afterTableComplete : onAfterTableComplete // A hook for after table render complete.", "del_tokens": "mode : \"radio\" , sortOrder : \"desc\" //default sort order", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "missing", "commit", "message", "."], "add_tokens": "var gh = this . gh , error ; if ( ! message ) { error = new Error ( 'Commit must have a message.' ) ; error . code = 400 ; return callback ( error ) ; }", "del_tokens": "var gh = this . gh ;", "commit_type": "add"}
{"commit_tokens": ["change", "blue", "color", "to", "green", "."], "add_tokens": "var command = chalk . green", "del_tokens": "var command = chalk . blue", "commit_type": "change"}
{"commit_tokens": ["Added", "helper", "module", "to", "enhance", "a", "web", "pack", "config", "with", "any", "needed", "loaders"], "add_tokens": "var webpackSettings = require ( '../../webpack-helper' ) ; module . exports = webpackSettings ( { filename : './js/app.min.js' 'tungstenjs/adaptors/backbone' : path . join ( __dirname , '../../adaptors/backbone' ) , 'tungstenjs' : '../../src' modulesDirectories : [ 'node_modules' ] } ) ;", "del_tokens": "module . exports = { filename : './js/app.min.js' , path : path . resolve ( './js' ) 'tungstenjs/adaptors/backbone' : path . join ( __dirname , '../../adaptors/backbone' ) , 'tungstenjs' : '../../src' modulesDirectories : [ 'node_modules' , path . join ( __dirname , '../../node_modules/' ) , path . join ( __dirname , '../../precompile' ) ] } , module : { loaders : [ { test : / \\.mustache$ / , loader : 'tungsten_template' } , { test : / \\.json$ / , loader : 'json-loader' } ] } ;", "commit_type": "add"}
{"commit_tokens": ["adds", "function", "to", "delete", "stacks"], "add_tokens": "region : options . region || 'us-east-1' region : options . region || 'us-east-1' config . deleteStack = function ( options , callback ) { // `options` object should include // - region: Defaults to 'us-east-1'. The AWS region to deploy into // - name: Required. Name of the Cloudformation stack var cfn = new AWS . CloudFormation ( _ ( env ) . extend ( { region : options . region || 'us-east-1' } ) ) ; cfn . deleteStack ( { StackName : options . name } , callback ) ; } ;", "del_tokens": "region : options . region region : options . region", "commit_type": "add"}
{"commit_tokens": ["Added", "alpha", "to", "Graphics", "component"], "add_tokens": "if ( _ . isUndefined ( params . alpha ) ) { params . alpha = 1 ; } this . alpha = params . alpha ; // Set and proxy alpha. graphics [ entity . uid ] . alpha = entity . c . graphic . alpha ; proxy ( entity . c . graphic , 'alpha' , graphics [ entity . uid ] , 'alpha' ) ; console . log ( graphics [ entity . uid ] ) ;", "del_tokens": "//console.log(graphics[entity.uid]);", "commit_type": "add"}
{"commit_tokens": ["Changed", "stringify", "function", "for", "statecharts"], "add_tokens": "proto . stringify = function ( ) { return \"\" + this . id + ( this . _event . type === \"red_event\" ? \",\" + this . _event . id : \"\" ) ; } ; cloned_event = event . clone ( parent , context , state_map . get ( event . statechart ) ) ; cloned_event = event . clone ( parent , context , this ) ; return event . type + \" -(\" + transition . stringify ( ) + \")-> \" + to ;", "del_tokens": "cloned_event = event . clone ( state_map . get ( event . statechart ) ) ; cloned_event = event . clone ( this ) ; return event . type + \" -(\" + transition . id + \")-> \" + to ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "problem", "with", "paths", "and", "white", "spaces", "or", "special", "chars"], "add_tokens": "lookingFor = decodeURIComponent ( client . pathname ) ,", "del_tokens": "lookingFor = client . pathname ,", "commit_type": "fix"}
{"commit_tokens": ["added", "gen", "test", "specs", "and", "compliance", "with", "spec", "tests"], "add_tokens": "var MultiStream = require ( '../../src/' ) } ) . listen ( 8010 ) var socket = tcp . connect ( { port : 8010 } , connected )", "del_tokens": "var MultiStream = require ( '../src/' ) } ) . listen ( 8124 ) var socket = tcp . connect ( { port : 8124 } , connected )", "commit_type": "add"}
{"commit_tokens": ["Remove", "use", "of", "undefined", "variable", "."], "add_tokens": "if ( win ) {", "del_tokens": "if ( win && ! hasSln ) {", "commit_type": "remove"}
{"commit_tokens": ["Use", "node", "-", "serializer", "instead", "of", "nodetk", "/", "serializer", "."], "add_tokens": ", serializer = require ( 'serializer' ) CLIENT . serializer = serializer . createSecureSerializer ( cconf . crypt_key , cconf . sign_key ) ;", "del_tokens": ", SecureSerializer = require ( 'nodetk/serializer' ) . SecureSerializer , querystring = require ( 'querystring' ) CLIENT . serializer = new SecureSerializer ( cconf . crypt_key , cconf . sign_key ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "tests", "to", "cover", "error", "responses"], "add_tokens": "} ) ; describe ( 'errors' , function ( ) { it ( 'GET /models/doesnt/exist should return a 404 error' , function ( done ) { request ( app ) . get ( '/posts/doesnt/exist' ) . expect ( 404 ) . end ( done ) ; } ) ; } ) ;", "del_tokens": "} )", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "to", "new", "forms", "and", "new", "router", "3"], "add_tokens": "'@angular/forms' ,", "del_tokens": "'@angular/router-deprecated' ,", "commit_type": "upgrade"}
{"commit_tokens": ["fix", "bug", "with", "extraneous", "lines"], "add_tokens": "let res = await this . _exec ( thread ? ` ${ thread } ${ cmd } ` : cmd , 'cli' ) return thread ? res . split ( '\\n' ) . slice ( 2 ) . join ( '\\n' ) : res", "del_tokens": "return await this . _exec ( thread ? ` ${ thread } ${ cmd } ` : cmd , 'cli' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "emtpy", "texture", "usage", "to", "AnimatedParticle", "."], "add_tokens": "this . texture = this . textures [ frame ] || ParticleUtils . EMPTY_TEXTURE ; this . setTexture ( this . textures [ frame ] || ParticleUtils . EMPTY_TEXTURE ) ;", "del_tokens": "this . texture = this . textures [ frame ] ; this . setTexture ( this . textures [ frame ] ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "build", "watcher", "code", "to", "another", "internal", "module"], "add_tokens": "const watchBuildLog = require ( './build-watcher' ) ;", "del_tokens": "const request = require ( 'request' ) ; const chalk = require ( 'chalk' ) ; // https://192.168.99.100:8443/api/v1/namespaces/node-demo-1/pods/wfswarm-rest-http-s2i-5-build/log?pretty=false&follow=true'; // Probably do this somewhere else eventually function watchBuildLog ( config , build ) { return new Promise ( ( resolve , reject ) => { const req = { url : ` ${ config . openshiftRestClient . kubeUrl } ${ config . context . namespace } ${ build } ` , auth : { bearer : config . user . token } , strictSSL : false // just for testing since self-signed cert } ; request . get ( req ) . on ( 'data' , ( chunk ) => { console . log ( chalk . blue ( chunk . toString ( 'utf8' ) ) ) ; } ) . on ( 'end' , ( ) => { return resolve ( ) ; } ) . on ( 'error' , ( err ) => { return reject ( err ) ; } ) ; } ) ; }", "commit_type": "move"}
{"commit_tokens": ["add", "err", "log", "in", "test"], "add_tokens": "test ( 'add node illegal cons error: (propLabelAi)' , function ( ) { test ( 'add node illegal cons error msg: (propLabelAi)' , function ( ) { ( function ( ) { KB . add ( A . propLabelAi ) } ) . should . throw ( / Node constraints violated: The empty field, undefined, cannot be used as hash as demanded by 'hash_by' / ) } )", "del_tokens": "test ( 'add node illegal cons error: (propLabelA)' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "fast", "-", "or", "-", "slow", "test", "framework"], "add_tokens": "root : root , lib : root + '/lib' , fixture : root + '/test/fixture' , tmp : root + '/test/tmp' , exports . assert = require ( 'assert' ) ;", "del_tokens": "root : root , lib : root + '/lib' , fixture : root + '/test/fixture' , tmp : root + '/test/tmp' , exports . fastOrSlow = require ( 'fast-or-slow' ) ; exports . assert = require ( 'assert' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "on", "-", "load", "and", "define", "an", "element", "identifier"], "add_tokens": "} , belCreateElement . caller . caller . caller )", "del_tokens": "} )", "commit_type": "update"}
{"commit_tokens": ["fixed", "buggy", "expression", "missing", "escapes", "in", ":", "target", "pseudo", "class", "resolver", "(", "jddalton", ")"], "add_tokens": "source = 'if(e.id==location.href.match(/#((?:[-_\\\\w]|\\\\\\\\.)+)$/)[1]){' + source + '}' ;", "del_tokens": "source = 'if(e.id==location.href.match(/#((?:[-_\\w]|\\\\.)+)$/)[1]){' + source + '}' ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "print", "-", "schema", "script"], "add_tokens": "import { parseSchemaIntoAST } from '../../../language/schema/' ; import { buildASTSchema , introspectionQuery } from '../../../utilities/' ; import { graphql } from '../../../' ; var ast = parseSchemaIntoAST ( body ) ; var astSchema = buildASTSchema ( ast , argDict . query , argDict . mutation ) ; var result = await graphql ( astSchema , introspectionQuery ) ; -- query < queryType > : The query type ( root type ) of the schema . Optional : -- mutation < mutationType > : The mutation type ( root type ) of the schema . ` ;", "del_tokens": "import { getIntrospectionResult } from '../../../language/schema/printer' ; var result = await getIntrospectionResult ( body , argDict . query ) ; -- query < queryType > : The query type ( root type ) of the schema . ` ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "position", "for", "list", "elements", "changes"], "add_tokens": "function setElement ( placeholder , keep , parent , data , beforeEl ) { } else if ( parent !== undefined && beforeEl !== undefined ) { params . parent . insertBefore ( el , beforeEl ) ; } else if ( parent ) { run : function ( fragment , keep , parent , data , beforeEl ) { return setElement . call ( self , placeholder , keep , parent , obj , beforeEl ) ;", "del_tokens": "function setElement ( placeholder , keep , parent , data , index ) { } else if ( parent ) { params . parent . appendChild ( el ) ; } else if ( parent && index !== undefined ) { params . parent . insertBefore ( el , params . parent . childNodes [ index ] ) ; run : function ( fragment , keep , parent , data , index ) { return setElement . call ( self , placeholder , keep , parent , obj , index ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "globals", "mocking", "to", "test", "."], "add_tokens": "globals : mocks ? mocks . globals : { } globals : { Date : function ( ) { return new Date ( 2001 , 0 , 1 ) ; } } } ;", "del_tokens": "globals : { Date : function ( ) { return mocks . text_date ; } } text_date : new Date ( 2001 , 0 , 1 ) }", "commit_type": "move"}
{"commit_tokens": ["Added", "ignoreInitial", "flag", "to", "watcher", "so", "it", "doesn", "t", "re", "-", "scan", "the", "packages", "a", "bunch", "of", "times", "on", "launch"], "add_tokens": "var watcher = chokidar . watch ( 'packages/' , { ignored : / [\\/\\\\]\\. / , persistent : true , ignoreInitial : true } ) ; pkgs = parsePackages ( ) ;", "del_tokens": "var watcher = chokidar . watch ( 'packages/' , { ignored : / [\\/\\\\]\\. / , persistent : true } ) ; // The current implementation runs way too often and will be very heavy once people start having dozens of pkgs pkgs = readPackageManifests ( ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "config", "option", "to", "deep", "watch", "data"], "add_tokens": "* AngularJS - nvD3 , v0 .1 .0 ; MIT License ; 01 / 26 / 2015 11 : 50 var defaultConfig = { extended : false , visible : true , disabled : false , autorefresh : true , refreshDataOnly : false , deepWatchData : true } ; } , scope . _config . deepWatchData ) ;", "del_tokens": "* AngularJS - nvD3 , v0 .1 .0 ; MIT License ; 10 / 06 / 2014 17 : 12 var defaultConfig = { extended : false , visible : true , disabled : false , autorefresh : true , refreshDataOnly : false } ; } , true ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "options", "to", "Session", "constructor"], "add_tokens": "bindPort : 0 , self . socket . on ( 'message' , self . options . msgReceived || msgReceived . bind ( self ) ) ; port : self . options . bindPort , // unless otherwise specified, get a random port automatically", "del_tokens": "self . socket . on ( 'message' , msgReceived . bind ( self ) ) ; port : 0 , //get a random port automatically", "commit_type": "add"}
{"commit_tokens": ["add", "MYSQL", "support", "+", "tests"], "add_tokens": "'sqlite3' : [ __dirname + '/base/*.js' , __dirname + '/stores/sql/**/*.js' , __dirname + '/stores/sqlite3/*.js' ] , 'mysql' : [ __dirname + '/base/*.js' , __dirname + '/stores/sql/**/*.js' , __dirname + '/stores/mysql/*.js' ]", "del_tokens": "'sqlite3' : [ __dirname + '/base/*.js' , __dirname + '/stores/sql/**/*.js' , __dirname + '/stores/sqlite3/*.js' ]", "commit_type": "add"}
{"commit_tokens": ["add", "implementation", "of", "String", "syntax", "node"], "add_tokens": "case 'String' : if ( ! node || node . data . type !== 'String' ) { break mismatch ; } result . push ( node . data ) ; node = node . next ; break ;", "del_tokens": "default : throw new Error ( 'Not implemented yet combinator: `' + syntaxNode . combinator + '`' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "nested", "folders", "in", "templates", "folder", "was", "not", "processed"], "add_tokens": "scanFolder ( filePath , files ) ;", "del_tokens": "scanFolder ( name , files ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "same", "nodeResolve", "options", "as", "other", "components"], "add_tokens": "nodeResolve ( { jsnext : true , module : true , main : false } )", "del_tokens": "nodeResolve ( { jsnext : true } )", "commit_type": "use"}
{"commit_tokens": ["Changing", "to", "prop", "-", "types", "package", "not", "from", "React", "to", "prevent", "errors"], "add_tokens": "import T from 'prop-types' ; import React from 'react' ;", "del_tokens": "import React , { PropTypes as T } from 'react'", "commit_type": "change"}
{"commit_tokens": ["Add", "div_safe", "to", "try", "to", "avoid", "numerical", "errors", "when", "dividing"], "add_tokens": "var q = div_safe ( this . base_scalar , target . base_scalar ) ; function div_safe ( a , b ) { return mul_safe ( a , 1 / b ) ; } Qty . div_safe = div_safe ;", "del_tokens": "var q = this . base_scalar / target . base_scalar ;", "commit_type": "add"}
{"commit_tokens": ["Removes", "some", "deprecated", "code", "&", "update", "specs", "accordingly", "."], "add_tokens": "from . patch ( to ) ;", "del_tokens": "patch . node ( from , to ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "autoscaling", ";", "refactor", "mockApp"], "add_tokens": "timeout : 5 * 1000 ,", "del_tokens": "timeout : 5000 ,", "commit_type": "add"}
{"commit_tokens": ["changed", "keyup", "event", "to", "use", "live"], "add_tokens": "cli . live ( 'keyup' , function ( e ) {", "del_tokens": "cli . keyup ( function ( e ) {", "commit_type": "change"}
{"commit_tokens": ["Moved", "TODO", "to", "a", "separate", "folder"], "add_tokens": "render ( new Worker ( '/dist/dbmonster/worker-impl.js#rows=' + ENV . rows + '&timeout=' + ENV . timeout ) , document . getElementById ( 'topLevelContainer-' + i ) ) ;", "del_tokens": "render ( new Worker ( '/dist/worker-impl.js#rows=' + ENV . rows + '&timeout=' + ENV . timeout ) , document . getElementById ( 'topLevelContainer-' + i ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "track24", "to", "support", "full", "proxy", "url"], "add_tokens": "const URL = 'https://track24.net/ajax/tracking100500.ajax.php' * @ param callback ( Error , Track24TrackerInfo ) exportModule . getInfoProxy = function ( id , proxyUrl , callback ) { obtainInfo ( proxyUrl , id , callback ) timeout : 20000 , maxAttempts : 1 ,", "del_tokens": "const URL = 'https://track24.net/ajax/tracking2.ajax.php' const URL_PROXY = '/ajax/tracking2.ajax.php' * @ param callback ( Error , DHLTrackerInfo ) exportModule . getInfoProxy = function ( id , proxy , callback ) { obtainInfo ( proxy + URL_PROXY , id , callback ) timeout : 30000", "commit_type": "change"}
{"commit_tokens": ["Added", "entity", "detach", "/", "attach", "support"], "add_tokens": "apply ( componentNames , callback ) { // Check if index group has any of the components that the entity has let hasAny = componentNames . some ( name => group . components . has ( name ) ) // Check if the current index group is supposed to match all entities let isMatchAllGroup = ( ( componentNames == undefined || componentNames . length === 0 ) && group . components . size == 0 ) if ( hasAny || isMatchAllGroup ) { add ( entity , ... componentNames ) { this . apply ( componentNames , ( entities ) => { remove ( entity , ... componentNames ) { this . apply ( componentNames , ( entities ) => { // Add an entity and all of its components to the index addEntity ( entity ) { this . add ( entity , ... Object . keys ( entity . data ) ) } // Remove an entity and all of its components from the index removeEntity ( entity ) { this . remove ( entity , ... Object . keys ( entity . data ) ) }", "del_tokens": "apply ( componentName , callback ) { if ( group . components . has ( componentName ) || ( componentName == undefined && group . components . size == 0 ) ) { add ( entity , componentName ) { this . apply ( componentName , ( entities ) => { remove ( entity , componentName ) { this . apply ( componentName , ( entities ) => {", "commit_type": "add"}
{"commit_tokens": ["Add", "--", "skipGoodbye", "to", "suppress", "closing", "output", "."], "add_tokens": "if ( ! options [ 'skipGoodbye' ] ) { this . log ( '\\nGadget has ' + chalk . red ( 'finished' ) + ' setting up the Drupal project scaffold with Grunt Drupal Tasks!\\n' ) ; this . log ( 'Run `' + chalk . red ( 'grunt' ) + '` to start the first build of this project.\\n' ) ; }", "del_tokens": "this . log ( '\\nGadget has ' + chalk . red ( 'finished' ) + ' setting up the Drupal project scaffold with Grunt Drupal Tasks!\\n' ) ; this . log ( 'Run `' + chalk . red ( 'grunt' ) + '` to run the first build of this project.\\n' ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "structure", "of", "example", "project"], "add_tokens": "const IsomorphicPlugin = require ( '../../plugin' ) ;", "del_tokens": "const IsomorphicPlugin = require ( '../plugin' ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "initialization", "with", "typed", "arrays"], "add_tokens": "indexed = ndarray ( pool . malloc ( n * ( d + 1 ) , type ) , [ n , d + 1 ] ) }", "del_tokens": "indexed = ndarray ( pool . malloc ( n * ( d + 1 ) ) , [ n , d + 1 ] ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "spec", "startTime", "&", "duration"], "add_tokens": "this . specs [ payload . specId ] = Object . assign ( { suites : { } } , payload ) spec . suites [ payload . suiteId ] = Object . assign ( { tests : [ ] } , payload ) specEnd ( payload ) { const spec = this . specs [ payload . specId ] spec . duration = payload . duration spec . failures = payload . failures }", "del_tokens": "this . specs [ payload . specId ] = payload spec . suites = spec . suites || { } spec . suites [ payload . suiteId ] = Object . assign ( { tests : [ ] } , payload )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "notice", "if", "no", "manifest", "is", "found"], "add_tokens": "task : ( task ) => { if ( ! manifest ) { task . title = 'No front-end detected (no manifest.json)' } else if ( ! manifest . start_url ) { task . title = 'No front-end detected (no start_url defined)' }", "del_tokens": "task : ( ) => {", "commit_type": "add"}
{"commit_tokens": ["Use", "correct", "button", "text", "option"], "add_tokens": "var button , _ref3 , _ref4 , _ref5 , _ref6 , _ref7 , _ref8 , _ref9 ; } else if ( ( ( _ref8 = window . localStorage ) != null ? _ref8 . eagerShepherdHasRun : void 0 ) !== 'true' ) { localStorage . eagerShepherdHasRun = 'true' ; button . appendChild ( document . createTextNode ( options . buttonText ) ) ; if ( ( ( _ref9 = options . buttonLocation ) != null ? _ref9 . appendChild : void 0 ) != null ) {", "del_tokens": "var button , _ref10 , _ref3 , _ref4 , _ref5 , _ref6 , _ref7 , _ref8 , _ref9 ; } else if ( ( _ref8 = ( _ref9 = window . localStorage ) != null ? _ref9 . eagerShepherdHasRun : void 0 ) !== 'true' && _ref8 !== true ) { localStorage . eagerShepherdHasRun = true ; button . appendChild ( document . createTextNode ( buttonText ) ) ; if ( ( ( _ref10 = options . buttonLocation ) != null ? _ref10 . appendChild : void 0 ) != null ) {", "commit_type": "use"}
{"commit_tokens": ["moved", "next", "prototype", "preparing", "to", "the", "end"], "add_tokens": "// Prepare next prototype in the chain prepareLogic ( proto ) ;", "del_tokens": "// Prepare next prototype in the chain prepareLogic ( proto ) ;", "commit_type": "move"}
{"commit_tokens": ["Implemented", "a", "simple", "web", "server"], "add_tokens": "var argv = require ( \"commander\" ) . option ( \"-p, --port <n>\" , \"port to use\" , parseInt ) . parse ( process . argv ) ; PORT = 80 ; // Default port. if ( argv . port ) { PORT = argv . port ; } // Run the server! var Server = new ( require ( \"./lib/server.js\" ) ) ( ) . listen ( PORT ) ;", "del_tokens": "console . log ( \"Hello, world.\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "build", "scripts", "and", "templates", "for", "docs", "."], "add_tokens": "this . classList . add ( 'mdl-layout__header' ) ;", "del_tokens": "this . classList . add ( 'mdl-layout__layout__header' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "default", "values", "for", "normal", "options"], "add_tokens": "entityTableName : _ . snakeCase ( jdlObject . entities [ entityNames [ i ] ] . tableName ) , dto : 'no' , pagination : 'no' , service : 'no'", "del_tokens": "entityTableName : _ . snakeCase ( jdlObject . entities [ entityNames [ i ] ] . tableName )", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "output", "option", "to", "output", "CSS", "file", "from", "the", "command", "line"], "add_tokens": "} , output : '' if ( typeof options . output === 'string' && options . output . length > 0 ) { try { fs . writeFileSync ( options . output , '' , 'utf8' ) ; } catch ( err ) { options . output = '' ; console . error ( err ) ; } } if ( typeof options . output === 'string' && options . output . length > 0 ) { try { fs . appendFileSync ( options . output , data , 'utf8' ) ; } catch ( err ) { console . error ( err ) ; } done ( ) ; return ; } } else { that . push ( null ) ;", "del_tokens": "} that . push ( null ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "arrayProperties", "to", "arrayType", "for", "consistency", "."], "add_tokens": "// index: [Type] or index: [] is translated to index: {type: Array, arrayType: Type} properties . arrayType = properties . type [ 0 ] ; // index: {} or index: SchemaObject is translated to index: {type: Object, objectType: Type} this . _properties = properties . arrayType ; delete this . _properties . arrayType ; obj [ objIndex ] = properties . arrayType ? new SchemaArray ( self , properties ) : [ ] ;", "del_tokens": "// index: [Properties] or index: [] is translated to index: {type: Array, arrayProperties: Properties} properties . arrayProperties = properties . type [ 0 ] ; // index: {} or index: {schema: Type} or index: SchemaObject is translated to index: {type: Object, objectType: Type} this . _properties = properties . arrayProperties ; delete this . _properties . arrayProperties ; obj [ objIndex ] = properties . arrayProperties ? new SchemaArray ( self , properties ) : [ ] ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "PhantomJS", "support", ":", "add", "http", "scheme", "if", "necessary"], "add_tokens": "DEF_FORMAT = 'png' , URL_PREFIX_HTTP = 'http://' , URL_PREFIX_HTTPS = 'https://' ; function fixUrl ( url ) { var http = url . indexOf ( URL_PREFIX_HTTP ) === 0 , https = url . indexOf ( URL_PREFIX_HTTPS ) === 0 ; return ( http || https ) ? url : ( URL_PREFIX_HTTP + url ) ; } page = createPage ( options ) , url = fixUrl ( options . url ) ; page . open ( url , function ( ) {", "del_tokens": "DEF_FORMAT = 'png' ; page = createPage ( options ) ; page . open ( options . url , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "callback", "to", "be", "passed", "as", "the", "only", "prop", "to", "bind"], "add_tokens": "var normalizeBindOptions = require ( './normalizeBindOptions' ) UdpSocket . prototype . bind = function ( ... args ) { let { port , address , callback } = normalizeBindOptions ( ... args )", "del_tokens": "UdpSocket . prototype . bind = function ( port , address , callback ) { if ( typeof address === 'function' ) { callback = address address = undefined }", "commit_type": "allow"}
{"commit_tokens": ["fix", "broken", "watchPosition", "/", "clearWatch"], "add_tokens": "watchPosition : function ( successCallback , errorCallback , args ) { clearWatch : function ( successCallback , errorCallback , args ) {", "del_tokens": "watchPosition : function ( success , error , args ) { clearWatch : function ( success , error , args ) {", "commit_type": "fix"}
{"commit_tokens": ["Using", "constants", "instead", "of", "magic", "numbers", "."], "add_tokens": "var MAX_HTTP_PAYLOAD_SIZE = 16383 ; var chunk_size = Math . min ( MAX_HTTP_PAYLOAD_SIZE , buffer . length )", "del_tokens": "var chunk_size = Math . min ( 16383 , buffer . length )", "commit_type": "use"}
{"commit_tokens": ["add", "babelify", "to", "test", "build", "process"], "add_tokens": "debug : true , transform : [ [ 'babelify' , { presets : [ 'es2015' ] } ] ]", "del_tokens": "debug : true", "commit_type": "add"}
{"commit_tokens": ["fix", "parallel", "requests", "by", "sourceData"], "add_tokens": "//console.log(cfg);", "del_tokens": "console . log ( cfg ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "p", ".", "catch", "(", "errorhandler", ")", "sugar"], "add_tokens": "/ ** * Terminates chain and catches errors * * Example : Catch error * p = uP ( ) ; * p . then ( function ( ) { throw \"an error occured\" ; } ) * . done ( function ( v ) { * console . log ( \"no error\" , v ) ; * } ) * . catch ( function ( e ) { * console . log ( \"error:\" , e ) ; * } ) ; * p . resolve ( \"hello there\" ) ; * * @ param { Function } onError callback * @ return undefined * @ api public * / uP . prototype . catch = function ( error ) { this . done ( undefined , error ) ; } ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "base", "for", "unit", "tests"], "add_tokens": "if ( name . indexOf ( 'mac' ) >= 0 || name . indexOf ( 'osx' ) >= 0 || name . indexOf ( 'darwin' ) >= 0 ) prefix = platforms . OSX ;", "del_tokens": "if ( name . indexOf ( 'mac' ) >= 0 || name . indexOf ( 'osx' ) >= 0 || name . indexOf ( 'darwin' ) >= 0 ) prefix = platforms . OSX ;", "commit_type": "add"}
{"commit_tokens": ["Add", "files", "-", "property", "to", "package", ".", "json", ".", "Update", "dependencies"], "add_tokens": "var write = require ( 'customize-write-files' ) var path = require ( 'path' ) var httpGet = require ( 'get-promise' ) var Customize = customize . Customize Customize . prototype . build = function ( jsonFile , targetDir ) { } ) generate : function generate ( ) { return withData . run ( ) . then ( write ( targetDir ) ) watch : function ( ) { return withData . watch ( ) . on ( 'update' , write ( targetDir ) ) }", "del_tokens": "var qfs = require ( 'q-io/fs' ) var write = require ( \"customize-write-files\" ) var path = require ( \"path\" ) ; var httpGet = require ( 'get-promise' ) ; var Customize = customize . Customize ; Customize . prototype . build = function ( jsonFile , targetDir ) { } ) ; generate : function generate ( ) { return withData . run ( ) . then ( write ( targetDir ) ) ; watch : function ( ) { return withData . watch ( ) . on ( \"update\" , write ( targetDir ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Make", "logger", "verbosity", "more", "explicitly", "configurable"], "add_tokens": "module . exports = ( function ( ) { var verbose_ = false ; return { setVerbose : function ( v ) { verbose_ = v ; } , log : function ( str ) { if ( verbose_ ) { console . log ( new Date ( ) + ' ' + str ) ; } } } ; } ) ( ) ;", "del_tokens": "module . exports . log = function ( str ) { if ( process . env [ 'CARELINK_VERBOSE' ] ) { console . log ( new Date ( ) + ' ' + str ) ; } } ;", "commit_type": "make"}
{"commit_tokens": ["Move", "405", "501", "and", "OPTIONS", "responses", "into", "router", ".", "allowedMethods", "()", "middleware", "."], "add_tokens": "app . use ( router . allowedMethods ( ) ) ; res . header . should . have . property ( 'allow' , 'HEAD, GET, PUT' ) ; app . use ( router . allowedMethods ( ) ) ; res . header . should . have . property ( 'allow' , 'HEAD, GET, PUT' ) ; app . use ( router . allowedMethods ( ) ) ; . search ( '/users' )", "del_tokens": "res . header . should . have . property ( 'allow' , 'GET, PUT' ) ; res . header . should . have . property ( 'allow' , 'GET, PUT' ) ; . del ( '/users' )", "commit_type": "move"}
{"commit_tokens": ["Add", "failing", "test", ":", "non", "-", "required", "oneOf", "doesn", "t", "type", "check"], "add_tokens": "var props = { bar : 42 } ;", "del_tokens": "foo : React . PropTypes . oneOf ( [ \"foo\" ] ) . isRequired , var props = { foo : \"bar\" , bar : 42 } ;", "commit_type": "add"}
{"commit_tokens": ["Move", "architectural", "definitions", "to", "arch", ".", "js"], "add_tokens": "const { TRITS_PER_TRYTE , TRYTES_PER_WORD , TRITS_PER_WORD , MAX_TRYTE , MIN_TRYTE , MEMORY_SIZE } = require ( './arch' ) ;", "del_tokens": "const TRITS_PER_TRYTE = 5 ; const TRYTES_PER_WORD = 2 ; const TRITS_PER_WORD = TRITS_PER_TRYTE * TRYTES_PER_WORD ; const MAX_TRYTE = + ( 3 ** TRITS_PER_TRYTE - 1 ) / 2 ; const MIN_TRYTE = - ( 3 ** TRITS_PER_TRYTE - 1 ) / 2 ; const MEMORY_SIZE = 3 ** ( TRITS_PER_WORD ) ;", "commit_type": "move"}
{"commit_tokens": ["make", "sure", "default_languages", "is", "in", "languages", "object"], "add_tokens": "// make sure default_language is valid if ( default_language && ! ( default_language in this . get ( 'languages' ) ) ) { default_language = null ; } // \"title\": \"document\", // \"tagline\": \"Create your document site with just one command.\", // // used by current theme // \"theme\": \"navy\",", "del_tokens": "// \"title\": \"DAUX.IO\", // \"tagline\": \"The Easiest Way To Document Your Project\", // X \"docs_path\": \"../cortex/doc\", // X \"theme\": \"navy\",", "commit_type": "make"}
{"commit_tokens": ["Updated", "logger", "fixed", "errors", "jshinted"], "add_tokens": "module . exports = { error : { BadRequestError : require ( './lib/error/badRequestError' ) . BadRequestError , ForbiddenError : require ( './lib/error/forbiddenError' ) . ForbiddenError , InternalError : require ( './lib/error/internalError' ) . InternalError , UnauthorizedError : require ( './lib/error/notAuthorizedError' ) . UnauthorizedError , NotFoundError : require ( './lib/error/notFoundError' ) . NotFoundError , ServiceUnavailableError : require ( './lib/error/serviceUnavailableError' ) . ServiceUnavailableError } , plugin : { oauth : require ( './lib/plugin/authorization/oauth' ) . oauth } , runServer : app . runServer , createServer : app . createServer , VERSION : meta . VERSION } ;", "del_tokens": "var exports = { } ; exports . error = { BadRequestError : require ( './lib/error/badRequestError' ) . BadRequestError , ForbiddenError : require ( './lib/error/forbiddenError' ) . ForbiddenError , InternalError : require ( './lib/error/internalError' ) . InternalError , UnauthorizedError : require ( './lib/error/notAuthorizedError' ) . UnauthorizedError , NotFoundError : require ( './lib/error/notFoundError' ) . NotFoundError , ServiceUnavailableError : require ( './lib/error/serviceUnavailableError' ) . ServiceUnavailableError } ; exports . plugin = { oauth : require ( './lib/plugin/authorization/oauth' ) . oauth } ; exports . runServer = app . runServer ; exports . VERSION = meta . VERSION ; module . exports = exports ;", "commit_type": "update"}
{"commit_tokens": ["add", "done", "callbacks", "to", "integration", "tests", "and", "fix", "uncovered", "error"], "add_tokens": "return Knex . migrate . rollback ( config ) ;", "del_tokens": "return Knex . migrate . rollback ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "where", "sequences", "couldn", "t", "be", "rescheduled", "due", "to", "events", "not", "being", "cleaned", "up", "properly"], "add_tokens": "seq . once ( \"completed\" , function ( ) {", "del_tokens": "seq . on ( \"completed\" , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["allow", "using", "the", "heroku", "client", "with", "no", "auth", "token"], "add_tokens": "token : context . auth ? context . auth . password : null ,", "del_tokens": "if ( ! context . auth || ! context . auth . password ) { return 'set `needsApp: true` on the command' ; } token : context . auth . password ,", "commit_type": "allow"}
{"commit_tokens": ["Added", "interop", "support", "for", "default", "root", "SSL", "certs"], "add_tokens": "function runTest ( address , host_override , test_case , tls , test_ca , done ) { var ca_path ; if ( test_ca ) { ca_path = path . join ( __dirname , '../test/data/ca.pem' ) ; } else { ca_path = process . env . SSL_CERT_FILE ; } argv . test_case , argv . use_tls === 'true' , argv . use_test_ca === 'true' , function ( ) { console . log ( 'OK:' , argv . test_case ) ; } ) ;", "del_tokens": "function runTest ( address , host_override , test_case , tls , done ) { var ca_path = path . join ( __dirname , '../test/data/ca.pem' ) ; argv . test_case , argv . use_tls === 'true' ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "dot", "notation", "for", "WaveFile", "main", "properties"], "add_tokens": "treeshake : false , input : 'index.js' , treeshake : false ,", "del_tokens": "input : 'index.js' ,", "commit_type": "use"}
{"commit_tokens": ["Add", "Marathon", "/", "Mesos", "support"], "add_tokens": "process . env [ 'PORT0' ] = \"3001\" ; delete process . env [ 'PORT0' ] ;", "del_tokens": "process . env [ 'VCAP_APP_PORT' ] = \"3001\" ; delete process . env [ 'VCAP_APP_PORT' ] ;", "commit_type": "add"}
{"commit_tokens": ["Use", "node", "-", "sass", "output", "instead", "of", "traversing", "the", "tree"], "add_tokens": ". option ( '-p, --path <path>' , 'Path to shake relative to the current working directory. Current working directory by default' ) sassShake . shake ( options ) ;", "del_tokens": ". option ( '-p, --path <path>' , 'Path to shake, current working directory by default' ) sassShake ( options ) ;", "commit_type": "use"}
{"commit_tokens": ["Adds", "close", "functionality", "for", "alerts"], "add_tokens": "import close from '../../commons/dialog/close' ; import closest from 'closest' ; } ) ; delegate ( document . body , '.dqpl-close, .dqpl-cancel' , 'click' , ( e ) => { const button = e . delegateTarget ; const modal = closest ( button , '.dqpl-modal, .dqpl-alert' ) ; close ( modal ) ; window . removeEventListener ( 'resize' , onWindowResize ) ; function onWindowResize ( ) { sizer ( document . querySelector ( '.dqpl-dialog-show' ) ) ; }", "del_tokens": "function onWindowResize ( ) { sizer ( document . querySelector ( '.dqpl-dialog-show' ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "issues", "with", "not", "updating", "component", "instances", "when", "the", "parent", "node", "of", "a", "nested", "component", "didn", "t", "change", "."], "add_tokens": "if ( patch$$1 . replace ) { // traverse replaced node // to get nested component nodes. // when not replacing a node, // traversal is done by the dom patcher. foundComponentNodes = getComponentNodes ( patch$$1 . node , false ) ;", "del_tokens": "// faster than outerhtml if ( $node . isEqualNode ( $newNode ) ) { patch . equal = true ; return patches ; } if ( patch$$1 . update ) { // on update only add the parent node. // traversal is done by the dom patcher. foundComponentNodes = getComponentNodes ( patch$$1 . node , false ) ; } else if ( patch$$1 . replace ) { // traverse only if isEqualNode, // otherwise the dom patcher traverses. foundComponentNodes = getComponentNodes ( patch$$1 . node , ! ! patch$$1 . equal ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "updated", "audio", "-", "through"], "add_tokens": "var AudioThrough = require ( 'audio-through' ) ; var moment = time + i / self . outputFormat . sampleRate ;", "del_tokens": "var AudioThrough = require ( '../audio-through' ) ; var moment = time + i / self . sampleRate ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "removeFunctions", "()", "function", "implement", "function", "to", "modify", "parent", "elements"], "add_tokens": "* @ version 0.0 .8 } else if ( typeof object [ i ] === 'object' && object [ i ] !== null ) {", "del_tokens": "* @ version 0.0 .7 } else if ( typeof object [ i ] === 'object' ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "theme", "-", "color", "meta", "tag"], "add_tokens": "var GenerateManifest = require ( './lib/broccoli/generate-manifest-json' ) ; var tags = [ ] ; tags = tags . concat ( require ( './lib/android-link-tags' ) ( this . manifest , config ) ) ; tags = tags . concat ( require ( './lib/android-meta-tags' ) ( this . manifest , config ) ) ; return tags . join ( '\\n' ) ;", "del_tokens": "var GenerateManifest = require ( './lib/broccoli/generate-manifest' ) ; return ` ${ config . rootURL } ` ;", "commit_type": "add"}
{"commit_tokens": ["Move", "conductor", "action", "code", "example", "to", "a", "separate", "file"], "add_tokens": "const code = ` ${ conductor } ${ JSON . stringify ( action . exec . composition ) } ` // invoke conductor on composition", "del_tokens": "const code = ` ${ conductor } ${ JSON . stringify ( action . exec . composition ) } \\n ` // invoke conductor on composition", "commit_type": "move"}
{"commit_tokens": ["removing", "adapter", "type", "as", "identification", "for", "write", "queues", "-", "this", "will", "allow", "multiple", "queues", "of", "the", "same", "type"], "add_tokens": "xit ( 'timer test' , function ( done ) { path : path . join ( __dirname , '../' , 'log/test.out.log' ) , counter = 100 + 1 ,", "del_tokens": "it ( 'timer test' , function ( done ) { path : path . join ( __dirname , '../' , 'log/std.out.log' ) , counter = 100 , console . log ( 'index' , index ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "JS", "module", "to", "accept", "object", "with", "options", "instead", "of", "only", "headers", "."], "add_tokens": "* DEPRECATED ! WILL BE REMOVED EVENTUALLY ! * * If you want to set config - url - use chcp . fetchUpdate ( callback , options ) . * If you want to set auto - download / auto - install preference - do it in config . xml instead of this method . * * @ param { Object } options - additional options , such as \"config-url\" and additional http headers . fetchUpdate : function ( callback , options ) { callNativeMethod ( pluginNativeMethod . FETCH_UPDATE , options , callback ) ;", "del_tokens": "* @ param headers - provide optional headers object . This will be used to configure server request fetchUpdate : function ( callback , headers ) { callNativeMethod ( pluginNativeMethod . FETCH_UPDATE , headers , callback ) ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "Rye", "()", ".", "find"], "add_tokens": "exports . find = function ( selector ) { elements = this . elements . reduce ( function ( elements , element ) { return elements . concat ( qsa ( selector , element ) ) } , [ ] )", "del_tokens": "exports . find = function find ( selector ) { elements = this . elements . map ( function ( ) { return qsa ( selector , this ) } )", "commit_type": "fix"}
{"commit_tokens": ["added", "test", "script", "in", "gruntfile"], "add_tokens": "run : { test : { cmd : 'npm' , args : [ 'test' ] } } grunt . loadNpmTasks ( 'grunt-run' ) ; grunt . registerTask ( \"test\" , [ \"run:test\" ] ) ; grunt . registerTask ( \"origami:concat\" , [ \"concat\" ] ) ; grunt . registerTask ( \"build\" , [ \"concat\" , \"uglify\" , \"test\" ] ) ;", "del_tokens": "grunt . registerTask ( \"pre-build\" , [ \"concat\" ] ) ; grunt . registerTask ( \"build\" , [ \"concat\" , \"uglify\" ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "operation", "property", "to", "each", "req"], "add_tokens": "assert . ok ( stack . length > 1 , ` ${ operation . id } ` )", "del_tokens": "assert . ok ( stack . length > 0 , ` ${ operation . id } ` )", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "to", "allow", "for", "new", "fixture"], "add_tokens": "var css2 = \"test/fixtures/assets/print.css\" ; expect ( cb ) . toHaveBeenCalledWith ( [ css2 , css , scss ] ) ; expect ( cb ) . toHaveBeenCalledWith ( [ file2 , file1 , file3 , css2 , css , scss ] ) ;", "del_tokens": "expect ( cb ) . toHaveBeenCalledWith ( [ css , scss ] ) ; expect ( cb ) . toHaveBeenCalledWith ( [ file2 , file1 , file3 , css , scss ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "module", "to", "instantiate", "a", "new", "captcha", "object", "each", "call", "added", "namespace", "support", "to", "sessions"], "add_tokens": "visualCaptcha = require ( visualCaptchaPath ) ( sessionMock , false , imageOptions ) ; visualCaptcha = require ( visualCaptchaPath ) ( sessionMock , false , false , audioOptions ) ;", "del_tokens": "visualCaptcha = require ( visualCaptchaPath ) ( sessionMock , imageOptions ) ; visualCaptcha = require ( visualCaptchaPath ) ( sessionMock , false , audioOptions ) ;", "commit_type": "update"}
{"commit_tokens": ["Update", "version", "and", "conversion", "space", "to", "tabs"], "add_tokens": "* @ version 1.1 .105 version : '1.1.105'", "del_tokens": "* @ version 1.1 .103 version : '1.1.103'", "commit_type": "update"}
{"commit_tokens": ["updated", "Px", ".", "code", "to", "return", "values", "if", "codes", "are", "unavailable"], "add_tokens": "/ *! px - v0.1.0 - 2012-08-06 if ( ! this . metadata . CODES || ! this . keyword ( 'CODES' ) [ varName ] ) { return this . keyword ( 'VALUES' ) [ varName ] ; } else { return this . keyword ( 'CODES' ) [ varName ] ; } grpIdx = _ . indexOf ( s , '*' ) , codes = this . codes ( grpIdx ) , datacol = this . datacol ( s ) ;", "del_tokens": "/ *! px - v0.1.0 - 2012-08-05 else if ( _ . isRegExp ( v ) ) { return _ . indexOf ( vars , _ . find ( vars , function ( el ) { return el . match ( v ) ; } ) ) ; } return this . keyword ( 'CODES' ) [ varName ] ; grpIdx = _ . indexOf ( s , '*' ) , codes = this . codes ( grpIdx ) , datacol = this . datacol ( s ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "indice", "attribute", "to", "choropleth", "fix", "rendering", "issue"], "add_tokens": "isPickable : false , // this._renderGridLayer(), this . _renderChoroplethLayer ( ) , // this._renderHexagonLayer(), // this._renderScatterplotLayer(), // this._renderArcLayer()", "del_tokens": "isPickable : true , this . _renderGridLayer ( ) , // this._renderChoroplethLayer(), this . _renderHexagonLayer ( ) , this . _renderScatterplotLayer ( ) , this . _renderArcLayer ( )", "commit_type": "add"}
{"commit_tokens": ["Made", "tests", "more", "robust", "."], "add_tokens": "var assert = require ( 'assert' ) ; var format = require ( 'util' ) . format ; this . Given ( '[TEST] testDataRoot path is configured' , function ( done ) { this . Given ( / ^\\[TEST\\] I assert property (.+) equals (.+)$ / , function ( key , value , done ) { var actual = eval ( 'this.' + key ) ; //jshint ignore:line var expected = eval ( 'test = ' + value ) ; //jshint ignore:line assert . deepEqual ( expected , actual ) ; done ( ) ; } ) ; this . Given ( / ^\\[TEST\\] I set (.+) to (.+)$ / , function ( key , value , done ) { var evalString = format ( 'this.%s = %s' , key , value ) ; eval ( evalString ) ; //jshint ignore:line done ( ) ; } ) ; this . Given ( / ^\\[TEST\\] I assert properties (.+) and (.+) are not the same$ / , function ( key1 , key2 , done ) { var value1 = eval ( 'this.' + key1 ) ; //jshint ignore:line var value2 = eval ( 'this.' + key2 ) ; //jshint ignore:line assert . notDeepEqual ( value1 , value2 ) ; done ( ) ; } ) ;", "del_tokens": "this . Given ( 'testDataRoot path is configured' , function ( done ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "doamain", ":", "~notdomain"], "add_tokens": "let shouldSkipDomainCheck = domains . some ( ( domain ) => domain [ 0 ] === '~' && ! isThirdPartyHost ( domain . substring ( 1 ) , contextParams . domain ) ) ; if ( shouldSkipDomainCheck || domains . every ( ( domain ) => isThirdPartyHost ( domain , contextParams . domain ) ) ) {", "del_tokens": "if ( domains . every ( ( domain ) => isThirdPartyHost ( domain , contextParams . domain ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "handling", "of", "empty", "files"], "add_tokens": "if ( fs . existsSync ( file ) ) { var buf = fs . readFileSync ( file ) return ( buf || '' ) . toString ( ) . trim ( ) }", "del_tokens": "if ( fs . existsSync ( file ) ) return fs . readFileSync ( file )", "commit_type": "fix"}
{"commit_tokens": ["Added", "template", "configuration", "(", "and", "predefined", "templates", ")"], "add_tokens": "$breadcrumbProvider . setOptions ( { prefixStateName : 'home' , template : 'bootstrap2' } ) ;", "del_tokens": "$breadcrumbProvider . setPrefixState ( 'home' ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "wrong", "require", "in", "integration", "test", "preparations"], "add_tokens": "const shell = require ( 'shelljs' ) ;", "del_tokens": "const shell = require ( 'shelljs/global' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "module", "resolution", "for", "nested", "modules"], "add_tokens": "var nmPath = this . nodeModulesPath ; var pkg = relative ( dep . moduleName + '/package.json' , nmPath ) ; var depFolder = path . dirname ( relative . resolve ( dep . moduleName + '/package.json' , nmPath ) ) ;", "del_tokens": "var pkg = require ( dep . moduleName + '/package.json' ) ; var depFolder = path . dirname ( require . resolve ( dep . moduleName + '/package.json' ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "gl", "-", "object", "-", "copy", ".", "js"], "add_tokens": "//so it can be added to our array of grocery lists and will work fine. //i separate it - because it's a better approach and it can be easily tested \"name\" : \"19 Gluten-Free Foods Shopping List\" , //later coma will be important. keep it in mind.", "del_tokens": "so it can be added to our array of grocery lists and will work fine . i separate it - because it ' \"name\" : \"\" , later coma will be important . keep it in mind .", "commit_type": "update"}
{"commit_tokens": ["updated", "plugin", "to", "start", "generating", "the", "bgs", "files", ".", "need", "to", "flesh", "out", "with", "state", "code", "and", "state", "transition", "code", "."], "add_tokens": "config . core . enableCustomConstraints = true ; config . plugin . allowServerExecution = true ; 'hfsm' : './src/common/' , 'CodeEditor' : 'panels/CodeEditor/CodeEditorPanel' , 'panels' : './src/visualizers/panels' , 'widgets' : './src/visualizers/widgets' , 'panels/CodeEditor' : './node_modules/webgme-codeeditor/src/visualizers/panels/CodeEditor' , 'widgets/CodeEditor' : './node_modules/webgme-codeeditor/src/visualizers/widgets/CodeEditor'", "del_tokens": "'CodeEditor' : 'panels/CodeEditor/CodeEditorPanel' , 'panels' : './src/visualizers/panels' , 'widgets' : './src/visualizers/widgets' , 'panels/CodeEditor' : './node_modules/webgme-codeeditor/src/visualizers/panels/CodeEditor' , 'widgets/CodeEditor' : './node_modules/webgme-codeeditor/src/visualizers/widgets/CodeEditor'", "commit_type": "update"}
{"commit_tokens": ["make", "tests", "match", "new", "migration", "rules", "add", "missing", "types"], "add_tokens": "await runMigrations ( manifest , 41 , root ) ; test ( \"v42 is not run against 42+\" , async t => { t . plan ( 2 ) ; const root = new Root ( ) ; t . equal ( root . get ( \"name\" ) , \"jacob\" , \"pre-migration name is jacob\" ) ; await runMigrations ( manifest , 42 , root ) ; t . equal ( root . get ( \"name\" ) , \"jacob\" , \"post-migration name is jacob\" ) ; } ) ;", "del_tokens": "await runMigrations ( manifest , 42 , root ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "stack", "overflow", "with", "cyclic", "dependency"], "add_tokens": "var packageJson = packages [ packageJsonPath ] if ( packageJson ) { return packageJson if ( ! fs . existsSync ( basePath ) ) { packages [ packageJsonPath ] = null return } packageJson = packages [ packageJsonPath ] = JSON . parse ( fs . readFileSync ( packageJsonPath ) )", "del_tokens": "var packageJson = packages [ packageJsonPath ] if ( ! packageJson ) { if ( ! fs . existsSync ( basePath ) ) { packages [ packageJsonPath ] = null return } packageJson = packages [ packageJsonPath ] = JSON . parse ( fs . readFileSync ( packageJsonPath ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "Ruben", "s", "text", "selection", "mode"], "add_tokens": "ace . Editor . prototype . resize = function ( ) { this . renderer . scrollToY ( this . renderer . getScrollTop ( ) ) ; \"selection\" , \"text\" ) ;", "del_tokens": "ace . Editor . prototype . resize = function ( ) { \"selection\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "links", "to", "project", "page", "."], "add_tokens": "* @ link http : //stevenbenner.github.com/jquery-powertip/ * < http : //stevenbenner.github.com/jquery-powertip/>", "del_tokens": "* @ link https : //github.com/stevenbenner/jquery-powertip * < https : //github.com/stevenbenner/jquery-powertip>", "commit_type": "change"}
{"commit_tokens": ["Add", "option", "to", "include", "in", "frontmatter"], "add_tokens": "const publication = options . publication || matter . attributes . publication", "del_tokens": "const publication = options . publication", "commit_type": "add"}
{"commit_tokens": ["moving", "example", "to", "examples", "folder", "and", "renaming", "to", "deeply", "-", "nested"], "add_tokens": "var tree = require ( '../' ) ;", "del_tokens": "var tree = require ( './' ) ;", "commit_type": "move"}
{"commit_tokens": ["Removed", "necessity", "of", "encoding", "conversion"], "add_tokens": "const stripBom = require ( 'strip-bom' ) ; const text = stripBom ( fs . readFileSync ( path . join ( txt_dir , file ) , { encoding : 'utf16le' } ) ) ;", "del_tokens": "const text = fs . readFileSync ( path . join ( txt_dir , file ) , { encoding : 'utf8' } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "to", "standard", ".", "js"], "add_tokens": "] ] ] ] ] ] ] ]", "del_tokens": "] ; ] ; ] ; ] ; ] ; ] ; ] ; ] ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "command", "section", "handling", "."], "add_tokens": "return this . cmd . sections ( ) && this . cmd . sections ( ) [ key ] ? this . cmd . sections ( ) [ key ] : null ; //var sections = Object.keys(this.cmd.sections()); //if(~sections.indexOf(key)) { //return true;", "del_tokens": "return this . cmd . sections && this . cmd . sections [ key ] ? this . cmd . sections [ key ] : null ; //if(process.env.CLI_TOOLKIT_HELP2MAN) return true; var conf = this . cli . configure ( ) ; //if(conf.help && conf.help.sections && conf.help.sections[key] === false) { //return false; var sections = Object . keys ( this . cmd . sections ( ) ) ; if ( ~ sections . indexOf ( key ) ) { return true ; }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "argument", "of", "_run", "from", "up", ":", "boolean", "to", "method", ":", "enum", "{", "up", "down", "}"], "add_tokens": "return this . _run ( 'up' , options , this . pending . bind ( this ) ) ; return this . _run ( 'down' , options , getExecuted . bind ( this ) ) ; _run : function ( method , options , rest ) { return this . _run ( method , [ options ] ) ; return method === 'up' ? return this . _run ( method , { migrations : options } ) ; method : method return method === 'up' ? return this . _run ( method , { migrations : migrationFiles } ) ;", "del_tokens": "return this . _run ( true , options , this . pending . bind ( this ) ) ; return this . _run ( false , options , getExecuted . bind ( this ) ) ; _run : function ( up , options , rest ) { return this . _run ( up , [ options ] ) ; return up ? return this . _run ( up , { migrations : options } ) ; method : up ? 'up' : 'down' return up ? return this . _run ( up , { migrations : migrationFiles } ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "touches", "on", "virtual", "buttons"], "add_tokens": "this . input = new Input ( input , canvas ) ;", "del_tokens": "this . input = new Input ( input ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "from", ".", "bind", "()", "to", ".", "on", "()"], "add_tokens": "jQuery ( selector ) . on ( eventName , handler ) ;", "del_tokens": "jQuery ( selector ) . bind ( eventName , handler ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "safer", "-", "buffer", "in", "place", "of", "Buffer"], "add_tokens": "Buffer = require ( 'safer-buffer' ) . Buffer , stream . push ( Buffer . from ( stream . formatter ( stream . headers , true ) , \"utf8\" ) ) ;", "del_tokens": "stream . push ( new Buffer ( stream . formatter ( stream . headers , true ) , \"utf8\" ) ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "data", "more", "single", "page", "navigation", "friendly"], "add_tokens": "< % if ( stateName . match ( / :state / ) ) { % > params : [ 'initData' ] , < % } else { % > url : '/<%-stateName.replace(/.*:state:/,\"\")%>' , < % } % > controller : function ( $scope , $state , $stateParams , RestService , SocketService ) { if ( $stateParams . initData ) { console . log ( $stateParams ) $scope . data [ 'init' ] = JSON . parse ( $stateParams . initData ) ; } $state . go ( '<%-s.friendly.replace(/\\.state.*/,\"\") %>' + stateName , { initData : JSON . stringify ( initData ) } , { location : true } ) ;", "del_tokens": "url : '/<%-stateName.replace(/.*:state:/,\"\")%>' , controller : function ( $scope , $stateParams , RestService , SocketService ) { $scope . goState ( '<%-s.friendly.replace(/\\.state.*/,\"\") %>' + stateName )", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "large", "defer", "queue", "by", "default"], "add_tokens": "var queue = new Array ( 100 ) ; queue [ i ] = null ; queue [ l ] = fn ; if ( ++ l === 1 ) { nextTick ( flush ) ; }", "del_tokens": "var queue = [ ] ; queue = [ ] ; l = queue . push ( fn ) ; if ( l === 1 ) { nextTick ( flush ) ; }", "commit_type": "use"}
{"commit_tokens": ["Fixed", "text", "binding", "when", "data", "is", "not", "a", "string", "."], "add_tokens": "val = ( val + '' ) . replace ( / & / g , \"&amp;\" ) . replace ( / > / g , \"&gt;\" ) . replace ( / < / g , \"&lt;\" ) ;", "del_tokens": "val = val . replace ( / & / g , \"&amp;\" ) . replace ( / > / g , \"&gt;\" ) . replace ( / < / g , \"&lt;\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["creating", "client", "with", "a", "path"], "add_tokens": "var fs = require ( 'fs' ) ; if ( typeof spore == 'string' ) { // call to readFileSync should be avoid var spec = fs . readFileSync ( spore ) ; spore = JSON . parse ( spec ) ; }", "del_tokens": "", "commit_type": "create"}
{"commit_tokens": ["Added", "special", "escape", "case", "for", ":", "to", "fix", "EC2", "signature", "."], "add_tokens": "return escape ( str ) . replace ( / \\+ / g , '%2B' ) . replace ( / \\/ / g , '%2F' ) . replace ( / %7E / g , '~' ) . replace ( / = / g , '%3D' ) ;", "del_tokens": "return encodeURI ( str ) . replace ( / \\/ / g , '%2F' ) . replace ( / \\+ / g , '%2B' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "iOS", "/", "iPad", "flickering"], "add_tokens": "// this order is important: ios safari sometimes has sync raf requestAnimationFrame ( render )", "del_tokens": "requestAnimationFrame ( render )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "index", "template", "for", "development"], "add_tokens": "// sqlite3: 'server',", "del_tokens": "sqlite3 : 'server' ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "retry", "on", "pngquant", "status", "99", "an", "optional", "behavior"], "add_tokens": "if ( options . retry && error && code === 99 && tries === 1 ) { iebug : false , retry : false", "del_tokens": "if ( error && code === 99 && tries === 1 ) { iebug : false", "commit_type": "make"}
{"commit_tokens": ["Remove", "shim", "for", "lutimes", "graceful", "-", "fs", "provides", "this", "now"], "add_tokens": "utimes = \"utimes\"", "del_tokens": "if ( ! fs . futimes ) fs . ltimes = function ( a , b , c , cb ) { return cb ( ) } else fs . lutimes = function ( path , atime , mtime , cb ) { var c = require ( \"constants\" ) fs . open ( path , c . O_SYMLINK , function ( er , fd ) { if ( er ) return cb ( er ) fs . futimes ( fd , atime , mtime , function ( er ) { if ( er ) return cb ( er ) fs . close ( fd , cb ) } ) } ) }", "commit_type": "remove"}
{"commit_tokens": ["Added", "deprecated", "flag", "and", "improved", "returns", "flag"], "add_tokens": "var doc = { 'parameters' : [ ] , 'description' : '' , 'scope' : 'public' , 'deprecated' : false , 'return' : { 'type' : null , 'description' : '' } } ; // Parameter // Deprecated flag else if ( check . isDeprecated ( line ) ) { doc . deprecated = check . isDeprecated ( line ) [ 1 ] || true ; } // Return var ret = check . isReturn ( line ) ; doc . return . type = ret [ 1 ] . split ( '|' ) ; doc . return . description = ret [ 2 ] ; // Scope // Separator, skip // Description", "del_tokens": "var doc = { parameters : [ ] , description : '' } ; doc . return = this . parseReturn ( line ) . split ( '|' ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "vcode", "page", "of", "example"], "add_tokens": "onClick ( ) { const canvas = this . selectComponent ( '#custom-canvas' ) canvas && canvas . draw ( ) } , } )", "del_tokens": "} )", "commit_type": "update"}
{"commit_tokens": ["Add", "versioning", "Add", "more", "grunt", "tasks"], "add_tokens": "} , version : { src : [ '<banner:meta.banner>' , 'src/terraformer.js' ] , dest : 'versions/terraformer-<%= meta.version %>.min.js' } , version : { src : [ '<banner:meta.banner>' , 'src/terraformer.js' ] , dest : 'versions/terraformer-<%= meta.version %>.min.js' grunt . registerTask ( 'default' , 'lint jasmine_node jasmine concat min concat:version min:version' ) ; grunt . registerTask ( 'build' , 'lint jasmine_node jasmine concat min' ) ; grunt . registerTask ( 'version' , 'lint jasmine_node jasmine concat:version min:version' ) ; grunt . registerTask ( 'browser' , 'lint jasmine' ) ; } ;", "del_tokens": "grunt . registerTask ( 'default' , 'lint jasmine_node jasmine concat min' ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "when", "supplying", "a", "Query", "Update", "or", "Aggregate", "class"], "add_tokens": "if ( _ . isPlainObject ( aggregate ) ) aggregate = createAggregate ( aggregate ) ; this . aggregate = aggregate . getData ( ) ;", "del_tokens": "this . aggregate = createAggregate ( aggregate ) . getData ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "log", "as", "unique", "logger"], "add_tokens": "ob . log = createLogger ( \"LOG\" , ob . _prefixes ) ;", "del_tokens": "ob . log = ob . info ;", "commit_type": "use"}
{"commit_tokens": ["Added", "cancel", "to", "client", "APIs", "and", "cancelled", "event", "to", "server", "APIs"], "add_tokens": "this . _call . cancel ( ) ;", "del_tokens": "self . _call . cancel ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "test", "/", "opening", "a", "can", "of", "worms", "/", "WIP", "/", "needs", "to", "be", "discussed"], "add_tokens": "// pelias analysis does not ensure that we get ['Great Britain'] instead of ['Great','Britain'] // TODO this needs to be addressed t . equal ( schema . index_analyzer , 'pelias' , 'should be pelias' ) ; t . equal ( schema . search_analyzer , 'pelias' , 'should be pelias' ) ;", "del_tokens": "// keyword analysis ensures that we get ['Great Britain'] instead of ['Great','Britain'] t . equal ( schema . index_analyzer , 'keyword' , 'should be keyword' ) ; t . equal ( schema . search_analyzer , 'keyword' , 'should be keyword' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "to", "domino", "for", "perf", "&", "simplicity"], "add_tokens": "var domino = require ( \"domino\" ) ; var doc = domino . createDocument ( input ) ; recurseTree ( doc , ( node ) => { return doc . documentElement . outerHTML ;", "del_tokens": "var jsdom = require ( \"jsdom\" ) ; var doc = jsdom . jsdom ( input , { features : { FetchExternalResources : false , ProcessExternalResources : false } } ) ; var window = doc . defaultView ; recurseTree ( window . document , ( node ) => { return jsdom . serializeDocument ( doc ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "inprog", "errors", "in", "popup", "/", "dialog", "close"], "add_tokens": "fp . app . factory ( \"fpDialogs\" , [ \"$compile\" , \"$parse\" , \"$templateCache\" , \"fpUi\" , \"$timeout\" , function ( $compile , $parse , $templateCache , fpUi , $timeout ) { $timeout ( function ( ) { if ( onClose ) scope . $apply ( onClose ) ; scope . $destroy ( ) ; } ) ;", "del_tokens": "fp . app . factory ( \"fpDialogs\" , [ \"$compile\" , \"$parse\" , \"$templateCache\" , \"fpUi\" , function ( $compile , $parse , $templateCache , fpUi ) { if ( onClose ) scope . $apply ( onClose ) ; scope . $evalAsync ( scope . $destroy . bind ( scope ) ) ; // $destroy fails when $digest is in progress", "commit_type": "fix"}
{"commit_tokens": ["Added", "stackTrace", "to", "console", ".", "trace"], "add_tokens": "'log' , 'info' , 'warn' , 'error' , 'trace' , 'debug' / ** * Returns stack trace * @ returns { string } * / function getTrace ( ) { return new Error ( ) . stack . split ( '\\n' ) . splice ( 3 ) . join ( '\\n' ) ; } /** Add trace to console.trace */ if ( messageType === 'trace' ) { message += ` \\n ${ getTrace ( ) } ` ; } _console . log ( message ) ;", "del_tokens": "'log' , 'info' , 'warn' , 'error' , 'trace' if ( messageType in _consoleKeys ) { _console [ messageType ] ( message ) ; } else { _console . log ( message ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "ignore", "option"], "add_tokens": "ignore : [ ] ,", "del_tokens": "// if (options.inlineJS == null) options.inlineJS = true; // if (options.inlineCSS == null) options.inlineCSS = true;", "commit_type": "add"}
{"commit_tokens": ["Added", "logs", "for", "testing", "purposes"], "add_tokens": "let controllerProxyHost = ( ( process . env . SOAJS_ENV ) ? process . env . SOAJS_ENV . toLowerCase ( ) : 'dev' ) + '-controller' ; console . log ( ' > getServiceHost(), get services: ' ) ; console . log ( error ) ; console . log ( JSON . stringify ( servicesList , null , 2 ) ) ;", "del_tokens": "let controllerProxyHost = process . env . SOAJS_ENV . toLowerCase ( ) + '-controller' ;", "commit_type": "add"}
{"commit_tokens": ["Add", "timeout", "parameter", "to", "prevent", "app", "hanging"], "add_tokens": "cmd = _ . union ( command , [ scriptFile , base64 , outputFile ] ) , opts = { timeout : config . timeout } ; utils . execProcess ( cmd , opts , onFinish ) ;", "del_tokens": "cmd = _ . first ( command ) , args = _ . union ( _ . rest ( command ) , [ scriptFile , base64 , outputFile ] ) ; utils . execProcess ( cmd , args , onFinish ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "hub", "signal", "multiplexer", "."], "add_tokens": "exports . signal = signal exports . expand = expand", "del_tokens": "exports . expand = expand", "commit_type": "implement"}
{"commit_tokens": ["Adds", "checking", "of", "error", "messages", "in", "throws", "tests", "for", "new", "-", "page"], "add_tokens": "const throwsTemplate = async ( t , options , erorrMessage ) => { try { await newPage ( options ) ; } catch ( error ) { t . is ( erorrMessage , error ) ; } test ( 'Throws on missing name' , throwsTemplate , { folderPath : tempy . directory ( ) } , 'No page name provided.' ) ; test ( 'Throws on missing path' , throwsTemplate , { componentName : 'a' } , 'No path provided.' ) ; test ( 'Throws on non-existing path' , throwsTemplate , { componentName : 'a' , folderPath : 'a/b' } , \"Path 'a/b' does not exist.\" ) ;", "del_tokens": "const throwsTemplate = ( t , options ) => { newPage ( options ) . then ( ( ) => { t . fail ( ) ; t . end ( ) ; } ) . catch ( ( ) => { t . pass ( ) ; t . end ( ) ; } ) ; test . cb ( 'Throws on missing name' , throwsTemplate , { folderPath : tempy . directory ( ) } ) ; test . cb ( 'Throws on missing path' , throwsTemplate , { componentName : 'a' } ) ; test . cb ( 'Throws on non-existing path' , throwsTemplate , { componentName : 'a' , folderPath : 'a/b' } ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "babel", "-", "lodash", "for", "smaller", "builds", "."], "add_tokens": "import BabiliPlugin from 'babili-webpack-plugin' ; // Faster transpiling for minor loose in formatting compact : true , cacheDirectory : true , // Keep origin information alive sourceMaps : true , // Nobody needs the original comments when having source maps comments : false , 'lodash' ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "libs", "resolve", "and", "ria", ".", "__CFG", "search"], "add_tokens": "if ( script . src . toString ( ) . match ( / \\/_bootstrap\\.js$ / i ) ) { var text = ( script . innerText || script . innerHTML ) . toString ( ) ; if ( text . match ( / \\s*ria\\.__CFG = \\{ / ) ) { var json = text . split ( '=' ) . slice ( 1 ) ; ria . __CFG = JSON . parse ( json . join ( '=' ) ) ; break ; } } ) ( ) ;", "del_tokens": "if ( script . src . toString ( ) . match ( / ria\\/_bootstrap\\.js$ / i ) ) { var text = ( script . innerText || script . innerHTML ) . toString ( ) . split ( '=' ) . slice ( 1 ) ; ria . __CFG = JSON . parse ( text . join ( '=' ) ) ; } ) ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "manual", "test", "for", "the", "write", "out", "issue"], "add_tokens": "var test = process . argv [ 2 ] || 'ui-components' ; var data = null ; try { data = require ( './' + test + '/data.json' ) ; } catch ( e ) { } if ( ! data ) { try { data = require ( './' + test + '/data' ) ; } catch ( e ) { } } return engine . render ( fn , data ) ;", "del_tokens": "var test = 'ui-components' ; return engine . render ( fn , require ( './' + test + '/data.json' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "validation", "to", "Typeahead", "editor"], "add_tokens": "if ( typeof ( val ) === 'string' ) { } if ( typeof ( val ) === 'string' ) { } if ( inp . type !== 'date' ) { '<div class=\"input-group\" ng-show=\"isEditing\">' + '<input ng-model=\"value\" placeholder=\"{{placeholder}}\" ' + 'class=\"form-control {{css}}\" ng-readonly=\"lastSet.indexOf(value) !== -1\" typeahead=\"{{ selectOptions }}\" ' + 'ng-required=\"required\" /> ' + '<div class=\"input-group-addon\" ng-hide=\"lastSet.indexOf(value) !== -1\"><i class=\"fa fa-pencil\"></i></div>' + '<span class=\"input-group-btn\" ng-show=\"lastSet.indexOf(value) !== -1\">' + '<button class=\"btn btn-default\" type=\"button\" ng-click=\"value = null\"><i class=\"fa fa-times\"></i>' + '</span>' + '</div>' + $scope . lastSet = [ ] ; if ( angular . isUndefined ( $scope . $component ) || $scope . $component == null ) { } var p = $scope . $component . dataService . retrieveDataAsync ( { p . then ( function ( data ) { $scope . lastSet = data ; return data ; } ) ; return p ; $scope . lastSet = $scope . options ;", "del_tokens": "if ( typeof ( val ) === 'string' ) if ( typeof ( val ) === 'string' ) if ( inp . type != 'date' ) { '<input ng-show=\"isEditing\" ng-model=\"value\" placeholder=\"{{placeholder}}\" ' + 'class=\"form-control {{css}}\" typeahead=\"{{ selectOptions }}\" ' + 'ng-required=\"required\" />' + if ( angular . isUndefined ( $scope . $component ) || $scope . $component == null ) return $scope . $component . dataService . retrieveDataAsync ( {", "commit_type": "add"}
{"commit_tokens": ["Added", "coveralls", "and", "made", "it", "to", "100%", "code", "coverage", "."], "add_tokens": "// Throw an error if the model could not be found if ( _ . isObject ( result ) ) { if ( ! callback ) { // Test if the callback is defined and throw an error if not throw new Error ( 'Please provide a callback.' ) ; }", "del_tokens": "if ( _ . isPlainObject ( result ) ) { // Default the callback to a noop function so that we don't have to check later on callback = callback || function ( ) { } ;", "commit_type": "add"}
{"commit_tokens": ["Use", "dist", "as", "build", "destination"], "add_tokens": ". pipe ( gulp . dest ( './dist' ) ) ;", "del_tokens": ". pipe ( gulp . dest ( '.' ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "storage", ".", "process", "to", "return", "error", "when", "ok", "==", "false"], "add_tokens": "var response ; return cb ( null , null ) ; response = entity . filter ( formData ) ; response = entity . data || entity ; cb ( ( response . ok === false ) ? response . error : null , response ) ; module . exports = Storage ;", "del_tokens": "return cb ( null , null ) cb ( null , entity . filter ( formData ) ) ; cb ( null , entity . data || entity ) module . exports = Storage ;", "commit_type": "fix"}
{"commit_tokens": ["implemented", "AST", "construction", "in", "parser", "for", "for", "-", "in", "for", "-", "of", ";", "added", "unicode"], "add_tokens": "filterExpression : this . filterExpr . toJSON ( ) , filterExpression : this . filterExpr . toJSON ( ) ,", "del_tokens": "filterExpression : this . filterExp . toJSON ( ) , filterExpression : this . filterExp . toJSON ( ) ,", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "for", "rerunning", "systems", "by", "returning", "true"], "add_tokens": "results = world . every ( [ 'position' ] , ( ) => { } ) results = world . every ( [ ] , ( ) => { } )", "del_tokens": "results = world . every ( [ 'position' ] , ( ) => true ) results = world . every ( [ ] , ( ) => true )", "commit_type": "add"}
{"commit_tokens": ["Fix", "dangling", "reference", "to", "this", "in", "import", "error", "logging", "."], "add_tokens": "console . log ( 'While running exports for ' , name , ':' ) ; console . log ( e . stack || e ) ; function doRuns ( name , runs ) { console . log ( 'While running runWhenLoaded for ' , name , ':' ) ; console . log ( e . stack || e ) ; doRuns ( this . name , runs ) ;", "del_tokens": "console . log ( 'While running exports for ' + name + ':' , e . stack || e ) ; if ( e . stack ) console . log ( e . stack ) ; function doRuns ( runs ) { console . log ( 'While running runWhenLoaded for ' + this . name + ':' , e . stack || e ) ; if ( e . stack ) console . log ( e . stack ) ; doRuns ( runs ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "babel", "transpiler", ".", "EdgeRing", "doesnt", "inherit", "from", "Array", "emulated", "behaviour"], "add_tokens": "const Graph = require ( './Graph' ) , EdgeRing = require ( './EdgeRing' ) ,", "del_tokens": "const Graph = require ( './src/Graph' ) , EdgeRing = require ( './src/EdgeRing' ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "promises", "(", "doesn", "t", "work", "with", "chained", "functions", "like", "getRunes", "with", "name", "parameter", ")"], "add_tokens": "this . madeRequests . push ( ( new Date ( ) ) . getTime ( ) + ( this . seconds * 1000 ) )", "del_tokens": "this . madeRequests . push ( ( new Date ( ) ) . getTime ( ) + ( this . seconds * 1000 + ( ( this . seconds * 1000 ) / 75 ) ) )", "commit_type": "add"}
{"commit_tokens": ["update", "qunit", "runner", "to", "new", "zuul", "reporter", "stuff"], "add_tokens": "var ZuulReporter = require ( '../zuul' ) ; var reporter = ZuulReporter ( run ) ; QUnit . config . autostart = false ; QUnit . begin ( function ( ) { } ) ; reporter . done ( ) ; QUnit . testStart ( function ( details ) { reporter . test ( { name : details . name } ) ; } ) ; QUnit . testDone ( function ( details ) { reporter . test_end ( { name : details . name , passed : details . passed } ) ; } ) ; QUnit . log ( function ( details ) { reporter . assertion ( { result : details . result , expected : details . expected , actual : details . actual , message : details . message , source : details . source } ) ; } ) ; QUnit . start ( ) ;", "del_tokens": "var load = require ( 'load-script' ) ; details . passed = details . failed === 0 ; window . zuul_results = details ; load ( '/__zuul/test-bundle.js' , run ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "3", "hours", "to", "TAU", ".", "Example", "updated"], "add_tokens": "ticketDate : moment ( ) . add ( 3 , 'hours' ) . format ( ) ,", "del_tokens": "ticketDate : moment ( ) . format ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "npm", "package", "require", "fallback", "in", "generator", "example"], "add_tokens": "var materialLetterIcons = require ( '../generator' ) || require ( 'material-letter-icons' ) ;", "del_tokens": "var materialLetterIcons = require ( '../generator' ) ;", "commit_type": "add"}
{"commit_tokens": ["improve", "code", "coverage", "and", "build"], "add_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'karma:unit' , 'uglify' , 'cssmin' , 'concat:build' , 'coveralls' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'karma:unit' , 'uglify' , 'cssmin' , 'concat:build' ] ) ;", "commit_type": "improve"}
{"commit_tokens": ["remove", "default", "concept", ".", "add", "generators", "for", "output", "format"], "add_tokens": "var getResolver = require ( './resolver' ) . getResolver ; if ( key == 'resolve' ) { webpackConfig . resolve = loadNameOrUseSource ( obj , getResolver ) ; } return _ . extend ( webpackConfig , _ . omit ( shortHandConfig , Object . keys ( webpackConfig ) ) ) ;", "del_tokens": "return webpackConfig ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "problem", "with", "escaping", "backslashes", "in", "strings", "and", "regexs"], "add_tokens": "// console.log(input) // console.log(token.klass, \": \", token.text) unknown . fn . klass = \"unknown\" whitespace . fn . klass = \"whitespace\" word . fn . klass = \"word\" string . fn . klass = \"string\" regex . regex = / \\/[^/ ][^/\\n]* / g ///\\/[^/ ][^\\n]*\\//g regex . fn . klass = \"regex\" comment . fn . klass = \"comment\" operator . regex = / instanceof|[!%^&*\\-=+:,.|\\\\~<>\\?]+|\\/|\\/= / g operator . fn . klass = \"operator\" semi . fn . klass = \"semi\" bracket . fn . klass = \"bracket\" var backslash_in_a_row = 0 if ( last == \"\\\\\" ) backslash_in_a_row ++ else backslash_in_a_row = 0 var esc = backslash_in_a_row % 2 if ( ch == mode && ! esc ) return word var regex = \"/\" , prev = \"\" , esc , inSQ , start = index var backslash_in_a_row = 0 if ( prev == \"\\\\\" ) backslash_in_a_row ++ else backslash_in_a_row = 0 esc = backslash_in_a_row % 2 //console.log(ch, esc, backslash_in_a_row) regex : regex ,", "del_tokens": "regex . regex = / \\/[^*\\/ ][^\\n]*\\/ / g operator . regex = / [!%^&*\\-=+:,.|\\\\~<>\\?]+|\\/|\\/= / g if ( ch == mode && last != \"\\\\\" ) return word var regex = \"/\" , prev = \"\" , esc , inSQ esc = prev == \"\\\\\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "sort", "and", "pinyin", "fonts"], "add_tokens": "rootPath : '../../flarej/' , initTheme : 'concise' , ver : null , themeStoreName : 'fj_theme' , GB2312Pinyin : { } , //Chinese pinyin fonts", "del_tokens": "rootPath : '../../flarej/' , initTheme : 'concise' , ver : null , themeStoreName : 'fj_theme'", "commit_type": "add"}
{"commit_tokens": ["Remove", "beep", "after", "each", "reload"], "add_tokens": "grunt . log . writeln ( String (", "del_tokens": "var beep = ( ! grunt . option ( 'no-color' ) ) ? '\\x07' : '' ; grunt . log . writeln ( beep ) . write ( String (", "commit_type": "remove"}
{"commit_tokens": ["Adding", "comments", "and", "white", "space", "to", "the", "lws", "-", "mirror", "-", "protocol", "example", "."], "add_tokens": "// We only care about text messages // Clear canvas command received // Record all other commands in the history // Re-broadcast the command to all connected clients", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "Users", "to", "the", "client"], "add_tokens": "var Users = require ( './resources/users' ) ; * @ constructor this . users = new Users ( this . dispatcher ) ;", "del_tokens": "* * *", "commit_type": "add"}
{"commit_tokens": ["remove", "api", "+", "add", "manager"], "add_tokens": "module . exports . start = async ( enableListener , callback ) => { const manager = require ( './src/manager' ) ( staticTorrentList ) ; if ( callback ) { staticTorrentList . addListener ( callback ) ; if ( enableListener ) { lDebug ( 'Launch listener' ) ; launchListener . start ( staticTorrentList ) ; } return manager ;", "del_tokens": "const api = require ( './src/api/api' ) ; let express = null , api_enabled = false ; / ** * @ param app * / module . exports . enableExpressApi = async ( app ) => { try { lDebug ( 'Check connections' ) ; await checkConnection ( ) ; api_enabled = true ; express = app ; api . enable ( staticTorrentList , express ) ; } catch ( e ) { lError ( ` ${ e } ` ) ; } } ; * @ param listener module . exports . start = async ( listener ) => { if ( listener ) { staticTorrentList . addListener ( listener ) ; lDebug ( 'Launch listener' ) ; launchListener . start ( staticTorrentList ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "karma", "configuration", "for", "using", "sinon", "."], "add_tokens": "frameworks : [ 'qunit' , 'commonjs' , 'jquery-2.1.0' , 'sinon' ] , 'karma-sinon' ,", "del_tokens": "frameworks : [ 'qunit' , 'commonjs' , 'jquery-2.1.0' ] ,", "commit_type": "fix"}
{"commit_tokens": ["fix", ":", "css", "output", "should", "be", "valid"], "add_tokens": "const uniqueRules = Array . from ( new Set ( rules . slice ( 0 , rules . length - 1 ) ) ) . join ( '\\n' ) ;", "del_tokens": "const uniqueRules = Array . from ( new Set ( rules ) ) . join ( '\\n' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "XOR", "to", "ensure", "unique", "IDs", "."], "add_tokens": "return ( process . pid << 32 ) ^ ( nextId ++ ) ;", "del_tokens": "return ( process . pid << 32 ) | ( nextId ++ ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "based", "on", "PR", "feedback", "."], "add_tokens": "* @ param { boolean } filter . return Return true to indicate that the * bundle name should be returned in the list . Otherise the bundle * name will be skipped . var bundleName , bundleNames = [ ] ; for ( bundleName in bundles ) { if ( bundles . hasOwnProperty ( bundleName ) ) { bundle = bundles [ bundleName ] ; pkgJSON = require ( libpath . resolve ( bundle . baseDirectory , 'package.json' ) ) ; // if no package.json found, tall the filter so! pkgJSON = undefined ; if ( filter ( bundle , pkgJSON ) ) { bundleNames . push ( bundleName ) ; return bundleNames ;", "del_tokens": "var key , list = [ ] ; for ( key in bundles ) { if ( bundles . hasOwnProperty ( key ) ) { bundle = bundles [ key ] ; pkgJSON = require ( bundle . baseDirectory + '/package.json' ) ; // NOTE: synthesize one. what else is required ? pkgJSON = { name : bundle . name // description // version } ; if ( filter ( key , pkgJSON ) ) { list . push ( key ) ; return list ;", "commit_type": "update"}
{"commit_tokens": ["Changed", "some", "expect", "calls", "to", "be", "less", "sensitive", "to", "control", "chars", "which", "are", "different", "on", "Windows", "."], "add_tokens": "return expect ( stdout ) . to . match ( / Reporter class not implemented: Nonesuch / ) ; return expect ( stdout ) . to . match ( / Failed to find mocha on the page. / ) ; return expect ( stdout ) . to . match ( / Failed to start mocha. / ) ;", "del_tokens": "return expect ( stdout ) . to . equal ( \"Reporter class not implemented: Nonesuch\\n\" ) ; return expect ( stdout ) . to . equal ( \"Failed to find mocha on the page.\\n\" ) ; return expect ( stdout ) . to . equal ( \"Failed to start mocha.\\n\" ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "initial", "suite", "value", "for", "the", "root", "suite", "in", "the", "mocha_reporter", "in", "case", "a", "hook", "fails", "before", "the", "first", "suite", "is", "loaded"], "add_tokens": "// on other platforms, open expects app to be the name of the executale...", "del_tokens": "// on other platforms, open expects app to be the name of the executable...", "commit_type": "add"}
{"commit_tokens": ["fixed", "git", "validator", "for", "those", "using", "apple", "git"], "add_tokens": "//http://stackoverflow.com/questions/82064/a-regex-for-version-number-parsing let found = result . match ( / (\\d+\\.)?(\\d+\\.)?(\\d+) / i ) ; return found [ 0 ] === version ;", "del_tokens": "let found = result . match ( / git version (.*) / i ) ; return found . length > 1 ? found [ 1 ] === version : false ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "sparse", "output", "hashes", "when", "getting", "error"], "add_tokens": "iterations = iterations || 10000 ; error += Math . pow ( output [ id ] - ( target [ id ] || 0 ) , 2 ) ; if ( this . prevLayer ) return value ; this . bias += rate * this . delta ;", "del_tokens": "iterations = iterations || 20000 ; error += Math . pow ( output [ id ] - target [ id ] , 2 ) ; if ( this . prevLayer ) return value ; this . bias += rate * this . delta ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", ":", "circle", "-", ">", "cycle"], "add_tokens": "plugin . bindLifeCycle = ( ) => { plugin . bindLifeCycle ( ) ;", "del_tokens": "plugin . bindLifeCircle = ( ) => { plugin . bindLifeCircle ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "RegEx", "options", "width", "and", "height", "from", "EXIF", "data"], "add_tokens": "regexPatterns : [ / SomeRegEx / g ] , Note : regexMatches and regexPatterns are only present when the - r option is used , so be sure", "del_tokens": "regexPattern : / SomeRexEx / g , Note : regexMatches and regexPattern are only present when the - r option is used , so be sure", "commit_type": "allow"}
{"commit_tokens": ["added", "express", "support", "via", "app", ".", "engine", ";", "added", "test", "cases"], "add_tokens": "templates . cache = { } ; templates . prepare = function ( str ) { return str ; } ; tpl = filename . replace ( options . settings . views + '/' , '' ) ; if ( ! templates . cache [ tpl ] ) { templates . cache [ tpl ] = templates . prepare ( html . toString ( ) ) ; return fn ( err , templates . parse ( templates . cache [ tpl ] , options ) ) ; return fn ( null , templates . parse ( templates . cache [ tpl ] , options ) ) ;", "del_tokens": "path = require ( 'path' ) ; if ( 'function' === typeof options ) { fn = options , options = false ; } var tpl = filename . replace ( path . join ( __dirname + '/../templates/' ) , '' ) . replace ( '.' + options . settings [ 'view engine' ] , '' ) ; if ( ! templates [ tpl ] ) { templates [ tpl ] = templates . prepare ( html . toString ( ) ) ; return fn ( err , templates [ tpl ] . parse ( options ) ) ; return fn ( null , templates [ tpl ] . parse ( options ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "event", "name"], "add_tokens": "this . once ( 'esl::event::api::response' , cb ) ;", "del_tokens": "this . once ( 'esl::event::api::reply' , cb ) ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "the", "babel", "-", "polyfill", "less", "annoying"], "add_tokens": "subschema : ( isNode ? './src/index.jsx' : './src/dist.js' ) loader : extractCSS . extract ( [ cssStr , 'less' ] )", "del_tokens": "subschema : './src/index.jsx' loader : extractCSS . extract ( [ cssStr , 'less' ] )", "commit_type": "make"}
{"commit_tokens": ["fixed", "a", ":", "href", "attribute", "view", "-", "model", "mapping"], "add_tokens": "var vars = new RegExp ( / \\B\\$var\\[(.*[^\\[\\]])] / g ) ,", "del_tokens": "var vars = new RegExp ( / \\B\\$model\\[(.*[^\\[\\]])] / g ) ,", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "flag", "name", "for", "the", "host", "option", "in", "the", "REPL"], "add_tokens": ". option ( '-t, --host <host>' , 'Remote Debugging Protocol host' )", "del_tokens": ". option ( '-h, --host <host>' , 'Remote Debugging Protocol host' )", "commit_type": "change"}
{"commit_tokens": ["Fix", "some", "issues", "with", "bedgraph", "parsing", "and", "updated", "unit", "test", "data"], "add_tokens": "this . color = descriptor . color || \"rgb(150,150,150)\" var track = this , chr = refFrame . chr ; canvas . fillRect ( rectOrigin , rectBaseline , rectWidth , rectHeight , { fillStyle : track . color } ) ;", "del_tokens": "var chr = refFrame . chr ; canvas . fillRect ( rectOrigin , rectBaseline , rectWidth , rectHeight , { fillStyle : igv . randomRGB ( 32 , 224 ) } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "findAll", "()", "internally", "instead", "of", "find", "()", "."], "add_tokens": ". map ( ( ) => id ? store . find ( type , id ) : store . findAll ( type ) )", "del_tokens": ". map ( ( ) => id ? store . find ( type , id ) : store . find ( type ) )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "the", "imageExists", "-", "method", "would", "return", "an", "error", "as", "the", "exists", "-", "parameter", "in", "the", "callback", ".", "Added", "tests", "for", "imageExists", "."], "add_tokens": "callback ( undef , res . statusCode == 200 ) ;", "del_tokens": "callback ( res . statusCode == 200 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", ":", "correct", "detection", "of", "tags", "with", "namespaces"], "add_tokens": "var platforms = doc . getElementsByTagNameNS ( cocoonNS , 'platform' ) ; var plugins = doc . getElementsByTagNameNS ( cocoonNS , 'plugin' ) ;", "del_tokens": "var platforms = doc . getElementsByTagNameNS ( 'cocoon' , 'platform' ) ; var plugins = doc . getElementsByTagNameNS ( 'cocoon' , 'plugin' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "logging", "in", "tinyg", ".", "js"], "add_tokens": "port = 8082 ; app . listen ( port ) ; console . log ( \"Open your browser to http://localhost:\" + port ) ;", "del_tokens": "app . listen ( 8082 ) ;", "commit_type": "add"}
{"commit_tokens": ["removing", "router", "for", "now", "as", "it", "needs", "an", "overhaul!"], "add_tokens": "export * from './streamy-helpers' ;", "del_tokens": "export * from './streamy-helpers' ; export * from './router' ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "new", "option", "to", "listen", "to", "when", "tree", "is", "ready"], "add_tokens": "this . _onReadyCallbacks = [ ] ; for ( var word in wordList ) { this . addWord ( wordList [ word ] ) ; } this . _isReady = true ; setTimeout ( function ( ) { for ( var fn in this . _onReadyCallbacks ) { this . _onReadyCallbacks [ fn ] . call ( null ) ; } } . bind ( this ) , 0 ) ; / ** * Add a listener for when the tree is ready * @ param { Function } fn Callback function * / ready : function ready ( fn ) { if ( this . _isReady ) { return fn . call ( null ) ; } return this . _onReadyCallbacks . push ( fn ) ; } , if ( Array . isArray ( jsonData . words ) ) { } . bind ( this ) ) } . bind ( this ) ) ;", "del_tokens": "var word ; for ( var _word_ in wordList ) { word = wordList [ _word_ ] ; //Get the current word to be added to the three this . addWord ( word ) ; } if ( Array . isArray ( jsonData . words ) ) { } ) console . error ( error ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "productAddedDate", "in", "test", "data"], "add_tokens": "db . products . insertMany ( fixProductDates ( jsonData . products ) ) , db . products . remove ( { } , { } ) , db . menu . remove ( { } , { } ) db . products . insertMany ( fixProductDates ( jsonData . products ) ) , console . log ( 'Error inserting test data' , err ) ; console . log ( 'Error removing existing test data' , err ) ; // Adds current date to product added date when smashing into DB function fixProductDates ( products ) { let index = 0 ; products . forEach ( ( product ) => { products [ index ] . productAddedDate = new Date ( ) ; index ++ ; } ) ; return products ; }", "del_tokens": "db . products . insertMany ( jsonData . products ) , db . products . remove ( { } , { } ) db . products . insertMany ( jsonData . products ) ,", "commit_type": "fix"}
{"commit_tokens": ["made", "http2", "part", "of", "the", "ssl", "options"], "add_tokens": "if ( opts . ssl . http2 ) {", "del_tokens": "if ( opts . http2 ) {", "commit_type": "make"}
{"commit_tokens": ["remove", "event", "listener", "after", "end", "."], "add_tokens": "stream . once ( 'end' , function ( ) {", "del_tokens": "stream . on ( 'end' , function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["moving", "schema", "grammar", "files", "into", "client", "adapters"], "add_tokens": "this . grammar = new Knex . SchemaGrammar ( Knex . client . schemaGrammar ) ;", "del_tokens": "this . grammar = new Knex . SchemaGrammar ( Knex . client . getSchemaGrammar ( ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "proper", "subprocess", "version", "&", "add", "jshint"], "add_tokens": "}", "del_tokens": "} ;", "commit_type": "use"}
{"commit_tokens": ["changed", "deps", "to", "custom", "webpack"], "add_tokens": "new webpack . optimize . UglifyJsPlugin ( { compress : { warnings : true } } ) exclude : / (node_modules|bower_components) / , loader : require . resolve ( 'babel-loader' ) , query : { plugins : [ // require.resolve('babel-plugin-transform-es2015-modules-commonjs'), require . resolve ( 'babel-plugin-transform-async-to-generator' ) , ] , // presets: ['es2015', 'stage-3'], cacheDirectory : true , } , } , { test : / \\.js$ / , include : / (node_modules\\/template-binding) / , plugins : [ // require.resolve('babel-plugin-transform-es2015-modules-commonjs'), require . resolve ( 'babel-plugin-transform-async-to-generator' ) , ] , // presets: ['es2015', 'stage-3'],", "del_tokens": "new webpack . optimize . UglifyJsPlugin ( { compress : { warnings : false } } ) include : / (src|components|node_modules\\/template-binding) / , presets : [ 'es2015' , 'stage-3' ] ,", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "type", "casts", "to", "make", "subset", "/", "superset", "operations", "to", "work", "better", "with", "json", "field", "reference", "in", "both", "side", "."], "add_tokens": "var refRefQuery = [ \"(\" , fieldReference , \")::jsonb \" , operator , \" (\" , rightHandReference , \")::jsonb\" ] . join ( \"\" ) ; return this . whereRaw ( refRefQuery ) ; var refValQuery = [ \"(\" , fieldReference , \")::jsonb \" , operator , \" ?::jsonb\" ] . join ( \"\" ) ; return this . whereRaw ( refValQuery , JSON . stringify ( jsonObjectOrFieldExpression ) ) ; throw new Error ( \"Disabled because of knex issue #519.\" ) ; // return this.whereJsonFieldRightStringArrayOnLeft(fieldExpression, '?|', keys); throw new Error ( \"Disabled because of knex issue #519.\" ) ; // return this.whereJsonFieldRightStringArrayOnLeft(fieldExpression, '?&', keys);", "del_tokens": "return this . whereRaw ( fieldReference + \" \" + operator + \" \" + rightHandReference ) ; return this . whereRaw ( fieldReference + \" \" + operator + \" ?\" , JSON . stringify ( jsonObjectOrFieldExpression ) ) ; return this . whereJsonFieldRightStringArrayOnLeft ( fieldExpression , '?|' , keys ) ; return this . whereJsonFieldRightStringArrayOnLeft ( fieldExpression , '?&' , keys ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "the", "config", "filepath", "inside", "the", "config", "file"], "add_tokens": "const { config , filepath } = explorer . load ( searchPathAbsolute , configPathAbsolute ) return { ... ( config || { } ) , filepath }", "del_tokens": "const { config } = explorer . load ( searchPathAbsolute , configPathAbsolute ) return config || { }", "commit_type": "add"}
{"commit_tokens": ["Add", "use", "loading", "to", "container", "."], "add_tokens": "it ( \"get a service with a global variable injection\" , function ( ) { context . gVar = \"hello global\" ; var testObject = new CoreJs . DependencyInjection . Container ( { services : { \"my_test\" : { \"class\" : \"TCoreJs.Test\" , \"arguments\" : [ \"$gVar\" ] } } } ) ; var result = testObject . get ( \"my_test\" ) ; assert . equal ( true , result instanceof context . TCoreJs . Test , \"Service has wrong instance type\" ) ; assert . equal ( \"hello global\" , result . injected ) ; } ) ; it ( \"load classes\" , function ( ) { var testObject = new CoreJs . DependencyInjection . Container ( { services : { \"my_test\" : { \"class\" : \"TCoreJs.Test\" , } } } ) ; var orgUse = global . use ; global . use = sinon . stub ( ) ; testObject . load ( ) ; use . should . been . calledWithExactly ( \"TCoreJs.Test\" ) global . use = orgUse ; } ) ; it ( \"set a service from outside\" , function ( ) {", "del_tokens": "it ( \"set a service from outside\" , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["removing", ".", "toString", "()", "of", "id", "generation"], "add_tokens": "var _id = uuid . v4 ( ) ;", "del_tokens": "var _id = uuid . v4 ( ) . toString ( ) ; //function _generateUUID() { // var d = new Date().getTime(); // var uuid; // uuid = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'. // replace(/[xy]/g, function (c) { // var r = (d + Math.random() * 16) % 16 | 0; // d = Math.floor(d / 16); // return (c == 'x' ? r : (r & 0x3 | 0x8)).toString(16); // }); // return uuid; // //};", "commit_type": "remove"}
{"commit_tokens": ["Improve", "dialog", "widget", "-", "complete", "unit", "test", "."], "add_tokens": "'<div class=\"cm-dialog-img-content\" style=\"<%= data.img.cssText %>\"></div>' , '<img src=\"<%= data.img.url %>\"' , '<% if (data.img.width) { %>' , 'style=\"width: <%= data.img.width %>px;\"' , '<% } %>' , '>' , // tag config . tag = gearbox . str . trim ( config . tag ) . toLowerCase ( ) || 'div' // id config . id = gearbox . str . stripHash ( config . id ) imgStyleRules . push ( 'background-image: url(' + img . url + ')' ) img . cssText = imgStyleRules . join ( '; ' ) btn . tag = gearbox . str . trim ( btn . tag ) . toLowerCase ( ) if ( btn . tag !== 'a' ) btn . tag = 'button'", "del_tokens": "'<div class=\"cm-dialog-img-content\" style=\"<%= data.img.style %>\"></div>' , '<img src=\"<%= data.img.url %>\">' , config . tag = config . tag || 'div' imgStyleRules . push ( 'background: url(' + img . url + ') no-repeat top center' ) imgStyleRules . push ( 'background-size: 100% 100%' ) img . style = imgStyleRules . join ( '; ' ) if ( _ . isString ( btn . tag ) ) { btn . tag = btn . tag . trim ( ) if ( btn . tag !== 'a' ) btn . tag = 'button' } else { btn . tag = 'button' }", "commit_type": "improve"}
{"commit_tokens": ["Add", "query", "parser", "to", "all", "routes"], "add_tokens": "var queryHelper = require ( './query' ) ; var middleware = [ queryHelper . queryParser , docFetcher ] ; . get ( middleware , routes . query ( this , Mod ) ) . post ( middleware , routes . create ( this , Mod ) ) ; . get ( middleware , routes . get ( this , Mod ) ) . put ( middleware , routes . update ( this , Mod ) ) . patch ( middleware , routes . update ( this , Mod ) ) . delete ( middleware , routes . delete ( this , Mod ) ) ;", "del_tokens": ". get ( docFetcher , routes . query ( this , Mod ) ) . post ( docFetcher , routes . create ( this , Mod ) ) ; . get ( docFetcher , routes . get ( this , Mod ) ) . put ( docFetcher , routes . update ( this , Mod ) ) . patch ( docFetcher , routes . update ( this , Mod ) ) . delete ( docFetcher , routes . delete ( this , Mod ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "strip", "function", "for", "ssh", "urls"], "add_tokens": "return url . replace ( / (https?:\\/\\/|git@)github\\.com(\\/|:)|\\.git / g , '' ) }", "del_tokens": "return url . replace ( / (https?|git):\\/\\/github\\.com\\/|\\.git / g , '' ) }", "commit_type": "fix"}
{"commit_tokens": ["Changed", ":", "pass", "Test", "object", "to", "beforEach", "/", "afterEach"], "add_tokens": "fn ( test ) ; fn ( test ) ;", "del_tokens": "fn ( ) ; fn ( ) ;", "commit_type": "change"}
{"commit_tokens": ["changed", "name", "from", "intersectWith", "to", "intersect"], "add_tokens": "newArray . intersect = function ( array ) { if ( ! Array . isArray ( array ) ) { testing . assertEquals ( arrayA . intersect ( arrayB ) , [ 3 ] , 'Invalid intersection' , callback ) ; testing . assertEquals ( arrayB . intersect ( arrayC ) , [ 4 , 5 ] , 'Invalid intersection' , callback ) ; testing . assertEquals ( arrayA . intersect ( arrayC ) , [ ] , 'Invalid intersection' , callback ) ; testing . assertEquals ( arrayA . intersect ( empty ) , [ ] , 'Invalid intersection' , callback ) ;", "del_tokens": "newArray . intersectWith = function ( array ) { if ( Array . isArray ( array ) ) { testing . assertEquals ( arrayA . intersectWith ( arrayB ) , [ 3 ] , 'Invalid intersection' , callback ) ; testing . assertEquals ( arrayB . intersectWith ( arrayC ) , [ 4 , 5 ] , 'Invalid intersection' , callback ) ; testing . assertEquals ( arrayA . intersectWith ( arrayC ) , [ ] , 'Invalid intersection' , callback ) ; testing . assertEquals ( arrayA . intersectWith ( empty ) , [ ] , 'Invalid intersection' , callback ) ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "a", "bug", "with", "wheel", "()"], "add_tokens": "document . body . addEventListener ( 'wheel' , ( e ) => this . handleWheel ( e ) )", "del_tokens": "document . body . addEventListener ( 'wheel' , ( ) => this . handleWheel ( ) )", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "bug", "of", "mootools", "on", "ie", "<", "8", "that", "document", ".", "body", "and", "html", "don", "t", "support", "most", "of", "the", "method", "because", "they", "haven", "t", "dollared", "yet"], "add_tokens": "readyList . push ( function ( ) { $ ( document . body ) ; $ ( document . documentElement ) ; } ) ; function _ready ( ) { doc . removeListener ( eventType , _ready ) . removeListener ( 'load' , _ready ) ; doc . addListener ( eventType , _ready ) ; doc . addListener ( 'load' , _ready ) ;", "del_tokens": "$ ( document . body ) ; $ ( document . documentElement ) ; function ready ( ) { doc . removeListener ( eventType , ready ) . removeListener ( 'load' , ready ) doc . addListener ( eventType , ready ) ; doc . addListener ( 'load' , ready ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "the", "controller", "index", "now", "it", "will", "properly", "use", "the", "name", "from", "the", "definition", "and", "the", "folder", "name", "is", "truly", "unimportant", "."], "add_tokens": "console . log ( \"\\n\\n sSSs .S S. .S_sSSs sSSs .S_sSSs .S sSSs \" ) ; console . log ( \" d%%%%SP .SS SS. .SS~YS%%%%b d%%%%SP .SS~YS%%%%b .SS d%%%%SP \" ) ; var controller = new Controller ( self ) ; self . controllers [ controller . name ] = controller ; var controller = new Controller ( self ) ; self . controllers [ controller . name ] = controller ;", "del_tokens": "console . log ( \" sSSs .S S. .S_sSSs sSSs .S_sSSs .S sSSs \" ) ; console . log ( \" d%%SP .SS SS. .SS~YS%%b d%%SP .SS~YS%%b .SS d%%SP \" ) ; self . controllers [ moduleName ] = new Controller ( self ) ; self . controllers [ controllerName ] = new Controller ( self ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "section", "indexing", "to", "the", "rules", "engine", "to", "handle", "repeating", "sections"], "add_tokens": "_unit_args : '-A -u exports --recursive -t 10000 ./test/unit/' ,", "del_tokens": "_unit_args : '-A -u exports --recursive -t 10000 ./test/unit' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "stringifyRequestData", "to", "deal", "with", "nested", "objs"], "add_tokens": "amount : '1500' , currency : 'usd' , shipping : { address : { line1 : 'foo' } } data : { amount : '1500' , currency : 'usd' , shipping : { address : { line1 : 'foo' } } }", "del_tokens": "amount : '1500' , currency : 'usd' data : { amount : '1500' , currency : 'usd' }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unused", "argument", "from", "loadContent", "."], "add_tokens": "module . exports = function ( ) {", "del_tokens": "module . exports = function ( dir ) {", "commit_type": "remove"}
{"commit_tokens": ["Remove", "key", "parameter", "from", "replace", "and", "use", "React", ".", "cloneElement"], "add_tokens": "replacement = options . replace ( node ) ; // specify a \"key\" prop if element has siblings // https://fb.me/react-warning-keys if ( len > 1 ) { replacement = React . cloneElement ( replacement , { key : i } ) ; }", "del_tokens": "replacement = options . replace ( node , i ) ; // i = key", "commit_type": "remove"}
{"commit_tokens": ["Fix", "isAsyncFunction", "for", "babel", "7"], "add_tokens": "&& val . toString ( ) . replace ( / \\n / gi , '' ) . replace ( / / gi , '' ) . replace ( / _ / gi , '' ) === tools . nop$ . toString ( ) . replace ( / \\n / gi , '' ) . replace ( / / gi , '' ) . replace ( / _ / gi , '' ) ) ;", "del_tokens": "&& val . toString ( ) === tools . nop$ . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "navigation", "parsed", "in", "footer"], "add_tokens": "var files , summary , navigation , tpl ; // Parse navigation navigation = parse . navigation ( summary ) ; summary : summary , allNavigation : navigation", "del_tokens": "var files , summary , tpl ; summary : summary", "commit_type": "add"}
{"commit_tokens": ["add", "unit", "test", "on", "fitTextRenderer"], "add_tokens": "/ ** * Inspired by https : //beta.observablehq.com/@mbostock/fit-text-to-circle * @ param text * @ returns { * } * / if ( text === undefined || text === null ) { return { lines : [ ] } } var text = String ( text ) ; var lines2 = lines . map ( function ( d ) { return { \"text\" : d . text , \"linesLength\" : lines . length } var scale = 1 ; if ( d . textRadius !== 0 && d . textRadius ) { scale = provider . node . getSize ( d ) / d . textRadius ; }", "del_tokens": "var lines2 = [ ] ; lines . map ( function ( d ) { lines2 . push ( { \"text\" : d . text , \"textRadius\" : textRadius , \"linesLength\" : lines . length } ) var scale = provider . node . getSize ( d ) / d . textRadius ;", "commit_type": "add"}
{"commit_tokens": ["using", "history", ".", "pushState", "instead", "of", "location", "change", "in", "courtesy", "of", "@medikoo"], "add_tokens": "// so both `#slide-id` and \"legacy\" `#/slide-id` will work // Setting fragment URL with `history.pushState` // and it has to be set after animation finishes, because in Chrome it history . pushState ( { } , '' , '#' + el . id ) ;", "del_tokens": "// so both \"fallback\" `#slide-id` and \"enhanced\" `#/slide-id` will work // `#/step-id` is used instead of `#step-id` to prevent default browser // scrolling to element in hash // // and it has to be set after animation finishes, because in chrome it window . location . hash = \"#/\" + el . id ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "display", "of", "round", "/", "stage", "info", "in", "ultimatum", ";"], "add_tokens": "node . game . lastStage = currentStage ; function selectLanguage ( ) { console . log ( 'Select Language' ) ; } console . log ( 'Questionnaire' ) ; console . log ( 'Endgame' ) ; stager . addStage ( { id : 'selectLanguage' , cb : selectLanguage , minPlayers : [ MIN_PLAYERS , notEnoughPlayers ] } ) ; . next ( 'selectLanguage' )", "del_tokens": "node . game . lastStage = currentStage ; console . log ( 'questionnaire' ) ; console . log ( 'endgame' ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "persistent", "property", "to", "lf", ".", "schema", ".", "Index", "."], "add_tokens": "* @ param { boolean } persistent lf . schema . Index = function ( tableName , name , isUnique , persistent , columnNames ) { /** @type {boolean} */ this . persistent = persistent ;", "del_tokens": "lf . schema . Index = function ( tableName , name , isUnique , columnNames ) {", "commit_type": "add"}
{"commit_tokens": ["add", "textarea", "support", "to", "play", "the", "same", "as", "input"], "add_tokens": "extendCustomValidations . directive ( 'textarea' , function ( customValidationUtil ) { return { require : '?ngModel' , restrict : 'E' , link : customValidationUtil . createValidationLink ( customValidation ) } ; } ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "awareness", "for", "appConfig", "disablePty"], "add_tokens": "function registerEvents ( emitter , disablePty ) { , usePty = ! disablePty && data . repo_config . pseudo_terminal registerEvents ( context . emitter , context . config . disablePty )", "del_tokens": "function registerEvents ( emitter ) { , usePty = data . repo_config . pseudo_terminal registerEvents ( context . emitter )", "commit_type": "add"}
{"commit_tokens": ["Fix", "event", "emitter", "and", "listener", "docs"], "add_tokens": "/ ** * A mixin , providing event emitting capabilities to an object . Events are simply strings . When they are * emitted , zero or more parameters can be passed as arguments to the listening functions . * @ exports bff / event - emitter * @ mixin * / * @ instance * @ instance * @ instance * @ instance", "del_tokens": "/ ** * A mixin , providing event emitting capabilities to an object . Events are simply strings . When they are * emitted , zero or more parameters can be passed as arguments to the listening functions . * @ module bff / event - emitter * @ mixin * /", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "trouble", "using", "arguments", ".", "callee", "in", "the", "patch", "."], "add_tokens": "var checkElement = function checkElement ( ) { setTimeout ( checkElement , 20 ) ; } checkElement ( ) ;", "del_tokens": "( function ( ) { setTimeout ( arguments . callee , 20 ) ; } ) ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "chained", "methods", "for", "Builder", "as", "well"], "add_tokens": "Builder . prototype . setReader = function ( reader ) { this . reader = reader return this } Builder . prototype . addTransformer = function ( transformer ) { if ( this . transformer != null ) throw new Error ( 'multiple transformers not yet supported' ) this . transformer = transformer return this }", "del_tokens": "this . reader = options . reader this . transformer = options . transformer", "commit_type": "use"}
{"commit_tokens": ["adding", "windows", "homedir", "for", "config"], "add_tokens": "var fs = require ( 'fs' ) ; var configDir = ( process . platform === 'win32' ) ? process . env . HOMEPATH : process . env . HOME ; if ( ! configDir ) configDir = '.' ; var configPath = path . join ( configDir , '.pinoccio' ) //var altConfigPath = configDir+'.pinoccio.json'", "del_tokens": "var fs = require ( 'fs' ) var configDir = process . env . HOME ; var configPath = configDir + '/.pinoccio' var altConfigPath = configDir + '/.pinoccio.json'", "commit_type": "add"}
{"commit_tokens": ["Allow", "FS", "events", "if", "not", "on", "windows", "but", "polling", "not", "set", "to", "false"], "add_tokens": "if ( opts . usePolling == null ) opts . usePolling = ( ! isWindows && ! canUseFsEvents ) ;", "del_tokens": "if ( opts . usePolling == null ) opts . usePolling = ! isWindows ;", "commit_type": "allow"}
{"commit_tokens": ["adding", "support", "for", "generate", "-", "dest", "fix", "--", "d", "/", "dest", "flag"], "add_tokens": "* Generate a ` ` file to the current working directory . * * You can override the default template by adding a custom template * at the following path : ` ` ( in user home ) . * * To use a different destination directory , you can either : * - pass the path on the ` ` or ` ` flag . * - pipe the [ generate - dest ] ( https : //github.com/generate/generate-dest) * plugin before ` ` . * $ gen dest contributing app . task ( 'contributing' , [ 'setup' ] , function ( cb ) { var destFlag = app . options . d || app . options . dest || false ; destFlag = destFlag ? path . resolve ( destFlag ) : false ; var cwd = destFlag || base . options . dest || app . cwd ;", "del_tokens": "* Generate a ` ` file to the current working directory . To use * a different destination directory , pass the path on the ` ` or ` ` flag . app . task ( 'contributing' , [ 'setup' ] , function ( cb ) { var cwd = app . options . dest || app . cwd ;", "commit_type": "add"}
{"commit_tokens": ["Using", "Promise", ".", "method", "."], "add_tokens": "var BluebirdPromise = require ( 'bluebird' ) ; connect : BluebirdPromise . method ( function ( ) { } ) , disconnect : BluebirdPromise . method ( function ( ) { } )", "del_tokens": "connect : function ( ) { } , disconnect : function ( ) { }", "commit_type": "use"}
{"commit_tokens": ["Fix", "an", "issue", "with", "originalData", ".", "In", "fact", "the", "response", "was", "unwrap", "before", "to", "be", "deserialized", ".", "So", "we", "already", "modify", "the", "response", "when", "we", "execute", "the", "RailsResource", ".", "deserialize", "function", "."], "add_tokens": "expect ( railsRootWrapper . unwrap ( { data : wrappedData } , Resource ) ) . toEqualData ( { data : unwrappedData , originalData : wrappedData } ) ;", "del_tokens": "expect ( railsRootWrapper . unwrap ( { data : wrappedData } , Resource ) ) . toEqualData ( { data : unwrappedData } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "map", "-", "tiles", "not", "being", "loaded", "for", "leaflet", "demos"], "add_tokens": "/ * * * * * L . tileLayer ( 'http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png' , {", "del_tokens": "/ * * * * * L . tileLayer ( 'http://{s}.tiles.mapbox.com/v3/ijzerenhein.iil33fn1/{z}/{x}/{y}.png' , {", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "grecaptcha", ".", "execute", "()", "API", "method"], "add_tokens": "/ ** * Executes the reCaptcha * / execute : function ( widgetId ) { validateRecaptchaInstance ( ) ; recaptcha . execute ( widgetId ) ; } ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Removed", "g", "?", ":", "D"], "add_tokens": "* / } ;", "del_tokens": "* / g } ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "rendering", "EJS", "/", "View", "rendering", "error"], "add_tokens": "renderResponseData = function ( rendererror ) { // console.log('this is rendererror',rendererror); if ( rendererror ) { err = rendererror ; } if ( err ) { logger . error ( err ) ; res . status ( 500 ) ; // if(appconfig.settings().theme) res . render ( 'home/error500' , { message : err . message , error : err } ) ; res . end ( ) ; } else if ( useCacheTest && global . CoreCache ) { renderResponseData ( err ) ;", "del_tokens": "renderResponseData = function ( ) { // console.log('this is res data'); if ( useCacheTest && global . CoreCache ) { renderResponseData ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "some", "testing", "for", "createFromText", "and", "the", "reading", "the", "passthrough", "res", ".", "sentry", "object", "."], "add_tokens": "} , client = new raven . Client ( options ) ; client . createFromText ( 'Testing!!!' , function ( result ) { } ) ; raven . patchGlobal ( options ) ; function handle_request ( req , res ) { throw new Error ( 'broke' ) ; } connect ( function connect ( req , res ) { handle_request ( req , res ) ; } , raven_middleware ( client ) , function ( err , req , res , next ) { res . statusCode = 500 ; res . end ( JSON . stringify ( res . sentry ) ) ; } ) . listen ( 3000 ) ; //ffdasfsd.fdasfd;", "del_tokens": "} ; raven . patch_global ( options ) ; connect ( function ( req , res ) { idontexist [ 'what' ] ; } , raven_middleware ( options ) ) . listen ( 3000 ) ; ffdasfsd . fdasfd ;", "commit_type": "add"}
{"commit_tokens": ["add", "inject", "-", "loader", "dependency"], "add_tokens": "browsers : [ 'PhantomJS' , 'Chrome' ]", "del_tokens": "browsers : [ 'PhantomJS' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "functions", "for", "publishing", "with", "metadata"], "add_tokens": "function encode ( body , meta ) { var message = { props : meta , buffer : { } } ; message . buffer = new Buffer ( body , \"utf8\" ) ; message . buffer = body ; if ( ! message . props ) message . props = { } ; message . props . contentType = \"application/json\" ; message . buffer = new Buffer ( JSON . stringify ( body ) , \"utf8\" ) ; return message ; if ( ! message . properties ) {", "del_tokens": "function encode ( body ) { return { buffer : new Buffer ( body , \"utf8\" ) } ; return { buffer : body } ; return { props : { contentType : \"application/json\" } , buffer : new Buffer ( JSON . stringify ( body ) , \"utf8\" ) } ; if ( ! message . properties ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "disableBoundParameters", "deprecated", "query", ".", "useBoundParameters", "."], "add_tokens": "* Causes queryize to insert escaped data directly into the query instead of using data bound placeholders . * This is not recommended and should only be used for debugging purposes . * @ category Data query . disableBoundParameters = function disableBoundParameters ( bool ) { this . _attributes . useBoundParameters = isDefined ( bool ) ? ! bool : false ; return this ; } ; / ** * @ memberOf query * @ deprecated Use disableBoundParameters instead . * @ category Data * @ param { Boolean } bool * @ return { query } Exports ` ` for chaining * / query . useBoundParameters = function ( bool ) { this . disableBoundParameters ( isDefined ( bool ) ? ! bool : true ) ;", "del_tokens": "* Controls if compiled queries should have values replaced with placeholders for * data binding , or simply have escaped values directly in the query . * * By default , queryize will use data binding . Passing false to this function will disable this behavior . query . useBoundParameters = function useBoundParameters ( on ) { this . _attributes . useBoundParameters = isDefined ( on ) ? on : true ;", "commit_type": "add"}
{"commit_tokens": ["Use", "default", "mode", "for", "mkdirSync", "."], "add_tokens": "fs . mkdirSync ( dirname , \"0755\" ) ;", "del_tokens": "fs . mkdirSync ( dirname ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "to", "using", "a", "webserver", "to", "more", "accurately", "run", "tests"], "add_tokens": "/*global require:true*/ var path = require ( \"path\" ) ; } , connect : { server : { options : { port : 9001 , base : path . join ( \"test\" , \"files\" ) } } grunt . loadNpmTasks ( \"grunt-contrib-connect\" ) ; grunt . registerTask ( \"default\" , [ \"jshint\" , \"connect\" , \"nodeunit\" ] ) ;", "del_tokens": "grunt . registerTask ( \"default\" , [ \"jshint\" , \"nodeunit\" ] ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "two", "modules", "into", "container"], "add_tokens": "\"./utils/SPDebugXMLHttpResult\" , \"./value-added/SPFindMMSPicker\" , \"./value-added/SPRequireUnique\" , \"./value-added/SPScriptAudit\" ,", "del_tokens": "\"./value-added/SPRequireUnique\" ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "support", "for", "any", "valid", "ArrayDataView"], "add_tokens": "case 'typedarray' : encode . buffer ( buffers , Buffer . from ( data . buffer , data . byteOffset , data . byteLength ) ) ; break", "del_tokens": "case 'typedarray' : encode . buffer ( buffers , Buffer . from ( data . buffer ) ) ; break", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "relative", "symlinks", "."], "add_tokens": ", sName = compDir + \"/\" + sPath c . name + \".json\"", "del_tokens": ", target = Path . relative ( CWD , compDir + \"/\" + c . name + \".json\" ) , sName = Path . relative ( CWD , compDir + \"/\" + sPath ) console . log ( target , sName ) ; target", "commit_type": "fix"}
{"commit_tokens": ["Adding", "flag", "for", "testing", "image", "magick"], "add_tokens": "smith . set ( { imagemagick : process . env . TEST_IMAGEMAGICK } ) ; }", "del_tokens": "smith . set ( { imagemagick : false } ) ; } , // TODO: Re-enable this // 'running against imagemagick': function () { // smith.set({imagemagick: true}); // }", "commit_type": "add"}
{"commit_tokens": ["add", "modifiers", "prop", "to", "Dropdown", "and", "Tooltip"], "add_tokens": "< vk-dropdown : placement = \"placement\" : modifiers = \"modifiers\" > Dropdown < / vk-dropdown> placement : 'right' , modifiers : { flip : { enabled : false } }", "del_tokens": "< vk-dropdown : placement = \"placement\" > Dropdown < / vk-dropdown> placement : 'right'", "commit_type": "add"}
{"commit_tokens": ["made", "multi", "datepicker", "a", "little", "more", "UI", "friendly"], "add_tokens": "if ( col . isSelected || col . isSelectedEndDate || col . isSelectedMulti ) { // || //(!isMultiSelect && !selectedFullDate && col.isToday) || //(isMultiSelect && !selectedEndDate && col.isToday)) {", "del_tokens": "if ( col . isSelected || col . isSelectedEndDate || col . isSelectedMulti || ( ! isMultiSelect && ! selectedFullDate && col . isToday ) || ( isMultiSelect && ! selectedEndDate && col . isToday ) ) {", "commit_type": "make"}
{"commit_tokens": ["Improve", "code", "that", "handles", "default", "options", "."], "add_tokens": "this . options_ = { } ; goog . object . extend ( this . options_ , this . defaultOptions_ , options || { } ) ; this . logSizeThreshold_ = this . options_ . logSizeThreshold ; this . logMaxTimestampDeltaMillis_ = this . options_ . logMaxTimestampDeltaMillis ; maxFiles : this_ . options_ . loggerMaxFiles , maxsize : this_ . options_ . loggerMaxFileSize maxSockets : this . options_ . httpAgentMaxSockets AppEngine . prototype . defaultOptions_ = { logSizeThreshold : 1024 * 1024 , // 1 MB logMaxTimestampDeltaMillis : 60000 , // 60 seconds loggerMaxFiles : 1 , loggerMaxFileSize : 100 * 1024 * 1024 , // 100 MB httpAgentMaxSockets : 100 } ;", "del_tokens": "this . options_ = options || { } ; this . defaults_ = { logSizeThreshold : 1024 * 1024 , // 1 MB logMaxTimestampDeltaMillis : 60000 , // 60 seconds loggerMaxFiles : 1 , loggerMaxFileSize : 100 * 1024 * 1024 , // 100 MB httpAgentMaxSockets : 100 } ; this . logSizeThreshold_ = this . options_ . logSizeThreshold || this . defaults_ . logSizeThreshold ; this . logMaxTimestampDeltaMillis_ = this . options_ . logMaxTimestampDeltaMillis || this . defaults_ . logMaxTimestampDeltaMillis ; maxFiles : this_ . options_ . loggerMaxFiles || this_ . defaults_ . loggerMaxFiles , maxsize : this_ . options_ . loggerMaxFileSize || this_ . defaults_ . loggerMaxFileSize , maxSockets : this . options_ . httpAgentMaxSockets || this . defaults_ . httpAgentMaxSockets", "commit_type": "improve"}
{"commit_tokens": ["use", "this", "as", "getter", "function", "for", "blocks"], "add_tokens": "return prop . apply ( this . _store . get , args ) ;", "del_tokens": "args . push ( this . _store . get ) ; return prop . apply ( this , args ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "register", "promise", "used", "when", "dynamically", "loading", "messages"], "add_tokens": "import Message from 'gdbots/pbj/message' ; let _registerPromise = null ; / ** * Used when dynamically loading messages . * * @ see self : : registerMap * * @ var Promise * / static registerPromise ( ) { return _registerPromise || Promise . resolve ( true ) ; } if ( value instanceof Message ) { _messages [ message . schema ( ) . getId ( ) . getCurieMajor ( ) ] = message ; } else { promises . push ( SystemUtils . import ( value ) ) ; } _registerPromise = Promise . all ( promises ) . then ( function ( messages ) { _registerPromise = null ;", "del_tokens": "promises . push ( SystemUtils . import ( value ) ) ; Promise . all ( promises ) . then ( function ( messages ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "public", "API", "for", "batchedUpdates"], "add_tokens": "let batchedUpdates ; batchedUpdates = require ( 'react/addons' ) . addons . batchedUpdates ; batchedUpdates = ReactDOM . unstable_batchedUpdates ;", "del_tokens": "const batchedUpdates = require ( 'react/lib/ReactUpdates' ) . batchedUpdates ;", "commit_type": "use"}
{"commit_tokens": ["Made", "new", "SPE", "object", ".", "Updated", "README", "and", "package", ".", "json"], "add_tokens": "var SPE = SPE || { } ; SPE . Emitter = function ( options ) { SPE . Emitter . prototype = { * Update this emitter 's particle' s positions . Called by the SPE . Group // Extend SPE.Emitter's prototype with functions from utils object. for ( var i in SPE . utils ) { SPE . Emitter . prototype [ '_' + i ] = SPE . utils [ i ] ;", "del_tokens": "function ShaderParticleEmitter ( options ) { ShaderParticleEmitter . prototype = { * Update this emitter 's particle' s positions . Called by the ShaderParticleGroup // Extend ShaderParticleEmitter's prototype with functions from utils object. for ( var i in shaderParticleUtils ) { ShaderParticleEmitter . prototype [ '_' + i ] = shaderParticleUtils [ i ] ;", "commit_type": "make"}
{"commit_tokens": ["adds", "option", "menu", "and", "radio", "button", "tests"], "add_tokens": "if ( this . element ) { document . body . removeChild ( this . element ) ; return this ;", "del_tokens": "if ( this . fixture ) { document . body . removeChild ( this . fixture ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "automatic", "positioning", "on", "polygon", "centroids", "and", "symbol", "tooltips"], "add_tokens": "SVGMap . prototype . getLayerPath = function ( layer_id , path_id ) { var me ; me = this ; if ( ( me . layers [ layer_id ] != null ) && me . layers [ layer_id ] . hasPath ( path_id ) ) { return me . layers [ layer_id ] . getPath ( path_id ) ; } return null ; } ; warn ( 'choropleth error: layer \"' + layer_ihad + '\" not found' ) ; MapLayer . prototype . hasPath = function ( id ) { var me ; me = this ; return ( me . pathsById != null ) && ( me . pathsById [ id ] != null ) ; } ; MapLayer . prototype . getPath = function ( id ) { var me ; me = this ; if ( me . hasPath ( id ) ) return me . pathsById [ id ] [ 0 ] ; throw 'path ' + id + ' not found' ; } ; Function . prototype . bind = function ( scope ) { var _func ; _func = this ; return function ( ) { return _func . apply ( scope , arguments ) ; } ; } ;", "del_tokens": "warn ( 'choropleth error: layer \"' + layer_id + '\" not found' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "some", "old", "callback", "references", "from", "the", "deferred", ".", "promise", "refactor", "."], "add_tokens": "logger . write = function ( type , category , message ) {", "del_tokens": "logger . write = function ( type , category , message , cb ) { cb . call ( this , ( result != null ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "about", "userContext", "of", "Spec", ".", "There", "was", "an", "issue", "when", "Spec", "was", "embedded", "."], "add_tokens": "var spec = this . env [ api ] . call ( this . env , desc , ( function ( done ) { fn . call ( this ) ; } ) . bind ( this . env . userContext ) , timeout ) ;", "del_tokens": "var spec = this . env [ api ] . call ( this . env , desc , function ( done ) { fn . call ( this . userContext ) ; } , timeout ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "GroupJoin", "+", "tests", "+", "doc"], "add_tokens": "* @ function Collection . From function From ( iterable ) { / ** * Represents a empty Collection , e . g . Collection . Empty . ToArray ( ) - > [ ] * * @ name Collection . Empty * @ static * / const collectionStaticMethods = { From , from : From , Range , Repeat }", "del_tokens": "* @ function from function from ( iterable ) { const collectionStaticMethods = { from , From : from , Range , Repeat }", "commit_type": "implement"}
{"commit_tokens": ["add", "support", "for", "search", "query", "analytics", "[", "wip", "]"], "add_tokens": "export function addComponent ( component , name = null ) { name ,", "del_tokens": "export function addComponent ( component ) {", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "we", "export", "the", "right", "thing"], "add_tokens": "const { assign , create , hasOwnProperty } = Object ; const { apply } = Reflect ; let config = create ( null ) ; create ( null ) , let name = ` ${ optionsForFile . name || 'template' } ` ; if ( ! / ^\\w+$ / . test ( name ) ) { name = 'template' ; optionsForFile . name = name ; } if ( apply ( hasOwnProperty , pugOptions , [ '__proto__' ] ) ) { // __proto__ interacts badly with Object.assign throw new Error ( ) ; }", "del_tokens": "const { assign } = Object ; let config = { } ; { } , const name = optionsForFile . name || 'template' ;", "commit_type": "make"}
{"commit_tokens": ["adding", "maxout", "activation", "neurons", ".", "They", "take", "a", "set", "of", "input", "neurons", "and", "max", "over", "groups", "of", "them", ".", "In", "a", "convnet", "this", "happens", "only", "along", "depth", "preserving", "spatial", "dimensions", "x", "y", ".", "The", "group", "size", "can", "be", "adjusted", "as", "a", "parameter", ".", "Feel", "free", "to", "try", "them", "out", "instead", "of", "sigmoid", "or", "relu!", "maxouts", "have", "very", "nice", "properties", "in", "that", "they", "are", "safe", "to", "train", "compared", "to", "relus", "that", "can", "die", "and", "sigmoids", "that", "can", "take", "very", "long", "to", "train", "."], "add_tokens": "if ( ( def . type === 'fc' || def . type === 'conv' ) else if ( def . activation === 'maxout' ) { // create maxout activation, and pass along group size, if provided var gs = def . group_size !== 'undefined' ? def . group_size : 2 ; new_defs . push ( { type : 'maxout' , group_size : gs } ) ; } case 'maxout' : this . layers . push ( new global . MaxoutLayer ( def ) ) ; break ; if ( t === 'maxout' ) { L = new global . MaxoutLayer ( ) ; }", "del_tokens": "if ( ( def . type === 'fc' || def . type === 'conv' || def . type === 'local' )", "commit_type": "add"}
{"commit_tokens": ["updated", "web", "-", "sdk", "submodule", "and", "rebuilt", "with", "logout", "fix"], "add_tokens": "app . branch_key = \"key_test_hdiu9rtcwDTTZy8PPw3sylhewveqJnUu\" ;", "del_tokens": "app . branch_key = \"key_live_hohBTjb6eJS9jou8Tl1kIhddokjfbXJF\" ;", "commit_type": "update"}
{"commit_tokens": ["Add", "ability", "to", "toggle", "visibility", "with", "show", "/", "hide", "functions"], "add_tokens": "hide : function ( el , mode ) { if ( ! mode ) mode = 'display' ; storeDisplayStyle ( el , mode ) ; hide ( el , mode ) ; show : function ( el , mode ) { if ( ! mode ) mode = 'display' ; show ( el , mode ) ; function storeDisplayStyle ( el , mode ) { dom . setAttribute ( el , 'data-anddom-' + mode , el . style [ mode ] ) ; function show ( el , mode ) { el . style [ mode ] = dom . getAttribute ( el , 'data-anddom-' + mode ) || '' ; function hide ( el , mode ) { el . style [ mode ] = ( mode === 'visibility' ? 'hidden' : 'none' ) ;", "del_tokens": "hide : function ( el ) { storeDisplayStyle ( el ) ; hide ( el ) ; show : function ( el ) { show ( el ) ; function storeDisplayStyle ( el ) { dom . setAttribute ( el , 'data-anddom-display' , el . style . display ) ; function show ( el ) { el . style . display = dom . getAttribute ( el , 'data-anddom-display' ) || '' ; function hide ( el ) { el . style . display = 'none' ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "new", "control", "Spinner", "that", "allows", "the", "user", "to", "chose", "from", "a", "range", "of", "possible", "choices", "."], "add_tokens": "Version 1.1 .6 version : \"1.1.6\" , ancestorByTag : function ( selector ) { return this . ancestor ( selector ) ; } , ancestorByClass : function ( selector ) { selector = \".\" + selector ; return this . ancestor ( selector ) ; } , ancestorByPosition : function ( position ) { return this . ancestor ( position ) ; } , var key = key . camelize ( ) ; } else { } } , camelize : function ( ) { return this . replace ( / \\-(.) / g , function ( m , l ) { return l . toUpperCase ( ) } ) ; } , deCamelize : function ( ) { return this . replace ( / ([A-Z]) / g , '-$1' ) . toLowerCase ( ) ; ios : / ip(hone|od|ad) / i . test ( navigator . userAgent ) ,", "del_tokens": "Version 1.1 .5 version : \"1.1.5\" , } else { } ios : $ . iphone || $ . ipad || $ . ipod ,", "commit_type": "add"}
{"commit_tokens": ["Add", "sizes", "to", "TextInput", "component"], "add_tokens": "size : PropTypes . oneOf ( [ 'small' , 'medium' , 'large' ] ) , style : 'default' , size : 'medium'", "del_tokens": "size : PropTypes . oneOf ( [ 'small' , 'large' ] ) , style : 'default'", "commit_type": "add"}
{"commit_tokens": ["Changed", "benchmark", "to", "mocha", "test"], "add_tokens": "var myStringify = require ( '../index' ) , data = require ( \"../fixtures/index\" ) . input ;", "del_tokens": "var myStringify = require ( '../' ) , data = require ( \"../fixtures\" ) . input ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "issue", "where", "auto", "filter", "wasn", "t", "being", "applied"], "add_tokens": "var opts = opts ? opts : { } ; thisWB . opts = { } ; thisWB . opts . jszip = { } ; thisWB . opts . jszip . compression = 'DEFLATE' ; if ( opts . jszip ) { Object . keys ( opts . jszip ) . forEach ( function ( k ) { thisWB . opts . jszip [ k ] = opts . jszip . compression ; } ) ; } ; console . log ( thisWB . opts . jszip . compression ) ; return xlsx . generate ( { type : \"nodebuffer\" , compression : thisWB . opts . jszip . compression } ) ;", "del_tokens": "return xlsx . generate ( { type : \"nodebuffer\" } ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "dyno", "throughput", "retries", "default", "to", "off"], "add_tokens": "var defaultAttempts = config . retryAggressively ? 24 : 0 ; Math . min ( opts . throughputAttempts , 24 ) : defaultAttempts ;", "del_tokens": "Math . min ( opts . throughputAttempts , 24 ) : 24 ;", "commit_type": "make"}
{"commit_tokens": ["Update", "example", "and", "remove", "repeated", "files"], "add_tokens": "const image = path . resolve ( __dirname , '../../tests/assets/images/cosmic.png' ) ;", "del_tokens": "const image = path . resolve ( __dirname , 'cosmic.png' ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "all", "browsers", "work", "with", "native", "component", "model"], "add_tokens": "//TODO: make universal trigger: jquery/chrome/ie/etc compatible //self.dispatchEvent(new CustomEvent(\"create\")); //this.dispatchEvent(new CustomEvent(\"dragstart\", this.dragstate)) //this.dispatchEvent(new CustomEvent(\"change\", this.dragstate)) //this.dispatchEvent(new CustomEvent(\"drag\", this.dragstate)) //this.dispatchEvent(new CustomEvent(\"change\", this.dragstate)) //this.dispatchEvent(new CustomEvent(\"dragstop\", this.dragstate));", "del_tokens": "self . dispatchEvent ( new CustomEvent ( \"create\" ) ) ; this . dispatchEvent ( new CustomEvent ( \"dragstart\" , this . dragstate ) ) this . dispatchEvent ( new CustomEvent ( \"change\" , this . dragstate ) ) this . dispatchEvent ( new CustomEvent ( \"drag\" , this . dragstate ) ) this . dispatchEvent ( new CustomEvent ( \"change\" , this . dragstate ) ) this . dispatchEvent ( new CustomEvent ( \"dragstop\" , this . dragstate ) ) ;", "commit_type": "make"}
{"commit_tokens": ["upgraded", "npm", "packages", "fixed", "a", "test", "to", "suit", "newer", "asmcrypto", ".", "js"], "add_tokens": "* * // Extend timeout, this test takes longer. this . timeout ( 50000 ) ;", "del_tokens": "* *", "commit_type": "upgrade"}
{"commit_tokens": ["fix", "enoent", "in", "travis", "readme", "updates"], "add_tokens": "fs . writeFileSync ( filePath , '' ) ; logTransports . push ( new ( winston . transports . File ) ( { filename : filePath } ) ) ;", "del_tokens": "fs . openSync ( filePath , 'a+' ) ; logTransports . push ( new ( winston . transports . File ) ( { filename : filePath } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "could", "cause", "the", "application", "to", "crash", "in", "case", "of", "parsing", "error", "."], "add_tokens": "try { var func = new Function ( \"$template\" , \"$tools\" , \"_\" , \"$data\" , \"$helpers\" , \"$callback\" , compiled ) ; } catch ( err ) { return callback ( err ) ; }", "del_tokens": "var func = new Function ( \"$template\" , \"$tools\" , \"_\" , \"$data\" , \"$helpers\" , \"$callback\" , compiled ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "pos", "param", "to", "move", "and", "clone", "calls"], "add_tokens": "* @ param pos { ( String | Number ) } The position to place the list , possible values are \"top\" , \"bottom\" , or a positive floating point number moveList ( listId , toBoardId , toListName , pos = 'bottom' ) { return this . _client . put ( ` ${ listId } ${ toListName } ${ toBoardId } ${ pos } ` ) ; * @ param pos { ( String | Number ) } The position to place the list , possible values are \"top\" , \"bottom\" , or a positive floating point number copyList ( listId , toBoardId , toListName , pos = 'bottom' ) { return this . _client . post ( ` ${ encodeURIComponent ( toListName ) } ${ toBoardId } ${ fromListId } ${ pos } ` ) ;", "del_tokens": "moveList ( listId , toBoardId , toListName ) { return this . _client . put ( ` ${ listId } ${ toListName } ${ toBoardId } ` ) ; copyList ( listId , toBoardId , toListName ) { return this . _client . post ( ` ${ encodeURIComponent ( toListName ) } ${ toBoardId } ${ fromListId } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "roles", "and", "db", "scripts"], "add_tokens": "var onSQLResult = function ( err , rslt , sql ) {", "del_tokens": "var onSQLResult = function ( err , rslt ) {", "commit_type": "update"}
{"commit_tokens": ["Allow", "custom", "page", "types", "to", "be", "defined", "in", "search", "config"], "add_tokens": "// Check for special page types for ( var t in this . searchOptions . pageTypes ) { var func = this . searchOptions . pageTypes [ t ] ; if ( func ( item ) ) { type = t ; }", "del_tokens": "// This is a special one that Foundation uses // [TODO] Find a way to make it generic if ( item . library ) { type = 'library' ;", "commit_type": "allow"}
{"commit_tokens": ["added", "file", "check", "before", "installing", "gulp"], "add_tokens": "process . stdout . write ( colors . magenta ( 'Setting up hot reloading with gulp and borwser-sync...\\n' ) ) ; if ( ! fs . existsSync ( path . join ( process . cwd ( ) , 'node_modules/gulp' ) ) ) { exec ( ` ` , ( err , stdout ) => { if ( err ) process . stderr . write ( colors . white ( err ) ) ; process . stdout . write ( stdout ) ; } ) ; }", "del_tokens": "process . stdout . write ( colors . magenta ( 'Setting up hot reloading with gulp and browser-sync...\\n' ) ) ; exec ( ` ` , ( err , stdout ) => { if ( err ) process . stderr . write ( colors . white ( err ) ) ; process . stdout . write ( stdout ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "git", "progress", "from", "console", "output"], "add_tokens": "console . log ( 'Creating %s example in %s (this may take a moment)' , type , name ) ; var command = 'git clone --quiet --depth 1 git@github.com:strongloop/' + repo + '.git ' + name ; console . error ( 'git exited with code %s (`%s`)' , exitCode , command ) ;", "del_tokens": "console . log ( 'Downloading %s example into %s' , type , name ) ; var command = 'git clone --depth 1 git@github.com:strongloop/' + repo + '.git ' + name ; console . error ( 'git exited with code %s' , exitCode ) ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "info", "window", "interporation", "marks", "from", "{{", "to", "[[", "so", "that", "AngularJS"], "add_tokens": "var matches = contents . match ( / \\[\\[[^\\]]+\\]\\] / g ) var expression = matches [ i ] . replace ( / \\[\\[ / , '' ) . replace ( / \\]\\] / , '' ) ;", "del_tokens": "var matches = contents . match ( / {{[^}]+}} / g ) var expression = matches [ i ] . replace ( / {{ / , '' ) . replace ( / }} / , '' ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "up", "disqus", "tweaking", "events"], "add_tokens": "$scope . discussionsEnabled = config . discussions && config . discussions . shortName ; $scope . discussions = config . discussions ; path : '#!/documentation/' + item . path + '/index' path : '#!/documentation/' + group . path + '/docApi/' + parentItem [ 0 ] . root + '/' + parentItem [ 0 ] . id", "del_tokens": "path : '#/documentation/' + item . path + '/index' path : '#/documentation/' + group . path + '/docApi/' + parentItem [ 0 ] . root + '/' + parentItem [ 0 ] . id", "commit_type": "fix"}
{"commit_tokens": ["added", "warning", "for", "readPoints", "()", "in", "development", "moment", ".", "updated", "docs", "increased", "timeout", "in", "tests", "for", "deleteDatabase", "()"], "add_tokens": "host : host || 'localhost' , port : port || 8086 , username : username || 'root' , password : password || 'root' , database : database , devmode : 'development' == process . env . NODE_ENV if ( this . options . devmode ) console . log ( 'influx.readPoints() has been depreciated, please use influx.query()' ) ;", "del_tokens": "host : host || 'localhost' , port : port || 8086 , username : username || 'root' , password : password || 'root' , database : database", "commit_type": "add"}
{"commit_tokens": ["Changed", "useBundlePath", "so", "that", "defaults", "to", "OFF", "for", "devmode", "and", "ON", "for", "non", "-", "devmode", "."], "add_tokens": "this . useBundlePath = ! opt . devmode ; // useBundlePath is already set from the bincmd cli args for devmode.", "del_tokens": "this . useBundlePath = false ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "debug", "-", "TLS", "cleanup"], "add_tokens": "//module.exports.tls_ecc(protocol) basicCrypto ( \"ecc\" , protocol , ( opt , host , port , cert , ready , cb ) => { stream = tls . connect ( { host , port , stream = tls . connect ( { host , port ,", "del_tokens": "module . exports . tls_ecc ( protocol ) basicCrypto ( \"ecc\" , protocol , ( opt , socket , cert , ready , cb ) => { stream = new tls . TLSSocket ( socket , { stream = tls . connect ( socket , {", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "all", "linter", "errors", "."], "add_tokens": "target : [ 'Gruntfile.js' , 'angular-poller.js' , 'test/*.js' ] 'angular-poller.js' , 'test/*.js' grunt . registerTask ( 'develop' , [ 'jshint' , 'jscs' , 'karma:develop' ] ) ; grunt . registerTask ( 'test' , [ 'jshint' , 'jscs' , 'karma:continuous' , 'coveralls' ] ) ; grunt . registerTask ( 'default' , [ 'test' , 'ngAnnotate' , 'uglify' ] ) ;", "del_tokens": "target : [ 'Gruntfile.js' , 'angular-poller.js' , 'test/*.js' ] 'angular-poller.js' , 'karma.config.js' , 'test/**/*.js' grunt . registerTask ( 'develop' , [ 'jshint' , 'jscs' , 'karma:develop' ] ) ; grunt . registerTask ( 'test' , [ 'jshint' , 'jscs' , 'karma:continuous' , 'coveralls' ] ) ; grunt . registerTask ( 'default' , [ 'test' , 'ngAnnotate' , 'uglify' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "to", "plask", "-", "wrap", "to", "avoid", "-", "i", "plask", "browserify", "flag"], "add_tokens": "var plask = require ( 'plask-wrap' ) ;", "del_tokens": "var plask = isPlask ? require ( 'plask' ) : { } ;", "commit_type": "move"}
{"commit_tokens": ["Add", "terminal", "/", "console", "output"], "add_tokens": "await output ( fixture , console )", "del_tokens": "await output ( lena , console )", "commit_type": "add"}
{"commit_tokens": ["add", "newline", "at", "the", "end"], "add_tokens": "}", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["move", "test", "-", "cases", "to", "test", "/", "cases"], "add_tokens": "var createCases = require ( \"../../test/cases/database\" ) ;", "del_tokens": "var createCases = require ( \"../../test-cases/database\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "proper", "initial", "load", "with", "value"], "add_tokens": "//adopt passed options //it may contain value/min/max, so create picker later extend ( self , options ) ; //picker value should be inited after picker is added to pickers list //because setting value triggers callback, which should get full-featured env self . picker . value = this . value ; var el = document . createElement ( 'div' ) ; //need to be appended before to bubble events this . element . appendChild ( el ) ; var picker = new Picker ( el , options ) ;", "del_tokens": "//adopt passed options extend ( self , options ) ; * @ type { number } Object . defineProperties ( proto , { /** Set or get value of active picker */ value : { get : function ( ) { return this . picker . value ; } , set : function ( value ) { this . picker . value = value ; } } , /** Set or get list of values for pickers */ values : { get : function ( ) { return this . pickers . map ( function ( picker ) { return picker . value ; } ) ; } , set : function ( values ) { values . forEach ( function ( value , i ) { this . pickers [ i ] . value = value ; } ) ; } } } ) ; var picker = new Picker ( null , options ) ; this . element . appendChild ( picker . element ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "process", ".", "stdout", ".", "isTTY", "in", "the", "basic", "example", "."], "add_tokens": "if ( ! process . stdout . isTTY ) {", "del_tokens": "if ( ! require ( 'tty' ) . isatty ( process . stdout . fd ) ) {", "commit_type": "use"}
{"commit_tokens": ["make", "zone", "part", "of", "the", "fromObject", "object"], "add_tokens": "example ( \"DateTime.fromObject({year: 2017, month: 5, day: 15, hour: 17, minute: 36, zone: 'America/New_York' })\" ) ; example ( \"DateTime.fromObject({year: 2017, month: 5, day: 15, hour: 17, minute: 36, zone: 'Asia/Singapore' })\" ) ;", "del_tokens": "example ( \"DateTime.fromObject({year: 2017, month: 5, day: 15, hour: 17, minute: 36}, 'America/New_York')\" ) ; example ( \"DateTime.fromObject({year: 2017, month: 5, day: 15, hour: 17, minute: 36}, 'Asia/Singapore')\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "local", "babel", "in", "babel", "-", "plugin", "-", "espower"], "add_tokens": "var options = { blacklist : hasGenerators ? [ 'regenerator' ] : [ ] , optional : hasGenerators ? [ 'asyncToGenerator' , 'runtime' ] : [ 'runtime' ] , plugins : [ createEspowerPlugin ( babel , { patterns : require ( './enhance-assert' ) . PATTERNS } ) ] } ;", "del_tokens": "var options = { blacklist : hasGenerators ? [ 'regenerator' ] : [ ] , optional : hasGenerators ? [ 'asyncToGenerator' , 'runtime' ] : [ 'runtime' ] , plugins : [ createEspowerPlugin ( require ( 'babel-core' ) , { patterns : require ( './enhance-assert' ) . PATTERNS } ) ] } ;", "commit_type": "use"}
{"commit_tokens": ["Added", "clean", "fixed", "docco", "defs", "."], "add_tokens": "clean : { app : { src : [ \"dist\" , \"docs\" ] } } , app : { src : [ '**/*.coffee' , '**/*.js' ] } grunt . registerTask ( 'default' , 'clean lint docco coffee concat min' ) ;", "del_tokens": "files : [ 'src/**/*' ] grunt . loadNpmTasks ( 'grunt-coffee' ) ; grunt . registerTask ( 'default' , 'lint coffee concat min' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "event", "behavior", "of", "PropertyArray", "Methods", "."], "add_tokens": "this . _prop . trigger ( eventProxy . eventType . CHILD_CREATED , pushArgs ) ; if ( args . length > 2 ) { // we are adding new elements var added = args . slice ( 2 ) ; this . _prop . trigger ( eventProxy . eventType . CHILD_CREATED , added ) ; // TODO use count to determin if should be called } return removed ; //splice returns array of removed elements", "del_tokens": "this . _prop . trigger ( eventProxy . eventType . CHILD_CREATED , args ) ; // A little more difficult!! this . _prop . trigger ( eventProxy . eventType . CHILD_CREATED ) ; // TODO use count to determin if should be called return removed ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "hasContent", "method", "for", "inputAssistance", "rules"], "add_tokens": "if ( ! dom . $ ( this ) . val ( ) && ! dom . $ ( this ) . text ( ) ) {", "del_tokens": "if ( ! dom . $ ( this ) . val ( ) ) {", "commit_type": "improve"}
{"commit_tokens": ["Add", "basic", "test", "cases", "for", "requiredIf", ".", "Or", "parameter"], "add_tokens": "const equalInput = mapping => { const equalInput = mappingKey => { return _ . get ( mappingKey , inputObj ) === _ . get ( mappingKey , this . mappings ) ; return _ . some ( equalInput , _ . keys ( this . mappings ) ) ; if ( ( shouldUseSatisfied ( targetProperty ) && targetProperty . satisfied ( inputObj ) ) ) { return required . validate ( val ) ; } if ( ! _ . isUndefined ( inputObj [ targetProperty ] ) && inputObj [ targetProperty ] === ruleObj . params [ 1 ] ) {", "del_tokens": "const equalInput = function ( mapping ) { const equalInput = function ( mapping ) { return _ . get ( mapping . key , inputObj ) === mapping . value ; return _ . some ( equalInput , this . mappings ) ; if ( ( shouldUseSatisfied ( targetProperty ) && targetProperty . satisfied ( inputObj ) ) || ( inputObj [ targetProperty ] === ruleObj . params [ 1 ] ) ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "set", "config", "path", "environment", "variable", "."], "add_tokens": "path = require ( 'path' ) ; process . env . SPROUT_CONFIG_PATH = path . join ( __dirname , '.config' , 'sprout' ) var sprout = require ( '../..' ) , should = chai . should ( ) ;", "del_tokens": "path = require ( 'path' ) , sprout = require ( '../..' ) ; var should = chai . should ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "requireIndex", "which", "seems", "unreliable"], "add_tokens": "module . exports = { rules : { 'jsx-no-invalid-props' : require ( './rules/jsx-no-invalid-props' ) } } ;", "del_tokens": "//------------------------------------------------------------------------------ // Requirements //------------------------------------------------------------------------------ var requireIndex = require ( \"requireindex\" ) ; module . exports . rules = requireIndex ( \"./rules\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "duplicate", "update", "messages", "from", "Services", "."], "add_tokens": "if ( self . services [ name ] . update ( service . data ) ) { self . emit ( 'update' , name , self . services [ name ] , reason ) ; } else { debug ( 'Data unchanged, ignoring.' ) ; } if ( self . services [ name ] . available ) { debug ( 'Already considered available, ignoring.' ) ; return ; } if ( self . services [ name ] ) { if ( self . services [ name ] . available ) { self . services [ name ] . available = false ; } else { debug ( 'Already considered unavailable, ignoring.' ) ; return ; } } else { service . available = false ; self . services [ name ] = new Service ( service ) ; }", "del_tokens": "self . services [ name ] . update ( service . data ) ; self . emit ( 'update' , name , self . services [ name ] , reason ) ; self . services [ name ] . available = false ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "multi", "-", "line", "comments"], "add_tokens": "/ * Old built - ins may appear in conditional requires which will lead to inclusion in the graph . This examples shows that filtered built - ins , old or new are ignored . This doesn ' because it ' * /", "del_tokens": "// Old built-ins may appear in conditional requires // which will lead to inclusion in the graph. // This examples shows that filtered built-ins, // old or new are ignored. // // This doesn't belong in \"project-conditional\" // because it's specifically testing filter semantics.", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "passing", "a", "url", "prop", "on", "initial", "render", "(", "useful", "for", "server", "-", "rendering", ")", "/", "cc", "@impronunciable"], "add_tokens": "constructor ( props ) { super ( ) ; this . state = { url : props . url || getCurrentUrl ( ) } ;", "del_tokens": "getInitialState ( ) { return { url : getCurrentUrl ( ) } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "append", "timestamp", "to", "generated", "report", "filename", "."], "add_tokens": "var basename = path . basename ( opts . reportFilename , '.html' ) ; var filename = basename + ( ( opts . uniqueFilename ) ? Date . now ( ) : '' ) + '.html' ; var outputPath = path . join ( opts . reportsDirectory , filename ) ; fs . writeFile ( outputPath , html , function ( err ) { callback ( err , outputPath , html , testRun ) ; callback ( null , outputPath , html , testRun ) ; return outputPath ;", "del_tokens": "var filename = path . join ( opts . reportsDirectory , opts . reportFilename ) ; fs . writeFile ( filename , html , function ( err ) { callback ( err , filename , html , testRun ) ; callback ( null , filename , html , testRun ) ; return filename ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ID", "and", "image", "to", "all", "scrapes"], "add_tokens": "function cardIdFromUrl ( url ) { return url . match ( new RegExp ( \"/(\\\\w+/\\\\w+)/$\" ) ) [ 1 ] ; } var url = Url . resolve ( SCRAPE_URL , $card . find ( \"a\" ) . attr ( \"href\" ) ) ; url : url , image : Url . resolve ( SCRAPE_URL , $card . find ( \"img\" ) . attr ( \"src\" ) ) , id : cardIdFromUrl ( url ) //Add the ID because we don't need the actual page for that card . id = cardIdFromUrl ( url ) ; //Scrape the image var $img = $ ( \".card-image>img\" ) ; card . image = Url . resolve ( url , $img . attr ( 'src' ) ) ;", "del_tokens": "url : Url . resolve ( SCRAPE_URL , $card . find ( \"a\" ) . attr ( \"href\" ) ) , image : Url . resolve ( SCRAPE_URL , $card . find ( \"img\" ) . attr ( \"src\" ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "multiple", "issues", "when", "trying", "to", "import", "this", "module"], "add_tokens": "// The usage of the commonjs exporting syntax instead of the new ECMAScript // one is actually inteded and prevents weird behaviour if we are trying to // import this module in another module using Babel. module . exports = {", "del_tokens": "export {", "commit_type": "fix"}
{"commit_tokens": ["Added", "parent", "and", "childs", "properties", "to", "ActionManager"], "add_tokens": "constructor ( context , parent = null ) { this . _parent = parent ; this . _childs = [ ] ; if ( parent !== null ) { parent . childs . push ( this ) ; } get childs ( ) { return this . _childs ; } get parent ( ) { return this . _parent ; }", "del_tokens": "constructor ( context ) {", "commit_type": "add"}
{"commit_tokens": ["updated", "deps", "and", "lint", "code"], "add_tokens": "reducer . on = function on ( type , transition ) { payload : payloadReducer . apply ( undefined , arguments ) if ( arguments . length === 1 && arguments [ 0 ] instanceof Error ) { action . meta = metaReducer . apply ( undefined , arguments ) ;", "del_tokens": "reducer . on = function ( type , transition ) { for ( var _len = arguments . length , args = Array ( _len ) , _key = 0 ; _key < _len ; _key ++ ) { args [ _key ] = arguments [ _key ] ; } payload : payloadReducer . apply ( undefined , args ) if ( args . length === 1 && args [ 0 ] instanceof Error ) { action . meta = metaReducer . apply ( undefined , args ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "test", "suite", "for", "numeric"], "add_tokens": "} ) , new CustomType ( { context : { } , func : function ( object , context ) { if ( object . length != 3 ) { return new Error ( 'field must have 3 characters' ) ; } } assert . equal ( 2 , results . length ) ; assert . equal ( 'field must have 3 characters' , results [ 1 ] . message ) ; assert . equal ( 'object.field' , results [ 1 ] . path ) ; assert . equal ( '' , results [ 1 ] . value ) ; assert . ok ( results [ 1 ] . rule instanceof DocumentType ) ;", "del_tokens": "assert . equal ( 1 , results . length ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "period", "to", "the", "ignored", "character", "list"], "add_tokens": "return name . replace ( / [^\\w-_.] / g , '' ) . trim ( ) console . log ( res )", "del_tokens": "return name . replace ( / [^\\w-_] / g , '' ) . trim ( )", "commit_type": "add"}
{"commit_tokens": ["Use", "cheerio", "for", "html", "dom", "comparison"], "add_tokens": "cheerio = require ( 'cheerio' ) , actual : cheerio . load ( grunt . file . read ( grunt . file . expand ( 'tmp/' + path ) [ 0 ] ) ) . html ( ) , expected : cheerio . load ( grunt . file . read ( grunt . file . expand ( 'test/expected/' + path ) [ 0 ] ) ) . html ( ) ,", "del_tokens": "actual : grunt . file . read ( grunt . file . expand ( 'tmp/' + path ) [ 0 ] ) , expected : grunt . file . read ( grunt . file . expand ( 'test/expected/' + path ) [ 0 ] ) ,", "commit_type": "use"}
{"commit_tokens": ["makes", "submenu", "links", "clickable", "anywhere", "in", "the", "menuitem"], "add_tokens": "/ ** * TODO : Handle submenus ( other than menu ) of topbar * / . on ( 'click' , '[role=\"menuitem\"]' , function ( e ) { if ( $trigger . attr ( 'aria-controls' ) ) { toggleSubmenu ( $trigger , function ( $submenu , done ) { // TODO: CSS Transition? $submenu . slideToggle ( ) ; $trigger . toggleClass ( 'dqpl-weight-bold' ) ; setTimeout ( done ) ; } ) ; } else { var $link = $trigger . find ( 'a' ) ; if ( $link . length ) { $link [ 0 ] . click ( ) ; } }", "del_tokens": "// top level side bar menu items var $sideMenuTopLevels = findTopLevels ( $menu ) ; . on ( 'click' , '[role=\"menuitem\"][aria-controls]' , function ( e ) { toggleSubmenu ( $trigger , function ( $submenu , done ) { // TODO: CSS Transition? $submenu . slideToggle ( ) ; $trigger . toggleClass ( 'dqpl-weight-bold' ) ; setTimeout ( done ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "jshint", "and", "jscs", "to", "test"], "add_tokens": "grunt . registerTask ( 'test' , [ 'clean' , 'jshint' , 'jscs' , 'px_to_rem' , 'nodeunit' ] ) ;", "del_tokens": "grunt . registerTask ( 'test' , [ 'clean' , 'px_to_rem' , 'nodeunit' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "tests", "to", "use", "new", "mutacc", "definitions", "."], "add_tokens": "context . entities ( hostsEntity ) ; ok ( ct . entities ( ) [ 0 ] . context ( ) . id ( ) === ct . id ( ) , \"Navigating relationships succeeded.\" ) ; hostsEntity . properties ( properties ) ; ok ( hostsEntity . properties ( ) . length === 4 , \"4 properties added.\" ) ;", "del_tokens": "context . add_entities ( hostsEntity ) ; ok ( ct . get_entities ( ) [ 0 ] . get_context ( ) . id ( ) === ct . id ( ) , \"Navigating relationships succeeded.\" ) ; hostsEntity . add_properties ( properties ) ; ok ( hostsEntity . get_properties ( ) . length === 4 , \"4 properties added.\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Move", "stringlength", "to", "utils", "and", "use", "everywhere", "for", "correct", "cell", "maxlen", "when", "multiple", "cells", "are", "colored", "."], "add_tokens": ": ( ( typeof cell == 'object' ? utils . strlen ( cell . text ) : utils . strlen ( cell ) ) + ( style [ 'padding-left' ] || 0 ) + ( style [ 'padding-right' ] || 0 ) ) , length = utils . strlen ( str ) ? pad ( str , ( width + ( str . length - length ) ) , ' ' , align == 'left' ? 'right' :", "del_tokens": ": ( ( typeof cell == 'object' ? String ( cell . text ) : String ( cell ) ) . length + ( style [ 'padding-left' ] || 0 ) + ( style [ 'padding-right' ] || 0 ) ) , length = str . length // // For consideration of terminal \"color\" programs like colors.js, // which can add ANSI escape color codes to strings, // we destyle the ANSI color escape codes for padding calculations. // // see: http://en.wikipedia.org/wiki/ANSI_escape_code // var code = / \\u001b\\[\\d+m / g ; var stripped = ( \"\" + str ) . replace ( code , '' ) ; length = stripped . length ; ? pad ( str , ( width + ( str . length - stripped . length ) ) , ' ' , align == 'left' ? 'right' :", "commit_type": "move"}
{"commit_tokens": ["adding", "Ember", ".", "instrument", "to", "test", "performance", ";", "introducing", "enableProfiling", "function", "&", "Ember", ".", "ENABLE_PROFILING"], "add_tokens": "Ember . instrument ( 'view.updateContext' , null , function ( ) { Ember . instrument ( 'view.updateContext.render' , null , function ( ) { set ( this , 'context' , newContext ) ; } , this ) ; Ember . instrument ( 'view.updateContext.reposition' , null , function ( ) { } , this ) ;", "del_tokens": "Ember . instrument ( 'updateContext' , this , function ( ) { set ( this , 'context' , newContext ) ; Ember . instrument ( 'updateContext.render' , this , function ( ) { } , this ) ; console . log ( 'render' ) ; Ember . instrument ( 'updateContext.reposition' , this , function ( ) { } , this ) ; console . log ( 'repositions' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "comments", "remove", "unused", "code"], "add_tokens": "// Discover conflicts (i.e. two statements in separate modules both define `foo`) // Rename conflicting identifiers so they can live in the same scope // Apply new names", "del_tokens": "getSafeReplacement ( name , requestingModule ) { // assume name is safe until proven otherwise let safe = true ; name = sanitize ( name ) ; let pathParts = requestingModule . relativePath . split ( sep ) ; do { let safe = true ; let i = this . modulesArray . length ; while ( safe && i -- ) { const module = this . modulesArray [ i ] ; if ( module === requestingModule ) continue ; let j = module . definedNames . length ; while ( safe && j -- ) { if ( module . definedNames [ j ] === name ) { safe = false ; } } } if ( ! safe ) { if ( pathParts . length ) { name = sanitize ( pathParts . pop ( ) ) + ` ${ name } ` ; } else { name = ` ${ name } ` ; } } } while ( ! safe ) ; return name ; }", "commit_type": "add"}
{"commit_tokens": ["add", "secondary", "configuration", "file", "to", "sockbot", "this", "one", "is", "excluded", "from", "git", "via", "gitignore"], "add_tokens": "function getAlt ( ) { try { return require ( './.SockBot.conf.json' ) ; } catch ( e ) { console . warn ( 'Alternate conf file not found: ' + e ) ; return { } ; } } exports . configuration = merge ( def , conf , getAlt ( ) ) ;", "del_tokens": "exports . configuration = merge ( def , conf ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "tapkick", "example", "to", "deploy", "specific", "revision"], "add_tokens": "var opts = { cwd : stack . config . tapkick_dir , env : process . env } ; async . series ( [ function fetch ( callback ) { misc . taskSpawn ( baton , args , [ 'git' , 'fetch' ] , opts , callback ) ; } , function checkout ( callback ) { misc . taskSpawn ( baton , args , [ 'git' , 'checkout' , args . revision ] , opts , callback ) ; ] , callback ) ;", "del_tokens": "var cmd = [ 'git' , 'pull' , 'origin' , 'master' ] , opts = { cwd : stack . config . tapkick_dir , env : process . env } ; misc . taskSpawn ( baton , args , cmd , opts , function ( err , stdout , stderr ) { if ( ! err ) { baton . log . info ( 'ran git pull' ) ; callback ( err ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Upgraded", "module", "light", ".", "js", "from", "requiring", "witness_proof", ".", "js", "to", "witness_pow_proof", ".", "js", "and", "two", "associated", "functions", "were", "upgraded", "by", "the", "way", "."], "add_tokens": "var witnessPowProof = require ( './witness_pow_proof.js' ) ; witnessPowProof . preparePowWitnessProof ( 0 , function ( err , arrUnstableMcJoints , last_ball_unit , last_ball_mci ) // POW DEL //function(err, arrUnstableMcJoints, arrWitnessChangeAndDefinitionJoints, last_ball_unit, last_ball_mci) { / ** * POW DEL * @ author XING * / // if (arrWitnessChangeAndDefinitionJoints.length > 0) // objResponse.witness_change_and_definition_joints = arrWitnessChangeAndDefinitionJoints; // // POW MOD // @auth XING // @datetime 2018/8/10 9:56 AM // // witnessPowProof.processPowWitnessProof( // objResponse.unstable_mc_joints, objResponse.witness_change_and_definition_joints, false, // function(err, arrLastBallUnits, assocLastBallByLastBallUnit) // witnessPowProof . processPowWitnessProof ( objResponse . unstable_mc_joints , false , function ( err , arrLastBallUnits , assocLastBallByLastBallUnit ) {", "del_tokens": "var witnessProof = require ( './witness_proof.js' ) ; witnessProof . prepareWitnessProof ( arrWitnesses , 0 , function ( err , arrUnstableMcJoints , arrWitnessChangeAndDefinitionJoints , last_ball_unit , last_ball_mci ) { if ( arrWitnessChangeAndDefinitionJoints . length > 0 ) objResponse . witness_change_and_definition_joints = arrWitnessChangeAndDefinitionJoints ; witnessProof . processWitnessProof ( objResponse . unstable_mc_joints , objResponse . witness_change_and_definition_joints , false , function ( err , arrLastBallUnits , assocLastBallByLastBallUnit ) {", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "flag", "to", "output", "JSON"], "add_tokens": "flags , flags = parsedArgs . flags ; function lintFile ( homeConf , file , prevReport ) { var newConf = extend ( conf , cmdLineOpts ) , report = Node . jslint ( data , newConf ) ; if ( flags . raw ) { return prevReport . concat ( { file : file , option : report . option , stop : report . stop , warnings : report . warnings } ) ; } displayErrors ( file , report ) ; var promise = filePaths . reduce ( function ( prom , file ) { } , Promise . resolve ( [ ] ) ) ; if ( flags . raw ) { return promise . then ( function ( out ) { process . stdout . write ( JSON . stringify ( out ) ) ; } ) ; } return promise ;", "del_tokens": "function lintFile ( homeConf , file ) { var newConf = extend ( conf , cmdLineOpts ) ; displayErrors ( file , Node . jslint ( data , newConf ) ) ; return filePaths . reduce ( function ( prom , file ) { } , Promise . resolve ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "skip", "from", "integration", "test"], "add_tokens": "it ( 'must not include any top-level members other than \"data,\" \"meta,\" \"links,\" or \"linked\"' , function ( done ) {", "del_tokens": "it . skip ( 'must not include any top-level members other than \"data,\" \"meta,\" \"links,\" or \"linked\"' , function ( done ) {", "commit_type": "remove"}
{"commit_tokens": ["Making", "polymer", "controls", "better", "."], "add_tokens": "// Avoid node to exit before build is complete", "del_tokens": "// avoid node to exit before build is complete", "commit_type": "make"}
{"commit_tokens": ["Using", "PORT", "from", "process", ".", "env", "instead", "if", "it", "exists"], "add_tokens": "const port = process . env . PORT || await findAvailablePort ( 8000 )", "del_tokens": "const port = await findAvailablePort ( 8000 )", "commit_type": "use"}
{"commit_tokens": ["change", "tests", "to", "use", "source", "files", "so", "rebuild", "isn", "t", "required"], "add_tokens": "Autolinker = { } ; eval ( fileContents ) ; var regex = Autolinker . matcherRegex ;", "del_tokens": "var regex = eval ( fileContents ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "multiple", "instances", "bug", "(", "each", "instance", "has", "the", "same", "username", "/", "pass", ")"], "add_tokens": "// Can't use multilple instances of Reslter services // // Because each instance shares the defaults and the only way to set // the username & password is to use the defaults each instance will // actually be the same // // So instead when we create another instance of a Stallion service // we'll actually create a seperate instance of a Restler service var OurService = function ( username , password ) { var restler_defaults = { baseURL : config . baseUrl } ; var RestlerService = restler . service ( default_init , restler_defaults , api ) ; return new RestlerService ( username , password ) ; } ; OurService . api = Object . keys ( api ) ; OurService . resources = this . objectsToResources ( config ) ; // TODO: this right //OurService.resources = objects.map(x => { return x.toLowerCase() }); return OurService ;", "del_tokens": "// Configure Restler var restler_config = { baseURL : config . baseUrl } ; var service = restler . service ( default_init , restler_config , api ) ; service . api = Object . keys ( api ) ; service . resources = this . objectsToResources ( config ) ; // TODO: this right //service.resources = objects.map(x => { return x.toLowerCase() }); return service ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "dataReducer", "to", "better", "handle", "subcollections", "."], "add_tokens": "// Return state if payload are invalid // Get doc from subcollections if they exist const docName = meta . subcollections ? meta . subcollections . slice ( - 1 ) [ 0 ] . doc // doc from last item of subcollections array : meta . doc ; // doc from top level meta // Data to set to state is doc if doc name exists within meta const data = docName ? get ( payload . data , docName ) : payload . data ; // Get previous data at path to check for existence // Only merge if data does not already exist or if meta contains subcollections // Set data to state immutabily (lodash/fp's setWith creates copy) // Otherwise merge with existing data // Set data to state (with merge) immutabily (lodash/fp's setWith creates copy) // support keeping data when logging out - #125 of react-redux-firebase", "del_tokens": "const data = meta . doc && ! meta . subcollections ? get ( payload . data , meta . doc ) : payload . data ; // Do not merge if no existing data or if meta contains subcollections // Merge with existing data // support keeping data when logging out - #125", "commit_type": "update"}
{"commit_tokens": ["Add", "Visibility", ".", "change", "(", "callback", ")", "to", "listen", "visibility", "state", "changes"], "add_tokens": "// Callbacks from change method, that wait visibility changes. _changeCallbacks : [ ] , _onVisibilityChange : function ( event ) { var state = this . state ( ) ; for ( var i = 0 ; i < this . _changeCallbacks . length ; i ++ ) { this . _changeCallbacks [ i ] . call ( this . _doc , event , state ) ; } this . _onVisibleCallbacks [ i ] ( ) ; this . _onVisibleCallbacks = [ ] ; // Call callback when visibility will be changed. First argument of // callback will be original event object, second will be visibility // state name. // If Page Visibility API doesn't supported method will be return false // and callback never will be called. // It is just proxy to visibilitychange event, but use vendor prefix. change : function ( callback ) { if ( ! this . support ( ) ) { return false ; } this . _changeCallbacks . push ( callback ) ; this . _setListener ( ) ; return true ; } , this . _setListener ( ) ;", "del_tokens": "_onVisibilityChange : function ( ) { this . _onVisibleCallbacks [ i ] ( ) this . _onVisibleCallbacks = [ ] this . _setListener ( )", "commit_type": "add"}
{"commit_tokens": ["Use", "proper", "array", "semantics", "(", "element", "not", "item", ")"], "add_tokens": "* Invokes a callback function on each element in the array . * 1. ` ` always refers to the current element in the iteration ( the ` ` argument to the callback ) . * element in the array . * Retrieve an element in the array . * @ param { number } index - A zero - based integer indicating which element to retrieve . * @ returns { * } The element at the specified index . * Returns an array containing every distinct element that is in either this array or the input array ( s ) .", "del_tokens": "* Invokes a callback function on each item in the array . * 1. ` ` always refers to the current item in the iteration ( the ` ` argument to the callback ) . * item in the array . * Retrieve an item in the array . * @ param { number } index - A zero - based integer indicating which item to retrieve . * @ returns { * } The item at the specified index . * Returns an array containing every distinct item that is in either this array or the input array ( s ) .", "commit_type": "use"}
{"commit_tokens": ["Add", "top", "-", "level", "reset", "method", "."], "add_tokens": "Backbone . Radio . reset ( ) ;", "del_tokens": "_ . invoke ( Backbone . Radio . _channels , 'reset' ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "transitionend", "event", "listener", "when", "callback", "completes"], "add_tokens": "$ ( this ) . attr ( 'aria-expanded' , expanded ) . off ( 'transitionend' ) ;", "del_tokens": "$ ( this ) . attr ( 'aria-expanded' , expanded ) ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "--", "compress", "to", "build", "for", "css"], "add_tokens": "'lessc ./template/less/bootstrap.less > ../css/F2.css --compress' ,", "del_tokens": "'lessc ./template/less/bootstrap.less > ../css/F2.css' , //--compress", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "Time", ".", "_deltaSeconds"], "add_tokens": "this . _deltaSeconds = this . _delta / 1000 ;", "del_tokens": "this . _deltaSeconsd = this . _delta / 1000 ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "item", "extension", "(", "per", "-", "resource", ")", "."], "add_tokens": "results = resultBuilder ( self . api , rawResults , resolved . resolvedConfig ) ;", "del_tokens": "results = resultBuilder ( rawResults , resolved . resolvedConfig ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "clarification", "on", "step", "matching", "during", "the", "generate", "command", "."], "add_tokens": "* Generate step definitions from a feature object or file given : [ 'given' , 'when' , 'then' ] , // used by default or when previous step resolves to a given when : [ 'when' , 'then' , 'given' ] , // use when previous step resolves to a when then : [ 'then' , 'given' , 'when' ] // use when previous step resolve to a then", "del_tokens": "* Generate step definitions from a feature object given : [ 'given' , 'when' , 'then' ] , when : [ 'when' , 'then' , 'given' ] , then : [ 'then' , 'given' , 'when' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "manifest", "option", "and", "add", "tests", "."], "add_tokens": "// Favicon and manifest if ( self . options . manifest ) { return self . addFileToAssets ( self . options . manifest , compilation ) . then ( function ( manifestBasename ) { assets . manifest = manifestBasename ; } ) ; }", "del_tokens": "// Favicon", "commit_type": "fix"}
{"commit_tokens": ["Fix", "references", "to", "--", "no", "-", "archive"], "add_tokens": "'\\tnpm-cache install --noArchive npm\\t# do not compress/archive the cached dependencies' ,", "del_tokens": "'\\tnpm-cache install --no-archive npm\\t# do not compress/archive the cached dependencies' ,", "commit_type": "fix"}
{"commit_tokens": ["fix", "disjoin", "for", "nested", "stylesheets"], "add_tokens": "if ( ! Array . isArray ( child ) ) { continue ; } if ( child [ 1 ] === 'ruleset' ) { } else { // try disjoin nested stylesheets, i.e. @media, @support etc. this . disjoin ( child ) ;", "del_tokens": "if ( child && child [ 1 ] === 'ruleset' ) { // Q: is it really needed? for rules in atrule block? // if (child.some(Array.isArray)) { // this.disjoin(child); // }", "commit_type": "fix"}
{"commit_tokens": ["removing", "node", "-", "uuid", "dependency"], "add_tokens": "tmpPluginDir = '/tmp/plugin' ; process . on ( 'exit' , function ( code ) { spawn ( 'rm' , [ '-rf' , tmpPluginDir ] ) ; } ) ;", "del_tokens": "uuid = require ( 'node-uuid' ) , tmpPluginDir = '/tmp/plugin-' + uuid . v1 ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "test", "case", "for", "joined", "requests", "."], "add_tokens": "reader . parse ( \"FAKEID|GUI|S|user|S|item+1|S|item+2\\r\\nFAKEID|GUI|S|user|S|item+7\\r\\n\" , false ) ; var msg = reader . pop ( ) ; test . equal ( msg . itemNames [ 0 ] , \"item 7\" ) ;", "del_tokens": "reader . parse ( \"FAKEID|GUI|S|user|S|item+1|S|item+2\\r\\n\" , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "tests", "and", "sample", "files"], "add_tokens": "var command = 'lessc' + ' ' + file . replace ( / \\s+ / g , '\\\\ ' ) + ' > ' + outputFolder + filename . replace ( / \\s+ / g , '\\\\ ' ) + '.css' ; console . log ( command )", "del_tokens": "var command = 'lessc -x ' + file . replace ( / \\s+ / g , '\\\\ ' ) + ' ' + outputFolder + filename . replace ( / \\s+ / g , '\\\\ ' ) + '.css' ; // console.log(command)", "commit_type": "add"}
{"commit_tokens": ["Updated", "jasmine", "version", "and", "tests"], "add_tokens": "it ( 'test events are being called' , function ( done ) { scope . data . push ( { id : 'ajson5' , parent : 'ajson2' , text : 'New Child' } ) ; $rootScope . $digest ( ) ; setTimeout ( function ( ) { expect ( callbackCalled ) . toBeTruthy ( ) ; done ( ) ; } , 500 ) ; } ) ;", "del_tokens": "it ( 'test events are being called' , function ( ) { spyOn ( scope , 'createNodeCB' ) ; runs ( function ( ) { scope . data . push ( { id : 'ajson5' , parent : 'ajson2' , text : 'New Child' } ) ; $rootScope . $digest ( ) ; } , \"an asynchronous method\" ) ; waitsFor ( function ( ) { return callbackCalled === true ; } , \"callback to be called\" , 1000 ) ; } ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "the", "default", "look", "position", "of", "the", "photospheres", "."], "add_tokens": "// By default, it should be at the center of the image. this . camera . parent . rotation . y = Math . PI / 2 + phi ;", "del_tokens": "this . camera . parent . rotation . y = phi ;", "commit_type": "fix"}
{"commit_tokens": ["add", ".", "then", "()", "and", "other", "promise", "functions", "-", "currently", "for", "find", "only"], "add_tokens": "transaction . rollback ( 'beforeSave' ) ; options . transaction . rollback ( 'afterSave' ) ; options . transaction . rollback ( 'afterUpdate' ) ; options . transaction . rollback ( 'beforeUpdate' ) ; options . transaction . rollback ( 'afterSave' ) ; options . transaction . rollback ( 'afterCreate' ) ; options . transaction . rollback ( 'beforeCreate' ) ;", "del_tokens": "transaction . rollback ( ) ; options . transaction . rollback ( ) ; options . transaction . rollback ( ) ; options . transaction . rollback ( ) ; options . transaction . rollback ( ) ; options . transaction . rollback ( ) ; options . transaction . rollback ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "line", "breaks", "before", "TODO", ".", "Add", "links", "to", "github", "code", "if", "wiki", "description", "is", "absent", "."], "add_tokens": "* Method change the Network id . { @ link https : //github.com/nebulasio/go-nebulas/blob/67dbb0d03e34a737ab09a2454cdb26b587d3cad4/rpc/admin_service.go#L145}<br> * \"2000000\" , * Method getter for dpos dynasty . { @ link https : //github.com/nebulasio/go-nebulas/blob/0c3439f9cedc539f64f64dd400878d2318cb215f/rpc/api_service.go#L596}<br> * Method start listen provided port . { @ link https : //github.com/nebulasio/go-nebulas/blob/1bd9bc9c9c6ca4fa0d515b620aa096f7e1c45088/neblet/neblet.go#L159}<br>", "del_tokens": "* Method change the Network id . * 2000000 \" * Method getter for dpos dynasty . * Method start listen provided port . { @ link https : //github.com/nebulasio/go-nebulas/blob/1bd9bc9c9c6ca4fa0d515b620aa096f7e1c45088/neblet/neblet.go#L159}", "commit_type": "add"}
{"commit_tokens": ["added", "functions", "section", "for", "hook"], "add_tokens": "] , functions : [ 'api/hooks/permissions-api/index.js'", "del_tokens": "'api/hooks/sails-permissions/index.js'", "commit_type": "add"}
{"commit_tokens": ["Removed", "most", "of", "underscore", "code", "and", "replaced", "it", "with", "a", "non", "-", "regex", "centric"], "add_tokens": "test ( \"slash_escape\" , function ( ) { var tmpl = e . buildTemplate ( \"\\\\${1+1}\" ) ; equal ( tmpl ( ) , \"${1+1}\" ) ; var tmpl = e . buildTemplate ( \"\\\\\\\\${1+1}\" ) ; equal ( tmpl ( ) , \"\\\\2\" ) ; var tmpl = e . buildTemplate ( \"\\\\\\\\\\\\${1+1}\" ) ; equal ( tmpl ( ) , \"\\\\${1+1}\" ) ; var tmpl = e . buildTemplate ( \"\\\\\\\\\\\\\\\\${1+1}\" ) ; equal ( tmpl ( ) , \"\\\\\\\\2\" ) ; var tmpl = e . buildTemplate ( \"\\\\\\\\\\\\\\\\\\\\${1+1}\" ) ; equal ( tmpl ( ) , \"\\\\\\\\${1+1}\" ) ; } ) ;", "del_tokens": "var tmpl = e . buildTemplate ( \" \\\\\\\\\\\\% lalala\" ) ; equal ( tmpl ( ) , \" \\\\% lalala\" ) ; r = e . testcallmacro ( ) ; equal ( transform ( r ) , \"lalala\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["allow", "webpack", "configuration", "to", "be", "overriden"], "add_tokens": "var context = require ( '../context' ) ; // Developers should be able to pass in their own Webpack configuration // in order to override the defaults (loaders, entry points, etc.) // // EX: // // workflow.use({ // gulp: gulp, // wepback: require('./loca/webpack.config') // }); // var externalWebpack = context . webpack || { } ; // return merge ( this . webpackConfig , externalWebpack ) ;", "del_tokens": "return this . webpackConfig ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "dummy", "classes", "for", "TODO", "controllers", "and", "updated", "demo", "/", "gui", "css"], "add_tokens": "var Controller = function ( ) { // TODO var BooleanController = function ( ) { this . type = \"boolean\" ; Controller . apply ( this , arguments ) ; // TODO } ; BooleanController . prototype = new Controller ( ) ; BooleanController . prototype . constructor = BooleanController ; var FunctionController = function ( ) { this . type = \"function\" ; Controller . apply ( this , arguments ) ; // TODO } ; FunctionController . prototype = new Controller ( ) ; FunctionController . prototype . constructor = FunctionController ;", "del_tokens": "var Controller = function ( object , propertyName ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "scope", "of", "loaded", "dependencies"], "add_tokens": "var YAML = require ( 'js-yaml' ) ; var coffee = require ( 'coffee-script' ) ; var toml = require ( 'toml' ) ;", "del_tokens": "var YAML = require ( 'js-yaml' ) , coffee , toml ; if ( ! coffee ) { coffee = require ( 'coffee-script' ) ; } if ( ! toml ) { toml = require ( 'toml' ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "custom", "matcher", "support", "for", "expectJSONTypes", "JSON", "spec"], "add_tokens": "place : function ( val ) { expect ( val ) . toMatchOrBeNull ( \"Oklahoma City, OK\" ) ; } , // Custom matcher in_reply_to_screen_name : function ( val ) { expect ( val ) . toBeTypeOrNull ( String ) ; } , // Custom matcher", "del_tokens": "place : function ( val ) { expect ( val ) . toMatchOrBeNull ( \"Oklahoma City, OK\" ) ; } ,", "commit_type": "add"}
{"commit_tokens": ["use", "more", "consistent", "names", "and", "move", "encrypt", "/", "decrypt", "keys", "into", "stateless"], "add_tokens": "remote : state . remote . publicKey , boxes . createUnboxStream ( state . decryptKey , de_nonce ) boxes . createBoxStream ( state . encryptKey , en_nonce ) ,", "del_tokens": "var en_key = hash ( concat ( [ state . secret , state . remote . public ] ) ) var de_key = hash ( concat ( [ state . secret , state . local . public ] ) ) remote : state . remote . public , boxes . createUnboxStream ( de_key , de_nonce ) boxes . createBoxStream ( en_key , en_nonce ) ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "creation", "of", "branch", "in", "local", "driver"], "add_tokens": "return that . repo . create_branch ( name ) ;", "del_tokens": "return that . create_branch ( name ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "start", "a", "mutating", "session"], "add_tokens": "model . invalidateClassCache ( ) ; Through . invalidateClassCache ( ) ; if ( ! model . isSetUp ) { model . isSetUp = true ; if ( ! model . isSetUp ) { model . isSetUp = true ; getDefaultState ( ) { const models = this . getModelClasses ( ) ; const state = { } ; models . forEach ( modelClass => { state [ modelClass . modelName ] = modelClass . getDefaultState ( ) ; } ) ; return state ; } withMutations ( state ) { return new Session ( this . getModelClasses ( ) , state , undefined , true ) ; }", "del_tokens": "model . invalidateCaches ( ) ; Through . invalidateCaches ( ) ; if ( ! model . _setupDone ) { model . _setupDone = true ; if ( ! model . _setupDone ) { model . _setupDone = true ;", "commit_type": "add"}
{"commit_tokens": ["move", "lifecycle", "hooks", "into", "config"], "add_tokens": "function mergeHook ( parentVal , childVal ) { config . _lifecycleHooks . forEach ( hook => { strats [ hook ] = mergeHook } )", "del_tokens": "strats . init = strats . created = strats . ready = strats . attached = strats . detached = strats . beforeMount = strats . mounted = strats . beforeUpdate = strats . updated = strats . beforeDestroy = strats . destroyed = strats . activate = function ( parentVal , childVal ) {", "commit_type": "move"}
{"commit_tokens": ["add", "actionDeserializer", "callback", "to", "persistState"], "add_tokens": "export default function persistState ( sessionId , stateDeserializer = null , actionDeserializer = null ) { if ( ! fullState || typeof stateDeserializer !== 'function' ) { committedState : stateDeserializer ( fullState . committedState ) , state : stateDeserializer ( computedState . state ) function deserializeActions ( fullState ) { if ( ! fullState || typeof actionDeserializer !== 'function' ) { return fullState ; } return { ... fullState , stagedActions : fullState . stagedActions . map ( ( action ) => { return actionDeserializer ( action ) ; } ) } ; } finalInitialState = deserializeActions ( deserializeState ( JSON . parse ( localStorage . getItem ( key ) ) ) ) || initialState ;", "del_tokens": "export default function persistState ( sessionId , deserializer = null ) { if ( ! fullState || typeof deserializer !== 'function' ) { committedState : deserializer ( fullState . committedState ) , state : deserializer ( computedState . state ) finalInitialState = deserializeState ( JSON . parse ( localStorage . getItem ( key ) ) ) || initialState ;", "commit_type": "add"}
{"commit_tokens": ["added", "test", "to", "prove", "the", "error", "of", "not", "shutting", "down"], "add_tokens": "[ 'inventory' , it ( 'try to boot without plugins without shutting down, expect failure' , ( done ) => { tymly . boot ( { } , ( err , tymlyServices ) => { expect ( err . length ) . to . eql ( 2 ) expect ( err [ 0 ] . name ) . to . eql ( 'unknownService' ) expect ( err [ 1 ] . name ) . to . eql ( 'unknownService' ) done ( ) } ) } )", "del_tokens": "[ 'inventory' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "paths", "on", "Windows"], "add_tokens": "const remoteTargetPath = path . posix . join ( serverBasePath , requestPath ) ; : urlTools . normalisePath ( path . posix . relative ( serverBasePath , href ) ) ;", "del_tokens": "const remoteTargetPath = path . join ( serverBasePath , requestPath ) ; : urlTools . normalisePath ( path . relative ( serverBasePath , href ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "cli", ".", "color", ".", "{", "app", "attachment", "addon", "}", "methods"], "add_tokens": "exports . color = require ( './lib/color' ) ;", "del_tokens": "exports . color = require ( 'chalk' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "production", "docker", "-", "compose", ".", "hammer", "the", "release", "process", "aka", "build", "for", "prod", "down", "to", "a", "single", "command", "."], "add_tokens": "const redisClient = redis . createClient ( process . env . REDIS_CONN_URI ) ;", "del_tokens": "const redisClient = redis . createClient ( getConfig ( 'redis.url' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "keyForRelationship", "to", "convert", "keys", "for", "relationships", "in", "serializeBelongsTo", "and", "serializeHasMany"], "add_tokens": "keyForRelationship : function ( key ) { return key ; } , var attr = relationship . key ; var belongsTo = get ( record , attr ) ; var key = this . keyForRelationship ( attr ) ; var attr = relationship . key ; var key = this . keyForRelationship ( attr ) ; json . links [ key ] = get ( record , attr ) . mapBy ( 'id' ) ;", "del_tokens": "var key = relationship . key ; var belongsTo = get ( record , key ) ; var key = relationship . key ; json . links [ key ] = get ( record , key ) . mapBy ( 'id' ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "int", "arg", "to", "be", "0"], "add_tokens": "if ( typeof fromArgs !== 'undefined' ) { let propVal = value if ( typeof option . defaultValue !== 'undefined' && typeof propVal !== typeof option . defaultValue ) { propVal = option . defaultValue } // Add option to list contents [ name ] = propVal", "del_tokens": "if ( fromArgs ) { let propVal = value || option . defaultValue // Add option to list if it has a value if ( propVal ) { contents [ name ] = propVal }", "commit_type": "allow"}
{"commit_tokens": ["Make", "find", "blueprint", "use", "JsonApiService"], "add_tokens": "var type = pluralize ( req . options . model || req . options . controller ) ; return res . ok ( JsonApiService . serialize ( type , matchingRecords ) ) ;", "del_tokens": "matchingRecords . forEach ( ( record ) => { var id = record . id ; delete record . id data . data . push ( { id : id . toString ( ) , type : pluralize ( req . options . model || req . options . controller ) , attributes : record } ) ; } ) return res . ok ( data ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "react", "resolver", "from", "webpack", "config"], "add_tokens": "'bootstrap' : 'bootstrap/dist/js/bootstrap.js'", "del_tokens": "'bootstrap' : 'bootstrap/dist/js/bootstrap.js' , 'react' : path . join ( __dirname , 'node_modules' , 'react' )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "encloses", "()", "function", "so", "that", "a", "circle", "encloses", "itself"], "add_tokens": "return dr >= - 1e-6 && dr * dr * ( 1 + 1e-9 ) >= dx * dx + dy * dy ;", "del_tokens": "return dr >= - 1e-6 && dr * dr * ( 1 + 1e-9 ) > dx * dx + dy * dy ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "needsWork", "to", "needReview", "in", "statistic", "change", "state", "to", "status", "in", "PUT", "endpoint"], "add_tokens": ". body ( { revision : 2 , status : 'translated' } )", "del_tokens": ". body ( { revision : 2 , state : 'translated' } )", "commit_type": "change"}
{"commit_tokens": ["Add", "Promise", "and", "fetch", "polyfills"], "add_tokens": "entry : [ require . resolve ( './polyfills' ) , path . join ( paths . appSrc , 'index' ) ] ,", "del_tokens": "entry : path . join ( paths . appSrc , 'index' ) ,", "commit_type": "add"}
{"commit_tokens": ["allow", "correct", "size", "allocation", "for", "data", "views"], "add_tokens": "collectCoverageFrom : [ './src/**/*.ts' , './adblocker.ts' ] ,", "del_tokens": "collectCoverageFrom : [ './src/*' , './adblocker.ts' ] ,", "commit_type": "allow"}
{"commit_tokens": ["Fix", "up", "issue", "in", "node", ".", "js", "impl", "of", "basename"], "add_tokens": "FileSystem : FileSystem , Path : require ( 'src/path' )", "del_tokens": "FileSystem : FileSystem", "commit_type": "fix"}
{"commit_tokens": ["Fix", "regex", "for", "string", "literal", "that", "has", "CRLF", "linefeed"], "add_tokens": "'|' + '(' + '\"(?:' + '\\\\\\\\[\\\\s\\\\S]' + '|' + '(?:' + '[^\"' + lineTerminator + '\\\\\\\\]' + '|' + '[^\"\\\\r\\\\\\\\][^\"\\\\n\\\\\\\\]' + ')' + ')*\"' + '|' + \"'(?:\" + '\\\\\\\\[\\\\s\\\\S]' + '|' + '(?:' + \"[^'\" + lineTerminator + \"\\\\\\\\]\" + '|' + \"[^'\\\\r\\\\\\\\][^'\\\\n\\\\\\\\]\" + ')' + \")*'\" + var DEFAULT_MAXLINELEN = 32000 ;", "del_tokens": "var DEFAULT_MAXLINELEN = 32000 ; '|' + '(' + '\"(?:\\\\\\\\[\\\\s\\\\S]|[^\"' + lineTerminator + '\\\\\\\\])*\"' + '|' + \"'(?:\\\\\\\\[\\\\s\\\\S]|[^'\" + lineTerminator + \"\\\\\\\\])*'\" +", "commit_type": "fix"}
{"commit_tokens": ["Improve", "media", "query", "combination", "algorithm"], "add_tokens": "export function distributeQueryAcrossQuery ( a , b ) { const aParts = explodeMediaQuery ( a ) ; const bParts = explodeMediaQuery ( b ) ; return aParts . map ( ( aPart ) => bParts . map ( ( bPart ) => ` ${ aPart } ${ bPart } ` ) . join ( ', ' ) )", "del_tokens": "export function distributeQueryAcrossQuery ( retinaQuery , parentQuery ) { return retinaQuery . split ( ', ' ) . map ( ( segment ) => ` ${ segment } ${ parentQuery } ` )", "commit_type": "improve"}
{"commit_tokens": ["Allow", "use", "of", "query", "string", "functionality", "without", "cookies", "."], "add_tokens": "if ( typeof props . cookie !== 'undefined' ) { req . cookies [ props . cookie . name ] = queryLanguage ; res . cookie ( props . cookie . name , queryLanguage , props . cookie . options ) ; }", "del_tokens": "req . cookies [ props . cookie . name ] = queryLanguage ; res . cookie ( props . cookie . name , queryLanguage , props . cookie . options ) ;", "commit_type": "allow"}
{"commit_tokens": ["Made", "a", "couple", "of", "improvements", "."], "add_tokens": "return obj ? obj . model : { } ;", "del_tokens": "return obj . model ;", "commit_type": "make"}
{"commit_tokens": ["Add", "sanitize", "fn", "for", "icon", "naming"], "add_tokens": "/ ** * Replace whitespace and underscores with dashes , then lowercase * @ param { String } str * / function sanitize ( str ) { return str . replace ( / \\s+|_+ / g , '-' ) . toLowerCase ( ) ; } const filename = sanitize ( path . basename ( f ) ) ;", "del_tokens": "const filename = path . basename ( f ) . toLowerCase ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "switch", "between", "blockly", "and", "code", "editor"], "add_tokens": "setEditorType , MOVE , SET_EDITOR_TYPE } from './taskEnvironment' ; setEditorType , SET_EDITOR_TYPE ,", "del_tokens": "MOVE } from './taskEnvironment' ;", "commit_type": "allow"}
{"commit_tokens": ["Changed", "references", "to", "refer", "to", ".", "instead", "of", "soft", "link", "."], "add_tokens": "let Base = require ( './Base.js' ) let Logger = require ( './Logger.js' ) ( 'Helper' ) let SbEvent = require ( './SbEvent.js' ) ; let StopWords = require ( './Stopwords.js' ) ;", "del_tokens": "let Base = require ( 'sb/etc/Base.js' ) let Logger = require ( 'sb/etc/Logger.js' ) ( 'Helper' ) let SbEvent = require ( 'sb/etc/SbEvent.js' ) ; let StopWords = require ( 'sb/etc/Stopwords.js' ) ;", "commit_type": "change"}
{"commit_tokens": ["Allow", "caniuse", "-", "compat", "to", "fill", "in", "missing", "caniuse", "data"], "add_tokens": "caniuse : feature . caniuse in caniuse . features ? caniuse . feature ( caniuse . features [ feature . caniuse ] ) : 'caniuse-compat' in feature ? { stats : feature [ 'caniuse-compat' ] } : false ,", "del_tokens": "caniuse : feature . caniuse in caniuse . features ? caniuse . feature ( caniuse . features [ feature . caniuse ] ) : false ,", "commit_type": "allow"}
{"commit_tokens": ["Fix", "Bug", "876461", "-", "Strip", "out", "remixUrl", "and", "fix", "bug", "with", "remixedFrom"], "add_tokens": "type : String , es_index : \"not_analyzed\" Make . publicFields = [ \"url\" , \"contentType\" , \"locale\" , \"locales\" ,", "del_tokens": "remixUrl : { type : String , es_indexed : true , validate : validate ( { passIfEmpty : true } , \"isUrl\" ) , es_index : \"not_analyzed\" } , type : Number , es_index : \"not_analyzed\" , es_type : \"long\" Make . publicFields = [ \"url\" , \"remixUrl\" , \"contentType\" , \"locale\" , \"locales\" ,", "commit_type": "fix"}
{"commit_tokens": ["implemented", "basic", "working", "fullscreen", "mode", "in", "demo"], "add_tokens": "files : 'demo/css/*.less' , paths : [ \"demo/css\" ] \"demo/css/main.css\" : \"demo/css/main.less\"", "del_tokens": "files : 'css/*.less' , paths : [ \"css\" ] \"css/main.css\" : \"css/main.less\"", "commit_type": "implement"}
{"commit_tokens": ["add", "support", "for", "refresh", "tokens"], "add_tokens": "serializeClient . accessSerializer ( function ( body , req , next ) {", "del_tokens": "serializeClient . serializeToken ( function ( body , req , next ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", ":", "Special", "context", "for", "callbacks"], "add_tokens": "var EventMixin ; context = context || null ; context === undefined && event === undefined ) { this . events [ event ] [ x ] . context === context ) {", "del_tokens": "var EventMixin , emptyContext ; emptyContext = { } ; context = context || emptyContext ; context === undefined && event === undefined ) { this . events [ event ] [ x ] . context === context ) {", "commit_type": "remove"}
{"commit_tokens": ["updated", "gitignore", "renamed", "wavloader", "reading", "function", "because", "the", "name", "was", "very", "long", "and", "reading", "is", "fun"], "add_tokens": "var read_fun = \"readUIntBE\" ; output [ i ] = _d [ read_fun ] ( i , _numBytesPerSample ) ; output [ i ] = source [ read_fun ] ( i , _numBytesPerSample ) ;", "del_tokens": "var readFunctionWithSignednessAndEndianness = \"readUIntBE\" ; output [ i ] = _d [ readFunctionWithSignednessAndEndianness ] ( i , _numBytesPerSample ) ; output [ i ] = source [ readFunctionWithSignednessAndEndianness ] ( i , _numBytesPerSample ) ;", "commit_type": "update"}
{"commit_tokens": ["Improved", "AWS", "Unique", "ID", "loading"], "add_tokens": "_this . post ( dataToSend , url , _this . getHeaderContentType ( ) ) ;", "del_tokens": "} ) . then ( function ( ) { _this . post ( dataToSend , url , _this . getHeaderContentType ( ) , function ( ) { } ) ;", "commit_type": "improve"}
{"commit_tokens": ["Changed", "from", "queueSize", "to", "timer", "based", "messaging"], "add_tokens": "import { RENDER_TIME , RENDER_QUEUE , CONSTRUCTOR , APPEND_CHILD , RENDER , SET_ATTRIBUTES , SET_CONTENT } from './../common/constants' ; this . channel . send ( RENDER_TIME , { time : 1 , count : 0 } ) ; var start = performance . now ( ) ; this . channel . send ( RENDER_TIME , { time : performance . now ( ) - start , count : data . args . length } ) ;", "del_tokens": "import { RENDER_QUEUE , CONSTRUCTOR , APPEND_CHILD , RENDER , SET_ATTRIBUTES , SET_CONTENT } from './../common/constants' ;", "commit_type": "change"}
{"commit_tokens": ["Add", "collapsed", "and", "full", "reference", "links"], "add_tokens": "label : links . normalizeReference ( str . slice ( 1 , labelEnd ) ) ,", "del_tokens": "label : str . slice ( 1 , labelEnd ) . trim ( ) . replace ( / \\s+ / g , ' ' ) ,", "commit_type": "add"}
{"commit_tokens": ["adds", "vinyl", "-", "fs", "tests"], "add_tokens": "it . skip ( 'should change to the specified base as string' , function ( cb ) { it . skip ( 'should change to the specified base as function' , function ( cb ) { it . skip ( 'should see a file with special chmod (setuid/setgid/sticky) as matching' , function ( cb ) {", "del_tokens": "it ( 'should change to the specified base as string' , function ( cb ) { it ( 'should change to the specified base as function' , function ( cb ) { it ( 'should see a file with special chmod (setuid/setgid/sticky) as matching' , function ( cb ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "dependencies", "and", "the"], "add_tokens": "fs . writeSync ( fd , '<meta http-equiv=\"refresh\" content=\"0; url=http://cloudkidstudio.github.io/PixiParticles/docs/\" />' ) ;", "del_tokens": "fs . writeSync ( fd , '<meta http-equiv=\"refresh\" content=\"0; url=http://springroll.github.io/SpringRoll/docs/\" />' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "be", "in", "line", "with", "standards"], "add_tokens": "var firstArg = program . args [ program . args . length - 1 ] . _name ; var commandIsUnknown = typeof firstArg === 'undefined' ; if ( commandIsUnknown ) { return log ( 'error' , 'Unknown option \\'%s\\', please use --help for assistance' , program . args [ 0 ] ) ; }", "del_tokens": "if ( typeof program . args [ program . args . length - 1 ] . _name === 'undefined' ) { log ( 'error' , 'Unknown option \\'%s\\', please use --help for assistance' , program . args [ 0 ] ) ; }", "commit_type": "update"}
{"commit_tokens": ["added", "karma", "-", "spec", "-", "reporter"], "add_tokens": "reporters : [ 'progress' , 'spec' , 'coverage' ] ,", "del_tokens": "reporters : [ 'progress' , 'coverage' ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "IE8", "issue", "with", "Array#forEach"], "add_tokens": "* TODO : remove prior releasing 1.0 util . forEach ( [ 'addTest' , 'addSuite' , 'createTest' , 'createSuite' ] , function ( method ) {", "del_tokens": "* TODO : remove [ 'addTest' , 'addSuite' , 'createTest' , 'createSuite' ] . forEach ( function ( method ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "feature", "to", "generate", "multiple", "colors"], "add_tokens": "// Multiple colors if ( options . count ) { var colors = [ ] , totalColors = options . count ; options . count = false ; while ( colors . length < totalColors ) { colors . push ( randomColor ( options ) ) } return colors }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "CLI", "params", "."], "add_tokens": "var extend = require ( \"underscore\" ) . extend ; var execute = require ( \"./task\" ) ; return execute ( manifest , extend ( options , { command : \"run\" } ) ) ;", "del_tokens": "var _ = require ( \"underscore\" ) ; var xpi = require ( \"./xpi\" ) ; var createProfile = require ( \"./profile\" ) ; var runFirefox = require ( \"./firefox\" ) ; var console = require ( \"./utils\" ) . console ; var fs = require ( \"fs-promise\" ) ; function extendWith ( source , field ) { return function ( value ) { source [ field ] = value ; return source ; } } function removeXPI ( options ) { return fs . unlink ( options . xpi ) . then ( function ( ) { return options ; } ) ; } // Generate XPI and get the path return xpi ( manifest , options ) . then ( extendWith ( options , \"xpi\" ) ) . then ( function ( options ) { return options . profile || createProfile ( options ) ; } ) . then ( extendWith ( options , \"profile\" ) ) . then ( removeXPI ) . then ( runFirefox )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Date", "objects"], "add_tokens": "} , 'fr_FR' : { prefixAgo : 'il y a' , prefixFromNow : null , suffixAgo : null , suffixFromNow : 'from now' , seconds : 'moins d\\'une minute' , minute : 'environ une minute' , minutes : '%d minutes' , hour : 'environ une heure' , hours : 'environ %d heures' , day : 'un jour' , days : '%d jours' , month : 'environ un mois' , months : '%d mois' , year : 'environ un an' , years : '%d ans' , numbers : [ ] if ( iso8601 instanceof Date ) { return iso8601 ; } ] ) ;", "del_tokens": "] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "where", "filtered", "signals", "weren", "t", "unmounted", "properly"], "add_tokens": "const subscription = s . subscribe ( { ... emit , next } ) return ( ) => subscription . unsubscribe ( )", "del_tokens": "return s . subscribe ( { ... emit , next } )", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "setting", "couch", "url", "when", "using", "local", "-", "tld", "and", "check", "for", "correct", "status", "code", "in", "couchdb", "response", "when", "polling"], "add_tokens": "couchr = require ( 'couchr' ) , else if ( err ) { return callback ( err ) ; } else if ( res . statusCode !== 200 ) { return callback ( couchr . statusCodeError ( res . statusCode ) ) ; } else { // We got a response! process . stdout . write ( ' done!\\n' ) ; return callback ( ) ; }", "del_tokens": "// We got a response! process . stdout . write ( ' done!\\n' ) ; return callback ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "player", "name", "only", "send", "if", "the", "name", "changed"], "add_tokens": "var newName = element . value . replace ( / [<>] / g , '' ) ; if ( newName . length == 0 ) { element . value = name ; } else if ( newName != name ) { name = newName ; sendName ( ) ;", "del_tokens": "var playerRE = / ^Player\\d+$ / i ; name = element . value . replace ( / [<>] / g , '' ) ; // Only set the cookie if the name isn't \"Player\\d+\" if ( ! playerRE . test ( name ) ) { sendName ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "matching", "tests", "and", "fix", "cosmetics", "entity", "matching"], "add_tokens": "return fs . readFileSync ( path . resolve ( __dirname , '../../' , filepath ) , 'utf-8' ) ;", "del_tokens": "return fs . readFileSync ( path . resolve ( __dirname , '../../../' , filepath ) , 'utf-8' ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "Licence", "from", "GPL3", "to", "Apache", "2"], "add_tokens": "Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; you may not use this file except in compliance with the License . You may obtain a copy of the License at http : //www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing , software distributed under the License is distributed on an \"AS IS\" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the License for the specific language governing permissions and limitations under the License . console . log ( 'Server running at http://127.0.0.1:8124/' ) ;", "del_tokens": "This program is free software : you can redistribute it and / or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation , either version 3 of the License , or ( at your option ) any later version . This program is distributed in the hope that it will be useful , but WITHOUT ANY WARRANTY ; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the GNU General Public License for more details . You should have received a copy of the GNU General Public License along with this program . If not , see < http : //www.gnu.org/licenses/>. console . log ( 'Server running at http://127.0.0.1:8124/' ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "tie", "symbol", "(", "~", ")"], "add_tokens": "[ / ^[)\\]?!] / , \"close\" ] , [ / ^~ / , \"spacing\" ] [ / ^} / , \"}\" ] , [ / ^~ / , \"spacing\" ]", "del_tokens": "[ / ^[)\\]?!] / , \"close\" ] [ / ^} / , \"}\" ]", "commit_type": "add"}
{"commit_tokens": ["Add", "supports", "for", "cassandra", "3", ".", "x", ".", "Update", "dependencies", "."], "add_tokens": "const cassandra = require ( 'cassandra-driver' ) ; config . authProvider = new cassandra . auth . PlainTextAuthProvider ( config . user , config . password ) ; var client = new cassandra . Client ( config ) ;", "del_tokens": "//var async = require('async'); var cassandraDriver = require ( 'cassandra-driver' ) ; var CassandraClient = cassandraDriver . Client ; var CassandraPlainTextAuthProvider = cassandraDriver . auth . PlainTextAuthProvider ; config . authProvider = new CassandraPlainTextAuthProvider ( config . user , config . password ) ; var client = this . cassandraClient = new CassandraClient ( config ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "buildAttributes", "setting", "of", "empty", "[]", "and", "{}"], "add_tokens": "// json value is null // use current attribute value or default to `[]` if ( _ . isNull ( jsonVal ) ) { // json value is null // use current attribute value or default to `{}` if ( _ . isNull ( jsonVal ) ) {", "del_tokens": "// No value in json, use current attribute value or default to `[]` if ( _ . isNull ( jsonVal ) || _ . isEmpty ( jsonVal ) ) { // No value in json, use current attribute value or default to `{}` if ( _ . isNull ( jsonVal ) || _ . isEmpty ( jsonVal ) ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "schema", "tests", "changed", "options", "ot", "json", "/", "graphql"], "add_tokens": "json : true , graphql : true , // console.log(options); if ( options . graphql ) { if ( ! options . json ) { if ( ! options . json ) { if ( options . json ) { message : 'Invalid schema file' ,", "del_tokens": "generateSchema : true , printSchema : true , if ( options . printSchema ) { if ( ! options . generateSchema ) { if ( ! options . generateSchema ) { if ( options . generateSchema ) {", "commit_type": "add"}
{"commit_tokens": ["use", "Tag", "suffix", "for", "generated", "styled", "element", "exports"], "add_tokens": "const reserved = Object . getOwnPropertyNames ( global ) const suffix = 'Tag' return reserved . includes ( name ) ? ` ${ name } ${ suffix } ` : name const buildFile = resolve ( __dirname , './lib/index.js' ) appendFileSync ( buildFile , ` \\n ${ elementExports } ` )", "del_tokens": "const reserved = require ( 'reserved' ) const prefix = 'Html' return reserved . includes ( name ) ? ` ${ prefix } ${ name } ` : name const buildFile = resolve ( __dirname , './lib/index.js' ) const toWrite = ` \\n ${ elementExports } ` appendFileSync ( buildFile , toWrite )", "commit_type": "use"}
{"commit_tokens": ["remove", "USD", "as", "default", "currency", "in", "specs", "accidentally", "added"], "add_tokens": "var CURRENCY = '_DEFAULT_CURRENCY_NOT_YET_GOTTEN_' ;", "del_tokens": "var CURRENCY = 'USD' ;", "commit_type": "remove"}
{"commit_tokens": ["improve", "jiya", "with", "full", "biaodian", "support"], "add_tokens": "close : new RegExp ( '(' + rBdClose + ')' , 'g' ) , filteredElemList = 'style script' , filteredElemList : filteredElemList , mat . match ( TYPESET . char . biaodian . open ) ? 'open' : mat . match ( TYPESET . char . biaodian . close ) ? 'close end' : mat . match ( TYPESET . char . biaodian . end ) ? 'end' : ''", "del_tokens": "filteredElemList : 'style script' , mat . match ( TYPESET . char . biaodian . open ) ? 'open' : mat . match ( TYPESET . char . biaodian . end ) ? 'end' : ''", "commit_type": "improve"}
{"commit_tokens": ["Fix", "most", "non", "-", "ASCII", "characters", "treated", "as", "fullwidth"], "add_tokens": "isFullWidth = ( cc > 0xff00 && cc < 0xff61 ) || ( cc > 0xffdc && cc < 0xffe8 ) || cc > 0xffee ;", "del_tokens": "isFullWidth = ( cc > 0xff && cc < 0xff61 ) || ( cc > 0xffdc && cc < 0xffe8 ) && cc > 0xffee ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "empty", "table", "with", "wrong", "columns", "bug", "."], "add_tokens": "tableRows . push ( < TableRow key = \"##table-empty##\" > < td colSpan = { this . props . columns . length + ( isSelectRowDefined ? 1 : 0 ) } style = { { textAlign : \"center\" } } > There is no data to display < / td > < / TableRow > );", "del_tokens": "tableRows . push ( < TableRow key = \"##table-empty##\" > < td colSpan = { this . props . columns . length } style = { { textAlign : \"center\" } } > There is no data to display < / td > < / TableRow > )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "pre", "-", "existing", "CSS", "backgrounds"], "add_tokens": "console . log ( this . css ( 'backgroundImage' ) ) ; if ( images === undefined && this . css ( 'backgroundImage' ) ) { images = [ this . css ( 'backgroundImage' ) . replace ( / url\\(|\\)|\"|' / g , \"\" ) ] ; } $ . error ( \"No images were supplied for Backstretch\" ) ; * e . g . $ . backstretch ( '/path/to/image.jpg' ) * So , we need to turn this back into an array . * / } ( jQuery , window ) ) ;", "del_tokens": "$ . error ( \"No images were supplied for Backstretch\" ) ; * e . g . $ . backstretch ( '/path/to/image.jpg' ) * So , we need to turn this back into an array . * / } ( jQuery , window ) ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "dead", "code", "from", "previous", "implementation", "of", "nextLink"], "add_tokens": "return pathWithQuery ( _this . path + pathSuffix , odataQuery ) ;", "del_tokens": "return _this . _nextLink || pathWithQuery ( _this . path + pathSuffix , odataQuery ) ; Object . defineProperty ( CollectionNode . prototype , \"nextLink\" , { set : function ( pathWithQuery ) { this . _nextLink = pathWithQuery ; } , enumerable : true , configurable : true } ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "better", "test", "for", "history", "api"], "add_tokens": "if ( hasHistory ( ) ) { / ** * Test for history API ( Modernizr ) * @ returns { Boolean } * / function hasHistory ( ) { var ua = navigator . userAgent ; // Stock android browser 2.2 & 2.3 & 4.0.x are buggy, ignore if ( ( ua . indexOf ( 'Android 2.' ) !== - 1 || ( ua . indexOf ( 'Android 4.0' ) !== - 1 ) ) // Chrome identifies itself as 'Mobile Safari' && ua . indexOf ( 'Mobile Safari' ) !== - 1 && ua . indexOf ( 'Chrome' ) === - 1 ) { return false ; } // Usual test return ( window . history && 'pushState' in window . history ) ; }", "del_tokens": "if ( ! ! ( window . history && window . history . pushState ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "to", "ensure", "listen", "is", "called"], "add_tokens": "cleanup : false , listen : false listen : function ( ) { called . listen = true } ,", "del_tokens": "cleanup : false", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "jsdoc", "for", "modules", "api"], "add_tokens": "* @ param { Boolean } options . reset - Trigger a rebuild of the modules ( Requires administrative token )", "del_tokens": "* @ param { Boolean } poptions . reset - Trigger a rebuild of the modules ( Requires administrative token )", "commit_type": "fix"}
{"commit_tokens": ["Move", "presentation", "templates", "to", "subdir"], "add_tokens": "var PRESENTATION_SUBDIR = \"presentation/\" ; iframe_url : template_dir + PRESENTATION_SUBDIR + doctype + \".html\" , var presentation_dir = output_dir + PRESENTATION_SUBDIR ; var load_presentation_template = loadFile ( template_dir + PRESENTATION_SUBDIR + doctype + \".mustache\" , false , true ) ; file_path_relative = PRESENTATION_SUBDIR + file_name ;", "del_tokens": "* @ todo better template files structure iframe_url : template_dir + \"presentation_\" + doctype + \".html\" , var presentation_subdir = \"presentation/\" ; var presentation_dir = output_dir + presentation_subdir ; var load_presentation_template = loadFile ( template_dir + \"presentation_\" + doctype + \".mustache\" , false , true ) ; file_path_relative = presentation_subdir + file_name ;", "commit_type": "move"}
{"commit_tokens": ["Update", "to", "use", "new", "verbose", "option", "for", "logging"], "add_tokens": "this . log ( 'building app to `' + outputPath + '` using buildEnv `' + buildEnv + '`...' , { verbose : true } ) ; self . log ( ' ' + p th, { v rbose: t ue } ; self . log ( 'build ok' , { verbose : true } ) ;", "del_tokens": "this . log ( 'building app to `' + outputPath + '` using buildEnv `' + buildEnv + '`...' ) ; self . log ( ' ' + p th); self . log ( 'build ok' ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "missing", "semicolon", "before", "else", "keyword", "which", "caused", "problem", "with", "--", "lines", "-", "preserve", "option"], "add_tokens": "exports . version = \"0.1.3e\" ;", "del_tokens": "exports . version = \"0.1.3d\" ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "secret", "proof", "tx", "unittest"], "add_tokens": "Catapult . Buffers . SecretProofTransactionBuffer . prototype . recipient = function ( index ) { Catapult . Buffers . SecretProofTransactionBuffer . prototype . recipientLength = function ( ) { Catapult . Buffers . SecretProofTransactionBuffer . prototype . recipientArray = function ( ) { Catapult . Buffers . SecretProofTransactionBuffer . addRecipient = function ( builder , recipientOffset ) { Catapult . Buffers . SecretProofTransactionBuffer . createRecipientVector = function ( builder , data ) { Catapult . Buffers . SecretProofTransactionBuffer . startRecipientVector = function ( builder , numElems ) { export default Catapult ;", "del_tokens": "Catapult . Buffers . SecretProofTransactionBuffer . prototype . recipient = function ( index ) { Catapult . Buffers . SecretProofTransactionBuffer . prototype . recipientLength = function ( ) { Catapult . Buffers . SecretProofTransactionBuffer . prototype . recipientArray = function ( ) { Catapult . Buffers . SecretProofTransactionBuffer . addRecipient = function ( builder , recipientOffset ) { Catapult . Buffers . SecretProofTransactionBuffer . createRecipientVector = function ( builder , data ) { Catapult . Buffers . SecretProofTransactionBuffer . startRecipientVector = function ( builder , numElems ) { export default Catapult ;", "commit_type": "update"}
{"commit_tokens": ["changed", "license", "from", "MIT", "to", "ISC"], "add_tokens": "/*! (C) Andrea Giammarchi ISC License */", "del_tokens": "/*! (C) Andrea Giammarchi Mit Style License */", "commit_type": "change"}
{"commit_tokens": ["Fixing", "luis", "apps", "create", "bug", ".", "adding", "missing", "prebuiltEntities", "field"], "add_tokens": "constructor ( { name /* string */ , versionId /* string */ , desc /* string */ , culture /* string */ , intents /* HierarchicalModel[] */ , entities /* HierarchicalModel[] */ , bing_entities /* string[] */ , actions /* JSONAction[] */ , closedLists /* JSONClosedList[] */ , composites /* HierarchicalModel[] */ , regex_features /* JSONRegexFeature[] */ , model_features /* JSONModelFeature[] */ , utterances /* JSONUtterance[] */ , prebuiltEntities /* prebuiltEntities[] */ } = { } ) { utterances /* JSONUtterance[] */ , prebuiltEntities /* prebuitl entities[] */ const { name /* string */ , versionId /* string */ , desc /* string */ , culture /* string */ , intents /* HierarchicalModel[] */ , entities /* HierarchicalModel[] */ , bing_entities /* string[] */ , actions /* JSONAction[] */ , closedLists /* JSONClosedList[] */ , composites /* HierarchicalModel[] */ , regex_features /* JSONRegexFeature[] */ , model_features /* JSONModelFeature[] */ , utterances /* JSONUtterance[] */ , prebuiltEntities /* prebuiltEntities[] */ } = source ; utterances /* JSONUtterance[] */ , prebuiltEntities /* prebuitl entities[] */", "del_tokens": "constructor ( { name /* string */ , versionId /* string */ , desc /* string */ , culture /* string */ , intents /* HierarchicalModel[] */ , entities /* HierarchicalModel[] */ , bing_entities /* string[] */ , actions /* JSONAction[] */ , closedLists /* JSONClosedList[] */ , composites /* HierarchicalModel[] */ , regex_features /* JSONRegexFeature[] */ , model_features /* JSONModelFeature[] */ , utterances /* JSONUtterance[] */ } = { } ) { utterances /* JSONUtterance[] */ const { name /* string */ , versionId /* string */ , desc /* string */ , culture /* string */ , intents /* HierarchicalModel[] */ , entities /* HierarchicalModel[] */ , bing_entities /* string[] */ , actions /* JSONAction[] */ , closedLists /* JSONClosedList[] */ , composites /* HierarchicalModel[] */ , regex_features /* JSONRegexFeature[] */ , model_features /* JSONModelFeature[] */ , utterances /* JSONUtterance[] */ } = source ; utterances /* JSONUtterance[] */", "commit_type": "fix"}
{"commit_tokens": ["moved", "Matter", ".", "Inspector", "and", "Matter", ".", "Gui", "to", "the", "MatterTools", "project"], "add_tokens": "Query = Matter . Query ; // MatterTools aliases var Gui = MatterTools . Gui , Inspector = MatterTools . Inspector ; _useInspector = false , if ( ! _isMobile && Inspector && _useInspector ) { if ( _engine . input . mouse . offset ) { _engine . input . mouse . offset . x = 0 ; _engine . input . mouse . offset . y = 0 ; }", "del_tokens": "Gui = Matter . Gui , Query = Matter . Query , Inspector = Matter . Inspector ; if ( ! _isMobile && Inspector ) { _engine . input . mouse . offset . x = 0 ; _engine . input . mouse . offset . y = 0 ;", "commit_type": "move"}
{"commit_tokens": ["Make", ".", "wait", "*", "actions", "reject", "Promise", "on", "timeout"], "add_tokens": "var TimeoutError = HorsemanPromise . TimeoutError ; debug ( '.waitForNextPage() timed out' ) ; if ( typeof self . page . onTimeout === 'function' ) { self . page . onTimeout ( ) ; } reject ( new TimeoutError ( 'timeout duing .waitForNextPage()' ) ) ; debug ( '.waitFor()' , fn . name || '<anonymous>' , value ) ; debug ( '.waitFor() timed out' ) ; if ( typeof self . page . onTimeout === 'function' ) { self . page . onTimeout ( ) ; } reject ( new TimeoutError ( 'timeout during .waitFor()' ) ) ;", "del_tokens": "reject ( 'Timeout occurred before url changed.' ) ; } ) . catch ( function ( err ) { if ( err === 'Timeout occurred before url changed.' ) { debug ( 'Timeout during waitForNextPage()' ) ; if ( typeof self . page . onTimeout === 'function' ) { self . page . onTimeout ( ) ; } } debug ( '.waitFor()' ) ; reject ( 'Timeout occurred before url changed.' ) } ) . catch ( function ( err ) { if ( err === 'Timeout occurred before url changed.' ) { debug ( 'Timeout during waitFor()' ) ; if ( typeof self . page . onTimeout === 'function' ) { self . page . onTimeout ( ) ; } }", "commit_type": "make"}
{"commit_tokens": ["Adding", "proper", "error", "implementation", "."], "add_tokens": "return new Error ( 'Template theme variables are not permitted ' + usage + ':\\n>>> ' + Node . toString ( parent ) ) ;", "del_tokens": "return 'Template theme variables are not permitted ' + usage + ':\\n>>> ' + Node . toString ( parent ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "extend", "less"], "add_tokens": "//extend helper function var extend = function ( destination , source ) { for ( var property in source ) { if ( destination [ property ] && ( typeof ( destination [ property ] ) == 'object' ) && ( destination [ property ] . toString ( ) == '[object Object]' ) && source [ property ] ) { extend ( destination [ property ] , source [ property ] ) ; } else { destination [ property ] = source [ property ] ; } } return destination ; } //less tree function extends options . treeFunctions = options . treeFunctions || { } ; if ( ! ! Object . keys ( options . treeFunctions ) . length ) { extend ( less . tree . functions , options . treeFunctions ) ; } } ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "snmp", "tests", "asserts", "for", "job", ".", "routingKey"], "add_tokens": "var graphId = uuid . v4 ( ) ; this . ipmi = new this . Jobclass ( { } , { graphId : graphId } , uuid . v4 ( ) ) ; expect ( this . ipmi . routingKey ) . to . equal ( graphId ) ;", "del_tokens": "this . ipmi = new this . Jobclass ( { } , { graphId : uuid . v4 ( ) } , uuid . v4 ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "doc", "for", "personality", "insights"], "add_tokens": "* - include_raw : include raw results *", "del_tokens": "* - include_raw : ? TODO *", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "up", "the", "coveralls", "issue"], "add_tokens": "var libPath = process . env [ 'CREATESEND_NODE_COV' ] ? './lib-cov' : './lib' ;", "del_tokens": "var libPath = process . env [ 'KALLY_RAZOR_COV' ] ? './lib-cov' : './lib' ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "emit", "to", "call", "local", "handlers", "without", "registration", ";", "export", "default"], "add_tokens": "export default class Emitter { * @ throws { TypeError } // add a wrapper around the handler and listen to the requested event // remove the wrapper so that the event doesn't call us again // emit locally first to onEvent handlers try { let sanitizedEvent = evt . replace ( / \\: / g , \"_\" ) , ProperEventCase = sanitizedEvent [ 0 ] . toUpperCase ( ) + sanitizedEvent . substr ( 1 ) , onProperEventCase = \"on\" + ProperEventCase , localHandler ; if ( localHandler = this [ onProperEventCase ] ) { if ( async ) { setImmediate ( ( ) => { tryWrapper ( localHandler . bind ( sender ) , sender , evt , ... args ) ; } ) ; } else { tryWrapper ( localHandler . bind ( sender ) , sender , evt , ... args ) ; } } } catch ( err ) { console . log ( \"EMITTER WARNING: Something broke while trying to call local methods.\" , err ) ; }", "del_tokens": "export class Emitter {", "commit_type": "allow"}
{"commit_tokens": ["Update", "node", "-", "example", ".", "js"], "add_tokens": "var XMLHttpRequest = require ( \"xmlhttprequest\" ) . XMLHttpRequest ; var Neb = require ( \"../dist/neb-node\" ) ; var neb = new Neb ( ) ; neb . api . getAccountState ( \"8a209cec02cbeab7e2f74ad969d2dfe8dd24416aa65589bf\" ) . then ( function ( state ) { console . log ( state ) ; neb . api . sendTransaction ( \"8a209cec02cbeab7e2f74ad969d2dfe8dd24416aa65589bf\" , \"22ac3a9a2b1c31b7a9084e46eae16e761f83f02324092b09\" , neb . nasToBasic ( 5 ) , parseInt ( state . nonce ) + 1 ) . then ( function ( result ) { console . log ( result ) ; } ) ; } ) . catch ( function ( err ) { console . log ( err ) ; } ) ; neb . admin . unlockAccount ( \"8a209cec02cbeab7e2f74ad969d2dfe8dd24416aa65589bf\" , \"passphrase\" ) . then ( function ( result ) { console . log ( result ) ; } ) . catch ( function ( err ) { console . log ( err ) ; } ) ; neb . api . getAccountState ( \"22ac3a9a2b1c31b7a9084e46eae16e761f83f02324092b09\" ) . then ( function ( state ) { console . log ( state ) ; } ) . catch ( function ( err ) { console . log ( err ) ; } ) ;", "del_tokens": "// var XMLHttpRequest = require(\"xmlhttprequest\").XMLHttpRequest; // var Neb = require(\"../dist/neb-node\"); // // var neb = new Neb(); // // console.log(neb.api.accounts()); // var state = neb.api.getAccountState(\"8a209cec02cbeab7e2f74ad969d2dfe8dd24416aa65589bf\"); // console.log(state); // var result = neb.admin.unlockAccount(\"8a209cec02cbeab7e2f74ad969d2dfe8dd24416aa65589bf\", \"passphrase\"); // console.log(result); // result = neb.api.sendTransaction(\"8a209cec02cbeab7e2f74ad969d2dfe8dd24416aa65589bf\", \"22ac3a9a2b1c31b7a9084e46eae16e761f83f02324092b09\", neb.nasToBasic(5), parseInt(state.nonce)+1); // console.log(result); // state = neb.api.getAccountState(\"22ac3a9a2b1c31b7a9084e46eae16e761f83f02324092b09\"); // console.log(state);", "commit_type": "update"}
{"commit_tokens": ["Remove", "css", "min", "-", "width", "from", "table", "on", "destroy"], "add_tokens": "$table . css ( 'minWidth' , '' ) ; } ) ( jQuery ) ;", "del_tokens": "} ) ( jQuery ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "info", "about", "unsupported", "Opbeat", "transports"], "add_tokens": "this . defaultPort = 80 ; // Opbeat currently doesn't support HTTP // Opbeat currently doesn't support UDP", "del_tokens": "this . defaultPort = 80 ;", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "to", "var", "coming", "from", "settings", ".", "json", "file", "to", "avoid", "errors"], "add_tokens": "var fromName = ( pluginSettings && pluginSettings . fromName ) ? pluginSettings . fromName : \"Etherpad\" ; var fromEmail = ( pluginSettings && pluginSettings . fromEmail ) ? pluginSettings . fromEmail : \"pad@etherpad.org\" ; var urlToPads = ( pluginSettings && pluginSettings . urlToPads ) ? pluginSettings . urlToPads : \"http://beta.etherpad.org/p/\" ; var emailServer = ( pluginSettings && pluginSettings . emailServer ) ? pluginSettings . emailServer : { host : \"127.0.0.1\" } ;", "del_tokens": "var fromName = pluginSettings . fromName || \"Etherpad\" ; var fromEmail = pluginSettings . fromEmail || \"pad@etherpad.org\" ; var urlToPads = pluginSettings . urlToPads || \"http://beta.etherpad.org/p/\" ; var emailServer = pluginSettings . emailServer || { host : \"127.0.0.1\" } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "carry", "on", "running", "after", "hint", "."], "add_tokens": "try { var results = inspector ( files , config ) ; var writer = new XmlWriter ( ) ; writer . writeResults ( results ) ; var output = spitterOuter ( results ) ; for ( var i = 0 ; i < output . length ; i ++ ) { console . log ( output [ i ] ) ; } } catch ( e ) { if ( config . watch ) { console . log ( \"Still watching... carry on BDD'ing!\" ) ; }", "del_tokens": "var results = inspector ( files , config ) ; var writer = new XmlWriter ( ) ; writer . writeResults ( results ) ; var output = spitterOuter ( results ) ; for ( var i = 0 ; i < output . length ; i ++ ) { console . log ( output [ i ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "SSH", "command", "spawn", "."], "add_tokens": "[ 'user@host' , 'my-command' , '-x' ] , [ '-tt' , 'user@host' , 'sudo my-command' , '-x' ] ,", "del_tokens": "[ 'my-command' , '-x' ] , [ '-tt' , 'sudo my-command' , '-x' ] ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "identity", "function", "as", "default", "transform", "for", "schemas"], "add_tokens": "import identity from 'lodash/identity' ; export default function ssml ( tagName , props , ... args ) { if ( typeof tagName === 'function' ) { return tagName ( { ... props , children } ) ; if ( typeof tagName !== 'string' ) { throw new Error ( ` ${ tagName } ` ) ; // make sure we have a known tag const { tag , schema , transform = identity } = schemas [ tagName . toLowerCase ( ) ] || { } ; if ( ! tag ) { throw new Error ( ` ${ tagName } ` ) ; tag , props : transform ( validateProps ( props , schema ) ) ,", "del_tokens": "export default function ssml ( tag , props , ... args ) { if ( typeof tag === 'function' ) { return tag ( { ... props , children } ) ; if ( typeof tag !== 'string' ) { throw new Error ( ` ${ tag } ` ) ; // make sure we have a known tag const type = schemas [ tag . toLowerCase ( ) ] ; if ( ! type ) { throw new Error ( ` ${ tag } ` ) ; // validate and transform props let newProps = validateProps ( props , type . schema ) ; newProps = type . transform ( newProps ) ; tag : type . tag , props : newProps ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "animation", "width", "/", "height", "."], "add_tokens": "if ( this . frames . length === 1 ) {", "del_tokens": "if ( frames . length === 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "template", "ViewEventListener", ".", "py"], "add_tokens": "let methodsDefaultValue = [ true , false , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null ]", "del_tokens": "let methodsDefaultValue = [ false , false , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "sign", "-", "tx", "only", "without", "broadcast"], "add_tokens": "if ( ! isNode ) NRS . showRawTransactionModal ( response ) ; callback ( response ) ;", "del_tokens": "NRS . showRawTransactionModal ( response ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "issues", "with", "undefined", "values"], "add_tokens": "let val , isobj ; isobj = true ; isobj = false ; let undef = typeof val === \"undefined\" ; if ( ! isobj ) { if ( safe && ! undef ) return val ; else if ( ! safe || undef ) { let args = toArray ( arguments ) . slice ( 2 ) ; for ( let i = 0 ; i < args . length ; i ++ ) {", "del_tokens": "let val ; if ( ! isPlainObject ( val ) ) { if ( safe ) return val ; else if ( ! safe ) { var args = toArray ( arguments ) . slice ( 2 ) ; for ( var i = 0 ; i < args . length ; i ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "so", "bound", "text", "inputs", "retian", "their", "cursor", "position", "when", "changed", "."], "add_tokens": "inputTypes = { 'null' : true , 'text' : true , 'email' : true , 'password' : true , 'search' : true , 'url' : true , 'tel' : true , 'hidden' : true , 'number' : true , 'color' : true , 'date' : true , 'datetime' : true , 'datetime-local:' : true , 'month' : true , 'range' : true , 'time' : true , 'week' : true } , return ( domElement . value !== String ( attr ) ) ? domElement . value = ( attr || '' ) : attr ;", "del_tokens": "inputTypes = { 'null' : true , 'text' : true , 'email' : true , 'password' : true , 'search' : true , 'url' : true , 'tel' : true , 'hidden' : true } , return domElement . value = ( attr ) ? attr : '' ;", "commit_type": "fix"}
{"commit_tokens": ["update", "basic", "package", "-", "file", "testing"], "add_tokens": "/* jshint -W097 */ /* jshint strict:false */ /* jslint node: true */ /* jshint expr: true */ expect ( ioPackage . common . authors ) . to . exist ; if ( ioPackage . common . name . indexOf ( 'template' ) !== 0 ) { if ( Array . isArray ( ioPackage . common . authors ) ) { expect ( ioPackage . common . authors . length ) . to . not . be . equal ( 0 ) ; if ( ioPackage . common . authors . length === 1 ) { expect ( ioPackage . common . authors [ 0 ] ) . to . not . be . equal ( 'my Name <my@email.com>' ) ; } } else { expect ( ioPackage . common . authors ) . to . not . be . equal ( 'my Name <my@email.com>' ) ; } } else { console . log ( 'Testing for set authors field in io-package skipped because template adapter' ) ; }", "del_tokens": "/* jshint -W097 */ // jshint strict:false /*jslint node: true */", "commit_type": "update"}
{"commit_tokens": ["improve", "error", "phrasing", "to", "be", "more", "clear"], "add_tokens": "* version 2.4 .2 message : 'resource not found' ,", "del_tokens": "* version 2.4 .1 message : 'endpoint unreachable' ,", "commit_type": "improve"}
{"commit_tokens": ["Implement", "basic", "sequential", "search", "and", "update", "readme"], "add_tokens": "* Re - implementation of readtags . c in nodejs findSequential ( tag ) { return Promise . coroutine ( function * findit ( self ) { const matches = [ ] let line while ( line = yield self . _readTagLine ( ) ) { const entry = self . _parseTagLine ( line ) if ( entry . valid && entry . name === tag ) { matches . push ( entry ) } } return matches } ) ( this ) }", "del_tokens": "* Re - implementation of readtags . c in nodejs", "commit_type": "implement"}
{"commit_tokens": ["add", "file", "hashing", "functionality", "to", "react", "fine", "uploader"], "add_tokens": "function makeTextFile ( text , file ) { let textFileBlob = new Blob ( [ text ] , { type : 'text/plain' } ) ; let textFile = new File ( [ textFileBlob ] , 'hash-of-' + file . name + '.txt' , { lastModifiedDate : file . lastModifiedDate , lastModified : file . lastModified , type : 'text/plain' } ) ; return textFile ; let blobTextFile = makeTextFile ( fileHash , file ) ; resolve ( blobTextFile ) ;", "del_tokens": "function makeTextFile ( text ) { let data = new Blob ( [ text ] , { type : 'text/plain' } ) ; return window . URL . createObjectURL ( data ) ; let hashFile = makeTextFile ( fileHash ) ; console . info ( 'hash: ' , hashFile ) ; resolve ( hashFile ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "provisionConfig", "static", "function", "to", "Config", "class"], "add_tokens": "tmpOpenSslConfigFile = tmp . fileSync ( ) if ( options . san && options . san . length ) {", "del_tokens": "tmpOpenSslConfigFile = tmp . fileSync ( { } ) if ( options . san . length > 0 ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "issues", "with", "Connections", "view"], "add_tokens": "} else if ( connections . length > 0 ) { this . setSelectedIndex ( 0 ) ; return connections [ 0 ] ; } else if ( discoveredList . length > 0 ) { this . setDiscoveredIndex ( 0 ) ; return discoveredList [ 0 ] ; return \"2.2\" ;", "del_tokens": "} else { return undefined ; return \"2.1\" ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "node", "url", ".", "parse", "definition"], "add_tokens": "parseQueryString ? : boolean ,", "del_tokens": "parseQueryString : ? boolean ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "GCE", "info", "in", "the", "example", "README", ".", "Don", "t", "repeat", "log", "entries", "when", "deploying"], "add_tokens": "let previousPodStatus = '' ; const currentPodStatus = _ . map ( functionPods , p => ( JSON . stringify ( p . status . containerStatuses [ 0 ] . state ) ) ) ; if ( ! _ . isEqual ( previousPodStatus , currentPodStatus ) ) { this . serverless . cli . log ( ` ${ funcName } ` + ` ${ currentPodStatus } ` ) ; previousPodStatus = currentPodStatus ; }", "del_tokens": "this . serverless . cli . log ( ` ${ funcName } ` + ` ${ _ . map ( functionPods , p => JSON . stringify ( p . status . containerStatuses [ 0 ] . state ) ) } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "in", "first", "impl", "of", "chrome", ".", "runtime", ".", "lastError"], "add_tokens": "typeof callback == \"function\" && callback ( chrome . runtime . lastError , openInfo ) ; chrome . serial . send ( this . connectionId , buffer , function ( info ) { callback ( chrome . runtime . lastError , info ) ; } ) ; SerialPort . prototype . onClose = function ( callback , result ) { console . log ( \"Closed port\" , result ) ; typeof callback == \"function\" && callback ( chrome . runtime . lastError , result ) ; callback ( chrome . runtime . lastError , result ) ; callback ( chrome . runtime . lastError , portObjects ) ;", "del_tokens": "typeof callback == \"function\" && callback ( null , openInfo ) ; chrome . serial . send ( this . connectionId , buffer , callback ) ; SerialPort . prototype . onClose = function ( callback ) { console . log ( \"Closed port\" , arguments ) ; typeof callback == \"function\" && callback ( null ) ; if ( result ) callback ( ) ; else callback ( result ) ; callback ( null , portObjects ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "stringReadable", "test", "fix", "convenience", "constructor", "test"], "add_tokens": "var flushed = false ; var flushed = false ; . intoString ( function ( error ) { . intoString ( function ( error ) {", "del_tokens": ". intoString ( function ( error , str ) { . intoString ( function ( error , str ) {", "commit_type": "add"}
{"commit_tokens": ["Adds", "test", "for", "non", "-", "transformable", "stateful", "component"], "add_tokens": "test ( 'Happy path' , async t => { const componentName = 'component-stateful' ; const fixturePath = path . resolve ( __dirname , '..' , 'fixtures' , componentName ) ; test ( 'With not transformable component' , async t => { const componentName = 'component-stateful-no-transform' ; const fixturePath = path . resolve ( __dirname , '..' , 'fixtures' , componentName ) ; const tempDir = tempy . directory ( ) ; const filePath = path . join ( tempDir , componentName , ` ${ componentName } ` ) ; fsExtra . copySync ( fixturePath , path . join ( tempDir , componentName ) ) ; const error = await t . throwsAsync ( toStateless ( { eslintConfig , filePath } ) . catch ( errorMessage => { throw new Error ( errorMessage ) ; } ) ) ; t . is ( ` Component can '  s ate o r ferences t s ate  c ass m thods  r fs`, // NOTE: the error message also contains a stack trace after the fourth line with is excluded here error . message . split ( '\\n' ) . slice ( 0 , 4 ) . join ( '\\n' ) ) ; } ) ;", "del_tokens": "const componentName = 'component-stateful' ; const fixturePath = path . resolve ( __dirname , '..' , 'fixtures' , componentName ) ; test ( 'To stateless' , async t => {", "commit_type": "add"}
{"commit_tokens": ["added", "unit", "tests", "for", "readStream"], "add_tokens": "var types = [ 'continent' , 'country' , 'county' , 'dependency' , 'disputed' , 'empire' , 'localadmin' , 'locality' , 'macrocounty' , 'macrohood' , 'macroregion' , 'metroarea' , 'microhood' , 'neighbourhood' , 'region' ] ; readStream ( directory , types , wofRecords , function ( ) {", "del_tokens": "readStream ( directory , wofRecords , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "try", "/", "catch", "block", "to", "give", "better", "error", "messages"], "add_tokens": "return require ( filePath ) ;", "del_tokens": "var config ; try { config = require ( filePath ) ; } catch ( err ) { // handle only not found errors, throw the rest if ( err . code === \"MODULE_NOT_FOUND\" ) { throw new Error ( \"Config not found at '\" + filePath + \"'\" ) ; } throw err ; } return config ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "type", "of", "fontSize", "style"], "add_tokens": "fontSize : numberOrString ,", "del_tokens": "fontSize : string ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "property", "method", "assignment"], "add_tokens": "case ParseTreeType . PROPERTY_METHOD_ASSIGNMENT : 'accessor, property name assignment or property method assigment expected' ) ;", "del_tokens": "'accessor or property name assignment expected' ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "sync", "info", "event", "to", "sync_info", "to", "avoid", "overlap", "with", "backbone", "builtins"], "add_tokens": "self . trigger ( 'sync_info' , syncInfo ) ; module . exports = Db ;", "del_tokens": "self . trigger ( 'sync' , syncInfo ) ; module . exports = Db ;", "commit_type": "change"}
{"commit_tokens": ["Make", "buffer", "size", "and", "interval", "configurable"], "add_tokens": "function WebSocketStream ( target , protocols , options ) { if ( protocols && ! Array . isArray ( protocols ) && 'object' === typeof protocols ) { // accept the \"options\" Object as the 2nd argument options = protocols protocols = null } if ( ! options ) options = { } // browser only: sets the maximum socket buffer size before throttling var bufferSize = options . browserBufferSize || 1024 * 512 // browser only: how long to wait when throttling var bufferTimeout = options . browserBufferTimeout || 1000 socket = new WS ( target , protocols , options ) if ( socket . bufferedAmount > bufferSize ) { setTimeout ( socketWriteBrowser , bufferTimeout , chunk , enc , next )", "del_tokens": "function WebSocketStream ( target , protocols ) { socket = new WS ( target , protocols ) if ( socket . bufferedAmount > 16384 ) { setTimeout ( socketWriteBrowser , 10 , chunk , enc , next )", "commit_type": "make"}
{"commit_tokens": ["update", "dataset", "watchers", "to", "handle", "datasets", "which", "are", "not", "set", "on", "startup"], "add_tokens": "scope . chooseDatasetWatcher ( ) ; var length = 0 ; if ( angular . isArray ( scope . dataset ) ) { length = scope . dataset . length ; } if ( length < limit ) {", "del_tokens": "if ( angular . isArray ( scope . dataset ) ) { scope . chooseDatasetWatcher ( ) ; } if ( scope . dataset . length < limit ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "suffix", "like", "@2x", "and", "_2x", "."], "add_tokens": "// Check whether the image is retina, // Both `@2x` and `_2x` are support. return / [@_](\\d)x\\.[a-z]{3,4}$ / gi . test ( url ) ; var matches = / [@_](\\d)x\\.[a-z]{3,4}$ / gi . exec ( url ) ; if ( ! matches ) { return 1 ; }", "del_tokens": "// Check whether the image is retina return / @(\\d)x\\.[a-z]{3,4}$ / gi . test ( url ) ; var matches = / @(\\d)x\\.[a-z]{3,4}$ / gi . exec ( url ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tolerance", "for", "images", "with", "no", "src", "attribute"], "add_tokens": "return src ? '![' + ( alt && alt [ 1 ] ? alt [ 1 ] : '' ) + ']' + '(' + src [ 1 ] + ( title && title [ 1 ] ? ' \"' + title [ 1 ] + '\"' : '' ) + ')' : '' ;", "del_tokens": "return '![' + ( alt && alt [ 1 ] ? alt [ 1 ] : '' ) + ']' + '(' + src [ 1 ] + ( title && title [ 1 ] ? ' \"' + title [ 1 ] + '\"' : '' ) + ')' ;", "commit_type": "add"}
{"commit_tokens": ["removed", "submodules", "new", "builds", "updated", "CHANGES"], "add_tokens": "almond : '../utils/almond' , start : \"//v0.1.2 toxiclibs.js (http://haptic-data.com/toxiclibsjs)\\nvar toxi = {};\\n(function(){\\n\" ,", "del_tokens": "almond : '../utils/almond/almond' , start : \"//v0.1.1 toxiclibs.js (http://haptic-data.com/toxiclibsjs)\\nvar toxi = {};\\n(function(){\\n\" ,", "commit_type": "remove"}
{"commit_tokens": ["updated", "some", "package", "related", "files"], "add_tokens": "const Needle = { } ; Needle . SinglyLinkedList = SinglyLinkedList ; Needle . Queue = Queue ; Needle . Stack = Stack ; Needle . DoublyLinkedList = DoublyLinkedList ; Needle . BinaryHeap = BinaryHeap ; Needle . BinarySearchTree = BinarySearchTree ; Needle . Hashmap = Hashmap ; Needle . SortedArray = SortedArray ; Needle . RollingHash = RollingHash ; exports = module . exports = Needle ; window . Needle = Needle ;", "del_tokens": "const needle = { } ; needle . SinglyLinkedList = SinglyLinkedList ; needle . Queue = Queue ; needle . Stack = Stack ; needle . DoublyLinkedList = DoublyLinkedList ; needle . BinaryHeap = BinaryHeap ; needle . BinarySearchTree = BinarySearchTree ; needle . Hashmap = Hashmap ; needle . SortedArray = SortedArray ; needle . RollingHash = RollingHash ; exports = module . exports = needle ; window . needle = needle ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "bin", "check", "when", "JAVA_HOME", "unset"], "add_tokens": "if ( process . env . JAVA_HOME ) { let javaHomeBin = path . resolve ( process . env . JAVA_HOME , 'bin' ) ; if ( process . env . PATH . indexOf ( javaHomeBin ) + 1 ) { return ok ( 'Bin directory of $JAVA_HOME is set' ) ; }", "del_tokens": "let javaHomeBin = path . resolve ( process . env . JAVA_HOME , 'bin' ) ; if ( process . env . PATH . indexOf ( javaHomeBin ) + 1 ) { return ok ( 'Bin directory of $JAVA_HOME is set' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "metadata", "from", "column", "selector"], "add_tokens": "var keys = _ . keys ( _ . omit ( this . props . results [ 0 ] , meta ) ) ;", "del_tokens": "var keys = _ . keys ( this . props . results [ 0 ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "issue", "with", "parsing", "AESearch", "service", "instance", "in", "VCAP"], "add_tokens": "for ( var key in vcapServices [ 'user-provided' ] ) { var fullInfo ; if ( vcapServices [ 'user-provided' ] [ key ] . name . indexOf ( 'AESearch' ) === 0 ) { // If we are bound to the analytics elastic search service, // the SDK will be running in elasticsearch mode. logger . log ( 'Bound to Analytics Elasticsearch service. SDK will use Elasticsearch.' ) ; fullInfo = vcapServices [ key ] [ 0 ] ; if ( fullInfo . credentials ) { esCredentials = fullInfo . credentials ;", "del_tokens": "for ( var key in vcapServices ) { if ( vcapServices . hasOwnProperty ( key ) ) { var fullInfo ; if ( key . indexOf ( 'AESearch' ) === 0 ) { // If we are bound to the analytics elasticsearch service, // the SDK will be running in elasticsearch mode. logger . log ( 'Bound to Analytics Elasticsearch service. SDK will use Elasticsearch.' ) ; fullInfo = vcapServices [ key ] [ 0 ] ; if ( fullInfo . credentials ) { esCredentials = fullInfo . credentials ; }", "commit_type": "fix"}
{"commit_tokens": ["Updated", "slate", "-", "irc", "and", "tabcomplete"], "add_tokens": ". tabcomplete ( commands , { hint : false } ) ; . tabcomplete ( commands , { hint : false } )", "del_tokens": ". tabComplete ( commands , { hint : false } ) ; . tabComplete ( commands , { hint : false } )", "commit_type": "update"}
{"commit_tokens": ["add", "createTopics", "&", "modify", "interface", "param", "for", "zookeeper"], "add_tokens": "if ( topic . topicError !== 0 ) { topicMetadata [ topic . topicName ] = { } ; continue ; } console . log ( 'hihi' , topics ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "example", "formatting", "a", "bit"], "add_tokens": "/ * Parses the AST of a set of JavaScript files , uses report rules to convert the AST into a report , and optionally combines the report with the view or renders the report into an output format . @ example var doctor = require ( 'doctor' ) ; var options = { files : [ 'package.json' ] , view : [ 'default' , 'doctor' ] } ; doctor . examine ( options , function ( err , report ) { console . log ( JSON . stringify ( report ) ) ; } ) * /", "del_tokens": "/ * Parses the AST of a set of JavaScript files, uses report rules to convert the AST into a report , and optionally combines the report with the view or renders the report into an output format . * /", "commit_type": "fix"}
{"commit_tokens": ["Add", "tip", "for", "incorrect", "2x", "or", "3x", "dimensions", "."], "add_tokens": "// 2x check even dimensions. if ( image . ratio == 2 ) { if ( image . coordinates [ 'width' ] % 2 !== 0 || image . coordinates [ 'height' ] % 2 !== 0 ) { log ( options . logLevel , 'lv3' , [ 'Lazysprite:' , gutil . colors . red ( path . relative ( process . cwd ( ) , image . path ) ) , '`2x` image should have' + ' even dimensions.' ] ) ; } } // 3x check dimensions. if ( image . ratio == 3 ) { if ( image . coordinates [ 'width' ] % 3 !== 0 || image . coordinates [ 'height' ] % 3 !== 0 ) { log ( options . logLevel , 'lv3' , [ 'Lazysprite:' , gutil . colors . red ( path . relative ( process . cwd ( ) , image . path ) ) , '`3x` image should have' + ' correct dimensions.' ] ) ; } }", "del_tokens": "// debug(sourceImgPath) // fs.stat(sourceImgPath, function (err, stat) { // if (err == null) { // image.hasSourceImg = true; // } else { // image.hasSourceImg = false; // } // });", "commit_type": "add"}
{"commit_tokens": ["Fix", "toString", "without", "col", "widths", "by", "cloning", "array"], "add_tokens": ", colWidths = options . colWidths || new Array ( this . head . length ) this . slice ( 0 ) . concat ( [ head ] ) . forEach ( function ( cells ) {", "del_tokens": ", colWidths = options . colWidths || [ ] this . concat ( [ head ] ) . forEach ( function ( cells ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "to", "supply", "the", "PORT", "RANGE", "https", ":", "//", "github", ".", "com", "/", "shakyShane", "/", "grunt", "-", "browser", "-", "sync", "/", "issues", "/", "9"], "add_tokens": "// Ports Config defaultConfig = this . _setPortsConfig ( defaultConfig , argv ) ; / ** * * @ param { Object } defaultConfig * @ param { Object } argv * @ returns { Object } * @ private * / _setPortsConfig : function ( defaultConfig , argv ) { if ( argv . ports ) { if ( typeof argv . ports === \"number\" ) { defaultConfig . ports = { min : argv . ports } } else { var split = argv . ports . replace ( \" \" , \"\" ) . split ( \",\" ) ; defaultConfig . ports = { min : parseInt ( split [ 0 ] , 10 ) , max : ( split [ 1 ] ) ? parseInt ( split [ 1 ] , 10 ) : null } ; } } return defaultConfig ; } ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "defered", "call", "using", "setImmediate", "to", "avoid", "the", "call", "stack"], "add_tokens": "async . times ( 250000 , function forEach ( n , next ) { setImmediate ( function ( ) { data . push ( { name : generateRandomName ( ) , id : n } ) ; return next ( ) ;", "del_tokens": "async . times ( 1400 , function forEach ( n , next ) { data . push ( { name : generateRandomName ( ) , id : n return next ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "controlled", "components", "(", "WIP", ")"], "add_tokens": "var value = input . props . value ; var dispatchChange = input . props . hasOwnProperty ( 'value' ) ? function ( ) { return dispatch ( changeMethod ( model , value ) ) ; } : function ( e ) { return dispatch ( changeMethod ( model , e ) ) ; } ; dispatchChange = function ( e ) { return dispatch ( changeMethod ( model , e ) ) ; } ; dispatchChange = function ( e ) { return dispatch ( changeMethod ( model , e ) ) ; } ;", "del_tokens": "var value = input . props . value || props . value || '' ; var dispatchChange = input . props . hasOwnProperty ( 'value' ) ? function ( ) { return dispatch ( changeMethod ( model , value ) ) ; } : function ( e ) { return dispatch ( changeMethod ( model , e ) ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["updating", "regex", "to", "let", "bad", "quotes", "through"], "add_tokens": ", WHITELIST_PRESERVE_LINEBREAKS = / [^A-Za-z\\x80-\\xFF 0-9 \\u2018\\u2019\\u2026 \\u4E00-\\u9FFF \\.,\\?\"\"!@#\\$%\\^&\\*\\(\\)-_=\\+;:<>\\/\\\\\\|\\}\\{\\[\\]`~'-\\w\\n\\r]* / g , WHITELIST_STRIP_LINEBREAKS = / [^A-Za-z\\x80-\\xFF 0-9 \\u2018\\u2019\\u2026 \\u4E00-\\u9FFF \\.,\\?\"\"!@#\\$%\\^&\\*\\(\\)-_=\\+;:<>\\/\\\\\\|\\}\\{\\[\\]`~'-\\w]* / g", "del_tokens": ", WHITELIST_PRESERVE_LINEBREAKS = / [^A-Za-z\\x80-\\xFF 0-9 \\u2026 \\u4E00-\\u9FFF \\.,\\?\"\"!@#\\$%\\^&\\*\\(\\)-_=\\+;:<>\\/\\\\\\|\\}\\{\\[\\]`~'-\\w\\n\\r]* / g , WHITELIST_STRIP_LINEBREAKS = / [^A-Za-z\\x80-\\xFF 0-9 \\u2026 \\u4E00-\\u9FFF \\.,\\?\"\"!@#\\$%\\^&\\*\\(\\)-_=\\+;:<>\\/\\\\\\|\\}\\{\\[\\]`~'-\\w]* / g", "commit_type": "update"}
{"commit_tokens": ["Use", "documentElement", "when", "matching", "delegated", "event", "targets"], "add_tokens": "unit . test ( 'domEvents.addDelegateListener handles document correctly' , function ( assert ) { var html = document . querySelector ( 'html' ) ; var handler = function handler ( ) { } ; domEvents . addDelegateListener ( html , 'click' , 'input' , handler ) ; domEvents . dispatch ( html , 'click' ) ; domEvents . removeDelegateListener ( html , 'click' , 'input' , handler ) ; assert . ok ( true , 'works' ) ; } ) ;", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "update", "function", "s", "time", "argument", "in", "the", "spinning", "example", "and", "cleanup", "code", "."], "add_tokens": "var angle = 0 ; // This gets called every frame. // Update your game state here. game . update ( function ( t ) { // Calculate one rotation per second, in radians angle = ( 2 * Math . PI / 60 ) * t ; fillRotatedRect ( ctx , 50 , 100 , 200 , 20 , angle ) ; fillRotatedRect ( ctx , 400 , 50 , 200 , 150 , - angle / 8 ) ; fillRotatedRect ( ctx , 200 , 250 , 200 , 200 , angle * 0.5 ) ;", "del_tokens": "var seconds = 0 ; // This gets called every frame. Update your game state here. game . update ( function ( ) { // Calculate the time passed, based on 60 frames per second seconds += 1 / 60 ; // Calculate one rotation per second var angle = seconds * ( Math . PI / 2 ) ; fillRotatedRect ( ctx , 50 , 100 , 200 , 20 , angle * 4 ) ; fillRotatedRect ( ctx , 400 , 50 , 200 , 150 , - angle / 2 ) ; fillRotatedRect ( ctx , 200 , 250 , 200 , 200 , angle * 2 ) ;", "commit_type": "use"}
{"commit_tokens": ["updated", "providers", "and", "added", "tests", "for", "all", "providers"], "add_tokens": "apiKey : 'TEST' } ) ( ) ;", "del_tokens": "apiKey : 'TEST' , environment : 'production' , verbose : true } ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Move", "AST", "helpers", "into", "helpers", "/", "ast", "directory"], "add_tokens": "import toReference from \"./helpers/ast/to-reference\" ; import toFunctionCall from \"./helpers/ast/to-function-call\" ;", "del_tokens": "toReference , toFunctionCall ,", "commit_type": "move"}
{"commit_tokens": ["Add", "alias", "for", "host", "."], "add_tokens": "inside = inside . replace ( / ^\\\\\\*$ / g , '(?:(?<host>.+))' ) ;", "del_tokens": "inside = inside . replace ( / ^\\\\\\*$ / g , '(?:(.+))' ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "spread", "operator", "instead", "of", "lodash", "/", "toArray", "."], "add_tokens": "opts . base = resolver . glob ( [ ... opts . base ] ) ;", "del_tokens": "const toarray = require ( 'lodash/toArray' ) ; opts . base = resolver . glob ( toarray ( opts . base ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "spelling", "mistake", "in", "docs"], "add_tokens": "* Call the callback stored with the given id . Also do some internal", "del_tokens": "* Call the calback stored with the given id . Also do some internal", "commit_type": "fix"}
{"commit_tokens": ["Removed", "an", "extra", "semicolon", "."], "add_tokens": "fontDescription , fontTestString ) ;", "del_tokens": "fontDescription , fontTestString ) ; ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "partial", "arc", "bug", "in", "IE", "(", "degrees", "-", ">", "radians", ")"], "add_tokens": "ctx . arc ( point . canvasx , point . canvasy , pointSize , 0 , 2 * Math . PI , false ) ;", "del_tokens": "ctx . arc ( point . canvasx , point . canvasy , pointSize , 0 , 360 , false ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "populate", "with", "undefined", "array", "field"], "add_tokens": "return result && val && ! validator . isMongoId ( val . toString ( ) ) ; return obj && ! validator . isMongoId ( obj . toString ( ) ) ;", "del_tokens": "return result && ! validator . isMongoId ( val . toString ( ) ) ; return ! validator . isMongoId ( obj . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "previous", "commit", ";", "more", "optimizations", "."], "add_tokens": "this . holidays = holidays . getHolidaysForYear ( year ) . filter ( function ( h ) { return h . date . getMonth ( ) === month ; } , this ) ; var year = this . getYearObject ( ) ; var year = this . getYearObject ( ) ;", "del_tokens": "var year = ( this . getMonthObject ( ) && this . getYearObject ( ) ) || new Hebcal ( this . getFullYear ( ) ) ; var year = ( this . getMonthObject ( ) && this . getYearObject ( ) ) || new Hebcal ( this . getFullYear ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "it", "possible", "to", "extend", "the", "ticker", "s", "config", "after", "construction"], "add_tokens": "it ( 'missing config properties should result in an error when starting' , function ( ) { var ticker = Ticker ( ) ; ticker . start . bind ( ticker ) . should [ 'throw' ] ( / missing config prop / i ) ; ticker . use ( { } ) . start . bind ( ticker ) . should . not [ 'throw' ] ( Error ) ;", "del_tokens": "it ( 'missing config properties should result in an error' , function ( ) { Ticker . should [ 'throw' ] ( / missing config prop / i ) ; Ticker . bind ( null , { } ) . should . not [ 'throw' ] ( Error ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "coverage", "and", "complexity", "analysis"], "add_tokens": "var error = { noFilename : 'Missing fileName option for gulp-concat-filenames' , noStreaming : 'Streaming not supported' } ; throw new PluginError ( 'gulp-concat-filenames' , error . noFilename ) ; var errorNoStream = new PluginError ( 'gulp-concat-filenames' , error . noStreaming ) ;", "del_tokens": "throw new PluginError ( 'gulp-concat-filenames' , 'Missing fileName option for gulp-concat-filenames' ) ; var errorNoStream = new PluginError ( 'gulp-concat-filenames' , 'Streaming not supported' ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "examples", "easier", "to", "read", "and", "added", "link", "to", "CodePen"], "add_tokens": "if ( ! e ) { history . pushState ( null , '' , path ) ; _this3 . setState ( { location : path } ) ;", "del_tokens": "if ( e === null || e === undefined || e === false ) { history . pushState ( null , '' , to ) ; return _this3 . setState ( { location : path } ) ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "a", "partials", "dir", "s", "templates", "to", "be", "preloaded", "by", "the", "user"], "add_tokens": "var templates ; var namespace ; // templates promise and a namespace. templates = dir . templates ; namespace = dir . namespace ; dir = dir . dir ; templates || ( templates = this . getTemplates ( dir , options ) ) ; return templates . then ( function ( templates ) { namespace : namespace } ;", "del_tokens": "var dirOptions = options ; // namespace. dirOptions = utils . extend ( { } , options , dir ) ; dir = dir . dir ; return this . getTemplates ( dir , dirOptions ) . then ( function ( templates ) { namespace : dirOptions . namespace } ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "unit", "tests", "to", "use", "the", "new", "Node", ".", "js", "signature", "for", "EnvelopesApi", ".", "getDocument"], "add_tokens": "envelopesApi . getDocument ( accountId , envelopeSummary . envelopeId , 'combined' , null , function ( err , pdfBytes , response ) { envelopesApi . getDocument ( accountId , envelopeSummary . envelopeId , 'combined' , null , function ( error , pdfBytes , response ) {", "del_tokens": "envelopesApi . getDocument ( accountId , envelopeSummary . envelopeId , 'combined' , function ( err , pdfBytes , response ) { envelopesApi . getDocument ( accountId , envelopeSummary . envelopeId , 'combined' , function ( error , pdfBytes , response ) {", "commit_type": "update"}
{"commit_tokens": ["made", "e2e", "run", "against", "dist"], "add_tokens": "} = require ( \"../dist/open-attestation\" ) ;", "del_tokens": "// digestDocument, // sign, } = require ( \"../src/index\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "to", "allow", "the", "user", "to", "specify", "whether", "the", "currDragItem"], "add_tokens": "/ ** * Whether the currDragItem is always displayed . By default the list * collapses , the currDragItem ' * hover over a draglist . * @ type { boolean } * @ private * / this . isCurrDragItemAlwaysDisplayed_ = false ; / ** * Sets the property of the currDragItem that it is always displayed in the * list . * / goog . fx . DragListGroup . prototype . setIsCurrDragItemAlwaysDisplayed = function ( ) { this . isCurrDragItemAlwaysDisplayed_ = true ; } ; // Not hovering over a drag list, so remove the item altogether unless // specified otherwise by the user. if ( ! this . isCurrDragItemAlwaysDisplayed_ ) { this . currDragItem_ . style . display = 'none' ; }", "del_tokens": "// Not hovering over a drag list, so remove the item altogether. this . currDragItem_ . style . display = 'none' ;", "commit_type": "add"}
{"commit_tokens": ["Add", "column", "to", "error", "tests"], "add_tokens": "line : ex . line , column : ex . column", "del_tokens": "line : ex . line", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "atlas", "file"], "add_tokens": "\"three\" : \"THREE\" , \"jquery\" : \"$\"", "del_tokens": "// \"three\": \"THREE\", // \"jquery\": \"jquery\"", "commit_type": "add"}
{"commit_tokens": ["Improve", "testing", "framework", "set", "up"], "add_tokens": "Generates a UUIDv4 compliant string that should be reasonably unique Excerpt from : http : //www.broofa.com/Tools/Math.uuid.js (v1.4) Intended to be inherited by objects with properties that store display values in a language based \"dictionary\"", "del_tokens": "Excerpt from : Math . uuid . js ( v1 .4 ) Intended to be inherited by objects with properties that store display values in a language based \"dictionary\"", "commit_type": "improve"}
{"commit_tokens": ["Changed", "assets", "to", "resources", "to", "match", "with", "change", "in", "Webpack", "Web"], "add_tokens": "if ( WEB && settings . build . resources ) { return settings . build . resources . map ( ( path ) => {", "del_tokens": "if ( WEB && settings . build . assets ) { return settings . build . assets . map ( ( path ) => {", "commit_type": "change"}
{"commit_tokens": ["Make", "moduleDefines", "more", "space", "tolerant"], "add_tokens": "return input . replace ( / \\bdefine\\s*\\(\\s*function\\s*\\(require,\\s*exports,\\s*module\\)\\s*\\{ / ,", "del_tokens": "return input . replace ( / \\bdefine\\(\\s*function\\s*\\(require,\\s*exports,\\s*module\\)\\s*\\{ / ,", "commit_type": "make"}
{"commit_tokens": ["Fix", "logout", "bug", ".", "(", "destroyData", ")"], "add_tokens": "destroyData : function ( session ) { return feathersClient . logout ( ) . then ( function ( ) { return session ; } ) ;", "del_tokens": "destroyData : function ( ) { return Promise . resolve ( feathersClient . logout ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "React", "16", "."], "add_tokens": "xtest ( 'opens and closes on click' , ( ) => { xtest ( 'closes on outside click' , ( ) => {", "del_tokens": "test ( 'opens and closes on click' , ( ) => { test ( 'closes on outside click' , ( ) => {", "commit_type": "update"}
{"commit_tokens": ["Move", "logging", "to", "a", "better", "place"], "add_tokens": "if ( modules . length ) { else { console . log ( 'jQuery is not used.' ) ; }", "del_tokens": "if ( modules ) {", "commit_type": "move"}
{"commit_tokens": ["adding", "bitbucket", "support", "to", "command", "line", "and", "indicating", "it", "in", "readme"], "add_tokens": ", mode = 'github.com' function transformAndSave ( files , mode ) { , result = transform ( content , mode ) ; if ( argv . length < 3 ) { var bitbucketIdx = argv . indexOf ( '--bitbucket' ) ; if ( ~ bitbucketIdx ) { mode = 'bitbucket.org' ; argv . splice ( bitbucketIdx , 1 ) ; } console . log ( '\\nDocToccing \"%s\" and its sub directories for %s.' , target , mode ) ; console . log ( '\\nDocToccing single file \"%s\" for %s.' , target , mode ) ; transformAndSave ( files , mode ) ;", "del_tokens": "function transformAndSave ( files ) { , result = transform ( content ) ; if ( argv . length !== 3 ) { console . log ( '\\nDocToccing \"%s\" and its sub directories.' , target ) ; console . log ( '\\nDocToccing single file \"%s\".' , target ) ; transformAndSave ( files ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "individual", "lines", "of", "coverage", "to", "console", "reporting", "."], "add_tokens": "var coverageLine ; coverageLine = \"0\" ; } else if ( data [ num ] !== undefined ) { coverageLine = data [ num ] ; } else { coverageLine = 'U' ; } coverageLine = coverageLine + \" \" + line ; console . log ( coverageLine ) ; } ) ;", "del_tokens": "} else if ( data [ num ] !== undefined ) { } } ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "TODO", "to", "unknown", "spec", "types"], "add_tokens": "} ) . join ( '' ) + '\\n TODO\\n </div>\\n ' ;", "del_tokens": "} ) . join ( '' ) + '\\n </div>\\n ' ;", "commit_type": "add"}
{"commit_tokens": ["Update", "public", "site", "with", "most", "recent", "changes"], "add_tokens": "require ( [ \"jquery\" , \"./ui.js\" , \"pattern-library/js/modernizr-custom\" , \"pattern-library/js/afontgarde\" , \"pattern-library/js/edx-icons\" ] , function ( r , e ) { } ) ;", "del_tokens": "require . config ( { baseUrl : \"/public/js\" , paths : { jquery : \"/public/js/jquery.min\" , modernizr : \"/public/js/modernizr-custom\" , afontgarde : \"/public/js/afontgarde\" , edxicons : \"/public/js/edx-icons\" } , shim : { jquery : { exports : \"jquery\" } , afontgarde : { exports : \"AFontGarde\" } } } ) , require ( [ \"jquery\" , \"/public/js/ui.js\" , \"/public/js/modernizr-custom.js\" , \"afontgarde\" , \"/public/js/edx-icons.js\" ] , function ( e , r ) { } ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "better", "defaults", "for", "default", "schema", "locations"], "add_tokens": "let rootdir = require ( 'app-root-dir' ) ; constants : rootdir . get ( ) + '/schemas/contants.yml' , folder : rootdir . get ( ) + '/schemas' ,", "del_tokens": "constants : './schemas/contants.yml' , folder : './schemas' ,", "commit_type": "make"}
{"commit_tokens": ["Updated", "steal", "-", "tools", "to", "use", "latest", "steal"], "add_tokens": "main : options . main , root : process . cwd ( )", "del_tokens": "main : options . main", "commit_type": "update"}
{"commit_tokens": ["Removed", "unncessary", "word", "correctly", "from", "all", "tests"], "add_tokens": "it ( 'should build whois lists' ) ; it ( 'should verify passwords' ) ; it ( 'should handle incoming login requests for users for whom a password is required' , function ( ) { it ( 'should handle room join requests' ) ; it ( 'should handle user list requests' ) ; it ( 'should handle room list requests' ) ; it ( 'should handle room user list requests' ) ; it ( 'should handle user count requests' ) ; it ( 'should handle room count requests' ) ; it ( 'should handle room user count requests' ) ;", "del_tokens": "it ( 'should correctly build whois lists' ) ; it ( 'should correctly verify passwords' ) ; it ( 'should correctly handle incoming login requests for users for whom a password is required' , function ( ) { it ( 'should correctly handle room join requests' ) ; it ( 'should correctly handle user list requests' ) ; it ( 'should correctly handle room list requests' ) ; it ( 'should correctly handle room user list requests' ) ; it ( 'should correctly handle user count requests' ) ; it ( 'should correctly handle room count requests' ) ; it ( 'should correctly handle room user count requests' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Change", "how", "authentication", "works", "in", "WPRequest"], "add_tokens": "auth : function ( ) { return this ; } ,", "del_tokens": "set : function ( ) { return this ; } ,", "commit_type": "change"}
{"commit_tokens": ["added", "tagName", "param", "to", "findProps", "function", "for", "formatMessage", "+", "tests"], "add_tokens": "function findProps ( node , tagName ) { if ( tagName === \"formatMessage\" ) { var prop = { } ; var name_2 ; node . properties . forEach ( function ( p ) { if ( ts . isPropertyAssignment ( p ) && ts . isStringLiteral ( p . initializer ) ) { name_2 = p . name . escapedText ; prop [ name_2 ] = p . initializer . text ; } } ) ; res . push ( prop ) ; } var props = findProps ( nodeProps , tagName ) ; var fm = findFirstJsxOpeningLikeElementWithName ( sourceFile , \"formatMessage\" , true ) ; return res . concat ( dm ) . concat ( fm ) ;", "del_tokens": "function findProps ( node ) { var props = findProps ( nodeProps ) ; return res . concat ( dm ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "toString", "()", "for", "human", "readable", "output"], "add_tokens": "this . output = { } ; // Generate human readable output. // If the name of a unit is passed, the unit will first be converted to the target unit before output. // output is cached so subsequent calls for the same format will be fast toString : function ( target_units ) { if ( this . output [ target_units ] ) { console . log ( \"cached\" ) ; return this . output [ target_units ] ; } var out = target_units ? this . to ( target_units ) : this ; out = ( out . scalar + \" \" + out . units ( ) ) . trim ( ) ; this . output [ target_units ] = out ; return out ; } ,", "del_tokens": "this . output = null ;", "commit_type": "add"}
{"commit_tokens": ["Add", "compare", "functions", "to", "module", "exports"], "add_tokens": "'geometryTransformation' : require ( './comparators/geometry-transformation' ) , 'compare_geometry' : require ( './comparators/compare_geometry' ) , 'compare_tag' : require ( './comparators/compare_tag' ) , 'place_significant' : require ( './comparators/place_significant' ) , 'user_changesets' : require ( './comparators/user_changesets' ) , 'count_tag' : require ( './comparators/count_tag' ) , 'delete_create' : require ( './comparators/delete_create' ) , 'landmark' : require ( './comparators/landmark' ) , 'city_deleted' : require ( './comparators/city_deleted' ) , 'compare_properties' : require ( './comparators/compare_properties' ) , 'compare_geometries' : require ( './comparators/compare_geometries' ) , 'highway_deleted' : require ( './comparators/highway_deleted' )", "del_tokens": "'geometryTransformation' : require ( './comparators/geometry-transformation' )", "commit_type": "add"}
{"commit_tokens": ["Added", "digital", "signature", "capability", "to", "the", "SecurityUtilities", "library", "."], "add_tokens": "expected = 64 ; } , 'Test Signatures' : function ( test ) { var keyPair = security . generateKeyPair ( ) ; var publicKey = keyPair . publicKey ; var privateKey = keyPair . privateKey ; test . expect ( 10 ) ; for ( var i = 0 ; i < 10 ; i ++ ) { var bytes = security . generateRandomBytes ( i ) ; var signatureBytes = security . signString ( privateKey , bytes ) ; var isValid = security . signatureIsValid ( publicKey , bytes , signatureBytes ) ; test . ok ( isValid , 'The signature is not valid.' ) ; } test . done ( ) ;", "del_tokens": "expected = 105 ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "tests", "for", "branch", "and", "pull_request_number", "for", "gitlab", "."], "add_tokens": "pull_request_number = process . env . CI_MERGE_REQUEST_ID", "del_tokens": "pull_request_number = process . env . CI_PULL_REQUEST_NUMBER", "commit_type": "fix"}
{"commit_tokens": ["Allow", "global", "version", "for", "<b", ":", "include", ">", "to", "prevent", "cache", "problems"], "add_tokens": "this . urlSuffix = null ; this . bindster . render ( data ) ; controller . setIncludeURLSuffix = function ( suffix ) { this . bindster . urlSuffix = suffix } , if ( ! file . match ( / \\? / ) && this . urlSuffix ) file = file + this . urlSuffix ;", "del_tokens": "this . bindster . render ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Improve", "detection", "of", "actual", "list", "(", "borrowed", "from", "jQuery", "UI", "tabs", ")"], "add_tokens": "this . list = $ ( e ) . find ( 'ul,ol' ) . eq ( 0 ) ;", "del_tokens": "this . list = $ ( e ) . find ( '>ul,>ol,div>ul,div>ol' ) ;", "commit_type": "improve"}
{"commit_tokens": ["fix", "implicit", "$or", "instead", "of", "$in", "for", "non", "-", "logical", "operators"], "add_tokens": "* @ param { JsonFilterOperator } [ parent ] * @ param { boolean } [ contextDisabled ] Used for operators where no context is expected JsonFilter . parse = function ( operand , operators , parent , contextDisabled ) { if ( ! parent || parent . logical ) { operand = { $or : operand } ; } else { operand = { $in : operand } ; }", "del_tokens": "* @ param { boolean } contextDisabled Used for operators where no context is expected JsonFilter . parse = function ( operand , operators , contextDisabled ) { operand = { $or : operand } ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "placeholder", "upload", "method", "."], "add_tokens": ". then ( this . adapter . upload . bind ( this . adapter ) )", "del_tokens": "// @todo upload all remaining files", "commit_type": "add"}
{"commit_tokens": ["Added", "back", "original", "fitWidth", "and", "fitHeight"], "add_tokens": "parent . container . scale . x = this . x || this . value parent . container . scale . y = this . y || this . value", "del_tokens": "if ( this . x ) { parent . container . scale . x = this . x parent . container . scale . y = this . y } else { parent . container . scale . x = this . value parent . container . scale . y = this . value }", "commit_type": "add"}
{"commit_tokens": ["Add", "node", "to", "Listener", ".", "pushed", "call", "."], "add_tokens": "this . _listeners [ i ] . pushed ( this , this . head )", "del_tokens": "this . _listeners [ i ] . pushed ( this )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "dlpa", "node", "."], "add_tokens": "\"--span\" , config . span ? config . span : \"300\"", "del_tokens": "\"--span\" , config . span ? config . span || \"300\"", "commit_type": "fix"}
{"commit_tokens": ["Allow", "the", "element", "itself", "to", "contain", "actions"], "add_tokens": "var actions = element . children ( ) . andSelf ( ) . filter ( '.' + settings . prefix + '-actions' ) ; if ( actions . length === 0 ) { actions = $ ( '<div class=\"' + settings . prefix + '-actions\"></div>' ) ;", "del_tokens": "if ( element . find ( '> .' + settings . prefix + '-actions' ) . length === 0 ) { var actions = $ ( '<div class=\"' + settings . prefix + '-actions\"></div>' ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "wappblog", "also", "in", "chrome", "working", "on", "wappmail", "in", "chrome"], "add_tokens": "// res.push({\"body\":'ERROR - PubSign '+sig+' does not correctly sign '+cmdStr+' for key '+ret[msg].cmd.SenderSub.n, // \"SenderSub\":{\"r\":\"not valid\", \"c\":\"not valid\", \"n\":\"not valid\"}});", "del_tokens": "res = res + '\",\"ERROR - PubSign ' + sig + ' does not correctly sign ' + cmdStr + ' for key ' + ret [ msg ] . cmd . SenderSub . n ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "rules", "for", "cssComplexSelectorsByAttribute", "and", "cssDuplicatedProperties"], "add_tokens": "$scope . phantomasResults . metrics . cssComplexSelectors * 5 + $scope . phantomasResults . metrics . cssComplexSelectorsByAttribute * 15 ; $scope . phantomasResults . metrics . cssDuplicatedProperties +", "del_tokens": "$scope . phantomasResults . metrics . cssComplexSelectors * 5 ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "restify", "v2"], "add_tokens": "var path ; / * * In older versions of restify , \"path\" was a regular property . * / if ( typeof ( request . path ) == 'function' ) path = request . path ( ) ; else path = request . path ; if ( path != svc . kns_uri_base + '/snapshot' && path != svc . kns_uri_base + '/schema' ) { if ( path == svc . kns_uri_base + '/snapshot' )", "del_tokens": "if ( request . path != svc . kns_uri_base + '/snapshot' && request . path != svc . kns_uri_base + '/schema' ) { if ( request . path == svc . kns_uri_base + '/snapshot' )", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "toSlug", "helper", "and", "move", "to", "an", "underscore", "mixin"], "add_tokens": "} , to_slug : function ( str ) { return str . toLowerCase ( ) . replace ( / [^\\w ]+ / g , '' ) . replace ( / + / g , '-' ) ; this . blockCSSClass = _ . to_slug ( this . type ) ;", "del_tokens": "/* String to slug */ function toSlug ( string ) { return string . toLowerCase ( ) . replace ( / [^\\w ]+ / g , '' ) . replace ( / + / g , '-' ) ; } this . blockCSSClass = toSlug ( this . type ) ;", "commit_type": "remove"}
{"commit_tokens": ["Removing", "tests", "that", "will", "never", "pass"], "add_tokens": "expect ( 12 ) ; // FIXME: currently failing becuase we don't have a way to distinguish which fn is being sought // equals(pst.findFunctionName(['a:function(){},b:function(){', '};'], 1), 'b');", "del_tokens": "test ( \"recursion other\" , function ( ) { // TODO currently failing, e.g. in Midori 0.3 (AppleWebKit/531.2+ Midori/0.3) var mode = pst . mode ( UnitTest . fn . createGenericError ( ) ) ; expect ( mode == 'other' ? 2 : 0 ) ; if ( mode == 'other' ) { function recurse ( b ) { if ( ! b ) { var message = pst . other ( arguments . callee ) , message_string = message . join ( \"\\n\" ) ; //alert((arguments.callee + \"\").replace(/{[\\s\\S]*/, \"\") + \"\\n\" + //(arguments.callee.caller + \"\").replace(/{[\\s\\S]*/, \"\") + \"\\n\" + //(arguments.callee.caller.caller + \"\").replace(/{[\\s\\S]*/, \"\") + \"\\n\" + //message_string); //equals(message_string, '', 'debug'); equals ( message [ 0 ] . indexOf ( 'recurse(false)' ) >= 0 , true , 'first: recurse(false): ' + message [ 0 ] ) ; equals ( message [ 1 ] . indexOf ( 'recurse(true)' ) >= 0 , true , 'second: recurse(true): ' + message [ 1 ] ) ; } else { recurse ( true ) ; } } recurse ( false ) ; } } ) ; // TODO currently failing expect ( 13 ) ; equals ( pst . findFunctionName ( [ 'a:function(){},b:function(){' , '};' ] , 1 ) , 'b' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "another", "function", "for", "backwards", "compatability", "."], "add_tokens": "function innerGetDeviceScanner ( whichScanner ) { } exports . getDeviceScanner = innerGetDeviceScanner ; exports . deviceScanner = innerGetDeviceScanner ;", "del_tokens": "exports . getDeviceScanner = function ( whichScanner ) { } ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "electron", "API", "changes", "for", "requiring", "module", "as", "per", "http", ":", "//", "blog", ".", "atom", ".", "io", "/", "2015", "/", "11", "/", "17", "/", "electron", "-", "api", "-", "changes", ".", "html"], "add_tokens": "var ipc = require ( 'electron' ) . ipcRenderer ; ipc . on ( 'params' , function ( event , message ) {", "del_tokens": "var ipc = require ( 'ipc' ) ; ipc . on ( 'params' , function ( message ) { console . log ( appArgs ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixing", "typo", "getZindex", "-", ">", "getZIndex"], "add_tokens": "this . markerWrapper_ . style [ 'zIndex' ] = this . getZIndex ( ) ;", "del_tokens": "this . markerWrapper_ . style [ 'zIndex' ] = this . getZindex ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "tests", "and", "fix", "bugs"], "add_tokens": "schema = schema || { } ; options = options || { } ; args [ key ] = magico . get ( state . value , this . refs [ key ] . __key ) ; locale = locale || 'en' ; args = args || [ ] ; if ( this . locale ) msg = magico . get ( this . locale , ` ${ locale } ` ) ;", "del_tokens": "args [ key ] = magico . get ( state . value , args [ key ] . __key ) ; if ( this . locale ) msg = this . locale . __msg [ locale ] ;", "commit_type": "add"}
{"commit_tokens": ["use", "heroku", "-", "cli", "-", "util", "for", "colors"], "add_tokens": "console . log ( ` ${ h . color . cyan ( remote ) } ${ h . color . cyan ( url ) } ` ) ;", "del_tokens": "let chalk = require ( 'chalk' ) ; console . log ( ` ${ chalk . cyan ( remote ) } ${ chalk . cyan ( url ) } ` ) ;", "commit_type": "use"}
{"commit_tokens": ["updating", "example", "to", "use", ".", "name", "option"], "add_tokens": "this . use ( tree ( { name : 'updaters' } ) ) ;", "del_tokens": "this . use ( tree ( { plural : 'updaters' } ) ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "content", "length", "for", "utf8", "bodies", "in", "the", "http", "connector"], "add_tokens": "request . setHeader ( 'Content-Length' , Buffer . byteLength ( params . body , 'utf8' ) ) ;", "del_tokens": "request . setHeader ( 'Content-Length' , params . body . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "sitemap", "middleware", "to", "send", "content", "-", "type", "and", "length"], "add_tokens": "const view = handlebars . compile ( const html = view ( toc ) res . set ( { 'Content-Type' : 'text/html' , 'Content-Length' : html . length } ) res . send ( html )", "del_tokens": "const nav = handlebars . compile ( res . send ( nav ( toc ) )", "commit_type": "fix"}
{"commit_tokens": ["Make", "a", "one", "time", "label", "test"], "add_tokens": "const sentencePattern = / .* / ; const fetchHandler = ( sentence ) => { speechListener . once ( sentencePattern , fetchHandler ) ; speechListener . once ( sentencePattern , fetchHandler ) ; // expected label const labelTest = ( actualLabel , sentence ) => { // This makes it a one-time test labelEmitter . off ( labelTest ) ; return [ sentence , label ] ; } ; labelEmitter . on ( labelTest , resolve ) ;", "del_tokens": "const test = / .* / ; const handler = ( sentence ) => { speechListener . once ( test , handler ) ; speechListener . once ( test , handler ) ; // expected label. // TODO: We can force memory leak by removing the label matcher event listener // leaving the event listener above still registered. This should be fixed in the // future labelEmitter . once ( ( actualLabel , sentence ) => { return [ [ sentence , label ] ] ; } , resolve ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "failing", "tests", "under", "macOS"], "add_tokens": "const { writeFileSync , statSync , existsSync , realpathSync } = require ( 'fs' ) ; cwd = realpathSync ( dir ) ;", "del_tokens": "const { writeFileSync , statSync , existsSync } = require ( 'fs' ) ; cwd = dir ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "in", "QueryMaker", ".", "prototype", ".", "delimitedArgs", "when", "called", "with", "len", "=", "0"], "add_tokens": "var resultStr = '' ; if ( len > 0 ) { var delimiter = opt_delimiter || ', ' ; var result = [ ] ; var end = start + len - 1 ; for ( var i = start ; i <= end ; i ++ ) { result . push ( i ) ; } resultStr = '$' + result . join ( delimiter + '$' ) ; return resultStr ;", "del_tokens": "var delimiter = opt_delimiter || ', ' ; var result = [ ] ; var end = start + len - 1 ; for ( var i = start ; i <= end ; i ++ ) { result . push ( i ) ; return '$' + result . join ( delimiter + '$' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "unification", "to", "Earley", "Parser"], "add_tokens": "if ( cseq . length ) { // constraints specified rule . process_constraints ( cseq , grammar . type_lattice ) ; grammar . type_lattice = options . type_lattice ;", "del_tokens": "if ( cseq . length ) { rule . process_constraints ( cseq , type_lattice ) ; var type_lattice = options . type_lattice ;", "commit_type": "add"}
{"commit_tokens": ["Add", "helpers", "methods", "encryptStream", "encryptToStream", "and", "associated", "decrypt"], "add_tokens": "it ( 'should encrypt stream with callStreaming()' , function ( done ) { it ( 'should encrypt stream with encryptStream()' , function ( done ) { var args = [ '--default-key' , '6F20F59D' , '--recipient' , '6F20F59D' , '--armor' , '--trust-model' , 'always' , // so we don't get \"no assurance this key belongs to the given user\" ] ; var inStream = fs . createReadStream ( './test/hello.txt' ) ; gpg . encryptStream ( inStream , args , function ( err , res ) { assert . ifError ( err ) ; assert . ok ( / BEGIN PGP MESSAGE / . test ( res ) ) ; done ( ) ; } ) ; } ) ; it ( 'should decrypt stream with callStreaming()' , function ( done ) { it ( 'should decrypt stream with decryptStream()' , function ( done ) { var args = [ '--default-key' , '6F20F59D' , '--recipient' , '6F20F59D' , '--trust-model' , 'always' , // so we don't get \"no assurance this key belongs to the given user\" ] ; var inStream = fs . createReadStream ( './test/hello.gpg' ) ; gpg . decryptStream ( inStream , args , function ( err , res ) { assert . ifError ( err ) ; assert . ok ( / Hello World / . test ( res ) ) ; done ( ) ; } ) ; } ) ;", "del_tokens": "it ( 'should encrypt stream' , function ( done ) { it ( 'should decrypt stream' , function ( done ) { '--armor' ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "webpack", "-", "related", "bug"], "add_tokens": "if ( packageFile && packageFile . indexOf ( electronModule ) !== - 1 ) {", "del_tokens": "if ( packageFile . indexOf ( electronModule ) !== - 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "module", "exports"], "add_tokens": "exports . CalendarProperty = require ( './base' ) . CalendarProperty ;", "del_tokens": "exports . CalendarObject = require ( './base' ) . CalendarProperty ;", "commit_type": "fix"}
{"commit_tokens": ["add", "subscribe", "handler", "commands", "to", "result", "promise", "of", "cmd", "exec"], "add_tokens": "return maybeMap ( handlers , handler => handler ( arg ) ) ; resPromise . add ( this . emit ( MODEL_UPDATED_EVENT , cmd ) ) ; resPromise . add ( this . rootProc . emit ( CHILD_MODEL_UPDATED_EVENT , cmd ) ) ;", "del_tokens": "maybeForEach ( handlers , handler => handler ( arg ) ) ; this . emit ( MODEL_UPDATED_EVENT , cmd ) ; this . rootProc . emit ( CHILD_MODEL_UPDATED_EVENT , cmd ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "Last", "state", "not", "being", "sent", "to", "kernel", "while", "throttling", "."], "add_tokens": "this . msg_buffer = null ; if ( this . msg_buffer != null ) { if ( this . msg_throttle == this . pending_msgs && this . msg_buffer . length > 0 ) { var output_area = this . _get_msg_output_area ( msg ) ; var callbacks = this . _make_callbacks ( output_area ) ; var data = { sync_method : 'update' , sync_data : this . msg_buffer } ; comm . send ( data , callbacks ) ; this . msg_buffer = null ; } else { // Only decrease the pending message count if the buffer // doesn't get flushed (sent). -- this . pending_msgs ; } if ( this . msg_buffer == null ) { this . msg_buffer = $ . extend ( { } , model_json ) ; // Copy }", "del_tokens": "this . msg_buffer = { } ; if ( this . msg_throttle == this . pending_msgs && this . msg_buffer . length > 0 ) { var output_area = this . _get_msg_output_area ( msg ) ; var callbacks = this . _make_callbacks ( output_area ) ; var data = { sync_method : 'patch' , sync_data : this . msg_buffer } ; comm . send ( data , callbacks ) ; this . msg_buffer = { } ; } else { // Only decrease the pending message count if the buffer // doesn't get flushed (sent). -- this . pending_msgs ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "redundant", "filter", "-", "call", "in", "createDirectoryTree"], "add_tokens": "* @ returns { object } an object structure compatible with ` ` representing the file tree", "del_tokens": "* @ returns an object structure compatible with ` ` representing the file tree if ( filter && ! filter ( somePath ) ) { debug ( 'Omitting ' + somePath + ' based on glob' ) return '' }", "commit_type": "remove"}
{"commit_tokens": ["fix", "a", "bug", "where", "passing", "args", "as", "an", "array", "with", "nothing", "else", "broke"], "add_tokens": "var lastArg = args [ args . length - 1 ] ; if ( typeof lastArg == 'object' && ! lastArg . length ) {", "del_tokens": "if ( typeof args [ args . length - 1 ] == 'object' ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "comments", "to", "MySQL", "example"], "add_tokens": "/** Connect to the MySQL database using login info stored externally */ /** Configure a new EZ Object called DatabaseRecord with one 'id' property */ /** Create the DatabaseRecord object */ /** Configure a new EZ Object called Person that extends from the DatabaseRecord object and adds several additional properties and an index */ /** Wrap our test code in a self-executing asynchronous function so we can 'await' responses */ /** Try/catch/finally to cleanly catch errors and close database connection */ /** Await table creation if it doesn't already exist */ /** Create the Person object */ /** Create a new instance of the Person object, loaded with data passed to the constructor */ /** Log the current value of the person */ /** Await the insertion of that Person object into the database */ /** Log the current value of the person */ /** Create a second instance of the Person object */ const person2 = new Person ( ) ; . /** Await loading of database record with ID 2 into person2 */ /** Log the current value of person2 */ /** Set person2's checking balance to 50.74 */ /** Await update of person2 in database */ /** Log any caught errors */ /** Close database connection */", "del_tokens": "const person2 = new Person ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "webdriver_atoms", ".", "js", "module", "."], "add_tokens": "var atomFileName = module . dirname + \"/third_party/webdriver-atoms/\" + atomName + \".js\" ; } ;", "del_tokens": "var atomFileName = \"./third_party/webdriver-atoms/\" + atomName + \".js\" ; } ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "option", "check", "logic", "for", "naverCallerName", "and", "removed", "duplicated", "check"], "add_tokens": "navermap : options . naverCallerName ? 'nmap://' : 'nmap-disabled://'", "del_tokens": "navermap : 'nmap://'", "commit_type": "change"}
{"commit_tokens": ["Fix", "URI", "for", "sprite", "file", "."], "add_tokens": ", staticUriPrefix : ( cfg . staticUriPrefix || '' ) + '/' , baseDirName : cfg . static . build . baseDirName , buildBaseDir : buildBaseDir , options : '--css=<%=destSpritesCss%> --img=<%=destSpritesImg%> --less --url=<%=staticUriPrefix%><%=baseDirName%> --namespace=s --sprite-namespace= --recursive --crop --optipng'", "del_tokens": ", staticUriPrefix : cfg . staticUriPrefix , buildBaseDir : buildBaseDir , options : '--css=<%=destSpritesCss%> --img=<%=destSpritesImg%> --less --url=<%=staticUriPrefix%> --namespace= --sprite-namespace= --recursive --crop --optipng'", "commit_type": "fix"}
{"commit_tokens": ["Added", "equalDeep", "and", "exception", "support", "to", "assertions", ".", "Added", "utility", "function", "to", "support", "optional", "parameters", "."], "add_tokens": "// gT.s.fail = function (url, logAction) { // return gIn.wrap('Intentional fail for debug: ... ', logAction, function () { // return promise.rejected('Intentional fail'); // }); // };", "del_tokens": "gT . s . fail = function ( url , logAction ) { return gIn . wrap ( 'Intentional fail for debug: ... ' , logAction , function ( ) { return promise . rejected ( 'Intentional fail' ) ; } ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["moving", "searchers", "to", "server", "side"], "add_tokens": "// initial doc is saved to state queue with queue: { relevance: 2 }", "del_tokens": "// initial doc is saved to state queue with queue: { relevance: 3 }", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "loading", "service", "extensions", "to", "the", "yaas", "client", "for", "additional", "services", "that", "you", "have", "running", "on", "yaas", "and", "want", "to", "consume", "with", "the", "same", "client", "as", "core", "yaas", "services", "."], "add_tokens": "this . init = function ( theClientId , theClientSecret , theScope , theProjectId , yaasExtensions ) { if ( yaasExtensions ) { yaasExtensions . forEach ( function ( extension ) { var Service = require ( extension . path ) ; this [ extension . serviceName ] = new Service ( this . requestHelper ) ; Service = undefined ; } . bind ( this ) ) ; } return Promise . resolve ( this ) ;", "del_tokens": "this . init = function ( theClientId , theClientSecret , theScope , theProjectId ) { return Promise . resolve ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "should", "and", "added", "ltl", ".", "templates"], "add_tokens": "// Store all of the templates that have been compiled. templates : { } , // Default to empty options. options = options || { } ; var template = eval . f ; // If there's a path specified, cache the template in the module at that path. if ( options . path ) { this . templates [ options . path ] = template ; } return template ;", "del_tokens": "return eval . f ;", "commit_type": "remove"}
{"commit_tokens": ["removing", "render", "method", "in", "favor", "of", "alone", "method"], "add_tokens": "expectedDirname = path . join ( __dirname , 'swig/expected' ) ; alone ( { src : srcDirname , dest : destDirname , data : { SOMEKEY : \"somevalue\" } , engine : \"swig\" , done : done } ) ;", "del_tokens": "expectedDirname = path . join ( __dirname , 'swig/expected' ) , globalData = { SOMEKEY : \"somevalue\" } ; alone . render ( srcDirname , destDirname , globalData , \"swig\" , done ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "update", "alias", "to", "cubemap"], "add_tokens": "var checkerRoom = new CheckerRoom ( 20 , 20 , 4 ) ; envMap : lightProbe . getCubeMap ( 64 , 1 * ratio * ratio * ratio , 3 , false )", "del_tokens": "var checkerRoom = new CheckerRoom ( ) ; envMap : lightProbe . getCubeMap ( 64 , 1 * ratio * ratio * ratio , 3 , true )", "commit_type": "add"}
{"commit_tokens": ["Added", "back", "the", "possibility", "to", "override", "createBuilder", "in", "the", "configuration"], "add_tokens": "return require ( configPath || path . join ( process . cwd ( ) , 'roc.config.js' ) ) . config ;", "del_tokens": "return require ( configPath || path . join ( process . cwd ( ) , 'roc.config.js' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "mdfind", "to", "find", "the", "locations", "of", "the", "apps", "on", "OS", "X", "."], "add_tokens": "var spawnSync = require ( \"spawn-sync\" ) ; var channelNames = [ \"firefox\" , \"firefoxdeveloperedition\" , \"beta\" , \"nightly\" , \"aurora\" ] ; var result = null ; if ( platform === \"osx\" && channelNames . indexOf ( binaryPath ) !== - 1 ) { // Try to find the app for this channel. // mdfind \"kMDItemCFBundleIdentifier == 'org.mozilla.firefoxdeveloperedition'\" var results = spawnSync ( \"mdfind\" , [ \"kMDItemCFBundleIdentifier == 'org.mozilla.\" + binaryPath + \"'\" ] ) ; if ( results . stdout ) { result = results . stdout . toString ( ) . split ( '\\n' ) [ 0 ] ; } } binaryPath = result || normalizeBinary . paths [ app + \" on \" + platform ] || \"firefoxdeveloperedition on osx\" : \"/Applications/FirefoxDeveloperEdition.app/Contents/MacOS/firefox-bin\" ,", "del_tokens": "binaryPath = normalizeBinary . paths [ app + \" on \" + platform ] || var channelNames = [ \"firefox\" , \"beta\" , \"nightly\" , \"aurora\" ] ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "pim", ".", "calendar", "automated", "test", "for", "recurring", "events"], "add_tokens": "var start = new Date ( \"Jan 6, 2030, 12:00\" ) , end = new Date ( \"Jan 6, 2030, 12:30\" ) , \"expires\" : new Date ( \"Dec 31, 2030\" ) , expect ( starts ) . toContain ( new Date ( \"Jan 6, 2030, 12:00\" ) . toISOString ( ) ) ; expect ( starts ) . toContain ( new Date ( \"Feb 6, 2030, 12:00\" ) . toISOString ( ) ) ; expect ( starts ) . toContain ( new Date ( \"Mar 6, 2030, 12:00\" ) . toISOString ( ) ) ; expect ( starts ) . toContain ( new Date ( \"Apr 6, 2030, 12:00\" ) . toISOString ( ) ) ;", "del_tokens": "var start = new Date ( \"Jan 6, 2046, 12:00\" ) , end = new Date ( \"Jan 6, 2046, 12:30\" ) , \"expires\" : new Date ( \"Dec 31, 2046\" ) , expect ( starts ) . toContain ( new Date ( \"Jan 6, 2046, 12:00\" ) . toISOString ( ) ) ; expect ( starts ) . toContain ( new Date ( \"Feb 6, 2046, 12:00\" ) . toISOString ( ) ) ; expect ( starts ) . toContain ( new Date ( \"Mar 6, 2046, 12:00\" ) . toISOString ( ) ) ; expect ( starts ) . toContain ( new Date ( \"Apr 6, 2046, 12:00\" ) . toISOString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "number", "parser"], "add_tokens": "else if ( ch !== \"0\" || str . length === 1 ) val = parseInt ( str , 10 ) ;", "del_tokens": "else if ( ch !== \"0\" ) val = parseInt ( str , 10 ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "lambda", "name", "to", "zip", "file"], "add_tokens": "const zipFile = ` ${ lambda . hash } ${ lambda . name } ` ;", "del_tokens": "const zipFile = ` ${ lambda . hash } ` ;", "commit_type": "add"}
{"commit_tokens": ["made", "PExpr", ".", "check", "::", "grammar", "*", "[", "val", "]", "-", ">", "boolean"], "add_tokens": "return new Grammar ( this . name , this . superGrammar , this . ruleDecls , ruleDict , optNamespace ) ;", "del_tokens": "return new Grammar ( optNamespace , this . name , this . superGrammar , this . ruleDecls , ruleDict ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "sku", "to", "increment", "and", "decrement", "tracking"], "add_tokens": "increment : true , decrement : true plusIcon : function ( ) { this . send ( 'increment' , this . get ( 'trackedModel' ) ) ; } , minusIcon : function ( ) { this . send ( 'decrement' , this . get ( 'trackedModel' ) ) ; } ,", "del_tokens": "decrement : true , increment : true", "commit_type": "add"}
{"commit_tokens": ["added", "isNodeType", "to", "spec", "."], "add_tokens": "/ ** * * @ param node * @ param type * @ returns { boolean } * / function isNodeType ( node , type ) { return node instanceof Array && node [ 0 ] === type ; } macro : macro , isNodeType : isNodeType", "del_tokens": "macro : macro", "commit_type": "add"}
{"commit_tokens": ["made", "validateListening", "error", "messages", "type", "agnostic"], "add_tokens": "return \"Listener is not able to listen to itself\" ; return \"Listener cannot listen to this listenable because of circular loop\" ;", "del_tokens": "return \"Store is not able to listen to itself\" ; return \"Store cannot listen to this listenable because of circular loop\" ;", "commit_type": "make"}
{"commit_tokens": ["Make", "dump", "()", "a", "bit", "better"], "add_tokens": "// default adapter - write to stdout var msg = browser + ' DUMP: ' ; if ( dump . length > 1 ) { msg += dump . length + ' entries\\n' + dump . join ( '\\n' ) ; } else { msg += dump [ 0 ] ; } this . writeCommonMsg ( msg + '\\n' ) ;", "del_tokens": "// default adapter - write to stdou this . writeCommonMsg ( browser + ' DUMP: ' + util . inspect ( dump ) + '\\n' ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "test", "case", "for", "custom", "argv", "parser", "."], "add_tokens": "describe ( 'argv disabled:' , function ( ) { it ( 'should write to file with no escape sequences (--color)' , it ( 'should write to file with no escape sequences (--color=always)' , it ( 'should write to file with no escape sequences (--color always)' ,", "del_tokens": "describe ( 'ttycolor:' , function ( ) { it ( 'should write to file with escape sequences (--color)' , it ( 'should write to file with escape sequences (--color=always)' , it ( 'should write to file with escape sequences (--color always)' ,", "commit_type": "add"}
{"commit_tokens": ["add", "onchange", "event", "implementation", "and", "tests"], "add_tokens": "/ * test ( 'newWindow - throw if too few arguments' , t => { libui . Ui . init ( ) ; let emitted ; const entry = new libui . UiEntry ( ) ; entry . onChange ( ( ) => { emitted = true ; } ) ; entry . text = 'some value' ; t . true ( emitted ) ; } ) ;", "del_tokens": "/ *", "commit_type": "add"}
{"commit_tokens": ["Updated", "MySQL", "example", "with", "instanceOf", "check"], "add_tokens": "docket . title ( ` ` ) ;", "del_tokens": "docket . title ( ` ` ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "after", "success", "and", "after", "failure", "arguments", "for", "addMethod"], "add_tokens": "// Handle the after success and failure messages . done ( function ( body ) { if ( _ . isFunction ( config . afterSuccess ) ) { when ( config . afterSuccess ( body ) ) . done ( resolve , reject ) ; // TODO right way to handle rejections? } else { resolve ( body ) ; } } , function ( err ) { if ( _ . isFunction ( config . afterFailure ) ) { when ( config . afterFailure ( err ) ) . done ( reject , reject ) ; // TODO right way to handle rejections? } else { reject ( err ) ; } } ) ;", "del_tokens": ". done ( resolve , reject ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "UMD", "module", "definition", "for", "increase", "compatibility", "."], "add_tokens": "( function ( root , factory ) { if ( typeof define === \"function\" && define . amd ) { define ( [ './ResizeSensor.js' ] , factory ) ; } else if ( typeof exports === \"object\" ) { module . exports = factory ( require ( './ResizeSensor.js' ) ) ; } else { root . ElementQueries = factory ( root . ResizeSensor ) ; } ( this , function ( ResizeSensor ) { return ElementQueries ; } ) ) ;", "del_tokens": "( function ( ) { var ResizeSensor = window . ResizeSensor ; if ( typeof module !== 'undefined' && typeof module . exports !== 'undefined' ) { ResizeSensor = require ( './ResizeSensor' ) ; } ) ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "the", "extend", "-", "info", "and", "extra", "-", "resource", "arguments", "for", "creating", "the", "Mac"], "add_tokens": "// If an extend-info file was supplied, copy its contents in first if ( opts [ 'extend-info' ] ) { var extendAppPlist = plist . parse ( fs . readFileSync ( opts [ 'extend-info' ] ) . toString ( ) ) for ( var key in extendAppPlist ) { appPlist [ key ] = extendAppPlist [ key ] } } // Now set fields based on explicit options if ( opts . protocols && opts . protocols . length ) { // Copy in the icon, if supplied // Copy in any other extras var extras = opts [ 'extra-resource' ] if ( extras ) { if ( ! Array . isArray ( extras ) ) extras = [ extras ] extras . forEach ( function ( val ) { operations . push ( function ( cb ) { ncp ( val , path . join ( contentsPath , 'Resources' , path . basename ( val ) ) , cb ) } ) } ) }", "del_tokens": "if ( opts . protocols ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "getMultiparts", "and", "updated", "tests"], "add_tokens": "let tmpObj = { } ; mp . is_valid = mp . isValid ( ) . success ; if ( c == 0 ) { mp . is_first_part = true ; if ( c . indexOf ( \"oip042\" ) !== 0 ) { mp . hasJSONPrefix = true } // @TODO: Implement multipart signing // mp.sign();", "del_tokens": "/ ** * Set the TXID * @ param { string } txid - The transaction ID * @ example * artifact . setTXID ( \"2982JE9\" ) * / setTXID ( txid ) { this . txid = txid ; } / ** * Get the TXID of an artifact * @ example * artifact . getTXID ( ) * / getTXID ( ) { return this . txid ; } var tmpObj = { } ; if ( c === 0 ) { // @TODO: Implement multipart signing mp . sign ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "gosquared", "hopefully", "fixing", "travis"], "add_tokens": "e . initMouseEvent ( 'click' , true , true , null , null , null , null , null , null , true , true , true , true ) ;", "del_tokens": "e . initMouseEvent ( 'click' , true , true , null , null , null , null , null , null , null , null , null , true ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "passing", "React", "components", "as", "matchElement"], "add_tokens": "matchElement : PropTypes . oneOfType ( [ React . PropTypes . string , React . PropTypes . func ] ) ,", "del_tokens": "matchElement : PropTypes . string ,", "commit_type": "allow"}
{"commit_tokens": ["fixed", "multiple", "files", "upload", "(", "name", "of", "files", "was", "wrong", ")"], "add_tokens": "// default name for the file = the uploaded file name if ( path . charAt ( path . length - 1 ) == '/' ) { path += request . files . data . name ; } console . log ( 'uploading multiple files ' + files . length ) ; var file = files . shift ( ) ; fs . readFile ( file . path , function ( err , data ) { console . log ( 'uploading file to ' + dstPath + file . name ) ; service . put ( dstPath + file . name , data , path : dstPath + file . name ,", "del_tokens": "fs . readFile ( files . shift ( ) . path , function ( err , data ) { service . put ( dstPath , data , path : dstPath ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "fallbacks", "from", "breaking", "change", "in", "last", "commit"], "add_tokens": "// to overwrite default highlight color, // add a css rule on .highlight and mark it !important // // eg. // // .highlight { // fill: anotherColor!important; // } e . selection . classed ( 'highlight' , false ) . style ( 'fill' , '' ) ; target . selection . classed ( 'highlight' , true ) . style ( 'fill' , 'lightgrey' ) ; e . selection . classed ( 'highlight' , false ) . style ( 'fill' , '' ) ; var shadow = new Plottable . Plots . Rectangle ( ) . addClass ( 'shadow' ) . addDataset ( dataset ) . attr ( 'data-title' , props . title ) . attr ( 'data-content' , props . content ) . attr ( 'fill' , 'rgba(0, 0, 0, 0.1)' ) ;", "del_tokens": "e . selection . classed ( 'highlight' , false ) ; target . selection . classed ( 'highlight' , true ) ; e . selection . classed ( 'highlight' , false ) ; var shadow = new Plottable . Plots . Rectangle ( ) . addClass ( 'shadow' ) . addDataset ( dataset ) . attr ( 'data-title' , props . title ) . attr ( 'data-content' , props . content ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "examples", ".", "Move", "instrument", "list", "to", "its", "own", "file", ".", "Move", "decode", "-", "buffer", "function", "to", "its", "own", "file"], "add_tokens": "var decodeBuffer = require ( './lib/decode-buffer' ) return decodeBuffer ( bank . ctx , bank . data [ note ] )", "del_tokens": "var base64DecodeToArray = require ( './lib/b64decode.js' ) return decodeNote ( bank . ctx , bank . data [ note ] ) / * * Given a WAA context and a base64 encoded buffer data returns * a Promise that resolves when the buffer is decoded * / function decodeNote ( context , data ) { return new Promise ( function ( done , reject ) { var decodedData = base64DecodeToArray ( data . split ( ',' ) [ 1 ] ) . buffer context . decodeAudioData ( decodedData , function ( buffer ) { done ( buffer ) } , function ( e ) { reject ( 'DecodeAudioData error' , e ) } ) } ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "deprecated", "new", "Buffer", "call"], "add_tokens": "this . buf = Buffer . alloc ( nextPow2 ( initsize || 8192 ) ) ; var buf = Buffer . alloc ( nextPow2 ( this . buf . length + size - this . writeAvail ( ) ) ) ; var swap = Buffer . alloc ( buf . length ) ;", "del_tokens": "this . buf = new Buffer ( nextPow2 ( initsize || 8192 ) ) ; var buf = new Buffer ( nextPow2 ( this . buf . length + size - this . writeAvail ( ) ) ) ; var swap = new Buffer ( buf . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "choosing", "loading", "bar", "parent", "element"], "add_tokens": "this . loadingBarParentSelector = 'body' ; var $loadingBarParentSelector = this . loadingBarParentSelector ; var $parent = $document . find ( $loadingBarParentSelector ) , $animate . enter ( loadingBarContainer , $parent ) ; $animate . enter ( spinner , $parent ) ; includeSpinner : this . includeSpinner , loadingBarParentSelector : this . loadingBarParentSelector ,", "del_tokens": "var $body = $document . find ( 'body' ) , $animate . enter ( loadingBarContainer , $body ) ; $animate . enter ( spinner , $body ) ; includeSpinner : this . includeSpinner", "commit_type": "allow"}
{"commit_tokens": ["Fix", "an", "assumption", "around", "read", "/", "page_handler", "order", "of", "operations"], "add_tokens": "var nextPage = this . hasNextPage ( ) ? this . nextPage ( ) : null ; if ( nextPage ) nextPage . send ( page_handler ) ; else stream . push ( null ) ;", "del_tokens": "req = this . hasNextPage ( ) ? this . nextPage ( ) : null ; if ( ! req ) stream . push ( null ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "bug", "with", "metadata", "refresh"], "add_tokens": "this . refreshMetadata ( topicNames , 0 , function ( ) {", "del_tokens": "self . refreshMetadata ( topicNames , 0 , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "getIndex", "()", "getEndPos", "()", "to", "FASTAReader"], "add_tokens": "FASTAReader . prototype . getEndPos = function ( id ) { return unit . getEndPos ( ) ; return unit . getIndex ( pos ) ;", "del_tokens": "FASTAReader . prototype . getLength = function ( id ) { return unit . getEndIndex ( ) ; return unit . getEndIndex ( pos ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "grabbable", "maxGrabbers", "property", "to", "enable", "limits", "on", "multiple", "grabbers", "tests", "and", "documentation"], "add_tokens": "usePhysics : { default : 'ifavailable' } , maxGrabbers : { type : 'int' , default : NaN } if ( this . grabbers . indexOf ( evt . detail . hand ) === - 1 && ( ! Number . isFinite ( this . data . maxGrabbers ) || this . grabbers . length < this . data . maxGrabbers ) ) { evt . detail . hand . body && ! this . constraints . has ( evt . detail . hand ) && ( ! Number . isFinite ( this . data . maxGrabbers ) || this . constraints . size < this . data . maxGrabbers ) ) {", "del_tokens": "usePhysics : { default : 'ifavailable' } , // if (this.grabbers.indexOf(evt.detail.hand) !== -1) { return; } //already grabbed // this.grabbers.push(evt.detail.hand); if ( this . grabbers . indexOf ( evt . detail . hand ) === - 1 ) { evt . detail . hand . body && ! this . constraints . has ( evt . detail . hand ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "basic", "xml", "format", "for", "tokens"], "add_tokens": "themeConfig . platforms = { template : 'custom-simplejson' } , xml : { transformGroup : 'scss' , buildPath : 'dist/tokens/web/' , files : [ { destination : ` ${ themeName } ` , template : 'custom-xml' } ] dict . registerTemplate ( { name : 'custom-simplejson' , template : __dirname + '/utilities/tokens/simple.json.template' } ) ; name : 'custom-xml' , template : __dirname + '/utilities/tokens/xml.template'", "del_tokens": "const platforms = { template : 'website/simplejson' themeConfig . platforms = platforms ; name : 'website/simplejson' , template : __dirname + '/utilities/tokens/simple.json.template'", "commit_type": "add"}
{"commit_tokens": ["Fix", "Travis", "CI", "to", "run", "gulp", "coveralls", "on", "after_success", "due", "to", "randomly", "fail"], "add_tokens": "gulp . task ( \"coveralls\" , function ( ) {", "del_tokens": "gulp . task ( \"coveralls\" , [ \"coverage\" ] , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "bug", "when", "fn", "is", "not", "defined", "on", "init"], "add_tokens": "if ( fn && typeof fn === 'function' ) fn . apply ( this , arguments ) ;", "del_tokens": "fn . apply ( this , arguments ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "license", "field", "in", "test"], "add_tokens": "* Copyright ( c ) 2013 'name' , 'version' , 'description' , 'keywords' , 'homepage' , 'dependencies' , 'license' 'name' , 'version' , 'description' , 'keywords' , 'repository > repo' , 'license'", "del_tokens": "* Copyright ( c ) 2013 'name' , 'version' , 'description' , 'keywords' , 'homepage' , 'dependencies' , { license : '/licenses/0/type' } 'name' , 'version' , 'description' , 'keywords' , 'repository > repo' , { license : '/licenses/0/type' }", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "setFlags", "for", "updating", "message", "flags"], "add_tokens": "{ raw : \"Subject: hello 5\\r\\n\\r\\nWorld 5!\" , flags : [ \"$MyFlag\" , \"\\\\Deleted\" ] , uid : 557 } ,", "del_tokens": "{ raw : \"Subject: hello 5\\r\\n\\r\\nWorld 5!\" } ,", "commit_type": "implement"}
{"commit_tokens": ["Change", "to", "type", ".", "js", "to", "make", "it", "easier", "to", "write", "custom", "types", "."], "add_tokens": "if ( ! props . type ) { props . type = type . type ; }", "del_tokens": "props . type = type . type ;", "commit_type": "change"}
{"commit_tokens": ["Use", "buffer", "-", "xor", "instead", "of", "bitwise", "-", "xor", "for", "better", "speed"], "add_tokens": "const xor = require ( 'buffer-xor' )", "del_tokens": "const xor = require ( 'bitwise-xor' )", "commit_type": "use"}
{"commit_tokens": ["add", "second", "translation", "task", "for", "testing", "single", "and", "multi", "catalog"], "add_tokens": "gulp . task ( 'translateMultidirs' , [ 'build' ] , function ( ) { gulp . task ( 'translatesingledir' , [ 'build' ] , function ( ) { return gulp . src ( [ 'build' ] , { cwd : __dirname } ) . pipe ( statici18n ( { localeDirs : [ localePath ] } ) ) ; } ) ; gulp . task ( 'default' , [ 'translateMultidirs' ] ) ; gulp . task ( 'single' , [ 'translatesingledir' ] ) ;", "del_tokens": "gulp . task ( 'translate' , [ 'build' ] , function ( ) { gulp . task ( 'default' , [ 'translate' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "version", "of", "compiled", "front", "end"], "add_tokens": "'ui.router' , 'ngAnimate' } ; } ) . filter ( 'decodeHtml' , function ( ) { return function ( string ) { var map = { '&amp;' : ' & ' '&gt;' : ' > ' '&lt;' : ' < ' '&quot;' : '\"' , '&#39;' : \"'\" , '&apos;' : \"'\" } ; for ( var m in map ) { string = string . replace ( new RegExp ( m , 'gim' ) , map [ m ] ) ; } return string ; } ; // Check section level (main/sub/sub-sub/sub-sub-sub) $scope . getLevel = function ( section ) { if ( / ([0-9]\\.[0-9]\\.[0-9]\\.) / . test ( section . reference ) ) { return 'sub-sub-sub' ; } if ( / ([0-9]\\.[0-9]\\.) / . test ( section . reference ) ) { return 'sub-sub' ; } if ( / ([0-9]\\.) / . test ( section . reference ) ) { return 'sub' ; } return 'main' ; } var re = new RegExp ( '(^' + $scope . currentSection + '$)|(^' + $scope . currentSection + '\\\\.)' ) ;", "del_tokens": "'ui.router' } var re = new RegExp ( '(^' + $scope . currentSection + ')' ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "a", "way", "to", "trigger", "google", "analytics", "when", "faking", "server", "requests"], "add_tokens": "// client.express.js JavaScript Routing, version: 0.5.4 ClientExpress . googleAnalytics = function ( ) { return function ( ) { var server = this ; server . eventBroker . addListener ( 'onRequestProcessed' , function ( event ) { if ( ! event . isRedirect ) { if ( _gaq ) { _gaq . push ( [ '_trackPageview' , event . request . originalUrl ] ) ; } } } ) ; } ; } ; this . version = '0.5.4' ;", "del_tokens": "// client.express.js JavaScript Routing, version: 0.4.4 this . version = '0.4.4' ;", "commit_type": "add"}
{"commit_tokens": ["Change", ":", "Do", "not", "log", "entry", "/", "master", "DISCONNECTED", "error", "when", "disconnecting", "."], "add_tokens": "if ( err && ( err . code !== 'DISCONNECTED' ) ) M . log . error ( err ) ;", "del_tokens": "if ( err ) M . log . error ( err ) ;", "commit_type": "change"}
{"commit_tokens": ["Removing", "useless", "usage", "of", "seq"], "add_tokens": "a = new Set ( a ) ; b = new Set ( b ) ;", "del_tokens": "import { seq } from '../../helpers' ; a = new Set ( seq ( a ) ) ; b = new Set ( seq ( b ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Change", "the", "defaults", "for", "minisplunk", "to", "point", "to", "the", "ronnie", "server", "for", "now"], "add_tokens": "var username = this . $ ( \"#id_username\" ) . val ( ) || \"admin\" ; var host = this . $ ( \"#id_host\" ) . val ( ) || \"ronnie.splunk.com\" ; var port = this . $ ( \"#id_port\" ) . val ( ) || \"2911\" ; var app = this . $ ( \"#id_app\" ) . val ( ) || \"foursquare\" ;", "del_tokens": "var username = this . $ ( \"#id_username\" ) . val ( ) || \"itay\" ; var host = this . $ ( \"#id_host\" ) . val ( ) || \"localhost\" ; var port = this . $ ( \"#id_port\" ) . val ( ) || \"8000\" ; var app = this . $ ( \"#id_app\" ) . val ( ) || \"-\" ;", "commit_type": "change"}
{"commit_tokens": ["Add", "setAxes", "method", "to", "quat"], "add_tokens": "function _fromMat39 ( a , m0 , m1 , m2 , m3 , m4 , m5 , m6 , m7 , m8 ) { function setAxes ( a , x , y , z ) { return _fromMat39 ( a , x [ 0 ] , x [ 1 ] , x [ 2 ] , y [ 0 ] , y [ 1 ] , y [ 2 ] , z [ 0 ] , z [ 1 ] , z [ 2 ] ) } setAxes : setAxes ,", "del_tokens": "function _fromMat39 ( a , m0 , m1 , m2 , m3 , m4 , m5 , m6 , m7 , m8 ) {", "commit_type": "add"}
{"commit_tokens": ["add", "empty", "validation", "for", "TextField"], "add_tokens": "{ type : 'string' , id : 'formValidationDanjubianhao' , label : '', validation : { type : 'required' } } ,", "del_tokens": "{ type : 'string' , id : 'formValidationDanjubianhao' , label : ''},", "commit_type": "add"}
{"commit_tokens": ["Add", "update", "single", "model", "mutataion"], "add_tokens": "if ( hasResolve ) return GraphQLID // other models, use ID as reference", "del_tokens": "if ( hasResolve ) return GraphQLID // other model type", "commit_type": "add"}
{"commit_tokens": ["Added", "default", "export", "and", "used", "the", "default", "export", "from", "CatalystToggleButton", "."], "add_tokens": "import CatalystToggleButton from '../../catalyst-toggle-button/dist/catalyst-toggle-button.js' ; export default CatalystToggleSwitch ;", "del_tokens": "import { CatalystToggleButton } from '../../catalyst-toggle-button/dist/catalyst-toggle-button.js' ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "local", "function", "usage", "commands", "to", "work", "with", "multiple", "-", "entries"], "add_tokens": "loadHandler ( stats , functionId , purge ) { const handler = this . serverless . service . functions [ functionId ] . handler . split ( '.' ) ; const moduleFileName = ` ${ handler [ 0 ] } ` ; moduleFileName if ( purge ) { utils . purgeCache ( handlerFilePath ) ; } const module = require ( handlerFilePath ) ; const functionObjectPath = handler . slice ( 1 ) ; let func = module ; for ( let p of functionObjectPath ) { func = func [ p ] ; } return func ; const handler = this . loadHandler ( stats , functionName ) ; const handler = this . loadHandler ( stats , functionName , true ) ;", "del_tokens": "loadHandler ( stats ) { stats . compilation . options . output . filename utils . purgeCache ( handlerFilePath ) ; return require ( handlerFilePath ) ; const handler = this . loadHandler ( stats ) [ functionName ] ; const handler = this . loadHandler ( stats ) [ functionName ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "disown", "method", "to", "un", "-", "hook", "child", "entries"], "add_tokens": "if ( ! me . _paused && ! entry . _disowned ) { if ( me . _paused && ! entry . _disowned ) { entry . on ( \"disown\" , onend ) if ( ! me . _paused ) { me . _read ( ) } DirReader . prototype . disown = function ( entry ) { entry . emit ( \"beforeDisown\" ) entry . _disowned = true entry . parent = entry . root = null if ( entry === this . _currentEntry ) { this . _currentEntry = null } entry . emit ( \"disown\" ) }", "del_tokens": "if ( ! me . _paused ) { if ( me . _paused ) { me . _read ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "animated", "multi", "zoom", "out"], "add_tokens": "depthToStartAt = 1 + newZoomLevel - this . _topClusterLevel . _zoom ,", "del_tokens": "i , depthToStartAt = previousZoomLevel - this . _topClusterLevel . _zoom ,", "commit_type": "fix"}
{"commit_tokens": ["make", "code", "context", "object", "more", "consistent", "with", "other", "classes"], "add_tokens": "this . context = ctx ; this . value = val . trim ( ) ; this . line = lineno ; this . loc = { start : { line : lineno , pos : pos end : { line : lineno , pos : pos + val . length }", "del_tokens": "return { context : ctx , line : lineno , loc : { start : { line : lineno , pos : pos } , end : { line : lineno , pos : pos + val . length } value : val . trim ( )", "commit_type": "make"}
{"commit_tokens": ["Remove", "the", "different", "sixes", "of", "the", "icons", "and", "only", "keep", "biggest", "to", "reduce", "bundle", "size", "."], "add_tokens": ". filter ( appName => this . props . appsWhiteList . includes ( appName ) ) height : 50 , borderRadius : 25", "del_tokens": ". filter ( appName => this . props . appsWhiteList . includes ( appName ) ) height : 50", "commit_type": "remove"}
{"commit_tokens": ["Removed", "invalid", "access", "token", "for", "github", "."], "add_tokens": "\"url\" : \"https://api.github.com/repos/create-conform\"", "del_tokens": "\"url\" : \" https : //api.github.com/repos/create-conform\", \"github\" : { \"token\" : \"b0d01994e47a92f792b434bfe69e27684fea022a\" , \"branch\" : \"master\" , \"enablePreRelease\" : true }", "commit_type": "remove"}
{"commit_tokens": ["Moved", "schema", "path", "expansion", "into", "config"], "add_tokens": "var path = require ( 'path' ) ; schemapath : path . join ( __dirname , 'lib/api.json' ) ,", "del_tokens": "schemapath : 'lib/api.json' ,", "commit_type": "move"}
{"commit_tokens": ["Fix", "prettier", "config", "to", "remove", "unecessary", "diff"], "add_tokens": "'react-jsx' : 2 'bsc-flags' : [ '-bs-super-errors' ] 'react-jsx' : 2 'bsc-flags' : [ '-bs-super-errors' ]", "del_tokens": "'react-jsx' : 2 , 'bsc-flags' : [ '-bs-super-errors' ] , 'react-jsx' : 2 , 'bsc-flags' : [ '-bs-super-errors' ] ,", "commit_type": "fix"}
{"commit_tokens": ["Allow", "wei", "to", "be", "passed", "in", "as", "a", "hex", "string", "."], "add_tokens": "if ( typeof ( wei ) === 'number' ) { // @TODO: Warn if truncation will occur? wei = new utils . BN ( wei ) ; } else if ( utils . isHexString ( wei ) ) { wei = new utils . BN ( wei . substring ( 2 ) ) ; }", "del_tokens": "if ( typeof ( wei ) === 'number' ) { wei = new utils . BN ( wei ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "npm", "audit", "command"], "add_tokens": "async function post ( path , body ) { const opts = Object . assign ( { body } , getRequestOpts ( ) ) const req = await HTTP . post ( url . resolve ( config . uplink . href , path ) , opts ) return req . body } get , post ,", "del_tokens": "get : get ,", "commit_type": "add"}
{"commit_tokens": ["fix", "handling", "of", "ulong", "descriptor"], "add_tokens": "var descriptor = amqp_types . unwrap ( link . remote . attach . source . filter [ 'jms-selector' ] . descriptor ) ; assert . equal ( descriptor . readUInt32BE ( 0 ) , 0x0000468C ) ; assert . equal ( descriptor . readUInt32BE ( 4 ) , 0x00000004 ) ; assert . equal ( link . remote . attach . source . filter [ 'jms-selector' ] , \"colour = 'green'\" ) ;", "del_tokens": "assert . equal ( amqp_types . unwrap ( link . remote . attach . source . filter ) [ 'jms-selector' ] , \"colour = 'green'\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "cycle", "of", "requires", "in", "AnimatedParam"], "add_tokens": "import InternalAnimatedValue from './InternalAnimatedValue' ;", "del_tokens": "import InternalAnimatedValue from './AnimatedValue' ;", "commit_type": "remove"}
{"commit_tokens": ["update", "minimap", "control", "+", "Leaflet", ".", "Sync"], "add_tokens": "/ * * Leaflet . layerscontrol - minimap * * Layers control with synced minimaps for Leaflet . * * Jan Pieter Waagmeester < jieter @ jieter . nl > * / 'use strict' ; if ( layer instanceof L . Polygon || layer instanceof L . Rectangle ) { return L . polygon ( layer . getLatLngs ( ) , options ) ; } var layergroup = L . layerGroup ( ) ; layergroup . addLayer ( cloneLayer ( inner ) ) ; return layergroup ;", "del_tokens": "'use strict' ; if ( layer instanceof L . Polygon || layer instanceof L . Rectangle ) { return L . polygon ( layer . getLatLngs ( ) , options ) ; } var ret = L . layerGroup ( ) ; ret . addLayer ( cloneLayer ( inner ) ) ; return ret ;", "commit_type": "update"}
{"commit_tokens": ["fix", "typo", "in", "npm", "dependencies"], "add_tokens": "'broccoli-sass'", "del_tokens": "'broccoli-sasss'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "when", "a", "collection", "has", "been", "deleted", "and", "recreated", "remotely"], "add_tokens": "if ( changedNodes . length === 0 && Object . keys ( actions ) . length === 1 ) { //no create, update or move on any children in opposite, directory can safely be removed, if actions.delete is the only action", "del_tokens": "if ( changedNodes . length === 0 ) { //no create, update or move on any children in opposite, directory can safely be removed", "commit_type": "fix"}
{"commit_tokens": ["added", ":", "optional", "support", "for", "oc", ":", "relevantMsg", "attribute"], "add_tokens": "var xsltParams = survey . includeRelevantMsg ? { 'include-relevant-msg' : 1 } : { } ; return _transform ( sheets . xslForm , xformDoc , xsltParams ) ; delete survey . includeRelevantMsg ; function _transform ( xslStr , xmlDoc , xsltParams ) { var params = xsltParams || { } ; stylesheet . apply ( xmlDoc , params , function ( error , result ) {", "del_tokens": "return _transform ( sheets . xslForm , xformDoc ) ; function _transform ( xslStr , xmlDoc ) { stylesheet . apply ( xmlDoc , function ( error , result ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "user", "info", "to", "the", "request", "when", "the", "client", "ip", "is", "present", "."], "add_tokens": "if ( goog . isDefAndNotNull ( req . headers [ 'x-appengine-user-email' ] ) || goog . isDefAndNotNull ( req . headers [ 'x-appengine-user-ip' ] ) ) { if ( goog . isDefAndNotNull ( req . headers [ 'x-appengine-country' ] ) ) { if ( goog . isDefAndNotNull ( req . headers [ 'x-appengine-taskname' ] ) ) {", "del_tokens": "if ( req . headers [ 'x-appengine-user-email' ] ) { if ( req . headers [ 'x-appengine-country' ] ) { if ( req . headers [ 'x-appengine-taskname' ] ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "callback", "for", "find", "query"], "add_tokens": "ecDB . prototype . find = function ( table , query , callback ) { callback ( true ) ; self . DB . find ( table , query , function ( _err , _data ) {", "del_tokens": "ecDB . prototype . find = function ( table , data , callback ) { console . log ( 'nothing to find' ) ; self . DB . find ( table , data , function ( _err , _data ) {", "commit_type": "fix"}
{"commit_tokens": ["remove", "html", "parser", "for", "testing"], "add_tokens": "//Message.parsers.html = Message.parsers.txt;", "del_tokens": "Message . parsers . html = Message . parsers . txt ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "options", ".", "closeTransport", "."], "add_tokens": "const pCloseTransport = Symbol ( 'closeTransport' ) this [ pCloseTransport ] = isBoolean ( options . closeTransport ) ? options . closeTransport : true if ( ! this [ pSocketClosed ] && this [ pCloseTransport ] ) { / ** * Check if argument is boolean . * @ param { any } flag * @ returns { boolean } * / function isBoolean ( flag ) { return typeof flag === 'boolean' }", "del_tokens": "if ( ! this [ pSocketClosed ] ) {", "commit_type": "add"}
{"commit_tokens": ["added", "html", "to", "text", "config"], "add_tokens": "text : message . text || htmlToText . fromString ( message . html || '' , config . htmlToTextOpts ) , logger . debug ( 'Send message: ' , JSON . stringify ( data , null , 2 ) ) ;", "del_tokens": "text : message . text || htmlToText . fromString ( message . html || '' ) , logger . log ( 'Send message: ' , data ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "swarm", ".", "connect", "and", "swarm", ".", "peers", "tests"], "add_tokens": "addrs [ key ] = id . Addresses [ 0 ] // apiAddrs[key] + '/ipfs/' + id.ID it ( '.swarm.peers' , function ( done ) { assert ( res . Strings . length >= 2 ) if ( err ) { throw err }", "del_tokens": "addrs [ key ] = apiAddrs [ key ] + '/ipfs/' + id . ID console . log ( addrs ) console . log ( '->' , res ) it . skip ( '.swarm.peers' , function ( done ) { console . log ( 'should have 2 nodes' , res ) assert ( res . length >= 2 ) if ( err ) console . error ( err )", "commit_type": "fix"}
{"commit_tokens": ["Use", "can", ".", "viewModel", "symbol", "for", "setting", "the", "viewModel"], "add_tokens": "[ n ( \"can-symbol\" ) , \"canSymbol\" ] ,", "del_tokens": "[ n ( \"can-util/dom/data/data\" ) , \"domData\" ] ,", "commit_type": "use"}
{"commit_tokens": ["using", "curl", "says", "it", "s", "a", "bot"], "add_tokens": "} else if ( ua . match ( / curl|Bot|B-O-T|Crawler|Spider|Spyder|Yahoo|ia_archiver|Covario-IDS|findlinks|DataparkSearch|larbin|Mediapartners-Google|NG-Search|Snappy|Teoma|Jeeves|Charlotte|NewsGator|TinEye|Cerberian|SearchSight|Zao|Scrubby|Qseero|PycURL|Pompos|oegp|SBIder|yoogliFetchAgent|yacy|webcollage|VYU2|voyager|updated|truwoGPS|StackRambler|Sqworm|silk|semanticdiscovery|ScoutJet|Nymesis|NetResearchServer|MVAClient|mogimogi|Mnogosearch|Arachmo|Accoona|holmes|htdig|ichiro|webis|LinkWalker|lwp-trivial / i ) && ! ua . match ( / phone|Playstation / i ) ) {", "del_tokens": "} else if ( ua . match ( / Bot|B-O-T|Crawler|Spider|Spyder|Yahoo|ia_archiver|Covario-IDS|findlinks|DataparkSearch|larbin|Mediapartners-Google|NG-Search|Snappy|Teoma|Jeeves|Charlotte|NewsGator|TinEye|Cerberian|SearchSight|Zao|Scrubby|Qseero|PycURL|Pompos|oegp|SBIder|yoogliFetchAgent|yacy|webcollage|VYU2|voyager|updated|truwoGPS|StackRambler|Sqworm|silk|semanticdiscovery|ScoutJet|Nymesis|NetResearchServer|MVAClient|mogimogi|Mnogosearch|Arachmo|Accoona|holmes|htdig|ichiro|webis|LinkWalker|lwp-trivial / i ) && ! ua . match ( / phone|Playstation / i ) ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "property", "-", "owner", "check", "(", "compatibility", "with", "prototype", "-", "js", ")"], "add_tokens": "// Get an new UniqueId if ( ! body . hasOwnProperty ( i ) ) { continue ; } // Only process properties that belong to object. if ( ! object . hasOwnProperty ( prop ) ) { continue ; } if ( product . hasOwnProperty ( prop ) ) { }", "del_tokens": "// Get an new UniqueId if ( product . hasOwnProperty ( prop ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "so", "listen", "doesnt", "create", "an", "error", "when", "not", "using", "a", "name", "since", "the", "name", "isnt", "important"], "add_tokens": "var zonar = require ( \"../\" ) ; var z = zonar . create ( { name : \"bar.service\" , net : 'tjena' } ) ; z . start ( ) ;", "del_tokens": "var Hitta = require ( \"../\" ) . Hitta ; var node = new Hitta ( { id : \"bar.service\" , port : 5778 } ) ; node . start ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "attributes", "from", "control", "channel", "hints"], "add_tokens": "dflt : 5 , min : 1 , max : 10 expect ( hints . dflt ) . toBe ( 5 ) ; expect ( hints . min ) . toBe ( 1 ) ; expect ( hints . max ) . toBe ( 10 ) ;", "del_tokens": "attributes : 'attributes' expect ( hints . attributes ) . toBeUndefined ( ) ; expect ( hints . attributes ) . toBe ( 'attributes' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "things", "work", "with", "JSDom"], "add_tokens": "var xhr = new window . XMLHttpRequest ( ) ; spriteImage = new window . Image ( ) ; if ( style ) { style . setZIndex ( i ) ; styles [ stylesLength ] = style ; }", "del_tokens": "var xhr = new XMLHttpRequest ( ) ; spriteImage = new Image ( ) ; style . setZIndex ( i ) ; styles [ stylesLength ] = style ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "a", "couple", "of", "mistakes", "brought", "to", "light", "to", "publisuing", "buffers", ".", "Namely", ":", "a", "one", "-", "off", "false", "alarm", "in", "serializeInt", ";", "and", "accidentally", "writing", "two", "bytes", "for", "a", "frame", "end", "because", "206", "isn", "t", "an", "ascii", "char", "."], "add_tokens": "if ( b . used + size > b . length ) { b [ 0 ] = 206 ; return this . write ( b . slice ( 0 , 1 ) ) ; // frameEnd", "del_tokens": "if ( b . used + size >= b . length ) { return this . write ( String . fromCharCode ( 206 ) ) ; // frameEnd", "commit_type": "fix"}
{"commit_tokens": ["adding", "in", "support", "for", "korean"], "add_tokens": "'ja' : require ( './ja' ) , 'ko' : require ( './ko' )", "del_tokens": "'ja' : require ( './ja' )", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "omit", "automated", "back", "matter", "page", "(", "now", "the", "default", ")", "."], "add_tokens": "includeCopyrightPage : true , includeBackMatterPage : true if ( metadata . includeBackMatterPage ) { files . push ( { name : 'back.xhtml' , folder : '' , compress : true , content : getBackMatter ( self ) } ) ; } if ( document . metadata . includeBackMatterPage ) { opf += \" <item id='back' media-type='application/xhtml+xml' href='back.xhtml'/>[[EOL]]\" ; } if ( document . metadata . includeBackMatterPage ) { opf += \" <itemref idref='back'/>[[EOL]]\" ; }", "del_tokens": "includeCopyrightPage : true ; files . push ( { name : 'back.xhtml' , folder : '' , compress : true , content : getBackMatter ( self ) } ) ; opf += \" <item id='back' media-type='application/xhtml+xml' href='back.xhtml'/>[[EOL]]\" ; opf += \" <itemref idref='back'/>[[EOL]]\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "a", "footer", "option", "so", "that", "we", "can", "add", "a", "new", "line", "at", "the", "end", "of", "file"], "add_tokens": "footer : '' , var footer = grunt . template . process ( options . footer ) ; var output = banner + result . min + footer ;", "del_tokens": "var output = banner + result . min ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "converting", "value", "to", "changing", "expression", "for", "Windows", "matching"], "add_tokens": "* @ param { Boolean } path Whether it should adapt the pattern to match paths . const planckmatch = function ( value , patterns , options , path ) { planckmatch . parse ( patterns , options , path ) ,", "del_tokens": "// Node modules. const assert = require ( ` ` ) ; const planckmatch = function ( value , patterns , options = { } , isWindows ) { // Validate arguments. assert ( typeof ( value ) === ` ` , ` ` ) ; assert ( typeof ( patterns ) === ` ` || ( Array . isArray ( patterns ) && patterns . length > 0 && typeof ( patterns [ 0 ] === ` ` ) ) , ` ` ) ; planckmatch . parse ( patterns , options ) , isWindows", "commit_type": "remove"}
{"commit_tokens": ["fix", "bug", "with", "tenant", "/", "tenantId", "normalization"], "add_tokens": "tenantId : context . tenant || context . tenantId , // URI templates expect tenantId", "del_tokens": "tenantId : context . tenant , // URI templates expect tenantId", "commit_type": "fix"}
{"commit_tokens": ["Add", "comment", "for", "further", "work", "and", "fix", "issue", "with", "channel", "not", "existing", "anywhere", "but", "on", "root"], "add_tokens": "// See: https://github.com/derbyparty/derby-faq/tree/master/en#how-to-require-a-module-that-will-run-only-on-the-server-of-a-derby-application model . root . channel . send ( 'derby-ar-rpc' , data , cb ) ;", "del_tokens": "model . channel . send ( 'derby-ar-rpc' , data , cb ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "report", "and", "so", "on", "..."], "add_tokens": "var REPORT = ( function ( global ) { if ( ! _config . report ) return ; var _isInited = false ; pushMsg : function ( msg ) { //  return report ; report : function ( ) { //  _sendMsg ( ) ; return report ; } , init : function ( config ) { //  // id var id = parseInt ( _config . id , 10 ) ; if ( id ) { _config . report = _config . url + \"?id={{id}}&uin={{uin}}&msg=\" . replace ( / {{id}} / , id ) . replace ( / {{uin}} / , parseInt ( _config . uin , 10 ) ) ; ! _isInited && _run ( ) ; _isInited = true ; } return report ;", "del_tokens": "( function ( global ) { pushMsg : function ( msg ) { init : function ( config ) { _config . report = _config . url + \"?id={{id}}&uin={{uin}}&msg=\" . replace ( / {{id}} / , parseInt ( _config . id , 10 ) ) . replace ( / {{uin}} / , parseInt ( _config . uin , 10 ) ) ; _run ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "reliance", "on", "jsdom", "replace", "with", "can", "-", "simple", "-", "dom"], "add_tokens": "\"use strict\" ; var SimpleWindow = require ( 'can-simple-window' ) ; var cache = { } ; if ( ! cache [ version ] ) { SimpleWindow . env ( '<h1>can-compile</h1>' , cache [ version ] = win ; callback ( null , cache [ version ] ) ; callback ( null , cache [ version ] ) ; type = options . extensions [ type ] || type ;", "del_tokens": "'use strict' ; var jsdom = require ( \"jsdom\" ) ; var window = { } ; if ( ! window [ version ] ) { jsdom . env ( '<h1>can-compile</h1>' , window [ version ] = win ; callback ( null , window [ version ] ) ; callback ( null , window [ version ] ) ; type = options . extensions [ type ] || type ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "explicit", "import", "paths", "."], "add_tokens": "import { Octant } from \"../core/octant.js\" ;", "del_tokens": "import { Octant } from \"../core\" ;", "commit_type": "use"}
{"commit_tokens": ["fixed", ":", "isPublish", "determine", "conditions"], "add_tokens": "const isPublish = reactScriptsLinked || const hasConfigJs = fs . existsSync ( path . resolve ( appDirectory , isPublish ? '' : demoDirectory , '.config.js' ) ) // isPublish || console.log('\\n.config.js\\n', { // reactScriptsPath, // reactScriptsLinked, // isPublish, // // 'fs.existsSync(reactScriptsPath)':fs.existsSync(reactScriptsPath), // // 'fs.lstatSync(reactScriptsPath).isSymbolicLink()':fs.lstatSync(reactScriptsPath).isSymbolicLink(), // 'ownPackageJson.name': ownPackageJson.name, // // \"__dirname.indexOf(path.join('packages', ownPackageJson.name, 'config')) === -1\":__dirname.indexOf(path.join('packages', ownPackageJson.name, 'config')) === -1, // hasConfigJs // }) // return } = config", "del_tokens": "const isPublish = reactScriptsLinked && const hasConfigJs = fs . existsSync ( path . resolve ( appDirectory , demoDirectory , '.config.js' ) ) } = config", "commit_type": "fix"}
{"commit_tokens": ["added", "static", "method", "List", ".", "dbPath", "()", "to", "help", "facilite", "easy", "access", "to", "paths"], "add_tokens": "/ ** * If you want to just get the ` ` of a Model you can call * this static method and the path will be returned . * * ** Note : ** the optional second parameter lets you pass in any * dynamic path segments if that is needed for the given model . * / static dbPath ( model , offsets ) { const obj = offsets ? List . create ( model , { offsets } ) : List . create ( model ) ; return obj . dbPath ; } throw new errors_1 . FireModelError ( ` ${ util_1 . capitalize ( this . modelName ) } ${ JSON . stringify ( Object . keys ( this . _offsets || { } ) ) } ${ dbOffset } ` ) ;", "del_tokens": "throw new errors_1 . FireModelError ( ` ${ util_1 . capitalize ( this . modelName ) } ${ JSON . stringify ( Object . keys ( this . _offsets ) ) } ${ dbOffset } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "scrolling", "of", "content", "and", "highlighting", "of", "selected", "link"], "add_tokens": "var firstLink = $ ( '#toc a:first' ) ; firstLink . click ( ) ; if ( nested ) { if ( doc . selectedLink ) { doc . selectedLink . removeClass ( 'selected' ) ; } a . addClass ( 'selected' ) ; doc . selectedLink = a ; }", "del_tokens": "$ ( '#toc a:first' ) . click ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "dynamic", "view", "transaction", "and", "resultset", ".", "copy", "()"], "add_tokens": "result . filteredrows = this . filteredrows . slice ( ) ; this . cachedresultset = this . resultset . copy ( ) ;", "del_tokens": "result . filteredrows = this . filteredrows ; this . cachedresultset = this . resultset ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", "with", "query", "strings", "containing", "objects", "in", "Node", ".", "js", "version"], "add_tokens": "var opts_data = opts . data || { } ; for ( var k in opts_data ) { if ( opts_data . hasOwnProperty ( k ) && typeof opts_data [ k ] === 'object' ) { var subObj = opts_data [ k ] ; for ( var kk in subObj ) { opts_data [ k + '[' + kk + ']' ] = subObj [ kk ] ; } delete opts_data [ k ] ; } } query = qstr . stringify ( opts_data ) ; console . log ( query ) ;", "del_tokens": "query = qstr . stringify ( opts . data || { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "detection", "of", "root", "element", "in", "parent", "function"], "add_tokens": "} else if ( path . isFunction ( ) || path . isProgram ( ) ) {", "del_tokens": "} else if ( path . isFunction ( ) ) { path . parentPath . traverse ( jsxVisitor , state ) ; } else if ( path . isProgram ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "--", "run", "-", "self", "-", "tests", "option", "."], "add_tokens": "-- run - self - tests - Run tests for the engine ( from tia / tests directory ) . 'debug-max' , 'run-self-tests' var path = require ( 'path' ) ; if ( args . runSelfTests ) { args . testsDir = path . join ( __dirname , '..' , 'tests' ) ; }", "del_tokens": "'debug-max' var path = require ( 'path' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "checking", "idevicelocation", "for", "ios", "real", "device"], "add_tokens": "return 'Why fbsimctl is needed and how to install it: http://appium.io/docs/en/drivers/ios-xcuitest/' ; return 'Why applesimutils is needed and how to install it: http://appium.io/docs/en/drivers/ios-xcuitest/' ; class OptionalIdevicelocationCommandCheck extends DoctorCheck { async diagnose ( ) { const idevicelocationPath = await resolveExecutablePath ( 'idevicelocation' ) ; return idevicelocationPath ? okOptional ( ` ${ idevicelocationPath } ` ) : nokOptional ( 'idevicelocation cannot be found' ) ; } async fix ( ) { // eslint-disable-line require-await return 'idevicelocation is used to set geolocation for real device. Please read https://github.com/JonGabilondoAngulo/idevicelocation to install it' ; } } checks . push ( new OptionalIdevicelocationCommandCheck ( ) ) ; AuthorizationDbCheck , CarthageCheck , OptionalFbsimctlCommandCheck , OptionalApplesimutilsCommandCheck , OptionalIdevicelocationCommandCheck", "del_tokens": "return ` ` ; return ` ` ; AuthorizationDbCheck , CarthageCheck , OptionalFbsimctlCommandCheck , OptionalApplesimutilsCommandCheck", "commit_type": "add"}
{"commit_tokens": ["Make", "quadratic", "points", "explicit", "for", "canvas"], "add_tokens": "// a + (a - b) = 2a - b where a is the position and b is the last control point [ 1.3333333333333333 , 1 , 1.6666666666666667 , 1 , 2 , 1 ] , [ 2.3333333333333333 , 1 , 2.6666666666666665 , 0 , 3 , 0 ] , [ 3.3333333333333335 , 0 , 3.8333333333333335 , 0 , 4 , 0 ]", "del_tokens": "[ 1.6666666666666667 , 1 , 2 , 1 ] , [ 2.6666666666666665 , 0 , 3 , 0 ] , [ 3.8333333333333335 , 0 , 4 , 0 ]", "commit_type": "make"}
{"commit_tokens": ["Added", "super", "-", "ish", "calls"], "add_tokens": "var opts = arguments . length <= 1 || arguments [ 1 ] === undefined ? { } : arguments [ 1 ] ;", "del_tokens": "var opts = arguments [ 1 ] === undefined ? { } : arguments [ 1 ] ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "reference", "to", "Sections", "constructor", "instance"], "add_tokens": "window . __sections__ . off ( this . namespace ) ; remove ( window . __sections__ . instances , { id : this . id } ) ;", "del_tokens": "sections . off ( this . namespace ) ; remove ( sections . instances , { id : this . id } ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "metadata", "and", "index", "file", "to", "new", "bundle", "dirs", "still", "troubleshooting", "tests", "though"], "add_tokens": "assert . equal ( err , undefined , ': GPX was processed' ) ; assert . ok ( fs . existsSync ( path . join ( outdirectory , 'metadata.json' ) ) , ': contains metadata for original gpx' ) ;", "del_tokens": "console . log ( tmpdir ) ; assert . equal ( err , undefined , ': GPX was processed' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "to", "check", "iso", "dates", "."], "add_tokens": "if ( date && date . toString ( ) === 'Invalid Date' ) {", "del_tokens": "if ( date === 'Invalid Date' ) {", "commit_type": "add"}
{"commit_tokens": ["improved", "performance", "of", "the", "tree", "control"], "add_tokens": "function shallowCopy ( src , dst ) { if ( angular . isArray ( src ) ) { dst = dst || [ ] ; for ( var i = 0 ; i < src . length ; i ++ ) { dst [ i ] = src [ i ] ; } } else if ( angular . isObject ( src ) ) { dst = dst || { } ; for ( var key in src ) { if ( hasOwnProperty . call ( src , key ) && ! ( key . charAt ( 0 ) === '$' && key . charAt ( 1 ) === '$' ) ) { dst [ key ] = src [ key ] ; } } } return dst || src ; } a = shallowCopy ( a ) ; b = shallowCopy ( b ) ;", "del_tokens": "a = angular . copy ( a ) ; b = angular . copy ( b ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "interrupt", "function", "ot", "scheduler", "fixed", "line", "follower", "example"], "add_tokens": "} ) . when ( function ( ) {", "del_tokens": "} ) . once ( function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Change", ":", "Default", "kind", ".", "getCaption", "returns", "optional", "entry", ".", "data", ".", "caption", "too", "."], "add_tokens": "return ( entry . data && ( entry . data . name || entry . data . caption ) ) || entry . id ;", "del_tokens": "return entry . data && entry . data . name || entry . id ;", "commit_type": "change"}
{"commit_tokens": ["fix", "bug", "in", "name", "collisions", "by", "creating", "a", "naming", "hierarchy", "with", "sectionof"], "add_tokens": "preprocess : function ( context , Handlebars ) { // console.log(JSON.stringify(context.sections,null,2)); console . log ( context . sections ) ; context . scripts . push ( 'https://cdn.jsdelivr.net/prism/1.4.1/components/prism-j.min.js' , 'https://cdn.jsdelivr.net/prism/1.4.1/plugins/show-language/prism-show-language.min.js' ) ; context . stylesheets . push ( 'https://cdn.jsdelivr.net/prism/1.4.1/plugins/show-language/prism-show-language.css' ) ;", "del_tokens": "preprocess : function ( resolve , reject ) { // console.log(arguments); // console.log(this); // console.log(JSON.stringify(this.context.sections,null,2)); // console.log(this.context.sections); // console.log(this.context); this . context . scripts . push ( 'https://cdn.jsdelivr.net/prism/1.4.1/components/prism-j.min.js' , 'https://cdn.jsdelivr.net/prism/1.4.1/plugins/show-language/prism-show-language.min.js' ) ; this . context . stylesheets . push ( 'https://cdn.jsdelivr.net/prism/1.4.1/plugins/show-language/prism-show-language.css' ) ; resolve ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "in", "width", "of", "PreFooter"], "add_tokens": "background - color : ${ colors . Rain . Shark } ; background - image : url ( $ { preFooterBackground } ) ; background - repeat : no - repeat ; background - position : 50 % 50 % ; background - size : cover ;", "del_tokens": "background : $ { colors . Rain . Shark } url ( $ { preFooterBackground } ) no - repeat 50 % 50 % ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "documentation", "around", "how", "to", "use", "the", "library", "and", "install", "everything"], "add_tokens": "// context.sses = sendSysExString; var sendPixel = function ( red , green , blue , pos ) { //var send = send || false; var send = true ;", "del_tokens": "context . sses = sendSysExString ; var sendPixel = function ( red , green , blue , pos , send ) { var send = send || false ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "deps", "and", "getting", "karma", "working"], "add_tokens": "var path = require ( 'path' ) ; var ngCode = [ path . normalize ( __dirname + '/../node_modules/angular/angular.js' ) , path . normalize ( __dirname + '/../node_modules/angular-mocks/angular-mocks.js' ) ] ;", "del_tokens": "var ngCode = [ 'node_modules/angular/angular.js' , 'node_modules/angular-mocks/angular-mocks.js' ] ;", "commit_type": "update"}
{"commit_tokens": ["Added", "option", "to", "disable", "rounding", "px", "values", "."], "add_tokens": "mediaQuery : false , round : false function preciseRound ( num ) { var decimals = options . round ? 0 : 1 ; var pxValue = preciseRound ( unitlessValue * rootSize ) + 'px' ;", "del_tokens": "mediaQuery : false function preciseRound ( num , decimals ) { var pxValue = preciseRound ( unitlessValue * rootSize , 0 ) + 'px' ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "copyright", "header", "to", "jCanvas"], "add_tokens": "http : //calebevans.me/projects/jcanvas/ Copyright 2011 , Caleb Evans Licensed under the MIT license http : //calebevans.me/projects/jcanvas/license.html", "del_tokens": "Caleb Evans", "commit_type": "add"}
{"commit_tokens": ["Add", "padding", "and", "font", "style", "to", "Tooltip", "component"], "add_tokens": "import TooltipContent from './TooltipContent' < Tooltip tip = \"Hello\" placement = \"right\" > placement : PropTypes . oneOf ( [ 'top' , 'bottom' , 'left' , 'right' ] ) , size : PropTypes . oneOf ( [ 'small' , 'medium' , 'large' ] ) placement : 'top' , size : 'small' < TooltipContent id = { this . _tipId } > { this . props . tip } < / TooltipContent >", "del_tokens": "< Tooltip tip = { < Heading > Hello < / Heading > } placement = \"right\" > placement : PropTypes . oneOf ( [ 'top' , 'bottom' , 'left' , 'right' ] ) placement : 'top' < div id = { this . _tipId } role = \"tooltip\" > { this . props . tip } < / div >", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "need", "for", "an", "isolated", "scope"], "add_tokens": "scope : false , link : function ( scope , element , attrs ) { scope . $watch ( attrs . froalaView , function ( nv ) {", "del_tokens": "scope : { content : '=froalaView' } , link : function ( scope , element ) { scope . $watch ( 'content' , function ( nv ) {", "commit_type": "remove"}
{"commit_tokens": ["use", "plugins", "instead", "of", "renderFile", "in", "write", "task"], "add_tokens": "generate . questions . setData ( pkg ) ; generate . plugin ( 'render' , function ( ) { var data = generate . get ( 'answers' ) ; return generate . renderFile ( 'text' , data ) ; } ) ; . on ( 'error' , console . log ) . pipe ( generate . pipeline ( ) ) . on ( 'error' , console . log )", "del_tokens": "if ( ! generate . templates ) { generate . create ( 'templates' ) ; } generate . questions . setData ( pkg || { } ) ; answers . name = answers . name || utils . project ( ) ; var data = generate . get ( 'answers' ) ; . pipe ( generate . renderFile ( 'text' , data ) )", "commit_type": "use"}
{"commit_tokens": ["Use", "one", "-", "time", "binding", "in", "layermanager", "example"], "add_tokens": "map : '=layerManager' controller : function ( ) { } , controllerAs : 'ctrl' , bindToController : true , 'ctrl.map.getLayers().getArray()' +", "del_tokens": "map : '=layerManager' , layers : '=layerManagerLayers' 'map.getLayers().getArray()' +", "commit_type": "use"}
{"commit_tokens": ["CHANGED", "credentials", "replaced", "with", "browser", ".", "on", "(", "authenticate", "fn", ")"], "add_tokens": "// HTTP Basic authentication const authenticate = { host , username : null , password : null } ; this . emit ( 'authenticate' , authenticate ) ; const { username , password } = authenticate ; if ( username && password ) { this . log ( ` ${ username } ${ password } ` ) ; const base64 = new Buffer ( ` ${ username } ${ password } ` ) . toString ( 'base64' ) ; headers . authorization = ` ${ base64 } ` ; }", "del_tokens": "// Apply authentication credentials const credentials = this . authenticate ( host , false ) ; if ( credentials ) credentials . apply ( headers ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "ios", "sdk", "version", "logic"], "add_tokens": "logger . debug ( \"Setting iOS SDK Version\" ) ; this . iOSSDKVersion = await utils . getAndCheckIosSdkVersion ( ) ; logger . debug ( \"iOS SDK Version set to \" + this . iOSSDKVersion ) ;", "del_tokens": "//await this.setiOSSDKVersion();", "commit_type": "add"}
{"commit_tokens": ["Fix", "ESLint", "output", "for", "gulp"], "add_tokens": "stream . add ( eslint . results ( results => { const count = results . errorCount ; if ( count ) { const message = \"ESLint failed with \" + count + ( count === 1 ? \" error\" : \" errors\" ) ; cb ( new crafty . Information ( message ) ) ; } } ) ) ;", "del_tokens": "stream . add ( eslint . failAfterError ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "_updateItemCount", "function", "and", "fixed", "a", "bug", "where", "remove", "didn", "t", "update", "the", "item", "count", "."], "add_tokens": "_updateItemCount : function ( ) { this . visibleItems = this . $items . filter ( '.filtered' ) . length ; return this ; } , fire : function ( name , args ) { this . $container . trigger ( name + '.shuffle' , args && args . length ? args : [ this ] ) ; self . _updateItemCount ( ) ; self . _updateItemCount ( ) ; shuffle . _updateItemCount ( ) ; shuffle . fire ( 'removed' , [ $collection , shuffle ] ) ; shuffle . shuffle . apply ( shuffle , args ) ; useTransition : true , // You don't want transitions on shuffle items? Fine, but you're weird supported : Modernizr . csstransforms && Modernizr . csstransitions // supports transitions and transforms", "del_tokens": "fire : function ( name ) { this . $container . trigger ( name + '.shuffle' , [ this ] ) ; self . visibleItems = self . $items . filter ( '.filtered' ) . length ; self . visibleItems = self . $items . filter ( '.filtered' ) . length ; shuffle . shuffle . apply ( shuffle , [ opts ] ) ; useTransition : true // You don't want transitions on shuffle items? Fine, but you're weird supported : Modernizr . csstransforms && Modernizr . csstransitions , // supports transitions and transforms", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "options", ".", "page"], "add_tokens": "all : [ 'example/test/**/!(test2|testBail|testPage).html' ] , } , // Test page options testPage : { src : [ 'example/test/testPage.html' ] , options : { page : { settings : { userAgent : 'grunt-mocha-agent' } } } grunt . task . registerTask ( 'testPage' , [ 'mocha:testPage' ] ) ; 'testPage' , 'testBail' ,", "del_tokens": "all : [ 'example/test/**/!(test2|testBail).html' ] , 'testBail'", "commit_type": "add"}
{"commit_tokens": ["adding", "ability", "to", "load", "local", "plugins"], "add_tokens": "it ( \"should insert stylesheets in layout\" , function ( done ) { var uid = triggerBuild ( { enabledFormats : [ \"html\" ] , layout : \"spec/support/book/layouts/assets.html\" , stylesheets : { files : [ \"spec/support/book/stylesheets/styles.css\" , \"spec/support/book/stylesheets/otherstyles.scss\" ] } , success : function ( ) { expect ( buildPath ( uid , \"html/first-chapter.html\" ) ) . toHaveContent ( \"<LINKscript type=\\\"text/javascript\\\" src=\\\"assets/styles.css\\\"></script>\" ) ; expect ( buildPath ( uid , \"html/first-chapter.html\" ) ) . toHaveContent ( \"<LINKscript type=\\\"text/javascript\\\" src=\\\"assets/otherstyles.css\\\"></script>\" ) ; done ( ) ; } } ) ; } ) ;", "del_tokens": "it ( \"should insert the stylesheets in the layout\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "existing", "manifest", "regex", "test"], "add_tokens": "if ( / \\smanifest\\s*= / . test ( match ) ) {", "del_tokens": "if ( match . test ( / \\smanifest\\s*= / ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "owner", "-", "of", "-", "erc721", "-", "token", "example"], "add_tokens": "async function getERC721PropertyNews ( ) { getERC721PropertyNews ( )", "del_tokens": "/ * Check all BCH and token balances for an address * / async function getSingleBalance ( ) { getSingleBalance ( )", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "where", "face", "wasn", "t", "flipping", "when", "the", "digits", "are", "!", "(", "instanceOf", "Date", ")"], "add_tokens": "if ( ! ( t . factory . time . time instanceof Date ) ) {", "del_tokens": "if ( ! t . factory . time . time instanceof Date ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "feature", "detection", "for", "passive", "event", "option"], "add_tokens": "this . supportsEventPassiveOption = this . detectEventPassiveOption ( ) ; / ** * Feature detection : addEventListener passive option * https : //dom.spec.whatwg.org/#dom-addeventlisteneroptions-passive * https : //github.com/WICG/EventListenerOptions/blob/gh-pages/explainer.md * / Selectr . prototype . detectEventPassiveOption = function ( ) { var supportsPassiveOption = false ; try { var opts = Object . defineProperty ( { } , 'passive' , { get : function ( ) { supportsPassiveOption = true ; } } ) ; window . addEventListener ( 'test' , null , opts ) ; } catch ( e ) { } return supportsPassiveOption ; } } , this . supportsEventPassiveOption ? { passive : true } : false ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "dasherize", "and", "underscored", "text", "helpers"], "add_tokens": "} , dasherize : function ( text , render ) { return helpers . trim ( text ) . replace ( / ([A-Z]) / g , '-$1' ) . replace ( / [-_\\s]+ / g , '-' ) . toLowerCase ( ) ; } , underscored : function ( text , render ) { return helpers . trim ( text ) . replace ( / ([a-z\\d])([A-Z]+) / g , '$1_$2' ) . replace ( / [-\\s]+ / g , '_' ) . toLowerCase ( ) ; }", "del_tokens": "} //dasherize //underscored", "commit_type": "add"}
{"commit_tokens": ["allow", "null", "response", "from", "async", "action", "creators"], "add_tokens": "import { default as compose } from 'lodash.flowright' ( action ? next ( action ) : null ) if ( exec ) return tagType ( { type , exec } , ACTION )", "del_tokens": "import { flowRight as compose } from 'lodash.flowright' next ( action ) return tagType ( { type , exec } , ACTION )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "various", "code", "style", "issues"], "add_tokens": "function CoverageFile ( filename ) { function numericHits ( hits ) { if ( hits === '-' ) { return 0 ; } return parseInt ( hits , 10 ) ; } function mergedBRDAHits ( existingBRDAHits , newBRDAHits ) { // If we've never executed the branch code path in an existing coverage // record and we've never executed it here either, then keep it as '-' // (eg, never executed). If either of them is a number, then // use the number value. if ( existingBRDAHits !== '-' || newBRDAHits !== '-' ) { return numericHits ( existingBRDAHits ) + numericHits ( newBRDAHits ) ; } return '-' ; } currentCoverageFile = new CoverageFile ( currentFileName ) ; // it as a string and let mergedBRDAHits work it out. existingBRDA . hits = mergedBRDAHits ( existingBRDA . hits , hits ) ;", "del_tokens": "function coverageFile ( filename ) { function _numericHits ( hits ) { if ( hits === '-' ) { return 0 ; } return parseInt ( hits , 10 ) ; } function _mergedBRDAHits ( existingBRDAHits , newBRDAHits ) { // If we've never executed the branch code path in an existing coverage // record and we've never executed it here either, then keep it as '-' // (eg, never executed). If either of them is a number, then // use the number value. if ( existingBRDA . hits !== '-' || hits !== '-' ) { return _numericHits ( existingBRDAHits ) + _numericHits ( newBRDAHits ) ; } return '-' ; } currentCoverageFile = new coverageFile ( currentFileName ) ; // it as a string and let _mergedBRDAHits work it out. existingBRDA . hits = _mergedBRDAHits ( existingBRDA . hits , hits ) ; continue ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "xml", "output", ".", "Respond", "based", "on", "HTTP", "Accept", "header", ".", "Fix", "res", ".", "headersSent", "typo"], "add_tokens": "var js2xmlparser = require ( \"js2xmlparser\" ) ; if ( res . headersSent ) { res . format ( { json : function ( ) { res . jsonp ( res . code , res . data ) ; } , xml : function ( ) { var xmlString = js2xmlparser ( 'message' , res . data ) ; res . set ( 'Content-Type' , 'application/xml; charset=utf-8' ) ; res . send ( res . code , xmlString ) ; } , text : function ( ) { res . send ( res . code , res . data ) ; } } ) ;", "del_tokens": "if ( res . headerSent ) { // Respond with correct format, defaulting to json res . fmt = res . fmt || 'json' ; if ( res . fmt === 'json' ) { // json res . jsonp ( res . code , res . data ) ; } else if ( res . fmt === 'xml' ) { // xml res . set ( 'Content-Type' , 'application/xml; charset=utf-8' ) ; res . send ( res . code , res . data ) ; } else { // text or html res . send ( res . code , res . data ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "data", "attrs", "for", "label"], "add_tokens": "labelDataAttrs , const labelDataAttributes = getDataAttributes ( labelDataAttrs ) ; < div { ... dataAttributes } className = { classNames } > < label { ... labelDataAttributes } aria - checked = { checked } className = \"ui-radio__label\" htmlFor = { id } role = \"radio\" > / ** * Data attribute . You can use it to set up any custom data - * attribute for label . * / labelDataAttrs : PropTypes . oneOfType ( [ PropTypes . bool , PropTypes . object , ] ) ,", "del_tokens": "< div className = { classNames } { ... dataAttributes } > < label aria-checked = { checked } className = \"ui-radio__label\" htmlFor = { id } role = \"radio\" >", "commit_type": "add"}
{"commit_tokens": ["Add", "script", "to", "remove", "ephemeral", "nodes", "fiddle", "with", "readme"], "add_tokens": "if ( znode . match ( '/zookeeper' ) ) {", "del_tokens": "if ( znode === '/zookeeper' ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "code", "style", "issues"], "add_tokens": "'use strict' ; var chai = require ( 'chai' ) ; var language = require ( '../src/language' ) ;", "del_tokens": "\"use strict\" ; var chai = require ( \"chai\" ) ; var language = require ( \"../src/language\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "meta", "+", "backspace", "which", "clears", "up", "to", "the", "start", "of", "line", "."], "add_tokens": "FormattedTextField . prototype . deleteBackwardToBeginningOfLine = function ( event ) { var caret ; if ( this . hasSelection ) { return this . deleteBackward ( event ) ; } event . preventDefault ( ) ; caret = this . caret ; caret . start = 0 ; this . caret = caret ; return this . clearSelection ( ) ; } ; switch ( modifiers ) { case ' ' _this . deleteBackward ( event ) ; break ; case 'alt' : case 'alt+shift' : _this . deleteWordBackward ( event ) ; break ; case 'ctrl' : case 'ctrl+shift' : _this . deleteBackwardByDecomposingPreviousCharacter ( event ) ; break ; case 'meta' : case 'meta+shift' : _this . deleteBackwardToBeginningOfLine ( event ) ; break ; default : throw new Error ( \"unhandled backspace+\" + modifiers ) ;", "del_tokens": "if ( altKey ) { _this . deleteWordBackward ( event ) ; } else if ( ctrlKey ) { _this . deleteBackwardByDecomposingPreviousCharacter ( event ) ; } else { _this . deleteBackward ( event ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "test", "case", "for", "id", "property", "being", "strings"], "add_tokens": "it ( 'should return the requested resource by its id (as number)' , function ( ) { it ( 'should return the requested resource by its id (as string)' , function ( ) { PersonModel . get ( '123' ) . then ( function ( theFetchedPerson ) { expect ( theFetchedPerson ) . toBeDefined ( ) ; expect ( theFetchedPerson . name ) . toEqual ( 'Juri' ) ; } ) ; $httpBackend . expectGET ( '/api/people/123' ) ; $httpBackend . flush ( ) ; } ) ;", "del_tokens": "it ( 'should return the requested resource by its id' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "call", "with", "context", "to", "the", "Type", "function"], "add_tokens": "'\\tvar context = options.context;\\n' + '\\tif(context) {\\n' + '\\t\\tchannel.callMethod(reqPayload, context, callback);\\n' + '\\t} else {\\n' + '\\t\\tchannel.callMethod(reqPayload, callback);\\n' + '\\t}\\n' ;", "del_tokens": "'\\tchannel.callMethod(reqPayload, callback);\\n' ;", "commit_type": "add"}
{"commit_tokens": ["update", "config", "with", "correct", "job", "number"], "add_tokens": "config . sauceUser = process . env . SAUCE_USERNAME ; config . sauceKey = process . env . SAUCE_ACCESS_KEY ; 'tunnel-identifier' : process . env . TRAVIS_JOB_NUMBER , 'build' : process . env . TRAVIS_BUILD_NUMBER ,", "del_tokens": "config . sauceUser = 'mdasberg' ; //process.env.SAUCE_USERNAME; config . sauceKey = '6819c778-bd98-452d-a89f-5ab3902083aa' ; //process.env.SAUCE_ACCESS_KEY; 'tunnel-identifier' : '1' , //process.env.TRAVIS_JOB_NUMBER, 'build' : '1' , //process.env.TRAVIS_BUILD_NUMBER,", "commit_type": "update"}
{"commit_tokens": ["add", "getTarget", "method", "to", "help", "compile", "target", "url", "and", "query", "parameters"], "add_tokens": "} , getTarget : function ( params ) { var target = $ . getOpt ( 'target' ) ; if ( target . indexOf ( '?' ) < 0 ) { target += '?' ; } else { target += '&' ; } return target + params . join ( '&' ) ; $ . xhr . open ( \"GET\" , $h . getTarget ( params ) ) ; target = $h . getTarget ( params ) ;", "del_tokens": "var targetUrl = $ . getOpt ( 'target' ) ; if ( targetUrl . indexOf ( '?' ) < 0 ) { targetUrl += '?' ; } else { targetUrl += '&' ; } $ . xhr . open ( \"GET\" , targetUrl + params . join ( '&' ) ) ; target += '?' + params . join ( '&' ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "_send", "into", "constructor", "as", "an", "inline", "function"], "add_tokens": "// Default callback is noop this . send = function ( err , resp , body ) { } ;", "del_tokens": "// TODO: add as prototype? // Default callbacks function _send ( err , resp , body ) { } this . send = _send ;", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "the", "following", "browsers", ":", "Safari", "IE", "(", "11", "+", ")", "Tested", "on", "Edge", "and", "figured", "out", "that", "condition", "isChrome", "was", "true", "on", "Edge", ":", "the", "stack", "trace", "is", "the", "same", "as", "in", "Chrome", "so", "renamed", ":", "isChrome", "to", "isChromeOrEdge", "Tested", "on", "Safari", "IE", "11", "Edge", "Adapted", "readme"], "add_tokens": "if ( isChromeOrEdge ( ) || isIE11Plus ( ) ) { } else if ( isFirefox ( ) || isSafari ( ) ) { var isChromeOrEdge = function ( ) { } ; var isSafari = function ( ) { return navigator . userAgent . toLowerCase ( ) . indexOf ( 'safari' ) > - 1 ; } ; var isIE11Plus = function ( ) { return document . documentMode && document . documentMode >= 11 ; var match = String ( origLine ) . match ( ( isChromeOrEdge ( ) || isIE11Plus ( ) ) ?", "del_tokens": "if ( isChrome ( ) ) { } else if ( isFirefox ( ) ) { var isChrome = function ( ) { var match = String ( origLine ) . match ( isChrome ( ) ?", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", "tests", "and", "package", ".", "json"], "add_tokens": "function testProcessStream ( processProvider , options , callback ) { es . readArray ( source ) . pipe ( dest ) . pipe ( es . wait ( callback ) ) ; testProcessStream ( function ( ) { testProcessStream ( function ( input , output ) { testProcessStream ( function ( input ) { testProcessStream ( function ( input , output ) { return cp . exec ( \"cp \" + input + \" \" + output ) ;", "del_tokens": "var stream = require ( \"stream\" ) ; var fs = require ( \"fs\" ) ; function testFunction ( processProvider , options , callback ) { es . readArray ( source ) . pipe ( dest ) . pipe ( es . wait ( function ( err , target ) { callback ( err , target ) ; } ) ) ; testFunction ( function ( input , output ) { testFunction ( function ( input , output ) { testFunction ( function ( input , output ) { testFunction ( function ( input , output ) { var exec = cp . exec ( \"cat \" + input ) ; exec . stdout . pipe ( fs . createWriteStream ( output ) ) ; return exec ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "tests", "to", "properly", "handle", "folded", "headers", "in", "test"], "add_tokens": "test . equal ( email . headers . Xfolded , xfolded . replace ( / \\r\\n\\s / , \" \" ) , \"Should have the folded header\" ) ;", "del_tokens": "test . equal ( email . headers . Xfolded , xfolded . replace ( / \\r\\n\\s+ / , \" \" ) , \"Should have the folded header\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "round", "-", "robining", "when", "no", "partition", "provided", "to", "produce"], "add_tokens": "if ( params . partition !== undefined ) { return ( ( _producePartition ++ ) % _topics [ _makeTopicKey ( params ) ] . topics [ params . topic ] . partitions . length ) ;", "del_tokens": "if ( params . partition !== 0 ) { return ( ( ++ _producePartition ) % _topics [ _makeTopicKey ( params ) ] . topics [ params . topic ] . partitions . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "where", "launch", "cmd", "was", "not", "sent", "to", "controller", "if", "controller", "sent", "empty", "name"], "add_tokens": "this . showPlaceInQueue = true ; var newName = msg . name . replace ( / [<>] / g , '' ) ; if ( ! newName ) { this . playerName = newName ; this . showPlaceInQueue = true ; g_updateStatus = true ; this . showPlaceInQueue = false ;", "del_tokens": "this . showPlaceInQueue = false ; if ( ! msg . name ) { this . showPlaceInQueue = true ; this . playerName = msg . name . replace ( / [<>] / g , '' ) ; g_updateStatus = true ; this . showPlaceInQueue = true ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "fragments", "support", "for", "DZSlides", "backend"], "add_tokens": "return page . evaluate ( function ( ) { var count = 0 ; for ( var i = 0 ; i < Dz . slides . length ; i ++ ) { var fragments = Dz . slides [ i ] . $$ ( '.incremental > *' ) . length ; count += fragments ? fragments + 1 : 1 ; } return count ; } ) ; return page . evaluate ( function ( ) { return Dz . idx == Dz . slides . length && Dz . step == Dz . slides [ Dz . idx - 1 ] . $$ ( '.incremental > *' ) . length ; } ) ; return page . evaluate ( function ( ) { return Dz . idx + \".\" + Dz . step ; } ) ;", "del_tokens": "return page . evaluate ( function ( ) { return Dz . slides . length ; } ) ; return page . evaluate ( function ( ) { return Dz . idx == Dz . slides . length ; } ) ; return page . evaluate ( function ( ) { return Dz . idx ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "customization", "of", "output", "filename"], "add_tokens": "var path = require ( 'path' ) module . exports = function ( outputName , config ) { // default the args var outputName = 'atomic.css' atomicFile . path = path . join ( latestFile . base , outputName )", "del_tokens": "module . exports = function ( config ) { // default the config to an empty object", "commit_type": "allow"}
{"commit_tokens": ["uses", "nock", "to", "record", "all", "HTTP", "interactions", ".", "need", "to", "cleanup", "record", ".", "js", "a", "bit", "."], "add_tokens": "NS1 = require ( '../lib' ) , record = require ( './record' ) ( 'rest_resource' ) before ( function ( ) { record . before ( ) this . timeout ( 10000 ) } ) after ( record . after )", "del_tokens": "NS1 = require ( '../lib' )", "commit_type": "use"}
{"commit_tokens": ["use", "number", "for", "file", "key"], "add_tokens": "'I$(%s,%s);' , 'I$(%s,%s);' , 'I$(%s,%s);' , _list . push ( _doGenFileKey ( _deps [ i ] ) ) ; _argc . push ( 'I$(' + _doGenFileKey ( _deps [ i ] ) + ')' ) ; 'I$(%s,%s);' ,", "del_tokens": "'I$(\"%s\",%s);' , 'I$(\"%s\",%s);' , 'I$(\"%s\",%s);' , _list . push ( '\"' + _doGenFileKey ( _deps [ i ] ) + '\"' ) ; _argc . push ( 'I$(\"' + _doGenFileKey ( _deps [ i ] ) + '\")' ) ; 'I$(\"%s\",%s);' ,", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "use", "standardized", "axis", "ticks", "/", "labels", "names", "."], "add_tokens": "datum . ticks ? index ++ : - 1 , // ticks index datum . labels ? index ++ : - 1 , // labels index index + ( + datum . domain ) // title index", "del_tokens": "datum . tick ? index ++ : - 1 , // tick index datum . label ? index ++ : - 1 , // label index index + ( + datum . domain ) // title index", "commit_type": "update"}
{"commit_tokens": ["fixing", "@import", "fixing", "braces", "inside", "@media"], "add_tokens": "skipCharset = false , // CSS 2.1 / 4.1.5 At-rules skipImport = false , // CSS 2.1 / 4.1.5 At-rules function pushOneLineAtrule ( node , r ) { if ( ! node . content . length && ! node . nodes . length ) { r . push ( { type : 'atrule' , value : node . value . slice ( ) , content : [ ] , nodes : [ ] } ) ; } } skipCharset = skipImport = true ; if ( ! skipCharset ) { pushOneLineAtrule ( node , r ) ; case ' import ' if ( ! skipImport ) { pushOneLineAtrule ( node , r ) ; } skipCharset = true ; break ; case 'namespace' : pushOneLineAtrule ( node , r ) ; skipCharset = skipImport = true ; break ; skipCharset = skipImport = true ;", "del_tokens": "skipCharset = false , skipCharset = true ; if ( ! skipCharset ) skipCharset = true ; else break ; case ' import ' case 'namespace' : if ( ! node . content . length && ! node . nodes . length ) { r . push ( { type : 'atrule' , value : node . value . slice ( ) , content : [ ] , nodes : [ ] } ) ; skipCharset = true ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "to", "output", "private", "functions"], "add_tokens": "private : true ,", "del_tokens": "private : false ,", "commit_type": "change"}
{"commit_tokens": ["Add", "reboot", "/", "reset", "CLI", "commands"], "add_tokens": "const discover = function ( args ) { UFO . discover ( args , function ( err , data ) { if ( err ) quitError ( err ) ; else console . log ( JSON . stringify ( data , null , 2 ) ) ; } ) ; } cli . command ( 'reboot' ) . description ( 'Reboots the UFO.' ) . action ( function ( ) { go ( function ( ) { this . reboot ( ) ; } ) ; } ) ; cli . command ( 'factory-reset' ) . description ( 'Resets the UFO to factory settings. No confirmation prompt will occur; USE CAUTION.' ) . action ( function ( ) { go ( function ( ) { this . factoryReset ( ) ; } ) ;", "del_tokens": "const discover = function ( args ) { UFO . discover ( args , function ( err , data ) { if ( err ) quitError ( err ) ; else console . log ( JSON . stringify ( data , null , 2 ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "malformed", "Response", "object", "."], "add_tokens": "\"status\" : statusCode || ghostdriver . ResponseStatusCodes . SUCCESS ,", "del_tokens": "\"statusCode\" : statusCode || ghostdriver . ResponseStatusCodes . SUCCESS ,", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "of", "test", ".", "case", "and", "test", ".", "suite", "test", "information", "objects", "."], "add_tokens": "vars : _vars , test : { case : { name : tc . name , iteration : tcit } , suite : { name : ts . name , iteration : tsit } }", "del_tokens": "vars : _vars", "commit_type": "add"}
{"commit_tokens": ["Change", "sample", "frontend", "fonts", "and", "adapt", "wording"], "add_tokens": "connection pushes every new event in realtime . Try opening this app in a new window and change something there !", "del_tokens": "connection pushes every new event . Try opening this app in a new window and change something there !", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "_clone", "suffix", "to", "id", "attributes", "in", "clones"], "add_tokens": "} , uniqueID : function ( $clone ) { $clone . find ( '[id]' ) . each ( function ( ) { var $this = $ ( this ) ; $this . attr ( 'id' , $this . attr ( 'id' ) + '_clone' ) ; } ) ; return $clone ; } methods . uniqueID ( slider . slides . first ( ) . clone ( ) . addClass ( 'clone' ) ) . appendTo ( slider . container ) ; methods . uniqueID ( slider . slides . last ( ) . clone ( ) . addClass ( 'clone' ) ) . prependTo ( slider . container ) ;", "del_tokens": "} slider . container . append ( slider . slides . first ( ) . clone ( ) . addClass ( 'clone' ) ) . prepend ( slider . slides . last ( ) . clone ( ) . addClass ( 'clone' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "ignore", "tests", "and", "regex", "catch", "hidden", "files", "without", "dir"], "add_tokens": "if ( opts . ignoreHidden !== false ) defaultOpts . ignore . push ( / ^[\\.|.*\\/\\.] / )", "del_tokens": "if ( opts . ignoreHidden !== false ) defaultOpts . ignore . push ( / [\\/\\\\]\\. / )", "commit_type": "add"}
{"commit_tokens": ["Added", "slow", "test", "indicator", "to", "the", "console", "reporter"], "add_tokens": "var data = [ ] ; // Add duration to the test string if the test is slow. if ( test . speed !== 'fast' ) { data . push ( test . speed === 'medium' ? String ( '(' + toSeconds ( test . duration ) + ')' ) . yellow : String ( '(' + toSeconds ( test . duration ) + ')' ) . red ) ; } console . log ( data . join ( ' ' ) ) ;", "del_tokens": "console . log ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "body", "for", "main", "file"], "add_tokens": "denorm . onEventMissing ( function ( info , evt ) { // info.aggregateId // info.aggregate // info.context // info.aggregateRevision // info.eventRevision // request the appropriate missing events from domain... } ) ; // to replay denorm . replay ( [ /* array of ordered events */ ] , function ( err ) { } ) ; // to replay streamed denorm . replayStreamed ( function ( replay , done ) { replay ( evt1 ) ; replay ( evt2 ) ; replay ( evt3 ) ; done ( function ( err ) { } ) ; } ) ;", "del_tokens": "// denorm.on('eventMissing', function (id, aggregateRevision, eventRevision, evt) { // // request the appropriate missing events from domain... // }), // or ??? TBD!!! // denorm.onEventMissing(function (id, aggregateRevision, eventRevision, evt) { // // request the appropriate missing events from domain... // }), // // to replay // denorm.replay([] /* array of ordered events */, function(err) {}); // // to replay streamed // denorm.replayStreamed(function(replay, done) { // replay(evt1); // replay(evt2); // replay(evt3); // done(function(err) { }); // });", "commit_type": "add"}
{"commit_tokens": ["add", "rule", "no", "-", "single", "-", "chain"], "add_tokens": "'matches-prop-shorthand' : require ( './lib/rules/matches-prop-shorthand' ) , 'no-single-chain' : require ( './lib/rules/no-single-chain' ) 'matches-prop-shorthand' : 0 , 'no-single-chain' : 0", "del_tokens": "'matches-prop-shorthand' : require ( './lib/rules/matches-prop-shorthand' ) 'matches-prop-shorthand' : 0", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "appRoot", "param", "optional"], "add_tokens": "var path = require ( \"path\" ) ; exports . nails = ( appRoot = path . dirname ( require . main . filename ) ) => {", "del_tokens": "exports . nails = appRoot => {", "commit_type": "make"}
{"commit_tokens": ["Fixed", ".", "/", "gulpfile", ".", "js"], "add_tokens": "const shevchenko = require ( './dist/cjs/shevchenko' ) ;", "del_tokens": "const shevchenko = require ( './dist/cjs/main' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "redux", "example", "increment", "value"], "add_tokens": "return state + 1 ;", "del_tokens": "return state + 5 ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "test", "for", "loading", "through", "index", ".", "js"], "add_tokens": "it ( 'should load code from local path' , function ( done ) { it ( 'should load from absolute path' , function ( done ) { it ( 'should load from index in path' , function ( done ) { let p = require . resolve ( './fixtures/foo.js' ) expect ( path . isAbsolute ( p ) ) . to . be . true live . require ( './fixtures/bloom' , function ( exports ) { expect ( exports . name ) . to . equal ( 'Bloom' ) done ( ) } ) } )", "del_tokens": "it ( 'should evaluate code from local path' , function ( done ) { it ( 'should #eval from absolute path' , function ( done ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "missing", "QUnit", ".", "reset", "()", "."], "add_tokens": "QUnit . reset ( ) ;", "del_tokens": "reset ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "in", "test", "case"], "add_tokens": "check_json : function ( test ) {", "del_tokens": "check_son : function ( test ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "empty", "message", "content", "handling"], "add_tokens": "if ( value !== undefined && typeof value !== \"object\" /* 1 */ ) { if ( value === undefined ) { if ( value !== undefined ) {", "del_tokens": "if ( value && typeof value !== \"object\" /* 1 */ ) { if ( ! value ) { if ( value ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "Content", "-", "Length", "and", "Unicode"], "add_tokens": "var version = '0.9.11' ; else if ( isString ( config . data ) ) opts . headers [ 'content-length' ] = Buffer . byteLength ( config . data ) ;", "del_tokens": "var version = '0.9.10' ; else if ( isString ( config . data ) ) opts . headers [ 'content-length' ] = config . data . length ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "callback", "and", "type", "rules", "for", "change_password", "action"], "add_tokens": "user : { type$ : [ 'object' , 'string' ] } , return ( null , { ok : true } )", "del_tokens": "user : { object$ : true } , return { ok : true }", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "test", "reliablity", "for", "DownloadArtifactsTfsGit", "(", "4", ")"], "add_tokens": "tl . error ( 'OperationFailed: ' + operationName )", "del_tokens": "tl . error ( 'OperationFailed' + operationName )", "commit_type": "fix"}
{"commit_tokens": ["add", "AMD", "compat", ";", "export", "in", "Node", ".", "js", "as", "a", "function", "instead", "of", "object"], "add_tokens": "function simplify ( points , tolerance , highestQuality ) { // export either as a Node.js module, AMD module or a global browser variable if ( typeof exports === 'object' ) { module . exports = simplify ; } else if ( typeof define === 'function' && define . amd ) { define ( function ( ) { return simplify ; } ) ; } else { global . simplify = simplify ; } } ( this ) ) ;", "del_tokens": "var root = ( typeof exports !== undefined + '' ) ? exports : global ; root . simplify = function ( points , tolerance , highestQuality ) { } ( this ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "nodegit", "dependencies", "and", "instead", "use", "simple", "-", "git"], "add_tokens": "const simpleGit = require ( 'simple-git' ) const cloneRepo = ( owner , repo , targetDir ) => new Promise ( resolve => { return simpleGit ( ) . clone ( ` ${ owner } ${ repo } ` , targetDir , ( ) => { resolve ( ) } ) } )", "del_tokens": "const nodegit = require ( 'nodegit' ) const cloneRepo = ( owner , repo , targetDir ) => { return nodegit . Clone ( ` ${ owner } ${ repo } ` , targetDir , { checkoutBranch : 'master' } ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "secure", "field", "to", "ConnectToServerOptions", "interface"], "add_tokens": "name : null , secure : false", "del_tokens": "name : null", "commit_type": "add"}
{"commit_tokens": ["create", "an", "empty", "Combinator", "if", "none", "was", "specified", ".", "Refactored", "Combinator", "generation", "and", "added", "+", "~", "::"], "add_tokens": "return this . combinator . toCSS ( ) + this . value ; this . value = value ? value . trim ( ) : \"\" ; case ' : : ': return ' : : ' case ' + ': return ' + ' case ' ~ ': return ' ~ '", "del_tokens": "var css = ( this . combinator ? this . combinator . toCSS ( ) : ' ' ) + this . value ; return css ; this . value = value . trim ( ) ;", "commit_type": "create"}
{"commit_tokens": ["Updated", "to", "reflect", "repo", "rename", "."], "add_tokens": "const PLUGIN_NAME = 'amphtml-autoscript' ;", "del_tokens": "const PLUGIN_NAME = 'amphtml-import-tags' ;", "commit_type": "update"}
{"commit_tokens": ["made", "EntitySet", "more", "reliant", "on", "Storage", "-", "no", "longer"], "add_tokens": "// current index of component defs // a map of schema ids to componentDef objects // an array of component def ids to componentDef objects // we use an entityset to keep track of entities and components this . entitySet = odgn . entity . EntitySet . create ( this . memoryStorage , this , options ) ; var self = this ; options = options || { } ; var storage = this . memoryStorage ; var result = odgn . entity . EntitySet . create ( storage , this , options ) ; var componentDefs = this . toComponentDefs ( components ) ; result . _componentDefIds = _ . map ( componentDefs , function ( componentDef ) { log . debug ( 'mapped in ' + componentDef . defId + ' for ' + componentDef . schema . id ) ; return componentDef . defId ; } ) ; return result . reload ( function ( err ) { self . trigger ( 'entity_set:create' , result ) ; // return this.getEntitiesWithComponents( components, options, function(err, entityArray, componentDefs){ // result.setComponentDefs( componentDefs ); // result.setEntities( entityArray ); // self.trigger('entity_set:create', result); // return callback(null, result); // });", "del_tokens": "// we use an entityset to keep track of entities and components this . entitySet = odgn . entity . EntitySet . create ( this , options ) ; // log.debug('adding component ' + component + ' to entity ' + entity.id ); var result = odgn . entity . EntitySet . create ( this , options ) ; return this . getEntitiesWithComponents ( components , options , function ( err , entityArray , componentDefs ) { result . setComponentDefs ( componentDefs ) ; result . setEntities ( entityArray ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "readDir", "instead", "of", "getDirElement", "to", "ensure", "dir", "is", "watched", "."], "add_tokens": "const res = files . readDir ( 'core' ) ; Object . assign ( elementById , res . elementById ) ; children : res . elements ,", "del_tokens": "const dirEle = files . getDirElement ( 'core' , elementById ) ; children : dirEle . children , elementById [ 'core' ] = dirEle ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "issues", "with", "default", "service"], "add_tokens": "throw new Error ( 'Circular reference since ' + modulePath + ' is in ' + JSON . stringify ( moduleStack ) ) ;", "del_tokens": "throw new Error ( 'Circular reference: ' + JSON . stringify ( moduleStack ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "flush", "block", "in", "deflate_slow", "&", "enable", "windowBits", "test"], "add_tokens": "/*** FLUSH_BLOCK_ONLY(s, 0) ***/", "del_tokens": "/*** FLUSH_BLOCK(s, 0); ***/ if ( s . strm . avail_out === 0 ) { return BS_NEED_MORE ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "custom", "Chrome", "launcher", "for", "Travis", "CI"], "add_tokens": "var configuration = { browsers : [ 'Chrome' ] , customLaunchers : { Chrome_travis_ci : { base : 'Chrome' , flags : [ '--no-sandbox' ] } } } if ( process . env . TRAVIS ) { configuration . browsers = [ 'Chrome_travis_ci' ] ; } config . set ( configuration ) ;", "del_tokens": "config . set ( { browsers : [ 'Chrome' ] } )", "commit_type": "add"}
{"commit_tokens": ["move", "exports", "to", "the", "top"], "add_tokens": "/ ** * Module dependencies . * / / ** * Module exports . * / module . exports = Struct", "del_tokens": "module . exports = Struct", "commit_type": "move"}
{"commit_tokens": ["Remove", "useless", "defaults", "in", "the", "REPL"], "add_tokens": ". option ( '-h, --host <host>' , 'Remote Debugging Protocol host' ) . option ( '-p, --port <port>' , 'Remote Debugging Protocol port' )", "del_tokens": "var defaults = require ( '../lib/defaults.js' ) ; . option ( '-h, --host <host>' , 'Remote Debugging Protocol host' , defaults . HOST ) . option ( '-p, --port <port>' , 'Remote Debugging Protocol port' , defaults . PORT )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "comparison", "file", "requirement", "."], "add_tokens": "throw new Error ( \"A comparison file must be specified\" ) } if ( args [ 4 ] === undefined ) { config . comparisonFile = args [ 3 ] ; config . outputFile = args [ 4 ] ;", "del_tokens": "config . outputFile = args [ 3 ] ;", "commit_type": "add"}
{"commit_tokens": ["Add", "step", "to", "cd", "to", "release", "zip", "dir", "in", "installation", "doc"], "add_tokens": "\"this script via 'npm run \" + path . basename ( __filename , '.js' ) + \"'.\" )", "del_tokens": "\"this script via 'npm run dist'.\" )", "commit_type": "add"}
{"commit_tokens": ["Use", "single", "-", "quote", "for", "tileurl", "and", "tab", "like", "Leaflet", "codebase"], "add_tokens": "var tileLayerCode = 'var ' + layerName + ' = L.tileLayer(\\'' + layer . _url + '\\', {\\n' ; tileLayerCode += '\\t' + option + ': ' ;", "del_tokens": "var tileLayerCode = 'var ' + layerName + ' = L.tileLayer(\"' + layer . _url + '\", {\\n' ; tileLayerCode += ' ' + option + ': ' ;", "commit_type": "use"}
{"commit_tokens": ["Add", "API", "methods", "for", "manipulating", "directories"], "add_tokens": "//api.supportedLanguages(handleTestResult); //api.uploadGlossary(config.project_identifier, fs.createReadStream('cordova.tbx')); //api.createDirectory(config.project_identifier, 'test', handleTestResult); //api.deleteDirectory(config.project_identifier, 'test', handleTestResult); //api.changeDirectory(config.project_identifier, 'test', { new_name: 'test1', title: 'Test directory', export_pattern: '%original_path%/%two_letters_code%' }, handleTestResult); //api.changeDirectory(config.project_identifier, 'test1', { new_name: 'test', title: '', export_pattern: 'test' }, handleTestResult);", "del_tokens": "/*api.supportedLanguages();*/ api . uploadGlossary ( config . project_identifier , fs . createReadStream ( 'cordova.tbx' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "recent", "examples", "to", "spion", "benchmark"], "add_tokens": "fileId = iFileId ;", "del_tokens": "fileId = iFileId ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "compiler", "issues", "on", "exposing", "computed", "properties", "adopting", "more", "tests"], "add_tokens": "get : computedFn ,", "del_tokens": "get ( ) { return computedFn . call ( this ) ; } ,", "commit_type": "fix"}
{"commit_tokens": ["makes", "it", "so", "connected", "events", "get", "called", "immediately"], "add_tokens": "// this makes it so `connected` events will be called immediately domMutate . flushRecords ( ) ;", "del_tokens": "//domMutate.flushRecords();", "commit_type": "make"}
{"commit_tokens": ["Fix", "error", "for", "FireFox", "3"], "add_tokens": "* history API JavaScript Library v2 .0 .4 * Update : 06 - 04 - 2012 // simlink for browser supported History API - ( not recommended use ) History . location = Location ; o . type = \"popstate\" ;", "del_tokens": "* history API JavaScript Library v2 .0 .3 * Update : 29 - 03 - 2012 o . type = \"popstate\" ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "onProgress", "()", "handler", "support", "."], "add_tokens": "if ( s3ClientOpts . onProgress ) { s3ClientOpts . onProgress ( progressInfo ) ; } else { receiver . emit ( 'progress' , progressInfo ) ; //  for backwards compatibility }", "del_tokens": "receiver . emit ( 'progress' , progressInfo ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "save", ":", "false", "not", "working"], "add_tokens": "if ( options . save === undefined ) { options . save = makeDefault ( 'save' ) ; } } ;", "del_tokens": "if ( ! options . save ) { options . save = makeDefault ( 'save' ) ; } } ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "NPE", "when", "using", "enabled", ":", "false", "for", "items", "in", "pages"], "add_tokens": "removeDisabledItems ( page ) ; const page = deepClone ( artifactsByRef . pages [ pageRef ] ) ; removeDisabledItems ( page ) ; return page ; //validate: validators.features.pages[ page.name ], compositions : [ ]", "del_tokens": "return deepClone ( artifactsByRef . pages [ pageRef ] ) ; removeDisabledItems ( page ) ; compositions : [ ] , //validate: validators.features.pages[ page.name ]", "commit_type": "fix"}
{"commit_tokens": ["made", "the", "code", "a", "little", "prettier", "added", "some", "documentation"], "add_tokens": "// Dynamically import a config file if exist // search from the root of the process if the user didnt specify a config file, // or use the custom path if a file is passed. const { config } = explorer . load ( return config || { } return { }", "del_tokens": "// Dynamically import the config file if exist let config // Check if exist the default directory of configuration const { config : _config } = explorer . load ( config = _config return config || { }", "commit_type": "make"}
{"commit_tokens": ["updated", "examples", "nav", "included", "file", "-", "ext", "source"], "add_tokens": "// Make sure all files within the input have one of the defined mimetypes // Make sure all files within the input have one of the defined extensions window . Parsley . addValidator ( 'fileExt' , { requirementType : 'string' , validateString : function ( value , extensions , parsleyFieldInstance ) { var allExts = utils . parseArrayStringParameter ( extensions ) ; var files = parsleyFieldInstance . $element [ 0 ] . files ; // If a file is present in the input if ( files . length > 0 ) { // Loop over the files for ( var i = 0 ; i < files . length ; i ++ ) { var explodeNames = files [ i ] . name . split ( '.' ) ; if ( allExts . indexOf ( explodeNames [ explodeNames . length - 1 ] ) == - 1 ) { return false ; } } } return true ; } , messages : { en : 'This file does not have the correct extensions.' } } ) ; // Make sure all images within the input have specific dimensions", "del_tokens": "// Make sure all files within the input are an image // Make sure all images withing the input have specific dimensions", "commit_type": "update"}
{"commit_tokens": ["create", "/", "delete", ".", "git", "repository", "in", "fixtures", "for", "tests"], "add_tokens": "var del = require ( 'delete' ) ; var git = path . resolve ( project , '.git' ) ; before ( function ( cb ) { del ( git , function ( err ) { if ( err ) return cb ( err ) ; repo = gitty ( project ) ; repo . initSync ( ) ; repo . addSync ( [ '.' ] ) ; repo . commitSync ( 'first commit' ) ; cb ( ) ; } ) ; del ( git , cb ) ;", "del_tokens": "before ( function ( ) { repo = gitty ( project ) ; repo . initSync ( ) ; repo . addSync ( [ '.' ] ) ; repo . commitSync ( 'first commit' ) ; del ( project + './git' , cb ) ;", "commit_type": "create"}
{"commit_tokens": ["Use", "the", "AssetLoader", "to", "load", "fonts", "and", "OBJs"], "add_tokens": "this . _assetLoader = AssetLoader . Singleton", "del_tokens": "this . _assetLoader = new AssetLoader ( )", "commit_type": "use"}
{"commit_tokens": ["Add", "feature", "to", "create", "and", "use", "firefox", "profiles"], "add_tokens": "var xtend = require ( 'xtend' ) ; return avail . slice ( - 1 ) . map ( addProfile ) ; return avail . slice ( 0 , 1 ) . map ( addProfile ) ; return [ start ] . map ( addProfile ) ; } ) . map ( addProfile ) ; } ) . map ( addProfile ) ; function addProfile ( browser ) { if ( req . firefox_profile ) { return xtend ( browser , { firefox_profile : req . firefox_profile } ) ; } else { return browser ; } }", "del_tokens": "return avail . slice ( - 1 ) ; return avail . slice ( 0 , 1 ) ; return [ start ] ; } ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "animation", "events", "and", "examples"], "add_tokens": "defaultStyles = { } , animHistory animHistory = { fxObj [ this . uuid ( ) ] = animHistory this . fire ( 'animpush' , animHistory ) this . fire ( 'animpop' , fx )", "del_tokens": "defaultStyles = { } fxObj [ this . uuid ( ) ] = {", "commit_type": "add"}
{"commit_tokens": ["Add", "relay", "node", "/", "resolve", "support"], "add_tokens": "var isPlainObject = require ( 'lodash/lang/isPlainObject' ) ; function buildObject ( obj ) { var fields = [ ] , key ; for ( key in obj ) { fields . push ( b . property ( 'init' , b . literal ( key ) , castValue ( obj [ key ] ) ) ) ; } function castValue ( val ) { if ( isPlainObject ( val ) ) { return buildObject ( val ) ; } else if ( val === null ) { return b . identifier ( 'null' ) ; } else if ( typeof val === 'undefined' ) { return b . identifier ( 'undefined' ) ; } return b . literal ( val ) ; } module . exports = buildObject ;", "del_tokens": "module . exports = function buildObject ( obj ) { var fields = [ ] ; for ( var key in obj ) { fields . push ( b . property ( 'init' , b . literal ( key ) , b . literal ( obj [ key ] ) ) ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "selfhosting", "OWIN", "server", "for", "examples", "+", "cleanup"], "add_tokens": "templateUrl : 'js/gnap/sidebar.html' , templateUrl : 'js/gnap/breadcrumbs.html' , templateUrl : 'js/gnap/search.html' ,", "del_tokens": "templateUrl : 'gnap/sidebar.html' , templateUrl : 'gnap/breadcrumbs.html' , templateUrl : 'gnap/search.html' ,", "commit_type": "add"}
{"commit_tokens": ["add", "domain", ".", "exit", "()", "and", "dispoe", "()"], "add_tokens": "var nodeDomain = require ( 'domain' ) ; * var domain = nodeDomain . create ( ) ; domain . once ( 'error' , cb ) ; domain . run ( function ( ) { cb ( err , path , document , domain ) ; function ( path , document , domain , cb ) { // Clean domain domain . exit ( ) ; domain . dispose ( ) ;", "del_tokens": "var domain = require ( 'domain' ) ; * var d = domain . create ( ) ; d . once ( 'error' , cb ) ; d . run ( function ( ) { cb ( err , path , document ) ; function ( path , document , cb ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "neverending", "for", "last", "slide"], "add_tokens": "$ ( \".slider .slide[data-index='\" + prevSlide + \"'] .slidecontent\" ) . fadeOut ( ) ; $ ( \".slider .slide[data-index='\" + newSlide + \"'] .slidecontent\" ) . hide ( ) ;", "del_tokens": "$ ( \".slider .slide[data-index='\" + prevSlide + \"'] .slidecontent\" ) . fadeOut ( ) ; $ ( \".slider .slide[data-index='\" + newSlide + \"'] .slidecontent\" ) . hide ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "convenience", "functions", "for", "FileRecvControlEvent", "updated", "file", "transfer", "example"], "add_tokens": "e . controlName ( ) ) ; if ( e . isCancel ( ) ) { tox . controlFileSync ( e . friend ( ) , e . file ( ) , 'resume' ) ; tox . controlFileSync ( e . friend ( ) , e . file ( ) , 'cancel' ) ; tox . controlFileSync ( e . friend ( ) , e . file ( ) , 'cancel' ) ;", "del_tokens": "var getControlName = function ( control ) { if ( control === RESUME ) { return 'RESUME' ; } else if ( control === PAUSE ) { return 'PAUSE' ; } else if ( control === CANCEL ) { return 'CANCEL' ; } else { return 'UNKNOWN (' + control + ')' ; } } ; getControlName ( e . control ( ) ) ) ; if ( e . control ( ) === CANCEL ) { tox . controlFileSync ( e . friend ( ) , e . file ( ) , RESUME ) ; tox . controlFileSync ( e . friend ( ) , e . file ( ) , CANCEL ) ; tox . controlFileSync ( e . friend ( ) , e . file ( ) , CANCEL ) ;", "commit_type": "add"}
{"commit_tokens": ["Improving", "self", "tests", ".", "Inner", "docs", "corrections", "."], "add_tokens": "gT . a . equal ( gIn . config . dummyExpectedRootDirConfigOption , 'dummyExpectedRootDirConfigOption' , 'Root dir config check' ) ; gT . a . equal ( gT . suiteConfig . dummyGoodSuitConfigOption , 'dummyGoodSuitConfigOption' , 'Suite config Expected value check' ) ;", "del_tokens": "gT . a . equal ( gT . suiteConfig . dummyGoodSuitConfigOption , 'dummyGoodSuitConfigOption' , 'Suite config Expected value check' ) ; // t.checkTrue(typeof gT !== 'undefined', 'gT exists'); // t.checkTrue('config' in gT, 'gIn.config exists'); // t.checkTrue('tInfo' in gT, 'gIn.tInfo exists'); // t.checkTrue('data' in gIn.tInfo, 'gIn.tInfo.data exists');", "commit_type": "improve"}
{"commit_tokens": ["Moved", "qunit", "after", "lint", "in", "grunt", "default", "task", "."], "add_tokens": "grunt . registerTask ( 'default' , 'lint:grunt lint:tests concat lint:dist qunit min' ) ;", "del_tokens": "grunt . registerTask ( 'default' , 'lint:grunt lint:tests qunit concat lint:dist min' ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "GIT", "commands", "execution", "under", "Windows", "OS"], "add_tokens": "var updatingVersionMessage = 'Updating to a version to ' ; \"vcTagCmd\" : \"git tag -a v${version} -m \\\"Tagging the ${version} release\\\"\" execSync ( ` ${ updatingVersionMessage } ${ targetVersion } ` ) ; }", "del_tokens": "var updatingVersionMessage = 'Updating to a version ' ; // \"changesCmd\": \"printf ''\" execSync ( 'git commit -m \\'' + updatingVersionMessage + targetVersion + '\\'' ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ipmi", "-", "job", "test", "config", "post", "-", "concurrency", "limitations", "per", "machine"], "add_tokens": "var config = { host : '10.1.1.' , user : 'admin' , password : 'admin' , workItemId : 'testworkitemid' } ; _ . forEach ( _ . range ( 100 ) , function ( i ) { var _config = _ . cloneDeep ( config ) ; _config . host += i ; self . ipmi . emit ( 'test-subscribe-ipmi-sdr-command' , _config ) ;", "del_tokens": "_ . forEach ( _ . range ( 100 ) , function ( ) { self . ipmi . emit ( 'test-subscribe-ipmi-sdr-command' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "interpolate", "doc", "comments", "for", "accuracy"], "add_tokens": "* returns an HtmlSnippet object whose . toString ( ) method returns : * Since escaping is done by default , this is safe to use for rendering untrusted * input within html . For example : * * ~ ~ ~ javascript * HtmlUtils . interpolateHtml ( * 'User said {emStart}{comment}{emEnd}' , * { * emStart : HtmlUtils . HTML ( '<em>' ) , * comment : '<script>alert(\"test\");</script>' , * emEnd : HtmlUtils . HTML ( '</em>' ) , * } * ) ; * ~ ~ ~ * * returns an HtmlSnippet object whose . toString ( ) method returns : * * ~ ~ ~ javascript * 'User said <em>&lt;script&gt;alert(&quot;test&quot;);&lt;/script&gt;</em>' * ~ ~ ~ *", "del_tokens": "* returns :", "commit_type": "update"}
{"commit_tokens": ["removed", "need", "to", "pass", "in", "config", "into", "function"], "add_tokens": "var checkConfiguration = function ( msg , node , cb ) { //taSettings.tones = msg.tones || config.tones; //taSettings.sentences = msg.sentences || config.sentences; //taSettings.contentType = msg.contentType || config.contentType checkConfiguration ( msg , node , function ( err , settings ) { var tones = msg . tones || config . tones ; var sentences = msg . sentences || config . sentences ; var contentType = msg . contentType || config . contentType 'sentences' : sentences , // settings.sentences, 'isHTML' : contentType // settings.contentType if ( tones !== 'all' ) { options . tones = tones ;", "del_tokens": "var checkConfiguration = function ( msg , config , node , cb ) { taSettings . tones = msg . tones || config . tones ; taSettings . sentences = msg . sentences || config . sentences ; taSettings . contentType = msg . contentType || config . contentType checkConfiguration ( msg , config , node , function ( err , settings ) { 'sentences' : settings . sentences , 'isHTML' : settings . contentType if ( settings . tones !== 'all' ) { options . tones = settings . tones ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "first", "param", "validation", "test"], "add_tokens": "return pequire ( '../lib/index' , _ . assign ( { } , HAPPY_PROXY_DEPS , proxyDeps ) ) ;", "del_tokens": "return pequire ( '../lib/index' , _ . assign ( { } , HAPPY_PROXY_DEPS , proxyDeps ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "DEEZER_APP_ID", "and", "DEEZER_CHANNEL_URL", "constants", "for", "integration", "back", "in", "whyd"], "add_tokens": "// WARNING: // The following global constants must be set before instantiation: // DEEZER_APP_ID and DEEZER_CHANNEL_URL appId : DEEZER_APP_ID , channelUrl : DEEZER_CHANNEL_URL ,", "del_tokens": "// WARNING: this player needs to provide a channel file => not working on localhost // PARAMETERS var p = p || { } ; var APP_ID = p . appId ; var CHANNEL_URL = p . channelUrl ; appId : APP_ID , channelUrl : CHANNEL_URL ,", "commit_type": "add"}
{"commit_tokens": ["changing", "host", "for", "test", "-", "saucelabs", "script"], "add_tokens": "var url = 'http://canjs.test:3000/test.html?hidepassed' ;", "del_tokens": "var url = 'http://localhost:3000/test.html?hidepassed' ;", "commit_type": "change"}
{"commit_tokens": ["fixing", "connection", "bugs", "and", "clearing", "out", "base", "connection", "class", "to", "support", "TCP", "and", "UDP"], "add_tokens": "/ ** * Perform general validation before accepting and handling a message * / Connection . onBeforeMessage = function ( ) { return false ; return true ; } ; Connection . onMessage = function ( message ) { // This method should be implemented in extending classes return ;", "del_tokens": "Connection . onMessage = function ( message ) { // Alert the client that the server is paused return ; } // Accept message var payload ; if ( message . type === 'utf8' ) { try { payload = JSON . parse ( message . utf8Data ) ; } catch ( ex ) { // Unable to parse data this . send ( messages . invalidData ) ; return ; } else if ( message . type === 'binary' ) { // Convert from binary back to object try { if ( Buffer . isBuffer ( message . binaryData ) ) { payload = JSON . parse ( message . binaryData . toString ( 'utf8' ) ) ; } else { // Something has gone horribly wrong... this . send ( messages . malformedData ) ; return ; } } catch ( ex ) { // Unable to parse data this . send ( messages . invalidData ) ; return ; } } // Call the appropriate handler this . fire ( payload . type , payload . data ) ;", "commit_type": "fix"}
{"commit_tokens": ["move", "suspendUntil", "in", "dom", "and", "string", "output"], "add_tokens": "suspendUntil : function ( xpr ) { return this . exec ( 'suspendUntil' , [ interpolable ( xpr ) , this . _queue . length + 1 , this ] , false , true ) ;", "del_tokens": "suspendUntil : function ( xpr , handler ) { var xpr = interpolable ( xpr ) , index = this . _queue . length + 1 , self = this ; return this . exec ( { suspendAfter : true , dom : function ( context , container ) { var val = xpr . __interpolable__ ? xpr . output ( context ) : xpr , rest , instance ; var exec = function ( type , path , value ) { if ( value ) { instance . destroy ( ) ; rest . call ( container , context ) ; } } ; if ( val ) exec ( 'set' , null , val ) ; else if ( xpr . __interpolable__ ) { rest = new Template ( self . _queue . slice ( index ) ) ; instance = xpr . subscribeTo ( context , exec ) ; } } } ) ;", "commit_type": "move"}
{"commit_tokens": ["Using", "html", "-", "webpack", "-", "plugin", "chunk", "sorter", "to", "correctly", "sort", "assets", "+", "tests", "to", "prove", "it"], "add_tokens": "{ id : 1 , entry : false , parents : [ '3' ] , name : 'test1' , files : [ 'test1.js' ] } , { id : 2 , entry : false , parents : [ '3' ] , name : 'test2' , files : [ 'test2.js' ] } , { id : 3 , entry : true , name : 'test3' , files : [ 'test3.js' ] } console . log ( json ) ; { entry : true , name : 'test' , files : [ 'test.js' ] }", "del_tokens": "{ entry : false } , { entry : false } , { entry : true } { entry : true }", "commit_type": "use"}
{"commit_tokens": ["Changing", "jeff", "to", "jeff", "-", "core"], "add_tokens": "var jeff = require ( 'jeff-core' ) ;", "del_tokens": "var jeff = require ( 'jeff' ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "negative", "decimals", "less", "than", "-", "10", "don", "t", "work"], "add_tokens": "var match = / ^((?:\\d+)?-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$ / i . exec (", "del_tokens": "var match = / ^((?:\\d+)?\\-?\\d?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$ / i . exec (", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "input", "map", "paths", "."], "add_tokens": "new ActionMap ( [ ... this . _actionManager . filters ] , \"/static/potassium-es/actions/flat-action-map.json\" ) new ActionMap ( [ ... this . _actionManager . filters ] , \"/static/potassium-es/actions/portal-action-map.json\" ) new ActionMap ( [ ... this . _actionManager . filters ] , \"/static/potassium-es/actions/immersive-action-map.json\" )", "del_tokens": "new ActionMap ( [ ... this . _actionManager . filters ] , \"/input/flat-action-map.json\" ) new ActionMap ( [ ... this . _actionManager . filters ] , \"/input/portal-action-map.json\" ) new ActionMap ( [ ... this . _actionManager . filters ] , \"/input/immersive-action-map.json\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", ".", "pooled"], "add_tokens": "var wrappedSelf = this ; args . unshift ( client ) ; return decorated . apply ( wrappedSelf , args ) ;", "del_tokens": "args . shift ( client ) ; return decorated . apply ( null , args ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "basic", "neighbor", "chord", "implementation"], "add_tokens": "it ( 'should handle neighbor chords' , function ( ) { analysisShouldBe ( [ 'V' , 'I' , 'IV' , 'I' , 'iii' ] , [ [ 'Dominant' , 'IM with neighbor' , 'Neighbor of IM' , 'Tonic' , 'Tonic' ] , [ 'V / IM' , 'IM with neighbor' , 'Neighbor of IM' , 'Tonic' , 'Tonic' ] ] ) ; } ) ;", "del_tokens": "assert . equal ( failurePoint . previousStates . length , 1 ) ; assert . equal ( failurePoint . previousStates . length , 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "formatter", "option", "to", "strip", "ANSI", "escape", "codes"], "add_tokens": "if ( 'strip' in options ) { this . _strip = options . strip ; } this . _colorize = this . _strip ? false : options . colorize ; _strip : false , if ( this . _strip ) { formatted = chalk . stripColor ( formatted ) ; }", "del_tokens": "this . _colorize = options . colorize ;", "commit_type": "add"}
{"commit_tokens": ["Add", "documentation", "for", "categorial", "facets"], "add_tokens": "// Data structure for working with categorial data // it helps with mapping a dataitem (category) on a group category : [ 'any' , true , '' ] , // string format of regexp to match data against count : [ 'number' , true , 0 ] , // number of items in this category group : [ 'any' , true , '' ] , // name of the group this is mapped to", "del_tokens": "category : [ 'any' , true , '' ] , count : [ 'number' , true , 0 ] , group : [ 'any' , true , '' ] ,", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "if", "-", "else", "branches", "within", "Node", ".", "js"], "add_tokens": "res . status ( 400 ) . set ( 'Content-Type' , 'application/json' ) . send ( JSON . stringify ( { error : 'invalid state name' } ) ) ; } else { res . status ( 200 ) . set ( 'Content-Type' , 'application/json' ) . send ( JSON . stringify ( module . exports . config . states [ req . params . name ] ) ) ;", "del_tokens": "res . status ( 400 ) . set ( 'Content-Type' , 'application/json' ) . send ( JSON . stringify ( { error : 'invalid state name' } ) ) ; res . status ( 200 ) . set ( 'Content-Type' , 'application/json' ) . send ( JSON . stringify ( module . exports . config . states [ req . params . name ] ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "remocking", "with", "new", "values"], "add_tokens": "if ( services [ service ] . methodMocks [ method ] ) { restoreMethod ( service , method ) ; } services [ service ] . methodMocks [ method ] = { replace : replace } ; // If the constructor was already invoked, we need to mock the method here. if ( services [ service ] . invoked ) { mockServiceMethod ( service , services [ service ] . client , method , replace ) ;", "del_tokens": "if ( ! services [ service ] . methodMocks [ method ] ) { services [ service ] . methodMocks [ method ] = { replace : replace } ; // If the constructor was already invoked, we need to mock the method here. if ( services [ service ] . invoked ) { mockServiceMethod ( service , services [ service ] . client , method , replace ) ; }", "commit_type": "allow"}
{"commit_tokens": ["added", "simple", "check", "function", "and", "readme", "update"], "add_tokens": "* Utilities to management secrets / * * Utilities to management token * / otplib . prototype . token = { // Simple checking method for token check : function check ( token , secret , type , counter ) { var _systemToken = '' ; if ( type == 'totp' ) { _systemToken = this . totp ( secret ) ; } else { _counter = counter || 0 ; _systemToken = this . hotp ( secret , _counter ) ; } return ( _systemToken === token ) ? true : false ; } }", "del_tokens": "* Uttilities to management secrets", "commit_type": "add"}
{"commit_tokens": ["Fix", "associations", ":", "type", "-", "model"], "add_tokens": "assocPk = assocModel . primaryKey ; record [ assoc . alias ] = linkedRecords [ 0 ] [ assocPk ] ; // reduce embedded record to id", "del_tokens": "record [ assoc . alias ] = linkedRecords [ 0 ] . id ; // reduce embedded record to id", "commit_type": "fix"}
{"commit_tokens": ["Allow", "buildRenderUrl", "without", "an", "explicit", "outfit"], "add_tokens": "return ` ${ baseRenderUrl } ${ comicId } ${ avatarId } ${ transparent } ${ scale } ${ outfit ? ` ${ outfit } ` : '' } ` ;", "del_tokens": "return ` ${ baseRenderUrl } ${ comicId } ${ avatarId } ${ transparent } ${ scale } ${ outfit } ` ;", "commit_type": "allow"}
{"commit_tokens": ["Changing", "default", "page", "expiry", "to", "5", "years"], "add_tokens": "default : new Date ( Date . now + 1000 * 60 * 60 * 24 * 365 * 5 ) //5 years default!", "del_tokens": "default : new Date ( Date . now + 1000 * 60 * 60 * 24 * 365 * 50 ) //50 years default!", "commit_type": "change"}
{"commit_tokens": ["Fix", "header", "not", "disappearing", "after", "table", "out", "of", "view"], "add_tokens": "tableHeight = $table . outerHeight ( ) ; if ( tableContainerGap > scrollingContainerTop || scrollingContainerTop - tableContainerGap > tableHeight ) { } ) ( jQuery ) ;", "del_tokens": "tableHeight = $table . outerHeight ( ) ; if ( tableContainerGap > scrollingContainerTop ) { } ) ( jQuery ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "readable", "errors", "for", "documentation", "js", "parsing", "logic"], "add_tokens": "import { codeFrameColumns } from '@babel/code-frame' ; . then ( comments => buildMarkdown ( comments , { title : title , } ) , error => { if ( error . loc ) { error . codeFrame = codeFrameColumns ( documentationSource , { start : error . loc , } ) ; error . message += ` \\n ${ error . codeFrame } ` ; } error . message = ` ${ error . message } ` ; throw error ; } ,", "del_tokens": ". then ( comments => buildMarkdown ( comments , { title : title , } ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "app", "module", "alias", "and", "support", "nerv", "react", "-", "like", "framework"], "add_tokens": "if ( ! Document . prototype ) {", "del_tokens": "if ( ! Document . prototype || ! Document . prototype . isReactComponent ) {", "commit_type": "add"}
{"commit_tokens": ["changed", "filecompiler", "to", "write", ".", "traceur", ".", "js"], "add_tokens": "var path = require ( 'path' ) ; filename = path . join ( path . dirname ( process . argv [ 1 ] ) , filename ) ; if ( result . errors . hadError ( ) ) { console . log ( 'Compilation of ' + filename + ' failed.' ) ; filename = path . basename ( filename , 'js' ) + '.traceur.js' ; fs . writeFileSync ( filename + '.traceur' , new Buffer ( result . result ) ) ;", "del_tokens": "if ( result . errors . length > 0 ) { console . warn ( 'Traceur compilation errors' , result . errors ) ; fs . writeFileSync ( filename , new Buffer ( result . result ) ) ; console . log ( 'WARNING: files are modified in place.' ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "test", ".", "js", "to", "linter"], "add_tokens": "// jscs:disable requireCamelCaseOrUpperCaseIdentifiers // jscs:enable requireCamelCaseOrUpperCaseIdentifiers env . HTTP_PROXY = 'Crazy \\n!() { :: }' ; // jscs:disable requireCamelCaseOrUpperCaseIdentifiers // jscs:enable requireCamelCaseOrUpperCaseIdentifiers env . FTP_PROXY = 'http://ftp-proxy' ; // jscs:disable requireCamelCaseOrUpperCaseIdentifiers // jscs:enable requireCamelCaseOrUpperCaseIdentifiers", "del_tokens": "env . http_proxy = 'Crazy \\n!() { :: }' ; env . ftp_proxy = 'http://ftp-proxy' ;", "commit_type": "add"}
{"commit_tokens": ["changed", "app", "title", "prop", "from", "docTitle", "to", "title"], "add_tokens": "title : { if ( title ) { document . title = title ; }", "del_tokens": "docTitle : { value : 'Application' , document . title = title ;", "commit_type": "change"}
{"commit_tokens": ["removing", "console", ".", "log", "and", "adding", "main"], "add_tokens": "( pkg . main ? \"System.main = \" + JSON . stringify ( pkg . main ) + \";\\n\" : \"\" ) +", "del_tokens": "console . log ( \"WROTE OUT NPM\" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "inline", "-", "form", "and", "DI", "improvements"], "add_tokens": "var path = require ( 'path' ) , config = require ( path . join ( process . cwd ( ) , 'config' , 'prod' ) ) , di = { path : path , config : config , kernel = new ( require ( path . join ( __dirname , 'src' , 'core' , 'GraoKernel' ) ) ) ( di ) ,", "del_tokens": "var http = require ( 'http' ) , di = { config : require ( './../../config/prod' ) , kernel = new ( require ( './src/core/GraoKernel' ) ) ( di ) ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "@returns", "annotation"], "add_tokens": "return tag . title === \"return\" || tag . title === \"returns\" ;", "del_tokens": "return tag . title === \"return\" ;", "commit_type": "add"}
{"commit_tokens": ["removing", "unused", "keypair", "creation", "in", "_authenticate"], "add_tokens": "", "del_tokens": "var keypair = KeyPair ( this . _options . privkey ) ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "resource", "container", "version", "to", "string"], "add_tokens": "version : 7 ,", "del_tokens": "version : '7.0' ,", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "self", "closing", "tags"], "add_tokens": "'pattern' : / ( & lt ; ) | ( \\/ ? & gt ; ) / g", "del_tokens": "'pattern' : / ( & lt ; ) | ( & gt ; ) / g", "commit_type": "add"}
{"commit_tokens": ["Fix", "getter", "of", "params", "and", "session", "variables", "."], "add_tokens": "return ( typeof err . session === 'object' ) return ( typeof err . params === 'object' )", "del_tokens": "return ( err . session instanceof Object ) return ( err . params instanceof Object )", "commit_type": "fix"}
{"commit_tokens": ["Updating", "all", "custom", "on", "events", "so", "that", "returning", "false", "will", "prevent", "the", "event", "from", "executing"], "add_tokens": "if ( onRemoveFromCart . call ( minicart , product ) === false ) { return ; } if ( onCheckout . call ( minicart , e ) === false ) { e . preventDefault ( ) ; return ; } if ( onRender . call ( minicart ) === false ) { return ; } if ( onShow . call ( minicart , e ) === false ) { return ; } if ( onHide . call ( minicart , e ) === false ) { return ; } if ( onReset . call ( minicart ) === false ) { return ; }", "del_tokens": "onRemoveFromCart . call ( minicart , product ) ; onCheckout . call ( minicart , e ) ; onRender . call ( minicart ) ; onShow . call ( minicart , e ) ; onHide . call ( minicart , e ) ; onReset . call ( minicart ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "bug", "with", "identifier", "on", "iOS8"], "add_tokens": "client = getTouch ( ev . changedTouches , touch . identifier || 0 ) client = getTouch ( ev . changedTouches , touch . identifier || 0 )", "del_tokens": "client = getTouch ( ev . changedTouches , touch . identifier | 0 ) client = getTouch ( ev . changedTouches , touch . identifier | 0 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "specific", "error", "for", "malformed", "webhook", "target", "url"], "add_tokens": "const webhookUrl = 'http://some-url.com/webhook' ; const malformedWebhookUrl = 'some-url-missing-http-prefix.com' ; const malformedTargetUrl = 'Malformed target url.' ; target : webhookUrl , it ( 'should return an error if props url target is malformed' , ( done ) => { api . validateProps ( { target : malformedWebhookUrl , event : 'message' } ) . catch ( ( e ) => { e . message . should . equal ( malformedTargetUrl ) ; done ( ) ; } ) ; } ) ; target : webhookUrl it ( 'should return an error if target url is malformed' , ( done ) => { api . create ( { target : malformedWebhookUrl } ) . catch ( ( e ) => { e . message . should . equal ( malformedTargetUrl ) ; done ( ) ; } ) ; } ) ; target : webhookUrl it ( 'should return an error if target url is malformed' , ( done ) => { api . update ( webhookId , { target : malformedWebhookUrl } ) . catch ( ( e ) => { e . message . should . equal ( malformedTargetUrl ) ; done ( ) ; } ) ; } ) ;", "del_tokens": "target : 'target' , target : 'http://some-url.com' target : 'http://some-url.com'", "commit_type": "add"}
{"commit_tokens": ["add", "port", "to", "parent", "param", "on", "iframe", "url"], "add_tokens": "options . parent = this . _currentBaseUrl ( ) ; // window.location.protocol + '//' + window.location.hostname;", "del_tokens": "options . parent = window . location . protocol + '//' + window . location . hostname ;", "commit_type": "add"}
{"commit_tokens": ["improving", "documentation", "adding", "util", "functions"], "add_tokens": "* GET / db / ddoc / _view / view * @ param { mixed } [ data ] Array = pass as ` ` in body . Other = pass as complete body * @ return { object } this * GET / db / ddoc / _view / view", "del_tokens": "/ *! * CouchDB - API * @ author Dominic Barnes < contact @ dominicbarnes . us > * / /** Module Dependencies */ * ` ` * @ param { mixed } [ data ] Array = pass as ` ` ; Other = pass as full body * @ return { object } this Chainable * ` `", "commit_type": "improve"}
{"commit_tokens": ["Added", "a", "test", "for", "a", "defect", "fix", "in", "history", "fixed", "history", "defect"], "add_tokens": "this . start = function ( ) { var startCheck = function ( ) { if ( ! Augmented . History . started ) { Augmented . history . start ( ) ; } } ; startCheck ( ) } ; if ( Augmented . History . started ) {", "del_tokens": "this . start = function ( ) { function ( ) { if ( ! Augmented . history . started ) { Augmented . history . start ( ) ; } } } ; if ( Augmented . history . started ) {", "commit_type": "add"}
{"commit_tokens": ["create", "markup", "functionality", "support", "and", "add", "req", "tests", "docs", "and", "change", "notes"], "add_tokens": "utils : require ( './sl-utils' ) , markup : require ( './sl-markup' )", "del_tokens": "utils : require ( './sl-utils' )", "commit_type": "create"}
{"commit_tokens": ["fixing", "case", "of", "String", "parameter", "in", "js", "docs"], "add_tokens": "* @ type { String } * @ type { String } * @ type { String } * @ type { String } * @ type { String }", "del_tokens": "* @ type { string } * @ type { string } * @ type { string } * @ type { string } * @ type { string }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "location", "of", "filePath", "definition"], "add_tokens": "// Absolute path to the requested file const filePath = path . join ( srcPath , fileRoute ) // Get mime type of request files const contentType = mime . lookup ( filePath )", "del_tokens": "// Absolute path to the requested file const filePath = path . join ( srcPath , fileRoute ) // Get mime type of request files const contentType = mime . lookup ( filePath )", "commit_type": "change"}
{"commit_tokens": ["Fix", "Bug", "877325", "-", "updatedAt", "and", "createdAt", "weren", "t", "being", "return", "with", "make", "objects"], "add_tokens": "\"username\" , \"remixedFrom\" , \"_id\" , \"emailHash\" , \"createdAt\" , \"updatedAt\" ] . forEach ( function ( prop ) {", "del_tokens": "\"username\" , \"remixedFrom\" , \"_id\" , \"emailHash\" ] . forEach ( function ( prop ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "optDependencies", "to", "the", "list", "of", "dependency", "types", "to", "upgrade", "."], "add_tokens": "const DEPENDENCY_TYPES = [ 'dependencies' , 'devDependencies' , 'peerDependencies' , 'optDependencies' ] ; module . exports = PkjUtil ;", "del_tokens": "const DEPENDENCY_TYPES = [ 'dependencies' , 'devDependencies' , 'peerDependencies' ] ; module . exports = PkjUtil ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "console", "error", "on", "Web", "Worker", "table", "methods", "which", "return", "undefined", "."], "add_tokens": "if ( result ) { if ( result . then ) { result . then ( data => { if ( data ) { self . postMessage ( { id : msg . id , data : data } ) ; } } ) ; } else { self . postMessage ( { id : msg . id , data : result } ) ; }", "del_tokens": "if ( result . then ) { result . then ( data => { if ( data ) { self . postMessage ( { id : msg . id , data : data } ) ; } } ) ; } else if ( result ) { self . postMessage ( { id : msg . id , data : result } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "explicit", "dependency", "on", "browserify", "."], "add_tokens": "// uglify-js does not work properly due to Node 0.11.7 bug. // (https://github.com/joyent/node/issues/6235) try { require . resolve ( \"browserify\" ) ; // Throws if missing. enqueue ( bundle , [ \"./test/tests.es5.js\" , \"test/tests.browser.js\" ] ) ; } catch ( ignored ) { console . error ( \"browserify not installed; skipping bundle step\" ) ; }", "del_tokens": "// uglify-js does not work properly due to Node 0.11.7 bug. // (https://github.com/joyent/node/issues/6235) enqueue ( bundle , [ \"./test/tests.es5.js\" , \"test/tests.browser.js\" ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "function", "for", "collision", "collection", "names"], "add_tokens": "mongo . collection ( collisionCollection ( dataset_id ) ) . insertOne ( collisionFields , cb ) ; mongo . collection ( collisionCollection ( dataset_id ) ) . find ( ) . toArray ( cb ) ; mongo . collection ( collisionCollection ( dataset_id ) ) . remove ( { \"_id\" : uid } , cb ) ; function collisionCollection ( dataset_id ) { return dataset_id + '_collision' ; }", "del_tokens": "var COLL_POSTFIX = '_collision' ; mongo . collection ( dataset_id + COLL_POSTFIX ) . insertOne ( collisionFields , cb ) ; mongo . collection ( dataset_id + COLL_POSTFIX ) . find ( ) . toArray ( cb ) ; mongo . collection ( dataset_id + COLL_POSTFIX ) . remove ( { \"_id\" : uid } , cb ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "stream", ".", "write", "()", "and", "server", ".", "emit", "()", "overrides", "to", "call", "the", "original"], "add_tokens": "origEmit . apply ( this , arguments ) ; origWrite . apply ( this , arguments ) ; origEmit . apply ( this , arguments ) ;", "del_tokens": "origEmit . apply ( server , arguments ) ; origWrite . apply ( stream , arguments ) ; origEmit . apply ( server , arguments ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "more", "than", "just", "strings", "for", "the", "select", "options"], "add_tokens": "type : [ 'string' , 'number' , 'boolean' ]", "del_tokens": "type : 'string'", "commit_type": "allow"}
{"commit_tokens": ["update", "docs", "for", "bid", "&", "slot"], "add_tokens": "* @ arguments pubfood / model . BaseModelObject", "del_tokens": "* @ memberof pubfood / model", "commit_type": "update"}
{"commit_tokens": ["Fix", "double", "quotes", "&", "missing", "semicolon", "."], "add_tokens": "options . tempDir = fs . mkdtempSync ( 'bugsnag-sourcemaps' ) ;", "del_tokens": "options . tempDir = fs . mkdtempSync ( \"bugsnag-sourcemaps\" )", "commit_type": "fix"}
{"commit_tokens": ["improved", "handling", "of", "invalid", "nicknames", "in", "NAMES"], "add_tokens": "var userlistEntries = [ ] ; namesList . trim ( ) . split ( ' ' ) . forEach ( function ( nickWithFlags ) { var userlistEntryMaybe = parseUserlistEntry ( nickWithFlags ) ; if ( userlistEntryMaybe !== null ) { userlistEntries . push ( userlistEntryMaybe ) ; } } ) ; var success = server . channels . some ( function ( channel ) { return true ; // break out return false ; // continue", "del_tokens": "var userlistEntries = namesList . trim ( ) . split ( ' ' ) . map ( parseUserlistEntry ) ; console . log ( 'ulentries: %j' , userlistEntries ) ; var success = ! server . channels . every ( function ( channel ) { return false ; // break out return true ; // continue", "commit_type": "improve"}
{"commit_tokens": ["add", "test", "for", "searching", "with", "regex"], "add_tokens": "it ( 'searches for source files using regex' , async ( ) => { let gdb = await createGDB ( 'hello-world' ) await gdb . init ( ) let res = await gdb . sourceFiles ( 'hello.c$' ) await gdb . exit ( ) expect ( res ) . to . deep . equal ( [ '/examples/hello-world/hello.c' ] ) } )", "del_tokens": "// TODO: the example with multiple files will make more sense", "commit_type": "add"}
{"commit_tokens": ["Make", "last", "test", "to", "pass", "green"], "add_tokens": "setTimeout ( _ => { assert_false ( content2 . hidden ) ; async1 . done ( ) ; document . body . removeChild ( div ) ; rc . next ( ) ; } , 10 ) ;", "del_tokens": "// Pretty strange behavior // consider the issue #4 setTimeout ( _ => { document . body . removeChild ( div ) ; rc . next ( ) ; } , 50 ) ; assert_false ( content2 . hidden ) ; assert_false ( content2 . hidden ) ; async1 . done ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "test", "/", "mock", "/", "server", ".", "js", "to", "use", "SCRAMSHA256", "authentication"], "add_tokens": "if ( algorithm === \"SCRAMPBKDF2SHA256\" ) { var algorithm = fields [ 3 ] . toString ( 'ascii' ) ; } }", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["Implement", "support", "for", "power", "-", "chord", "inferring"], "add_tokens": "// Special case for power-chords (which aren't actual chords) if ( notes . length === 2 ) { var root = notes [ 0 ] , interval = root . interval ( notes [ 1 ] ) , val = interval . value ( ) , num = Math . abs ( val ) ; if ( ( num !== 4 && num !== 5 ) || interval . quality ( ) !== 'P' ) return [ ] ; if ( val === - 5 || val === 4 ) root = notes [ 1 ] ; return [ { root : root . name ( ) . toUpperCase ( ) + root . accidental ( ) , type : '5' , exts : [ ] } ] ; } return indexes . indexOf ( note . toString ( ) ) === - 1 ;", "del_tokens": "return indexes . indexOf ( note . toString ( ) ) === - 1 ;", "commit_type": "implement"}
{"commit_tokens": ["Remove", "spaces", "from", "being", "part", "of", "a", "wait", "actions", "subject"], "add_tokens": "match : / ^wait for (fragment|hash|host|path|url)( to (not )?be)? ([^\\s]+)$ / i ,", "del_tokens": "match : / ^wait for (fragment|hash|host|path|url)( to (not )?be)? (.+)$ / i ,", "commit_type": "remove"}
{"commit_tokens": ["Fix", "chained", "constructor", "/", "method", "call", "bug", ".", "Add", "compilation", "unit", "test", "for", "case"], "add_tokens": "// Peek ahead to see if this is non-newed contract constructor chained to a method call // AST represents this as nested nested call expressions and we only want to instrument it once. if ( expression . callee . object && expression . callee . object . type === 'CallExpression' ) { parse [ expression . callee . type ] ( contract , expression . callee ) ; } else { instrumenter . instrumentStatement ( contract , expression ) ; parse [ expression . callee . type ] ( contract , expression . callee ) ; }", "del_tokens": "instrumenter . instrumentStatement ( contract , expression ) ; parse [ expression . callee . type ] ( contract , expression . callee ) ; // for (x in expression.arguments){ // parse[expression.arguments[x].type](contract, expression.arguments[x]) // }", "commit_type": "fix"}
{"commit_tokens": ["fix", "callback", "invocation", "and", "dependencies", "loading"], "add_tokens": "return nodeHelpers . invoke ( callback ) ; return nodeHelpers . invoke ( callback ) ;", "del_tokens": "var nodeHelpers = require ( './node-helpers' ) ; return callback ( ) ; return callback ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "bindings", "with", "limitedOutput", "functions", "for", "compression"], "add_tokens": "this . compress = o . highCompression ? lz4_binding . compressHCLimited : lz4_binding . compressLimited var compressed = new Buffer ( data . length ) var compressedSize = this . compress ( data , compressed , data . length - 1 ) if ( compressedSize === 0 ) { compressed = compressed . slice ( 0 , compressedSize )", "del_tokens": "this . compress = o . highCompression ? lz4_binding . compressHC : lz4_binding . compress // Avoid LZ4 call if possible var compressed = new Buffer ( data . length === this . options . blockMaxSize ? this . chunkBound : lz4_binding . compressBound ( data . length ) ) var compressedSize = this . compress ( data , compressed ) if ( compressedSize < compressed . length ) compressed = compressed . slice ( 0 , compressedSize ) if ( compressedSize > this . options . blockMaxSize ) {", "commit_type": "update"}
{"commit_tokens": ["Use", "copy", "-", "dereference", "instead", "of", "deprecated", "copyRecursivelySync"], "add_tokens": "var copyDereferenceSync = require ( 'copy-dereference' ) . sync ; copyDereferenceSync ( results . directory , buildPath ) ;", "del_tokens": "var mkdir = require ( 'fs' ) . mkdir ; var copyRecursivelySync = require ( 'broccoli-kitchen-sink-helpers' ) . copyRecursivelySync ; mkdir ( buildPath ) ; copyRecursivelySync ( results . directory , buildPath ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "support", "for", "connection", "pool", "size", "allowing", "multiple", "connections", "per", "host"], "add_tokens": "getAConnectionTimeout : 3500 , //number of connections to open for each host poolSize : 1 var connCount = 0 ; while ( connCount ++ < self . options . poolSize ) { var c = new Connection ( connOptions ) ; c . indexInPool = index ; self . connections . push ( c ) ; } this . emit ( 'log' , 'info' , this . connections . length + ' connections created across ' + options . hosts . length + ' hosts.' ) ;", "del_tokens": "getAConnectionTimeout : 3500 var c = new Connection ( connOptions ) ; c . indexInPool = index ; self . connections . push ( c ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "error", "from", "addMany", "cb"], "add_tokens": "return cb ( ) ;", "del_tokens": "return cb ( new Error ( 'Message list length must be greater than 0' ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "try", "-", "catch", "for", "compilefn"], "add_tokens": "var compiled = null ; var factory = null ; try { compiled = _self . compile ( templateName , src ) ; factory = _self . loadCompiledSource ( compiled ) ; } catch ( e ) { Promise . reject ( e ) ; }", "del_tokens": "var compiled = _self . compile ( templateName , src ) ; var factory = _self . loadCompiledSource ( compiled ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "multi", "-", "deck", "split", "options"], "add_tokens": "RunTest ( \"Three-card 11 against 6\" , [ 2 , 3 , 6 ] , 6 , 1 , true , null , \"hit\" ) ; // Some single deck cases RunTest ( \"Split 6s against dealer 2\" , [ 6 , 6 ] , 2 , 1 , true , { numberOfDecks : 1 , doubleAfterSplit : false } , \"split\" ) ; RunTest ( \"Split 9s against Ace single deck\" , [ 9 , 9 ] , 1 , 1 , true , { strategyComplexity : \"advanced\" , numberOfDecks : 1 , doubleAfterSplit : true } , \"split\" ) ; RunTest ( \"Surrender pair of 7s against dealer 10 single deck with exact composition\" , [ 7 , 7 ] , 10 , 1 , true , { numberOfDecks : 1 , strategyComplexity : \"exactComposition\" } , \"surrender\" ) ;", "del_tokens": "RunTest ( \"Surrender pair of 7s against dealer 0 single deck with exact composition\" , [ 7 , 7 ] , 10 , 1 , true , { numberOfDecks : 1 , strategyComplexity : \"exactComposition\" } , \"surrender\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "mongo", "-", "xlsx", ".", "js"], "add_tokens": "return xlsxRW . writeXlsx ( xlsxData , options , function ( err , data ) { return xlsxRW . writeXlsxMultiPage ( excelDataArray , sheetNamesArray , options , function ( err , data ) {", "del_tokens": "xlsxRW . writeXlsx ( xlsxData , options , function ( err , data ) { xlsxRW . writeXlsxMultiPage ( excelDataArray , sheetNamesArray , options , function ( err , data ) {", "commit_type": "update"}
{"commit_tokens": ["Use", "Promise", "chaining", "in", "dynamicCaller", "()"], "add_tokens": "return rules . reduce ( function ( curr , rule ) { return curr . then ( function ( ) { return rule . Fire ( self , constraint ) } ) } , Promise . resolve ( ) )", "del_tokens": "return Promise . all ( rules . map ( function ( rule ) { return rule . Fire ( self , constraint ) } ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "in", "traverse", "logic", "in", "GoldenLayoutContentUtils", "."], "add_tokens": "GoldenLayoutContentUtils . _traverseWidgetContents ( goldenLayoutContents , widgetContent => { widgetNames . add ( widgetContent . component ) ; return false ; } ) ; return Array . from ( widgetNames . values ( ) ) ; if ( ( content . type === 'component' ) && ( content . componentName === 'lm-react-component' ) ) { if ( consumer ( content ) ) { return content ; }", "del_tokens": "GoldenLayoutContentUtils . _traverseWidgetContents ( goldenLayoutContents , widgetContent => widgetNames . add ( widgetContent . component ) ) ; return widgetNames ; if ( ( content . type === 'component' ) && ( content . componentName === 'lm-react-component' ) && consumer . consume ( content ) ) { return content ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "template", "ViewEventListener", ".", "py", "fixed", "exports", "name", "index", ".", "js"], "add_tokens": "eventListenerList : require ( './jslib/eventListenerList.js' ) , viewEventListenerList : require ( './jslib/viewEventListenerList.js' )", "del_tokens": "eventListeners : require ( './jslib/eventListenerList.js' ) , viewEventListeners : require ( './jslib/viewEventListenerList.js' )", "commit_type": "fix"}
{"commit_tokens": ["add", "Mapquest", "Open", "Aerial", "tiles"], "add_tokens": "var mapQuestAttr = 'Tiles Courtesy of <a href=\"http://www.mapquest.com/\">MapQuest</a> &mdash; ' ; url : 'http://otile{s}.mqcdn.com/tiles/1.0.0/osm/{z}/{x}/{y}.png' , options : { attribution : mapQuestAttr + osmDataAttr , subdomains : '1234' } L . TileLayer . MapQuestOpen . Aerial = L . TileLayer . MapQuestOpen . extend ( { url : 'http://oatile{s}.mqcdn.com/naip/{z}/{x}/{y}.jpg' , options : { attribution : mapQuestAttr + 'Portions Courtesy NASA/JPL-Caltech and U.S. Depart. of Agriculture, Farm Service Agency' } } ) ;", "del_tokens": "var mapQuestAttr = 'Tiles Courtesy of <a href=\"http://www.mapquest.com/\">MapQuest</a> &mdash; ' + osmDataAttr ; url : 'http://{s}.mqcdn.com/tiles/1.0.0/osm/{z}/{x}/{y}.png' , options : { attribution : mapQuestAttr , subdomains : [ 'otile1' , 'otile2' , 'otile3' , 'otile4' ] }", "commit_type": "add"}
{"commit_tokens": ["Use", "explicit", "annotation", "in", "in", "-", "view", "-", "container", "directive"], "add_tokens": "controller : [ '$element' , function ( $element ) { } ]", "del_tokens": "controller : function ( $element ) { }", "commit_type": "use"}
{"commit_tokens": ["use", "latest", "nan", ".", "h", ".", "comments", "."], "add_tokens": "* Copyright ( c ) 2012 - 2015 , Christopher Jeffrey ( MIT License )", "del_tokens": "* Copyright ( c ) 2012 , Christopher Jeffrey ( MIT License )", "commit_type": "use"}
{"commit_tokens": ["Add", ".", "js", "files", "for", "es6", "transpilation"], "add_tokens": "{ test : / \\.jsx?$ / , exclude : / node_modules / , loader : 'babel-loader?presets[]=es2015&presets[]=react' } , { test : / \\.js?$ / , exclude : / node_modules / , loader : 'babel-loader?presets[]=es2015' }", "del_tokens": "{ test : / \\.jsx?$ / , exclude : / node_modules / , loader : 'babel-loader?presets[]=es2015&presets[]=react' }", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "program", "and", "update", "benchmark"], "add_tokens": "var md = new rs . Markdown ( rend ) ; return md . renderSync ( text ) ; main . bench ( 'robotskirt (reuse all)' , robotskirt ) ; return ( new rs . Markdown ( new rs . HtmlRenderer ( ) ) ) . renderSync ( text ) ; main . bench ( 'robotskirt (new renderer and parser)' , robotskirt_slow ) ;", "del_tokens": "return rs . markdownSync ( rend , text ) ; main . bench ( 'robotskirt (reuse renderer)' , robotskirt ) ; return rs . markdownSync ( new rs . HtmlRenderer ( ) , text ) ; main . bench ( 'robotskirt (new renderer)' , robotskirt_slow ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "the", "base", "option", "when", "reading", "files", "+", "fix", "inlining", "(", "there", "was", "an", "accidental", "global", "var", "being", "used", ")"], "add_tokens": "var currentDir = path . dirname ( filename ) loader : defaultLoader , base : undefined var relativeFilename = options . base ? path . relative ( options . base , filename ) : filename filename : relativeFilename , filename : relativeFilename ,", "del_tokens": "currentDir = path . dirname ( filename ) loader : defaultLoader filename : filename , filename : filename ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "set", "text", "()", "method", "to", "work", "with", "root", "element"], "add_tokens": "this . children = textElement . children ; return $ . updateDOM ( this . children , this ) ;", "del_tokens": "return this . children = textElement ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "parameters", "not", "being", "passed", "through", "when", "paging"], "add_tokens": "return self . request ( 'GET' , path , _ . extend ( parameters , { page : n } ) ) ;", "del_tokens": "return self . request ( 'GET' , path , { page : n } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "comment", "to", "another", "line"], "add_tokens": "// this is illegal even though it's not used anywhere", "del_tokens": "// this is illegal even though it's not used anywhere", "commit_type": "move"}
{"commit_tokens": ["Implement", "better", "acking", "and", "nacking", "."], "add_tokens": "q . subscribe ( options , function ( message , headers , deliveryInfo , messageObject ) { var m = new Message ( message , headers , deliveryInfo , messageObject ) ;", "del_tokens": "q . subscribe ( options , function ( message , headers , deliveryInfo ) { var m = new Message ( q , message , headers , deliveryInfo ) ;", "commit_type": "implement"}
{"commit_tokens": ["fixed", "a", "load", "of", "bugs", "and", "updated", "readme"], "add_tokens": "// opnames: ['br', 'add', 'ld', 'st', 'jsr', 'and', 'ldr', 'str', 'rti', 'not', 'ldi', 'sti', 'jsrr', 'ret', 'lea', 'trap'] opnames : { 'nop' : 0 , 'br' : 0 , 'add' : 1 , 'ld' : 2 , 'st' : 3 , 'jsr' : 4 , 'jmp' : 4 , 'and' : 5 , 'ldr' : 6 , 'str' : 7 , 'rti' : 8 , 'not' : 9 , 'ldi' : 10 , 'sti' : 11 , 'jsrr' : 12 , 'jmprr' : 12 , 'ret' : 13 , 'lea' : 14 , 'trap' : 15 }", "del_tokens": "opnames : [ 'br' , 'add' , 'ld' , 'st' , 'jsr' , 'and' , 'ldr' , 'str' , 'rti' , 'not' , 'ldi' , 'sti' , 'jsrr' , 'ret' , 'lea' , 'trap' ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "for", "hiding", "success", "cases", "from", "the", "generated", "report", "."], "add_tokens": "} , 'c' : { alias : 'compact' , describe : 'Hides success cases and only shows error cases.' var compact = typeof ( nconf . get ( 'compact' ) ) !== 'undefined' ; var testSuite = new TestSuite ( suite , filename , _ ) ; if ( ! compact || ( compact && testSuite . isFailure ) ) testSuites . push ( testSuite ) ;", "del_tokens": "testSuites . push ( new TestSuite ( suite , filename , _ ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "template", "and", "examples", "."], "add_tokens": "if ( doclet . longname == helper . globalName ) { template . kinds . global . forEach ( function ( kind ) { symbols [ kind ] = template . find ( { kind : kind , memberof : { isUndefined : true } } ) ; } ) ; } else { template . kinds . symbols . forEach ( function ( kind ) { symbols [ kind ] = template . find ( { kind : kind , memberof : doclet . longname } ) ; } ) ; }", "del_tokens": "template . kinds . symbols . forEach ( function ( kind ) { symbols [ kind ] = template . find ( { kind : kind , memberof : doclet . longname } ) ; } ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "function", "&", "add", "func", "-", "names", "rule"], "add_tokens": "inject : function ( runtime ) { this . _reactRuntime = runtime ; } ,", "del_tokens": "inject : ( runtime ) => { this . _reactRuntime = runtime ; } ,", "commit_type": "fix"}
{"commit_tokens": ["Updating", "jangular", "w", "new", "parser"], "add_tokens": "//var newrelic = require('newrelic'); //var startTime = (new Date()).getTime(); //var renderedPage = newrelic.createTracer('jng.pages::renderPage::render', function () { // return jangular.render(view, model, routeInfo.strip); //})(); //var endTime = (new Date()).getTime(); //console.log('main page ' + (endTime - startTime)); //startTime = endTime; //renderedPage = newrelic.createTracer('jng.pages::renderPage::renderLayout', function () { // return me.renderLayout(routeInfo.appName, routeInfo.layout, pageDeps); //})(); renderedPage = me . renderLayout ( routeInfo . appName , routeInfo . layout , pageDeps ) ; //endTime = (new Date()).getTime(); //console.log('layout ' + (endTime - startTime)); //renderedPage = newrelic.createTracer('jng.pages::renderPage::renderWrapper', function () { // return me.renderLayout(routeInfo.appName, routeInfo.wrapper, pageDeps); //})(); renderedPage = me . renderLayout ( routeInfo . appName , routeInfo . wrapper , pageDeps ) ;", "del_tokens": "renderedPage = this . renderLayout ( routeInfo . appName , routeInfo . layout , pageDeps ) ; renderedPage = this . renderLayout ( routeInfo . appName , routeInfo . wrapper , pageDeps ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "apn", "and", "fcm", "to", "integrations", "api", "wrapper"], "add_tokens": "frontendEmail : new IntegrationType ( [ ] , [ 'fromAddress' ] ) , fcm : new IntegrationType ( [ 'serverKey' , 'senderId' ] ) , apn : new IntegrationType ( [ 'certificate' ] , [ { name : 'autoUpdateBadge' , type : 'boolean' } , 'password' ] )", "del_tokens": "frontendEmail : new IntegrationType ( [ ] , [ 'fromAddress' ] )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "person", "object", "person", ".", "username"], "add_tokens": "person . username = _ . split ( person . email , '@' , 2 ) [ 0 ] ;", "del_tokens": "person . userame = _ . split ( person . email , '@' , 2 ) [ 0 ] ;", "commit_type": "fix"}
{"commit_tokens": ["change", "some", "==", "to", "===", "to", "comply", "with", "the", "style", "guide"], "add_tokens": "if ( number % 1 === 0 ) { if ( pValueText === '0%' ) { . left ( function ( data ) { var l = scale ( data ) ; return ( this . index === 0 ) ? l - 1 : l ; } ) . anchor ( function ( ) { return ( this . index === 0 ) ? 'left' : 'right' ; } ) . text ( function ( ) { return ( this . index === 0 ) ? '-' : '+' ; } ) ;", "del_tokens": "if ( number % 1 == 0 ) { if ( pValueText == '0%' ) { . left ( function ( data ) { var l = scale ( data ) ; return ( this . index == 0 ) ? l - 1 : l ; } ) . anchor ( function ( ) { return ( this . index == 0 ) ? 'left' : 'right' ; } ) . text ( function ( ) { return ( this . index == 0 ) ? '-' : '+' ; } ) ;", "commit_type": "change"}
{"commit_tokens": ["adds", "history", "cache", "to", "prevent", "infinite", "loops"], "add_tokens": "this . limit = this . options . limit || 25 ; this . versions = { } ; this . history = { } ; this . history [ key ] = this . history [ key ] || 0 ; if ( o . path != null && this . history [ key ] < this . limit ) { this . history [ key ] ++ ;", "del_tokens": "if ( o . path != null ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "webpack", "config", "function"], "add_tokens": "function handleFunction ( options ) { if ( typeof options === 'function' ) { return options ( ) ; } return options ; } function handleWebpackConfig ( webpackConfig ) { return Array . isArray ( webpackConfig ) ? webpackConfig . map ( handleFunction ) . find ( c => c . target === 'node' ) : handleFunction ( webpackConfig ) ; } const config = handleWebpackConfig ( webpackConfig ) ;", "del_tokens": "const config = Array . isArray ( webpackConfig ) ? webpackConfig . find ( c => c . target === 'node' ) : webpackConfig ;", "commit_type": "add"}
{"commit_tokens": ["Create", "t3", "-", "testing", "bundle"], "add_tokens": "DIST_TESTING_BUNDLE_NAME = 't3-testing' , SRC_FILES = [ 'lib/box.js' , 'lib/event-target.js' , 'lib/context.js' , 'lib/application.js' ] , TESTING_FILES = [ 'lib/box.js' , 'lib/event-target.js' , 'lib/application-stub.js' , 'lib/test-service-provider.js' ] , minDistFilename = distFilename . replace ( / \\.js$ / , '.min.js' ) , distTestingFilename = DIST_DIR + DIST_TESTING_BUNDLE_NAME + '.js' ; cat ( TESTING_FILES ) . to ( distTestingFilename ) ; ( copyrightComment + versionComment + cat ( distTestingFilename ) ) . to ( distTestingFilename ) ; ( cat ( distTestingFilename ) + '\\n' ) . to ( distTestingFilename ) ; cp ( distTestingFilename , distTestingFilename . replace ( '.js' , '-' + pkg . version + '.js' ) ) ;", "del_tokens": "SRC_FILES = [ 'lib/box.js' , 'lib/event-target.js' , 'lib/context.js' , 'lib/application.js' ] , minDistFilename = distFilename . replace ( / \\.js$ / , '.min.js' ) ;", "commit_type": "create"}
{"commit_tokens": ["Make", "sure", "address", "strings", "are", "null", "-", "term", "d", "before", "Buffered"], "add_tokens": "address = new Buffer ( address + '\\0' ) ; publicKey = ( new Buffer ( publicKey ) ) . fromHex ( ) ; address = new Buffer ( address + '\\0' ) ; publicKey = ( new Buffer ( publicKey ) ) . fromHex ( ) ; address = new Buffer ( address + '\\0' ) ; publicKey = ( new Buffer ( publicKey ) ) . fromHex ( ) ; address = new Buffer ( address + '\\0' ) ; publicKey = ( new Buffer ( publicKey ) ) . fromHex ( ) ;", "del_tokens": "address = new Buffer ( address ) ; publicKey = util . fromHex ( publicKey ) ; address = new Buffer ( address ) ; publicKey = util . fromHex ( publicKey ) ; address = new Buffer ( address ) ; publicKey = util . fromHex ( publicKey ) ; address = new Buffer ( address ) ; publicKey = util . fromHex ( publicKey ) ;", "commit_type": "make"}
{"commit_tokens": ["Changing", "weight", "of", "default", "contexts", "so", "their", "reactions", "can", "be", "easily", "overridden", "."], "add_tokens": "// @todo: Eventually we may want to add an operator and also allow OR // and ANDs. weight : - 10 ,", "del_tokens": "// @todo: Eventually we may want to add an operator and also alow OR and // ANDs. weight : 0 ,", "commit_type": "change"}
{"commit_tokens": ["Added", "lean", "query", "option", "and", "added", "keepSortOrder", "query", "option"], "add_tokens": "* @ param { Boolean } options . keepSortOrder If getting an array of objects , whether we should keep same sort order of * returned objects as the < code > id < / code>'s passed in. * Default : < code > false < / code > let modelObjs = _ . map ( results , _ . bind ( this . _createModelObject , this ) ) ; if ( options . keepSortOrder ) { modelObjs = _ . sortBy ( modelObjs , o => { return id . indexOf ( o . getDocumentKeyValue ( ) ) ; } ) ; } let idToGet = res . value . key || res . value . keys ; if ( options . lean ) { if ( this . config . alwaysReturnArrays && ! Array . isArray ( idToGet ) ) { idToGet = [ idToGet ] ; } return fn ( err , idToGet ) ; }", "del_tokens": "const modelObjs = _ . map ( results , _ . bind ( this . _createModelObject , this ) ) ; const idToGet = res . value . key || res . value . keys ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "task", "to", "tests", "on", "browser", ".", "Update", "the", "README", "file"], "add_tokens": "'pkg' : grunt . file . readJSON ( 'package.json' ) , 'concat' : { 'dist' : { 'src' : sourcesFiles , 'dest' : 'parse.js' 'http-server' : { 'dev' : { 'port' : 5000 , 'root' : '/apps/ParseJS/' } } , 'jshint' : { 'files' : [ 'gruntfile.js' , 'parse.js' ] 'karma' : { 'unit' : { 'configFile' : 'tests/tests.config.js' 'uglify' : { 'options' : { 'sourceMap' : true , 'sourceMapName' : 'parse.map' 'dist' : { 'files' : { 'watch' : { 'files' : [ 'gruntfile.js' , 'src/**/*.js' , 'tests/**/*.js' ] , 'tasks' : [ 'concat' , 'uglify' , 'jshint' , 'karma' ] grunt . loadNpmTasks ( 'grunt-http-server' ) ; grunt . registerTask ( 'tests-client' , [ 'http-server' ] ) ;", "del_tokens": "pkg : grunt . file . readJSON ( 'package.json' ) , concat : { dist : { src : sourcesFiles , dest : 'parse.js' jshint : { files : [ 'gruntfile.js' , 'parse.js' ] karma : { unit : { configFile : 'tests/tests.config.js' uglify : { options : { sourceMap : true , sourceMapName : 'parse.map' dist : { files : { watch : { files : [ 'gruntfile.js' , 'src/**/*.js' , 'tests/**/*.js' ] , tasks : [ 'concat' , 'uglify' , 'jshint' , 'karma' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "multi", "-", "key", "object", "packing"], "add_tokens": "var value = object [ i + keys ] ;", "del_tokens": "var value = object [ key + keys ] ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "so", "it", "only", "overwrites", "a", "file", "is", "there", "was", "stripped", "code", "."], "add_tokens": "var contents = grunt . file . read ( filepath ) , replacement = contents . replace ( pattern , \"\" ) ; // if replacement is different than contents, save file and print a success message. if ( contents != replacement ) { if ( f . dest ) { grunt . file . write ( f . dest , replacement ) ; grunt . log . writeln ( \"Stripped code from \" + filepath + \" and saved to \" + f . dest ) ; } else { grunt . file . write ( filepath , replacement ) ; grunt . log . writeln ( \"Stripped code from \" + filepath ) ; }", "del_tokens": "// strip test blocks from the file var contents = grunt . file . read ( filepath ) . replace ( pattern , \"\" ) ; // save file and print a success message. if ( f . dest ) { grunt . file . write ( f . dest , contents ) ; grunt . log . writeln ( \"Stripped code from \" + filepath + \" and saved to \" + f . dest ) ; } else { grunt . file . write ( filepath , contents ) ; grunt . log . writeln ( \"Stripped code from \" + filepath ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "the", "error", "()", "method", "on", "services"], "add_tokens": "* Reject the service promise with an forbidden status * @ param { String } message / ** * Reject the service promise with an error status * The HTTP server encountered an unexpected condition which prevented * it from fulfilling the request . * For example this error can be caused by a serveur misconfiguration , * or a resource exhausted or denied to the server on the host machine . * * @ param { String } message * / this . error = function ( message ) { service . httpstatus = 500 ; service . outcome . success = false ; service . outcome . alert . push ( { type : 'danger' , message : message } ) ; service . deferred . reject ( new Error ( message ) ) ; } ;", "del_tokens": "* @ param { [ [ Type ] ] } message [ [ Description ] ]", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "numbers", "to", "match", "GitHub", "releases", "."], "add_tokens": "/*! PixiParticles 1.2.2 */", "del_tokens": "/*! PixiParticles 1.1.1 */", "commit_type": "update"}
{"commit_tokens": ["Improve", "performance", "of", "Promise", ".", "try", "and", "extend", "it"], "add_tokens": "runFile ( files . shift ( ) ) ;", "del_tokens": "runFile ( files [ i ] ) ;", "commit_type": "improve"}
{"commit_tokens": ["Removed", "throw", "for", "undefined", "data"], "add_tokens": "if ( ! err ) {", "del_tokens": "if ( err ) { throw err ; } else {", "commit_type": "remove"}
{"commit_tokens": ["Removes", "Math", ".", "trunc", "IE", "doesn", "t", "support", "method"], "add_tokens": "var shift = Math . pow ( 10 , 0 ) ; var number = 1 + ( ( request . Skip / response . FilteredRecordCount ) * response . TotalPages ) ; response . CurrentPage = ( ( number * shift ) | 0 ) / shift ;", "del_tokens": "response . CurrentPage = Math . trunc ( 1 + ( ( request . Skip / response . FilteredRecordCount ) * response . TotalPages ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["moved", "ThreadList", "into", "thread", "submodule"], "add_tokens": "import { Thread , ThreadList } from './thread' ;", "del_tokens": "import Thread from './thread' ; import ThreadList from './topic' ;", "commit_type": "move"}
{"commit_tokens": ["fixes", "optional", "options", "value", "in", "background", "image"], "add_tokens": "if ( options && options . backgroundPosition ) style . backgroundPosition = getBackgroundPosition ( options . backgroundPosition )", "del_tokens": "if ( options . backgroundPosition ) style . backgroundPosition = getBackgroundPosition ( options . backgroundPosition )", "commit_type": "fix"}
{"commit_tokens": ["Added", "event", "handlers", "for", "PieceFinished", "and", "TorrentChecked"], "add_tokens": "var torrentHandle = alert . handle var torrent = this . torrents . get ( torrentHandle . infoHash ( ) ) if ( torrent ) { torrent . _onTorrentChecked ( ) } var torrentHandle = alert . handle var torrent = this . torrents . get ( torrentHandle . infoHash ( ) ) if ( torrent ) { torrent . _onPieceFinished ( alert . pieceIndex ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "getFallbackLocales", "methods", "to", "find", "fallback", "locales", "of", "current", "locale"], "add_tokens": "import fallbacks from './languages/fallbacks.json' getFallbackLocales ( ) { return [ ... ( fallbacks [ this . locale ] || [ ] ) , this . finalFallback ] } const fallbackLocales = this . getFallbackLocales ( this . locale ) locale = fallbackLocales [ fallbackIndex ]", "del_tokens": "import FALLBACKS from './languages/fallbacks.json' if ( locale === this . finalFallback ) { break } locale = ( FALLBACKS [ this . locale ] && FALLBACKS [ this . locale ] [ fallbackIndex ] ) || this . finalFallback", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplicate", "default", "definitions", "for", "config", "."], "add_tokens": "* @ param service { String } URL to the ESI service * @ param source { String } Data source used * @ param agent { String } Custom user agent string to send with each request * @ param language { String } Language character code * @ param timeout { Number } Request timeout in milliseconds service : service , source : source , agent : agent , language : language , timeout : timeout } ) {", "del_tokens": "* @ param service { String } URL to the ESI service , defaults to * ` ` . * @ param source { String } Data source used , defaults to ` ` . * @ param agent { String } Custom user agent string to send with each request , * which defaults to this project but really should be set for your app * @ param language { String } Language character code , defaults to ` ` * @ param timeout { Number } Request timeout in milliseconds , defaults to ` ` service : service = 'https://esi.tech.ccp.is/latest' , source : source = 'tranquility' , agent : agent = 'eve-swagger-js / https://github.com/lhkbob/eve-swagger-js' , language : language = 'en-us' , timeout : timeout = 6000 } = { } ) {", "commit_type": "remove"}
{"commit_tokens": ["Update", "node", "unit", "test", "for", "fingerprint32"], "add_tokens": "0xee , 0xd8 , 0x6e , 0xa9 // csum:4", "del_tokens": "0x9b , 0x59 , 0xe9 , 0xf3 // csum:4", "commit_type": "update"}
{"commit_tokens": ["Updated", "documentation", "and", "tests", "."], "add_tokens": "* to those routes . A typical implementation is to \"use\" then \"handle\" . NOTE : When you create middleware if you * want data to get bubbled up in the resolved promise you will need to add the data to the \"payload\" property . * This allows us to add things to the kontx but only bubble up specific data . * kontx . payload . test = 0 ; * kontx . payload . ab = 1 ; * runner . handle ( 'example.method' , { } ) . then ( function ( payload ) { * payload . ab . not . equal ( 1 ) ;", "del_tokens": "* to those routes . A typical implementation is to \"use\" then \"handle\" * kontx . test = 0 ; * kontx . ab = 1 ; * runner . handle ( 'example.method' , { } ) . then ( function ( kontx ) { * kontx . ab . not . equal ( 1 ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "tests", "for", "logging", "and", "reporting", "in", "workers", "."], "add_tokens": "var clone = require ( '101/clone' ) ; var opts = clone ( this . _workerOptions [ queueName ] ) ;", "del_tokens": "var set = require ( '101/set' ) ; var opts = { } ; set ( opts , this . _workerOptions [ queueName ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "parsing", "of", "large", "numbers"], "add_tokens": "factor = factor * 256 ;", "del_tokens": "factor = factor << 8 ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "unneeded", "nodeready", "event", "listener"], "add_tokens": "el . setAttribute ( propName , props [ propName ] ) ;", "del_tokens": "if ( el . isNode ) { el . setAttribute ( propName , props [ propName ] ) ; } else { el . addEventListener ( 'nodeready' , function ( ) { console . log ( \"WAITING\" ) ; el . setAttribute ( propName , props [ propName ] ) ; } ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Use", "path", ".", "join", "instead", "of", "whack", "concatenation", "when", "creating", "filePath", "inside", "readdirsync", "callback", "."], "add_tokens": "this . log ( 'processTemplate: template=\"' + template + '\", root=\"' + root + '\"' ) ; var filePath = path . join ( template , file ) ; if ( extn . test ( filePath ) || fs . statSync ( filePath ) . isDirectory ( ) ) { self . processTemplate ( filePath , root || template ) ;", "del_tokens": "var path = template + '/' + file ; if ( extn . test ( path ) || fs . statSync ( path ) . isDirectory ( ) ) { self . processTemplate ( path , root || template ) ;", "commit_type": "use"}
{"commit_tokens": ["Using", "destructuring", "to", "improve", "the", "Gulp", "tasks"], "add_tokens": "const { dest , src , task } = require ( 'gulp' ) ; task ( 'compress:php' , ( ) => src ( 'path/to/**/*.php' , { read : false } ) . pipe ( dest ( 'path/to/out' ) )", "del_tokens": "const gulp = require ( 'gulp' ) ; gulp . task ( 'compress:php' , ( ) => gulp . src ( 'path/to/**/*.php' , { read : false } ) . pipe ( gulp . dest ( 'path/to/out' ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "HTTP2", "error", "handler"], "add_tokens": "var m = p . errors [ 2 ] ; if ( m ) res = m ; msg : res", "del_tokens": "res = p . errors [ 2 ] ; msg : res", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "multiple", "examples", "api", "."], "add_tokens": "var logger = require ( './logger' ) ; logger . log ( '[WARN]' . red , 'Skip. Different headers' ) ; logger . log ( '[WARN]' . red , 'Skip. Different body' ) ; logger . log ( '[WARN]' . red , 'Skip. Different content-types ' , httpMediaType , ' !== ' , specMediaType ) ;", "del_tokens": "console . warn ( 'Skip. Different headers' ) ; console . warn ( 'Skip. Different body' ) ; console . warn ( 'Skip. Different content-types ' , httpMediaType , ' !== ' , specMediaType ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "max", "syntax", "highlighting", "to", "usage", "doc"], "add_tokens": "\\` \\` \\` jsx", "del_tokens": "\\` \\` \\` js", "commit_type": "add"}
{"commit_tokens": ["added", "popup", "messages", "for", "debugger"], "add_tokens": "var utils = require ( './utils' ) ; return utils . show_popup_message ( 'Limitations: You can start only 5 runners.' ) ;", "del_tokens": "dialogs . showModalDialog ( INFO_DIALOG_ID , 'Brackets nodejs integration - limitations' , 'You can start only 5 runners.' ) ; return ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "if", "statement", "merging", "bug"], "add_tokens": "// Merge nested if statements if possible if ( node . alternate || node . consequent . alternate ) { return ;", "del_tokens": "if ( node . alternate ) { return ; } if ( node . consequent . alternate ) { node . alternate = node . consequent . alternate ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "basic", "tests", "for", "manual", "config", "of", "throttler"], "add_tokens": "describe ( 'Configire Custom Limit Handler' , function ( ) { } )", "del_tokens": "// app.use(throttle({ rateLimit: { ttl: 600, max: 5 } })) describe ( 'Configire Limit' , function ( ) { } ) // app.use(throttle(function (req, res, hits, remaining) { // var until = new Date((new Date()).getTime() + remaining) // res.statusCode = 420 // res.send('You shall not pass ' + hits + ' until ' + until + '!') // })) describe ( 'Configire Custom Limit Header' , function ( ) { } )", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "extra", "check", "on", "the", "vnode"], "add_tokens": "this . $_componentId = this . $vnode && this . $vnode . data . ref ? this . $vnode . data . ref : this . $options . name ;", "del_tokens": "this . $_componentId = this . $vnode ? this . $vnode . data . ref : this . $options . name ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bunch", "of", "cases", "in", "sysrev", "test"], "add_tokens": "var Sysrev = require ( '../../lib/sysrev/sysrev' ) ; var getTmpDir = require ( '../helpers/get-tmp-dir' ) ; var tmpDir = getTmpDir ( ) ; var sysrev = new Sysrev ( { systemsRoot : tmpDir } ) ; sysrev . createSystem ( user , 'test' , 'test' , tmpDir , function ( err , system ) { assert . equal ( systems . length , 1 ) ; assert . equal ( systems [ 0 ] . name , 'test' ) ;", "del_tokens": "var _ = require ( 'lodash' ) ; var sysrev = require ( '../../lib/sysrev/sysrev' ) ( { systemsRoot : '/tmp/nfd/systems' } ) ; sysrev . createSystem ( user , 'test' , 'test' , function ( err , system ) { assert ( systems [ 0 ] . name === 'test_test' ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "grunt", "to", "run", "tests", "before", "build"], "add_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'jasmine' , 'preprocess' , 'concat' , 'uglify' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'preprocess' , 'concat' , 'uglify' ] ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "typeof", "to", "the", "list", "of", "keywords", "to", "the", "function", "tokenizer"], "add_tokens": "keyword : / \\b(?:var|let|for|if|else|in|class|function|typeof|return|with|case|break|switch|export|new|while|do|throw|catch)\\b / ,", "del_tokens": "keyword : / \\b(?:var|let|for|if|else|in|class|function|return|with|case|break|switch|export|new|while|do|throw|catch)\\b / ,", "commit_type": "add"}
{"commit_tokens": ["add", "session", "store", "and", "express", "to", "openbiz"], "add_tokens": "/ ** * This is an alias of { @ link openbiz . services . ObjectService . getPolicy } * @ memberof openbiz * @ method * @ see { @ link openbiz . services . ObjectService . getPolicy } * /", "del_tokens": "/ ** * This is an alias of { @ link openbiz . services . ObjectService . getPolicy } * @ memberof openbiz * @ method * @ see { @ link openbiz . services . ObjectService . getPolicy } * /", "commit_type": "add"}
{"commit_tokens": ["Updated", "demo", "and", "fixed", "edge", "alignment", "issue"], "add_tokens": "return popperRenderer . createPopperObject ( this [ 0 ] , createOptionsObject ( this [ 0 ] , userOptions ) ) ; return createReferenceObject . getRef ( this [ 0 ] , createOptionsObject ( this [ 0 ] , userOptions ) ) ; //Create a options object with required default values function createOptionsObject ( target , userOptions ) { popper : { } , let pan = target . cy ( ) . pan ( ) ; let zoom = target . cy ( ) . zoom ( ) ;", "del_tokens": "return popperRenderer . createPopperObject ( this [ 0 ] , appendValues ( this [ 0 ] , userOptions ) ) ; return createReferenceObject . getRef ( this [ 0 ] , appendValues ( this [ 0 ] , userOptions ) ) ; //Append element specific values to the options function appendValues ( target , userOptions ) { let pan = target . pan ( ) ; let zoom = target . zoom ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "_", ".", "defaults", "in", "Task", ".", "createRegistryObject", "()", ".", "create", "()", "fix"], "add_tokens": "var options = _ . defaults ( definitionOverrides , _definition ) ;", "del_tokens": "var _definition = _ . cloneDeep ( definition ) ; var options = _ . defaults ( _definition , definitionOverrides ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "offset", "bug", "added", "publish", "info"], "add_tokens": "scrollBox . style . top = style . headerCellHeight + ( style . headerCellBorderWidth * 2 ) + 'px' ; scrollBox . style . left = '0px' ; container . style . backgroundColor = style . backgroundColor ; window . addEventListener ( 'resize' , function ( ) { requestAnimationFrame ( resize ) ; } ) ;", "del_tokens": "scrollBox . style . top = container . getBoundingClientRect ( ) . top + style . headerCellHeight + ( style . headerCellBorderWidth * 2 ) + 'px' ; scrollBox . style . left = container . getBoundingClientRect ( ) . left + 'px' ; container . style . background = '#0F0' ; window . addEventListener ( 'resize' , resize ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "comments", "to", "redux", "-", "wasp", "and", "wasp", "-", "graphql"], "add_tokens": "// --------------------", "del_tokens": "// --------------------", "commit_type": "add"}
{"commit_tokens": ["Added", "template", "to", "extend", "Jasmine", "to", "have", "notDeepEqual", "assertion"], "add_tokens": "var notDeepEqualTemplate = 'it(\\'{{=it.assertionMessage}}\\', function() {\\nvar pass;\\ntry {\\npass = true;\\nassert.notDeepEqual(file.{{=it.assertionInput}}, {{=it.assertionOutput}});\\n} catch (e) {\\npass = false;\\n}\\nexpect(pass).toBe(true);\\n});\\n' ; deepEqual : deepEqualTemplate , notDeepEqual : notDeepEqualTemplate", "del_tokens": "deepEqual : deepEqualTemplate //Commented these out since we will be implementing them soon //notDeepEqual: notDeepEqualTemplate", "commit_type": "add"}
{"commit_tokens": ["Added", "object", "properties", "ordering", "capability", "to", "uiSchema", "."], "add_tokens": "const cls = this . state . valid ? \"valid\" : \"invalid\" ; < span className = { ` ${ cls } ${ icon } ` } / >", "del_tokens": "< span className = { ` ${ icon } ` } / >", "commit_type": "add"}
{"commit_tokens": ["fixed", "generated", "bug", "when", "there", "are", "multiple", "schema", "dirs"], "add_tokens": "function loadViews ( schemaDirs , str , schema , synchronousPlugins , cb ) { view = viewMinnowize ( schemaDirs , view , schema , synchronousPlugins ) ; //console.log('schemaDirs: ' + JSON.stringify(schemaDirs)) function viewMinnowize ( schemaDirs , view , schema , synchronousPlugins ) { //console.log(new Error().stack) //console.log('wrote generated: ' + schemaDirs[0] + '/view.schema.generated') fs . writeFile ( schemaDirs [ 0 ] + '/view.schema.generated' , vsStr , 'utf8' ) ;", "del_tokens": "function loadViews ( schemaDir , str , schema , synchronousPlugins , cb ) { view = viewMinnowize ( schemaDir , view , schema , synchronousPlugins ) ; function viewMinnowize ( schemaDir , view , schema , synchronousPlugins ) { fs . writeFile ( schemaDir + '/view.schema.generated' , vsStr , 'utf8' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "issues", "monitoring", "connections", "which", "don", "t", "have", "admin", "access", "to", "DB"], "add_tokens": "var docCounts = \"\" ; var activeClients = \"\" ; var pid = \"N/A\" ; var version = \"N/A\" ; var uptime = \"N/A\" ; var connections = \"\" ; var memory = \"\" ; // set the values if we can get them if ( info ) { docCounts = getDocCounts ( currDocCounts , info . metrics . document ) ; activeClients = info . globalLock . activeClients ; pid = info . pid ; version = info . version ; uptime = info . uptime ; connections = info . connections ; memory = info . mem ; } pid : pid , version : version , uptime : uptime , activeClients : activeClients , connections : connections , memory : memory ,", "del_tokens": "var docCounts = getDocCounts ( currDocCounts , info . metrics . document ) pid : info . pid , version : info . version , uptime : info . uptime , activeClients : info . globalLock . activeClients , connections : info . connections , memory : info . mem ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "flattern", "helper", "into", "an", "underscore", "mixin"], "add_tokens": "} , flattern : function ( obj ) { var x = { } ; _ . each ( obj , function ( a , b ) { x [ ( _ . isArray ( obj ) ) ? a : b ] = true ; } ) ; return x ; this . blockTypes = _ . flattern ( ( _ . isUndefined ( this . options . blockTypes ) ) ? SirTrevor . Blocks : this . options . blockTypes ) ;", "del_tokens": "/ * Given an array or object , flatten it and return only the key => true * / function flattern ( obj ) { var x = { } ; _ . each ( obj , function ( a , b ) { x [ ( _ . isArray ( obj ) ) ? a : b ] = true ; } ) ; return x ; } this . blockTypes = flattern ( ( _ . isUndefined ( this . options . blockTypes ) ) ? SirTrevor . Blocks : this . options . blockTypes ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "L", "externs", "just", "in", "case", "someone", "uses", "leaflet"], "add_tokens": "Java . type = function ( name ) { } ; / ** * leaflet . js will always create a window . L global * this can lead to very hard to debug errors in : advanced builds * https : //github.com/Leaflet/Leaflet/pull/2943 * * just reserving it always doesn 't harm builds that don' t use it * @ const * / var L = { } ;", "del_tokens": "Java . type = function ( name ) { } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "jshint", "ignore", "comments", "for", "JSX"], "add_tokens": "return ( /* jshint ignore:start */ < a onClick = { this . handleClick } { ... this . props } > { this . props . children } < / a > /* jshint ignore:end */ ) ;", "del_tokens": "return < a onClick = { this . handleClick } { ... this . props } > { this . props . children } < / a > ;", "commit_type": "add"}
{"commit_tokens": ["update", "cAF", "typo", "in", "demo"], "add_tokens": "window . cancelAnimationFrame ( gamepads . updateStatus ) ;", "del_tokens": "window . cancelRequestAnimationFrame ( gamepads . updateStatus ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "settings", "pre", "-", "dashboard", "rework"], "add_tokens": "let props = { } ;", "del_tokens": "let props = include ? Object . assign ( { } , include ) : { } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "display", "of", "param", "types", "."], "add_tokens": "fp = require ( 'lodash/fp' ) , expression = _ . get ( tag , 'expression' ) , case 'RestType' : result = '...' + result ; break ; case 'TypeApplication' : expression = undefined ; result = _ ( tag ) . chain ( ) . get ( 'applications' ) . map ( _ . flow ( reduceParamType , fp . add ( fp , '[]' ) ) ) . sort ( util . compareNatural ) . join ( '|' ) . value ( ) ; break ; . chain ( ) . join ( '|' ) . value ( ) desc = util . format ( _ . get ( tag , 'description' ) ) ,", "del_tokens": ". join ( '|' ) ; break ; case 'RestType' : result = '...' + result ; var expression = _ . get ( tag , 'expression' ) ; desc = _ . get ( tag , 'description' ) || '' ,", "commit_type": "fix"}
{"commit_tokens": ["remove", "unused", "UserAgent", ".", "WEB_VIEW", "=", "null", ";", "code"], "add_tokens": "\"AOSP\" : { \"get\" : function ( ) { return this . _AOSP ; } } , // is AOSP Stock Browser.", "del_tokens": "UserAgent [ \"WEB_VIEW\" ] = null ; \"AOSP\" : { \"get\" : function ( ) { return this . _AOSP ; } } , // is AOSP Stock UserAgent.", "commit_type": "remove"}
{"commit_tokens": ["fixed", "the", "last", "failing", "test", "on", "base", "http", "usage", "(", "thanks", "@coderarity", ")"], "add_tokens": "url : '/' + path . join ( baseDir , '404.html' ) ,", "del_tokens": "url : '/404.html' ,", "commit_type": "fix"}
{"commit_tokens": ["Changed", "constructor", "to", "use", "instanceof"], "add_tokens": "if ( ! ( this instanceof HeDate ) ) {", "del_tokens": "if ( ! this || ! this . constructor . toString ( ) . match ( / ^function HeDate\\(\\) / ) ) {", "commit_type": "change"}
{"commit_tokens": ["fixed", "issue", "with", "Blob", ".", "js", "not", "loading", "."], "add_tokens": "return this . addBowerPackageToProject ( \"file-saver\" ) . then ( function ( ) { return this . addBowerPackageToProject ( \"Blob\" ) ; } ) ;", "del_tokens": "return this . addBowerPackageToProject ( \"file-saver\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixes", "strings", "in", "modules", "import"], "add_tokens": "text += '@import \"' + sanitize ( file ) + '\";\\n' ;", "del_tokens": "text += '@import ' + sanitize ( file ) + ';\\n' ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "string", "s", "empty", "property", "true", "as", "default", "when", "is", "used", "with", "pattern"], "add_tokens": "if ( $ { schema . empty } ! == false && len === 0 ) { // Do nothing } else {", "del_tokens": "if ( $ { schema . empty } ! == true || len !== 0 ) {", "commit_type": "make"}
{"commit_tokens": ["fix", "broken", "builds", "by", "bundling", "arcgis", "-", "rest", "-", "js", "libs", "in", "vendor", ".", "js"], "add_tokens": "// at runtime amCharts loads the minified version (pdfmake.min.js) this . import ( 'vendor/@esri/arcgis-rest-request/arcgis-rest-request.umd.js' ) ; this . import ( 'vendor/@esri/arcgis-rest-feature-service/arcgis-rest-feature-service.umd.js' ) ; // copy arcgis-rest-js dist files to vendor var arcgisRestRequestTree = new Funnel ( path . dirname ( require . resolve ( '@esri/arcgis-rest-request/dist/umd/arcgis-rest-request.umd.js' ) ) , { files : [ 'arcgis-rest-request.umd.js' , 'arcgis-rest-request.umd.js.map' ] , destDir : '@esri/arcgis-rest-request' } ) ; var arcgisRestFeatureServiceTree = new Funnel ( path . dirname ( require . resolve ( '@esri/arcgis-rest-feature-service/dist/umd/arcgis-rest-feature-service.umd.js' ) ) , { files : [ 'arcgis-rest-feature-service.umd.js' , 'arcgis-rest-feature-service.umd.js.map' ] , destDir : '@esri/arcgis-rest-feature-service' } ) ; var treesToMerge = [ vendorTree , arcgisRestRequestTree , arcgisRestFeatureServiceTree , cedarTree ] ;", "del_tokens": "// at runtime amCharts loads the minified version (pdfmake.min.js) var treesToMerge = [ vendorTree , cedarTree ] ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "Map", "methods", "delete", "and", "forEach"], "add_tokens": "function getIndex ( key ) { return keys . indexOf ( key ) ; } return values [ getIndex ( key ) ] ; return getIndex ( key ) !== - 1 ; var index = getIndex ( key ) ; function deleteFunc ( key ) { var index = getIndex ( key ) ; if ( index === - 1 ) { return false ; } delete keys [ index ] ; delete values [ index ] ; return true ; } function forEach ( callback ) { keys . forEach ( function ( key , index ) { if ( key !== undefined ) { callback ( values [ index ] , key ) ; } } ) ; } delete : deleteFunc , forEach : forEach ,", "del_tokens": "return values [ keys . indexOf ( key ) ] ; return keys . indexOf ( key ) !== - 1 ; var index = keys . indexOf ( key ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "draggable", "range", "when", "floor", "is", "not", "0"], "add_tokens": "newMaxValue = this . minValue + this . dragging . difference ;", "del_tokens": "newMaxValue = this . dragging . difference ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "default", "formatter", "and", "colors", "for", "the", "outputs"], "add_tokens": "'use strict' ; getMessages : function ( ) { return this . messages ; } , hasMessages : function ( ) {", "del_tokens": "hasErrors : function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "port", ":", "1776", "to", "development", "env"], "add_tokens": "// }, port : 1776", "del_tokens": "// }", "commit_type": "move"}
{"commit_tokens": ["updated", "_filterTouchableElements", "to", "always", "return", "the", "element", "if", "it", "matches", "the", "view", "element"], "add_tokens": "Ember . Logger . debug ( 'Filtering Touchable Elements' ) ; exclude = this . get ( 'hammerExclude' ) , viewEl = this . $ ( ) [ 0 ] ; if ( element === viewEl ) { return element ; } return allowed . length ? element : false ;", "del_tokens": "exclude = this . get ( 'hammerExclude' ) ; return allowed . length ? allowed [ 0 ] : false ;", "commit_type": "update"}
{"commit_tokens": ["move", "app", "to", "cms", "to", "avoid", "clashes", "with", "the", "project", "installing", "webforge", "-", "cms"], "add_tokens": "// we pass \"our\" require here on purpose (but i have forgotten why) this . jsBuilder = new WebforgeBuilder ( gulp , { root : rootDir , dest : \"www/assets\" , moduleSearchPaths : [ cmsDir ] } , require ) ; name : \"cms/main\" name : \"cms/login\" // .registerTask('templates', { path: 'cms/Resources/tpl' }) builder . add ( 'js' , 'cms' ) . src ( cmsDir + '/src/js/cms/**/*.js' ) . pipe ( builder . dest , 'cms' )", "del_tokens": "this . jsBuilder = new WebforgeBuilder ( gulp , { root : rootDir , dest : \"www/assets\" , moduleSearchPaths : [ cmsDir ] } , rootRequire ) ; name : \"app/main\" name : \"app/login\" // .registerTask('templates', { path: 'app/Resources/tpl' }) builder . add ( 'js' , 'app' ) . src ( cmsDir + '/src/js/app/**/*.js' ) . pipe ( builder . dest , 'app' )", "commit_type": "move"}
{"commit_tokens": ["fix", "curls", "and", "link", "ref", "resolution"], "add_tokens": "var options = loaderUtils . parseQuery ( this . query ) ; var transformeredSchema = transformer ( this . inputValue [ 0 ] , options ) ;", "del_tokens": "//var query = loaderUtils.parseQuery(this.query); //var config = loaderUtils.getLoaderConfig(this, \"jsonSchemaExampleLoader\"); var transformeredSchema = transformer ( this . inputValue [ 0 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "React", ".", "isValidElement", "()", "for", "argument", "detection"], "add_tokens": "var arg2IsReactElement = props && React . isValidElement ( props )", "del_tokens": "var arg2IsReactElement = ( props && typeof props === 'object' && typeof props . ref !== 'undefined' && typeof props . props === 'object' )", "commit_type": "use"}
{"commit_tokens": ["Added", "ability", "to", "use", "jquery", "-", "templates"], "add_tokens": "paths . forEach ( function ( path , i ) { else if ( flow . jst_lang === 'jquery-tmpl' ) { var preprocess_jquery = require ( './preprocessors/jquery-tmpl.js' ) ; preprocess_jquery ( flow ) ; } console . log ( flow . _strings ) ;", "del_tokens": "paths . forEach ( function ( path , i ) {", "commit_type": "add"}
{"commit_tokens": ["removed", "dependency", "imagemin", "in", "tests", "and", "use", "a", "simple", "stub"], "add_tokens": "fileMeta . contents = '' ; return fileMeta ;", "del_tokens": "import Imagemin from 'imagemin' ; import imageminJpegoptim from 'imagemin-jpegoptim' ; return Imagemin . buffer ( fileMeta . contents , { plugins : [ imageminJpegoptim ( { size : '1%' } ) ] } ) . then ( result => { fileMeta . contents = result ; return fileMeta ; } ) . catch ( err => console . log ( err ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "to", "-", "arraybuffer", "instead", "of", "manual", "conversion"], "add_tokens": "var toArrayBuffer = require ( 'to-arraybuffer' ) return toArrayBuffer ( buffer )", "del_tokens": "if ( buffer instanceof Uint8Array ) { return buffer } else { var buf = new Uint8Array ( buffer . length ) for ( var i = 0 , len = buf . length ; i < len ; i ++ ) { buf [ i ] = buffer [ i ] } return buf }", "commit_type": "use"}
{"commit_tokens": ["used", "this", "instead", "of", "module", "exports", "within", "the", "exports"], "add_tokens": "app . use ( function attach_templates ( req , res , next ) { return next ( ) ; var self = this ; self . templates [ funcName ] = jade . compile ( fileData ) ;", "del_tokens": "app . use ( '/' , function attach_templates ( req , res , next ) { next ( ) ; module . exports . templates [ funcName ] = jade . compile ( fileData ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "handling", "of", "ranges", "schedules", "that", "never", "go", "invalid"], "add_tokens": "end ? new Date ( endDate ? Math . min ( end , endDate ) : end ) : undefined end ? new Date ( Math . min ( startDate , next . getTime ( ) + later . SEC ) ) : undefined if ( ! end ) break ; // last iteration valid until the end of time function ( a , b ) { return ! b || ( a . getTime ( ) > b . getTime ( ) ) ; } : function ( a , b ) { return ! a || ( b . getTime ( ) > a . getTime ( ) ) ; } ;", "del_tokens": "new Date ( endDate ? Math . min ( end , endDate ) : end ) new Date ( Math . min ( startDate , next . getTime ( ) + later . SEC ) ) function ( a , b ) { return a . getTime ( ) > b . getTime ( ) ; } : function ( a , b ) { return b . getTime ( ) > a . getTime ( ) ; } ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "option", "to", "async", "inject", "scripts"], "add_tokens": "function getScript ( url , async , cb ) { if ( typeof async === 'function' ) { cb = async ; async = false ; } // Should the script be loaded asynchronously? if ( async ) el . async = true ;", "del_tokens": "function getScript ( url , cb ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "requirement", "of", "fs"], "add_tokens": "var model = null ; try { model = require ( './assembler/' + type ) ; } catch ( e ) { console . log ( 'ERROR' , e ) ; } return model ; //console.log(assembler.getType('foo')); //console.log(''); //console.log('baseassembler', assembler.getType('baseassembler')); //console.log(''); //console.log('bidassembler', assembler.getType('bidassembler'));", "del_tokens": "var fs = require ( 'fs' ) ; / ** * @ type { object } * @ private * / _types : ( function ( ) { var obj = { } ; var path = './assembler/' ; fs . readdirSync ( path ) . forEach ( function ( f ) { var name = f . split ( '.' ) [ 0 ] ; obj [ name ] = require ( path + f ) ; } ) ; return obj ; } ) ( ) , return this . _types [ type ] || null ; console . log ( assembler . getType ( 'foo' ) ) ; console . log ( '' ) ; console . log ( 'baseassembler' , assembler . getType ( 'baseassembler' ) ) ; console . log ( '' ) ; console . log ( 'bidassembler' , assembler . getType ( 'bidassembler' ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "path", "for", "one", "of", "the", "imports"], "add_tokens": "var Connection = require ( parentDir . dirname ( currentDir ) + '/dist/api/connection' ) . Connection", "del_tokens": "var Connection = require ( '../dist/api/connection' ) . Connection", "commit_type": "fix"}
{"commit_tokens": ["fix", "ms", "(", "100", ")", "etc", "that", "I", "broke"], "add_tokens": "var m = / ^((?:\\d+)?\\.?\\d+) *(ms|seconds?|s|minutes?|m|hours?|h|days?|d|years?|y)?$ / i . exec ( str ) ; var type = ( m [ 2 ] || 'ms' ) . toLowerCase ( ) ;", "del_tokens": "var m = / ^((?:\\d+)?\\.?\\d+) *(ms|seconds?|s|minutes?|m|hours?|h|days?|d|years?|y)$ / i . exec ( str ) ; var type = m [ 2 ] . toLowerCase ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "implode", "to", "remove", "#$path", "properties", "after", "implosion"], "add_tokens": ", referenced = [ ] configurable : true referenced . push ( val ) var result = traverse ( obj , [ '#' ] ) , q , ref while ( ( ref = referenced . shift ( ) ) ) delete ref [ '$path' ]", "del_tokens": "writable : true var result = traverse ( obj , [ '#' ] ) , q", "commit_type": "make"}
{"commit_tokens": ["using", "double", "-", "star", "in", "$select"], "add_tokens": "const selection = { $select : params . $select } ; const selectTail = fp . pipe ( fp . map ( splitTail ) , // remove the head fp . tap ( debug ) , fp . reject ( fp . isEmpty ) , // remove empty fp . tap ( debug ) , fp . when ( fp . complement ( fp . isEmpty ) , fp . append ( '*' ) ) // add * for non-empty ) ; // $select with * for next populate level params . $select = selectTail ( params . $select ) ;", "del_tokens": "const selection = { $select : params . query . $select } ; // $select for next populate level params . $select = fp . reject ( fp . isEmpty , fp . map ( splitTail , params . $select || [ ] ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "multiple", "parameters", "on", "server", "and", "in", "test", "app"], "add_tokens": "commandSpec . parameters . forEach ( function ( param ) { var paramVal = config [ param . name ] ; if ( param . type && param . type == 'multi' ) { href += '&' + param . name + '=' + encodeURI ( paramVal [ i ] ) ; href += '&' + param . name + '=' + encodeURI ( paramVal ) ; } ) //console.log(reqOptions)", "del_tokens": "if ( commandSpec . parameter ) { var paramVal = config [ commandSpec . parameter . name ] ; if ( commandSpec . parameter . type && commandSpec . parameter . type == 'multi' ) { href += '&' + commandSpec . parameter . name + '=' + encodeURI ( paramVal [ i ] ) ; href += '&' + commandSpec . parameter . name + '=' + encodeURI ( paramVal ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "on", "RPC", "namespace", "."], "add_tokens": "constructor ( ) { RPC : { rpc : {", "del_tokens": "constructor ( ) { rpc : { RPC : {", "commit_type": "fix"}
{"commit_tokens": ["fix", "cwd", "/", "options", "in", "resolve", "tests"], "add_tokens": "assert ( generate . resolve ( 'a' , { cwd : fixtures ( ) } ) ) ; assert ( generate . resolve ( 'a' , { cwd : fixtures ( ) } ) ) ; var fp = generate . resolve ( 'a' , { cwd : fixtures ( ) } ) ;", "del_tokens": "assert ( generate . resolve ( 'a' , fixtures ( ) ) ) ; assert ( generate . resolve ( 'a' , fixtures ( ) ) ) ; var fp = generate . resolve ( 'a' , fixtures ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "more", "robust", "forge", "implementation", "for", "getPemBody", "()", "and", "splitPemChain", "()", "move", "to", "crypto", "module"], "add_tokens": "const forge = require ( './crypto/forge' ) ; const body = forge . getPemBody ( csr ) ; const body = forge . getPemBody ( cert ) ;", "del_tokens": "const body = util . getPemBody ( csr ) ; const body = util . getPemBody ( cert ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "test", "for", "source", "+", "readable"], "add_tokens": "if ( source && ! readable ) readable = createReadStream ( source ) readable . pipe ( process . stdout ) await handleWriteStream ( destination , readable , source ) const handleWriteStream = async ( destination , readable , source ) => { if ( readable . path == destination || source == destination ) {", "del_tokens": "if ( source ) readable = createReadStream ( source ) readable . pipe ( writable ) await handleWriteStream ( destination , readable ) const handleWriteStream = async ( destination , readable ) => { if ( readable instanceof ReadStream && readable . path == destination ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "some", "bugs", ";", "added", "some", "tests", ";", "performance", "improvements"], "add_tokens": "/ *_this.remove(i + array.length, { } ) ; * /", "del_tokens": "_this . remove ( i + array . length , { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "http", "/", "https", "request", "in", "real", "world", "."], "add_tokens": ", https = require ( 'https' ) this . httpClient = { http : http , https : https }", "del_tokens": "this . httpClient = http ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "table", "-", "driven", "tests", "to", "be", "skipped"], "add_tokens": "'present tense' ] , skip : true var itFn = t . skip ? it . skip : it ; itFn ( util . format ( 'should have %d error(s)' , errNo ) , function ( ) { itFn ( util . format ( 'should have %d warning(s)' , warNo ) , function ( ) { itFn ( 'should have the correct title' , function ( ) { itFn ( 'should have the correct body' , function ( ) { itFn ( 'should validate imperative present tense' ) ; itFn ( 'should identify github issues correctly' ) ;", "del_tokens": "'present tense' ] it ( util . format ( 'should have %d error(s)' , errNo ) , function ( ) { it ( util . format ( 'should have %d warning(s)' , warNo ) , function ( ) { it ( 'should have the correct title' , function ( ) { it ( 'should have the correct body' , function ( ) { it ( 'should validate imperative present tense' ) ; it ( 'should identify github issues correctly' ) ;", "commit_type": "allow"}
{"commit_tokens": ["Improve", "detection", "of", "cjs", "global"], "add_tokens": "var globalExp = / global / ;", "del_tokens": "var globalExp = / global\\. / ;", "commit_type": "improve"}
{"commit_tokens": ["Use", "_read32", "for", "32", "-", "bit", "nodes", "because", "it", "needs", "to", "be", "unsigned"], "add_tokens": "return this . _read32 ( idx ) ; return this . _read32 ( idx + 4 ) ;", "del_tokens": "return concat4 ( this . _read ( idx ++ ) , this . _read ( idx ++ ) , this . _read ( idx ++ ) , this . _read ( idx ++ ) ) ; idx += 4 ; return concat4 ( this . _read ( idx ++ ) , this . _read ( idx ++ ) , this . _read ( idx ++ ) , this . _read ( idx ++ ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "GET", "request", "handling", "in", "SPARQL", "proxy"], "add_tokens": "query = req . query . query ;", "del_tokens": "query = req . param . query ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "non", "empty", "contentTypes", "add", "test", "case"], "add_tokens": "for ( var i = 0 ; i < specReq . headers . length ; i ++ ) { if ( / content\\-type / i . test ( specReq . headers [ i ] . name ) ) { return getMediaType ( specReq . headers [ i ] . value ) ; } var httpMediaType = getMediaTypeFromHttpReq ( httpReq ) ; var specMediaType = getMediaTypeFromSpecReq ( specReq ) ; if ( httpMediaType === specMediaType ) { if ( isBodyEqual ( httpReq , specReq , httpMediaType ) ) { console . warn ( 'Skip. Different content-types ' , httpMediaType , \" !== \" , specMediaType ) ;", "del_tokens": "specReq . headers . forEach ( function ( r , header ) { if ( / content\\-type / i . test ( header . name ) ) { return getMediaType ( header . value ) ; } ) ; function isContentTypeEqual ( httpReq , specReq ) { return getMediaTypeFromSpecReq ( specReq ) === getMediaTypeFromHttpReq ( httpReq ) ; } if ( isContentTypeEqual ( httpReq , specReq ) ) { if ( isBodyEqual ( httpReq , specReq , getMediaTypeFromHttpReq ( httpReq ) ) ) { console . warn ( 'Skip. Different content-types' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "frame", "count", "property", "to", "Scene"], "add_tokens": "/ ** * @ type { Number } * / this . frameCount = 0 ; super . render ( this . ctx ) ; ++ this . frameCount ; this . fire ( new BaseEvent ( this , \"draw\" ) ) ; return this ;", "del_tokens": "this . fire ( new BaseEvent ( this , \"draw\" ) ) ; return super . render ( this . ctx ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "JSHint", "and", "nice", "reporter"], "add_tokens": "this . filters [ name ] = filter ;", "del_tokens": "filters [ name ] = filter ;", "commit_type": "use"}
{"commit_tokens": ["Move", "schemas", "to", "jskos", "repository"], "add_tokens": "resource : require ( \"./jskos/schemas/resource.schema.json\" ) , item : require ( \"./jskos/schemas/item.schema.json\" ) , concept : require ( \"./jskos/schemas/concept.schema.json\" ) , scheme : require ( \"./jskos/schemas/scheme.schema.json\" ) , mapping : require ( \"./jskos/schemas/mapping.schema.json\" ) , concordance : require ( \"./jskos/schemas/concordance.schema.json\" ) , registry : require ( \"./jskos/schemas/registry.schema.json\" ) , distribution : require ( \"./jskos/schemas/distribution.schema.json\" ) , occurrence : require ( \"./jskos/schemas/occurrence.schema.json\" ) , conceptBundle : require ( \"./jskos/schemas/conceptBundle.schema.json\" )", "del_tokens": "resource : require ( \"./schemas/resource.schema.json\" ) , item : require ( \"./schemas/item.schema.json\" ) , concept : require ( \"./schemas/concept.schema.json\" ) , scheme : require ( \"./schemas/scheme.schema.json\" ) , mapping : require ( \"./schemas/mapping.schema.json\" ) , concordance : require ( \"./schemas/concordance.schema.json\" ) , registry : require ( \"./schemas/registry.schema.json\" ) , distribution : require ( \"./schemas/distribution.schema.json\" ) , occurrence : require ( \"./schemas/occurrence.schema.json\" ) , conceptBundle : require ( \"./schemas/conceptBundle.schema.json\" )", "commit_type": "move"}
{"commit_tokens": ["Removed", "unused", "ENV_VARS", ".", "APIFY_INTERNAL_PORT", "constant", "renamed", "ACT_RESTART_ON_ERROR", "to", "ACTOR_RESTART_ON_ERROR", "DOCKER_LABELS", ".", "ACT_XXX", "to", "DOCKER_LABELS", ".", "ACTOR_XXX"], "add_tokens": "ACTOR_BUILD_ID : 'com.apify.actBuildId' , ACTOR_RUN_ID : 'com.apify.actRunId' , // Kept for backwards compatibility, will be removed soon export const ACTOR_RESTART_ON_ERROR = { / ** * Kept for backwards compatibility , will be removed soon . * / export const ACT_RESTART_ON_ERROR = ACTOR_RESTART_ON_ERROR ;", "del_tokens": "export const ACT_RESTART_ON_ERROR = { // NOTE: These two are deprecated and shouldn't be used. INTERNAL_PORT : 'APIFY_INTERNAL_PORT' ,", "commit_type": "remove"}
{"commit_tokens": ["added", "feature", "and", "unit", "test", "for", "ajaxIncludeFilter", "event", "which", "allows", "modification", "of", "ajax", "response", "before", "it", "is", "appended", "to", "DOM", ".", "Currently", "undocumented", "."], "add_tokens": "$ . get ( url , function ( data ) { els . trigger ( \"ajaxIncludeResponse\" , [ data ] ) ; . bind ( \"ajaxIncludeResponse\" , function ( e , data ) { var content = data ; var subset = content . match ( new RegExp ( \"<entry url=[\\\"']*\" + el . data ( \"url\" ) + \"['\\\"]*>(?:(?!</entry>)(.|\\n))*\" , \"gmi\" ) ) ; if ( subset ) { content = subset [ 0 ] ; } var filteredContent = el . triggerHandler ( \"ajaxIncludeFilter\" , [ content ] ) ; if ( filteredContent ) { content = filteredContent ; } el [ el . data ( \"method\" ) ] ( content ) . trigger ( \"ajaxInclude\" , [ content ] ) ;", "del_tokens": "$ . get ( url , function ( data ) { els . trigger ( \"ajaxInclude\" , [ data ] ) ; . bind ( \"ajaxInclude\" , function ( e , data ) { var content = $ ( data ) ; content = content . filter ( \"entry[url=\\\"\" + $ ( this ) . data ( \"url\" ) + \"\\\"]\" ) . html ( ) ; el [ el . data ( \"method\" ) ] ( content ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "unresolved", "parent", "operators", "."], "add_tokens": "if ( p ) { df . connect ( p , [ op ] ) ; op . targets ( ) . add ( p ) ; } else { ( ctx . unresolved = ctx . unresolved || [ ] ) . push ( function ( ) { p = ctx . get ( spec . parent . $ref ) ; df . connect ( p , [ op ] ) ; op . targets ( ) . add ( p ) ; } ) ; } resolve : function ( ) { ( this . unresolved || [ ] ) . forEach ( function ( fn ) { fn ( ) ; } ) ; delete this . unresolved ; return this ; } ,", "del_tokens": "df . connect ( p , [ op ] ) ; op . targets ( ) . add ( p ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "clobbering", "of", "the", "ManagerWrapper", "prototype", "when", "multiple", "datasets", "are", "managed", "."], "add_tokens": "self [ methodName ] = function ( ) {", "del_tokens": "ManagerWrapper . prototype [ methodName ] = function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "set", "of", "unit", "tests", "also", "minor", "cleanup"], "add_tokens": "'test/**/*.spec.js' 'test/**/*.spec.js' : [ 'webpack' ] // add preprocessor to the files that should be // processed via browserify // preprocessors: { // 'test/*.spec.js': [ 'browserify' ] // },", "del_tokens": "'test/*.spec.js' 'test/*.spec.js' : [ 'webpack' ] // add preprocessor to the files that should be // processed via browserify // preprocessors: { // 'test/*.spec.js': [ 'browserify' ] // },", "commit_type": "add"}
{"commit_tokens": ["fix", "small", "mistake", "in", "syntax"], "add_tokens": "} ;", "del_tokens": "} ,", "commit_type": "fix"}
{"commit_tokens": ["adding", "cross", "-", "env", "and", "appveyor"], "add_tokens": "loader : 'babel' , warnings : false , } , config . devtool = null ; module . exports = createConfig ( process . env . NODE_ENV === 'production' ) ;", "del_tokens": "loader : 'babel' warnings : false } config . devtool = null module . exports = createConfig ( process . env . NODE_ENV === 'production' )", "commit_type": "add"}
{"commit_tokens": ["Added", "jwt", "-", "token", "header", "handler", "for", "custom", "auth"], "add_tokens": "if ( req . headers . hasOwnProperty ( key ) ) { return req . headers [ key ] ; } return null ; req . authorization . credentials = getHeaderValue ( req , prefix + 'jwt-token' ) ; req . username = req . authorization . bearer . username ;", "del_tokens": "return req . headers [ key ] ; req . authorization . credentials = '' ; req . username = req . authorization . bearer . username ;", "commit_type": "add"}
{"commit_tokens": ["make", "ClayConfig", ".", "destroy", "()", "return", "self"], "add_tokens": "* @ returns { ClayConfig } return self ;", "del_tokens": "* @ return { void }", "commit_type": "make"}
{"commit_tokens": ["added", "refresh", "as", "race", "bug", "on", "circleci"], "add_tokens": "errMsg = 'FATAL ERROR starting selenium: ' + data + ' is java runtime installed?' ;", "del_tokens": "errMsg = 'FATAL ERROR starting selenium: ' + data ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "send", "keydown", "events", "to", "the", "outside", "."], "add_tokens": "this . publicAPI = { open : this . open . bind ( this ) , close : this . close . bind ( this ) , toggle : this . _actions . toggle . bind ( this ) } ; registerActionsInParent ( this . publicAPI ) ; let onKeydown = this . get ( 'onKeydown' ) ; if ( onKeydown ) { onKeydown ( this . publicAPI , e ) ; } if ( e . defaultPrevented ) { return ; }", "del_tokens": "registerActionsInParent ( { open : this . open . bind ( this ) , close : this . close . bind ( this ) , toggle : this . _actions . toggle . bind ( this ) } ) ; didInsertElement ( ) { this . _super ( ... arguments ) ; this . element . addEventListener ( 'dropdown:toggle' , e => this . toggle ( e ) ) ; this . element . addEventListener ( 'dropdown:open' , e => this . open ( e ) ) ; this . element . addEventListener ( 'dropdown:close' , e => this . close ( e , true ) ) ; } , let onKeydown = this . get ( 'onKeydown' ) ; if ( onKeydown ) { onKeydown ( e ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Added", "callback", "on", "completing", "each", "page", "testing"], "add_tokens": "} ) ;", "del_tokens": "} )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "windows", "resource", "busy", "bug"], "add_tokens": "const { promisify } = require ( 'util' ) const rename = promisify ( fs . rename ) const sleep = promisify ( setTimeout ) await renameSafe ( path . join ( args . workingDir , isolateLog ) , isolateLogPath ) async function renameSafe ( from , to , tries = 0 ) { try { await rename ( from , to ) } catch ( e ) { if ( tries > 5 ) { throw e } await sleep ( 1000 ) await renameSafe ( from , to , tries ++ ) } } }", "del_tokens": "fs . renameSync ( path . join ( args . workingDir , isolateLog ) , isolateLogPath ) }", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "|", "populate", "all", "the", ".", "js", "files", "which", "export", "code"], "add_tokens": "fs . writeFileSync ( ` ${ TEST_PATH } ${ fileName } ${ fileName } ` , exportFile ) ;", "del_tokens": "fs . writeFileSync ( ` ${ TEST_PATH } ${ fileName } ${ fileName } ` , exportFile ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "in", "string", "method", "split"], "add_tokens": "return fix_umlauts ( name . split ( ' ' ) . join ( glue ) ) ;", "del_tokens": "return fix_umlauts ( name . splite ( ' ' ) . join ( glue ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "test", "for", "exported", "errors"], "add_tokens": "ErrorLocked : require ( './locked.error.js' ) , ErrorUnauthorized : require ( './unauthorized.error.js' )", "del_tokens": "ErrorUnauthorized : require ( './unauthorized.error.js' ) , ErrorLocked : require ( './locked.error.js' )", "commit_type": "add"}
{"commit_tokens": ["add", "not", "contain", "mod1", "content", "test", "case"], "add_tokens": "outputFile = path . resolve ( distPath , 'package1/alias.js' ) ; it ( 'should contain mod2 contents.' , function ( ) { it ( 'should not contain mod1 contents' , function ( ) { var outputContent = fs . readFileSync ( outputFile ) ; / \\[mod1 / . test ( outputContent ) . should . equal ( false ) ; } ) ;", "del_tokens": "outputFile = path . resolve ( distPath , 'package1/aliasjs' ) ; dep . type . should . equal ( 'css' ) ; it ( 'should have mod2 contents.' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["removed", "pipe_utils", ".", "pipe", "is", "now", "like", "underscore"], "add_tokens": "var t = pipe . myText ( ) . replace ( \"|\" , \"_\" ) . replace ( / / g , \"\" ) tokens = Token . ize ( t + \".\" + pipe . pipe_function )", "del_tokens": "var t = pipe . myText ( ) . replace ( \"|\" , \"__\" ) . replace ( / / g , \"\" ) tokens = Token . ize ( t + \".\" + pipe . pipe_function + \".call\" ) tokens . append ( \"this, \" )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "unused", "import", "on", "router", ".", "js", "fixed", "nineplate", "to", "allow", "better", "amd", "widgets", "integration"], "add_tokens": "define ( [ '../core/array' , '../core/deferredUtils' , '../core/ext/Evented' , '../core/ext/Properties' , '../core/extend' , '../core/on' , './hash' ] , function ( array , def , Evented , Properties , extend , on , hash ) {", "del_tokens": "define ( [ '../core/objUtils' , '../core/extend' , '../core/ext/Evented' , '../core/ext/Properties' , './hash' , '../core/on' , '../core/array' , '../core/deferredUtils' ] , function ( objUtils , extend , Evented , Properties , hash , on , array , def ) {", "commit_type": "fix"}
{"commit_tokens": ["Change", "whitespace", "syntax", "files", "to", "use", ".", "styl", "extension"], "add_tokens": "return path . extname ( file ) === '.styl' ? whitespace ( css ) : css", "del_tokens": "return path . extname ( file ) === '.wcss' ? whitespace ( css ) : css", "commit_type": "change"}
{"commit_tokens": ["Make", "UTs", "pass", "in", "IE9"], "add_tokens": "var context = { aContext : true } ;", "del_tokens": "var context = 3 ;", "commit_type": "make"}
{"commit_tokens": ["removed", "testing", "schema", ".", "txt"], "add_tokens": "//require('fs').writeFileSync('schema.txt', JSON.stringify(simplifiedSchema, null, 2))", "del_tokens": "require ( 'fs' ) . writeFileSync ( 'schema.txt' , JSON . stringify ( simplifiedSchema , null , 2 ) )", "commit_type": "remove"}
{"commit_tokens": ["Use", "writeFileSync", "to", "write", "to", "out", "file"], "add_tokens": "const ConcatStream = require ( 'concat-stream' ) : ConcatStream ( writeOutFile ) function writeOutFile ( buffer ) { fs . writeFileSync ( outFile , buffer ) }", "del_tokens": ": fs . createWriteStream ( outFile )", "commit_type": "use"}
{"commit_tokens": ["Removes", "div", "from", "pug", "output"], "add_tokens": "let str = node . tagName === 'DIV' ? '' : node . tagName . toLowerCase ( )", "del_tokens": "let str = node . tagName . toLowerCase ( )", "commit_type": "remove"}
{"commit_tokens": ["move", "project", "sync", "into", "the", "VFS", "server", "and", "the", "docker", "daemon"], "add_tokens": "if ( res . json ) return next ( ) ;", "del_tokens": "if ( res . json ) return next ( ) ; ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "Internet", "Explorer", "<", "9"], "add_tokens": "var matches = rgb . match ( / ^rgb\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)$ / ) ; if ( matches === null ) { // Fix for Internet Explorer < 9 // Variable rgb is already a hexadecimal value return rgb ; } else { return \"#\" + hex ( matches [ 1 ] ) + hex ( matches [ 2 ] ) + hex ( matches [ 3 ] ) ; }", "del_tokens": "rgb = rgb . match ( / ^rgb\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)$ / ) ; return \"#\" + hex ( rgb [ 1 ] ) + hex ( rgb [ 2 ] ) + hex ( rgb [ 3 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["removing", "jsfeat", "legacy", "on", "export"], "add_tokens": "window . convnetjs = lib ; // in ordinary browser attach library to window", "del_tokens": "window . jsfeat = lib ; // in ordinary browser attach library to window", "commit_type": "remove"}
{"commit_tokens": ["Add", "missing", "trailing", "semi", "-", "colons", "in", "doc", "examples"], "add_tokens": "* df . groupBy ( \"department\" ) . agg ( F . max ( \"age\" ) , F . sum ( \"expense\" ) ) ;", "del_tokens": "* df . groupBy ( \"department\" ) . agg ( F . max ( \"age\" ) , F . sum ( \"expense\" ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "tests", "robust", "against", "IE", "problems"], "add_tokens": "[ \"/h2[2]\" , 0 , \"/p[4]\" , 0 , \"Header Level 2\\n Mauris lacinia ipsum nulla, id iaculis quam egestas quis.\" , \"No text node at the end and offset 0\" ] ,", "del_tokens": "[ \"/h2[2]\" , 0 , \"/p[4]\" , 0 , \"Header Level 2\\n Mauris lacinia ipsum nulla, id iaculis quam egestas quis.\\n\" , \"No text node at the end and offset 0\" ] ,", "commit_type": "make"}
{"commit_tokens": ["Remove", "unwanted", "Start", "log", "."], "add_tokens": "logSeparation ( ) ; logSeparation ( ) ; function logSeparation ( ) { console . log ( \"\\n\\n =================================\\n\" ) ; }", "del_tokens": "console . log ( '\\nStart\\n' ) ; console . log ( \"\\n\\n =================================\\n\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["update", "Resolutor", ".", "resolve", "()", "to", "only", "resolve", "first", "encounter"], "add_tokens": "// ensure to only resolve first matching literal // because we're processing left to right for ( let i = 0 ; i < _body . length ; i += 1 ) { let literal = _body [ i ] ; // add remaining body literals for ( let j = i + 1 ; j < _body . length ; j += 1 ) { literal = _body [ j ] ; unresolvedBodyLiterals . push ( literal ) ; } break ; }", "del_tokens": "_body . forEach ( ( literal ) => { } ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "resolve", ".", "jsx", "files"], "add_tokens": "modules : [ path . resolve ( __dirname , \"src\" ) , \"node_modules\" ] , extensions : [ \".js\" , \".json\" , \".jsx\" ] ,", "del_tokens": "modules : [ path . resolve ( __dirname , \"./src\" ) , \"node_modules\" , ] , extensions : [ \".js\" , \".json\" , \"jsx\" , ] ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "boolean", "return", "value", "to", "Entity", ".", "remove"], "add_tokens": "* * Returns true , if an entity was deleted . Notice that it only makes sense * to read the return value if calling with ` ` set . } ) . then ( function ( ) { return true ; } , function ( err ) { return false ;", "del_tokens": "} ) . catch ( function ( err ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "getter", "/", "setter", "when", "source", "is", "not", "getter", "/", "setter"], "add_tokens": "target [ property ] = source [ property ] ;", "del_tokens": "target . __defineGetter__ ( property , ( ) => { return source [ property ] ; } ) ; if ( descriptor . writable ) { target . __defineSetter__ ( property , val => { source [ property ] = val ; } ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Update", "to", "v1", "after", "fixing", "demo", "pages"], "add_tokens": "/** @type {Number[]} - Safari's 4-channel map for AAC codec. */", "del_tokens": "/** @type {Number[]} - Safari's 4-channel map. */", "commit_type": "update"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "Length", "doesn", "t", "not", "work", "properly", "when", "minlength", "and", "maxlength", "come", "in", "a", "strings", "."], "add_tokens": "this . min = parseInt ( boundaries . min ) ; this . max = parseInt ( boundaries . max ) ;", "del_tokens": "this . min = boundaries . min ; this . max = boundaries . max ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "supernode", ":", "require", "bug"], "add_tokens": "eventBus . on ( 'headless_wallet_ready' , function ( ) { readSingleWallet ( function ( address ) { my_address = address ; } ) ;", "del_tokens": "readSingleWallet ( function ( address ) { my_address = address ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "keyname", "argument", "in", "constructor"], "add_tokens": "it ( 'accepts root path as argument' , function ( ) { expect ( tree . rootPath ) . to . equal ( './hello' ) ; expect ( tree . rootPath ) . to . equal ( '.' ) ;", "del_tokens": "it ( 'accepts root path or options object as argument' , function ( ) { expect ( tree . settings . rootpath ) . to . equal ( './hello' ) ; var _tree = new Wiretree ( { rootpath : './hello' } ) ; expect ( _tree . settings . rootpath ) . to . equal ( './hello' ) ; expect ( tree . settings . rootpath ) . to . equal ( '.' ) ; } ) ; it ( 'set exports keyname as \"wiretree\" by default' , function ( ) { var tree = new Wiretree ( ) ; expect ( tree . settings . keyname ) . to . equal ( 'wiretree' ) ; } ) ; it ( 'set root path from options argument' , function ( ) { var tree = new Wiretree ( { rootpath : './hello' } ) ; expect ( tree . settings . rootpath ) . to . equal ( './hello' ) ; } ) ; it ( 'set exports keyname from options argument' , function ( ) { var tree = new Wiretree ( { keyname : '_tree' } ) ; expect ( tree . settings . keyname ) . to . equal ( '_tree' ) ;", "commit_type": "remove"}
{"commit_tokens": ["adding", "link", "to", "mapbox", "style", "spec", "for", "saved", "map"], "add_tokens": "< h2 > To < a href = \"https://www.mapbox.com/mapbox-gl-js/style-spec/\" > MapBox Style Specification < / a > < / h2 >", "del_tokens": "< h2 > To .json: < / h2 >", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "single", "click", "zoom"], "add_tokens": "// if the zoom region is tiny, the user clicked instead of clicking // and dragging. In this case, just make the zoom region half of the timeline, // centered around where they clicked var zoomFactor = 2.0 ; // Also, if the zoomFactor was predetermined as a result of the user clicking // rather than clicking and dragging, use that value timeline . zoomFactor ( zoomFactor ? zoomFactor : 0.75 * width / selectWidth ) ;", "del_tokens": "timeline . zoomFactor ( 0.75 * width / selectWidth ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "the", "format", "of", "the", "docs", "a", "bit", "and", "fixed", "the", "generator"], "add_tokens": "params = params || { } ; params . cwd = path . resolve ( __dirname , '../' ) ; this . run ( params , done ) ; task . apply ( tasks , args ) ;", "del_tokens": "task . apply ( null , args ) ;", "commit_type": "improve"}
{"commit_tokens": ["adds", "sinon", "for", "stubbing", "and", "uses", "it", "in", "test", "case"], "add_tokens": "var sinon = require ( 'sinon' ) ; // NOTE: the middleware has to check the verification token, poweredBy headers var expectedSyncResponse ; var expectedAsyncRequest ; var adapter = this . adapter ; expectedAsyncRequest = new Promise ( function ( resolve , reject ) { sinon . stub ( adapter . axios , 'post' ) . callsFake ( function ( url , body ) { try { assert . equal ( url , requestPayload . response_url ) ; assert . deepEqual ( body , replacement ) ; resolve ( ) ; } catch ( error ) { reject ( error ) ; } } ) ; } ) ; expectedSyncResponse = Promise . resolve ( dispatchResponse . content ) return Promise . all ( [ expectedSyncResponse , expectedAsyncRequest ] ) ;", "del_tokens": "// NOTE: the middleware has to check the verification token // TODO: introduce nock to capture the request to the `response_url` return Promise . resolve ( dispatchResponse . content )", "commit_type": "add"}
{"commit_tokens": ["fixed", "css", "file", "list", "when", "routing", "on", "client"], "add_tokens": "'renderer' , 'context' , 'utils/cmpProcessor' , 'requestFilters' , 'resolver/file' , 'jquerycookie' function ( $ , _ , rehydrate , prune , state , doc , prime , renderer , Context , cmpProcessor , filter , file ) { LAZO . logger . warn ( '[client.post.destroy] Error while destroying component' , ctl , e ) ; var controllers ; var cmpCss ; } else { // get a list of components in the new page context controllers = _ . map ( renderer . getList ( 'component' , ctl ) , function ( ctl ) { return ctl . name ; } ) ; // get list of files for the components and filter by file extension cmpCss = file . getComponentFiles ( controllers , function ( fileName ) { return fileName . substr ( - 4 , 4 ) === '.css' ; } ) ; // set paths to absolute cmpCss = _ . map ( cmpCss , function ( cssLink ) { return '/' + cssLink ; } ) ; // remove old component css ctx . _rootCtx . dependencies . css = state . cleanUpCssDependencies ( ctx . _rootCtx . dependencies . css , cmpCss ) ;", "del_tokens": "'renderer' , 'context' , 'utils/cmpProcessor' , 'requestFilters' , 'jquerycookie' function ( $ , _ , rehydrate , prune , state , doc , prime , renderer , Context , cmpProcessor , filter ) { LAZO . logger . log ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "expo", "constants", "package", "to", "obtain", "statusbarHeight"], "add_tokens": "import Constants from 'expo-constants' return Constants . statusBarHeight + 6 ;", "del_tokens": "return global . Expo . Constants . statusBarHeight + 6 ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "non", "existing", "file", "from", "gruntfile", ".", "js", "."], "add_tokens": "files : [ './stampit.js' , './test/stampit-specs.js' , './mixer.js' ] ,", "del_tokens": "files : [ './stampit.js' , './test/stampit-specs.js' , './mixer.js' , './merger.js' ] ,", "commit_type": "remove"}
{"commit_tokens": ["added", "local", "compare", "file", "pointers"], "add_tokens": "$http . get ( './config.json' ) ) $scope . testPairs . push ( new testPairObj ( '../' + o . local_reference , '../' + o . local_test , null , o ) ) ;", "del_tokens": "$http . get ( './' + ( params . path || 'config.json' ) ) $scope . testPairs . push ( new testPairObj ( '../' + o . reference , '../' + o . test , null , o ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "non", "-", "ssl", "tests", "to", "allow", "setting", "debug", "to", "false"], "add_tokens": "config . debug = true ; // allow log verification", "del_tokens": "config . instrumental . debug = true ; // allow log verification", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "in", "the", "column", "labels", "where", "the", "y", "key", "was", "used", "by", "default", "and", "it", "instead", "should", "have", "been", "the", "value", "key", ".", "Additionally", "this", "commit", "makes", "the", "stacked", "column", "connectors", "work", "for", "stacked", "row", "charts", "as", "well", "."], "add_tokens": "return d3 . format ( '' ) . call ( this , d [ this . valueKey ] ) ;", "del_tokens": "return d3 . format ( '' ) . call ( this , d [ this . y . $key ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "options", ".", "customFilters", "."], "add_tokens": "expected = compatHtml ( expected , options . noInterWS , sortAttributes , fixZWS , options . fixStyles , fixNbsp , options . noTempElements , options . customFilters ) ; actual = compatHtml ( actual , options . noInterWS , sortAttributes , fixZWS , options . fixStyles , fixNbsp , options . noTempElements , options . customFilters ) ; } ) ( window , bender ) ;", "del_tokens": "expected = compatHtml ( expected , options . noInterWS , sortAttributes , fixZWS , options . fixStyles , fixNbsp , options . noTempElements ) ; actual = compatHtml ( actual , options . noInterWS , sortAttributes , fixZWS , options . fixStyles , fixNbsp , options . noTempElements ) ; } ) ( window , bender ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "type", "info", "to", "example"], "add_tokens": "/ ** * @ example is a multiline annotation * check if there is something on the first line and use it as the type information * * @ example html * < div > < / div > * / var example = { type : 'scss' , // Default to scss code : text } ; // Get the optional type info var optionalType = text . substr ( 0 , text . indexOf ( '\\n' ) ) ; if ( optionalType . length !== 0 ) { example . type = optionalType ; example . code = text . substr ( optionalType . length + 1 ) ; // Remove the type } // remove all leading/trailing line breaks. example . code = example . code . replace ( / ^\\n|\\n$ / g , '' ) ; return example ;", "del_tokens": "return text ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "user", "fetcher", "methods", "that", "can", "be", "added", "in", "the", "service", "config", "to", "retreive"], "add_tokens": "const userService = require ( './services/user' ) ; . then ( users => userService . fetchUsers ( users , req . options , req . campsi ) ) . then ( fetchedUsers => helpers . json ( res , fetchedUsers ) ) . then ( users => userService . fetchUsers ( users , req . options , req . campsi ) ) . then ( users => userService . fetchUsers ( users , req . options , req . campsi ) )", "del_tokens": ". then ( result => helpers . json ( res , result ) )", "commit_type": "add"}
{"commit_tokens": ["Updated", "lib", "/", "partition", ":", "Impl", ".", "extended", "boolean"], "add_tokens": "return // MS Extended Partition (CHS) this . type === 0x05 || // MS Extended Partition (LBA) this . type === 0x0F || // Linux Extended Partition this . type === 0x85 || // Other Extended Partition Types // Hidden this . type === 0x15 || this . type === 0x1F || this . type === 0x91 || this . type === 0x9B || // Access-restricted this . type === 0x5E || this . type === 0x5F || // Secured this . type === 0xCF || this . type === 0xD5 || // DR DOS Secured Extended Partition this . type === 0xC5", "del_tokens": "throw new Error ( 'Not implemented' )", "commit_type": "update"}
{"commit_tokens": ["Add", ":", "keyboard", "zaInputNumber", "component"], "add_tokens": "Object . keys ( baseWebpackConfig . entry ) . forEach ( function ( name ) { baseWebpackConfig . entry [ name ] = [ './build/dev-client' ] . concat ( baseWebpackConfig . entry [ name ] )", "del_tokens": "var path = require ( 'path' ) Object . keys ( baseWebpackConfig . entry ) . forEach ( function ( name ) { // baseWebpackConfig.entry[name] = ['./build/dev-client'].concat(baseWebpackConfig.entry[name]) // remove __webpack_hmr 404 warning [ baseWebpackConfig . entry [ name ] ] . push ( 'webpack-hot-middleware/client?path=/__webpack_hmr&noInfo=true&reload=true&timeout=10000' ) devServer : { contentBase : path . join ( __dirname , '../' ) , historyApiFallback : true , port : 9000 , hot : true , } , new webpack . optimize . OccurrenceOrderPlugin ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Update", "README", ".", "md", "and", "fix", "typo", "."], "add_tokens": "// TODO: Make a way to validate an interface", "del_tokens": "// TODO: Make a way to validate a class", "commit_type": "update"}
{"commit_tokens": ["Remove", "todo", "and", "tst", "into", "separate", "repos", "."], "add_tokens": "export { U , T , E , F , C , V , UpCount , UpStyle , FADE } ; export { test , testGroup , skip , unskip , consoleReporter , htmlReporter } from './src/Tst' ;", "del_tokens": "import { test , testGroup , skip , unskip } from './src/Tst' ; export { U , T , E , F , C , V , UpCount , UpStyle , FADE , test , testGroup , skip , unskip } ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "union", "of", "unions", "implementation"], "add_tokens": "var t = type . dispatch ( x ) ; if ( ! isNil ( t ) ) { return t ; }", "del_tokens": "return type . dispatch ( x ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "has", "function", ".", "Used", "to", "determine", "if", "a", "key", "is", "stored", "/", "exists", "or", "not", ".", "Returns", "true", "or", "false", "."], "add_tokens": "assert ( store . has ( 'foo' ) == false , \"key 'foo' exists when it shouldn't\" ) assert ( store . has ( 'foo' ) == true , \"key 'foo' doesn't exist when it should\" )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "possibility", "to", "globally", "switch", "contenttype", "to", "json", "for", "put", "/", "post"], "add_tokens": "headers : { } , json : false _frisbyGlobalSetup . request . json = false ; json : params . json || ( _frisbyGlobalSetup && _frisbyGlobalSetup . request && _frisbyGlobalSetup . request . json || false ) ,", "del_tokens": "headers : { } json : params . json || false ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "scanned", "devices", "weren", "t", "being", "inserted", "via", "the", "scan"], "add_tokens": "'connectionTypes' : [ { 'name' : 'USB' , 'insertionMethod' : 'scan' , } , { 'name' : 'Ethernet' , 'insertionMethod' : 'scan' , } , { 'name' : 'Wifi' } ] 'connectionTypes' : [ { 'name' : 'USB' , 'insertionMethod' : 'scan' , } ] device . connectionTypes . forEach ( function ( connectionType , i ) { var expectedConnectionType = expectedDeviceData . connectionTypes [ i ] ; var expectedKeys = Object . keys ( expectedConnectionType ) ; // console.log(' - ', expectedConnectionType); expectedKeys . forEach ( function ( key ) { test . strictEqual ( connectionType [ key ] , expectedConnectionType [ key ] , 'Unexpected connectionType Data' ) ; } )", "del_tokens": "'connectionTypes' : [ { } , { } , { } ] 'connectionTypes' : [ { } ] device . connectionTypes . forEach ( function ( connectionType ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "incorrect", "rage", "detecting", "logic", "when", "serializing", "numbers"], "add_tokens": "if ( data > MAX_SAFE_INT32 || data < MIN_SAFE_INT32 ) {", "del_tokens": "if ( data > MAX_SAFE_INT32 && data < MIN_SAFE_INT32 ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "dataStream", "and", "dataPoint", "object"], "add_tokens": "* @ param { string } apiKey Your pachube api key . * @ param { number } id The feed id . Feed . prototype . read = function ( id , parameters , callback , optionalDataFormat ) { * @ param { number } id The feed id . * @ param { string } dataFile The path to data file . * @ param { function } callback The callback function . Feed . prototype . update = function ( id , dataFile , callback , optionalDataFormat ) { id = id . toSring ( ) ;", "del_tokens": "* @ param { string } key The pachube api key . * @ param { number } id The feed id . Feed . prototype . read = function ( id , parameters , callback , optionalDataFormat ) { * @ param { number } id The feed id . * @ param { string } dataFile The path to data file . * @ param { function } callback The callback function . Feed . prototype . update = function ( id , dataFile , callback , optionalDataFormat ) { id = id . toSource ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "exception", "when", "no", "service", "UUIDs", "are", "advertised"], "add_tokens": "this . _uuids = peripheral . advertisement . serviceUuids ? peripheral . advertisement . serviceUuids . map ( fromNobleUuid ) : [ ] ;", "del_tokens": "this . _uuids = this . _peripheral . advertisement . serviceUuids . map ( fromNobleUuid ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "tools", "to", "use", "drag", "event"], "add_tokens": "$ ( element ) . off ( 'CornerstoneToolsMouseDrag' , mouseMoveCallback ) ; $ ( element ) . on ( \"CornerstoneToolsMouseDrag\" , eventData , mouseMoveCallback ) ; disable : function ( element ) { $ ( element ) . off ( 'CornerstoneToolsMouseDrag' , mouseMoveCallback ) ; } , enable : function ( element ) { $ ( element ) . off ( 'CornerstoneToolsMouseDrag' , mouseMoveCallback ) ; } , deactivate : function ( element ) { $ ( element ) . off ( 'CornerstoneToolsMouseDrag' , mouseMoveCallback ) ; } ,", "del_tokens": "$ ( element ) . off ( 'CornerstoneToolsMouseMove' , mouseMoveCallback ) ; $ ( element ) . on ( \"CornerstoneToolsMouseMove\" , eventData , mouseMoveCallback ) ; disable : function ( element ) { $ ( element ) . off ( 'CornerstoneToolsMouseDown' , mouseMoveCallback ) ; } , enable : function ( element ) { $ ( element ) . off ( 'CornerstoneToolsMouseDown' , mouseMoveCallback ) ; } , deactivate : function ( element ) { $ ( element ) . off ( 'CornerstoneToolsMouseDown' , mouseMoveCallback ) ; } ,", "commit_type": "update"}
{"commit_tokens": ["fixed", "bug", "in", "paramter", "setting", "when", "query", "string", "parameter", "does", "not", "apply", "to", "datasource"], "add_tokens": "if ( param ) { args [ 1 ] = param . value ; }", "del_tokens": "args [ 1 ] = param . value ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "mocha", ".", "Fixed", "eslint", "config", "."], "add_tokens": "return ( obj [ TAG ] ? true : false ) ; ctx . onLibraryValidation ( ( ) => { ctx . onLibraryValidation ( ( ) => { ctx . onContainerComplete ( ( ) => { ctx . onLibraryComplete ( ( ) => {", "del_tokens": "return obj [ TAG ] ; ctx . onLibraryValidation ( recordTypes => { ctx . onLibraryValidation ( recordTypes => { ctx . onContainerComplete ( container => { ctx . onLibraryComplete ( recordTypes => {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "hotspot", "rendering", "(", "thanks", "ulothix", ")", "."], "add_tokens": "( ( hs . yaw > 90 || hs . yaw <= - 90 ) && z <= 0 ) ) {", "del_tokens": "( hs . yaw > 90 || hs . yaw <= - 90 && z <= 0 ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Adds", "escapeHTML", "util", "method", "to", "be", "used", "on", "writeFileReport", "in", "order", "to", "prevent", "the", "source", "code", "to", "be", "broken", "when", "the", "JavaScript", "file", "contains", "HTML", "tags"], "add_tokens": "source : util . escapeHTML ( source ) ,", "del_tokens": "source : source ,", "commit_type": "add"}
{"commit_tokens": ["added", "rebuilt", "and", "remap", "meta"], "add_tokens": "// stats.setPackageName(packageName); stats . setPackageName ( packageName . split ( \"$\" ) [ 0 ] ) ; stats . setVersion ( packageName . split ( \"$\" ) [ 1 ] || '' ) ; function extractLiteralFromBuiltin ( stats , packageName , fileName ) { stats . setPackageName ( packageName ) ; stats . setFileName ( fileName ) ; return stats ; }", "del_tokens": "stats . setPackageName ( packageName ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "comparator", "and", "fixed", "list", "wait", "length"], "add_tokens": "const util_1 = require ( \"../../utility_functions/util\" ) ; waitLength ( { length , timeout = this . timeout , interval = 250 , comparator = \"==\" /* equalTo */ } ) { browser . waitUntil ( ( ) => util_1 . compare ( this . _elements . value . length , length , comparator ) , timeout , ` ${ this . selector } ${ comparator . toString ( ) } ${ length } ` , interval ) ;", "del_tokens": "waitLength ( { length , timeout = this . timeout } ) { browser . waitUntil ( ( ) => this . _elements . value . length === length , timeout , ` ${ this . selector } ${ length } ` , timeout ) ;", "commit_type": "add"}
{"commit_tokens": ["using", "can", "-", "attribute", "-", "observable", ".", "set", "instead", "of", "setAttrOrProp"], "add_tokens": "queues . domUIQueue . enqueue ( attr . set , attr , [ el , attributeName , newVal ] ) ; attr . set ( el , attributeName , canReflect . getValue ( compute ) ) ;", "del_tokens": "queues . domUIQueue . enqueue ( attr . setAttrOrProp , attr , [ el , attributeName , newVal ] ) ; attr . setAttrOrProp ( el , attributeName , canReflect . getValue ( compute ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "in", "-", "memory", "transform", "and", "apply", "it", "inside", "RAF"], "add_tokens": "module . exports = getSvgTransformMatrix function getSvgTransformMatrix ( svgElement ) {", "del_tokens": "module . exports = getTransform function getTransform ( svgElement ) {", "commit_type": "use"}
{"commit_tokens": ["add", "ability", "to", "define", "starting", "player", "to", "TurnOrder"], "add_tokens": "{ name : 'A' , turnOrder : { first : ( ) => '10' , next : ( ) => '3' } } expect ( state . ctx . currentPlayer ) . toBe ( '10' ) ;", "del_tokens": "{ name : 'A' , turnOrder : ( ) => '3' } , expect ( state . ctx . currentPlayer ) . toBe ( '0' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "babelify", "as", "a", "global", "transform", "in", "all", "cases"], "add_tokens": "es6 = browserify ( { cache : { } , packageCache : { } , standalone : 'tfbn0jc14vb9nha' + name } ) ; es6 . transform ( babelify . configure ( { compact : false } ) , { global : true } ) ;", "del_tokens": "es6 = browserify ( { cache : { } , packageCache : { } , standalone : 'tfbn0jc14vb9nha' + name } ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "fs", "check", "for", "enclave", ".", "js", "file"], "add_tokens": "var fs = require ( 'fs' ) // Runs only if enclave.js file doesn't exist fs . access ( clientFiles . config , fs . F_OK , function ( err ) { if ( err ) { / ** * Start the CLI prompt . * / prompt . start ( ) / ** * Throw down that postinstall logo . * / shell . exec ( 'bash ./src/cli-helpers/postinstall-logo' ) / ** * Clean out any currently existing config file for a fresh one . * / shell . exec ( 'rm ' + clientFiles . config ) shell . exec ( 'touch ' + clientFiles . config ) / ** * Actually executing all of this magic . * / prompt . get ( prompts , configureConfigFile ) } } )", "del_tokens": "/ ** * Start the CLI prompt . * / prompt . start ( ) / ** * Throw down that postinstall logo . * / shell . exec ( 'bash ./src/cli-helpers/postinstall-logo' ) / ** * Clean out any currently existing config file for a fresh one . * / shell . exec ( 'rm ' + clientFiles . config ) shell . exec ( 'touch ' + clientFiles . config ) / ** * Actually executing all of this magic . * / prompt . get ( prompts , configureConfigFile )", "commit_type": "add"}
{"commit_tokens": ["Updated", "gruntfile", "to", "use", "Karma", "instead", "of", "Testacular"], "add_tokens": "grunt . loadNpmTasks ( 'grunt-karma' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'karma' ] ) ; var karmaConfig = function ( configFile , customOptions ) { karma : { options : karmaConfig ( 'test/test.conf.js' )", "del_tokens": "grunt . loadNpmTasks ( 'grunt-testacular' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'testacular' ] ) ; var testacularConfig = function ( configFile , customOptions ) { testacular : { options : testacularConfig ( 'test/test.conf.js' )", "commit_type": "update"}
{"commit_tokens": ["Updating", "Karam", "coverage", "dir", "and", "adding", "it", "to", "gitignore"], "add_tokens": "dir : 'coverage-client'", "del_tokens": "dir : '../coverage-client'", "commit_type": "update"}
{"commit_tokens": ["Fix", "highlighting", "bugs", "when", "using", "findNodes", "()"], "add_tokens": "this . disableHoverInteractions = ! ! searchString ; // If !!searchString, clear any highlighted object if ( this . disableHoverInteractions && this . currentGraph . highlightedObject ) { this . currentGraph . highlightObject ( ) ; } // if !searchString and highlighted object, do nothing if ( searchString || ! this . currentGraph . highlightedObject ) { // Highlight matches const matchesFound = this . currentGraph . highlightMatchedNodes ( searchString ) ; matchesFound . total = this . currentGraph . nodeCounts . total ; matchesFound . visible = this . currentGraph . nodeCounts . visible ; this . emit ( 'matchesFound' , matchesFound ) ; return matchesFound ; } } return undefined ;", "del_tokens": "this . disableHoverInteractions = ! ! searchString ; const matchesFound = this . currentGraph . highlightMatchedNodes ( searchString ) ; matchesFound . total = this . currentGraph . nodeCounts . total ; matchesFound . visible = this . currentGraph . nodeCounts . visible ; } this . emit ( 'matchesFound' , matchesFound ) ; return matchesFound ;", "commit_type": "fix"}
{"commit_tokens": ["removing", "the", "snippet", "which", "offsets", "the", "tooltip", "when", "hiding", "it"], "add_tokens": "// d3.select(\"#\" + pie.cssPrefix + \"tooltip\" + tt.currentTooltip) // .attr(\"transform\", function(d, i) { // // klutzy, but it accounts for tooltip padding which could push it onscreen // var x = pie.options.size.canvasWidth + 1000; // var y = pie.options.size.canvasHeight + 1000; // return \"translate(\" + x + \",\" + y + \")\"; // });", "del_tokens": "d3 . select ( \"#\" + pie . cssPrefix + \"tooltip\" + tt . currentTooltip ) . attr ( \"transform\" , function ( d , i ) { // klutzy, but it accounts for tooltip padding which could push it onscreen var x = pie . options . size . canvasWidth + 1000 ; var y = pie . options . size . canvasHeight + 1000 ; return \"translate(\" + x + \",\" + y + \")\" ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "app", ".", "listen", "(", "...", ")"], "add_tokens": "this . appServer = this . app . listen ( this . serverPort ) ; this . crossDomainAppServer = this . crossDomainApp . listen ( this . crossDomainServerPort ) ; config ( this . app ) ; config ( this . crossDomainApp ) ;", "del_tokens": "this . appServer = http . createServer ( this . app ) . listen ( this . serverPort ) ; this . crossDomainAppServer = http . createServer ( this . crossDomainApp ) . listen ( this . crossDomainServerPort ) ; config ( this . app , this . appServer ) ; config ( this . crossDomainApp , this . crossDomainAppServer ) ;", "commit_type": "use"}
{"commit_tokens": ["changed", "ordering", "of", "export", "methods"], "add_tokens": "} } } exports . print = function ( ) { console . log ( tableToString ( ) ) ; } exports . html = function ( attributes ) { return tableToHTML ( attributes ) ; }", "del_tokens": "} ; } ; } ; exports . print = function ( ) { console . log ( tableToString ( ) ) ; } exports . html = function ( attributes ) { return tableToHTML ( attributes ) ; }", "commit_type": "change"}
{"commit_tokens": ["Add", "cache", "(", "expirable", ")", "fix", "model", "creation", "..."], "add_tokens": "* * @ param { function } extension The extending class * @ param { object } options Extra options * * @ returns { function } A new class if ( ! options . name ) { // Passing the __extending__ option will make sure // the init() method is not called // Create the first part of the new constructor // We apply it later on inside new_constructor, this way we don't have to // put everything inside a big string // The __extending__ option was found, so init() is not called // Use eval, that way we can set the function name (options.name) // Set the name in the prototype, so objects will have this set correctly // Don't forget: once a function's .name has been set, it can't be changed new_constructor . prototype . name = options . name ;", "del_tokens": "if ( typeof options . name == 'undefined' ) { console . log ( 'This name & cons & extension: ' + this . name + ' - ' + this . constructor . name + ' - ' + extension . name ) ; // Use eval, that way we can set the function name if ( extension . name == 'ProductModel' ) { var t = new new_constructor ( ) ; console . log ( 'PM: ' + t . name + ' - ' + t . constructor . name + '--' + new_constructor . constructor . name ) ; }", "commit_type": "add"}
{"commit_tokens": ["Remove", "remodel", "for", "pages", "unless", "needed"], "add_tokens": ". success ( function ( respData ) { deferred . resolve ( respData ) ; _ . each ( delims , function ( adelim ) { var codeParts = str . split ( adelim ) ; /* eslint no-console:0 */ if ( fn && ( typeof fn === 'function' ) ) { } else { if ( ! fnOrObj ) { return true ; } /* eslint no-console:0 */ return isPartial ? scope . remodel ( ) : true ; for ( i = 0 ; i < fns . length ; i ++ ) {", "del_tokens": ". success ( function ( data ) { deferred . resolve ( data ) ; _ . each ( delims , function ( delim ) { var codeParts = str . split ( delim ) ; if ( fn && ( typeof ( fn ) === 'function' ) ) { } else { if ( ! fnOrObj ) { return ; } if ( isPartial ) { return scope . remodel ( ) ; } else { return true ; } for ( var i = 0 ; i < fns . length ; i ++ ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "Reference", "element", "class", "to", "match", "the", "Bali", "language", "element", "."], "add_tokens": "var elements = require ( '../../elements' ) ; '<https://google.com>' , '<bali:/#RKVVW90GXFP44PBTLFLF8ZG8NR425JYM>' , '<bali:/#RKVVW90GXFP44PBTLFLF8ZG8NR425JYMv3.1>' , '<bali:/bali/elements/Text>' , '<bali:/bali/elements/Text?version=6.12.1>' , '<bali:/abcCorp/reports/2010/Q3>' var jsObject = new elements . Reference ( testValues [ i ] ) ;", "del_tokens": "var url = require ( 'url' ) ; var elements = require ( '../../elements' ) ; 'https://google.com' , 'bali:/#RKVVW90GXFP44PBTLFLF8ZG8NR425JYM' , 'bali:/#RKVVW90GXFP44PBTLFLF8ZG8NR425JYMv3.1' , 'bali:/bali/elements/Text' , 'bali:/bali/elements/Text?version=6.12.1' , 'bali:/abcCorp/reports/2010/Q3' var jsObject = url . parse ( testValues [ i ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "routing", "coding", "style", "with", "object", "."], "add_tokens": "initRouter : function ( ) { this . app . use ( this . app . router ) ; } ,", "del_tokens": "this . app . use ( this . app . router ) ;", "commit_type": "update"}
{"commit_tokens": ["Changed", "how", "the", "luaTypeInt", "is", "acquired", ".", "Moved", "the", "capability", "to", "the"], "add_tokens": "// regEntry.luaTypeInt = luaTypeInt;", "del_tokens": "regEntry . luaTypeInt = luaTypeInt ;", "commit_type": "change"}
{"commit_tokens": ["Allow", "for", "trailing", "whitespace", "in", "JSON", "-", "P", "response"], "add_tokens": ". replace ( / \\)\\s*;?\\s*$ / , '' ) ;", "del_tokens": ". replace ( / \\);?$ / , '' ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "theme", "-", "section", ".", "js", "breaking", "on", "section", "reload"], "add_tokens": "getInstances , getInstanceById describe ( 'getInstanceById()' , ( ) => { beforeEach ( ( ) => { registerSections ( ) ; load ( '*' ) ; } ) ; test ( 'retrieves section instance which matches provided id' , ( ) => { var instance = getInstanceById ( '2' ) ; expect ( instance ) . not . toBeUndefined ( ) ; expect ( instance . id ) . toBe ( '2' ) ; } ) ; } ) ;", "del_tokens": "getInstances", "commit_type": "fix"}
{"commit_tokens": ["removing", "a", "reference", "to", "plugin", "registry", "that", "is", "no", "longer", "needed"], "add_tokens": "var editorContainer = new eclipse . EditorContainer ( serviceRegistry ,", "del_tokens": "var editorContainer = new eclipse . EditorContainer ( pluginRegistry , serviceRegistry ,", "commit_type": "remove"}
{"commit_tokens": ["Adding", "commander", "and", "command", "line", "parsing", "bootstrap"], "add_tokens": "/ ** * Module dependencies . * / var program = require ( 'commander' ) ; var pkg = require ( './package.json' ) ; program . version ( pkg . version ) . option ( '-b, --build' , 'Builds the project' ) . parse ( process . argv ) ; if ( program . build ) console . log ( 'Building..' ) ; console . log ( 'Done' ) ;", "del_tokens": "console . log ( 'Hello, world!' ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "we", "support", "latest", "node", "and", "legacy", "node"], "add_tokens": "// bring node-fetch closer to browser behavior by setting content-length automatically for POST, PUT, PATCH requests when body is empty or string if ( ! headers . has ( 'content-length' ) && options . method . substr ( 0 , 1 ) . toUpperCase ( ) === 'P' ) { if ( typeof options . body === 'string' ) { headers . set ( 'content-length' , Buffer . byteLength ( options . body ) ) ; // this is only necessary for older nodejs releases (before iojs merge) } else if ( options . body === undefined || options . body === null ) { headers . set ( 'content-length' , '0' ) ; }", "del_tokens": "// bring node-fetch closer to browser behavior by setting content-length automatically for POST, PUT, PATCH requests when body is string if ( ! headers . has ( 'content-length' ) && typeof options . body === 'string' && options . method . substr ( 0 , 1 ) . toUpperCase ( ) === 'P' ) { headers . set ( 'content-length' , Buffer . byteLength ( options . body ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Update", "how", "the", "Api", "constructor", "is", "exposed", "."], "add_tokens": "const ExtendableFunction = require ( './internal/ExtendableFunction' ) ; * specific modules as needed . The Api instance is also a function that can * be invoked to create a new Api instance with a different configuration . class Api extends ExtendableFunction { super ( config => new Api ( config ) ) ;", "del_tokens": "* specific modules as needed . class Api {", "commit_type": "update"}
{"commit_tokens": ["allow", "extensions", "to", "be", "named", "without", "a", "period"], "add_tokens": "if ( this . extname [ 0 ] !== '.' ) { this . extname = '.' + this . extname ; }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Added", "jsdoc", "file", "header", "w", "/", "version"], "add_tokens": "/ ** * @ fileoverview gl - matrix - High performance matrix and vector operations for WebGL * @ author Brandon Jones * @ author Colin MacKenzie IV * @ version 2.0 .0 * /", "del_tokens": "/ * * Copyright ( c ) 2012 Brandon Jones , Colin MacKenzie IV * * This software is provided 'as-is' , without any express or implied * warranty . In no event will the authors be held liable for any damages * arising from the use of this software . * * Permission is granted to anyone to use this software for any purpose , * including commercial applications , and to alter it and redistribute it * freely , subject to the following restrictions : * * 1. The origin of this software must not be misrepresented ; you must not * claim that you wrote the original software . If you use this software * in a product , an acknowledgment in the product documentation would be * appreciated but is not required . * * 2. Altered source versions must be plainly marked as such , and must not * be misrepresented as being the original software . * * 3. This notice may not be removed or altered from any source * distribution . * / ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "readme", "and", "examples", "for", "correct", "callback", "API"], "add_tokens": "} , function ( data , req , res , callback ) {", "del_tokens": "} , function ( callback , data ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "URLs", "specified", "with", "trailing", "/", "and", "mounting", "things", "at", "root"], "add_tokens": "baseFilePath = path . format ( path . parse ( baseFilePath ) ) ; //Make sure filePath uses OS native separators var baseUrlPath ; if ( typeof p [ 'url' ] === 'string' ) { baseUrlPath = p [ 'url' ] || p [ 'file' ] } else if ( ! path . isAbsolute ( p [ 'file' ] ) ) { baseUrlPath = p [ 'file' ] ; } else { throw new Error ( 'URL must be specified when an absolute file path is given: ' + p [ 'file' ] ) ; } //Make sure URL starts with / but doesn't contain a trailing / if ( ! baseUrlPath . startsWith ( '/' ) ) { if ( baseUrlPath . endsWith ( '/' ) ) { baseUrlPath = baseUrlPath . substring ( 0 , baseUrlPath . length - 1 ) ; }", "del_tokens": "var baseUrlPath = p [ 'url' ] || p [ 'file' ] ; if ( ! baseUrlPath . startsWith ( '/' ) ) { //Make sure URL starts with / baseFilePath = path . format ( path . parse ( baseFilePath ) ) ; //Make sure filePath uses OS native separators", "commit_type": "fix"}
{"commit_tokens": ["Added", "landing", "page", "and", "navigation"], "add_tokens": "import { Link } from 'react-router' ; import { Menu , MenuItem } from '../../src/components/Menu' ; import { Grid , GridColumn } from '../../src/components/Grid' ; < div className = \"header\" > < Grid > < GridColumn span = { 2 } > < Link to = \"/\" > < Logo / > < / Link > < / GridColumn > < GridColumn span = { 8 } > < Menu > < Link to = \"/components\" > < MenuItem text = \"Components\" / > < / Link > < MenuItem text = \"Style Guide\" / > < / Menu > < / GridColumn > < / Grid > < / div >", "del_tokens": "< div className = \"header\" > < a href = \"http://weave.works\" > < Logo / > < / a > < / div >", "commit_type": "add"}
{"commit_tokens": ["Move", "reopen", "()", "to", "SuspendResume", "class"], "add_tokens": "rpc = new RPC ( { Promise , url : 'http://localhost:4848' , createSocket : url => new SocketMock ( url , false ) } ) ; const reopen = suspendResume . reopen ; suspendResume . reopen = ( val , force ) => reopen . call ( suspendResume , force ? val : 5 ) ; it ( 'should return SESSION_CREATED when reopen hits the timeout' , ( ) => { const reopen = suspendResume . reopen ( 25 , true ) ; return reopen . then ( state => expect ( state ) . to . equal ( 'SESSION_CREATED' ) ) ; } ) ; it ( 'should return SESSION_ATTACHED when it receives the session attached notification' , ( ) => { const reopen = suspendResume . reopen ( 1000000 , true ) ; setTimeout ( ( ) => rpc . emit ( 'notification' , { method : 'OnConnected' , params : { qSessionState : 'SESSION_ATTACHED' } } ) , 25 ) ; return reopen . then ( state => expect ( state ) . to . equal ( 'SESSION_ATTACHED' ) ) ; } ) ;", "del_tokens": "class Dummy extends RPC { reopen ( ) { return super . reopen ( 5 ) ; } } rpc = new Dummy ( { Promise , url : 'http://localhost:4848' , createSocket : url => new SocketMock ( url , false ) } ) ;", "commit_type": "move"}
{"commit_tokens": ["Allow", "overriding", "map", "default", "options"], "add_tokens": "var opts = { excludeAntartica : options . excludeAntarctica || true , disableBackground : options . disableBackground || true , disableMapBackground : options . disableMapBackground || true , disableGraticule : options . disableGraticule || true , disableFill : options . disableFill || true module . exports = Map", "del_tokens": "var opts = { excludeAntartica : true , disableBackground : true , disableMapBackground : true , disableGraticule : true , disableFill : true module . exports = Map", "commit_type": "allow"}
{"commit_tokens": ["Added", "null", "value", "check", "in", "lengthOf", "()", "."], "add_tokens": "return obj == null ? null : ( obj [ $length ] !== undefined ? obj [ $length ] : obj . length ) ;", "del_tokens": "return obj [ $length ] !== undefined ? obj [ $length ] : obj . length ;", "commit_type": "add"}
{"commit_tokens": ["Added", "experimental", "autoConfig", "for", "redis"], "add_tokens": "var redular = new Redular ( { autoConfig : true } ) ;", "del_tokens": "var redular = new Redular ( ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "schema", "to", "support", "resource", "formats"], "add_tokens": "var id = - 1 , result = zipper ( query ( 'select id from resource where slug=\"' + resource . slug + '\" and project_id=' + id = result [ 0 ] . id ; // add formats for ( var format of resource . formats ) { // TODO: add formats } save ( ) ; return id ;", "del_tokens": "save ( ) ; var result = zipper ( query ( 'select id from resource where slug=\"' + resource . slug + '\" and project_id=' + return result [ 0 ] . id ; return - 1 ;", "commit_type": "update"}
{"commit_tokens": ["Add", "traverse", "and", "other", "helper", "methods"], "add_tokens": "t ( 'add tests' , function ( ) { var hydro = new Hydro ; hydro . addSuite ( 'suite 1' , function ( ) { hydro . addTest ( 'test 1.1' ) ; hydro . addSuite ( 'suite 2' , function ( ) { hydro . addTest ( 'test 2.1' ) ; } ) ; } ) ; var tests = hydro . tests ( ) ; assert ( tests [ 0 ] . title === 'test 2.1' ) ; assert ( tests [ 1 ] . title === 'test 1.1' ) ; } ) ; t ( 'add a test without a suite' , function ( ) {", "del_tokens": "t ( 'adding a test without a suite' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "MutationObserver", "to", "update", "scroller", "."], "add_tokens": "var MutationObserver = window . MutationObserver || window . WebKitMutationObserver || window . MozMutationObserver || null ; obs : { childList : true , subtree : true , characterData : true , } \"<div class='scroll-wrapper {{class}}' id='{{id}}' intro='updateScroll'>\" + if ( MutationObserver ) { this . obs = new MutationObserver ( update ) ; this . obs . observe ( this . node , this . opts . obs ) ; } else { console . warn ( 'Scroll: Your browser does not support MutationObserver.' ) } this . obs && this . obs . disconnect ( ) ;", "del_tokens": "var fs = require ( 'fs' ) ; \"<div class='scroll-wrapper {{class}}' id='{{id}}' intro='updateScroll'>\" + // Monkey patch Ractive.set to that // it emits custom `set` event with // the returned promise as argument. // // This allows to wait for transitions to finish. var mutators = [ 'set' , 'shift' , 'unshift' , 'push' , 'pop' ] ; mutators . forEach ( function ( meth ) { var old = Ractive . prototype [ meth ] ; Ractive . prototype [ meth ] = function ( ) { var ret = old . apply ( this , arguments ) ; this . fire ( meth , ret ) ; return ret ; } ; } ) ; // One level deep, unfortunately this . _parent . on ( mutators . join ( ' ' ) , function ( ret ) { ret . then ( update ) ; } ) ; this . s = null ;", "commit_type": "use"}
{"commit_tokens": ["fix", "AMD", "and", "window", "declaration"], "add_tokens": "define ( function ( ) { } ) ; } if ( isBrowser ) { window . Vein = Vein ;", "del_tokens": "define ( \"Vein\" , ( function ( ) { } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "significant", "regression", "in", "getAncestors", "behavior", "with", "four", "or", "three", "options"], "add_tokens": "options = arguments [ 2 ] ; criteriaArg = { } ; callback = arguments [ 2 ] ;", "del_tokens": "criteriaArg = { } ; options = arguments [ 2 ] ; callback = arguments [ 2 ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "filename", "of", "XML", "report", "to", "package", "name", "."], "add_tokens": "if ( ! pkg . name ) { pkg . name = result . testsuites . filename ; } else { pkg . name = result . testsuites . filename + '-' + pkg . name ; }", "del_tokens": "if ( ! pkg . name ) pkg . name = suite . pkgName ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "ArrayBuffer", "and", "related", "views", "as", "data"], "add_tokens": "if ( utils . isArrayBuffer ( data ) ) { return data ; } if ( utils . isArrayBufferView ( data ) ) { return data . buffer ; } if ( utils . isObject ( data ) && ! utils . isFile ( data ) && ! utils . isBlob ( data ) ) { return JSON . stringify ( data ) ; } return data ;", "del_tokens": "return utils . isObject ( data ) && ! utils . isFile ( data ) && ! utils . isBlob ( data ) ? JSON . stringify ( data ) : data ;", "commit_type": "allow"}
{"commit_tokens": ["Making", "collected", "items", "actually", "instances", "of", "Model", "."], "add_tokens": "var Type = module . exports = function ( application , name , settings ) { // Store name and application. this . application = application ; return this . settings . process ? this . settings . process ( key , values ) : this . application . new ( this . name , values ) ;", "del_tokens": "var Type = module . exports = function ( name , settings ) { return this . settings . process ? this . settings . process ( key , values ) : values ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "_uvcache", "object", "initialization", ".", "Closes", "GH", "-", "5"], "add_tokens": "this . _uvcache = Object . create ( null ) ;", "del_tokens": "this . _uvcache = [ ] ; if ( self . _uvcache . length > 0 ) { return self . _uvcache ; }", "commit_type": "fix"}
{"commit_tokens": ["Update", "_core", "-", "types", ".", "esm", ".", "js"], "add_tokens": "class BinaryData { class BinaryInt extends BinaryData { export { BinaryData } ; export { BinaryInt } ;", "del_tokens": "class __BinaryData { class __BinaryInt extends BinaryData { export const BinaryData = __BinaryData ; export const BinaryInt = __BinaryInt ;", "commit_type": "update"}
{"commit_tokens": ["Added", "handling", "for", "unimplemeneted", "methods", "on", "the", "server"], "add_tokens": "if ( stream ) { stream . emit ( 'cancelled' ) ; } if ( handlers . hasOwnProperty ( data . method ) ) { handler = handlers [ data . method ] ; } else { call . serverEndInitialMetadata ( 0 ) ; call . startWriteStatus ( grpc . status . UNIMPLEMENTED , \"This method is not available on this server.\" , function ( ) { } ) ; return ; }", "del_tokens": "if ( handlers . hasOwnProperty ( data . method ) ) { handler = handlers [ data . method ] ; } stream . emit ( 'cancelled' ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "stopOnTwoNewlines", "argument", "in", "block", "parser"], "add_tokens": "LexerBlock . prototype . tokenize = function ( state , startLine , endLine ) { // two empty lines should stop the parser in list mode if ( line < endLine && state . listMode && isEmpty ( state , line ) ) { break ; }", "del_tokens": "LexerBlock . prototype . tokenize = function ( state , startLine , endLine , stopOnTwoNewlines ) { // two empty lines should stop the parser if ( line < endLine && stopOnTwoNewlines && isEmpty ( state , line ) ) { break ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "client", "side", "logging", "function", "error"], "add_tokens": "ClientLogger [ method ] = getLoggingFunc ( method ) ; function getLoggingFunc ( method ) { return function ( ) { if ( ClientLogger . level . v <= levels [ method . toUpperCase ( ) ] . v ) { var args = [ ] ; args . push ( method . toUpperCase ( ) + \":\" ) ; for ( var i = 0 ; i < arguments . length ; i ++ ) args . push ( arguments [ i ] ) ; if ( method == 'trace' ) console . debug . apply ( console , args ) ; else console [ method ] . apply ( console , args ) } } }", "del_tokens": "ClientLogger [ method ] = function ( ) { if ( ClientLogger . level . v <= levels [ method . toUpperCase ( ) ] . v ) { var args = [ ] ; args . push ( method . toUpperCase ( ) + \":\" ) ; for ( var i = 0 ; i < arguments . length ; i ++ ) args . push ( arguments [ i ] ) ; if ( method == 'trace' ) console . debug . apply ( console , args ) ; else console [ method ] . apply ( console , args ) } }", "commit_type": "fix"}
{"commit_tokens": ["add", "type", "to", "messages", "defaults", "to", "chat", "/", "text"], "add_tokens": "* @ param { Object } opts - Options : date , username , type ( message type ) var type = opts . type || \"chat/text\" var m = { author : username , time : date , content : message , type : type }", "del_tokens": "* @ param { Object } opts - Options : date , username var m = { author : username , time : date , content : message }", "commit_type": "add"}
{"commit_tokens": ["Adds", "an", "option", "to", "disable", "spell", "-", "checking", "of", "statements", "."], "add_tokens": "ignoreRequire : { type : 'boolean' , default : false } , ( options . ignoreRequire && aNode . parent . type === 'CallExpression' && aNode . parent . callee . name === 'require' )", "del_tokens": "( aNode . parent . type === 'CallExpression' && aNode . parent . callee . name === 'require' )", "commit_type": "add"}
{"commit_tokens": ["Change", "text", "size", "to", "14px", "for", "consistency"], "add_tokens": "* Text ! Normal , Large and Extra Large are 0.875 em , 2 em , and 2.827 em respectively . * Default text size ; 0.875 em", "del_tokens": "* Text ! Normal , Large and Extra Large are 1 em , 2 em , and 2.827 em respectively . * Default text size ; 1 em", "commit_type": "change"}
{"commit_tokens": ["Add", "options", "for", "decoding", "for", "tests"], "add_tokens": "* @ param { object } [ options . decodeOptions ] this . decode ( this . file , options . decodeOptions ) ;", "del_tokens": "this . decode ( this . file ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "test", "case", "for", "refresh", "token", "revokation", "/", "expiration"], "add_tokens": "} , \", then again expire access token and expire refresh token\" : { topic : function ( ) { conn . accessToken = \"invalid access token\" ; conn . refreshToken = \"invalid refresh token\" ; conn . query ( \"SELECT Id FROM User\" , this . callback ) ; } , \"should return error response\" : function ( err , user ) { assert . isObject ( err ) ; assert . equal ( \"invalid_grant\" , err . error ) ; } } } } } } } } }", "del_tokens": "} } } } } } } }", "commit_type": "add"}
{"commit_tokens": ["fix", "getTimingPoint", "()", "always", "returning", "the", "first", "one", "and", "add", "beatLength", "inheritance"], "add_tokens": "for ( var i = beatmap . timingPoints . length - 1 ; i >= 0 ; i -- ) { timingPoints [ i ] . beatLength = timingPoints [ i - 1 ] . beatLength ; timingPoints [ i ] . bpm = timingPoints [ i - 1 ] . bpm ;", "del_tokens": "for ( var i = 0 , l = beatmap . timingPoints . length ; i < l ; i ++ ) { timingPoints [ i ] . bpm = timingPoints [ i - 1 ] . bpm ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "nonstandard", "writestring", "and", "conform", "to", "node", "-", "serial", "which", "allows", ".", "write", "of", "a", "string"], "add_tokens": "if ( typeof buffer === 'string' ) { buffer = str2ab ( buffer ) ; }", "del_tokens": "SerialPort . prototype . writeString = function ( string , callback ) { this . write ( str2ab ( string ) , callback ) ; } ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bugs", "and", "document", "a", "lot", "of", "functionality"], "add_tokens": "/* global x */ ( function ( q ) { q . module ( 'franky' ) ; q . test ( 'Components: custom call of init' , function ( ) { q . equal ( q . test ( 'Components: check init' , function ( ) { var doc = document . createElement ( 'div' ) , testData = \"\" ; doc . setAttribute ( \"data-xapp\" , \"hello\" ) ; doc . setAttribute ( \"data-var1\" , \"hello\" ) ; doc . setAttribute ( \"data-var2\" , \"world\" ) ; x . Component . extend ( { 'id' : \"hello\" , 'init' : function ( ) { testData = this . var1 + \" \" + this . var2 ; } } ) ; x . Component . initByHTML ( doc ) ; q . equal ( testData , \"hello world\" , \"check init failed\" ) ; } ) ; } ) ( QUnit ) ;", "del_tokens": "/* global x, equal, ok */ ( function ( ) { QUnit . module ( 'franky' ) ; test ( 'Components: custom call of init' , function ( ) { equal ( / * if ( typeof document !== \"undefined\" ) { test ( 'Components: initByHTML' , function ( ) { x . Component . initByHTML ( ) ; equal ( testVariable , \"olollo\" , \"The result must be 123\" ) ; } ) ; } * / } ) ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "AMD", "partial", "with", "no", "namespace"], "add_tokens": "amd_partials_use_namespace : { options : { amd : [ 'handlebars' ] , partialsUseNamespace : true } , files : { 'tmp/amd_partials_use_namespace.js' : [ 'test/fixtures/_partial.hbs' , 'test/fixtures/one.hbs' ] } } , amd_partials_no_namespace : { options : { amd : [ 'handlebars' ] , partialsUseNamespace : false } , files : { 'tmp/amd_partials_no_namespace.js' : [ 'test/fixtures/_partial.hbs' , 'test/fixtures/one.hbs' ] } } , commonjs_compile : {", "del_tokens": "commonjs_compile : {", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "p", "/", "--", "port", "option", "to", "specify", "the", "port", "to", "run", "the", "webpack", "dev", "server", "on", "."], "add_tokens": "module . exports = function server ( config , options ) { historyApiFallback : true , stats : { colors : true } } ) . listen ( options . port , 'localhost' , function ( err , result ) { console . log ( 'react-heatpack listening at http://localhost:' + options . port )", "del_tokens": "module . exports = function server ( config ) { historyApiFallback : true } ) . listen ( 3000 , 'localhost' , function ( err , result ) { console . log ( 'react-heatpack listening at localhost:3000' )", "commit_type": "add"}
{"commit_tokens": ["Move", "json", "test", "up", "one", "test", "directory", "."], "add_tokens": "require ( '../../redux' ) ( 1 , function ( assert ) { var proof = require ( '../../proof' )", "del_tokens": "require ( '../../../redux' ) ( 1 , function ( assert ) { var proof = require ( '../../../proof' )", "commit_type": "move"}
{"commit_tokens": ["updated", "docs", "added", "es6", "module", "version"], "add_tokens": "* @ function return multi ( 'MultiSurface' , 'surfaceMember' , Polygon , coords , gmlId , params ) ;", "del_tokens": "/* eslint-disable no-alert, no-console */ * @ function return multi ( 'MultiSurface' , 'surfaceMember' , Polygon , coords , gmlId , params ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "camel", "case", "for", "node", "/", "edge", "/", "graph", "attrs"], "add_tokens": "defaultInt ( g . attrs , \"nodeSep\" , 50 ) ; defaultFloat ( attrs , \"strokeWidth\" , 1.5 ) ; defaultVal ( attrs , \"fontColor\" , \"#333\" ) ; defaultVal ( attrs , \"fontName\" , \"Times New Roman\" ) ; defaultInt ( attrs , \"fontSize\" , 14 ) ; defaultFloat ( attrs , \"strokeWidth\" , 1.5 ) ;", "del_tokens": "defaultInt ( g . attrs , \"nodesep\" , 50 ) ; defaultFloat ( attrs , \"strokewidth\" , 1.5 ) ; defaultVal ( attrs , \"fontcolor\" , \"#333\" ) ; defaultVal ( attrs , \"fontname\" , \"Times New Roman\" ) ; defaultInt ( attrs , \"fontsize\" , 14 ) ; defaultFloat ( attrs , \"strokewidth\" , 1.5 ) ;", "commit_type": "use"}
{"commit_tokens": ["Removed", "node_modules", "from", "the", "example", "."], "add_tokens": "/ * Function to convert an object from value / override structure to a simple object * / function fixObject ( object ) { for ( var i in object ) { object [ i ] = object [ i ] . value ; } } var permissions = fixObject ( userappUser . permissions ) , properties = fixObject ( userappUser . properties ) , features = fixObject ( userappUser . features ) ; permissions : permissions , features : features , properties : properties ,", "del_tokens": "permissions : userappUser . permissions , features : userappUser . features , properties : userappUser . properties , properties : userappUser . properties ,", "commit_type": "remove"}
{"commit_tokens": ["Moved", "all", "the", "main", "functions", "under", "main", "namespace", "instead", "of", "registry", "namespace"], "add_tokens": "EJS . systemPathPrefix = 'EJS' ; //TODO: move it to the init stage EJS . registry = { getNode : function ( axes , createIfNotExists ) { var node = this . getNode ( path , false ) ; } ;", "del_tokens": "EJS . registry = _ . assign ( EJS . registry || { } , { systemPathPrefix : 'EJS' , _getNode : function ( axes , createIfNotExists ) { var node = this . _getNode ( path , false ) ; } ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "rendering", "components", "in", "stache", "templates"], "add_tokens": "this . nodeList = nodeList ; // This adds support for components being rendered as values in stache templates var viewInsertSymbol = canSymbol . for ( \"can.viewInsert\" ) ; Component . prototype [ viewInsertSymbol ] = function ( viewData ) { viewData . nodeList . newDeepChildren . push ( this . nodeList ) ; return this . element ; } ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "windows", "global", "install", "with", "forever"], "add_tokens": "var windows = false ; interpretArguments ( ) ; if ( ! windows ) { startApi ( ) ; } else { console . log ( process . argv [ 1 ] . split ( \"castWebApi.js\" ) [ 0 ] ) ; } if ( args . windows ) { windows = true ; }", "del_tokens": "startApi ( ) ; interpretArguments ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "ping", "command", "and", "connectListener"], "add_tokens": "exports . createTCPClient = function ( host , port , connectListener ) var connection = net . createConnection ( port , host , connectListener ) ;", "del_tokens": "exports . createTCPClient = function ( host , port ) var connection = net . createConnection ( port , host ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "regression", "in", "the", "build", "system"], "add_tokens": "else del ( ` ${ pkg . name } ` ) . then ( resolve , reject ) ; return new Promise ( ( resolve , reject ) => child . exec ( command , { maxBuffer : 5 * 1024 * 1024 } , ( err , stdout ) => {", "del_tokens": "else del ( ` ${ pkg . name } ` , err => err ? reject ( err ) : resolve ( ) ) ; return new Promise ( ( resolve , reject ) => child . exec ( command , { maxBuffer : 2 * 1024 * 1024 } , ( err , stdout ) => {", "commit_type": "fix"}
{"commit_tokens": ["added", "release", "notes", "&", "documentation"], "add_tokens": "const register = ( code ) => { code && registerTag ( code , document . body ) ; callback ( ) ; } ; if ( typeof path !== 'string' ) return register ( path ) ; register ( code ) ;", "del_tokens": "code && registerTag ( code , document . body ) ; callback ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "delete", "capability", "associated", "example", "and", "README", "update"], "add_tokens": "const anotherPerson = new Person ( ) ; /** Await loading of database record with ID 1 into person2 */ await anotherPerson . load ( db , 1 ) ; console . log ( anotherPerson ) ; anotherPerson . checkingBalance ( 50.74 ) ; await anotherPerson . update ( db ) ; /** Delete the person at ID # 1 */ await anotherPerson . delete ( db ) ; /** Try to load person at ID # 1 (will throw error) */ await anotherPerson . load ( db , 1 ) ;", "del_tokens": "const person2 = new Person ( ) ; /** Await loading of database record with ID 2 into person2 */ await person2 . load ( db , 2 ) ; console . log ( person2 ) ; person2 . checkingBalance ( 50.74 ) ; await person2 . update ( db ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "get", "user", "by", "id"], "add_tokens": ". reply ( 200 , helper . load ( \"all\" ) , { server : 'nginx' , status : '200 OK' } ) ; helper . nock ( helper . test_shop ) . get ( '/admin/users/799407056.json' ) . reply ( 200 , helper . load ( \"single\" ) , { server : 'nginx' , status : '200 OK' it ( 'able to get user by id' , function ( done ) { resource . get ( '799407056' , function ( err , res ) { res . should . be . a . Object ( ) ; res . id . should . equal ( 799407056 ) ; done ( ) ; } ) ; } ) ;", "del_tokens": ". reply ( 200 , helper . load ( \"all\" ) , { server : 'nginx' , status : '200 OK'", "commit_type": "add"}
{"commit_tokens": ["fix", "sync", "calling", "of", "callbacks", "in", "waterfall"], "add_tokens": "var i = - 1 ; i ++ ;", "del_tokens": "var i = 0 ; i ++ ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "nordnet", "/", "cordova", "-", "universal", "-", "links", "-", "plugin", "/", "issues", "/", "47"], "add_tokens": "var appID = teamId + '.' + getBundleId ( ) , paths = host . paths . slice ( ) ; // if paths are '*' - we should add '/' to it to support root domains. // https://github.com/nordnet/cordova-universal-links-plugin/issues/46 if ( paths . length == 1 && paths [ 0 ] === '*' ) { paths . push ( '/' ) ; } \"paths\" : paths", "del_tokens": "var appID = teamId + '.' + getBundleId ( ) ; \"paths\" : host . paths", "commit_type": "fix"}
{"commit_tokens": ["remove", "gulp", "tasks", "that", "deal", "with", "client"], "add_tokens": "'lib/**/*.js' , 'index.js' , var docGlobs = [ 'index.js' , 'lib/**' ] ; gulp . task ( 'test' , [ 'mocha' ] ) ; gulp . task ( 'default' , [ 'lint' , 'concat' , 'mocha' ] ) ;", "del_tokens": "var karmaVendorFiles = [ 'client/bower_components/angular/angular.js' , 'client/bower_components/angular-mocks/angular-mocks.js' , 'client/bower_components/sinon-chai/lib/sinon-chai.js' , 'client/testing/lib/*.js' ] ; var karmaFiles = [ 'client/src/**/*.js' ] ; gulp . task ( 'karma' , rg . karma ( { files : karmaFiles , vendor : karmaVendorFiles } ) ) ; gulp . task ( 'karma-ci' , rg . karma ( { files : karmaFiles , vendor : karmaVendorFiles , karmaConf : 'client/testing/karma-ci.conf.js' } ) ) ; gulp . task ( 'karma-watch' , rg . karmaWatch ( { files : karmaFiles , vendor : karmaVendorFiles } ) ) ; 'client/src/**/*.js' , 'server/lib/**/*.js' , 'server/index.js' , var docGlobs = [ 'server/index.js' , 'server/lib/**' ] ; gulp . task ( 'concat' , rg . concatAndUglify ( { files : 'client/src/**/*.js' , name : 'koast' , dist : 'client/dist/' } ) ) ; gulp . task ( 'test' , [ 'karma' , 'mocha' ] ) ; gulp . task ( 'default' , [ 'lint' , 'concat' , 'mocha' , 'karma' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", ":", "Recursion", "to", "isInstance", "method"], "add_tokens": "Empty_Mixin , Extended_Customer , test_customer , extended_test_customer ; Empty_Mixin = modelo . define ( ) ; Extended_Customer = Customer . extend ( Empty_Mixin ) ; extended_test_customer = new Extended_Customer ( ) ; expect ( extended_test_customer . isInstance ( Customer ) ) . to . be ( true ) ; expect ( extended_test_customer . isInstance ( Empty_Mixin ) ) . to . be ( true ) ; expect ( extended_test_customer . isInstance ( Person ) ) . to . be ( true ) ; expect ( extended_test_customer . isInstance ( Walker ) ) . to . be ( true ) ; expect ( extended_test_customer . isInstance ( Talker ) ) . to . be ( true ) ; expect ( extended_test_customer . isInstance ( function ( ) { } ) ) . to . be ( false ) ;", "del_tokens": "test_customer ;", "commit_type": "add"}
{"commit_tokens": ["updated", "plugin", ".", "xml", "native", "src", "files"], "add_tokens": "Camera = require ( 'org.apache.cordova.core.CameraLauncher.CameraConstants' ) , CameraPopoverHandle = require ( 'org.apache.cordova.core.CameraLauncher.CameraPopoverHandle' ) ;", "del_tokens": "Camera = require ( 'org.apache.cordova.core.CameraConstants' ) , CameraPopoverHandle = require ( 'org.apache.cordova.core.CameraPopoverHandle' ) ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "postMessage", "to", "result", "async", "process"], "add_tokens": "} ) . done ( function ( data ) { window . ga ( 'send' , 'event' , '[done] ' + url , data . url , dimensions ) ; } ) . fail ( function ( err ) { window . ga ( 'send' , 'event' , '[error] ' + url , err . message , dimensions ) ;", "del_tokens": "} ) . done ( function ( ) { window . ga ( 'send' , 'event' , 'success' , url , dimensions ) ; } ) . fail ( function ( ) { window . ga ( 'send' , 'event' , 'failed' , url , dimensions ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "two", "pointless", "string", "concats"], "add_tokens": "if ( o . shadow ) ins ( seg , css ( fill ( '#000' , '0 0 4px #000' ) , { top : '2px' } ) )", "del_tokens": "if ( o . shadow ) ins ( seg , css ( fill ( '#000' , '0 0 4px ' + '#000' ) , { top : 2 + 'px' } ) )", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "to", "grunt", "watch", "task", "(", "this", "will", "live", "preload", "changes", "from", "library", "source", "code", ")"], "add_tokens": "watch : { options : { livereload : true } , css : { files : [ '<%= dir.src %>/**/*.less' , '<%= dir.src %>/**/*.css' ] , tasks : [ 'build' ] } , js : { files : [ '<%= dir.src %>/**/*.js' ] , tasks : [ 'build' ] } } , hostname : '*' , //livereload: 35729 compiler : { compress : true } , grunt . task . run ( 'openui5_connect:' + ( target || 'src' ) ) ; grunt . task . run ( 'watch' ) ;", "del_tokens": "hostname : '*' grunt . task . run ( 'openui5_connect:' + ( target || 'src' ) + ':keepalive' ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "use", "of", "irish", "-", "pub", "to", "use", "built", "-", "in", "NPM", "dry", "run", "command"], "add_tokens": "* to git . Otherwise we ' shell . exec ( SHOULD_PUBLISH ? \"npm publish --access public\" : \"npm publish --dry-run\" ) ;", "del_tokens": "* to git . Otherwise we ' shell . exec ( SHOULD_PUBLISH ? \"npm publish --access public\" : \"irish-pub\" ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "gulp", "watch", "/", "test", "/", "lint", "tasks"], "add_tokens": "} ; } ; }", "del_tokens": "} var type = typeof value ; } } ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "splice", "error", "."], "add_tokens": "for ( var index = 0 ; ; index ++ ) { if ( files [ index ] == undefined ) break ; index -- ;", "del_tokens": "for ( var index in files ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "dynamic", "html", "elements"], "add_tokens": "const tag = path . get ( 'name' ) ( name . charAt ( 0 ) !== name . charAt ( 0 ) . toUpperCase ( ) || Object . values ( path . scope . bindings ) . some ( binding => binding . referencePaths . some ( r => r === tag ) ) )", "del_tokens": "name . charAt ( 0 ) !== name . charAt ( 0 ) . toUpperCase ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "qs", ".", "stringify", "when", "argument", "is", "not", "an", "object"], "add_tokens": "return _stringify ( obj ) ; if ( typeof prefix === 'undefined' ) { throw new Error ( \"Value must be a hash\" ) ; }", "del_tokens": "return _stringify ( obj , null ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "code", "style", "(", "changed", "quotes", "to", "apostrophes", ")", "added", "a", "try", "-", "catch", "around", "the", "executed", "task", "to", "ensure", "proper", "releasing", "of", "a", "lock", "a", "task", "throwing", "an", "error", "added", "a", "mechanism", "for", "safely", "acquiring", "multiple", "locks", "for", "a", "task"], "add_tokens": "constructor ( message = '' ) { this . name = 'TimeoutError'", "del_tokens": "constructor ( message = \"\" ) { this . name = \"TimeoutError\"", "commit_type": "update"}
{"commit_tokens": ["Make", "the", "dispatcher", "a", "bit", "more", "reusable"], "add_tokens": "/ ** * Export ` ` . * / module . exports . dispatcher = dispatcher ; [ 'skip' , 'suite' , 'on' ] . forEach ( function ( method ) {", "del_tokens": "[ 'skip' , 'run' , 'suite' , 'on' ] . forEach ( function ( method ) {", "commit_type": "make"}
{"commit_tokens": ["remove", "redundancy", "and", "minor", "performance", "optimization"], "add_tokens": "var chn = prefix + '#' + packet . nsp + '#' ; var msg = msgpack . encode ( [ uid , packet , opts ] ) ; var chnRoom = chn + '#' + room + '#' ; pub . publish ( chnRoom , msg ) ;", "del_tokens": "var chn = prefix + '#' + packet . nsp + '#' + room + '#' ; var msg = msgpack . encode ( [ uid , packet , opts ] ) ; pub . publish ( chn , msg ) ; var chn = prefix + '#' + packet . nsp + '#' ; var msg = msgpack . encode ( [ uid , packet , opts ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", ":", "existing", "font", "-", "feature", "-", "settings", "being", "duplicated", "."], "add_tokens": "if ( fontFeatureSettings . value && fontFeatureSettings . value !== newValue ) {", "del_tokens": "if ( fontFeatureSettings . value ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "extended", "browser", "info", "logging", "and", "public", "pageInfo", "()", "method"], "add_tokens": "var nav = window . navigator || { doNotTrack : undefined } ; url : location . pathname , referrer : document . referrer , screen : { width : screen . width , height : screen . height } , window : { width : window . innerWidth , height : window . innerHeight } , browser : { name : nav . appName , version : nav . appVersion , cookie_enabled : nav . cookieEnabled , do_not_track : nav . doNotTrack } , platform : nav . platform this . pageInfo = _agentInfo ( ) ; // single arg to stop compiler complaining var _log = function ( msg ) { } , pageInfo : function ( ) { _log ( logger . pageInfo ) . level ( 'PAGE' ) . send ( ) ;", "del_tokens": "var navigator = window . navigator || { } ; name : navigator . userAgent , screenWidth : screen . width , screenHeight : screen . height , windowWidth : window . innerWidth , windowHeight : window . innerHeight , url : location . pathname var _log = function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "isImmutable", "and", "tests", "."], "add_tokens": "var immutabilityTag = \"__immutable_invariants_hold\" ; addPropertyTo ( target , immutabilityTag , true ) ; } function isImmutable ( target ) { if ( typeof target === \"object\" ) { return target === null || target . hasOwnProperty ( immutabilityTag ) ; } else { // Only objects are even potentially mutable. return true ; } isImmutable : isImmutable ,", "del_tokens": "addPropertyTo ( target , \"__immutable_invariants_hold\" , true ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "_yui", "instead", "of", "!yui", "for", "def"], "add_tokens": "var cx = infer . cx ( ) , mods = cx . definitions [ data [ \"!name\" ] ] [ \"_yui\" ] ;", "del_tokens": "var cx = infer . cx ( ) , mods = cx . definitions [ data [ \"!name\" ] ] [ \"!yui\" ] ;", "commit_type": "use"}
{"commit_tokens": ["Add", "tests", "for", "AppManager", "and", "Distribution", "js", "wrappers"], "add_tokens": "import truffleContract from 'truffle-contract' const DEFAULT_TX_PARAMS = { gas : 6721975 , gasPrice : 100000000000 , from : web3 . eth . accounts [ 0 ] } provideContractsFromTruffle ( ) function provideContractsFromTruffle ( ) { ContractsProvider . getByJSONData = ( data ) => { const contract = truffleContract ( data ) contract . setProvider ( web3 . currentProvider ) contract . defaults ( DEFAULT_TX_PARAMS ) return contract } ContractsProvider . getFromKernel = contractName => { const data = require ( ` ${ contractName } ` ) ; return ContractsProvider . getByJSONData ( data ) } global . ContractsProvider = ContractsProvider }", "del_tokens": "global . ContractsProvider = ContractsProvider", "commit_type": "add"}
{"commit_tokens": ["remove", "encode", "function", "from", "sessionService"], "add_tokens": "session . __socket__ . send ( msg ) ;", "del_tokens": "session . __socket__ . send ( encode ( msg ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "tokenization", "of", "the", "input"], "add_tokens": "return _ . filter ( html . split ( / ({{.+?}}(?!})|[{}\\(\\)\\[\\]#\\*`=:;,.<>\"'\\/]|\\s+) / ) ) ;", "del_tokens": "return _ . filter ( html . split ( / ({{.+?}}(?!})|[{}\\(\\)\\[\\]#\\*`=:;,<>\"'\\/]|\\s+) / ) ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "support", "for", "winston", "logging"], "add_tokens": "// aspect ratio could not be parsed, return error // aspect ratio could not be parsed, return error", "del_tokens": "// aspect ratio could not be parsed, throw error // aspect ratio could not be parsed, throw error", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "couple", "more", "tests", "for", "the", "relative", "behavior", "."], "add_tokens": "it ( 'should change the timezone' , function ( ) { var d = new time . Date , old = d . getTime ( ) d . setTimezone ( 'US/Pacific' , true ) d . getTimezone ( ) . should . not . equal ( process . env . TZ ) } ) it ( 'should keep local values' , function ( ) { } ) it ( 'should change the date\\'s internal time value' , function ( ) { var d = new time . Date , old = d . getTime ( ) d . setTimezone ( 'US/Pacific' , true ) d . getTime ( ) . should . not . equal ( old )", "del_tokens": "it ( 'should keep local values, but change the timezone' , function ( ) { d . getTimezone ( ) . should . not . equal ( process . env . TZ )", "commit_type": "add"}
{"commit_tokens": ["removed", "skip", "tag", "from", "test"], "add_tokens": "it ( 'should not render phone because is not part of @view.bind' , ( ) => {", "del_tokens": "it . skip ( 'should not render phone because is not part of @view.bind' , ( ) => {", "commit_type": "remove"}
{"commit_tokens": ["updated", "readme", "and", "jquery", "plugin", "defaults"], "add_tokens": "$ ( \".Valiant360\" ) . Valiant360 ( ) ; // $(\".Valiant360\").Valiant360('play');", "del_tokens": "$ ( \".Valiant360\" ) . Valiant360 ( { debug : true } ) ; $ ( \".Valiant360\" ) . Valiant360 ( 'play' ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "node_modules", "/", ".", "bin", "not", "being", "included", "to", "PATH", "."], "add_tokens": "opts . env . PATH = pathlib . join ( __dirname , '..' , '..' , '..' , 'node_modules' , '.bin' ) ;", "del_tokens": "opts . env . PATH = pathlib . join ( __dirname , '..' , '..' , 'node_modules' , '.bin' ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "pretty", "printing", "of", "JSON"], "add_tokens": "'hljs' , 'formly'", "del_tokens": "'formly' ,", "commit_type": "add"}
{"commit_tokens": ["Moved", "respondBasedOnResult", "to", "request", "from", "session_request_handler", "."], "add_tokens": "_errors = require ( \"./errors.js\" ) , _respondBasedOnResultDecorator = function ( session , req , result ) { //console.log(\"respondBasedOnResult => \"+JSON.stringify(result)); // Convert string to JSON if ( typeof ( result ) === \"string\" ) { try { result = JSON . parse ( result ) ; } catch ( e ) { // In case the conversion fails, report and \"Invalid Command Method\" error _errors . handleInvalidReqInvalidCommandMethodEH ( req , this ) ; } } // In case the JSON doesn't contain the expected fields if ( result === null || typeof ( result ) === \"undefined\" || typeof ( result ) !== \"object\" || typeof ( result . status ) === \"undefined\" || typeof ( result . value ) === \"undefined\" ) { _errors . handleFailedCommandEH ( _errors . FAILED_CMD_STATUS . UNKNOWN_ERROR , \"Command failed without producing the expected error report\" , req , this , session , \"ReqHand\" ) ; } // An error occurred but we got an error report to use if ( result . status !== 0 ) { _errors . handleFailedCommandEH ( _errors . FAILED_CMD_STATUS_CODES_NAMES [ result . status ] , result . value . message , req , this , session , \"ReqHand\" ) ; } // If we arrive here, everything should be fine, birds are singing, the sky is blue this . success ( session . getId ( ) , result . value ) ; } , response . respondBasedOnResult = _respondBasedOnResultDecorator ;", "del_tokens": "", "commit_type": "move"}
{"commit_tokens": ["Add", "all", "PureScript", "files", "as", "webpack", "dependencies"], "add_tokens": "console . log ( Prelude , test , foo , baz ) ;", "del_tokens": "var bar = require ( './Foo/Bar.purs' ) ; console . log ( Prelude , test , foo , baz , bar ) ;", "commit_type": "add"}
{"commit_tokens": ["Implementing", "memory", "strategy", "for", "the", "middleware"], "add_tokens": "var curry = require ( \"bassline\" ) . curry ; module . exports = function ( memory ) { memory = memory || { } ; // Allows for a value to be placed into the memory at the given key if // the caller so choses to do so. function reserver ( key , value ) { memory [ key ] = value ; return value ; } get : function ( onget , onelse , key ) { if ( key in memory ) onget ( memory [ key ] ) ; else onelse ( curry ( reserver ) ( key ) , key ) ;", "del_tokens": "module . exports = function ( ) { var memory = { } ; getOrElse : function ( key , callback ) { console . log ( \"getting or elsing\" ) ; } , put : function ( key , value ) { console . log ( \"putting\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "ios", "safari", "autocomplete", "bug"], "add_tokens": "this . inputElement . addEventListener ( 'input' , function ( event ) { var isCustomEvent = event instanceof CustomEvent ; // Safari AutoFill fires CustomEvents // Set state to format before calling format listener if ( isCustomEvent ) { this . _stateToFormat = { selection : { start : 0 , end : 0 } , value : this . inputElement . value } ; } this . _formatListener ( ) ; if ( ! isCustomEvent ) { this . _fixLeadingBlankSpaceOnIos ( ) ; } } . bind ( this ) ) ;", "del_tokens": "this . inputElement . addEventListener ( 'input' , this . _formatListener . bind ( this ) ) ; this . _fixLeadingBlankSpaceOnIos ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "Node", ".", "contains", "workaround"], "add_tokens": "var i , j , keys , branch , boundNode if ( ! node . contains ( boundNode ) ) throw new Error ( 'The bound DOM Node must be either ' + 'contained in or equal to its parent binding.' )", "del_tokens": "var i , j , keys , branch , boundNode , document , walker , match // Node.contains is part of the DOM living standard, and might not be // implemented. In this case, TreeWalker may also work. if ( node . contains ) { if ( ! node . contains ( boundNode ) ) throw new Error ( 'The bound DOM Node must be either ' + 'contained in or equal to its parent binding.' ) } else { document = scope ? scope . document : window . document walker = document . createTreeWalker ( node ) while ( walker . nextNode ( ) ) if ( walker . currentNode === boundNode ) { match = true break } if ( ! match ) throw new Error ( 'The bound DOM Node must be either ' + 'contained in or equal to its parent binding. Also, the Node ' + '\"contains\" method is non-existent.' ) }", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "library", "require", "in", "the", "test", "suite"], "add_tokens": "var Db = require ( '../lib/db' ) ;", "del_tokens": "var Db = require ( '../' ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "back", "opts", ".", "length", "and", "upgrade", "hypdrive", "again"], "add_tokens": "opts . file = function ( name , opts ) { return raf ( path . join ( dir , name ) , opts . length , opts && typeof opts . length === 'number' && { length : opts . length } )", "del_tokens": "opts . file = function ( name ) { return raf ( path . join ( dir , name ) )", "commit_type": "add"}
{"commit_tokens": ["fix", "path", "name", "for", "diagnostics", "zip", "file"], "add_tokens": "var archFileName = path . join ( os . tmpdir ( ) , 'spm-diagnose.zip' )", "del_tokens": "var archFileName = os . tmpdir ( ) + 'spm-diagnose.zip'", "commit_type": "fix"}
{"commit_tokens": ["Add", "shorthand", "support", "to", "SSH", "connection", "pool", "."], "add_tokens": "var async = require ( 'async' ) , Connection = require ( './connection' ) ; // Create connection if necessary. connections = connections . map ( function ( connection ) { if ( connection instanceof Connection ) return connection ; return new Connection ( connection ) ; } ) ;", "del_tokens": "var async = require ( 'async' ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "heartbeats", "and", "amqpproduct", "name"], "add_tokens": "var url = require ( \"url\" ) ; var qs = require ( \"querystring\" ) ; confirm : false , heartbeat : 10 , productName : require ( \"./package.json\" ) . name function connect ( amqpUrl , behaviour , callback ) { return doConnect ( amqpUrl , behaviour , callback ) ; function doConnect ( amqpUrl , behaviour , callback ) { var urlObj = url . parse ( amqpUrl ) ; urlObj . search = qs . stringify ( _ . defaults ( qs . parse ( urlObj . search ) , { heartbeat : behaviour . heartbeat } ) ) ; amqpUrl = url . format ( urlObj ) ; var opts = { clientProperties : { product : behaviour . productName } } ; amqp . connect ( amqpUrl , opts , function ( connErr , newConnection ) {", "del_tokens": "confirm : false function connect ( url , behaviour , callback ) { return doConnect ( url , behaviour , callback ) ; function doConnect ( url , behaviour , callback ) { // TODO: enable heartbeats amqp . connect ( url , function ( connErr , newConnection ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "*", ".", "gql", "to", "supported", "file", "type"], "add_tokens": "exports . findFiles = function ( regex = / .*.(query|graphql|gql)$ / i ) {", "del_tokens": "exports . findFiles = function ( regex = / .*.(query|graphql)$ / i ) {", "commit_type": "add"}
{"commit_tokens": ["Update", "resin", "-", "lint", "to", "@balena", "/", "lint"], "add_tokens": "return new MBR ( buf ) . partitions . filter ( ( p ) => p . type ) ; const extended = info . partitions . find ( ( p ) => MBR . Partition . isExtended ( p . type ) ) ;", "del_tokens": "return new MBR ( buf ) . partitions . filter ( p => p . type ) ; const extended = info . partitions . find ( p => MBR . Partition . isExtended ( p . type ) ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "feature", "set", "draggable", "for", "individual", "block"], "add_tokens": "} , onComplete : function ( lastItem , lastBlock , setting ) { wall . container . find ( \".example-draggable\" ) . removeAttr ( \"data-position\" ) ; window [ \"console\" ] && console . log ( wall ) ;", "del_tokens": "//wall.container.width('auto')", "commit_type": "add"}
{"commit_tokens": ["fixing", "spacing", "in", "generated", "jsdoc", "."], "add_tokens": "* @ param { Object } call * @ returns { Object } * @ param { number } id * /", "del_tokens": "* @ param { Object } call * @ returns { Object } * @ param { number } id * /", "commit_type": "fix"}
{"commit_tokens": ["Move", "inline", "-", "requires", "-", "test", "into", "place", "make", "it", "pass"], "add_tokens": "plugins : [ require ( '../inline-requires.js' ) ] ,", "del_tokens": "plugins : [ '../inline-require.js' ] ,", "commit_type": "move"}
{"commit_tokens": ["Updated", "lib", ":", "Made", "device", ".", "open", "(", "cb", ")", "async"], "add_tokens": "* @ param { Function } callback open : function ( callback ) { var self = this if ( this . fd != null ) { return this . close ( function ( error ) { if ( error != null ) return callback . call ( self , error ) self . open ( self . path , self . mode , callback ) } ) } this . fs . open ( this . path , this . mode , function ( error , fd ) { self . fd = fd callback . call ( self , error , fd ) } )", "del_tokens": "open : function ( ) { if ( this . fd != null ) this . close ( ) this . fd = this . fs . openSync ( this . path , this . mode )", "commit_type": "update"}
{"commit_tokens": ["Add", "showXcodeLog", "cap", "and", "functionality"], "add_tokens": "import { settings as iosSettings , defaultServerCaps } from 'appium-ios-driver' ; import desiredCapConstraints from './desired-caps' ;", "del_tokens": "import { settings as iosSettings , desiredCapConstraints , defaultServerCaps } from 'appium-ios-driver' ;", "commit_type": "add"}
{"commit_tokens": ["added", "ods", "support", "bumped", "j"], "add_tokens": ", path = require ( 'path' ) ; var jBin = path . join ( __dirname , '../../node_modules/j/bin/j.njs' ) + ' ' + filePath ; exec ( jBin , function ( error , stdout , stderr ) { if ( error !== null ) { error = new Error ( \"Could not extract \" + path . basename ( filePath ) + \", \" + error . message ) ; cb ( error , null ) ; return ; } cb ( null , stdout ) ; } ) ; types : [ \"application/vnd.ms-excel\" , \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" , \"application/vnd.ms-excel.sheet.binary.macroEnabled.12\" , \"application/vnd.ms-excel.sheet.macroEnabled.12\" , \"application/vnd.oasis.opendocument.spreadsheet\" ] , extract : extractText", "del_tokens": ", path = require ( 'path' ) ; var jBin = path . join ( __dirname , '../../node_modules/j/bin/j.njs' ) + ' ' + filePath ; exec ( jBin , function ( error , stdout , stderr ) { if ( error !== null ) { error = new Error ( \"Could not extract \" + path . basename ( filePath ) + \", \" + error ) ; cb ( error , null ) ; return ; } cb ( null , stdout ) ; } ) ; types : [ \"application/vnd.ms-excel\" , \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" , \"application/vnd.ms-excel.sheet.binary.macroEnabled.12\" , \"application/vnd.ms-excel.sheet.macroEnabled.12\" ] , extract : extractText", "commit_type": "add"}
{"commit_tokens": ["Add", "protocol", "methods", "for", "publish", "run", "command"], "add_tokens": "friendlyName : 'Base Test Poller' , injectableName : 'Task.Base.Test.Poller' , runJob : 'Job.Poller.Test' , 'ipmiSdrRoutingKey' , 'snmpRoutingKey'", "del_tokens": "friendlyName : 'Ipmi Sdr Requester' , injectableName : 'Task.Base.Ipmi.Sdr' , runJob : 'Job.Ipmi.Sdr' , 'ipmiSdrRoutingKey'", "commit_type": "add"}
{"commit_tokens": ["Remove", "console", "log", "statements", "and", "restore", "inputUnitsLeft", "logic"], "add_tokens": "inputUnitsLeft = ( inputs [ curInput ] ) ? ( ( null == inputs [ curInput ] . assetQuantity ) ? 0 : inputs [ curInput ] . assetQuantity ) : 0 ;", "del_tokens": "sconsole . log ( '===_computeAssetIds===' ) ; sconsole . log ( 'inputs:' ) ; inputs . forEach ( function ( i ) { sconsole . log ( inputs . toString ( ) ) ; } ) ; sconsole . log ( 'markerOutputIndex: ' + markerOutputIndex ) ; sconsole . log ( 'outputs' ) ; sconsole . log ( outputs ) ; sconsole . log ( 'assetQuantities:' ) ; sconsole . log ( assetQuantities ) ; sconsole . log ( '=======================' ) ; //inputUnitsLeft = (inputs[curInput]) // ? ((null == inputs[curInput].assetQuantity) ? 0 : inputs[curInput].assetQuantity) // : 0; inputUnitsLeft = 0 ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "log", "output", "fix", "display", "of", "array", "types"], "add_tokens": "return this . items . type + \"[]\" ;", "del_tokens": "console . log ( result ) ; return this . items + \"[]\" ;", "commit_type": "remove"}
{"commit_tokens": ["update", "tests", "for", "2", ".", "x"], "add_tokens": "* Copyright 2017 Brigham Young University module . exports = captureError ; function captureError ( ) { let e ; return { catch : function ( err ) { e = err ; } , get : function ( ) { return e ; } , report : function ( ) { if ( e ) throw e ; } } }", "del_tokens": "* Copyright 2016 Brigham Young University module . exports = function ( ) { const result = { } ; result . promise = new Promise ( function ( resolve , reject ) { result . resolve = resolve ; result . reject = reject ; } ) ; return result ; } ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "JS", "files", "to", "be", "wrapped", "by", "AMD", "define", "calls", "if", "they", "have", "a", "/", "**", "@amd", "*", "/", "pragma", "in", "them"], "add_tokens": "postTransforms : _ . sortBy ( _ . map ( postTransforms , function ( transform ) { } ) , 'priority' )", "del_tokens": "postTransforms : _ . map ( postTransforms , function ( transform ) { } )", "commit_type": "allow"}
{"commit_tokens": ["use", "handler", "path", "for", "zipping", "and", "uploading"], "add_tokens": "function getFolderName ( handler ) { return handler . split ( '.' ) [ 0 ] ; } function zipLambda ( lambdaConfig ) { // get folder name from handler const folderName = getFolderName ( lambdaConfig . handler ) ; const lambdaPath = path . join ( process . cwd ( ) , 'dist' , folderName ) ; exec ( ` ${ folderName } ${ folderName } ` ) ; zipLambda ( lambda ) ; zipLambda ( lambda ) ; const folderName = getFolderName ( lambda . handler ) ; -- zip - file fileb : //build/lambda/${folderName}.zip \\", "del_tokens": "function zipLambda ( name , includeConfig ) { // copy config file if ( includeConfig ) { exec ( ` ${ name } ` ) ; } const lambdaPath = path . join ( process . cwd ( ) , 'dist' , name ) ; exec ( ` ${ name } ${ name } ` ) ; zipLambda ( lambda . name , lambda . includeConfig ) ; // Update the zip file zipLambda ( name ) ; -- zip - file fileb : //build/lambda/${name}.zip \\", "commit_type": "use"}
{"commit_tokens": ["Move", "RSS", "alongside", "KML", "."], "add_tokens": "case '.rss' :", "del_tokens": "case '.rss' :", "commit_type": "move"}
{"commit_tokens": ["Add", "tasks", "dir", "to", "running", "GraoJs"], "add_tokens": "dirProject = process . cwd ( ) , dirProject = ( dirProject . indexOf ( 'tasks' ) >= 0 ) ? path . join ( dirProject , \"..\" ) : dirProject ; config = require ( path . resolve ( dirProject , 'config' , 'prod' ) ) ,", "del_tokens": "config = require ( path . join ( process . cwd ( ) , 'config' , 'prod' ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "set", "container", "page", "titles", "for", "widget", "multicontainer"], "add_tokens": "// Set tab titles var titles = this . model . get ( '_titles' ) ; for ( var page_index in titles ) { var accordian_toggle = this . containers [ page_index ] . find ( '.accordion-heading' ) . find ( '.accordion-toggle' ) ; accordian_toggle . html ( titles [ page_index ] ) ; } . addClass ( 'accordion-body collapse' )", "del_tokens": "// TODO: Set tab titles // // Apply flexible box model properties by adding and removing // // corrosponding CSS classes. // // Defined in IPython/html/static/base/less/flexbox.less // var flex_properties = ['vbox', 'hbox', 'center', 'end', 'center']; // for (var index in flex_properties) { // if (this.model.get('_' + flex_properties[index])) { // this.$el.addClass(flex_properties[index]); // } else { // this.$el.removeClass(flex_properties[index]); // } // } . addClass ( 'accordion-body collapse in' )", "commit_type": "add"}
{"commit_tokens": ["Updated", "NO_PROXY", "to", "include", "/", "log"], "add_tokens": "[ 'POST' , new RegExp ( '^/session/[^/]+/appium/device/hide_keyboard' ) ] , [ 'POST' , new RegExp ( '^/session/[^/]+/log' ) ]", "del_tokens": "[ 'POST' , new RegExp ( '^/session/[^/]+/appium/device/hide_keyboard' ) ]", "commit_type": "update"}
{"commit_tokens": ["Fixed", "falsy", "values", "merging", "."], "add_tokens": "var args = Array . prototype . slice . call ( arguments ) while ( args . length ) result = merge . call ( this , result , args . shift ( ) ) ;", "del_tokens": "var source , args = Array . prototype . slice . call ( arguments ) while ( ( source = args . shift ( ) ) ) result = merge . call ( this , result , source ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "upcoming", "crx", ".", "load", "(", "[", "file", "file", "...", "]", ")", "to", "filter", "unwanted", "items"], "add_tokens": "function buildXML ( taskConfig , ChromeExtension , callback ) { var dest = path . dirname ( taskConfig . dest ) ;", "del_tokens": "function buildXML ( ChromeExtension , callback ) { var dest = path . dirname ( ChromeExtension . dest ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "where", "we", "throw", "a", "file", "not", "found", "error"], "add_tokens": "throw new Error ( \"The filename you have given is not found at this url.\" ) ; return page . evaluate ( function ( file ) { var ret = false ; var styleSheets = Array . prototype . slice . call ( window . document . styleSheets ) ; styleSheets . forEach ( function ( sheet ) { if ( sheet . href . match ( file ) ) { ret = true ; } } ) ; return ret ; } , filename ) ;", "del_tokens": "phantom . exit ( 1 ) ; return page . evaluate ( function ( ) { return true ; } ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "copypaste", "bug", "for", "onBegin", "/", "onEachBegin", "callbacks"], "add_tokens": "await this . runCallbacks ( true , this . parent . onEachBeginCallbacks ) ; await this . runCallbacks ( true , this . onBeginCallbacks ) ;", "del_tokens": "await this . runCallbacks ( true , this . parent . onEachSuccessCallbacks ) ; await this . runCallbacks ( true , this . onSuccessCallbacks ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "angular", "-", "timeago", ".", "js"], "add_tokens": "prefixFromNow : 'dans' ,", "del_tokens": "prefixFromNow : 'en' ,", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "the", "Role", "tag", "."], "add_tokens": "/** @constructor */ shaka . dash . mpd . Role = function ( ) { /** @type {?string} */ this . value = null ; } ; /** @type {boolean} */ this . main = false ; / ** * @ type { ? string } * @ expose * / / ** * @ type { ! Array . < ! Node > } * @ expose * / /** @const {string} */ shaka . dash . mpd . Role . TAG_NAME = 'Role' ; var role = mpd . parseChild_ ( this , elem , mpd . Role ) ; this . main = role && role . value == 'main' ; / ** * Parses a \"Role\" tag . * @ param { ! shaka . dash . mpd . AdaptationSet } parent The parent AdaptationSet . * @ param { ! Node } elem The Role XML element . * / shaka . dash . mpd . Role . prototype . parse = function ( parent , elem ) { var mpd = shaka . dash . mpd ; // Parse attributes. this . value = mpd . parseAttr_ ( elem , 'value' , mpd . parseString_ ) ; } ;", "del_tokens": "/** @type {?string} */ /** @type {!Array.<!Node>} */", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "all", "dependencies", "and", "move", "to", "Karma", "runner"], "add_tokens": "var leche = require ( '../../lib/leche' ) ;", "del_tokens": "var sinon = compatRequire ( 'sinon' ) || sinon , assert = ( compatRequire ( 'chai' ) || chai ) . assert , leche = compatRequire ( '../../lib/leche' ) || leche ; / ** * An abstraction over require ( ) to allow these tests to be run in a browser . * @ param { string } name The name of the package to load . * @ returns { ? Object } The module in Node . js , null in browsers . * @ private * / function compatRequire ( name ) { if ( typeof require === 'function' ) { return require ( name ) ; } else { return null ; } }", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "backtraces", "with", "optargs", "and", "no", "arguments"], "add_tokens": "// This works before there is no prefix term than can be called with no normal argument but with an optarg if ( Array . isArray ( term [ 1 ] ) && ( term [ 1 ] . length > 1 ) ) { carify ( result , \", \" , underline ) ; }", "del_tokens": "carify ( result , \", \" , underline ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "IE", "invalid", "calling", "object"], "add_tokens": "return { } . toString . call ( value ) === '[object Date]' ; return { } . toString . call ( obj ) === '[object File]' ; return { } . toString . call ( obj ) === '[object Blob]' ; return { } . toString . call ( value ) === '[object Array]' ;", "del_tokens": "return toString . call ( value ) === '[object Date]' ; return toString . call ( obj ) === '[object File]' ; return toString . call ( obj ) === '[object Blob]' ; return toString . call ( value ) === '[object Array]' ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "name", "for", "config", "file", "to", "nativefier", ".", "json"], "add_tokens": "const APP_ARGS_FILE_PATH = __dirname + '/nativefier.json' ;", "del_tokens": "const APP_ARGS_FILE_PATH = __dirname + '/targetUrl.txt' ;", "commit_type": "change"}
{"commit_tokens": ["remove", "unused", "code", "from", "loader"], "add_tokens": "}", "del_tokens": "'js' : function ( test ) { test . deepEqual ( schema , loader ( __dirname + '/for-parser-tests/simple/schema.js' ) ) ; test . done ( ) ; } , } , // //'json': function (tests) { // tests.deepEqual(schema, loader(__dirname + '/for-parser-tests/simple/schema.js')); // tests.done(); //}", "commit_type": "remove"}
{"commit_tokens": ["add", "hostname", "ipv4", "ipv6", "&", "uri", "defined", "formats", "."], "add_tokens": "// convert defined formats to regex patterns delete data . format case 'date-time' : data [ 'pattern' ] = constants . FORMAT_REGEXPS [ 'date-time' ] break data [ 'pattern' ] = constants . FORMAT_REGEXPS [ 'email' ] case 'hostname' : data [ 'pattern' ] = constants . FORMAT_REGEXPS [ 'hostname' ] break case 'ipv4' : data [ 'pattern' ] = constants . FORMAT_REGEXPS [ 'ipv4' ] break case 'ipv6' : data [ 'pattern' ] = constants . FORMAT_REGEXPS [ 'ipv6' ] break case 'uri' : data [ 'pattern' ] = constants . FORMAT_REGEXPS [ 'uri' ] data [ 'pattern' ] = format", "del_tokens": "// convert formats data [ 'format' ] = constants . RFC5332Email case 'date-time' : data [ 'format' ] = constants . RFC3339DatetimePattern data [ 'format' ] = format", "commit_type": "add"}
{"commit_tokens": ["Improve", "the", "foldl", "()", "foldr", "()", "performances"], "add_tokens": "var foldl = curry ( function ( f , init , list ) { return list . reduce ( f , init ) } ) ; foldr : curry ( function ( f , init , list ) { return list . reduceRight ( f , init ) } ) ,", "del_tokens": "var foldl = curry ( function ( f , init , list ) { return reduce ( f , init , list ) } ) ; // var foldl = curry(function (f, init, list) {return (list.length === 0) ? init : foldl(f, f(init, list[0]), list.slice(1));}); foldr : curry ( function ( f , init , list ) { return foldl ( f , init , reverse ( list ) ) } ) ,", "commit_type": "improve"}
{"commit_tokens": ["added", "in", "functionality", "to", "create", "directories", "specified", "in", "dest", "if", "necessary"], "add_tokens": "host : \"sample.hello.com\" , dest : \"test/html/\" , 'README.md'", "del_tokens": "host : \"sample.serverB.com\" , dest : \"/test/\" , '.gitignore'", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "veged", "/", "borschik", "/", "issues", "/", "93"], "add_tokens": ". join ( '|' ) + '|' + // RegExp to find comments \"/**/\" \"//\" and borschik.link(\"path/to/image.png\") '\\\\/\\\\/.*|\\\\/\\\\*[\\\\s\\\\S]*?\\\\*\\\\/|borschik\\\\.link\\\\([\\'\"]([^@][^\"\\']+?)[\\'\"]\\\\)' , 'g' ) , . replace ( allIncRe , function ( _ , incCommFile , incStrFile , borschikLink ) { if ( incFile ) { includes . push ( { file : _this . pathTo ( incFile ) , type : incStrFile ? 'include-json' : 'include-inline' } ) ; } else if ( borschikLink ) { file : _this . pathTo ( borschikLink ) ,", "del_tokens": ". join ( '|' ) , 'g' ) , / ** * RegExp to find borschik . link ( \"path/to/image.png\" ) * @ const * @ type { RegExp } * / var borschikLinkRe = / \\/\\/.*|\\/\\*[\\s\\S]*?\\*\\/|borschik\\.link\\(['\"]([^@][^\"']+?)['\"]\\) / g ; . replace ( allIncRe , function ( _ , incCommFile , incStrFile ) { includes . push ( { file : _this . pathTo ( incFile ) , type : incStrFile ? 'include-json' : 'include-inline' } ) ; return uniqStr ; } ) // finds borschik.link() . replace ( borschikLinkRe , function ( _ , include ) { if ( include ) { file : _this . pathTo ( include ) ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "parser", "encode", "/", "decode", "test", "with", "long", "dash"], "add_tokens": "it ( 'should encode a utf8 special chars message packet' , function ( done ) { encode ( { type : 'message' , data : 'utf8  string' } f nction(d a ta) { expect ( decode ( data ) ) . to . eql ( { type : 'message' , data : 'utf8  string' } ; done ( ) ; } ) ; } ) ; encPayload ( [ { type : 'message' , data : 'a' } , { type : 'ping' } ] , function ( data ) {", "del_tokens": "encPayload ( [ { type : 'message' , data : 'a' } , { type : 'ping' } ] , function ( data ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "id#toString", "()", "to", "the", "bottom", "of", "the", "file", "and", "add", "a", "function", "comment", "block", "."], "add_tokens": "/ ** * The id wrap 's overidden toString() function proxies up to the id' s * description method : [ [ id descrption ] UTF8String ] * / proto . toString = function toString ( ) { return this ( 'description' ) ( 'UTF8String' ) ; }", "del_tokens": "proto . toString = function toString ( ) { return this ( 'description' ) ( 'UTF8String' ) ; }", "commit_type": "move"}
{"commit_tokens": ["fix", "suffix", "and", "prefix", "settings", "also", "lint", "tenprint", "sketch"], "add_tokens": "const createSketch = require ( '../' ) ; context . fillStyle = 'black' ; context . lineWidth = '4' ; context . strokeStyle = 'white' ;", "del_tokens": "const createSketch = require ( \"../\" ) ; console . log ( tiles ) ; context . fillStyle = \"black\" ; context . lineWidth = \"4\" ; context . strokeStyle = \"white\" ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "default", "grunt", "task", "to", "run", "only", "the", "test", "task"], "add_tokens": "grunt . registerTask ( 'default' , [ 'test' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'build' ] ) ;", "commit_type": "change"}
{"commit_tokens": ["Adds", "support", "for", "css", "@apply", "rule"], "add_tokens": "var CSS_SELECTOR = RegExp ( '([{}]|^)[; ]*((?:[^@ ;{}][^{}]*)?[^@ ;{}:] ?)(?={)|' + S_LINESTR , 'g' )", "del_tokens": "var CSS_SELECTOR = RegExp ( '([{}]|^)[ ;]*([^@ ;{}][^{}]*)(?={)|' + S_LINESTR , 'g' )", "commit_type": "add"}
{"commit_tokens": ["added", "linuxAgent", "and", "helper", "linuxMetrics", "for", "osMetrics"], "add_tokens": "var osPlattform = os . platform ( ) if ( os . platform ( ) === 'linux' ) { var LinuxAgent = require ( './linuxAgent.js' ) return new LinuxAgent ( ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "in", "bbox", "calculation", "of", "bezier", "curves"], "add_tokens": "//console.log('pointAt', t, tInAngle, this.delta) //console.log(angle) while ( this . theta < angle ) angle -= 360 return this . pointAt ( ( ( angle - this . theta ) % 360 ) / ( this . delta ) ) // TODO: replace that call with pointAtAngle //return this.pointAt(((angle-1)%360)/(2-1)) if ( a == 0 ) return [ - c / b ] . filter ( function ( el ) { return el > 0 && el < 1 } )", "del_tokens": "//console.log('pointAt', t, tInAngle) //console.log(angle-1) return this . pointAt ( ( ( angle - 1) % 3 60) / (  2- 1 ))", "commit_type": "fix"}
{"commit_tokens": ["Improved", "skin", "-", "win7", "for", "tables", "and", "columnview"], "add_tokens": "// Remove expander and add a trailing triangle instead // var $expander = $(node.span).find(\"span.fancytree-expander\").detach(); // $(node.span).append($expander); // $(node.span).find(\"span.fancytree-expander\").hide(); $ ( node . span ) . find ( \"span.fancytree-expander\" ) . remove ( ) ; if ( node . hasChildren ( ) !== false && ! $ ( node . span ) . find ( \"span.fancytree-cv-right\" ) . length ) { $ ( node . span ) . append ( $ ( \"<span class='fancytree-icon fancytree-cv-right'>\" ) ) ; } // Move <ul> with children into the appropriate <td>", "del_tokens": "// Move <ul> with children into the appropriate <td>", "commit_type": "improve"}
{"commit_tokens": ["Fix", "silly", "error", "where", "sychronous", "resolve", "was", "being", "used", "after", "async", "-", "resolve", "calculation"], "add_tokens": "return loadModule ( modulePath ) ;", "del_tokens": "return loadModule ( require . resolve ( modulePath ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "hook", "into", "Model", "onChange", "event"], "add_tokens": "const onChange = ( ) => { if ( typeof origOpts . onChange === 'function' ) { origOpts . onChange ( ) ; } $rootScope . $evalAsync ( ) ; } ;", "del_tokens": "const onChange = ( ) => { $rootScope . $evalAsync ( ) ; } ;", "commit_type": "add"}
{"commit_tokens": ["Change", "signature", "of", "onDeviceDisconnected", "."], "add_tokens": "* @ param { function ( error : ? Error , device : Device ) } listener - callback returning error as a reason of disconnection onDeviceDisconnected ( deviceIdentifier : string , listener : ( error : ? Error , device : Device ) => void ) : Subscription { if ( deviceIdentifier !== device . id ) return", "del_tokens": "* @ param { function ( error : ? Error , device : ? Device ) } listener - callback returning error as a reason of disconnection onDeviceDisconnected ( deviceIdentifier : string , listener : ( error : ? Error , device : ? Device ) => void ) : Subscription { if ( deviceIdentifier !== device . uuid ) return", "commit_type": "change"}
{"commit_tokens": ["Updated", "make", "-", "grid", "-", "columns", "mixin", "to", "create", "supported", "column", "classes", "with", "styles", "that", "match", "latest", "Bootstrap", "styles"], "add_tokens": "* Copyright 2017 - 2019 UCF Web Communications * Copyright 2017 - 2019 UCF Web Communications", "del_tokens": "* Copyright 2017 - 2018 UCF Web Communications * Copyright 2017 - 2018 UCF Web Communications", "commit_type": "update"}
{"commit_tokens": ["Fixed", "lint", "issues", "in", "tests", "."], "add_tokens": "it ( 'should report start errors' , function ( ) { it ( 'should report and rethrow stop errors' , function ( ) {", "del_tokens": "it ( 'should report start errors' , function ( ) { it ( 'should report and rethrow stop errors' , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "dont", "call", "done", "twice"], "add_tokens": "if ( server . _handle ) { server . close ( ) ; } if ( secureServer . _handle ) { secureServer . close ( ) ; } done ( ) ;", "del_tokens": "if ( server . _handle ) { server . close ( done ) ; } if ( secureServer . _handle ) { secureServer . close ( done ) ; }", "commit_type": "make"}
{"commit_tokens": ["Fixing", "a", "bug", "in", "the", "define", "(", "AMD", "/", "requirejs", ")", "call"], "add_tokens": "root . define ( factory ( ) ) ;", "del_tokens": "root . define ( [ ] , function ( ) { // Export to global too, for backward compatiblity root . Mediator = factory ( ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "env", "variable", "preparsing", "for", "Windows"], "add_tokens": "var preparser = require ( './../preparser' ) ; vorpal . command ( 'echo [arg...]' ) . parse ( preparser ) . option ( '-e' , 'enable interpretation of the following backslash escapes' ) . option ( '-E' , 'explicitly suppress interpretation of backslash escapes' ) . action ( function ( args , callback ) {", "del_tokens": "vorpal . command ( 'echo [arg...]' ) . option ( '-e' , 'enable interpretation of the following backslash escapes' ) . option ( '-E' , 'explicitly suppress interpretation of backslash escapes' ) . action ( function ( args , callback ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "domain", "matching"], "add_tokens": "if ( ! testHost . endsWith ( baseContextHost ) ) { return true ; } let prefix = testHost . slice ( 0 , - baseContextHost . length ) ; if ( prefix . length > 0 && ! prefix . endsWith ( '.' ) ) { return true ; return false ; // By specifying context params, you can filter out the number of rules which are // considered. // Lazilly fill this out to be more efficient // Element type checks // Domain option check if ( contextParams . domain !== undefined && parsedFilterData . options ) { let domainOption = parsedFilterData . options . find ( ( parsedFilter ) => parsedFilter . startsWith ( 'domain' ) ) ; if ( domainOption ) { let domains = domainOption . split ( '=' ) [ 1 ] . trim ( ) . split ( '|' ) ; if ( domains . every ( ( domain ) => isThirdPartyHost ( domain , contextParams . domain ) ) ) { return false ; } } } let inputHostIsThirdParty = isThirdPartyHost ( parsedFilterData . host , inputHost ) ;", "del_tokens": "let index = testHost . indexOf ( baseContextHost ) ; if ( index === - 1 ) { return false ; return index + baseContextHost . length !== testHost . length ; let inputHostIsThirdParty = isThirdPartyHost ( parsedFilterData . domain , inputHost ) ;", "commit_type": "add"}
{"commit_tokens": ["uses", "Observation", ".", "updateUntil", "for", "dynamic", "depths", "we", "should", "change", "this", "to", "read", "the", "observationInfo", "value", "instead"], "add_tokens": "var recordingObservation = Observation . isRecording ( ) ; if ( recordingObservation && this . _canObserve !== false ) { if ( recordingObservation && this . observedInfo && this . observedInfo . getDepth ( ) >= recordingObservation . getDepth ( ) ) { Observation . updateUntil ( this . observedInfo ) ; }", "del_tokens": "if ( Observation . isRecording ( ) && this . _canObserve !== false ) {", "commit_type": "use"}
{"commit_tokens": ["Changed", "tests", "to", "be", "quicker"], "add_tokens": "require . define ( \"/lib/index.js\" , function ( require , module , exports , __dirname , __filename , process , global ) { / ** * * @ projectName nools * @ github https : //github.com/C2FO/nools * @ includeDoc [ Change Log ] . . / History . md * @ header [ . . / readme . md ] * / \"use strict\" ;", "del_tokens": "require . define ( \"/lib/index.js\" , function ( require , module , exports , __dirname , __filename , process , global ) { \"use strict\" ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "naming", "issue", "with", "loss", "function", "update"], "add_tokens": "loss = lossFunction ; var solution = layoutFunction ( data , { lossFuncton : loss } ) ; if ( ! arguments . length ) return loss ; loss = _ ;", "del_tokens": "lossFunction = loss ; var solution = layoutFunction ( data , { lossFuncton : lossFunction } ) ; if ( ! arguments . length ) return lossFunction ; lossFunction = _ ;", "commit_type": "fix"}
{"commit_tokens": ["move", "cost", "into", "the", "GraphNode", "object", "preparing", "for", "variable", "weighted", "paths"], "add_tokens": "var gScore = currentNode . g + neighbor . cost ( ) ;", "del_tokens": "// 1 is the distance from a node to it's neighbor - this could be variable for weighted paths. var gScore = currentNode . g + 1 ;", "commit_type": "move"}
{"commit_tokens": ["Make", "UNIX", "line", "endings", "mandatory"], "add_tokens": "cmd : \"tabfix -t --line=UNIX -r -m*.js,*.css,*.html,*.json -inode_modules src demo test\"", "del_tokens": "cmd : \"tabfix -t -r -m*.js,*.css,*.html,*.json -inode_modules src demo test\"", "commit_type": "make"}
{"commit_tokens": ["fixed", "issue", "with", "links", "on", "touch", "devices", "(", "tap", "wasn", "t", "working", ")"], "add_tokens": "if ( event . touches . length === 1 ) { // Never prevent taps on anchors and images if ( event . target . tagName . toLowerCase ( ) === 'a' || event . target . tagName . toLowerCase ( ) === 'img' ) { return ; }", "del_tokens": "if ( event . touches . length == 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "items", "list", "overlay", "position", "."], "add_tokens": "position : 'fixed' ,", "del_tokens": "position : 'absolute' ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "for", "skipping", "removal", "of", "dom", "node", "in", "etch", ".", "destroy"], "add_tokens": "export function destroy ( component , remove = true ) { destroySync ( component , remove ) destroySync ( component , remove ) export function destroySync ( component , remove = true ) { if ( syncDestructionsInProgressCounter === 1 && remove ) component . element . remove ( )", "del_tokens": "export function destroy ( component ) { destroySync ( component ) destroySync ( component ) export function destroySync ( component ) { if ( syncDestructionsInProgressCounter === 1 ) component . element . remove ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "minSizeLimit", "option"], "add_tokens": "minSizeError : \"{file} is too small, minimum file size is {minSizeLimit}.\" , fontSize : '118px' ,", "del_tokens": "minSizeError : \"{file} is too small, minimum file size is {minsizeLimit}.\" , fontSize : '118px'", "commit_type": "add"}
{"commit_tokens": ["Make", "writeMockToDisk", "public", "so", "Record", "can", "use", "it"], "add_tokens": "function writeMockToDisk ( response , path ) { var serializedResponse = JSON . stringify ( response , true , 2 ) ; // write file async to disk. overwrite if it already exists. prettyprint. fs . writeFile ( path , serializedResponse ) ; } this . writeMockToDisk = writeMockToDisk ;", "del_tokens": "// TODO: re-factor to remove dupe in mock.js, record.js function writeMockToDisk ( response , path ) { var serializedResponse = JSON . stringify ( response , true , 2 ) ; // write file async to disk. overwrite if it already exists. prettyprint. fs . writeFile ( path , serializedResponse ) ; }", "commit_type": "make"}
{"commit_tokens": ["added", "Casper", ".", "getGlobal", "()"], "add_tokens": "* Retrieves current document url . / ** * Retrieves global variable . * * @ param String name The name of the global variable to retrieve * @ return mixed * / getGlobal : function ( name ) { return this . evaluate ( function ( ) { return window [ window . __casper_params__ . name ] ; } , { 'name' : name } ) ; } ,", "del_tokens": "* Retrieve current document url .", "commit_type": "add"}
{"commit_tokens": ["implement", "login", "with", "success", "and", "login", "that", "failed", "(", "CMS", "-", "3", ")"], "add_tokens": "define ( [ 'jquery' , 'knockout' , './MainModel' , './TabModel' , 'bootstrap/button' , 'bootstrap/transition' , 'bootstrap/collapse' , 'bootstrap/dropdown' ] , function ( $ , ko , Main , Tab ) {", "del_tokens": "define ( [ 'jquery' , 'knockout' , './MainModel' , './TabModel' , 'bootstrap/button' , 'bootstrap/transition' , 'bootstrap/collapse' ] , function ( $ , ko , Main , Tab ) {", "commit_type": "implement"}
{"commit_tokens": ["use", "Step", "()", "in", "ActivityPump", ".", "checkCredentials", "()"], "add_tokens": "var user = null ; Step ( function ( ) { User . get ( nickname , this ) ; } , function ( err , result ) { if ( err ) throw err ; user = result ; bcrypt . compare ( password , user . passwordHash , this ) ; } , function ( err , res ) { if ( err ) { callback ( err , null ) ; } else if ( ! res ) { callback ( null , null ) ; } else { // Don't percolate that hash around user . sanitize ( ) ; callback ( null , user ) ; } ) ;", "del_tokens": "User . get ( nickname , function ( err , user ) { if ( err ) { callback ( err , null ) ; } else { bcrypt . compare ( password , user . passwordHash , function ( err , res ) { if ( err ) { callback ( err , null ) ; } else { // Don't percolate that hash around user . sanitize ( ) ; callback ( null , user ) ; } } ) ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "trailing", "whitespace", "character", "when", "verifying", "http", "-", "01", "challenge", "response"], "add_tokens": "const data = ( resp . data || '' ) . replace ( / \\s+$ / , '' ) ; if ( ! data || ( data !== keyAuthorization ) ) {", "del_tokens": "if ( ! resp . data || ( resp . data !== keyAuthorization ) ) {", "commit_type": "allow"}
{"commit_tokens": ["add", "point", "-", "specific", "radius", "support", "for", "the", "scatterplot", "layer"], "add_tokens": "color : [ 88 , 9 , 124 ] , radius : ( Math . random ( ) * ( 15 - 5 + 1 ) + 5 ) / 10 // [0.5, 1.5]", "del_tokens": "color : [ 88 , 9 , 124 ]", "commit_type": "add"}
{"commit_tokens": ["add", "test", "to", "cover", "update", "function", "add", "merge", "style", "update", "pass", "option", "to", "model", "toJSON"], "add_tokens": "var _ = require ( 'lodash' ) ; var modelTests = require ( './test.model.js' ) ; var collectionTests = require ( './test.collection.js' ) ; collectionTests ( d ) ; modelTests ( d ) ;", "del_tokens": "var _ = require ( 'lodash' ) ; require ( './test.model.js' ) ( d ) ; require ( './test.collection.js' ) ( d ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "creating", "array", "with", "a", "given", "size", ":", "lenth", "--", ">", "length"], "add_tokens": "var points = new Array ( keys . length ) ;", "del_tokens": "var points = new Array ( keys . lenth ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "Sass", "compiling", "and", "Autoprefixer", "task"], "add_tokens": "var assetsDir = './lib/client/assets/' ; return gulp . src ( [ './*.js' , './lib/*.js' , assetsDir + 'scripts/**/*.js' ] ) gulp . task ( 'styles' , function ( ) { return gulp . src ( assetsDir + 'styles/*.scss' ) . pipe ( $ . sass ( ) ) . pipe ( $ . autoprefixer ( ) ) . pipe ( gulp . dest ( assetsDir + 'styles' ) ) ; } ) ; gulp . task ( 'build' , [ 'styles' ] ) ; gulp . task ( 'default' , [ 'test' , 'build' ] ) ;", "del_tokens": "return gulp . src ( [ '*.js' , 'lib/*.js' , 'lib/client/assets/scripts/**/*.js' ] ) gulp . task ( 'default' , [ 'test' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "rollup", "trying", "to", "build", "the", "yeoman", "generator"], "add_tokens": "const configurations = getPackages ( __dirname ) . filter ( pkg => pkg . package [ \"slate-kit\" ] && pkg . package [ \"slate-kit\" ] . type === \"module\" ) . reduce ( ( acc , { package : pkg , location } ) => [ ... acc , ... factory ( pkg , location ) ] , [ ] ) ;", "del_tokens": "const configurations = getPackages ( __dirname ) . reduce ( ( acc , { package : pkg , location } ) => [ ... acc , ... factory ( pkg , location ) ] , [ ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "in", "header", "middleware", "to", "parse", "body", "content"], "add_tokens": "app . use ( function ( req , res , next ) { if ( req . header ( 'Content-Type' ) && req . header ( 'Content-Type' ) === 'application/vnd.api+json' ) { req . rawBody = '' ; req . setEncoding ( 'utf8' ) ; req . on ( 'data' , function ( chunk ) { req . rawBody += chunk ; } ) ; req . on ( 'end' , function ( ) { try { req . body = JSON . parse ( req . rawBody ) } catch ( e ) { console . error ( 'failed to parse raw request body' ) } console . log ( req . body ) next ( ) ; } ) ; } else { console . log ( req . body ) next ( ) ; }", "del_tokens": "var remotes = app . remotes ( ) ; remotes . after ( '**' , function setJSONApiHeader ( ctx , next ) { ctx . res . set ( { 'Content-Type' : 'application/vnd.api+json' } ) ; next ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "relative", "path", "from", "cwd", "to", "avoid", "problems", "with", "paths", "with", "spaces"], "add_tokens": "return childProcess . spawn ( './' + PROTRACTOR_COMMAND , args , { command = childProcess . spawn ( './' + WEB_DRIVER_COMMAND , [ WEB_DRIVER_START_COMMAND ] , { 'cwd' : PROTRACTOR_DIR } ) ;", "del_tokens": "return childProcess . spawn ( path . resolve ( PROTRACTOR_DIR , PROTRACTOR_COMMAND ) , args , { command = childProcess . spawn ( path . resolve ( PROTRACTOR_DIR , WEB_DRIVER_COMMAND ) , [ WEB_DRIVER_START_COMMAND ] , { 'cwd' : PROTRACTOR_DIR } ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "props", ".", "disabled", "to", "prevent", "erroring", "when", "soundfont", "isn", "t", "loaded"], "add_tokens": "instrument : null , this . oscillator = new Oscillator ( { audioContext , gain : 0.1 , } ) ; componentDidMount ( ) { // Sound names here: http://gleitz.github.io/midi-js-soundfonts/MusyngKite/names.json Soundfont . instrument ( audioContext , 'acoustic_grand_piano' ) . then ( ( instrument ) => { this . setState ( { instrument , } ) ; } ) ; } const audioNode = this . state . instrument . play ( midiNumber ) ; disabled = { ! this . state . instrument } disabled = { ! this . state . instrument }", "del_tokens": "// Sound names here: http://gleitz.github.io/midi-js-soundfonts/MusyngKite/names.json Soundfont . instrument ( audioContext , 'acoustic_grand_piano' ) . then ( ( instrument ) => { this . instrument = instrument ; } ) ; oscillator = new Oscillator ( { audioContext , gain : 0.1 , } ) ; const audioNode = this . instrument . play ( midiNumber ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "path", "instead", "of", "url"], "add_tokens": "pageReference = prefix + new Buffer ( req . host + req . baseUrl + req . path ) . toString ( 'base64' ) ;", "del_tokens": "pageReference = prefix + new Buffer ( req . host + req . baseUrl + req . url ) . toString ( 'base64' ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "response", "handler"], "add_tokens": "globalResponseInterceptor : function ( dataset_id , params , cb ) { return cb ( ) ; } , doResponseInterceptor : function ( dataset_id , params , cb ) { self . getDataset ( dataset_id , function ( err , dataset ) { if ( err ) return cb ( err ) ; if ( dataset . responseInterceptor ) { dataset . responseInterceptor ( dataset_id , params , cb ) ; } else { self . globalResponseInterceptor ( dataset_id , params , cb ) ; } } ) ; } , setGlobalResponseInterceptor : generateGlobalSetter ( 'globalResponseInterceptor' , self ) , doResponseInterceptor : self . doResponseInterceptor ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Removed", "JS", ".", "Class", "from", "parser"], "add_tokens": "_parser = require ( './parser' ) , __ = $$ . import ( 'scanner' ) ; _parser . Parser . call ( this ) ; . include ( __ . Scanner ) ; _parser . Parser . prototype ,", "del_tokens": "__ = $$ . import ( 'reader' , 'scanner' , 'parser' ) ; __ . Parser . __init__ ( this ) ; . include ( __ . Scanner ) . include ( __ . Parser ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "demo", "output", "easier", "to", "read"], "add_tokens": "console . log ( 'Demoing output for ' + info [ 0 ] ) } , 110 )", "del_tokens": "} , 10 )", "commit_type": "make"}
{"commit_tokens": ["added", "support", "for", "searching", "retweets"], "add_tokens": "favs : 'http://api.twitter.com/1/favorites/%user%.json?page=%page|1%include_entities=true&skip_status=true' , retweets : 'http://api.twitter.com/1/statuses/retweeted_by_user.json?screen_name=%user%&count=%limit|200%&since_id=%since|remove%&page=%page|1%' container [ twitterlib ] . custom ( 'retweets' ) ;", "del_tokens": "favs : 'http://api.twitter.com/1/favorites/%user%.json?page=%page|1%include_entities=true&skip_status=true'", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "href", "source", "is", "not", "replace", "with", "mapped", "value"], "add_tokens": "xmlDoc . find ( '//*[@src] | //a[@href]' ) . forEach ( function ( mediaEl ) { var attribute = ( mediaEl . name ( ) . toLowerCase ( ) === 'a' ) ? 'href' : 'src' ; var src = mediaEl . attr ( attribute ) . value ( ) ; mediaEl . attr ( attribute , replacement ) ;", "del_tokens": "xmlDoc . find ( '//*[@src]' ) . forEach ( function ( mediaEl ) { var src = mediaEl . attr ( 'src' ) . value ( ) ; mediaEl . attr ( 'src' , replacement ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "ipify", ".", "org", "as", "a", "fallback"], "add_tokens": "var options = { host : 'api.ipify.org' , protocol . request ( options , httpCallback )", "del_tokens": "var canihazipOptions = { host : 'canihazip.com' , path : '/s' protocol . request ( canihazipOptions , httpCallback )", "commit_type": "use"}
{"commit_tokens": ["use", "rexxar", "widget", "helpers", "deprecate", "getRexxarWidget"], "add_tokens": "exports . dispatch = exports . callbackListener = exports . assemblePayload = exports . widgetMessenger = exports . rexxarFetch = exports . getRexxarWidget = undefined ; var _widgetMessenger = require ( './widgetMessenger' ) ; var _widgetMessenger2 = _interopRequireDefault ( _widgetMessenger ) ; var _assemblePayload = require ( './assemblePayload' ) ; var _assemblePayload2 = _interopRequireDefault ( _assemblePayload ) ; var _callbackListener = require ( './callbackListener' ) ; var _callbackListener2 = _interopRequireDefault ( _callbackListener ) ; var _dispatch = require ( './dispatch' ) ; var _dispatch2 = _interopRequireDefault ( _dispatch ) ; exports . rexxarFetch = _rexxarFetch2 . default ; exports . widgetMessenger = _widgetMessenger2 . default ; exports . assemblePayload = _assemblePayload2 . default ; exports . callbackListener = _callbackListener2 . default ; exports . dispatch = _dispatch2 . default ;", "del_tokens": "exports . rexxarFetch = exports . getRexxarWidget = undefined ; exports . rexxarFetch = _rexxarFetch2 . default ;", "commit_type": "use"}
{"commit_tokens": ["Added", "missing", "data", "parameter", "to", "the", "internal", "get", "function", "that", "s", "called", "in", "stripe", ".", "token", ".", "retrieve", "."], "add_tokens": "get ( \"/v1/tokens/\" + token_id , { } , cb )", "del_tokens": "get ( \"/v1/tokens/\" + token_id , cb )", "commit_type": "add"}
{"commit_tokens": ["Use", "typed", "array", "to", "convert", "BRGA", "pixels", "when", "loading", "image"], "add_tokens": "var rgba = new Uint8Array ( width * height * 4 ) rgba [ i + 0 ] = pixels [ i + 2 ] rgba [ i + 1 ] = pixels [ i + 1 ] rgba [ i + 2 ] = pixels [ i + 0 ] rgba [ i + 3 ] = pixels [ i + 3 ]", "del_tokens": "var rgba = [ ] rgba . push ( pixels [ i + 2 ] , pixels [ i + 1 ] , pixels [ i + 0 ] , pixels [ i + 3 ] )", "commit_type": "use"}
{"commit_tokens": ["Make", "routine", "call", "synonym", "of", "the", "trigger", "action"], "add_tokens": "function call ( payload , ... args ) { return routine . trigger ( payload , ... args )", "del_tokens": "function call ( payload , enhancer = identity ) { return enhancer ( routine . trigger ( payload ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "base", "style", "for", "files", "tabs"], "add_tokens": "define ( 'hr/args' , [ ] , function ( ) { return { \"revision\" : 1382303007359 , \"baseUrl\" : \"/\" } ; } ) ;", "del_tokens": "define ( 'hr/args' , [ ] , function ( ) { return { \"revision\" : 1382302328094 , \"baseUrl\" : \"/\" } ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "trailing", "slash", "in", "allowedOrigins"], "add_tokens": "allowedOrigins : [ 'https://functions.azure.com' ] // Allows the portal to talk to the function app module . exports = ProjectCreateHandler ;", "del_tokens": "allowedOrigins : [ 'https://functions.azure.com/' ] // Allows the portal to talk to the function app module . exports = ProjectCreateHandler ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "select", "fields", "to", "be", "manually", "entered"], "add_tokens": "var progress = function ( results , cb ) { cb ( ) ; } ; prompt . before = input . before || progress ; prompt . after = input . after || progress ; prompt . before ( prompt , function ( skip ) {", "del_tokens": "var progress = function ( results , cb ) { cb ( ) ; } ; prompt . before = input . before || progress ; prompt . after = input . after || progress ; prompt . before ( results , function ( skip ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "tests", "for", "first", "three", "possible", "cases", "using", "translateProvider", ".", "registerLoader", "()"], "add_tokens": "if ( ! $translationTable [ langKey ] && ( ! $asyncLoaders . length ) ) {", "del_tokens": "if ( ! $translationTable [ langKey ] && ( ! $asyncLoaders . length || ! angular . isObject ( $asyncLoaders ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "nolayout", "option", "in", "favor", "of", "using", "middleware", "/", "events"], "add_tokens": "if ( view . options . nomerge ) continue ;", "del_tokens": "// if `view` is a function, it's probably from chaining // a collection method if ( typeof view === 'function' ) { return view . call ( this ) ; } // apply layout to partial, if defined if ( ! opts . noLayout ) { view = self . applyLayout ( view ) ; } if ( view . options . nomerge ) return ;", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "getAllResponseHeaders", "()", "and", "started", "abort", "()", "."], "add_tokens": "var defaultHeaders = { var headers = defaultHeaders ; this . abort ( ) ; setState ( this . OPENED ) ; if ( this . readyState < this . HEADERS_RECEIVED ) { throw \"INVALID_STATE_ERR: Headers have not been received.\" ; } var result = \"\" ; foreach ( header in headers ) { result += header + \": \" + headers [ header ] + \"\\r\\n\" ; } return result . substr ( 0 , result . length - 2 ) ; if ( this . readyState != this . OPENED ) { throw \"INVALID_STATE_ERR: connection must be opened before send() is called\" ; } setState ( this . OPENED ) ; if ( settings . method == \"GET\" || settings . method == \"HEAD\" ) { data = null ; } else if ( data ) { if ( ! headers [ \"Content-Type\" ] ) { headers [ \"Content-Type\" ] = \"text/plain;charset=UTF-8\" ; } headers = defaultHeaders ; this . readyState = this . UNSENT ; this . responseText = \"\" ; this . responseXML = \"\" ;", "del_tokens": "var headers = { return null ; setState ( this . OPENED ) ; if ( data ) {", "commit_type": "implement"}
{"commit_tokens": ["fixing", "case", "on", "authors", "in", "authors", "filter"], "add_tokens": "phaser . context . authors = opts . authors || phaser . utils . authors ( ) || [ ] ;", "del_tokens": "phaser . context . authors = opts . authors || phaser . utils . AUTHORS ( ) || [ ] ;", "commit_type": "fix"}
{"commit_tokens": ["added", "timeout", "to", "process", "ending"], "add_tokens": "retries = 10 * ( 1000 / delay ) ; if ( retries -- < 0 ) { clearInterval ( waitForProcessToDie ) ;", "del_tokens": "timeout = 10 * ( 1000 / delay ) ; timeout -= delay ; if ( timeout < 0 ) { clearInterval ( waitForProcessToDie ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "twitter", "grid", "added", "tests", "and", "updated", "documentation"], "add_tokens": "version : 'v2.10' , delete global . window ; delete global . document ;", "del_tokens": "version : 'v2.8' , delete global . window delete global . document", "commit_type": "add"}
{"commit_tokens": ["move", "rules", "to", "separate", "rules", ".", "js", "file"], "add_tokens": "addRules : require ( './rules' )", "del_tokens": "addRules : [ { 'type' : 'helper' , 'id' : 'test-helper' , 'name' : 'Test Helper' , 'matcher' : 'test-helper' , 'noParams' : true , 'styles' : { 'cursor' : 'pointer' } } , { 'type' : 'pattern' , 'id' : 'test-pattern' , 'name' : 'Test Pattern' , 'matcher' : 'TestPattern' , 'allowParamToValue' : false , 'styles' : { 'background-repeat' : '$0' } , 'arguments' : [ { 'n' : 'no-repeat' } ] } ]", "commit_type": "move"}
{"commit_tokens": ["Add", "key", "to", "all", "the", "blocks"], "add_tokens": "{ children . map ( block => < Block key = { block . property } { ... block } / > ) }", "del_tokens": "{ children . map ( props => < Block { ... props } / > ) }", "commit_type": "add"}
{"commit_tokens": ["add", "l10n", "-", "args", "support", "for", "l20n", "-", "xml", "bindings"], "add_tokens": "var args = nodes [ i ] . getAttribute ( 'l10n-args' ) ; if ( args ) { args = JSON . parse ( args ) ; } nodes [ i ] . innerHTML = ctx . get ( l10nId , args ) ; var attrs = ctx . getAttributes ( l10nId , args ) ;", "del_tokens": "nodes [ i ] . innerHTML = ctx . get ( l10nId ) ; var attrs = ctx . getAttributes ( l10nId ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "how", "we", "inherit", "static", "from", "couchbase", "document", ".", "started", "writing", "couchbase", "document", "populate", "code"], "add_tokens": "var k ; for ( k in hooks ) { for ( k in CouchbaseDocument ) { Model [ k ] = CouchbaseDocument [ k ] ; } / *['findById', '$_createModelObject'].forEach(function (f) { } ) ; * /", "del_tokens": "for ( var k in hooks ) { [ 'findById' ] . forEach ( function ( f ) { } ) ;", "commit_type": "change"}
{"commit_tokens": ["fixes", "https", ":", "//", "github", ".", "com", "/", "micromatch", "/", "micromatch", "/", "issues", "/", "113"], "add_tokens": "var isInside = node . isInside . paren || node . isInside . brace ; if ( parsed && type !== 'slash' && type !== 'bos' && ! isInside ) {", "del_tokens": "if ( parsed && type !== 'slash' && type !== 'bos' ) {", "commit_type": "fix"}
{"commit_tokens": ["remove", "method", "+", "test", "fix"], "add_tokens": "test ( 'InsertBefore: Use a string as the target parameter' , assert => { test ( 'InsertBefore: Use undefined as the target parameter' , assert => { test ( 'InsertBefore: Use an invalid HTMLElement target parameter' , assert => { test ( 'InsertBefore: Use undefined as the node parameter' , assert => {", "del_tokens": "test ( 'Use a string as the target parameter argument' , assert => { test ( 'Use undefined as the target parameter' , assert => { option = document . createElement ( 'option' ) ; test ( 'Use an invalid HTMLElement target parameter' , assert => { option = document . createElement ( 'option' ) ; test ( 'Use a string as the target parameter argument' , assert => {", "commit_type": "remove"}
{"commit_tokens": ["Use", "react", "-", "addons", "-", "test", "-", "utils"], "add_tokens": "const React = require ( \"react\" ) ; const TestUtils = require ( \"react-addons-test-utils\" ) ; const DayPicker = require ( \"../src/DayPicker\" ) ;", "del_tokens": "const React = require ( \"react/addons\" ) ; const DayPicker = require ( \"../src/DayPicker\" ) ; const TestUtils = React . addons . TestUtils ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "hardy", "clean", "to", "remove", "all", "screenshots"], "add_tokens": "} else if ( PROPERTIES . clean ) { // Check the screenshot directory exists. If it doesn't, there's nothing to clean if ( ! fs . existsSync ( 'screenshots/' ) ) { printMessageAndExit ( 'screenshot directory does not exist' , 1 ) ; } else { // Directory is there, let's remove everything in it cleanDirectory ( 'screenshots' ) ; createScreenshotsFolder ( ) ; printMessageAndExit ( 'Directory initialised' ) ; } function createScreenshotsFolder ( ) { } function createTestFolder ( ) { fs . writeFileSync ( 'test.feature' , \"Feature:\" ) ; createScreenshotsFolder ( ) ; function cleanDirectory ( dirPath ) { try { var files = fs . readdirSync ( dirPath ) ; } catch ( e ) { return ; } if ( files . length > 0 ) for ( var i = 0 ; i < files . length ; i ++ ) { var filePath = dirPath + '/' + files [ i ] ; if ( fs . statSync ( filePath ) . isFile ( ) ) fs . unlinkSync ( filePath ) ; else cleanDirectory ( filePath ) ; } fs . rmdirSync ( dirPath ) ; } ; module . exports = hardyCLI ( ) ;", "del_tokens": "function createTestFolder ( ) { fs . writeFileSync ( 'test.feature' , \"Feature:\" ) ; module . exports = hardyCLI ( ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "lever", "to", "handle", "numbers", "properly", "and", "added", "equals", "symbol"], "add_tokens": "'=' , // unify / binary '>=' , // more than or equal / binary '!=' , // not equals / binary '==' // equals decimalSymbol : '.'", "del_tokens": "'=' , // equality / binary '>=' // more than or equal / binary numberBodyTest : / ^[0-9.]$ /", "commit_type": "update"}
{"commit_tokens": ["Makes", "sure", "we", "only", "save", "each", "file", "once", "per", "process"], "add_tokens": "var saveFile = false ; jsstana . traverse ( ast , function ( node ) { if ( saveFile && ! self . _options . skipFileOverride ) { self . _saveFile ( file , ast ) ; } module . exports = ConfigGenerator ;", "del_tokens": "jsstana . traverse ( ast , function ( node ) { var saveFile ; if ( saveFile && ! self . _options . skipFileOverride ) { self . _saveFile ( file , ast ) ; } module . exports = ConfigGenerator ;", "commit_type": "make"}
{"commit_tokens": ["updated", "name", "of", "sha", "gen"], "add_tokens": "var hashStream = require ( './hash-stream' ) ,", "del_tokens": "var hashStream = require ( './sha-256-generator' ) ,", "commit_type": "update"}
{"commit_tokens": ["Added", "dependencies", "tests", "all", "passing"], "add_tokens": "// // Filter out a single test file for now // testFiles = testFiles.filter(function(x) { // // return !( // // x.indexOf('dependencies.json') != -1 // // ); // // return x.indexOf('ref.json') != -1 // // return x.indexOf('refRemote.json') != -1 // return x.indexOf('dependencies.json') != -1 // // return x.indexOf('maxProperties.json') != -1 // // return x.indexOf('maxLength.json') != -1 // // return x.indexOf('refRemote.json') != -1 // // return x.indexOf('dependencies.json') != -1 // }); // console.log(\"-------------------------------------------- Execute\")", "del_tokens": "// Filter out a single test file for now testFiles = testFiles . filter ( function ( x ) { // return !( // x.indexOf('dependencies.json') != -1 // ); // return x.indexOf('ref.json') != -1 // return x.indexOf('refRemote.json') != -1 return x . indexOf ( 'dependencies.json' ) != - 1 // return x.indexOf('maxProperties.json') != -1 // return x.indexOf('maxLength.json') != -1 // return x.indexOf('refRemote.json') != -1 // return x.indexOf('dependencies.json') != -1 } ) ; console . log ( \"-------------------------------------------- Execute\" )", "commit_type": "add"}
{"commit_tokens": ["using", "drafter", "instead", "of", "protagonist", "in", "the", "meantime", "so", "we", "can", "parse", "MSON", "as", "well"], "add_tokens": "var Drafter = require ( 'drafter' ) ; var drafter = new Drafter ( ) ; drafter . make ( data , function ( err , result ) {", "del_tokens": "var protagonist = require ( 'protagonist' ) ; protagonist . parse ( data , function ( err , result ) {", "commit_type": "use"}
{"commit_tokens": ["adds", "is", "-", "glob", "to", "detect", "globs"], "add_tokens": "var isGlob = require ( 'is-glob' ) ; // leave `pattern` unmodified tok . isGlob = isGlob ( pattern ) ; tok . dirname = tok . dirname ? unescape ( tok . dirname ) : '' ; tok . filename = tok . filename ? unescape ( tok . filename ) : '' ; tok . basename = tok . basename ? unescape ( tok . basename ) : '' ; tok . extname = tok . extname ? unescape ( tok . extname ) : '' ; tok . ext = tok . ext ? unescape ( tok . ext ) : '' ;", "del_tokens": "tok . dirname = unescape ( tok . dirname ) ; tok . filename = unescape ( tok . filename ) ; tok . basename = unescape ( tok . basename ) ; tok . extname = unescape ( tok . extname ) ; tok . ext = unescape ( tok . ext ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "watchCollection", "and", "fixing", "bugs"], "add_tokens": "var i , watchExp , firstChar ; firstChar = watchExp . charAt ( 0 ) ; if ( firstChar === '^' ) { scope . $watchCollection ( watchExp . substring ( 1 ) , scope . recomputeModel ) ; } else if ( firstChar === '*' ) { scope . $watch ( watchExp . substring ( 1 ) , scope . recomputeModel , true ) ; } else { scope . $watch ( watchExp , scope . recomputeModel ) ; }", "del_tokens": "var i , watchExp ; scope . $watch ( watchExp , scope . recomputeModel ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "global", "_", "by", "default"], "add_tokens": "engine = false ,", "del_tokens": "engine = 'underscore' ,", "commit_type": "use"}
{"commit_tokens": ["use", "jqLight", "instead", "of", "jQuery", ".", "-", ">", "cant", "use", ".", "find", "()", "function", ";", "using", ".", "querySelector", "()", "instead"], "add_tokens": "var wrapper = element [ 0 ] . querySelector ( '.scroller-wrapper' ) ;", "del_tokens": "var wrapper = element . find ( '.scroller-wrapper' ) . get ( 0 ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "keepCycle", "optional", "param", "to", "setMilliseconds", "method", "."], "add_tokens": "* @ param { Number } ms - The new duration of the timer * @ param { Boolean } [ keepCycle = false ] - If true , retains the decimal value from the previous tick , keeping the cycle consistent . Rieussec . prototype . setMilliseconds = function ( ms , keepCycle ) { // Retains the decimal portion of the previous number, which keeps the tick cycle consistent if ( keepCycle ) { ms = Math . floor ( ms ) + this . _milliseconds % 1 ; }", "del_tokens": "Rieussec . prototype . setMilliseconds = function ( ms ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "VFK", "/", "gulp", "-", "html", "-", "replace", "/", "issues", "/", "19"], "add_tokens": "var linefeed = / \\r\\n / g . test ( content ) ? '\\r\\n' : '\\n' ; var lines = linefeed ? content . split ( linefeed ) : [ content ] ;", "del_tokens": "var linefeed = content . match ( / [\\r\\n]+ / ) ; var lines = linefeed ? content . split ( linefeed [ 0 ] ) : [ content ] ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "-", "H", "for", "an", "horizontal", "millipede"], "add_tokens": ". option ( '-H, --horizontal' , 'rotate the millipede, and display it horizontally' )", "del_tokens": ". option ( '-h, --horizontal' , 'rotate the millipede, and display it horizontally' )", "commit_type": "use"}
{"commit_tokens": ["Adding", "application", "update", "()", "remove", "()"], "add_tokens": "// update an application // @param id: ID of the application to be updated // @param updates: JSON patch updates // @param userOpts: option overrides for this request // @returns Returns a promise that resolves to the updated application function update ( id , updates , userOpts ) { check . string ( id , 'id must be a string' ) ; check . array ( updates , 'updates must be an array' ) ; return context . http . makeRequest ( { method : 'PATCH' , body : updates , url : ` ${ ENDPT } ${ id } ` } , userOpts ) ; } // delete an application // @param id: ID of the application to be updated // @param userOpts: option overrides for this request // @returns Returns a promise function remove ( id , userOpts ) { check . string ( id , 'id must be a string' ) ; return context . http . makeRequest ( { method : 'DELETE' , url : ` ${ ENDPT } ${ id } ` } , userOpts ) ; } create , update , remove", "del_tokens": "create", "commit_type": "add"}
{"commit_tokens": ["fixed", "slow", "test", "by", "adding", "a", "new", "expected", "file", ".", "testing", "grunt", ".", "txt", "against", "mocha", ".", "txt", "makes", "no", "sense", "as", "mutationTest", ":", "grunt", "tests", "more", "files", "than", "mutationTest", ":", "mocha"], "add_tokens": "( function ( ) { 'use strict' ; var assertExpectedReport = require ( './test-utils' ) . assertExpectedReport ; describe ( 'Mutation Testing' , function ( ) { it ( 'flags all mutations for which a grunt run returns a good status' , function ( ) { assertExpectedReport ( 'tmp/grunt.txt' , 'test/expected/grunt.txt' ) ; } ) ; } ) ( ) ;", "del_tokens": "'use strict' ; var assertExpectedReport = require ( './test-utils' ) . assertExpectedReport ; describe ( 'Mutation Testing' , function ( ) { it ( 'flags all mutations for which a grunt run returns a good status' , function ( ) { assertExpectedReport ( 'tmp/grunt.txt' , 'test/expected/mocha.txt' ) ; } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "apostille", "hash", "in", "transaction"], "add_tokens": "// Full checksum is 0xFE (added automatically if hex txes) + 0x4E + 0x54 + 0x59 + hashing version byte checksum = \"4e5459\" + hashing . signedVersion ; checksum = \"4e5459\" + hashing . version ; let checksum = hash . substring ( 0 , 8 ) ; let dataHash = hash . substring ( 8 ) ; // Set message type to hexadecimal transaction . messageType = 0 ; \"hash\" : apostilleHash . substring ( 8 ) , \"hash\" : \"fe\" + apostilleHash , \"checksum\" : \"fe\" + apostilleHash . substring ( 0 , 8 ) ,", "del_tokens": "// Full checksum is 0xFE + 0x4E + 0x54 + 0x59 + hashing version byte checksum = \"fe4e5459\" + hashing . signedVersion ; checksum = \"fe4e5459\" + hashing . version ; let checksum = hash . substring ( 0 , 10 ) ; let dataHash = hash . substring ( 10 ) ; \"hash\" : apostilleHash . substring ( 10 ) , \"hash\" : apostilleHash , \"checksum\" : apostilleHash . substring ( 0 , 10 ) ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "lookup", "()"], "add_tokens": "if ( result && ( ( Array . isArray ( result ) && intKey in result ) || ( typeof result === 'string' && intKey < result . length ) ) ) { } else if ( result && typeof result === 'object' && key in result ) { result = result [ key ] ;", "del_tokens": "if ( result && typeof result === 'object' && key in result ) { result = result [ key ] ; } else if ( ( Array . isArray ( result ) && result . includes ( intKey ) ) || ( typeof result === 'string' && intKey < result . length ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "ki", "macro", "and", "includes"], "add_tokens": "case { _ macro ( $x . . . ) ( $y . . . ) } => { return # { } ; }", "del_tokens": "//case {_ macro ($x ...) ($y ...)} => { // return #{}; //}", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "error", "case", "work", "more", "reliably", "in", "IE8", "-", "10"], "add_tokens": "try { if ( $contents . length && $contents [ 0 ] === $form [ 0 ] ) { isFailure = false ; } } catch ( e ) { if ( e && e . number == - 2146828218 ) { // IE 8-10 throw a permission denied after the form reloads on the \"$contents[0] === $form[0]\" comparison isFailure = true ; } else { throw e ; } } // IE 8-10 don't always have the full content available right away, they need a litle bit to finish setTimeout ( function ( ) { internalCallbacks . onFail ( formDoc . body . innerHTML , fileUrl ) ; cleanUp ( true ) ; } , 100 ) ;", "del_tokens": "if ( $contents . length && $contents [ 0 ] === $form [ 0 ] ) { isFailure = false ; } internalCallbacks . onFail ( formDoc . body . innerHTML , fileUrl ) ; cleanUp ( true ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "tests", "and", "added", "default", "chapter", "titles", "for", "converted", "Bible", "projects"], "add_tokens": "chapterTOC . chunks . push ( 'title' ) ; fs . writeFileSync ( path . join ( chapterDir , 'title.' + chunk_ext ) , chapter . title ) ; } else { var title = localizeChapterTitle ( props . language . slug , chapter . number ) ; fs . writeFileSync ( path . join ( chapterDir , 'title.' + chunk_ext ) , title ) ; / ** * Returns a localized chapter title . e . g . \"Chapter 1\" * If the language does not have a match a default localization will be used . * @ param language_slug the language into which the chapter title will be localized * @ param chapter_number the chapter number that is being localized * / function localizeChapterTitle ( language_slug , chapter_number ) { var translations = { 'ar' : ' %', 'en' : 'Chapter %' , 'ru' : ' %', 'hu' : '%. fejezet' , 'sr-Latin' : ' %', 'default' : 'Chapter %' } ; var title = translations [ language_slug ] ; if ( ! title ) title = translations [ 'default' ] ; return title . replace ( '%' , chapter_number ) ; } localizeChapterTitle : localizeChapterTitle ,", "del_tokens": "chapterTOC . chunks . push ( 'title' ) ; fs . writeFileSync ( path . join ( chapterDir , 'title.' + chunk_ext ) , chapter . title )", "commit_type": "fix"}
{"commit_tokens": ["changed", "path", "of", "config", "file", "relative", "to", "node", "cwd"], "add_tokens": "// populate args object with key-value pairs process . stdout . write ( colors . yellow ( 'Deleting WASM template...\\n' ) ) ; process . stdout . write ( colors . cyan ( 'Creating WASM template...\\n' ) ) ; const config = require ( path . join ( process . cwd ( ) , './wasm.config.js' ) ) ;", "del_tokens": "process . stdout . write ( colors . cyan ( 'Creating WASM template...\\n' ) ) ; // populate args object with key-value pairs const config = require ( './../../../wasm.config.js' ) ; // const config = require('./../wasm.config.js');", "commit_type": "change"}
{"commit_tokens": ["Add", "events", "expand", "collapse", "and", "error"], "add_tokens": "var errorMessage ; // Error codes. // https://mapzen.com/documentation/search/http-status-codes/ errorMessage = 'A valid API key is needed for this search feature.' ; break ; case 404 : errorMessage = 'The search service cannot be found. :-(' ; break ; case 408 : errorMessage = 'The search service took too long to respond. Try again in a second.' ; break ; case 429 : errorMessage = 'There were too many requests. Try again in a second.' ; errorMessage = 'The search service is not working right now. Please try again later.' ; break ; case 502 : errorMessage = 'Connection lost. Please try again later.' ; errorMessage = 'The search service is having problems :-(' ; this . showMessage ( errorMessage ) ; this . fire ( 'error' , { results : results , endpoint : endpoint , requestType : type , params : params , errorCode : err . code , errorMessage : errorMessage } ) ; this . fire ( 'expand' ) ; this . fire ( 'collapse' ) ;", "del_tokens": "case 429 : this . showMessage ( 'There were too many requests. Try again in a second.' ) ; break ; this . showMessage ( 'A valid API key is needed for this search feature.' ) ; this . showMessage ( 'The search service is not working right now. Please try again later.' ) ; this . showMessage ( 'The search service is having problems :-(' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "output", "for", "for", "while", "if", "blocks", "++"], "add_tokens": "console . log ( ast [ i ] . toJS ( ) ) ;", "del_tokens": "if ( ast [ i ] . toJS ) { console . log ( ast [ i ] . toJS ( ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "disabled", "and", "isLoading", "state", "to", "ComboBox"], "add_tokens": "autocompleteProps : PropTypes . object , / ** * Makes the input element disabled . * / disabled : PropTypes . bool , / ** * When true , show a loading spinner . This also disables the button . * / isLoading : PropTypes . bool openOnFocus : false , disabled : false , isLoading : false isLoading , const disabled = props . disabled || isLoading disabled = { disabled } icon = { isLoading ? '' : 'caret-down' } paddingLeft = { isLoading ? 12 : 0 } disabled = { disabled } isLoading = { isLoading }", "del_tokens": "autocompleteProps : PropTypes . object openOnFocus : false icon = \"caret-down\" paddingLeft = { 0 }", "commit_type": "add"}
{"commit_tokens": ["Create", "and", "list", "fixed", "token", "."], "add_tokens": "const propertyId = 219 ;", "del_tokens": "const propertyId = 216 ;", "commit_type": "create"}
{"commit_tokens": ["Added", "missing", "libs", "to", "index", ".", "js"], "add_tokens": "'MySQL' : require ( './mysql.js' ) , 'is' : require ( './is.js' ) , 'Raw' : require ( './Raw.js' ) , 'query' : require ( './query.js' )", "del_tokens": "'MySQL' : require ( './mysql.js' )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "test", "reliablity", "for", "DownloadArtifactsTfsGit"], "add_tokens": "function executeWithRetries ( operationName , operation , currentRetryCount ) { var deferred = Q . defer ( ) operation ( ) . then ( ( result ) => { deferred . resolve ( result ) } ) . fail ( ( error ) => { if ( currentRetryCount <= 0 ) { tl . error ( 'OperationFailed: git clone' ) tl . setResult ( tl . TaskResult . Failed , error ) ; deferred . reject ( error ) } else { console . log ( 'RetryingOperation' , operationName , currentRetryCount ) currentRetryCount = currentRetryCount - 1 setTimeout ( ( ) => executeWithRetries ( operationName , operation , currentRetryCount ) , 4 * 1000 ) } } ) return deferred . promise } Q ( 0 ) . then ( ( ) => executeWithRetries ( 'gitclone' , function ( code ) { } , 4 ) ) . then ( function ( code ) { tl . setResult ( tl . TaskResult . Failed , error ) ;", "del_tokens": "Q ( 0 ) . then ( function ( code ) { } ) . then ( function ( code ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "parsing", "fork", "exec", "args"], "add_tokens": "fork : undefined , type : 'string' , describe : 'Launch compiled assets in forked process with optional node exec arguments. With ' , if ( value === undefined ) return false ; return value . split ( ',' ) ;", "del_tokens": "fork : [ undefined ] , type : 'array' , describe : 'Launch compiled assets in forked process with optional node exec arguments' , if ( value [ 0 ] === undefined ) return false ; return value ;", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "Built", "-", "in", "bind", "method", "to", "wrapper"], "add_tokens": "var boundArgs ; if ( ! ! Function . prototype . bind ) { boundArgs = Array . prototype . slice . call ( arguments , 1 ) ; return Function . prototype . bind . apply ( fn , boundArgs ) ; } boundArgs = Array . prototype . slice . call ( arguments , 2 ) ;", "del_tokens": "var boundArgs = Array . prototype . slice . call ( arguments , 2 ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "box3", "and", "vector3", "."], "add_tokens": "import { Vector3 } from \"./vector3.js\" ;", "del_tokens": "import { Vector3 } from \"./vector3\" ;", "commit_type": "update"}
{"commit_tokens": ["fix", "max", "-", "node", "-", "version", "check"], "add_tokens": "if ( ! semver . satisfies ( process . versions . node , '<=' + MAX_NODE_VERSION ) ) {", "del_tokens": "if ( semver . gt ( process . versions . node , MAX_NODE_VERSION ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "one", "method", "to", "Event", "class", "that", "triggers", "an", "event", "only", "once", "."], "add_tokens": "this . oneSubscribers = { } ; one : function ( eventType , fn ) { if ( ! ( eventType in this . oneSubscribers ) ) this . oneSubscribers [ eventType ] = [ ] ; this . oneSubscribers [ eventType ] . push ( fn ) ; this . on ( eventType , fn ) ; } , // Remove \"one\" subscribers: if ( eventType in this . oneSubscribers ) { for ( i = 0 , l = this . oneSubscribers [ eventType ] . length ; i < l ; i ++ ) { this . off ( eventType , this . oneSubscribers [ eventType ] [ i ] ) ; } this . oneSubscribers [ eventType ] = [ ] ; } } one : function ( eventType , fn ) { return this . events . one ( eventType , fn ) ; } ,", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Adding", "toggle", "switch", "for", "tcp", "/", "http", "servers"], "add_tokens": "logInvalidAuthData : true , tcpServerEnabled : true , webServerEnabled : true logger : { log : function ( logLevel , event , msg ) { } } , tcpServerEnabled : true , webServerEnabled : true", "del_tokens": "logInvalidAuthData : true logger : { log : function ( logLevel , event , msg ) { } }", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "for", "testing", "empty", "body"], "add_tokens": "} ) ; yield this . render ( 'empty' ) ; } ) ;", "del_tokens": "} ) yield this . render ( 'blank' ) ; } )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "API", "documentation", "for", "id"], "add_tokens": "* The last path element of the referenced document . * The last path element of the referenced collection .", "del_tokens": "* The last path document of the referenced document . * ID of the referenced collection .", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "test", "for", "another", "wrong", "format"], "add_tokens": "it ( \"will throw an error if the subtasks are wrongly nested\" , async ( ) => { const fp = ` ${ __dirname } ` ; expect . assertions ( 1 ) ; await expect ( storage . load ( fp ) ) . rejects . toThrow ( / format / i ) ; } ) ; const fp = ` ${ __dirname } ` ; } ) ;", "del_tokens": "const fp = ` ${ __dirname } ` ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "Used", "wrong", "object", "to", "find", "compiler", "when", "compiling", "accessors"], "add_tokens": "var imBuffer = exports . compileToIMBuffer ( b , \"Accessors\" , this . options ) ;", "del_tokens": "var imBuffer = ObjJAcornCompiler . compileToIMBuffer ( b , \"Accessors\" , this . options ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "spec", "for", "ensuring", "swapFile", "is", "not", "called", "if", "the", "element", "doesn", "t", "exist"], "add_tokens": "return elems [ match ] ;", "del_tokens": "return elems [ match ] || null ;", "commit_type": "add"}
{"commit_tokens": ["use", "opt", ".", "highWaterMark", "for", "max", "bufferedAmount"], "add_tokens": "highWaterMark : 1024 * 1024 // max bufferedAmount / duplex stream option if ( self . _channel . bufferedAmount > self . highWaterMark ) { if ( ! self . _cb || ! self . _channel || self . _channel . bufferedAmount > self . highWaterMark ) return", "del_tokens": "var MAX_BUFFERED_AMOUNT = 1000 * 1000 highWaterMark : 1024 * 1024 // duplex stream option if ( self . _channel . bufferedAmount > MAX_BUFFERED_AMOUNT ) { if ( ! self . _cb || ! self . _channel || self . _channel . bufferedAmount > MAX_BUFFERED_AMOUNT ) return", "commit_type": "use"}
{"commit_tokens": ["Removing", "postprocessing", "on", "the", "path", "since", "it", "doesn", "not", "make", "sense", "."], "add_tokens": "css : function ( css , req ) { return css ; }", "del_tokens": "css : function ( css , req ) { return css ; } , path : function ( pathname , req ) { return pathname ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "close", "reason"], "add_tokens": "session . on ( 'end' , function ( code , reason ) { console . log ( 'server ended:' , code , reason ) ;", "del_tokens": "session . on ( 'end' , function ( code ) { console . log ( 'server ended:' , code ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "to", "allow", "roundtripping", "all", "queries", "thru", "JSON", "serialization", "."], "add_tokens": "var pred = new AndOrPredicate ( \"and\" , __arraySlice ( arguments ) ) ; // return undefined if empty return pred . op && pred ; var pred = new AndOrPredicate ( \"or\" , __arraySlice ( arguments ) ) ; return pred . op && pred ; if ( this . preds . length == 0 ) { // marker for an empty predicate this . op = null ; } if ( this . preds . length == 1 ) { return preds [ 0 ] ; } if ( this . preds . length == 0 ) return __noop ; if ( this . preds . length == 0 ) return ;", "del_tokens": "return new AndOrPredicate ( \"and\" , __arraySlice ( arguments ) ) ; return new AndOrPredicate ( \"or\" , __arraySlice ( arguments ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "accept", "headers", "and", "clean", "up", "example", "folder"], "add_tokens": "\"use strict\" ; accept : request . headers . accept accept : request . headers . accept } ;", "del_tokens": "mode : parseAcceptHeader ( request ) , mode : parseAcceptHeader ( request ) , // todo finish and fix to use standard http_request var parseAcceptHeader = function ( request ) { / *var accept = request.header('Accept').split(\",\"); var parse_regex = / (\\w+\\/\\w+)(; q=(\\d\\.\\d))* //*; var i = 0 ; var result = null ; var media_range = null ; var quality = 0 ; for ( i = 0 ; i < accept . length ; i ++ ) { result = accept [ i ] . match ( parse_regex ) ; media_rage = result [ 0 ] quality = result [ 2 ] ; } * / return 'text/html' ; } ; } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "prefix", "to", "docs", "url"], "add_tokens": "urlPrefix : ` ${ moduleName } ` , . pipe ( replace ( / http: / g , 'https:' ) )", "del_tokens": "// urlPrefix: '/docs', . pipe ( replace ( / http\\: / g , 'https:' ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "subscriptions", "locally", "once", "we", "ve", "fired", "the", "unsub", "message"], "add_tokens": "/ ** * Removes the subscription from the current session . This is called * internally when a subscription is ` ` ped . * * @ param { String } subKey The subscription key that is unique to the * subscription ( generated from the name and parameters ) . * / _removeSubscription ( subKey ) { delete this . _subscriptions [ subKey ] ; }", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["update", "google", "storage", "endpoint", "."], "add_tokens": "const googleStorageEndpoint = ` ` ;", "del_tokens": "const googleStorageEndpoint = ` ` ;", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "URLParams", "boolean", "in", "global", "state"], "add_tokens": "export function updateQuery ( componentId , query , value , label = null , onQueryChange , URLParams = false ) { dispatch ( setValue ( componentId , value , label , URLParams ) ) ; export function setValue ( component , value , label , URLParams ) { label , URLParams", "del_tokens": "export function updateQuery ( componentId , query , value , label = null , onQueryChange ) { dispatch ( setValue ( componentId , value , label ) ) ; export function setValue ( component , value , label ) { label", "commit_type": "add"}
{"commit_tokens": ["fix", "Node", ".", "js", "v4", "syntax", "problem"], "add_tokens": "try { init ( runtimePath ) { runtimePath = runtimePath || findRuntimePath ( ) ;", "del_tokens": "try { init ( runtimePath = findRuntimePath ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "example", "resolver", "in", "tests", "/", "docs", "to", "work", "with", "falsey", "source", "values"], "add_tokens": "if ( Array . isArray ( targetVal ) && sourceVal ) {", "del_tokens": "if ( Array . isArray ( targetVal ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "FocusBlurBinder", "class", "for", "two", "way", "focus", "/", "blur", "binding", "and", "FocusBinder", "class", "for", "one", "-", "way", "focus", "binding", "(", "as", "opposite", "to", "the", "BlurBinder", ")", "."], "add_tokens": "'./src/binders/kff.BlurBinder.js' , './src/binders/kff.FocusBlurBinder.js' , options : { mangle : true } ,", "del_tokens": "// browserify: { // \"kff-all-bf.js\": { // //requires: ['traverse'], // entries: ['kff.js', 'kff.*.js'] // // prepend: ['<banner:meta.banner>'], // // append: [], // // hook: function (bundle) { // // // Do something with bundle // // } // } // }, './src/binders/kff.BlurBinder.js' ,", "commit_type": "add"}
{"commit_tokens": ["removed", "stringify", "on", "socket", "message", "api"], "add_tokens": "// mqttclient.publish('broadcast', JSON.stringify(dataMessage), {qos:qos}); mqttclient . publish ( 'broadcast' , dataMessage , { qos : qos } ) ; // mqttclient.publish(device, JSON.stringify(dataMessage), {qos:qos}); mqttclient . publish ( device , dataMessage , { qos : qos } ) ;", "del_tokens": "console . log ( \"converting message\" ) ; mqttclient . publish ( 'broadcast' , JSON . stringify ( dataMessage ) , { qos : qos } ) ; mqttclient . publish ( device , JSON . stringify ( dataMessage ) , { qos : qos } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "id", "hostname", "port", "in", "instance"], "add_tokens": "callback ( null , this . _buildInstance ( data ) ) ; / ** * Build the instance detail . * * @ param { Object } data The data . * * @ returns { Object } The instance detail . * / _buildInstance ( data ) { var id = getId ( data . host . hostname ) ; var parts = id . split ( ':' ) ; return _ . assignIn ( data , { _id : id , hostname : parts [ 0 ] , port : parseInt ( parts [ 1 ] , 10 ) } ) ; }", "del_tokens": "callback ( null , _ . assignIn ( data , { _id : getId ( data . host . hostname ) } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moving", "newrelic", "down", "so", "wont", "break", "batch"], "add_tokens": "var newrelic = require ( 'newrelic' ) ;", "del_tokens": "var newrelic = require ( 'newrelic' ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "all", "uses", "of", "attributes", "from", "order", "phase"], "add_tokens": "return function ( g , orderIters , ranks ) { for ( var i = 0 ; i < orderIters ; ++ i ) {", "del_tokens": "return function ( g , ranks ) { var iters = g . attrs . orderIters ; for ( var i = 0 ; i < iters ; ++ i ) {", "commit_type": "remove"}
{"commit_tokens": ["added", "more", "options", "to", "be", "passed", "to", "the", "pagination", "component"], "add_tokens": "activeClassName = { this . props . activeClassName } nextClassName = { this . props . nextClassName } previousClassName = { this . props . previousClassName } pageClassName = { this . props . pageClassName } disabledClassName = { this . props . disabledClassName }", "del_tokens": "activeClassName = { \"active\" }", "commit_type": "add"}
{"commit_tokens": ["Add", "exit", "option", "to", "dantil", ".", "tryCatchWrapper", "()"], "add_tokens": "* @ param { boolean } [ exitProcessIfFailure ] Specify ending the process with 'failure' code ` ` after catching an error from ` ` and printing its stack trace . The shell that executed Node will see the exit code as ` ` . exports . tryCatchWrapper = function ( func , exitProcessIfFailure ) { if ( exitProcessIfFailure ) process . exit ( 1 )", "del_tokens": "* @ param { boolean } rethrow Specify rethrowing a caught error from ` ` after printing the stack trace . exports . tryCatchWrapper = function ( func , rethrow ) { if ( rethrow ) throw e", "commit_type": "add"}
{"commit_tokens": ["add", "patch", "also", "for", "remove", "operations"], "add_tokens": "let patch const previousEntity = previousState . find ( ( s ) => s . entityId === c . entityId ) patch = createPatch ( c . path , previousEntity . entity , { } , c . entitySet , documentModel , { context : Number . MAX_VALUE , bufferEncoding : 'utf8' } )", "del_tokens": "return res . concat ( change ) let patch", "commit_type": "add"}
{"commit_tokens": ["Fix", "SRCROOT", "not", "quoted", "for", "iOS", "build", "phase"], "add_tokens": "var script = '\"' + '\\\\\"${SRCROOT}\\\\\"' + \"/\\\\\\\"\" + utilities . getAppName ( context ) + \"\\\\\\\"/Plugins/cordova-fabric-plugin/Fabric.framework/run \" + pluginConfig . apiKey + \" \" + pluginConfig . apiSecret + '\"' ;", "del_tokens": "var script = '\"' + '${SRCROOT}' + \"/\\\\\\\"\" + utilities . getAppName ( context ) + \"\\\\\\\"/Plugins/cordova-fabric-plugin/Fabric.framework/run \" + pluginConfig . apiKey + \" \" + pluginConfig . apiSecret + '\"' ;", "commit_type": "fix"}
{"commit_tokens": ["allowing", "image", "to", "be", "passed", "into", "constructor"], "add_tokens": "if ( typeof successCB === \"function\" ) successCB . call ( self , ev , self ) ; if ( typeof failCB === \"function\" ) failCB . call ( self , ev , self ) ; if ( typeof failCB === \"function\" ) failCB . call ( self , ev , self ) ; //otherwise see if we have an 'image' specified else if ( options . image ) { this . uploadImage ( options . image , options . format , options . dataType , options . data , options . genMipmaps ) ; } uploadSubImage : function ( ) { } ,", "del_tokens": "if ( successCB ) successCB ( ev ) ; if ( failCB ) failCB ( ev ) ; if ( failCB ) failCB ( ev ) ;", "commit_type": "allow"}
{"commit_tokens": ["Change", "maintainer", "from", "Google", "to", "MobilityData"], "add_tokens": "* Copyright 2015 - 2019 Google Inc . , MobilityData", "del_tokens": "* Copyright 2015 Google Inc .", "commit_type": "change"}
{"commit_tokens": ["Add", "eslint", "+", "minimal", "config"], "add_tokens": "'use strict' ; var childProcess = require ( 'child_process' ) ; cp = childProcess [ method ] . apply ( childProcess , args ) ; cp = childProcess . spawn ( command , args , options ) ;", "del_tokens": "var child_process = require ( 'child_process' ) ; cp = child_process [ method ] . apply ( child_process , args ) ; cp = child_process . spawn ( command , args , options ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "missing", "usage", "test", "into", "usage", ".", "t", ".", "js", "."], "add_tokens": "require ( 'proof' ) ( 12 , function ( assert ) { var none = extractUsage ( 'en_US' , path . join ( __dirname , 'sub.js' ) , [ 'missing' ] ) assert ( none == null , 'missing' )", "del_tokens": "require ( 'proof' ) ( 11 , function ( assert ) {", "commit_type": "move"}
{"commit_tokens": ["Making", "image", "diff", "tests", "platform", "-", "specific"], "add_tokens": "stdio : 'inherit'", "del_tokens": "stdio : 'inherit' , 'phantomjs' : hardyPath + 'node_modules/phantomjs/bin/phantomjs'", "commit_type": "make"}
{"commit_tokens": ["Added", "runtime", "dependency", "checks", "for", "AFRAM", "and", "THREE", "libs"], "add_tokens": "import checkDependencies from './aframe/check-dependencies.js' checkDependencies ( { three : false , aFrame : true , onError : function ( ) { console . log ( 'AFRAME library not found: related features will be disabled.' ) } , function registerComponents ( ) { } )", "del_tokens": "import runtime from './core/runtime.js' if ( runtime . has . aFrame ) registerComponents ( ) // helpers function registerComponents ( ) { if ( typeof window === 'undefined' || ! window . AFRAME ) { console . warn ( 'AFRAME not found. 3dio components not registered' ) return }", "commit_type": "add"}
{"commit_tokens": ["make", "all", "tests", "pass", "add", "a", "set", "up", "and", "teardown", "step"], "add_tokens": "datastore . exists ( block1 . key ( ) . toString ( 'hex' ) , function ( err , exists ) { t . ifErr ( err , 'Failed to check if block exists' ) t . is ( exists , false , 'Block was deleted' )", "del_tokens": "datastore . exists ( block1 . key ( ) . toString ( 'hex' ) , function ( err , obj ) { t . is ( ! ! err , true , 'Failed to check if block exists' ) console . log ( exist ) t . is ( exist , false , 'Block was deleted' )", "commit_type": "make"}
{"commit_tokens": ["Use", "jshintcli", ".", "loadConfig", "()", "to", "load", "jshintrc", "as", "it", "may", "contain", "comments"], "add_tokens": "var jshintcli = require ( 'jshint/src/cli' ) ; var jshintrc = jshintcli . loadConfig ( filePath ) ;", "del_tokens": "var jshintrc = fs . readJSONSync ( filePath ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "a", "ssh", "for", "a", "remote", "controle", "through", "a", "socket", ".", "io", "server"], "add_tokens": "verbose : true , ssh : true ,", "del_tokens": "verbose : true", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "/", "non", "-", "existant", "endpoint"], "add_tokens": "} ;", "del_tokens": "\"authentication_base\" : [ \"/${apiVersion}/api/clients/\" , \"POST\" ] , } ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "child_process", ".", "spawn", "()", "in", "place", "of", "child_process", ".", "exec", "()"], "add_tokens": "var spawn = require ( 'child_process' ) . spawn ; var args = require ( 'shell-quote' ) . parse ( cmd ) ; var bin = args . shift ( 0 ) ; // Allow .run('') without attempting if ( cmd === '' ) { fn ( undefined ) ; return ; } var child = spawn ( bin , args , self . world ) ; var stdout = '' ; var stderr = '' ; var err ; if ( self . world . timeout ) { setTimeout ( function ( ) { child . kill ( ) ; err = { killed : true } ; } , self . world . timeout ) ; } child . stdout . on ( 'data' , function ( data ) { stdout += data ; } ) ; child . stderr . on ( 'data' , function ( data ) { stderr += data ; } ) ; child . on ( 'exit' , function ( code ) { console . log ( 'exit' , code ) ;", "del_tokens": "var exec = require ( 'child_process' ) . exec ; exec ( cmd , self . world , function ( err , stdout , stderr ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "about", "email", "validation", "when", "using", "capital", "letter", "at", "first", "character", "."], "add_tokens": "* Version : 0.4 .0 ( 01 November 2013 ) regMail = new RegExp ( / ^[a-zA-Z]{1}[\\d\\w\\.-]+@[\\d\\w-]{3,}\\.[\\w]{2,3}(\\.\\w{2})?$ / ) ,", "del_tokens": "* Version : 0.3 .0 ( 28 October 2013 ) regMail = new RegExp ( / ^[a-z]{1}[\\d\\w\\.-]+@[\\d\\w-]{3,}\\.[\\w]{2,3}(\\.\\w{2})?$ / ) ,", "commit_type": "fix"}
{"commit_tokens": ["add", "claims_convert", "endpoint", "include", "test"], "add_tokens": "describe ( '#claimsConvert(' , function ( ) { it ( 'should convert a x12 claims file' , function ( done ) { var text = 'valid x12 claim file content' ; pokitdok . claimsConvert ( text , function ( err , res ) { assert . equal ( null , err ) ; assert . equal ( res . meta instanceof Object , true ) ; assert . equal ( res . data instanceof Object , true ) ; done ( ) ; } ) ; } ) ; } ) ; type : ' ultation'", "del_tokens": "type : 'consultation'", "commit_type": "add"}
{"commit_tokens": ["Changed", "counter", "collection", "name", "and", "removed", "mongoose", "from", "dependencies", ".", "Added", "mongoose", "as", "a", "peer", "dependency", "."], "add_tokens": "var Counter = mongoose . connection . model ( 'mai-id-counters' , counterSchema ) ;", "del_tokens": "var Counter = mongoose . connection . model ( 'MAIC-Counter' , counterSchema ) ;", "commit_type": "change"}
{"commit_tokens": ["ADD", "detect", "middleware", "function", "length"], "add_tokens": "'boolean' : function ( val ) { return typeof val === 'boolean' ; } , //trigger pipe var fn = pipe [ index ] ; var len = fn . length ; if ( len === 2 ) fn . call ( self , ctx , next ) ; else if ( len === 1 ) fn . call ( self , next ) ; else if ( len === 0 ) throw new Error ( 'Require function callback' ) ;", "del_tokens": "//no method name, iterate all methods //trigger next pipe [ index ] . call ( self , ctx , next ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", ":", "no", "reporter", "is", "concurrency", "was", "1"], "add_tokens": "if ( opts . customReporter ) { // to allow customReporter // check ./mocha-sauce-reporter or https://github.com/saadtazi/gmwd-teamcity-reporter opts . reporter = require ( opts . reporter ) ( browser , opts ) ; }", "del_tokens": "} else { // to allow customReporter // check ./mocha-sauce-reporter or https://github.com/saadtazi/gmwd-teamcity-reporter opts . reporter = require ( opts . reporter ) ( browser ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "is", "-", "generator", "-", "function"], "add_tokens": "var isGeneratorFunction = require ( 'is-generator-function' ) ; exports . isGeneratorFunction = isGeneratorFunction ;", "del_tokens": "function isGeneratorFunction ( value ) { return ObjectToString ( value ) === '[object GeneratorFunction]' ; } exports . isGeneratorFunction = isGeneratorFunction ;", "commit_type": "use"}
{"commit_tokens": ["allow", "whitespaces", "before", "and", "after", "-", ">", "e", ".", "g", ".", "$obj", "-", ">", "method"], "add_tokens": "var re = / ^(?:\\.|\\s*->\\s*|\\[\\s*) / ;", "del_tokens": "var re = / ^(?:\\.|->|\\[\\s*) / ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "how", "model", "fetch", "tCode", "in", "case", "of", "sub", "tenant", "and", "main", "tenant", "roaming", "is", "on"], "add_tokens": "if ( soajs . tenant . main && soajs . tenant . main . code ) { tCode = soajs . tenant . main . code ; } if ( dbCodes [ c ] . includes ( tCode ) ) {", "del_tokens": "let dbCodeFound = false ; if ( dbCodes [ c ] . includes ( soajs . tenant . code ) ) { dbCodeFound = true ; if ( ! dbCodeFound && soajs . tenant . main && soajs . tenant . main . code ) { tCode = soajs . tenant . main . code ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "clean", "exit", "functions", "using", "Ctrl", "+", "C"], "add_tokens": "this . cmd = data . cmd ;", "del_tokens": "this . cmd = data . cmd", "commit_type": "add"}
{"commit_tokens": ["Added", "phantomPath", "option", "to", "instantiation", "options", "."], "add_tokens": "} var instantiationOptions = { parameters : phantomOptions } ; if ( typeof this . options . phantomPath !== \"undefined\" ) { instantiationOptions [ 'phantomPath' ] = this . options . phantomPath ; } , instantiationOptions ) ;", "del_tokens": "} , { parameters : phantomOptions } ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "console", ".", "log", "if", "node", "<", "boron"], "add_tokens": "if ( process . emitWarning ) process . emitWarning ( deprecatedMessage ) else console . log ( deprecatedMessage )", "del_tokens": "process . emitWarning ( deprecatedMessage )", "commit_type": "use"}
{"commit_tokens": ["fixed", "issues", "with", "json", ".", "splice", "on", "foreach", "nodes"], "add_tokens": "ni . TYPE = \"# foreach\" ; // for debugging purposes sz += 1 ; pendingItems [ i ] = null ; // remove item from current array (may have been put in pendingItems list if needed later) sz -= 1 ; ni . replaceNodeBy ( ni . node , this . node ) ; sz += 1 ; pendingItems [ i ] = null ; ni . replaceNodeBy ( ni . node , this . node ) ; ni . TYPE = \"# item\" ; // for debugging purposes", "del_tokens": "ni . node = this . node ; ni . node = this . node ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", "with", "index", ".", "js"], "add_tokens": "testGen : testGen }", "del_tokens": "'use strict' ; testGen : testGen } ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "how", "keepCycle", "works", "."], "add_tokens": "this . _milliseconds = Math . floor ( ms ) + this . _milliseconds % 1 ; } else { this . _milliseconds = ms ; this . _tick ( this . _milliseconds ) ;", "del_tokens": "ms = Math . floor ( ms ) + this . _milliseconds % 1 ; this . _milliseconds = ms ; this . _tick ( this . _milliseconds ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "the", "parser", "to", "handle", "IdentifierName", "correctly"], "add_tokens": "var showLineNumbers ; var highlighted = null ; // TODO: can we make this argument order more sane? if ( arguments . length === 1 ) { showLineNumbers = true ; } else if ( arguments . length === 2 ) { showLineNumbers = arguments [ 1 ] ;", "del_tokens": "var showLineNumbers , highlighted ; if ( arguments . length <= 2 ) { showLineNumbers = arguments [ 1 ] || true ; highlighted = null ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "some", "schema", "validation", "a", "bit", "to", "handle", "type", "properly", "and", "not", "falsy", "fail", "or", "pass", "a", "validation"], "add_tokens": "_ . schema = { } ; function validateObject ( type , obj ) { if ( _ . schema [ type ] === undefined ) { return true ; } if ( typeof obj !== _ . schema [ type ] . type ) { return false ; } for ( var key in _ . schema [ type ] . properties ) { if ( typeof obj [ key ] !== _ . schema [ type ] . properties [ key ] . type ) { return false ; } if ( ( _ . schema [ type ] . properties [ key ] . required ) && if ( ! validateObject ( type , new_obj ) ) { _ . schema [ type ] = schema ;", "del_tokens": "function validateObject ( obj ) { if ( _ . schema === undefined ) { return true ; } if ( typeof obj !== _ . schema . type ) { return false ; } for ( var key in _ . schema . properties ) { if ( typeof obj [ key ] !== _ . schema . properties [ key ] . type ) { return false ; } if ( ( _ . schema . properties [ key ] . required ) && if ( ! validateObject ( new_obj ) ) { _ . schema = schema ;", "commit_type": "fix"}
{"commit_tokens": ["update", "all", "-", "stars", "use", "object", "-", "assign", "to", "merge", "person", "data"], "add_tokens": "authors [ fakeAuthorId ] = { index [ packageJson . author . name ] = fakeAuthorId ; index [ packageJson . author . email ] = fakeAuthorId ; t . is ( author . npmUser , fakeAuthorId ) ; t . is ( author . githubUser , fakeAuthorId ) ;", "del_tokens": "let allStarAuthors = authors ( ) ; let allStarIndex = index ( ) ; allStarAuthors [ fakeAuthorId ] = { allStarIndex [ packageJson . author . name ] = fakeAuthorId ; allStarIndex [ packageJson . author . email ] = fakeAuthorId ; t . is ( author . npm , fakeAuthorId ) ; t . is ( author . github , fakeAuthorId ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "new", "keyword", "when", "instanciating", "a", "List", "()", "in", "tests"], "add_tokens": "var list3 = List . of ( 1 , 2 , 3 ) ; expect ( new List ( ) ) . to . be . empty ; expect ( list3 ) . to . not . equal ( new List ( ) ) ; expect ( list3 ) . to . not . equal ( new List ( ) ) ; expect ( list3 ) . to . not . equals ( new List ( ) ) ; expect ( list3 ) . to . not . eq ( new List ( ) ) ; expect ( list3 ) . to . not . deep . equal ( new List ( ) ) ;", "del_tokens": "var list3 = List ( [ 1 , 2 , 3 ] ) ; expect ( List ( ) ) . to . be . empty ; expect ( list3 ) . to . not . equal ( List ( ) ) ; expect ( list3 ) . to . not . equal ( List ( ) ) ; expect ( list3 ) . to . not . equals ( List ( ) ) ; expect ( list3 ) . to . not . eq ( List ( ) ) ; expect ( list3 ) . to . not . deep . equal ( List ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "WoW", "and", "SC2", "requires"], "add_tokens": "spell : require ( './wow/spell' ) ( battlenet ) profile : require ( './sc2/profile' ) ( battlenet )", "del_tokens": "spell : require ( './wow/spell' ) ( battlenet ) , user : require ( './wow/user.js' ) ( battlenet ) profile : require ( './sc2/profile' ) ( battlenet ) , user : require ( './sc2/user.js' ) ( battlenet )", "commit_type": "fix"}
{"commit_tokens": ["Add", "licence", "in", "some", "files", "begin", "TManAdapter"], "add_tokens": "throw new SyntaxError ( 'NEED A BASE (a RPS or an another overlay)' )", "del_tokens": "throw new Error ( 'NEED A BASE (a RPS or an another overlay)' )", "commit_type": "add"}
{"commit_tokens": ["Added", "ngmin", "and", "angular", "-", "poller", ".", "min", ".", "js", "."], "add_tokens": "} , ngmin : { factory : { files : [ { src : 'angular-poller.js' , dest : 'angular-poller.min.js' } ] } } , uglify : { options : { banner : '/*! <%= pkg.name %> <%= grunt.template.today(\"dd-mm-yyyy\") %> */\\n' } , dist : { files : { '<%= pkg.name %>.min.js' : [ 'angular-poller.min.js' ] } } grunt . registerTask ( 'default' , [ 'test' , 'ngmin' , 'uglify' ] ) ;", "del_tokens": "uglify : { options : { banner : '/*! <%= pkg.name %> <%= grunt.template.today(\"dd-mm-yyyy\") %> */\\n' } , dist : { files : { '<%= pkg.name %>.min.js' : [ 'angular-poller.js' ] } } } , grunt . registerTask ( 'default' , [ 'test' , 'uglify' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "proxy", "for", "injecting", "scripts"], "add_tokens": "it ( \"should return ports three available ports\" , function ( ) { var ports = methods . getPorts ( 3 , cb , { } ) ; var arg3 = cb . mostRecentCall . args [ 0 ] [ 2 ] ; expect ( / ^(\\d){4}$ / . test ( arg3 ) ) . toBe ( true ) ;", "del_tokens": "it ( \"should return ports two available ports\" , function ( ) { var ports = methods . getPorts ( 2 , cb , { } ) ; expect ( arg1 !== arg2 ) . toBe ( true ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "create", "loading", "el", "function"], "add_tokens": "$loadingImage : morpheus . Util . createLoadingEl ( ) , if ( this . options . name == null ) {", "del_tokens": "$loadingImage : $ ( '<div style=\"overflow:hidden;text-align:center;\"><i class=\"fa fa-spinner fa-spin fa-3x\"></i><span style=\"padding-left:4px;vertical-align:middle;font-weight:bold;\">Loading...</span></div>' ) , if ( ! this . options . name ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "unused", "config", "passed", "to", "build", "command"], "add_tokens": "module . exports = function ( env , platform ) {", "del_tokens": "module . exports = function ( env , platform , config ) {", "commit_type": "remove"}
{"commit_tokens": ["fixed", "splitOnComma", "preserving", "whitespace", "at", "the", "beginning", "of", "the", "first", "argument", "and", "end", "of", "the", "last", "argument"], "add_tokens": "return str . split ( \",\" ) . map ( item => item . trim ( ) ) ;", "del_tokens": "return str . split ( / \\s*,\\s* / ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "the", "logic", "in", "the", "loop", "conditions", "test", "loop"], "add_tokens": "if ( testForCurr ( brkpt ) ) { if ( entr !== undefined ) { entr . call ( ) ; } if ( testForCurr ( brkpt ) ) { if ( entr !== undefined && ! mediaInit [ i ] ) { enterArray . push ( entr ) ; } } else { if ( exit !== undefined && mediaInit [ i ] ) { exitArray . push ( exit ) ; }", "del_tokens": "if ( testForCurr ( brkpt ) && entr ) { entr . call ( ) ; // update corresponding entry to mediaInit to true if ( testForCurr ( brkpt ) && entr && ! mediaInit [ i ] ) { enterArray . push ( entr ) ; } else if ( testForCurr ( brkpt ) && entr && mediaInit [ i ] ) { mediaInit [ i ] = true ; } else if ( exit && mediaInit [ i ] ) { exitArray . push ( exit ) ; mediaInit [ i ] = false ; } else if ( mediaInit [ i ] ) {", "commit_type": "improve"}
{"commit_tokens": ["fix", "caching", "calculation", "to", "align", "with", "npm"], "add_tokens": "// var npm = require('../')(); // using data store var npm = require ( '../' ) ( { store : require ( '../lib/stores/data' ) ( ) } ) ;", "del_tokens": "var npm = require ( '../' ) ( ) ; // // using data store // var npm = require('../')({ // store: require('../lib/stores/data')() // });", "commit_type": "fix"}
{"commit_tokens": ["remove", "hoist", "dep", "from", "binding"], "add_tokens": "var BindableSetter , Binding , bindableSetter , deepPropertyWatcher , toarray , utils ;", "del_tokens": "var BindableSetter , Binding , bindableSetter , deepPropertyWatcher , hoist , toarray , utils ; hoist = require ( \"hoist\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "methods", "to", "handle", "video", "of", "tests"], "add_tokens": "cancel : 'cancelTest.php' , videoCreation : 'video/create.php' , videoView : 'video/view.php' function getEmbedVideoPlayer ( id , options , callback ) { var params = { embed : 1 , id : id } ; options . args = options . args || { type : 'text/html' , encoding : options . dataURI ? 'utf8' : options . encoding } ; options . parser = function ( data ) { return data . toString ( ) ; } ; api . call ( this , paths . videoView , callback , params , options ) ; } function createVideo ( tests , options , callback ) { //prefer the json format because the xml format is buggy with wpt 2.11 var params = { tests : tests , f : 'json' , end : options . end || visual' } ; api . call ( this , paths . videoCreation , callback , params , options ) ; } getEmbedVideoPlayer : getEmbedVideoPlayer , createVideo : createVideo ,", "del_tokens": "cancel : 'cancelTest.php'", "commit_type": "add"}
{"commit_tokens": ["Add", "create", "-", "powerbi", "-", "visual", "project"], "add_tokens": "resourceId : 'rId0' , config . build . output . dir , ` ${ config . metadata . name } ${ config . metadata . version } `", "del_tokens": "resourceId : 'rId0' path . dirname ( config . build . output . dir ) , config . metadata . name + '_' + config . metadata . version + '_OSS_Report.csv' ,", "commit_type": "add"}
{"commit_tokens": ["improves", "cycle", "warnings", "for", "https", ":", "//", "github", ".", "com", "/", "canjs", "/", "can", "-", "stache", "-", "bindings", "/", "issues", "/", "499"], "add_tokens": "var warningRegex = / Printing mutation history: 3 2 / ; var parentSet = helpers . protectAgainstInfiniteLoops ( helpers . incrementByOne ) ; Object . defineProperty ( parentSet , \"name\" , { value : \"PARENT\" , configurable : true } ) ; var parent = new SettableObservable ( parentSet , null , 0 ) ; var childSet = helpers . protectAgainstInfiniteLoops ( helpers . incrementByOne ) ; Object . defineProperty ( childSet , \"name\" , { value : \"CHILD\" , configurable : true } ) ; var child = new SettableObservable ( childSet , null , 0 ) ; parent : parent , child : child ,", "del_tokens": "var warningRegex = / The parent value will remain unchanged; its currently: %o 3 2/; parent : new SettableObservable ( helpers . protectAgainstInfiniteLoops ( helpers . incrementByOne ) , null , 0 ) , child : new SettableObservable ( helpers . protectAgainstInfiniteLoops ( helpers . incrementByOne ) , null , 0 ) ,", "commit_type": "improve"}
{"commit_tokens": ["Create", "application", "directory", "in", "utils", ".", "getPath"], "add_tokens": "var mkdirp = require ( \"mkdirp\" ) ; //var config = { // data: { }, // get: function(offset) { // offset = offset.split(\".\"); // var obj; // if (! config.data[__dirname]) { // config.data[__dirname] = { }; // } // for (var idx in offset) { // obj = obj[offset[idx]]; // if (obj === undefined) { break; } // } // return obj; // }, // set: function(offset, data) { // var obj = config.get(offset); // obj = data; // return data; // } //}; var target = _paths [ pathname ] || null ; if ( target ) { mkdirp . sync ( target ) ; } return target ;", "del_tokens": "return _paths [ pathname ] || null ;", "commit_type": "create"}
{"commit_tokens": ["remove", "{", "from", "comments", "to", "unconfuse", "vi"], "add_tokens": "else { // BG is not yet rising } else {", "del_tokens": "else { // if (glucose_status.delta <= 0) { // BG is not yet rising } else { // if (profile_data.min_bg < eventualBG < profile_data.max_bg) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "an", "initial", "error", "dialogbox", "check", "on", "init"], "add_tokens": "this . log ( 'debug' , 'Restarting VBOLE instances' ) ; this . vbole_checker . on ( 'error' , function onError ( err ) { that . log ( 'error' , 'Checker error:' , err ) ; } ) ; // Do an initial error dialog check that . sendCheckerJSON ( { type : 'checkerrordialog' } , function didInitialCheck ( err , data ) { that . log ( 'debug' , 'Initial error check:' , err , data ) ; } ) ; if ( this . vbole_checker . send_count ) { timeout = 400 ; } else { if ( ! this . vbole_checker . send_count ) { this . vbole_checker . send_count = 0 ; } timeout = 900 ; } this . vbole_checker . send_count ++ ;", "del_tokens": "timeout = 400 ;", "commit_type": "add"}
{"commit_tokens": ["added", "inbound", "and", "outbound", "methods"], "add_tokens": "if ( el . data && el . data . tearDown ) { el . data . tearDown ( ) }", "del_tokens": "if ( el . tearDown ) { el . tearDown ( ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "require", "spoofing", "for", "browsers"], "add_tokens": "! function ( require ) { } ( typeof require !== 'undefined' ? require : function ( path ) { return { 'backbone' : Backbone , 'underscore' : _ } [ path ] ; } ) ;", "del_tokens": "! function ( ) { if ( typeof require === 'undefined' ) { require = function ( path ) { return { 'backbone' : Backbone , 'underscore' : _ } [ path ] ; } ; } } ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "default", "values", "for", "token", "and", "loglevel"], "add_tokens": "this . logLevel = params . logLevel ; this . token = params . token ;", "del_tokens": "this . logLevel = params . logLevel || 'PROD' ; this . token = params . token || process . env . token ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "task", "decorator", "for", "backwards", "compatibility", "with", "decorator", "/", "decorators", "change"], "add_tokens": "{ name : 'identifier' , fileName : 'identifier' } , { name : 'decorator' , fileName : 'decorator' }", "del_tokens": "{ name : 'identifier' , fileName : 'identifier' }", "commit_type": "add"}
{"commit_tokens": ["Changed", "create", "-", "virtual", "-", "node", "to", "assembly", "in", "assembly"], "add_tokens": "import isArray from '../../libs/isArray' ; const assembly = ( tagName ) => { if ( isArray ( item ) ) { export default assembly ;", "del_tokens": "export default ( tagName ) => { if ( item instanceof Array ) {", "commit_type": "change"}
{"commit_tokens": ["updated", "docs", "and", "added", "examples", "on", "API", "section"], "add_tokens": "options . limit = this . req . body . limit ;", "del_tokens": "options . limit = this . req . body . limit . toInt ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "cache", "bust", "option", ".", "Updated", "tests", "and", "README", ".", "md", "."], "add_tokens": "* @ param { Boolean } options . bustCache Whether to force the reload of a module by deleting it from the cache . * @ param { String | Array . < String > } options . helperReducer Custom reducer for registering helpers . * @ param { String | Array . < String > } options . partialReducer Custom reducer for registering partials . options . reducer = options . helperReducer || ( registerModule . bind ( null , handlebars , 'registerHelper' ) ) ; options . reducer = options . partialsReducer || ( registerModule . bind ( null , handlebars , 'registerPartial' ) ) ;", "del_tokens": "options . reducer = registerModule . bind ( null , handlebars , 'registerHelper' ) ; options . reducer = registerModule . bind ( null , handlebars , 'registerPartial' ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "source", "map", "build", "tests", "into", "temp"], "add_tokens": "} , devtool : 'source-map'", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Add", "axios", "to", "call", "rest", "apis", "in", "a", "sample", "widget"], "add_tokens": "props : { id : uuid + 'pieChart' } , props : { id : id } , myLayout . on ( 'stateChanged' , function ( ) { document . getElementById ( \"menuContainer\" ) . innerHTML = \"\" ; initializeWidgetList ( ) ; } ) ;", "del_tokens": "props : { id : uuid + 'pieChart' } , props : { id } , // myLayout.on('stateChanged', function () { // $('#menuContainer').empty(); // initializeWidgetList(); // });", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "situation", "where", "table", "header", "had", "other", "li", "elements", "in", "the", "table", "."], "add_tokens": "this . sortableTable . movingRow = this . sortableTable . el . find ( '> li:nth-child(' + this . originalTable . startIndex + ')' ) ;", "del_tokens": "this . sortableTable . movingRow = this . sortableTable . el . find ( 'li:nth-child(' + this . originalTable . startIndex + ')' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "pack", "command", "and", "installing", "from", "local", "tar", ".", "gz", "file"], "add_tokens": "async . map ( tmp_paths , rimraf , function ( err2 ) { ncp ( filename , tmp , { stopOnError : true } , function ( err ) { tar . extract ( tmp , tmp_extracted , function ( err ) {", "del_tokens": "rimraf ( tmp_paths , function ( err2 ) { ncp ( cdir , p , { stopOnError : true } , function ( err ) { tar . extract ( tmp , function ( err ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "vm", ".", "runInThisContext", "instead", "of", "eval"], "add_tokens": "var defaultReviver , nodeTypeString , nodes , parse , parseStringLiteral , runInThisContext , syntaxErrorMessage ; runInThisContext = require ( 'vm' ) . runInThisContext ; parseStringLiteral = function ( literal ) { return runInThisContext ( literal ) ; } ; return parseStringLiteral ( value ) ; return parseStringLiteral ( value ) ;", "del_tokens": "var defaultReviver , nodeTypeString , nodes , parse , syntaxErrorMessage ; return eval ( value ) ; return eval ( value ) ;", "commit_type": "use"}
{"commit_tokens": ["Removing", "directories", "creating", "directories", "and", "testing", "if", "CLI", "install", "tool", "exists", "is", "done", "using", "x", "-", "platform", "libraries", ".", "SHOULD", "mean", "this", "will", "work", "on", "windows", "now"], "add_tokens": "var fs = require ( 'fs-extra' ) ; fs . mkdirsSync ( cacheDirectory ) ;", "del_tokens": "var fs = require ( 'fs' ) ; var shell = require ( 'shelljs' ) ; shell . mkdir ( '-p' , cacheDirectory ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "parameter", "order", "of", "pow", "for", "power", "sets"], "add_tokens": "if ( typify ( rhs ) === SET && lhs === 2 ) { return makePow ( rhs , Set . of ( Set ( ) ) ) ;", "del_tokens": "if ( typify ( lhs ) === SET && rhs === 2 ) { return makePow ( lhs , Set . of ( Set ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "resolution", "for", "classes", "and", "values", "from", "transitive", "addons"], "add_tokens": "parent : this . owner . getParent ( )", "del_tokens": "project : this . owner . getProject ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "benchmark", "for", "pre", "-", "rendered", "React", "components", "."], "add_tokens": "import PrerenderedComponent from \"./prerendered-component\" ; ) . then ( ( ) => time ( \"rapscallion, pre-rendered\" , ( ) => Promise . all ( range ( CONCURRENCY ) . map ( ( ) => render ( < PrerenderedComponent depth = { DEPTH } leafText = \"hi there!  <\" / > ) . toPromise ( ) ) ) , baseTime )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["change", "post", "title", "for", "test"], "add_tokens": "title : 'Random Post Title' ,", "del_tokens": "title : 'Just Another Post' ,", "commit_type": "change"}
{"commit_tokens": ["made", "sure", "to", "pass", "along", "named", "parameters", "into", "context", ".", "req", ".", "params"], "add_tokens": "", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "change", "style", "example"], "add_tokens": "createLayer = olHelpers . createLayer , createStyle = olHelpers . createStyle ; if ( layer . style && ! equals ( layer . style , oldLayer . style ) ) { var style = createStyle ( layer . style ) ; olLayer . setStyle ( style ) ; }", "del_tokens": "createLayer = olHelpers . createLayer ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "boolean", "and", "object", "serialize"], "add_tokens": "let exportObj = { TRUE : [ 0x01 , 0x01 ] , const BUFFER_LIST = [ 'TYPE_HEADER' ] ; for ( let key in exportObj ) { if ( BUFFER_LIST . indexOf ( key ) === - 1 ) continue ; for ( let key2 in exportObj [ key ] ) { exportObj [ key ] [ key2 ] = Uint8Array . from ( exportObj [ key ] [ key2 ] ) . buffer ; } } module . exports = exportObj ;", "del_tokens": "module . exports = { TRUE : [ 0x01 , 0x00 ] , } , TYPE_CONTENT : { NULL : [ ] , FALSE : [ 0x00 ] , TRUE : [ 0x01 ]", "commit_type": "fix"}
{"commit_tokens": ["Update", "resolver", "and", "loader", "syntax", "to", "work", "with", "webpack", "4"], "add_tokens": "if ( Array . isArray ( loader . options && loader . options . plugins ) ) { else if ( loader . options && typeof loader . options . plugins === 'function' ) {", "del_tokens": "if ( Array . isArray ( loader . options . plugins ) ) { else if ( typeof loader . options . plugins === 'function' ) { ! loader . options . plugins &&", "commit_type": "update"}
{"commit_tokens": ["use", "_", ".", "get", "directly"], "add_tokens": "const isGlobalRollbarConfigured = ( ) => get ( global . Rollbar , 'options.accessToken' , 'undefined' ) !== 'undefined' ;", "del_tokens": "const isGlobalRollbarConfigured = ( ) => _ . get ( global . Rollbar , 'options.accessToken' , 'undefined' ) !== 'undefined' ;", "commit_type": "use"}
{"commit_tokens": ["Added", "some", "of", "the", "fixes", "discussed", "over", "at", "Dean", "s", "blog", "concerning", "DOM", "Ready", "."], "add_tokens": "document . write ( '<scr' + 'ipt id=__ie_init defer=true ' + 'src=javascript:void(0)><\\/script>' ) ;", "del_tokens": "document . write ( '<script id=\"__ie_init\" defer=\"true\" ' + 'src=\"javascript:void 0\"><\\/script>' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "phantomjs", "spawn", "argument", "typo", "detatched", "."], "add_tokens": "detached : false ,", "del_tokens": "detatched : false ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "yet", "another", "stuffup", "."], "add_tokens": "module . exports = require ( \"./reporter\" ) ;", "del_tokens": "module . exports = reporter ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "error", "message", "if", "inspection", "is", "not", "available"], "add_tokens": "tabError = new Error ( 'Chosen tab does not support inspection' ) ;", "del_tokens": "tabError = new Error ( 'Unable to connect to the WebSocket' ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "open", "packet", "decoding", "and", "ECDH", "woo"], "add_tokens": "console . log ( rinfo , msg . toString ( \"hex\" ) ) ;", "del_tokens": "console . log ( rinfo , msg ) ;", "commit_type": "add"}
{"commit_tokens": ["updating", "schemas", "so", "that", "their", "ids", "are", "uris"], "add_tokens": "async . each ( schemas . schemasToGenerate , async . apply ( getSchemaForDefinition , data ) , allSchemasGenerated ) ; function allSchemasGenerated ( err ) {", "del_tokens": "async . each ( schemas . schemasToGenerate , async . apply ( getSchemaForDefinition , data ) , allSchemasWritten ) ; function allSchemasWritten ( err ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "tolerance", "for", "bad", "JSON", "in", "resumed", "backup", "files"], "add_tokens": "if ( obj !== '' ) { try { var arr = JSON . parse ( obj ) ; if ( typeof arr === 'object' && arr . length > 0 ) { for ( var i in arr ) { buffer . push ( arr [ i ] ) ; } // optionally write to the buffer this . pause ( ) ; processBuffer ( false , function ( ) { done ( ) ; } ) ; } else { console . error ( 'ERROR on line' , linenumber , ': not an array' ) ; done ( ) ; } } catch ( e ) { console . error ( 'ERROR on line' , linenumber , ': cannot parse as JSON' ) ; // Could be an incomplete write that was subsequently resumed }", "del_tokens": "var arr = [ ] ; try { arr = JSON . parse ( obj ) ; } catch ( e ) { console . error ( 'ERROR on line' , linenumber , ': cannot parse as JSON' ) ; } if ( typeof arr === 'object' && arr . length > 0 ) { for ( var i in arr ) { buffer . push ( arr [ i ] ) ; } // optionally write to the buffer this . pause ( ) ; processBuffer ( false , function ( ) { } ) ; console . error ( 'ERROR on line' , linenumber , ': not an array' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "closing", "bracket", "for", "alpha", "not", "showing"], "add_tokens": "return \"alpha(opacity=\" + ( this . value . toCSS ? this . value . toCSS ( ) : this . value ) + \")\" ;", "del_tokens": "return \"alpha(opacity=\" + ( this . value . toCSS ? this . value . toCSS ( ) : this . value + \")\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "stats", ".", "js", "to", "delete", "counters"], "add_tokens": "delete ( metrics . counters [ key ] ) ;", "del_tokens": "metrics . counters [ key ] = 0 ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "required", "to", "be", "specified", "without", "a", "value"], "add_tokens": "var required = value === '' ? true : scope . $eval ( value ) ; fileInput . attr ( 'required' , required ) ;", "del_tokens": "var required = scope . $eval ( value ) ; fileInput . attr ( 'required' , angular . isUndefined ( required ) || required ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", ":", "alarm", "were", "displayed", "in", "the", "wrong", "order", "in", "the", "list", "view"], "add_tokens": "date = alarm . getDateObject ( ) . beginningOfDay ( ) ; date : this . model . get ( 'date' ) . format ( \"{dd}/{MM}/{yyyy}\" )", "del_tokens": "date = alarm . getFormattedDate ( '{dd}/{MM}/{yyyy}' ) ; date : this . model . get ( 'date' )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "extract", "-", "text", "s", "loader", "comparison"], "add_tokens": "// using string-based comparison here, since webpack-merge tends to deep-cloning things ( loader ) => String ( loader . test ) === String ( context . fileType ( fileType ) )", "del_tokens": "( loader ) => loader . test === context . fileType ( fileType )", "commit_type": "fix"}
{"commit_tokens": ["fix", "plugin", "needs", "return", "json"], "add_tokens": "this . plugins . forEach ( plugin => { let result = plugin ( tree ) ; if ( result ) { tree = result ; } } ) ;", "del_tokens": "this . plugins . forEach ( plugin => tree = plugin ( tree ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "initial", "binder", "support", "."], "add_tokens": "var eventListeners = { passThrough : function ( e , message ) { msngr . send ( { topic : message . topic , category : message . category , dataType : message . dataType , payload : e } ) ; } } ; if ( msngr . utils . isNullOrUndefined ( element ) ) { msngr . utils . ThrowRequiredParameterMissingOrUndefinedException ( \"element\" ) ; } if ( msngr . utils . isNullOrUndefined ( event ) ) { msngr . utils . ThrowRequiredParameterMissingOrUndefinedException ( \"event\" ) ; } if ( msngr . utils . isNullOrUndefined ( message ) ) { msngr . utils . ThrowRequiredParameterMissingOrUndefinedException ( \"message\" ) ; } if ( ! msngr . utils . isValidMessage ( message ) ) { msngr . utils . ThrowInvalidMessage ( ) ; } // Assume element is a valid HTMLElement. // TODO: Expand scope to support element being: a selector, an array of selectors, // an array of HTMLElement, a NodeList of HTMLElements element . addEventListener ( event , function ( e ) { eventListeners . passThrough . apply ( this , [ e , message ] ) ; } , false ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "config", "loading", "even", "lazier"], "add_tokens": "return ( root , result ) => { if ( _ . isFunction ( options ) ) { options = options ( ) } const config = mergeConfig ( defaultConfig , options ) return postcss ( [ generateUtilities ( config ) , substituteHoverableAtRules ( config ) , substituteResponsiveAtRules ( config ) , substituteBreakpointAtRules ( config ) , substituteClassApplyAtRules ( config ) , stylefmt , ] ) . process ( result ) }", "del_tokens": "if ( _ . isFunction ( options ) ) { options = options ( ) } const config = mergeConfig ( defaultConfig , options ) return postcss ( [ generateUtilities ( config ) , substituteHoverableAtRules ( config ) , substituteResponsiveAtRules ( config ) , substituteBreakpointAtRules ( config ) , substituteClassApplyAtRules ( config ) , stylefmt , ] )", "commit_type": "make"}
{"commit_tokens": ["Add", "destroy", "method", "for", "Component"], "add_tokens": "// extract key and expr from \"key: expression\" format var key key = m . replace ( / :$ / , '' ) . trim ( ) bindParams . push ( key )", "del_tokens": "var multiSep = ',' if ( expr . match ( multiSep ) ) { var parts = expr . split ( multiSep ) return parts . map ( function ( item ) { return new Directive ( vm , scope , tar , def , name , '{' + item + '}' ) } ) } // do with single var propertyName propertyName = m . replace ( / :$ / , '' ) . trim ( ) bindParams . push ( propertyName )", "commit_type": "add"}
{"commit_tokens": ["ADD", ":", "test", "for", "iframe", "with", "computedStyle", "check"], "add_tokens": "} , { cssom : { frame : iframe } } ) // check widget DOM color, ensure it's applied var widget = iframe . contentDocument . getElementById ( 'widget' ) var computedCSS = iframe . contentWindow . getComputedStyle ( widget ) log ( computedCSS . color , 'rgb(255, 0, 0)' ) result . obj . p . fontSize = '22px' log ( css ( result ) , 'p { color: red; font-size: 22px; }\\n' ) // check widget DOM color, ensure it's applied computedCSS = iframe . contentWindow . getComputedStyle ( widget ) log ( computedCSS . color , 'rgb(255, 0, 0)' ) log ( computedCSS . fontSize , '22px' )", "del_tokens": "} , { cssom : { frame : document . getElementById ( 'frame' ) } } ) result . obj . p . fontSize = '12px' log ( css ( result ) , 'p { color: red; font-size: 12px; }\\n' )", "commit_type": "add"}
{"commit_tokens": ["implement", "DELETE", "/", "user", "/", ":", "nickname"], "add_tokens": "app . del ( '/user/:nickname' , function ( req , res , next ) { store . del ( 'user' , req . params . nickname , function ( err ) { if ( err instanceof jsonstore . NoSuchThingError ) { res . writeHead ( 404 , { 'Content-Type' : 'application/json' } ) ; res . end ( JSON . stringify ( err . message ) ) ; } else if ( err ) { res . writeHead ( 500 , { 'Content-Type' : 'application/json' } ) ; res . end ( JSON . stringify ( err . message ) ) ; } else { res . writeHead ( 200 , { 'Content-Type' : 'application/json' } ) ; res . end ( JSON . stringify ( \"Deleted.\" ) ) ; } } ) ; } ) ;", "del_tokens": "app . del ( '/user/:nickname' , notYetImplemented ) ;", "commit_type": "implement"}
{"commit_tokens": ["update", "crypto", "-", "added", "getPubKeyByPrivKey"], "add_tokens": "throw new Error ( 'given Public Key is not a valid Public Key String' ) ; throw new Error ( 'given Private Key is not a valid Private Key string' ) ; / ** * Get a public key based on given private key * @ param { String } privateKey a 64 bytes of hex string * @ returns { String } a 32 bytes of hex string a . k . a public key * / cxo . getPubKeyByPrivKey = ( privateKey ) => { if ( ! util . isPrivateKey ( privateKey ) ) { throw new Error ( 'given Private Key is not a valid Private Key string' ) } return privateKey . substring ( 64 , 128 ) ; } ;", "del_tokens": "throw new Error ( 'Public Key is not a valid Public Key String' ) ; throw new Error ( 'Private Key is not a valid Private Key string' ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "panel", "positioning", "after", "resize"], "add_tokens": "\"stroke-opacity\" : \"0.6\" jQuery ( \"#panel\" ) . resizable ( { stop : function ( event , ui ) { jQuery ( \"#panel\" ) . css ( 'position' , 'fixed' ) ; } } ) ;", "del_tokens": "\"stroke-opacity\" : \"0.6\" , jQuery ( \"#panel\" ) . resizable ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "travis", "removed", "node", "-", "gyp", "dep"], "add_tokens": "import bcrypt from 'bcryptjs' ;", "del_tokens": "import bcrypt from 'bcrypt' ;", "commit_type": "add"}
{"commit_tokens": ["removing", "binding", "ip", "of", "default", "config"], "add_tokens": "\"listen\" : [ 80 ]", "del_tokens": "\"listen\" : [ 80 , \"127.0.0.1\" ]", "commit_type": "remove"}
{"commit_tokens": ["Add", "tests", "and", "update", "documentation"], "add_tokens": "gulp . task ( 'lint' , function ( ) { gulp . task ( 'test' , function ( ) { . on ( 'error' , function ( err ) { gulp . task ( 'develop' , function ( ) { gulp . watch ( './test/**/*.spec.js' , function ( ) { gulp . run ( 'test' ) ; } ) ;", "del_tokens": "gulp . task ( 'lint' , function ( ) { gulp . task ( 'test' , function ( ) { . on ( 'error' , function ( err ) { gulp . task ( 'develop' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "devtool", ":", "eval", "for", "speed", "and", "reload", "on", "change"], "add_tokens": "devtool : 'eval' , entry : [ './src/index.js' , 'webpack-dev-server/client?http://localhost:3000' ] ,", "del_tokens": "devtool : 'source-map' , entry : './src/index.js' ,", "commit_type": "use"}
{"commit_tokens": ["implement", "proper", "nested", "scoping", "when", "blocks", "introduce", "variables"], "add_tokens": "this . emitLine ( ');' ) ; ' += includeTemplate.render(' + 'context.getVariables(), frame);' ) ; 'parentTemplate.rootRenderFunc(env, context, frame);' ) ;", "del_tokens": "this . emitLine ( ')' ) ; ' += includeTemplate.render(context.getVariables());' ) ; 'parentTemplate.rootRenderFunc(env, context);' ) ;", "commit_type": "implement"}
{"commit_tokens": ["Use", "stringprep", "instead", "of", "libidn"], "add_tokens": "var stringprep = require ( 'stringprep' ) . stringprep ;", "del_tokens": "var stringprep = require ( 'libidn' ) . stringprep ;", "commit_type": "use"}
{"commit_tokens": ["Improve", "error", "handling", "during", "initalisation", "of", "discovery"], "add_tokens": "noInit : true , mdns . on ( \"ready\" , ( ) => { mdns . query ( [ { name : domain , type : \"A\" } , { name : domain , type : \"AAAA\" } , { name : domain , type : \"PTR\" } , { name : domain , type : \"SRV\" } , { name : domain , type : \"TXT\" } , ] ) ; } ) ; mdns . on ( \"error\" , reject ) ; mdns . initServer ( ) ;", "del_tokens": "mdns . query ( [ { name : domain , type : \"A\" } , { name : domain , type : \"AAAA\" } , { name : domain , type : \"PTR\" } , { name : domain , type : \"SRV\" } , { name : domain , type : \"TXT\" } , ] ) ;", "commit_type": "improve"}
{"commit_tokens": ["fix", "bug", "with", "jumping", "to", "state", "[", "0", "]"], "add_tokens": "if ( actions . length == 1 ) { % >", "del_tokens": "if ( actions . length > 0 ) { % >", "commit_type": "fix"}
{"commit_tokens": ["Allow", "passing", "of", "user", "object", "with", "email", "/", "password"], "add_tokens": "var requestData = convertLocalAuthData ( data ) ; return feathersClient . authenticate ( requestData ) . then ( function ( response ) { return decode ( response . accessToken ) ;", "del_tokens": "return feathersClient . authenticate ( data ) . then ( function ( data ) { return decode ( data . accessToken ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "or", "sign", "in", "link", "to", "iframe", "too"], "add_tokens": "let dom = splash ( { coc , path , name , org , channels , active , total , iframe : true } ) ;", "del_tokens": "let dom = splash ( { coc , path , name , channels , active , total , iframe : true } ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "a", "pile", "of", "test", "cases"], "add_tokens": "d . inputs = ( sd => sd [ from ] . filter ( d . input_filter ) . map ( value => ( { [ to ] : value } ) ) ) ( self ) ; . filter ( d . input_filter ) ; d . inputs = d . inputs . filter ( d . input_filter ) . map ( input => ( { [ d . input_field ] : input } ) ) ;", "del_tokens": "d . inputs = sd => sd [ from ] . map ( value => ( { [ to ] : value } ) ) ; d . inputs = d . inputs ( self ) d . inputs = d . inputs . map ( input => ( { [ d . input_field ] : input } ) )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "errors", "to", "be", "caught", "and", "implementing", "recover"], "add_tokens": "program . command ( 'recover <string> <signature>' ) . action ( standard ) require ( ` ${ name } ` ) ( ... args , params ) . then ( ret => { console . log ( ret ) } ) . catch ( e => { winston . error ( e ) } )", "del_tokens": "console . log ( await require ( ` ${ name } ` ) ( ... args , params ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "EventDispatcher", "and", "NEXT", "lib", "."], "add_tokens": "* * * eventObj . target = target || this ; if ( o . handleEvent ) { ret = ret || o . handleEvent ( eventObj ) ; } else { ret = ret || o ( eventObj ) ; }", "del_tokens": "* * * eventObj . target = target || this ; if ( o instanceof Function ) { ret = ret || o . apply ( null , [ eventObj ] ) ; } else if ( o . handleEvent ) { ret = ret || o . handleEvent ( eventObj ) ; }", "commit_type": "update"}
{"commit_tokens": ["Use", "base", "directory", "when", "checking", "package", ".", "json", "exists"], "add_tokens": "fs . stat ( path . join ( baseDirectory , moduleInfoPath ) , function ( error ) {", "del_tokens": "fs . stat ( moduleInfoPath , function ( error ) {", "commit_type": "use"}
{"commit_tokens": ["Updating", "how", "the", "validation", "for", "adding", "common", "items", "works", "."], "add_tokens": "var result = validate ( schemaKeyRef , data ) ; if ( ! result . valid ) { var error = new Error ( result . message ) ; error . errors = result . errors ; throw error ;", "del_tokens": "var valid = ajv . validate ( schemaKeyRef , data ) ; if ( ! valid ) { throw new Error ( getErrorMessage ( ajv . errors ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", "some", "logic", "to", "the", "filter", "instead", "."], "add_tokens": "fs . stat ( opt . filename , function ( err ) { if ( ! err || err . code !== 'ENOENT' ) { return next ( new Error ( 'Filename ' + opt . filename + ' already exists.' ) ) ; } next ( ) ; } ) ;", "del_tokens": "next ( ) ; { task : function ( opt , next ) { fs . stat ( opt . filename , function ( err ) { if ( ! err || err . code !== 'ENOENT' ) { return next ( new Error ( 'Filename ' + opt . filename + ' already exists.' ) ) ; } next ( ) ; } ) ; } } ,", "commit_type": "change"}
{"commit_tokens": ["Updating", "property", "handling", "in", "gateway"], "add_tokens": "_report ( properties ) { Object . keys ( properties ) . forEach ( key => { switch ( key ) { case 'illumination' : // TODO: What scale does this actually have? Lux? this . setProperty ( 'illuminance' , properties [ key ] ) ; break ; } } ) ; } const device = this . _devices [ deviceInfo . id ] = new type ( this , deviceInfo ) ; this . devApi . on ( 'properties' , this . _report . bind ( this ) ) ; . then ( ( ) => this . findDeveloperKey ( ) ) . then ( ( ) => this ) ; // Read data for ourself this . send ( { cmd : 'read' , sid : this . sid } ) ; } else if ( data . sid === this . sid ) { this . emit ( 'properties' , JSON . parse ( data . data ) ) ; } else if ( data . sid === this . sid ) { this . emit ( 'properties' , JSON . parse ( data . data ) ) ;", "del_tokens": "const device = this . devices [ deviceInfo . id ] = new type ( this , deviceInfo ) ; . then ( ( ) => this . findDeveloperKey ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "result", "collection", "add", "checks", "to", "github", "config", "test", "."], "add_tokens": "//console.error(err); //console.dir(results); _ . each ( results , function ( result ) { _ . each ( result , function ( repo ) {", "del_tokens": "console . error ( err ) ; console . dir ( results ) ; results . forEach ( function ( result ) { result . forEach ( function ( repo ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "send", "variable", "local", "instead", "of", "global"], "add_tokens": "var send ;", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Fix", "main", "margin", "on", "mobile", "mode"], "add_tokens": "let mainClass = \"responsive-margin-top\" ; mainClass = \"\" ; align - content : stretch ; \" class = \"${mainClass}\" ;", "del_tokens": "let mainStyle = \"margin-top: 3rem\" ; mainStyle = \"\" ; align - content : stretch ; $ { mainStyle } \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "icons", "to", "chrome", "extension", "."], "add_tokens": "chrome . devtools . panels . create ( \"Meiosis\" ,", "del_tokens": "chrome . devtools . panels . create ( \"Meiosis Tracer\" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "time", "to", "messages", "and", "make", "message", "history", "date", "agnostic"], "add_tokens": "var moment = require ( 'moment' ) ; models . message . limit ( 100 ) posted : message . posted , time : moment ( message . posted ) . calendar ( ) time : moment ( message . posted ) . calendar ( ) ,", "del_tokens": "var today = new Date ( ) query . from = query . from || new Date ( today ) . setDate ( today . getDate ( ) - 1 ) query . room = query . room || '' ; models . message . where ( 'posted' ) . gte ( query . from ) posted : message . posted", "commit_type": "add"}
{"commit_tokens": ["use", "require", "()", "to", "load", "features", "-", "json", "data"], "add_tokens": "let featureData = require ( 'caniuse-db/features-json/' + feature )", "del_tokens": "let fs = require ( 'fs' ) let json = fs . readFileSync ( require . resolve ( 'caniuse-db/features-json/' + feature ) ) let featureData = JSON . parse ( json )", "commit_type": "use"}
{"commit_tokens": ["fixed", "bad", "call", "to", "generateTag", "on", "deploy"], "add_tokens": "var tag = commands . generateTag ( config , system , containerDef ) ;", "del_tokens": "var tag = commands . generateTag ( config , system , system ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "WeMo", "switch", "names"], "add_tokens": "this . name = config [ \"name\" ] ; this . wemoName = config [ \"wemo_name\" ] || this . name ; // fallback to \"name\" if you didn't specify an exact \"wemo_name\" callback ( new Error ( \"Device not found\" ) , false ) ; var switchService = new Service . Switch ( this . name ) ; . on ( 'set' , this . setTargetDoorState . bind ( this ) ) . supportsEventNotification = false ;", "del_tokens": "this . wemoName = config [ \"wemo_name\" ] || config [ \"name\" ] ; // fallback to \"name\" if you didn't specify an exact \"wemo_name\" callback ( new Error ( \"Device not found\" ) ) ; var switchService = new Service . Switch ( \"Switch\" ) ; . on ( 'set' , this . setTargetDoorState . bind ( this ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "baseUrl", "relative", "to", "host", "project", "after", "rebase"], "add_tokens": "let rendered = nunjucks . renderString ( cheerio . html ( children ) , { baseUrl : ` ${ newBase } ` } ) ;", "del_tokens": "let rendered = nunjucks . renderString ( cheerio . html ( children ) , { baseUrl : ` ${ newBase } ` } ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "disableAudio", "option", "to", "prevent", "audio", "capture", "with", "screenshares"], "add_tokens": "if ( CHROME_VERSION >= 50 && ! ( opts || { } ) . disableAudio ) {", "del_tokens": "if ( CHROME_VERSION >= 50 ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "in", "more", "Javascript", "-", "like", "naming", "conventions", "as", "aliases", "."], "add_tokens": "_ . getIdent = _ . get_ident = function getIdent ( result ) { var event_id = uuid ( ) . replace ( / - / g , '' ) , kwargs [ 'event_id' ] = event_id ; // this will happen asynchronously. We don't care about it's response. return { 'id' : event_id , 'checksum' : checksum } ; _ . createFromText = _ . create_from_text = function createFromText ( message , kwargs , callback ) { kwargs [ 'message' ] = message ; params : { } _ . createFromError = _ . create_from_error = function createFromError ( err , kwargs , callback ) { module . exports . patchGlobal = module . exports . patch_global = function patchGlobal ( options ) {", "del_tokens": "_ . get_ident = function get_ident ( result ) { var message_id = uuid ( ) . replace ( / - / g , '' ) , kwargs [ 'event_id' ] = message_id ; return { 'id' : message_id , 'checksum' : checksum } ; _ . create_from_text = function create_from_text ( message , kwargs , callback ) { params : kwargs _ . create_from_error = function create_from_exception ( err , kwargs , callback ) { module . exports . patch_global = function patch_global ( options ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "error", "method", "for", "handling", "sync", "errors"], "add_tokens": "this . error ( 'Invalid margin array.' ) ; Worker . prototype . error = function error ( msg ) { // Throw the error in the Promise chain. return this . then ( function ( ) { throw msg ; } ) ; } ;", "del_tokens": "throw 'Invalid margin array.' ;", "commit_type": "add"}
{"commit_tokens": ["ADD", ":", "tests", "to", "ensure", "proper", "operation", "for", "multi", "packet", "messages"], "add_tokens": "parseGanglion , processMultiBytePacket , processMultiBytePacketStop", "del_tokens": "parseGanglion", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "setting", "of", "the", "filename", "as", "the", "img", "alt", "attribute", "on", "the", "preview", "icons", "of", "the", "preview", "multiple", "tab"], "add_tokens": "var cdnURL , fileEl , filePreview , filename filename = fileEl . find ( '.uploadcare--file__name' ) . text ( ) . attr ( 'alt' , filename )", "del_tokens": "var cdnURL , fileEl , filePreview", "commit_type": "add"}
{"commit_tokens": ["Moving", "to", "a", "more", "component", "based", "map", "control"], "add_tokens": "renderMapControl ( children ) { return this . renderMapControl ( this . props . children ) ; mapControl . propTypes = { mapControl . defaultProps = {", "del_tokens": "renderPopup ( children ) { return this . renderPopup ( this . props . children ) ; Popup . propTypes = { Popup . defaultProps = {", "commit_type": "move"}
{"commit_tokens": ["add", "assets", ":", "list", "to", "documents", "dependencies"], "add_tokens": "this . graph . node ( 'documents' , [ 'assets:list' , 'manifest:color' , 'style:bundle' , 'scripts:bundle' , 'reload:bundle' ] , documentNode )", "del_tokens": "this . graph . node ( 'documents' , [ 'manifest:color' , 'style:bundle' , 'scripts:bundle' , 'reload:bundle' ] , documentNode )", "commit_type": "add"}
{"commit_tokens": ["Update", "ajax", "initializer", "to", "comply", "with", "container", "/", "registry", "reform"], "add_tokens": "name : 'ajax-service' , initialize : function ( application ) { application . register ( 'ajax:node' , { application . inject ( 'adapter' , 'ajax' , 'ajax:node' ) ;", "del_tokens": "name : \"ajax-service\" , initialize : function ( registry ) { registry . register ( 'ajax:node' , { registry . injection ( 'adapter' , 'ajax' , 'ajax:node' ) ;", "commit_type": "update"}
{"commit_tokens": ["move", "animation", "class", "from", "instance", "to", "Potion"], "add_tokens": "this . playerAnimation = new Potion . Animation ( this . assets . get ( 'test.png' ) , 130 , 150 , 7 ) ;", "del_tokens": "this . playerAnimation = new this . animation ( this . assets . get ( 'test.png' ) , 130 , 150 , 7 ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "mkdirp", "and", "a", "bit", "cleaner", "error", "messaging"], "add_tokens": "var mess ; if ( e . err ) { if ( e . err . message ) { mess = e . err . message ; } else { mess = JSON . stringify ( e . err ) ; } } else { mess = e . message ; }", "del_tokens": "var mess = e && e . message ? e . message : e ;", "commit_type": "use"}
{"commit_tokens": ["Added", "react", "-", "native", "new", "-", "library", "command"], "add_tokens": "var utils = require ( '../local-cli/generator-utils' ) ; utils . validatePackageName ( name ) ;", "del_tokens": "if ( ! name . match ( / ^[$A-Z_][0-9A-Z_$]*$ / i ) ) { console . error ( '\"%s\" is not a valid name for a project. Please use a valid identifier ' + 'name (alphanumeric).' , name ) ; process . exit ( 1 ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "two", "mispelled", "description", "keys", "in", "fpad", "vocab", "added", "registrationOrder", "to", "schemas", "for", "oada", "-", "formats", "-", "viz", "to", "recreate", "order"], "add_tokens": "description : ` product describes the particular type of item being evaluated in the audit . May describe the fruit , vegetable , etc . as well as other descriptors such as 'chopped' , 'pitted' , 'organic' , etc . ` , description : ` ` ,", "del_tokens": "desciption : ` product describes the particular type of item being evaluated in the audit . May describe the fruit , vegetable , etc . as well as other descriptors such as 'chopped' , 'pitted' , 'organic' , etc . ` , desccription : ` ` ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "humanize", "()", "to", "CS", "variant"], "add_tokens": "+ ' +' + debug . humanize ( ms ) ; / ** * Humanize the given ` ` . * * @ param { Number } m * @ return { String } * @ api private * / debug . humanize = function ( ms ) { var sec = 1000 , min = 60 * 1000 , hour = 60 * min ; if ( ms >= hour ) return ( ms / hour ) . toFixed ( 1 ) + 'h' ; if ( ms >= min ) return ( ms / min ) . toFixed ( 1 ) + 'm' ; if ( ms >= sec ) return ( ms / sec | 0 ) + 's' ; return ms + 'ms' ; } ;", "del_tokens": "+ ' +' + ms + 'ms' ;", "commit_type": "add"}
{"commit_tokens": ["removing", "example", "directory", "from", "bower", "package"], "add_tokens": "/*! cornerstone - v0.1.2 - 2014-04-13 | (c) 2014 Chris Hafey | https://github.com/chafey/cornerstone */", "del_tokens": "/*! cornerstone - v0.1.0 - 2014-04-13 | (c) 2014 Chris Hafey | https://github.com/chafey/cornerstone */", "commit_type": "remove"}
{"commit_tokens": ["updated", "code", "to", "properly", "trigger", "callback", "functions", "and", "update", "render", "count"], "add_tokens": "// When a view has been resolved, ensure that it is correctly updated // and that any done callbacks are triggered. function viewResolve ( el ) { // Only refresh the view if its not a list item, otherwise it would // cause duplicates. if ( ! append ) { // Ensure no events are not lost when re-applying the partial // method options . detach ( view . el ) ; options . partial ( root . el , name , view . el ) ; } // Only call the done function if a callback was provided. if ( _ . isFunction ( done ) ) { done ( view . el ) ; } viewDeferred . resolve ( view . el ) . then ( viewResolve ) ; } if ( ! view . __manager__ . isManaged ) { return viewDeferred . resolve ( view . el ) . then ( viewResolve ) ;", "del_tokens": "if ( ! view . __manager__ . isManaged ) { return viewDeferred . resolve ( view . el ) ; viewDeferred . resolve ( view . el ) . then ( function ( el ) { // Only refresh the view if its not a list item, otherwise it would // cause duplicates. if ( ! append ) { // Ensure no events are not lost when re-applying the partial // method options . detach ( view . el ) ; options . partial ( root . el , name , view . el ) ; } // Only call the done function if a callback was provided. if ( _ . isFunction ( done ) ) { done ( view . el ) ; } } ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "create", "to", "call", "toJSON", "with", "options", "when", "storing", "the", "model"], "add_tokens": "debug ( 'CREATE: %o' , model . toJSON ( options ) ) ; self . store ( ) . setItem ( getKey ( model ) , JSON . stringify ( model . toJSON ( options ) ) , function ( err , res ) {", "del_tokens": "debug ( 'CREATE: %o' , model . toJSON ( ) ) ; self . store ( ) . setItem ( getKey ( model ) , JSON . stringify ( model ) , function ( err , res ) {", "commit_type": "fix"}
{"commit_tokens": ["making", "events", "forgiving", "of", "non", "-", "selectors", "..."], "add_tokens": "var eventSplitter = / ^(\\w+)\\s*(.*)$ / ; // Omitting the selector binds the event to `this.el`. // `\"change\"` events are not delegated through the view because IE does not", "del_tokens": "var eventSplitter = / ^(\\w+)\\s+(.*)$ / ; // Passing a selector of `el` binds to the view's root element. // Change events are not delegated through the view because IE does not", "commit_type": "make"}
{"commit_tokens": ["fix", "border", "by", "adding", "gutter", "and", "box", "shadow"], "add_tokens": "// noreintegrate keyboard bindings whiteKeyGutter : 0.02 , border : \"1px solid #888\" , boxShadow : \"inset -2px -2px 2px #fff, 0 0 5px #ccc\" , background : \"#f6f5f3\" border : \"1px solid #fff\" , const distanceBetweenWhiteKeys = 1 / numWhiteKeys ; const whiteKeyWidth = distanceBetweenWhiteKeys * ( 1 - this . props . whiteKeyGutter ) ; const leftPosition = left = { ratioToPercentage ( leftPosition * distanceBetweenWhiteKeys ) }", "del_tokens": "// noreintegrate can override sounds // noreintegrate active notes // noreintegrate UI - bottom border fix, animate height when pressed border : \"2px solid #999\" , background : \"#fff\" border : \"2px solid #eee\" , const whiteKeyWidth = 1 / numWhiteKeys ; const leftRatio = left = { ratioToPercentage ( leftRatio * whiteKeyWidth ) }", "commit_type": "fix"}
{"commit_tokens": ["Move", "parse_reference", "to", "its", "own", "file"], "add_tokens": "var parseRef = require ( '../parse_ref' ) ; var endLine , content , pos , while ( content . length ) { pos = parseRef ( content , state . lexer . inline , state . options , state . env ) ; if ( pos < 0 ) { break ; } content = content . slice ( pos ) . trim ( ) ; if ( content . length ) {", "del_tokens": "var endLine , content , ref , t , while ( ( ref = state . lexer . inline . parse_reference ( content , state . options , state . env ) ) ) { t = state . env . references ; t [ ref . label ] = t [ ref . label ] || { title : ref . title , href : ref . href } ; content = ref . remaining . trim ( ) ; if ( content ) {", "commit_type": "move"}
{"commit_tokens": ["Added", "html", "block", "draft", "+", "minor", "fixes"], "add_tokens": "rules . html = function ( state , token /*, idx*/ ) { state . result += token . content ; } ; if ( name === 'blockquote_open' ) { tightStack . push ( state . tight ) ; state . tight = false ; } if ( name === 'blockquote_close' ) { state . tight = tightStack . pop ( ) ; } if ( next === 'bullet_list_open' || next === 'ordered_list_open' || next === 'blockquote_open' ) {", "del_tokens": "if ( next === 'bullet_list_open' || next === 'ordered_list_open' ) {", "commit_type": "add"}
{"commit_tokens": ["improve", "style", "of", "danmaku", "setting", "box"], "add_tokens": "< label > < input type = \"radio\" name = \"dplayer-danmaku-type\" value = \"right\" checked > < span > </sp a n > < / label >", "del_tokens": "< label > < input type = \"radio\" name = \"dplayer-danmaku-type\" value = \"right\" checked > < span > </sp a n > < / label >", "commit_type": "improve"}
{"commit_tokens": ["Add", "option", "to", "disable", "text", "selection", "prevention", "."], "add_tokens": "if ( ! options . disableTextSelectionPrevention ) { preventTextSelection . capture ( e . target || e . srcElement ) } if ( ! options . disableTextSelectionPrevention ) { preventTextSelection . release ( ) }", "del_tokens": "preventTextSelection . capture ( e . target || e . srcElement ) preventTextSelection . release ( )", "commit_type": "add"}
{"commit_tokens": ["Changing", "cors", "origin", "to", "be", "input", "optional", "value"], "add_tokens": "origin : opts . hosts || [ ] ,", "del_tokens": "origin : [ '*.gethuman.com' ] ,", "commit_type": "change"}
{"commit_tokens": ["made", "DBMonster", "in", "one", "shot", "and", "fast"], "add_tokens": "var html = update ( i ++ ) . innerHTML ; var html = update ( i ++ ) . innerHTML ; var html = update ( 'hello' ) . innerHTML ; return render ` ${ click } ` ; var html = update ( 'hello' ) . innerHTML ;", "del_tokens": "var html = update ( i ++ ) ; var html = update ( i ++ ) ; var html = update ( 'hello' ) ; return render ` ${ click } ` ; var html = update ( 'hello' ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "search", "around", "buffer", "when", "using", "Leaflet", ".", "LayerIndex"], "add_tokens": "processGuide . call ( this , guide ) ;", "del_tokens": "processGuide ( guide ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "file", "name", "to", "upload", "analysis"], "add_tokens": "* @ param { String } file_name name for the file uploadScript ( analyze_id , file_name , file ) { const data = { file , file_name } ;", "del_tokens": "uploadScript ( analyze_id , file ) { const data = { file } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "build", "&", "set", "content", "type", "for", "empty", "response", "error", "too"], "add_tokens": "if ( ! response . headers ) { response . headers = { } ; } //response.headers.connection = 'close'; response . headers [ 'content-type' ] = 'application/error+json' ;", "del_tokens": "if ( ! response . headers ) { response . headers = { } ; } response . headers . connection = 'close' ;", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "folders", "in", "controllers"], "add_tokens": "this . normalizeRoutes ( routes , files ) ; normalizeRoutes : function ( routes , files ) { for ( var controllerName in files ) { if ( files . hasOwnProperty ( controllerName ) ) { var file = require ( 'path' ) . resolve ( this . controllerPath + '/' + controllerName + '.js' ) ; this . controllers [ file ] = files [ controllerName ] ; var controller = files [ controllerName ] ; if ( _ . isPlainObject ( controller ) ) { this . normalizeRoutes ( routes , controller ) ; } else { var ctrl = new controller ( file ) ; ctrl . normalizeRoutes ( routes ) ; } } } } ,", "del_tokens": "for ( var controllerName in files ) { if ( files . hasOwnProperty ( controllerName ) ) { var file = require ( 'path' ) . resolve ( this . controllerPath + '/' + controllerName + '.js' ) ; this . controllers [ file ] = files [ controllerName ] ; var controller = files [ controllerName ] ; var ctrl = new controller ( file ) ; ctrl . normalizeRoutes ( routes ) ; } }", "commit_type": "add"}
{"commit_tokens": ["Fix", "type", "annotation", "on", "T_ARRAYS", "-", "it", "only", "ever", "contains", "arrays", "of", "arrays", "of", "numbers"], "add_tokens": "* @ type { Array . < Array . < number >> }", "del_tokens": "* @ type { Array . < Array . < * >> }", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "custom", "start", "file"], "add_tokens": "'index' : { description : 'Name of the First page in the flow. Defaults to index.html' } , googleAnalytics : opts [ 'google-analytics' ] , index : opts [ 'index' ]", "del_tokens": "googleAnalytics : opts [ 'google-analytics' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "back", "the", "semantic", "validation", "for", "required", "schema", "object", "property", "definitions"], "add_tokens": "function getSchemaProperties ( schema ) { var properties = _ . keys ( schema . properties ) ; // Start with the defined properties // Add properties defined in the parent _ . forEach ( schema . allOf , function ( parent ) { _ . forEach ( getSchemaProperties ( parent ) , function ( property ) { if ( _ . indexOf ( properties , property ) === - 1 ) { properties . push ( property ) ; } } ) ; } ) ; return properties ; } function validateSchemaProperties ( response , schema , path ) { _ . forEach ( _ . difference ( schema . required || [ ] , getSchemaProperties ( schema ) ) , function ( name ) { response . errors . push ( { code : 'OBJECT_MISSING_REQUIRED_PROPERTY_DEFINITION' , message : 'Missing required property definition: ' + name , path : path } ) ; } ) ; } validateDefaultValue , validateSchemaProperties", "del_tokens": "validateDefaultValue", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "a", "call", "function"], "add_tokens": "if ( ! { 'handshake-reply' : 1 , call : 1 , emit : 1 , reply : 1 , request : 1 } [ message . data . postmate ] ) return false ; call ( property , data ) { // Send information to the child this . child . postMessage ( { postmate : 'call' , type : MESSAGE_TYPE , property , data , } , this . childOrigin ) ; } const { property , uid , data } = e . data ; if ( e . data . postmate === 'call' ) { if ( property in this . model && typeof this . model [ property ] === 'function' ) { this . model [ property ] . call ( this , data ) ; } return ; } static Promise = window ? window . Promise : Promise ;", "del_tokens": "const { property , uid } = e . data ; static Promise = Promise ;", "commit_type": "add"}
{"commit_tokens": ["add", "document", "for", "from", "method"], "add_tokens": "moment . locale ( \"en\" ) ; m . locale ( \"en\" ) ; m . locale ( \"fa\" ) ; var m2 = moment . from ( \"11/1367/04\" , \"fa\" , \"MM/YYYY/DD\" ) ; m1 . format ( \"YYYY/MM/DD\" ) . should . be . equal ( \"1989/01/24\" ) ;", "del_tokens": "moment . locale ( 'en' ) ; m . locale ( 'en' ) ; m . locale ( 'fa' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "collapse", "&", "expand", "in", "mocha", "tree", "view"], "add_tokens": "$ ( this ) . parent ( ) . parent ( ) . find ( '.test-list' ) . find ( 'input' ) . prop ( 'checked' , false ) ; $ ( this ) . parent ( ) . parent ( ) . find ( '.test-list' ) . find ( 'input' ) . prop ( 'checked' , true ) ;", "del_tokens": "$ ( this ) . parent ( ) . parent ( ) . find ( '.test-list' ) . find ( 'ul' ) . hide ( ) ; $ ( this ) . parent ( ) . parent ( ) . find ( '.test-list' ) . find ( 'ul' ) . show ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "ability", "to", "choose", "which", "CSS", "preprocessor", "will", "be", "used", "during", "the", "styles", "task", "."], "add_tokens": "modules : { // module to use to preprocess your stylesheets. default: less // possible values: less, sass, sassCompass, stylus, myth. styles : 'less' } , // styles sources folder. default: styles/ styles : '' , partials : '' // production ready styles folder. default: css/ styles : '' ,", "del_tokens": "// css sources folder. default: less/ css : '' , partials : '' , // production ready css folder. default: css/ css : '' ,", "commit_type": "implement"}
{"commit_tokens": ["Change", "to", "postcss", "async", "api", "to", "fix", "problems"], "add_tokens": "post . use ( autoprefixer ( browserConfig ) ) return post . process ( css , options )", "del_tokens": "post . use ( autoprefixer ( browserConfig ) . postcss ) css = post . process ( css , options ) . css return css ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "another", "test", "broken", "by", "the", "environment", "changes"], "add_tokens": "var airbrake = require ( common . dir . root ) . createClient ( common . key , 'production' ) ;", "del_tokens": "var airbrake = require ( common . dir . root ) . createClient ( common . key ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "fatal", "errors", "from", "Mocha"], "add_tokens": "shell . config . fatal = true ; shell . exit ( shell . exec ( ) . code ) ;", "del_tokens": "shell . config . fatal = true ; shell . exec ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "remove", "and", "removeAll", "to", "selections"], "add_tokens": "type : this . type , params : this . params , content : this . content . map ( function ( item ) {", "del_tokens": "type : type , params : params , content : content . map ( function ( item ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "output", "for", "tts", "format"], "add_tokens": "params = extend ( { accept : 'audio/ogg; codecs=opus' } , params ) ;", "del_tokens": "params = extend ( { accept : 'audio/ogg;codecs=opus' } , params ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "properties", "to", "data", "object", "so", "that", "popup", "can", "get", "at", "them"], "add_tokens": "_data [ val . location ] = { fillKey : val . value } ; // Set extra fields in case we want to use them in the popup angular . forEach ( val , function ( prop , key ) { if ( key !== 'value' && key !== 'location' ) { _data [ val . location ] [ key ] = prop ; } } ) ;", "del_tokens": "_data [ val . location ] = { fillKey : val . value } ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "new", "event", "for", "initial", "image", "loaded"], "add_tokens": "DRAW : 'draw' , INITIAL_IMAGE_LOADED_EVENT : 'initial-image-loaded' , }", "del_tokens": "DRAW : 'draw' }", "commit_type": "add"}
{"commit_tokens": ["remove", "=", ">", "from", "tests"], "add_tokens": "glob . sync ( 'test/**/.DS_Store' ) . forEach ( function ( dsStore ) {", "del_tokens": "glob . sync ( 'test/**/.DS_Store' ) . forEach ( dsStore => {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "chrome", "param", "destructuring", "bug"], "add_tokens": "let environment ; try { environment = require ( \"./environment\" ) ; } catch ( e ) { environment = { } ; } let config = { // NOTE: This is only needed to fix a bug with chrome devtools' debugger and // destructuring params https://github.com/jlongster/debugger.html/issues/67 if ( environment . transformParameters ) { config . module . loaders . push ( { test : / \\.js$ / , exclude : / (node_modules|bower_components) / , loader : \"babel\" , query : { plugins : [ \"transform-es2015-parameters\" ] } } ) ; } module . exports = config ;", "del_tokens": "module . exports = {", "commit_type": "fix"}
{"commit_tokens": ["move", "minimaps", "to", "the", "right", "again", "some", "cleanup"], "add_tokens": "this . _layerList = this . _form = container ; L . DomEvent . on ( this . _layerList , 'scroll' , this . _onLayerListScroll ) ; _onLayerListScroll : function ( ) { var minimapHeight = 110 ; var gridHeight = this . clientHeight ; var perRow = 1 ; self . _onLayerListScroll . call ( self . _layerList ) ;", "del_tokens": "this . _layerList = this . _form = L . DomUtil . create ( 'div' , 'layer-grid' , container ) ; L . DomEvent . on ( this . _layerList , 'scroll' , this . _onLayerGridScroll ) ; _onLayerGridScroll : function ( ) { var minimapHeight = 90 ; var gridHeight = 200 ; var perRow = 3 ; // show the minimaps currently into view self . _onLayerGridScroll . call ( self . _layerList ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "code", "style", "a", "little", "use", "ES6", "syntax", "in", "React", "s", "render", "methods", ".", "See"], "add_tokens": "sourceMapBasepath : __dirname } ) ) . on ( 'error' , console . error . bind ( console ) ) . pipe ( $ . autoprefixer ( { browsers : AUTOPREFIXER_BROWSERS } ) ) function bundle ( err , stats ) {", "del_tokens": "sourceMapBasepath : __dirname } ) . on ( 'error' , console . error . bind ( console ) ) ) . pipe ( $ . autoprefixer ( { browsers : AUTOPREFIXER_BROWSERS } ) ) function bundle ( err , stats ) {", "commit_type": "fix"}
{"commit_tokens": ["removed", "hardcoded", "path", "for", "windows"], "add_tokens": "JSONDriver = new JSONDBFS ( ) ;", "del_tokens": "JSONDriver = new JSONDBFS ( { path : 'C:\\\\Users\\\\Manuel\\\\Desktop' } ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "fertilize", "and", "update", "methods"], "add_tokens": "myTerminal . nu = \"esto es nu\" ; myTerminal . colors . nu = 'red' ; myTerminal . header . push ( \">>nu\" ) ; audrey . update ( myTerminal ) ; console . log ( myTerminal ) ; audrey . fertilize ( { name : \">>otro nuevo\" , value : \"aaaagh\" , color : 'blue' } , \"body\" ) ; audrey . sing ( ) ;", "del_tokens": "audrey . talk ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "common", "pouchdb", "adapter", "functions", "to", "mixin"], "add_tokens": "import PouchAdapterUtils from \"hospitalrun/mixins/pouch-adapter-utils\" ; export default DS . PouchDBAdapter . extend ( PouchAdapterUtils , {", "del_tokens": "export default DS . PouchDBAdapter . extend ( { _idToPouchId : function ( id , type ) { type = type . typeKey || type ; return [ type , id ] . join ( \"_\" ) ; } , _pouchError : function ( reject ) { return function ( err ) { var errmsg = [ err [ \"status\" ] , ( err [ \"name\" ] || err [ \"error\" ] ) + \":\" , ( err [ \"message\" ] || err [ \"reason\" ] ) ] . join ( \" \" ) ; Ember . run ( null , reject , errmsg ) ; } ; } ,", "commit_type": "move"}
{"commit_tokens": ["Added", "examples", "to", "the", "helper", "error", "messages"], "add_tokens": "var errorMsg = 'The repeat helper requires either a repeat count or min and max values, eg: {{#repeat 5}} or {{#repeat min=5 max=10}}' ; throw new Error ( errorMsg ) ; throw new Error ( errorMsg ) ; throw new Error ( 'The int helper requires two numeric params, eg: {{int 2 6}}' ) ; throw new Error ( 'The float helper requires two numeric params, eg: {{float 5 8}}' ) ; throw new Error ( ` ` ) ; throw new Error ( ` ` ) ; throw new Error ( ` ` ) ; var errorMsg = 'The lorem helper requires either a word count or min and max values, eg: {{lorem 5}} or {{lorem min=5 max=10}}' ; throw new Error ( errorMsg ) ; throw new Error ( errorMsg ) ; throw new Error ( errorMsg ) ; throw new Error ( ` ` ) ; throw new Error ( 'The add helper requires two number params, eg: {{add 2 4}}' ) ; throw new Error ( 'The step helper requires a numeric value and can only be used inside #repeat and #each blocks, eg: {{step 10}}' ) ;", "del_tokens": "throw new Error ( 'The repeat helper requires either a single count value or both min and max values' ) ; throw new Error ( 'The repeat helper requires either a single count value or both min and max values' ) ; throw new Error ( 'The int helper requires two numeric params' ) ; throw new Error ( 'The float helper requires two numeric params' ) ; throw new Error ( 'The date helper requires two string params' ) ; throw new Error ( 'The time helper requires two string params' ) ; throw new Error ( 'The char helper requires one string param' ) ; throw new Error ( 'The lorem helper requires either a word count or min and max values' ) ; throw new Error ( 'The lorem helper requires either a word count or min and max values' ) ; throw new Error ( 'The lorem helper requires either a word count or min and max values' ) ; throw new Error ( 'The random helper requires at least one param' ) ; throw new Error ( 'The add helper requires two number params' ) ; throw new Error ( 'The step helper require a numeric value and can only be used inside #repeat and #each blocks' ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "dots", "in", "tag", "names", "when", "renaming", "(", "JSX", ")"], "add_tokens": "const m = name . match ( / [\\w:.-]+ / ) ;", "del_tokens": "const m = name . match ( / [\\w:\\-]+ / ) ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "default", "location", "to", "map", "options"], "add_tokens": "baseLayer : projectedTiles [ \"Arctic Connect: EPSG:3571\" ] , center : [ 90 , 0 ] , zoom : 2", "del_tokens": "baseLayer : projectedTiles [ \"Arctic Connect: EPSG:3571\" ]", "commit_type": "move"}
{"commit_tokens": ["Add", "more", "information", "to", "emitted", "events", "and", "change", "the", "way", "emit", "works"], "add_tokens": "// Constructor init : function ( data ) { this . type = null ; this . target = null ; this . data = null ; if ( typeof data !== 'undefined' ) { this . data = data ; } } , if ( ! ( event instanceof Event ) ) { var data = event ; event = new Event ( data ) ; event . target = this ; ( typeof exports === 'undefined' ? this . chic : exports ) ,", "del_tokens": "if ( typeof event !== 'undefined' && ! ( event instanceof Event ) ) { throw new Error ( 'Event must be an Event object or undefined' ) ; } if ( ! event ) { event = new Event ( ) ; ( typeof exports === 'undefined' ? ( this . chic = this . chic || { } ) : exports ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "form", "and", "table", "examples"], "add_tokens": "$ ( '.date-range-picker' ) . daterangepicker ( if ( jQuery ( ) . timepicker ) { $ ( '.time-picker' ) . timepicker ( { minuteStep : 1 , showSeconds : false , showMeridian : false , defaultTime : false } ) . next ( ) . on ( ace . click_event , function ( ) { $ ( this ) . prev ( ) . focus ( ) ; } ) ; }", "del_tokens": "$ ( 'input[name=date-range-picker]' ) . daterangepicker (", "commit_type": "add"}
{"commit_tokens": ["Add", "comment", "for", "future", "cleanup", "."], "add_tokens": "// TODO: refactor to break down into a more modular design with less global state. missingResourcesIndex ++ ;", "del_tokens": "missingResourcesIndex ++ ;", "commit_type": "add"}
{"commit_tokens": ["Creating", "a", "unified", "Controls", "class"], "add_tokens": "/ ** * Set the pair ( key , value ) into the server * @ value can be an object literal . * * * /", "del_tokens": "// If 'value' is not passed, it is assumed that we are passing // already an object with 'key' // node.set = function (key, value) { // // var data = {}; // if ('undefined' === value) { // data = key; // } // else { // data[key] = value; // necessary, otherwise the key is called key // } // // that.emit('out.set.DATA', data); // }", "commit_type": "create"}
{"commit_tokens": ["add", "a", "root", "flag", "for", "forced", "root", "expansion"], "add_tokens": "var root = ( dat . _flags ) && ( dat . _flags [ str ] ) && ( dat . _flags [ str ] . root ) ; if ( root && dat [ root ] && ( ( typeof dat [ root ] ) == \"object\" ) ) { return plated_chunks . replace ( dat [ str ] , dat [ root ] ) } else { return dat [ str ] ; } if ( a == \"\" ) // when we want to spit out nothing if a value is unset we can end on an empty string eg {value||}", "del_tokens": "return dat [ str ] ; if ( a == \"\" ) // when we want to spit out nothing if a value is unset we can end on an empty string eg {value|}", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "form", "-", "builder", "to", "include", "the", "whole", "form", "."], "add_tokens": "form : '=' Restangular . one ( 'app' , $scope . form . appId ) . all ( 'resource' ) . getList ( ) . then ( function ( resources ) { if ( ! $scope . form . components ) { $scope . form . components = [ ] ; '<button class=\"btn btn-xs btn-default component-settings-button\" style=\"z-index: 1000\" ng-click=\"editComponent(form.components, component)\"><span class=\"glyphicon glyphicon-cog\"></span></button>' + 'dnd-list=\"form.components\"' + 'dnd-drop=\"addComponent(form.components, item)\">' + '<li ng-if=\"form.components.length === 0\">' + '<li ng-repeat=\"component in form.components\" ' + 'dnd-moved=\"form.components.splice($index, 1)\">' + 'dnd-moved=\"component.components.splice($index, 1)\">' +", "del_tokens": "components : '=' Restangular . all ( 'resource' ) . getList ( ) . then ( function ( resources ) { if ( ! $scope . components ) { $scope . components = [ ] ; '<button class=\"btn btn-xs btn-default component-settings-button\" style=\"z-index: 1000\" ng-click=\"editComponent(components, component)\"><span class=\"glyphicon glyphicon-cog\"></span></button>' + 'dnd-list=\"components\"' + 'dnd-drop=\"addComponent(components, item)\">' + '<li ng-if=\"components.length === 0\">' + '<li ng-repeat=\"component in components\" ' + 'dnd-moved=\"components.splice($index, 1)\">' + 'dnd-moved=\"components.splice($index, 1)\">' +", "commit_type": "fix"}
{"commit_tokens": ["Add", "semicolon", "to", "generated", "ImportStatement", "strings"], "add_tokens": "return [ 'from' , ` ${ this . path } ` ] ;", "del_tokens": "return [ 'from' , ` ${ this . path } ` ] ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "events", "for", "after", "crud", "functions", "and", "tests"], "add_tokens": "self . emit ( 'afterCreate' , extendedObject ) self . emit ( 'afterUpdate' , updatedObject , overwrite ) self . emit ( 'afterDeleteMany' , query ) self . emit ( 'afterDelete' , id )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "import", "of", "modules", "n", "commonjs", "env"], "add_tokens": "console . log ( 'node' ) module . exports = factory ( console . log ( 'browser' )", "del_tokens": "module . exports = factory . apply (", "commit_type": "fix"}
{"commit_tokens": ["changed", "postinstall", "script", "fixed", "help", "command"], "add_tokens": "if ( args . length >= 1 ) {", "del_tokens": "if ( args . length === 1 ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "alternate", "bass", "chords"], "add_tokens": "chordLength = 2 , additionals = [ ] , bass , note ; // Remove whitespace, commas and parentheses bass = name . split ( '/' ) ; if ( bass . length === 2 ) { name = bass [ 0 ] ; bass = bass [ 1 ] ; } else { bass = null ; } if ( ! c ) break ; if ( bass ) { bass = new TeoriaNote ( bass ) ; var interval = teoria . interval . between ( root , bass ) ; bass . octave -= ( interval . direction === 'up' ) ? 1 : 0 ; this . notes . splice ( 0 , 0 , bass ) ; } note = this . root . interval ( notes [ i ] ) ; if ( bass && note . toString ( true ) === bass . toString ( true ) ) { continue ; } this . notes . push ( note ) ;", "del_tokens": "chordLength = 2 , additionals = [ ] ; if ( ! c ) { break ; } this . notes . push ( this . root . interval ( notes [ i ] ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "codesearch", "plugin", "some", "more", "and", "escapeXml", "()", "util", "function"], "add_tokens": "Util . escapeXml ( options . query ) , '\">' ) ; aXml . push ( '<d:excerpt line=\"' , parts . shift ( ) , '\">' , Util . escapeXml ( truncate ( parts . join ( \":\" ) , options ) ) , '</d:excerpt>' ) ;", "del_tokens": "Util . escapeXml ( options . query , '\"' ) , '\">' ) ; aXml . push ( '<d:excerpt line=\"' , parts . shift ( ) , '\"><![CDATA[' , truncate ( parts . join ( \":\" ) , options ) , ']]></d:excerpt>' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "Surface", "to", "support", "setting", "DOMElement", "content"], "add_tokens": "for ( var n in attributes ) { this . attributes [ n ] = attributes [ n ] ; if ( this . el ) this . el . setAttribute ( n , attributes [ n ] ) ; } return this ; return this . attributes ; if ( ! this . el ) return ; if ( typeof content === 'string' ) { this . el . setContent ( content ) ; return ; } if ( ! this . _currentTarget ) return ; // dom object if ( this . content instanceof Node ) { var target = this . _currentTarget ; while ( target . hasChildNodes ( ) ) target . removeChild ( target . firstChild ) ; target . appendChild ( content ) ; } if ( this . content && this . content instanceof Node ) this . setContent ( this . content ) ; this . _eventOutput . emit ( 'deploy' ) ;", "del_tokens": "// if it is not string... if ( this . el ) this . el . setContent ( this . content ) ; this . eventOutput . emit ( 'deploy' ) ;", "commit_type": "implement"}
{"commit_tokens": ["Making", "postRegistrationHandler", "work", "for", "account", "verification", "as", "well", "."], "add_tokens": "if ( req . app . get ( 'stormpathPostRegistrationHandler' ) ) { req . app . get ( 'stormpathPostRegistrationHandler' ) ( req . user , res , function ( ) { helpers . render ( req . app . get ( 'stormpathAccountVerificationCompleteView' ) , res ) ; } ) ; } else { helpers . render ( req . app . get ( 'stormpathAccountVerificationCompleteView' ) , res ) ; }", "del_tokens": "helpers . render ( req . app . get ( 'stormpathAccountVerificationCompleteView' ) , res ) ;", "commit_type": "make"}
{"commit_tokens": ["changed", "how", "getters", "are", "being", "defined", "to", "the", "more", "standards", "complient", "defineProperty"], "add_tokens": "Object . defineProperty ( self , modelName , { get : function ( ) { return models [ modelName ] ( self ) } , enumerable : true , configurable : true", "del_tokens": "self . __defineGetter__ ( modelName , function ( ) { return models [ modelName ] ( self )", "commit_type": "change"}
{"commit_tokens": ["allowing", "opts", ".", "style", "for", "backwards", "compatibility"], "add_tokens": "addEdge ( sourceNode , targetNode , opts = { } ) { const style = opts . style || opts", "del_tokens": "addEdge ( sourceNode , targetNode , style = { } ) {", "commit_type": "allow"}
{"commit_tokens": ["added", "click", "method", "to", "Elm", "class", ".", "closeOnclick", "added", "on", "focus"], "add_tokens": "console . log ( key ) ; click ( fn ) { this . element . addEventListener ( 'click' , function ( ) { fn ( ) ; } ) ; } padding : 0 , closeOnClick : null /////////////////////////make if statement for options trigger right : new Elm ( 'div.to_right' , { click : ( ) => { this . remove ( ) } } , document . body ) , top : new Elm ( 'div.to_top' , { click : ( ) => { this . remove ( ) } } , document . body ) , bottom : new Elm ( 'div.to_bottom' , { click : ( ) => { this . remove ( ) } } , document . body ) , left : new Elm ( 'div.to_left' , { click : ( ) => { this . remove ( ) } } , document . body )", "del_tokens": "padding : 0 right : new Elm ( 'div.to_right' , { } , document . body ) , top : new Elm ( 'div.to_top' , { } , document . body ) , bottom : new Elm ( 'div.to_bottom' , { } , document . body ) , left : new Elm ( 'div.to_left' , { } , document . body )", "commit_type": "add"}
{"commit_tokens": ["Added", "enabled", "flag", "on", "the", "debug", "logger", "."], "add_tokens": "* the debug message . The function also has a read - only Boolean property * < code > enabled < / code > , which tells if the logger is enabled or if it is a noop . const enabled = re . test ( process . env . NODE_DEBUG ) ; if ( enabled ) { Object . defineProperty ( logger , 'enabled' , { value : enabled , writable : false } ) ;", "del_tokens": "* the debug message . if ( re . test ( process . env . NODE_DEBUG ) ) {", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "latest", "packages", "fix", "ESLint", "error"], "add_tokens": ". cached ( function ( data , status , headers , config , itemCache ) { var cacheInfo = itemCache . info ( ) cacheInfo . id . should . equal ( 'testCache' ) } ) . cached ( function ( data , status , headers , config , itemCache ) { var cacheInfo = itemCache . info ( ) cacheInfo . id . should . equal ( 'testCache' ) cacheInfo . itemKey . should . equal ( 'testItemKey' ) } )", "del_tokens": ". cached ( function ( data , status , headers , config , itemCache ) { var cacheInfo = itemCache . info ( ) cacheInfo . id . should . equal ( 'testCache' ) } ) . cached ( function ( data , status , headers , config , itemCache ) { var cacheInfo = itemCache . info ( ) cacheInfo . id . should . equal ( 'testCache' ) cacheInfo . itemKey . should . equal ( 'testItemKey' ) } )", "commit_type": "update"}
{"commit_tokens": ["Add", "testcase", "for", "string", "functions"], "add_tokens": "return typeof val === 'string' || val instanceof String ;", "del_tokens": "return typeof val === 'string' ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Google", "Analytics", "&", "Disqus", "scripts", "as", "partials"], "add_tokens": "options : { config : '<%= happyplan.build.jekyllConfig %>' } , options : { } , dist : { }", "del_tokens": "config : grunt . util . _ . extend ( { } , happyplan . build . jekyllConfig ) dist : { config : '<%= happyplan.build.jekyllConfig %>' }", "commit_type": "add"}
{"commit_tokens": ["add", "filterp", "and", "lift2", "-", "5"], "add_tokens": "exports . liftp2 = exports . liftp3 = exports . liftp4 = exports . liftp5 = exports . liftp ; //# filterp :: (a -> Promise Boolean) -> Array a -> Promise Array a //. Takes a predicat that returns a Promise and an array of a, returns a Promise of array a //. > filterp(function(a) { return Promise.resolve(a > 3); })([2, 3, 4]) exports . filterp = function ( predictp ) { return function ( xs ) { return Promise . filter ( xs , predictp ) ; } ;", "del_tokens": "//# filterp :: (a -> Boolean) -> Array Promise a -> Promise Array a //. Takes a predicate and an array of Promise a, returns a Promise of array a //. > filterp(function(a) { return a > 3; })([ //. Promise.resolve(2), //. Promise.resolve(3), //. Promise.resolve(4)]) exports . filterp = function ( fn ) { return pipe ( exports . sequencep , exports . fmapp ( filter ( fn ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "enter", "to", "keybinding", "key_names"], "add_tokens": "export var KEY_NAMES = { 'enter' : 13 ,", "del_tokens": "var KEY_NAMES = {", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "default", "setting", "for", "enforce", "-", "define"], "add_tokens": "\"enforce-define\" : 0", "del_tokens": "\"enforce-deifne\" : 0", "commit_type": "fix"}
{"commit_tokens": ["Changing", "module", "configuration", "so", "that", "utility", "functions", "can", "be", "accessed", "in", "node", ".", "js"], "add_tokens": "version : '1.0.2' ,", "del_tokens": "version : '1.0.1' ,", "commit_type": "change"}
{"commit_tokens": ["Add", "slice_blob", "and", "report_upload_progress", "capabilities", "."], "add_tokens": "shimExec : function ( component , action ) { var args = [ ] . slice . call ( arguments , 2 ) ; return I . getShim ( ) . exec . call ( this , this . uid , component , action , args ) ; _files = [ ] . slice . call ( this . files ) ; report_upload_progress : function ( ) { return ! ! ( window . XMLHttpRequest && ( new XMLHttpRequest ) . upload ) ; } , slice_blob : ! ! ( window . File && ( File . prototype . mozSlice || File . prototype . webkitSlice || File . prototype . slice ) ) , stream_upload : function ( ) { return can ( 'slice_blob' ) && can ( 'send_multipart' ) ; } ,", "del_tokens": "shimExec : function ( component , action , args ) { return self . getShim ( ) . exec . call ( this , this . uid , component , action , args ) ; _files = this . files ; stream_upload : ! ! ( window . File && ( File . prototype . mozSlice || File . prototype . webkitSlice || File . prototype . slice ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "messages", "from", "gauge", "widget"], "add_tokens": "throw \"error: canvas context does not exist. setData() for gauges must be called after the gauge has been added to the screen via screen.append()\" throw \"error: canvas context does not exist. setData() for gauges must be called after the gauge has been added to the screen via screen.append()\" module . exports = Gauge", "del_tokens": "throw \"error: canvas context does not exist. setData() for line charts must be called after the chart has been added to the screen via screen.append()\" throw \"error: canvas context does not exist. setData() for line charts must be called after the chart has been added to the screen via screen.append()\" module . exports = Gauge", "commit_type": "fix"}
{"commit_tokens": ["added", "simple", "and", "nested", "array", "comprehensions", "with", "spec"], "add_tokens": "const expected = ` var { a , b } = abam ; ` expect ( compile ( example ) ) . toBe ( expected ) ; a , b : { c : { d } expect ( compile ( example ) ) . toBe ( expected ) ; } ) ; it ( 'maps simple array destructuring assignments' , ( ) => { const example = ` ` ; const expected = ` ` expect ( compile ( example ) ) . toBe ( expected ) ; it ( 'maps nested array destructuring assignments' , ( ) => { const example = ` ` ; const expected = ` ` expect ( compile ( example ) ) . toBe ( expected ) ; } ) ;", "del_tokens": "const expected = ` ` a , b : { c : { d }", "commit_type": "add"}
{"commit_tokens": ["Allow", "0", "for", "start", "and", "stop"], "add_tokens": "opts . start = parseInt ( opts . start , 10 ) ; opts . start = isNaN ( opts . start ) ? undefined : opts . start ; opts . stop = parseInt ( opts . stop , 10 ) ; opts . stop = isNaN ( opts . stop ) ? opts . start + OFFSET || undefined : opts . stop ; // 0 step is ignored.", "del_tokens": "opts . start = parseInt ( opts . start , 10 ) || undefined ; opts . stop = parseInt ( opts . stop , 10 ) || opts . start + OFFSET || undefined ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "issue", "where", "numbers", "in", "option", "values", "would", "not", "be", "added"], "add_tokens": "* v1 .14 .3 currentSelections . push ( $ ( this ) . attr ( 'data-value' ) ) ; var selection = $ ( this ) . attr ( 'data-value' ) ;", "del_tokens": "* v1 .14 .2 currentSelections . push ( $ ( this ) . data ( 'value' ) ) ; var selection = $ ( this ) . data ( 'value' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "to", "destory", "stream", "on", "error"], "add_tokens": "value . on ( 'error' , err => error ( input , err ) ) input . destroy ( value )", "del_tokens": "value . on ( 'error' , err => input . emit ( 'error' , err ) ) Promise . resolve ( ) . then ( ( ) => input . emit ( 'error' , value ) )", "commit_type": "make"}
{"commit_tokens": ["Made", "sure", "that", "using", "innerHTML", "re", "-", "renders", "the", "component"], "add_tokens": "} ) ) , content = document . createDocumentFragment ( ) , div = document . createElement ( 'div' ) ; div . className = '-shadow-root' ; content . appendChild ( div ) ; content . querySelector ( 'div' ) . innerHTML = code . content ; tag . replaceChild ( content , tag . firstChild ) ; tag . innerHTML = '<div class=\"-shadow-root\"></div>' ; Object . defineProperty ( tag , 'innerHTML' , { set : function ( val ) { tag . __originalInnerHTML = val ; renderInstance ( tagDescription , tag ) ; } , get : function ( ) { return tag . __originalInnerHTML ; } } ) ; if ( selector . match ( / :host\\b / ) || selector . match ( new RegExp ( '^\\\\s*' + tag + '\\\\b' ) ) ) { return selector ; }", "del_tokens": "} ) ) ; tag . innerHTML = code . content ; if ( selector . match ( / :host\\b / ) || selector . indexOf ( tag ) >= 0 ) { return selector ; }", "commit_type": "make"}
{"commit_tokens": ["change", "restkin", "test", "to", "express", "add", "content", "-", "type", "to", "restkin", "tracer"], "add_tokens": "headers : { \"X-Auth-Token\" : token , \"X-Tenant-Id\" : tenantId , \"Content-Type\" : \"application/json\" } ,", "del_tokens": "headers : { \"X-Auth-Token\" : token , \"X-Tenant-Id\" : tenantId } ,", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "or", "and", "map", "in", "toJsonSchema"], "add_tokens": "toJSONSchema ( subschema ) { return { type : 'object' , properties : subschema . values } ; toJSONSchema ( subschema ) { return { anyOf : subschema . alternatives } ; }", "del_tokens": "toJSONSchema ( ) { return { type : 'object' } ;", "commit_type": "add"}
{"commit_tokens": ["Use", "as", "default", "subdivision", "id", "instead", "of", "null"], "add_tokens": "if ( node . subdivisions . filter ( d => d . id === '' ) . length === 0 ) { defaultSub = { id : '' } if ( ! subs . has ( s ) ) s = '' if ( ! subs . has ( s ) ) s = ''", "del_tokens": "if ( node . subdivisions . filter ( d => d . id === null ) . length === 0 ) { defaultSub = { id : null } if ( ! subs . has ( s ) ) s = null if ( ! subs . has ( s ) ) s = null", "commit_type": "use"}
{"commit_tokens": ["Making", "sure", "no", "port", "in", "URL", "if", "80", "or", "443"], "add_tokens": "var apiPort = config . api . port + '' ; if ( apiPort !== '80' && apiPort !== '433' ) {", "del_tokens": "var apiPort = config . api . port ; if ( apiPort !== 80 && apiPort !== 443 ) {", "commit_type": "make"}
{"commit_tokens": ["added", "air", "-", "async", "adaptor", "for", "asynchronous", "SQLite", "operations", "in", "AIR"], "add_tokens": "'air' : window . AIRSQLiteAdaptor , 'air-async' : window . AIRSQLiteAsyncAdaptor", "del_tokens": "'air' : window . AIRSQLiteAdaptor", "commit_type": "add"}
{"commit_tokens": ["change", "object", "update", "schema", "in", "Collection", ".", "js", "and", "cap", "method", "names", "in", "Endpoint", ".", "options", "()"], "add_tokens": "schema : self . schema || { requiredProperties : [ '_id' ] } ,", "del_tokens": "schema : { requiredProperties : [ '_id' ] , properties : { _id : { type : { } } } } ,", "commit_type": "change"}
{"commit_tokens": ["remove", "left", "-", "over", "console", ".", "log"], "add_tokens": "", "del_tokens": "console . log ( arffData . data . length ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "memory", "flush", "to", "disk"], "add_tokens": "process . nextTick ( function ( ) { if ( typeof content === 'function' ) { callback = content ; content = [ ] ; } content = JSON . stringify ( _ . flatten ( content ) , null , 0 ) ; fs . writeFile ( file , content , function afterWriteFile ( err ) { return callback ( err ) ; } ) ; } else { readSync : function readSync ( file ) { return JSON . parse ( fs . readFileSync ( file , ENCODING ) ) ; } ,", "del_tokens": "if ( typeof content === 'function' ) { callback = content ; content = [ ] ; } content = JSON . stringify ( _ . flatten ( content ) , null , 0 ) ; fs . writeFile ( file , content , function afterWriteFile ( err ) { return callback ( err ) ; } else {", "commit_type": "fix"}
{"commit_tokens": ["Add", "header", "option", "for", "custom", "header", "name"], "add_tokens": "// header name var header = options . header || 'X-Response-Time' if ( this . getHeader ( header ) ) { return } this . setHeader ( header , ms . toFixed ( digits ) + 'ms' )", "del_tokens": "if ( this . getHeader ( 'X-Response-Time' ) ) return ; this . setHeader ( 'X-Response-Time' , ms . toFixed ( digits ) + 'ms' )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "an", "issue", "with", "PhantomJS", "disconnection", "."], "add_tokens": "// Id for this instance of PhantomJS var id = new Date ( ) . getTime ( ) % 100 ; var logHeader = \"[PhantomJS \" + id + \"]\" ; console . log ( logHeader + \" opening URL \" + url ) ; console . log ( logHeader + \" exiting\" ) ; console . log ( logHeader + \" log: \" , msg ) ; page . evaluate ( \"function(){window.top.attester.testError(\" + JSON . stringify ( error ) + \");}\" ) ; // For an unknown reason, page.evaluate does not always load the function in the top window, // but can sometimes load it in an iframe inside the page... var topWindow = window . top ; if ( ! topWindow . attester ) { topWindow . console . log ( 'autoexit check error: attester does not seem to be correctly loaded!' ) ; topWindow . console . log ( \"PHANTOMJS-ATTESTER-DISCONNECT\" ) ; } else if ( ! topWindow . attester . connected ) { topWindow . console . log ( 'autoexit check error: attester does not seem to be connected!' ) ; topWindow . console . log ( \"PHANTOMJS-ATTESTER-DISCONNECT\" ) ;", "del_tokens": "console . log ( \"[PhantomJS] opening URL \" + url ) ; console . log ( \"[PhantomJS] exiting\" ) ; console . log ( \"[PhantomJS] log: \" , msg ) ; page . evaluate ( \"function(){window.attester.testError(\" + JSON . stringify ( error ) + \");}\" ) ; if ( ! window . attester || ! window . attester . connected ) { console . log ( \"PHANTOMJS-ATTESTER-DISCONNECT\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["using", "BaseObject", "to", "reduce", "boilerplate"], "add_tokens": "var BaseObject = require ( 'kami-util' ) . BaseObject ; BaseObject . call ( this , context ) ;", "del_tokens": "var wrapContext = require ( 'kami-util' ) . wrapContext ; if ( ! context || typeof context !== \"object\" ) throw \"valid GL context not specified to SpriteBatch\" ; this . context = wrapContext ( context ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "undefined", "css", "class", "names"], "add_tokens": "className : ` ${ boxModelClassName } ${ className || '' } ` ,", "del_tokens": "className : ` ${ boxModelClassName } ${ className } ` ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "getOptions", "instead", "of", "parseQuery"], "add_tokens": "const query = Object . assign ( { } , DEFAULT_QUERY_VALUES , loaderUtils . getOptions ( this ) ) ;", "del_tokens": "const query = Object . assign ( { } , DEFAULT_QUERY_VALUES , loaderUtils . parseQuery ( this . query ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "direct", "printing", "syntax", "feature", "to", "the", "compiler", ".", "(", "e", ".", "g", ".", "<?js", ":", "will", "be", "printed", "?", ">", ")", ".", "Fixed", "error", "in", "file", "tests", "."], "add_tokens": "var _COMPILE_OUTPUT_FUNCTION = 'process.stdout.write' ; CodeBlockIndicators : [ // Defines the code block syntax to use. [0] ...code... [1] format. [2] = Direct print shortcut (e.g ) [0][2]...value to be passed to print function...[1] [ '<?js' , '?>' , ':' ] , [ '<%' , '%>' , '=' ] BeginHtmlBlock : _COMPILE_OUTPUT_FUNCTION + '(\\'' , EndHtmlBlock : '\\');' , BeginCodeDirectPrint : _COMPILE_OUTPUT_FUNCTION + '(' , EndCodeDirectPrint : ');' var openingCharacter = buffer [ start - 1 ] ; var printShortcut = openingCharacter == EnumJsHtmlSection . CodeBlockIndicators [ codeBlockEntryIndex ] [ 2 ] ; if ( printShortcut ) { outBuffer += EnumJsHtmlSection . BeginCodeDirectPrint ; } else if ( ( ' \\t\\n\\r\\v' ) . indexOf ( openingCharacter ) === - 1 ) { if ( printShortcut ) { outBuffer += EnumJsHtmlSection . EndCodeDirectPrint ; }", "del_tokens": "CodeBlockIndicators : [ // Defines the code block syntax to use. <[0] ...code... [1]> format [ '<?js' , '?>' ] , [ '<%' , '%>' ] BeginHtmlBlock : 'process.stdout.write(\\'' , EndHtmlBlock : '\\');' if ( ( ' \\t\\n\\r\\v' ) . indexOf ( buffer [ start - 1 ] ) === - 1 ) {", "commit_type": "add"}
{"commit_tokens": ["FIXED", ":", "X", "-", "UT", "-", "Route", "value"], "add_tokens": "'X-UT-Route' : ' https : //utas.external.fut.ea.com',", "del_tokens": "'X-UT-Route' : ' https : //utas.fut.ea.com',", "commit_type": "fix"}
{"commit_tokens": ["Updated", "sample", "app", "and", "Dockerfile"], "add_tokens": "var Flint = require ( 'node-flint' ) ;", "del_tokens": "var Flint = require ( './flint' ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "logging", "and", "make", "help", "clearer"], "add_tokens": ". option ( '-p, --platform [platform]' , '\\'linux\\', \\'win32\\', or \\'darwin\\'' ) . option ( '-a, --arch [architecture]' , '\\'ia32\\' or \\'x64\\'' )", "del_tokens": "console . log ( ` ${ options . version } ` ) ; console . log ( options ) ; . option ( '-p, --platform [platform]' , 'linux, win32, or darwin' ) . option ( '-a, --arch [architecture]' , 'ia32 or x64' )", "commit_type": "remove"}
{"commit_tokens": ["Add", "formating", "on", "inline", "help", "generation", "."], "add_tokens": ". addCommand ( 'lorem' , 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce et tempor tellus. Quisque dolor dui, ' + 'ullamcorper sit amet purus ut, tincidunt accumsan dolor. Etiam volutpat ipsum sit amet purus congue ' + 'mollis. Sed ut scelerisque dolor, eu condimentum nullam.' , function ( ) { } ) . addCommand ( 'lol' , \"The lol function\" , function ( ) {", "del_tokens": ". addCommand ( 'lol' , \"The lol function\" , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["add", "a", "comment", "on", "Function", ".", "caller"], "add_tokens": "} , // We have to use non-standard `caller` to find who invokes `belCreateElement` belCreateElement . caller . caller . caller )", "del_tokens": "} , belCreateElement . caller . caller . caller )", "commit_type": "add"}
{"commit_tokens": ["Add", "filters", "for", "places", ".", "getPlaces", "()"], "add_tokens": "getPlaces : generate . newGet ( \"places\" , paramsConfig . places . get ) ,", "del_tokens": "getPlaces : generate . newGet ( \"places\" , [ ] ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "setup", "command", "to", "cli"], "add_tokens": "var fs = require ( 'fs' ) ; var _ = require ( \"underscore\" ) ; var setup = require ( path . join ( __dirname , '../lib/setup.js' ) ) ; var generator = require ( path . join ( __dirname , '../lib/site_generator.js' ) ) ; var server = require ( path . join ( __dirname , '../lib/server.js' ) ) ; var publisher = require ( path . join ( __dirname , '../lib/publisher.js' ) ) ; var config_handler = require ( path . join ( __dirname , '../lib/config_handler.js' ) ) ; return setup . bare_structure ( args [ 0 ] )", "del_tokens": "var fs = require ( 'fs' ) ; var _ = require ( \"underscore\" ) ; var generator = require ( path . join ( __dirname , '../lib/site_generator.js' ) ) ; var server = require ( path . join ( __dirname , '../lib/server.js' ) ) ; var publisher = require ( path . join ( __dirname , '../lib/publisher.js' ) ) ; var config_handler = require ( path . join ( __dirname , '../lib/config_handler.js' ) ) ; // punch setup - Use the default template to create the site // punch setup boilerplate.zip - fetch the given template to create the site // punch setup --bare / punch setup -b - create a bare structure in current path // punch setup -b path - create a bare structure in given path", "commit_type": "add"}
{"commit_tokens": ["Move", "html2pdf", "initialization", "code", "out", "of", "Worker"], "add_tokens": "import Worker from './worker.js' ; var html2pdf = function html2pdf ( src , opt ) { // Create a new worker with the given options. var worker = new html2pdf . Worker ( opt ) ; if ( src ) { // If src is specified, perform the traditional 'simple' operation. return worker . from ( src ) . save ( ) ; } else { // Otherwise, return the worker for new Promise-based operation. return worker ; } } html2pdf . Worker = Worker ;", "del_tokens": "import { objType , createElement , cloneNode , unitConvert } from './utils.js' ;", "commit_type": "move"}
{"commit_tokens": ["fix", "issue", "with", "Button", "that", "ignore", "size", "prop"], "add_tokens": "shadowStyle , < View style = { [ this . styles . innerContainer , sizeStyle , link && this . styles . innerContainerLink ] } >", "del_tokens": "sizeStyle , shadowStyle , < View style = { [ this . styles . innerContainer , link && this . styles . innerContainerLink ] } >", "commit_type": "fix"}
{"commit_tokens": ["Added", "required", "fields", "validation", "and", "proper", "validation", "messages", ".", "Sorted", "out", "formatting", "too", "."], "add_tokens": "parent = item . parent ( ) , parents = item . parents ( 'text-block' ) ; if ( ! ( item . hasClass ( this . className ) || parent . hasClass ( this . className ) || item . hasClass ( 'text-block' ) || parent . length > 0 ) ) {", "del_tokens": "parent = item . parent ( ) ; if ( ! ( item . hasClass ( this . className ) || parent . hasClass ( this . className ) || item . hasClass ( 'text-block' ) || parent . hasClass ( 'text-block' ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["add", "IP", "tips", "in", "starting", "process"], "add_tokens": "const ip = require ( 'ip' ) ; console . log ( colors . green ( `", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "application", "router", "error", "handler", "."], "add_tokens": "//todo: make RequestErrror instead of SuperJS error //if super js error, the request has failed //else, an unknown error has occurred } else { //make the error stack easier to read if ( typeof err . stack === 'string' ) { err . stack = err . stack . split ( '\\n' ) ; //output the error object to the console //delete extra error object variables //prepare response object //move err.status out to the meta section //store the error on the response object //merge changes onto the existing response object self . setResponse ( response , res , response . meta . status ) ; //send the response to the user", "del_tokens": "} else { if ( err . stack ) { err . stack = err . stack . split ( '\\n' ) ; //delete internal error variables //move status out to the meta section self . setResponse ( response , res , err . status ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "node", "/", "links", "removal", "tests"], "add_tokens": "t . ok ( ! rectangleIsEmpty ( rect ) , 'Graph rectangle is not empty' ) ; test ( 'it removes removed nodes' , function ( t ) { var graph = createGraph ( ) ; var layout = createLayout ( graph ) ; var link = graph . addLink ( 1 , 2 ) ; layout . step ( ) ; graph . clear ( ) ; // since we removed evrything from graph rect should be empty: var rect = layout . getGraphRect ( ) ; t . ok ( rectangleIsEmpty ( rect ) , 'Graph rect is empty' ) ; t . end ( ) ; } ) ; return ( pos1 . x !== pos2 . x ) || ( pos1 . y !== pos2 . y ) ; function rectangleIsEmpty ( rect ) { return rect . x1 === 0 && rect . y1 === 0 && rect . x2 === 0 && rect . y2 === 0 ; }", "del_tokens": "t . ok ( Math . abs ( rect . x2 - rect . x1 ) > 0 || Math . abs ( rect . y2 - rect . y1 ) > 0 , 'Graph rectangle is not empty' ) ; return pos1 . x !== pos2 . x || pos1 . y !== pos2 . y ;", "commit_type": "add"}
{"commit_tokens": ["remove", "source", "maps", "after", "running", "tests"], "add_tokens": "var outMap = outFile + '.map' map : outMap return Promise . all ( [ fs . removeAsync ( outFile ) , fs . removeAsync ( outMap ) ] )", "del_tokens": "map : outFile + '.map' return fs . removeAsync ( outFile )", "commit_type": "remove"}
{"commit_tokens": ["added", "grunt", "uglify", "task", "and", "resulting", "dist", "/", "stampit", ".", "min", ".", "js"], "add_tokens": "} , uglify : { dist : { src : 'dist/stampit.js' , dest : 'dist/stampit.min.js' } grunt . loadNpmTasks ( 'grunt-contrib-uglify' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'browserify' , 'uglify' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'browserify' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "find", "model", "instance", "logic"], "add_tokens": "let model = this . config . models [ name ] ; if ( model ) { return model ; } let handle = this . config . handle ; if ( ! helper . isFunction ( handle ) ) { handle = this . constructor ; } return new handle ( name , this . config ) ;", "del_tokens": "return this . config . models [ name ] ;", "commit_type": "add"}
{"commit_tokens": ["Use", "common", "start", "/", "stopFrameRefreshTimer", "functions"], "add_tokens": "var realtime = me . realtime ; helpers . stopFrameRefreshTimer ( realtime ) ; helpers . startFrameRefreshTimer ( realtime , function ( ) { scroll ( me ) ; } ) ; realtime . head = Date . now ( ) ; helpers . stopFrameRefreshTimer ( me . realtime ) ;", "del_tokens": "function startFrameRefreshTimer ( scale ) { var realtime = scale . realtime ; if ( ! realtime . frameRequestID ) { var frameRefresh = function ( ) { scroll ( scale ) ; realtime . frameRequestID = helpers . requestAnimFrame . call ( window , frameRefresh ) ; } ; realtime . head = Date . now ( ) ; realtime . frameRequestID = helpers . requestAnimFrame . call ( window , frameRefresh ) ; } } function stopFrameRefreshTimer ( scale ) { var realtime = scale . realtime ; var frameRequestID = realtime . frameRequestID ; if ( frameRequestID ) { helpers . cancelAnimFrame . call ( window , frameRequestID ) ; delete realtime . frameRequestID ; } } startFrameRefreshTimer ( me ) ; stopFrameRefreshTimer ( me ) ; startFrameRefreshTimer ( me ) ; me . realtime . head = Date . now ( ) ; stopFrameRefreshTimer ( me ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "protocol", ".", "d", ".", "ts", "since", "it", "was", "unused", ";", "update", "tsserver", "path"], "add_tokens": "var tssPath = path . join ( __dirname , \"..\" , \"..\" , \"..\" , \"..\" , \"..\" , \"node_modules\" , \"typescript\" , \"lib\" , \"tsserver.js\" ) ;", "del_tokens": "var tssPath = path . join ( __dirname , \"..\" , \"node_modules\" , \"typescript\" , \"lib\" , \"tsserver.js\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "karma", "-", "firefox", "-", "launcher"], "add_tokens": "browsers : [ 'Chrome' , 'Firefox' ] ,", "del_tokens": "browsers : [ 'Chrome' ] ,", "commit_type": "add"}
{"commit_tokens": ["Added", "mkdirp", "and", "touch", "commands", "to", "create", "the", "output", "directory", "and", "file", "since", "browserify", "throws", "errors", "if", "they", "don", "t", "exist"], "add_tokens": "mkdirp = require ( 'mkdirp' ) , touch = require ( 'touch' ) , var outputDir = path . join ( patternDir , relativeDir ) ; // dest/subdir var outputPath = path . join ( outputDir , fileBaseName + fileExtName ) ; // dest/subdir/my-file.min.js // Create the output directory and file, // since browserify throws errors if they don't exist mkdirp ( outputDir , function ( ) { touch ( outputPath ) ; } ) ;", "del_tokens": "var outputPath = path . join ( patternDir , relativeDir , fileBaseName + fileExtName ) ; // dest/subdir/my-file.min.js", "commit_type": "add"}
{"commit_tokens": ["Changed", "skyinfo", "entity", "to", "be", "consistent", "with", "others", "sky", "entities"], "add_tokens": "status : m . trim ( )", "del_tokens": "message : m . trim ( )", "commit_type": "change"}
{"commit_tokens": ["add", "test", "coverage", "for", "missing", "return", "for", "dndPreview", "()", "callback", "."], "add_tokens": "// source with handler, a dndPreview returns undefined dndService . addSource ( { dndModel : model2 , dndElement : box_0_4 , dndPreview : ( ) => undefined } , { handler : box_0_4_handler } ) ; // dndPreview() returns undefined, fall back to default preview. t . equal ( preview . text ( ) , '04' ) ;", "del_tokens": "// source with handler dndService . addSource ( { dndModel : model2 , dndElement : box_0_4 } , { handler : box_0_4_handler } ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "arrays", "as", "column", "values", "."], "add_tokens": "if ( val instanceof Array ) { return $as . array ( val ) ; } else { // it is either unknown object or a number; return typeof ( val ) === 'object' ? null : val . toString ( ) ; } // Converts array-value into Postgres format; // It supports arrays of any dimension; function formatArray ( arr ) { var s = '{' ; for ( var i = 0 ; i < arr . length ; i ++ ) { if ( i ) { s += ',' ; } if ( arr [ i ] instanceof Array ) { s += formatArray ( arr [ i ] ) ; } else { s += formatValue ( arr [ i ] ) ; } } return s + '}' ; } array : function ( arr ) { if ( isDBNull ( arr ) ) { return 'null' ; } if ( arr instanceof Array ) { return wrapText ( formatArray ( arr ) ) ; } else { throw new Error ( wrapText ( arr ) + \" doesn't represent a valid Array object.\" ) ; } } ,", "del_tokens": "// it is either unknown object or a number; return typeof ( val ) === 'object' ? null : val . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "rule", "applies", "to", "undefined", "and", "null"], "add_tokens": "' \\n \\n \\t' , null , undefined", "del_tokens": "' \\n \\n \\t'", "commit_type": "make"}
{"commit_tokens": ["added", "optional", "factory", "method", "to", "THREE", ".", "BAS", ".", "PrefabBufferGeometry", ".", "createAttribute"], "add_tokens": "THREE . BAS . PrefabBufferGeometry . prototype . createAttribute = function ( name , itemSize , factory ) { if ( factory ) { for ( var i = 0 , offset = 0 ; i < this . prefabCount ; i ++ ) { var r = factory ( i , this . prefabCount ) ; for ( var j = 0 ; j < this . prefabVertexCount ; j ++ ) { for ( var k = 0 ; k < itemSize ; k ++ ) { buffer [ offset ++ ] = typeof r === 'number' ? r : r [ k ] ; } } } }", "del_tokens": "THREE . BAS . PrefabBufferGeometry . prototype . createAttribute = function ( name , itemSize ) {", "commit_type": "add"}
{"commit_tokens": ["updated", "export", "defs", ".", "whoops", "."], "add_tokens": "export { MessageService } from './src/message.service' ;", "del_tokens": "export { MessagesService } from './src/users.service' ;", "commit_type": "update"}
{"commit_tokens": ["adding", "server", "config", "to", "turn", "off", "the", "browser"], "add_tokens": "specs : 'spec/**/*.js' , server : { openBrowser : true } } , 'jasmine-server' : { browser : true", "del_tokens": "specs : 'spec/**/*.js'", "commit_type": "add"}
{"commit_tokens": ["Updated", "test", "paths", "to", "work", "on", "Windows", "and", "Unix"], "add_tokens": "expect ( endpoints . index . filename ) . to . match ( / [\\\\\\/]testApi[\\\\\\/]index\\.js$ / ) ; expect ( endpoints . user . filename ) . to . match ( / [\\\\\\/]testApi[\\\\\\/]user\\.js$ / ) ; expect ( endpoints [ 'sub/index' ] . filename ) . to . match ( / [\\\\\\/]testApi[\\\\\\/]sub[\\\\\\/]index\\.js$ / ) ; expect ( endpoints [ 'sub/subs' ] . filename ) . to . match ( / [\\\\\\/]testApi[\\\\\\/]sub[\\\\\\/]subs\\.js$ / ) ; expect ( endpoints [ 'sub/level3/index' ] . filename ) . to . match ( / [\\\\\\/]testApi[\\\\\\/]sub[\\\\\\/]level3[\\\\\\/]index\\.js$ / ) ;", "del_tokens": "expect ( endpoints . index . filename ) . to . match ( / \\\\testApi\\\\index\\.js$ / ) ; expect ( endpoints . user . filename ) . to . match ( / \\\\testApi\\\\user\\.js$ / ) ; expect ( endpoints [ 'sub/index' ] . filename ) . to . match ( / \\\\testApi\\\\sub\\\\index\\.js$ / ) ; expect ( endpoints [ 'sub/subs' ] . filename ) . to . match ( / \\\\testApi\\\\sub\\\\subs\\.js$ / ) ; expect ( endpoints [ 'sub/level3/index' ] . filename ) . to . match ( / \\\\testApi\\\\sub\\\\level3\\\\index\\.js$ / ) ;", "commit_type": "update"}
{"commit_tokens": ["updated", "readme", "(", "and", "minor", "update", "to", "readfiles", "require", "path", ")"], "add_tokens": "exports . readFiles = require ( path . join ( __dirname , 'lib' , 'readfiles' ) ) ;", "del_tokens": "exports . readFiles = require ( path . join ( __dirname + '/lib/readfiles' ) ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "error", "message", "on", "bad", "operation"], "add_tokens": "function emit ( operation ) { if ( ! cli . emit ( args . join ( ' ' ) ) ) { console . log ( 'illegal operation: \"%s\"' . red , operation ) ; cli . emit ( 'help' ) ; } } setTimeout ( emit , 1 , args . join ( ' ' ) ) ;", "del_tokens": "setTimeout ( cli . emit , 1 , args . join ( ' ' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "handling", "and", "logging"], "add_tokens": "request = require ( 'request' ) ; yahoo . logging = geo . logging ; / ** * Report error . * / var onError = function ( msg ) { if ( module . exports . error ) { module . exports . error ( msg ) ; } } ; var yahoo = { logging : false } ; if ( yahoo . logging ) console . log ( 'Requesting %s' , url ) ; parser . parseString ( body , function ( err , result ) { try { var weather = result . channel . item [ 'yweather:condition' ] [ '@' ] ; } catch ( e ) { onError ( 'Failed to find weather' ) ; return ; } if ( yahoo . logging ) console . log ( 'Requesting %s' , url ) ;", "del_tokens": "request = require ( 'request' ) ; var yahoo = { } ; parser . parseString ( body , function ( err , result ) { var weather = result . channel . item [ 'yweather:condition' ] [ '@' ] ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "generated", "doc", "links", "."], "add_tokens": "baseURL : 'https://github.com/googleads/videojs-ima/blob/master/'", "del_tokens": "baseURL : 'https://github.com/googleads/videojs-ima/blob/master'", "commit_type": "fix"}
{"commit_tokens": ["adding", "greeting", "and", "reporting", "on", "versions", "at", "startup"], "add_tokens": "thisPkg = require ( './package.json' ) , project : { } , env : process . env . GILT_ENV || 'development' require ( 'colors' ) ; console . log ( ' ' swig-project'. r ed v' hisPkg. v ersion \\n'); console . log ( ' ' gulpfile: '. b lue odule. p arent. i d. r eplace( p rocess. e nv. H OME, ~') . g rey \\n') ; swig . log . warn ( 'swig-project' , '.swigrc not found at: ' + '~/.swigrc' . grey + '. Please grab a copy from ' + '/web/tools/config.\\n' . grey ) ; swig . log . info ( 'swig-test' , 'This is a test info message.\\n' ) ; swig . log . error ( 'swig-test' , 'This is a test error message.\\n' ) ;", "del_tokens": "project : { } swig . log ( '[swig-project]' . yellow + ' .swigrc not found at: ' + '~/.swigrc' . grey + '.\\nPlease grab a copy from /web/tools/config' ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "keeping", "track", "of", "line", "index", "while", "iterating", "over", "line", "."], "add_tokens": "s = lineIterator . take ( chars ) ; textIterator . skip ( 1 ) ; // begin attribute processing after lmkr character assem . append ( getXmlForLineSpan ( textIterator , text . length , startIndex - getIteratorIndex ( textIterator , text . length ) ) . withMarkup ) ; assem . append ( getXmlForLineSpan ( textIterator , text . length , textIterator . remaining ( ) ) . withMarkup ) ;", "del_tokens": "var idx = 0 ; var lmkrRemoved = false ; s = \"\" ; if ( lmkr && ! lmkrRemoved ) { s = lineIterator . take ( chars + 1 ) ; s = s . substring ( 1 ) ; lmkrRemoved = true ; } else { s = lineIterator . take ( chars ) ; } idx = 1 ; // begin attribute processing after lmkr character assem . append ( getXmlForLineSpan ( textIterator , text . length , startIndex - idx ) . withMarkup ) ; idx += startIndex - idx ; idx += urlLength ; assem . append ( getXmlForLineSpan ( textIterator , text . length , text . length - idx ) . withMarkup ) ; idx += text . length - idx ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "get", "and", "count", "methods", "support", "ranges", "and", "directions"], "add_tokens": "var range = ( options . range && options . range instanceof window . IDBKeyRange ) ? options . range : null ; iterateRequest = objStore . index ( options . index ) . openCursor ( range , direction ) ; iterateRequest = objStore . openCursor ( range , direction ) ; var range = ( options . range && options . range instanceof window . IDBKeyRange ) ? options . range : null ; countRequest = objStore . index ( options . index ) . count ( range ) ; countRequest = objStore . count ( range ) ;", "del_tokens": "// @todo keyrange + iterate direction iterateRequest = objStore . index ( options . index ) . openCursor ( null , direction ) ; // @todo keyrange + iterate direction - https://developer.mozilla.org/en-US/docs/IndexedDB/IDBKeyRange iterateRequest = objStore . openCursor ( null , direction ) ; // @todo keyrange countRequest = objStore . index ( options . index ) . count ( ) ; // @todo keyrange countRequest = objStore . count ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "test", "that", "shows", "that", "injector", "is", "broken"], "add_tokens": "key ( { \"Highlevel Injected key\" : [ \"Injected key\" , \"=> $return\" ] } ) ; key . run ( \"Highlevel Injected key\" ) . then ( function ( retVal ) { expect ( retVal ) . to . eql ( \"This is the return value from the next\" ) ; } ) ;", "del_tokens": "expect ( name ) . to . eql ( \"Injected key\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Created", "behaviors", "that", "use", "feathers", "-", "client", "."], "add_tokens": "const stealTools = require ( 'steal-tools' ) ; const path = require ( 'path' ) ; system : { config : path . join ( __dirname , '/package.json!npm' ) } , outputs : { '+cjs' : { } , '+amd' : { } , '+global-js' : { } } } ) . catch ( function ( e ) { setTimeout ( function ( ) { throw e ; } , 1 ) ;", "del_tokens": "var stealTools = require ( \"steal-tools\" ) ; system : { config : __dirname + \"/package.json!npm\" } , outputs : { \"+cjs\" : { } , \"+amd\" : { } , \"+global-js\" : { } } } ) . catch ( function ( e ) { setTimeout ( function ( ) { throw e ; } , 1 ) ;", "commit_type": "create"}
{"commit_tokens": ["add", "mysql", "order", "by", "column", "format", ".", "mysql", "doesn", "t", "allow", "brackets", "around", "the", "order", "items", "."], "add_tokens": "var OrderByColumnNode = require ( __dirname + '/node/orderByColumn' ) ; this . desc = this . descending = new OrderByColumnNode ( { column : this . toNode ( ) , direction : new TextNode ( 'DESC' )", "del_tokens": "this . desc = this . descending = new BinaryNode ( { left : this . toNode ( ) , right : new TextNode ( 'DESC' ) , operator : ''", "commit_type": "add"}
{"commit_tokens": ["Changed", "button", "to", "use", "custom", "messages", "instead", "of", "state", "to", "communicate", "events", "."], "add_tokens": "var data = { 'custom_content' : content } ;", "del_tokens": "var data = { custom_content : content } ;", "commit_type": "change"}
{"commit_tokens": ["add", "snackbar", "switch", "and", "slider", "component", "."], "add_tokens": "_onclick ( ) { this . _input . dispatchEvent ( new Event ( 'change' , { bubbles : true } ) ) ;", "del_tokens": "_onclick ( e ) { e . preventDefault ( ) ; this . _input . dispatchEvent ( new Event ( 'change' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "force", "change", "event", "for", "IE", "on", "radio", "&", "checkboxes"], "add_tokens": "var getDataStub , eventMock , func , dataStub , changeSpy ; changeSpy = sinon . stub ( bs . utils , \"forceChange\" ) ; afterEach ( function ( ) { changeSpy . reset ( ) ; } ) ; it ( \"should force the change event if elem type is radio or checkbox\" , function ( ) { eventMock . target . type = \"checkbox\" ; func ( eventMock ) ; sinon . assert . called ( changeSpy ) ; } ) ; it ( \"should force the change event if elem type is radio or checkbox\" , function ( ) { eventMock . target . type = \"radio\" ; func ( eventMock ) ; sinon . assert . called ( changeSpy ) ; } ) ;", "del_tokens": "var getDataStub , eventMock , func , dataStub ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "when", "a", "command", "had", "a", "string", "it"], "add_tokens": "const parts = command . match ( / (?:[^\\s\"]+|\"[^\"]*\")+ / g ) ; const parts = command . match ( / (?:[^\\s\"]+|\"[^\"]*\")+ / g ) ;", "del_tokens": "const parts = command . split ( / \\s+ / g ) ; const parts = command . split ( / \\s+ / g ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "operator", "for", "string", "comparison"], "add_tokens": "rules : context . rules , regexps : context . regexps", "del_tokens": "rules : context . rules", "commit_type": "add"}
{"commit_tokens": ["changed", "default", "dom", "element", "to", "document", ".", "body"], "add_tokens": "e = document . body shell . element = document . body", "del_tokens": "e = window shell . element = window", "commit_type": "change"}
{"commit_tokens": ["adding", "a", "hook", "for", "post", "-", "processing", "the", "duo", "build"], "add_tokens": ". fluent ( \"hook\" ) var hook = this . hook ( ) ; build . run ( function ( err , src ) { if ( err ) return callback ( err ) ; if ( hook ) src = hook ( src , build . entry ( ) ) ; callback ( null , src ) ; } ) ;", "del_tokens": "build . run ( callback ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "timer", "tests", "to", "separate", "file", "made", "descending", "timer", "test", "fixed", "bug", "with", "descending", "timers"], "add_tokens": "return this . millis - ( new Date ( ) . getTime ( ) - this . start ) ; return this . millis + ( new Date ( ) . getTime ( ) - this . start ) ;", "del_tokens": "return this . millis - new Date ( ) . getTime ( ) - this . start ; return this . millis + new Date ( ) . getTime ( ) - this . start ;", "commit_type": "move"}
{"commit_tokens": ["fix", "deepFreeze", "to", "handle", "functions", "as", "values", "in", "strict", "mode"], "add_tokens": "Object . keys ( o ) . forEach ( function eachProp ( prop ) {", "del_tokens": "Object . getOwnPropertyNames ( o ) . forEach ( function eachProp ( prop ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "===", "instead", "of", "==", "for", "comparision", "."], "add_tokens": "defaultEntryParser = typeof this . opts . entryParser === \"function\" ? this . opts . entryParser : defaultEntryParser ;", "del_tokens": "defaultEntryParser = typeof this . opts . entryParser == \"function\" ? this . opts . entryParser : defaultEntryParser ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "path", "handling", "for", "windows"], "add_tokens": "var ROOT_DIR = path . resolve ( __dirname , '..' ) ; if ( ! external ) filename = path . resolve ( ROOT_DIR , filename ) ; if ( path . resolve ( pathname ) == pathname ) return pathname ; return path . resolve ( path . dirname ( inputPath ) , pathname ) ;", "del_tokens": "var ROOT_DIR = path . normalize ( __dirname + '/../' ) ; if ( ! external ) filename = ROOT_DIR + filename ; return path . normalize ( path . dirname ( inputPath ) + '/' + pathname ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "function", "to", "remove", "all", "lights"], "add_tokens": "Version 0.6 ~ dev , generated on Mon Dec 29 14 : 40 : 51 CET 2014. / ** * Remove all light sources * / ROT . Lighting . prototype . clearLights = function ( ) { this . _lights = { } ; }", "del_tokens": "Version 0.6 ~ dev , generated on Tue Oct 14 15 : 41 : 20 CEST 2014.", "commit_type": "add"}
{"commit_tokens": ["Remove", "function", "declaration", "from", "loop"], "add_tokens": "var vertex ; var enqueue = function ( neighbor ) { if ( callbacks . allowTraversal ( vertex , neighbor ) ) { callbacks . onTraversal ( vertex , neighbor ) ; vertexQueue . push ( neighbor ) ; } } ; while ( ! vertexQueue . isEmpty ( ) ) { vertex = vertexQueue . pop ( ) ; graph . neighbors ( vertex ) . forEach ( enqueue ) ;", "del_tokens": "/* jshint loopfunc: true */ while ( ! vertexQueue . isEmpty ( ) ) { var vertex = vertexQueue . pop ( ) ; graph . neighbors ( vertex ) . forEach ( function ( neighbor ) { if ( callbacks . allowTraversal ( vertex , neighbor ) ) { callbacks . onTraversal ( vertex , neighbor ) ; vertexQueue . push ( neighbor ) ; } } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "uglify", "and", "concat", "for", "client", "-", "side", "javascript", "."], "add_tokens": "concat : { options : { separator : ';' , } , dist : { src : [ 'lib/motionpredict.js' ] , dest : '<%= pkg.name %>.js' , } , } , } , uglify : { options : { // banner: '/*! <%= pkg.name %> <%= grunt.template.today(\"yyyy-mm-dd\") %> Copyright by <%= pkg.author.name %> <%= pkg.author.email %> */$ } , build : { src : '<%= pkg.name %>.js' , dest : '<%= pkg.name %>.min.js' } grunt . loadNpmTasks ( 'grunt-contrib-concat' ) ; grunt . loadNpmTasks ( 'grunt-contrib-uglify' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'mochaTest' , 'concat' , 'yuidoc' , 'uglify' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'mochaTest' , 'yuidoc' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "assert", "failed", "message", "when", "the", "slave", "is", "not", "found", "when", "processing", "slaveDisconnected", "events"], "add_tokens": "var createSocketSlaveHandler = function ( methodName , ignoreMissingSlave ) { } else if ( ! ignoreMissingSlave ) { Orchestrator . prototype . onSocketSlaveDisconnected = createSocketSlaveHandler ( \"onSlaveDisconnected\" , true ) ;", "del_tokens": "var createSocketSlaveHandler = function ( methodName ) { } else { Orchestrator . prototype . onSocketSlaveDisconnected = createSocketSlaveHandler ( \"onSlaveDisconnected\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "in", "utils", ".", "log", "function", "on", "client", "side"], "add_tokens": "* @ since 0.0 .1 * @ version 0.0 .11 if ( level === 'error' && typeof message === 'object' ) {", "del_tokens": "* @ since 2013.01 .22 * @ version 2013.01 .23 if ( level === 'error' ) {", "commit_type": "fix"}
{"commit_tokens": ["Updating", "invoker", "adding", "split", "."], "add_tokens": "// Passing the optional `len` parameter restricts the function to the initial `len` parameters of the method. var invoker = R . invoker = function ( name , obj , len ) { var length = len === undef ? method . length : len ; return method && _ ( nAry ( length + 1 , function ( ) { // The string split into substring at the specified token // // split('.', 'a.b.c.xyz.d') //=> // ['a', 'b', 'c', 'xyz', 'd'] R . split = invoker ( \"split\" , String . prototype , 1 ) ;", "del_tokens": "var invoker = R . invoker = function ( name , obj ) { return method && _ ( nAry ( method . length + 1 , function ( ) {", "commit_type": "update"}
{"commit_tokens": ["Made", "flappy", "bird", "slightly", "responsive"], "add_tokens": "// Keep the game window sensible dimensions. if ( levelHeight < 800 ) { levelHeight = 800 ; } var minimumEdgeDistance = levelHeight * 0.2 ; var pipePosition = minimumEdgeDistance - ( Math . random ( ) * pipeHeight / 2 ) ; x : levelWidth * 0.15 , y : levelHeight / 2", "del_tokens": "var minimumTopDistance = 200 ; var pipePosition = minimumTopDistance - ( Math . random ( ) * pipeHeight / 2 ) ; x : 320 , y : levelHeight / 2", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "few", "benchmarks", "."], "add_tokens": "var today = new Hebcal . HDate , year = new Hebcal ; console . log ( '.tachanun() for every day of the year' ) ; hrtimer ( 'today.tachanun()' ) ; year . map ( function ( d ) { d . tachanun ( ) } ) ; hrtimer ( 'today.tachanun()' ) ; console . log ( '' ) ; console . log ( '.hallel() for every day of the year' ) ; hrtimer ( 'today.hallel()' ) ; year . map ( function ( d ) { d . hallel ( ) } ) ; hrtimer ( 'today.hallel()' ) ; console . log ( '' ) ; console . log ( '.holidays() for every day of the year' ) ; hrtimer ( 'today.holidays()' ) ; year . map ( function ( d ) { d . holidays ( ) } ) ; hrtimer ( 'today.holidays()' ) ; console . log ( '' ) ; console . log ( '.getSedra() for every day of the year' ) ; hrtimer ( 'today.getSedra()' ) ; year . map ( function ( d ) { d . getSedra ( ) } ) ; hrtimer ( 'today.getSedra()' ) ; console . log ( '' ) ;", "del_tokens": "var today = new Hebcal . HDate ;", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "levels", "and", "abilities"], "add_tokens": "const actions = [ ] ; if ( unit . explode ) { actions . push ( 'explode' ) ; } const addedUnit = this . unit ( unit . type , unit . x , unit . y , unit . facing , actions ) ; if ( unit . explode ) { addedUnit . getActions ( ) . explode . setTime ( unit . explode ) ; }", "del_tokens": "this . unit ( unit . type , unit . x , unit . y , unit . facing ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "column", "positioning", "and", "column", "max", "width"], "add_tokens": "//var dataLength = Math.min(a.data.length,chart.q.series.length) for ( var i = 0 ; i < a . data . length ; i ++ ) { if ( i < chart . q . series . length ) { a . data [ i ] = $ . extend ( { } , chart . q . series [ i ] , d ) } else { //defaults for new series a . data [ i ] . type = \"line\" }", "del_tokens": "var dataLength = Math . min ( a . data . length , chart . q . series . length ) for ( var i = 0 ; i < dataLength ; i ++ ) { a . data [ i ] = $ . extend ( { } , chart . q . series [ i ] , d )", "commit_type": "fix"}
{"commit_tokens": ["changed", "SPM", "event", "field", "content", "and", "version", "info"], "add_tokens": "var info = os . platform ( ) + ', ' + os . arch ( ) + ', ' + runtime + ' ' + process . versions . node name : ( process . env . SPM_REPORTED_HOSTNAME || os . hostname ( ) ) , creator : packageName + ' ' + programVersion + ' / ' + 'spm-agent (nodejs) ' + clientVersion", "del_tokens": "var info = ( process . env . SPM_REPORTED_HOSTNAME || os . hostname ( ) ) + ': ' + os . platform ( ) + ', ' + os . arch ( ) + ', ' + runtime + ' ' + process . versions . node + ', ' + 'spm ' + programVersion name : packageName + ' ' + programVersion , creator : 'spm-agent (nodejs) ' + clientVersion", "commit_type": "change"}
{"commit_tokens": ["Fix", "epub", "standard", "problems", ":", "Containers", "must", "include", "a", "mimetype", "file", "as", "the", "first", "file", "and", "the", "first", "playOrder", "value", "in", "a", "document", "shall", "be", "1"], "add_tokens": "handlebars . registerHelper ( 'playOrder' , function ( index ) { return index + 1 ; } ) ; var addStaticFiles = function ( ) { } ; // add dynamic files var addDynamicFiles = function ( ) { addStaticFiles ( ) ; addDynamicFiles ( ) ; } ;", "del_tokens": "var addBasicFiles = function ( ) { addBasicFiles ( ) ; } ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "linux", "DISPLAY", "environment", "variable", "check", "on", "startup"], "add_tokens": "const _check = ( ) => { if ( os . platform ( ) === 'linux' && ! process . env [ 'DISPLAY' ] ) { return Promise . reject ( new Error ( 'DISPLAY environment variable not set; cannot create window' ) ) ; } else { return Promise . resolve ( ) ; } } ; _check ( ) . then ( ( ) => _prepare ( ) )", "del_tokens": "_prepare ( )", "commit_type": "add"}
{"commit_tokens": ["Remove", "references", "to", "unimplemented", "definition", "command"], "add_tokens": "var commands = [ 'app' , 'print' ] ;", "del_tokens": "var commands = [ 'app' , 'print' , 'definition' ] ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", ":", "Block", "position", "error", "with", "Bootstrap", "3", ".", "x"], "add_tokens": "* jQuery Schedule v1 .2 .1", "del_tokens": "* jQuery Schedule v1 .2 .0", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "basic", "plugin", "system"], "add_tokens": "plugin : require ( './core/plugin' ) , Point : require ( '../lib/pixi/src/core/math/Point' ) , ParticleContainer : require ( './display/ParticleContainer' )", "del_tokens": "Point : require ( '../lib/pixi/src/core/math/Point' )", "commit_type": "add"}
{"commit_tokens": ["Added", "deprecation", "warning", "to", "workbook", ".", "addWorksheet", "for", "options", ".", "tabColor"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "issues", "with", "encoded", "slashes", "in", "path"], "add_tokens": "pathMatch = this . pathObject . regexp . exec ( parseUrl ( req . url ) . pathname ) ; // decode URI component here to avoid issues with encoded slashes value = decodeURIComponent ( pathMatch [ _ . findIndex ( this . pathObject . regexp . keys , function ( key ) { } ) + 1 ] ) ;", "del_tokens": "// Since we get the raw path parameter value, we need to URI decode it pathMatch = this . pathObject . regexp . exec ( parseUrl ( decodeURIComponent ( req . url ) ) . pathname ) ; value = pathMatch [ _ . findIndex ( this . pathObject . regexp . keys , function ( key ) { } ) + 1 ] ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "Tooltip", "proptypes"], "add_tokens": "children : PropTypes . node . isRequired ,", "del_tokens": "children : PropTypes . node . isRequried ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "utility", "method", "to", "load", "dump", "files"], "add_tokens": "utils . loadDumpFile ( database , __dirname + '/fixture/companies/ddl.grn' ) ; utils . loadDumpFile ( database , __dirname + '/fixture/companies/data.grn' ) ;", "del_tokens": "schemeDump . split ( '\\n' ) . forEach ( function ( command ) { database . commandSyncString ( command ) ; } ) ;", "commit_type": "use"}
{"commit_tokens": ["adding", "output", "to", "init", "script"], "add_tokens": "console . log ( '\\nPlease enter the full path of your data directory\\n' + '(be sure and include /data, so will look something like /path/to/repo/calvin-network-data/data ): ' ) ; console . log ( 'Example build: node nodejs/prm build --prefix test' ) ; console . log ( 'Full Docs: https://github.com/ucd-cws/calvin-network-tools' ) ;", "del_tokens": "console . log ( '\\nPlease enter the full path of your data directory: ' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "wrong", "element", "output", "."], "add_tokens": "case 'markdown' : element . name = 'div' ; element . children = cheerio . parseHTML ( md . render ( cheerio . html ( element . children ) ) ) ; break ; cb ( null , cheerio . html ( nodes ) ) ;", "del_tokens": "case 'markdown' : element . name = 'div' ; element . children = cheerio . parseHTML ( md . render ( cheerio . html ( element . children ) ) ) ; break ; cb ( null , cheerio . html ( dom ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "race", "condition", "where", "authorizer", ".", "actionList", "is", "called", "before", "all", "resources", "are", "loaded"], "add_tokens": "this . loadResources ( resources ) . done ( function ( ) { this . processResource ( 'api' , require ( './_autohost/resource.js' ) ( this ) , path . resolve ( __dirname , './_autohost' ) ) ; if ( this . authorizer ) { var list = [ ] ; _ . each ( this . actions , function ( actions , resource ) { _ . each ( actions , function ( action ) { list . push ( { name : action , resource : resource } ) ; } ) ; this . authorizer . actionList ( list , function ( ) { } ) ; } } . bind ( this ) ) ;", "del_tokens": "this . loadResources ( resources ) ; this . processResource ( 'api' , require ( './_autohost/resource.js' ) ( this ) , path . resolve ( __dirname , './_autohost' ) ) ; if ( this . authorizer ) { var list = [ ] ; _ . each ( this . actions , function ( actions , resource ) { _ . each ( actions , function ( action ) { list . push ( { name : action , resource : resource } ) ; } ) ; this . authorizer . actionList ( list , function ( ) { } ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fixing", "typo", "in", "cloudside", "/", "unhosted", ".", "php"], "add_tokens": "var SubscribingPasswordMe = { \"error\" : \"... please follow the README instructions and generate this file with genkey page before use\" } ;", "del_tokens": "var SubscribingPasswordMe = { \"r\" : \"7db31\" , \"c\" : \"example.unhosted.org\" , \"n\" : \"cd1d52edc48e125d5f01dbdb38f14796c13cc990363662e71ed9cc988b725e465553fcfcea1ad96d095f31afe16ab617a36ae4f77fc32dd750ef7143806c5635\" , \"s\" : \"bf184d7a9fae58593c36eb46cb09226b\" } ;", "commit_type": "fix"}
{"commit_tokens": ["added", "tests", "for", "parsing", "row", "definition", "messages", "of", "various", "lenghts"], "add_tokens": "var fields = [ ] ; fields [ i ] = this . parseField ( ) ; msg . fields = fields ; return row ;", "del_tokens": "msg . fields = [ ] ; msg . fields [ i ] = this . parseField ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "validation", "of", "plugins", "property", "on", "configuration"], "add_tokens": "// Handle plugins special since we can't predict how they will look. // For example plugins.createBuilder can be an object with new keys or it might not be it. if ( isPlainObject ( value ) && oldPath !== 'plugins.' ) {", "del_tokens": "if ( isPlainObject ( value ) ) {", "commit_type": "change"}
{"commit_tokens": ["removed", "year", "and", "time", "as", "datetime", "indicators"], "add_tokens": "var output = { data : data , datetime : ( / date / gi ) . test ( data [ 0 ] . name ) } if ( ( / date / gi ) . test ( a [ i ] [ 0 ] ) ) {", "del_tokens": "var output = { data : data , datetime : ( ( / date / gi ) . test ( data [ 0 ] . name ) || ( / time / gi ) . test ( data [ 0 ] . name ) ) } if ( ( / date / gi ) . test ( a [ i ] [ 0 ] ) || ( / time / gi ) . test ( a [ i ] [ 0 ] ) || ( / year / gi ) . test ( a [ i ] [ 0 ] ) ) {", "commit_type": "remove"}
{"commit_tokens": ["use", "local", "loading", "status", "mixin"], "add_tokens": "var loadingStatus = require ( './lib/loading-status' ) ; loadingStatus ,", "del_tokens": "var LoadingStatusMixin = require ( 'react-loading-status-mixin' ) ; LoadingStatusMixin ,", "commit_type": "use"}
{"commit_tokens": ["Fixed", "the", "openingTime", "and", "closingTime", "property", "wrong", "access", "made", "active", "not", "correct"], "add_tokens": "ride_data . active = ride_data . schedule . openingTime ? true : false ; ride_data . active = moment ( ) . isBetween ( ride_data . schedule . openingTime , ride_data . schedule . closingTime ) ;", "del_tokens": "ride_data . active = ride_data . openingTime ? true : false ; ride_data . active = moment ( ) . isBetween ( ride_data . openingTime , ride_data . closingTime ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "debug", "mode", "for", "RequestHelper", "externally"], "add_tokens": "var debug = false ; var verbose = false ; if ( verbose ) { console . log ( 'Got new token:' , accessToken ) ; } if ( debug ) { console . log ( \"Sending data:\" , data ) ; } if ( debug ) { console . log ( response ) ; } if ( verbose ) { console . log ( \"Unauthorized, trying to get new token...\" ) ; } if ( verbose ) { console . log ( \"Retrying request...\" ) ; } return path . replace ( \"{{projectId}}\" , projectId ) ; } function setDebug ( state ) { debug = state ; } function setVerbose ( state ) { verbose = state ; setDebug : setDebug , setVerbose : setVerbose ,", "del_tokens": "console . log ( 'Got new token:' , accessToken ) ; console . log ( \"Unauthorized, trying to get new token...\" ) ; console . log ( \"Retrying request...\" ) ; var preparedPath = path . replace ( \"{{projectId}}\" , projectId ) ; return preparedPath ;", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "ignoring", "paths"], "add_tokens": "var isIgnored = cfg . ignore . some ( isPrefixOf ( m . required ) ) if ( ! isIgnored && ( cfg . deps == - 1 || getLevel ( m . required ) <= cfg . deps ) ) { function isPrefixOf ( value ) { return function ( prefix ) { return value . indexOf ( prefix ) === 0 } }", "del_tokens": "if ( cfg . deps == - 1 || getLevel ( m . required ) <= cfg . deps ) {", "commit_type": "add"}
{"commit_tokens": ["change", "the", "default", "number", "of", "connections"], "add_tokens": "var DEFAULT_NUMBER_OF_CONNECTIONS = 30 ;", "del_tokens": "var DEFAULT_NUMBER_OF_CONNECTIONS = 10 ;", "commit_type": "change"}
{"commit_tokens": ["adds", "joshs", "version", "of", "hoist", ".", "js"], "add_tokens": "laxcomma : true , expr : true grunt . registerTask ( \"default\" , [ 'jshint' ] ) ;", "del_tokens": "laxcomma : true", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "on", "all", "tools", "example", "page", "when", "selecting", "ww", "/", "wc", "tool"], "add_tokens": "if ( cornerstoneTools . lineHelper . pointNearLineSegment ( coords , data . handles ) === true )", "del_tokens": "if ( pointNearTool ( data , coords ) === true )", "commit_type": "fix"}
{"commit_tokens": ["use", "describeStacks", "instead", "of", "listStacks", "also", "don", "t", "say", "you", "deleted", "something", "if", "you", "didn", "t"], "add_tokens": "config . deleteStack ( argv , function ( err , data ) { if ( err ) throw err ; console . log ( data ? 'Deleted stack: ' + argv . name : '' ) ;", "del_tokens": "config . deleteStack ( argv , function ( err ) { console . log ( err ? err : 'Deleted stack: ' + argv . name ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "typo", "in", "ember", "-", "cli", "-", "build"], "add_tokens": "includePolyfill : ( EmberAddon . env ( ) === 'test' ) ,", "del_tokens": "includePolyfill : ( EmberApp . env ( ) === 'test' ) ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "_read", "_write", "and", "_content", "setters"], "add_tokens": "var props = [ '_path' , '_name' , '_ext' , '_type' , '_content' , '_read' , '_write' , '_base' ] ; get : function ( ) { return fs . readFileSync ( filePath , 'utf8' ) ; } , set : function ( c ) { fs . writeFileSync ( filePath , c , 'utf8' ) ; } '_read' : { } , '_write' : { get : function ( ) { return fs . createWriteStream ( filePath ) ; }", "del_tokens": "var props = [ '_path' , '_name' , '_ext' , '_type' , '_content' , '_contentS' , '_base' ] ; get : function ( ) { return fs . readFileSync ( filePath , 'utf8' ) ; } '_contentS' : {", "commit_type": "add"}
{"commit_tokens": ["Added", "root", "path", "support", "in", "app", "."], "add_tokens": "function App ( options ) { options = options || { } ; var router = new Router ( ) , mapHandler ; mapHandler = this . appContainer . _match . bind ( this . appContainer ) ; } else { mapHandler = function ( ) { } } if ( options . rootRoute !== undefined ) { router . match ( function ( match ) { match ( options . rootRoute , mapHandler ) ; } ) ; } else { router . match ( mapHandler ) ; this . el = this . appContainer . el ; init : function ( ) { start : function ( container ) {", "del_tokens": "function App ( ) { var router = new Router ( ) ; router . match ( this . appContainer . _match . bind ( this . appContainer ) ) ; this . el = this . appContainer . el ; init : function ( ) { start : function ( container ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "few", "unit", "tests", "for", "Logger"], "add_tokens": "it ( 'should Set AND Get the filters correctly #1' , function ( done ) { \"pkgOne\" : \"INFO\" , \"pkgTwo\" : \"DEBUG\"", "del_tokens": "xit ( 'should Set AND Get the filters correctly #1' , function ( done ) { \"pkgOne\" : MFPLogger . INFO , \"pkgTwo\" : MFPLogger . DEBUG", "commit_type": "fix"}
{"commit_tokens": ["Fix", "broken", "directory", "exist", "check", "."], "add_tokens": "if ( gadget . fsExistsSync ( srcFiles ) ) {", "del_tokens": "var fs = require ( 'fs' ) ; if ( ( fs . existsSync && fs . existsSync ( srcFiles ) ) || fs . accessSync ( srcFiles , fs . R_OK ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "resolver", "test", "assertions", "."], "add_tokens": "test . ifError ( err ) ; test . ifError ( err ) ; test . ifError ( err ) ; test . ifError ( err ) ;", "del_tokens": "test . strictEqual ( err , null , err ) ; test . strictEqual ( err , null , err ) ; test . strictEqual ( err , null , err ) ; test . strictEqual ( err , null , err ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "bug", "with", "empty", "layouts"], "add_tokens": "body : body || [ ]", "del_tokens": "body : body", "commit_type": "fix"}
{"commit_tokens": ["add", "retry", "api", "for", "try", "call", "current", "step", "handler", "once", "again"], "add_tokens": "* @ RuntimeMethod only be called in runtime chainDummy . __callee = item chainDummy . __arguments = xArgs * @ RuntimeMethod only be called in runtime * Run current step once again ** / retry : function ( ) { if ( this . _end || this . _destroy ) return this . __callee . apply ( this . _context , this . __arguments ) } , / ** * @ RuntimeMethod only be called in runtime * @ RuntimeMethod only be called in runtime * Save , Update , Get data in current chain instance", "del_tokens": "* @ RuntimeMethod can be call in runtime * @ RuntimeMethod can be call in runtime * comment * @ RuntimeMethod can be call in runtime * * Save / Update / Get data in current chain instance", "commit_type": "add"}
{"commit_tokens": ["make", "webpack", "work", "with", "http", "-", "server", "from", "root"], "add_tokens": "publicPath : '../build/'", "del_tokens": "publicPath : '/build/'", "commit_type": "make"}
{"commit_tokens": ["Fixing", "issue", "with", "excessive", "filtering", "when", "merging", "terms"], "add_tokens": "module . exports . sentiment . BayesSentimentAnalyser = require ( './sentiment/bayesanalyser' ) ;", "del_tokens": "module . exports . sentiment . BayesSentimentAnalyser = require ( './sentiment/bayes_sentiment_analyser' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "display", "of", "debug", "option"], "add_tokens": ". describe ( 'debug' , 'enable debug mode, adds specification-extensions' )", "del_tokens": ". describe ( 'enable debug mode, adds specification-extensions' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "example", "for", "code", "editor"], "add_tokens": "import SpaceGame from './components/SpaceGame' ; import CodeEditor from './components/CodeEditor' ; CodeEditor ,", "del_tokens": "import SpaceGame from './components/SpaceGame' ;", "commit_type": "add"}
{"commit_tokens": ["add", "global", "availability", "of", "public", "API", "methods"], "add_tokens": "nameSpace : 'errorShelter' , //can be changed to fit app needs availableGlobal : true , // make the nameSpace available either GLOBAL.nameSpace || window.nameSpace } ; // The available methods exposed for API consumption var publicApi = { getStorage : getStorage , emptyStorage : initializeEmptyStorage if ( config . availableGlobal ) { if ( window ) { window [ config . nameSpace ] = publicApi ; } } window . Error [ config . nameSpace ] = publicApi ;", "del_tokens": "nameSpace : 'errorShelter' , //can be changed to fit app needs window . Error [ config . nameSpace ] = { getStorage : getStorage , emptyStorage : initializeEmptyStorage } ; // makes these methods accessible on the Error method", "commit_type": "add"}
{"commit_tokens": ["Add", "__mocks__", "folder", "to", "default", "ignoreDir"], "add_tokens": "it ( 'ignores files in node_modules, __tests__ and __mocks__ by default' , ( ) => { createTempfiles ( null , '__mocks__' ) ;", "del_tokens": "it ( 'ignores files in node_modules and __tests__ by default' , ( ) => {", "commit_type": "add"}
{"commit_tokens": ["Adds", "assertion", "for", "inclusion", "of", "an", "object"], "add_tokens": "'test object()' : function ( ) { var obj = { foo : 'bar' , baz : { baaz : 42 } , qux : 13 } ; obj . should . include . object ( { foo : 'bar' } ) ; obj . should . include . object ( { baz : { baaz : 42 } } ) ; obj . should . include . object ( { foo : 'bar' , qux : 13 } ) ; obj . should . not . include . object ( { foo : 'baz' } ) ; obj . should . not . include . object ( { foo : 'bar' , baz : { baaz : - 42 } } ) ; err ( function ( ) { ( 3 ) . should . include . object ( { foo : 'bar' } ) ; } , \"expected 3 to be a object\" ) ; err ( function ( ) { var obj = { foo : 'bar' } ; obj . should . include . object ( { foo : 'baz' } ) ; } , \"expected { foo: 'bar' } to include { foo: 'baz' }\" ) ; err ( function ( ) { var obj = { foo : 'bar' } ; obj . should . not . include . object ( { foo : 'bar' } ) ; } , \"expected { foo: 'bar' } to not include { foo: 'bar' }\" ) ; } , } ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["allow", "passing", "in", "output", "object", "to", "map"], "add_tokens": "function map ( obj , iter , out ) { var out = out || { } each ( obj , function ( val , path ) { set ( out , path , iter ( val , path ) ) return out", "del_tokens": "function map ( obj , iter ) { var o = { } each ( obj , function ( v , path ) { set ( o , path , iter ( v , path ) ) return o", "commit_type": "allow"}
{"commit_tokens": ["Added", "default", "background", "listener", "and", "a", "warning", "."], "add_tokens": "var backgroundListeners = { } ; var noopListenerId = \"__NOP__\" ; if ( ! backgroundListeners [ noopListenerId ] ) { var nop = function ( ) { } ; exports . registerBackgroundListener ( noopListenerId , nop , nop ) ; } console . debug ( \"Networking has been resumed\" ) ; config . listenerId = config . listenerId || noopListenerId ; if ( listenerId === noopListenerId ) { console . warn ( \"A default background listener has been used where none was specified.\" ) ; }", "del_tokens": "var backgroundListeners = { } ; console . error ( \"Found an error uploading. Will save for later: \" + err ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "bugs", "with", "integration", "execution", "and", "responding"], "add_tokens": "const regex = new RegExp ( '$' + key ) ;", "del_tokens": "const regex = new RegExp ( key ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "inherit", "feed", ".", "js", "-", ">", "dataStream", ".", "js", "-", ">", "dataPoint", ".", "js"], "add_tokens": "var DataStream = require ( './dataStream.js' ) , request = require ( './http.js' ) . request , / ** * @ augments DataStream * / DataPoint . prototype = DataStream . prototype ;", "del_tokens": "var request = require ( './http.js' ) . request ,", "commit_type": "make"}
{"commit_tokens": ["Add", "Average", "of", "Identifier", "metric"], "add_tokens": "totalIdentifiers : 0 , result . identifiers . forEach ( function ( obj ) { result . totalIdentifiers += obj . count ; } ) ; * { Number } averageOfIdentifier , if ( this . selectors . length && this . options . selectors && this . options . simplicity ) { analysis . simplicity = analysis . rules / this . selectors . length ; } if ( this . selectors . length && this . options . averageOfIdentifier ) { analysis . averageOfIdentifier = selectorAnalysis . totalIdentifiers / this . selectors . length ;", "del_tokens": "if ( this . options . rules && this . options . selectors && this . options . simplicity ) { analysis . simplicity = analysis . rules / analysis . selectors ;", "commit_type": "add"}
{"commit_tokens": ["Add", ".", "less", "compiling", "to", "css"], "add_tokens": "less : { development : { options : { compress : true , yuicompress : true , optimization : 2 } , files : { // target.css file: source.less file \"dist/jquery.nstSlider.css\" : \"src/jquery.nstSlider.less\" } } } , styles : { files : [ 'src/*.less' ] , tasks : [ 'less' ] , options : { nospawn : true } } grunt . loadNpmTasks ( 'grunt-contrib-less' ) ; grunt . registerTask ( 'default' , [ 'less' , 'jshint' , 'qunit' , 'clean' , 'concat' , 'uglify' ] ) ; grunt . registerTask ( 'default' , [ 'watch' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'jshint' , 'qunit' , 'clean' , 'concat' , 'uglify' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "watcher", "for", "dev", "folder"], "add_tokens": "gulp . task ( 'dev-js' , [ 'js' , 'sass' ] , function ( ) { gulp . task ( 'default' , [ 'clay' ] ) ; gulp . task ( 'dev' , [ 'dev-js' ] , function ( ) { gulp . watch ( 'src/styles/**/*.scss' , [ 'sass' ] ) ; gulp . watch ( [ 'src/scripts/**/*.js' , 'src/templates/**/*.tpl' ] , [ 'js' ] ) ; gulp . watch ( [ 'dev/**/*.js' ] , [ 'dev-js' ] ) ; } ) ;", "del_tokens": "gulp . task ( 'default' , [ 'clay' ] ) ; gulp . task ( 'dev' , [ 'js' , 'sass' ] , function ( ) { gulp . watch ( 'src/styles/**/*.scss' , [ 'sass' ] ) ; gulp . watch ( [ 'src/scripts/**/*.js' , 'src/templates/**/*.tpl' ] , [ 'js' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "setting", "uplink", "via", "env", "var"], "add_tokens": "baseUrl : ` ${ config . uplink } ` , https . get ( ` ${ config . uplink } ${ name } ${ filename } ` , function ( res ) {", "del_tokens": "baseUrl : 'https://registry.npmjs.org' , https . get ( ` ${ name } ${ filename } ` , function ( res ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "doubledot", "-", "browserify", "to", "the", "hello", "example", ".", "This", "is", "to", "temporarily", "avoid", "a", "bug", "in", "browserify", "..", "more", "information", "can", "be", "found", "at", ":", "https", ":", "//", "github", ".", "com", "/", "substack", "/", "node", "-", "browserify", "/", "issues", "/", "36#issuecomment", "-", "5643901"], "add_tokens": "var browserify = require ( 'doubledot-browserify' )", "del_tokens": "var browserify = require ( 'browserify' )", "commit_type": "add"}
{"commit_tokens": ["Add", "custom", "constructors", "eg", "Person", ".", "fromFullname"], "add_tokens": "constructor ( schema , options = { } ) { const SO = SchemaObjectInstanceFactory ( schema , options ) ; // Add custom constructors _ . each ( options . constructors , ( constructor , key ) => { SO [ key ] = function ( ) { const obj = new SO ( ) ; constructor . apply ( obj , arguments ) ; return obj ; } ; } ) ; return SO ; // Represents an object INSTANCE factory with typed indexes. // Represents an actual instance of an object. // Normalize schema properties to allow for shorthand declarations. // May return actual object instance or Proxy, depending on harmony support.", "del_tokens": "constructor ( schema , options ) { return SchemaObjectInstanceFactory ( schema , options ) ; // Represents an object INSTANCE with typed indexes. if ( ! options ) { options = { } ; } // Normalize schema properties to allow for letious shorthand declarations. // If the proxy is available, we use that, otherwise fallback.", "commit_type": "add"}
{"commit_tokens": ["fix", "double", "commit", "and", "change", "style", "layout"], "add_tokens": "if ( item . getAttribute ( 'class' ) != 'at' ) { item . setAttribute ( 'target' , '_blank' ) ; } let at = ` ${ defaultComment . rid } ${ defaultComment . at } ` ; if ( item . getAttribute ( 'class' ) != 'at' ) { item . setAttribute ( 'target' , '_blank' ) ; }", "del_tokens": "item . setAttribute ( 'target' , '_blank' ) ; let at = ` ${ defaultComment . rid } ${ defaultComment . at } ` ; item . setAttribute ( 'target' , '_blank' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "extra", "data", "parameter", "on", "ask", "and", "tell"], "add_tokens": "emma . listen ( 'my age is' ) . listen ( function ( age , context ) { jack . tell ( 'emma' , 'my age is' ) . tell ( 27 ) ;", "del_tokens": "emma . listen ( 'tell age' ) . run ( function ( age , context ) { jack . tell ( 'emma' , 'tell age' , 27 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "node", "labels", "."], "add_tokens": "var g = this . _digraph . directed ( ) ; // Add edges in both directions \"nodes\" , \"hasNode\" , \"addNode\" , \"addNodes\" , \"nodeLabel\" , \"removeNode\" ,", "del_tokens": "var g = new dig . DiGraph ( ) ; dig_util_forEach ( this . nodes ( ) , function ( v ) { g . addNode ( v ) ; } ) ; \"nodes\" , \"hasNode\" , \"addNode\" , \"addNodes\" , \"removeNode\" ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "adding", "th", "title", "attribute"], "add_tokens": "headerTitle : el . attr ( 'x-data-header-title' ) || el . attr ( 'data-header-title' ) || el . attr ( 'header-title' ) || parsedTitle ( ) , $templateCache . put ( 'ng-table/header.html' , '<tr> <th title=\"{{column.headerTitle}}\" ng-repeat=\"column in $columns\" ng-class=\"{ \\'sortable\\': parse(column.sortable), \\'sort-asc\\': params.sorting()[parse(column.sortable)]==\\'asc\\', \\'sort-desc\\': params.sorting()[parse(column.sortable)]==\\'desc\\' }\" ng-click=\"sortBy(column, $event)\" ng-show=\"column.show(this)\" ng-init=\"template=column.headerTemplateURL(this)\" class=\"header {{column.class}}\"> <div ng-if=\"!template\" ng-show=\"!template\" ng-bind=\"parse(column.title)\"></div> <div ng-if=\"template\" ng-show=\"template\"><div ng-include=\"template\"></div></div> </th> </tr> <tr ng-show=\"show_filter\" class=\"ng-table-filters\"> <th ng-repeat=\"column in $columns\" ng-show=\"column.show(this)\" class=\"filter\"> <div ng-repeat=\"(name, filter) in column.filter\"> <div ng-if=\"column.filterTemplateURL\" ng-show=\"column.filterTemplateURL\"> <div ng-include=\"column.filterTemplateURL\"></div> </div> <div ng-if=\"!column.filterTemplateURL\" ng-show=\"!column.filterTemplateURL\"> <div ng-include=\"\\'ng-table/filters/\\' + filter + \\'.html\\'\"></div> </div> </div> </th> </tr> ' ) ;", "del_tokens": "$templateCache . put ( 'ng-table/header.html' , '<tr> <th ng-repeat=\"column in $columns\" ng-class=\"{ \\'sortable\\': parse(column.sortable), \\'sort-asc\\': params.sorting()[parse(column.sortable)]==\\'asc\\', \\'sort-desc\\': params.sorting()[parse(column.sortable)]==\\'desc\\' }\" ng-click=\"sortBy(column, $event)\" ng-show=\"column.show(this)\" ng-init=\"template=column.headerTemplateURL(this)\" class=\"header {{column.class}}\"> <div ng-if=\"!template\" ng-show=\"!template\" ng-bind=\"parse(column.title)\"></div> <div ng-if=\"template\" ng-show=\"template\"><div ng-include=\"template\"></div></div> </th> </tr> <tr ng-show=\"show_filter\" class=\"ng-table-filters\"> <th ng-repeat=\"column in $columns\" ng-show=\"column.show(this)\" class=\"filter\"> <div ng-repeat=\"(name, filter) in column.filter\"> <div ng-if=\"column.filterTemplateURL\" ng-show=\"column.filterTemplateURL\"> <div ng-include=\"column.filterTemplateURL\"></div> </div> <div ng-if=\"!column.filterTemplateURL\" ng-show=\"!column.filterTemplateURL\"> <div ng-include=\"\\'ng-table/filters/\\' + filter + \\'.html\\'\"></div> </div> </div> </th> </tr>' ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "base", "classes", "for", "task", "and", "command"], "add_tokens": "var self = this ; var cmds = self . getWaitingCommands ( frame ) ; _ . each ( cmds , function ( cmd ) { if ( cmd . callback ) { cmd . callback ( null , frame ) ; delete cmd . callback ; } self . commandQueue . splice ( _ . indexOf ( self . commandQueue , cmd ) , 1 ) ; } ) ; self . checkForNextExecution ( ) ; MyConnection . prototype . getWaitingCommands = function ( frame ) { return _ . filter ( this . commandQueue , function ( cmd ) { return frame && frame . length > 0 && frame [ 0 ] === cmd . command . data [ 0 ] ; } ) ; } ; MyConnection . prototype . executeCommand = function ( command , callback ) { this . commandQueue . push ( { command : command , callback : callback } ) ; this . frameHandler . send ( command . data ) ;", "del_tokens": "var self = this ; MyConnection . prototype . executeCommand = function ( commandData , callback ) { this . frameHandler . send ( 'send' , commandData ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "query", "params", "handling", "to", "accept", "query", "params", "matching"], "add_tokens": "var queryParams = req . query ; if ( Object . keys ( queryParams ) . length === 0 ) {", "del_tokens": "var queryParams = Object . keys ( req . query ) ; if ( queryParams . length === 0 ) {", "commit_type": "change"}
{"commit_tokens": ["make", "it", "work", "better", "for", "firefox"], "add_tokens": "this [ 'emit' ] ( 'connect' , null ) ; this [ 'emit' ] ( 'connect' , null ) ; this [ 'once' ] ( 'connect' , function ( ) { this . postMessage ( m ) ; } ) ;", "del_tokens": "console . warn ( \"Channel not functioning.\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "initialize", "()", "function", "."], "add_tokens": "var ttycolor = require ( '../..' ) ( ) ;", "del_tokens": "var ttycolor = require ( '../..' ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "validation", "for", "the", "new", "schema", "mechanism"], "add_tokens": "throw new Error ( \"timeseries requires an index_prefix\" ) ; format : function ( value ) { // This will generate logstash style timeseries names if ( value && ( ! _ . contains ( [ 'daily' , 'monthly' , 'yearly' ] , value ) ) ) { throw new Error ( \"timeseries must be one of 'daily', 'monthly', 'yearly'\" ) ; } } default : '@timestamp' ,", "del_tokens": "// This will generate logstash style timeseries names if ( opConfig . timeseries && ( ! _ . contains ( [ 'daily' , 'monthly' , 'yearly' ] , opConfig . timeseries ) ) ) { throw \"timeseries must be one of 'daily', 'monthly', 'yearly'\" ; } throw \"timeseries requires an index_prefix\" } // date_field is required if timeseries is specified. If not present we'll use a default. if ( opConfig . timeseries && ! opConfig . date_field ) { opConfig . date_field = '@timestamp' ; format : 'optional_String' default : '' ,", "commit_type": "update"}
{"commit_tokens": ["added", "value", "and", "ctor", "registration", "methods"], "add_tokens": "var msg = 'Factory couldnt be created for:`' + model . key + '`'", "del_tokens": "var msg = 'Factory couldnt be created for:`' + this . cfg . key + '`'", "commit_type": "add"}
{"commit_tokens": ["implemented", "two", "s", "complement", "and", "improved", "toList"], "add_tokens": "if ( n >= 0 ) return n return ( ( max + n ) & ( max - 1 ) ) + 1 if ( n === 0 ) return 0 return ( ( ( max - n ) & ( max - 1 ) ) + 1 ) * - 1", "del_tokens": "if ( n > 0 ) return n return max - n return n + max", "commit_type": "implement"}
{"commit_tokens": ["Update", "how", "mixins", "vs", "functions", "are", "displayed"], "add_tokens": "// @include mixinName($param, $param) { } var str = '@include ' ; handlebars . registerHelper ( 'writeFunction' , function ( func ) { var name = func [ 'context' ] [ 'name' ] ; var params = func [ 'parameter' ] ; var str = '' ; str += name + '(' ; for ( var i in params ) { str += '$' + params [ i ] [ 'name' ] + ', ' ; } str = str . slice ( 0 , - 2 ) ; str += ')' ; return str ; } ) ;", "del_tokens": "// @mixin mixinName($param, $param) { } var str = '@mixin ' ; // Returns content inside the block if any parameters are truthy // {{#ifany param1 param2 etc}}{{/ifany}} handlebars . registerHelper ( 'ifany' , function ( ) { arguments = Array . prototype . slice . call ( arguments ) ; var args = arguments . slice ( 0 , - 1 ) ; var context = arguments . slice ( - 1 ) [ 0 ] ; for ( var item in args ) { if ( args [ item ] . length > 0 ) return context . fn ( this ) ; } } ) ;", "commit_type": "update"}
{"commit_tokens": ["remove", "options", "from", "head", "listing"], "add_tokens": "Hyperlog . prototype . heads = function ( cb ) { valueEncoding : 'utf-8'", "del_tokens": "Hyperlog . prototype . heads = function ( opts , cb ) { if ( ! opts ) opts = { } valueEncoding : 'utf-8' , reverse : opts . reverse", "commit_type": "remove"}
{"commit_tokens": ["Add", "npm", "scripts", "for", "running", "and", "remove", "linter", "as", "precommit", "hook"], "add_tokens": "// var map = require('map-stream'); gulp . parallel ( 'sass' , 'svg' , 'watch' , 'browser-sync' )", "del_tokens": "var map = require ( 'map-stream' ) ; gulp . parallel ( 'sass' , 'svg' , 'browser-sync' , 'watch' )", "commit_type": "add"}
{"commit_tokens": ["Updating", "changes", "from", "@bantic", "so", "prototype", "extensions", "are", "not", "required"], "add_tokens": "/* global Ember, DS */ if ( get ( hasManyLoaded , 'length' ) ) { return new Ember . RSVP . Promise ( function ( resolve , reject ) { reject ( ) ; } ) ; } var fn = Ember . isArray ( snapshot ) ? 'serializeArray' : 'serialize' ; var json = { data : serializer [ fn ] ( snapshot , { includeId : true , type : type . typeKey } ) } ;", "del_tokens": "if ( hasManyLoaded . get ( 'length' ) ) { return new Ember . RSVP . Promise ( function ( resolve , reject ) { reject ( ) ; } ) ; } var pluralType = Ember . String . pluralize ( type . typeKey ) ; var json = { } ; json . data = serializer . serialize ( snapshot , { includeId : true } ) ; if ( ! json . data . hasOwnProperty ( 'type' ) ) { json . data . type = pluralType ; }", "commit_type": "update"}
{"commit_tokens": ["Make", "index", ".", "js", "ES5", "compatible"], "add_tokens": "var path = null ;", "del_tokens": "let path = null ;", "commit_type": "make"}
{"commit_tokens": ["Added", "same", "fix", "for", "remove"], "add_tokens": "} else if ( typeof target === 'number' || typeof target === 'string' ) {", "del_tokens": "} else if ( typeof target === 'number' ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "argv", "at", "spec", "level"], "add_tokens": "const argv = ( task . argv || [ ] ) . concat ( this . config . getArgv ( ) ) . concat ( process . argv . slice ( 2 ) )", "del_tokens": "const argv = [ ... process . argv . slice ( 2 ) , ... this . config . getArgv ( ) , ... ( task . argv || [ ] ) ]", "commit_type": "add"}
{"commit_tokens": ["moved", "forbidden", "checks", "to", "module"], "add_tokens": "'lodash' , 'forbidden' ] , function ( appHandler , assetsHandler , cls , cluster , fs , hapi , path , resolver , safeHandler , streamHandler , tunnelHandler , _ , forbidden ) { if ( forbidden ( request . url . path ) ) { return reply ( hapi . error . forbidden ( ) ) ; // TODO: probably don't need this since we no longer AJAX on client app.navigate // TODO: do we still need to handle POST request for routes?", "del_tokens": "'lodash' ] , function ( appHandler , assetsHandler , cls , cluster , fs , hapi , path , resolver , safeHandler , streamHandler , tunnelHandler , _ ) { // do not serve server code; TODO: move to dir black, white list plugin if ( request . url . path . indexOf ( '/server/' ) !== - 1 || request . url . path . lastIndexOf ( '/server' ) !== - 1 || request . url . path . indexOf ( '/node_modules/' ) !== - 1 || request . url . path . lastIndexOf ( '/node_modules' ) !== - 1 ) { return next ( hapi . error . forbidden ( ) ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "worker", "queueing", "for", "consistent", "slicing", "and", "processing"], "add_tokens": "var Queue = require ( './utils/queue' ) ; var workerQueue = new Queue ; var scheduler = code . scheduler ( nextSlice , start , workerQueue ) ; function enqueue ( msg ) { if ( msg . message === 'ready' ) { workerQueue . enqueue ( msg ) ; } } cluster . workers [ worker . id ] . on ( 'message' , enqueue ) ; sendMessage ( cluster , worker . id , { message : 'ready' , data : null } ) setInterval ( function ( ) { if ( workerQueue . size ( ) ) { scheduler ( ) } } , 1 )", "del_tokens": "var scheduler = code . scheduler ( nextSlice , start ) ; cluster . workers [ worker . id ] . on ( 'message' , scheduler ) ; sendMessage ( cluster , worker . id , { message : 'ready' , data : null } )", "commit_type": "add"}
{"commit_tokens": ["Removed", "prototypes", "(", "except", "for", "regions", "that", "are", "massively", "instanciated", ")"], "add_tokens": "self . targetRatio = self . ratio * ( delta > 0 ? self . p . zoomMultiply : 1 / self . p . zoomMultiply ) ;", "del_tokens": "self . targetRatio = self . ratio * ( delta > 0 ? self . p . zoomMultiply : 1 / self . p . zoomMultiply ) ;", "commit_type": "remove"}
{"commit_tokens": ["removed", "interval", "openess", "control", "fixed", "intersection"], "add_tokens": "let diffFromObjs = ( o1 , o2 , ... units ) => Instant . fromObject ( o1 ) . diff ( Instant . fromObject ( o2 ) , ... units ) , diffObjs = ( o1 , o2 , ... units ) => diffFromObjs ( o1 , o2 , ... units ) . toObject ( ) ; test ( 'Instant#diff defaults to milliseconds' , t => { t . deepEqual ( diffObjs ( { year : 2017 , millisecond : 12 } , { year : 2017 } ) , { milliseconds : 12 } ) ; t . is ( diffFromObjs ( { year : 2017 } , { year : 2017 } ) . milliseconds ( ) , 0 ) ; t . end ( ) ; } ) ; t . deepEqual ( diffObjs ( { year : 2017 } , { year : 2017 } , 'years' ) , { } ) ; t . deepEqual ( diffObjs ( { year : 2015 , month : 3 , day : 14 } , { year : 2009 , month : 3 , day : 16 } , 'years' , 'days' , 'hours' ) , { years : 5 , days : 363 } ) ;", "del_tokens": "let diffObjs = ( o1 , o2 , ... units ) => Instant . fromObject ( o1 ) . diff ( Instant . fromObject ( o2 ) , ... units ) . toObject ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "watch", "task", "to", "grunt"], "add_tokens": "watch : { files : '<config:lint.files>' , tasks : 'lint qunit' } ,", "del_tokens": "Backbone : true ,", "commit_type": "add"}
{"commit_tokens": ["update", "tests", "for", "no", "-", "callback", "-", "literal"], "add_tokens": "'callback(undefined, data)' , 'cb(undefined, \"super\")' ,", "del_tokens": "{ code : 'callback(undefined, \"snork\")' , errors : [ { message : 'Expected \"null\" instead of \"undefined\" in error position of callback.' } ] } , { code : 'cb(undefined, \"snork\")' , errors : [ { message : 'Expected \"null\" instead of \"undefined\" in error position of callback.' } ] } ,", "commit_type": "update"}
{"commit_tokens": ["added", "tables", "-", "of", "-", "contents", "to", "README", ".", "md", "s"], "add_tokens": "const match = / (\\n<!-- TOC -->\\n)(?:[^\\n]|\\n(?!<!--))*(\\n<!-- \\/TOC -->\\n) / . exec ( markdown ) ; if ( match ) { return ` ${ markdown . substring ( 0 , match . index ) } ${ match [ 1 ] } ${ toc } ${ match [ 2 ] } ${ markdown . substring ( match . index + match [ 0 ] . length ) } ` ; } if ( toc ) { return markdown ; toc = toc . join ( '' ) ;", "del_tokens": "const match = / (\\n<!-- TOC -->\\n).*?(\\n<!-- \\/TOC -->\\n) / . exec ( markdown ) ; if ( ! match ) { return ` ${ markdown . substring ( 0 , match . index ) } ${ match [ 1 ] } ${ toc } ${ match [ 2 ] } ${ markdown . substring ( match . index + match [ 0 ] . length ) } ` ; toc = toc . join ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "cwd", "option", "for", "selenium", "spawn", "call"], "add_tokens": "var spawnOptions = options [ 'cwd' ] ? { cwd : options [ 'cwd' ] } : null ; seleniumServerProcess = spawn ( 'java' , selOptions , spawnOptions ) ; maxSession : false , cwd : null", "del_tokens": "seleniumServerProcess = spawn ( 'java' , selOptions ) ; maxSession : false", "commit_type": "add"}
{"commit_tokens": ["Updated", "rustlib", ".", "js", "so", "that", "cxs_init", "()", "Take", "4", "String", "Arguments"], "add_tokens": "'cxs_init' : [ 'int' , [ 'string' , 'string' , 'string' , 'string' ] ]", "del_tokens": "'cxs_init' : [ 'int' , [ ] ]", "commit_type": "update"}
{"commit_tokens": ["Moving", "demo", "app", "to", "sidemenu"], "add_tokens": "// 'starter.controllers' is found in controllers.js angular . module ( 'starter' , [ 'ionic' , 'starter.controllers' ] ) // org.apache.cordova.statusbar required . config ( function ( $stateProvider , $urlRouterProvider ) { $stateProvider . state ( 'app' , { url : \"/app\" , abstract : true , templateUrl : \"templates/menu.html\" , controller : 'AppCtrl' } ) . state ( 'app.plugin' , { url : \"/plugin/:pluginSlug\" , views : { 'menuContent' : { templateUrl : function ( stateParams ) { return \"templates/plugins/\" + stateParams . pluginSlug + \".html\" ; } } } } ) ; // if none of the above states are matched, use this as the fallback $urlRouterProvider . otherwise ( '/app' ) ; } ) ;", "del_tokens": "angular . module ( 'starter' , [ 'ionic' ] )", "commit_type": "move"}
{"commit_tokens": ["fixed", "lost", "final", "byte", "on", "file", "downloads"], "add_tokens": "hexReadHelper : \"function __hexread() while true do c = file.read(1) if c == nil then print('') break end uart.write(0, string.format('%02X', string.byte(c))) end end\"", "del_tokens": "hexReadHelper : \"function __hexread() while true do c = file.read(1) if c == nil then break end uart.write(0, string.format('%02X', string.byte(c))) end end\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "req", ".", "params", "instead", "of", "req", ".", "param", "()"], "add_tokens": "req . params . service , req . params . subservice", "del_tokens": "req . param ( 'service' ) , req . param ( 'subservice' )", "commit_type": "use"}
{"commit_tokens": ["Make", "the", "configuration", "less", "API", "specific"], "add_tokens": "base : process . env . BASE_URL || 'http://localhost'", "del_tokens": "base : process . env . BASE_URL || ( process . env . NODE_ENV === 'production' ? 'https://api.testlio.com' : 'http://localhost' )", "commit_type": "make"}
{"commit_tokens": ["changed", "the", "text", "and", "rewrote", "some", "examples", "for", "the", "chained"], "add_tokens": "$button1 . next ( \".result\" ) . empty ( ) . append ( $dom . create ( 'div.panel.red' ) ) ;", "del_tokens": "var result = $button1 . next ( \".result\" ) . empty ( ) ; $dom . create ( 'div.panel.red' ) . appendTo ( result ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "how", "rounded", "corners", "works"], "add_tokens": "cornerRadius : 3 , rounded : false , if ( params . rounded === true ) { ctx . lineCap = 'round' ; ctx . lineJoin = 'round' ; } if ( args . cornerRadius > 0 || params . rounded === true ) { r = params . cornerRadius || params . strokeWidth ;", "del_tokens": "cornerRadius : 0 , ctx . lineCap = params . strokeCap ; ctx . lineJoin = params . strokeJoin ; if ( params . cornerRadius > 0 ) { r = params . cornerRadius ;", "commit_type": "change"}
{"commit_tokens": ["Add", "--", "debugPlugin", "argument", "and", "parsing"], "add_tokens": "const debugPlugin = parsedArgs [ \"debugPlugin\" ] ; const pluginManager = new PluginManager_1 . PluginManager ( screen , debugPlugin ) ; constructor ( screen , debugPlugin ) { this . _debugPluginPath = debugPlugin ; if ( this . _debugPluginPath ) { this . _plugins . push ( new Plugin_1 . Plugin ( this . _debugPluginPath , true ) ) ; } constructor ( pluginRootDirectory , debugMode ) { if ( this . _oniPluginMetadata . debugging || debugMode ) {", "del_tokens": "const pluginManager = new PluginManager_1 . PluginManager ( screen ) ; constructor ( screen ) { constructor ( pluginRootDirectory ) { if ( this . _oniPluginMetadata . debugging ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "memory", "leak", "/", "race", "condition", "on", "credentials"], "add_tokens": "var gettingCredentials = false ; function initAwsCredentials ( ) { if ( gettingCredentials ) { return ; } else { acquireAwsCredentials ( ) ; } } gettingCredentials = true ; initAwsCredentials ( ) ;", "del_tokens": "acquireAwsCredentials ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "configuring", "the", "sort", "helper"], "add_tokens": "/ ** * The sortable helper to use in galleries where gallery items * can be sorted . * / 'sortableHelper' : 'cloneGalleryItem' , 'helper' : this . _options . sortableHelper", "del_tokens": "'helper' : 'cloneGalleryItem'", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "modification", "of", "object", "property", "of", "an", "inner", "object", "in", "client"], "add_tokens": "var subj = local . inputObject !== undefined ? local . objectApiCache [ local . inputObject ] : local var pv = subj [ property . name ] //.cachedProperties[ps.name] subj . obj [ local . inputProperty ] = setObj ; subj [ property . name ] = setObj subj . emit ( edit , 'set' , property . name , setObj ) var subj = local . inputObject !== undefined ? local . objectApiCache [ local . inputObject ] : local var ps = subj . typeSchema . propertiesByCode [ local . inputProperty ] ; subj [ ps . name ] = undefined subj . obj [ local . inputProperty ] = undefined", "del_tokens": "var pv = local [ property . name ] //.cachedProperties[ps.name] local . obj [ local . inputProperty ] = setObj ; local [ property . name ] = setObj local . emit ( edit , 'set' , property . name , setObj ) var ps = local . typeSchema . propertiesByCode [ local . inputProperty ] ; local [ ps . name ] = undefined local . obj [ local . inputProperty ] = undefined", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "sending", "data", "via", "GET"], "add_tokens": "get : function ( url , data , cb ) { if ( cb === undefined && typeof data === 'function' ) { cb = data ; data = null ; } socket . get ( url , data , function ( ) { data = null ; data = null ; data = null ;", "del_tokens": "get : function ( url , cb ) { socket . get ( url , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "socket", "error", "handler", "to", "handle", "ECONNREFUSED", ".", "In", "event", "of", "ECONNREFUSED", "the", "port", "is", "available"], "add_tokens": "var connectionRefused = false ; if ( exception . code !== \"ECONNREFUSED\" ) { error = exception } else connectionRefused = true ; status = 'closed' socket . on ( 'close' , function ( exception ) { if ( exception && ! connectionRefused ) error = exception ; else error = null ;", "del_tokens": "error = exception status = 'closed' socket . on ( 'close' , function ( ) {", "commit_type": "change"}
{"commit_tokens": ["fix", "fuzzy", "+", "kill", "ZeroClipboard"], "add_tokens": "'app/**/*.styl' ] )", "del_tokens": "'app/**/*.styl' ] )", "commit_type": "fix"}
{"commit_tokens": ["Changing", "version", "tracking", ";", "some", "breaking", "API", "changes", "are", "incoming", ":", "D"], "add_tokens": "version : \"2.0.0\" ,", "del_tokens": "version : \"1.0.0\" ,", "commit_type": "change"}
{"commit_tokens": ["add", "EAI_AGAIN", "to", "the", "list", "of", "retriable", "network", "errors"], "add_tokens": "var RETRIABLE_ERRORS = [ 'ECONNRESET' , 'ENOTFOUND' , 'ESOCKETTIMEDOUT' , 'ETIMEDOUT' , 'ECONNREFUSED' , 'EHOSTUNREACH' , 'EPIPE' , 'EAI_AGAIN' ] ;", "del_tokens": "var RETRIABLE_ERRORS = [ 'ECONNRESET' , 'ENOTFOUND' , 'ESOCKETTIMEDOUT' , 'ETIMEDOUT' , 'ECONNREFUSED' , 'EHOSTUNREACH' , 'EPIPE' ] ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "setting", "translate_mode", "on", "resources"], "add_tokens": "resource . slug = resource . slug . toLowerCase ( ) ; switch ( resource . slug ) { case 'obs' : case 'ulb' : resource . status . translate_mode = 'all' ; break ; default : resource . status . translate_mode = 'gl' ; }", "del_tokens": "resource . status . translate_mode = resource . slug . toLowerCase ( ) === 'obs' ? 'all' : 'gl' ;", "commit_type": "fix"}
{"commit_tokens": ["improve", "event", "loop", "OSC", "handling"], "add_tokens": "var OSC = require ( 'node-osc' ) ; // OSC server. https://github.com/TheAlphaNerd/node-osc // Convert OSC messages to objects and emit them similar to sockets. global . osc = new OSC . Server ( 3001 ) ; osc . on ( 'message' , function ( msg , rinfo ) { osc . emit ( action , message ) ; // Set up models. var ServerState = require ( './model/serverState.js' ) . ServerState ; var serverState = new ServerState ( ) ; // Set up view routing. app . use ( '/static' , express . static ( __dirname + '/view' ) ) ; app . get ( '/' , function ( req , res ) { res . sendfile ( __dirname + '/view/index.html' ) ; } ) ; // Update clients with server state when they ask for it. // paths broken? // serverstate for server, appstate for app", "del_tokens": "var osc = require ( 'node-osc' ) ; // OSC server. https://github.com/TheAlphaNerd/node-osc // Set up models. var ServerState = require ( './model/serverState.js' ) . ServerState ; var serverState = new ServerState ( ) ; // Set up view routing. app . use ( '/static' , express . static ( __dirname + '/view' ) ) ; app . get ( '/' , function ( req , res ) { res . sendfile ( __dirname + '/view/index.html' ) ; } ) ; // Set up OSC routing. var oscServer = new osc . Server ( 3001 ) ; oscServer . on ( 'message' , function ( msg , rinfo ) { // Forward messages to the UI. serverState . onOSC ( action , message ) ; // Update clients by sending the whole state every frame. // TODO: This sort of sucks. It would be nice to do some fancier syncing. // Pull model -- client requests frame, requests again after it gets it", "commit_type": "improve"}
{"commit_tokens": ["removed", "unused", "request", "module", "from", "several", "models", ".", "added", "sync", "module", "to", "subseason", "model"], "add_tokens": "_ . extend ( config , conf )", "del_tokens": "var request = require ( 'request' ) config = conf", "commit_type": "remove"}
{"commit_tokens": ["fixes", "issue", "for", "when", "base", "json", "is", "on", "root", "level"], "add_tokens": "var folderPath = getFolder ( path ) || \".\" ;", "del_tokens": "var folderPath = getFolder ( path ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implementing", "custom", "styles", "for", "ReactAutocomplete", "[", "skip", "ci", "]"], "add_tokens": "placeholder : PropTypes . string , styles : PropTypes . object ,", "del_tokens": "placeholder : PropTypes . string", "commit_type": "implement"}
{"commit_tokens": ["allow", "parse", "to", "fallback", "to", "parsing", "a", "regular", "string", "if", "callback", "is", "not", "defined"], "add_tokens": "if ( loader && callback ) { if ( ! cache [ templates ] ) { loader ( template , function ( err , loaded ) { if ( loaded ) { cache [ template ] = loaded ; } callback ( err , parse ( template , obj , bind ) ) ; } ) ; } else { callback ( null , parse ( cache [ template ] , obj , bind ) ) ; } return parse ( template , obj , bind ) ;", "del_tokens": "if ( loader && ! cache [ templates ] ) { loader ( template , function ( err , loaded ) { if ( loaded ) { cache [ template ] = loaded ; } callback ( err , parse ( template , obj , bind ) ) ; } ) ; } else if ( loader ) { callback ( null , parse ( cache [ template ] , obj , bind ) ) ; } else { return parse ( template , obj , bind ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "loading", "for", "wechat", "-", "example"], "add_tokens": "header . className = \"header slide reverse in\" ; footer . className = \"footer slide reverse in\" ;", "del_tokens": "header . className = \"header slide back in\" ; footer . className = \"footer slide back in\" ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "paths", "to", "be", "based", "on", "the", "running", "environment", "for", "the", "cache", "file", "tests", "."], "add_tokens": "var expandExpected = function ( file ) { return file . replace ( / \\{\\$\\} / g , middlewareSrc ) ; } var cacheFileExpected = JSON . parse ( expandExpected ( fs . readFileSync ( expectedFile , 'utf8' ) ) ) ;", "del_tokens": "var cacheFileExpected = JSON . parse ( fs . readFileSync ( expectedFile , 'utf8' ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "batchSize", "to", "setup", "example"], "add_tokens": "steamid : 'the steamid of the account you got the user token from' , batchSize : 10 // only create 10 listings at a time", "del_tokens": "steamid : 'the steamid of the account you got the user token from'", "commit_type": "add"}
{"commit_tokens": ["Added", "globalAutoUpdate", "for", "pause", "/", "resume", "all", "spine", "animations", "at", "once"], "add_tokens": "* phaser - spine - version 3.0 .8 * Build at 04 - 07 - 2017 if ( Spine . globalAutoUpdate ) { this . lastTime = this . lastTime || Date . now ( ) ; var timeDelta = ( Date . now ( ) - this . lastTime ) * 0.001 ; this . lastTime = Date . now ( ) ; this . update ( timeDelta ) ; } else { this . lastTime = 0 ; } Spine . globalAutoUpdate = true ;", "del_tokens": "* phaser - spine - version 3.0 .7 * Build at 07 - 06 - 2017 this . lastTime = this . lastTime || Date . now ( ) ; var timeDelta = ( Date . now ( ) - this . lastTime ) * 0.001 ; this . lastTime = Date . now ( ) ; this . update ( timeDelta ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "JSLint", "to", "dev", "dependencies", ".", "Corrected", "errors", "JSLint", "found", "."], "add_tokens": "'use strict' ; var defaultEscapeCharsRegex = / [\\-|\\\\{}()\\[\\]\\^$+*?.] / g ;", "del_tokens": "'use strict' var defaultEscapeCharsRegex = / [-|\\\\{}()[\\]^$+*?.] / g ;", "commit_type": "add"}
{"commit_tokens": ["Add", "graph", ".", "isConnected", "()"], "add_tokens": "describe ( \"dig.Graph\" , function ( ) { describe ( \"isConnected()\" , function ( ) { it ( \"returns false for an empty graph\" , function ( ) { assert . isFalse ( new dig . Graph ( ) . isConnected ( ) ) ; } ) ; it ( \"returns true for node1\" , function ( ) { assert . isTrue ( graphs . node1 . isConnected ( ) ) ; } ) ; it ( \"returns false for node2\" , function ( ) { assert . isFalse ( graphs . node2 . isConnected ( ) ) ; } ) ; it ( \"treats the graph as undirected\" , function ( ) { assert . isTrue ( graphs . edge1 . isConnected ( ) ) ; } ) ; it ( \"returns true for scc3\" , function ( ) { assert . isTrue ( graphs . scc3 . isConnected ( ) ) ; } ) ; } ) ;", "del_tokens": "describe ( \"new dig.Graph\" , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "bug", "fixes", "for", "social", "auth", "and", "model", "processing"], "add_tokens": "angular . module ( 'pancakesAngular' ) . factory ( 'tplHelper' , function ( $q , $injector , config , pageSettings , eventBus ) { var locals = { currentScope : scope , defaults : scope . defaults } ;", "del_tokens": "angular . module ( 'pancakesAngular' ) . factory ( 'tplHelper' , function ( $q , $injector , pageSettings , eventBus ) { var locals = { currentScope : scope , defaults : scope . defaults } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "events", "on", "constructor", "too", "just", "pass", "options", ".", "events", "with", "key", "as", "event", "name", "and", "a", "function", "used", "as", "a", "callback", "for", "the", "value", "."], "add_tokens": "//Bind to user supplied events if ( this . emitEvents && options . events ) { bindEventMap ( options . events , this ) ; } * @ param { { skipFetch : boolean } } [ options ] / ** * Bind to user supplied event map , where key is event name * @ param { { } } eventMap * @ param { EventEmitter } eventEmitter * / function bindEventMap ( eventMap , eventEmitter ) { var eventNames = Object . keys ( eventMap ) ; eventNames . map ( function ( eventName ) { eventEmitter . on ( eventName , eventMap [ eventName ] ) ; } ) ; }", "del_tokens": "* @ param { { skipFetch : boolean } } options //Bind to user supplied events if ( options . events ) { var eventNames = Object . keys ( options . events ) ; eventNames . map ( function ( eventName ) { cache . on ( eventName , options . events [ eventName ] ) ; } ) ; }", "commit_type": "add"}
{"commit_tokens": ["added", "remove", "function", "to", "EventCache"], "add_tokens": "/ *! vissense - v0.0.1 - 2014-06-12", "del_tokens": "/ *! vissense - v0.0.1 - 2014-06-11", "commit_type": "add"}
{"commit_tokens": ["fix", "new", "toggle", "method", "to", "work", "against", "current", "master"], "add_tokens": "toggle : function ( el , mode ) { dom . hide ( el , mode ) ; dom . show ( el , mode ) ;", "del_tokens": "toggle : function ( el ) { storeDisplayStyle ( el ) ; hide ( el ) ; show ( el ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "and", "use", "root", "commands"], "add_tokens": "function findRootCommands ( config , populate ) { if ( ! config || ! config . commands ) { return [ ] } let commands if ( config . final ) { commands = config . commands . filter ( ( c ) => c . root ) } else { let nonRootCommands = config . commands . reduce ( ( results , command ) => { command . commands && command . commands . forEach ( ( id ) => { nonRootCommands [ id ] = true } ) return results } , { } ) commands = commands . filter ( ( command ) => ! nonRootCommands [ command . id ] ) } if ( populate ) { commands = commands . map ( ( c ) => populateCommand ( config , c ) ) } return commands } findOptionById , findCommandByFullName , findDefaultCommand , findRootCommands , populateCommand , updateCommandById , updateOptionById , optionsToObject , compareNames , getCommandFromEvent , assignDefaults , createCommand , createOption ,", "del_tokens": "findOptionById , findCommandByFullName , findDefaultCommand , populateCommand , updateCommandById , updateOptionById , optionsToObject , compareNames , getCommandFromEvent , assignDefaults , createCommand , createOption ,", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "browser", "testing"], "add_tokens": "gulp . task ( 'test' , [ 'test:browser' , 'test:node' ] ) ; gulp . task ( 'test:browser' , ( ) => { if ( process . platform == 'win32' ) process . env . FIREFOX_BIN = 'firefox.exe' ; return _exec ( 'node_modules/.bin/karma' , [ 'start' , '--single-run' ] ) ; } ) ; gulp . task ( 'test:node' , ( ) => _exec ( 'node_modules/.bin/nyc' , [ normalize ( 'node_modules/.bin/mocha' ) ] ) ) ;", "del_tokens": "gulp . task ( 'test' , ( ) => _exec ( 'node_modules/.bin/nyc' , [ normalize ( 'node_modules/.bin/mocha' ) ] ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "AMD", "loaders"], "add_tokens": "pass_amd : { options : { run : false } , src : [ 'test/pass-amd.html' ] } , } , fail_amd : { options : { run : false } , src : [ 'test/fail-amd.html' ] grunt . registerTask ( 'pass' , [ 'mochaTest:pass' , 'mocha:pass' , 'mocha:pass_amd' ] ) ; grunt . registerTask ( 'fail' , [ 'mochaTest:fail' , 'mocha:fail' , 'mocha:fail_amd' ] ) ;", "del_tokens": "grunt . registerTask ( 'pass' , [ 'mochaTest:pass' , 'mocha:pass' ] ) ; grunt . registerTask ( 'fail' , [ 'mochaTest:fail' , 'mocha:fail' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "child_process", ".", "spawn", "over", "execFile", "to", "avoid", "buffer", "overflow"], "add_tokens": "var phantomProc = childProcess . spawn ( phantom . path , phantomOpts ) ;", "del_tokens": "var phantomProc = childProcess . execFile ( phantom . path , phantomOpts ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "non", "-", "serializable", "exception", "in", "prepare"], "add_tokens": "var cb1 = toSysErrorF ( msg , ERROR_CODES . prepareFailure , 'prepareFailed' , cb0 ) ; var cb2 = function ( err , data ) { cb1 ( err ) ; try { snapshot = JSON . stringify ( data ) ; } catch ( ex ) { err = ex ; } cb1 ( err , snapshot ) ;", "del_tokens": "var cb1 = function ( err , data ) { cb0 ( err ) ; snapshot = JSON . stringify ( data ) ; cb0 ( err , snapshot ) ; var cb2 = toSysErrorF ( msg , ERROR_CODES . prepareFailure , 'prepareFailed' , cb1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "the", "example", "to", "use", "the", "configure", "(", "development", "...", ")"], "add_tokens": "server . configure ( 'development' , function ( ) { server . use ( server . logger ( ) ) ; } ) ; server . enable ( 'development' ) ; var template_engine = { compile : function ( template_url , args ) { var template_html ; $ . ajax ( { type : \"GET\" , url : template_url , async : false , success : function ( text ) { template_html = text ; } } ) ; return require ( \"ejs\" ) . render ( template_html , { locals : args } ) ; } } ;", "del_tokens": "var template_engine = { compile : function ( template_url , args ) { var template_html ; $ . ajax ( { type : \"GET\" , url : template_url , async : false , success : function ( text ) { template_html = text ; } } ) ; return require ( \"ejs\" ) . render ( template_html , { locals : args } ) ; } } ; server . use ( server . logger ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "jsdoc", "for", "public", "logOut", "method"], "add_tokens": "exports . revokeOauthToken = function ( accessToken , baseUrl , callback ) { / ** * Revoke the given DocuSign OAuth2 ` ` . * * @ memberOf Auth * @ public * @ alias logOut * @ function * @ param { function } callback - Returned in the form of function ( error , response ) . * @ returns { Promise } - A thenable bluebird Promise ; if callback is given it is called before the promise is resolved * / return function logOut ( callback ) {", "del_tokens": "exports . revokeOauthToken = function ( accessToken , baseUrl ) { return function ( callback ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "window", "in", "the", "document", "property"], "add_tokens": "complement : window . document . title , return window . document . getElementsByTagName ( place ) [ 0 ] * Undo the window . document title for previous state window . document . title = state . before * Change window . document title window . document . title = ` ${ val . inner } ${ val . separator || opt . separator } ${ val . complement || opt . complement } ` let el = window . document . getElementById ( obj . id ) || window . document . createElement ( tag )", "del_tokens": "complement : document . title , return document . getElementsByTagName ( place ) [ 0 ] * Undo the document title for previous state document . title = state . before * Change document title document . title = ` ${ val . inner } ${ val . separator || opt . separator } ${ val . complement || opt . complement } ` let el = document . getElementById ( obj . id ) || document . createElement ( tag )", "commit_type": "add"}
{"commit_tokens": ["Move", "certain", "mobile", "only", "hacks", "to", "mobilehacks", "js"], "add_tokens": "netPlayer . addEventListener ( 'busy' , Player . prototype . handleBusyMsg . bind ( this ) ) ; this . name = name ; Player . prototype . handleBusyMsg = function ( msg ) { // The busy message is send by PlayerNameHandler when the user is editing their name. // msg.busy = true means they are entering their name. false = they are not. // This can be used to make the player invicible for a moment remove then from play etc. // Of course that can be used to cheat by editing the name just before getting hit // So it's up the game to decide what if anything to do. } ; name : this . name this . name = msg . name . replace ( / [<>] / g , '' ) ; ctx . fillText ( this . name , this . position [ 0 ] + 10 , this . position [ 1 ] - 8 ) ;", "del_tokens": "this . playerName = name ; name : this . playerName this . playerName = msg . name . replace ( / [<>] / g , '' ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "isEmpty", "()", "bumped", "version", "number", "."], "add_tokens": "var jshint = require ( 'gulp-jshint' ) , mocha = require ( 'gulp-mocha' ) , istanbul = require ( 'gulp-istanbul' ) , gulp = require ( 'gulp' ) , runSequence = require ( 'run-sequence' ) ; gulp . task ( 'coverage' , function ( cb ) { gulp . src ( [ 'lib/**/*.js' , 'index.js' ] ) . pipe ( istanbul ( ) ) // Covering files . pipe ( istanbul . hookRequire ( ) ) // Force `require` to return covered files . on ( 'finish' , function ( ) { gulp . src ( [ 'test/*.js' ] ) . pipe ( mocha ( ) ) . pipe ( istanbul . writeReports ( { reporters : [ 'lcov' , 'text-summary' ] } ) ) // Creating the reports after tests runned . on ( 'end' , cb ) ; } ) ; } ) ; gulp . task ( 'test' , function ( cb ) { runSequence ( 'lint' , 'mocha' , cb ) ; } ) ;", "del_tokens": "var jshint = require ( 'gulp-jshint' ) ; var mocha = require ( 'gulp-mocha' ) ; var gulp = require ( 'gulp' ) ; gulp . task ( 'test' , [ 'mocha' , 'lint' ] , function ( ) { } ) ;", "commit_type": "add"}
{"commit_tokens": ["allowing", "to", "override", "browserify", "instance", "and", "bundle", "opts", "in", "config"], "add_tokens": "var bundle = config . browserify ? config . browserify ( ) : browserify ( ) ; var bundleOpts = config . bundleOpts || { insertGlobals : true , debug : ! ! argv . server } bundle . bundle ( bundleOpts , function ( err , src ) {", "del_tokens": "var bundle = browserify ( ) ; bundle . bundle ( { insertGlobals : true } , function ( err , src ) {", "commit_type": "allow"}
{"commit_tokens": ["Make", ":", "read", "subscribe", "to", "the", "stream", "in", "question", "."], "add_tokens": "var self = this ; // TODO unsubscribe later: self . vox . subscribe ( stream , { updateDatabase : false } ) . then ( function ( subscription ) { self . showStreamPage ( voxurl . toCanonicalUrl ( stream ) ) ; } )", "del_tokens": "this . showStreamPage ( voxurl . toCanonicalUrl ( stream ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "examples", "to", "the", "new", "syntax"], "add_tokens": "key ( require ( './lowlevel-keywords' ) ) ;", "del_tokens": "var _ = require ( 'underscore' ) ; _ . forEach ( require ( './lowlevel-keywords' ) , function ( fn , name ) { key ( name , fn ) ; } ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "files", "to", "package", ".", "json", "."], "add_tokens": "var emoji = require ( '../lib/emoji' ) ;", "del_tokens": "var emoji = require ( '../index' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "--", "encoding", "option", "for", "testRunner"], "add_tokens": ". string ( 'encoding' ) . alias ( 'e' , 'encoding' ) . default ( 'encoding' , 'utf8' ) . describe ( 'encoding' , 'encoding for input/output files' ) var srcStr = fs . readFileSync ( path . resolve ( file ) , options . encoding ) ;", "del_tokens": "var srcStr = fs . readFileSync ( path . resolve ( file ) , 'utf8' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "and", "cleaned", "up", "caching", "implementation", "code", "."], "add_tokens": "console . log ( \"Could not read cache[\" + key + \"]\" ) ; console . log ( err ) ; console . log ( \"Could not write cache[\" + key + \"]\" ) ; console . log ( err ) ; cb . call ( this , false ) ; console . log ( \"Could not remove cache[\" + key + \"]\" ) ; console . log ( err ) ; cb . call ( this , false ) ;", "del_tokens": "cb . call ( this , err ) ; cb . call ( this , err ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "insight", "-", "api", "interface", "for", "lookupTransaction"], "add_tokens": "type BcParsedAddress = { hash : string ; network : string ; type : string ; } ; type BcNotification = { address : BcParsedAddress ; rejected : boolean ; } & BcTransactionInfo ; // requires insight-api, see: // https://github.com/bitpay/bitcore-node/issues/423 return lookupInsightTransaction ( this . socket , hash ) . then ( ( r ) => this . insightToInfo ( r ) ) ; addresses : [ bitcoreToAddress ( r . address ) ] , // TODO: network function bitcoreToAddress ( r : BcParsedAddress ) : string { // TODO: network let script = new Buffer ( r . hash , 'hex' ) ; return baddress . fromOutputScript ( script ) ; }", "del_tokens": "type BcNotification = { address : string ; rejected : boolean ; } & BcTransactionInfo ; return lookupInsightTransaction ( this . socket , hash ) . then ( ( r ) => this . insightToInfo ( r ) ) ; // return lookupTransaction(this.socket, hash).then((r) => this.toInfo(r)); addresses : [ r . address ] , // TODO: pull the address out of BcHistory or BcNotification", "commit_type": "fix"}
{"commit_tokens": ["Allow", "passing", "queue", "and", "reconnect", "parameters"], "add_tokens": "// @param opts extrac configurations: // max_queue - max number of items in queue, defaults to 2000 // new items will be discarded // max_recon_retries - max number of reconnection attempts // defaults to 120 // recon_interval_ms - interval in milliseconds between // reconnection attempts. Defaults to 1000. // function VarnishQueue ( host , port , secret , opts ) { opts = opts || { } ; if ( ! opts . hasOwnProperty ( 'max_queue' ) ) opts . max_queue = 2000 ; if ( ! opts . hasOwnProperty ( 'max_recon_retries' ) ) opts . max_recon_retries = 120 ; if ( ! opts . hasOwnProperty ( 'recon_interval_ms' ) ) opts . recon_interval_ms = 1000 ; var MAX_QUEUE = opts . max_queue ; var MAX_RECONNECT_TRIES = opts . max_recon_retries ; var RECONNECT_INTERVAL = opts . recon_interval_ms ; } , RECONNECT_INTERVAL ) ;", "del_tokens": "function VarnishQueue ( host , port , secret ) { var MAX_QUEUE = 2000 ; var MAX_RECONNECT_TRIES = 120 ; // 2 minutes } , 1000 ) ;", "commit_type": "allow"}
{"commit_tokens": ["Improve", "module", "detection", "fix", "ajax", "deps"], "add_tokens": "//'jquery.js',", "del_tokens": "'jquery.js' ,", "commit_type": "improve"}
{"commit_tokens": ["add", "supports", "for", "function", "in", "buildTypes"], "add_tokens": "buildType : 'default' , if ( _ . isFunction ( self . options . buildType ) ) { releasePath = self . options . buildType . call ( self . options ) ; } else { // buildTypes switch ( self . options . buildType ) { case 'timestamped' : releasePath = self . options . appName + ' - ' + Math . round ( Date . now ( ) / 1000 ) . toString ( ) ; break ; case 'versioned' : releasePath = self . options . appName + ' - v' + self . options . appVersion ; break ; default : releasePath = self . options . appName ; }", "del_tokens": "buildType : 'default' , // timestamped // buildTypes switch ( self . options . buildType ) { case 'timestamped' : releasePath = self . options . appName + ' - ' + Math . round ( Date . now ( ) / 1000 ) . toString ( ) ; break ; case 'versioned' : releasePath = self . options . appName + ' - v' + self . options . appVersion ; break ; case 'default' : releasePath = self . options . appName ; break ; default : releasePath = self . options . appName ;", "commit_type": "add"}
{"commit_tokens": ["Make", "index", ".", "js", "executable"], "add_tokens": "#!/usr/bin/env node var path = require ( 'path' ) ; var ConfigGeneraror = require ( path . join ( __dirname , '../lib/config-generator' ) ) ; var pkg = require ( path . join ( __dirname , '../package.json' ) ) ;", "del_tokens": "var ConfigGeneraror = require ( '../lib/config-generator' ) ; var pkg = require ( '../package.json' ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixing", "tests", "use", "name", "from", "package", ".", "json"], "add_tokens": ", info = require ( './package.json' ) \"version\" : info . version , \"name\" : info . name , \"version\" : info . version , \"name\" : info . name ,", "del_tokens": "\"version\" : \"0.0.2\" , \"version\" : \"0.0.2\" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "drop", "targets", "to", "Drag", "&", "Drop", "example"], "add_tokens": "import { DragSource , DragDropContext , DropTarget } from 'react-dnd' ; /* drag sources */ function collectSource ( connect ) { DraggableEventWrapper = DragSource ( 'event' , eventSource , collectSource ) ( DraggableEventWrapper ) ; /* drop targets */ const dropTarget = { drop ( props , monitor ) { const event = monitor . getItem ( ) ; alert ( ` ${ event . title } ` ) ; } } ; function collectTarget ( connect , monitor ) { return { connectDropTarget : connect . dropTarget ( ) } ; } class DroppableBackgroundWrapper extends React . Component { render ( ) { const { connectDropTarget , children } = this . props ; const BackgroundWrapper = BigCalendar . components . backgroundWrapper ; return ( < BackgroundWrapper children = { children } ref = { instance => connectDropTarget ( findDOMNode ( instance ) ) } / >); } } DroppableBackgroundWrapper = DropTarget ( [ 'event' ] , dropTarget , collectTarget ) ( DroppableBackgroundWrapper ) ; components = { { eventWrapper : DraggableEventWrapper , backgroundWrapper : DroppableBackgroundWrapper } }", "del_tokens": "import { DragSource , DragDropContext } from 'react-dnd' ; function collect ( connect ) { DraggableEventWrapper = DragSource ( 'event' , eventSource , collect ) ( DraggableEventWrapper ) ; components = { { eventWrapper : DraggableEventWrapper } }", "commit_type": "add"}
{"commit_tokens": ["add", "getCloudModules", "and", "getCloudModule", "methods"], "add_tokens": "} , '/cloudbits' : { get : { fname : 'getCloudModules' } } , '/cloudbits/{bit_id}' : { get : { fname : 'getCloudModule' } exports . table = table ;", "del_tokens": "exports . table = table ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "Date", "equality", "-", "check", "bug", ":", "isEqual", "()", "can", "rely", "on", ".", "valueOf", "()", "for", "compatible", "object", "comparison"], "add_tokens": "it ( \"Date\" , ( ) => { var date1 = new Date ( '2019-06-18' ) , date2 = new Date ( '2019-08-21' ) , date3 = new Date ( '2019-08-21' ) ; doormen . not . equals ( date1 , date2 ) ; doormen . equals ( date2 , date3 ) ; } ) ; var dateString = date . toISOString ( ) ; // .toString() doesn't work: it strips millisecond", "del_tokens": "var dateString = date . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "postcss", "task", "to", "not", "care", "about", "css", "filename"], "add_tokens": "return gulp . src ( ` ${ c . outputPath } ` )", "del_tokens": "return gulp . src ( ` ${ c . outputPath } ${ c . compiledFileName } ` )", "commit_type": "update"}
{"commit_tokens": ["Removed", "$class", "and", "replaced", "it", "with", "the", "standard", "constructor", "key", ".", "Also"], "add_tokens": "_ . extend ( claz . prototype , prototype ) ; if ( typeof ( obj ) === \"object\" && obj . constructor && obj . constructor . isSubClass && return obj . constructor . isSubClass ( type ) ; var cons = prototype . constructor ; p . constructor = cons ;", "del_tokens": "prototype : { } , $class : ring . Object , claz . prototype = prototype ; prototype . $class = claz ; if ( typeof ( obj ) === \"object\" && obj . $class && return obj . $class . isSubClass ( type ) ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "proper", "error", "handling", "for", "edge", "cases", "in", "the", "verificationComplete"], "add_tokens": "helpers . render ( req . app . get ( 'stormpathAccountVerificationFailedView' ) , res ) ; helpers . render ( req . app . get ( 'stormpathAccountVerificationFailedView' ) , res ) ; helpers . render ( req . app . get ( 'stormpathAccountVerificationFailedView' ) , res ) ;", "del_tokens": "res . send ( 400 ) ; res . send ( 400 ) ; res . send ( 500 ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "syn", "to", "work", "with", "FF4"], "add_tokens": "setTimeout ( function ( ) { if ( Syn . support . ready == 2 ) { for ( var name in Syn . support ) { st . log ( name + \": \" + Syn . support [ name ] ) } } else { setTimeout ( arguments . callee , 1 ) ; } , 1 ) ;", "del_tokens": "( function ( ) { for ( var name in Syn . support ) { st . log ( name + \": \" + Syn . support [ name ] ) } ) ( ) ;", "commit_type": "update"}
{"commit_tokens": ["add", ".", "parent", ".", "parents", "methods", "fix", ".", "on", "event", "with", "target"], "add_tokens": "jBone . fn . on = function ( originEvent ) { var callback , target , namespace , fn , events , expectedTarget ; originEvent . split ( \" \" ) . forEach ( function ( event ) { } else if ( ( expectedTarget = jBone ( e . target ) . parents ( target ) ) && ~ jBone ( el ) . find ( target ) . indexOf ( expectedTarget [ 0 ] ) ) { expectedTarget . trigger ( originEvent ) ;", "del_tokens": "jBone . fn . on = function ( ) { var event = arguments [ 0 ] , callback , target , namespace , fn , events ; event . split ( \" \" ) . forEach ( function ( event ) {", "commit_type": "add"}
{"commit_tokens": ["add", "more", "matchers", "create", "matchers", "that", "don", "t", "type", "coerce"], "add_tokens": "this . alternative = undefined ; // matchTypeExactly: case 6 : isMatch = typeof subObject == record . type ; break ; // matchAnything: case 7 : isMatch = true ; break ;", "del_tokens": "this . alternative = function ( ) { throw new Error ( \"No methods with matching input patterns were found\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["removes", "unnecessary", "newline", "on", "removing", "_if"], "add_tokens": "var regex = / (\\n?)([ |\\t]*)<!--\\(\\s?bake\\s+([\\w\\/.\\-]+)\\s?([^>]*)\\)--> / g ; function replace ( linebreak , indent , includePath , attributes , filePath , values ) { return linebreak + fragment ; return linebreak + parse ( includeContent , includePath , values ) ; fileContent = fileContent . replace ( regex , function ( match , linebreak , indent , includePath , attributes ) { return replace ( linebreak , indent , includePath , attributes , filePath , values ) ;", "del_tokens": "var regex = / ([ |\\t]*)<!--\\(\\s?bake\\s+([\\w\\/.\\-]+)\\s?([^>]*)\\)--> / g ; function replace ( indent , includePath , attributes , filePath , values ) { return fragment ; return parse ( includeContent , includePath , values ) ; fileContent = fileContent . replace ( regex , function ( match , indent , includePath , attributes ) { return replace ( indent , includePath , attributes , filePath , values ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "Error", "object", "for", "errors"], "add_tokens": "var error = new Error ( 'Unable to connect to the WebSocket' ) ; self . notifier . emit ( 'error' , error ) ; var error = new Error ( 'Invalid tab index' ) ; self . notifier . emit ( 'error' , error ) ;", "del_tokens": "self . notifier . emit ( 'error' , 'Unable to connect to the WebSocket' ) ; self . notifier . emit ( 'error' , 'Invalid tab index' ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "mousefollower", "+", "fix", "load", "src", "test"], "add_tokens": "if ( element . tagName == 'IMG' && ! element . src ) { callback ( null , element , 'image without src' ) ;", "del_tokens": "if ( ! element . src ) { callback ( null , element , 'no src' ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "done", "in", "all", "tests", "that", "make", "async", "calls", "."], "add_tokens": "it ( 'handles low-level errors' , function ( done ) { done ( ) ; it ( 'handles success responses' , function ( done ) { done ( ) ; it ( 'handles python exceptions' , function ( done ) { done ( ) ; it ( 'handles java exceptions' , function ( done ) { done ( ) ; it ( 'handles non-200 status codes' , function ( done ) { done ( ) ; it ( 'handles low-level http errors' , function ( done ) { done ( ) ;", "del_tokens": "it ( 'handles low-level errors' , function ( ) { it ( 'handles success responses' , function ( ) { it ( 'handles python exceptions' , function ( ) { it ( 'handles java exceptions' , function ( ) { it ( 'handles non-200 status codes' , function ( ) { it ( 'handles low-level http errors' , function ( ) {", "commit_type": "use"}
{"commit_tokens": ["Adding", "new", "way", "to", "discover", "and", "connect", "to", "devices"], "add_tokens": "let token = this . _packet . checksum . toString ( 'hex' ) ; if ( token . match ( / ^[fF]+$ / ) ) { token = null ; } token : token", "del_tokens": "token : this . _packet . checksum . toString ( 'hex' ) // TODO: Is there any way to discover the model of the device?", "commit_type": "add"}
{"commit_tokens": ["fixed", "function", "name", "in", "alpha", ".", "js"], "add_tokens": "node . Alpha = function Alpha ( val ) {", "del_tokens": "node . Alpha = function URL ( val ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "PNG", "rendering", "outside", "of", "root", "directory", "."], "add_tokens": "var path = require ( 'path' ) , dirname = path . dirname ; var fmt = require ( 'util' ) . format ; var BatikRasterizerPath = path . resolve ( __dirname , '..' , 'batik/batik-rasterizer.jar' ) ; var batikCommand = fmt ( 'java -jar %s -dpi %d %s.svg' , BatikRasterizerPath , data . dpi , tmpfile ) ; exec ( batikCommand , function ( err , stdout , stderr ) {", "del_tokens": "var dirname = require ( 'path' ) . dirname ; exec ( \"java -jar batik/batik-rasterizer.jar -dpi \" + data . dpi + \" \" + tmpfile + \".svg\" , function ( err , stdout , stderr ) {", "commit_type": "fix"}
{"commit_tokens": ["change", "template", "selector", "on", "click"], "add_tokens": "d3 . select ( '#show_slide' ) . text ( t ) ;", "del_tokens": "divHeader . select ( '#show_slide' ) . text ( t ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "bug", "where", "marker", "would", "sometimes", "end", "up", "in", "two", "clusters", "at", "the", "same", "zoom", "."], "add_tokens": "if ( ! added && cluster . getCenter ( ) && break ;", "del_tokens": "if ( cluster . getCenter ( ) &&", "commit_type": "fix"}
{"commit_tokens": ["Remove", "myth", "files", "in", "grunt", "watch", "."], "add_tokens": "grunt . registerTask ( 'src' , [ 'concat' , 'myth' , 'clean' ] ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'src' , 'grunticon:tablesaw' , 'qunit' , 'bytesize' ] ) ;", "del_tokens": "grunt . registerTask ( 'src' , [ 'concat' , 'myth' ] ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'src' , 'clean' , 'grunticon:tablesaw' , 'qunit' , 'bytesize' ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "type", "and", "field", "names", "for", "failed", "struct", "convertions"], "add_tokens": "var TEST_FILES_GLOBS = [ 'test/lib/*.js' , 'test/server.js' , 'test/client.js' ] ; gulp . src ( TEST_FILES_GLOBS , { read : false } ) gulp . src ( TEST_FILES_GLOBS , { read : false } )", "del_tokens": "gulp . src ( [ 'test/server.js' , 'test/client.js' ] , { read : false } ) gulp . src ( [ 'test/server.js' , 'test/client.js' ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "ending", "offset", "to", "tokens", "list", "prepare", "to", "remove", "storing", "content", "."], "add_tokens": "start , // [6] Start position / Source index end , // [7] End position", "del_tokens": "start , // [6] Source index", "commit_type": "add"}
{"commit_tokens": ["Allow", "newlines", "in", "Resource", "Paths"], "add_tokens": "const RESOURCE_PATH_RE = // Note: [\\s\\S] matches all characters including newlines. / ^projects\\/([^/]*)\\/databases\\/([^/]*)(?:\\/documents\\/)?([\\s\\S]*)$ / ;", "del_tokens": "const RESOURCE_PATH_RE = / ^projects\\/([^/]*)\\/databases\\/([^/]*)(?:\\/documents\\/)?(.*)$ / ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "a", "cycle", "video", "button", "."], "add_tokens": "* @ param { boolean = } opt_immediate If true , switch immediately . Otherwise , * switch when convenient . Defaults to true . shaka . player . Player . prototype . selectVideoTrack = function ( id , opt_immediate ) { var immediate = ( opt_immediate == undefined ) ? true : opt_immediate ; return this . videoSource_ . selectVideoTrack ( id , immediate ) ;", "del_tokens": "shaka . player . Player . prototype . selectVideoTrack = function ( id ) { return this . videoSource_ . selectVideoTrack ( id , true ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "imported", "ngmin", "tests", "to", "test", "-", "runner", ".", "Two", "failing", "test", "cases", "(", "$routeProvider", ")"], "add_tokens": "test ( original , ngAnnotate ( annotated , { remove : true } ) . src , \"original.js\" ) ; const ngminOriginal = slurp ( \"tests/ngmin-tests/ngmin_original.js\" ) ; console . log ( \"testing adding annotations (imported tests)\" ) ; const ngminAnnotated = ngAnnotate ( ngminOriginal , { add : true , regexp : \"^myMod\" } ) . src ; test ( slurp ( \"tests/ngmin-tests/ngmin_with_annotations.js\" ) , ngminAnnotated , \"ngmin_with_annotations.js\" ) ; console . log ( \"testing removing annotations (imported tests)\" ) ; test ( ngminOriginal , ngAnnotate ( ngminAnnotated , { remove : true , regexp : \"^myMod\" } ) . src , \"ngmin_original.js\" ) ;", "del_tokens": "const deAnnotated = ngAnnotate ( annotated , { remove : true } ) . src ; test ( original , deAnnotated , \"original.js\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "small", ".", "fetch", "detail"], "add_tokens": "para ( keys , function ( loop , docKey ) {", "del_tokens": "para ( keys , function ( loop , cache , i ) { var docKey = keys [ i ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "or", "clause", "to", "attribute", "reference"], "add_tokens": "* @ param { Mixed } args . orExpr An optional object representing an expression that gets evaluated if the reference does not exist . this . orExpr = args . orExpr ; /* Generate the or expression that gets evaluated if the reference does not exist */ var orExpr ; if ( this . orExpr === undefined ) { orExpr = \"\" ; } else { orExpr = nijs . jsToIndentedNix ( this . orExpr , indentLevel ) ; if ( ( this . refExpr instanceof nijs . NixFunction ) || ( this . refExpr instanceof nijs . NixFunInvocation ) ) { // Function definitions and function invocations require ( ) around them to make them work orExpr = \"(\" + orExpr + \")\" ; } orExpr = \" or \" + orExpr ; } return attrSetExprStr + \".\" + refExprStr + orExpr ;", "del_tokens": "return attrSetExprStr + \".\" + refExprStr ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "name", "as", "dflt", "fallback"], "add_tokens": "default : throw new Error ( ) ;", "del_tokens": "default : throw new Error ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "test", "case", "for", "empty", "arrays", "."], "add_tokens": ", 'with an empty Array param' : { topic : function ( ) { var xml = '<methodResponse><params>' + '<param><value><array><data></data></array></value></param>' + '</params></methodResponse>' xmlrpcParser . parseMethodResponse ( null , xml , this . callback ) } , 'contains an empty array' : function ( error , value ) { assert . isArray ( value , 'array' ) assert . deepEqual ( value , [ ] ) } }", "del_tokens": "console . log ( error ) console . log ( error . message )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "that", "prevented", "finally", "block", "execution", "after", "exceptional", "catches", "."], "add_tokens": "var skipNextTryEntry = null ; entry instanceof FinallyEntry ) { skipNextTryEntry = entry ; // If an exception was thrown from inside a catch block and this // try statement has a finally block, make sure we execute that // finally block. if ( skipNextTryEntry instanceof CatchEntry && entry . finallyEntry ) { finallyEntries . push ( entry . finallyEntry ) ; } skipNextTryEntry = null ;", "del_tokens": "var skipNextTryEntry = false ; entry instanceof FinallyEntry ) { skipNextTryEntry = true ; skipNextTryEntry = false ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "real", "pointer", "size", "."], "add_tokens": "pptrRef . putPointer ( val . ref ( ) ) ;", "del_tokens": "var what = ( val == null || \"__isStructInstance__\" in val ) ? val : new type ( val ) ; pptrRef . putPointer ( what ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "rendering", "inlined", "HTML", "in", "MD", "documents"], "add_tokens": "import htmlSyntax from 'markup-it/syntaxes/html' ; [ BLOCKS . HTML ] : ( token ) => { return < MarkitupReactRenderer value = { token . get ( 'raw' ) } syntax = { htmlSyntax } / >; } , const raw = token . get ( 'raw' ) ; if ( typeof nodeType === 'function' ) { return nodeType ( token ) ; } console . log ( data . toJS ( ) ) ;", "del_tokens": "[ BLOCKS . HTML ] : ( props ) => null ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "styles", "paths", "in", "template", "App", ".", "js"], "add_tokens": "require ( '../../styles/normalize.css' ) ; require ( '../../styles/main.css' ) ;", "del_tokens": "require ( 'styles/normalize.css' ) ; require ( 'styles/main.css' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "carcass", ".", "Improved", "manager", ".", "getConsumer", "()", "to", "allow", "multiple", "arguments", "."], "add_tokens": "configName : carcass . helpers . accessor ( '_configName' , function ( ) { var _ref , _ref1 ; return ( _ref = ( _ref1 = this . _id ) != null ? _ref1 : this . constructor . name ) != null ? _ref : null ;", "del_tokens": "configName : carcass . helpers . accessor ( '_configName' , { getDefault : function ( ) { var _ref , _ref1 ; return ( _ref = ( _ref1 = this . _id ) != null ? _ref1 : this . constructor . name ) != null ? _ref : null ; }", "commit_type": "update"}
{"commit_tokens": ["Added", "parent", "()", "facility", "to", "traverse", "up", "the", "tree"], "add_tokens": "var deepData = JSON . stringify ( require ( \"../data/deep-data.json\" ) ) ; this . Given ( / ^the sample data containing deep data is loaded$ / , function ( ) { this . data = JSON . parse ( deepData ) ; } ) ; this . When ( / ^I navigate to the parent (\\d+) times$ / , function ( repeats ) { while ( repeats -- > 0 ) this . result = this . result . parent ( ) ; } ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "travis", "tunnel", "info", "for", "saucelabs"], "add_tokens": "if ( environment === 'travis' ) { config . multiCapabilities . forEach ( function ( capability ) { capability [ 'tunnel-identifier' ] = process . env . TRAVIS_JOB_NUMBER ; capability [ 'build' ] = process . env . TRAVIS_BUILD_NUMBER ; } ) ;", "del_tokens": "if ( environment === 'travis' ) {", "commit_type": "add"}
{"commit_tokens": ["updated", "with", "company", "name", "test"], "add_tokens": "var INPUT_DATA_COMPANY_NAME = '1216d8fe00f2027265656c7961637469766507' ; var EXPECTED_DATA = { var EXPECTED_DATA_COMPANY_NAME = { uuid : \"fed8\" , data : \"00f2027265656c7961637469766507\" , companyName : \"Google\" } it ( 'should parse BLE advertiser data service data with companyName' , function ( ) { servicedata . process ( INPUT_DATA , CURSOR , ADVERTISER_DATA ) ; assert . deepEqual ( ADVERTISER_DATA . serviceData , EXPECTED_DATA ) ; } ) ;", "del_tokens": "var EXPECTED_DATA = {", "commit_type": "update"}
{"commit_tokens": ["Add", "error", "handling", "to", "chekcing", "package", ".", "json"], "add_tokens": "let config config = require ( path . join ( process . cwd ( ) , 'package.json' ) ) } catch ( e ) { } try { schema = require ( path . join ( process . cwd ( ) , ( config && config . schema ) || 'schema' ) ) switch ( e . code ) { case 'MODULE_NOT_FOUND' : console . log ( '\\nSchema not found. Trying running `gest` with your `schema.js` in the current working directory.\\n' ) break default : console . log ( e ) }", "del_tokens": "const { graphql : config } = require ( path . join ( process . cwd ( ) , 'package.json' ) ) schema = require ( path . join ( process . cwd ( ) , ( config && config . schema ) || 'schema.js' ) ) console . log ( '\\nSchema not found. Trying running `gest` with your `schema.js` in the current working directory.\\n' )", "commit_type": "add"}
{"commit_tokens": ["Adding", "sentiment", "accuracy", "test", "against", "sentiment", "corpus", "from", "import"], "add_tokens": "/ * * / this . terms = tokens . length ; if ( ! tokens [ i ] ) { continue ; } while ( keepCurrent || ( current && current . next ) ) {", "del_tokens": "while ( keepCurrent || current . next ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "conditional", "statement", "simplification"], "add_tokens": "exit : [ alt = next . node ;", "del_tokens": "enter : [", "commit_type": "fix"}
{"commit_tokens": ["moved", "files", "added", "reload", "cli"], "add_tokens": "case 'reload' : require ( './reload' ) break require ( '../webpacker' ) ( inPath , outPath )", "del_tokens": "require ( './webpacker' ) ( inPath , outPath )", "commit_type": "move"}
{"commit_tokens": ["create", "generic", "Protocol", "to", "inherit", "from"], "add_tokens": "this . connection = new Connection ( this . options ) ; this . protocol = new Protocol ( { board : this . board , connection : this . connection , debug : this . options . debug } ) ;", "del_tokens": "this . connection = new Connection ( this . options , this . options . debug ) ; this . protocol = new Protocol ( this . board , this . connection , this . options . debug ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "error", "on", "Linux", "."], "add_tokens": "if ( os . type ( ) == \"Windows_NT\" ) { latex_content += ` \\\\ \\n \\\\ \\n \\n \\ } else { // without chinese support latex_content += ` \\\\ \\n \\\\ \\n \\n \\ \\\\u sepackage [ table ] { xcolor } \\n \\ \\\\u sepackage [ utf8 ] { inputenc } \\n \\ \\\\u sepackage { multirow } \\n \\ \\\\u sepackage { float } \\n \\ \\\\u sepackage { listings } \\n \\ \\\\u sepackage { color } \\n \\ \\\\u sepackage { tcolorbox } \\n \\ \\ \\t cbuselibrary { skins , breakable , theorems } \\n \\ \\ n \\n ` ; } module . exports = engine ;", "del_tokens": "latex_content += ` \\\\ \\n \\\\ \\n \\n \\ module . exports = engine ;", "commit_type": "fix"}
{"commit_tokens": ["add", "example", "of", "filtered", "relation"], "add_tokens": "} , chapters : function ( ) { return this . hasMany ( require ( '../chapters/model' ) ) ; } , firstChapters : function ( ) { return this . hasMany ( require ( '../chapters/model' ) ) . query ( function ( qb ) { qb . where ( 'ordering' , 1 ) ; } ) ; chapters : 'chapters' , firstChapters : 'firstChapters' , / * unsupported specificChapter : function ( params ) { return this . hasMany ( '../chapters/model' ) . query ( function ( qb ) { } ) ; } * / series : 'series' , author : 'author'", "del_tokens": "author : 'author' , series : 'series'", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "pausable", "registration"], "add_tokens": "it ( \"Should fail to register module if registration is paused\" , async ( ) => { let errorThrown = false ; try { await I_ModuleRegistry . pause ( { from : account_polymath } ) ; await I_ModuleRegistry . registerModule ( I_GeneralTransferManagerFactory . address , { from : account_polymath } ) ; } catch ( error ) { console . log ( ` ` . grey ) ; errorThrown = true ; ensureException ( error ) ; } assert . ok ( errorThrown , message ) ; } ) ; it ( \"Should succssfully register the module\" , async ( ) => { await I_ModuleRegistry . unpause ( { from : account_polymath } ) ;", "del_tokens": "it ( \"Should succssfully registered the module\" , async ( ) => {", "commit_type": "add"}
{"commit_tokens": ["move", "some", "logic", "back", "into", "main", "to", "make", "init", "process", "clearer", "and", "reduce", "scope", "of", "configs"], "add_tokens": "const DevToolsUtils = require ( \"devtools-sham/shared/DevToolsUtils\" ) ; const AppConstants = require ( \"devtools-sham/sham/appconstants\" ) . AppConstants ; const { isEnabled } = require ( \"../../config/feature\" ) ; // Set various flags before requiring app code. if ( isEnabled ( \"clientLogging\" ) ) { DevToolsUtils . dumpn . wantLogging = true ; } if ( isEnabled ( \"development\" ) ) { AppConstants . DEBUG_JS_MODULES = true ; } function getTargetFromQuery ( ) { const href = window . location . href ; const nodeMatch = href . match ( / ws=([^&#]*) / ) ; const firefoxMatch = href . match ( / firefox-tab=([^&#]*) / ) ; const chromeMatch = href . match ( / chrome-tab=([^&#]*) / ) ; if ( nodeMatch ) { return { type : \"node\" , param : nodeMatch [ 1 ] } ; } else if ( firefoxMatch ) { return { type : \"firefox\" , param : firefoxMatch [ 1 ] } ; } else if ( chromeMatch ) { return { type : \"chrome\" , param : chromeMatch [ 1 ] } ; } return null ; } } else if ( process . env . NODE_ENV === \"DEVTOOLS_PANEL\" ) {", "del_tokens": "const { getTargetFromQuery , setConfigs , isDevToolsPanel } = require ( \"../../config/feature\" ) ; setConfigs ( ) ; } else if ( isDevToolsPanel ( ) ) {", "commit_type": "move"}
{"commit_tokens": ["Use", "QUnit", "and", "testee", "to", "run", "tests"], "add_tokens": "'use strict' ; } ) ;", "del_tokens": "} ) ;", "commit_type": "use"}
{"commit_tokens": ["move", "facetInit", "and", "middleware", "instantiation", "to", "FacetCore"], "add_tokens": "FacetApiCore . super_ . call ( this , options ) ; // this.setCommonAttributes( options );", "del_tokens": "this . setCommonAttributes ( options ) ; // load the appropriate middleware generating class // this.middleware = new require('./middleware/'+this.middlewareType)(this); var middlewareClass = require ( './middleware/' + this . middlewareType ) ; this . middleware = new middlewareClass ( this ) ; //EventEmitter.call(this); / ** * Returns middleware that sets up a nodeStack and emits it for other modules . * This function is to be used when no other facet middleware is used in your app . * * @ return { function } * / FacetApiCore . prototype . facetInit = function ( ) { return this . middleware . facetInitBuilder ( this ) ; } ;", "commit_type": "move"}
{"commit_tokens": ["Use", "mapbox", "-", "to", "-", "ol", "-", "style", "and", "remove", "getStyleFunction", "()"], "add_tokens": "import should from 'should/as-function' ; import { applyStyle } from '../' ; delete brightV9 . sprite ; describe ( 'ol-mapbox-style' , function ( ) { should ( layer . getStyle ( ) ) . be . null ; applyStyle ( layer , brightV9 , 'mapbox' ) . then ( function ( ) { should ( layer . getStyle ( ) ) . be . a . Function ;", "del_tokens": "import expect from 'expect.js' ; import olms from '../' ; describe ( 'ol-mapbox-gl-style' , function ( ) { describe ( 'getStyleFunction' , function ( ) { it ( 'creates a style function and calls onChange' , function ( done ) { var resolutions = layer . getSource ( ) . getTileGrid ( ) . getResolutions ( ) ; var style = olms . getStyleFunction ( brightV9 , 'mapbox' , resolutions , function ( ) { done ( ) ; // Callback will be called multiple times, but call done8) only once done = function ( ) { } ; } ) ; expect ( typeof style ) . to . be ( 'function' ) ; } ) ; } ) ; olms . applyStyle ( layer , brightV9 , 'mapbox' ) . then ( function ( ) {", "commit_type": "use"}
{"commit_tokens": ["fix", "a", "bug", "where", "lambda", "file", "was", "corrupted", "due", "to", "race", "condition"], "add_tokens": "const pLimit = require ( 'p-limit' ) ; const limit = pLimit ( 1 ) ; const ps = Object . keys ( nested ) . map ( ( name ) => limit ( ( ) => { } ) ) ;", "del_tokens": "const ps = Object . keys ( nested ) . map ( ( name ) => { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "npm", "link", "-", "ed", "version", "in", "ci", ".", "js"], "add_tokens": "var elmTest = \"elm-test\" ;", "del_tokens": "var elmTest = path . join ( __dirname , '..' , 'bin' , 'elm-test' ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "Logic", "to", "Pass", "Tests"], "add_tokens": "if ( value && $ . isArray ( sources ) && propNames && propNames . value ) { value = ko . utils . arrayFirst ( sources , function ( opt ) { return opt [ propNames . value ] == value ; } ) || value ; } if ( value && propNames && propNames . input ) { element . value = value [ propNames . input ] ; } else { element . value = value ;", "del_tokens": "if ( $ . isArray ( sources ) ) { value = ko . utils . arrayFirst ( sources , function ( opt ) { return opt [ propNames . value ] == value ; } ) ; element . value = value [ propNames . input ] || value ;", "commit_type": "update"}
{"commit_tokens": ["added", "references", "to", "callbacks", "so", "they", "are", "not", "GC"], "add_tokens": "// connection_create tests // connection_connect tests // connection_get_data tests // connection_getState tests // connection_release tests function ( handle , err , data ) { if ( err ) { reject ( err ) return } resolve ( data ) } ) handle , callback // this will timeout if condition is never met // get_data will return \"\" because the connection object was released } )", "del_tokens": "// connection_create tests // connection_connect tests // connection_get_data tests // connection_getState tests // connection_release tests function ( handle , err , data ) { if ( err ) { reject ( err ) return } resolve ( data ) } ) handle , callback // this will timeout if condition is never met // get_data will return \"\" because the connection object was released } )", "commit_type": "add"}
{"commit_tokens": ["Add", "nanomatch", ".", "capture", "to", "return", "captured", "matches"], "add_tokens": "if ( this . options . capture ) { val = '(' + val + ')' ; } var output = prefix + star ; if ( this . options . capture ) { output = '(' + output + ')' ; } return this . emit ( output , node ) ; val += ( this . options . contains ? '\\\\/?' : '(?:\\\\/|$)' ) ;", "del_tokens": "return this . emit ( prefix + star , node ) ; val += ( this . options . contains ? '\\\\/?' : '(\\\\/|$)' ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "a", "few", "doc", "comments", "and", "variable", "names", "on", "Autolinker", "and", "AnchorTagBuilder", "."], "add_tokens": "* ` ` if 'http://' or 'https://' and / or the 'www.' should be stripped from the beginning of URL links ' * ` ` otherwise . * adding a two period ellipsis ( '..' ) to the end of the string . * something like this : 'yahoo.com/some/long/pat..'", "del_tokens": "* ` ` if 'http://' or 'https://' and / or the 'www.' should be stripped from the beginning of links , ` ` otherwise . * adding a two period ellipsis ( '..' ) into the middle of the string . * something like this : 'http://www...th/to/a/file'", "commit_type": "update"}
{"commit_tokens": ["added", "utils", "to", "function", "methods"], "add_tokens": "var url = substitute ( config . url , params , utils ) ; var options = substitute ( config . options || { } , params , utils ) ; url = setParam ( url , substitute ( value , params , utils ) ) ; var data = ( method === 'get' ) ? substitute ( config . query || { } , params , utils ) : substitute ( config . data || { } , params , utils ) ;", "del_tokens": "var url = substitute ( config . url , params ) ; var options = substitute ( config . options || { } , params ) ; url = setParam ( url , substitute ( value , params ) ) ; var data = ( method === 'get' ) ? substitute ( config . query || { } , params ) : substitute ( config . data || { } , params ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "indention", "and", "documented", "on", "-", "cancel", "in", "readme"], "add_tokens": "//onCancel is linked to controller via wizard directive: $scope . onCancel ( ) ;", "del_tokens": "//onCancel is linked to controller via wizard directive: $scope . onCancel ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "link", "-", "development", "and", "link", "-", "production", "command", ".", "I", "don", "t", "think", "they", "ll", "actually", "be", "useful", "to", "anyone", "."], "add_tokens": "var linkEnv = require ( '../tasks/link-environment' ) ; var Project = require ( '../models/project' ) ; linkEnv ( Project . closest ( ) , 'ember/dist' ) ; linkEnv ( Project . closest ( ) , 'ember/tmp/output' ) ;", "del_tokens": "( new ( require ( '../commands/link-production' ) ) ) . validateAndRun ( ) ; ( new ( require ( '../commands/link-development' ) ) ) . validateAndRun ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "this", "instead", "of", "req", "for", "__depth", "lookup"], "add_tokens": "if ( this . __depth > this . options . maxDepth ) { depth : this . __depth __depth : ( this . __depth || 0 ) + 1", "del_tokens": "if ( req . __depth > this . options . maxDepth ) { depth : req . __depth __depth : ( self . __depth || 0 ) + 1", "commit_type": "use"}
{"commit_tokens": ["make", "sure", "the", "total", "of", "range", "and", "page", "queries", "is", "an", "integer"], "add_tokens": "total : _ . parseInt ( arr [ 1 ] )", "del_tokens": "total : arr [ 1 ]", "commit_type": "make"}
{"commit_tokens": ["Added", "reconnect", "on", "the", "internal", "MJPEG", "stream"], "add_tokens": "var imageChecker = function ( ) { if ( that . axisCam . _image ) { assert . equal ( that . axisCam . _image . readUInt16BE ( 0 ) , 0xffd8 ) assert . equal ( that . axisCam . _image . readUInt16BE ( that . axisCam . _image . length - 2 ) , 0xffd9 ) that . axisCam . jpgStream . removeListener ( 'data' , imageChecker ) // So done isn't called multiple times done ( ) } } // Might have to go through two events, depending on which listener is added first this . axisCam . jpgStream . on ( 'data' , imageChecker )", "del_tokens": "this . axisCam . jpgStream . once ( 'data' , function ( data ) { assert ( that . axisCam . _image ) assert . equal ( that . axisCam . _image . readUInt16BE ( 0 ) , 0xffd8 ) assert . equal ( that . axisCam . _image . readUInt16BE ( data . length - 2 ) , 0xffd9 ) done ( ) } )", "commit_type": "add"}
{"commit_tokens": ["Add", "setting", "to", "print", "stack", "-", "traces", "in", "reverse", "order"], "add_tokens": "stack = text . slice ( splitAt ) ; /** Print stack traces in reverse order if the option's enabled */ if ( this . options . reverseStackTraces ) stack = stack . reverse ( ) ; stack = stack . filter ( i => i ) . join ( \"\\n\" ) . replace ( /** Mop up any stray line-breaks floating between tags */ . replace ( / >(?:[\\x20\\t]*\\n[\\x20\\t]*)+< / g , \">\\n<\" )", "del_tokens": "stack = text . slice ( splitAt ) . join ( \"\" ) . replace (", "commit_type": "add"}
{"commit_tokens": ["Make", "filePath", "configurable", "by", "using", "reporterOptions"], "add_tokens": "* @ param { Object } options - reporter options function MochaJUnitReporter ( runner , options ) { var filePath ; if ( options && options . mochaFile ) { filePath = options . mochaFile ; } else { filePath = process . env . MOCHA_FILE || 'test-results.xml' ; }", "del_tokens": "function MochaJUnitReporter ( runner ) { var filePath = process . env . MOCHA_FILE || 'test-results.xml' ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "to", "instantiate", "analysis", "with", "custom", "database", "service"], "add_tokens": "function AnalysisFactory ( DatabaseServiceClass ) { this . DatabaseServiceClass = DatabaseServiceClass ; } AnalysisFactory . prototype . create = function ( configuration , definition , callback ) { var databaseService = new this . DatabaseServiceClass ( configuration . db , configuration . batch ) ; } ; module . exports = AnalysisFactory ; var analysisFactory = new AnalysisFactory ( DatabaseService ) ; module . exports . create = analysisFactory . create . bind ( analysisFactory ) ;", "del_tokens": "function create ( configuration , definition , callback ) { var databaseService = new DatabaseService ( configuration . db , configuration . batch ) ; } module . exports . create = create ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "readFile", "instead", "of", "readFileSync", "in", "tests"], "add_tokens": "const { readdirSync , readFile } = require ( 'fs' ) js : new Promise ( ( resolve , reject ) => { readFile ( fixture ( file ) , ( err , data ) => { if ( err ) return reject ( err ) resolve ( data . toString ( ) ) } ) } ) , re : new Promise ( ( resolve , reject ) => { readFile ( fixture ( file . replace ( '.js' , '.re' ) ) , ( err , data ) => { if ( err ) return reject ( err ) resolve ( data . toString ( ) ) } ) } ) const compareSources = async ( t , { js , re } ) => { t . is ( compile ( await js ) , format ( await re ) )", "del_tokens": "const { readdirSync , readFileSync } = require ( 'fs' ) js : readFileSync ( fixture ( file ) ) . toString ( ) , re : readFileSync ( fixture ( file . replace ( '.js' , '.re' ) ) ) . toString ( ) const compareSources = ( t , { js , re } ) => { t . is ( compile ( js ) , format ( re ) )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "some", "docs", "for", "v2"], "add_tokens": "{ title : \"City\" , key : \"city\" } , city : faker . address . city ( ) , expenses : '$' + faker . finance . amount ( ) , doc . setTextColor ( 0 ) ; doc . autoTable ( columns , getData ( ) , { margins : { top : 345 , bottom : 40 , right : 40 , left : 40 } , theme : 'plain' } ) ;", "del_tokens": "expenses : '$5' , doc . autoTable ( columns , getData ( ) , { margins : { top : 345 , bottom : 40 , right : 40 , left : 40 } , styles : { padding : 0 } , theme : 'plain' } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "service", "call", "name", "configurable"], "add_tokens": "function CacheModule ( cacheName , serviceHandler , serviceCallName ) { if ( serviceCallName == null ) { serviceCallName = \"call\" ; } this . serviceCallName = serviceCallName ; this . service [ this . serviceCallName ] ( params ) . then ( function ( data ) {", "del_tokens": "function CacheModule ( cacheName , serviceHandler ) { this . service . call ( params ) . then ( function ( data ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "race", "condition", "in", "simple", "case", "and", "remove", "logs"], "add_tokens": "process . nextTick ( function ( ) { Object . keys ( containers ) . forEach ( function ( key ) { containers [ key ] . handleBroadcast ( name , message ) ; } ) ;", "del_tokens": "console . log ( \"P\" , container ) ; console . log ( container . name , provides ) ; console . log ( containers , name ) ; Object . keys ( containers ) . forEach ( function ( key ) { containers [ key ] . handleBroadcast ( name , message ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "only", "firefox", "for", "travis"], "add_tokens": "", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["Changed", "demo", "directory", "structure", "minor", "demo", "tweaks"], "add_tokens": "// amd.js", "del_tokens": "requirejs . config ( { baseUrl : '../../bower_components' , paths : { 'jquery' : '../demo/bower_demo_components/jquery/dist/jquery' , 'underscore' : 'underscore/underscore' , 'backbone' : 'backbone/backbone' , 'backbone.select' : '/dist/amd/backbone.select' } } ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "toJSON", "method", "to", "return", "JSON", "object"], "add_tokens": "return objToJSON", "del_tokens": "return JSON . stringify ( objToJSON )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "some", "linting", "errors", ";", "leaving", "others", "as", "reminder", "of", "what", "I", "need", "to", "do", "."], "add_tokens": "return targetAxios . request ( newConfig ) . catch ( ( err ) => { return emptyPromise ( ) ; const responseDataConverters = { stream ( data ) { return data ; } , json ( data ) { return streamToString ( data ) . then ( ( str ) => { try { return JSON . parse ( str ) ; } catch ( err ) { return str ; } } ) ; } , string ( data ) { return streamToString ( data ) ; } } ;", "del_tokens": "return targetAxios . request ( newConfig ) . catch ( err => { return emptyPromise ( ) const responseDataConverters = { stream ( data ) { return data ; } , json ( data ) { return streamToString ( data ) . then ( str => { try { return JSON . parse ( str ) ; } catch ( err ) { return str ; } } ) ; } , string ( data ) { return streamToString ( data ) ; } } ;", "commit_type": "fix"}
{"commit_tokens": ["add", "session", "store", "and", "express", "to", "openbiz"], "add_tokens": "mongoose = require ( 'mongoose' ) ;", "del_tokens": "mongoose = require ( 'mongoose' ) , express = require ( 'express' ) , mongoStore = require ( 'connect-mongo' ) ( express ) ; //setup the session store app . sessionStore = new mongoStore ( { url : options . db . uri } ) ; session : app . sessionStore ,", "commit_type": "add"}
{"commit_tokens": ["Add", "start", "method", "to", "http", "protocol"], "add_tokens": "'Services.Messenger' function httpProtocolFactory ( messenger ) { function HttpProtocol ( ) { this . exchange = 'http' ; } HttpProtocol . prototype . start = function start ( ) { return messenger . exchange ( this . exchange , 'topic' , { durable : true } ) ; } ; return new HttpProtocol ( ) ; }", "del_tokens": "function httpProtocolFactory ( ) { return { } ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "fragment", "references", "in", "placeholders"], "add_tokens": "HydrationOpcodeCompiler . prototype . endTemplate = function ( block ) { if ( block . length === 1 && typeof block . children [ 0 ] !== 'string' ) { this . opcodes . shift ( ) ; this . opcodes . pop ( ) ; }", "del_tokens": "HydrationOpcodeCompiler . prototype . endTemplate = function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "redirect", "for", "/", "docs", "endpoint"], "add_tokens": ", Fs = require ( 'fs' ) const swaggerUIIndex = Fs . readFileSync ( ` ${ Path . dirname ( require . resolve ( 'swagger-ui' ) ) } ` , 'utf8' ) ; hosts [ hostId ] [ \"router\" ] . get ( '/docs' , ( req , res ) => { if ( ! req . originalUrl . endsWith ( '/' ) ) { res . redirect ( 301 , req . originalUrl + '/' ) ; return ; } res . send ( swaggerUIIndexWithPath ) ; } ) ;", "del_tokens": ", fs = require ( 'fs' ) const swaggerUIIndex = fs . readFileSync ( ` ${ Path . dirname ( require . resolve ( 'swagger-ui' ) ) } ` , 'utf8' ) ; hosts [ hostId ] [ \"router\" ] . get ( '/docs' , ( req , res ) => res . send ( swaggerUIIndexWithPath ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Moving", "over", "to", "KSS", "and", "starting", "a", "stylist", "."], "add_tokens": "import cleanup from 'rollup-plugin-cleanup' import commonjs from 'rollup-plugin-commonjs' import resolve from 'rollup-plugin-node-resolve' const production = ! process . env . ROLLUP_WATCH ; input : './hello-world/app.js' , file : './hello-world/build.js' , comments : 'none' }", "del_tokens": "import replace from 'rollup-plugin-replace' ; import cleanup from 'rollup-plugin-cleanup' ; import commonjs from 'rollup-plugin-commonjs' ; import resolve from 'rollup-plugin-node-resolve' ; input : 'src/module.js' , file : './dist/potassium.js' , replace ( { 'process.env.NODE_ENV' : JSON . stringify ( 'production' ) , } ) , comments : 'none' , } ;", "commit_type": "move"}
{"commit_tokens": ["Change", "the", "second", "argument", "to", "on", "()", "to", "be", "a", "String", "URL", "prefix", "instead", "of", "an", "exact", "match"], "add_tokens": "if ( handler . exec ? e . req . url . match ( handler ) : e . req . url . indexOf ( handler ) === 0 ) {", "del_tokens": "if ( e . req . url === handler || ( handler . exec && e . req . url . match ( handler ) ) ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "mistyped", "method", "name", "."], "add_tokens": "function close ( ) {", "del_tokens": "function closel ( ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "use", "strict", "to", "all", "tests"], "add_tokens": "return method . apply ( this , scopeArgs ) ;", "del_tokens": "return method . apply ( null , scopeArgs ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "and", "sample", "page", "for", "integrating", "style", "overrides", "on", "charts", "."], "add_tokens": "const supportedTypes = [ 'bar' , 'bar-horizontal' ] ;", "del_tokens": "const supportedTypes = [ 'bar' , 'bar-horizontal' , 'bar-override' ] ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "how", "subscribing", "to", "events", "worked"], "add_tokens": "setTimeout ( function ( ) { exec ( win , null , \"Sync\" , \"sync\" , [ options . src , options . type ] ) ; } , 10 ) ; setTimeout ( function ( ) { exec ( publishCancel , null , 'Sync' , 'cancel' , [ ] ) ; } , 10 ) ;", "del_tokens": "exec ( win , null , \"Sync\" , \"sync\" , [ options . src , options . type ] ) ; exec ( publishCancel , null , 'Sync' , 'cancel' , [ ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "by", "using", "document", ".", "location", "instead", "of", "location"], "add_tokens": "let moduleName = ev . path . replace ( document . location . pathname . slice ( 1 ) , '' )", "del_tokens": "let moduleName = ev . path . replace ( location . pathname . slice ( 1 ) , '' )", "commit_type": "fix"}
{"commit_tokens": ["Use", "standard", "webpack", "dev", "client"], "add_tokens": "// require.resolve('react-dev-utils/webpackHotDevClient'), ` ${ require . resolve ( 'webpack-dev-server/client' ) } ` ,", "del_tokens": "require . resolve ( 'react-dev-utils/webpackHotDevClient' ) ,", "commit_type": "use"}
{"commit_tokens": ["Add", "scope", ".", "setParameter", "function"], "add_tokens": "} , extraParameters : { } , setParameter : function ( name , value ) { // These parameters aren't stored separately (not in this.parameters) // because they are not transformed to the defined type. this . extraParameters [ name ] = value ; * @ param { object } req Request object * @ param { object } res Response object var scope = this ; var value = callback . params [ name ] ; // Extra parameters are set using scope.setParameter, and override the path parameters. if ( typeof scope . extraParameters [ name ] !== 'undefined' ) { value = scope . extraParameters [ name ] ; } args . push ( value ) ;", "del_tokens": "* @ param { object } req Request objec * @ param { object } res Response objec args . push ( callback . params [ name ] ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "l10nData", "property", "on", "document", "and", "nodes"], "add_tokens": "HTMLElement . prototype . __defineGetter__ ( 'l10nData' , function ( ) { return this . nodeData ; } ) ; HTMLDocument . prototype . __defineGetter__ ( 'l10nData' , function ( ) { return ctx . data ; } ) ; var args ; // node.nodeData // must not be exposed if ( node . nodeData ) { args = node . nodeData ; } else if ( node . hasAttribute ( 'l10n-args' ) ) { args = JSON . parse ( node . getAttribute ( 'l10n-args' ) ) ; node . nodeData = args ;", "del_tokens": "var args = node . getAttribute ( 'l10n-args' ) ; if ( args ) { args = JSON . parse ( args ) ;", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "method", "to", "unload", "dictionaries", "when", "blurred"], "add_tokens": "return { language : alternatesTable [ langCode ] , dictionary : await this . dictionarySync . loadDictionaryForLanguage ( alternatesTable [ langCode ] ) } ; autoUnloadDictionariesOnBlur ( ) { let ret = new CompositeDisposable ( ) ; let hasUnloaded = false ; ret . add ( Observable . fromEvent ( window , 'blur' ) . subscribe ( ( ) => { d ( ` ` ) ; this . currentSpellchecker = null ; hasUnloaded = true ; } ) ) ; ret . add ( Observable . fromEvent ( window , 'focus' ) . flatMap ( ( ) => { if ( ! hasUnloaded ) return Observable . empty ( ) ; if ( ! this . currentSpellcheckerLanguage ) return Observable . empty ( ) ; d ( ` ` ) ; return this . switchLanguage ( this . currentSpellcheckerLanguage ) . catch ( ( e ) => { d ( ` ${ e . message } ` ) ; return Observable . empty ( ) ; } ) ; } ) . subscribe ( ) ) ; return ret ; }", "del_tokens": "return await this . dictionarySync . loadDictionaryForLanguage ( alternatesTable [ langCode ] ) ;", "commit_type": "create"}
{"commit_tokens": ["Added", "auto", "-", "require", "of", "directories", "."], "add_tokens": "if ( requiredDirectory . charAt ( 0 ) == \"/\" ) { require ( 'require-all' ) ( requiredDirectory ) ; } else { require ( 'require-all' ) ( U . UrlJoin ( process . cwd ( ) , \"/\" , requiredDirectory ) ) ; }", "del_tokens": "require ( \"require-all\" ) ( { dirname : U . UrlJoin ( __dirname , \"/\" , requiredDirectory ) , excludeDirs : / ^\\.(git|svn)$ / , recursive : true } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "small", "documentation", "errors"], "add_tokens": "* @ param { ... * } Values to merge * @ param { Object } oldProto First prototype * @ param { Object } newProto Second prototype", "del_tokens": "* @ params { ... * } Values to merge * @ property { Object } oldProto First prototype * @ property { Object } newProto Second prototype", "commit_type": "fix"}
{"commit_tokens": ["Changed", "blockType", "to", "be", "block"], "add_tokens": "An example of a SirTrevor . Block SirTrevor . Blocks . Example = SirTrevor . Block . extend ( { // Element shorthands // this.$editor // this.$$() (same as this.$editor.find('')) // Bound variables // Helper methods", "del_tokens": "An example of a SirTrevor . BlockType var Example = SirTrevor . BlockType . extend ( { // Element shorthands (on a Block) // this.$block // Bound variables (on a Block) // this.blockType (A SirTrevor.BlockType) // Helper methods (on a Block) // this._super(function, args) // Extendable functions // -- // These all have 'this' bound to the currently executing block // This means that any other methods you define on this class *won't* be accessible through 'this' // For example: extraFunction : function ( option ) { } , // Will only be able to be called from one of these functions via a 'super' call. // this._super(\"extraFunction\", option); // Add this block type to the available BlockTypes // This is imperative in order to be able to use this block. SirTrevor . BlockTypes . Example = new Example ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "another", "check", "in", "messy", "input", "for", "components", "that", "are", "not", "in", "the", "dictionary", "but", "in", "the", "decomp", "data"], "add_tokens": "if ( \"undefined\" == typeof getComponents ( character ) ) { if ( \"undefined\" != typeof characters [ character ] ) { return false ; } return true ; }", "del_tokens": "if ( \"undefined\" == typeof getComponents ( character ) ) { return true ; }", "commit_type": "add"}
{"commit_tokens": ["updated", "unit", "tests", "to", "account", "for", "new", "parameter"], "add_tokens": "hl : undefined , badge : undefined", "del_tokens": "hl : undefined", "commit_type": "update"}
{"commit_tokens": ["Fixing", "test", "for", "earlier", "ecma", "versions"], "add_tokens": "it ( ` ` , ( ) => { // const testMaybe = Maybe.of(); // expect(testMaybe.__value).to.equal(testType.value); } ) ; [ ] . concat ( NULL_UNDEFINED_VALUES , VALID_TEST_VALUES ) . forEach ( testValue => {", "del_tokens": "[ ... NULL_UNDEFINED_VALUES , ... VALID_TEST_VALUES ] . forEach ( testValue => {", "commit_type": "fix"}
{"commit_tokens": ["using", "both", "suggestions", "label", "and", "value", "to", "identify", "the", "suggestion", "to", "the", "user", "#GH", "-", "38"], "add_tokens": "var optionValue = opt . value , label = opt . getAttribute ( 'label' ) , text = opt . text ; / * ... put this option into the fragment that is meant to get inserted into the select. Additionally according to the specs ... \"Each option element that is a descendant of the datalist element, that is not disabled, and whose value is a string that isn't the empty string, represents a suggestion. Each suggestion has a value and a label.\" \"If appropriate, the user agent should use the suggestion's label and value to identify the suggestion to the user.\" * / ( ( optionValue !== '' && optionValue . toLowerCase ( ) . indexOf ( inputValue . toLowerCase ( ) ) !== - 1 ) || ( label && label !== '' && label . toLowerCase ( ) . indexOf ( inputValue . toLowerCase ( ) ) !== - 1 ) || ( text !== '' && text . toLowerCase ( ) . indexOf ( inputValue . toLowerCase ( ) ) !== - 1 ) ) && var textOptionPart = text . substr (", "del_tokens": "var optionValue = opt . value ; // ... put this option into the fragment that is meant to get inserted into the select // \"Each option element that is a descendant of the datalist element, that is not disabled, and whose value is a string that isn't the empty string, represents a suggestion. Each suggestion has a value and a label.\" (W3C) optionValue !== '' && optionValue . toLowerCase ( ) . indexOf ( inputValue . toLowerCase ( ) ) !== - 1 && var label = opt . getAttribute ( 'label' ) , text = opt . text , textOptionPart = text . substr (", "commit_type": "use"}
{"commit_tokens": ["fixed", "problem", "with", "SVG", "classList"], "add_tokens": "var className = node . className , value = ( typeof className === 'object' ? className . baseVal : className ) . replace ( trim , '' ) ; if ( value . length ) { value . split ( spaces )", "del_tokens": "var className = node . className . replace ( trim , '' ) ; if ( className . length ) { className . split ( spaces )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "env", "for", "adding", "immutability", "check"], "add_tokens": "if ( IN_PRODUCTION ) {", "del_tokens": "const CHECK_IMMUTABILITY = ! ! process . env . CHECK_IMMUTABILITY ; if ( ! CHECK_IMMUTABILITY && IN_PRODUCTION ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "folder", "matching", "with", "/", "rule"], "add_tokens": "const isDir = file . isDirectory ( ) ; if ( options . onlyFiles && isDir ) { // Signal to PathMatcher whether the file is a directory or not, and // avoid sending '/' instead of './'. let pth = ( toUnixSeparator ( file . relative ) || '.' ) + ( isDir ? '/' : '' ) ;", "del_tokens": "if ( options . onlyFiles && file . isDirectory ( ) ) { let pth = toUnixSeparator ( file . relative ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "data", "-", "align", "=", "center", "support", "to", "Menu"], "add_tokens": "switch ( this . $container . data ( 'align' ) ) case 'right' : { css . right = 1 + Garnish . $win . width ( ) - ( btnOffset . left + btnWidth ) ; break ; } case 'center' : { css . left = Math . round ( ( btnOffset . left + btnWidth / 2 ) - ( this . $container . outerWidth ( ) / 2 ) ) ; break ; } default : { css . left = 1 + btnOffset . left ; }", "del_tokens": "if ( this . $container . attr ( 'data-align' ) == 'right' ) css . right = 1 + Garnish . $win . width ( ) - ( btnOffset . left + btnWidth ) ; } else { css . left = 1 + btnOffset . left ;", "commit_type": "add"}
{"commit_tokens": ["Add", "add", "command", ".", "Support", "/", "as", "command", "prefix", "."], "add_tokens": "function isCommand ( input ) { return _ . include ( [ \":\" , \"/\" ] , input . charAt ( 0 ) ) } if ( isCommand ( input ) ) { case \"add\" :", "del_tokens": "// check for invalid commands etc // check for command if ( input . charAt ( 0 ) === \":\" ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "dimensions", "prop"], "add_tokens": "{ A : 2 , B : 6 }", "del_tokens": "{ A : 2 , B : 3 }", "commit_type": "fix"}
{"commit_tokens": ["add", "feature", "for", "select", "row", "and", "edit", "cell", "together"], "add_tokens": "clickToSelect : React . PropTypes . bool , clickToSelectAndEditCell : React . PropTypes . bool clickToSelect : false , clickToSelectAndEditCell : false", "del_tokens": "clickToSelect : React . PropTypes . bool clickToSelect : false", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "choosing", "if", "a", "page", "is", "in", "navigation"], "add_tokens": "var seen = { } ; } , [ ] ) . filter ( function ( tag ) { return seen . hasOwnProperty ( tag ) ? false : ( seen [ tag ] = true ) ; } ) ; if ( page . expiresAt ) { page . expiresAt = new Date ( page . expiresAt ) ; }", "del_tokens": "} , [ ] ) ; page . expiresAt = new Date ( page . expiresAt ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "and", "fixed", "bugs"], "add_tokens": "aux . queryEntities = function ( queryOptions ) { client . queryEntities ( table , queryOptions , function ( err , data , token ) {", "del_tokens": "aux . queryEntities = function ( options ) { client . queryEntities ( table , options , function ( err , data , token ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "a", "bug", "with", "StentEmitter"], "add_tokens": "var _CircularJSON = require ( '../helpers/vendors/CircularJSON' ) ; var _CircularJSON2 = _interopRequireDefault ( _CircularJSON ) ; var _moment = require ( 'moment' ) ; var _moment2 = _interopRequireDefault ( _moment ) ; return { name : 'running' , noway : ( 0 , _moment2 . default ) ( ) } ;", "del_tokens": "return { name : 'running' } ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "literals", "for", "enum", "property", "names"], "add_tokens": "b . literal ( snakeCase ( name ) . toUpperCase ( ) ) ,", "del_tokens": "b . identifier ( snakeCase ( name ) . toUpperCase ( ) ) ,", "commit_type": "use"}
{"commit_tokens": ["add", "field", "limitation", "for", "input", "modal", "."], "add_tokens": "field : column . props . dataField , editable : column . props . editable field : this . props . children . props . dataField , editable : this . props . children . props . editable", "del_tokens": "field : column . props . dataField field : this . props . children . props . dataField", "commit_type": "add"}
{"commit_tokens": ["added", "pre", "-", "interpolation", "to", "SharedState"], "add_tokens": "} ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["adds", "@httpActionConsumer", "(", "name", "consumer", ")", "decorator"], "add_tokens": "/ ** * @ param { string } name * @ param { Function | HttpConsumer } consumer * @ returns { Function } * / function httpActionConsumer ( name , consumer ) { return function ( target , key , descriptor ) { if ( typeof descriptor . value !== 'function' ) { throw new Error ( 'Decorator is not valid on this declaration type.' ) ; } if ( consumer instanceof HttpConsumer ) { //set consumer descriptor . value [ name ] = consumer ; //and exit return descriptor ; } //validate consumer function if ( typeof consumer !== 'function' ) { throw new Error ( 'Consumer may be a function.' ) ; } descriptor . value [ name ] = new HttpConsumer ( consumer ) ; return descriptor ; } ; } module . exports . defineDecorator = defineDecorator ; module . exports . httpActionConsumer = httpActionConsumer ;", "del_tokens": "module . exports . defineDecorator = defineDecorator ;", "commit_type": "add"}
{"commit_tokens": ["update", "immutable", "warning", "and", "example", "project"], "add_tokens": "expect ( console . warn ) . toHaveBeenCalledWith ( ` ` ) ;", "del_tokens": "expect ( console . warn ) . toHaveBeenCalledWith ( ` ` ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "delimiter", "option", "and", "some", "more", "ref", "doc", "index", "test"], "add_tokens": "var toRemove = _ . difference ( initialValue || [ ] , currentValue || [ ] ) || [ ] ; var union = _ . union ( initialValue || [ ] , currentValue || [ ] ) || [ ] ; var toAdd = _ . difference ( union , toRemove ) || [ ] ; ret . push ( {", "del_tokens": "var toRemove = _ . difference ( initialValue || [ ] , currentValue || [ ] ) ; var union = _ . union ( initialValue || [ ] , currentValue || [ ] ) ; var toAdd = _ . difference ( union , toRemove ) ; ret . add . push ( {", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "issue", "where", "skip", "and", "limit", "are", "getting", "defaulted"], "add_tokens": "if ( err ) { return res . json ( err ) ; return res . json ( data ) ;", "del_tokens": "if ( ! err ) { return res . json ( data ) ; } else { return console . log ( err ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "query", ".", "compile", "to", "support", "fully", "rendered", "builders"], "add_tokens": "var query = builders [ this . _attributes . builder ] . call ( this ) ; if ( typeof query === 'string' ) { return this . _convertNamedParameters ( query ) ; } else { if ( typeof query !== 'object' || ! query . query ) throw new Error ( 'INTERNAL ERROR: Query builder returned unrecognized output.' ) ; return query ; }", "del_tokens": "var queryString = builders [ this . _attributes . builder ] . call ( this ) ; return this . _convertNamedParameters ( queryString ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "defered", "apis", "to", "prevent", "corner", "-", "cases", "."], "add_tokens": "} , 'incoming' ) ; Camp . start ( 80 , 10 ) ;", "del_tokens": "} ) ; Camp . start ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Implement", "specific", "sets", "in", "schemas"], "add_tokens": "for ( let type of types ) { ajv . addSchema ( schemas [ type ] ) }", "del_tokens": "ajv . addSchema ( schemas . resource ) ajv . addSchema ( schemas . item ) ajv . addSchema ( schemas . conceptBundle )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "documentation", "around", "assert", ".", "equal", "and", "assert", ".", "notEqual"], "add_tokens": "* Asserts that the values of ` ` are equivalent to the values of * ` ` . Note that ` ` and ` ` assert * Asserts that the values of ` ` are not equivalent to the values of * ` ` . Note that ` ` and ` ` assert", "del_tokens": "* Asserts that the values of the target are equvalent to the values of * ` ` . Note that ` ` and ` ` assert * Asserts that the values of the target are not equvalent to the values of * ` ` . Note that ` ` and ` ` assert", "commit_type": "fix"}
{"commit_tokens": ["Remove", "some", "code", "tests", "related", "to", "older", "decisions", "."], "add_tokens": "// Is there a better way to check for this? // List all of the possible events? filterBy : function ( filterName , filter ) { addFilter . call ( this , filterName , createFilter ( filter ) ) ;", "del_tokens": "this . trigger ( 'before:filter' ) ; this . trigger ( 'after:filter' ) ; // TODO: Is there a better way to check for this? // List all of the possible events? filterBy : function ( filterName , filter , keys ) { addFilter . call ( this , filterName , createFilter ( filter , keys ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["adds", "tests", "for", "no", "-", "space", "languages"], "add_tokens": "assert . true ( arr [ 0 ] === first && arr [ 1 ] === \"test\" , ` ${ char } ` ) ; const chinese = split ( \"\"); assert . true ( chinese [ 0 ] === \"\" & c inese[1 ] = = \" \", \"sim p ified chinese\"); const burmese = split ( \"\"); assert . true ( burmese [ 0 ] === \"\" && burm se 1] === \"   \", burmese\"); const lao = split ( \".\"); assert . true ( lao [ 0 ] === \"\" && la [1 == = \" .\" \"lao\");", "del_tokens": "assert . true ( arr [ 0 ] === first && arr [ 1 ] === \"test\" , ` ${ char } ` ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "flow", ".", "js", "as", "hard", "dependency", "to", "rAppid", ":", "js"], "add_tokens": "( function ( exports , inherit , require , define , underscore , XMLHttpRequest , flow ) { if ( ! flow ) { throw \"flow.js is needed\" ; } define ( \"flowjs\" , function ( ) { return flow ; } ) ; typeof window !== \"undefined\" ? window . XMLHttpRequest : global . XMLHttpRequest , typeof flow === \"undefined\" ? global . flow : flow ) ;", "del_tokens": "( function ( exports , inherit , require , define , underscore , XMLHttpRequest ) { typeof window !== \"undefined\" ? window . XMLHttpRequest : global . XMLHttpRequest ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "tree", "where", "the", "first", "line", "is", "not", "displayed", "until", "you", "move"], "add_tokens": "// Do not set height, since this create a bug where the first line is not always displayed", "del_tokens": "height : 0 ,", "commit_type": "fix"}
{"commit_tokens": ["added", "type", "cast", "for", "text", "type"], "add_tokens": "// Typecast the value to blob, false, or null // Typecast the value to true, false, or null __typecastValueText : function ( value ) { if ( comb . isInstanceOf ( value , Buffer ) ) { return value ; } else if ( Array . isArray ( value ) || comb . isString ( value ) ) { return new Buffer ( value ) ; } else { throw new Error ( \"Invalid value for blob \" + value ) ; } } ,", "del_tokens": "// Typecast the value to true, false, or null", "commit_type": "add"}
{"commit_tokens": ["Add", "--", "prefer", "-", "reference", "option"], "add_tokens": "'prefer-reference' : Boolean , console . log ( \" --prefer-reference Refer to definitions as possible\" ) ; var options = { preferReference : opts [ 'prefer-reference' ] } ; apib2swagger . convert ( blueprint , options , function ( error , result ) {", "del_tokens": "apib2swagger . convert ( blueprint , function ( error , result ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "View", "preventDefault", "method", "."], "add_tokens": "view . addEventListener ( type , send ) ;", "del_tokens": "view . _handler . on ( type , send ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "files", "into", "resource", "directory", "so", "previous", "asset", "pipeline", "require", "statements", "would", "work", "properly"], "add_tokens": "//= require_tree ./utils //= require ./serialization //= require ./resource", "del_tokens": "//= require_tree utils //= require serialization //= require resource", "commit_type": "move"}
{"commit_tokens": ["add", "support", "for", "relative", "root", "dir"], "add_tokens": "var resolve = path . resolve ; view = resolve ( root , view ) ;", "del_tokens": "var join = path . join ; view = join ( root , view ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "React", "v15"], "add_tokens": "expect ( this . $r . html ( ) ) . to . eq ( '<p>Te</p><p><strong>xt</strong></p>' ) ; expect ( this . $r . find ( 'p' ) . at ( 1 ) . html ( ) ) . to . eq ( '<strong>xt</strong>' ) ; it ( 'returns the attribute value' , function ( ) { expect ( this . $r . val ( ) ) . to . eq ( 'hello' ) ;", "del_tokens": "expect ( this . $r . html ( ) ) . to . match ( new RegExp ( '<p data-reactid=\"[^\"]+\">Te</p><p data-reactid=\"[^\"]+\"><strong data-reactid=\"[^\"]+\">xt</strong></p>' ) ) ; expect ( this . $r . find ( 'p' ) . at ( 1 ) . html ( ) ) . to . match ( new RegExp ( '<strong data-reactid=\"[^\"]+\">xt</strong>' ) ) ; it ( 'returns undefined' , function ( ) { expect ( this . $r . val ( ) ) . to . be . undefined ;", "commit_type": "add"}
{"commit_tokens": ["Add", "rmTree", "and", "rmTreeSync", "for", "tests"], "add_tokens": "var utils = require ( 'test-utils' ) ; var fs = require ( 'fs' ) ; var path = require ( 'path' ) ; var BatchProcessor = require ( '../lib/batch' ) . BatchProcessor ; suiteSetup ( function ( ) { utils . recreateTemporaryDirectory ( ) ; } ) ; suite ( 'batch' , function ( ) { test ( 'initialize' , function ( ) { var processor = new BatchProcessor ( { databasePath : utils . databasePath , domain : 'test-domain' } ) ; assert . equal ( processor . databasePath , databasePath ) ; assert . equal ( processor . domain , 'test-domain' ) ;", "del_tokens": "suite ( 'batch' , function ( ) { setup ( function ( ) { } ) ; test ( 'test' , function ( ) { var actual = 'foo' ; var expected = 'foo' ; assert . equal ( actual , expected ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "simple", "example", "."], "add_tokens": "\"./ServiceQueue\" , \"./NativeXhrDataProvider\" ServiceQueue , NativeXhrDataProvider provider : new NativeXhrDataProvider ( { } ) ,", "del_tokens": "\"./ServiceQueue\" ServiceQueue", "commit_type": "add"}
{"commit_tokens": ["updated", "all", "dependencies", "and", "babel", "config"], "add_tokens": "export default rangesliderJs", "del_tokens": "module . exports = rangesliderJs", "commit_type": "update"}
{"commit_tokens": ["Remove", "the", ".", "at", "the", "end", "of", "the", "init", "message"], "add_tokens": "console . log ( 'Success! Created ' + appName + ' at ' + appPath ) ;", "del_tokens": "console . log ( 'Success! Created ' + appName + ' at ' + appPath + '.' ) ;", "commit_type": "remove"}
{"commit_tokens": ["moved", "test", "results", "rendering", "to", "assert", ".", "js"], "add_tokens": "self . renderResults ( ) ;", "del_tokens": "self . echo ( \"==========================================\" ) ; var total = testResults . passed + testResults . failed ; self . echo ( total + ' tests executed, ' + testResults . passed + ' passed, ' + testResults . failed + ' failed.' ) ; self . exit ( ) ;", "commit_type": "move"}
{"commit_tokens": ["fix", "miles", "and", "add", "more", "units"], "add_tokens": "// unit multipliers for conversion from kilometers var factors = { miles : 1000 / 1609.344 , nauticalmiles : 1000 / 1852 , meters : 1000 , metres : 1000 , yards : 1000 / 0.9144 , feet : 1000 / 0.3048 , inches : 1000 / 0.0254 } ; var m = units ? factors [ units ] : 1 ;", "del_tokens": "// multiplier for unit conversion var m = units === 'miles' ? 1.609344 : units === 'meters' ? 1000 : 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "cross", "disk", "problem", "with", "tingodb"], "add_tokens": "option . pathname = ( ! ! dbURL . protocol && dbURL . protocol . length > 2 ) ? \".\" + dbURL . pathname : dbURL . href ;", "del_tokens": "option . pathname = ( ! ! dbURL . protocol && dbURL . protocol . length > 2 ) ? \".\" + dbURL . pathname : dbURL . pathname ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "it", "so", "that", "you", "can", "reset", "the", "suite", "to", "an", "initial", "state", "(", "at", "which", "point", "tests", "can", "be", "dynamically", "loaded", "and", "run", "for", "example", ")", "."], "add_tokens": "// Initialize the configuration options init : function init ( ) { config = { stats : { all : 0 , bad : 0 } , started : + new Date , blocking : false , assertions : [ ] , pollution : [ ] , filters : [ ] , queue : [ ] } ; var tests = id ( \"qunit-tests\" ) , banner = id ( \"qunit-banner\" ) , result = id ( \"qunit-testresult\" ) ; if ( tests ) { tests . innerHTML = \"\" ; } if ( banner ) { banner . className = \"\" ; } if ( result ) { result . parentNode . removeChild ( result ) ; } } , // Initialize the config, saving the execution queue var queue = config . queue ; QUnit . init ( ) ; config . queue = queue ;", "del_tokens": "// Logging the passes and failures stats : { all : 0 , bad : 0 } , // The log of global variables to check against pollution : [ ] , // queue of test assertions assertions : [ ] , config . started = + new Date ;", "commit_type": "make"}
{"commit_tokens": ["Added", ".", "bowerrc", "renamed", "component", ".", "json", "to", "bower", ".", "json", "updated", "bower", ".", "json", "ignore", "updated", "demo", "&", "test", ".", "conf", ".", "js"], "add_tokens": "'bower_components/jquery/jquery.js' , 'bower_components/jquery-ui/ui/jquery-ui.custom.js' , 'bower_components/angular/angular.js' , 'bower_components/angular-mocks/angular-mocks.js' ,", "del_tokens": "'components/jquery/jquery.js' , 'components/jquery-ui/ui/jquery-ui.custom.js' , 'components/angular/angular.js' , 'components/angular-mocks/angular-mocks.js' ,", "commit_type": "add"}
{"commit_tokens": ["Add", "emptyOnZero", "option", "to", "display", "total", ":", "0", "bars", "as", "empty", "not", "full"], "add_tokens": "progress = ( this . options && this . options . emptyOnZero ) ? 0.0 : 1.0 ;", "del_tokens": "progress = 1.0 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "image", "static"], "add_tokens": "import ImageLayer from 'ol/layer/image' ; import ImageStaticSource from 'ol/source/imagestatic' ; function configureImageSource ( glSource ) { const coords = glSource . coordinates ; const source = new ImageStaticSource ( { url : glSource . url , imageExtent : [ coords [ 0 ] [ 0 ] , coords [ 3 ] [ 1 ] , coords [ 1 ] [ 0 ] , coords [ 0 ] [ 1 ] ] , projection : 'EPSG:4326' return source ; // tiled raster layer. } else if ( glSource . type === 'image' ) { return configureImageSource ( glSource ) ; } else if ( layer_src . type === 'image' ) { new_layer = new ImageLayer ( { source : this . sources [ layer . source ] , opacity : layer . paint ? layer . paint [ \"raster-opacity\" ] : undefined , } ) ;", "del_tokens": "function configureRasterLayer ( olSource , glLayer ) { return new TileLayer ( { source : olSource , visible : glLayer . layout ? glLayer . layout . visibility !== 'none' : true , // tiled rater layer.", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "specify", "custom", "sentence", "separator"], "add_tokens": "var PARSER = 'stanford-parser.jar' ; var MODEL = 'models/englishPCFG.caseless.ser.gz' ; StanfordParser . parseSentencesSync = function ( sentences , separator ) { var separatorJS = typeof ( separator ) === 'undefined' || separator === 'newline' ? '\\n' : separator ; fs . writeSync ( fd , sentences . join ( separatorJS ) ) ; ' -cp \"' + PARSER + '\" ' + ( separator ? ( '-sentences \"' + separator + '\" ' ) : '' ) + MODEL + ' ' + tmpfile ; java . classpath . push ( path . join ( PARSER_PATH , PARSER ) ) ; path . join ( PARSER_PATH , MODEL )", "del_tokens": "var MODEL_PATH = 'models/englishPCFG.caseless.ser.gz' ; StanfordParser . parseSentencesSync = function ( sentences ) { fs . writeSync ( fd , sentences . join ( '\\n' ) ) ; ' -cp \"stanford-parser.jar\" ' + MODEL_PATH + ' ' + tmpfile ; java . classpath . push ( path . join ( PARSER_PATH , 'stanford-parser.jar' ) ) ; path . join ( PARSER_PATH , MODEL_PATH )", "commit_type": "add"}
{"commit_tokens": ["add", "rate", "-", "limit", "-", "reset"], "add_tokens": "res . setHeader ( \"X-Rate-Limit-Reset\" , store . resetTime ) ;", "del_tokens": "//res.setHeader(\"X-Rate-Limit-Reset\", reset); // ?", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "ES", "modules"], "add_tokens": "// Check if method should be disallowed __esModule : true ,", "del_tokens": "// Check if method should be disallowed (and handle OPTIONS method)", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "all", "methods", "return", "promises"], "add_tokens": "return steem . broadcast . commentAsync ( ) ; return steem . broadcast . voteAsync ( ) ; return steem . broadcast . voteAsync ( ) ;", "del_tokens": "steem . broadcast . commentAsync ( ) . catch ( err => { throw ( new Error ( ` ${ this . targetUsername } ${ this . targetPermlink } \\n ${ err . message } ` ) ) ; } ) ; steem . broadcast . voteAsync ( ) . catch ( ( err ) => { throw ( new Error ( ` ` ) ) ; } ) ; steem . broadcast . voteAsync ( ) . catch ( ( err ) => { throw ( new Error ( ` ${ err . message } ` ) ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "splitting", "-", "to", "-", "lines", "to", "determine", "new", "-", "line", "-", "at", "-", "eof"], "add_tokens": "var lines = file . content . split ( / \\r\\n|\\r|\\n / ) ; var hasNewLineAtEOF = _ . last ( lines ) === '' ; line : lines . length } ;", "del_tokens": "var hasNewLineAtEOF = file . content . match ( / \\r\\n|\\r|\\n$ / ) ; line : file . content . split ( / \\r\\n|\\r|\\n / ) . length } ;", "commit_type": "use"}
{"commit_tokens": ["removed", "cover", "task", "from", "gulp", "build"], "add_tokens": "runSequence ( \"mocha\" , \"eslint\" , callback ) ;", "del_tokens": "gulp . task ( \"cover\" , ( ) => { return gulp . src ( [ \"src/**/*.js\" ] ) . pipe ( istanbul ( ) ) . pipe ( istanbul . hookRequire ( ) ) ; } ) ; runSequence ( \"cover\" , \"mocha\" , \"eslint\" , callback ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "run", "block", "in", "the", "example"], "add_tokens": "angular . module ( 'HelloWorld' , [ ] ) . run ( [ '$timeout' , function ( $timeout ) { $timeout ( function ( ) { console . log ( 'hello world' ) ; } ) } ] ) . factory ( '$worldmessage' , function ( ) { return \"Hello World\" ; } ) ;", "del_tokens": "angular . module ( 'HelloWorld' , [ ] ) . factory ( '$worldmessage' , function ( ) { return \"Hello World\" ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "OSX", "screenshot", "to", "readme"], "add_tokens": "menu / * , multilineEntry * /", "del_tokens": "menu , multilineEntry", "commit_type": "add"}
{"commit_tokens": ["added", "a", "new", "structure", "for", "the", "gulp", "tasks"], "add_tokens": "config = require ( './gulp/config.json' ) , requireDir = require ( 'require-dir' ) ; var tasks = requireDir ( './gulp/tasks' ) ; gulp . task ( 'default' , [ config . defaultTask ] ) ;", "del_tokens": "browserify = require ( 'browserify' ) , watchify = require ( 'watchify' ) , source = require ( 'vinyl-source-stream' ) ; var entryPoint = './src/index.js' , debugMode = true , namespace = 'PQ' ; var args = watchify . args || { } ; args . debug = debugMode ; args . fullPaths = false ; args . standalone = namespace ; var bundle = browserify ( entryPoint , args ) ; var bundler = watchify ( bundle ) ; function createBundle ( ) { console . log ( 'Now building...' ) ; return bundler . bundle ( ) . pipe ( source ( 'perenquen.js' ) ) . pipe ( gulp . dest ( './build' ) ) ; } gulp . task ( 'dev' , createBundle ) ; bundler . on ( 'update' , createBundle ) ; bundler . on ( 'time' , function ( time ) { console . log ( 'Done at ' + ( time / 1000 ) ) ; } ) ; gulp . task ( 'default' , [ 'dev' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "metadata", "support", "for", "apps", "API"], "add_tokens": "params : [ 'name' , 'settings' , 'metadata' ] , optional : [ 'settings' , 'metadata' ] , func : function create ( url , name , settings , metadata ) { if ( metadata ) { params . metadata = metadata ; }", "del_tokens": "params : [ 'name' , 'settings' ] , optional : [ 'settings' ] , func : function create ( url , name , settings ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "promise", "always", "200", "response", "bug", "in", "iframeUpload", "on", "ie8"], "add_tokens": "} catch ( e ) { deferred . reject ( { data : { message : 'fail to upload file!' } } ) ; return ; }", "del_tokens": "} catch ( e ) { }", "commit_type": "fix"}
{"commit_tokens": ["Allow", "series", "exclusion", "from", "labels", "or", "legend"], "add_tokens": "var chartData = _ . compact ( _ . map ( extractData ( chart , allData ) , function ( series , index ) { if ( series . excludeFromLegend ) return ; } ) ) ;", "del_tokens": "var chartData = _ . map ( extractData ( chart , allData ) , function ( series , index ) { } ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "event", "emitter", "and", "callbacks", "for", "CoAP", "lib"], "add_tokens": "this . route = { } ; this . handlers = { } ; this . emit ( 'newThing' , { name : request . url } ) ; var coapRequest = function ( request , response ) { self . onRequest ( request , response ) ; response : response , server : self route ( request . url , connection , handlers , self . clientsPath ) ; server . on ( 'request' , coapRequest ) ;", "del_tokens": "response . writeHead ( 200 , { \"Content-Type\" : \"text/plain\" } ) ; response . end ( ) ; / ** * handlers * / var onCoapRequest = function ( request , response ) { var url = request . url ; response : response route ( url , connection , handlers , self . clientsPath ) ; // register this thing //self.emit('newThing', { // name: connection.pathname //}); server . on ( 'request' , onCoapRequest ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "more", "solid", "way", "to", "reset", "the", "console"], "add_tokens": "process . stdout . write ( '\\x1bc' ) ;", "del_tokens": "process . stdout . write ( '\\x1B[2J\\x1B[0f' ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "tuple", "s", "item", "path"], "add_tokens": "const itemPath = ` ${ path } ${ i } ` ;", "del_tokens": "const itemPath = path + \"[]\" ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "difficulty", "formula", "(", "EIP", "100", ")"], "add_tokens": "// Byzantium // max((2 if len(parent.uncles) else 1) - ((timestamp - parent.timestamp) // 9), -99) var uncleAddend = parentBlock . header . uncleHash . equals ( utils . SHA3_RLP_ARRAY ) ? 1 : 2 var a = blockTs . sub ( parentTs ) . idivn ( 9 ) . ineg ( ) . iaddn ( uncleAddend )", "del_tokens": "// homestead // 1 - (block_timestamp - parent_timestamp) // 10 var a = blockTs . sub ( parentTs ) . idivn ( 10 ) . ineg ( ) . iaddn ( 1 )", "commit_type": "add"}
{"commit_tokens": ["added", "a", "parameter", "to", "getRecipients", "to", "add", "tabs", "for", "recipients"], "add_tokens": "* @ param { boolean } [ include_tabs ] - When true the tab information associated with the recipient is included in the response . getRecipients : function ( envelopeId , include_tabs , callback ) { console . log ( 'arguments: ' + arguments . length ) ; console . log ( 'include_tabs: ' + include_tabs ) ; console . log ( 'callback: ' + callback ) ; // handle the case where people omit the tabs if ( arguments . length === 2 && Object . prototype . toString . call ( include_tabs ) === '[object Function]' ) { callback = include_tabs ; include_tabs = false ; } else if ( arguments . length === 1 ) { include_tabs = false ; } return getRecipients ( accessToken , baseUrl , envelopeId , include_tabs ) . asCallback ( callback ) ; * @ param { boolean } [ include_tabs ] - When true the tab information associated with the recipient is included in the response . function getRecipients ( apiToken , baseUrl , envelopeId , include_tabs ) { url : baseUrl + '/envelopes/' + envelopeId + '/recipients?include_tabs=' + include_tabs , console . log ( 'options: ' + options . url ) ;", "del_tokens": "getRecipients : function ( envelopeId , callback ) { return getRecipients ( accessToken , baseUrl , envelopeId ) . asCallback ( callback ) ; function getRecipients ( apiToken , baseUrl , envelopeId ) { url : baseUrl + '/envelopes/' + envelopeId + '/recipients' ,", "commit_type": "add"}
{"commit_tokens": ["Make", "default", "app", "look", "less", "sketchy"], "add_tokens": "import logo from './logo.png' ; < div > < h1 > Welcome to < img src = { logo } className = \"App--logo\" alt = \"React logo\" / > React < / h1 > < p > To get started , edit < code > src / App . js < / code> and save the file to update . < / p >", "del_tokens": "import reactImage from './react.png' ; < div className = \"App\" > Hello world ! < img src = { reactImage } alt = \"React rocks!\" / >", "commit_type": "make"}
{"commit_tokens": ["Adding", "items", "to", "indexed", "collection", "sets", "parent", "&", "wraps", "if", "necessary"], "add_tokens": "record : this . wrapRecordInMetaObjectIfNeccessary ( record ) if ( object instanceof FP . MetaModel ) { object . set ( \"parent\" , this ) ; return this . itemFromRecord ( object ) ; } else if ( object instanceof Ember . Object ) { return this . itemFromRecord ( object ) ; } else { return object ; } return _this . wrapRecordInMetaObjectIfNeccessary ( resolved , item . snapshot ) ; return this . wrapRecordInMetaObjectIfNeccessary ( record , item . snapshot ) ; wrapRecordInMetaObjectIfNeccessary : function ( record , snapshot ) { var store = get ( this , \"store\" ) , priority = snapshot ? snapshot . getPriority ( ) : null ; priority : priority , snapshot : snapshot ,", "del_tokens": "record : record return ( object instanceof Ember . Object ) ? this . itemFromRecord ( object ) : object ; return _this . wrapRecordInMetaObjectIfNeccessary ( resolved , item ) ; return this . wrapRecordInMetaObjectIfNeccessary ( record , item ) ; wrapRecordInMetaObjectIfNeccessary : function ( record , item ) { var store = get ( this , \"store\" ) ; priority : item . snapshot . getPriority ( ) , snapshot : item . snapshot ,", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "sync", "api"], "add_tokens": "timeout : 20000 ,", "del_tokens": "timeout : 10000 , 'async-only' : true ,", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "names", "&", "properties"], "add_tokens": "[ 'Xenon' , 'Xerxes' , 'Xavier' , 'Xanto' , 'Xadrian' , 'Xenor' , 'Xorn' , 'Xylander' , 'Xylon' , 'Xenophon' , 'Xipil' , 'Xilxor' , 'Xhaiden' , 'Xelle' ] , [ 'Yoda' , 'Yoshi' , 'Yukon' , 'Yadid' , 'Yan' , 'Yanni' , 'Yanto' , 'Yardley' , 'Yates' , 'Yestin' , 'Yorick' , 'Yosef' , 'Yosu' , 'Yule' , 'Yves' , 'Yuri' ] , [ 'Zack' , 'Zeke' ] [ 'Xalvadora' , 'Xandra' , 'Xantara' , 'Xaria' , 'Xava' , 'Xeraphina' , 'Xia' , 'Ximena' , 'Xiomara' , 'Xyxa' , 'Xena' , 'Xarissa' , 'Xhosa' , 'Xylona' , 'Xenia' , 'Xexilia' , 'Xara' ] , [ 'Yvonne' , 'Yvette' , 'Yordana' , 'Yolanda' , 'Yoko' , 'Yedida' , 'Yara' , 'Yakira' , 'Yuna' , 'Yesenia' ]", "del_tokens": "[ 'Xenon' , 'Xerxes' , 'Xavier' , 'Xanto' , 'Xadrian' , 'Xenor' , 'Xorn' , 'Xylander' , 'Xylon' , 'Xenophon' , 'Xipil' , 'Xilxor' , 'Xhaiden' , 'Xelle' ] [ 'Xalvadora' , 'Xandra' , 'Xantara' , 'Xaria' , 'Xava' , 'Xeraphina' , 'Xia' , 'Ximena' , 'Xiomara' , 'Xyxa' , 'Xena' , 'Xarissa' , 'Xhosa' , 'Xylona' , 'Xenia' , 'Xexilia' , 'Xara' ]", "commit_type": "add"}
{"commit_tokens": ["fixed", "mockParentController", "when", "using", "super"], "add_tokens": "const controllerName = this . __controllerName || this . constructor . name ; const newContext = { state : internalState . value , component : context . component , __controllerName : context . constructor . name } ;", "del_tokens": "const controllerName = this . constructor . name ; const newContext = { state : internalState . value , component : context . component } ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "unique", "key", "to", "be", "based", "in", "UUID", "instead", "of", "name", "field"], "add_tokens": "const id = 'ed2d52a7-d8ff-4fdd-897a-7033dee598f4' ; id , const updatedServer = await servers . update ( serverToUpdate ) ; expect ( configAfter . servers . find ( srv => srv . id === id ) ) . to . eql ( serverToUpdate ) ; const createdServer = await servers . addOrUpdate ( newServer ) ; const id = 'ed2d52a7-d8ff-4fdd-897a-7033dee598f4' ; id , const updatedServer = await servers . addOrUpdate ( serverToUpdate ) ; expect ( configAfter . servers . find ( srv => srv . id === id ) ) . to . eql ( serverToUpdate ) ; await servers . removeById ( 'c94cbafa-8977-4142-9f34-c84d382d8731' ) ;", "del_tokens": "const currentName = 'mysql' ; const updatedServer = await servers . update ( currentName , serverToUpdate ) ; expect ( configAfter . servers . find ( srv => srv . name === 'mysql-vm' ) ) . to . eql ( serverToUpdate ) ; const createdServer = await servers . addOrUpdate ( null , newServer ) ; const currentName = 'mysql' ; const updatedServer = await servers . addOrUpdate ( currentName , serverToUpdate ) ; expect ( configAfter . servers . find ( srv => srv . name === 'mysql-vm' ) ) . to . eql ( serverToUpdate ) ; const currentName = 'pg-vm' ; await servers . removeByName ( currentName ) ;", "commit_type": "change"}
{"commit_tokens": ["Adding", "Expectation", "base", "class", "+", "Args", "expectation", "."], "add_tokens": "/ ** * Module dependencies . * / var util = require ( 'util' ) ; / ** * Expectation base . * * @ type { Function } * / var Expectation = require ( '../expectation' ) ; // `Args`. inhertis from `Expectation`. util . inherits ( Count , Expectation ) ;", "del_tokens": "/ ** * Returns an error message . * * @ param { String } Mode . * @ param { Object } Params . * @ returns { String } Error message . * @ api private * / Count . prototype . error = function ( message , params ) { var msg = this . messages [ message ] ; Object . keys ( params ) . forEach ( function ( param ) { msg = msg . replace ( ':' + param , params [ param ] ) ; } ) ; return msg ; } ;", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "not", "bundling", "on", "errors"], "add_tokens": "gWB ( './test/fixtures/@(foo|bar).js' , { gWB ( './test/fixtures/@(foo|bar).js' , { touch ( './test/fixtures/modules/hello.js' , { } , function ( ) { gWB ( './does/not/exist/**/*' , null , function ( ) { it ( 'should not bundle on errors' , function ( done ) { var streamsCount = 0 ; gWB ( './test/fixtures/baz.js' , null , function ( stream ) { return stream . pipe ( streamAssert . first ( function ( ) { streamsCount ++ ; } ) ) . pipe ( streamAssert . end ( ) ) ; } , function ( ) { assert . equal ( streamsCount , 0 ) ; done ( ) ; } ) ; } ) ;", "del_tokens": "gWB ( './test/fixtures/*.js' , { gWB ( './test/fixtures/*.js' , { touch ( './test/fixtures/modules/hello.js' , false , function ( ) { gWB ( './does/not/exist/**/*' , { } , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "prompt", "function", "."], "add_tokens": "// accept an array of prompts or a function that returns an array of prompts const prompts = typeof config . prompts === 'function' ? config . prompts ( this ) : config . prompts if ( ! prompts && prompts . length ) { const answers = await this . prompt ( prompts ) // transform the answers with the parse function if it exists // otherwise add to this.templateData as-is", "del_tokens": "if ( ! config . prompts && config . prompts . length ) { const answers = await this . prompt ( config . prompts )", "commit_type": "add"}
{"commit_tokens": ["Update", "css", "-", "purge", ".", "js"], "add_tokens": "if ( j < i && ( j - i ) > 1 ) { //check comparison distance if ( j < i && ( j - i ) > 1 ) { //check comparison distance if ( j < i && ( j - i ) > 1 ) { //check comparison distance if ( j < i && ( j - i ) > 1 ) { //check comparison distance", "del_tokens": "if ( ( j - i ) > 1 ) { //check comparison distance if ( ( j - i ) > 1 ) { //check comparison distance if ( ( j - i ) > 1 ) { //check comparison distance if ( ( j - i ) > 1 ) { //check comparison distance", "commit_type": "update"}
{"commit_tokens": ["use", "a", "better", "provider", "algorithm", "to", "ensure", "backward", "compabiliy"], "add_tokens": "var provider = null ; if ( req . query . useProvider ) provider = req . params . provider provider : provider req . session . logins [ state . provider || \"salesforce\" ] = sfRes . body ;", "del_tokens": "provider : req . params . provider req . session . logins [ \"salesforce\" ] = sfRes . body ; req . session . logins [ state . provider ] = sfRes . body ;", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "refreshKeys", "dict", "is", "updated"], "add_tokens": "refreshKeys [ key ] = { expiration : exp , lifeSpan : expiration , refresh : refresh } ; } ) ; }", "del_tokens": "refreshKeys [ key ] = { expiration : exp , lifeSpan : expiration , refresh : refresh } ; } ) ; }", "commit_type": "make"}
{"commit_tokens": ["adds", "or", "operator", "to", "match", "option"], "add_tokens": "let query = { $and : [ ] , $or : [ ] } // check for or operator if ( 'or' in options . match ) { for ( const key in options . match . or ) { let q = { } ; q [ key ] = options . match . or [ key ] ; query . $or . push ( q ) } } else { query . $and . push ( mapValues ( options . match , value => Array . isArray ( value ) ? { $in : value } : value ) ) } if ( ! query . $or . length ) delete query . $or if ( 'replace' in update && Object . keys ( update . replace ) . length )", "del_tokens": "let query = { $and : [ ] } query . $and . push ( mapValues ( options . match , value => Array . isArray ( value ) ? { $in : value } : value ) ) if ( 'replace' in update )", "commit_type": "add"}
{"commit_tokens": ["removing", "old", "reconnect", "as", "a", "dep", "for", "faster", "install", "times"], "add_tokens": "var reconnect = require ( 'reconnect-core' ) ;", "del_tokens": "var reconnect = require ( 'reconnect' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Change", "main", "namespace", "to", "Backbone", ".", "LocalStorage", "so", "it", "is", "more", "akin", "to", "the", "name", "of", "the", "library", "."], "add_tokens": "// window.Store is deprectated, use Backbone.LocalStorage instead Backbone . LocalStorage = window . Store = function ( name ) { _ . extend ( Backbone . LocalStorage . prototype , { // window.Store.sync is deprectated, use Backbone.LocalStorage.sync instead Backbone . LocalStorage . sync = window . Store . sync = Backbone . sync = function ( method , model , options , error ) {", "del_tokens": "window . Store = function ( name ) { _ . extend ( Store . prototype , { window . Store . sync = Backbone . sync = function ( method , model , options , error ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "SignaturePad#fromDataURL", "on", "HiDPI", "screens"], "add_tokens": "image = new Image ( ) , ratio = window . devicePixelWidth || 1 , width = this . _canvas . width / ratio , height = this . _canvas . height / ratio ; self . _ctx . drawImage ( image , 0 , 0 , width , height ) ;", "del_tokens": "image = new Image ( ) ; self . _ctx . drawImage ( image , 0 , 0 , self . _canvas . width , self . _canvas . height ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "files", "per", "schema", "and", "includes", "."], "add_tokens": "var files = SCHEMAS [ namespace ] ; if ( ! _ . isArray ( files ) ) { files = [ files ] ; } async . each ( files , function ( file , cb ) { var content = fs . readFileSync ( file , { encoding : 'utf-8' } ) ; xmlxsd2js . addSchema ( namespace , content , cb ) ; } , cb )", "del_tokens": "var content = fs . readFileSync ( SCHEMAS [ namespace ] , { encoding : 'utf-8' } ) ; xmlxsd2js . addSchema ( namespace , content , cb ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "emoji", "related", "error", "on", "Windows"], "add_tokens": "if ( typeof _icon !== \"string\" ) { , displayEmoji : deffy ( displayEmoji , ! isWin ( ) || ! _icon )", "del_tokens": "if ( ! _icon ) { , displayEmoji : deffy ( displayEmoji , ! isWin ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "statsd", "sink", "."], "add_tokens": "if ( ! statsdClients [ this . host + ':' + this . port ] ) { statsdClients [ this . host + ':' + this . port ] = new StatsD ( options ) ; this . client = statsdClients [ this . host + ':' + this . port ] ;", "del_tokens": "if ( ! statsdClients [ host + ':' + port ] ) { statsdClients [ host + ':' + port ] = new StatsD ( options ) ; this . client = statsdClients [ host + ':' + port ] ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "sync", "command", "for", "plural", "messages"], "add_tokens": "let isPlural = ! ! ( p4 && p5 && p6 ) let parts = [ this . escapeCharacter ( msgstr , quotes ) , p3 ] ; if ( isPlural ) { parts . push ( p4 , this . escapeCharacter ( msgstrPlural , quotes ) , p6 ) ; } return parts . join ( '' ) ;", "del_tokens": "return [ this . escapeCharacter ( msgstr , quotes ) , p3 , p4 , this . escapeCharacter ( msgstrPlural , quotes ) , p6 ] . join ( '' ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "opsHead", "to", "opsRe", "in", "lib", "/", "constrain", ".", "js", "for", "chaining"], "add_tokens": "var wOpsRe = genOpsRe ( wOps0 , wOps1 , wOps2 , wOpsHead ) var sOpsRe = genOpsRe ( sOps0 , sOpsHead ) var rOpsRe = genOpsRe ( rOps0 , rOpsHead ) // console.log(\"tailStr:\", tailStr, re) var legal = _ . prod ( _ . map ( fullSplit , cons . isLegalAtom ) ) ;", "del_tokens": "var wOpsRe = genOpsRe ( wOps0 , wOps1 , wOps2 ) var sOpsRe = genOpsRe ( sOps0 ) var rOpsRe = genOpsRe ( rOps0 ) var legal = _ . prod ( _ . map ( fullSplit , cons . isLegalAtom ) ) ; // console.log(\"tailStr:\", tailStr)", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "displaying", "color", "RGB", "images"], "add_tokens": "/*! cornerstone - v0.1.3 - 2014-04-16 | (c) 2014 Chris Hafey | https://github.com/chafey/cornerstone */ if ( image . color ) { cornerstone . storedColorPixelDataToCanvasImageData ( image , lut , renderCanvasData . data ) ; } else { cornerstone . storedPixelDataToCanvasImageData ( image , lut , renderCanvasData . data ) ; } function storedColorPixelDataToCanvasImageData ( image , lut , canvasImageDataData ) { var canvasImageDataIndex = 0 ; var storedPixelDataIndex = 0 ; var numPixels = image . width * image . height * 3 ; var storedPixelData = image . storedPixelData ; var localLut = lut ; var localCanvasImageDataData = canvasImageDataData ; while ( storedPixelDataIndex < numPixels ) { localCanvasImageDataData [ canvasImageDataIndex ++ ] = localLut [ storedPixelData [ storedPixelDataIndex ++ ] ] ; // red localCanvasImageDataData [ canvasImageDataIndex ++ ] = localLut [ storedPixelData [ storedPixelDataIndex ++ ] ] ; // green localCanvasImageDataData [ canvasImageDataIndex ++ ] = localLut [ storedPixelData [ storedPixelDataIndex ++ ] ] ; // blue canvasImageDataIndex ++ ; } } cornerstone . storedColorPixelDataToCanvasImageData = storedColorPixelDataToCanvasImageData ;", "del_tokens": "/*! cornerstone - v0.1.3 - 2014-04-13 | (c) 2014 Chris Hafey | https://github.com/chafey/cornerstone */ cornerstone . storedPixelDataToCanvasImageData ( image , lut , renderCanvasData . data ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "correct", "path", "of", "module", "utils", "-", "extend", "for", "tests"], "add_tokens": "var extend = require ( './_lib/utils-extend' ) ;", "del_tokens": "var extend = require ( '../lib/utils/extend' ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "getUid", "to", "work", "on", "mac", "but", "support", "only", "one", "runner", "at", "a", "time"], "add_tokens": "if ( Object . keys ( filters . specs ) . length > 0 ) { for ( const spec in filters . specs ) { for ( const testcase in parseResults . specs . specTable [ spec ] . testcases ) { filteredTestcases [ testcase ] = true ; } for ( const testcase in filters . testcases ) { if ( ! ( testcase in filteredTestcases ) ) { delete filters . testcases [ testcase ] ; }", "del_tokens": "for ( const spec in filters . specs ) { for ( const testcase in parseResults . specs . specTable [ spec ] . testcases ) { filteredTestcases [ testcase ] = true ; } for ( const testcase in filters . testcases ) { if ( ! ( testcase in filteredTestcases ) ) { delete filters . testcases [ testcase ] ;", "commit_type": "change"}
{"commit_tokens": ["Adding", "button", "to", "save", "view", "and", "make", "default"], "add_tokens": "$scope . saveView = function ( makeDefault ) { socket . emit ( \"addView\" , view , function ( err , view ) { return $scope . dialogError = err ; if ( makeDefault ) { socket . emit ( \"editPad\" , { defaultView : view . id } , function ( err ) { if ( err ) return $scope . dialogError = err ; $scope . saveViewName = null ; $scope . closeDialog ( ) ; } ) ; } else { $scope . saveViewName = null ; }", "del_tokens": "$scope . saveView = function ( ) { socket . emit ( \"addView\" , view , function ( err ) { $scope . dialogError = err ; else", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "for", "certain", "legacy", "items"], "add_tokens": "// Remove the resistance that some legacy items still have hardcoded in them. // They also have the agony infusions giving the actual resistance if ( item . rarity === 'Ascended' && details . type !== 'Default' ) {", "del_tokens": "// Legacy rings have agony infusion on them even if it has an agony infusion inserted if ( item . rarity === 'Ascended' && details . type === 'Ring' ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "custom", "updateSchemaCreators"], "add_tokens": "t . plan ( 11 ) ; const mastermind = createMastermind ( { store , updateSchemaCreators : testData . updaateSchemaCreators } ) 'createMastermind creates a mastermind object' 'updateIn and updateFunction work correctly' // test deleting using custom updateSchemaCreator mastermind . update ( 'deleteTodo' , 'randomId' ) t . ok ( ! store . getState ( ) . testBranch_1 . toJS ( ) . todos . randomId , 'custom updateSchemaCreator works' )", "del_tokens": "t . plan ( 10 ) ; const mastermind = createMastermind ( { store } ) 'createMastermind creates a mastermind function' 'updateFunction works correctly' console . log ( store . getState ( ) . testBranch_1 . toJS ( ) . todos . randomId . complete )", "commit_type": "add"}
{"commit_tokens": ["implemented", "isLeaf", "override", "function", "to", "customize", "selection", "of", "which", "node", "is", "displayed", "as", "a", "leaf", "and", "which", "node", "is", "displayed", "as", "a", "branch"], "add_tokens": "browsers : [ 'Chrome' ]", "del_tokens": "browsers : [ 'PhantomJS' ]", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "the", "updater", "it", "downloads", "and", "fetches", "commits", "from", "github", "."], "add_tokens": "args . package = fs . readFileSync ( args . string , 'utf8' ) ; this . package = JSON . parse ( args . package ) ; // the parsed file this . package . path = path . dirname ( args . string ) ; // folder of the bundle this . package . source = args . package ; // stringified content this . package . location = args . string ; // location of the bundle bundle . content = fs . readFileSync ( location , 'utf8' ) ; , self = this , backup ; if ( content ) backup = content ; else content = backup ;", "del_tokens": "this . package = JSON . parse ( fs . readFileSync ( args . string , 'utf8' ) ) ; this . package . path = path . dirname ( args . string ) ; bundle . content = fs . readFileSync ( location ) ; , self = this ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "bin", "scripts", "correctly", "in", "package", ".", "json", "."], "add_tokens": "// Generated automatically by nearley, version 2.11.1 function id ( x ) { return x [ 0 ] ; }", "del_tokens": "// Generated automatically by nearley function id ( x ) { return x [ 0 ] ; }", "commit_type": "use"}
{"commit_tokens": ["Add", "to", "ignore", "aria", "-", "generated", "attrs"], "add_tokens": "// ignore generated attributes ignoreAttributes : [ 'id' , 'for' , 'aria-labelledby' , 'aria-describedby' ] ,", "del_tokens": "ignoreAttributes : [ 'id' , 'for' ] ,", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "Travis", "testing", "task"], "add_tokens": "twitterLocal : { ] , options : { locally : true } } , twitterDistant : { urls : [ 'https://twitter.com' , 'https://twitter.com/tos' ] , failConditions : [ 'fail if at least one url has a global score < 70/100' ] , options : { locally : false }", "del_tokens": "twitter : { ]", "commit_type": "add"}
{"commit_tokens": ["Use", "element", ".", "closest", "()", "+", "polyfill", "Performance", "win", "."], "add_tokens": "src : [ 'src/polyfill.closest.legacy.js' , 'src/polyfill.getMatchedCSSRules.js' , 'node_modules/raf.js/raf.js' , 'src/polyfill.object-fit.core.js' ] , 'src/polyfill.closest.legacy.js' ,", "del_tokens": "src : [ 'src/polyfill.getMatchedCSSRules.js' , 'node_modules/raf.js/raf.js' , 'src/polyfill.object-fit.core.js' ] ,", "commit_type": "use"}
{"commit_tokens": ["Update", "jquery", "-", "scrolltofixed", ".", "js"], "add_tokens": "return ! ! $ ( el ) . data ( 'ScrollToFixed' ) ;", "del_tokens": "return $ ( el ) . data ( 'ScrollToFixed' ) !== undefined ;", "commit_type": "update"}
{"commit_tokens": ["Use", "npm", "-", "pack", "-", "dependents"], "add_tokens": "\"use strict\" const GetDependents = require ( 'npm-pack-dependents' ) , SameTime = require ( \"same-time\" ) , PackageJson = require ( \"package-json\" ) callback = version version = \"latest\" if ( err ) { return callback ( err ) } fn ( null , json ) fn ( err ) } ) } callback ( err , packages || [ ] ) } ) } ) module . exports = PackageDependents", "del_tokens": "// Dependencies var GetDependents = require ( 'npm-get-dependents' ) , SameTime = require ( \"same-time\" ) , PackageJson = require ( \"package-json\" ) ; callback = version ; version = \"latest\" ; if ( err ) { return callback ( err ) ; } fn ( null , json ) ; fn ( err ) ; } ) ; } ; callback ( err , packages || [ ] ) ; } ) ; } ) ; module . exports = PackageDependents ;", "commit_type": "use"}
{"commit_tokens": ["added", "transformerPlugin", "in", "vue", "-", "native", "-", "scripts", "which", "will", "transform", ".", "vue", "file", "to", ".", "js", "file"], "add_tokens": "module . exports . compileVueToRn = require ( './src/scripts/compiler.js' ) ; module . exports . transform = require ( './src/scripts/transformerPlugin.js' ) ;", "del_tokens": "module . exports = require ( './src/scripts/compiler.js' ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "lodash", "collection", "mixin", "instead", "of", "underscore", "collection", "mixin", "for", "better", "perf"], "add_tokens": "var lodashMixin = require ( 'ampersand-collection-lodash-mixin' ) ; conf , lodashMixin , restMixin", "del_tokens": "var underscoreMixin = require ( 'ampersand-collection-underscore-mixin' ) ; conf , underscoreMixin , restMixin", "commit_type": "use"}
{"commit_tokens": ["Add", "beautiful", "icons", "in", "reporter"], "add_tokens": "const figures = require ( 'figures' ) debug : figures . pointer , info : figures . info , warning : figures . warning , error : figures . cross , success : figures . tick const icon = chalk [ color ] ( symbol ) console . log ( ` ${ icon } ${ message } ` )", "del_tokens": "debug : '-' , info : 'i' , warning : '~' , error : '!' , success : '=' const icon = chalk [ color ] ( ` ${ symbol } ` ) console . log ( ` ${ icon } ${ message } ` )", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "getListings", "()"], "add_tokens": "describe ( 'Listing' , ( ) => { // console.log(`result: ${JSON.stringify(result, null, 2)}`) describe ( 'getListings()' , ( ) => { it ( 'should return an array of store listings' , async ( ) => { const listings = await ob . getListings ( config ) // console.log(`listings: ${JSON.stringify(listings, null, 2)}`) assert . isArray ( listings , 'Returns an array' ) } ) } )", "del_tokens": "describe ( 'Create Listing' , ( ) => { //console.log(`result: ${JSON.stringify(result, null, 2)}`)", "commit_type": "add"}
{"commit_tokens": ["adding", "the", "export", "installations", "method"], "add_tokens": "remove : remove , exporter : exporter / ** A function for exporting as JSON representation ( gzip ' @ param { string } variantId - The id of the variant @ returns { Promise } A promise that will resolve with the Array of installation objects @ example adminClient ( baseUrl , settings ) . then ( ( client ) => { client . installations . exporter ( variantId ) . then ( ( installations ) => { console . log ( installations ) // [{...},{...}, ...] } ) ; } ) ; * / function exporter ( client ) { return function exporter ( variantId ) { const req = { url : ` ${ client . baseUrl } ${ variantId } ` , method : 'GET' } ; return request ( client , req ) . then ( ( response ) => { // API says there is only a 200 response return Promise . resolve ( response . body ) ; } ) ; } ; }", "del_tokens": "remove : remove", "commit_type": "add"}
{"commit_tokens": ["Add", "flag", "option", "mask", "to", "allow", "for", "password", "field", "types"], "add_tokens": "type : current . type === Boolean ? 'confirm' : current . mask ? 'password' : 'input'", "del_tokens": "type : current . type === Boolean ? 'confirm' : 'input'", "commit_type": "add"}
{"commit_tokens": ["Added", "the", ".", "ipAddress", "attribute", "."], "add_tokens": "exports . mock_device_test = mock_device_test . tests ; // Passing exports . mock_device_defaults_cache_test = mock_device_defaults_cache_test . tests ; // Passing exports . mock_device_attrs_test = mock_device_attrs_test . tests ; // exports.t7_thermocouple_speed_test = t7_thermocouple_speed_test.tests;", "del_tokens": "// exports.mock_device_test = mock_device_test.tests; // Passing // exports.mock_device_defaults_cache_test = mock_device_defaults_cache_test.tests;// Passing // exports.mock_device_attrs_test = mock_device_attrs_test.tests; exports . t7_thermocouple_speed_test = t7_thermocouple_speed_test . tests ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "latest", "swagger", "-", "ui"], "add_tokens": "return string ; //.toLowerCase() // .replace(/(^|-)(\\w)/g, // function(s) { return s.toUpperCase(); });", "del_tokens": "return string . toLowerCase ( ) . replace ( / (^|-)(\\w) / g , function ( s ) { return s . toUpperCase ( ) ; } ) ;", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "new", "dev", "environment"], "add_tokens": "import isFunction from 'is-function' if ( ! isFunction ( promiseFunction ) ) {", "del_tokens": "if ( typeof promiseFunction !== 'function' ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "right", "click", "issues", "on", "Firefox"], "add_tokens": "elem = elem || document . documentElement ;", "del_tokens": "elem = elem || document ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "any", "characters", "in", "tag", "names", "used", "in", "selectors"], "add_tokens": "var parts = selector . match ( / [^\\s>]+|> / ig ) ;", "del_tokens": "var parts = selector . match ( / [a-z0-9\\:]+|> / ig ) ;", "commit_type": "allow"}
{"commit_tokens": ["Update", "express", "-", "handlebars", ".", "js"], "add_tokens": "defaultLayout : 'main' ,", "del_tokens": "defaultLayout : 'default' ,", "commit_type": "update"}
{"commit_tokens": ["updating", "lib", "to", "mirror", "change", "on", "the", "spec", "the", "7", "/", "20", "/", "2013"], "add_tokens": "run : true , log : true", "del_tokens": "run : true", "commit_type": "update"}
{"commit_tokens": ["Added", "jsdoc", "for", "findElement", "and", "protractor", ".", "By"], "add_tokens": "* @ see webdriver . WebDriver . findElement * @ returns { ! webdriver . WebElement } * @ see webdriver . WebDriver . findElements * @ return { ! webdriver . promise . Promise } A promise that will be resolved to an * array of the located { @ link webdriver . WebElement } s . * The Protractor Locator . * @ augments webdriver . Locator . Strategy / ** * @ type { ProtractorBy } * /", "del_tokens": "* See webdriver . WebDriver . findElement * * See webdriver . WebDriver . findElements * * Locators .", "commit_type": "add"}
{"commit_tokens": ["use", "MutationObserver", "for", "animate", "helper"], "add_tokens": "var hasMutationObserver = typeof MutationObserver !== 'undefined' var hasDocument = typeof document !== 'undefined' var observer // Trigger class addition after the element is inserted. if ( hasMutationObserver && hasDocument ) { observer = new MutationObserver ( function ( mutations ) { var i , j , k , l , mutation , addedNode for ( i = 0 , j = mutations . length ; i < j ; i ++ ) { mutation = mutations [ i ] for ( k = 0 , l = mutation . addedNodes . length ; k < l ; k ++ ) { addedNode = mutation . addedNodes [ k ] if ( addedNode === node ) { // Hack to trigger reflow. void node . offsetWidth node . classList . add ( insertClass ) observer . disconnect ( ) } } } } ) observer . observe ( document . documentElement , { childList : true , subtree : true } ) }", "del_tokens": "var hasRAF = typeof requestAnimationFrame === 'function' // Hack to trigger class addition after it is inserted. if ( hasRAF ) requestAnimationFrame ( function ( ) { node . classList . add ( insertClass ) } )", "commit_type": "use"}
{"commit_tokens": ["made", "ImapSimple", "an", "event", "emitter"], "add_tokens": "var util = require ( 'util' ) ; var EventEmitter = require ( 'events' ) . EventEmitter ; var self = this ; self . imap = imap ; // flag to determine whether we should suppress ECONNRESET from bubbling up to listener self . ending = false ; // pass most node-imap `Connection` events through 1:1 [ 'alert' , 'mail' , 'expunge' , 'uidvalidity' , 'update' , 'close' , 'end' ] . forEach ( function ( event ) { self . imap . on ( event , self . emit . bind ( self , event ) ) ; } ) ; // special handling for `error` event self . imap . on ( 'error' , function ( err ) { // if .end() has been called and an 'ECONNRESET' error is received, don't bubble if ( err && self . ending && ( err . code === 'ECONNRESET' ) ) { return ; } self . emit ( 'error' , err ) ; } ) ; util . inherits ( ImapSimple , EventEmitter ) ; // set state flag to suppress 'ECONNRESET' errors that are triggered when .end() is called. self . ending = true ; self . ending = false ;", "del_tokens": "this . imap = imap ; // We want to explicitly ignore 'ECONNRESET' errors when calling .end(), function ignoreECONNRESETErrorHandler ( err ) { if ( err && ( err . code === 'ECONNRESET' ) ) { return ; } throw err ; } self . imap . on ( 'error' , ignoreECONNRESETErrorHandler ) ; self . imap . removeListener ( 'error' , ignoreECONNRESETErrorHandler ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "test", "with", "fragment", "shorthand", "in", "function"], "add_tokens": "return { condition : true , condition2 : true } ; return { condition : true } ; return { condition : true } ; } , { code : ` const styles = StyleSheet . create ( { text : { } } ) const Hello = ( ) => ( < > < Text style = { styles . b } > Hello < / Text > < / > ) ; ` , errors : [ { message : 'Unused style detected: styles.text' , } ] ,", "del_tokens": "return { condition : true , condition2 : true } ; return { condition : true } ; return { condition : true } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "last", "piece", "of", "uncovered", "code", "(", "except", "polyfill", "methods", ")"], "add_tokens": "\"undefined\" : undefined , \"undefineds\" : { \"ONE\" : undefined , \"TWO\" : undefined , \"THREE\" : undefined }", "del_tokens": "\"undefined\" : undefined", "commit_type": "add"}
{"commit_tokens": ["Made", "cleanup", "do", ":", "end", "()", "destroy", "()", "and", "unref", "()"], "add_tokens": "client . end ( ) ; client . destroy ( ) ; client . unref ( ) ; cleanUp ( ) ;", "del_tokens": "client . end ( ) ; cleanUp ( ) ; cleanUp ( ) ; client . destroy ( ) ; client . unref ( ) ;", "commit_type": "make"}
{"commit_tokens": ["changed", "dir", "mode", "from", "775", "to", "0755"], "add_tokens": "mode : 0644 sftpConn . mkdir ( remotePath , { mode : 0755 } , function ( err ) {", "del_tokens": "mode : 755 sftpConn . mkdir ( remotePath , { mode : 775 } , function ( err ) {", "commit_type": "change"}
{"commit_tokens": ["Fixed", "pkgDeps", "/", "packages", "inconsistency", "and", "don", "t", "break", "when", "resolving", "a", "package", "that", "contains", "no", "file", "dependencies", "."], "add_tokens": "delete pkg . pkgDeps ; if ( pkg . packages && pkg . packages . length > 0 ) { pkg . packages . forEach ( function ( pkgTargetFileName ) { if ( ! urls . length ) { return cb ( null , assetConfigs ) ; }", "del_tokens": "if ( pkg . pkgDeps && pkg . pkgDeps . length > 0 ) { pkg . pkgDeps . forEach ( function ( pkgTargetFileName ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "to", "developer", "certificates", "not", "being", "entirely", "returned"], "add_tokens": "var exec = require ( \"child_process\" ) . exec ; . listen ( port , ( ) => { var url = ` ${ port } ` ; console . log ( ` ${ url } ` ) ; var cmd = path . join ( __dirname , \"xdg-open\" ) ; if ( process . platform === \"darwin\" ) cmd = \"open\" ; else if ( process . platform === \"win32\" ) cmd = ` ` ; exec ( ` ${ cmd } ${ url } ` ) ; } ) ;", "del_tokens": ". listen ( port , ( ) => console . log ( ` ${ port } ` ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "work", "with", "the", "vendors", "and", "will", "replace", "all", "if", "found"], "add_tokens": "buildInfo . vendors [ key ] = devBuildInfo . vendors [ key ] ;", "del_tokens": "if ( key != 'distributions' ) buildInfo . vendors [ key ] = devBuildInfo . vendors [ key ] ; } // vendor's distribution if ( devBuildInfo . vendors . distributions ) { for ( key in devBuildInfo . vendors . distributions ) { buildInfo . vendors . distributions [ key ] = devBuildInfo . vendors . distributions [ key ] ; }", "commit_type": "update"}
{"commit_tokens": ["Fix", "test", "for", "jshint", "add", "dist", "versions"], "add_tokens": "return 'string' === typeof a && ! ! ~ a . indexOf ( b ) ; return 'string' !== typeof a || ! ~ a . indexOf ( b ) ; return versionCompare ( a , b ) === 0 ;", "del_tokens": "return ! ! ~ a . indexOf ( b ) ; return ! ~ a . indexOf ( b ) ; return ! versionCompare ( a , b ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "basic", "support", "for", "redirect", "mode"], "add_tokens": "if ( self . isRedirect ( res . statusCode ) && options . redirect !== 'manual' ) { if ( options . redirect === 'error' ) { reject ( new FetchError ( 'redirect mode is set to error: ' + options . url , 'no-redirect' ) ) ; return ; } // normalize location header for manual redirect mode if ( options . redirect === 'manual' ) { headers . set ( 'location' , resolve_url ( options . url , headers . get ( 'location' ) ) ) ; }", "del_tokens": "if ( self . isRedirect ( res . statusCode ) ) {", "commit_type": "add"}
{"commit_tokens": ["Removed", "an", "unnecessary", "else", "block"], "add_tokens": "} if ( cacheEntry . loading ) {", "del_tokens": "} else if ( cacheEntry . loading ) {", "commit_type": "remove"}
{"commit_tokens": ["add", "type", "support", "and", "default", "type", "is", "xtpl"], "add_tokens": "cfg . type = cfg . type === 'tpl' ? 'tpl' : 'xtpl' ; if ( self . cfg . type === 'xtpl' || src . match ( / \\.xtpl\\.html$ / ) ) { if ( self . cfg . type === 'xtpl' || src . match ( / \\.xtpl\\.html$ / ) ) {", "del_tokens": "if ( src . match ( / \\.xtpl\\.html$ / ) ) { if ( src . match ( / \\.xtpl\\.html$ / ) ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "extensive", "basket", "test"], "add_tokens": "// Update + Enter + Exit div . call ( fruitBasket , [ { apples : [ \"Red Delicious\" , \"Honeycrisp\" , \"Granny Nice\" ] , oranges : [ \"Navel\" , \"Pomelo\" ] } , { oranges : [ \"Mandarin\" ] } ] ) ; test . equal ( div . html ( ) , [ \"<div>\" , '<span class=\"apple\">Red Delicious</span>' , '<span class=\"apple\">Honeycrisp</span>' , '<span class=\"orange\">Navel</span>' , '<span class=\"orange\">Pomelo</span>' , '<span class=\"apple\">Granny Nice</span>' , \"</div>\" , \"<div>\" , '<span class=\"orange\">Mandarin</span>' , \"</div>\" ] . join ( \"\" ) ) ; / ************************************* ** ** ** ** ** ** Utilities ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * / function createDiv ( ) { return d3 . select ( jsdom . jsdom ( ) . body ) . append ( \"div\" ) ; }", "del_tokens": "/ ************************************* ** ** ** ** ** ** Utilities ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * / function createDiv ( ) { return d3 . select ( jsdom . jsdom ( ) . body ) . append ( \"div\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "measurement", "regex", "s", "to", "allow", "for", "multiple", "digits", "before", "decimal", "point"], "add_tokens": "var lengthRegEx = / ^(0|[\\-+]?[0-9]*\\.?[0-9]+(in|cm|em|mm|pt|pc|px))$ / ; var percentRegEx = / ^[\\-+]?[0-9]*\\.?[0-9]+%$ / ; var angleRegEx = / ^([\\-+]?[0-9]*\\.?[0-9]+)(deg|grad|rad)$ / ;", "del_tokens": "var lengthRegEx = / ^(0|[\\-+]?[0-9]?\\.?[0-9]+(in|cm|em|mm|pt|pc|px))$ / ; var percentRegEx = / ^[\\-+]?[0-9]?\\.?[0-9]+%$ / ; var angleRegEx = / ^([\\-+]?[0-9]?\\.?[0-9]+)(deg|grad|rad)$ / ;", "commit_type": "fix"}
{"commit_tokens": ["add", "methodsfor", "set", "bounds", "and", "clear", "background"], "add_tokens": "} , setBounds : function ( axisIndex , range ) { this . bounds [ 0 ] [ axisIndex ] = range . min this . bounds [ 1 ] [ axisIndex ] = range . max } , setClearColor : function ( clearColor ) { this . clearColor = clearColor } , clearRGBA : function ( ) { this . gl . clearColor ( this . clearColor [ 0 ] , this . clearColor [ 1 ] , this . clearColor [ 2 ] , this . clearColor [ 3 ] ) this . gl . clear ( this . gl . COLOR_BUFFER_BIT | this . gl . DEPTH_BUFFER_BIT ) scene . clearRGBA ( )", "del_tokens": "var clearColor = scene . clearColor gl . clearColor ( clearColor [ 0 ] , clearColor [ 1 ] , clearColor [ 2 ] , clearColor [ 3 ] ) gl . clear ( gl . COLOR_BUFFER_BIT | gl . DEPTH_BUFFER_BIT )", "commit_type": "add"}
{"commit_tokens": ["Adding", "bower", "base", "path", "in", "gulp", "file"], "add_tokens": "// Defining base pathes var basePaths = { bower : './bower_components/' } ; // Defining requirements gulp . src ( basePaths . bower + 'bootstrap-sass/assets/javascripts/*.js' ) gulp . src ( basePaths . bower + 'bootstrap-sass/assets/fonts/bootstrap/*.{ttf,woff,eof,svg}' ) gulp . src ( basePaths . bower + 'fontawesome/fonts/**/*.{ttf,woff,eof,svg}' ) gulp . src ( basePaths . bower + 'jquery/dist/*.js' ) gulp . src ( basePaths . bower + '_s/js/*.js' )", "del_tokens": "gulp . src ( './bower_components/bootstrap-sass/assets/javascripts/*.js' ) gulp . src ( './bower_components/bootstrap-sass/assets/fonts/bootstrap/*.{ttf,woff,eof,svg}' ) gulp . src ( './bower_components/fontawesome/fonts/**/*.{ttf,woff,eof,svg}' ) gulp . src ( './bower_components/jquery/dist/*.js' ) gulp . src ( './bower_components/_s/js/*.js' )", "commit_type": "add"}
{"commit_tokens": ["Add", "parameter", "binding", "for", "DELETE", "queries", "."], "add_tokens": "this . bindValuesInSearchCondition ( ) ;", "del_tokens": "goog . require ( 'lf.pred.ValuePredicate' ) ; var searchCondition = /** @type {?lf.pred.PredicateNode} */ ( this . query . where ) ; if ( goog . isDefAndNotNull ( searchCondition ) ) { searchCondition . traverse ( function ( node ) { if ( node instanceof lf . pred . ValuePredicate ) { node . bind ( this . boundValues ) ; } } , this ) ; }", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", "added", "template", "file"], "add_tokens": "// checks to see if a .jsproj file exists in the project root", "del_tokens": "// checks to see if a .csproj file exists in the project root", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "custom", "tsconfig", "option", "to", "the", "plugin"], "add_tokens": "function parseTsConfig ( tsconfig , context ) { var fileName = ts . findConfigFile ( process . cwd ( ) , ts . sys . fileExists , tsconfig ) ; throw new Error ( \"couldn't find '\" + tsconfig + \"' in \" + process . cwd ( ) ) ; tsconfig : \"tsconfig.json\" var parsedConfig = parseTsConfig ( options . tsconfig , context ) ;", "del_tokens": "function parseTsConfig ( context ) { var fileName = ts . findConfigFile ( process . cwd ( ) , ts . sys . fileExists , \"tsconfig.json\" ) ; throw new Error ( \"couldn't find 'tsconfig.json' in \" + process . cwd ( ) ) ; var parsedConfig = parseTsConfig ( context ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "better", "examples", "to", "static", "and", "prototype", "types", "."], "add_tokens": "* $ . Controller . extend ( 'Cookbook.Controllers.Recipe' , * / * @Static *| * { * onDocument : true * } , * / * @Prototype *| * { * / ** * * When the page loads , gets all recipes to be displayed . * * | * load : function ( ) { * if ( ! $ ( \"#recipe\" ) . length ) * $ ( document . body ) . append ( $ ( '&lt;div/&gt;' ) . attr ( 'id' , 'recipe' ) ) * Cookbook . Models . Recipe . findAll ( { } , this . callback ( 'list' ) ) ; * } , * ...", "del_tokens": "* / * prototype *|", "commit_type": "add"}
{"commit_tokens": ["Fixing", "functions", "deployment", "issue", "from", "Windows"], "add_tokens": "// KUBECONFIG paths list is semicolon delimited for Windows // and colon delimited for Mac and Linux let kubeConfigDelimiter ; if ( process . platform === 'win32' ) { kubeConfigDelimiter = ';' ; } else { kubeConfigDelimiter = ':' ; } const configFiles = process . env . KUBECONFIG . split ( kubeConfigDelimiter ) ;", "del_tokens": "const configFiles = process . env . KUBECONFIG . split ( ':' ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "month", "/", "year", "setters", "to", "keep", "on", "the", "right", "month"], "add_tokens": "return this . offset ( ) > this . month ( 1 ) . offset ( ) || this . offset ( ) > this . month ( 5 ) . offset ( ) ; // if we didn't set the day but we ended up on an overflow date, // use the last day of the right month if ( Util . isUndefined ( normalized . day ) ) { mixed . day = Math . min ( Util . daysInMonth ( mixed . year , mixed . month ) , mixed . day ) ; }", "del_tokens": "return this . offset ( ) > this . month ( 0 ) . offset ( ) || this . offset ( ) > this . month ( 5 ) . offset ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "layer", "copying", "during", "order", "phase"], "add_tokens": "improveLayer ( i , layering [ j - 1 ] , layering [ j ] , \"inEdges\" ) ; improveLayer ( i , layering [ j + 1 ] , layering [ j ] , \"outEdges\" ) ; function improveLayer ( i , fixed , movable , neighbors ) { function copyLayering ( layering ) { return layering . map ( function ( l ) { return l . slice ( 0 ) ; } ) ; } var bestLayering = copyLayering ( layering ) ; improveOrdering ( i , layering ) ; bestLayering = copyLayering ( layering ) ;", "del_tokens": "layering = layering . slice ( 0 ) ; improveRank ( layering [ j - 1 ] , layering [ j ] , \"inEdges\" ) ; improveRank ( layering [ j + 1 ] , layering [ j ] , \"outEdges\" ) ; return layering ; function improveRank ( fixed , movable , neighbors ) { var bestLayering = layering ; layering = improveOrdering ( i , layering ) ; bestLayering = layering ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "environment", "variable", "to", "set", "log", "level"], "add_tokens": "level : process . env . SFX_CLIENT_LOG_LEVEL || 'info' ,", "del_tokens": "level : 'info' ,", "commit_type": "add"}
{"commit_tokens": ["use", "readdirSync", "no", "need", "for", "filter", "-", "files"], "add_tokens": "module . exports = function ( dir ) { fs . readdirSync ( dir ) . forEach ( function ( name ) {", "del_tokens": "var files = require ( 'filter-files' ) ; module . exports = function ( dir , recurse ) { files . sync ( dir , recurse ) . forEach ( function ( name ) {", "commit_type": "use"}
{"commit_tokens": ["Implemented", "/", "el", ";", "ement", "/", "_", "/", "displayed", "GET", "command", "."], "add_tokens": "// Need to check for undefined to prevent errors when trying to return boolean false if ( typeof ( value ) === \"undefined\" ) value = { } ; \"value\" : value", "del_tokens": "\"value\" : value || { }", "commit_type": "implement"}
{"commit_tokens": ["fix", "signatures", "for", "same", "address", "utxos"], "add_tokens": "var signatures = _ . map ( privs , function ( priv , i ) { return _ . find ( t . getSignatures ( priv ) , { inputIndex : i } ) . signature . toDER ( ) . toString ( 'hex' ) ;", "del_tokens": "var signatures = [ ] ; _ . each ( privs , function ( p ) { var s = t . getSignatures ( p ) [ 0 ] . signature . toDER ( ) . toString ( 'hex' ) ; signatures . push ( s ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "example", "use", "assets", "-", "images", "plugin"], "add_tokens": "require . resolve ( 'roc-plugin-browsersync' ) , require . resolve ( 'roc-plugin-assets-images' )", "del_tokens": "require . resolve ( 'roc-plugin-browsersync' )", "commit_type": "make"}
{"commit_tokens": ["Implemented", "maintenance", "()", "for", "kubernetes", "driver"], "add_tokens": "return callback ( null , { result : false , ts : new Date ( ) . getTime ( ) , error : { msg : 'Unable to get the ip address of the container' } } ) ;", "del_tokens": "return callback ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["removed", "cruft", "tested", "sort", "-", "tree", "-", "by", "-", "types"], "add_tokens": "module . exports . sortTreeByTypes = function ( ) {", "del_tokens": ", getLocalRequires = require ( './get-module-dependencies' ) module . exports . sortDependencies = function ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "typo", "static", "msg", "content", "c&p", "from", "button", "widget", "view", "."], "add_tokens": "this . model . send ( content , this . cell ) ;", "del_tokens": "this . model . send ( { event : 'click' } , this . cell ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "molecule", "creation", "from", "idCode"], "add_tokens": "if ( moleculeInfo . value ) molecule = Molecule . fromIDCode ( moleculeInfo . value ) ; molecule = Molecule . fromIDCode ( moleculeInfo . idCode ) ; molecule = Molecule . fromIDCode ( moleculeInfo . oclCode ) ;", "del_tokens": "if ( moleculeInfo . value ) molecule = Molecule . fromMolfile ( moleculeInfo . value ) ; molecule = Molecule . fromMolfile ( moleculeInfo . idCode ) ; molecule = Molecule . fromMolfile ( moleculeInfo . oclCode ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "for", "duration", "failing", "appropriately"], "add_tokens": "throw \"no options provided, some are required\" ; // XXX rename opts? // defaults opts . cookieName = opts . cookieName || \"session_state\" ; opts . duration = opts . duration || 24 * 60 * 60 * 1000 ;", "del_tokens": "throw \"no options provided, some are required\" ; opts . cookieName = opts . cookieName || \"session\" ;", "commit_type": "add"}
{"commit_tokens": ["Update", "Cesium", "and", "fix", "time", "control", "hiding", "."], "add_tokens": "$ ( '.cesium-viewer-animationContainer' ) . css ( 'visibility' , 'visible' ) ; $ ( '.cesium-viewer-timelineContainer' ) . css ( 'visibility' , 'visible' ) ; if ( defined ( viewer ) ) { viewer . forceResize ( ) ; } $ ( '.cesium-viewer-animationContainer' ) . css ( 'visibility' , 'hidden' ) ; $ ( '.cesium-viewer-timelineContainer' ) . css ( 'visibility' , 'hidden' ) ; viewer . forceResize ( ) ;", "del_tokens": "viewer . showTimeControls = true ; viewer . showTimeControls = false ;", "commit_type": "update"}
{"commit_tokens": ["Removing", "use", "of", "String", ".", "startsWith"], "add_tokens": "return element . indexOf ( \"[\" ) === 0 ? whereMatcher ( element ) : pathMatcher ( element ) ;", "del_tokens": "return element . startsWith ( \"[\" ) ? whereMatcher ( element ) : pathMatcher ( element ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "naming", "convention", "in", "REPL"], "add_tokens": "var Chrome = require ( '../' ) ; Chrome ( function ( chrome ) {", "del_tokens": "var ChromeInterface = require ( '../' ) ; ChromeInterface ( function ( chrome ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "test", "fixtures", "fix", "typos"], "add_tokens": "//Loop through entire json object", "del_tokens": "//FLoop through entire json object", "commit_type": "add"}
{"commit_tokens": ["fix", "initializing", "with", "a", "host", "string"], "add_tokens": "if ( typeof ( host ) == \"string\" ) {", "del_tokens": "if ( typeof ( address ) == \"string\" ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "linting", "issues", "with", "vr", "-", "text"], "add_tokens": "map : texture // ,color: '#00B000', wireframe: true", "del_tokens": "map : texture , //color: '#00B000', //wireframe: true,", "commit_type": "fix"}
{"commit_tokens": ["updating", "unit", "tests", "and", "jsdocs"], "add_tokens": "/ ** * Shows a warning or error message . Used to indicate a method * has been depricated and what to use instead . * @ function depreciated * @ param { string } method The name of the method being depricated . * @ param { boolean } error Throws an error if called when true . * @ param { string } message Instructions on what to use instead of the depricated method . * / if ( error ) { var err = new Error ( msg ) ; err . name = 'JSCAD_UTILS_DEPRECATED' ; throw err ; }", "del_tokens": "if ( error ) throw new Error ( msg ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "ident", "to", "def", "defn", "and", "ns", "following", "@fasterthanlime", "s", "suggestion"], "add_tokens": "rule { ( ns $ns : ident $sexprs . . . ) } => { rule { ( ns_get $ns : ident $x ) } => { rule { ( def $n : ident $sexpr ) } => { rule { ( defn $n : ident [ $args . . . ] $sexprs . . . ) } => { rule { ( defn $n : ident ( [ $args . . . ] $sexprs . . . ) $rest . . . ) } => { rule { ( defmulti $n : ident $dispatch_fn ) } => { rule { ( defmethod $n : ident $dispatch_val [ $args . . . ] $sexprs . . . ) } => {", "del_tokens": "rule { ( ns $ns $sexprs . . . ) } => { rule { ( ns_get $ns $x ) } => { rule { ( def $n $sexpr ) } => { rule { ( defn $n [ $args . . . ] $sexprs . . . ) } => { rule { ( defn $n ( [ $args . . . ] $sexprs . . . ) $rest . . . ) } => { rule { ( defmulti $n $dispatch_fn ) } => { rule { ( defmethod $n $dispatch_val [ $args . . . ] $sexprs . . . ) } => {", "commit_type": "add"}
{"commit_tokens": ["moved", "test", "components", "and", "entity", "templates", "out", "into"], "add_tokens": "var components = JSON . parse ( fs . readFileSync ( Common . pathFixture ( 'components.json' ) ) ) ; var entityTemplates = JSON . parse ( fs . readFileSync ( Common . pathFixture ( 'entity_templates.json' ) ) ) ; self . registry . registerEntityTemplate ( entityTemplates , cb ) ;", "del_tokens": "var components = [ { \"id\" : \"/component/es_a\" , \"properties\" : { \"name\" : { \"type\" : \"string\" } } } , { \"id\" : \"/component/es_b\" , \"properties\" : { \"is_active\" : { \"type\" : \"boolean\" } } } , { \"id\" : \"/component/es_c\" , \"properties\" : { \"age\" : { \"type\" : \"integer\" } } } ] ; var entityTemplate = { \"id\" : \"/entity_template/a\" , \"type\" : \"object\" , \"properties\" : { \"a\" : { \"$ref\" : \"/component/es_a\" } , \"c\" : { \"$ref\" : \"/component/es_c\" } , } } ; self . registry . registerEntityTemplate ( entityTemplate , cb ) ;", "commit_type": "move"}
{"commit_tokens": ["Change", "scroll", "zoom", "math", "to", "be", "more", "stable", "."], "add_tokens": "var rate = 0.2 ; delta *= rate ; delta += 1 ;", "del_tokens": "delta = delta > 0 ? delta + zoomRate : Math . abs ( delta ) - zoomRate ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "error", "in", "IE8", "-", "for", "empty", "elements"], "add_tokens": "} ( this ) )", "del_tokens": "} ( this ) ) var elements = document . getElementsByTagName ( 'textarea' ) Countable . live ( elements , function ( counter ) { console . log ( counter ) } ) Countable . die ( elements [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "against", "keys", "not", "found"], "add_tokens": "it ( 'warns user when keys are not found' , function ( done ) { // Run doubleshot against unused keys files var cmd = doubleshot + ' --content test/test_files/keys_not_found/content.js --outline test/test_files/keys_not_found/outline.json' ; exec ( cmd , function handleDblKeysNotFound ( err , stdout , stderr ) { // If there is an error, callback if ( err ) { return done ( err ) ; } // Assert stderr contains info about failing items expect ( stderr ) . to . contain ( 'equals two' ) ; expect ( stderr ) . to . match ( / not .* found / ) ; // Callback done ( ) ; } ) ;", "del_tokens": "it ( 'warns user when keys are not found' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "readyState", "to", "XHR", "getter", "/", "setter"], "add_tokens": "[ \"response\" , \"responseText\" , \"responseType\" , \"responseURL\" , \"status\" , \"statusText\" , \"readyState\" ] . forEach ( function ( prop ) { module . exports = can . fixture ;", "del_tokens": "[ \"response\" , \"responseText\" , \"responseType\" , \"responseURL\" , \"status\" , \"statusText\" ] . forEach ( function ( prop ) { module . exports = can . fixture ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "the", "ability", "to", "properly", "map", "an", "iterative", "object", "as", "tested", "in", "the", "newly", "added", "case", "14", "."], "add_tokens": "var v = data [ mappings [ ii ] . dataKey ] ; newdata = isArray ( v ) ? that . iterate ( html , v , components , tagname , value ) : tagbody + ( typeof v === 'object' ? that . iterate ( html , v , components , tagname , value ) : newdata ) ; buffer += newdata || '' ;", "del_tokens": "buffer += tagbody + ( newdata || '' ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "instances", "of", "preset", "usage"], "add_tokens": ". babel ( { stage : 0 , sourceMaps : true } )", "del_tokens": ". babel ( { presets : [ \"es2015\" ] , sourceMaps : true } )", "commit_type": "remove"}
{"commit_tokens": ["Add", "bitwise", "operators", ";", "move", ".", "member", "references", "to", "Identifiers"], "add_tokens": "* [ _deref_call , _deref_this where this = 3 ]", "del_tokens": "* [ operators [ '()' ] , function ( ) { return a [ 3 ] } ]", "commit_type": "add"}
{"commit_tokens": ["Added", "colors", "for", "tests", "into", "visualiser", "."], "add_tokens": "www = require ( './visualiser/www' ) ,", "del_tokens": "www = require ( '../lib/www' ) ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "drag", "-", "and", "-", "drop", "in", "firefox"], "add_tokens": "var effect = e . dataTransfer . effectAllowed ; if ( effect == 'move' || effect == 'linkMove' ) { e . dataTransfer . dropEffect = 'move' ; // for FF (only move allowed) } else { e . dataTransfer . dropEffect = 'copy' ; // for Chrome }", "del_tokens": "e . dataTransfer . dropEffect = 'copy' ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "HTTP", "schema", "finding", "error"], "add_tokens": "let schema try { schema = require ( path . join ( process . cwd ( ) , options . schema ) ) } catch ( e ) { if ( ! flags . baseUrl ) throw e }", "del_tokens": "const schema = require ( path . join ( process . cwd ( ) , options . schema ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "some", "tests", "for", "indent"], "add_tokens": "import { fixtures , testWithHistory , createEvent } from \"../../../support/test-helpers\" ; fixtures ( __dirname , \"queries\" , ( { module } ) => { const { input , output , options = { } , default : fn } = module ; const editor = new Editor ( { value : input , plugins } ) ; expect ( output ) . toEqual ( fn ( editor ) ) ; } ) ; fixtures ( __dirname , \"onKeydown\" , ( { module } ) => { const { input , output , options = { } , default : fn } = module ; const editor = new Editor ( { plugins } ) ; const opts = { preserveSelection : true , ... options } ; testWithHistory ( input , output , editor , opts , fn , createEvent ) ; } ) ;", "del_tokens": "import { fixtures , testWithHistory } from \"../../../support/test-helpers\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "SVG", "issues", "in", "IE"], "add_tokens": "/* global HTMLDocument */ // Handle SVG <use> elements in IE if ( target . correspondingUseElement ) { target = target . correspondingUseElement ; } // Fall back to parentNode since SVG children have no parentElement in IE target = target . parentElement || target . parentNode ; // Do not traverse up to document root when using parentNode, though if ( target instanceof HTMLDocument ) { break ; }", "del_tokens": "target = target . parentElement ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "SVG", "drawing", "(", "createShape", ")", "support", ".", "Wow", ".", "Such", "Drawing", ".", "God", "like", "danmaku", "23333"], "add_tokens": "} ; } ; var fn = BASE_URL + scriptname ; importScripts ( fn ) ; } ;", "del_tokens": "} } importScripts ( BASE_URL + scriptname ) ; }", "commit_type": "add"}
{"commit_tokens": ["fix", "linting", "issue", "and", "make", "eslint", "a", "local", "dev", "dependency"], "add_tokens": "` Android Debug Bridge version 1.0 .39 Version 0.0 .1 - 4500957 Installed as / Users / XXX / Library / Android / sdk / platform - tools / adb `", "del_tokens": "\"Android Debug Bridge version 1.0.39\\nVersion 0.0.1-4500957\\nInstalled as /Users/XXX/Library/Android/sdk/platform-tools/adb\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "HEAD", "via", "GET", "test"], "add_tokens": ". head ( '/pet/123' ) . expect ( 200 )", "del_tokens": ". put ( '/pet/123' ) . expect ( 405 )", "commit_type": "fix"}
{"commit_tokens": ["Improved", "logging", "a", "tiny", "bit"], "add_tokens": "const err = new Error ( 'Slug: \"' + data . slug + '\" is used by another image entry, try setting another one manually.' ) ; log . verbose ( logPrefix + err . message ) ; return cb ( err ) ;", "del_tokens": "return cb ( new Error ( 'Slug is used by another image entry, try setting another one manually.' ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "validation", "when", "supplying", "value", "to", "validate", "()"], "add_tokens": "return this . validator . validate ( value ) ;", "del_tokens": "return this . validator . validate ( arguments [ 1 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "test", "and", "wording", "of", "warning", "."], "add_tokens": "const nonBuildBranch = ` ${ skipPrefix } ${ TRAVIS_BRANCH } `", "del_tokens": "const nonBuildBranch = ` ${ skipPrefix } ${ TRAVIS_BRANCH } `", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "unit", "test", "for", "worker", "timeouts", ".", "Set", "the", "timeout", "used", "in", "the"], "add_tokens": "} , timeout : 1 it ( 'respects the timeout option' , function ( ) { var opts = { id : 'testworker' , host : 'example.com' , port : 3000 , timeout : 20 } ; var w = new fivebeans . worker ( opts ) ; w . timeout . should . equal ( 20 ) ; } ) ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["fixed", "process", ".", "getVersion", "()"], "add_tokens": "setPath ( 'node' , _ ( process . argv [ 0 ] ) ) ; var str = fs . readFileSync ( _ ( bundlesPath + '/' + bundle + '/config/app.json' ) ) . toString ( ) ; var version = JSON . parse ( str ) . version ; return version ;", "del_tokens": "return gna . getConfig ( 'app' ) . version ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "parse", "function", "in", "yogini", "file", "."], "add_tokens": "const id = x => x ... ( this . yoginiFile . parse ?? id ) ( answers ) ,", "del_tokens": "... answers ,", "commit_type": "add"}
{"commit_tokens": ["Improve", "documentation", "of", "the", "error", "submodule"], "add_tokens": "* @ returns true if token fulfills said requirements , false otherwise * @ returns promise , which fulfills to decoded token , or rejects with auth related error reject ( new Error ( '403' , 'Forbidden' ) ) ;", "del_tokens": "reject ( Error ( '403' , 'Forbidden' ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Remove", "pattern", "matching", "array", "decomposition", "to", "support", "node", "v5", ".", "x"], "add_tokens": "lhs = theRule . split ( '->' ) . map ( ( side ) => side . trim ( ) ) ; rhs = lhs [ 1 ] ; lhs = lhs [ 0 ] ;", "del_tokens": "[ lhs , rhs ] = theRule . split ( '->' ) . map ( ( side ) => side . trim ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Improved", "by", "far", "the", "logic", "of", "js", "-", "protocols", "-", "babylon", "-", "now", "we", "re", "working", "with", "the", "AST", "as", "we", "should"], "add_tokens": "code = code . replace ( / \\.\\*\\[ / g , '._jsProtocol[' ) . replace ( / \\.\\* / g , '._jsProtocol.' ) . replace ( / use\\s+protocols\\s+from / mg , '_jsProtocolProvider:' ) ; return babylon . parse ( code , options ) ;", "del_tokens": "const protofy = require ( './bin/protofy' ) ; return babylon . parse ( protofy . processString ( code ) , options ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "uglification", "with", "source", "maps", "of", "dist", "files"], "add_tokens": "gruntConfig . uglify . dist . files [ 0 ] . rename = function ( dest , src ) { return dest + src . replace ( '.js' , '.min.js' ) ; } ; grunt . loadNpmTasks ( 'grunt-contrib-uglify' ) ; grunt . loadNpmTasks ( 'grunt-contrib-clean' ) ; grunt . registerTask ( 'build-dist' , [ 'clean' , 'concat' , 'wrap' , 'jshint' , 'uglify' ] ) ; grunt . registerTask ( 'test' , [ 'build-dist' , 'jasmine' ] ) ; grunt . registerTask ( 'default' , [ 'test' ] ) ;", "del_tokens": "grunt . registerTask ( 'default' , [ 'concat' , 'wrap' , 'jshint' , 'jasmine' ] ) ; grunt . registerTask ( 'test' , [ 'concat' , 'wrap' , 'jshint' , 'jasmine' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "reload", "via", "setOption", "(", "source", "...", ")"], "add_tokens": "* * @ param { function | string } filter * @ lends Dynatree . prototype * @ requires jquery . dynatree . filter . js this . $div . addClass ( \"dynatree-ext-filter\" ) ; * Reset the filter . * @ lends Dynatree . prototype * @ requires jquery . dynatree . filter . js this . $div . removeClass ( \"dynatree-ext-filter\" ) ; // Override virtual methods for this extension.", "del_tokens": "* @ param { function | string | false } filter this . $div . addClass ( \"dynatree-filter\" ) ; this . $div . removeClass ( \"dynatree-filter\" ) ; // Overide virtual methods for this extension.", "commit_type": "allow"}
{"commit_tokens": ["Make", "english", "and", "romanized", "languages", "the", "fallback", "of", "only", "Latin", "languages"], "add_tokens": "} ) . filter ( code => code !== this . langCode ) ; // 5. If we requested a language that is in Latin script // let's try to latinize the content. We only do that if // the requested language is Latin already; Otherwise // we want to fallback to the local script instead of // assuming latinization is expected if ( this . langScript === 'Latn' ) { // 5. Look for known latinized codes // - Suffix of -rm // - Code 'zh_pinyin' // Romanized or Chinese Pinyin if ( langCode . endsWith ( '_rm' ) || langCode === 'zh_pinyin' ) {", "del_tokens": "} ) ; // 5. English result = values [ this . prefixedEnglish ] ; if ( result ) { return result ; } // 6. Any language with suffix 'Latn' // Only do this if the script isn't already latin; // otherwise, we've done it in step 3 if ( this . langScript !== 'Latn' ) { // Latin or Romanized if ( langCode . endsWith ( '-Latn' ) ) { // 7. Look for known latinized codes // - Suffix of -rm // - Code 'zh_pinyin' for ( const langCode of valueLangCodes ) { // Romanized or Chinese Pinyin if ( langCode . endsWith ( '_rm' ) || langCode === 'zh_pinyin' ) { return values [ langCode ] ; } }", "commit_type": "make"}
{"commit_tokens": ["Fixed", "the", "identity", "module", "to", "directly", "integrate", "with", "the", "db", "modules", "."], "add_tokens": "db = require ( '../db' ) , db . tokens . getById ( kontx . token ) . then ( function ( token ) { db . users . getById ( token . uid ) . then ( function ( identity ) { kontx . user = identity ; next ( ) ; } ) . fail ( function ( err ) { next ( err ) ; } ) ; } ) . fail ( function ( err ) {", "del_tokens": "tokens = require ( '../entities/tokens' ) , tokens . validate ( kontx . token ) . then ( function ( identity ) { kontx . user = identity ; next ( ) ; } ) . fail ( function ( err ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "outerWidth", "()", "for", "height", "calculation", "."], "add_tokens": "width : element . outerWidth ( ) , } ( ) ) ;", "del_tokens": "width : element . width ( ) , } ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "promise", "await", "to", "redis", "init", "on", "startup"], "add_tokens": "var _initApplication = async function ( ) { var redis = await Shared . redis ( true ) ;", "del_tokens": "var _initApplication = function ( ) { var redis = Shared . redis ( true ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "gulp", "combine", "Cesium", "."], "add_tokens": "return exec ( '\"Tools/apache-ant-1.8.2/bin/ant\" build combine' , { gulp . task ( 'default' , [ 'build-cesium' , 'scripts' , 'docs' ] , function ( ) {", "del_tokens": "return exec ( '\"Tools/apache-ant-1.8.2/bin/ant\" build' , { gulp . task ( 'default' , function ( ) { gulp . run ( 'build-cesium' , 'scripts' , 'docs' ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "cwd", "argument", "to", "utils", ".", "exec", "()", "."], "add_tokens": "* Execute a child process with the current working * directory set to the target by default ; optionally * pass a relative path to set the current working * directory . this . exec = function ( cmd , cwd ) { var wd = cwd ? path . resolve ( target , cwd ) : target ; return exec ( cmd , { cwd : wd } ) ;", "del_tokens": "* Execute a child process , with the current working * directory set to the target . this . exec = function ( cmd ) { return exec ( cmd , { cwd : target } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "logger", "verbosity", "to", "storjshare", "create", "options"], "add_tokens": ". option ( '--verbosity <verbosity>' , 'specify the logger verbosity' ) let validVerbosities = new RegExp ( / ^[0-4]$ / ) ; if ( storjshare_create . verbosity && ! validVerbosities . test ( storjshare_create . verbosity ) ) { console . error ( ' \\n \\n \\ 3 - INFO | 2 - WARN | 1 - ERROR | 0 - SILENT \\n * Default value of % s \\ will be used . ', getDefaultConfigValue(' loggerVerbosity ' storjshare_create . verbosity = null ; } { option : storjshare_create . manualforwarding , name : 'doNotTraverseNat' } , { option : storjshare_create . verbosity , name : 'loggerVerbosity' }", "del_tokens": "{ option : storjshare_create . manualforwarding , name : 'doNotTraverseNat' }", "commit_type": "add"}
{"commit_tokens": ["Added", "channel", "option", "for", "Maps", "premium", "plan", "(", "https", ":", "//", "developers", ".", "google", ".", "com", "/", "maps", "/", "premium", "/", "overview#client", "-", "id", ")"], "add_tokens": "asclientid : PropTypes . bool , channel : PropTypes . string const { map : _map , googlekey , maptype , asclientid , channel , ... props } = this . props ;", "del_tokens": "asclientid : PropTypes . bool const { map : _map , googlekey , maptype , asclientid , ... props } = this . props ;", "commit_type": "add"}
{"commit_tokens": ["changed", "defaultSortColumn", "to", "default", "to", "idColumn"], "add_tokens": "* @ param { number | string } [ options . defaultSortColumn = this . idColumn . index ] - Name or index of the grouping column . The grouping column must contain discrete values within each level of grouping . ( this . defaultSortColumn = this . getColumnInfo ( options . defaultSortColumn , this . idColumn . index ) )", "del_tokens": "* @ param { number | string } [ options . defaultSortColumn = this . treeColumn . index ] - Name or index of the group column . ( this . defaultSortColumn = this . getColumnInfo ( options . defaultSortColumn , this . treeColumn . index ) )", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "Click", "on", "Enter", "after", "term", "or", "product", "in", "list"], "add_tokens": "this . isAutocompleteShow = false ; handleAutocompleteToggle = flag => { this . isAutocompleteShow = flag ; } ; if ( data . key === 'enter' && ! this . isAutocompleteShow ) { onMouseUp : this . handleMouseUp , onToggle : this . handleAutocompleteToggle", "del_tokens": "if ( data . key === 'enter' ) { onMouseUp : this . handleMouseUp", "commit_type": "fix"}
{"commit_tokens": ["Removing", "qunit", "-", "cov", "task", "from", "Travis"], "add_tokens": "grunt . registerTask ( \"quick-build\" , [ \"concat\" , \"jshint\" , \"csslint\" , \"uglify\" ] ) ; // Full build without version bump grunt . registerTask ( \"build\" , [ \"concat\" , \"qunit\" , \"qunit-cov\" , \"jshint\" , \"csslint\" , \"uglify\" ] ) ; grunt . registerTask ( \"travis\" , [ \"qunit\" , \"jshint\" , \"csslint\" ] ) ;", "del_tokens": "grunt . registerTask ( \"build\" , [ \"concat\" , \"jshint\" , \"csslint\" , \"uglify\" ] ) ; grunt . registerTask ( \"travis\" , [ \"qunit\" , \"jshint\" , \"csslint\" , \"qunit-cov\" ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "cached", "scan", "results", "."], "add_tokens": "self . cachedScanBundle = bundle ; this . cachedScanBundle = undefined ; // function returnResults(bundle) { // debugSS('in returnResults'); // self.cachedScanBundle = bundle; // self.scanInProgress = false; // var defered = q.defer(); // defered.resolve(bundle.deviceTypes); // return defered.promise; // } if ( self . cachedScanBundle ) { return returnResults ( self . cachedScanBundle ) ; return defered . promise ;", "del_tokens": "var defered = q . defer ( ) ; if ( ! self . scanInProgress ) { defered . resolve ( self . sortedResults ) ; return defered . promise ;", "commit_type": "add"}
{"commit_tokens": ["fix", "path", "to", "lightstreamer", "-", "adapter"], "add_tokens": "var DataProvider = require ( '../lib/lightstreamer-adapter' ) . DataProvider ,", "del_tokens": "var DataProvider = require ( 'lightstreamer-adapter' ) . DataProvider ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "Issue", "https", ":", "//", "github", ".", "com", "/", "BigstickCarpet", "/", "swagger", "-", "parser", "/", "issues", "/", "14"], "add_tokens": "this . path = util . path . ensureHash ( this . path ) + '/' + tokens . slice ( i ) . join ( '/' ) ; // Does the JSON reference have other properties (other than \"$ref\")? // If so, then don't resolve it, since it represents a new type if ( Object . keys ( pointer . value ) . length === 1 ) { var $refPath = url . resolve ( pointer . path , pointer . value . $ref ) ; // Is the value a reference to itself? If so, then there's nothing to do. if ( $refPath !== pointer . path ) { // Resolve the reference var resolved = pointer . $ref . $refs . _resolve ( $refPath ) ; pointer . $ref = resolved . $ref ; pointer . path = resolved . path ; // pointer.path = $refPath ??? pointer . value = resolved . value ; return true ; }", "del_tokens": "this . path += '#/' + tokens . slice ( i ) . join ( '/' ) ; var $refPath = url . resolve ( pointer . path , pointer . value . $ref ) ; // Is the value a reference to itself? If so, then there's nothing to do. if ( $refPath !== pointer . path ) { // Resolve the reference var resolved = pointer . $ref . $refs . _resolve ( $refPath ) ; pointer . $ref = resolved . $ref ; pointer . path = resolved . path ; // pointer.path = $refPath ??? pointer . value = resolved . value ; return true ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "ability", "to", "set", "binding"], "add_tokens": "binding = bindable . bind ( \"fish\" , \"fish2\" ) . now ( ) ;", "del_tokens": "binding = bindable . bind ( \"fish\" ) . now ( ) ; bindable . set ( \"fish2\" , binding ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "class", "for", "controls", "display"], "add_tokens": "removeClass_ ( this . controlsDiv , 'ima-controls-div-showing' ) ; addClass_ ( this . controlsDiv , 'ima-controls-div-showing' ) ;", "del_tokens": "this . controlsDiv . style . height = '14px' ; this . controlsDiv . style . height = '37px' ;", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "for", "Lock", ".", "prototype", ".", "acquire"], "add_tokens": "return Promise . reject ( new LockAcquisitionError ( 'Lock already held' ) ) ; return client . setAsync ( key , this . id , 'PX' , this . timeout , 'NX' ) . then ( function ( res ) { Lock . _acquiredLocks [ lock . id ] = lock ;", "del_tokens": "Promise . reject ( new LockAcquisitionError ( 'Lock already held' ) ) ; return client . setAsync ( key , this . id , 'PX' , this . timeout , 'nx' ) . then ( function ( res ) { Lock . _activeLocks [ lock . id ] = lock ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "around", "AssertionError", "messages"], "add_tokens": "} , 'expected { Object (foo) } to equal { Object (bar) }' ) ; } , 'expected { Object (foo) } to equal { Object (bar) }' ) ;", "del_tokens": "} , 'AssertionError: expected { Object (foo) } to equal { Object (bar) }' ) ; } , 'AssertionError: expected { Object (foo) } to equal { Object (bar) }' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "pointer", "length", "option", "to", "the", "javascript", "API", "."], "add_tokens": "enabled : true , length : '5.5em' , enabled : true , length : '5 ' wrapperClass : 'info-two' , pointer : { enabled : true , length : '41.12398123 px' } position : 'right' , pointer : { enabled : true , length : '20pt' }", "del_tokens": "enabled : false enabled : false wrapperClass : 'info-two' position : 'right'", "commit_type": "add"}
{"commit_tokens": ["fixing", "some", "issues", "fixing", "/", "revising", "some", "unit", "test", "related", "to", "model", "definition"], "add_tokens": "Model . define = function ( modelName , schema , customBaseClass = null , adapter = null ) {", "del_tokens": "Model . define = function ( modelName , schema = { } , customBaseClass = null , adapter = null ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "option", "delete", "param"], "add_tokens": "function deleteEmpty ( cwd , options , cb ) { if ( cb === undefined ) { cb = options ; options = { } ; } utils . del ( cwd , options , function ( err ) { utils . del ( dir , options , function ( err ) { deleteEmpty . sync = function ( cwd , options ) { utils . del . sync ( cwd , options ) ; utils . del . sync ( dir , options ) ;", "del_tokens": "function deleteEmpty ( cwd , cb ) { utils . del ( cwd , function ( err ) { utils . del ( dir , function ( err ) { deleteEmpty . sync = function ( cwd ) { utils . del . sync ( cwd ) ; utils . del . sync ( dir ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "test", "for", "deleting", "subscribers", "."], "add_tokens": "var sleep = require ( 'sleep' ) ; // This timeout is necessary. CM adds subscribers async so we need to wait from them to catch up. sleep . sleep ( 2 ) ; api . subscribers . updateSubscriber ( testList . listId , 'test@test.com' , { it ( 'should delete a subscriber' , function ( done ) { api . subscribers . deleteSubscriber ( testList . listId , 'test2@test.com' , function ( err ) { should . not . exist ( err ) ; done ( ) ; } ) ; } ) ;", "del_tokens": "api . subscribers . updateSubscriber ( testList . listId , testSubscriber . emailAddress , {", "commit_type": "add"}
{"commit_tokens": ["added", "late", "-", "require", "for", "Line2D", "in", "Ray2D"], "add_tokens": "describe ( '#toLine2DWithPointAtDistance' , function ( ) { it ( 'should create a Line2D' , function ( ) { var ray = new Ray2D ( 100 , 200 , new Vec2D ( 1 , 0.5 ) ) , line = ray . toLine2DWithPointAtDistance ( 100 ) ; assert . equal ( line . a . x , 100 ) ; assert . equal ( line . a . y , 200 ) ; assert . ok ( line . b ) ; } ) ; } ) ; } ) ;", "del_tokens": "} ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "incomplete", "support", "for", "boolean", "map", "node", "values"], "add_tokens": "VERSION = '0.2.8' , if ( reducedMap === reducedPrefix ) { // This is just a local file/dir to expose. //log('fetchContent(' + path + ', ' + dstPath + ', ...)');", "del_tokens": "VERSION = '0.2.7' , } else if ( reducedMap === true ) { getFile ( reducedPrefix + '/' + reducedSuffix , callback , addLineHints ) ; if ( reducedMap === true || reducedMap === reducedPrefix ) { // A true value means this is just a local file/dir to expose. //log('fetchContent(' + mapPath + ', ' + dstPath + ', ...)');", "commit_type": "remove"}
{"commit_tokens": ["Adding", "PhantomJS", "to", "the", "list", "of", "tested", "browsers", "."], "add_tokens": "browsers : [ 'Firefox' , 'PhantomJS' ] , browsers : [ 'PhantomJS' , 'SL_IE_7' , 'SL_IE_8' , 'SL_IE_9' , 'SL_IE_10' , 'SL_IE_11' , 'SL_Firefox' , 'SL_Chrome' , 'ANDROID' ] , browsers : [ 'PhantomJS' , 'SL_IE_7' , 'SL_IE_8' , 'SL_IE_9' , 'SL_IE_10' , 'SL_IE_11' , 'SL_Firefox' , 'SL_Chrome' , 'ANDROID' ] ,", "del_tokens": "browsers : [ 'Firefox' ] , browsers : [ 'SL_IE_7' , 'SL_IE_8' , 'SL_IE_9' , 'SL_IE_10' , 'SL_IE_11' , 'SL_Firefox' , 'SL_Chrome' , 'ANDROID' ] , browsers : [ 'SL_IE_7' , 'SL_IE_8' , 'SL_IE_9' , 'SL_IE_10' , 'SL_IE_11' , 'SL_Firefox' , 'SL_Chrome' , 'ANDROID' ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "undefined", "log", "object", "."], "add_tokens": "results . options . log = get . log ( options ) || { info : nop , warn : nop , error : nop } ; function nop ( ) { }", "del_tokens": "results . options . log = get . log ( options ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "and", "modify", "some", "things", "for", "clarity"], "add_tokens": "var getOptions = require ( './lib/getOptions' ) ;", "del_tokens": "function getOptions ( options ) { debug ( 'Setting options' ) ; if ( typeof options === 'undefined' ) { options = { } ; } if ( typeof options . slack === 'undefined' ) { options . slack = { } ; } if ( ! options . slack . hook ) { debug ( 'Detected no slack hook url set. Aborting.' ) ; throw new Error ( 'You need to set a url for slack communication.' ) ; } if ( ! options . slack . channel ) options . slack . channel = '#general' ; if ( ! options . slack . username ) options . slack . username = 'Mailgun' ; if ( ! options . slack . icon_emoji ) options . slack . icon_emoji = 'mailbox_with_mail' ; if ( typeof options . mailgun === 'undefined' ) { options . mailgun = { } ; } if ( ! options . mailgun . apikey ) { debug ( 'Not using Mailgun HMAC verification due to lack of an API key.' ) ; } if ( ! options . slack . options ) { debug ( 'No options passed to node-slack.' ) ; } return options ; } ;", "commit_type": "add"}
{"commit_tokens": ["fix", "container_id", "scoping", "for", "api", "create", "()"], "add_tokens": "// add in the api user's container_id if present if ( ! _ . isUndefined ( this . _req . apiUser . container_id ) ) { data [ 'container_id' ] = this . _req . apiUser . container_id ;", "del_tokens": "if ( ! data . hasOwnProperty ( 'container_id' ) && this . intercom . hasOwnProperty ( 'container_id' ) ) { data [ 'container_id' ] = this . intercom . container_id ; } if ( ! data . hasOwnProperty ( 'app_id' ) && this . intercom . hasOwnProperty ( 'app_id' ) ) { data [ 'app_id' ] = this . intercom . app_id ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "authorization", "header", "when", "logging", "reqOptions"], "add_tokens": "var reqOptionsForLog = Object . assign ( { } , reqOptions ) ; if ( reqOptionsForLog . headers && reqOptionsForLog . headers . Authorization ) reqOptionsForLog . headers . Authorization = 'xxx' ; logger . warning ( 'API: ' + errMsg , { category : 'api' , body , reqOptions : reqOptionsForLog } ) ;", "del_tokens": "logger . warning ( 'API: ' + errMsg , { category : 'api' , body , reqOptions } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "extension", "of", "required", "files", "and", "increase", "version", "."], "add_tokens": "var utils = require ( './utils.js' ) ; exports . sdkVersion = require ( '../package.json' ) . version ;", "del_tokens": "var utils = require ( './utils' ) ; exports . sdkVersion = require ( '../package' ) . version ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "copy", "()", "for", "Data", "with", "a", "test", "."], "add_tokens": "/ ** * @ ngdoc method * @ name copy * @ methodOf coa . data . class : Data * @ param { Data } target Another . * @ description * Clone the target object into this . * / Data . prototype . copy = function ( target ) { for ( var k = 0 ; k < this . _members . length ; k ++ ) { this [ this . _members [ k ] . name ] = this . _members [ k ] . copy ( target [ this . _members [ k ] . name ] ) ; } } ;", "del_tokens": "// TODO: Copy function using types and test for it verifying that references are not the same.", "commit_type": "implement"}
{"commit_tokens": ["Implement", "results", "for", "From", "Sender", "and", "ReplyTo"], "add_tokens": "return opts . simple ? result : result . addresses ; if ( ( ! result ) || ( ! opts . partial && ( opts . simple && result . length > 1 ) || ( ! opts . simple && result . addresses . length > 1 ) ) ) { return null ; } return opts . simple ? result && result [ 0 ] : result && result . addresses && result . addresses [ 0 ] ; return opts . simple ? result : result . addresses ;", "del_tokens": "// if ((!result) || // (!opts.partial && // (opts.simple && result.length > 1) || // (!opts.simple && result.addresses.length > 1))) { // return null; // } // return opts.simple ? // result && result[0] : // result && result.addresses && result.addresses[0];", "commit_type": "implement"}
{"commit_tokens": ["Fix", "RegExp", "for", "real", "this", "time"], "add_tokens": "return [ className . replace ( new RegExp ( '\\\\b' + BigText . LINE_CLASS_PREFIX + '\\\\d+\\\\b' ) , '' ) ,", "del_tokens": "return [ className . replace ( new RegExp ( '(?:^|\\\\s+)' + BigText . LINE_CLASS_PREFIX + '\\\\d+' ) , '' ) ,", "commit_type": "fix"}
{"commit_tokens": ["add", "request", "body", "tests", "post", "/", "put", "/", "patch", "/", "delete", "methods"], "add_tokens": "req . body = '' ; req . on ( 'data' , function ( data ) { req . body += data . toString ( ) ; } ) ; req . on ( 'end' , function ( ) { d ( req , res ) ; } ) ;", "del_tokens": "d ( req , res ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "amazon", "-", "fireos", "platform", "."], "add_tokens": "amazon_fireos : / cordova-amazon-fireos / , if ( window . device && device . platform && ( device . platform . toLowerCase ( ) == 'android' || device . platform . toLowerCase ( ) == 'amazon-fireos' ) ) {", "del_tokens": "if ( window . device && device . platform && device . platform . toLowerCase ( ) == 'android' ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "JSON", "proxy", "calls", "dependency", "updates"], "add_tokens": "var BUILD_PATH = './build/' , JS_LOCATIONS = [ './lib/*.js' ] , AUTOPREFIXER_BROWSERS = [ 'last 2 versions' , 'last 5 chrome versions' , 'safari >= 5' , 'ios >= 6' , 'android >= 2' , 'ff >= 30' , 'opera >= 22' , 'ie >= 8' , 'ie_mob >= 10' ] ;", "del_tokens": "var BUILD_PATH = './build/' ; var JS_LOCATIONS = [ './lib/*.js' ] ; var AUTOPREFIXER_BROWSERS = [ 'last 2 versions' , 'last 5 chrome versions' , 'safari >= 5' , 'ios >= 6' , 'android >= 2' , 'ff >= 30' , 'opera >= 22' , 'ie >= 8' , 'ie_mob >= 10' ] ;", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "running", "commands", "outside", "of", "project", "root"], "add_tokens": "require ( './check-cwd' ) ( ) ;", "del_tokens": "// try { // var configFile = fs.statSync('./shepherd-config.js') // } catch (e) { // console.log(chalk.red('No shepherd-config.js file present. Did you mean to run this command from the project root?')) // process.exit(1) // }", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "for", "marshal", "to", "step"], "add_tokens": "manualStep : opts . autoUpdate === undefined ? false : ! opts . autoUpdate , return this ; } , step : function ( deltaTime ) { driver . step ( deltaTime ) ;", "del_tokens": "onState : onState , function onState ( ) { }", "commit_type": "add"}
{"commit_tokens": ["use", "no", "sandbox", "for", "tests"], "add_tokens": "reporter . use ( chromePdf ( { launchOptions : { args : [ '--no-sandbox' ] } } ) )", "del_tokens": "reporter . use ( chromePdf ( ) )", "commit_type": "use"}
{"commit_tokens": ["added", "more", "info", "in", "user", "obj", "@", "token"], "add_tokens": "if ( record ) record . id = record . _id . toString ( ) ; return callback ( false , record ) ;", "del_tokens": "return callback ( false , { \"id\" : record . _id . toString ( ) } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "returned", "type", "of", "Option<T", ">", ".", "mapOr", "()", "."], "add_tokens": "* @ return { U }", "del_tokens": "* @ return { ! Option < U > }", "commit_type": "fix"}
{"commit_tokens": ["moved", ".", "every", "and", ".", "some", "to", "the", "list", "of", "terminating", "methods", "..", "arrayify", "ArrayTools", "contructor", "input"], "add_tokens": "this . _data = arrayify ( input ) ; [ \"filter\" , \"reverse\" , \"sort\" , \"concat\" , \"slice\" , \"map\" ] . forEach ( function ( method ) { /* Array method chain terminators, return a scalar or undefined */ [ \"join\" , \"every\" , \"some\" , \"forEach\" ] . forEach ( function ( method ) {", "del_tokens": "this . _data = input ; [ \"filter\" , \"reverse\" , \"sort\" , \"concat\" , \"slice\" , \"every\" , \"some\" , \"map\" ] . forEach ( function ( method ) { /* Array method chain terminators, return a scalar */ [ \"join\" ] . forEach ( function ( method ) {", "commit_type": "move"}
{"commit_tokens": ["Adding", "example", "flows", "with", "media", "dimensions", "included", ".", "Now", "used", "inside", "dynamorese", "."], "add_tokens": "interlace : [ '1' ] , packing : [ 'v210' ] } ,", "del_tokens": "interlace : [ '1' ] } ,", "commit_type": "add"}
{"commit_tokens": ["add", "props", "to", "generator", "objects"], "add_tokens": "var res = { } ; res . module = require . resolve ( path . resolve ( fp ) ) ; res . pkg = json ; res . name = json . name . split ( 'generate-' ) . join ( '' ) ; acc [ res . name ] = res ;", "del_tokens": "acc [ path . basename ( dir ) ] = require . resolve ( path . resolve ( fp ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "stopgap", "for", "https", ":", "//", "github", ".", "com", "/", "Project", "-", "OSRM", "/", "osrm", "-", "backend", "/", "pull", "/", "2159"], "add_tokens": ". filter ( v => { // TODO distance check is stopgap for https://github.com/Project-OSRM/osrm-backend/pull/2159 return v . maneuver . type !== 'arrive' && v . distance > 0 } )", "del_tokens": ". filter ( v => v . maneuver . type !== 'arrive' ) // console.log(instructions.legs[0].steps)", "commit_type": "add"}
{"commit_tokens": ["Added", "noRecord", "option", "to", "error", "on", "unknown", "requests"], "add_tokens": "* @ param { Boolean } opts . noRecord if true , requests will return a 404 error if the tape doesn ' if ( ! opts . noRecord ) { return proxy ( req , body , host ) . then ( function ( res ) { return record ( res . req , res , file ) ; } ) ; } else { throw { code : 'RECORDING_DISABLED' } ; } } ) . catch ( RecordingDisabledError , function ( /* err */ ) { res . statusCode = 404 ; res . end ( \"An HTTP request has been made that yakbak does not know how to handle (\" + req . url + \")\" ) ; / ** * Bluebird error predicate for matching recording disabled errors . * @ param { Error } err * @ returns { Boolean } * / function RecordingDisabledError ( err ) { return err . code === 'RECORDING_DISABLED' ; }", "del_tokens": "return proxy ( req , body , host ) . then ( function ( res ) { return record ( res . req , res , file ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "unit", "tests", "(", "ifComponentExists", "getRadicalMeaning", "getPinyin", ")"], "add_tokens": "it ( \"checks if component don't exist\" , function ( ) { assert ( ! hanzi . ifComponentExists ( '$' ) ) ; } ) ; assert . deepEqual ( hanzi . decompose ( 'a' ) , { \"character\" : \"a\" , \"components1\" : [ \"a\" ] , \"components2\" : [ \"a\" ] , \"components3\" : [ \"a\" ] } ) ; } ) ; it ( \"gets a character's pinyin\" , function ( ) { assert . deepEqual ( hanzi . getPinyin ( ''), [ d e5', ' i2', ' i4']) ; } ) ; it ( \"gets a radical's meaning\" , function ( ) { assert ( hanzi . getRadicalMeaning ( ''), \" ater\");", "del_tokens": "assert . equal ( hanzi . decompose ( 'a' ) , 'Invalid Input' ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "JSON", ".", "parse", "to", "prevent", "caching", "data"], "add_tokens": "var str = fs . readFileSync ( fp , 'utf8' ) ; return JSON . parse ( str ) ;", "del_tokens": "return require ( path . resolve ( fp ) ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "webpack", "-", "dev", "-", "middleware"], "add_tokens": "app : [ \"webpack-hot-middleware/client\" , path . join ( __dirname , \"client\" , \"main.js\" ) ] new webpack . HotModuleReplacementPlugin ( ) , new webpack . NoEmitOnErrorsPlugin ( )", "del_tokens": "app : path . join ( __dirname , \"client\" , \"main.js\" )", "commit_type": "add"}
{"commit_tokens": ["Implement", "processing", "of", "logical", "or", "operator", "."], "add_tokens": "} ) ; suite ( 'run against assignment expression' , function ( ) { var report ; setup ( function ( ) { report = cr . run ( 'var foo = \"bar\";' ) ; } ) ; teardown ( function ( ) { report = undefined ; } ) ; test ( 'aggregate has correct cyclomatic complexity' , function ( ) { assert . strictEqual ( report . aggregate . complexity . cyclomatic , 1 ) ; } ) ; } ) ; suite ( 'run against logical or expression assigned to variable' , function ( ) { var report ; setup ( function ( ) { report = cr . run ( 'var foo = true || false;' ) ; } ) ; teardown ( function ( ) { report = undefined ; } ) ; test ( 'aggregate has correct cyclomatic complexity' , function ( ) { assert . strictEqual ( report . aggregate . complexity . cyclomatic , 2 ) ;", "del_tokens": "test ( 'functions is empty' , function ( ) { assert . lengthOf ( report . functions , 0 ) ; } ) ; test ( 'functions is empty' , function ( ) { assert . lengthOf ( report . functions , 0 ) ; } ) ; test ( 'functions is empty' , function ( ) { assert . lengthOf ( report . functions , 0 ) ; // ternary operator", "commit_type": "implement"}
{"commit_tokens": ["ADD", "performance", "test", "and", "optimisations", "for", "node"], "add_tokens": "require ( './issues.test' ) ;", "del_tokens": "require ( './issues.test' ) ; require ( './performance.test' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "format", "with", "dashes", "and", "commas"], "add_tokens": "{ input : 'twenty-one' , expect : 'twenty-first' } , { input : 'twenty-two' , expect : 'twenty-second' } , { input : 'twenty-three' , expect : 'twenty-third' } , { input : 'twenty-four' , expect : 'twenty-fourth' } , { input : 'twenty-five' , expect : 'twenty-fifth' } , { input : 'twenty-six' , expect : 'twenty-sixth' } , { input : 'twenty-seven' , expect : 'twenty-seventh' } , { input : 'twenty-eight' , expect : 'twenty-eighth' } , { input : 'twenty-nine' , expect : 'twenty-ninth' } ,", "del_tokens": "{ input : 'twenty one' , expect : 'twenty-first' } , { input : 'twenty two' , expect : 'twenty-second' } , { input : 'twenty three' , expect : 'twenty-third' } , { input : 'twenty four' , expect : 'twenty-fourth' } , { input : 'twenty five' , expect : 'twenty-fifth' } , { input : 'twenty six' , expect : 'twenty-sixth' } , { input : 'twenty seven' , expect : 'twenty-seventh' } , { input : 'twenty eight' , expect : 'twenty-eighth' } , { input : 'twenty nine' , expect : 'twenty-ninth' } ,", "commit_type": "fix"}
{"commit_tokens": ["move", "to", "rc", "-", "yaml", "-", "2", "until", "PR", "for", "rc", "-", "yaml", "is", "accepted"], "add_tokens": "var RC = require ( 'rc-yaml-2' ) maxfiles : Number ( process . env . SPM_LOG_MAX_FILES ) || '2' , util . _extend ( this , rc ) return this . rcFlat [ key ] module . exports = new SpmConfig ( process . env . SPM_AGENT_APP_TYPE || 'spmagent' )", "del_tokens": "var RC = require ( 'rc-yaml' ) maxfiles : Number ( process . env . SPM_LOG_MAX_FILES ) || '2' , util . _extend ( this , rc ) return this . rcFlat [ key ] module . exports = new SpmConfig ( process . env . SPM_AGENT_APP_TYPE || 'spmagent' )", "commit_type": "move"}
{"commit_tokens": ["Adding", "state", "to", "passed", "and", "failed", "tests", "so", "Mocha", "reporters", "work", "properly"], "add_tokens": "var testProperties = [ 'async' , 'sync' , 'timedOut' , 'pending' , 'file' , 'duration' , 'state' ] ; state : 'failed' ,", "del_tokens": "var testProperties = [ 'async' , 'sync' , 'timedOut' , 'pending' , 'file' , 'duration' ] ;", "commit_type": "add"}
{"commit_tokens": ["adding", "subscription", "endpoint", "to", "rest", "api", "-", "not", "ready"], "add_tokens": "$or : [ { fromUuid : uuid } , { uuid : uuid } , { devices : { $in : [ uuid , \"all\" , \"*\" ] } } ]", "del_tokens": "$or : [ { fromUuid : uuid } , { uuid : uuid } , { devices : { $in : [ uuid , \"all\" ] } } ]", "commit_type": "add"}
{"commit_tokens": ["Move", "plugin", "templates", "to", "top", "-", "level", "dir", "(", "no", "need", "to", "copy", ")", "."], "add_tokens": "const tmplStr = fs . readFileSync ( path . join ( __dirname , \"../templates/localstorage.jst\" ) , \"utf-8\" ) ;", "del_tokens": "const tmplStr = fs . readFileSync ( path . join ( __dirname , \"templates/localstorage.jst\" ) , \"utf-8\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "g", ".", "toString", "()", "instead", "of", "dagre", ".", "graph", ".", "write", "(", "g", ")"], "add_tokens": "throw new Error ( \"Input graph is not acyclic: \" + g . toString ( ) ) ;", "del_tokens": "throw new Error ( \"Input graph is not acyclic: \" + dagre . graph . write ( g ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Update", "standalone", "-", "html", ".", "js"], "add_tokens": "var RawImgPath = $ ( this ) . attr ( 'src' ) . split ( '?' ) [ 0 ] ; var RawImgPath = $ ( this ) . attr ( 'src' ) . split ( '?' ) [ 0 ] ;", "del_tokens": "var RawImgPath = $ ( this ) . attr ( 'src' ) ; var RawImgPath = $ ( this ) . attr ( 'src' ) ;", "commit_type": "update"}
{"commit_tokens": ["removed", "an", "unused", "import", "and", "fixed", "the", "PluginHelper", ".", "toJSON", "()", "method"], "add_tokens": "* Serializes the { @ link PluginHelper } return this [ __internal ] . plugins ;", "del_tokens": "/* eslint no-unused-vars:off */ var omit = require ( '../../util/omit' ) ; * Allows the { @ link PluginHelper } to be safely serialized as JSON by removing circular references . * * @ returns { object } return omit ( this , __internal ) ;", "commit_type": "remove"}
{"commit_tokens": ["use", "a", "better", "hog", "descriptor"], "add_tokens": "image = image . scale ( { width : 20 , height : 20 } ) ; image = image . pad ( { size : 2 } ) ; cellSize : 5 , blockSize : 2 , let hogFeatures = hog . extractHOG ( image , optionsHog ) ; return hogFeatures ;", "del_tokens": "image = image . scale ( { width : 18 , height : 18 } ) ; cellSize : 4 , blockSize : 1 , return hog . extractHOG ( image , optionsHog ) ;", "commit_type": "use"}
{"commit_tokens": ["adding", "date", "filtering", "to", "showBuild"], "add_tokens": "var date = require ( './date' ) ; if ( results . nodes [ i ] . properties . prmname . toUpperCase ( ) === prmname . toUpperCase ( ) ) { print ( config , argv ) ; function print ( config , argv ) { if ( ! argv . showData ) { var start , stop ; if ( argv . start && argv . stop ) { start = date . toDate ( argv . start ) ; stop = date . toDate ( argv . stop ) ; } if ( start && stop ) { date . trim ( start , stop , data ) ; }", "del_tokens": "if ( results . nodes [ i ] . properties . prmname === prmname ) { print ( config , argv . showData ) ; function print ( config , showData ) { if ( ! showData ) {", "commit_type": "add"}
{"commit_tokens": ["changed", ".", "gitignore", "made", "grocery", "examples", "heroku", "runable"], "add_tokens": "/ ** * Created by ticup on 01 / 11 / 13. * / grocery . publish ( http ) ; // setup xhr-polling only for Heroku if ( process . env . HEROKU ) { grocery . server . io . configure ( function ( ) { grocery . server . io . set ( \"transports\" , [ \"xhr-polling\" ] ) ; grocery . server . io . set ( \"polling duration\" , 10 ) ; } ) ; } console . log ( \"#### CloudTypes Examples server running on \" + port + \" ####\" ) ;", "del_tokens": "grocery . publish ( http ) ;", "commit_type": "change"}
{"commit_tokens": ["removing", "files", "for", "new", "architecture"], "add_tokens": "var ScheduledTask = require ( './scheduled-task' ) , return new ScheduledTask ( expression , func , options ) ;", "del_tokens": "var Task = require ( './task' ) , ScheduledTask = require ( './scheduled-task' ) , var task = new Task ( expression , func ) ; return new ScheduledTask ( task , options ) ;", "commit_type": "remove"}
{"commit_tokens": ["removed", "narcissus", ".", "js", "+", "cosmetic", "fix", "to", "transform"], "add_tokens": "var Narcissus = require ( 'narcissus' ) ; return \"\\n\" + __global + \"\\n\" + _trim ( __cbStr ( options ) ) + \"\\n\" + _trim ( __nt ) + \"\\n\" + _trim ( __throw ) + \"\\n\" ; exports . version = \"0.1.1a\" ;", "del_tokens": "var Narcissus = require ( './narcissus' ) ; return \"\\n\" + __global + \"\\n\" + _trim ( __cbStr ( options ) ) + \"\\n\" + _trim ( __nt ) + \"\\n\" + _trim ( __throw ) ; exports . version = \"0.1.0b\" ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "stub", "handler", "respond", "with", "information", "about", "the", "controller", "being", "stubbed"], "add_tokens": "var createStubHandler = function createStubHandler ( req , res , msg ) { return function stubHandler ( req , res ) { res . end ( msg ) ; } ; handler = handlerCache [ operation . nickname ] = createStubHandler ( req , res , 'Stubbed response for ' + operation . nickname ) ;", "del_tokens": "var stubHandler = function stubHandler ( req , res ) { res . end ( 'OK' ) ; handler = handlerCache [ operation . nickname ] = stubHandler ;", "commit_type": "make"}
{"commit_tokens": ["Add", "ability", "to", "pass", "loaders", "as", "array", "of", "objects"], "add_tokens": "const extractSass = new ExtractTextPlugin ( 'app.css' ) ; 'text/scss' : extractSass . extract ( 'css-loader!sass-loader' ) , plugins : [ extractSass ]", "del_tokens": "const extractSass = new ExtractTextPlugin ( 'public/app.css' ) ; 'text/scss' : 'style-loader!css-loader!sass-loader' , // plugins: [ // extractSass // ]", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "reported", "line", "number", "in", "parser", "errors"], "add_tokens": "var DEDENT , INDENT , TERM , processInput , ws ; TERM = '\\uEFFF' ; this . p ( \"\\n\" ) ; this . p ( \"\" + DEDENT + TERM ) ; } else if ( this . ss . scan ( RegExp ( \"[\" + ws + \"]*\\\\#\" ) ) ) { this . p ( \"\" + DEDENT + TERM ) ;", "del_tokens": "var DEDENT , INDENT , processInput , ws ; this . p ( '\\n' ) ; this . p ( \"\" + DEDENT + \"\\n\" ) ; } else if ( this . ss . check ( RegExp ( \"[\" + ws + \"]*\\\\#\" ) ) ) { this . scan ( RegExp ( \"[\" + ws + \"]*\" ) ) ; this . ss . scan ( / # / ) ; this . p ( \"\" + DEDENT + \"\\n\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "one", "more", "test", "case", "for", "matching", "sources", "including", "pathnames"], "add_tokens": "redbird . close ( ) ; done ( ) ; } ) ; } ) it ( \"Should be proxyed to target with pathname and source pathname concatenated case 2\" , function ( done ) { var redbird = new Redbird ( opts ) ; expect ( redbird . routing ) . to . be . an ( \"object\" ) ; redbird . register ( '127.0.0.1/path' , '127.0.0.1:' + TEST_PORT + '/foo/bar/qux' ) ; expect ( redbird . routing ) . to . have . property ( \"127.0.0.1\" ) ; testServer ( ) . then ( function ( req ) { expect ( req . url ) . to . be . eql ( '/foo/bar/qux/a/b/c' ) } ) http . get ( 'http://127.0.0.1:' + PROXY_PORT + '/path/a/b/c' , function ( err , res ) { redbird . close ( ) ; res . write ( \"\" ) ; server . close ( ) ;", "del_tokens": "server . close ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "mocks", "for", "new", "Slack", "API", "requests"], "add_tokens": "beforeEach ( ( ) => { nock ( 'https://myorg.slack.com' ) . get ( '/api/users.list' ) . query ( { token : 'mytoken' , presence : '1' } ) . query ( { token : 'mytoken' } ) ok : true , members : [ { } ] nock ( 'https://myorg.slack.com' ) . get ( '/api/channels.list?token=mytoken' ) . reply ( 200 , { ok : true , channels : [ { } ] } ) ; nock ( 'https://myorg.slack.com' ) . get ( '/api/team.info?token=mytoken' ) . reply ( 200 , { ok : true , team : { icon : { } } } ) } ) ;", "del_tokens": "let mockNumUsers = ( org ) => { nock ( ` ${ org } ` ) . get ( '/api/rtm.start?token=mytoken' ) channels : [ { } ] , team : { name : 'myteam' , icon : { } } , users : [ { } ] } ; mockNumUsers ( opts . org ) ; mockNumUsers ( opts . org ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "recursion", "error", "in", "queue_ok"], "add_tokens": "return plugin . hook_queue_ok ( callback , connection , params ) ;", "del_tokens": "return plugin . hook_deny ( callback , connection , params ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "key", "existence", "check", "bugs"], "add_tokens": "if ( ! ( k in x ) ) { if ( ! ( k in val ) ) {", "del_tokens": "if ( ! k in x ) { if ( ! k in val ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "strange", "with", "saving", "a", "cached", "model"], "add_tokens": "save_promise . error ( function ( err ) { cached_promise . _error ( err ) ; } ) ;", "del_tokens": "save_promise . error ( cached_promise . _error . bind ( cached_promise ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "git", "push", "to", "include", "the", "bump", "commit"], "add_tokens": "return exec ( ` ${ githubToken } ${ owner } ${ repo } ` )", "del_tokens": "return exec ( ` ${ githubToken } ${ owner } ${ repo } ` )", "commit_type": "update"}
{"commit_tokens": ["remove", "copy", "-", "pasted", "comment"], "add_tokens": "req [ attr ] = getClientIp ( req ) ;", "del_tokens": "req [ attr ] = getClientIp ( req ) ; // on localhost > 127.0.0.1", "commit_type": "remove"}
{"commit_tokens": ["use", "correct", "container", "when", "debounce", "option", "is", "used"], "add_tokens": "item . customDebouncedCheck = function ( container ) { container = container || element ; return debounce ( ( function ( event ) { return checkInView ( [ item ] , container [ 0 ] , event ) ; } ) , options . debounce ) ( ) ; } ; i . customDebouncedCheck ( $element ) ;", "del_tokens": "item . customDebouncedCheck = debounce ( ( function ( event ) { return checkInView ( [ item ] , element [ 0 ] , event ) ; } ) , options . debounce ) ; i . customDebouncedCheck ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "renderer", "and", "logger", "to", "core", "dir"], "add_tokens": "import Renderer from './core/renderer.js' ; import Logger from './core/logger.js' ;", "del_tokens": "import Renderer from './renderer/renderer.js' ; import Logger from './logger.js' ;", "commit_type": "move"}
{"commit_tokens": ["Make", "more", "use", "of", "the", "Pos", ".", "prototype", ".", "depth", "getter"], "add_tokens": "if ( to == this . depth ) return this", "del_tokens": "if ( to == this . path . length ) return this", "commit_type": "make"}
{"commit_tokens": ["Added", "API", "to", "retrieve", "user", "info", "for", "given", "items", "."], "add_tokens": "\"use strict\" ; * @ param { Function } callback the callback is been passed a UT . User instance . console . log ( 'deprecated, please use UT.Post#user([item], callback) instead' ) ; user ( callback ) ; / ** * Asynchronously retrieve an UT . User instance given an optional array of items . * * @ param { object | Array } items from which to retrieve the user . * @ param { Function } callback the callback is been passed a UT . User instance . * / var user = this . user = function ( items , callback ) { if ( typeof items === 'function' ) { callback = items ; UT . Expression . _callAPI ( 'document.getUserData' , [ ] , callback ) ; } if ( items && Object . prototype . toString . call ( items ) === \"[object Array]\" ) { UT . Expression . _callAPI ( 'document.getUserData' , [ ] , callback ) ; } } ;", "del_tokens": "* @ param { Function } callback a callback called with the user datas UT . Expression . _callAPI ( 'document.getUserData' , [ ] , callback ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "new", "testdata", "type", "."], "add_tokens": "var path = require ( 'path' ) ; var util = require ( 'util' ) ; 'uuid()' : require ( 'node-uuid' ) . v4 , 'testdata' : loadTestData function loadTestData ( fileName ) { var testDataRoot = this . testConfig . testDataRoot || process . cwd ( ) ; var filePath = path . join ( testDataRoot , fileName + '.json' ) ; this . _log . trace ( { path : filePath } , 'Loading file.' ) ; //Don't use `require` because that caches the returned object. var json = require ( 'fs' ) . readFileSync ( filePath , { encoding : 'utf8' } ) ; var value = null ; try { value = JSON . parse ( json ) ; } catch ( err ) { throw new Error ( util . format ( 'File %s contained invalid JSON.' , filePath ) ) ; } this . _log . trace ( { loadedData : value } , 'File loaded.' ) ; return value ; }", "del_tokens": "'uuid()' : require ( 'node-uuid' ) . v4", "commit_type": "add"}
{"commit_tokens": ["allow", "result", "and", "dynamicview", "to", "utililze", "binaryindex"], "add_tokens": "if ( ( ! this . searchIsChained || ( this . searchIsChained && ! this . filterInitialized ) ) && this . collection . binaryIndices . hasOwnProperty ( property ) ) { t = this . collection . data ; var seg = this . calcseg ( operator , property , value , this ) ; for ( var idx = seg [ 0 ] ; idx <= seg [ 1 ] ; idx ++ ) { result . push ( t [ index . values [ idx ] ] ) ; } this . filteredrows = result ;", "del_tokens": "if ( ! this . searchIsChained && this . collection . binaryIndices . hasOwnProperty ( property ) ) { t = index ; i = t . length ; while ( i -- ) { if ( fun ( t [ i ] , value ) ) { result . push ( i ) ; } }", "commit_type": "allow"}
{"commit_tokens": ["Made", "blam", ".", "noConflict", "()", "work", "right", "."], "add_tokens": "// BLAM! v0.3 by Matt McCray (https://github.com/darthapo/blam.js) var old_blam = global . blam ; var args = slice . call ( arguments , 0 ) , html = '' ; if ( arguments [ 0 ] ) { } else { } return ( blam . compile == blam . _compile_fancy ) ; global . blam = old_blam ; var html = '<' , atts = '' , hash = '' , key = '' ;", "del_tokens": "; // BLAM! v0.3 by Matt McCray (https://github.com/darthapo/blam.js) var args = slice . call ( arguments , 0 ) , html = '' ; if ( arguments [ 0 ] ) else return blam . compile == blam . _compile_fancy ; delete global . blam ; var html = '<' , atts = '' , hash = '' , key = '' ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "to", "adjust", "zoom", "speed"], "add_tokens": "setTransformOrigin : setTransformOrigin , getZoomSpeed : getZoomSpeed , setZoomSpeed : setZoomSpeed function getZoomSpeed ( ) { return speed ; } function setZoomSpeed ( newSpeed ) { if ( ! Number . isFinite ( newSpeed ) ) { throw new Error ( 'Zoom speed should be a number' ) ; } speed = newSpeed ; }", "del_tokens": "setTransformOrigin : setTransformOrigin", "commit_type": "allow"}
{"commit_tokens": ["fix", "function", "order", "in", "publish", "format", "code"], "add_tokens": "var PROTOCOL_VERSION = '1.0.0' * @ param { Object } opts - this . db . use ( 'channels' , createChannelView ( memdb ( { valueEncoding : json } ) ) ) this . db . use ( 'users' , createUsersView ( memdb ( { valueEncoding : json } ) ) ) process . nextTick ( cb , PROTOCOL_VERSION ) if ( ! cb ) cb = noop", "del_tokens": "var PROTOCOL_VERSION = \"1.0.0\" * @ param { Object } opts - this . db . use ( 'channels' , createChannelView ( memdb ( { valueEncoding : json } ) ) ) this . db . use ( 'users' , createUsersView ( memdb ( { valueEncoding : json } ) ) ) process . nextTick ( cb , PROTOCOL_VERSION ) if ( ! cb ) cb = noop", "commit_type": "fix"}
{"commit_tokens": ["Adds", "Model", ".", "get", "."], "add_tokens": "if ( model . isEmpty || opts . refresh ) { model . __isBusy__ = true ; model . __promise__ = callMapper . call ( this , 'get' , [ id , getOpts ] ) . then ( ( result ) => { model . __isBusy__ = false ; delete model . __error__ ; this . load ( result ) ; } , ( error ) => { model . __isBusy__ = false ; model . __error__ = error ; throw error ; } ) ; } for ( let k in attrs ) { if ( k in this ) { this [ k ] = attrs [ k ] ; } } this . __sourceState__ = NEW ; this . __isBusy__ = false ; get isEmpty ( ) { return this . sourceState === EMPTY ; } get error ( ) { return this . __error__ ; }", "del_tokens": "const NOTFOUND = 'notfound' ; // FIXME //if (model.isEmpty || opts.refresh) { // mapperGet(model, getOpts) //} for ( let k in attrs ) { if ( k in this ) { this [ k ] = attrs [ k ] ; } } Model . NOTFOUND = NOTFOUND ;", "commit_type": "add"}
{"commit_tokens": ["Makes", "command", "line", "API", "more", "verbose"], "add_tokens": ". usage ( \"Usage: squiggle --input [file] --output [file]\" ) . option ( \"input\" , { alias : \"i\" , describe : \"Read Squiggle from this file\" , nargs : 1 , string : true , demand : true } ) var txt = fs . readFileSync ( argv . input , \"utf-8\" ) ;", "del_tokens": ". demand ( 1 ) . usage ( \"Usage: squiggle [options] [file] --output [file]\" ) var txt = fs . readFileSync ( argv . _ [ 0 ] , \"utf-8\" ) ;", "commit_type": "make"}
{"commit_tokens": ["use", "the", "test", "file", "path", "in", "the", "Babel", "whitelist", "instead", "of", "a", "pattern"], "add_tokens": "var path = process . argv [ 2 ] ; only : path ,", "del_tokens": "only : / (test|test\\-.+|test\\/.+)\\.js$ / , var path = process . argv [ 2 ] ;", "commit_type": "use"}
{"commit_tokens": ["added", "plugin", "logic", "added", "tests"], "add_tokens": "gulp . task ( 'default' , [ 'test' ] ) ;", "del_tokens": "gulp . task ( 'default' , [ 'lint' , 'test' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", ".", "&", "_", "where", "marked", "invalid"], "add_tokens": "|| ( ch === '.' ) || ( ch === '_' ) } ;", "del_tokens": "} ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "battlenet", "request", "methods", "for", "WoW", "Spells", "and", "SC2", "Profiles"], "add_tokens": "spell : require ( './wow/spell' ) ( battlenet ) profile : require ( './sc2/profile' ) ( battlenet )", "del_tokens": "spell : require ( './wow/spell' ) profile : require ( './sc2/profile' )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "loose", "comparison", "operators", "to", "strict", "."], "add_tokens": "if ( typeof tipText === 'function' ) { if ( typeof tipElem === 'function' ) { if ( placements [ 0 ] . y !== placements [ 1 ] . y || placements [ 0 ] . x !== placements [ 7 ] . x ) {", "del_tokens": "if ( typeof tipText == 'function' ) { if ( typeof tipElem == 'function' ) { if ( placements [ 0 ] . y != placements [ 1 ] . y || placements [ 0 ] . x != placements [ 7 ] . x ) {", "commit_type": "change"}
{"commit_tokens": ["Use", "reversed", "edges", "during", "rank", "phase", "only"], "add_tokens": "function verticalAlignment ( g , layering , type1Conflicts ) { var visited = { } ; visited [ v ] = true ; var related = g . neighbors ( v ) . filter ( function ( w ) { return w in visited ; } ) ; var align = verticalAlignment ( g , layering , type1Conflicts ) ;", "del_tokens": "function verticalAlignment ( g , layering , type1Conflicts , relationship ) { var related = g [ relationship ] ( v ) ; var align = verticalAlignment ( g , layering , type1Conflicts , vertDir === \"up\" ? \"predecessors\" : \"successors\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "ability", "to", "change", "module", "polling", "frequency"], "add_tokens": "var _pollFreq = 1000 ; this . setPollFreq = function ( timeout ) { clearTimeout ( pollHandle ) ; // Cancel scheduled polls if ( ! _ . isUndefined ( timeout ) ) self . _pollFreq = timeout ; pollHandle = setTimeout ( self . poll , self . _pollFreq ) ; return this ; } ; pollHandle = setTimeout ( self . poll , self . _pollFreq ) ; return this ;", "del_tokens": "pollHandle = setTimeout ( self . poll , 1000 ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "to", "prevent", "running", "unnecessary", "validations", "."], "add_tokens": "//loop through model validations //don't run validations if the attribute has not been provided and its not required if ( self . blueprint . actions [ req . action ] . params [ param ] . model . validate [ attribute ] . required === true || typeof parameters [ param ] [ attribute ] !== 'undefined' ) { modelValidations = modelValidations . concat ( self . app . services . validate . setup ( self . blueprint . actions [ req . action ] . params [ param ] . model . validate [ attribute ] , attribute , parameters [ param ] [ attribute ] , 'attribute' ) ) ; }", "del_tokens": "modelValidations = modelValidations . concat ( self . app . services . validate . setup ( self . blueprint . actions [ req . action ] . params [ param ] . model . validate [ attribute ] , attribute , parameters [ param ] [ attribute ] , 'attribute' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "a", "sleep", "command", "hack"], "add_tokens": "let docker = new Docker ( { socketPath : '/var/run/docker.sock' } ) OpenStdin : true await container . attach ( ) await container . remove ( { force : true } )", "del_tokens": "let docker = new Docker ( { socketPath : '/var/run/docker.sock' } ) Cmd : [ 'sleep' , '100' ] await container . remove ( { v : true , force : true } )", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "modulo", "bug", "in", "getInterval"], "add_tokens": "assert ( distance >= 0 && distance <= scale . length )", "del_tokens": "assert ( distance > 0 && distance <= scale . length )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "base", "layer", "selection", "in", "some", "cases"], "add_tokens": "if ( layers [ 0 ] . isBaseLayer )", "del_tokens": "if ( layers [ 0 ] . isBaseLayer && show )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "hoodie", ".", "admin", ".", "open"], "add_tokens": "return new Hoodie . Remote ( this . hoodie , options ) ;", "del_tokens": "return new Hoodie . Remote ( this , options ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "jshint", "happy", ".", "minor", "CHANGELOG", "update"], "add_tokens": "controller : function ( $scope ) { layerOptions . opacity = Number ( $scope . opacity ) ; } ) ( angular ) ;", "del_tokens": "controller : function ( $scope , $element , $attrs ) { layerOptions . opacity = Number ( $scope . opacity ) ; } ) ( angular ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "_", ".", "endsWith", "."], "add_tokens": "if ( filepath . length && ! _ . endsWith ( filepath , '/' ) ) {", "del_tokens": "if ( filepath . length && filepath [ filepath . length - 1 ] !== '/' ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "revoke", "method", "to", "meters", ".", "Created", "test", "for", "revoke", "meters"], "add_tokens": "var PATH_ASSIGN = '/meters/many/assign_to' ; var PATH_SHARE = '/meters/many/share_with' ; var PATH_REVOKE = '/meters/many/revoke' ; Meters . assign = _emShareAssign ( PATH_ASSIGN ) ; Meters . share = _emShareAssign ( PATH_SHARE ) ; Meters . revoke = _emRevoke ; function _emRevoke ( meterIds ) { return Api . request ( { url : Url . url ( PATH_REVOKE ) , method : 'PUT' , data : meterIds } ) ; }", "del_tokens": "Meters . assign = _emShareAssign ( '/meters/many/assign_to' ) ; Meters . share = _emShareAssign ( '/meters/many/share_with' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "root", "apiKey", "in", "EnrichIntegrationConfigStrategy", "."], "add_tokens": "return newError ( \"Application HREF '\" + application . href + \"' is not a valid Stormpath Application HREF.\" ) ;", "del_tokens": "return newError ( \"Application HREF is not a valid Stormpath Application HREF.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "showTimeControls", "branch", "of", "Cesium", "and", "fix", "tilt", "crash", "."], "add_tokens": "viewer . showTimeControls = true ; viewer . showTimeControls = false ; } ) , timeControlsInitiallyVisible : false", "del_tokens": "viewer . timeline . show = true ; viewer . animation . show = true ; viewer . timeline . show = false ; viewer . animation . show = false ; } )", "commit_type": "use"}
{"commit_tokens": ["Use", "lodash", ".", "defaults", "from", "gulp", "-", "util"], "add_tokens": "var defaults = require ( \"gulp/node_modules/gulp-util/node_modules/lodash.template/node_modules/lodash.defaults\" ) ; var fileOptions = defaults ( { } , options , file . jshint . opt ) ;", "del_tokens": "var _ = require ( \"gulp/node_modules/liftoff/node_modules/findup-sync/node_modules/lodash\" ) ; var fileOptions = _ . defaults ( { } , options , file . jshint . opt ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "browsers", "test", "with", "zuul", "in", "CI"], "add_tokens": ". pipe ( mocha ( { reporter : 'mocha-better-spec-reporter' , timeout : '10s' } ) ) ; . pipe ( mocha ( { reporter : 'mocha-better-spec-reporter' , timeout : '10s' } ) ) ;", "del_tokens": ". pipe ( mocha ( { reporter : 'tap' , timeout : '10s' } ) ) ; . pipe ( mocha ( { reporter : 'tap' , timeout : '10s' } ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "builder", "envs", "action", "."], "add_tokens": "var FLAG_BUFFER = { desc : \"Buffer output until process end (default: `false`)\" , types : [ Boolean ] , default : false } ; buffer : FLAG_BUFFER } , envs : { tries : FLAG_TRIES , queue : FLAG_QUEUE , buffer : FLAG_BUFFER , \"envs-path\" : { desc : \"Path to JSON env variable array file (default: `null`)\" , types : [ path ] , default : null", "del_tokens": "buffer : { desc : \"Buffer output until process end (default: `false`)\" , types : [ Boolean ] , default : false", "commit_type": "implement"}
{"commit_tokens": ["Adding", "basic", "edge", "counting", "methods"], "add_tokens": "import { capitalize , deepMerge , sameMembers , testBunches } from '../helpers' ; const counterName = 'count' + capitalize ( name ) ; // Array-creators } , // Counters [ '#.' + counterName ] : { 'it should count all the relevant edges.' : function ( ) { const nb = graph [ counterName ] ( ) ; assert . strictEqual ( nb , data . all . length ) ; } METHODS . forEach ( name => deepMerge ( tests , commonTests ( 'count' + capitalize ( name ) ) ) ) ;", "del_tokens": "import { deepMerge , sameMembers , testBunches } from '../helpers' ; // TEMP if ( ! data . path ) return ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "UpUp", "homepage", "url", "in", "API", "docs"], "add_tokens": "* The quickest way to get started is to visit the [ UpUp homepage ] ( https : //www.talater.com/upup/).", "del_tokens": "* The quickest way to get started is to visit the [ UpUp homepage ] ( http : //UpUp.rocks/).", "commit_type": "update"}
{"commit_tokens": ["Add", "HTTP", "/", "2", "example"], "add_tokens": "// Node.js 8: node async_await.js // Visit: http://127.0.0.1:3000/", "del_tokens": "// `/path-to-node-v7/node --harmony example/async_await.es.js`", "commit_type": "add"}
{"commit_tokens": ["fixed", "problem", "with", "iterating", "realms"], "add_tokens": "\"use strict\" ; var requestedRealmMetadata ; for ( let i = 0 ; i < req . realms . length ; i ++ ) { let match = req . realms [ i ] . find ( realmOrVariantMatchesRequestUrl ( req . url ) ) ; if ( match ) { requestedRealmMetadata = match ; break ; } } if ( ! requestedRealmMetadata ) return next ( ) ; var variants = requestedRealmMetadata . variants ; var realms = requestedRealmMetadata . realms ; data . realm = requestedRealmMetadata . realm ; var variantName = query . variant || requestedRealmMetadata . getDefaultVariant ( ) || \"default\" ;", "del_tokens": "console . log ( \"REALM URL\" , realmOrVariantUrl ) ; var metadata = req . realms . find ( realmOrVariantMatchesRequestUrl ( req . url ) ) ; console . log ( \"REQ URL\" , req . url ) ; console . log ( \"META\" , metadata ) ; if ( ! metadata ) return next ( ) ; var variants = metadata . variants ; var realms = metadata . realms ; data . realm = metadata . realm ; var variantName = query . variant || metadata . getDefaultVariant ( ) || \"default\" ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "baseUrl", "when", "serving", "the", "site", "."], "add_tokens": ". option ( '-b, --baseUrl <baseUrl>' , 'Base url for the live server (Default is \"/\")' ) options . baseUrl = options . baseUrl || '/' ; port : options . port || 8080 , mount : [ [ options . baseUrl , outputFolder ] ]", "del_tokens": "port : options . port || 8080", "commit_type": "add"}
{"commit_tokens": ["Add", "timout", "for", "DynamoDB", "requests"], "add_tokens": "var CLIENTS = { } , DEFAULT_TIMEOUT = 3000 ; Field : Type : Description : key String DynamoDB Key v String Value t Number Time created i Boolean Invalidation flag c Boolean Compression flag tableName : The name of your DynamoDB table . awsConfig : aws - sdk config . compress : Compress values ( default = false ) requestTimeout : Timeout for requests to Dynamo ( default = 3 s ) . timeout ( this . opt . requestTimeout || DEFAULT_TIMEOUT ) . putItem ( this . makeDDBPutParams ( this . key , val ) ) . timeout ( this . opt . requestTimeout || DEFAULT_TIMEOUT ) ;", "del_tokens": "var CLIENTS = { } ; field : type : key String v String t Number i Boolean c Boolean tableName : The name of your DynamoDB table awsConfig : aws - sdk config . compress : compress values ( default = false ) . putItem ( this . makeDDBPutParams ( this . key , val ) ) ;", "commit_type": "add"}
{"commit_tokens": ["updating", "jsDoc", "comments", "...", "wip!"], "add_tokens": "* * * @ private * Callback function used with the ` ` method . * * @ callback ElementsIterationCallback * @ param { ElementsIterationCallback } iterationCallback The callback * fn * to call for each element in the selection", "del_tokens": "* The ` ` function . * @ callback InstanceIterationCallback * @ param { InstanceIterationCallback } iterationCallback The callback * fn * to call at each iteration", "commit_type": "update"}
{"commit_tokens": ["Add", "base", "api", "for", "events", "and", "tests"], "add_tokens": "var register = function ( method , path , handler , options ) { 'handler' : handler , 'options' : _ . defaults ( options || { } , { auth : true , needed : [ ] } ) var args = _ . extend ( { } , req . query , req . body ) ; if ( _ . size ( method . options . needed ) > 0 && ! _ . contains . apply ( null , [ _ . keys ( args ) ] . concat ( method . options . needed ) ) ) { throw \"Need: \" + method . options . needed . join ( \", \" ) ; } return method . handler ( args ) ;", "del_tokens": "var register = function ( method , path , handler ) { 'handler' : handler return method . handler ( req . query , req . body ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "bug", "of", "the", "line", "begins", "with", "a", "space"], "add_tokens": "for ( let i = updatedOffset ; i < updatedOffset + length && i < characters . size ; i ++ ) {", "del_tokens": "for ( let i = updatedOffset ; i < updatedOffset + length ; i ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "native", "implementations", "of", "partial", "/", "bind", "forEach", "map", "reduce", "and", "filter"], "add_tokens": "first , apply , compose , when , equals , unary , flippedCall , mapArray ( unary ( partial ( flippedCall , val ) ) , stream . subscribers ) ; mapArray ( unary ( partial ( flippedCall , f ) ) , stream . subscriberSubscribers ) ; mapArray ( flippedCall , stream . closeSubscribers ) ; mapArray ( flippedCall , stream . emptySubscribers ) ;", "del_tokens": "first , apply , compose , when , equals , mapArray ( partial ( flip ( call ) , val ) , stream . subscribers ) ; mapArray ( partial ( flip ( call ) , f ) , stream . subscriberSubscribers ) ; mapArray ( flip ( call ) , stream . closeSubscribers ) ; mapArray ( flip ( call ) , stream . emptySubscribers ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "typo", "in", "the", "comment", "of", "storageserviceclient", ".", "js"], "add_tokens": "// we'll send the steam by chunk buffers which doesn't have this issue.", "del_tokens": "// we'll sent the steam by chunk buffers which doesn't have this issue.", "commit_type": "fix"}
{"commit_tokens": ["fixing", "issue", "with", "FAILURES", "message", "at", "end", "of", "tests"], "add_tokens": "var failure = PFT . tester . outQueue [ i ] . failures [ j ] ; var msg = \"Completed '\" + PFT . tester . outQueue . length + \"' tests in \" + duration + \" with \" + passes + \" passes, \" +", "del_tokens": "var failure = PFT . tester . outQueue [ i ] . failures [ i ] ; var msg = \"Completed all tests in \" + duration + \" with \" + passes + \" passes, \" +", "commit_type": "fix"}
{"commit_tokens": ["Added", "fetcher", "function", "to", "update", "DBO", "."], "add_tokens": "* @ param { ( Array . < Array > | module : x2node - dbos ~ UpdateDBO ~ recordsFetcher ) } [ filterOrFetcher ] * Either , filter specification or function that provides the DBO with * records , on which to perform the update . If fetcher function is provided , * the DBO will not * perform the initial fetch and lock for the records . If * neither filter nor fetcher function is specified , all records of the type * are fetched , locked and updated ( should be exceptionally rare case ) . buildUpdate ( recordTypeName , patch , filterOrFetcher ) { filterOrFetcher ) ;", "del_tokens": "* @ param { Array . < Array > } [ filter ] The filter specification . If unspecified , * all records of the type are updated . buildUpdate ( recordTypeName , patch , filterSpec ) { filterSpec ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "initialisation", ".", "Hopefullyer", "."], "add_tokens": "Promise . all ( proms ) . then (", "del_tokens": "proms [ proms . length - 1 ] . then (", "commit_type": "fix"}
{"commit_tokens": ["remove", "hard", "-", "coded", "group", "styles"], "add_tokens": "nodeSel . attr ( 'class' , d => ` ${ ( d . data || { } ) . style || 'default' } ` enter . append ( 'rect' ) ;", "del_tokens": "nodeSel . attr ( 'class' , d => ` ${ ( d . data || { } ) . style || 'default' } ` enter . append ( 'rect' ) . style ( 'fill' , '#eee' ) . style ( 'stroke' , '#bbb' ) . style ( 'stroke-width' , '0.5' ) ; . style ( 'fill' , '#999' ) exports . ease = function ( _x ) { if ( ! arguments . length ) return ease ; ease = _x ; return this ; } ;", "commit_type": "remove"}
{"commit_tokens": ["improving", "plugin", "api", "new", "plugin", "pretty", "-", "error", "updating", "deps"], "add_tokens": "export default ( { prependRest = true } = { } ) => { return ( ctx ) => { let newStats = JSON . parse ( JSON . stringify ( ctx . stats ) ) ; // quick deep cloning let newRest = ctx . args . slice ( ) ; ctx . stats = newStats ; ctx . args = newRest ;", "del_tokens": "export default ( { prependRest = true } = { } ) => { return ( id , level , stats , ... rest ) => { let newStats = JSON . parse ( JSON . stringify ( stats ) ) ; // quick deep cloning let newRest = rest . slice ( ) ; return [ id , level , newStats , ... newRest ] ;", "commit_type": "improve"}
{"commit_tokens": ["Make", "tests", "independent", "of", "the", "cwd"], "add_tokens": "{ rootDir : __dirname + '/plugin-fs' } ) ; var rootDir = __dirname + '/plugin-fs' ; var rootDir = __dirname + '/plugin-fs' ; var rootDir = __dirname + '/plugin-fs' ; var rootDir = __dirname + '/plugin-fs' ; var rootDir = __dirname + '/plugin-fs' ;", "del_tokens": "{ rootDir : './plugin-fs' } ) ; var rootDir = fs . realpathSync ( './plugin-fs' ) ; var rootDir = fs . realpathSync ( './plugin-fs' ) ; var rootDir = fs . realpathSync ( './plugin-fs' ) ; var rootDir = fs . realpathSync ( './plugin-fs' ) ; var rootDir = fs . realpathSync ( './plugin-fs' ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "currying", "forms", "of", "contains", "()", "&", "pull", "()", "for", "compose", "()", "/", "pipe", "()", "usages"], "add_tokens": "if ( arguments . length == 1 ) { // Manually currying value = list ; return ( list ) => contains ( list , value ) ; } } , false ) * @ returns boolean as follower . Returns values in follower that aren ' t in main pull : function pull ( list , ... values ) { if ( ! ( list && Array . isArray ( list ) ) ) { // Manually currying values = arguments ; return ( list ) => pull ( list , ... values ) ; }", "del_tokens": "} , false ) * @ returns boolean as follower . Returns values in follower that aren ' t in main pull : function ( list , ... values ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "for", "geocoding", "API", "."], "add_tokens": "validator : v . object ( { address : v . optional ( v . string ) , components : v . optional ( utils . pipedKeyValues ) , bounds : v . optional ( utils . bounds ) , region : v . optional ( v . string ) , language : v . optional ( v . string ) , retryOptions : v . optional ( utils . retryOptions ) } )", "del_tokens": "validator : v . compose ( [ v . mutuallyExclusiveProperties ( [ 'address' , 'components' ] ) , v . object ( { address : v . optional ( v . string ) , components : v . optional ( utils . pipedKeyValues ) , bounds : v . optional ( utils . bounds ) , region : v . optional ( v . string ) , language : v . optional ( v . string ) , retryOptions : v . optional ( utils . retryOptions ) } ) ] )", "commit_type": "add"}
{"commit_tokens": ["Adding", "preliminary", "support", "for", "listing", "npm", "modules"], "add_tokens": "// this makes me feel dirty. :( readInstalled = require ( __dirname + '/../node_modules/npm/lib/utils/read-installed.js' ) ; var module_cache = false ; module . exports . getModules = function getModules ( callback ) { if ( module_cache ) { return callback ( module_cache ) ; } readInstalled ( '.' , function ( err , list ) { if ( err ) { // uh oh, ignore silently return callback ( { } ) ; } module_cache = { } ; for ( var module in list . dependencies ) { var m = list . dependencies [ module ] ; module_cache [ m . name ] = m . version ; } cb ( module_cache ) ; } ) ; } ; module . exports . getModules = function ( ) { return module_cache ; } ; var LINES_OF_CONTEXT = 7 ;", "del_tokens": "LINES_OF_CONTEXT = 7 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "showTimeSpent", "option", "to", "visual", "test", "s", "config", "-", "template"], "add_tokens": "rstTitle : 'Gas Usage' , showTimeSpent : true", "del_tokens": "rstTitle : 'Gas Usage'", "commit_type": "add"}
{"commit_tokens": ["Use", "find", "-", "file", "to", "lookup", "imports"], "add_tokens": "var findFile = require ( 'find-file' ) ; var style = css . parse ( data ) . stylesheet ; file = findFile ( name , this . path , false ) [ 0 ] ;", "del_tokens": "var style ; style = css . parse ( data ) . stylesheet ; this . path = Array . isArray ( this . path ) ? this . path : [ this . path ] ; file = this . path . map ( function ( dir ) { return path . join ( dir , name ) ; } ) . filter ( fs . existsSync ) [ 0 ] ;", "commit_type": "use"}
{"commit_tokens": ["add", "big", "tasks", "for", "example"], "add_tokens": "read : function ( src , dest , fileObject ) { compressAndSplitJsonByKey : { options : { // read file and convert to JSON read : function ( src , dest , fileObject ) { return grunt . file . readJSON ( src ) ; } , // add someKey to content object process : function ( src , dest , content , fileObject ) { content . someKey = 123 ; return content ; } , // split json by object key save : function ( src , dest , content , fileObject ) { var files = { } ; _ . each ( content , function ( v , k ) { var file = fileObject . orig . dest + '/' + k + '.json' ; files [ file ] = JSON . stringify ( v ) ; } ) ; return files ; } } , files : [ { expand : true , cwd : 'tests/source/compress_and_split' , dest : '.tmp/compress_and_split' , src : [ '**/*.json' ] } ] } , read : function ( src , dest , fileObject ) {", "del_tokens": "read : function ( src , dest , readOptions , fileObject ) { read : function ( src , dest , readOptions , fileObject ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "refreshing", "tokens", "actually", "work", "and", "write", "tests", "for", "it", "."], "add_tokens": "switch ( response . status ) { if ( response . body . error === 'invalid_token' || response . body . error_description === 'expired_token' ) { this . _refreshToken ( this . request . bind ( this , request . method , request . path , request . data , options . callback , resolveRejectOptions ) ) ; } else { this . _clearAuthentication ( ) ; throw new PodioErrors . PodioAuthorizationError ( response . body , response . status , request . url ) ;", "del_tokens": "switch ( status ) { if ( body . error === 'invalid_token' ) { this . _refreshToken ( this . request . bind ( request . method , request . path , request . data , options . callback , resolveRejectOptions ) ) ;", "commit_type": "make"}
{"commit_tokens": ["change", "sails", ".", "lift", "to", "sails", ".", "load", "because", "sails", ".", "lift", "init", "http", "server", "and", "now", "port", "value", "-", "1", "is", "forbidden", "."], "add_tokens": "sails . load ( sailsConfig , function ( err ) {", "del_tokens": "sails . lift ( sailsConfig , function ( err ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "classifiedTiming", "calls", "in", "proxy", "timing"], "add_tokens": "statsd . classifiedTiming ( req . url , 'proxy_headers_received' , req . __proxyTimingFunctionHeadersReceived ( 'Received headers ' + req . url ) ) ; statsd . classifiedTiming ( req . url , 'proxy_body_received' , req . __proxyTimingFunctionBodyReceived ( 'Received body ' + req . url ) ) ;", "del_tokens": "statsd . classifiedTiming ( 'proxy_headers_received' , req . __proxyTimingFunctionHeadersReceived ( 'Received headers ' + req . url ) ) ; statsd . classifiedTiming ( 'proxy_body_received' , req . __proxyTimingFunctionBodyReceived ( 'Received body ' + req . url ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "trailing", "slashes", "in", "readdir", "requests"], "add_tokens": "it ( \"returns only the expected contents when using trailing slashes (#56)\" , function ( done ) { this . client . readdir ( \"/dir1/\" , ( err , contents ) => { expect ( err ) . to . be . null ; expect ( contents ) . to . deep . equal ( [ \"dir2\" ] ) ; done ( ) ; } ) ; } ) ;", "del_tokens": "// This should work in the future:", "commit_type": "add"}
{"commit_tokens": ["Adding", "native", "JS", "mesh", "settings", "register", "object", "for", "easier", "manipulation", "."], "add_tokens": "var ubeacon = new UBeaconUARTController ( program . serialPort , 115200 ) ;", "del_tokens": ". option ( '-b, --baud-rate [baud]' , 'Baud rate' , parseInt , 115200 ) var ubeacon = new UBeaconUARTController ( program . serialPort , program . baudRate ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "codesearch", "plugin", "(", "ack", "equivalent", ")", "to", "jsDAV"], "add_tokens": "var reportName = Util . toClarkNotation ( dom ) ;", "del_tokens": "var reportName = Util . toClarkNotation ( dom . firstChild ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "tests", "+", "add", "support", "for", "single", "file", "reading"], "add_tokens": "return this . selectAll ( type , options ) [ 0 ] return new Selection ( this . type , this . params , this . content . filter ( f ) , this . original )", "del_tokens": "return select ( this . selectAll ( type , options ) [ 0 ] ) return new Selection ( this . type , this . params , this . content . filter ( f ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "for", "max", "number", "of", "bars"], "add_tokens": "var that = this ; return data . slice ( 0 , that . model . get ( \"configuration.max\" , 4 ) ) ; 'field' : { 'type' : \"text\" , 'label' : \"Field\" } , 'max' : { 'type' : \"number\" , 'label' : \"Max Bars\" , 'min' : 1 , 'max' : 100 , 'default' : 4", "del_tokens": "return data . slice ( 0 , 4 ) ; field : { type : \"text\" , label : \"Field\"", "commit_type": "add"}
{"commit_tokens": ["add", "transitionOnRouteUpdate", "flag", "to", "enable", "or", "disable", "the", "transition", "on", "beforeRouteUpdate"], "add_tokens": "this . transitionOnRouteUpdate = false ; // trigger a transitionOut and transitionIn again. But sometimes we don't want this, therefore is requires the flag 'transitionOnRouteUpdate' ! this . _isDestroyed && this . transitionOnRouteUpdate", "del_tokens": "// trigger a transitionOut and transitionIn again. ! this . _isDestroyed", "commit_type": "add"}
{"commit_tokens": ["Moved", "example", "hosting", "to", "heroku"], "add_tokens": "/ ** * Create the angular - keyboard . js and angular - keyboard . min . js files . * / / ** * Watch for file - changes , start a livereload server and rebuild on every change . * / gulp . watch ( [ 'bower-angular-keyboard/*.js' , 'minisite/**/*.html' ] ) . on ( 'change' , livereload . changed ) ;", "del_tokens": "gulp . watch ( [ 'bower-angular-keyboard/*.js' , 'Examples/*.html' ] ) . on ( 'change' , livereload . changed ) ;", "commit_type": "move"}
{"commit_tokens": ["Made", "Transition", "setup", "non", "browser", "dependant"], "add_tokens": "CCLAnim . setTransition ( an . parent , \"all \" + an . ttl + \"ms linear\" ) ;", "del_tokens": "an . parent . style . transition = \"all \" + an . ttl + \"ms linear\" ;", "commit_type": "make"}
{"commit_tokens": ["use", "fireIf", "from", "utils", "in", "monitor"], "add_tokens": "return VisSenseUtils . fireIf ( function ( ) { } , callback ) ; return VisSenseUtils . fireIf ( function ( ) { var handler = this . fireIfVisibilityChanged ( VisSenseUtils . fireIf ( function ( ) {", "del_tokens": "function _noop ( ) { } function fireIf ( when , callback ) { return function ( ) { if ( when ( ) ) { callback ( arguments ) ; } } ; } return fireIf ( function ( ) { } , function ( ) { callback ( ) ; } ) ; return fireIf ( function ( ) { var handler = this . fireIfVisibilityChanged ( fireIf ( function ( ) {", "commit_type": "use"}
{"commit_tokens": ["updated", "doc", "and", "added", "some", "examples"], "add_tokens": "var extend = require ( 'extend' ) , uuid = require ( 'node-uuid' ) ; var m = new Message ( extend ( { } , this . data ) ) ;", "del_tokens": "var uuid = require ( 'node-uuid' ) ; var m = new Message ( this . data ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixing", "bug", "of", "the", "line", "begins", "with", "a", "space"], "add_tokens": "let result = / ^\\s+$ / . exec ( string ) ; if ( result ) { return [ result [ 0 ] ] ; } result = / ^[ ]+ / . exec ( string ) ; return tokens ;", "del_tokens": "let result = / ^[ ]+ / . exec ( string ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "how", "the", "server", "is", "configured"], "add_tokens": "// If there is a database, connect to the database. Otherwise, proceed // with acting as if we are connected to an imaginary database.", "del_tokens": "server . static ( path . resolve ( this . _appPath , '../public_html' ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fixing", "amount", "of", "parts", "in", "drawing", "chart"], "add_tokens": "for ( var i = 0 ; i <= numberOfParts ; i ++ ) {", "del_tokens": "for ( var i = 0 ; i < numberOfParts ; i ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "cache", "busters", "to", "async", "false", "test"], "add_tokens": "// add cache busters var pathsUncached = paths . slice ( 0 ) ; pathsUncached [ 0 ] += '?_=' + Math . random ( ) ; pathsUncached [ 1 ] += '?_=' + Math . random ( ) ; loadjs ( pathsUncached , {", "del_tokens": "loadjs ( paths , {", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "reference", "to", "the", "indexed", "-", "db", ".", "es6", "library", "in", "the", "documentation"], "add_tokens": "* @ param { Transaction } transaction The current indexed - db . es6 read - write * The current indexed - db . es6 read - write transaction to use to perform the", "del_tokens": "* @ param { Transaction } transaction The current IndexedDB . ES6 read - write * The current IndexedDB . ES6 read - write transaction to use to perform the", "commit_type": "fix"}
{"commit_tokens": ["improve", "handling", "of", "unencoded", "commas"], "add_tokens": "const sparseField = Array . isArray ( query [ parameter ] ) ? query [ parameter ] : query [ parameter ] . split ( ',' ) const value = Array . isArray ( query [ parameter ] ) ? query [ parameter ] : query [ parameter ] . split ( ',' ) request . include = ( Array . isArray ( query [ reservedKeys . include ] ) ? query [ reservedKeys . include ] : query [ reservedKeys . include ] . split ( ',' ) ) request . options . sort = ( Array . isArray ( query . sort ) ? query . sort : query . sort . split ( ',' ) )", "del_tokens": "const sparseField = query [ parameter ] . split ( ',' ) const value = query [ parameter ] . split ( ',' ) request . include = query [ reservedKeys . include ] . split ( ',' ) request . options . sort = query . sort . split ( ',' )", "commit_type": "improve"}
{"commit_tokens": ["Use", "jit", "-", "grunt", "for", "loading", "grunt", "plugins", "."], "add_tokens": "require ( 'jit-grunt' ) ( grunt ) ;", "del_tokens": "grunt . loadNpmTasks ( 'grunt-contrib-jshint' ) ; grunt . loadNpmTasks ( 'grunt-contrib-uglify' ) ; grunt . loadNpmTasks ( 'grunt-contrib-concat' ) ; grunt . loadNpmTasks ( 'grunt-contrib-watch' ) ; grunt . loadNpmTasks ( 'grunt-browserify' ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "fallback", "when", "cache", "disk", "path", "does", "not", "exist", "yet", "."], "add_tokens": "// module 'allume.request.github.0.1.13/' define . parameters . id = \"allume.request.github.0.1.13/\" ; \"version\" : \"0.1.13\" , function cacheQueryDone ( uriList ) { if ( uriList && uriList . code == \"ENOENT\" ) { uriList = [ ] ; } else { console . error ( \"Cache disk error.\" , uriList ) ; resolveURI ( release ? release . tarball_url : null ) ; } } cacheVolume . query ( PATH_CACHE ) . then ( cacheQueryDone , cacheQueryDone ) ;", "del_tokens": "// module 'allume.request.github.0.1.12/' define . parameters . id = \"allume.request.github.0.1.12/\" ; \"version\" : \"0.1.12\" , cacheVolume . query ( PATH_CACHE ) . then ( function ( uriList ) { } , function ( ) { // cache path error resolveURI ( release ? release . tarball_url : null ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "Dockerfiles", "to", "use", "newest", "node"], "add_tokens": "} , \"generate-vim-tags-file\" : { command : function ( ) { var cmd = 'find . -name \"*.js\" -path \"./src/*\" | xargs jsctags {} -f | sed \"/^$/d\" | sort > tags' ; return cmd ; } } , \"get-node-version\" : { command : function ( ) { var cmd = 'echo \"Fetching node version...\\n\" && node --version' ; return cmd ; } } , 'shell:get-node-version' ,", "del_tokens": "\"generate-vim-tags-file\" : { command : function ( ) { var cmd = 'find . -name \"*.js\" -path \"./src/*\" | xargs jsctags {} -f | sed \"/^$/d\" | sort > tags' ; return cmd ; } } , }", "commit_type": "update"}
{"commit_tokens": ["Fix", "reference", "error", "s", "/", "localval", "/", "local"], "add_tokens": "} else if ( check . call ( local ) == \"[object Object]\" ) {", "del_tokens": "} else if ( check . call ( localval ) == \"[object Object]\" ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "where", "settings", "werent", "resolved"], "add_tokens": "this . settings = settings = resolveSettings ( settings ) ; this . settings = settings = resolveSettings ( settings ) ; this . settings = settings = resolveSettings ( settings ) ; this . settings = settings = resolveSettings ( settings ) ; this . settings = settings = resolveSettings ( settings ) ; this . settings = settings = resolveSettings ( settings ) ;", "del_tokens": "this . settings = resolveSettings ( settings ) ; this . settings = resolveSettings ( settings ) ; this . settings = resolveSettings ( settings ) ; this . settings = resolveSettings ( settings ) ; this . settings = resolveSettings ( settings ) ; this . settings = resolveSettings ( settings ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typos", "in", "log", "."], "add_tokens": "\"Write conflicting session exception for notifyNewSession\" : function ( test ) { \"Write notification exception for notifyNewSession\" : function ( test ) { \"Write notification exception for notifyNewSession\" : function ( test ) {", "del_tokens": "\"Write credits exception for notifyNewSession\" : function ( test ) { \"Write credits exception for notifyNewSession\" : function ( test ) { \"Write credits exception for notifyNewSession\" : function ( test ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "spdx", "-", "license", "-", "ids", "module", "to", "DRY", "it", "up"], "add_tokens": ". concat ( require ( 'spdx-license-ids' ) . map ( ret ( 'LICENSE' ) ) )", "del_tokens": ". concat ( require ( '../source/licenses' ) . map ( ret ( 'LICENSE' ) ) )", "commit_type": "use"}
{"commit_tokens": ["Updated", "double", "sharp", "to", "cross", "ANSI", "x", ".", "Reflected", "in", "tests"], "add_tokens": "'2' : 'x' } ; var SIGNTOACCIDENTAL = { 'bb' : - 2 , 'b' : - 1 , '#' : 1 , 'x' : 2 var parser = name . match ( / ^([abcdefgh])(x|#|bb|b?)(-?\\d*) / i ) ; // 1 = note, 2 = accidentals, 3 = octave this . accidental . value = SIGNTOACCIDENTAL [ parser [ 2 ] ] ; var info = name . match ( / ^(,*)([abcdefgh])(x|#|bb|b?)([,\\']*)$ / i ) ; // 1 = pre, 2 = note, 3 = accidentals, 4 = pro this . accidental . value = SIGNTOACCIDENTAL [ info [ 3 ] ] ; root = name . match ( / ^([abcdefgh])(x|#|bb|b?) / i ) ;", "del_tokens": "'2' : '##' var parser = name . match ( / ^([abcdefgh])(##|#|bb|b?)(-?\\d*) / i ) ; // 1 = note, 2 = accidentals, 3 = octave this . accidental . value = ( parser [ 2 ] [ 0 ] === 'b' ) ? ( - parser [ 2 ] . length ) : ( parser [ 2 ] . length ) ; var info = name . match ( / ^(,*)([abcdefgh])(##|#|bb|b?)([,\\']*)$ / i ) ; // 1 = pre, 2 = note, 3 = accidentals, 4 = pro this . accidental . value = ( info [ 3 ] [ 0 ] === 'b' ) ? ( - info [ 3 ] . length ) : ( info [ 3 ] . length ) ; root = name . match ( / ^([abcdefgh])(##|#|bb|b?) / i ) ;", "commit_type": "update"}
{"commit_tokens": ["update", "chimera", "version", "dependencies", "on", "project", "template"], "add_tokens": "chimera . executeYaml ( fileName , inputs , presets , function ( data , success , errorMessage ) {", "del_tokens": "chimera . executeYaml ( fileName , inputs , presets , function ( data , success ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "tokens", "metadata", "file"], "add_tokens": "const gMeta = require ( './build-meta.js' ) ; if ( args . build . includes ( 'meta' ) ) { promises . push ( ( ) => { const filename = 'metadata.json' ; return gMeta ( ` ${ filename } ` , ` ${ filename } ` , pkgjson . version ) ; } ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["make", "--", "name", "and", "--", "machineType", "optional", "on", "jobs", "create", "method"], "add_tokens": "* @ param { string } [ params . machineType ] - An optional machine type to run the job on : either 'GPU+' , 'P4000' , 'P5000' , 'P6000' , 'V100' , 'C1' , 'C2' , 'C3' , 'C4' , 'C5' , 'C6' , 'C7' , 'C8' , 'C9' , or 'C10' . < p > Defaults to 'GPU+' . * machineType : 'P6000' , * -- container \"http://dockerhub.com/mycontainer\" \\ * -- machineType \"P6000\" * POST / jobs / createJob { \"container\" : \"http://dockerhub.com/mycontainer\" , \"machineType\" : \"P6000\" } * \"name\" : \"job for project myproject\" ,", "del_tokens": "* @ param { string } params . machineType - Job type : either 'GPU+' , 'P4000' , 'P5000' , 'P6000' , 'V100' , 'C1' , 'C2' , 'C3' , 'C4' , 'C5' , 'C6' , 'C7' , 'C8' , 'C9' , or 'C10' < p > * name : 'myjob' , * machineType : 'P6000' , * -- name \"myjob\" \\ * -- machineType \"P6000\" \\ * -- container \"http://dockerhub.com/mycontainer\" * POST / jobs / createJob { \"name\" : \"myjob\" , \"machineType\" : \"P6000\" , \"container\" : \"http://dockerhub.com/mycontainer\" } * \"name\" : \"myjob\" , if ( ! params . name ) params . name = 'job for project ' + ( params . project || params . projectId ) ; machineType : 'string' ,", "commit_type": "make"}
{"commit_tokens": ["Changed", "output", "slightly", "-", "needed", "to", "change", "test", "to", "get", "correct", "data", "."], "add_tokens": "var live = community . gseCrypto . hash ( params ) . output ;", "del_tokens": "var live = community . gseCrypto . hash ( params ) ;", "commit_type": "change"}
{"commit_tokens": ["remove", "cpr", "and", "make", "qdd", "smarter"], "add_tokens": "var rm = require ( 'rimraf' ) . sync * qdd installs modules using package - lock . json let env = process . env // env.QDD_DEBUG = 1 // env.QDD_NOCACHE = 1 rm ( path . join ( lock , 'node_modules' ) ) let p = spawn ( qdd , [ ] , { cwd : lock , shell : true , env } ) p . stderr . on ( 'data' , ( data ) => { console . log ( ` ${ data } ` ) ; } ) p . stdout . on ( 'data' , ( data ) => { console . log ( ` ${ data } ` ) ; } )", "del_tokens": "* cipm install modules using package - lock . json let p = spawn ( qdd , [ ] , { cwd : lock , shell : true , } )", "commit_type": "remove"}
{"commit_tokens": ["Updated", "to", "latest", "tsprojvect", "changes"], "add_tokens": "var tsResult = tsProject . src ( './src' ) ; return merge2 ( gulp . src ( files ) , tsResult ) . pipe ( sourcemaps . init ( ) ) . pipe ( concat ( 'exceptionless.js' ) ) . pipe ( gulp . dest ( 'dist' ) ) . pipe ( rename ( 'exceptionless.min.js' ) ) . pipe ( uglify ( ) ) . pipe ( sourcemaps . write ( '.' ) ) . pipe ( gulp . dest ( 'dist' ) ) ;", "del_tokens": "var tsconfig = require ( './src/tsconfig.json' ) ; var tsResult = gulp . src ( fixFilePath ( tsconfig . files ) ) . pipe ( ts ( tsconfig . compilerOptions ) ) ; //var tsResult = tsProject.src('./src'); return merge2 ( tsResult . dts . pipe ( gulp . dest ( 'dist' ) ) , merge2 ( gulp . src ( files ) , tsResult . js ) . pipe ( sourcemaps . init ( ) ) . pipe ( concat ( 'exceptionless.js' ) ) . pipe ( gulp . dest ( 'dist' ) ) . pipe ( rename ( 'exceptionless.min.js' ) ) . pipe ( uglify ( ) ) . pipe ( sourcemaps . write ( '.' ) ) . pipe ( gulp . dest ( 'dist' ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "exports", "detection", "to", "be", "compatible", "with", "browserify"], "add_tokens": "( d . WeakSet = f ( { \"delete\" : g , add : q , clear : h , has : m } , ! 0 ) ) } ) ( \"undefined\" != typeof exports && \"undefined\" != typeof global ? global : window ) ;", "del_tokens": "( d . WeakSet = f ( { \"delete\" : g , add : q , clear : h , has : m } , ! 0 ) ) } ) ( \"undefined\" == typeof exports ? window : global ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "check", "for", "assert", ".", "deepStrictEqual"], "add_tokens": "assert . deepStrictEqual ( stdout , String ( expected ) ) ; assert . deepStrictEqual ( stderr , '' ) ; assert . deepStrictEqual ( stdout , expected ) ; assert . deepStrictEqual ( stderr , Buffer . alloc ( 0 ) ) ; assert . deepStrictEqual ( stdout , String ( expected ) ) ; assert . deepStrictEqual ( stdout , expected ) ;", "del_tokens": "const deepEqual = assert . deepStrictEqual || assert . deepEqual ; deepEqual ( stdout , String ( expected ) ) ; deepEqual ( stderr , '' ) ; deepEqual ( stdout , expected ) ; deepEqual ( stderr , Buffer . alloc ( 0 ) ) ; deepEqual ( stdout , String ( expected ) ) ; deepEqual ( stdout , expected ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "which", "using", "the", "cornerRadius", "property", "repositioned", "the", "rectangle"], "add_tokens": "return this [ 0 ] . getContext ( ctx || '2d' ) ; x1 = params . x - params . width / 2 ; y1 = params . y - params . height / 2 ; x2 = params . x + params . width / 2 ; y2 = params . y + params . height / 2 ;", "del_tokens": "return this [ 0 ] . getContext ( '2d' ) ; x1 = params . x ; y1 = params . y ; x2 = params . x + params . width ; y2 = params . y + params . height ;", "commit_type": "fix"}
{"commit_tokens": ["add", "sort", "to", "collexction", "listener"], "add_tokens": "this . listenTo ( this . _items , 'add change remove sort' , this . renderItems ) ;", "del_tokens": "this . listenTo ( this . _items , 'add change remove' , this . renderItems ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "useless", "model", "construction", "from", "collection", "save", "the", "GC", "some", "pain"], "add_tokens": "if ( conf . model == null ) { throw new Error ( 'Missing model' ) ; } if ( conf . model . spec == null ) { throw new Error ( 'Model is missing a spec' ) ; } conf . sync = conf . model . spec . sync || sync ; conf . url = conf . model . spec . urlRoot ;", "del_tokens": "var inst = new conf . model ( ) ; conf . sync = inst . sync || sync ; conf . url = inst . urlRoot ; } if ( inst . spec == null ) { inst . spec = conf ;", "commit_type": "remove"}
{"commit_tokens": ["add", "form", "-", "validation", "demo"], "add_tokens": "RadioGroup : require ( './components/radio/group' ) , Validation : require ( './components/validation' )", "del_tokens": "RadioGroup : require ( './components/radio/group' )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "imports", "option"], "add_tokens": "let importsSource = [ ` ` ] const optionImports = Array . isArray ( this . options . imports ) ? this . options . imports : [ this . options . imports ] if ( this . options . imports ) { importsSource = importsSource . concat ( this . options . imports ) } importsSource = importsSource . concat ( this . imports . split ( '\\n' ) ) ? importsSource . join ( '\\n' ) : importsToCommonJS ( importsSource . join ( '\\n' ) )", "del_tokens": "let importsSource = ` \\n ` importsSource += ` ${ this . imports } ${ this . imports ? '\\n' : '' } ` ? importsSource : importsToCommonJS ( importsSource )", "commit_type": "add"}
{"commit_tokens": ["Fix", "misprint", "in", "disconnect", "function"], "add_tokens": "this . connection . disconnect ( ) extend ( Controller . prototype , EventEmitter . prototype )", "del_tokens": "this . connection . connect ( ) extend ( Controller . prototype , EventEmitter . prototype )", "commit_type": "fix"}
{"commit_tokens": ["add", "ability", "to", "use", "a", "target", "that", "contains", "a", "query", "string"], "add_tokens": "var targetUrl = $ . getOpt ( 'target' ) ; if ( targetUrl . indexOf ( '?' ) < 0 ) { targetUrl += '?' ; } else { targetUrl += '&' ; } $ . xhr . open ( \"GET\" , targetUrl + params . join ( '&' ) ) ;", "del_tokens": "$ . xhr . open ( \"GET\" , $ . getOpt ( 'target' ) + '?' + params . join ( '&' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "options", "headers", "and", "add", "file", "Urls"], "add_tokens": "if ( newOptions . headers ) { getProfilePictureUrl = ( userId , lastPictureUpdate ) => { const params = { } ; if ( lastPictureUpdate ) { params . time = lastPictureUpdate ; } return ` ${ this . getUserRoute ( userId ) } ${ buildQueryString ( params ) } ` ; } ; getFileUrl ( fileId , timestamp ) { let url = ` ${ this . getFileRoute ( fileId ) } ` ; if ( timestamp ) { url += ` ${ timestamp } ` ; } return url ; } getFileThumbnailUrl ( fileId , timestamp ) { let url = ` ${ this . getFileRoute ( fileId ) } ` ; if ( timestamp ) { url += ` ${ timestamp } ` ; } return url ; } getFilePreviewUrl ( fileId , timestamp ) { let url = ` ${ this . getFileRoute ( fileId ) } ` ; if ( timestamp ) { url += ` ${ timestamp } ` ; } return url ; }", "del_tokens": "if ( options . headers ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "rebuild", "by", "closing", "stream"], "add_tokens": "let closeStream = ( ) => { } closeStream = cb ; value . set ( initial ) since . set ( - 1 ) w . write ( initial ) closeStream ( )", "del_tokens": "value . set ( null ) ; w . write ( null )", "commit_type": "fix"}
{"commit_tokens": ["added", "parallel", "function", ";", "added", "PromiseResolver"], "add_tokens": "// promisification tests upon fs module describe ( 'promisify' , function ( ) {", "del_tokens": "describe ( '::promisify' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["added", "EventEmitter", "inheritance", ".", "some", "more", "tests"], "add_tokens": "var opts = _ . pick ( options || { } , [ 'cas' , 'expiry' , 'persist_to' , 'replicate_to' ] ) ; self . db . upsert ( id , doc , opts , function ( err , res ) { self . emit ( 'save' , self ) ; self . emit ( 'remove' , self ) ;", "del_tokens": "self . db . upsert ( id , doc , options , function ( err , res ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "unneeded", "width", "/", "height", "uniforms", "from", "equirect", "shader", "."], "add_tokens": "'colorOffset' , 'colorMatrix' , 'textureX' , 'textureY' , 'textureWidth' , 'textureHeight'", "del_tokens": "'uWidth' , 'uHeight' , 'colorOffset' , 'colorMatrix' , 'textureX' , 'textureY' , 'textureWidth' , 'textureHeight' this . gl . uniform1f ( this . shaderProgram . uWidth , rect . width ) ; this . gl . uniform1f ( this . shaderProgram . uHeight , rect . height ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "isLoaded", "()", "instance", "method"], "add_tokens": "isLoaded : function ( ) { return this . audioAdapter . loaded ; } , } ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Remove", "unnecessary", "dead", "variable", "setting"], "add_tokens": "/** @type {IDBDatabase} */", "del_tokens": "/** @type {IDBDatabase | undefined} */ this . _db ; // eslint-disable-line no-unused-expressions", "commit_type": "remove"}
{"commit_tokens": ["Fix", "crash", "in", "optional", "components", ".", "Now", "does", "less", ";", "we", "should", "rethink", "this", "once", "title", "etc", "stabilize", "."], "add_tokens": "// const abstract = dom.querySelector('d-abstract'); dom . body . insertBefore ( interstitial , dom . body . firstChild ) ; // if (data.title) { // let headline = dom.createElement('d-title'); // let h1 = dom.createElement('h1'); // headline.appendChild(h1); // h1.textContent = data.title; // abstract.parentNode.insertBefore(headline, abstract); // }", "del_tokens": "const abstract = dom . querySelector ( 'd-abstract' ) ; dom . body . insertBefore ( interstitial , article ) ; if ( data . title ) { let headline = dom . createElement ( 'd-title' ) ; let h1 = dom . createElement ( 'h1' ) ; headline . appendChild ( h1 ) ; h1 . textContent = data . title ; abstract . parentNode . insertBefore ( headline , abstract ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "test", "bug", "in", "reify", "updateTemporaryIdAddedElsewhere"], "add_tokens": "//return function(){ //}", "del_tokens": "return function ( ) { }", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "collapsing", "and", "uncollapsing", "grid", "rows"], "add_tokens": "'collapse-small' : props . collapseOnSmall , 'collapse-medium' : props . collapseOnMedium , 'collapse-large' : props . collapseOnLarge , 'uncollapse-small' : props . uncollapseOnSmall , 'uncollapse-medium' : props . uncollapseOnMedium , 'uncollapse-large' : props . uncollapseOnLarge , 'collapse' : props . isCollapsed , collapseOnSmall : PropTypes . bool , collapseOnMedium : PropTypes . bool , collapseOnLarge : PropTypes . bool , uncollapseOnSmall : PropTypes . bool , uncollapseOnMedium : PropTypes . bool , uncollapseOnLarge : PropTypes . bool , isCollapsed : PropTypes . bool ,", "del_tokens": "'collapse-small' : props . collapseOnSmall , 'collapse-medium' : props . collapseOnMedium , 'collapse-large' : props . collapseOnLarge , 'uncollapse-small' : props . uncollapseOnSmall , 'uncollapse-medium' : props . uncollapseOnMedium , 'uncollapse-large' : props . uncollapseOnLarge , collapseOnSmall : PropTypes . bool , collapseOnMedium : PropTypes . bool , collapseOnLarge : PropTypes . bool , uncollapseOnSmall : PropTypes . bool , uncollapseOnMedium : PropTypes . bool , uncollapseOnLarge : PropTypes . bool ,", "commit_type": "add"}
{"commit_tokens": ["Created", "a", "folder", "dedicated", "to", "test", "fixtures"], "add_tokens": "let report = Report . parse ( fs . readFileSync ( ` ${ __dirname } ` , 'utf8' ) ) ;", "del_tokens": "let report = Report . parse ( fs . readFileSync ( ` ${ __dirname } ` , 'utf8' ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Fixing", "a", "typo", "in", "the", "factory", "function"], "add_tokens": "var factory = Function ( \"values\" , factoryFn ) ;", "del_tokens": "var factory = Function ( factoryFn ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "task", ".", "addSource", "and", "task", ".", "removeSource", "methods"], "add_tokens": "hoodie . task = new TasksAPI ( hoodie , options ) ;", "del_tokens": "hoodie . task = new TasksAPI ( hoodie ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "postcss", "-", "plugin", "-", "weex", "&", "adjust", "order", "of", "postcss", "plugins", "array", "."], "add_tokens": "require ( 'postcss-plugin-px2rem' ) ( { rootValue : 75 , minPixelValue : 1.01 } ) , require ( 'postcss-plugin-weex' ) ( )", "del_tokens": "require ( 'postcss-plugin-weex' ) ( ) , require ( 'postcss-plugin-px2rem' ) ( { rootValue : 75 , minPixelValue : 1.01 } )", "commit_type": "update"}
{"commit_tokens": ["Added", "assertions", "for", ".", "id", "()", "and", ".", "rev", "()"], "add_tokens": "it ( 'has a _id field that equals the return value of .id()' , function ( ) { assert . strictEqual ( item . get ( '_id' ) , item . id ( ) ) it ( 'has a _rev field that equals the return value of .rev()' , function ( ) { assert . strictEqual ( item . get ( '_rev' ) , item . rev ( ) ) it ( 'has a type field that equals the return value of .type()' , function ( ) {", "del_tokens": "it ( 'has a _id field' , function ( ) { it ( 'has a _rev field' , function ( ) { it ( 'has a type field' , function ( ) { } ) it ( 'the type field equals the return value of .type()' , function ( ) {", "commit_type": "add"}
{"commit_tokens": ["make", "sense", "of", "values", "in", "test"], "add_tokens": "console . log ( 'values: ' , { repo , sha , event , commit_message , pull_request_number , branch , ci } )", "del_tokens": "console . log ( 'values: ' , repo , sha , event , commit_message , pull_request_number , branch , ci )", "commit_type": "make"}
{"commit_tokens": ["Fix", "tests", ".", "Signature", "of", "core", "s", "createConfig", "()", "changed", "."], "add_tokens": "const config = createConfig ( { webpack } , [ const config = createConfig ( { webpack } , [", "del_tokens": "const config = createConfig ( webpack , [ const config = createConfig ( webpack , [", "commit_type": "fix"}
{"commit_tokens": ["make", "command", "triggers", "case", "-", "insensitive"], "add_tokens": "name = args . shift ( ) . toLowerCase ( ) ; if ( direct && commands [ cmd = argv [ 0 ] . toLowerCase ( ) ] != null ) {", "del_tokens": "name = args . shift ( ) ; if ( direct && commands [ cmd = argv [ 0 ] ] != null ) {", "commit_type": "make"}
{"commit_tokens": ["Removed", "the", "new", "line", "in", "webpack", ".", "js"], "add_tokens": "} ;", "del_tokens": "} ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "expense", "form", "to", "be", "more", "expensey", "and", "ammended", "tests", "to", "check", "the", "new", "fields"], "add_tokens": "this . setMissingPropertiesToNull = resourceConfig . setMissingPropertiesToNull || false this . model . upsert ( docToPersist , { setMissingPropertiesToNull : this . setMissingPropertiesToNull } )", "del_tokens": "this . model . upsert ( docToPersist , { } )", "commit_type": "update"}
{"commit_tokens": ["fixed", "register", "mongoose", "admin", "user"], "add_tokens": "var AdminUserData = new mongoose . Schema ( { username : { type : String , required : true , unique : true } , passwordHash : { type : String , editable : false } , is_superuser : { type : Boolean , 'default' : false } , permissions : [ { type : mongoose . Schema . ObjectId , ref : '_MongooseAdminPermission' } ] } , { strict : true } ) ; mongoose . model ( '_MongooseAdminUser' , AdminUserData ) ;", "del_tokens": "var AdminUserData = new mongoose . Schema ( { username : { type : String , required : true , unique : true } , passwordHash : { type : String , editable : false } , is_superuser : { type : Boolean , 'default' : false } , permissions : [ { type : mongoose . Schema . ObjectId , ref : '_MongooseAdminPermission' } ] } , { strict : true } ) ; mongoose . model ( '_MongooseAdminUser' , AdminUserData ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "binary", "compiled", "version", "for", "tests"], "add_tokens": "// const metronome = require('../src') // metronome.should.itself.respondTo('createInstance')", "del_tokens": "const metronome = require ( '../src' ) metronome . should . itself . respondTo ( 'createInstance' )", "commit_type": "add"}
{"commit_tokens": ["added", "--", "color", "option", "needs", "refactor", "already"], "add_tokens": "console . log ( \" --colorize Colorize console output using ANSI color codes\" ) ; colorize : false , case '--colorize' : options . colorize = true ; break ; jarvis . defaultReporter = new CliReporter ( args . options . verbose , args . options . colorize ) ;", "del_tokens": "jarvis . defaultReporter = new CliReporter ( args . options . verbose ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "duck", "typing", "to", "detect", "the", "asset", "type"], "add_tokens": "if ( '_cachedSource' in asset ) { } else if ( '_value' in asset ) {", "del_tokens": "const CachedSource = require ( 'webpack-sources' ) . CachedSource ; const SourceMapSource = require ( 'webpack-sources' ) . SourceMapSource ; if ( asset instanceof CachedSource ) { } else if ( asset instanceof SourceMapSource ) {", "commit_type": "use"}
{"commit_tokens": ["Updated", "revwalk", "to", "iterate", "over", "all", "revisions"], "add_tokens": "function walk ( ) { var _tmp = git . commit ( self . repo ) ; self . revwalk . next ( _tmp . commit , function ( err ) { if ( err ) { return ; } var args = Array . prototype . slice . call ( arguments ) ; args [ 0 ] = git . util ( ) . error ( args [ 0 ] ) ; callback . apply ( _tmp , args . concat ( _tmp ) ) ; walk ( ) ; } ) ; } walk ( ) ;", "del_tokens": "var _tmp = git . commit ( self . repo ) ; self . revwalk . next ( _tmp . commit , function ( ) { var args = Array . prototype . slice . call ( arguments ) ; args [ 0 ] = git . util ( ) . error ( args [ 0 ] ) ; callback . apply ( _tmp , args . concat ( _tmp ) ) ; } ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "createGRPCError", "params", "optionals", "(", "JSDoc", ")"], "add_tokens": "* @ param { String | Number | Error | Object } [ message ] If < code > String < / code> the error message * @ param { Number | Object } [ code ] If < code > Number < / code> the error code * @ param { Object } [ metadata ] The error metadata . Either plain object representation or actual", "del_tokens": "* @ param { String | Number | Error | Object } message If < code > String < / code> the error message * @ param { Number | Object } code If < code > Number < / code> the error code * @ param { Object } metadata The error metadata . Either plain object representation or actual", "commit_type": "make"}
{"commit_tokens": ["update", "known", "caveats", "in", "readme"], "add_tokens": "} ) . join ( ' ' ) . replace ( / \\s+ / g , ' ' ) . trim ( ) ; var hNonText = AdaptiveCardFilter . getNonTextBlocks ( content ) ; return AdaptiveCardHelper . wrap ( [ AdaptiveCardHelper . createHeadingTextBlock ( hText , hLevel ) ] . concat ( hNonText ) ) ; currText = '' ;", "del_tokens": "} ) . join ( ' ' ) ; rules . paragraph = { filter : 'p' , replacement : function replacement ( content ) { return AdaptiveCardHelper . wrap ( content ) ; } } ; return AdaptiveCardHelper . createHeadingTextBlock ( hText , hLevel ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", "parser", "to", "correctly", "handle", "null", "value"], "add_tokens": "import PairValue from '../value/pair' ; frame . result = new PairValue ( ) ; frame . result = new BooleanValue ( false ) ;", "del_tokens": "frame . result = undefined ; frame . result = null ;", "commit_type": "change"}
{"commit_tokens": ["move", "cart", "to", "gameboy", "class"], "add_tokens": "const Cart = require ( './cart' ) ; this . _mmu . loadCart ( new Cart ( rom ) ) ;", "del_tokens": "this . _mmu . loadCart ( rom ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "ignoring", "of", "duplicate", "css", "classes"], "add_tokens": "return _ ( classList ) . filter ( ) . uniq ( ) . sort ( ) . join ( ' ' ) ;", "del_tokens": "return _ . filter ( classList ) . sort ( ) . join ( ' ' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "all", "methods", "to", "error", "type"], "add_tokens": "route : this . config . errorRoute ? this . config . errorRoute : 'core/error' , method : [ 'GET' , 'HEAD' , 'POST' , 'PUT' , 'DELETE' , 'TRACE' , 'OPTIONS' , 'CONNECT' , 'PATCH' ]", "del_tokens": "route : this . config . errorRoute ? this . config . errorRoute : 'core/error'", "commit_type": "add"}
{"commit_tokens": ["Fix", "feedback", "function", "and", "hull", "multiple", "layer", "handling"], "add_tokens": "node . oldlayercount = { } ; if ( node . oldlayercount [ newmsg . payload [ node . prop ] ] === undefined ) { node . oldlayercount [ newmsg . payload [ node . prop ] ] = 0 ; } var oldl = node . oldlayercount [ newmsg . payload [ node . prop ] ] ; if ( leafletHull . length === 2 && ( oldl === 1 || oldl === 3 ) ) { node . oldlayercount [ newmsg . payload [ node . prop ] ] = leafletHull . length ;", "del_tokens": "var oldl = 0 ; if ( leafletHull . length === 2 && ( oldl === 1 || oldl === 3 ) ) { oldl = leafletHull . length ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "jenkins#job", "."], "add_tokens": "if ( ! _ . isEmpty ( _ . keys ( result ) ) ) { _ . keys ( result ) . forEach ( function ( computer ) { console . log ( '+ ' + computer ) ; result [ computer ] . forEach ( function ( executor ) { if ( executor . idle ) { console . log ( ' - idle' ) ; } else { console . log ( ' - %s | %s%%s' , executor . name , executor . progress , ( executor . stuck ) ? ' stuck!' : '' ) ; } } ) ; } else { console . log ( 'No executor found' ) ; } desc : 'View job status reports' ,", "del_tokens": "_ . keys ( result ) . forEach ( function ( computer ) { console . log ( '+ ' + computer ) ; result [ computer ] . forEach ( function ( executor ) { if ( executor . idle ) { console . log ( ' - idle' ) ; } else { console . log ( ' - %s | %s%%s' , executor . name , executor . progress , ( executor . stuck ) ? ' stuck!' : '' ) ; } } ) ; desc : 'View job status' ,", "commit_type": "add"}
{"commit_tokens": ["Added", "req", "parameter", "and", "prepareLinks", "function"], "add_tokens": "* @ param { Object } req The request function prepareResponse ( status , req ) { if ( req ) { prepareLinks ( response , req ) ; } * @ param { Number } status Integer status code / ** * Prepares and adds the _links to the given API query response * @ param { Object } response JSON representation of the response * @ param { Object } req The request * / function prepareLinks ( response , req ) { var rootUrl = req . protocol + '://' + req . get ( 'host' ) ; var queryPath = req . originalUrl ; var selfLink = { \"href\" : rootUrl + queryPath } ; response . _links = { } ; response . _links [ \"self\" ] = selfLink ; }", "del_tokens": "function prepareResponse ( status ) { * @ param { String } status String representing the status message", "commit_type": "add"}
{"commit_tokens": ["Updated", "gulp", "test", "and", "test", "reporter", "handling", "."], "add_tokens": "// var shell = require('gulp-shell'); var tape = require ( 'gulp-tape' ) ; var tapDiff = require ( 'tap-diff' ) ; // gulp.task('test', shell.task([ // 'node test/test.js', // ])); gulp . task ( 'test' , function ( ) { return gulp . src ( 'test/*.js' ) . pipe ( tape ( { reporter : tapDiff ( ) } ) ) ; } ) ;", "del_tokens": "var shell = require ( 'gulp-shell' ) ; gulp . task ( 'test' , shell . task ( [ 'node test/test.js' , ] ) ) ;", "commit_type": "update"}
{"commit_tokens": ["make", "lineEnding", "default", "value", "to", "the", "destination", "file", "s", "line", "ending"], "add_tokens": "lineEnding : null , var useDestTpl = false ; useDestTpl = true ; } if ( ! options . lineEnding ) { var destination = options . template || options . templateString ; if ( useDestTpl ) { destination = options . destFile ; } var contents = String ( grunt . file . read ( destination ) ) ; var returnType = / \\r\\n / . test ( contents ) ? '\\r\\n' : '\\n' ; options . lineEnding = returnType ;", "del_tokens": "lineEnding : '\\n' ,", "commit_type": "make"}
{"commit_tokens": ["Added", "archive", "category", "tag", "settings"], "add_tokens": "var config = hexo . config . category , categories = locals . categories , if ( config ) { async . forEach ( keys , function ( key , next ) { var item = categories [ key ] ; item . category = key ; if ( config === 2 ) { paginator ( item . permalink , item , 'category' , render , next ) ; } else { render ( 'category' , item , function ( err , result ) { if ( err ) throw err ; file . write ( publicDir + item . permalink + 'index.html' , result , next ) ; } ) ; } } , callback ) ; } else { callback ( ) ; }", "del_tokens": "var categories = locals . categories , async . forEach ( keys , function ( key , next ) { var item = categories [ key ] ; paginator ( item . permalink + '/' , item , 'category' , render , next ) ; } , callback ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "env", "key", "for", "per", "-", "repo_config", "environment", "variable"], "add_tokens": "it ( 'should honour environment vars via opts arg' , function ( done ) { it ( 'should honour environment vars via repo_config' , function ( done ) { var key = 'MY_TEST_VAR2' var val = '54321' var env = { } env [ key ] = val mockGumshoeResult = { // Hook for ctx.forkProc prepare : function ( ctx , cb ) { var proc = ctx . forkProc ( { cmd : \"/usr/bin/env\" , cwd : __dirname , args : [ ] , env : { } } , function ( exitCode ) { expect ( exitCode ) . to . eql ( 0 ) expect ( proc . stdoutBuffer ) . to . have . string ( 'PAAS_NAME=strider' ) expect ( proc . stdoutBuffer ) . to . have . string ( key + '=' + val ) done ( ) } ) } , } worker ( containerCtx , function ( err , z ) { containerCtx . emitter . emit ( 'queue.new_job' , { repo_ssh_url : \"REPO_SSH_URL\" , repo_config : { env : env , privkey : \"REPO_CONFIG.PRIVKEY\" } } ) } ) } )", "del_tokens": "it ( 'should honour environment parameters' , function ( done ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "rebasing", "errors", "after", "filter", "-", "branching"], "add_tokens": "* Noop function that can be stuffed into required callback props export function noop ( ) { }", "del_tokens": "* Takes a list of object and merges their keys to one object . * Uses mergeOptions for two objects . * @ param { [ type ] } l [ description ] * @ return { [ type ] } [ description ] export function mergeOptions ( ... l ) { // If the objects submitted in the list have duplicates,in their key names, // abort the merge and tell the function's user to check his objects. if ( _doesObjectListHaveDuplicates ( l ) ) { throw new Error ( 'The objects you submitted for merging have duplicates. Merge aborted.' ) ; } return Object . assign ( { } , ... l ) ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "who", "/", "key", "support", "wrap", "ursa", "for", "crypto", "sends", "and", "receives", "packets", "now"], "add_tokens": "var test = th . hashname ( \"test\" , keypair ) ; test . setOperators ( [ \"1e9f22cdb675bd9d67ec10c2f21c020acc0bd20f,172.16.42.34,58625\" ] ) ; test . doWho ( \"1e9f22cdb675bd9d67ec10c2f21c020acc0bd20f\" , function ( err , key ) { console . log ( \"WHOM\" , err , key ) ; } ) ; / * * /", "del_tokens": "var test = th . listen ( \"test\" , keypair ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "security", "endpoints"], "add_tokens": "exports . getChallenges = require ( './src/security/get-challenges' ) exports . getSecureLocation = require ( './src/security/get-secure-location' ) exports . setSecureLocation = require ( './src/security/set-secure-location' ) exports . getNameHistory = require ( './src/mojang/get-name-history' ) exports . getProfileAt = require ( './src/mojang/get-profile-at' ) exports . getUser = require ( './src/mojang/get-user' ) exports . getUserProfiles = require ( './src/mojang/get-user-profiles' ) exports . setSkin = require ( './src/mojang/set-skin' ) exports . resetSkin = require ( './src/mojang/reset-skin' )", "del_tokens": "exports . getNameHistory = require ( './src/mojang/get-name-history' ) exports . getProfileAt = require ( './src/mojang/get-profile-at' ) exports . getUser = require ( './src/mojang/get-user' ) exports . getUserProfiles = require ( './src/mojang/get-user-profiles' ) exports . setSkin = require ( './src/mojang/set-skin' )", "commit_type": "add"}
{"commit_tokens": ["add", "jit", "-", "grunt", ".", "fix", "test", "task"], "add_tokens": "var grunto = require ( 'grunto' ) ; var jitGrunt = require ( 'jit-grunt' ) ; module . exports = grunto ( function ( grunt ) { jitGrunt ( grunt ) ;", "del_tokens": "module . exports = require ( 'grunto' ) ( function ( grunt ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "responsibility", "for", "source", "path", "to", "adapter", ".", "normalize", "()"], "add_tokens": "import retrieve from './retrieve' test ( 'should exist' , ( t ) => {", "del_tokens": "import { retrieve } from './json' test ( 'retrieve should exist' , ( t ) => {", "commit_type": "move"}
{"commit_tokens": ["Fix", "missing", "apk", "repo", "error"], "add_tokens": "var apk = { } , initialized = false var files ; try { files = fs . readdirSync ( repoDir , 'utf8' ) ; } catch ( e ) { console . log ( \"Cannot read apk repository directory : \" + repoDir ) ; return ; } initialized = true ; if ( ! initialized ) { init ( ) ; } if ( ! initialized ) { init ( ) ; }", "del_tokens": "var apk = null var files = fs . readdirSync ( repoDir , 'utf8' ) ; apk = { } ; if ( ! apk ) { init ( ) ; } if ( ! apk ) { init ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["allow", "for", "deleting", "items", "from", "sets"], "add_tokens": "if ( val === null ) continue ; if ( Array . isArray ( attrs ) ) { var deletes = [ ] ; if ( attrs [ a ] . Value === null ) delete attrs [ a ] . Value ;", "del_tokens": "if ( action === 'DELETE' ) { var deletes = { } ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "--", "debug", "parameter", "to", "bundle", ".", "js", "so", "that", "it", "outputs", "raw", "Lovefield", "code"], "add_tokens": "'schema' : pathMod , 'compiler' : pathMod , 'outputdir' : pathMod , 'debug' : [ Boolean , null ] var schemaPath = args . schema ; var outputDir = args . outputdir || process . cwd ( ) ; var compilerPath = args . compiler || process . env [ 'CLOSURE_COMPILER' ] ; var closureDir = args . library || process . env [ 'CLOSURE_LIBRARY' ] ; '--output_mode=' + ( args . debug ? 'script' : 'compiled' ) ,", "del_tokens": "'schema' : [ String ] , 'compiler' : [ String , null ] , 'outputdir' : [ String , null ] var schemaPath ; var outputDir ; var compilerPath ; var closureDir ; try { schemaPath = pathMod . resolve ( args . schema ) ; outputDir = pathMod . resolve ( pathMod . join ( process . cwd ( ) , args . outputdir || '' ) ) ; compilerPath = pathMod . resolve ( args . compiler || process . env [ 'CLOSURE_COMPILER' ] ) ; closureDir = pathMod . resolve ( args . library || process . env [ 'CLOSURE_LIBRARY' ] ) ; } catch ( e ) { // Swallow path resolve exceptions, non-resolved paths will be treated as // empty path and checked in following logic (which displays usage). } '--output_mode=compiled' ,", "commit_type": "add"}
{"commit_tokens": ["Use", "closured", "window", "constant", "instead", "of", "duplicating", "code"], "add_tokens": "factory ( window . linqjs = { } ) ; // jshint ignore:line", "del_tokens": "factory ( ( this || ( 0 , eval ) ( 'this' ) ) [ 'linqjs' ] = { } ) ; // jshint ignore:line console . log ( 'foo' ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "<use", ">", "attributes", "and", "linked", "demojs", ".", "html", "to", "dist", "folder"], "add_tokens": "// build: 2013-09-06 use : { \"class\" : 0 , externalResourcesRequired : 0 , x : 0 , y : 0 , width : 0 , height : 0 , \"xlink:href\" : 0 } ,", "del_tokens": "// build: 2013-09-05", "commit_type": "add"}
{"commit_tokens": ["Adding", "apis", "to", "the", "exports", "&", "client", "object", "."], "add_tokens": "var krpc = require ( './apis/krpc' ) ; var apis = { krpc : krpc } ; client . apis = apis ; module . exports . apis = apis ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["changed", "dump", "to", "this", ".", "dumpn", "in", "clone"], "add_tokens": "this . dumpn ( \"Cloning \" + name + \"\\n\" ) ;", "del_tokens": "dump ( \"Cloning \" + name + \"\\n\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Make", "the", "most", "common", "case", "the", "first", "if", "branch", "."], "add_tokens": "if ( 'string' === fnType ) { } else if ( 'number' === fnType ) { return createThrottlePipe ( fn )", "del_tokens": "if ( 'number' === fnType ) { return createThrottlePipe ( fn ) } else if ( 'string' === fnType ) {", "commit_type": "make"}
{"commit_tokens": ["remove", "overuse", "of", "the", "toString", "()", "and", "correct", "variable", "naming", "convention"], "add_tokens": "var win1251String = iconv . decode ( bufferString , 'win1251' ) ; responseString = iconv . encode ( win1251String , charset ) ;", "del_tokens": "var str = iconv . decode ( bufferString , 'win1251' ) . toString ( ) ; responseString = iconv . encode ( str , charset ) . toString ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "error", "callbacks", "on", "multiple", "queries"], "add_tokens": "queriedAndProcessedCallback ( err ) ; callback ( err ) ; return ;", "del_tokens": "console . error ( err ) ; callback ( err ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "entry", "files", "for", "browser", "and", "commonjs", "to", "automatically", "export", "namespacing"], "add_tokens": "for ( var key in esModule ) { if ( esModule . hasOwnProperty ( key ) && key !== 'default' ) { module . exports [ key ] = esModule [ key ] ; } }", "del_tokens": "module . exports . Auth = esModule . Auth ; module . exports . Format = esModule . Format ; module . exports . Item = esModule . Item ; module . exports . PubControlClient = esModule . PubControlClient ;", "commit_type": "update"}
{"commit_tokens": ["Add", "create", "plugin", "test", "spec", "."], "add_tokens": "module . exports = function ( ) { this . air . create = create ; this . air . el = el ;", "del_tokens": "module . exports = function ( conf ) { conf . main . create = create ; conf . main . el = el ;", "commit_type": "add"}
{"commit_tokens": ["Add", "overflow", "order", "and", "grid", "properties", "to", "stylelint", "config"], "add_tokens": "'justify-content' , 'order' , 'grid' , 'grid-area' , 'grid-auto-columns' , 'grid-auto-flow' , 'grid-auto-rows' , 'grid-column' , 'grid-column-end' , 'grid-column-gap' , 'grid-column-start' , 'grid-gap' , 'grid-row' , 'grid-row-end' , 'grid-row-gap' , 'grid-row-start' , 'grid-template' , 'grid-template-areas' , 'grid-template-columns' , 'grid-template-rows' 'min-height' , 'overflow'", "del_tokens": "'justify-content' 'min-height'", "commit_type": "add"}
{"commit_tokens": ["Updating", "pretifier", "and", "eslint", "overrides"], "add_tokens": "extends : [ 'airbnb-base' , 'plugin:prettier/recommended' ] , plugins : [ 'prettier' ] , parserOptions : { ecmaVersion : 8 , sourceType : 'script' , } , rules : { 'prettier/prettier' : 'warn' , semi : [ 'warn' , 'never' ] ,", "del_tokens": "'plugins' : [ 'lodash-template' ] , 'extends' : [ 'airbnb' , // 'plugin:lodash-template/recommended-with-html', ] , 'rules' : { // http://eslint.org/docs/rules/semi // no semi-colons (YOLO) .. if you really want semicolons, remove this rule and run // '.\\node_modules\\.bin\\eslint --fix src' from the app root to re-add 'semi' : [ 'warn' , 'never' ] ,", "commit_type": "update"}
{"commit_tokens": ["Adding", "third", "-", "party", "-", "notices", ".", "txt", "for", "msgpack5"], "add_tokens": "const browserOutDir = clientOutDir + '/../browser/' ; gulp . task ( 'build-ts-client' , [ 'clean' , 'compile-ts-client' , 'browserify' ] , ( ) => { return gulp . src ( './third-party-notices.txt' ) . pipe ( gulp . dest ( browserOutDir ) ) ; } ) ;", "del_tokens": "const browserOutDir = clientOutDir + '/../browser' ; const browserOutDir = clientOutDir + '/../browser' ; gulp . task ( 'build-ts-client' , [ 'clean' , 'compile-ts-client' , 'browserify' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "when", "shrinkwrap", ".", "dependencies", "is", "undefined"], "add_tokens": "if ( shrinkwrap . dependencies && lowercaseContains ( Object . keys ( shrinkwrap . dependencies ) , file ) ) {", "del_tokens": "if ( lowercaseContains ( Object . keys ( shrinkwrap . dependencies ) , file ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "client", "into", "a", "more", "efficient", "object"], "add_tokens": "if ( typeof client . domain [ key ] !== 'undefined' ) { client . domain [ key ] . emit ( result [ key ] , result ) ;", "del_tokens": "if ( typeof client . _domains [ key ] !== 'undefined' ) { client . _domains [ key ] . emit ( result [ key ] , result ) ;", "commit_type": "make"}
{"commit_tokens": ["improved", "pd", "file", "parsing", "+", "tests"], "add_tokens": "// Returns true if an object is an array, false otherwise. // Returns true if an object is a number, false otherwise. // If `val` is NaN, the function returns false. return typeof val === 'number' && ! isNaN ( val ) ; // Returns true if an object is a string, false otherwise.", "del_tokens": "// Returns true if an object is an array, false otherwise // Returns true if an object is a number, false otherwise return typeof val === 'number' ; // Returns true if an object is a string, false otherwise", "commit_type": "improve"}
{"commit_tokens": ["Create", "test", "case", "for", "using", "globs", "options", ".", "apis", "."], "add_tokens": "var routes2 = require ( './routes2' ) ; apis : [ './example/routes*.js' , './example/parameters.yaml' ] , routes2 . setup ( app ) ;", "del_tokens": "apis : [ './example/routes.js' , './example/parameters.yaml' ] ,", "commit_type": "create"}
{"commit_tokens": ["Fixing", "using", "of", "fritz", ".", "box", "and", "not", "using", "options", ".", "url", "when", "defined", "in", "constructor"], "add_tokens": "req = extend ( { } , options . url , req , options ) ;", "del_tokens": "/ * * Functional API * / var defaults = { url : 'http://fritz.box' } ; req = extend ( { } , defaults , req , options ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "custom", "server", "wrapper", "implement", "into", "main", "and", "clean", "up", "resource"], "add_tokens": "// todo replace this with a chunked renderer like mu? if ( ! ( request instanceof http_wrapper_component . Request ) || ! ( response instanceof http_wrapper_component . Response ) ) { throw new Error ( 'You must wrap your httprequest and httpresponse BEFORE you route them' ) ; if ( _self . config . debug === true ) { response . logger ( new Firebug ( response . response ( ) ) ) ; response . logger ( ) . log ( 'init' , true ) ; // empty function so we can just always call it without errors if ( typeof callback === \"undefined\" ) { callback = function ( ) { } ; }", "del_tokens": "//todo replace this with a chunked renderer like mu? if ( ! ( request instanceof http_wrapper_component . Request ) && ! ( request instanceof http_wrapper_component . Response ) ) { var cookie = new Cookie ( request , response ) ; request = new http_wrapper_component . Request ( request ) ; response = new http_wrapper_component . Response ( response ) ; response . cookie ( cookie ) ; if ( _self . config . debug === true ) { response . logger ( new Firebug ( response . response ( ) ) ) ; response . logger ( ) . log ( 'init' , true ) ; } if ( typeof callback === \"undefined\" ) { // empty function so we can just always call it without errors callback = function ( ) { } ;", "commit_type": "add"}
{"commit_tokens": ["add", "frontend", "parameter", "and", "change", "wpPort", "to", "clientPort", "in", "servers", ".", "json"], "add_tokens": "return ! ! server && ! ! server . frontend ; return ! ! server && ! server . frontend ;", "del_tokens": "return ! ! server && ! ! server . wsPort ; return ! ! server && ! server . wsPort ;", "commit_type": "add"}
{"commit_tokens": ["Added", "first", "(", "dirty", ")", "draft", "of", "filter", "support", "."], "add_tokens": "filters : { } , parsePattern : / \\{\\{\\s*([\\.\\-\\w]*(\\s\\|\\s*[\\-\\w]+)?)\\s*\\}\\} / g return template . replace ( options . parsePattern , function ( match , inner ) { var parts = inner . split ( '|' ) ; var key = mout . string . trim ( parts . shift ( ) ) ; var filterName = mout . string . trim ( parts . shift ( ) ) ; var res = resolveName ( key , content ) ; if ( ! mout . lang . isEmpty ( filterName ) ) { if ( mout . object . has ( options . filters , filterName ) ) { res = options . filters [ filterName ] ( res ) ; } else { grunt . log . error ( 'Unknown filter:' + filterName ) ; } } return res ;", "del_tokens": "parsePattern : / \\{\\{\\s*([\\.\\-\\w]*)\\s*\\}\\} / g return template . replace ( options . parsePattern , function ( match , key ) { return resolveName ( key , content ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "support", "for", "Unicode", "character", "ranges", "to", "be", "specified", "as", "CLI", "arguments", "with", "the", "format", "U", "+", "XXXX~YYYY", "."], "add_tokens": "return 'U+' + u + '~' + v + ' ' + this . name ;", "del_tokens": "return 'U+' + u + '' + v + ' ' + t is.n a me;", "commit_type": "add"}
{"commit_tokens": ["added", "localhost", "check", "for", "ALL", "hosts", "not", "just", "first"], "add_tokens": "// check all hosts to see if any is not localhost if ( config . esclient . hosts . some ( ( env ) => { return env . host !== 'localhost' ; } ) ) {", "del_tokens": "if ( config . esclient . hosts [ 0 ] . host !== \"localhost\" ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "destination", "directory", "in", "sample"], "add_tokens": "{ expand : true , cwd : 'test' , src : [ '**/*' ] }", "del_tokens": "{ expand : true , cwd : 'tasks' , src : [ '**/*' ] }", "commit_type": "change"}
{"commit_tokens": ["Added", "kff", ".", "View#getBindingIndex", "method", "(", "transparently", "bubbles", "up", "to", "nearest", "kff", ".", "BindingView", ")", "."], "add_tokens": "} , / ** * Returns index of item in bound collection ( closest collection in the view scope ) * * @ return { number } Item index * / getBindingIndex : function ( modelName ) { if ( this . parentView instanceof kff . View ) return this . parentView . getBindingIndex ( modelName ) ; return null ; if ( this . parentView instanceof kff . View ) return this . parentView . getBindingIndex ( modelName ) ;", "del_tokens": "if ( this . parentView instanceof kff . BindingView ) return this . parentView . getBindingIndex ( modelName ) ;", "commit_type": "add"}
{"commit_tokens": ["add", ".", "toStream", "to", "collection", "-", "less", "views"], "add_tokens": "it ( 'should add `toStream` to a view that is not on a collection' , function ( done ) { var files = [ ] ; var view = app . view ( 'foo.bar' , { content : 'this is foo' } ) ; view . toStream ( ) . on ( 'error' , done ) . on ( 'data' , function ( view ) { files . push ( view ) ; } ) . on ( 'end' , function ( ) { assert . equal ( files . length , 1 ) ; assert . equal ( files [ 0 ] . path , 'foo.bar' ) ; done ( ) ; } ) ; } ) ; app . onStream ( / \\.html$ / , function ( file , next ) {", "del_tokens": "app . onStream ( / \\.html / , function ( file , next ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "to", "option", "in", "getCode"], "add_tokens": "Account . prototype . getCode = function ( state , cb ) {", "del_tokens": "Account . prototype . getCode = function ( state , address , cb ) { if ( arguments . length === 2 ) { cb = address address = false }", "commit_type": "remove"}
{"commit_tokens": ["Updating", "with", "creating", "uploads", "directory", "and", "cleaning", "up", "upload", "code"], "add_tokens": "this . _storageProvider . storeFile ( req , res , function ( err ) { if ( ! req . file . mimetype . startsWith ( \"image/\" ) ) { error : \"The uploaded file must be an image\" return res . status ( 200 ) . send ( req . file . filename ) ;", "del_tokens": "const multer = require ( \"multer\" ) ; var upload_path = this . _config . uploads_dir ; var filename = \"\" ; var storage = multer . diskStorage ( { destination : function ( req , file , cb ) { cb ( null , upload_path ) ; } , filename : function ( req , file , cb ) { filename = file . originalname . substr ( 0 , file . originalname . lastIndexOf ( '.' ) ) + '-' + Date . now ( ) + file . originalname . substr ( file . originalname . lastIndexOf ( '.' ) ) ; cb ( null , filename ) ; } } ) ; var uploadimage = multer ( { storage : storage } ) . single ( \"file\" ) ; uploadimage ( req , res , function ( err ) { if ( ! req . file . mimetype . startsWith ( 'image/' ) ) { error : 'The uploaded file must be an image' return res . status ( 200 ) . send ( filename ) ;", "commit_type": "update"}
{"commit_tokens": ["Update", "the", "readme", "after", "my", "changes", ";", "in", "particular", "wrt", "the", "default", "exchange", ".", "Pass", "the", "name", "in", "the", "queue", "creation", "callback", "as", "it", "may", "have", "been", "generated", "and", "returned", "by", "the", "server", "."], "add_tokens": "if ( name != '' && options . type === undefined ) options . type = 'topic' ; // Publishes a message to the default exchange. this . _openCallback ( args . queue , args . messageCount , args . consumerCount ) ; this . emit ( 'open' , args . queue , args . messageCount , args . consumerCount ) ;", "del_tokens": "if ( options . type === undefined ) options . type = 'direct' ; // Publishes a message to the amq.topic exchange. this . _openCallback ( args . messageCount , args . consumerCount ) ; this . emit ( 'open' , args . messageCount , args . consumerCount ) ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "support", "for", "dynamic", "function", "name", "of", "_receive"], "add_tokens": "var receiveOriginal = agent . _receive ; this . receive = function ( from , message ) { if ( agent . _receive === this . receive ) agent . _receive = receiveOriginal ; // replace the agent's _receive function agent . _receive = this . receive ;", "del_tokens": "* - receive : string The name of an alternative * receive function available * on the actor . var receiveName = options && options . receive || 'receive' ; var receiveOriginal = agent [ receiveName ] || null ; this . receive = agent [ receiveName ] = function ( from , message ) { if ( agent [ receiveName ] === this . receive ) { if ( receiveOriginal ) { agent [ receiveName ] = receiveOriginal ; } else { delete agent [ receiveName ] ; } }", "commit_type": "remove"}
{"commit_tokens": ["Create", "a", "basic", "static", "layout", "."], "add_tokens": "inputDir : 'clients/web/src/templates' , 'clients/web/src/stylesheets/**/*.styl' , '!clients/web/src/stylesheets/apidocs/*.styl' 'clients/web/src/init.js' , 'clients/web/src/app.js' , 'clients/web/src/router.js' , 'clients/web/src/utility.js' , 'clients/web/src/models/**/*.js' , 'clients/web/src/collections/**/*.js' , 'clients/web/src/views/**/*.js' files : [ 'clients/web/src/templates/**/*.jade' ] , var inputFiles = grunt . file . expand ( config . inputDir + \"/**/*.jade\" ) ;", "del_tokens": "inputDir : 'templates' , 'clients/web/src/stylesheets/*.styl' 'clients/web/src/*.js' , 'clients/web/src/models/*.js' , 'clients/web/src/collections/*.js' , 'clients/web/src/views/*.js' files : [ 'clients/web/src/templates/*.jade' ] , var inputFiles = grunt . file . expand ( config . inputDir + \"/*.jade\" ) ;", "commit_type": "create"}
{"commit_tokens": ["Added", "cloning", "of", "data", "object", "when", "rendering", "a", "template", "."], "add_tokens": "data = null ; // Data defaults and / or cloning data = data ? _ . clone ( data ) : data ;", "del_tokens": "data = { } ; // Data defaults if ( ! data ) data = { } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "update", "method", "to", "coupon", "resource", "for", "metadata"], "add_tokens": "includeBasic : [ 'create' , 'list' , 'update' , 'retrieve' , 'del' ]", "del_tokens": "includeBasic : [ 'create' , 'list' , 'retrieve' , 'del' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "bug", "add", "more", "tests"], "add_tokens": "return rgbToHex ( rgb . r , rgb . g , rgb . b ) ;", "del_tokens": "return rgbToHex ( rgb . r , rgb . b , rgb . b ) ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "limit", "optional", "in", "ToneAnalyzer", "synonym"], "add_tokens": "requiredParams : [ 'words' ] ,", "del_tokens": "requiredParams : [ 'words' , 'limit' ] ,", "commit_type": "make"}
{"commit_tokens": ["Add", "more", "e2e", "tests", "for", "roads", "API", "."], "add_tokens": "] , interpolate : true ] , units : 'KPH' ] , units : 'MPH' speedLimit : closeTo ( 19 , 1 ) , units : 'MPH' function closeTo ( expected , delta ) { return { asymmetricMatch : function ( actual ) { return Math . abs ( actual - expected ) < delta ; } } ; }", "del_tokens": "] ] ] speedLimit : 30 , units : 'KPH'", "commit_type": "add"}
{"commit_tokens": ["Fix", "main", "file", "templates", "paths", "."], "add_tokens": "if ( ! this . fs . exists ( mainFilePath ) ) { this . fs . copy ( __dirname + '/templates/src/index.js' , this . destinationPath ( mainFilePath ) ) ; }", "del_tokens": "this . fs . copy ( __dirname + '/templates/' + mainFilePath , this . destinationPath ( mainFilePath ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "the", "build", "bug", ".", "see", "the", "notice", "in", "README", ".", "md"], "add_tokens": "use : [ { loader : 'vue-loader' , options : vueLoaderConfig } , { loader : 'iview-loader' , options : { prefix : true } } ]", "del_tokens": "loader : 'vue-loader' , options : vueLoaderConfig", "commit_type": "fix"}
{"commit_tokens": ["Added", "form", "and", "table", "examples"], "add_tokens": "$ ( '.date-range-picker' ) . daterangepicker ( if ( jQuery ( ) . timepicker ) { $ ( '.time-picker' ) . timepicker ( { minuteStep : 1 , showSeconds : false , showMeridian : false , defaultTime : false } ) . next ( ) . on ( ace . click_event , function ( ) { $ ( this ) . prev ( ) . focus ( ) ; } ) ; }", "del_tokens": "$ ( 'input[name=date-range-picker]' ) . daterangepicker (", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "a", "main", "script"], "add_tokens": "const { help , legal , repl , quiet , _ } = opts ; const mainScript = _ . length > 0 ; if ( repl && ! quiet && ! mainScript ) {", "del_tokens": "const { help , legal , repl , quiet } = opts ; if ( repl && ! quiet ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "webdriver", "-", "manager", "-", "update", "task", "to", "setup"], "add_tokens": "grunt . registerTask ( 'webdriver-manager-update' , function ( ) { grunt . util . spawn ( { cmd : 'node_modules/protractor/bin/webdriver-manager' , args : [ 'update' ] } ) ; } ) ; grunt . registerTask ( 'setup' , [ 'bower:setup' , 'webdriver-manager-update' ] ) ; 'setup-www' , 'webdriver-manager-update' , 'setup-www' ,", "del_tokens": "grunt . registerTask ( 'setup' , [ 'bower:setup' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "max", "width", "of", "DateAnswerComponent", "inside", "MaxtrixColumnCellComponent"], "add_tokens": "var DateAnswerComponent , H , MatrixColumnCellComponent , NumberAnswerComponent , R , React , SiteColumnAnswerComponent , UnitsAnswerComponent , _ , conditionsUtils , formUtils , DateAnswerComponent = require ( './answers/DateAnswerComponent' ) ; break ; case \"DateColumnQuestion\" : elem = R ( DateAnswerComponent , { style : { maxWidth : \"10em\" } , format : column . format , placeholder : column . placeholder , value : value , onValueChange : this . handleValueChange } ) ;", "del_tokens": "var H , MatrixColumnCellComponent , NumberAnswerComponent , R , React , SiteColumnAnswerComponent , UnitsAnswerComponent , _ , conditionsUtils , formUtils ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "charset", "to", "the", "Content", "-", "Type", "header"], "add_tokens": "res . setHeader ( 'Content-Type' , 'application/json; charset=utf-8' ) res . setHeader ( 'Content-Type' , 'text/plain; charset=utf-8' )", "del_tokens": "res . setHeader ( 'Content-Type' , 'application/json' ) ; res . setHeader ( 'Content-Type' , 'text/plain' ) ;", "commit_type": "add"}
{"commit_tokens": ["made", "the", "cloud", "component", "retrieve", "the", "machinepacks", "locally", "and", "made", "some", "checks", "at", "beginning", "of", "content", "post", "request", "if", "user", "has", "not", "provided", "certain", "inputs"], "add_tokens": "'platform' : 'Twitter' , 'user_url' : \" https : //twitter.com/POTUS\", 'user_name' : \"Elon Musk\" , 'user_screen_name' : 'elonmusk' , 'user_followers_count' : 120 , 'user_verified' : true , 'user_profile_image_url' : \" http : //pbs.twimg.com/profile_images/859982100904148992/hv5soju7_bigger.jpg\", 'tweet_text' : \"RT @TwitterDev: 1/ Today were sharing our vision for the future of the Twitter API platform!nhttps://t.co/XweGngmxlP\", 'tweet_url' : \" https : //twitter.com/POTUS/status/1049292990215278593\", 'tweet_favourite_count' : 20 , 'tweet_retweet_count' : 0 , \"tweet_created_at\" : \"Thu Apr 06 15:28:43 +0000 2017\" , 'media' : [ \"http://pbs.twimg.com/profile_images/859982100904148992/hv5soju7_bigger.jpg\" ]", "del_tokens": "'name' : \"Elon Musk\" , 'screen_name' : 'elonmusk' , 'text' : \"RT @TwitterDev: 1/ Today were sharing our vision for the future of the Twitter API platform!nhttps://t.co/XweGngmxlP\", 'favorite_count' : 0 , 'created_at' : \"Thu Apr 06 15:28:43 +0000 2017\" , 'profile_image_url' : \" http : //pbs.twimg.com/profile_images/822547732376207360/5g0FC8XX_bigger.jpg\", 'platform' : 'Twitter' , 'media' : [ ]", "commit_type": "make"}
{"commit_tokens": ["fix", "markdown", "options", "not", "overrided"], "add_tokens": "this . options = _ . defaults ( { } , options , defaultOptions ) ;", "del_tokens": "this . options = _ . extend ( { } , options , defaultOptions ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "for", "multi", "-", "points", "line"], "add_tokens": "* @ param { Array < Position > } points - * @ param { ComponentOptions } [ options ] - Drawing options constructor ( points , options ) { if ( points . length < 2 ) { throw new RangeError ( ` ${ points . length } ` ) ; } super ( points [ 0 ] , options ) ; / ** * @ type { Array < Position > } * / this . points = points ; this . points . slice ( 1 ) . forEach ( ( point ) => { const diff = point . subtract ( this . position ) ; ctx . lineTo ( diff . x , diff . y ) ; } ) ;", "del_tokens": "import Vector from \"@pencil.js/vector\" ; * @ param { Position } start - Start point * @ param { Position } end - End point * @ param { LineOptions } [ options ] - Drawing options constructor ( start , end , options ) { super ( start , options ) ; this . vector = new Vector ( start , end ) ; const delta = this . vector . getDelta ( ) ; ctx . lineTo ( delta . x , delta . y ) ; options . strokeWidth = 1 ;", "commit_type": "allow"}
{"commit_tokens": ["Update", "and", "clean", "up", "docstrings"], "add_tokens": "// : Whether to preserve the steps exactly as they came in. **Must** // be true when using the history together with the collaborative // editing plugin, to allow syncing the history when concurrent // changes come in.", "del_tokens": "// : Whether to throw away undone items. **Must** be true when // using the history together with the collaborative editing // plugin.", "commit_type": "update"}
{"commit_tokens": ["improved", "compatibility", "of", "Firefox", "with", "aborting", "a", "versionchange", "transaction"], "add_tokens": "request . onerror = ( function ( event ) { if ( wasBlocked ) { event . preventDefault ( ) ; return ; }", "del_tokens": "request . onerror = ( function ( ) {", "commit_type": "improve"}
{"commit_tokens": ["Added", "images", "array", "to", "JSON", "output"], "add_tokens": "} , images : [ ] } , images : [ ] } , images : [ ] } , images : [ ] var expected = / {\"chunks\":{\"main\":{\"js\":\"index-bundle-[0-9a-f]+\\.js\"}},\"images\":\\[\\]} / var expected = / {\"chunks\":{\"main\":{\"js\":\"main\\.js\\?[0-9a-f]+\"}},\"images\":\\[\\]} / } , images : [ ] chunks : { main : { js : 'index-bundle.js' } } , images : [ ] } , images : [ ] images : [ ] ,", "del_tokens": "} } } } var expected = / {\"chunks\":{\"main\":{\"js\":\"index-bundle-[0-9a-f]+\\.js\"}}} / var expected = / {\"chunks\":{\"main\":{\"js\":\"main\\.js\\?[0-9a-f]+\"}}} / } main : { js : 'index-bundle.js' } }", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "the", "wait", "-", "for", "-", "url", "host", "field"], "add_tokens": "match : / ^wait for (fragment|hash|path|url|host)( to (not )?be)? (.+)$ / i , case 'host' : value = window . location . host ; break ;", "del_tokens": "match : / ^wait for (fragment|hash|path|url)( to (not )?be)? (.+)$ / i ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "milestone", "regex", "to", "also", "support", "bigger", "versions"], "add_tokens": "const badgeRegex = / \\[!\\[v\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\sprogress\\]\\(http:\\/\\/progressed\\.io\\/bar\\/\\d{1,3}\\?title=v\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\)\\]\\(https:\\/\\/github.com\\/kristerkari\\/stylelint-scss\\/milestones\\/\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\) /", "del_tokens": "const badgeRegex = / \\[!\\[v\\d\\.\\d\\.\\d\\sprogress\\]\\(http:\\/\\/progressed\\.io\\/bar\\/\\d{1,3}\\?title=v\\d\\.\\d\\.\\d\\)\\]\\(https:\\/\\/github.com\\/kristerkari\\/stylelint-scss\\/milestones\\/\\d\\.\\d\\.\\d\\) /", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "passing", "an", "already", "-", "parsed", "object", "instead", "of", "a", "file", "path", "."], "add_tokens": "'use strict' ; / ** * @ name parser * @ type { { parse : function , defaults : defaults } } * / module . exports = { parse : require ( './parse' ) , defaults : require ( './defaults' ) } ;", "del_tokens": "'use strict' ; / ** * @ name parser * @ type { { parse : function , defaults : defaults } } * / module . exports = { parse : require ( './parse' ) , defaults : require ( './defaults' ) } ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "data", "to", "separate", "folder"], "add_tokens": "var graphOfGods = require ( './data/graphOfGodsData' ) ( ) ,", "del_tokens": "var graphOfGods = require ( './graphOfGodsData' ) ( ) ,", "commit_type": "move"}
{"commit_tokens": ["Add", "lint", "rules", "and", "suppress", "lin", "warnings"], "add_tokens": "'use strict' ; _this . restore . __programmedPush = [ chunk , encoding , done ] ;", "del_tokens": "_this . restore . __programmedPush = [ ] . slice . call ( arguments , 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "fluence", "-", "js", "webpack", "config", "for", "production", "use"], "add_tokens": "const production = ( process . env . NODE_ENV === 'production' ) ; const config = { if ( production ) { config . mode = 'production' ; } else { config . mode = 'development' ; config . devtool = 'inline-source-map' ; config . devServer = { contentBase : './bundle' , hot : true } ; config . plugins = [ ... config . plugins , new HtmlWebpackPlugin ( ) , new webpack . HotModuleReplacementPlugin ( ) ] ; } module . exports = config ;", "del_tokens": "module . exports = { devtool : 'inline-source-map' , devServer : { contentBase : './bundle' , hot : true } , mode : 'development' , new HtmlWebpackPlugin ( ) , new webpack . HotModuleReplacementPlugin ( )", "commit_type": "fix"}
{"commit_tokens": ["fix", "utf", "character", "var", "name", "bug"], "add_tokens": "var_name [ i ] === \".\" || code > 255 // utf ) {", "del_tokens": "var_name [ i ] === \".\" ) {", "commit_type": "fix"}
{"commit_tokens": ["fixing", "issue", "with", "context", "not", "being", "reloaded", "for", "each", "page"], "add_tokens": "phaser . log = require ( './lib/log' ) . init ( opts , phaser ) ; phaser . verbose = phaser . log . verbose ; } ; / ** * phaser . process * / phaser . process = function ( src , options ) { var opts = _ . extend ( { } , options ) ; phaser . init ( opts ) ;", "del_tokens": "phaser . log = require ( './lib/log' ) . init ( opts , phaser ) ; phaser . verbose = phaser . log . verbose ; } ; / ** * phaser . process * / phaser . process = function ( src , options ) { var opts = _ . extend ( { } , options ) ; phaser . init ( opts ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "dedicated", "express", "server", "with", "own", "config"], "add_tokens": "bases : '.' , server : __dirname + '/server.js'", "del_tokens": "bases : '.'", "commit_type": "add"}
{"commit_tokens": ["removed", "archive", "and", "compatibility", "mode"], "add_tokens": "// const COMPATIBILITY = require(path.join(__dirname, './archive/controller')); // const deprecate = require(path.join(__dirname, './utility/deprecate')); // module.exports.compatibility = deprecate(function (periodic, options) { // return new COMPATIBILITY(periodic, options); // }, 'CoreController compatibility mode will soon be removed');", "del_tokens": "const COMPATIBILITY = require ( path . join ( __dirname , './archive/controller' ) ) ; const deprecate = require ( path . join ( __dirname , './utility/deprecate' ) ) ; module . exports . compatibility = deprecate ( function ( periodic , options ) { return new COMPATIBILITY ( periodic , options ) ; } , 'CoreController compatibility mode will soon be removed' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "safe", "-", "buffer", "for", "improved", "Buffer", "API"], "add_tokens": "var Buffer = require ( 'safe-buffer' ) . Buffer value = Buffer . from ( binary , 'binary' ) . toString ( 'utf8' )", "del_tokens": "value = new Buffer ( binary , 'binary' ) . toString ( 'utf8' )", "commit_type": "use"}
{"commit_tokens": ["Changed", ".", "videoOut", "()", "to", ".", "video", "()"], "add_tokens": "wjs . prototype . video = function ( newBool ) {", "del_tokens": "this . video = { } ; // Video Object (holds width, height, pixelFormat) if ( vlcs [ this . context ] . width ) { this . video = { } ; this . video . width = vlcs [ this . context ] . width ; this . video . height = vlcs [ this . context ] . height ; this . video . pixelFormat = vlcs [ this . context ] . pixelFormat ; } wjs . prototype . videoOut = function ( newBool ) {", "commit_type": "change"}
{"commit_tokens": ["Allow", "passing", "in", "paths", "to", "the", "compiler", "and", "the", "server"], "add_tokens": "child_process = require ( 'child_process' ) , util = require ( './lib/util' ) module . exports = { compile : compile , addPath : util . addPath } searchPath = isRelative ? path . join ( pathBase , rawModulePath ) : ( util . resolve ( rawModulePath ) || '' ) . replace ( / \\.js$ / , '' ) ,", "del_tokens": "module . exports = { compile : compile } child_process = require ( 'child_process' ) searchPath = isRelative ? path . join ( pathBase , rawModulePath ) : ( require . resolve ( rawModulePath ) || '' ) . replace ( / \\.js$ / , '' ) ,", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "PushDownSelectionsPass", "to", "work", "for", "more", "complex", "trees", "."], "add_tokens": "var originalIndex = 0 ; originalIndex = parentNode . getChildren ( ) . indexOf ( node ) ; function ( child , index ) { parentNode . addChildAt ( child , originalIndex + index ) ;", "del_tokens": "function ( child ) { parentNode . addChild ( child ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "express", "-", "session", "settings", "and", "dependencies"], "add_tokens": "name : sessionIDKey , resave : true , rolling : true , unset : 'destroy'", "del_tokens": "//Refreshes the cookie time this . app . use ( function ( req , res , next ) { var cookieID ; if ( usingSignedCookie ) { cookieID = req . signedCookies [ sessionIDKey ] ; } else { cookieID = req . cookies [ sessionIDKey ] ; } //Creates a new cookie with the same ID //so it refreshes the time if ( cookieID ) { res . cookie ( sessionIDKey , cookieID , { httpOnly : true , signed : usingSignedCookie , maxAge : maxAge } ) ; } next ( ) ; } ) ; key : sessionIDKey , resave : true", "commit_type": "update"}
{"commit_tokens": ["using", "kami", "-", "util", "for", "base", "object"], "add_tokens": "var BaseObject = require ( 'kami-util' ) . BaseObject ; * @ param { String } options . crossOrigin the image cross - origin parameter ( if src is provided ) //sets up base Kami object.. BaseObject . call ( this , context ) ; var crossOrigin = options . crossOrigin ; img . crossOrigin = crossOrigin ;", "del_tokens": "var wrapContext = require ( 'kami-util' ) . wrapContext ; if ( ! context || typeof context !== \"object\" ) throw \"valid GL context not specified to Texture\" ; this . context = wrapContext ( context ) ; // e.g. --> new Texture(gl, 256, 256, gl.RGB, gl.UNSIGNED_BYTE, data); // creates a new empty texture, 256x256 // --> new Texture(gl); // creates a new texture but WITHOUT uploading any data.", "commit_type": "use"}
{"commit_tokens": ["updated", "later", "()", ".", "isValid", "()", "to", "ignore", "milliseconds"], "add_tokens": "it ( 'should ignore milliseconds of passed in date' , function ( ) { this . timeout ( 1 ) ; var r = recur ( ) . on ( 5 ) . second ( ) ; var start = new Date ( '2012-02-28T00:00:05Z' ) ; start . setMilliseconds ( 15 ) ; var l = later ( ) . isValid ( r , start ) ; l . should . be . true ; } ) ;", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["fixed", "context", "example", "and", "renamed", "scope", "variable", "in", "ContextQuery", "to", "context", "for", "the", "sake", "of", "consistency"], "add_tokens": "let context = first ( document . children ( this . options . selector ) ) ; if ( context !== undefined ) return this . options . inner . on ( context ) ;", "del_tokens": "let scope = first ( document . children ( this . options . selector ) ) ; if ( scope !== undefined ) return this . options . inner . on ( scope ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "an", "error", "with", "0", "values", "on", "hours", "and", "minutes"], "add_tokens": "if ( this . hasOwnProperty ( 'hours' ) && this . hasOwnProperty ( 'minutes' ) ) {", "del_tokens": "if ( this . hours && this . minutes ) {", "commit_type": "fix"}
{"commit_tokens": ["Move", "logic", "from", "index", ".", "js", "to", "codechecks", ".", "js"], "add_tokens": "", "del_tokens": "const CodeChecksReport = require ( \"./lib/codechecksReport\" ) ; const codechecks = new CodeChecksReport ( config ) ; codechecks . loadData ( ) ; codechecks . generate ( watch . data ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "the", "cli", "tool", "and", "allow", "custom", "command"], "add_tokens": "res . end ( \"Hello World \" + process . argv [ 2 ] ) ;", "del_tokens": "res . end ( \"Hello World\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "Math", ".", "imul", "and", "bitwise", "operations", "to", "compute", "the", "hash", "quickly"], "add_tokens": "if ( ! Math . imul ) Math . imul = function imul ( a , b ) { var ah = a >>> 16 ; var al = a & 0xffff ; var bh = b >>> 16 ; var bl = b & 0xffff ; return ( al * bl + ( ( ah * bl + al * bh ) << 16 ) ) | 0 ; } ; , hasher = 2654435761 var hash = Math . imul ( sequenceLowBits | ( sequenceHighBits << 16 ) , hasher ) >>> hashShift", "del_tokens": ", hasher = uint32 ( 2654435761 ) var Hash = uint32 ( ) // Reusable unsigned 32 bits integer var hash = Hash . fromBits ( sequenceLowBits , sequenceHighBits ) . multiply ( hasher ) . shiftr ( hashShift ) . toNumber ( )", "commit_type": "use"}
{"commit_tokens": ["Use", "unicode", "to", "send", "escape", "character", "to", "shell", "instead", "of", "octal", "to", "work", "with", "strict", "mode", "javascript"], "add_tokens": "fmt = ' \\u001b[9' + c + 'm' + name + ' ' + '\\u001b[3' + c + 'm\\u001b[90m' + fmt + '\\u001b[3' + c + 'm' + ' +' + humanize ( ms ) + '\\u001b[0m' ;", "del_tokens": "fmt = ' \\033[9' + c + 'm' + name + ' ' + '\\033[3' + c + 'm\\033[90m' + fmt + '\\033[3' + c + 'm' + ' +' + humanize ( ms ) + '\\033[0m' ;", "commit_type": "use"}
{"commit_tokens": ["added", "grunt", "-", "contrib", "-", "connect"], "add_tokens": "connect : { server : { options : { port : 8001 , hostname : '*' } } } grunt . loadNpmTasks ( 'grunt-contrib-connect' ) ; grunt . registerTask ( 'w' , [ 'connect' , 'build' , 'watch' ] ) ;", "del_tokens": "grunt . registerTask ( 'w' , [ 'build' , 'watch' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "setMap", "function", "to", "mocha", "runner", "script", "(", "tests", "no", "longer", "failing", ")"], "add_tokens": "addListener : function ( ) { } , setMap : function ( ) { }", "del_tokens": "addListener : function ( ) { }", "commit_type": "add"}
{"commit_tokens": ["Change", "if", "else", "to", "inline", "if"], "add_tokens": "return piece ? { x , y , isBlack : piece . isBlack } : { x , y } ;", "del_tokens": "if ( piece ) return { x , y , isBlack : piece . isBlack } ; else return { x , y } ;", "commit_type": "change"}
{"commit_tokens": ["changed", "remove", "to", "be", "more", "future", "proof"], "add_tokens": "// changed to a safer feature detection set if ( item . remove !== undefined ) {", "del_tokens": "if ( item . hasOwnProperty ( 'remove' ) ) {", "commit_type": "change"}
{"commit_tokens": ["added", "on", "connect", "event", "emitter"], "add_tokens": "connectListeners = [ ] , client . then ( connectHandler ) ; / ** * send the channel name when a subscription is accepted by the hub * * @ param listener - the handler function * / this . onConnect = function ( listener ) { log . info ( 'add a connection listener...' ) ; connectListeners . push ( listener ) ; } ; var connectHandler = function ( ) { log . info ( 'message subscription to ' , channel , ' accepted...' ) ; connectListeners . forEach ( function ( listener ) { listener . call ( null , channel ) ; } ) ; } ; listener . call ( null , message ) ;", "del_tokens": "client . then ( function ( ) { log . info ( 'subscription to ' , channel , ' accepted...' ) ; } ) ; listener ( message ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "self", "-", "reference", "to", "links", "object"], "add_tokens": "var id = model . id ; // always add a self-referential link links . self = '/' + typeName + '/' + model . id ; serialized . links = links ;", "del_tokens": "var id = model . get ( 'id' ) ; if ( Object . keys ( links ) . length > 0 ) { serialized . links = links ; }", "commit_type": "add"}
{"commit_tokens": ["Allow", "fileList", "to", "fail", "and", "return", "an", "empty", "array", "."], "add_tokens": "return q . nfcall ( this . fs . readFile , process . cwd ( ) + '/bitbin.manifest.json' , { encoding : 'utf8' } ) files = JSON . parse ( files ) ; } ) . catch ( function ( ) { // @todo should check the err here to see if file doesn't exist or general error. return [ ] ;", "del_tokens": "return q . nfcall ( this . fs . readFile , process . cwd ( ) + '/bitbin.manifest.json' )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "development", "server", "crashing", "on", "lint", "errors"], "add_tokens": "const failOnError = ! ( buildTarget === 'develop' || buildTarget === 'test' && watch ) bail : failOnError , failOnError", "del_tokens": "bail : ! watch , failOnError : ! watch", "commit_type": "fix"}
{"commit_tokens": ["Use", "reversed", "edges", "during", "rank", "phase", "only"], "add_tokens": "function verticalAlignment ( g , layering , type1Conflicts ) { var visited = { } ; visited [ v ] = true ; var related = g . neighbors ( v ) . filter ( function ( w ) { return w in visited ; } ) ; var align = verticalAlignment ( g , layering , type1Conflicts ) ;", "del_tokens": "function verticalAlignment ( g , layering , type1Conflicts , relationship ) { var related = g [ relationship ] ( v ) ; var align = verticalAlignment ( g , layering , type1Conflicts , vertDir === \"up\" ? \"predecessors\" : \"successors\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "transpiling", "issues", "with", "instanceof"], "add_tokens": "return value . constructor === Array ;", "del_tokens": "return value instanceof Array ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "broken", "test", "in", "IO", ".", "js"], "add_tokens": "expect ( res . headers [ 'content-length' ] ) . to . satisfy ( function ( contentLength ) { // This is the difference between returning an empty array vs. nothing at all return contentLength === undefined || contentLength === '0' ; } ) ;", "del_tokens": "expect ( res . headers [ 'content-length' ] ) . to . be . undefined ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "support", "for", "writing", "strings"], "add_tokens": "return _ . map ( object , function ( value , key ) { if ( typeof value === 'string' ) { return key + '=\"' + value + '\"' } else { return key + '=' + value } } ) . join ( ',' ) } InfluxDB . prototype . _createKeyTagString = function ( object ) { line += ',' + this . _createKeyTagString ( points [ 1 ] ) if ( typeof points [ 0 ] === 'string' ) { line += ' value=\"' + points [ 0 ] + '\"' } else { line += ' value=' + points [ 0 ] }", "del_tokens": "line += ',' + this . _createKeyValueString ( points [ 1 ] ) line += ' value=' + points [ 0 ]", "commit_type": "add"}
{"commit_tokens": ["changed", "status", "code", "from", "201", "to", "202"], "add_tokens": "return this . client . post ( '/firewalls' , attributes , 202 , 'firewall' , callback ) ;", "del_tokens": "return this . client . post ( '/firewalls' , attributes , 201 , 'firewall' , callback ) ;", "commit_type": "change"}
{"commit_tokens": ["removed", "superagent", "from", "backedn", "."], "add_tokens": "import request from './request' ; const $ = cheerio . load ( resp . body ) ; const json = tj . kml ( new DOMParser . DOMParser ( ) . parseFromString ( kmlRequest . body ) ) ;", "del_tokens": "import request from 'superagent' ; const $ = cheerio . load ( resp . text ) ; const json = tj . kml ( new DOMParser . DOMParser ( ) . parseFromString ( kmlRequest . text ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "user", "agent", "tests", "."], "add_tokens": "if ( / ^Mozilla / . test ( navigator . userAgent ) && ! / AppleWebKit / . test ( navigator . userAgent ) ) {", "del_tokens": "if ( / ^Mozilla / . test ( navigator . userAgent ) ) {", "commit_type": "fix"}
{"commit_tokens": ["create", "an", "empty", "Combinator", "if", "none", "was", "specified", ".", "Refactored", "Combinator", "generation", "and", "added", "+", "~", "::"], "add_tokens": "return this . combinator . toCSS ( ) + this . value ; this . value = value ? value . trim ( ) : \"\" ; case ' : : ': return ' : : ' case ' + ': return ' + ' case ' ~ ': return ' ~ '", "del_tokens": "var css = ( this . combinator ? this . combinator . toCSS ( ) : ' ' ) + this . value ; return css ; this . value = value . trim ( ) ;", "commit_type": "create"}
{"commit_tokens": ["use", "strings", "for", "empty", "message", "part", "check", "."], "add_tokens": "if ( '\\u0000' === String ( msg [ i ] ) ) {", "del_tokens": "if ( 0x00 === msg [ i ] [ 0 ] ) {", "commit_type": "use"}
{"commit_tokens": ["fixed", "API", ":", "Babel", ".", "prototype", ".", "getNamedVars", "()", "-", ">", "Babel", ".", "getNamedVars", "()"], "add_tokens": "Babel . getNamedVars = function getNamedVars ( str ) {", "del_tokens": "Babel . prototype . getNamedVars = function getNamedVars ( str ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "task", ":", "checkPackages", "task", ":", "checkConfig"], "add_tokens": "if ( err ) return console . log ( err ) ;", "del_tokens": "if ( err ) throw err ;", "commit_type": "add"}
{"commit_tokens": ["updated", "mos", "chunk", ".", "ID", "32", "dec", "."], "add_tokens": "mos . writeUInt16BE ( 0x0020 , 2 ) ;", "del_tokens": "mos . writeUInt16BE ( 0x0033 , 2 ) ;", "commit_type": "update"}
{"commit_tokens": ["using", "createTextNode", "()", "instead", "of", "new", "Text", "()"], "add_tokens": "var $textNode = this . textNode = document . createTextNode ( '' )", "del_tokens": "var $textNode = this . textNode = new Text ( )", "commit_type": "use"}
{"commit_tokens": ["Move", "out", "promise", "factory", "from", "prototype"], "add_tokens": "var imagesReady = new ImagesReady ( image , true ) ; var imagesReady = new ImagesReady ( '.content' , true ) ; var imagesReady = new ImagesReady ( '.fail' , true ) ; var imagesReady = new ImagesReady ( element , true ) ; var imagesReady = new ImagesReady ( image , true ) ; var imagesReady = new ImagesReady ( image , true ) ; var imagesReady = new ImagesReady ( images , true ) ; var imagesReady = new ImagesReady ( images , true ) ;", "del_tokens": "var imagesReady = new ImagesReady ( image , { jquery : true } ) ; var imagesReady = new ImagesReady ( '.content' , { jquery : true } ) ; var imagesReady = new ImagesReady ( '.fail' , { jquery : true } ) ; var imagesReady = new ImagesReady ( element , { jquery : true } ) ; var imagesReady = new ImagesReady ( image , { jquery : true } ) ; var imagesReady = new ImagesReady ( image , { jquery : true } ) ; var imagesReady = new ImagesReady ( images , { jquery : true } ) ; var imagesReady = new ImagesReady ( images , { jquery : true } ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "TypeError", "on", "string", "body", "error", "from", "rest", "-", "proxy"], "add_tokens": "if ( typeof body === 'object' && headers ) {", "del_tokens": "if ( body && headers ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "for", "Node", "<", "4", "(", "Object", ".", "assign", "problems", ")"], "add_tokens": "if ( options === undefined ) { options = { } ; } if ( options . keysLimit === undefined ) { options . keysLimit = 0 ; } var cacheEntry = this . cache [ key ] ; if ( cacheEntry . isValid ( ) ) {", "del_tokens": "options = Object . assign ( { keysLimit : 0 } , options || { } ) ; if ( this . cache [ key ] . isValid ( ) ) { var cacheEntry = Object . assign ( { } , this . cache [ key ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "heading", "in", "assemble", ".", "js"], "add_tokens": "* Assemble * Copyright ( c ) 2012 Brian Woodward * Licensed under the MIT license . var file = grunt . file ; var log = grunt . log ; var kindOf = grunt . util . kindOf ; var _ = grunt . util . _ ; var assemble = require ( '../lib/assemble' ) ; var path = require ( 'path' ) ; var fs = require ( 'fs' ) ; var util = require ( 'util' ) ;", "del_tokens": "* Assemble Assemble * Authored by Brian Woodward * Inspired by previous work by Jon Schlinkert var file = grunt . file ; var log = grunt . log ; var kindOf = grunt . util . kindOf ; var _ = grunt . util . _ ; var assemble = require ( '../lib/assemble' ) ; var path = require ( 'path' ) ; var fs = require ( 'fs' ) ; var util = require ( 'util' ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "full", "device", "support", "for", "response"], "add_tokens": "this . db . insert ( association , function ( err , device ) { var id ; if ( device ) { id = device . _id ; delete device . _id ; } callback ( err , id , device ) ; function ( err , numReplaced , device ) { if ( device ) { id = device . _id ; delete device . _id ; } else { device = association } ; callback ( err , id , device ) ;", "del_tokens": "this . db . insert ( association , function ( err , newDoc ) { var id = null ; if ( newDoc ) { id = newDoc . _id ; } callback ( err , id ) ; function ( err , numReplaced , newDoc ) { if ( newDoc ) { id = newDoc . _id ; } callback ( err , id ) ;", "commit_type": "add"}
{"commit_tokens": ["created", "build", "for", "the", "color", "features"], "add_tokens": "start : \"//v0.1.3-feature-color toxiclibs.js (http://haptic-data.com/toxiclibsjs)\\nvar toxi = {};\\n(function(){\\n\" ,", "del_tokens": "start : \"//v0.1.3 toxiclibs.js (http://haptic-data.com/toxiclibsjs)\\nvar toxi = {};\\n(function(){\\n\" ,", "commit_type": "create"}
{"commit_tokens": ["Add", "timeout", "param", ".", "to", "README", "and", "test", "."], "add_tokens": "run : true , timeout : 10000", "del_tokens": "run : true", "commit_type": "add"}
{"commit_tokens": ["Add", "browsersync", "to", "gulp", "tasks", "and", "run", "it", "automagically", "on", "gulp", "init"], "add_tokens": "var browserSync = require ( 'browser-sync' ) ; var src = { html : './public/**/*.html' , scss : './src/main/sass/**/*.scss' } var reload = browserSync . reload ; } ) ; gulp . src ( src . scss ) . pipe ( reload ( { stream : true } ) ) gulp . task ( 'browser-sync' , function ( ) { browserSync . init ( null , { proxy : 'localhost:3000' gulp . task ( 'watch' , function ( ) { gulp . watch ( src . html , reload ) ; gulp . watch ( src . scss , [ 'sass' ] ) ; } ) ; gulp . task ( 'default' , [ 'sass' , 'browser-sync' , 'watch' ] ) ;", "del_tokens": "var sassSrcFiles = './src/main/sass/**/*.scss' ; } ) gulp . src ( sassSrcFiles ) gulp . task ( 'watch' , function ( ) { gulp . watch ( sassSrcFiles , function ( ) { gulp . start ( 'sass' ) ; gulp . task ( 'default' , [ 'sass' , 'watch' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "the", "drawing", "point", "to", "use", "the", "snapped", "location"], "add_tokens": "_snap_on_click : function ( e ) { if ( e ) { // update the feature being drawn to reflect the snapped location: marker . setLatLng ( e . target . _latlng ) ; if ( this . _poly ) { var polyPointsCount = this . _poly . _latlngs . length ; this . _poly . _latlngs [ polyPointsCount - 1 ] = e . target . _latlng ; this . _poly . redraw ( ) ; } }", "del_tokens": "_snap_on_click : function ( ) {", "commit_type": "update"}
{"commit_tokens": ["add", "default", ".", "log", "method", "and", "use", "it", "when", "a", "mode", "is", "used", "as", "a", "function", "directly"], "add_tokens": "// default logger \"log\" this . create ( 'log' ) ; return function ( ) { this . stack . addMode ( mode ) ; if ( utils . hasType ( mode . type , 'negative' ) ) { var ModeWrapper = function ( ) { } ; var inst = new ModeWrapper ( ) ; inst . __proto__ = Logger . prototype ; return inst ; } var method ; if ( typeof this . methods [ name ] === 'function' ) { method = this . methods [ name ] ; } else { method = function ( /*message*/ ) { var args = [ ] . slice . call ( arguments ) ; args . unshift ( 'log' ) ; return this . _emit . apply ( this , args ) ; } . bind ( this ) ; this . methods [ name ] = method ; } method . __proto__ = Logger . prototype ; return method ; } . bind ( this ) ;", "del_tokens": "/* jshint validthis: true */ var self = this ; var getter = function ( ) { self . stack . addMode ( mode ) ; var ModeWrapper = function ( ) { } ; var inst = new ModeWrapper ( ) ; inst . __proto__ = Logger . prototype ; return inst ; } ; return getter ;", "commit_type": "add"}
{"commit_tokens": ["use", "the", "met", "light", "as", "default", "categorical", "color"], "add_tokens": "import { TheMetLight } from '../color/preset/metropolis' ; scheme : TheMetLight ,", "del_tokens": "import { MetroRain8 } from '../color/preset/metropolis' ; scheme : MetroRain8 ,", "commit_type": "use"}
{"commit_tokens": ["Move", "focus_outline_manager", "to", "use", "base", "namespace", "."], "add_tokens": "base . define ( 'base.ui' , function ( ) {", "del_tokens": "cr . define ( 'cr.ui' , function ( ) {", "commit_type": "move"}
{"commit_tokens": ["use", "node", "built", "-", "in", "path", ".", "delimiter"], "add_tokens": "opts . env . PATH += pathlib . delimiter ;", "del_tokens": "var isWindows = / ^win / . test ( process . platform ) ; opts . env . PATH += ( isWindows ) ? ';' : ':' ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "isInited", "()", "issue", "in", "Closure", "-", "compiled", "version"], "add_tokens": "if ( ! config . bits || ! config . radix || ! config . logs || ! config . exps || ! config . size || ! config . max || config . logs . length !== config . size || config . exps . length !== config . size ) {", "del_tokens": "var required = [ 'bits' , 'radix' , 'logs' , 'exps' ] ; for ( var i = 0 , len = required . length ; i < len ; i ++ ) { if ( ! config [ required [ i ] ] ) { return false ; } } if ( config . logs . length !== config . size || config . exps . length !== config . size ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "Cancel", "swal", "-", "form", "if", "required", "fields", "are", "missing"], "add_tokens": "this . swalForm = swalFormInstance . getFormValues ( isConfirm ) getFormValues : function ( isConfirm ) { if ( isConfirm && tag . dataset . swalFormsRequired && ! tag . value ) {", "del_tokens": "this . swalForm = swalFormInstance . getFormValues ( ) getFormValues : function ( ) { if ( tag . dataset . swalFormsRequired && ! tag . value ) {", "commit_type": "allow"}
{"commit_tokens": ["Adding", "a", "bunch", "of", "files", "and", "updating", "version", "."], "add_tokens": "let moduleAvailable = require ( 'module-available' ) let gc = { logging : { file : 'logger.log' , level : 'error' } } if ( moduleAvailable ( 'sb/etc/GetConfigValues.js' ) ) { let GetConfigValues = require ( 'sb/etc/GetConfigValues.js' ) gc = new GetConfigValues ( ) ; }", "del_tokens": "let GetConfigValues = require ( 'sb/etc/GetConfigValues.js' ) let gc = new GetConfigValues ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "flexibiliy", "to", "attribute", "selectors", "in", "preset", "patterns"], "add_tokens": "var attribute = '(?:\\\\[.+\\\\])?' ; var attribute = '(?:\\\\[.+\\\\])?' ;", "del_tokens": "var attribute = '(?:\\\\[\\\\S+\\\\])?' ; var attribute = '(?:\\\\[\\\\S+\\\\])?' ;", "commit_type": "add"}
{"commit_tokens": ["Add", "jsdoc", "documentation", "for", "transaction", ".", "js"], "add_tokens": "gulp . src ( [ 'README.md' , './lib/*.js' , './lib/**/*.js' ] )", "del_tokens": "gulp . src ( [ 'README.md' , './lib/*.js' ] )", "commit_type": "add"}
{"commit_tokens": ["Changed", "--", "windows", "for", "global", "install", "path"], "add_tokens": "console . log ( process . argv [ 1 ] . substring ( 0 , process . argv [ 1 ] . length - 13 ) ) ;", "del_tokens": "console . log ( process . argv [ 1 ] . replace ( \"\\bin\\cast-web-api\" , \"\" ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Make", "Alliances", ".", "spec", ".", "js", "tests", "pass"], "add_tokens": "return api . noAuth . post ( '/v2/universe/names/' , { body : ids } ) } ) ; * @ param api { ESIAgent } Internal api", "del_tokens": "return api . universe ( ) . newRequest ( 'postUniverseNames' , [ ids ] ) } ) * @ param api { ApiProvider } Internal api", "commit_type": "make"}
{"commit_tokens": ["Allow", "the", "fieldset", "wrapper", "to", "be", "configurable", "via", "a", "tag", "property"], "add_tokens": "return h ( this . tag ? this . tag : 'fieldset' , children ) ; props : [ 'form' , 'model' , 'fields' , 'customLayout' , 'tag' ] ,", "del_tokens": "return h ( 'fieldset' , children ) ; props : [ 'form' , 'model' , 'fields' , 'customLayout' ] ,", "commit_type": "allow"}
{"commit_tokens": ["Adding", "contact", "methods", "(", "create", "get", "update", "delete", "convert", ")"], "add_tokens": "'created_at' : seconds_since_epoch ( ) , 'created' : seconds_since_epoch ( ) , intercom . getConversation ( { id : 858210458 } , function ( err , res ) { function seconds_since_epoch ( ) { return Math . floor ( Date . now ( ) / 1000 ) }", "del_tokens": "'created_at' : ( new Date ( ) / 1000 ) , 'created' : ( new Date ( ) / 1000 ) , intercom . getConversation ( { id : 123 } , function ( err , res ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "execution", "of", "fixpack", "in", "projects", "with", "spaces", "in", "the", "CWD"], "add_tokens": "exec ( 'node \"' + fixpack + '\"' , function ( error , stdout , stderr ) {", "del_tokens": "exec ( 'node ' + fixpack , function ( error , stdout , stderr ) {", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "we", "always", "send", "apns", "-", "expiration", "as", "integer", "number"], "add_tokens": "expect ( notification . expiry ) . toEqual ( Math . round ( expirationTime / 1000 ) ) ; expect ( notification . expiry ) . toEqual ( Math . round ( expirationTime / 1000 ) ) ; expect ( notification . expiry ) . toEqual ( Math . round ( data [ 'expiration_time' ] / 1000 ) ) ; expect ( notification . expiry ) . toEqual ( Math . round ( data [ 'expiration_time' ] / 1000 ) ) ; expect ( notification . expiry ) . toEqual ( Math . round ( data [ 'expiration_time' ] / 1000 ) ) ;", "del_tokens": "expect ( notification . expiry ) . toEqual ( expirationTime / 1000 ) ; expect ( notification . expiry ) . toEqual ( expirationTime / 1000 ) ; expect ( notification . expiry ) . toEqual ( data [ 'expiration_time' ] / 1000 ) ; expect ( notification . expiry ) . toEqual ( data [ 'expiration_time' ] / 1000 ) ; expect ( notification . expiry ) . toEqual ( data [ 'expiration_time' ] / 1000 ) ;", "commit_type": "make"}
{"commit_tokens": ["Improve", "support", "for", "references", "with", "prefixes", "and", "custom", "fields", "typed", "any"], "add_tokens": "/// <reference path=\"../typings/bluebird/bluebird.d.ts\" /> /// <reference path=\"../typings/lodash/lodash.d.ts\" /> /// <reference path=\"../typings/underscore.string/underscore.string.d.ts\" /> any : \"any\" , var targetFieldName = toTitleCase ( field . targetIdFieldType ) || field . fieldNameProperCase ( ) ; var otherTableName = Sequelize . Utils . pluralize ( targetFieldName . substr ( 0 , targetFieldName . length - Schema . idSuffix . length ) , \"en\" ) ; return text == undefined ? undefined : text . charAt ( 0 ) . toUpperCase ( ) + text . substr ( 1 , text . length - 1 ) ;", "del_tokens": "var otherTableName = Sequelize . Utils . pluralize ( field . fieldNameProperCase ( ) . substr ( 0 , field . fieldName . length - Schema . idSuffix . length ) , \"en\" ) ; return text . charAt ( 0 ) . toUpperCase ( ) + text . substr ( 1 , text . length - 1 ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "tabs", "in", "build", "scripts"], "add_tokens": "spawn = require ( \"child_process\" ) . spawn ; which . sync ( \"bower\" ) ; console . error ( \"Bower must be installed to build jBone.\" ) ; console . error ( \"Please install Bower by running the following command:\" ) ; console . error ( \"npm install -g bower\" ) ; process . exit ( 0 ) ; stdio : \"inherit\"", "del_tokens": "spawn = require ( \"child_process\" ) . spawn ; which . sync ( \"bower\" ) ; console . error ( \"Bower must be installed to build jBone.\" ) ; console . error ( \"Please install Bower by running the following command:\" ) ; console . error ( \"npm install -g bower\" ) ; process . exit ( 0 ) ; stdio : \"inherit\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "icon", "option", "to", "support", "Safari", "s", "Pinned", "Tabs"], "add_tokens": "it ( 'returns safari pinned tab link tags' , function ( ) { var expected = '<link rel=\"mask-icon\" href=\"/foo/bar.svg\" color=\"red\">' ; var index = createIndex ( ) ; index . manifestConfiguration = { icons : [ { src : '/foo/bar.svg' , safariPinnedTabColor : 'red' , targets : [ 'safari-pinned-tab' ] , } ] } ; assert . ok ( index . contentFor ( 'head' , { rootURL : '/' } ) . includes ( expected ) ) ; } ) ;", "del_tokens": "var MockUI = require ( 'console-ui/mock' ) ; var stripAnsi = require ( 'strip-ansi' ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "simple", "concat", "as", "quick", "stats", "hash"], "add_tokens": "var file , sub , oldHash ; oldHash = cache [ file ] && cache [ file ] . statsHash ; dirStats . paths [ file ] . statsHash = stats . mode + '_' + stats . size + '_' + stats . mtime . getTime ( ) ; if ( ! oldHash || dirStats . paths [ file ] . statsHash !== oldHash ) {", "del_tokens": "var file , sub , oldStats ; oldStats = cache [ file ] && cache [ file ] . stats ; if ( ! oldStats || stats . mode !== oldStats . mode || stats . size !== oldStats . size || stats . mtime . getTime ( ) !== oldStats . mtime . getTime ( ) ) {", "commit_type": "use"}
{"commit_tokens": ["Adding", "test", "for", "twice", "."], "add_tokens": "} ,", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Move", "sync", "function", "template", "file", "to", "etc", "dir", "to", "unclutter", "the", "root", "of", "the", "project"], "add_tokens": "// This sync function for Couchbase Sync Gateway was generated by synctos: https://github.com/Kashoo/synctos", "del_tokens": "// This sync function for Couchbase Sync Gateway was generated by couchbase-sync-maker: https://github.com/Kashoo/couchbase-sync-maker", "commit_type": "move"}
{"commit_tokens": ["fix", "exceptions", "on", "missing", "document", ".", "body", "and", "reloading", "devtool", "panel"], "add_tokens": "var worker ; } worker = tab . attach ( { // prevents exception on trying to reload a reloading devtool panel if ( this . _iframe . contentWindow ) { this . _iframe . contentWindow . location . reload ( ) ; }", "del_tokens": "} ; var worker = tab . attach ( { this . _iframe . contentWindow . location . reload ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "rather", "obvious", "bug", "when", "writing", "to", "storage"], "add_tokens": "this . _options . storage . set ( recordName , record , function ( error ) { if ( error ) { this . _options . logger . log ( C . TOPIC . RECORD , C . EVENT . RECORD_CREATE_ERROR , 'storage:' + error ) ; }", "del_tokens": "this . _options . storage . set ( record , record , function ( error ) { if ( error ) { this . _options . logger . log ( C . TOPIC . RECORD , C . EVENT . RECORD_CREATE_ERROR , 'storage:' + error ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "latest", "version", "of", "cuttlefish"], "add_tokens": "TYPE_ORGANIZATION = 'Organization' ; angular . module ( 'reelyactive.cuttlefish' , [ 'ngAnimate' , 'ui.bootstrap' ] ) scope . toggle = scope . toggle || false ; scope . visible = scope . visible || [ ] ; case 'schema:Organization' : scope . organization = formatItem ( graph [ cItem ] , TYPE_ORGANIZATION ) ; scope . types . push ( TYPE_ORGANIZATION ) ; break ; scope . itemID = Bubble . generateID ( graph [ cItem ] [ \"@id\" ] ) ; scope . unsupported = true ; } //scope.types = Bubble.availableTypes(scope.visible, scope.types); if ( scope . types . length > 0 ) { scope . current = scope . types [ 0 ] ; scope . bubble = new Bubble ( scope ) ; scope . $on ( '$destroy' , function ( ) { scope . bubble . removed ( ) ; } ) ; size : \"@\" , toggle : \"=\" , visible : \"@\"", "del_tokens": "angular . module ( 'reelyactive.cuttlefish' , [ ] ) scope . toggle = 0 ; scope . itemID = graph [ cItem ] [ \"@id\" ] ; scope . current = scope . types [ 0 ] ; //scope.json = json; size : \"@\"", "commit_type": "update"}
{"commit_tokens": ["Changed", "method", "access", "level", "in", "templates", "."], "add_tokens": "return self . loadFileContent ( content ) ; loadFileContent : function ( file_content ) {", "del_tokens": "return self . _parseFile ( content ) ; _parseFile : function ( file_content ) {", "commit_type": "change"}
{"commit_tokens": ["using", "date", "-", "fns", "for", "date", "formatting", ";"], "add_tokens": "const date_fns_1 = require ( \"date-fns\" ) ; return date_fns_1 . format ( helper . faker . date . recent ( ) , \"YYYY-MM-DD\" ) ; return date_fns_1 . format ( helper . faker . date . past ( ) , \"YYYY-MM-DD\" ) ; return date_fns_1 . format ( helper . faker . date . future ( ) , \"YYYY-MM-DD\" ) ; return date_fns_1 . format ( helper . faker . date . soon ( ) , \"YYYY-MM-DD\" ) ;", "del_tokens": "function makeDateString ( aDate ) { return ` ${ aDate . getFullYear ( ) } ${ aDate . getMonth ( ) + 1 } ${ aDate . getDate ( ) } ` ; } return makeDateString ( helper . faker . date . recent ( ) ) ; return makeDateString ( helper . faker . date . past ( ) ) ; return makeDateString ( helper . faker . date . future ( ) ) ; return makeDateString ( helper . faker . date . soon ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "generic", "custom", "Error", "class"], "add_tokens": "module . exports . Error = require ( './lib/errorHandler/lib/error' ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "cases", "for", "trying", "to", "add", "/", "update", "an", "ambush", "function", "with", "an", "id", "that", "belong", "to", "an", "already", "stored", "ambush", "."], "add_tokens": "it ( 'Wrong ID: The id already exist in the database' , function ( ) { expect ( function ( ) { goblinDB . ambush . add ( { id : 'testing-simple-function' , category : [ 'test-category' ] , action : function ( ) { } , } ) ; } ) . to . throw ( errors . AMBUSH_PROVIDED_ID_ALREADY_EXIST ) ; } ) ; expect ( function ( ) { goblinDB . ambush . update ( 'testing-simple-function' , { id : 'testing-callback-function'", "del_tokens": "expect ( function ( ) { goblinDB . ambush . add ( { id : 'testing-simple-function' , category : [ 'test-category' ] , action : function ( ) { } ,", "commit_type": "add"}
{"commit_tokens": ["Move", "to", "a", "new", "node", "-", "creation", "scheme", "(", "partway", "these", "should", "end", "up", "as", "schema", "methods", ")"], "add_tokens": "export { $node , $text , Node , Span , nodeTypes , NodeType , findConnection } from \"./node\"", "del_tokens": "export { Node , Span , nodeTypes , NodeType , findConnection } from \"./node\"", "commit_type": "move"}
{"commit_tokens": ["Fix", "JS", "warning", "on", "access", "to", "private", "fields", "."], "add_tokens": "var childTooltip = this . getChildTooltip ( ) ; return ! ! childTooltip && childTooltip . isCoordinateInTooltip ( coord ) ; if ( ! this . isCoordinateActive_ ( this . cursorPosition ) && ! this . getActiveElement ( ) && // they may have an active element because of a focus event. Don't let this . setActiveElement ( null ) ; var childTooltip = this . getChildTooltip ( ) ; if ( childTooltip ) { childTooltip . setActiveElement ( null ) ; this . clearHideTimer ( ) ; if ( this . getActiveElement ( ) != this . getElement ( ) ) { this . setActiveElement ( this . getElement ( ) ) ;", "del_tokens": "return ! ! this . childTooltip_ && this . childTooltip_ . isCoordinateInTooltip ( coord ) ; if ( ! this . isCoordinateActive_ ( this . cursorPosition ) && ! this . activeEl_ && // they may have an activeEl_ because of a focus event. Don't let this . activeEl_ = null ; if ( this . childTooltip_ ) { this . childTooltip_ . activeEl_ = null ; this . clearHideTimer_ ( ) ; if ( this . activeEl_ != this . getElement ( ) ) { this . activeEl_ = this . getElement ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "VersionHandler", "class", "."], "add_tokens": "'tag' : new handlers . TagHandler ( ) , 'version' : new handlers . VersionHandler ( ) case 'VersionContext' : type = 'version' ; break ;", "del_tokens": "'tag' : new handlers . TagHandler ( )", "commit_type": "add"}
{"commit_tokens": ["add", "auto", "-", "detect", "in", "r", "-", "animation"], "add_tokens": "if ( param === \"leave\" ) { destroies . push ( animationDestroy ( element ) ) ; } else if ( param === \"enter\" ) { destroies . push ( animationDestroy ( element ) ) ; if ( ( \"on\" + param ) in element ) { // if dom have the event , we use dom event console . log ( 'ahah' ) destroies . push ( this . _handleEvent ( element , param , seed . start ) ) ; } else { // otherwise, we use component event this . $on ( param , seed . start ) ; destroies . push ( this . $off . bind ( this , param , seed . start ) ) ; } Regular . directive ( \"r-sequence\" , processAnimate )", "del_tokens": "if ( param === \"leave\" ) { } else if ( param === \"enter\" ) { // destroy = this._handleEvent( element, param, seed.start ); this . $on ( param , seed . start ) destroy = this . $off . bind ( this , param , seed . start ) ; // @TODO add destroies . push ( destroy ? destroy : animationDestroy ( element ) ) ; destroy = null ;", "commit_type": "add"}
{"commit_tokens": ["Update", "rocket", "-", "chat", ".", "js"], "add_tokens": "callback ( response . statusCode + ': Unable to connect to rocket chat during room create. Room may already exist.' ) ;", "del_tokens": "callback ( response . statusCode + ': Unable to connect to rocket chat during room create.' ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "some", "new", "features", "and", "docs"], "add_tokens": "style = options . style ; notify . classList . add ( CSS_ . notification ) ; if ( style ) { notify . classList . add ( CSS_ . notification + '--' + style ) ; } if ( options . default ) { input . value = options . default ; } if ( options . inputType ) { input . type = options . inputType ;", "del_tokens": "style = options . style || 'notify' ; if ( ! message ) { return ; notify . classList . add ( CSS_ . notification ) ; notify . classList . add ( CSS_ . notification + '--' + style ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "expression", "require", "in", "index", ".", "js"], "add_tokens": "// y.expression = require('./lib/parsers/expression');", "del_tokens": "y . expression = require ( './lib/parsers/expression' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "thresholds", "for", "code", "coverage", "~", "80%"], "add_tokens": "thresholds : { emitWarning : false , // set to `true` to not fail the test command when thresholds are not met global : { // thresholds for all files statements : 80 , lines : 80 , branches : 80 , functions : 80 } , each : { // thresholds per file statements : 80 , lines : 80 , branches : 80 , functions : 80 , overrides : { 'baz/component/**/*.js' : { statements : 80 } } } } , reports : [ 'text-summary' ] ,", "del_tokens": "reports : [ 'text-summary' ] ,", "commit_type": "add"}
{"commit_tokens": ["Changed", "function", "declaration", "so", "this", "will", "bind", "to", "the", "SessionStore", "object", "."], "add_tokens": "SessionStore . prototype . clear = function ( sessionId ) {", "del_tokens": "SessionStore . prototype . clear = ( sessionId ) => {", "commit_type": "change"}
{"commit_tokens": ["Added", "an", "option", "to", "set", "the", "filename", "prepend"], "add_tokens": "return str . replace ( / < / g , \"&lt;\" ) . replace ( / \\' / g , \"&apos;\" ) . replace ( / \\& / g , \"&amp;\" ) ; * @ param { string } filePrefix is the string value that is prepended to the * xml output file ; default : 'TEST-' var JUnitXmlReporter = function ( savePath , consolidate , useDotNotation , filePrefix ) { this . filePrefix = filePrefix || 'TEST-' ; var fileName = this . filePrefix + this . getFullName ( suite , true ) + '.xml' ;", "del_tokens": "return str . replace ( / \\& / g , \"&amp;\" ) . replace ( / < / g , \"&lt;\" ) . replace ( / \\' / g , \"&apos;\" ) ; var JUnitXmlReporter = function ( savePath , consolidate , useDotNotation ) { var fileName = this . getFullName ( suite , true ) + '.xml' ; // replace empty name with 'test' fullName = fullName . replace ( / ^$ / , \"test\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "timestamp", "from", "the", "console", "log", "since", "we", "can", "depend", "on", "logcat", "timestamp"], "add_tokens": "return options . level . toUpperCase ( ) + ' ' + options . meta . tag + ' ' + ( undefined !== options . message ? options . message : '' ) ; }", "del_tokens": "timestamp : function ( ) { return Date . now ( ) ; } , return options . timestamp ( ) + ' ' + options . level . toUpperCase ( ) + ' ' + options . meta . tag + ' =>' + ( undefined !== options . message ? options . message : '' ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "incorrect", "hex", "string", "checking", "logic"], "add_tokens": "const HEX_FORMAT_CHECKER = / ^0x[0-9a-fA-F]+$ / ; if ( hexString . substring ( 0 , 2 ) !== \"0x\" ) { hexString = \"0x\" + hexString ; }", "del_tokens": "const HEX_FORMAT_CHECKER = / ^0x[0-9a-fA-F]+$ / g ;", "commit_type": "fix"}
{"commit_tokens": ["make", "the", "default", "User", "-", "Agent", "string", "contain", "node", "-", "spotify", "-", "web"], "add_tokens": "this . userAgent = 'node-spotify-web (Chrome/13.37 compatible-ish)' ;", "del_tokens": "this . userAgent = 'spotify-websocket-api (Chrome/13.37 compatible-ish)' ;", "commit_type": "make"}
{"commit_tokens": ["Use", "gulp", "-", "uglify", "instead", "of", "gulp", "-", "uglifyjs"], "add_tokens": "var uglify = require ( 'gulp-uglify' ) ; preserveComments : 'some'", "del_tokens": "var uglify = require ( 'gulp-uglifyjs' ) ; output : { comments : / ^! / }", "commit_type": "use"}
{"commit_tokens": ["Add", "initial", "sn", "install", "command"], "add_tokens": "module . exports = function ( done ) { return function ( ) { console . log ( { versions : process . versions , platform : process . platform , config : process . config , execPath : process . execPath , features : process . features } ) ; done ( ) ; }", "del_tokens": "module . exports = function ( ) { console . log ( { versions : process . versions , platform : process . platform , config : process . config , execPath : process . execPath , features : process . features } ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "log", "messages", "and", "no", "version"], "add_tokens": "console . log ( \"Extracting DEFINES from Libsodium make file...\" ) ; console . log ( \"Detected system architecture \" + os . arch ( ) ) ; var libsodium_dir = \"./deps/libsodium\" ; console . log ( \"Libsodium Makefile : \" + libsodium_dir + \"/Makefile\" ) ; console . log ( \"Libsodium GYP template file \" + \"deps/libsodium.gyp.in\" ) ; console . log ( \"Writing output to GYP file deps/libsodium.gyp\" ) ;", "del_tokens": "console . log ( os . arch ( ) ) ; var version = \"1.0.2\" ; var libsodium_dir = \"./deps/libsodium-\" + version ; / *var defines = defs[1].match( / - D ( [ ^ \\s ] + ) / g ) ; var d = \"\" ; defines . forEach ( function ( element ) { d += \"\\t\\t\\t\\t'\" + element + \"',\\n\" ; } ) ; * / result = result . replace ( / {VERSION} / g , \"'\" + version + \"'\" ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "timer", "to", "compile", "command"], "add_tokens": "var start_time = new Date ( ) . getTime ( ) ; var duration = new Date ( ) . getTime ( ) - start_time ; logger . end ( opt . output + ' (' + duration + 'ms)' ) ;", "del_tokens": "logger . end ( opt . output ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "visitor", "logging", "for", "now"], "add_tokens": "//var isRobot = funnelweb; // better name for lib used to detect robots //var headers = req.headers || {}; //var userAgent = headers['user-agent'] || ''; //setTimeout(function () { // if (isRobot(userAgent)) { return; } // robots are not tracked as visitors // // visitorService.create({ // caller: visitorService.admin, // data: { _id: id } // ips: [ req.info.remoteAddress ], headers: req.headers // }) // .then(function (data) { // log.debug('Visitor info saved for ' + data._id, null); // }) // .catch(function (err) { // log.error(err, null); // }); //}, 1);", "del_tokens": "var isRobot = funnelweb ; // better name for lib used to detect robots var headers = req . headers || { } ; var userAgent = headers [ 'user-agent' ] || '' ; setTimeout ( function ( ) { if ( isRobot ( userAgent ) ) { return ; } // robots are not tracked as visitors visitorService . create ( { caller : visitorService . admin , data : { _id : id } // ips: [ req.info.remoteAddress ], headers: req.headers } ) . then ( function ( data ) { log . debug ( 'Visitor info saved for ' + data . _id , null ) ; } ) . catch ( function ( err ) { log . error ( err , null ) ; } ) ; } , 1 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "public", "path", "with", "entrypoints"], "add_tokens": "const getAssetOrFilename = file => { const asset = this . options . entrypointsUseAssets ? this . assets [ findAssetKeys ( file ) . pop ( ) ] || this . assets [ file ] : undefined ; return asset ? asset : this . getPublicPath ( file ) ; } ;", "del_tokens": "const getAssetOrFilename = this . options . entrypointsUseAssets ? file => this . assets [ findAssetKeys ( file ) . pop ( ) ] || this . assets [ file ] || file : undefined ;", "commit_type": "use"}
{"commit_tokens": ["Change", "non", "-", "numeric", "status", "code", "to", "500"], "add_tokens": "if ( typeof status !== 'number' || status < 400 || status > 599 ) {", "del_tokens": "if ( ! status || status < 400 || status > 599 ) {", "commit_type": "change"}
{"commit_tokens": ["Remove", "hover", "delay", "when", "clicking", "or", "double", "-", "clicking"], "add_tokens": "this . calculateMouseOver ( true ) ; calculateMouseOver ( immediate ) { if ( ! immediate && userData . object && ! ( this . currentGraph && this . currentGraph . highlightedObject ) ) {", "del_tokens": "this . calculateMouseOver ( ) ; calculateMouseOver ( ) { if ( userData . object && ! ( this . currentGraph && this . currentGraph . highlightedObject ) ) {", "commit_type": "remove"}
{"commit_tokens": ["added", "event", "to", "onload", "-", "cb"], "add_tokens": "if ( CTX . opt . onload ) CTX . opt . onload ( event )", "del_tokens": "if ( CTX . opt . onload ) CTX . opt . onload ( )", "commit_type": "add"}
{"commit_tokens": ["updating", "comment", "to", "be", "more", "clear"], "add_tokens": "* the { { # crossLink \"F2.AppConfig\" } } { { / crossLink}} object, but later * modified by calling * F2 . UI . { { # crossLink \"F2.UI/updateHeight\" } } { { / crossLink}}. This is used * for secure apps to be able to set the initial height of the iframe .", "del_tokens": "* the { { # crossLink \"F2.AppConfig\" } } { { / crossLink}} object, but later modified by * firing an * { { # crossLink \"F2.Constants.Events\" } } { { / crossLink}}.APP_HEIGHT_CHANGE * event .", "commit_type": "update"}
{"commit_tokens": ["Implement", "an", "unwrapper", "function", "for", "the", "C", "functions", "so", "those", "work", "now", "too", "."], "add_tokens": "// TODO: Handle 'variadic' arg functions (NSLog), will require // a \"function generator\" to get a Function from the passed // in args (and guess at the types that were passed in...) var f = core . Function ( curName , types . map ( curRtnType ) , curArgTypes . map ( types . map ) , false , isInline ? fw . inline : fw . lib ) ; // The unwrapper function unwraps passed in arguments, // and wraps up the result if necessary. function unwrapper ( ) { var args = core . unwrapValues ( arguments , curArgTypes ) , rtn = f . apply ( null , args ) return core . wrapValue ( rtn , curRtnType ) } // attach the rtn and arg types to the result Function, nice in the REPL unwrapper . func = curName ; unwrapper . rtn = curRtnType ; unwrapper . args = curArgTypes ; return _global [ curName ] = unwrapper ;", "del_tokens": "var f = core . Function ( curName , curRtnType , curArgTypes , false , isInline ? fw . inline : fw . lib ) ; return _global [ curName ] = f ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "note", ".", "value", "and", "note", ".", "fromValue"], "add_tokens": "return n . value ( ) ;", "del_tokens": "var value = n . clean ( ) . octave * 12 ; return value + note . create ( 'C' ) . getHalfSteps ( n ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "use", "of", "browserified", "node", "core", "modules"], "add_tokens": "// Skip node_modules directories if ( ! dir . match ( / node_modules / ) ) { walk ( file ) ; }", "del_tokens": "walk ( file ) ;", "commit_type": "allow"}
{"commit_tokens": ["removed", "some", "code", "that", "has", "become", "unnecessary"], "add_tokens": "var ancestry , assignee , compile , expression , protoMember ; protoMember = new CS . MemberAccessOp ( new CS . MemberAccessOp ( new CS . This , 'prototype' ) , this . assignee . data ) ;", "del_tokens": "var a , ancestry , assignee , compile , expression , parentClass , protoMember , _i , _len ; parentClass = null ; for ( _i = 0 , _len = ancestry . length ; _i < _len ; _i ++ ) { a = ancestry [ _i ] ; if ( a [ \"instanceof\" ] ( CS . Class ) ) { parentClass = a ; break ; } if ( ! a [ \"instanceof\" ] ( CS . SeqOp , CS . Block ) ) { throw new Error ( \"ClassProtoAssignOp must be within a Class, not \" + a . className ) ; } } if ( parentClass == null ) { throw new Error ( \"ClassProtoAssignOp must be within a Class\" ) ; } protoMember = new CS . MemberAccessOp ( new CS . MemberAccessOp ( parentClass . name , 'prototype' ) , this . assignee . data ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "authentication", "for", "some", "resources", "as", "an", "example"], "add_tokens": "var middleware = require ( './lib/middleware' ) ; var users = require ( './lib/users' ) ; server . use ( middleware . authorizationHandler ( server ) )", "del_tokens": "var users = require ( './lib/users' ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "access", "of", "methods", "to", "use", "jQuery", ".", "sub", "()"], "add_tokens": "$ ( '#jcarousel1' ) . jcarousel ( ) . destroy ( ) ; equal ( $ ( '#jcarousel1' ) . jcarousel ( ) . items ( ) . get ( 1 ) , $ ( '#jcarousel1 li:eq(1)' ) . get ( 0 ) , '#jcarousel1' ) ;", "del_tokens": "$ ( '#jcarousel1' ) . jcarousel ( 'destroy' ) ; equal ( $ ( '#jcarousel1' ) . jcarousel ( 'items' ) . get ( 1 ) , $ ( '#jcarousel1 li:eq(1)' ) . get ( 0 ) , '#jcarousel1' ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "small", "syntax", "change", "to", "appease", "jshint", "."], "add_tokens": "} ) ; if ( dep . main . length === 0 && testExclude === undefined ) {", "del_tokens": "} ) if ( dep . main . length === 0 && testExclude == undefined ) {", "commit_type": "add"}
{"commit_tokens": ["Allow", "one", "to", "customize", "serialized", "attributes", "key", "case"], "add_tokens": "getAttributesSerializedCaseSetting : function ( ) { var caseSetting = undefined ; if ( sails . config . jsonapi !== undefined ) { caseSetting = sails . config . jsonapi . attributesSerializedCase ; } return caseSetting ; } , convertCase : this . getAttributesSerializedCaseSetting ( ) ,", "del_tokens": "convertCase : 'kebab-case' ,", "commit_type": "allow"}
{"commit_tokens": ["Fix", "issue", "with", "documentation", "generation", "under", "Returns", "header"], "add_tokens": "output += '`' + retType . types . join ( ', ' ) . replace ( / ` / g , \"'\" ) + '`: ' + retType . description ;", "del_tokens": "output += 'Returns <' + DocComment . printableTypeList ( retType ) + '> ' + retType . description ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "property", "initialization", "when", "linked", "to", "a", "valuated", "attribute"], "add_tokens": "// Apply initial values to properties. // Skip only properties having an attribute's value set. return ! el . hasAttribute ( property . attName ) ; } ) ; // Apply attributes' values to properties. builder . wrap ( 'createdCallback' , function ( next , el ) { next ( arguments ) ; // Keep only properties having an attribute's value set. return el . hasAttribute ( property . attName ) ; el [ property . propName ] = property . attribute . boolean ? true : el . getAttribute ( property . attName ) ; } , Number . MAX_VALUE ) ;", "del_tokens": "// Wrap the method createdCallback. // Initialize the properties' value after the call of the createdCallback method. return ! property . attName ; return property . attName ; if ( el . hasAttribute ( property . attName ) ) { el [ property . propName ] = property . attribute . boolean ? true : el . getAttribute ( property . attName ) ; } else if ( property . hasOwnProperty ( 'value' ) ) { applyAttributeValue ( el , property . attName , property . value , property . attribute . boolean ) ; } } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "width", "=", "device", "-", "width", "to", "meta", "viewport", "for", "RWD"], "add_tokens": "dom ( 'meta name=viewport content=\"width=device-width,initial-scale=1.0,minimum-scale=1.0,user-scalable=no\"' ) ,", "del_tokens": "dom ( 'meta name=viewport content=\"initial-scale=1.0,user-scalable=no\"' ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "n", "-", "body", "force", "calculation"], "add_tokens": "var createQuadTree = require ( 'ngraph.quadtreebh' ) ; springs = [ ] , // Springs in this simulation. quadTree = createQuadTree ( ) ; / ** * Array of bodies , registered with current simulator * * Note : To add new body , use addBody ( ) method . This property is only * exposed for testing / performance purposes . * / bodies : bodies , * @ returns { Number } Total movement of the system . Calculated as : * ( total distance traveled by bodies ) ^ 2 / ( total # of bodies ) // I'm reluctant to check timeStep here, since this method is going to be // super hot, I don't want to add more complexity to it if ( bodies . length ) { accumulateForces ( ) ; return integrate ( bodies , timeStep ) ; } return 0 ; quadTree . insertBodies ( bodies ) ; // performance: O(n * log n) // Accumulate forces acting on bodies. var body , i = bodies . length ; while ( i -- ) { body = bodies [ i ] ; body . force . x = 0 ; body . force . y = 0 ; quadTree . updateBodyForce ( body ) ; // todo: drag force } // todo: springs", "del_tokens": "springs = [ ] ; // Springs in this simulation. * @ returns { Number } total distance traveled by bodies / total # of bodies accumulateForces ( ) ; return integrate ( bodies , timeStep ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "authCache", "logic", "auto", "-", "retry", "any", "command", "once", "if", "authCode", "is", "invalid"], "add_tokens": "this . config = _ . extend ( { } , config || { } ) // Recast the error with the `SoapError` to extract error data from the // XML response, then check if this is an authentication issue var custom = new Errors . SoapError ( err ) if ( custom . code === 'INVALID_AUTH_CODE' ) { custom = new Errors . AuthenticationError ( err . originalError ) } return rej ( custom ) // Check for invalid `authCode`, this seems to happen at random intervals // within the neulion API, so we will only know when a request fails . catch ( Errors . AuthenticationError , function ( err ) { // Authenticate and then try one more time return self . auth ( ) . then ( function ( ) { return new Promise ( handler ) } ) } ) debug ( '[exec] no `authCode` found, auto-authenticating' )", "del_tokens": "* - ` ` { Number } authCode TTL , default 1 hour this . config = _ . extend ( { authCache : HOUR } , config || { } ) , now = Date . now ( ) , authCache = this . config . authCache return rej ( new Neulion . SoapError ( err ) ) return this . auth ( ) . then ( go ) } // Check if the current authentication has expired if ( now - this . authTime > authCache ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "shadows", "and", "flex", "generators", "extract", "defineClass", "(", "es", ")"], "add_tokens": "const defineClass = require ( '../util/define-class' ) return defineClass ( ` ${ className } ` , { backgroundColor : findColor ( colors , colorName ) ,", "del_tokens": "const postcss = require ( 'postcss' ) const kebabClass = _ . kebabCase ( className ) return postcss . rule ( { selector : ` ${ kebabClass } ` } ) . append ( { prop : 'background-color' , value : findColor ( colors , colorName )", "commit_type": "add"}
{"commit_tokens": ["Remove", "warnin", "when", "compiling", "in", "simple", "mode", "with", "google", "closure", "compiler"], "add_tokens": "while ( new Date ( ) . getTime ( ) < dt . getTime ( ) ) { } ;", "del_tokens": "while ( new Date ( ) . getTime ( ) < dt . getTime ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "item", "key", "to", "locks"], "add_tokens": "* l1 . then ( function ( l ) { * // l.key contains the key of the locked_item * l ( ) ; / release the lock var lock = function ( ) { } ; lock . key = key ; resolve ( lock ) ;", "del_tokens": "* l1 . then ( function ( free ) { * free ( ) ; / release the lock resolve ( function ( ) { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "noImplicitAny", "to", "Typescript", "options"], "add_tokens": "experimentalDecorators : true , noImplicitAny : true experimentalDecorators : true , noImplicitAny : true", "del_tokens": "experimentalDecorators : true experimentalDecorators : true", "commit_type": "add"}
{"commit_tokens": ["making", "queue", "pass", "on", "a", "shared", "object", "&&", "still", "async", "problems"], "add_tokens": "import { Queue } from './queue' ; let queue = Queue ( [ ] ) ; queue . add ( ( elemLengths ) => applyChanges ( index , changes , parentElem , elemLengths ) ) ; queue . add ( ( elemLengths ) => applyChanges ( index , changes , parentElem , elemLengths ) ) ;", "del_tokens": "let elemLengths = [ ] ; elemLengths = applyChanges ( index , changes , parentElem , elemLengths ) ; elemLengths = applyChanges ( index , changes , parentElem , elemLengths ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "encoding", "parameter", "to", "#decode", "()"], "add_tokens": "* @ param { String } encoding function decode ( data , encoding ) { return new decode ( data , encoding ) this . encoding = encoding || null this . data = data default : return this . bytes ( ) return this . encoding ? bytes . toString ( this . encoding )", "del_tokens": "* @ param { Boolean } toString function decode ( data , toString ) { return new decode ( data , toString ) this . stringify = ! ! toString this . data = data default : return this . bytes ( ) return this . stringify ? bytes . toString ( )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "Travis", "grunt", "tests", "and", "demo", "page", "(", "because", "of", "module", "updates", ")", "."], "add_tokens": "'bower_components/jquery-ui/ui/jquery-ui.js' ,", "del_tokens": "'bower_components/jquery-ui/ui/jquery-ui.custom.js' ,", "commit_type": "fix"}
{"commit_tokens": ["added", "no", "-", "a11y", "-", "test", "class", "fixed", "return", "code", "of", "a11y", "test"], "add_tokens": "hideElements : '.sr-only, .is-visuallyhidden, .visuallyhidden, .no-a11y-test' ,", "del_tokens": "hideElements : '.skip-to, .is-visuallyhidden, .visuallyhidden' ,", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "JS", "requires", "exported", "as", "globals"], "add_tokens": "shadow . js . require = function ( name , opts ) { if ( opts ) { var globals = opts [ \"globals\" ] ; if ( globals ) { for ( var i = 0 ; i < globals . length ; i ++ ) { window [ globals [ i ] ] = exports ; } } }", "del_tokens": "shadow . js . require = function ( name ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "proxy", "environment", "variable", "handling", "to", "bag", ".", "http", ".", "requuest", "and", "bag", ".", "http", ".", "proxy", "."], "add_tokens": "function Jenkins ( url ) { url : url , qs : { start : parseInt ( result . headers [ 'x-text-size' ] , 10 ) } } , envProxy = bag . http . proxy ( url ) ; if ( envProxy ) { params . proxy = envProxy ;", "del_tokens": "* @ param { Object } opts : optional * - proxy : proxy server URL in format http : //user:pass@host:port function Jenkins ( url , opts ) { opts = opts || { } ; proxy : opts . proxy || process . env . http_proxy , url : url , qs : { start : parseInt ( result . headers [ 'x-text-size' ] , 10 ) } } ; if ( self . opts . proxy ) { params . proxy = self . opts . proxy ;", "commit_type": "move"}
{"commit_tokens": ["use", "trackBy", "instead", "getLabel", "for", "duplicate", "searching"], "add_tokens": "if ( oiUtils . intersection ( scope . output , [ option ] , null , trackBy , trackBy ) . length ) return ;", "del_tokens": "if ( oiUtils . intersection ( scope . output , [ option ] , null , getLabel , getLabel ) . length ) return ;", "commit_type": "use"}
{"commit_tokens": ["Removing", "the", "placeholder", "from", "the", "Angular", "URL", "after", "extra", "modules", "are", "loaded", "."], "add_tokens": "if ( window . location . hash . match ( / _WAITFORMODULES$ / ) ) { // Need to remove the extra URL bit, otherwise angular will route back window . location . hash = window . location . hash . replace ( '_WAITFORMODULES' , '' ) ; return continueBootstrap ( ) ;", "del_tokens": "if ( document . baseURI . match ( / _WAITFORMODULES$ / ) ) { // TODO(julie): Need to remove the extra URL bit, otherwise angular will route back // Can I just push the array? I think the injector takes arrays of modules. else { return continueBootstrap ( ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Remove", "test", "case", "for", "custom", "message", "as", "they", "are", "not", "supported"], "add_tokens": "it ( 'should fail using `not` and `deep` given an inexisting property' , function ( ) { expect ( obj ) . not . to . have . deep . property ( [ 'y' , 'x' ] , 2 ) ;", "del_tokens": "it ( 'not - should fail for missing deep property' , function ( ) { var obj = Immutable . fromJS ( { x : 1 } ) ; fail ( function ( ) { expect ( obj ) . not . to . have . deep . property ( [ 'y' , 'x' ] , 'different' , 'message' ) ; } ) ; } ) ; it ( 'not - should fail for deep property, no message' , function ( ) { expect ( obj ) . not . to . have . deep . property ( [ 'y' , 'x' ] , 2 , 'message' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Making", "tests", "work", "on", "<", "=", "IE8", "(", "which", "does", "not", "have", ".", "trim", "()", ")"], "add_tokens": "if ( t . trim ) return t . trim ( ) else return t", "del_tokens": "return t . trim ( )", "commit_type": "make"}
{"commit_tokens": ["Added", "comments", "for", "transition", ".", "js"], "add_tokens": "'test/temp.js' , 'test/deepStateRedirectSpec.js' , 'test/futureStateSpec.js' , 'test/stickyStateSpec.js' , 'test/previousStateSpec.js' , 'src/fsfactories/ngload.js' , 'src/fsfactories/iframe.js' ,", "del_tokens": "// 'test/temp.js', // 'test/deepStateRedirectSpec.js', // 'test/futureStateSpec.js', // 'test/stickyStateSpec.js', // 'test/previousStateSpec.js', // 'src/fsfactories/ngload.js', // 'src/fsfactories/iframe.js',", "commit_type": "add"}
{"commit_tokens": ["fixes", "the", "case", "where", "some", "scc", "files", "have", "different", "newlines"], "add_tokens": "if ( / \\r\\n / . test ( data . toString ( ) ) ) { lines = data . toString ( ) . split ( '\\r\\n' ) ; } else { lines = data . toString ( ) . split ( '\\n' ) ; }", "del_tokens": "lines = data . toString ( ) . split ( '\\r\\n' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "tests", "to", "truly", "go", "off", "the", "toString", "method", "and", "fixed", "resulting", "failures"], "add_tokens": "return this . messageWithDetails + '\\nStack:' ; PluginError . prototype . __defineGetter__ ( 'messageWithDetails' , function ( ) { var details = this . messageDetails ; if ( details === '' ) { return 'Message:\\t ' + this . message ; } return 'Message:\\t ' + this . message + '\\n' + details ; } ) ; return 'Details:' + res ; return '' ; msg = this . messageWithDetails + '\\n' + this . _stack ; msg = this . messageWithDetails + '\\n' + this . stack ;", "del_tokens": "return this . messageDetails + '\\nStack:' ; debugger ; return 'Message:\\n ' + this . message + '\\nDetails:' + res ; return 'Message:\\n ' + this . message ; msg = this . _stack ; msg = this . stack ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "nested", "environment", "variables", "mapping"], "add_tokens": "forOwnDeep ( value , callback , prefix + key ) ;", "del_tokens": "forOwnDeep ( value , callback , prefix ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "variable", ";", "lower", "limit", "from", "half", "-", "gig", "to", "50mb"], "add_tokens": "var defaultLimit = '50mb' ; someapp . use ( bodyParser . urlencoded ( { extended : true , limit : defaultLimit } ) ) ; someapp . use ( bodyParser . json ( { type : 'application/*+json' , limit : defaultLimit } ) ) ; someapp . use ( bodyParser . json ( { type : 'application/json' , limit : defaultLimit } ) ) ; someapp . use ( bodyParser . text ( { type : 'text/plain' , limit : defaultLimit } ) ) ; someapp . use ( bodyParser . raw ( { limit : defaultLimit } ) ) ;", "del_tokens": "someapp . use ( bodyParser . urlencoded ( { extended : true , limit : '512mb' } ) ) ; someapp . use ( bodyParser . json ( { type : 'application/*+json' , limit : '512mb' } ) ) ; someapp . use ( bodyParser . json ( { type : 'application/json' , limit : '512mb' } ) ) ; someapp . use ( bodyParser . text ( { type : 'text/plain' , limit : '512mb' } ) ) ; someapp . use ( bodyParser . raw ( { limit : '512mb' } ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "method", "submit", "and", "focus", "on", "Input", "and", "Form"], "add_tokens": "submit : function ( ) { this . refs . form . submit ( ) ; } , < form ref = \"form\" { ... this . props } >", "del_tokens": "< form { ... this . props } >", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "lang", "translator", "bug"], "add_tokens": "await i18n . changeLanguage ( initialLanguage )", "del_tokens": "i18n . language = initialLanguage", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "bsd", "-", "tar"], "add_tokens": "var childProcessExec = require ( 'child_process' ) . exec ; if ( ! options . zip_deploy ) return callback ( ) ; childProcessExec ( 'tar --version' , function ( error , stdout , stderr ) { if ( ! error ) { var isGnuTar = stdout . match ( / GNU tar / ) ; var command ; if ( isGnuTar ) { command = \"tar -czvf ./deploy.tgz --ignore-failed-read --directory=\" + options . local_path + \" . --exclude=deploy.tgz\" ; } else { command = \"tar -czvf ./deploy.tgz --directory=\" + options . local_path + \" .\" ; } grunt . log . subhead ( '--------------- ZIPPING FOLDER' ) ; grunt . log . subhead ( '--- ' + command ) ; execLocal ( command , callback ) ; } } ) ;", "del_tokens": "var childProcessExec = require ( 'child_process' ) . exec ; if ( ! options . zip_deploy ) return callback ( ) ; var command = \"tar -czvf ./deploy.tgz --ignore-failed-read --directory=\" + options . local_path + \" . --exclude=deploy.tgz\" ; grunt . log . subhead ( '--------------- ZIPPING FOLDER' ) ; grunt . log . subhead ( '--- ' + command ) ; execLocal ( command , callback ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "symbol", "as", "validation", "type"], "add_tokens": "function : Function , symbol : Symbol", "del_tokens": "function : Function", "commit_type": "add"}
{"commit_tokens": ["Added", "TinyMCE", "and", "enhanced", "scrollfix"], "add_tokens": "var top = elm . offset ( ) . top , original = '' ; attrs . uiScrollfix = top ; } else { original = attrs . uiScrollfix ; if ( attrs . uiScrollfix . indexOf ( '-' ) === 0 ) { attrs . uiScrollfix = top - attrs . uiScrollfix . substr ( 1 ) ; } else if ( attrs . uiScrollfix . indexOf ( '+' ) === 0 ) { attrs . uiScrollfix = top + parseInt ( attrs . uiScrollfix . substr ( 1 ) ) ; } $ ( window ) . unbind ( 'scroll.ui-scrollfix' + original ) . bind ( 'scroll.ui-scrollfix' + original , function ( ) {", "del_tokens": "attrs . uiScrollfix = elm . offset ( ) . top ; $ ( window ) . scroll ( function ( ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "system", "-", "npm", "work", "in", "a", "web", "worker"], "add_tokens": "if ( pkg . browser ) { * * * * var g = loader . global ;", "del_tokens": "if ( pkg . browser ) { * * * * var g ; if ( typeof window !== \"undefined\" ) { g = window ; } else { g = global ; }", "commit_type": "make"}
{"commit_tokens": ["Add", "jack#extend", "method", "and", "fix", "tests", "."], "add_tokens": "* Creates a mock . var mock = function ( method ) { * @ param { String } Method name . var spy = function ( method ) { / ** * Extends the Object . Thanks @ rstankov ! * * @ param { Object | Function } The object that will be extended . * @ returns { Object } ` ` . * @ api public * / jack . extend = function ( obj ) { if ( typeof obj === 'object' ) { obj . spy = spy ; obj . mock = obj . stub = mock ; } else { obj . prototype . spy = spy ; obj . prototype . mock = obj . prototype . stub = mock ; } } ; // Extend the Object. jack . extend ( Object ) ;", "del_tokens": "* Stubs an object method . * @ api public Object . prototype . mock = Object . prototype . stub = function ( method ) { * @ api public Object . prototype . spy = function ( method ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "warning", "about", "strip", ".", "stripLength", "()"], "add_tokens": "if ( ++ pos >= strip . length ) {", "del_tokens": "if ( ++ pos >= strip . stripLength ( ) ) {", "commit_type": "remove"}
{"commit_tokens": ["make", "travis", "run", "lerna", "bootstrap"], "add_tokens": "const promisify = require ( 'util.promisify' )", "del_tokens": "const { promisify } = require ( 'util' )", "commit_type": "make"}
{"commit_tokens": ["Fix", "binary", "string", "issue", "in", "Large", "event", "tests"], "add_tokens": "const largeData = Buffer . alloc ( 3 * 1024 * 1024 , \" \" ) ;", "del_tokens": "const largeData = Buffer . alloc ( 3 * 1024 * 1024 , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "link", "to", "better", "visualizing", "tool"], "add_tokens": "// Tip: use https://jex.im/regulex/ to visualize the regex", "del_tokens": "// Tip: use https://www.debuggex.com/ to visualize the regex", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "mixed", "plain", "color", "string", "and", "color", "map", "background", "defintitions"], "add_tokens": "backgroundColors = _ ( backgroundColors ) . flatMap ( color => { if ( _ . isString ( color ) ) { return [ [ color , color ] ] } return _ . toPairs ( color ) } ) . fromPairs ( )", "del_tokens": "backgroundColors = _ ( backgroundColors ) . map ( color => [ color , color ] ) . fromPairs ( )", "commit_type": "add"}
{"commit_tokens": ["add", "stop", "method", "to", "swsProcessor", "and", "swsInterface"], "add_tokens": "this . timer = setInterval ( this . tick , 200 , this ) ; } ; // Stop swsProcessor . prototype . stop = function ( ) { clearInterval ( this . timer ) ;", "del_tokens": "setInterval ( this . tick , 200 , this ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "login", "/", "logout", "state"], "add_tokens": "$requestBody = document . getElementById ( 'request-body' ) , $authStatus = document . getElementById ( 'auth-status' ) ; document . getElementById ( 'login-btn' ) . addEventListener ( 'click' , function ( ) { client . oauthRedirect ( ) ; } ) ; document . getElementById ( 'logout-btn' ) . addEventListener ( 'click' , function ( ) { client . deleteAccessToken ( ) ; window . location . reload ( ) ; } ) ; if ( response . statusCode === 401 ) { $authStatus . classList . remove ( 'loggedin' ) ; } else { $authStatus . classList . add ( 'loggedin' ) ; }", "del_tokens": "$requestBody = document . getElementById ( 'request-body' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "optional", "suggestionKey", "attribute", "to", "directive"], "add_tokens": "datasets : '=' , // The typeahead datasets to use (https://github.com/twitter/typeahead.js/blob/master/doc/jquery_typeahead.md#datasets) suggestionKey : '@' var newViewValue = ( angular . isDefined ( scope . suggestionKey ) ) ? suggestion [ scope . suggestionKey ] : suggestion ; ngModel . $setViewValue ( newViewValue ) ;", "del_tokens": "datasets : '=' // The typeahead datasets to use (https://github.com/twitter/typeahead.js/blob/master/doc/jquery_typeahead.md#datasets) ngModel . $setViewValue ( suggestion ) ;", "commit_type": "add"}
{"commit_tokens": ["updating", "tests", "to", "include", "escaped", "querystring", "values"], "add_tokens": "var querystring = require ( 'querystring' ) ; 'gith creates a server and listens to unescaped payloads on that port' : function ( test ) { } , 'gith creates a server and listens to escaped payloads on that port' : function ( test ) { test . expect ( 1 ) ; var gith = githFactory . create ( 9001 ) ; var payloadObject = require ( './payloads/add-file-and-dir.json' ) ; var failSafe = false ; gith ( ) . on ( 'all' , function ( payload ) { failSafe = true ; test . equal ( payload . original . after , payloadObject . after , \"payload data should equal sent payload data\" ) ; gith . close ( ) ; test . done ( ) ; } ) ; // just incase setTimeout ( function ( ) { if ( ! failSafe ) { gith . close ( ) ; test . ok ( false , 'payload event never fired after 200ms, shutting down server' ) ; test . done ( ) ; } } , 200 ) ; var request = http . request ( { port : 9001 , host : 'localhost' , method : 'POST' } ) ; request . write ( 'payload=' + querystring . escape ( JSON . stringify ( payloadObject ) ) ) ; request . end ( ) ;", "del_tokens": "'gith creates a server and listens to payloads on that port' : function ( test ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "yepnope", "includes", "file", ".", "Updated", "examples", ".", "js", "for", "yepnope", "compatibility", ".", "Transitioned", "basic", ".", "html", "to", "yepnope", "."], "add_tokens": "( function ( ) { } ) ( ) ;", "del_tokens": "document . observe ( 'dom:loaded' , function ( ) { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "binding", "to", "keypress", "event"], "add_tokens": "* it is responsible for listening in on keyup / keydown / keypress events document - wide , and if a if ( bindingName === 'keyup' || bindingName === 'keydown' || bindingName === 'keypress' ) {", "del_tokens": "* it is responsible for listening in on keyup / keydown events document - wide , and if a if ( bindingName === 'keyup' || bindingName === 'keydown' ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "wrapper", "property", "(", "for", "custom", "tooltip", ")"], "add_tokens": "wrapper : PropTypes . func , // It would be possible to store formatters for each `date_time_format` separately // but I'll just assume that you're using a single one application-wide. // If that's not the case then a Pull Request with a fix can be submitted. const { time , date , tooltip , wrapper , style , className } = this . props const full_date = this . full_date ( time || date ) title = { wrapper ? undefined : full_date } if ( wrapper ) { return React . createElement ( wrapper , { verbose : full_date } , markup ) }", "del_tokens": "const { time , date , tooltip , style , className } = this . props title = { this . full_date ( time || date ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "callbacks", "to", "the", "Media", "class", "for", "success", "and", "failure", "of", "playing", "a", "media", "file"], "add_tokens": "PhoneGap . exec ( \"Sound.play\" , this . src , this . successCallback , this . errorCallback ) ;", "del_tokens": "PhoneGap . exec ( \"Sound.play\" , this . src ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "double", "line", "breaks", "in", "output"], "add_tokens": "content = contents . join ( '\\n' ) ; content = \"\" + ( fs . readFileSync ( path . join ( __dirname , this . REQUIRE ) , 'utf8' ) ) + \"\\n\" + content ;", "del_tokens": "content = contents . join ( '\\n\\n' ) ; content = \"\" + ( fs . readFileSync ( path . join ( __dirname , this . REQUIRE ) , 'utf8' ) ) + \"\\n\\n\" + content ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "hoverbox", "bug", "on", "safari"], "add_tokens": "position : absolute ;", "del_tokens": "position : fixed ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "close", "event", "in", "firefox"], "add_tokens": "this . destroyed = true this . ready = false this . _channel . onopen = null this . _channel . onclose = null this . _pc = null this . _channel = null this . _channel . onclose = this . _onChannelClose . bind ( this ) if ( iceConnectionState === 'disconnected' || iceConnectionState === 'closed' ) Peer . prototype . _onChannelClose = function ( ) { this . _channelReady = false this . destroy ( ) }", "del_tokens": "this . _pc = null this . _channel = null this . destroyed = true this . ready = false if ( iceConnectionState === 'disconnected' )", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "error", "handling", "middlewares"], "add_tokens": "// normal (req, res) middleware if ( this . length === 2 ) { return function ( req , res , next ) { return fn . call ( this , req , res , function ( err , result ) { if ( err ) return next ( err ) ; if ( result !== true ) next ( ) ; } ) ; } } // error handling (err, req, res) middleware else if ( this . length === 3 ) { return function ( err , req , res , next ) { return fn . call ( this , err , req , res , function ( err , result ) { if ( err ) return next ( err ) ; if ( result !== true ) next ( ) ; } ) ; }", "del_tokens": "return function ( req , res , next ) { return fn . call ( this , req , res , function ( err , result ) { if ( err ) return next ( err ) ; if ( result !== true ) next ( ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "getCanvasSize", "bug", "and", "data", "opt", "format"], "add_tokens": "var strokes = [ ] ; var undos = [ ] ; if ( opts . data ) { opts . aspectRatio = opts . data . aspectRatio ; strokes = opts . data . strokes ; } this . getCanvasSize = getCanvasSize ; if ( strokes ) { redraw ( ) ; }", "del_tokens": "opts . data = opts . data || [ ] ; var strokes = opts . data ; var undos = [ ] ; version : 1 ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "getting", "content", "-", "length", "from", "response", "header"], "add_tokens": "if ( \"_contentLength\" in res && res [ '_contentLength' ] !== null ) { if ( res . getHeader ( 'content-length' ) !== null ) { resContentLength = parseInt ( res . getHeader ( 'content-length' ) ) ;", "del_tokens": "if ( \"_contentLength\" in res ) { if ( res . hasHeader ( 'content-length' ) ) { resContentLength = res . getHeader ( 'content-length' ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "console", "output", "tap", "compliant", "."], "add_tokens": "var testName = ' - ' + browser . name + ' ' + test . name", "del_tokens": "var testName = browser . name + ' - ' + test . name", "commit_type": "make"}
{"commit_tokens": ["Updated", "lib", "/", "partition", ":", "Better", "error", "msg", "on", "OOB"], "add_tokens": "if ( this . __OOB ( from ) || this . __OOB ( to ) ) { var msg = 'Block address out of bounds: ' + '[' + from + ',' + to + '] not in range ' + '[' + this . firstLBA + ',' + this . lastLBA + ']' return callback ( new Error ( msg ) ) } if ( this . __OOB ( from ) ) { var msg = 'Block address out of bounds: ' + '[' + from + ',' + to + '] not in range ' + '[' + this . firstLBA + ',' + this . lastLBA + ']' return callback ( new Error ( msg ) ) }", "del_tokens": "if ( this . __OOB ( from ) || this . __OOB ( to ) ) callback ( new Error ( 'Block address out of bounds' ) ) if ( this . __OOB ( from ) ) callback ( new Error ( 'Block address out of bounds' ) )", "commit_type": "update"}
{"commit_tokens": ["Adding", "the", "option", "for", "custom", "class", "configurations", "to", "the", "compiled", "templates", "file", "."], "add_tokens": "ignorePath : 'test/tmp/app' , clsConfig : { 'singleton' : true }", "del_tokens": "ignorePath : 'test/tmp/app'", "commit_type": "add"}
{"commit_tokens": ["Fix", "ES6", "syntax", "that", "was", "breaking", "index", ".", "js"], "add_tokens": "updateNotifier ( { pkg : pkg } ) . notify ( )", "del_tokens": "updateNotifier ( { pkg } ) . notify ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "details", "&", "summary", "element", "polyfill", "detection", "logic", "(", "hasOwnProperty", "(", "open", ")"], "add_tokens": "if ( details . length && goog . isBoolean ( details [ 0 ] . open ) ) { onclick ( ) ; // Start in a closed state.", "del_tokens": "if ( ! details . length || details [ 0 ] . hasOwnProperty ( 'open' ) ) { onclick ( ) ; // Start in a cloesd state.", "commit_type": "fix"}
{"commit_tokens": ["Added", "title", "&", "accesskey", "as", "allowed", "attributes", "for", "all", "tags"], "add_tokens": "'*' : [ 'title' , 'accesskey' ] , a : [ 'href' , 'name' , 'target' , 'aria-label' ] ,", "del_tokens": "a : [ 'href' , 'name' , 'target' , 'title' , 'aria-label' ] ,", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "template", "for", "a", "transition", "page"], "add_tokens": "import { AbstractPageTransitionComponent } from 'vue-transition-component' ;", "del_tokens": "import { AbstractTransitionComponent } from 'vue-transition-component' ;", "commit_type": "update"}
{"commit_tokens": ["Update", "html2canvas", "and", "change", "overlay", "-", "hiding", "to", "use", "opacity"], "add_tokens": "// overlayCSS.visibility = 'hidden'; overlayCSS . opacity = 0 ;", "del_tokens": "overlayCSS . visibility = 'hidden' ;", "commit_type": "update"}
{"commit_tokens": ["Add", "object", "mode", "to", "support", "http", "response"], "add_tokens": "* @ param { Boolean ? } objectMode * @ param { Stream ? } readable module . exports = function ( value , objectMode , readable ) { const result = stream ( readable , objectMode ) if ( typeof value === 'object' ) { else write ( objectMode ? value : JSON . stringify ( value ) )", "del_tokens": "module . exports = function ( value , readable ) { const bool = typeof value === 'object' const result = stream ( readable , bool ) if ( bool ) { else write ( value )", "commit_type": "add"}
{"commit_tokens": ["fixed", "custom", "component", "config", "loading"], "add_tokens": "var compConfig = getComponentConfiguration ( compName ) ;", "del_tokens": "var compConfig = getComponentConfiguration ( 'custom' + compName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "subclass", "custom", "error", "types", "in", "createErrorType"], "add_tokens": "* @ param ErrorClass { Function } An error class you wish to subclass . Defaults to Error . function createErrorType ( initialize = undefined , ErrorClass = undefined , prototype = undefined ) { ErrorClass = ErrorClass || Error ; Constructor . prototype = Object . assign ( Object . create ( ErrorClass . prototype ) , prototype ) ;", "del_tokens": "function createErrorType ( initialize = undefined , prototype = undefined ) { Constructor . prototype = Object . assign ( Object . create ( Error . prototype ) , prototype ) ;", "commit_type": "allow"}
{"commit_tokens": ["Allow", "subdirectories", "to", "be", "imported"], "add_tokens": "export const findModules = ( ) => fileMatching ( '{*,*/*}.{js,json}' )", "del_tokens": "export const findModules = ( ) => fileMatching ( '*.{js,json}' )", "commit_type": "allow"}
{"commit_tokens": ["add", "user", "prop", "to", "context"], "add_tokens": "expect ( ctx . user ) . not . toBeDefined ( ) ; nodeID : \"node-1\" , user : { id : 1 } expect ( ctx . user ) . toEqual ( { id : 1 } ) ; user : { id : 5 } , expect ( subCtx . user ) . toEqual ( { id : 5 } ) ;", "del_tokens": "nodeID : \"node-1\"", "commit_type": "add"}
{"commit_tokens": ["fix", "jquery", "-", "xdr", "(", "https", ":", "//", "github", ".", "com", "/", "jaubourg", "/", "ajaxHooks", "/", "pull", "/", "5", ")"], "add_tokens": "xdr . onprogress = function ( ) { } ; xdr . open ( s . type , s . url . replace ( / ^https?: / , '' ) ) ;", "del_tokens": "xdr . onprogress = jQuery . noop ; xdr . open ( s . type , s . url ) ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "for", "0x", "to", "be", "called", "in", "a", "repl", "without", "disrupting", "the", "parent", "repl", "(", "e", ".", "g", ".", "fuge", "integration", ")"], "add_tokens": "if ( process . stdin . isPaused ( ) ) { process . stdin . resume ( ) process . stdout . write ( '\\u001b[?25l' ) } if ( process . stdin . isPaused ( ) ) { process . stdin . resume ( ) process . stdout . write ( '\\u001b[?25l' ) }", "del_tokens": "process . stdin . resume ( ) process . stdout . write ( '\\u001b[?25l' ) process . stdin . resume ( ) process . stdout . write ( '\\u001b[?25l' )", "commit_type": "allow"}
{"commit_tokens": ["Added", "@typedef", "for", "FieldExpression", "and", "made", "couple", "of", "helpers", "private", "."], "add_tokens": "describe ( 'function whereJsonbRefOnLeftJsonbValOrRefOnRight(builder, fieldExpr, operator, <array|object|string>)' , function ( ) {", "del_tokens": "describe ( '.whereJsonObject(fieldExpr, operator, <array|object|string>)' , function ( ) { . dumpSql ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "updating", "phone", "service", "channels"], "add_tokens": "var PHP_CLIENT_VERSION = '1.0.12' ;", "del_tokens": "var PHP_CLIENT_VERSION = '1.0.11' ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "removed", "cli", "fixed", "tests", "."], "add_tokens": "module . exports = require ( \"./dist/parser\" ) ;", "del_tokens": "var fs = require ( \"fs\" ) ; var parse = require ( \"./dist/parser\" ) ; var path = process . argv [ 2 ] ; if ( ! path ) { console . error ( \"Usage: elmx file.elmx\" ) ; process . exit ( - 1 ) ; } var elmx = fs . readFileSync ( path , { encoding : 'UTF-8' } ) ; var elm = parse ( elmx ) ; console . log ( elm ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "tests", "for", "wtf", ".", "util", ".", "Options", "."], "add_tokens": "if ( goog . array . contains ( array , value ) ) { return ; } array . push ( value ) ; if ( goog . array . remove ( array , value ) ) { this . setValue_ ( key , array . length ? array : undefined ) ; }", "del_tokens": "goog . array . insert ( array , value ) ; goog . array . remove ( array , value ) ; this . setValue_ ( key , array . length ? array : undefined ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "watcher", "to", "column", "visibility"], "add_tokens": "scope : { visible : '=' } , $scope . $watch ( \"visible\" , function ( val ) { if ( angular . isDefined ( val ) ) { $scope . column . Visible = val ; } } ) ;", "del_tokens": "scope : true ,", "commit_type": "add"}
{"commit_tokens": ["Removed", "angular", "result", "functionality", "and", "moved", "server", "functionality", "to", "the", "cloud", "folder"], "add_tokens": "var config = require ( '../config' ) ;", "del_tokens": "var config = require ( './config' ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "test", "not", "working", "on", "windows"], "add_tokens": "var path = require ( 'path' ) ; path . normalize ( process . cwd ( ) + '/umzug.json' )", "del_tokens": "process . cwd ( ) + '/umzug.json'", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "stype", "to", "the", "error", "callback"], "add_tokens": "callback ( new Error ( 'No definition for this type; no way to serialize ' + stype ) ) ;", "del_tokens": "callback ( new Error ( 'No definition for this type; no way to serialize' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "of", "subscribe"], "add_tokens": "try { callbacks [ i ] ( result ) ; } catch ( e ) { }", "del_tokens": "callbacks [ i ] ( result ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "an", "issue", "in", "creating", "moment", "object"], "add_tokens": "return units ; if ( input && ( typeof input === 'string' ) && ! format && itsJalaliDate ) {", "del_tokens": "if ( input && ! format && itsJalaliDate ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "incorrect", "debug", "message", "during", "change", "event"], "add_tokens": "if ( err ) { debug ( 'Error reading channel value after change, %d' , readChannel ) ; return }", "del_tokens": "debug ( 'failed to read value after a change on channel %d' , readChannel ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "shaver", "code", "and", "tests"], "add_tokens": "module . exports = require ( './vtshaver.js' ) ;", "del_tokens": "module . exports = require ( './binding/module.node' ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "live", "-", "build", ".", "sh", "script", "for", "deployment"], "add_tokens": "$global . log = function ( ) { console . log . apply ( console , arguments ) } // placeholder for log.js", "del_tokens": "$global . log = function ( ) { console . log . apply ( console . log , arguments ) } // placeholder for log.js", "commit_type": "add"}
{"commit_tokens": ["Improve", "performance", "by", "removing", "a", "parseInt", "()", "call"], "add_tokens": "for ( var i = 0 , index = 0 ; i < len ; index ++ ) { var db = b - ( this . colorTab [ i ++ ] & 0xff ) ;", "del_tokens": "for ( var i = 0 ; i < len ; ) { var db = b - ( this . colorTab [ i ] & 0xff ) ; var index = parseInt ( i / 3 ) ; i ++ ;", "commit_type": "improve"}
{"commit_tokens": ["remove", "recursion", "for", "nested", "iframes"], "add_tokens": "console . log ( 'window: ' , window . top ) ; if ( window !== window . top ) console . log ( 'frameOffset: ' , window . frameElement . getBoundingClientRect ( ) ) ; console . log ( 'innerHeight: ' , window . top . innerHeight ) ; var rect = win . frameElement . getBoundingClientRect ( ) ; return rect . top ;", "del_tokens": "if ( win !== window . top ) { var rect = win . frameElement . getBoundingClientRect ( ) ; top += rect . top ; top = computeFrameOffset ( win . parent , top ) ; // recursion } return top ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "ability", "to", "create", "a", "user", "."], "add_tokens": "coordinator . use ( 'users.create' , [ middleware . identity , middleware . role ( roles . ADMIN ) , middleware . users . create ] ) ; middleware . identity , middleware . role ( roles . ADMIN ) , middleware . users . getByEmail create : function ( user ) { kontx . args . user = user ; return coordinator . handle ( 'users.create' , kontx ) ; } , kontx . args . email = email ;", "del_tokens": "middleware . identity , middleware . role ( roles . ADMIN ) , middleware . users . getByEmail kontx . email = email ;", "commit_type": "add"}
{"commit_tokens": ["Added", "s", ".", "setDbgClickHandler", "function", "added", "--", "ignore", "-", "skip", "-", "flag", "cmd", "line", "option", ".", "Inner", "docs", "corrections", "."], "add_tokens": "-- ignore - skip - flag - ignore 'skip' config option in config . js files . 'run-self-tests' , 'ignore-skip-flag' // , 'ignore-skip-flag': false", "del_tokens": "'run-self-tests'", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "logged", "stack", "including", "current", "method"], "add_tokens": "// add current call to stack after logging args . session . stack . push ( methodMeta . signature )", "del_tokens": "// add current call to stack args . session . stack . push ( methodMeta . signature )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "console", "scrolling", "using", "directive"], "add_tokens": ". controller ( 'ConsoleController' , function ( $scope , $timeout , ProcessService ) {", "del_tokens": ". controller ( 'ConsoleController' , function ( $scope , $element , $timeout , ProcessService ) { $scope . container = null ; // Auto scroll to bottom // TODO: Refactor implementation $scope . onload = function ( ) { $scope . container = $element . next ( ) . find ( '.console-wrapper' ) ; } ; $scope . scrollToBottom = function ( ) { if ( $scope . container ) { $scope . container . scrollTop ( $scope . container . prop ( 'scrollHeight' ) - $scope . container . prop ( 'offsetHeight' ) , 150 ) ; } } ; $scope . $watch ( 'process.log' , function ( ) { $timeout ( function ( ) { $scope . scrollToBottom ( ) ; } ) ; } ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "for", "the", "new", "events", "introduced", "in", "recent", "API", "changes", "including", "sub", "teams", "and", "do", "not", "disturb", "statuses"], "add_tokens": "reaction_removed : 'reaction_removed' , subteam_created : 'subteam_created' , subteam_updated : 'subteam_updated' , subteam_self_added : 'subteam_self_added' , subteam_self_removed : 'subteam_self_removed' , team_profile_change : 'team_profile_change' , team_profile_delete : 'team_profile_delete' , team_profile_reorder : 'team_profile_reorder' , dnd_updated : 'dnd_updated' , dnd_updated_user : 'dnd_updated_user' module . exports = slackAPI ;", "del_tokens": "reaction_removed : 'reaction_removed' module . exports = slackAPI ;", "commit_type": "add"}
{"commit_tokens": ["add", "special", "handling", "for", "localhost"], "add_tokens": "WebFinger . prototype . _isLocalhost = function ( domain ) { var local = / ^localhost(\\:[0-9]{1,6})$ / ; return local . test ( domain ) ; } ; var standard = / ^[A-Za-z0-9.-]+\\.[A-Za-z]{2,6}$ / ; return standard . test ( domain ) ; var self = this ; var host = parts [ 1 ] ; // host name for this useraddress var uri_index = 0 ; // track which URIS we've tried already var protocol = 'https' ; // we use https by default if ( this . _isLocalhost ( parts [ 1 ] ) ) { protocol = 'http' ; } else { cb ( { message : 'invalid host name' } ) ; return false ; } }", "del_tokens": "var pattern = / ^[A-Za-z0-9.-]+\\.[A-Za-z]{2,6}$ / ; return pattern . test ( domain ) ; cb ( { message : 'invalid host name' } ) ; return false ; var self = this ; var host = parts [ 1 ] ; // host name for this useraddress var uri_index = 0 ; // track which URIS we've tried already var protocol = 'https' ; // we use https by default }", "commit_type": "add"}
{"commit_tokens": ["fixed", "status", "json", "and", "runtime", "middleware"], "add_tokens": "next ( function ( response , next ) { next ( ) ; next ( function ( response , next ) { next ( ) ; next ( function ( response , next ) { next ( ) ;", "del_tokens": "next ( function ( response ) { next ( function ( response ) { next ( function ( response ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "acute", "handling", "for", "EX", "and", "IX", "forms"], "add_tokens": "// of rules it may only be possible for some regular forms, but worth a shot pluralForms . regularForms . push ( [ / (matr|vert|ind)(ix|ex)$ / , '$1ices' ] ) ; pluralForms . regularForms . push ( [ / (x|ch|ss|sh|s|z)$ / , '$1es' ] ) ; singularForms . regularForms . push ( [ / (vert|ind)(ices)$ / , '$1ex' ] ) ; singularForms . regularForms . push ( [ / (matr)(ices)$ / , '$1ix' ] ) ; singularForms . regularForms . push ( [ / (x|ch|ss|sh|s|z)es$ / , '$1' ] ) ; singularForms . regularForms . push ( [ / s$ / , '' ] ) ;", "del_tokens": "// of rules it may only be possible for some regular forms, but worth a shot pluralForms . regularForms . push ( [ / (x|ch|ss|sh|s)$ / , '$1es' ] ) ; singularForms . regularForms . push ( [ / (x|ch|ss|sh|s)es$ / , '$1' ] ) ; singularForms . regularForms . push ( [ / s$ / , '' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "support", "for", "testing", "in", "other", "projects", "."], "add_tokens": "// TODO: Put libraries to vendor settings for testing. var libs = ff . flatten ( ff . extLibFiles ( ) ) ; specs : specs , vendor : libs", "del_tokens": "specs : specs", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "up", "some", "user", "validation", "for", "mandatory", "fields"], "add_tokens": "function validateUser ( userObj , cb ) { isValid = true , totalProps = mandatoryProps . length , x = 0 ; console . log ( prop + ': Property not found.' ) ; x ++ ; if ( totalProps == x ) { cb . call ( this , isValid ) ; } } , function ( err ) { console . log ( 'isValid: ' + isValid ) ; callback ( ) ; } validateUser ( userObj , function ( result ) { if ( result ) { internal . app . db . addUser ( userObj , function ( val ) { console . log ( val ) ; } ) ; } else { callback . call ( this ) ; }", "del_tokens": "function validateUser ( userObj , cd ) { isValid = true ; console . log ( prop ) ; callback ( null , 'fdsafsdafa' ) ; //if(!_.contains(props, prop)){ // console.log('Property not found.'); // isValid = false; // } } , function ( err ) { console . log ( 'isValid: ' + isValid ) ; // callback(); } validateUser ( userObj , function ( ) { callback . call ( this ) ; //internal.app.db.addUser(userObj, function(val){ // console.log(val); //});", "commit_type": "fix"}
{"commit_tokens": ["changed", "return", "value", "of", "export", "function"], "add_tokens": "return cell ;", "del_tokens": "return cell . qNum !== 'NaN' ? Math . round ( cell . qNum , 5 ) : ( cell . qIsNull ? null : cell . qText ) ;", "commit_type": "change"}
{"commit_tokens": ["remove", "document", "click", "events", "when", "the", "menu", "is", "removed", "from", "the", "DOM"], "add_tokens": "if ( this . __documentClick ) { $ ( document ) . off ( 'mousedown' , this . __documentClick ) ; }", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "reading", "hashes", ".", "json"], "add_tokens": "console . log ( 'trying to read hashes.json' ) ; Hashes = require ( process . cwd ( ) + '/hashes' ) ; console . log ( 'hashes.json was not readed. ' ) ; fs . writeFile ( './hashes.json' , JSON . stringify ( Hashes ) , fileWrited ( pLastFile_b ) ) ;", "del_tokens": "Hashes = require ( 'hashes.json' ) ; fs . writeFile ( 'hashes.json' , JSON . stringify ( Hashes ) , fileWrited ( pLastFile_b ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["adds", "language", "autodect", "feature", "{", "autodetect", ":", "true", "}", "to", "attempt", "to", "automatically", "register", "a", "language", "that", "is", "specified", "after", "the", "first", "code", "boundary", "(", "delimiter", ")", ".", "e", ".", "g", ".", "---", "coffee", "."], "add_tokens": "var delims = require ( 'delims' ) ; var parsers = require ( './lib/parsers' ) ; var utils = require ( './lib/utils' ) ; function matter ( src , options ) { var opts = _ . extend ( { delims : [ '---' , '---' ] , lang : 'yaml' } , options ) ; var delimiters = delims ( opts . delims ) . evaluate ; // If true, will attempt to detect and register // the correct parser based on the returned string if ( opts . autodetect ) { opts . lang = utils . detectLang ( opts . delims [ 0 ] , content ) ; content = content . replace ( opts . lang , '' ) ; } try { metadata = parsers [ opts . lang ] ( fileObject [ 1 ] ) ; } catch ( e ) { e . origin = __filename ; console . warn ( 'Front-matter language not detected by gray-matter' , e ) ; }", "del_tokens": "var delim = require ( 'delims' ) ; var parse = require ( './lib/parsers' ) ; var matter = function ( src , options ) { var opts = _ . extend ( { delims : [ '---' , '---' ] , format : 'yaml' } , options ) var delimiters = delim ( opts . delims ) . evaluate ; metadata = parse [ opts . format ] ( fileObject [ 1 ] ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "exit", "animation", "for", "text", "boxes"], "add_tokens": "boxes . exit ( ) . transition ( ) . delay ( duration ) . remove ( ) ; boxes . exit ( ) . selectAll ( \"tspan\" ) . transition ( ) . duration ( duration ) . attr ( \"opacity\" , 0 ) ;", "del_tokens": "boxes . exit ( ) . remove ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "complex", "nested", "array", "ids", "."], "add_tokens": "it ( \"should render the input widgets with the expected ids\" , ( ) => { it ( \"should render nested input widgets with the expected ids\" , ( ) => { const complexSchema = { type : \"object\" , properties : { foo : { type : \"array\" , items : { type : \"object\" , properties : { bar : { type : \"string\" } , baz : { type : \"string\" } } } } } } ; const { node } = createFormComponent ( { schema : complexSchema , formData : { foo : [ { bar : \"bar1\" , baz : \"baz1\" } , { bar : \"bar2\" , baz : \"baz2\" } , ] } } ) ; const inputs = node . querySelectorAll ( \"input[type=text]\" ) ; expect ( inputs [ 0 ] . id ) . eql ( \"root_foo_0_bar\" ) ; expect ( inputs [ 1 ] . id ) . eql ( \"root_foo_0_baz\" ) ; expect ( inputs [ 2 ] . id ) . eql ( \"root_foo_1_bar\" ) ; expect ( inputs [ 3 ] . id ) . eql ( \"root_foo_1_baz\" ) ; } ) ;", "del_tokens": "it ( \"should render the select widget with the expected id\" , ( ) => {", "commit_type": "add"}
{"commit_tokens": ["Fix", "several", "methods", "for", "buffers", "with", "a", "non", "-", "zero", "byteOffset", "."], "add_tokens": "this . _start = byteOffset ; if ( this . _end >= bufferLength ) { throw new Error ( \"INDEX_SIZE_ERR: DOM Exception 1\" ) ; var int8array = new Int8Array ( this . _buffer , this . _start + byteOffset , length ) ; return new Uint8Array ( this . _buffer , this . _start + offset , 1 ) [ 0 ] ; return this . _buffer . charCodeAt ( this . _start + offset ) & 0xff ;", "del_tokens": "else { this . _start = byteOffset ; if ( this . _end >= bufferLength ) { throw new Error ( \"INDEX_SIZE_ERR: DOM Exception 1\" ) ; } var int8array = new Int8Array ( this . _buffer , byteOffset , length ) ; return new Uint8Array ( this . _buffer , offset , 1 ) [ 0 ] ; return this . _buffer . charCodeAt ( offset ) & 0xff ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "YeoSword", "instance", "to", "the", "repo"], "add_tokens": "import minimist from 'minimist' ; const args = minimist ( process . argv . slice ( 2 ) ) ; export default function ( ) {", "del_tokens": "export default function ( gulp , plugins , args , browserSync ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "cases", "for", "limit", "()", "and", "made", "it", "actually", "work", "(", "oops", ")"], "add_tokens": "if ( ! isDefined ( max ) ) max = 0 ; if ( ! isDefined ( offset ) ) offset = 0 ; if ( max ) { if ( offset ) { this . _attributes . limit = 'LIMIT ' + Number ( offset ) + ', ' + Number ( max ) ; } else { this . _attributes . limit = 'LIMIT ' + Number ( max ) ; } } else { this . _attributes . limit = false ; }", "del_tokens": "if ( isDefined ( max ) ) max = 0 ; if ( isDefined ( offset ) ) offset = 0 ; this . _attributes . limit = max ? [ 'LIMIT ' , Number ( offset ) , ', ' , Number ( max ) ] . join ( ) : false ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "retrieve", "title", "in", "metadata", "."], "add_tokens": "var title = / title *: ([^\\n]+) / . exec ( stderr ) ; title : ( title && title . length > 1 ) ? title [ 1 ] : null , }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["remove", "passport", "and", "authenticationProvider", "class"], "add_tokens": "Hub : Hub", "del_tokens": "var AuthenticationProvider = require ( './libs/AuthenticationProvider' ) ; Hub : Hub , AuthenticationProvider : AuthenticationProvider", "commit_type": "remove"}
{"commit_tokens": ["Implement", "a", "crude", "jump", "-", "to", "-", "definition", "function"], "add_tokens": "var cx = new tern . Context ( [ ecma5 , browser ] ) ; tern . withContext ( cx , function ( ) { var data = tern . analyze ( cm . getValue ( ) ) ; var end = cm . indexFromPos ( cm . getCursor ( ) ) ; var type = tern . expressionType ( data . ast , null , end ) , orig ; if ( type . types ) for ( var i = 0 ; i < type . types . length && ! orig ; ++ i ) orig = type . types [ i ] . origin ; else orig = type . origin ; if ( orig ) cm . setSelection ( cm . posFromIndex ( orig . end ) , cm . posFromIndex ( orig . start ) ) ; } ) ;", "del_tokens": "// FIXME", "commit_type": "implement"}
{"commit_tokens": ["remove", "border", "and", "some", "styles"], "add_tokens": "position : 'absolute' return dragDiv ( ord , hdep ++ ) . width ( hs ) . height ( hs ) . addClass ( cssClass ( 'handle' ) ) ;", "del_tokens": "position : 'absolute' , opacity : options . borderOpacity return dragDiv ( ord , hdep ++ ) . css ( { opacity : options . handleOpacity } ) . width ( hs ) . height ( hs ) . addClass ( cssClass ( 'handle' ) ) ; borderOpacity : 0.4 , handleOpacity : 0.5 ,", "commit_type": "remove"}
{"commit_tokens": ["Add", "analytics", "function", "to", "get", "metric", "keys"], "add_tokens": "// retrieve a list of unique metric keys // @param userOpts: option overrides for this request // @returns Returns a promise that resolves with an array of retrieved metric keys function getAllMetricKeys ( userOpts ) { return context . http . makeRequest ( { url : ` ${ context . applicationId } ${ ENDPT } ` } , userOpts ) . then ( obj => obj . data ) ; } getSubjectsSummaryIterator , getAllMetricKeys", "del_tokens": "getSubjectsSummaryIterator", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "history", ".", "back", "()"], "add_tokens": "if ( global . history && state == global . history . state && state . index != index ) history . back ( ) ;", "del_tokens": "if ( global . history && state == global . history . state ) history . back ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typos", "in", "CLI", "help", "and", "README"], "add_tokens": "'per argument, not including the leading \"--\". For example:\\n\\n' +", "del_tokens": "'per argument, not including the trailing \"--\". For example:\\n\\n' +", "commit_type": "fix"}
{"commit_tokens": ["Changed", "API", "from", "Struct", ".", "reg", "to", "Struct", ".", "define"], "add_tokens": "Struct . define ( 'ninja' , { Struct . getType ( sasuke ) ; // => Returns 'ninja' * Define new struct . Struct . define = function ( name , props ) { throw name + ' is already defined' ; throw 'Struct named \"' + name + '\" is not defined' ;", "del_tokens": "Struct . reg ( 'ninja' , { TODO : Check property descriptor when set value . * Register new struct . Struct . reg = function ( name , props ) { throw name + ' is already registered' ; throw 'Struct named \"' + name + '\" is not registered' ;", "commit_type": "change"}
{"commit_tokens": ["Added", "X", "-", "Apple", "-", "Widget", "-", "Key", "header", "and", "removed", "Cheerio"], "add_tokens": "appleWidgetKey : \"22d448248055bab0dc197c6271d738c3\" , headers : { 'Content-Type' : 'application/json' , 'X-Apple-Widget-Key' : this . options . appleWidgetKey } ,", "del_tokens": "cheerio = require ( 'cheerio' ) , headers : { 'Content-Type' : 'application/json' } , // Request ITC to get fresh post action request . get ( this . options . baseURL , function ( error , response , body ) { // Handle Errors // Search for action attribute var html = cheerio . load ( body ) ; var action = html ( 'form' ) . attr ( 'action' ) ; // Login to ITC request . post ( { url : self . options . baseURL + action , form : { 'theAccountName' : username , 'theAccountPW' : password , 'theAuxValue' : \"\" } } , function ( error , response , body ) { var cookies = response ? response . headers [ 'set-cookie' ] : null ; // Handle Errors if ( error || ! ( cookies && cookies . length ) ) { error = error || new Error ( 'There was a problem with recieving cookies. Please check your username and password.' ) ; self . options . errorCallback ( error ) ; } else { // Set _cookies and run callback self . _cookies = cookies ; self . options . loginCallback ( cookies ) ; // Start requests queue self . _queue . resume ( ) ; } } ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "and", "example", "table", ".", "js"], "add_tokens": "this . triggerBubble ( 'submit' , [ 'Hello, this person\\'s name is ' +", "del_tokens": "this . triggerBubble ( 'submit' , [ 'hello, this person\\'s name is ' +", "commit_type": "update"}
{"commit_tokens": ["remove", "mousewheel", "from", "scroll", "event"], "add_tokens": "on ( window , 'scroll' , callback )", "del_tokens": "on ( window , 'scroll mousewheel DOMMouseScroll' , callback )", "commit_type": "remove"}
{"commit_tokens": ["Changed", "three", ".", "js", "to", "a", "peer", "dependency", "so", "that", "this", "can", "be", "used", "by", "packages", "that", "include", "their", "own", "three", ".", "js", "."], "add_tokens": "var THREE = require ( 'three' ) ;", "del_tokens": "var THREE = require ( './lib/three' ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", ".", "__", "to", "use", "gettext", "and", "util", ".", "format"], "add_tokens": "res . locals . __ = function ( ) { var args = arguments if ( args . length === 0 ) { return \"\" ; } args [ 0 ] = res . locals . gettext ( args [ 0 ] ) ; return util . format . apply ( this , args ) ; } ;", "del_tokens": "res . locals . __ = res . locals . format ;", "commit_type": "change"}
{"commit_tokens": ["fix", "issues", "with", "provider", "name"], "add_tokens": "var providerName = req . headers [ 'provider' ] || \"salesforce\" ; return res . send ( \"Salesforce Authentication Token not found in session or in authorization header for provider: \" + providerName ) ;", "del_tokens": "var providerName = req . headers [ 'provider' ] || \"salesforce\" return res . send ( \"Salesforce Auth Token not found in session or in authorization header \" + providerName + \" \" + req . session . logins ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "jake", "task", ":", "deploy", "-", "mobile", "-", "spec"], "add_tokens": "MOBILE_SPEC_REPOS : { \"dir\" : path . normalize ( __dirname + \"/../test/cordova-mobile-spec\" ) , \"url\" : \"https://github.com/apache/cordova-mobile-spec.git\" } , TEST_SUITE_APP : path . normalize ( __dirname + \"/../test/test-suite/app\" ) , MOBILE_SPEC_APP : path . normalize ( __dirname + \"/../test/mobile-spec/app\" )", "del_tokens": "TEST_SUITE_APP : path . normalize ( __dirname + \"/../test/test-suite/app\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "type", "information", "to", "exported", "objects"], "add_tokens": "function makeValidator ( parseFn , type = 'unknown' ) { spec . type = type } , 'bool' ) } , 'num' ) exports . str = makeValidator ( input => input , 'str' ) } , 'email' ) } , 'url' ) } , 'json' )", "del_tokens": "function makeValidator ( parseFn ) { } ) } ) exports . str = makeValidator ( input => input ) } ) } ) } )", "commit_type": "add"}
{"commit_tokens": ["Add", "renderWithIntl", "method", "to", "round", "out", "enzyme", "api", "support", "."], "add_tokens": "import { mount , shallow , render } from 'enzyme' ; / ** * Equivalent to enzyme 's ' render ' * @ param { string } node React Component that requires react - intl . * @ return { object } * / function renderWithIntl ( node , { context , childContextTypes } = { } ) { const intlProvider = new IntlProvider ( { locale : locale , messages } , { } ) ; const { intl } = intlProvider . getChildContext ( ) ; return render ( React . cloneElement ( node , { intl } ) , { context : Object . assign ( { } , context , { intl } ) , childContextTypes : Object . assign ( { } , { intl : intlShape } , childContextTypes ) } ) ; } renderWithIntl : renderWithIntl ,", "del_tokens": "import { mount , shallow } from 'enzyme' ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "console", ".", "*", "in", "production", "."], "add_tokens": "warnings : false , drop_console : true", "del_tokens": "warnings : false", "commit_type": "remove"}
{"commit_tokens": ["Fix", "error", "in", "Bound", "version", "of", "String", "s", "postfix"], "add_tokens": "* @ version 0.1 .2 if ( ! Blast . Bound . String . endsWith ( str , postfix ) ) str += postfix ;", "del_tokens": "* @ version 0.1 .0 if ( ! str . endsWith ( postfix ) ) str += postfix ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "issues", "of", "\\", "n", "and", "given", "directory", "path", "load", "index", ".", "html"], "add_tokens": "actual : details . actual , expected : encodeURIComponent ( details . expected ) , message : encodeURIComponent ( details . message ) , source : encodeURIComponent ( details . source ) ,", "del_tokens": "actual : details . actual , expected : details . expected , message : details . message , source : details . source ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "endpoint", "for", "saving", "translations", "."], "add_tokens": "// Initially no translation for this id, but overriden with put below. endpoint ( '/trans/fr?ids=1238' , { } , { } ) , ( function ( ) { var putEndpoint = server . put ( '/trans/fr' ) . status ( 200 ) . body ( { } ) . delay ( config . latency ) ; putEndpoint . creates . get ( '/trans/fr?ids=1238' ) . status ( 200 ) . body ( getJSON ( '/trans/fr?ids=1238' ) ) . delay ( config . latency ) ; putEndpoint . creates . get ( '/source+trans/fr?ids=1238' ) . status ( 200 ) . body ( getJSON ( '/source+trans/fr?ids=1238-with-trans' ) ) . delay ( config . latency ) ; } ) , * @ query Optional object detailing query string parameters to match . Object key is the key , and the value may be a plain value or a regular expression .", "del_tokens": "* @ query Optional object detailing query string parameters to match . Object key is * the key , and the value may be a plain value or a regular expression .", "commit_type": "add"}
{"commit_tokens": ["Add", "grunt", "-", "release", "."], "add_tokens": "release : { options : { tagName : 'v<%= version %>' , commitMessage : 'Release v<%= version %>' , } } , messageTemplate : 'parseable' , grunt . loadNpmTasks ( 'grunt-release' ) ;", "del_tokens": "messageFormat : 'parseable' ,", "commit_type": "add"}
{"commit_tokens": ["Add", "documentation", "to", "all", "of", "the", "DrawnItemFactories", ".", "A", "couple", "of", "minor", "improvements", "as", "well", "."], "add_tokens": "/ ** * The paper . js Item object * @ external Item * @ see { @ link http : //paperjs.org/reference/item/|Item} * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "extra", "constructor", "checks", "before", "drying", "values", "with", "a", "Date", "or", "RegExp", "class", "name"], "add_tokens": "} else if ( class_name == 'RegExp' && value . constructor == RegExp ) { } else if ( class_name == 'Date' && value . constructor == Date ) {", "del_tokens": "} else if ( class_name == 'RegExp' ) { } else if ( class_name == 'Date' ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "setting", "a", "new", "grid", "would", "wipe", "away", "all", "tile", "costs", "."], "add_tokens": "if ( ! costMap [ collisionGrid [ y ] [ x ] ] ) { costMap [ collisionGrid [ y ] [ x ] ] = 1 }", "del_tokens": "* hi @ prettymuchbryce . com * * Based on Patrick Lester ' * http : //www.policyalmanac.org/games/aStarTutorial.htm costMap [ collisionGrid [ y ] [ x ] ] = 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "menus", "wouldn", "t", "always", "expand", "above", "the", "trigger", "when", "there", "s", "not", "enough", "room", "to", "show", "it", "below"], "add_tokens": "if ( bottomClearance >= menuHeight || bottomClearance >= topClearance )", "del_tokens": "if ( bottomClearance >= btnHeight || bottomClearance >= topClearance )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "callback", "to", "the", "constructor"], "add_tokens": "$ . fn . orgchart = function ( options , callback ) { ( typeof callback !== \"undefined\" && typeof callback === \"function\" ) ? callback ( ) : null ;", "del_tokens": "$ . fn . orgchart = function ( options ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "support", "for", "node", "8"], "add_tokens": "await rejects ( ( ) => Client . load ( {", "del_tokens": "rejects ( Client . load ( {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "zoom", "toggle", "to", "navigation", "counter"], "add_tokens": "this . counter = DOM . createNode ( 'a' , ELEMENT_ID . COUNTER ) ; this . counter . href = '#' ; this . counter . title = 'View all slides' ; this . counter . addEventListener ( 'click' , this . onButtonClicked_ . bind ( this ) ) ; } else if ( event . target === this . next ) { } else { this . ws_ . toggleZoom ( ) ;", "del_tokens": "this . counter = DOM . createNode ( 'span' , ELEMENT_ID . COUNTER ) ; } else {", "commit_type": "add"}
{"commit_tokens": ["implement", "caching", "for", "scoped", "css", "rewrites"], "add_tokens": "var cache = require ( 'lru-cache' ) ( 100 ) var key = id + '!!' + css var val = cache . get ( key ) if ( val ) { return Promise . resolve ( val ) } else { currentId = id return postcss ( [ addId ] ) . process ( css ) . then ( function ( res ) { var val = { source : res . css , type : 'style' } cache . set ( key , val ) return val } ) }", "del_tokens": "currentId = id return postcss ( [ addId ] ) . process ( css ) . then ( function ( res ) { return { source : res . css , type : 'style' } } )", "commit_type": "implement"}
{"commit_tokens": ["Added", "dependency", "to", "connect", "-", "bouncer", "via", "NPM"], "add_tokens": "server . use ( require ( 'connect-bouncer' ) ( require ( 'config' ) . bouncer ) ) ;", "del_tokens": "server . use ( require ( 'connect-throttle' ) ( require ( 'config' ) . throttle ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "different", "cases", "in", "action", "names"], "add_tokens": "} else if ( gestures . length === 1 && ( gestures [ 0 ] || '' ) . action . toLowerCase ( ) === 'doubletap' ) { } else if ( gestures . length === 1 && ( gestures [ 0 ] || '' ) . action . toLowerCase ( ) === 'longpress' ) {", "del_tokens": "} else if ( gestures . length === 1 && gestures [ 0 ] . action === 'doubleTap' ) { } else if ( gestures . length === 1 && gestures [ 0 ] . action === 'longpress' ) {", "commit_type": "allow"}
{"commit_tokens": ["Add", "grunt", "-", "contrib", "-", "concat", "custom", "process", "function", "which", "removes", "Sprockets", "directives", "from", "compiled", "angularjs", "-", "rails", "-", "resource", ".", "js"], "add_tokens": "dest : '<%= dirs.dest %>/<%= pkg.name %>.js' , options : { process : function ( src , filepath ) { return src . replace ( / ^\\/\\/= require.*\\n / gm , '' ) ; } , } ,", "del_tokens": "dest : '<%= dirs.dest %>/<%= pkg.name %>.js'", "commit_type": "add"}
{"commit_tokens": ["fixes", "not", "having", "an", "activeSource"], "add_tokens": "activeSource : source || \"\" ,", "del_tokens": "activeSource : \"\" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "options", "option", "to", "lex", "()"], "add_tokens": "function lex ( str , filename , options ) { var lexer = new Lexer ( str , filename , options ) ;", "del_tokens": "function lex ( str , filename ) { var lexer = new Lexer ( str , filename ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "multi", "mint", "in", "the", "st20", "generator"], "add_tokens": "var SELECTED_NETWORK = NETWORKS . GANACHE ; return \"0x97dc33d7f40863c09444f8c110e7a446ca209470\" ; return \"0x854b179252b51d2ee9abf50800cd52f96ec9c7d3\" ; return \"0xc47a7bd89c0ca065622b9f96a275e385642d2593\" ;", "del_tokens": "var SELECTED_NETWORK = NETWORKS . KOVAN ; return \"0x1b420511d1ef402f110317e1fc6faf58ad3b9c8a\" ; return \"0xee1fc6bf5535055eb2c505129acbcbbb789f3f8c\" ; return \"0xe1698c6c2f674d5fbbf34bbad1fd21fcbc46b345\" ;", "commit_type": "add"}
{"commit_tokens": ["create", "dir", "+", "catch", "exception"], "add_tokens": "// Make sure destination exists if ( ! fs . existsSync ( fileDestination ) ) { createDestination ( fileDestination . substr ( 0 , fileDestination . lastIndexOf ( '/' ) ) ) ; } copyFile ( file . path , fileDestination , function ( error ) { if ( error ) { throw new PluginError ( 'gulp-copy' , 'Could not copy file <' + file . path + '>: ' + error . message ) ; } function createDestination ( destination ) { var folders = destination . split ( '/' ) , path = [ ] , l = folders . length , i = 0 ; for ( ; i < l ; i ++ ) { path . push ( folders [ i ] ) ; if ( ! fs . existsSync ( path . join ( '/' ) ) ) { try { fs . mkdirSync ( path . join ( '/' ) ) ; } catch ( error ) { throw new PluginError ( 'gulp-copy' , 'Could not create destination <' + destination + '>: ' + error . message ) ; } } } }", "del_tokens": "copyFile ( file . path , fileDestination , function ( ) {", "commit_type": "create"}
{"commit_tokens": ["Use", "chalk", "instead", "of", "colors"], "add_tokens": "chalk = require ( 'chalk' ) , boldGreen = chalk . green . bold , boldRed = chalk . red . bold , console . error ( 'Option ' + boldRed ( '--bem' ) + ' is deprecated, use ' + boldGreen ( '--preset=bem' ) + ' option instead.' ) ; console . log ( boldRed ( val ) + ' is an invalid preset name. Available presets are: ' + Object . keys ( defaults . presets ) . map ( function ( preset ) { return boldGreen ( preset ) ; } ) . join ( ', ' ) + '.' ) ;", "del_tokens": "colors = require ( 'colors' ) , console . error ( 'Option ' + '--bem' . bold . red + ' is deprecated, use ' + '--preset=bem' . bold . green + ' option instead.' ) ; console . log ( val . bold . red + ' is an invalid preset name. Available presets are: ' + Object . keys ( defaults . presets ) . map ( colors . green ) . map ( colors . bold ) . join ( ', ' ) + '.' ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "blog", "post", "test", "case", "."], "add_tokens": "var contents = data . contents . toString ( ) . replace ( / ^\\n+ / g , '' ) ;", "del_tokens": "var contents = data . contents . toString ( ) . replace ( / ^\\s+ / g , '' ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "HTTP", "basic", "authentication", "."], "add_tokens": "// HTTP basic authentication var configAuth = config . auth || { } ; var auth = { username : configAuth . username || configAuth . user || '' , password : configAuth . password || configAuth . pass || '' } ; request . open ( config . method . toUpperCase ( ) , buildURL ( config . url , config . params , config . paramsSerializer ) , true , auth . username , auth . password ) ;", "del_tokens": "request . open ( config . method . toUpperCase ( ) , buildURL ( config . url , config . params , config . paramsSerializer ) , true ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "setUiState", "out", "of", "HOC"], "add_tokens": "var setUiState = ( 0 , _ . generateSetUiState ) ( this . props . set , this . uiStateName ) ;", "del_tokens": "var _this2 = this ; var setUiState = function setUiState ( state , cb ) { var updatedState = _this2 . props . set ( state , _this2 . uiStateName ) ; // optional callback to match setState API if ( cb ) { return cb ( updatedState . payload . state ) ; } return updatedState . payload . state ; } ; // these get passed to the child as props", "commit_type": "move"}
{"commit_tokens": ["Fixed", "arg", "-", "order", "bug", "in", "_", ".", "remove", "and", "added", "test"], "add_tokens": "return _ . keep ( array , function ( e ) { } ) ;", "del_tokens": "return _ . keep ( function ( e ) { } , array ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "dynamic", "geometry", "update", "bug", "update", "build", "output"], "add_tokens": "for ( var i = 0 ; i < this . _arrayChunks . length ; i ++ ) { var count = 0 ; attributeBuffers [ count ++ ] = new AttributeBuffer ( name , type , buffer , size , semantic ) ; } attributeBuffers . length = count ;", "del_tokens": "for ( var i = 0 ; i < chunks . length ; i ++ ) { attributeBuffers . push ( new AttributeBuffer ( name , type , buffer , size , semantic ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "minimal", "option", "from", "postcss", "-", "config"], "add_tokens": "const mixinsPath = path . join ( fixturesPath , 'css-mixins' ) ; it ( 'compiles CSS with custom mixin' , async ( ) => { const result = await postcss ( postcssConfig ( { mixinsPath } ) )", "del_tokens": "const mixinsDir = path . join ( fixturesPath , 'css-mixins' ) ; it ( 'compiles CSS with minimal option' , async ( ) => { const result = await postcss ( postcssConfig ( { minimal : true } ) ) . process ( sourceCss , options ) ; expect ( result . processor . plugins ) . not . toHaveLength ( 0 ) ; expect ( result . opts . from ) . toBeDefined ( ) ; expect ( result . map ) . toBeDefined ( ) ; expect ( result . css ) . toMatchSnapshot ( ) ; } ) ; it ( 'compiles CSS mixin with custom path' , async ( ) => { const result = await postcss ( postcssConfig ( { mixinsDir } ) )", "commit_type": "remove"}
{"commit_tokens": ["Change", "the", "way", "we", "export", "build_payload"], "add_tokens": "function build_payload ( metrics , time_stamp ) { exports . build_payload = build_payload ;", "del_tokens": "exports . build_payload = function build_payload ( metrics , time_stamp ) {", "commit_type": "change"}
{"commit_tokens": ["move", "selectLanguage", "()", "and", "setLanguage", "()", "to", "i18n"], "add_tokens": "i18n . selectLanguage ( languages , ( err , selectedLanguage ) => { i18n . selectLanguage ( languages ) i18n . setLanguage ( 'tlh' , localStorage ) ; i18n . selectLanguage ( [ 'tlh' , 'en' , 'ja' ] , ( err , selectedLanguage ) => { i18n . setLanguage ( 'tlh' , localStorage ) ; return i18n . selectLanguage ( [ 'tlh' , 'en' , 'ja' ] , null , localStorage )", "del_tokens": "i18n . translator . selectLanguage ( languages , ( err , selectedLanguage ) => { i18n . translator . selectLanguage ( languages ) i18n . translator . setLanguage ( 'tlh' , localStorage ) ; i18n . translator . selectLanguage ( [ 'tlh' , 'en' , 'ja' ] , ( err , selectedLanguage ) => { i18n . translator . setLanguage ( 'tlh' , localStorage ) ; return i18n . translator . selectLanguage ( [ 'tlh' , 'en' , 'ja' ] , null , localStorage )", "commit_type": "move"}
{"commit_tokens": ["add", "basic", "package", "-", "file", "testing"], "add_tokens": "if ( ! ioPackage . common . news || ! ioPackage . common . news [ ioPackage . common . version ] ) {", "del_tokens": "if ( ! ioPackage . common . news [ ioPackage . common . version ] ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "ap", "-", "ip", "command"], "add_tokens": "cli . command ( 'wifi-ap-ip [ip] [mask]' ) . description ( 'Gets/sets the IP address/netmask of the UFO when in AP mode.' ) ip ? this . setWifiApIp ( ip , mask , stop ( ) ) : this . getWifiApIp ( getAndStop ( true ) ) ;", "del_tokens": "cli . command ( 'wifi-ap-ip [ip]' ) . description ( 'Gets/sets the IP address of the UFO when in AP mode.' ) ip ? this . setWifiApIp ( ip , stop ( ) ) : this . getWifiApIp ( getAndStop ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "find", "and", "replace", "partials", "inside", "a", "section"], "add_tokens": "function iteratePartials ( parsed ) { parsed . filter ( function ( i ) { return i [ 0 ] == \"#\" ; } ) . map ( function ( i ) { iteratePartials ( i [ 4 ] ) . map ( function ( i ) { partialSet [ i ] = true ; } ) ; } ) ; function findPartials ( template ) { var partialSet = { } ; var parsed = mustache . parse ( template ) ; return iteratePartials ( parsed ) ; }", "del_tokens": "function findPartials ( template ) { var parsed = mustache . parse ( template ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "undefined", "actionType", "(", "causing", "errorsReducer", "to", "fire", "unnecessarily", ")", "."], "add_tokens": "const { CLEAR_ERRORS , CLEAR_ERROR , LISTENER_ERROR , ERROR } = actionTypes ;", "del_tokens": "const { CLEAR_ERRORS , CLEAR_ERROR , LOGIN_ERROR , LISTENER_ERROR , ERROR , } = actionTypes ; case LOGIN_ERROR : case LOGIN_ERROR :", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "error", "description", "incompatibility", "between", "the", "latest", "swagger", "-", "ui", "and", "swagger", "-", "core!"], "add_tokens": "function fix ( err ) { err . message = err . reason ; return err ; } \"description\" : \"Text To Speech REST API\" , { \"values\" : voices , \"valueType\" : \"LIST\" } , \"Alex\" fix ( swagger . errors . notFound ( 'voice' ) ) , fix ( swagger . errors . notFound ( 'text' ) ) , fix ( swagger . errors . invalid ( 'voice' ) ) \"description\" : \"Text To Speech REST API\" , fix ( swagger . errors . notFound ( 'voice' ) ) , fix ( swagger . errors . notFound ( 'text' ) ) , fix ( swagger . errors . invalid ( 'voice' ) ) , fix ( swagger . errors . invalid ( 'async' ) )", "del_tokens": "{ \"values\" : voices , \"valueType\" : \"LIST\" } swagger . errors . notFound ( 'voice' ) , swagger . errors . notFound ( 'text' ) , swagger . errors . invalid ( 'voice' ) swagger . errors . notFound ( 'voice' ) , swagger . errors . notFound ( 'text' ) , swagger . errors . invalid ( 'voice' ) , swagger . errors . invalid ( 'async' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "initial", "interface", "for", "deleteDatapoints"], "add_tokens": "// @param {function(err, device)} called with the created device // @param {function(err, deleted) called with whether the device was deleted or not // Delete a range of datapoints within a device, by sensor // // @param {String} deviceKey Device key to delete from // @param {String} sensorKey Sensor key to delete within the device // @param {Date} start The start of the delete range // @param {Date} end The end of the delete range // @param {function(err) callback Use deleteSummary.deleted to retrieve the number of datapoints deleted base . deleteDatapoints = function ( deviceKey , sensorKey , start , end , callback ) { base . _session . delete ( \"/v2/devices/\" + encodeURIComponent ( deviceKey ) + \"/sensors/\" + encodeURIComponent ( sensorKey ) + \"/datapoints\" , JSON . stringify ( { start : start , stop : end } ) , callback , function ( result ) { if ( result . code == HttpResult . OK ) { return { error : null } ; } } ) ; } ;", "del_tokens": "// @callback {function(err, device)} called with the created device // @callback {function(err, deleted) called with whether the device was deleted or not", "commit_type": "add"}
{"commit_tokens": ["Changing", "default", "marked", "engine", "options", "and", "updating", "package", ".", "json"], "add_tokens": "smartLists : true , breaks : false , sanitize : false", "del_tokens": "breaks : true , smartLists : true", "commit_type": "change"}
{"commit_tokens": ["Updated", "the", "copyright", "message", "to", "match", "new", "company", "branding"], "add_tokens": "* Copyright 2011 - 2012 Matthew Haag Verivo Software", "del_tokens": "* Copyright 2011 Matthew Haag", "commit_type": "update"}
{"commit_tokens": ["Use", "new", "Karma", "concurrency", "property", "for", "limiting", "parallel", "execution"], "add_tokens": "singleRun : true , // Concurrency level // how many browser should be started simultanous concurrency : 3 // SauceLabs open-source limitation", "del_tokens": "singleRun : true", "commit_type": "use"}
{"commit_tokens": ["Move", "CSS", "assembly", "into", "its", "own", "function", "that", "returns", "the", "output", "CSS"], "add_tokens": "const css = require ( './assets/css' ) ; fs . writeFileSync ( path . join ( BUILD_PATH , 'styles.css' ) , css ( options ) ) ;", "del_tokens": "const CSS_INPUT = ( options . css ) ? path . resolve ( options . css ) : false ; const CSS_OUTPUT = path . resolve ( path . join ( BUILD_PATH , 'styles.css' ) ) ; const LAYOUT_INPUT = path . resolve ( path . join ( IDYLL_PATH , 'layouts' , options . layout + '.css' ) ) ; const THEME_INPUT = path . resolve ( path . join ( IDYLL_PATH , 'themes' , options . theme + '.css' ) ) ; const inputCSS = CSS_INPUT ? fs . readFileSync ( CSS_INPUT ) : '' ; const layoutCSS = fs . readFileSync ( LAYOUT_INPUT ) ; const themeCSS = fs . readFileSync ( THEME_INPUT ) ; fs . writeFileSync ( CSS_OUTPUT , layoutCSS + '\\n' + themeCSS + '\\n' + inputCSS ) ;", "commit_type": "move"}
{"commit_tokens": ["Allow", "to", "specify", "the", "mode", "used", "with", "pdftotext"], "add_tokens": "if ( options . mode === undefined ) options . mode = 'layout' ; result . push ( '-' + options . mode ) ;", "del_tokens": "if ( options . layout === undefined ) options . layout = true ; if ( options . layout ) { result . push ( '-layout' ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Allow", "to", "set", "firebase", "data", "nodes", "from", "arrays", "."], "add_tokens": "if ( ! isObject ( value ) && ! Array . isArray ( value ) ) {", "del_tokens": "if ( ! isObject ( value ) ) {", "commit_type": "allow"}
{"commit_tokens": ["make", "dev", "format", "use", "the", "same", "token", "engine"], "add_tokens": "var color = 32 ; // green var status = res . statusCode ; if ( status >= 500 ) color = 31 ; // red else if ( status >= 400 ) color = 33 ; // yellow else if ( status >= 300 ) color = 36 ; // cyan var fn = compile ( '\\x1b[90m:method :url \\x1b[' + color + 'm:status \\x1b[90m:response-time ms - :res[content-length]\\x1b[0m' ) ; return fn ( tokens , req , res ) ;", "del_tokens": "var status = res . statusCode , len = parseInt ( res . getHeader ( 'Content-Length' ) , 10 ) , color = 32 ; if ( status >= 500 ) color = 31 else if ( status >= 400 ) color = 33 else if ( status >= 300 ) color = 36 ; len = isNaN ( len ) ? '' : len = ' - ' + bytes ( len ) ; return '\\x1b[90m' + req . method + ' ' + ( req . originalUrl || req . url ) + ' ' + '\\x1b[' + color + 'm' + res . statusCode + ' \\x1b[90m' + ( new Date - req . _startTime ) + 'ms' + len + '\\x1b[0m' ;", "commit_type": "make"}
{"commit_tokens": ["Use", "object", "-", "assign", "for", "Object", ".", "assign"], "add_tokens": "var assign = require ( 'object-assign' ) ; options = assign (", "del_tokens": "options = Object . assign (", "commit_type": "use"}
{"commit_tokens": ["Remove", "unused", "code", ";", "Rearrange", "Q", ".", "remove", "()"], "add_tokens": "if ( err ) return $done ( err ) ; else ( job ) job . remove ( $done ) ; if ( existing ) { if ( err ) $done ( err ) ; RED . hdel ( mapkey ( jobType ) , id , $done ) } else { } var msg = 'Removed job \"' + id + '\"' ; CONF . log . info ( msg ) $done ( )", "del_tokens": "if ( err ) return $done ( err ) ; if ( job ) { var id = [ job . data . user , job . data . raffle_num ] . join ( '-' ) job . remove ( function ( err ) { if ( err ) { $done ( err ) } else { var msg = 'Removed job #' + kid ; CONF . log . info ( msg ) RED . hdel ( mapkey ( job . type ) , id , $done ) } } ) } else { return $done ( ) } if ( existing ) $done ( err , true ) else RED . hdel ( mapkey ( jobType ) , id , $done )", "commit_type": "remove"}
{"commit_tokens": ["add", "new", "signed", "-", "off", "-", "by", "rule"], "add_tokens": "rules : { 'signed-off-by' : [ 0 , 'always' , ]", "del_tokens": "rules : {", "commit_type": "add"}
{"commit_tokens": ["Make", "private", "function", "names", "consistent"], "add_tokens": "function naturalCompareReverse ( a , b ) { return naturalCompare ( b , a ) ; function naturalCaseCompareReverse ( a , b ) { return naturalCompare . caseInsensitive ( b , a ) ; function numericalCompare ( a , b ) { return a - b ; function numericalCompareReverse ( a , b ) { return b - a ; return this . sort ( caseInsensitive ? naturalCaseCompareReverse : naturalCompareReverse ) ;", "del_tokens": "function numericalCompare ( a , b ) { return a - b ; function numericalCompareReverse ( a , b ) { return b - a ; function reverseNaturalCompare ( a , b ) { return naturalCompare ( b , a ) ; function reverseNaturalCaseCompare ( a , b ) { return naturalCompare . caseInsensitive ( b , a ) ; return this . sort ( caseInsensitive ? reverseNaturalCaseCompare : reverseNaturalCompare ) ;", "commit_type": "make"}
{"commit_tokens": ["Using", "nor", "-", "is", "and", "nor", "-", "extend", "modules"], "add_tokens": "var is = require ( 'nor-is' ) ;", "del_tokens": "var is = require ( './is.js' ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "regression", "for", "case", "where", "rendering", "<body", ">", "in", "renderWithTemplate"], "add_tokens": "// safeguard check to help developers debug situation where // they have more than one root element in the template. if ( wrappedEl [ 1 ] ) throw new Error ( 'Views can only have one root element.' ) ;", "del_tokens": "// safeguard check to help developers debug situation where // they have more than one root element in the template. if ( wrappedEl [ 1 ] ) throw new Error ( 'Views can only have one root element.' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "remaining", "localStorage", "helpers", "from", "shared", "tests"], "add_tokens": "// Clear localStorage before every test to prevent stored URLs to // interfere with our setup. if ( isBrowser ) { localStorage . clear ( ) ; }", "del_tokens": "var hasStorage = tus . canStoreURLs ; function expectLocalStorage ( key , expectedValue ) { if ( ! hasStorage ) { // Do not evaluate expectations on localStorage in node processes return ; } expect ( localStorage . getItem ( key ) , expectedValue ) ; } function clearLocalStorage ( ) { if ( ! hasStorage ) { // Do not evaluate expectations on localStorage in node processes return ; } localStorage . clear ( ) ; } clearLocalStorage ( ) ; expectLocalStorage ( \"fingerprinted\" , \"/uploads/blargh\" ) ; expectLocalStorage ( \"fingerprinted\" , \"/uploads/blargh\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "index", "to", "grocery", "example", "+", "added", "node", "-", "static", "to", "optional", "dependencies", "to", "run", "examples"], "add_tokens": "start ( app , 500 ) ;", "del_tokens": "start ( app , 2000 ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "relation", "parsing", "when", "accesing", "a", "nested", "model"], "add_tokens": "relations = utils . getRelationsFromContext ( ctx , app ) ; relations = model . relations ;", "del_tokens": "relations = utils . getRelationsFromContext ( ctx , app ) ;", "commit_type": "fix"}
{"commit_tokens": ["move", "code", "away", "from", "io", "event"], "add_tokens": "* If the window gains focus reset favicon count // update favicon _newLinesCount ++ ; Tinycon . setBubble ( _newLinesCount ) ;", "del_tokens": "* If windows gains focus reset favicon count _newLinesCount ++ ; Tinycon . setBubble ( _newLinesCount ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "list", "of", "methods", "to", "README"], "add_tokens": "'str' : [ 'String' , 'be a string' ] , 'fn' : [ 'Function' , 'be a function' ] , 'args' : [ 'Arguments' , 'be arguments' ] , 'regExp' : [ 'RegExp' , 'be a regular expression' ]", "del_tokens": "'sStr' : [ 'String' , 'be a string' ] , 'sFn' : [ 'Function' , 'be a function' ] , 'sArgs' : [ 'Arguments' , 'be arguments' ] , 'sRegExp' : [ 'RegExp' , 'be a regular expression' ]", "commit_type": "add"}
{"commit_tokens": ["Allow", "single", "attribute", "messages", ".", "Fixes", "issue", "-", "7", "."], "add_tokens": "this . single = false ; // Message is a 'multiple attribute message'. if ( typeof args === 'object' || typeof args === 'undefined' ) { this . args = args || { } ; } // Message is a 'single attribute message'. else { this . single = true ; this . args = args ; } if ( ! this . single ) { this . arg ( 'flowId' , this . args . flowId || Message . flowId ) ; } if ( this . single ) { throw new Error ( 'Cannot add arguments to a single attribute message.' ) ; } if ( this . single ) { return util . format ( '##teamcity[%s \\'%s\\']' , this . type , this . escape ( this . args ) ) ; }", "del_tokens": "this . args = typeof args === 'object' ? args : { } ; this . arg ( 'flowId' , this . args . flowId || Message . flowId ) ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "bug", "with", "upload", "document"], "add_tokens": "//Private corpus takes precedence, but change to public if there is one. if ( this . corpus . publiccorpus && ! this . corpus . cname ) { node . status ( { fill : \"blue\" , shape : \"ring\" , text : \"Getting account information\" } ) ; node . status ( { } ) ; console . log ( err ) ;", "del_tokens": "console . log ( cfenv ) . getAppEnv ( ) . getServices ( ) ; if ( this . corpus . publiccorpus ) { node . status ( { fill : \"blue\" , shape : \"ring\" , text : \"Getting account information\" } ) ; node . status ( { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "credential", "checking", "to", "separate", "function"], "add_tokens": "} ; // Check that the credentials have been provided // Credentials are needed for each the service. var checkCreds = function ( credentials ) { var taSettings = null ; username = sUsername || credentials . username ; password = sPassword || credentials . password ; if ( username && password ) { taSettings = { } ; taSettings . username = username ; taSettings . password = password ; } return taSettings ; var taSettings = null ; taSettings = checkCreds ( node . credentials ) ; if ( ! taSettings ) {", "del_tokens": "var taSettings = { } ; // Credentials are needed for each of the modes. username = sUsername || node . credentials . username ; password = sPassword || node . credentials . password ; if ( ! username || ! password ) { if ( ! message ) { taSettings . username = username ; taSettings . password = password ; }", "commit_type": "move"}
{"commit_tokens": ["added", "-", "important", "-", "method", "to", "validators"], "add_tokens": "var _validator = function ( baseScore , funcs ) { return total + baseScore ; return _validator ( baseScore , funcs . concat ( func ) ) ; return funcs . length + baseScore ; } ; v . important = function ( bump ) { bump = bump || 64 ; return _validator ( baseScore + bump , funcs ) ; return _validator ( 0 ) ;", "del_tokens": "var _validator = function ( funcs ) { return total ; return _validator ( funcs . concat ( func ) ) ; return funcs . length ; return _validator ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "eslint", "-", "plugin", "-", "flowtype", "."], "add_tokens": "\"react\" , \"flowtype\" \"flowtype/define-flow-type\" : 1 , \"flowtype/require-valid-file-annotation\" : [ \"error\" , \"always\" ] ,", "del_tokens": "\"react\"", "commit_type": "use"}
{"commit_tokens": ["Added", "querying", "of", "id", "s"], "add_tokens": ", _ = require ( 'underscore' ) // Id if ( qargs . id . length ) { match = _ . indexOf ( qargs . id , task . __uuid__ . substr ( 0 , 8 ) ) !== - 1 } , db = taskpool . db db . end ( function ( err ) {", "del_tokens": "taskpool . db . end ( function ( err ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "slashes", "with", "-", "d", "on", "Windows", ".", "Log", "each", "file", "path", "when", "using", "-", "d", "for", "debugging", "invalid", "ES6", "line", "numbers"], "add_tokens": "// Also make sure we're speaking the same slashes var relativeDir = fpath . replace ( absDirectory . replace ( / \\\\ / g , \"/\" ) , \"\" ) ; console . log ( fpath ) ;", "del_tokens": "var relativeDir = fpath . replace ( absDirectory , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "null", "from", "populated", "array"], "add_tokens": "set ( v , key , compact ( entry . map ( it => { } ) ) ) ; set ( item , target , compact ( entry . map ( it => { } ) ) ) ;", "del_tokens": "set ( v , key , entry . map ( it => { } ) ) ; set ( item , target , entry . map ( it => { } ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["made", "the", "package", "work", "now", "and", "also", "made", "the", "attach", "route", "work", "so", "the", "script", "file", "can", "be", "downloaded", "from", "the", "node_modules", "location"], "add_tokens": "response . download ( __dirname + '/dist/' + request . params [ 'file' ] ) ;", "del_tokens": "response . download ( __dirname + './../node_modules/clientexpress/dist/' + request . params [ 'file' ] ) ;", "commit_type": "make"}
{"commit_tokens": ["Update", "sample", "doc", "definitions", "with", "more", "immutable", "properties"], "add_tokens": "mustNotBeEmpty : true , immutable : true mustNotBeEmpty : true , immutable : true mustNotBeEmpty : true , immutable : true mustNotBeEmpty : true , immutable : true { propertyName : 'siteName' , type : 'string' , mustNotBeEmpty : true , immutable : true } , required : true , mustNotBeEmpty : true , immutable : true mustNotBeEmpty : true , immutable : true", "del_tokens": "mustNotBeEmpty : true mustNotBeEmpty : true mustNotBeEmpty : true mustNotBeEmpty : true mustNotBeEmpty : true mustNotBeEmpty : true", "commit_type": "update"}
{"commit_tokens": ["Implemented", "functions", "config", "start", "pause", "continue", "now", "time", "valueOf", "toString"], "add_tokens": "* A timer running faster or slower than real - time , and in continuous or * discrete time .", "del_tokens": "* A timer running faster or slower than realtime , in continuous or discrete * time .", "commit_type": "implement"}
{"commit_tokens": ["fixed", "object", "mixin", "&", "resolver", "callback"], "add_tokens": "// object mixin if ( proto && typeof proto === 'object' ) { for ( var key in uP . prototype ) proto [ key ] = uP . prototype [ key ] ; proto . _tuple = [ ] ; return proto ; } if ( ! ( this instanceof microPromise ) ) return new microPromise ( proto ) ; // resolver callback proto ( this . resolve , this . reject , this . progress , this . timeout ) ; }", "del_tokens": "if ( ! ( this instanceof uP ) ) return new uP ( proto ) ; var res = this . resolve . bind ( this ) , rej = this . reject . bind ( this ) , pro = this . progress . bind ( this ) , tim = this . timeout . bind ( this ) ; proto ( res , rej , pro , tim ) ; } else if ( proto ) for ( var key in proto ) this [ key ] = proto [ key ] ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "dummy", "setting", "and", "preparing", "for", "a", "real", "options", "object", "."], "add_tokens": "this . saveSettings ( ) ; this . loadSettings ( ) ; var options = { } ; var dockOption = options [ 'dock' ] || 'br' ; var wtfHudSettingsHudDockLocation = this . getChildElement ( 'wtfHudSettingsHudDockLocation' ) ; for ( var n = 0 ; n < wtfHudSettingsHudDockLocation . options . length ; n ++ ) { var option = wtfHudSettingsHudDockLocation . options [ n ] ; if ( option . value == dockOption ) { wtfHudSettingsHudDockLocation . selectedIndex = n ; break ; } } var options = { } ; var wtfHudSettingsHudDockLocation = this . getChildElement ( 'wtfHudSettingsHudDockLocation' ) ; var dockOption = wtfHudSettingsHudDockLocation . options [ wtfHudSettingsHudDockLocation . selectedIndex ] . value || 'br' ; options [ 'dock' ] = dockOption ;", "del_tokens": "this . save_ ( ) ; this . load_ ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Google", "as", "an", "authentication", "streategy", "."], "add_tokens": "res . render ( 'signin' , { strategies : passport . _strategies } ) ;", "del_tokens": "res . render ( 'signin' ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "require", "paths", "that", "were", "broken", "by", "plugin", "id", "changes"], "add_tokens": "Acceleration = require ( 'org.apache.cordova.core.device-motion.Acceleration' ) ;", "del_tokens": "Acceleration = require ( 'org.apache.cordova.core.AccelListener.Acceleration' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "a", "whole", "bunch", "of", "debug", "logging"], "add_tokens": "function callbackWatcher ( defaultTimeout ) { var fileWatcher = callbackWatcher ( 500 ) ;", "del_tokens": "function callbackWatcher ( defaultTimeout , noisy ) { if ( typeof noisy !== 'boolean' ) { noisy = true ; } if ( noisy ) console . log ( 'caught function with ' + arguments . length + ' (' + currentMsg + ')' ) ; //if (noisy) console.log(arguments); console . log ( 'clearing out (1) ' + currentMsg ) ; } else { if ( noisy ) console . log ( 'but nowhere to pass it (' + currentMsg + '??)' ) ; if ( noisy ) console . log ( 'starting watch with ' + msg ) ; console . log ( 'clearing out (2) ' + msg ) ; if ( noisy ) console . log ( 'about to set (' + msg + ')' ) ; if ( noisy ) console . log ( 'on time receipt of event (' + msg + ')' ) ; } else { if ( noisy ) console . log ( 'got callback but it was too late. OUTTATIME' ) ; if ( noisy ) console . log ( 'update set (' + msg + ')' ) ; var fileWatcher = callbackWatcher ( 500 , false ) ;", "commit_type": "remove"}
{"commit_tokens": ["Create", "generate", "-", "current", ".", "js"], "add_tokens": "// IMPORTANT: User-Agent header is required! var options = { url : 'http://alerts.weather.gov/cap/us.php?x=1' , headers : { 'User-Agent' : 'request' } } request . get ( options )", "del_tokens": "request . get ( 'http://alerts.weather.gov/cap/us.php?x=1' )", "commit_type": "create"}
{"commit_tokens": ["Fix", "JSDoc", "for", "referenceEqual", "rename", "referenceNotEqual", "into", "notReferenceEqual"], "add_tokens": "describe ( 'notReferenceEqual assertion' , function ( ) { assert . notReferenceEqual ( list1 , list2 ) ; fail ( ( ) => assert . notReferenceEqual ( list1 , list2 ) ) ;", "del_tokens": "describe ( 'referenceNotEqual assertion' , function ( ) { assert . referenceNotEqual ( list1 , list2 ) ; fail ( ( ) => assert . referenceNotEqual ( list1 , list2 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "release", "dir", "date", "(", "second", "instead", "of", "month", "-", "_", "-", ")", "."], "add_tokens": "shipit . releaseDirname = moment ( ) . format ( 'YYYYDDMMHHmmss' ) ;", "del_tokens": "shipit . releaseDirname = moment ( ) . format ( 'YYYYDDMMHHMMss' ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "default", "template", "to", "snowplow", ".", "js"], "add_tokens": "d : template ? template ( $get ) : { } ,", "del_tokens": "d : template ( $get ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "CSS", "file", "for", "popup", "styling"], "add_tokens": "btn . className = \"mapboxgl-ctrl-icon mapboxgl-ctrl-inspect\" ; this . _btn . className = \"mapboxgl-ctrl-icon mapboxgl-ctrl-inspect\" ; this . _btn . className = \"mapboxgl-ctrl-icon mapboxgl-ctrl-map\" ;", "del_tokens": "var InspectIcon = require ( './inspecticon' ) ; var MapIcon = require ( './mapicon' ) ; btn . className = \"mapboxgl-ctrl-icon mapboxgl-ctrl-inspector\" ; this . _btn . style [ 'background-image' ] = 'url(data:image/svg+xml;charset=utf8,' + encodeURI ( InspectIcon ) + ')' ; this . _btn . style [ 'background-image' ] = 'url(data:image/svg+xml;charset=utf8,' + encodeURI ( MapIcon ) + ')' ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "parameter", "type", "options"], "add_tokens": "* You can enforce types by setting values to objects with ` ` , ` ` and * ( optionally ) ` ` properties , e . g . , * value : 'two' , * options : { * length : 3 * } * For more information about type options , see : { @ link http : //pekim.github.io/tedious/api-request.html#function_addParameter}. var options = null ; options = null ; if ( value . hasOwnProperty ( 'options' ) ) { options = value . options ; } request . addParameter ( keys [ i ] , type , value , options ) ;", "del_tokens": "* You can enforce types by setting values to object with ` ` and ` ` properties , e . g . , * value : 'two' request . addParameter ( keys [ i ] , type , value ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "a", "choices", "validation", "argument", "."], "add_tokens": "CHOICEVAR : { choices : [ 'one' , 'two' , 'three' ] } , function ( ) { env . validate ( { } , basicSpec ) ; } , env . EnvError ) ; } ) ; it ( 'validates from a set of choices if given' , function ( ) { assert . throws ( function ( ) { env . validate ( { REQD : 'asdf' , CHOICEVAR : 'asdf' } , basicSpec ) ; } , env . EnvError ) ; var myEnv = env . validate ( { REQD : 'asdf' , CHOICEVAR : 'two' } , basicSpec ) ; assert . strictEqual ( myEnv . CHOICEVAR , 'two' ) ; assert . strictEqual ( env . get ( 'CHOICEVAR' ) , 'two' ) ;", "del_tokens": "function ( ) { env . validate ( { } , basicSpec ) ; } , Error ) ; //FIXME: more precise error checking", "commit_type": "add"}
{"commit_tokens": ["fixed", "DAWG", "Graph", "tests", "and", "passing", "DAWG", "Dataset", "tests"], "add_tokens": "this . defaultGraphUri = \"https://github.com/antoniogarrote/js-tools/types#default_graph\" ; this . defaultGraphUriTerm = { \"token\" : \"uri\" , \"prefix\" : null , \"suffix\" : null , \"value\" : this . defaultGraphUri , \"oid\" : this . defaultGraphOid } ; if ( uri === this . defaultGraphUri ) { callback ( this . defaultGraphOid ) ; } else if ( this . uriToOID [ uri ] == null ) { value : this . defaultGraphUri , console . log ( \"error in lexicon retrieving OID:\" ) ; console . log ( oid ) ; if ( e . message ) { console . log ( e . message ) ; } if ( e . stack ) { console . log ( e . stack ) ; }", "del_tokens": "if ( this . uriToOID [ uri ] == null ) { value : \"https://github.com/antoniogarrote/js-tools/types#default_graph\" , console . log ( \"error in lexicon\" ) ; console . log ( e . message ) ; console . log ( e . stack ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tooltip", "position", "in", "absolutely", "positioned", "elements"], "add_tokens": ", $container = $ ( \".\" + options . map . cssClass , this ) . empty ( ) , $tooltip = $ ( \"<div>\" ) . addClass ( options . map . tooltip . cssClass ) . css ( \"display\" , \"none\" ) . appendTo ( options . map . tooltip . target || $container ) cssClass : \"mapTooltip\" , target : null", "del_tokens": ", $tooltip = $ ( \"<div>\" ) . addClass ( options . map . tooltip . cssClass ) . css ( \"display\" , \"none\" ) , $container = $ ( \".\" + options . map . cssClass , this ) . empty ( ) . append ( $tooltip ) cssClass : \"mapTooltip\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "basic", "styles", "for", "tables", "."], "add_tokens": "var UndefinedEnum ; / ** * < table > * < caption > This is the table caption < / caption > * < thead > * < tr > < th > Fruit < / th > < th > Color < / th > < / tr > * < / thead > * < tbody > * < tr > < td > Apple < / td > < td > Red < / td > < / tr > * < tr > < td > Apple < / td > < td > Green < / td > < / tr > * < tr > < td colspan = \"2\" > Orange < / td > < / tr > * < / tbody > * < / table > * @ constructor * / function SomeCtor ( ) { }", "del_tokens": "var UndefinedEnum ;", "commit_type": "add"}
{"commit_tokens": ["Add", "parser", "for", "0x83", ";", "Receive", "Packet", "16", "-", "bit", "IO"], "add_tokens": "if ( S . offset > 3 ) { // unnessary check", "del_tokens": "if ( S . offset > 3 ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "qlobber", "-", "sub", ".", "js", "for", "aedes"], "add_tokens": "all : [ 'Gruntfile.js' , 'index.js' , 'lib/*.js' , 'aedes/*.js' , 'test/*.js' , 'bench/**/*.js' ] ,", "del_tokens": "all : [ 'Gruntfile.js' , 'index.js' , 'lib/*.js' , 'test/*.js' , 'bench/**/*.js' ] ,", "commit_type": "add"}
{"commit_tokens": ["fixes", "https", ":", "//", "github", ".", "com", "/", "jonschlinkert", "/", "extract", "-", "comments", "/", "issues", "/", "6"], "add_tokens": "endIdx = end ( str , startIdx , len ) ; if ( endIdx === - 1 ) break ; var quoted = utils . isQuotedString ( startIdx , ranges ) ; if ( quoted ) { startIdx = endIdx ; if ( startIdx >= len ) break ; if ( startIdx >= len || endIdx >= len ) { break ; } endIdx = end ( str , startIdx , len ) ; if ( endIdx === - 1 ) { endIdx = len ; var quoted = utils . isQuotedString ( startIdx , ranges ) ; if ( quoted ) { startIdx = endIdx + 1 ; continue ; }", "del_tokens": "var isQuoted = utils . isQuotedString ( startIdx , ranges ) ; if ( isQuoted ) { endIdx = end ( str , startIdx , len ) ; if ( endIdx === - 1 ) endIdx = len ; endIdx = end ( str , startIdx , len ) ; if ( endIdx === - 1 ) break ; endIdx = end ( str , startIdx , len ) ; if ( endIdx === - 1 ) endIdx = len ; var isQuoted = utils . isQuotedString ( startIdx , ranges ) ; if ( isQuoted ) { startIdx = start ( str , endIdx ) ; continue ;", "commit_type": "fix"}
{"commit_tokens": ["using", "parseint", "when", "setting", "port", "for", "replicaset", "to", "avoid", "error"], "add_tokens": "var port = parseInt ( split [ 1 ] ) || 27017 ;", "del_tokens": "var port = split [ 1 ] || 27017 ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "error", "from", "missing", "tls", ".", "createConnection", "()", "method", ":"], "add_tokens": "c = tls . connect ( self . connectOptions . port , self . connectOptions . host ) ;", "del_tokens": "c = tls . createConnection ( self . connectOptions ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "animated", "stroke", "on", "Safari"], "add_tokens": "let l = $el . strokeLength + 'px' ; let l = $el . strokeLength + 'px' ;", "del_tokens": "let l = $el . strokeLength ; let l = $el . strokeLength ;", "commit_type": "fix"}
{"commit_tokens": ["added", "context", "for", "nunjucks", "compiling"], "add_tokens": "var nunjucksContext = opt . context ; html = template . render ( nunjucksContext ) ;", "del_tokens": "html = template . render ( ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "robots", "-", "ENV", ".", "txt", "on", "deploy", "build"], "add_tokens": "function cleanupRobotsTxt ( outputPath ) { var files = glob . sync ( outputPath + path . sep + 'robots-*.txt' ) ; if ( files && files . length ) { files . forEach ( function ( path ) { fs . unlink ( path ) ; } ) ; } } cleanupRobotsTxt ( result . directory ) ; console . log ( chalk . yellow ( 'There is a robots.txt in /public and ENV specific robots.txt are ignored!' ) ) ; . then ( this . _cleanupRobotsTxt . bind ( this , distDir ) ) _cleanupRobotsTxt : function ( outputPath ) { cleanupRobotsTxt ( outputPath ) ; return outputPath ; } ,", "del_tokens": "var files = glob . sync ( result . directory + path . sep + 'robots-*.txt' ) ; if ( files && files . length ) { files . forEach ( function ( path ) { fs . unlink ( path ) ; } ) ; } console . log ( chalk . yellow ( 'There is a robots.txt in /public and ENV specifc robots.txt are ignored!' ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "function", "key", "in", "build", "phase", "."], "add_tokens": "function copyFunction ( a ) { return F . copy ( { key : 'function-' + a . name } , a ) ; } function copyModule ( a , bs ) { return F . copy ( { key : 'module-' + a . name , functions : bs } , a ) ; } // Builds the modules from the database `db`. var mixins = data . findModuleMixins ( db , module ) . get ( ) , searchModules = F . append ( module , mixins ) ; var functions = data . findModuleFunctions ( db , searchModules ) . order ( 'name' ) . map ( copyFunction ) ; return copyModule ( module , functions ) ;", "del_tokens": "// Builds the module objects. var mixins = data . findModuleMixins ( db , module ) . get ( ) , searchModules = F . append ( module , mixins ) , functions = data . findModuleFunctions ( db , searchModules ) . order ( 'name' ) ; // Merge the functions into the module object. return F . copy ( { functions : functions , key : 'module-' + module . name } , module ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "ReactRouter", "namespace", "in", "tests"], "add_tokens": "var Router = ReactRouter . Router ;", "del_tokens": "var Router = require ( '../lib/router' ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "empty", "key", "productions", "in", "parser"], "add_tokens": "console . log ( str ) ;", "del_tokens": "console . log ( str ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "infobar", "also", "show", "on", "filebrowser", "mode"], "add_tokens": "console . log ( 'selectorchange' , selector ) ; console . log ( 'done' ) ; dinfo . show ( ) ; dinfo . hide ( ) ; if ( this . client ) { return this . callClient ( 'elementsForSelector' , { selector : selector } , function ( data ) { return cb ( data . ids ) ; } ) ; } else { return _ . defer ( function ( ) { return cb ( null ) ; } ) ; }", "del_tokens": "return this . callClient ( 'elementsForSelector' , { selector : selector } , function ( data ) { return cb ( data . ids ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "migration_chain", "config", "(", "again", ")"], "add_tokens": "const currentPath = process . cwd ( ) lastLine = lines . length == 0 ? '' : lines [ lines . length - 1 ] assert ( output == expectedResult , 'FAIL, Expected: ' + expectedResult + ', Actual: ' + output + '\\n' ) ( callback ) => { testExecuteYaml ( 'Test executeYaml containing infinite loop, expect error' , 'tests/chain-infinite-loop.yaml' , [ 0 ] , { } , '' , callback ) } , ( callback ) => { testExecuteYaml ( 'Test executeYaml containing empty object' , 'tests/chain-empty.yaml' , [ 0 ] , { } , '' , callback ) } , ] , ( result , error ) => { assert ( process . cwd ( ) == currentPath , 'FAIL: current path doesn\\'t set back' ) console . log ( 'ALL TEST SUCCESS: there should be some error messages shown, but it is expected' ) console . log ( 'If you see this message, it means the errors are catched.' ) } )", "del_tokens": "lastLine = lines [ lines . length - 1 ] assert ( output == expectedResult , 'FAIL, Expected: ' + expectedResult + ', Actual: ' + lastLine + '\\n' ) ] , ( result , error ) => { } )", "commit_type": "add"}
{"commit_tokens": ["changed", "4", "style", "names", "to", "conform", "to", "existing", "convention", "on", "active", "styles", ".", "updated", "built", "in", "styles", "to", "conform", "to", "new", "style", "names", "."], "add_tokens": "[ 'activeHeaderCellColor' , 'rgba(0, 0, 0, 1)' ] , [ 'activeHeaderCellBackgroundColor' , 'rgba(225, 225, 225, 1)' ] , [ 'activeRowHeaderCellColor' , 'rgba(0, 0, 0, 1)' ] , [ 'activeRowHeaderCellBackgroundColor' , 'rgba(225, 225, 225, 1)' ] , [ 'activeCellOverlayBorderColor' , 'rgba(66, 133, 244, 1)' ] , [ 'activeCellOverlayBorderWidth' , 1.50 ] ,", "del_tokens": "[ 'headerCellActiveColor' , 'rgba(0, 0, 0, 1)' ] , [ 'headerCellActiveBackgroundColor' , 'rgba(225, 225, 225, 1)' ] , [ 'rowHeaderCellActiveColor' , 'rgba(0, 0, 0, 1)' ] , [ 'rowHeaderCellActiveBackgroundColor' , 'rgba(225, 225, 225, 1)' ] , [ 'activeCellOverlayBorderColor' , 'rgba(66, 133, 244, 1)' ] , [ 'activeCellOverlayBorderWidth' , 1.50 ] ,", "commit_type": "change"}
{"commit_tokens": ["Added", "isAliasOfType", "to", "be", "able", "to", "check", "if", "a", "given", "type", "is", "part", "of", "an", "alias", "group", "."], "add_tokens": "this . agx = { } ; // alias group index this . isAliasOfType = function ( type , alias ) { return ( this . agx [ type ] && this . agx [ type ] [ alias ] ) || false ; } ; var i , len , a ; a = alias [ i ] . split ( '.' ) ; if ( a . length === 2 ) { this . agx [ a [ 0 ] ] = this . agx [ a [ 0 ] ] || { } ; this . agx [ a [ 0 ] ] [ a [ 1 ] ] = true ; }", "del_tokens": "var i , len ;", "commit_type": "add"}
{"commit_tokens": ["Added", "jasmine", "test", "suite", "."], "add_tokens": "jshint : { files : [ 'index.js' , 'Gruntfile.js' , 'src/**/*.js' , 'spec/**/*.js' ] , options : { browser : true } } , banner : '/*! <= % pkg.name %> <%= grunt.template.today(\"yyyy-mm-dd\") %> */\\n' , report : 'gzip' jasmine : { downshow : { src : 'src/**/*.js' , options : { specs : 'spec/*.js' } grunt . loadNpmTasks ( 'grunt-contrib-jasmine' ) ; grunt . registerTask ( 'default' , [ 'jshint' , 'uglify' , 'jasmine' ] ) ;", "del_tokens": "banner : '/*! <= % pkg.name %> <%= grunt.template.today(\"yyyy-mm-dd\") %> */\\n' lint : { all : [ 'src/**/*.js' ] } , jshint : { files : [ 'gruntfile.js' , 'src/**/*.js' ] , options : { browser : true grunt . registerTask ( 'default' , [ 'jshint' , 'uglify' ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "label", "selector", "for", "kubernetes", "components", "to", "soajs", ".", "service", ".", "label"], "add_tokens": "\"soajs.service.label\" : serviceName \"soajs.service.label\" : \"soajs-service\" \"soajs.service.label\" : serviceName \"soajs.service.label\" : serviceName deployer . core . namespaces . pods . get ( { qs : { labelSelector : 'soajs.service.label=' + options . params . serviceName } } , ( error , podsList ) => { if ( onePod . metadata . labels [ 'soajs.service.label' ] === options . params . serviceName && onePod . status . phase === 'Running' ) { labelSelector : 'soajs.service.label=' + options . serviceName", "del_tokens": "\"soajs-app\" : serviceName \"soajs-app\" : \"soajs-service\" \"soajs-app\" : serviceName \"soajs-app\" : serviceName deployer . core . namespaces . pods . get ( { qs : { labelSelector : 'soajs-app=' + options . params . serviceName } } , ( error , podsList ) => { if ( onePod . metadata . labels [ 'soajs-app' ] === options . params . serviceName && onePod . status . phase === 'Running' ) { labelSelector : 'soajs-app=' + options . serviceName", "commit_type": "change"}
{"commit_tokens": ["Fix", "Port", "When", "using", "Webpack"], "add_tokens": "host : API_HOSTNAME ,", "del_tokens": "hostname : API_HOSTNAME ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "loading", "bubble", "on", "AJAX", "appliations"], "add_tokens": "console . error ( \"Your server does not allow storing data locally. Most likely it's because you've opened this page from your hard-drive. For testing you can disable your browser's security or start a localhost environment.\" ) var interactionsHistory = ( localStorageAvailable && JSON . parse ( localStorage . getItem ( interactionsLS ) ) ) || [ ] if ( ! localStorageAvailable ) return if ( ! localStorageAvailable ) return if ( ! turn ) return reply = typeof reply !== \"undefined\" ? reply : \"\" var typeSpeed = live ? this . typeSpeed : 0 live && setTimeout ( function ( ) {", "del_tokens": "console . error ( \"Your server does not allow storing data locally. Most likely it's because you've opened this page from your hard-drive. For testing you can disable your browser's security or start a localhost environment.\" ) ; var interactionsHistory = localStorageAvailable && JSON . parse ( localStorage . getItem ( interactionsLS ) ) || [ ] if ( ! localStorageAvailable ) return if ( ! localStorageAvailable ) return var typeSpeed = live ? typeSpeed : 0 reply = typeof reply !== \"undefined\" ? reply : \"\" setTimeout ( function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["update", "DocmaWeb", "deps", "to", "latest"], "add_tokens": "/ *! dustjs-linkedin - v2.7.5 * Copyright ( c ) 2016 Aleksander Williams ; Released under the MIT License * / \"version\" : \"2.7.5\" this . _isContext = true ; dust . isContext = function ( obj ) { return typeof obj === \"object\" && obj . _isContext === true ; } ; if ( dust . isContext ( context ) ) {", "del_tokens": "/ *! dustjs-linkedin - v2.7.2 * Copyright ( c ) 2015 Aleksander Williams ; Released under the MIT License * / \"version\" : \"2.7.2\" if ( context instanceof Context ) {", "commit_type": "update"}
{"commit_tokens": ["added", "initial", "app", "pool", "size", "to", "2"], "add_tokens": "this . once ( 'return' , function ( _result ) {", "del_tokens": "this . on ( 'return' , function ( _result ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "Promise", "support", "to", "upload", "function"], "add_tokens": "} ) . then ( ( ) => { console . log ( '#winning' ) ; } ) . catch ( err => { console . log ( 'Noooooo! ' + err . message ) ;", "del_tokens": "} , function ( err ) { if ( err ) { console . log ( 'Noooooo! ' + err . message ) ; } else { console . log ( '#winning' ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "iframe", "redirects"], "add_tokens": "var completed = false ; if ( ! completed ) { completed = true ; done ( ) ; } err = err || void 0 ; describe ( \"check can run request on iframe and get async response after an iframe redirect\" , function ( ) { it ( \"run request on iframe and get async response after an iframe redirect\" , function ( done ) { var request = courierGlobal . request ( { appName : \"host\" , reqName : \"Redirect\" } , function ( err , data ) { expect ( err ) . to . be . null ; expect ( data ) . to . be . equal ( \"Going to Redirect...\" ) ; setTimeout ( function ( ) { var request2 = courierGlobal . request ( { appName : \"host\" , reqName : \"Async Ma Shlomha?\" , data : { text : \"TODA!\" } } , function ( err , data ) { expect ( err ) . to . be . null ; expect ( data ) . to . be . equal ( \"TODA!\" ) ; done ( ) ; } ) ; } , 300 ) ; } ) ; expect ( request ) . to . be . undefined ; } ) ; } ) ;", "del_tokens": "done ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "text", "(", "unofficial", ")", "from", "descriptions"], "add_tokens": "this . addHoliday ( dateUtils . midsummerEve ( this . year ) , 'Midsummer Eve' ) ; // unofficial this . addHoliday ( dateUtils . createDate ( this . year , 12 , 24 ) , 'Christmas Eve' ) ; // unofficial", "del_tokens": "this . addHoliday ( dateUtils . midsummerEve ( this . year ) , 'Midsummer Eve' ) ; this . addHoliday ( dateUtils . createDate ( this . year , 12 , 24 ) , 'Christmas Eve (unofficial)' ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "clear", "all", "proc", "EP", "+", "add", "safe", "cloning"], "add_tokens": "clear_all_tasks : function ( req , res , next ) { pm2 . delete ( 'all' , function ( ) { res . send ( { success : true } ) ; } ) ; } , var task_id = req . body . task_id ; var url = 'http://localhost:' + global . _task_meta . list [ task_id ] . port ;", "del_tokens": "var task_file = req . body . task_file ; var task_param = req . body . params ; var url = 'http://localhost:' + global . _task_meta . list [ task_file ] . port ;", "commit_type": "add"}
{"commit_tokens": ["Allowing", "navigation", "with", "Home", "and", "End", "keys"], "add_tokens": "let argument ; case Keys . HOME : method = this . ws_ . goToSlide ; argument = 0 ; break ; case Keys . END : method = this . ws_ . goToSlide ; argument = this . ws_ . maxSlide_ - 1 ; break ; method . call ( this . ws_ , argument ) ;", "del_tokens": "method . call ( this . ws_ ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "some", "JSDoc", "-", "s", "instead", "of", "unformatted", "comments", "."], "add_tokens": "} / ** * Read files recursively * @ param { string } path Path to read * @ param { ReaddirPlusOptions | object } [ userOptions ] * @ param { function ( Error , ReaddirPlusFile [ ] ) } callback * / readdirPlus . ReaddirPlusFile = libVars . ReaddirPlusFile ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Fixing", "potential", "bug", "with", "updateOn", "as", "a", "decorator"], "add_tokens": "const { dispatch , model , updateOn } = props ; const updateOnEventHandler = ( typeof updateOn === 'function' ) const updaterFn = ( typeof updateOn === 'function' ) ? updateOn : identity ; dispatchChange = event => dispatch ( controlChangeMethod ( event ) ) ; eventActions [ updateOnEventHandler ] . push ( updaterFn ( dispatchChange ) ) ;", "del_tokens": "const { dispatch , model } = props ; const updateOn = ( typeof props . updateOn === 'function' ) / ** * updater does not exist . temporarily hard set to identity . possible bug * / // const updaterFn = (typeof updater === 'function') // ? updater // : identity; const updaterFn = identity ; dispatchChange = error => dispatch ( controlChangeMethod ( error ) ) ; eventActions [ updateOn ] . push ( updaterFn ( dispatchChange ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "random", "color", "string", "to", "generate", "random", "colors"], "add_tokens": "function randomIntInc ( low , high ) { return Math . floor ( Math . random ( ) * ( high - low + 1 ) + low ) ; } if ( red == 'random' ) { red = randomIntInc ( 0 , 255 ) ; green = randomIntInc ( 0 , 255 ) ; blue = randomIntInc ( 0 , 255 ) ; } else if ( hex = red . match ( / ^\\#[A-Za-z0-9]{6}$ / ) ) {", "del_tokens": "if ( hex = red . match ( / ^\\#[A-Za-z0-9]{6}$ / ) ) {", "commit_type": "add"}
{"commit_tokens": ["removing", "compression", "since", "it", "seems", "to", "cause", "trouble", "when", "running", "on", "heroku"], "add_tokens": "getRawFile ( request . url , function ( err , data ) {", "del_tokens": "zlib = require ( 'zlib' ) , var DEFLATE = 'deflate' , GZIP = 'gzip' ; var getCompressedFile = async . memoize ( function ( file , compression , cb ) { getRawFile ( file , function ( err , data ) { if ( err ) { return cb ( err ) ; } if ( compression == DEFLATE ) zlib . deflate ( data , cb ) ; else if ( compression == GZIP ) zlib . gzip ( data , cb ) ; else process . nextTick ( cb . bind ( cb , null , data ) ) ; } ) ; } ) ; if ( ( request . headers [ 'accept-encoding' ] || '' ) . match ( / \\bgzip\\b / ) ) { headers [ 'content-encoding' ] = GZIP ; } else if ( ( request . headers [ 'accept-encoding' ] || '' ) . match ( / \\bdeflate\\b / ) ) { headers [ 'content-encoding' ] = DEFLATE ; } getCompressedFile ( request . url , headers [ 'content-encoding' ] , function ( err , data ) {", "commit_type": "remove"}
{"commit_tokens": ["Remove", "deprecated", "gulp", "-", "rimraf"], "add_tokens": "const del = require ( 'del' ) ; gulp . task ( 'clean:tmp' , ( ) => del ( [ './tmp/*' ] ) ) ;", "del_tokens": "'use strict' ; const component = require ( './parseComponentName' ) ; const gulpRimraf = require ( 'gulp-rimraf' ) ; gulp . task ( 'clean:tmp' , ( ) => { gulp . src ( './tmp/' + ( component || '' ) , { read : false } ) . pipe ( gulpRimraf ( ) ) ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "array", "checking", "in", "getQuerySelector", "()"], "add_tokens": "if ( input . constructor !== Array ) {", "del_tokens": "if ( ! input . length ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "new", "set", "implementatio", "(", "still", "not", "in", "use", ")", ".", "Removed", "the", "CallSite", "package", "from", "code", "and", "from", "package", ".", "json", ".", "Changed", "the", "new", "Date", "()", "to", "Date", ".", "now", "()", "-", "should", "be", "much", "faster"], "add_tokens": "'var start = Date.now();\\n' +", "del_tokens": "callsite = require ( 'callsite' ) , 'var start = new Date();\\n' +", "commit_type": "add"}
{"commit_tokens": ["Make", "new", "panels", "appear", "in", "the", "middle", "and", "enable", "navigating", "between", "panels", "by", "scrolling", "as", "opposed", "to", "by", "stacking"], "add_tokens": "layout . width = layout . width || this . _layout . width ; layout . height = layout . height || this . _layout . height ;", "del_tokens": "layout . right = layout . right || this . _layout . right ; layout . bottom = layout . bottom || this . _layout . bottom ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "categories", "not", "showing", "up"], "add_tokens": "showEl . textContent = 'Categories' ; else showEl . style . display = 'none' ;", "del_tokens": "showEl . textContent = 'Category Filters' ; showEl . style . display = 'none' ; else", "commit_type": "fix"}
{"commit_tokens": ["Implement", "date", "format", "for", "ms", "and", "seconds", "since", "epoc"], "add_tokens": "if ( format . endsWith ( 's-epoc' ) ) { const ms = value . getTime ( ) return format === 'ms-epoc' ? String ( ms ) : String ( Math . round ( ms / 1000 ) ) } else { return dateTime . format ( value , format ) }", "del_tokens": "return dateTime . format ( value , format )", "commit_type": "implement"}
{"commit_tokens": ["add", "saturate", "functino", "and", "tests"], "add_tokens": "var ColorCache = { } ; // immutable values-- used for storing values associated with a string / ** * Increase or decrease the saturation of a color . * @ param percent positive values increase saturation , negative values desaturate . * / String . prototype . saturate = function ( percent ) { var hsl = this . toHSL ( ) ; var newHSL = [ hsl [ 0 ] , Math . min ( 100 , Math . max ( 0 , hsl [ 1 ] + percent ) ) , hsl [ 2 ] ] ; return hslToHtmlColor ( newHSL ) ; } ; // HSL 0 to 1 //RGB results from 0 to 255", "del_tokens": "var ColorCache = { } ; // used for storing values associated with a string // HSL 0 to 1 //RGB results from 0 to 255", "commit_type": "add"}
{"commit_tokens": ["Implement", "MessageBox", ".", "Alert", "."], "add_tokens": "\"file\" : \"plugins/org.apache.cordova.MessageBox/www/client.js\" , \"id\" : \"org.apache.cordova.MessageBox.client\" , \"org.apache.cordova.MessageBox\"", "del_tokens": "\"file\" : \"plugins\\\\community.templateplugin\\\\www\\\\client.js\" , \"id\" : \"community.templateplugin.client\" , \"community.templateplugin\"", "commit_type": "implement"}
{"commit_tokens": ["remove", "indent", "inside", "binary", "expressions"], "add_tokens": "_tk . removeInBetween ( node . startToken , node . endToken , [ 'LineBreak' , 'Indent' ] ) ;", "del_tokens": "_tk . removeInBetween ( node . startToken , node . endToken , 'LineBreak' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "Button", "throwing", "error", "when", "no", "onClick", "handler", "is", "provided", ";", "make", "button", "accept", "style", "prop"], "add_tokens": "import { withTheme } from '../../utils' ; it ( 'does not run the onClick callback when disabled' , ( ) => { const spy = jest . fn ( ) ; const button = shallow ( < Button onClick = { spy } text = \"MyCustomText\" disabled / > ) ; button . simulate ( 'click' ) ; expect ( spy . mock . calls . length ) . toEqual ( 0 ) ; } ) ; it ( 'is okay when no onClick callback is provided' , ( ) => { const button = shallow ( < Button text = \"MyCustomText\" disabled / > ) ; // Should not throw button . simulate ( 'click' ) ; } ) ;", "del_tokens": "import { ThemeProvider } from 'styled-components' ; import theme from '../../theme' ; const withTheme = component => < ThemeProvider theme = { theme } > { component } < / ThemeProvider > ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "standalone", "command", "line", "support"], "add_tokens": "ffRemover = require ( './unused-fontface-remover.js' ) , optionsParser = require ( '../options-parser' ) , var options ; options = optionsParser . parse ( system . args . slice ( 1 ) ) ; errorlog ( 'Caught error parsing arguments: ' + ex . message ) ;", "del_tokens": "var standaloneMode = standaloneMode || false ; var ffRemover ; if ( standaloneMode ) { ffRemover = unusedFontfaceRemover ; } else { ffRemover = require ( './unused-fontface-remover.js' ) ; } var parser , parse , usage , options ; // test to see if we are running as a standalone script // or as part of the node module if ( standaloneMode ) { parse = parseOptions ; usage = usageString ; } else { parser = require ( '../options-parser' ) ; parse = parser . parse ; usage = parser . usage ; } options = parse ( system . args . slice ( 1 ) ) ; errorlog ( 'Caught error parsing arguments: ' + ex . message ) ; // the usage string does not make sense to show if running via Node if ( standaloneMode ) { errorlog ( '\\nUsage: phantomjs penthouse.js ' + usage ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "hot", "apply", "methods", "binding"], "add_tokens": "ignoreErrored : true , // true - allows to restore state after errors. onUnaccepted : info => { onDeclined : info => { onErrored : info => {", "del_tokens": "ignoreErrored : true , // true allows to restore state after errors. onUnaccepted ( info ) { onDeclined ( info ) { onErrored ( info ) {", "commit_type": "fix"}
{"commit_tokens": ["Updating", "Grunt", "setup", "and", "converting", "to", "eslint"], "add_tokens": "const Plugin = require ( './Plugin' ) ; const Preprocessor = require ( './Preprocessor' ) ; gzippedFilePaths : [ 'value' , [ ] ] , 'preprocessor:gzip' : [ 'factory' , Preprocessor ] ,", "del_tokens": "var Plugin = require ( './Plugin' ) ; var Preprocessor = require ( './Preprocessor' ) ; 'gzippedFilePaths' : [ 'value' , [ ] ] , 'preprocessor:gzip' : [ 'factory' , Preprocessor ]", "commit_type": "update"}
{"commit_tokens": ["removed", "old", "occurencies", "of", "butter", "engine"], "add_tokens": "var jslardo = require ( './jslardo' ) ; //appendo jslardo all'app express app . jslardo = jslardo ; mongoose . connect ( 'mongodb://localhost/jslardo' ) ; //nota: le route sono importate, prima quelle di jslardo, poi quelle per ciascuno degli oggetti persistenti nel db //route specifiche di jslardo app . jslardo . defineRoutes ( app ) ; //app.jslardo.defineRoute404(app); app . jslardo . errorPage ( res , \"404 not found: \" + req . path ) ; console . log ( \"jslardo server listening on port %d in %s mode\" , app . address ( ) . port , app . settings . env ) ;", "del_tokens": "var butter = require ( './butter' ) ; //appendo butter all'app express app . butter = butter ; mongoose . connect ( 'mongodb://localhost/butter' ) ; //nota: le route sono importate, prima quelle di butter, poi quelle per ciascuno degli oggetti persistenti nel db //route specifiche di butter app . butter . defineRoutes ( app ) ; //app.butter.defineRoute404(app); app . butter . errorPage ( res , \"404 not found: \" + req . path ) ; console . log ( \"Butter server listening on port %d in %s mode\" , app . address ( ) . port , app . settings . env ) ;", "commit_type": "remove"}
{"commit_tokens": ["adds", ".", "only", "tests", "and", "modified", "package", ".", "json", "test", "runs"], "add_tokens": "require ( 'jsdom' ) ; // could throw jsdom = require ( 'mocha-jsdom' ) ; // jsdom is not supported... if ( typeof jsdom === 'function' ) {", "del_tokens": "require ( 'jsdom' ) ; // could throw jsdom = require ( 'mocha-jsdom' ) ; // jsdom is not supported... if ( typeof jsdom === 'function' ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "rest", "/", "spread", "error"], "add_tokens": "const { activeIndex , showMenu } = this . getInitialState ( ) ; activeIndex , showMenu ,", "del_tokens": "... this . getInitialState ( ) ,", "commit_type": "fix"}
{"commit_tokens": ["remove", "access_token", "from", "discussion", "and", "source", "references"], "add_tokens": "// TODO consider returning a URL return uri . replace ( / ^.*\\/ / , '' ) . replace ( / \\?.*$ / , '' ) ;", "del_tokens": "return uri . replace ( / ^.*\\/ / , '' ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "in", "older", "nodes"], "add_tokens": "vinylCjsDeps . dest = ( ) => { if ( vinylCjsDeps . gulp ) return vinylCjsDeps . gulp . dest . apply ( vinylCjsDeps . gulp , arguments ) ;", "del_tokens": "vinylCjsDeps . dest = ( ... params ) => { if ( vinylCjsDeps . gulp ) return vinylCjsDeps . gulp . dest . bind ( vinylCjsDeps . gulp ) ( ... params ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "some", "tests", "for", "route", "-", "tag"], "add_tokens": "frameworks : [ 'mocha' , 'riot' ] , 'karma-electron' , 'karma-riot' '../node_modules/riot/riot.js' , '../dist/route+tag.js' , 'tags/*.tag' , 'specs/core.specs.js' , 'specs/tag.specs.js' 'tags/*.tag' : [ 'riot' ] , '../dist/route-tag.js' : [ 'coverage' ]", "del_tokens": "frameworks : [ 'mocha' ] , 'karma-electron' '../dist/route.js' , 'specs/core.specs.js' '../dist/route.js' : [ 'coverage' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "hasHash", "to", "use", "new", "API"], "add_tokens": "function hasHash ( hash , callback ) { var type = typeCache [ hash ] ; if ( ! type ) return callback ( ) ; }", "del_tokens": "function hasHash ( type , hash , callback ) { }", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "Construct", "API", "coverage", "."], "add_tokens": "var workflow = require ( './workflow' ) ; var batch = require ( './batch' ) ; civicid : civicid , workflow : workflow , batch : batch", "del_tokens": "civicid : civicid", "commit_type": "add"}
{"commit_tokens": ["updated", "generator", "to", "support", "JS", "as", "primary", "type", "and", "coffee", "-", "script", "as", "command", "line", "option"], "add_tokens": "/ * * / var src = {", "del_tokens": "var = {", "commit_type": "update"}
{"commit_tokens": ["Fix", "the", "watching", "of", "the", "template", "files"], "add_tokens": "let absolutePath = File . find ( file ) . path ( ) ; let watcher = chokidar absolutePath , persistent : false watcher . unwatch ( absolutePath ) ; watchFile ( file , callback ) ;", "del_tokens": "file = File . find ( file ) ; chokidar file . path ( ) , persistent : true", "commit_type": "fix"}
{"commit_tokens": ["Use", "can", "-", "event", ".", "on", "to", "listen", "to", "property", "events"], "add_tokens": "canEvent . on . call ( target , eventName || propertyName , handler ) ; return canEvent . off . call ( target , eventName || propertyName , handler ) ;", "del_tokens": "canEvent . addEventListener . call ( target , eventName || propertyName , handler ) ; return canEvent . removeEventListener . call ( target , eventName || propertyName , handler ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "initial", "support", "to", "plugins"], "add_tokens": "plugins : { } , } ;", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "scale", "file", "-", "Implementation", "now", "in", "parser", "scaler", "and", "normalizer"], "add_tokens": "//scale.withdraw(imageStream, withdrawnStream, 4); //scale.reduce(withdrawnStream, reducedStream, 3); //scale.scale8to1bit(reducedStream, scaledStream); //scale.scale8to2bit(reducedStream, scaledStream); //scale.scale8to4bit(reducedStream, scaledStream); //scale.scale8to16bit(reducedStream, scaledStream);", "del_tokens": "var scale = require ( '../utils/scale' ) ; scale . withdraw ( imageStream , withdrawnStream , 4 ) ; scale . reduce ( withdrawnStream , reducedStream , 3 ) ; scale . scale8to1bit ( reducedStream , scaledStream ) ; scale . scale8to2bit ( reducedStream , scaledStream ) ; scale . scale8to4bit ( reducedStream , scaledStream ) ; scale . scale8to16bit ( reducedStream , scaledStream ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", ".", "map", "()", "for", "collection"], "add_tokens": "_Class . prototype . transform = function ( ) { return this . map . apply ( this , arguments ) ; } ; / * * / _Class . prototype . map = function ( value ) {", "del_tokens": "_Class . prototype . transform = function ( value ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "default", "sending", "content", "type", "header", "."], "add_tokens": "// Request header field Content-Type is not allowed by Access-Control-Allow-Headers. // Let's think about later on ;) //this._request.setRequestHeader(\"Content-Type\", this.contentType);", "del_tokens": "this . _request . setRequestHeader ( \"Content-Type\" , this . contentType ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "-", "p", "/", "--", "port", "command", "line", "option", "to", "specify", "port", "to", "run", "on"], "add_tokens": "parser . addArgument ( [ '-p' , '--port' ] , { type : 'int' , default : 8001 , help : 'Port to run on (default: 8001)' , } ) const port = process . env . PORT || args . port", "del_tokens": "const port = process . env . PORT || 8001", "commit_type": "add"}
{"commit_tokens": ["Make", "bottle", "name", "available", "as", "constant", "in", "container", "."], "add_tokens": "; ( function ( undefined ) { it ( 'will not have name if not passed a name parameter' , function ( ) { var bottle = Bottle . pop ( ) ; expect ( bottle . container . BOTTLE_NAME ) . toBe ( undefined ) ; } ) ; it ( 'will make the instance name available when a name is passed' , function ( ) { var bottle = Bottle . pop ( 'Soda' ) ; expect ( bottle . container . BOTTLE_NAME ) . toBe ( 'Soda' ) ; } ) ;", "del_tokens": "; ( function ( ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "docstrings", "in", "jsdoc", "format"], "add_tokens": "// This sample demonstrates how to register a DXL service to receive Request // messages and send Response messages back to an invoking client. // The topic for the service to respond to // Create DXL configuration from file // Create the client // Connect to the fabric, supplying a callback function which is invoked // when the connection has been established // Create service registration object // Add a topic for the service to respond to // Handle the receipt of an incoming service request // Extract information from request // Create the response message // Populate the response payload // Send the response // Register the service with the fabric // Destroy the client - frees up resources so that the application // stops running // If an error did not occur, invoke the service (send a request) // Create the request message // Populate the request payload // Send the request // Handle the response to the request // Destroy the client - frees up resources so that the application // stops running // Display the contents of an error, if one occurred // No error occurred, so extract information from the response", "del_tokens": "if ( error instanceof dxl . MessageError ) { console . log ( 'Registration error code: ' + error . code ) }", "commit_type": "add"}
{"commit_tokens": ["Improve", "module", "loading", "to", "make", "it", "browser", "compatible"], "add_tokens": "( function ( context , factory ) { module . exports = factory ( require ( 'immutable' ) ) ; context . chai . use ( factory ( context . Immutable ) ) ; } ( this , function ( Immutable ) { return function ( chai , utils ) { var Collection = Immutable . Collection ; var IndexedCollection = Immutable . Collection . Indexed ; var KeyedCollection = Immutable . Collection . Keyed ; var SetCollection = Immutable . Collection . Set ; } ) ) ;", "del_tokens": "( function ( ) { module . exports = chaiImmutable ; chai . use ( chaiImmutable ) ; var Immutable = require ( 'immutable' ) ; var Collection = Immutable . Collection ; var IndexedCollection = Immutable . Collection . Indexed ; var KeyedCollection = Immutable . Collection . Keyed ; var SetCollection = Immutable . Collection . Set ; function chaiImmutable ( chai , utils ) { } ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Allow", "an", "execution", "policy", "of", "Bypass"], "add_tokens": "const linesHit = output . filter ( ( line ) => line . includes ( 'Unrestricted' ) || line . includes ( 'RemoteSigned' ) || line . includes ( 'Bypass' ) )", "del_tokens": "const linesHit = output . filter ( ( line ) => line . includes ( 'Unrestricted' ) || line . includes ( 'RemoteSigned' ) )", "commit_type": "allow"}
{"commit_tokens": ["fix", "typo", "on", "sheet", "view", "showGridLines", "option"], "add_tokens": "add ( 'showGridLines' , '0' , model . showGridLines === false ) ; showGridLines : ! ( node . attributes . showGridLines === '0' ) , showGridLines : this . sheetView . showGridLines , showGridLines : this . sheetView . showGridLines ,", "del_tokens": "add ( 'showGridlines' , '0' , model . showGridlines === false ) ; showGridlines : ! ( node . attributes . showGridlines === '0' ) , showGridlines : this . sheetView . showGridlines , showGridlines : this . sheetView . showGridlines ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ARG", "and", "ENV", "name", "val", "rules", "being", "ignored"], "add_tokens": "logger = require ( './logger' ) , _ = require ( 'lodash' ) reference_url : ref_url return _ . contains ( [ 'ARG' , 'ENV' , 'LABEL' ] , cmd ) ;", "del_tokens": "logger = require ( './logger' ) ; reference_url : ref_url if ( cmd === 'LABEL' || cmd === 'ENV' || cmd === 'ARG' ) { return true ; } return false ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "prettier", "&", "update", "eslint", "configuration"], "add_tokens": "const m = function ( code , message ) { this . code = code this . message = message this . stack = new Error ( ) . stack", "del_tokens": "var m = function ( code , message ) { this . code = code this . message = message this . stack = ( new Error ( ) ) . stack", "commit_type": "use"}
{"commit_tokens": ["Fix", "missing", "param", "and", "comma", "in", "uuidPost"], "add_tokens": "\"c('rename','offer-list/'..c('get','offer-name/'..o),\" ,", "del_tokens": "\"c('rename','offer-list/'..c('get','offer-name/'..o)\" ,", "commit_type": "fix"}
{"commit_tokens": ["Updated", "how", "config", "file", "is", "handeled", "and", "better", "documentation", "about", "it"], "add_tokens": "if ( fs . existsSync ( process . cwd ( ) + '/config/images.json' ) ) { config = require ( process . cwd ( ) + '/config/images.json' ) ;", "del_tokens": "if ( fs . existsSync ( __dirname + '/config/images.json' ) ) { config = require ( __dirname + '/config/images.json' ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "demeteorizer", "crashes", "when", "encountering", "invalid", "package", ".", "json"], "add_tokens": "// Let's also test for invalid JSON in the package.json var packageJson ; var isValidJSON = true ; try { packageJson = JSON . parse ( packageData ) ; } catch ( e ) { console . log ( '*** Exception when parsing packageData: ' + e ) ; console . log ( 'packageData path: ' + path . join ( folder , file ) ) ; console . log ( 'packageData: ' + packageData ) ; isValidJSON = false ; } if ( isValidJSON && packageData . length > 0 ) {", "del_tokens": "if ( packageData . length > 0 ) { var packageJson = JSON . parse ( packageData ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "error", "listener", "on", "gulp", "test"], "add_tokens": "} ) ) ;", "del_tokens": "} ) ) . on ( 'error' , function ( err ) { // Make sure failed tests cause gulp to exit non-zero throw err ; } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "playlist", "methods", "&", "documentation", "."], "add_tokens": "this . activatePlaylist = __bind ( this . activatePlaylist , this ) ; this . playlistMoveSong = __bind ( this . playlistMoveSong , this ) ; PlugAPI . prototype . activatePlaylist = function ( playlist_id , callback ) { return this . sendRPC ( \"playlist.activate\" , [ playlist_id ] , callback ) ; } ; PlugAPI . prototype . playlistMoveSong = function ( playlist , song_id , position , callback ) { return this . sendRPC ( \"playlist.media.move\" , [ playlist . id , playlist . items [ position ] , [ song_id ] ] , callback ) ; } ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["remove", "Monitor", "module", "from", "bot"], "add_tokens": "paiScheduler", "del_tokens": "const PAIMonitorModule = require ( '@pai-tech/pai-monitor' ) . Module ; const paiMonitor = new PAIMonitorModule ( ) ; paiScheduler , paiMonitor paiMonitor . config . storage = new PAIModuleConfigStorageFiles ( { filePath : botSettingsFolder + paiMonitor . setModuleName ( ) + '.json' } ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "better", "error", "handling", "of", "negative", "HTTP", "response", "for", "WebJson", "data", "sources"], "add_tokens": "console . log ( str ) ; if ( response . statusCode == 200 ) { callback ( null , JSON . parse ( str ) ) ; } else { callback ( new Error ( response . statusCode + ' - ' http . STATUS_CODES [ response . statusCode ] ) ) ; }", "del_tokens": "console . log ( str ) ; callback ( null , JSON . parse ( str ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "addon", "to", "fix", "failing", "test", "after", "revamp"], "add_tokens": "console . warn ( '\\n\\nWarning: Unable to read asset-manifest.json from build with error: ' + error ) console . warn ( 'Warning: Proceeding without generated manifest; you will need to manually provide a manifest to the Asset Loader Service to load bundles at runtime. If this was intentional you can turn this message off via the `noManifest` flag.\\n\\n' ) ;", "del_tokens": "console . warn ( 'Warning: Unable to read asset-manifest.json from build with error: ' + error ) console . warn ( 'Warning: Proceeding without generated manifest; you will need to manually provide a manifest to the Asset Loader Service to load bundles at runtime. If this was intentional you can turn this message off via the `noManifest` flag.' ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "particleConstructor", "a", "getter", "/", "setter", "."], "add_tokens": "* @ property { Function } _particleConstructor * @ private this . _particleConstructor = Particle ; / ** * The constructor used to create new particles . The default is * the built in Particle class . Setting this will dump any active or * pooled particles , if the emitter has already been used . * @ property { Function } particleConstructor * / Object . defineProperty ( p , \"particleConstructor\" , { get : function ( ) { return this . _particleConstructor ; } , set : function ( value ) { if ( value != this . _particleConstructor ) { this . _particleConstructor = value ; if ( this . _activeParticles . length ) this . _activeParticles . length = 0 ; if ( this . _pool . length ) this . _pool . length = 0 ; } } } ) ;", "del_tokens": "* @ property { Function } particleConstructor this . particleConstructor = Particle ;", "commit_type": "make"}
{"commit_tokens": ["Added", "render", "from", "offset", "support"], "add_tokens": "node . adjustContentLength ( op . data . length , true ) ; node . emit ( update , this . cursor ) ; node . adjustContentLength ( - op . data . length , true ) ; node . emit ( update , this . cursor ) ;", "del_tokens": "node . adjustContentLength ( op . data . length ) ; node . adjustContentLength ( - op . data . length ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "calculation", "of", "the", "zoom", "ratio"], "add_tokens": "var newDuration = duration * ( 2 - zoom ) ;", "del_tokens": "var newDuration = duration / zoom ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "created", "time", "to", "PDF"], "add_tokens": "var created = new Date ( ) ; var year = created . getFullYear ( ) ; var month = ( created . getMonth ( ) + 1 ) ; var day = created . getDate ( ) ; var hour = created . getHours ( ) ; var minute = created . getMinutes ( ) ; var second = created . getSeconds ( ) ; out ( '/CreationDate (D:' + sprintf ( '%02d%02d%02d%02d%02d%02d' , year , month , day , hour , minute , second ) + ')' ) ;", "del_tokens": "out ( '/CreationDate (D:20091012101212)' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "by", "adding", "a", "missing", "space", "."], "add_tokens": "* @ param { Function } ` ` Optional . Function to transform commend objects ( AST tokens )", "del_tokens": "* @ param { Function } ` ` Optional . Functionto transform commend objects ( AST tokens )", "commit_type": "fix"}
{"commit_tokens": ["updates", "test", "to", "handle", "new", "Native", "Events", "as", "the", "floor", "each", "number"], "add_tokens": "let browsers = [ 'Chrome' ] ; // for local builds pattern : 'test/**/*.spec.js' ,", "del_tokens": "let browsers = [ 'Chrome' , 'Firefox' ] ; // for local builds pattern : 'test/**/*.js' ,", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "bug", "in", "migrating", "to", "JS"], "add_tokens": "jd = jd || 1", "del_tokens": "jd = jd || 0", "commit_type": "fix"}
{"commit_tokens": ["Added", "custom", "validators", "to", "array", "basic", "type"], "add_tokens": "// Generated from validation language // Custom validations { { customValidations } } // Execute all field level validations // // Generate custom validation functions // --------------------------------------------- // Do we have custom validations var customValidationsString = object . options . custom ? Utils . generateCustomValidations ( object . options . custom , context , ruleIndex , index ) : '' ; validations : validation , customValidations : customValidationsString", "del_tokens": "validations : validation", "commit_type": "add"}
{"commit_tokens": ["Improve", "code", "consistency", "when", "handling", "-", "abc", "case", "."], "add_tokens": "if ( checkAllAliases ( key , flags . nargs ) ) { setArg ( letters [ j ] , next ) next = args [ i + 1 ] if ( next && ! / ^(-|--)[^-] / . test ( next ) && setArg ( key , next ) } else if ( next && / true|false / . test ( next ) ) { setArg ( key , next )", "del_tokens": "if ( checkAllAliases ( letters [ j ] , flags . nargs ) ) { setArg ( letters [ j ] , arg . slice ( j + 2 ) ) if ( args [ i + 1 ] && ! / ^(-|--)[^-] / . test ( args [ i + 1 ] ) && setArg ( key , args [ i + 1 ] ) } else if ( args [ i + 1 ] && / true|false / . test ( args [ i + 1 ] ) ) { setArg ( key , args [ i + 1 ] )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "for", "consumer", "flowing", "mode"], "add_tokens": "var e = LibrdKafkaError . create ( errorCode ) ; this . emit ( 'error' , e ) ; throw e ;", "del_tokens": "throw LibrdKafkaError . create ( errorCode ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "running", "npm", "install", "from", "create", "-", "react", "-", "app", "command", "and", "init", "script", "on", "Windows"], "add_tokens": "var spawn = require ( 'cross-spawn' ) ;", "del_tokens": "var spawn = require ( 'child_process' ) . spawn ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "serious", "bug", "isOk", "/", "isSome", "returns", "true", "if", "their", "input", "is", "not", "so", "."], "add_tokens": "require ( './Undefinable/test_type_guard' ) ; require ( './PlainOption/test_type_guard' ) ; require ( './PlainResult/test_type_guard' ) ;", "del_tokens": "require ( './Undefinable/test_type_guard' ) ;", "commit_type": "fix"}
{"commit_tokens": ["changing", "color", "for", "better", "accessibility", "in", "linux", "terminals", "(", "dark", "mode", ")"], "add_tokens": "console . trace ( chalk . green ( '\\n' + JSON . stringify ( msg , null , 2 ) ) ) ; console . trace ( chalk . green ( msg ) ) ;", "del_tokens": "console . trace ( chalk . bgGreen . white ( '\\n' + JSON . stringify ( msg , null , 2 ) ) ) ; console . trace ( chalk . bgGreen . white ( msg ) ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "bad", "call", "to", ":", "valid", "fix", "select", "delegation", "in", "legacy", "browsers"], "add_tokens": "return ! selectors [ ':valid' ] ( el ) ; ; return _select ( sel ) ;", "del_tokens": "return ! selectors [ 'valid' ] ( el ) ; // return results.sort(order); if ( ~ sel . indexOf ( ' ' ) ) return _select ( sel ) ; return _select ( sel ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "missing", "some", "coverage", "for", "NO_DEBUG"], "add_tokens": "EventEmitter . setDebugLevel ( EventEmitter . DEBUG_THROW ) ; slowEmitTest ( ) ; quickEmitTest ( ) ; EventEmitter . setDebugLevel ( EventEmitter . NO_DEBUG ) ; slowEmitTest ( ) ; quickEmitTest ( ) ;", "del_tokens": "EventEmitter . setDebugLevel ( EventEmitter . DEBUG_THROW ) ; EventEmitter . setDebugLevel ( EventEmitter . DEBUG_THROW ) ; slowEmitTest ( ) ; EventEmitter . setDebugLevel ( EventEmitter . NO_DEBUG ) ; slowEmitTest ( ) ; EventEmitter . setDebugLevel ( EventEmitter . DEBUG_THROW ) ; quickEmitTest ( ) ; EventEmitter . setDebugLevel ( EventEmitter . NO_DEBUG ) ; quickEmitTest ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "whitespace", "was", "introduced", "to", "the", "end", "of", "whared", "component", "names", "from", "a", "faulty", "regex", "expression", "."], "add_tokens": "name = str . replace ( / .*<element[^>]*name=([\"'])?([^'\">\\s]+)\\1[^<>]*>.* / ig , '$2' ) ;", "del_tokens": "name = str . replace ( / .*<element[^>]*name=([\"'])?([^'\">\\s]+)\\1[^<>]*>.*> / ig , '$2' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "unwrapping", "null", "/", "undefined", "and", "primitives"], "add_tokens": "city : String , state : String describe ( 'Unwrapping' , function ( ) { it ( 'should allow unwrapping' , function ( ) { var address = new Address ( { city : 'Durham' , state : 'NC' } ) ; var addressData = Model . unwrap ( address ) ; expect ( addressData . city ) . to . equal ( 'Durham' ) ; expect ( addressData . state ) . to . equal ( 'NC' ) ; } ) ; it ( 'should allow unwrapping null/undefined' , function ( ) { expect ( Model . unwrap ( null ) ) . to . equal ( null ) ; expect ( Model . unwrap ( undefined ) ) . to . equal ( undefined ) ; } ) ; it ( 'should allow unwrapping primitive' , function ( ) { expect ( Model . unwrap ( 1 ) ) . to . equal ( 1 ) ; expect ( Model . unwrap ( 'test' ) ) . to . equal ( 'test' ) ; expect ( Model . unwrap ( false ) ) . to . equal ( false ) ; } ) ; } ) ;", "del_tokens": "'city' : String , 'state' : String", "commit_type": "allow"}
{"commit_tokens": ["Add", "empty", "array", "fallback", "to", "regex", "match"], "add_tokens": "regexResults = fileContent . match ( csDocRegex ) || [ ] ; regexResults = fileContent . match ( jsDocRegex ) || [ ] ;", "del_tokens": "regexResults = fileContent . match ( csDocRegex ) ; regexResults = fileContent . match ( jsDocRegex ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "the", "WatcherStore", "and", "the", "computedStream"], "add_tokens": "var CurrentProjectStore = require ( './mocks/CurrentProjectStore' ) var ExperimentStore = require ( './mocks/ExperimentStore' )", "del_tokens": "class CurrentProjectStore extends Store { initialize ( ) { this . state = Immutable . Map ( { } ) this . bindActions ( 'changeCurrentProject' , this . __changeCurrentProject ) } __changeCurrentProject ( payload ) { this . setState ( 'id' , payload . project . id ) } } class ExperimentStore extends Store { initialize ( ) { this . state = Immutable . Map ( { } ) this . bindActions ( 'experimentsFetched' , this . __loadExperiments ) } __loadExperiments ( payload ) { var experiments = payload . experiments ; this . state = this . state . withMutations ( state => { experiments . forEach ( exp => { state . set ( exp . id , exp ) } ) } ) } }", "commit_type": "implement"}
{"commit_tokens": ["Added", "config", "generator", "command", "config", "flag"], "add_tokens": "var create = function ( config ) { config . tunnel = config . tunnel . replace ( \"<port>\" , config . port ) ; tunnel = exec ( config . tunnel ) ;", "del_tokens": "config = require ( \"./config\" ) , var create = function ( ) { tunnel = exec ( 'pagekite.py ' + program . port + ' ' + config . tunnellink ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "sample", "project", "copying", "in", "tests"], "add_tokens": "var walkTree = require ( '../lib/walk_cached_sync' ) ; var symlinkOrCopy = require ( 'symlink-or-copy' ) . sync ; var sampleFiles = walkTree ( sampleProject ) . paths ; var file ; for ( file in sampleFiles ) { if ( sampleFiles [ file ] . isDirectory ) { fs . mkdirSync ( srcDir + '/' + file ) ; continue ; } symlinkOrCopy ( sampleProject + '/' + file , srcDir + '/' + file ) ;", "del_tokens": "var copyRecursive = require ( 'symlink-or-copy/node_modules/copy-dereference' ) . sync ; var stats , file ; var entries = fs . readdirSync ( sampleProject ) . sort ( ) ; for ( var i = 0 ; i < entries . length ; i ++ ) { copyRecursive ( sampleProject + '/' + entries [ i ] , srcDir + '/' + entries [ i ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "plantuml", "lang", "(", "gitlab", "style", ")"], "add_tokens": "umls = page . content . match ( / ```(uml|puml|plantuml)((.*[\\r\\n]+)+?)?``` / igm ) ; umls [ i ] . replace ( / ```(uml|puml|plantuml) / , '{% uml %}' ) . replace ( / ``` / , '{% enduml %}' ) ) ;", "del_tokens": "umls = page . content . match ( / ^```uml((.*[\\r\\n]+)+?)?```$ / igm ) ; umls [ i ] . replace ( / ^```uml / , '{% uml %}' ) . replace ( / ```$ / , '{% enduml %}' ) ) ; } } // Get all code texts umls = page . content . match ( / ^```puml((.*[\\r\\n]+)+?)?```$ / igm ) ; // Begin replace if ( umls instanceof Array ) { for ( var i = 0 , len = umls . length ; i < len ; i ++ ) { page . content = page . content . replace ( umls [ i ] , umls [ i ] . replace ( / ^```puml / , '{% uml %}' ) . replace ( / ```$ / , '{% enduml %}' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", ".", "csv", "/", ".", "tsv", "to", "the", "list", "of", "text", "files"], "add_tokens": "asText : [ / (\\.txt|\\.json|\\.csv|\\.tsv|\\.xml|\\.htaccess|\\.config|\\.cfg|\\.html|\\.htm|\\.xhtml|\\.md|\\.sh)$ / ] ,", "del_tokens": "asText : [ / (\\.txt|\\.json|\\.xml|\\.htaccess|\\.config|\\.cfg|\\.html|\\.htm|\\.xhtml|\\.md|\\.sh)$ / ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "test", "typo", ".", "Make", "jshint", "all", "the", "tests", ".", "Run", "tests", "without", "globally", "installed", "tape", "-", "run", "."], "add_tokens": "t . ok ( instance2 . called , 'Legacy stamp should compose enclosures with new.' ) ;", "del_tokens": "t . ok ( instance1 . called , 'Legacy stamp should compose enclosures with new.' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changing", "length", "prefixing", "to", "separator", "for", "JSON", "TS"], "add_tokens": "const message = \"\"; const message = \" SignalR\";", "del_tokens": "const message = \"Hi\" ; const message = \"Hello SignalR\" ;", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "errors", "."], "add_tokens": "if ( values instanceof Error ) { return new_from_error ( values , collection ) / ** * Generate a payload from an error object . * @ param { Object } values_object to get payload for . * @ param { Waterline . Collection } collection to base this conversion on . * @ return { Object } JSON API compliant payload with values set . * / function new_from_error ( values , collection ) { // For generating an error id. var uuid = require ( \"uuid\" ) var actual_values = { id : values . id || uuid . v4 ( ) , error : values , is_error : true } // Return the created JSON API compliant resource var data = new JSONAPIModel ( actual_values , collection ) // Validate the payload before returning it. This throws hard. validator . validate ( data . toJSON ( ) ) return data module . exports . new_from_error = new_from_error", "del_tokens": "if ( values . isBoom ) { return new_from_boom ( values , collection ) function new_from_boom ( values , collection ) { module . exports . new_from_boom = new_from_boom", "commit_type": "add"}
{"commit_tokens": ["Fix", "Typo", "From", "Linting", "Fix"], "add_tokens": "sinon . spy ( console , 'error' ) ; it ( 'Should send debug logs to console.debug' , function ( ) { it ( 'Should send info logs to console.info' , function ( ) { it ( 'Should send warn logs to console.warn' , function ( ) { it ( 'Should sent error logs to console.error' , function ( ) {", "del_tokens": "sinon . spy ( console , 'error\"' ) ; it ( 'Should have a default logger with level set to error' , function ( ) { it ( 'Should have a default logger with level set to error' , function ( ) { it ( 'Should have a default logger with level set to error' , function ( ) { it ( 'Should have a default logger with level set to error' , function ( ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "dev", "-", "form", "to", "docs", "and", "test"], "add_tokens": "{ id : 'dev-text' } , { id : 'dev-form' }", "del_tokens": "{ id : 'dev-text' }", "commit_type": "add"}
{"commit_tokens": ["moved", "to", "for", "..", "of"], "add_tokens": "for ( let element of elements ) { await element . preRender ( globals ) ; } for ( let $node of $nodes ) { } for ( let element of elements ) { await element . postRender ( globals ) ; }", "del_tokens": "elements . forEach ( async ( element ) => await element . preRender ( globals ) ) $nodes . forEach ( async ( $node ) => { } ) return elements . forEach ( async ( element ) => await element . postRender ( globals ) )", "commit_type": "move"}
{"commit_tokens": ["Use", "relative", "paths", "for", "modules"], "add_tokens": "var logic = './logic/' + name + '.js' ;", "del_tokens": "var logic = path . join ( __dirname , 'logic/' + name + '.js' )", "commit_type": "use"}
{"commit_tokens": ["Add", ".", "location", "option", "to", "both", "SW", "&", "AppCache"], "add_tokens": "this . location = options . publicLocation ; this . output = ( options . output || options . directory ) . replace ( / ^\\/ / , '' ) . replace ( / \\/$ / , '' ) + '/' ; this . basePath = ( 0 , _miscUtils . pathToBase ) ( this . output , true ) ; var path = this . output + this . name ; var location = this . location || ( plugin . publicPath || '' ) + this . output ; location : location ,", "del_tokens": "this . directory = options . directory . replace ( / ^\\/ / , '' ) . replace ( / \\/$ / , '' ) + '/' ; this . basePath = ( 0 , _miscUtils . pathToBase ) ( this . directory , true ) ; var path = this . directory + this . name ; directory : plugin . publicPath + this . directory ,", "commit_type": "add"}
{"commit_tokens": ["fixing", "compat", "issue", "with", "latest", "version", "of", "request"], "add_tokens": "options . uri = url . format ( uri ) ;", "del_tokens": "options . url = url . format ( uri ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "more", "examples", "with", "additonal", "bugfixes"], "add_tokens": "// Connect to a local Selenium stand-alone server and connect to firefox in synchronous mode. // Prepare access to objects // Navigate to the example homepage // Get the text of the title element and assert that the title is correct // Click on the header - only for demo; doesn't make much sense here // Click on a specific coordinate within the window - again just for demo purposes // Close browser", "del_tokens": "// Set url and assert a header-text // Click on element // Click on a specific coordinate", "commit_type": "add"}
{"commit_tokens": ["add", "immutability", "helpers", "to", "core"], "add_tokens": "var update = require ( 'react/lib/update' ) ; var component = require ( './lib/renderables/component' ) ; var view = require ( './lib/renderables/view' ) ; var modelView = require ( './lib/renderables/modelView' ) ; var collectionView = require ( './lib/renderables/collectionView' ) ; var model = require ( './lib/data/model' ) ; var collection = require ( './lib/data/collection' ) ; var classNames = require ( 'classnames' ) ; component : component , view : view , modelView : modelView , collectionView : collectionView , model : model , collection : collection , classes : classNames , update : update ,", "del_tokens": "component : require ( './lib/renderables/component' ) , view : require ( './lib/renderables/view' ) , modelView : require ( './lib/renderables/modelView' ) , collectionView : require ( './lib/renderables/collectionView' ) , model : require ( './lib/data/model' ) , collection : require ( './lib/data/collection' ) , classes : require ( 'classnames' ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "socket", "io", "to", "server"], "add_tokens": "let io ; io . emit ( 'reload' ) ; io = require ( 'socket.io' ) ( httpServer ) ;", "del_tokens": "console . log ( 'reloadBrowser' ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "long", "lines", "for", "do", "and", "for", "loops"], "add_tokens": "group ( concat ( [ '} while (' , group ( concat ( [ indent ( concat ( [ softline , handleNode ( node . test ) ] ) ) , softline ] ) ) , ');' ] ) ) group ( concat ( [ indent ( concat ( [ softline , group ( concat ( node . init . map ( init => handleNode ( init ) ) ) ) , softline , group ( concat ( [ concat ( node . test . map ( test => handleNode ( test ) ) ) , ';' ] ) ) , softline , group ( concat ( node . increment . map ( increment => handleNode ( increment ) ) ) ) ] ) ) , softline , ') {' ] ) ) ,", "del_tokens": "group ( concat ( [ '} while (' , handleNode ( node . test ) , ');' ] ) ) concat ( node . init . map ( init => handleNode ( init ) ) ) , concat ( node . test . map ( test => handleNode ( test ) ) ) , ';' , concat ( node . increment . map ( increment => handleNode ( increment ) ) ) , ') {' ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "module", "resolution", "for", "npm", "-", "link", "d", "packages"], "add_tokens": "] . map ( function ( p ) { return require . resolve ( 'babel-preset-' + p ) } ) , ] . map ( function ( p ) { return require . resolve ( 'babel-plugin-' + p ) } ) ,", "del_tokens": "] , ] ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "null", "pointer", "when", "scope", ".", "treeData", "hasn", "t", "been", "initialized", "yet"], "add_tokens": "function jsTreeCtrl ( ) { if ( arraySource ) { var array = angular . isFunction ( arraySource ) ? arraySource ( ) : arraySource ; for ( var i = 0 , n = array . length ; i < n ; i ++ ) { el = array [ i ] ; token = tokenFn ( el ) ; map [ token ] = el ; result . push ( token ) ; } nodesWatcher = controller . changeWatcher ( scope . treeData , controller . nodesFingerprint ) ;", "del_tokens": "function jsTreeCtrl ( $scope ) { this . nodes = $scope . treeData ; var array = angular . isFunction ( arraySource ) ? arraySource ( ) : arraySource ; for ( var i = 0 , n = array . length ; i < n ; i ++ ) { el = array [ i ] ; token = tokenFn ( el ) ; map [ token ] = el ; result . push ( token ) ; nodesWatcher = controller . changeWatcher ( controller . nodes , controller . nodesFingerprint ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "unnecessary", "JSON", ".", "stringify"], "add_tokens": "errMsg = util . format ( 'DS API %s (Error Code: %s) Error:\\n %s' , apiName , json . errorCode , json . message ) ;", "del_tokens": "errMsg = util . format ( 'DS API %s (Error Code: %s) Error:\\n %s' , apiName , json . errorCode , JSON . stringify ( json . message ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "it", "work", "under", "Mac", "OS", "X"], "add_tokens": "var pcsc = require ( './lib/node-pcsc' ) ;", "del_tokens": "var pcsc = require ( 'node-pcsc' ) ;", "commit_type": "make"}
{"commit_tokens": ["Removing", "behaviors", "from", "the", "app", "."], "add_tokens": "'</div>' +", "del_tokens": "'</div><br>' + '<button type=\"button\" class=\"btn btn-info btn-block\" ng-click=\"\"><i class=\"glyphicon glyphicon-plus-sign\"></i> Add Behavior</button>' +", "commit_type": "remove"}
{"commit_tokens": ["Fix", "dist", "folder", "tree", "+", "add", "tests", "to", "avoid", "breaking", "that", "part", "."], "add_tokens": "} , // Unit tests. nodeunit : { tests : [ 'test/*_test.js' ] grunt . registerTask ( 'test' , [ 'dist' , 'nodeunit' ] ) ;", "del_tokens": "grunt . registerTask ( 'test' , [ 'dist' ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "problem", "with", "removing", "listings"], "add_tokens": "const name = listing . intent == 0 ? this . schema . getName ( SKU . fromString ( listing . sku ) ) : null ; if ( listing . intent == 0 && name === this . schema . getName ( SKU . fromString ( v . sku ) ) ) {", "del_tokens": "const name = this . schema . getName ( SKU . fromString ( listing . sku ) ) ; if ( listing . intent == 0 && name === v . sku ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "library", "creation", "to", "example"], "add_tokens": "scene . remove ( library ) ; scene . add ( newLibrary ) ; camera . setParent ( newLibrary ) ;", "del_tokens": "scene . add ( library ) ; camera . setParent ( library ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "retry", "and", "agent", "logic", "..."], "add_tokens": "test ( \"tries 6 times, delayed\" , function ( ) { assert ( getInternalErrorCount < 6 , \"Shouldn't have completed 6 yet!\" ) ; assert ( getInternalErrorCount === 6 , \"expected 6 retries\" ) ; assert ( getConnectionErrorCount < 6 , \"Shouldn't have completed 6 yet!\" ) ; assert ( getConnectionErrorCount === 6 , \"expected 6 retries\" ) ;", "del_tokens": "test ( \"tries 5 times, delayed\" , function ( ) { assert ( getInternalErrorCount < 5 , \"Shouldn't have completed 5 yet!\" ) ; assert ( getInternalErrorCount === 5 , \"expected 5 retries\" ) ; assert ( getConnectionErrorCount < 5 , \"Shouldn't have completed 5 yet!\" ) ; assert ( getConnectionErrorCount === 5 , \"expected 5 retries\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "new", "tableview", "layout", "type", ":", "titled", "list"], "add_tokens": "$ ( actionSheetID ) . css ( \"right: 0; bottom: 0; left: 0;\" ) ; if ( window . innerWidth > window . innerHeight ) { $ ( actionSheetID ) . css ( \"right: 0; bottom: 0; left: 0; -webkit-transform: translate3d(0,70px,0);\" ) ; } else { $ ( actionSheetID ) . css ( \"right: 0; bottom: 0; left: 0; -webkit-transform: translate3d(0,0,0);\" ) ; }", "del_tokens": "$ ( actionSheetID ) . css ( \"right: 0; bottom: -90px; left: 0;\" ) ;", "commit_type": "add"}
