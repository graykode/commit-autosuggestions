{"commit_tokens": ["Added", "some", "more", "yardoc", "documentation", "."], "add_tokens": "# # This palette supports decoding colors from a palette if an explicit palette is provided # in a PNG datastream, and it supports encoding colors to an explicit matrix. # # @see ChunkyPNG::Pixel # Builds a palette instance from a PLTE chunk and optionally a tRNS chunk", "del_tokens": "# Builds a pelette instance from a PLTE chunk and optionally a tRNS chunk", "commit_type": "add"}
{"commit_tokens": ["remove", "warnings", "by", "using", "_id", "instead", "of", "id"], "add_tokens": "\"#{association_name.to_s.gsub(/^_/, '').singularize.camelize}#{parent.class.name.camelize}#{parent._id}\"", "del_tokens": "\"#{association_name.to_s.gsub(/^_/, '').singularize.camelize}#{parent.class.name.camelize}#{parent.id}\"", "commit_type": "remove"}
{"commit_tokens": ["Make", "test", "more", "resilient", "to", "platform", "changes", "."], "add_tokens": "let ( :distribution ) { Pkgr :: Distributions :: Debian . new ( \"ubuntu-precise\" ) } builder . stub ( :source_dir => dir , :distribution => distribution )", "del_tokens": "builder . stub ( :source_dir => dir )", "commit_type": "make"}
{"commit_tokens": ["Implement", "atomic", "option", "for", "CLI#output", "."], "add_tokens": "# @option options [Boolean] :atomic (false) provides a # pseudo-atomic mode for transcoded output. If true, the # transcode will go into a temporary file and only be copied to # the specified filename if it completes. The temporary filename # is the target filename with `.handbrake` appended. Any # `:overwrite` checking will be applied to the target filename # both before and after the transcode happens (the temporary # file will always be overwritten). This option is intended to # aid in writing automatically resumable batch scripts. atomic = options . delete :atomic interim_filename = if atomic \"#{filename}.handbrake\" else filename end run ( '--output' , interim_filename ) if filename != interim_filename replace = if File . exist? ( filename ) trace \"#{filename.inspect} showed up during transcode\" case overwrite when false raise FileExistsError , filename when :ignore trace \"- will leave #{filename.inspect} as is; copy #{interim_filename.inspect} manually if you want to replace it\" false else trace '- will replace with new transcode' true end else true end FileUtils . mv interim_filename , filename if replace end", "del_tokens": "run ( '--output' , filename )", "commit_type": "implement"}
{"commit_tokens": ["Add", "customer", "model", "and", "add", "some", "specs", "."], "add_tokens": "require 'active_model' require 'retentiongrid/version' require 'retentiongrid/api' require 'retentiongrid/customer' require 'retentiongrid/order'", "del_tokens": "require \"retentiongrid/version\" require \"retentiongrid/api\" require \"retentiongrid/order\"", "commit_type": "add"}
{"commit_tokens": ["Add", "Airbrake", "support", "for", "failed", "jobs", "."], "add_tokens": "def self . run_hooks_for ( name , * args ) hooks . each { | h | h . call ( * args ) } unless hooks . nil? || hooks . empty?", "del_tokens": "def self . run_hooks_for ( name ) hooks . each ( & :call ) unless hooks . nil? || hooks . empty?", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "for", "numeric", "validator"], "add_tokens": "opts [ :precision ] = property . precision opts [ :scale ] = property . scale", "del_tokens": "opts [ :precision ] = property . precision if property . precision > 0 opts [ :scale ] = property . scale if property . scale != 10", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "attr_readers", "to", "Component", "and", "Context"], "add_tokens": "let ( :data ) do <<-EOS let ( :component ) { QML :: Component . new engine , data : data } describe '#data' do it 'returns its data' do expect ( component . data ) . to eq data end end describe '#engine' do it 'returns its engine' do expect ( component . engine ) . to eq engine end end let ( :path ) { QML :: ROOT_PATH + 'spec/assets/testobj.qml' } let ( :component ) { QML :: Component . new engine , path : path } describe '#path' do it 'returns its path' do expect ( component . path ) . to eq path end end", "del_tokens": "let ( :component ) do QML :: Component . new engine , data : <<-EOS let ( :component ) do QML :: Component . new engine , path : QML :: ROOT_PATH + 'spec/assets/testobj.qml' end", "commit_type": "add"}
{"commit_tokens": ["Add", "NOTICE", ".", "rdoc", "file", ".", "[", "admin", "]"], "add_tokens": "require 'detroit/tool' # Copyright (c) 2011 Rubyworks # # This program is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation, either version 3 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program. If not, see <http://www.gnu.org/licenses/>.", "del_tokens": "# Copyright (c) 2011 Rubyworks # # This program is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation, either version 3 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program. If not, see <http://www.gnu.org/licenses/>. require 'detroit/tool'", "commit_type": "add"}
{"commit_tokens": ["Adding", "Machined", "::", "Initializable", "to", "help", "organize", "the", "initialization", "process"], "add_tokens": "require \"active_support/core_ext/hash/reverse_merge\" @machined ||= Machined :: Environment . new ( config . reverse_merge ( :skip_bundle => true ) )", "del_tokens": "@machined ||= Machined :: Environment . new ( config )", "commit_type": "add"}
{"commit_tokens": ["update", "AttrDeprecated", "to", "use", "a", "Set", "object", "to", "prevent", "duplicate", "attributes"], "add_tokens": "require \"active_model/deprecated_attribute_set\" require 'active_support/concern' extend ActiveSupport :: Concern included do class_attribute :_deprecated_attributes , instance_writer : false attr_names = DeprecatedAttributeSet . new ( attr_names . compact ) self . _deprecated_attributes ||= DeprecatedAttributeSet . new # Taking the difference of the two sets ensures we don't deprecate the same attribute more than once ( attr_names - _deprecated_attributes ) . each do | attribute | set_attribute_as_deprecated attribute self . _deprecated_attributes += attr_names def deprecated_attributes _deprecated_attributes . to_a #require \"active_record/\"", "del_tokens": "require 'active_support' def self . included ( base ) base . send :extend , ClassMethods @@attrs_deprecated = [ ] @@attrs_deprecated = attr_names @@attrs_deprecated . each do | original_attr_name | attributes = [ original_attr_name , \"#{original_attr_name}=\" . to_sym ] attributes . each do | attribute | set_attribute_as_deprecated attribute end def attrs_deprecated @@attrs_deprecated if instance_methods . include? ( original_getter . to_sym ) remove_method original_getter . to_sym end include AttrDeprecated", "commit_type": "update"}
{"commit_tokens": ["Moving", "files", "to", "reflect", "class", "names", "."], "add_tokens": "require 'sequel/schema/db_column_builder'", "del_tokens": "require 'sequel/schema/db_column_schema_parser'", "commit_type": "move"}
{"commit_tokens": ["Added", "ability", "to", "define", "attributes", "via", "a", "block"], "add_tokens": "VERSION = \"0.0.5\"", "del_tokens": "VERSION = \"0.0.4\"", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "thor", "gem", "dependency"], "add_tokens": "method_option \"app\" , method_option \"environment\" , method_option \"path\" ,", "del_tokens": "option \"app\" , option \"environment\" , option \"path\" ,", "commit_type": "add"}
{"commit_tokens": ["allow", "--", "help", "or", "-", "h", "at", "the", "end", "of", "the", "command"], "add_tokens": "class CLI < Command", "del_tokens": "class CLI < Thor", "commit_type": "allow"}
{"commit_tokens": ["Fix", "bug", "with", "Stack", "level", "to", "deep"], "add_tokens": "UnobtrusiveDatePicker :: DateTimePickerSelector . const_get ( meridian . upcase . to_sym )", "del_tokens": "ActionView :: Helpers :: DateTimeSelector . const_get ( meridian . upcase . to_sym )", "commit_type": "fix"}
{"commit_tokens": ["move", "to", "carrierwave", "-", "mongoid", "(", "last", "version", "of", "carrierwave", "for", "mongoid", ")", "+", "fix", "the", "broken", "tests", "suite", "about", "the", "file", "field", "type"], "add_tokens": "@project . tasks_custom_fields . build ( :label => 'Screenshot' , :_alias => 'screenshot' , :kind => 'File' )", "del_tokens": "@project . task_custom_fields . build ( :label => 'Screenshot' , :_alias => 'screenshot' , :kind => 'File' )", "commit_type": "move"}
{"commit_tokens": ["updating", "the", "gemspec", "for", "including", "the", "MIT", "license", "info"], "add_tokens": "VERSION = \"0.0.2.b3\" # Current VERSION of Cadenero", "del_tokens": "VERSION = \"0.0.2.b2\" # Current VERSION of Cadenero", "commit_type": "update"}
{"commit_tokens": ["Allow", "setting", "a", "different", "file", "search", "class"], "add_tokens": "class AkubraSystemFileResolver < AbstractFileSystemResolver", "del_tokens": "class AkubraSystemFileResolver def find ( id ) Riiif :: File . new ( path ( id ) ) end def path ( id ) search = pattern ( id ) Dir . glob ( search ) . first || raise ( ImageNotFoundError , search ) end", "commit_type": "allow"}
{"commit_tokens": ["implemented", "first", "version", "for", "unique", "check", "on", "controller", "level", "."], "add_tokens": "impressionist :actions => [ :show , :index ] , :unique => [ :action_name , :impressionable_id ]", "del_tokens": "impressionist :actions => [ :show , :index ]", "commit_type": "implement"}
{"commit_tokens": ["add", "coverage", "task", "to", "Rakefile"], "add_tokens": "if ENV [ 'COVERAGE' ] == '1' require 'simplecov' SimpleCov . start do add_filter %r{ ^/test/ } end", "del_tokens": "require 'simplecov' SimpleCov . start do add_filter %r{ ^/test/ }", "commit_type": "add"}
{"commit_tokens": ["Added", "documentation", "(", "mainly", "to", "dbus", ".", "rb", ")", "."], "add_tokens": "# dbus/introspection.rb - module containing a low-level D-Bus introspection implementation # # Copyright (C) 2007 Arnaud Cornet, Paul van Tilburg # # FIXME: license # = D-Bus interface class # # This class is the interface descriptor that comes from the XML we # parsed from the Introspect() call.", "del_tokens": "# This class is the interface descriptor that comes from the XML we parsed # from the Introspect() call", "commit_type": "add"}
{"commit_tokens": ["Create", "the", "XMLBuilder", "with", "simple", "RSpec", "test", "script", "."], "add_tokens": "#expect(false).to eq(true)", "del_tokens": "expect ( false ) . to eq ( true )", "commit_type": "create"}
{"commit_tokens": ["Fixed", "a", "problem", "when", "using", "the", "gem", "with", "ActiveSupport", "::", "JSON"], "add_tokens": "require 'json' unless defined? ( ActiveSupport :: JSON ) response elsif defined? ( ActiveSupport :: JSON ) ActiveSupport :: JSON . decode ( response ) end", "del_tokens": "require 'json' return response end", "commit_type": "fix"}
{"commit_tokens": ["Add", "better", "error", "messages", "and", "checking", "of", "error", "messages"], "add_tokens": "reference_string = missing . map do | obj | # obj[:target_value] can be a string or an array. If it's an array, break apart the # array and create one error message per element. src = \"#{obj[:source]['type'].downcase}[#{obj[:source]['title']}]\" tgv = obj [ :target_value ] . is_a? ( Array ) ? obj [ :target_value ] : [ obj [ :target_value ] ] tgv . map { | tv | \"#{src} -> #{obj[:target_type].downcase}[#{tv}]\" } . join ( '; ' ) end . join ( '; ' ) plural = missing . size == 1 ? '' : 's' raise ReferenceValidationError , \"Catalog has broken reference#{plural}: #{reference_string}\"", "del_tokens": "message = missing . inspect raise ReferenceValidationError , message", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "in", "show_variable", "method", "of", "AR", "adapter"], "add_tokens": "variables . first [ 'Value' ] unless variables . empty?", "del_tokens": "variables . first [ :Value ] unless variables . empty?", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "was", "preventing", "streaming", "connections", "from", "being", "established", "."], "add_tokens": "USER_AGENT = 'DataSiftRuby/' + File . open ( File . dirname ( File . dirname ( File . dirname ( __FILE__ ) ) ) + '/VERSION' ) . first . strip! ;", "del_tokens": "USER_AGENT = 'DataSiftRuby/' + File . open ( File . dirname ( File . dirname ( File . dirname ( __FILE__ ) ) ) + '/VERSION' ) . first ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "mongoid", "5", "support", "."], "add_tokens": "require 'mongoid/compatibility' update ( \"$set\" => { paranoid_field => time } ) update ( \"$unset\" => { paranoid_field => true } ) # Update value in the collection. # # @return [ Object ] Update result. def update ( value ) query = paranoid_collection . find ( atomic_selector ) if Mongoid :: Compatibility :: Version . mongoid5? query . update_one ( value ) else query . update ( value ) end end", "del_tokens": "paranoid_collection . find ( atomic_selector ) . update ( { \"$set\" => { paranoid_field => time } } ) paranoid_collection . find ( atomic_selector ) . update ( { \"$unset\" => { paranoid_field => true } } ) # # @since 2.3.1 # # @since 2.3.1", "commit_type": "add"}
{"commit_tokens": ["Use", "Association", ".", "foreign_key", "to", "get", "the", "foreign", "key", "on", "the", "object"], "add_tokens": "if clazz \"#{ActiveSupport::Inflector.underscore(clazz.to_s)}_id\" else \"t_\" + ActiveSupport :: Inflector . singularize ( name ) + \"_ids\" end", "del_tokens": "\"t_\" + ActiveSupport :: Inflector . singularize ( name ) + \"_ids\"", "commit_type": "use"}
{"commit_tokens": ["add", "cdata", "option", "for", "outcome", "data", "extension"], "add_tokens": "# adds the specified data. The data hash can have the keys \"text\", \"cdata_text\", or \"url\" # # If both cdata_text and text are sent, cdata_text will be used if data [ \"cdata_text\" ] req . outcome_cdata_text = data [ \"cdata_text\" ] elsif data [ \"text\" ] req . outcome_text = data [ \"text\" ] end attr_accessor :outcome_text , :outcome_url , :outcome_cdata_text if @outcome_text || @outcome_url || @outcome_cdata_text if @outcome_cdata_text res_data . text { res_data . cdata! @outcome_cdata_text } elsif @outcome_text res_data . text @outcome_text end", "del_tokens": "# adds the specified data. The data hash can have the keys \"text\" or \"url\" req . outcome_text = data [ \"text\" ] if data [ \"text\" ] attr_accessor :outcome_text , :outcome_url if @outcome_text || @outcome_url res_data . text @outcome_text if @outcome_text", "commit_type": "add"}
{"commit_tokens": ["Adds", "default", "version", "to", "payment_request", "response", "and", "transaction"], "add_tokens": "PagSeguro . site_url ( \"#{api_version}/checkout/payment.html?code=#{code}\" ) if code def api_version @api_version ||= 'v2' end", "del_tokens": "PagSeguro . site_url ( \"checkout/payment.html?code=#{code}\" ) if code", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "spec", "description"], "add_tokens": "describe 'no matching ruby files found' do", "del_tokens": "describe 'no matchig ruby files found' do", "commit_type": "fix"}
{"commit_tokens": ["allow", ":", "foo_bar", "to", "match", "foo", "-", "bar"], "add_tokens": "matcher . to_s . gsub ( '_' , '-' ) == name", "del_tokens": "matcher . to_s == name", "commit_type": "allow"}
{"commit_tokens": ["Add", "more", "debugging", "to", "the", "sandbox"], "add_tokens": "Strainer . ui . debug \"Sandbox#copy_cookbooks\" Strainer . ui . debug \"Sandbox#load_cookbooks(#{cookbook_names.inspect})\" Strainer . ui . debug \"Sandbox#load_cookbook('#{cookbook_name.inspect}')\"", "del_tokens": "Strainer . ui . debug \"Sandbox#load_cookbook('#{cookbook_name}')\"", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "to", "initialize", "@tables", "[", "name", "]", "only", "once", "via", "||", "="], "add_tokens": "def channel ( name , the_locspec , keys = [ ] , cols = [ ] ) @channels [ name ] = the_locspec @tables [ name ] ||= BudChannel . new ( name , keys , cols , the_locspec , self ) @tables [ name ] ||= BudPeriodic . new ( name , [ 'ident' ] , [ 'time' ] , self )", "del_tokens": "def channel ( name , locspec , keys = [ ] , cols = [ ] ) @channels [ name ] = locspec @tables [ name ] ||= BudChannel . new ( name , keys , cols , locspec , self ) @tables [ name ] = BudPeriodic . new ( name , [ 'ident' ] , [ 'time' ] , self )", "commit_type": "make"}
{"commit_tokens": ["added", "the", "branch", "name", "to", "the", "appname", "output"], "add_tokens": "name = [ fetch ( :application , nil ) , fetch ( :stage , nil ) ] . compact . join ( \" \" ) if fetch ( :branch , nil ) name = \"name / #{ branch }\" end name", "del_tokens": "[ fetch ( :application , '' ) . capitalize , fetch ( :stage , '' ) ] . compact . join ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Adds", "a", "missing", "true", "argument"], "add_tokens": "add_button = options . fetch ( :add_button , true )", "del_tokens": "add_button = options . fetch ( :add_button )", "commit_type": "add"}
{"commit_tokens": ["Allow", "parameters", "to", "be", "passed", "on", "method_missing"], "add_tokens": "def method_missing ( method , backend = nil , * args ) super if backend . nil? require \"xi/#{backend}\" cls = Class . const_get ( \"#{backend.to_s.capitalize}::Stream\" ) cls . new ( method , self . clock , * args )", "del_tokens": "def method_missing ( method , backend = nil , ** params ) cls = if backend require \"xi/#{backend}\" Class . const_get ( \"#{backend.to_s.capitalize}::Stream\" ) else Stream end cls . new ( method , self . clock ) s . set ( s : method , ** params ) unless params . empty?", "commit_type": "allow"}
{"commit_tokens": ["Fix", "duplication", "issue", "in", "#stream", "."], "add_tokens": "remaining = @limit > 0 ? reverse_each . to_a : [ ] remaining . push ( * fetch_prev_listing ) yield o remaining . clear", "del_tokens": "reverse_each ( & block ) if @limit > 0 remaining = fetch_prev_listing yield o", "commit_type": "fix"}
{"commit_tokens": ["Add", "client", "/", "server", "interceptor", "for", "bidi"], "add_tokens": "require 'grpc_kit/interceptors/client_bidi_streamer' require 'grpc_kit/interceptors/server_bidi_streamer'", "del_tokens": "# require 'grpc_kit/client_interceptors/bidi_streamer' # require 'grpc_kit/server_interceptors/bidi_streamer'", "commit_type": "add"}
{"commit_tokens": ["Make", "table", "actually", "work", "."], "add_tokens": "table ( [ [ \"Open issues:\" , a . number_of_issues ] , [ \"Open pull requests:\" , a . number_of_pulls ] , [ \"Issues per label:\" , \"TODO\" ] , [ \"PRs per label:\" , \"TODO\" ] , [ \"Average issue age:\" , a . average_issue_age ] , [ \"Average PR age:\" , a . average_pull_age ] , [ \"Oldest issue opened on:\" , a . oldest_issue_date . strftime ( oldest_date_format ) ] , [ \"Oldest PR opened on:\" , a . oldest_pull_date . strftime ( oldest_date_format ) ] , cell_style : { border_width : 0 } )", "del_tokens": "table [ [ \"Open issues\" , a . number_of_issues ] , [ \"Open pull requests\" , a . number_of_pulls ] , [ [ \"Issues per label.\" , \"TODO\" ] , [ \"PRs per label.\" , \"TODO\" ] , ] , [ [ \"Average issue age\" , a . average_issue_age ] , [ \"Average PR age\" , a . average_pull_age ] , ] , [ [ \"Oldest issue opened on\" , a . oldest_issue_date . strftime ( oldest_date_format ) ] , [ \"Oldest PR opened on\" , a . oldest_pull_date . strftime ( oldest_date_format ) ] , ]", "commit_type": "make"}
{"commit_tokens": ["Added", "comments", "to", "the", "hide", "method", "."], "add_tokens": "# Hide the method named +name+ in the BlankSlate class. Don't # hide +instance_eval+ or any method beginning with \"__\". # list of available BlankSlate methods. We handle this by defining a # hook in the Object and Kernel classes that will hide any defined # Detect method additions to Kernel and remove them in the # BlankSlate class. # Detect method additions to Object and remove them in the # BlankSlate class.", "del_tokens": "# list of available BlankSlate methods. We handle this by defining a hook in the Object and Kernel classes that will hide any defined", "commit_type": "add"}
{"commit_tokens": ["Remove", "line", "terminator", "from", "row", "ends"], "add_tokens": "row = CSV . parse ( line . chomp ( @line_terminator ) , @csv_options ) [ 0 ]", "del_tokens": "row = CSV . parse ( line , @csv_options ) [ 0 ]", "commit_type": "remove"}
{"commit_tokens": ["Removing", "the", "recursive", "materialization", "of", "JSON", "references", "."], "add_tokens": "keys = keys ? keys . merge_set ( partial_keys ) : partial_keys puts \"keys: #{keys.to_a.join(', ')}\" puts \"json: #{json}\"", "del_tokens": "keys = ( keys || Set . new ) . union ( partial_keys ) if partial_keys", "commit_type": "remove"}
{"commit_tokens": ["Updated", "client", "to", "reflect", "API", "bug", "fixes"], "add_tokens": "# Read username, password and account_id from file, or you can just pass them # as arguments when creating a new client. puts client . session . message #puts \"--MultiRunExecutable--\" #task = client.clouds(:id => 716).instances(:filters => ['name==S1']).multi_run_executable( # \"right_script_href=https://my.rightscale.com/api/right_scripts/296533\" + # \"&inputs[][name]=TEST_NAME&inputs[][value]=text:VAL1\") #puts task.api_methods # #The instance.terminated_at value is available in the extended or full view, but you have to filter and search for your instance first. #puts client.clouds(:id => 716, :view => 'extended', :filters => ['state==inactive', 'resource_uid==7I0K1GBTJ2I2T']).terminated_at", "del_tokens": "# Read username, password and account_id from file # TODO: the begin/rescue/end can be removed once the api/session returns a valid JSON/XML # body rather than just a string (API bug). begin client . session rescue JSON :: ParserError => e puts e . message . sub ( '706: unexpected token at ' , '' ) end ##puts \"--MultiRunExecutable--\" ## This is currently not supported by the API (the server_arrays.multi_run_executable is supported) ##task = client.clouds(:id => 716).instances(:filters => ['name==S1']).multi_run_executable( ## \"right_script_href=https://my.rightscale.com/api/right_scripts/296533\" + ## \"&inputs[][name]=TEST_NAME&inputs[][value]=text:VAL1\") ##puts task.api_methods # # It's not possible to get instance.terminated_at attribute since doing a get on the instance's RSID # doesn't work after it has been terminated (API bug?). #puts instance.terminated_at", "commit_type": "update"}
{"commit_tokens": ["Add", "proxy", "support", "and", "use", "of", "client", "certs"], "add_tokens": "@http = Net :: HTTP . new ( @opts [ :host ] , @opts [ :port ] , @opts [ :proxyHost ] , @opts [ :proxyPort ] ) certFile = \"/mts/home2/cdickmann/src/client.pem\" keyFile = \"/mts/home2/cdickmann/src/client.pem\" @http . cert = OpenSSL :: X509 :: Certificate . new ( File . read ( certFile ) ) @http . key = OpenSSL :: PKey :: RSA . new ( File . read ( keyFile ) ) # @http.ca_file = \"/mts/dbc4-a/cdickmann/vmkernel-main-dbc4-3/vmkernel-main/bora/vc.pem\"", "del_tokens": "@http = Net :: HTTP . new ( @opts [ :host ] , @opts [ :port ] )", "commit_type": "add"}
{"commit_tokens": ["add", "#to_sym", "method", "to", "results"], "add_tokens": "# The state of failure. # # @return [Boolean] The test was a failure. def failure? error . nil? end # The state of error. # # @return [Boolean] The test was an error. def error? ! failure? end # @return [Symbol] The identifier of the state. def to_sym failure? ? :failure : :error end # Express the result with one char. # # @return [String] The char that identify the result. if failure?", "del_tokens": "# @return [String] The char that identify the state of the result. if error . nil?", "commit_type": "add"}
{"commit_tokens": ["added", "equal", "method", "to", "FiniteLine"], "add_tokens": "# _start_point_ and _end_point_ should be Vector3. def initialize ( start_point = Vector3 . new ( 0.0 , 0.0 , 0.0 ) , end_point = Vector3 . new ( 1.0 , 0.0 , 0.0 ) ) Util . check_arg_type ( Vector3 , start_point ) Util . check_arg_type ( Vector3 , end_point ) @start_point = start_point @end_point = end_point # [Input] # _rhs_ should be FiniteLine. # [Output] # return true if rhs equals myself. def == ( rhs ) return false if rhs == nil Util . check_arg_type ( FiniteLine , rhs ) return false if ( self . start_point != rhs . start_point ) return false if ( self . end_point != rhs . end_point ) return true end", "del_tokens": "# _start_point_arg_ and _end_point_arg_ should be Vector3. def initialize ( start_point_arg = Vector3 . new ( 0.0 , 0.0 , 0.0 ) , end_point_arg = Vector3 . new ( 1.0 , 0.0 , 0.0 ) ) Util . check_arg_type ( Vector3 , start_point_arg ) Util . check_arg_type ( Vector3 , end_point_arg ) @start_point = start_point_arg @end_point = end_point_arg", "commit_type": "add"}
{"commit_tokens": ["Add", "tags", "to", "Mongo", "document", "and", "support", ":", "trace", "log_level", "through", "Rails", "config"], "add_tokens": "# Translate trace to debug level for BufferedLogger level = config . log_level == :trace ? :debug : config . log_level logger . level = ActiveSupport :: BufferedLogger . const_get ( level . to_s . upcase ) SemanticLogger :: Logger . default_level = config . log_level", "del_tokens": "logger . level = ActiveSupport :: BufferedLogger . const_get ( config . log_level . to_s . upcase ) SemanticLogger :: Logger . default_level = Rails . configuration . log_level", "commit_type": "add"}
{"commit_tokens": ["use", "a", "cleaner", "block", "syntax", "for", "building", "the", "Faraday", "::", "Response"], "add_tokens": "def initialize ( headers = nil , body = nil ) super ( headers || { } , body ) if block_given? yield self processed! end end self . body = body . join if body . respond_to? ( :join )", "del_tokens": "self . body = body . join", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "contacting", "Twitter", "via", "a", "proxy"], "add_tokens": "response = Net :: HTTP :: Proxy ( options [ :proxy_host ] , options [ :proxy_port ] ) . start ( uri . host , uri . port ) do | http |", "del_tokens": "response = Net :: HTTP . start ( uri . host , 80 ) do | http |", "commit_type": "add"}
{"commit_tokens": ["use", "default", "Environment", ".", "new", "check", "block_given?", "()", "from", "initialize", "()"], "add_tokens": "if block_given? yield self self . process end", "del_tokens": "class << self alias_method :orig_new , :new end def self . new ( * args ) e = Environment . orig_new ( * args ) if block_given? yield e e . process end e end", "commit_type": "use"}
{"commit_tokens": ["fixing", "specs", "for", "older", "versions", "of", "ruby", "and", "rspec"], "add_tokens": "} . should raise_error ( CanCan :: Error , \"Nom nom nom. I eated it.\" )", "del_tokens": "} . should raise_exception ( CanCan :: Error , \"Nom nom nom. I eated it.\" )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "to_json", "support", "for", ":"], "add_tokens": "def to_json options = nil return { md5 : self . md5 , rules : self . rules . to_json ( options ) , signature : self . signature . to_json ( options ) } . to_json ( options ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "native", "apps"], "add_tokens": "visit_token = generate_token visitor_token = params [ :visitor_token ] || generate_token v . visit_token = visit_token v . visitor_token = visitor_token v . platform = params [ :platform ] if v . respond_to? ( :platform= ) v . app_version = params [ :app_version ] if v . respond_to? ( :app_version= ) v . os_version = params [ :os_version ] if v . respond_to? ( :os_version= ) render json : { visit_token : visit . visit_token , visitor_token : visit . visitor_token } def generate_token SecureRandom . urlsafe_base64 ( 32 ) . gsub ( / [ \\- _] / , \"\" ) . first ( 32 ) end", "del_tokens": "v . visit_token = params [ :visit_token ] v . visitor_token = params [ :visitor_token ] render json : { visit_token : visit . visit_token }", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "caching", "to", "XmlBase", "instances", "to", "speed", "up", "document", "creation", "."], "add_tokens": "class << self attr_accessor :cache_method_calls end # in the markup block that isn't cached. cache_method_call ( sym ) if XmlBase . cache_method_calls # If XmlBase.cache_method_calls = true, we dynamicly create the method # missed as an instance method on the XMLBase object. Because XML # documents are usually very repetative in nature, the next node will # be handled by the new method instead of method_missing. As # method_missing is very slow, this speeds up document generation # significantly. def cache_method_call ( sym ) instance_eval <<-NEW_METHOD def #{sym.to_s}(*args, &block) tag! ( : #{ sym . to_s } , * args , & block ) end NEW_METHOD end XmlBase . cache_method_calls = true end", "del_tokens": "# in the markup block. end", "commit_type": "add"}
{"commit_tokens": ["updated", "hot", "reload", "script", "to", "only", "run", "in", "development"], "add_tokens": "< % if Rails . env . development? %> < script src = \"http://localhost:3808/webpack-dev-server.js\" > < / script > < % end %>", "del_tokens": "< script src = \"http://localhost:3808/webpack-dev-server.js\" > < / script >", "commit_type": "update"}
{"commit_tokens": ["Add", "failing", "pending", "specs", "for", "fixed", "-", "size", "body", "messages"], "add_tokens": "it \"can parse binary body\" , pending : \"fixed length messages\" do message = parser . parse ( \"CONNECT\\ncontent-length:1\\n\\n\\x00\\x00\" ) message . body . should eq \"body\" end specify \"content length cutting message short\" , pending : \"fixed length messages\" do parser . parse ( \"CONNECT\\ncontent-length:0\\n\\nx\\x00\" ) . should be_nil end specify \"not enough to fit content length\" , pending : \"fixed length messages\" do parser . parse ( \"CONNECT\\ncontent-length:2\\n\\nx\\x00\" ) . should be_nil end", "del_tokens": "it \"can parse binary body\"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "to", "Audio", "reCAPTCHA", "v2"], "add_tokens": "# @option options [Integer] :coordinatescaptcha (0) 1 if clickable captcha. args . merge! ( options )", "del_tokens": "# @option options [Integer] coordinatescaptcha (0) 1 if clickable captcha. [ :phrase , :regsense , :numeric , :calc , :min_len , :max_len , :language , :header_acao , :id_constructor , :coordinatescaptcha ] . each do | key | args [ key ] = options [ key ] if options [ key ] end", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "additional", "prefix", "lengths", "for", "ipv4", "()"], "add_tokens": "# ipv4 generates an IPv4 from an IPv6 address. The IPv4 address is generated based on the mechanism described by RFC 6052. # The argument pl (prefix length) should be one of: 32, 40, 48, 56, 64, or 96. Default is 96 unless one of the supported values is provided. def ipv4 ( pl = 96 ) if ( pl == 32 ) i = ( @addr >> 64 ) # get bits 32-63 into position return IPv4 . new ( i & NetAddr :: F32 ) elsif ( pl == 40 ) i = ( @addr >> 48 ) & 0xff # get the last 8 bits into position i2 = ( @addr & 0xffffff0000000000000000 ) >> 56 # get first 24 bits into position return IPv4 . new ( i | i2 ) elsif ( pl == 48 ) i = ( @addr >> 40 ) & 0xffff # get the last 16 bits into position i2 = ( @addr & 0xffff0000000000000000 ) >> 48 # get first 16 bits into position return IPv4 . new ( i | i2 ) elsif ( pl == 56 ) i = ( @addr >> 32 ) & 0xffffff # get the last 24 bits into position i2 = ( @addr & 0xff0000000000000000 ) >> 40 # get first 8 bits into position return IPv4 . new ( i | i2 ) elsif ( pl == 64 ) i = ( @addr >> 24 ) # get the 32 bits into position return IPv4 . new ( i & NetAddr :: F32 ) end return IPv4 . new ( @addr & NetAddr :: F32 )", "del_tokens": "# ipv4 generates an IPv4 address from an IPv6 address. The IPv4 address is generated based on # the mechanism described by RFC 6052 for /96 IPv4-embedded IPv6 addresses. def ipv4 ( ) i = @addr & NetAddr :: F32 return IPv4 . new ( i )", "commit_type": "add"}
{"commit_tokens": ["added", "Ooor", ".", "global_context", "support", "allowing", "to", "use", "the", "same", "OpenERP", "without", "specifying", "it", "for", "each", "request", ".", "For", "instance", "Ooor", ".", "global_context", "[", "lang", "]", "=", "fr_FR"], "add_tokens": "attr_accessor :logger , :config , :all_loaded_models , :binding , :common_url , :object_url , :global_context Ooor . global_context = Ooor . config [ :global_context ] || { }", "del_tokens": "attr_accessor :logger , :config , :all_loaded_models , :binding , :common_url , :object_url", "commit_type": "add"}
{"commit_tokens": ["make", "markdown", "default", ";", "move", "ext", "lookup", "to", "runner"], "add_tokens": "end if config . known_textile_extnames . include? ( extname ) @markup_type = :textile else # default/fallback use markdown @markup_type = :markdown", "del_tokens": "end if extname . empty? then extname = \".textile\" # default to .textile config . known_extnames . each do | e | logger . debug \"File.exists? #{dirname}/#{basename}#{e}\" if File . exists? ( \"#{dirname}/#{basename}#{e}\" ) then extname = e logger . debug \"extname=#{extname}\" break end end end if config . known_markdown_extnames . include? ( extname ) @markup_type = :markdown else @markup_type = :textile", "commit_type": "make"}
{"commit_tokens": ["Add", "more", "tests", "and", "bug", "fixes", "."], "add_tokens": "require 'byebug' # So we'll navigate the menu to get the option for the shell. # For this first navigation we allow a delay only if we are not connected to a serial device. # Serial connections are always on, so they don't need to initialize first. menu_option = get_menu_option 'Shell' , ! ( Shells :: SerialSession > self . class ) shell_regex = / \\[ (?<VER>[^ \\] ]*) \\] \\[ (?<USERHOST>[^ \\] ]*) \\] (?<CD> \\/ .*): \\s *$ / # Now we execute the menu option and wait for the shell_regex to match. # Once we have a match we should be able to repeat it and store the information from the shell. # Wait for the shell_regex to match again. temporary_prompt ( shell_regex ) { wait_for_prompt nil , 4 , false } def get_menu_option ( option_text , delay = true ) # give the prompt a few seconds to draw. if delay wait_for_prompt ( nil , 4 , false ) end if menu . nil?", "del_tokens": "menu_option = get_menu_option 'Shell' shell_regex = / \\[ (?<VER>[^ \\] ]*) \\] \\[ (?<USERHOST>[^ \\] ]*) \\] (?<CD> \\/ .*): \\s *$ / sleep 1 def get_menu_option ( option_text ) # give the prompt a few seconds unless we're running on a serial port. wait_for_prompt ( nil , 3 , false ) unless Shells :: SerialSession > self . class unless menu # FIXME: This should not cause an error to occur. # make sure it is the menu we expect. #menu = menu_regex.match(menu)['MENU']", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "remove", "()", "method", "in", "DObject", "more", "robust"], "add_tokens": "if pos != false if pos . length > 1 add_msg ( \"Warning: Method remove() does not allow an element query which yields multiple array hits. Please use array position instead of tag/name. Value NOT removed.\" ) else # Extract first array number: pos = pos [ 0 ] # Update group length: if @tags [ pos ] [ 5 .. 8 ] != \"0000\" change = @lengths [ pos ] vr = @types [ pos ] update_group_length ( pos , vr , change , - 1 ) end # Remove entry from arrays: @tags . delete_at ( pos ) @levels . delete_at ( pos ) @names . delete_at ( pos ) @types . delete_at ( pos ) @lengths . delete_at ( pos ) @values . delete_at ( pos ) @raw . delete_at ( pos ) add_msg ( \"Warning: The data element #{element} could not be found in the DICOM object. Method remove() has no data element to remove.\" )", "del_tokens": "if pos != nil # Extract first array number: pos = pos [ 0 ] # Update group length: if @tags [ pos ] [ 5 .. 8 ] != \"0000\" change = @lengths [ pos ] vr = @types [ pos ] update_group_length ( pos , vr , change , - 1 ) # Remove entry from arrays: @tags . delete_at ( pos ) @levels . delete_at ( pos ) @names . delete_at ( pos ) @types . delete_at ( pos ) @lengths . delete_at ( pos ) @values . delete_at ( pos ) @raw . delete_at ( pos ) add_msg ( \"The data element #{element} could not be found in the DICOM object.\" )", "commit_type": "make"}
{"commit_tokens": ["Use", "the", "receipts", "url", "attribute", "if", "available"], "add_tokens": "client . post ( receipts_url , { type : 'read' } ) client . post ( receipts_url , { type : 'delivery' } ) def receipts_url attributes [ 'receipts_url' ] || \"#{url}/receipts\" end", "del_tokens": "client . post ( \"#{url}/receipts\" , { type : 'read' } ) client . post ( \"#{url}/receipts\" , { type : 'delivery' } )", "commit_type": "use"}
{"commit_tokens": ["make", "sure", "all", "method", "names", "are", "in", "symbol", "to", "match", "names"], "add_tokens": "original_method = Mock . find_new_name ( self , defi . msg ) . to_sym", "del_tokens": "original_method = Mock . find_new_name ( self , defi . msg )", "commit_type": "make"}
{"commit_tokens": ["Add", "ability", "to", "set", "http_proxy"], "add_tokens": "@access_key_id = access_key_id @secret_access_key = secret_access_key # Manually set an http_proxy # # You can optionally set the `HTTP_PROXY` environment variable. def self . http_proxy = ( http_proxy ) @http_proxy = http_proxy end # Reads the `HTTP_PROXY` environment variable if ::http_proxy was not set manually. def self . http_proxy @http_proxy || ENV [ 'http_proxy' ] end test : \"http://localhost:3000\" . freeze , production : \"https://api.evident.io\" . freeze } . freeze # :nodoc: @host = host", "del_tokens": "@access_key_id = access_key_id @secret_access_key = secret_access_key test : \"http://localhost:3000\" . freeze , production : \"https://api.evident.io\" . freeze } . freeze # :nodoc: @host = host", "commit_type": "add"}
{"commit_tokens": ["removed", "client", "/", "worker", "code"], "add_tokens": "VER = \"0.9.7.6\"", "del_tokens": "VER = \"0.9.5\"", "commit_type": "remove"}
{"commit_tokens": ["Removing", "code", "duplication", "in", "normalize_description", "/", "normalize_keywords"], "add_tokens": "render_with_normalization ( tags , :description ) render_with_normalization ( tags , :keywords ) # Renders meta tag with normalization (should have a corresponding normalize_ # method in TextNormalizer). # @see TextNormalizer def render_with_normalization ( tags , name ) value = TextNormalizer . send ( \"normalize_#{name}\" , meta_tags . extract ( name ) ) normalized_meta_tags [ name ] = value tags << Tag . new ( :meta , :name => name , :content => value ) if value . present? send ( method , tags , property , content , options )", "del_tokens": "render_description ( tags ) render_keywords ( tags ) # Renders description meta tag. def render_description ( tags ) description = TextNormalizer . normalize_description ( meta_tags . extract ( :description ) ) normalized_meta_tags [ :description ] = description tags << Tag . new ( :meta , :name => :description , :content => description ) if description . present? end # Renders keywords meta tag. # # @param [Array<Tag>] tags a buffer object to store tag in. # def render_keywords ( tags ) keywords = TextNormalizer . normalize_keywords ( meta_tags . extract ( :keywords ) ) normalized_meta_tags [ :keywords ] = keywords tags << Tag . new ( :meta , :name => :keywords , :content => keywords ) if keywords . present? public_send ( method , tags , property , content , options )", "commit_type": "remove"}
{"commit_tokens": ["Add", "pages", "migration", "w", "translations", "."], "add_tokens": "def up Wafflemix :: Page . create_translation_table! :title => :string , :body => :text end def down drop_table :wafflemix_pages Wafflemix :: Page . drop_translation_table!", "del_tokens": "def change", "commit_type": "add"}
{"commit_tokens": ["change", "version", "to", "made", "gem", "spec", "version"], "add_tokens": "TINY = 7", "del_tokens": "TINY = 0", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "spec", ":", "Message#encoded", "raised", "a", "SystemStackError", "for", "a", "specific", "email", "."], "add_tokens": "include Deliverable", "del_tokens": "include Sendable", "commit_type": "add"}
{"commit_tokens": ["fixed", "now", "aliasing", "to", "be", "this", "second"], "add_tokens": "normalized_text . gsub! ( / \\b now \\b / , 'this second' )", "del_tokens": "normalized_text . gsub! ( / \\b now \\b / , 'this hour' )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "multiple", "pass", "phase", "handling"], "add_tokens": "attr_reader :fwplugin , :port , :docroot , :dports , :passphrases , :redir_protocol , :redir_hostname , :redir_port @redir_protocol = @config [ 'server' ] [ 'redirect' ] [ 'protocol' ] || 'http' @redir_hostname = @config [ 'server' ] [ 'redirect' ] [ 'hostname' ] || nil @redir_port = @config [ 'server' ] [ 'redirect' ] [ 'port' ] || 80 if @passfile and File . readable? @passfile", "del_tokens": "attr_reader :fwplugin , :port , :docroot , :dports , :passphrases if File . readable? @passfile", "commit_type": "implement"}
{"commit_tokens": ["Updated", "content", "label", "delete", "notification"], "add_tokens": "format . html { redirect_back ( fallback_location : content_label_assignments_path , notice : 'Label was removed.' ) }", "del_tokens": "format . html { redirect_back ( fallback_location : content_label_assignments_path , notice : 'Block was removed.' ) }", "commit_type": "update"}
{"commit_tokens": ["Change", "way", "of", "including", "all", "required", "files", "."], "add_tokens": "Dir . glob ( \"lib/gaapi/**/*.rb\" ) . each { | f | require f . gsub ( %r{ lib/ } , \"\" ) }", "del_tokens": "Dir . glob ( \"lib/gaapi/**/*.rb\" ) . each { | f | require Pathname . new ( f ) . relative_path_from ( Pathname . new ( \"lib\" ) ) }", "commit_type": "change"}
{"commit_tokens": ["Change", "to", "hide", "leaky", "abstraction", "for", "parent", "path", "."], "add_tokens": "@parent = Pathname . new ( parent )", "del_tokens": "@parent = parent", "commit_type": "change"}
{"commit_tokens": ["using", "/", "fonts", "instead", "of", "/", "font"], "add_tokens": "asset_path source , { :dir => 'fonts' } . merge ( options )", "del_tokens": "asset_path source , { :dir => 'font' } . merge ( options )", "commit_type": "use"}
{"commit_tokens": ["Move", "edges", "when", "transforming", "nodes", "due", "to", "the", "dependency", "cycle", "."], "add_tokens": "# TODO(lsmola) And if the result causes a cycle, we should repeat the build_dag method, with a max # depth 10. We should throw a warning maybe asking for simplifying the interconnections in the models. dto_collection_transformations = { } # TODO(lsmola) add a nice dependency_attributes setter? It's used also in actualize_dependencies method # Store a simple hash for transforming dto_collection to new_dto_collection dto_collection_transformations [ dto_collection ] = new_dto_collection end all_nodes = nodes + new_nodes # If we remove an attribute that was a dependency of another node, we need to move also the # dependency. So e.g. floating_ip depends on network_port's attribute vm, but we move that attribute to new # network_port dto_collection. We will need to move also the dependency to point to the new dto_collection. # # So we have to go through all dependencies that loads a key, which is the moved attribute. We can get a list # of attributes that are using a key from transitive_dependency_attributes, from there we can get a list of # dependencies. And from the list of dependencies, we can check which ones were moved just by looking into # dto_collection_transformations. all_nodes . each do | dto_collection | dto_collection . transitive_dependency_attributes . each do | transitive_dependency_attribute | transitive_dependencies = dto_collection . dependency_attributes [ transitive_dependency_attribute ] next if transitive_dependencies . blank? transitive_dependencies . map! do | dependency | transformed_dependency = dto_collection_transformations [ dependency ] transformed_dependency . blank? ? dependency : transformed_dependency end end construct_graph! ( all_nodes )", "del_tokens": "# TODO(lsmola) add a nice dependency_attributes setter? It's used also in actualize_dendencies method # TODO(lsmola) If we remove an attribute that was a dependency of another node, we need to move also the # dependency. So e.g. floating_ip depends on network_port's attribute vm, but we move that attribute to new # network_port dto_collection. We will need to move also the dependency to the new dto_collection. # So we have to go through all dependencies that loads a key, which is the moved attribute, I don't think we # even store that now. # So apart from dependency_attributes, we would store a dependency_attributes_keys, then if we find a # blacklisted_attribute in any dto_collection dependency_attribute_keys that depend on this dto collection, # we will also need to move this dependency. And if the result cause a cycle, we should repeat the build_dag # method, with a max depth 10. We should throw a warning maybe asking for simplifying the interconnections. construct_graph! ( nodes + new_nodes )", "commit_type": "move"}
{"commit_tokens": ["added", "support", "to", "inheritance", "for", "default", "options", "validations", "attributes", "and", "handlers"], "add_tokens": "_safe_update_queries ( @event . name ) _safe_manage_reloaded_event ( @event . name ) _safe_manage_event ( @event . name ) # Safe defined functions: def _safe_update_queries ( event ) update_queries = \"#{event}_update_queries\" return send ( update_queries ) if respond_to? update_queries nil end def _safe_manage_reloaded_event ( event ) manage_reloaded_event = \"#{event}_manage_reloaded_event\" return send ( manage_reloaded_event ) if respond_to? manage_reloaded_event nil end def _safe_manage_event ( event ) manage_event = \"#{event}_manage_event\" return send ( manage_event ) if respond_to? manage_event nil end", "del_tokens": "update_queries = \"#{@event.name}_update_queries\" send ( update_queries ) if respond_to? update_queries manage_reloaded_event = \"#{@event.name}_manage_reloaded_event\" send ( manage_reloaded_event ) if respond_to? manage_reloaded_event manage_event = \"#{@event.name}_manage_event\" send ( manage_event ) if respond_to? manage_event", "commit_type": "add"}
{"commit_tokens": ["add", "options", "arg", "in", "Sign", ".", "verify?"], "add_tokens": "def self . verify? ( params , options = { } ) sign = params . delete ( 'sign' ) key = options [ :key ] || Alipay . key verify_md5? ( key , sign , params ) verify_rsa? ( sign , params ) def self . verify_md5? ( key , sign , params ) def self . verify_rsa? ( sign , params )", "del_tokens": "def self . verify? ( params ) verify_md5? ( params ) verify_rsa? ( params ) def self . verify_md5? ( params ) key = params . delete ( 'key' ) || Alipay . key sign = params . delete ( 'sign' ) def self . verify_rsa? ( params ) sign = params . delete ( 'sign' )", "commit_type": "add"}
{"commit_tokens": ["Created", "ActiveAdmin", "::", "Renderer", "which", "gives", "us", "a", "an", "object", "oriented", "way"], "add_tokens": ":per_page => 30 ,", "del_tokens": ":per_page => 50 ,", "commit_type": "create"}
{"commit_tokens": ["Add", "Blacklist", "Endpoint", ".", "updated", "gem"], "add_tokens": "let ( :result ) { @client . create_user_authentication ( 7887 , context \"viewing a list of blacklisted users\" do use_vcr_cassette let ( :result ) { @client . blacklisted ( :limit => 2 ) } it \"should make a list of blacklisted users\" do user_usernames = result . users . collect { | u | u . user . username } user_usernames . should == [ \"timothy.sanders.39948\" ] end it \"should only return the right number of results\" do result . users . count . should == 1 end end context \"blacklisting a user\" do use_vcr_cassette let ( :result ) { @client . blacklist ( 8198 ) } it \"should return user's basic information\" do result . user . should_not be_nil end it \"should return user with activity_state of blacklisted\" do result . user . activity_state . should == 'blacklisted' end end context \"whitelisting a user\" do use_vcr_cassette let ( :result ) { @client . whitelist ( 8198 ) } it \"should return user with activity_state of fresh\" do result . user . activity_state . should == 'fresh' end end context \"blacklisting a non-existing user\" do use_vcr_cassette it \"should throw an error\" do expect do @client . blacklist ( 0 ) end . to raise_error ( Checkdin :: APIError , / 404 / ) end end", "del_tokens": "let ( :result ) { @client . create_user_authentication ( 7887 ,", "commit_type": "add"}
{"commit_tokens": ["Use", "-", "for", "non", "executable", "code"], "add_tokens": "bc [ buffer . line_for_position ( pos ) - 1 ] [ buffer . column_for_position ( pos ) ] = node . executable? ? 'x' : '-'", "del_tokens": "bc [ buffer . line_for_position ( pos ) - 1 ] [ buffer . column_for_position ( pos ) ] = node . executable? ? 'x' : '.'", "commit_type": "use"}
{"commit_tokens": ["fixed", "config", "file", "creation", "in", "install", ".", "rb"], "add_tokens": "File . open ( path , \"w\" ) do | f |", "del_tokens": "File . open ( path ) do | f |", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "bug", "that", "config", "[", ":", "config_file", "]", "is", "overwriten"], "add_tokens": "locate_config_file", "del_tokens": "config [ :config_file ] ||= locate_config_file", "commit_type": "fix"}
{"commit_tokens": ["Adding", "versions", "to", "Static", "Request"], "add_tokens": "def versions Proxy . new self , 'versions' end return perform_request ( api_url ( \"versions\" ) ) . parsed_response if endpoint == \"versions\" if %w( realm ) . include? endpoint", "del_tokens": "if endpoint == \"realm\"", "commit_type": "add"}
{"commit_tokens": ["Add", "plugins", ".", "rb", "back", "to", "merb", "-", "core"], "add_tokens": "autoload :BootLoader , \"merb-core/bootloader\"", "del_tokens": "autoload :BootLoader , \"merb-core/boot/bootloader\"", "commit_type": "add"}
{"commit_tokens": ["Use", "JSON", "s", "#to_json", "instead", "of", "Collection", "."], "add_tokens": "def to_json ( options = { } ) :: JSON . pretty_generate ( as_json , options )", "del_tokens": "def to_json :: JSON . dump ( as_json )", "commit_type": "use"}
{"commit_tokens": ["Fix", "Errno", "::", "ERANGE", "exception", "when", "looking", "for", "Math", ".", "log", "for", "weighting", "."], "add_tokens": "end ## parndt 2010/05/03 changed to records_size.to_f to avoid -Infinity Errno::ERANGE exceptions ## which would happen for example Math.log(1 / 20) == -Infinity but Math.log(1.0 / 20) == -2.99573227355399 out [ r_id ] = pos . size * Math . log ( records_size . to_f / @records . size )", "del_tokens": "end out [ r_id ] = pos . size * Math . log ( records_size / @records . size )", "commit_type": "fix"}
{"commit_tokens": ["Added", "handling", "of", "UserComment", "(", "type", "Undefined", ")", "to", "extract", "data", ".", "This", "fixes", "the"], "add_tokens": "@type = data . readshort ( pos + 2 ) case @type when 7 # undefined # UserComment if @tag == 0x9286 len , pack = count , proc { | d | d . strip } len -= 8 # reduce to account for first 8 bytes start = len > 4 ? @offset + 8 : ( pos + 8 ) # UserComment first 8-bytes is char code @value = [ pack [ data [ start .. ( start + len - 1 ) ] ] ] . flatten end if len && pack && @type != 7", "del_tokens": "case data . readshort ( pos + 2 ) if len && pack", "commit_type": "add"}
{"commit_tokens": ["Add", "emitter", "for", "binary", "operator", "methods"], "add_tokens": "( / bar / =~ foo ) ( foo =~ / bar / ) assert_source \"(1 #{operator} 2)\" assert_source \"(left.#{operator}(*foo))\" assert_source \"(left.#{operator}(a, b))\" assert_source \"(self #{operator} b)\" assert_source \"(a #{operator} b)\" assert_source \"(a #{operator} b).foo\" #context 'flip flops' do # context 'flip2' do # assert_source <<-RUBY # if (((i) == (4)))..(((i) == (4))) # foo # end # RUBY # end # context 'flip3' do # assert_source <<-RUBY # if (((i) == (4)))...(((i) == (4))) # foo # end # RUBY # end #end", "del_tokens": "/ bar / . =~ ( foo ) foo . =~ ( / bar / ) #context 'flip flops' do # context 'flip2' do # assert_source <<-RUBY # if (((i) == (4)))..(((i) == (4))) # foo # end # RUBY # end # context 'flip3' do # assert_source <<-RUBY # if (((i) == (4)))...(((i) == (4))) # foo # end # RUBY # end #end context \"on literals #{operator}\" do assert_source \"((1) #{operator} (2))\" end context \"#{operator} with splat args\" do assert_source \"((left).#{operator}(*foo))\" end context \"on self #{operator}\" do assert_source \"((self) #{operator} (b))\" end context \"on send #{operator}\" do assert_source \"((a) #{operator} (b))\" end", "commit_type": "add"}
{"commit_tokens": ["remove", "attr_reader", "order_desc", "from", "column"], "add_tokens": "attr_reader :name , :header", "del_tokens": "attr_reader :name , :header , :order_desc", "commit_type": "remove"}
{"commit_tokens": ["Updated", "version", "and", "gem", "dependencies"], "add_tokens": "VERSION = '0.10.2' . freeze", "del_tokens": "VERSION = '0.10.1' . freeze", "commit_type": "update"}
{"commit_tokens": ["Improve", "error", "handling", "loading", "custom", "hooks"], "add_tokens": "rescue LoadError , NameError => ex", "del_tokens": "rescue NameError => ex", "commit_type": "improve"}
{"commit_tokens": ["Add", "install", "generator", ".", "Change", "config", "defaults"], "add_tokens": "config . webpacked . load_manifest_on_initialize = false config . webpacked . bin = \"node_modules/.bin/webpack\" config . webpacked . config = \"frontend/main.config.js\"", "del_tokens": "config . webpacked . load_manifest_on_initialize = true", "commit_type": "add"}
{"commit_tokens": ["Use", "connection", ".", "stat", ".", "readable?", "for", "Socket#alive?"], "add_tokens": "connection . stat . readable?", "del_tokens": "return false if connection . closed? readable , = IO . select ( [ connection ] , [ connection ] , [ ] ) if readable [ 0 ] begin ! connection . eof? rescue Errno :: ECONNRESET false rescue true end else true end", "commit_type": "use"}
{"commit_tokens": ["Adding", "namespace", "parameter", "to", "the", "ajax", "data", "grid", "builder"], "add_tokens": "# The namespace allows the query parameters to be namespaced so # multiple tables can exist on the same page data [ \"grapple-ajax-namespace\" ] = options [ :namespace ] unless options [ :namespace ] . nil?", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixing", "Channel#streaming?", "/", "#stream", "methods", ".", "Adding", "specs", "for", "these", "methods", "."], "add_tokens": "Stream . get ( @name ) ! stream . nil?", "del_tokens": "# TODO: Use _links instead of hard-coding. json = connection . get ( \"streams/#{@name}\" ) stream_json = json [ 'stream' ] Stream . new ( stream_json ) stream . live?", "commit_type": "fix"}
{"commit_tokens": ["fixed", "numeric", "rule", "multipart", "flag"], "add_tokens": "return result1 if definition [ :multipart ] . to_s == \"false\" return rule_desc if definition [ :multipart ] . to_s == \"false\"", "del_tokens": "return result1 if definition [ :multipart ] == \"false\" return rule_desc if definition [ :multipart ] == \"false\"", "commit_type": "fix"}
{"commit_tokens": ["Move", "request", "spec", "initialization", "to", "the", "endpoint", "class", "."], "add_tokens": "def make_request ( endpoint_spec , request_spec ) Faraday . send ( endpoint_spec . method ) do | req | RequestBuilder . new ( token , endpoint_spec , request_spec , req ) . apply end", "del_tokens": "def make_request ( endpoint_spec , params : { } , header_overrides : { } , body : nil , ** url_args ) request_spec = RequestSpec . new ( url_args : url_args , params : params , header_overrides : header_overrides , body : body ) send ( endpoint_spec : endpoint_spec , request_spec : request_spec ) def send ( endpoint_spec : , request_spec : ) Faraday . send ( endpoint_spec . method ) do | req | RequestBuilder . new ( token , endpoint_spec , request_spec , req ) . apply end end", "commit_type": "move"}
{"commit_tokens": ["adding", "callback", "for", "appending", "content", "to", "the", "end", "of", "the", "nested", "form"], "add_tokens": "form_for ( * ( args << options ) , & block ) concat ( @after_nested_form_callback . call ) if @after_nested_form_callback end def after_nested_form ( & block ) @after_nested_form_callback = block", "del_tokens": "form_for ( * ( args << options ) , & block )", "commit_type": "add"}
{"commit_tokens": ["Implement", "more", "functionality", "in", "the", "models"], "add_tokens": "value . to_s attribute :mask , String , writer : :private attribute :imask , String , writer : :private attribute :modified , String , writer : :private def set_mask value self . mask = value end def set_imask value self . imask = value end def set_modified value self . modified = value end def set_status value self . status = value end def set_uuid value self . uuid = value end def set_date value self . date = value end # Refactoring idea, need to understand Virtus internals a bit better # [:mask, :imask, :modified, :status, :uuid, :entry].each do |ro_attr| # define_method(\"set_#{ro_attr.to_s}\") do |value| # self.class.find_by(ro_attr).send(\".=\", value) # end # end", "del_tokens": "value attribute :mask , String attribute :imask , String attribute :modified , String", "commit_type": "implement"}
{"commit_tokens": ["Remove", "references", "to", "jekyll", "-", "sitemap"], "add_tokens": "# copy feed template from source to destination File . open ( destination_path , 'w' ) { | f | f . write ( feed_content ) } def feed_content # Checks if a feed already exists in the site source", "del_tokens": "# copy sitemap template from source to destination File . open ( destination_path , 'w' ) { | f | f . write ( sitemap_content ) } def sitemap_content # Checks if a sitemap already exists in the site source", "commit_type": "remove"}
{"commit_tokens": ["Adding", "New", "Zealand", "nz", "to", "allowed", "databases"], "add_tokens": "DBS = [ :us , :uk , :ca , :ru , :de , :fr , :es , :it , :br , :au , :ar , :be , :ch , :dk , :fi , :hk , :ie , :il , :mx , :nl , :no , :pl , :se , :sg , :tr , :in , :nz ] #\"us\" - for Google.com, \"uk\" - for Google.co.uk, \"ru\" - for Google.ru, \"de\" for Google.de, \"fr\" for Google.fr, \"es\" for Google.es, \"it\" for Google.it Beta, \"br\" for Google.com.br Beta, \"au\" for Google.com.au Beta, etc", "del_tokens": "DBS = [ :us , :uk , :ca , :ru , :de , :fr , :es , :it , :br , :au , :ar , :be , :ch , :dk , :fi , :hk , :ie , :il , :mx , :nl , :no , :pl , :se , :sg , :tr , :in ] #\"us\" - for Google.com, \"uk\" - for Google.co.uk, \"ru\" - for Google.ru, \"de\" for Google.de, \"fr\" for Google.fr, \"es\" for Google.es, \"it\" for Google.it Beta, \"br\" for Google.com.br Beta, \"au\" for Google.com.au Beta, etc", "commit_type": "add"}
{"commit_tokens": ["Added", "all", "blocks", "started", "with", "inline", "elements"], "add_tokens": "def printBlock block , indent = 0 puts \"#{' ' * indent}#{block}\" if block . has_children? block . each do | child | printBlock child , indent + 1 end end end printBlock block", "del_tokens": "puts \"#{block}\"", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "Rails", "::", "Engine", "assets"], "add_tokens": "# Search for Rails Engines with assets and append those if defined? ( Rails ) && defined? ( Rails :: Engine ) Rails :: Engine . subclasses . each do | engine | append_paths assets , engine . paths [ \"vendor/assets\" ] . existent_directories append_paths assets , engine . paths [ \"lib/assets\" ] . existent_directories append_paths assets , engine . paths [ \"app/assets\" ] . existent_directories end end # Finally, configure Sprockets::Helpers to", "del_tokens": "# Finally, configure Sprockets::Helpers", "commit_type": "add"}
{"commit_tokens": ["Fix", "specs", "and", "version", "bump"], "add_tokens": "VERSION = '2.0.1'", "del_tokens": "VERSION = '2.0.0'", "commit_type": "fix"}
{"commit_tokens": ["Make", "rendering", "policy", "to", "cover", "all", "the", "cases"], "add_tokens": "CONTENT_TYPE = 'Content-Type' . freeze class NullAction include Lotus :: Action def call ( env ) end end action = NullAction . new . tap { | a | a . call ( env ) } [ DEFAULT_CODE , { CONTENT_TYPE => action . content_type } , DEFAULT_BODY , action ]", "del_tokens": "[ DEFAULT_CODE , { } , DEFAULT_BODY , nil ]", "commit_type": "make"}
{"commit_tokens": ["Added", "specs", "for", "the", "#cd", "command"], "add_tokens": "@dir = File . expand_path ( dir )", "del_tokens": "@dir = dir", "commit_type": "add"}
{"commit_tokens": ["Adds", "the", "ability", "to", "config", "the", "fields", "to", "use", "for", "all", "actions"], "add_tokens": "fields = bootstrap_admin_config . send ( \"#{params[:action]}_fields\" ) || bootstrap_admin_config . send ( \"action_fields\" ) || model_klass . accessible_attributes . reject ( & :blank? ) . map { | att | real_attribute_name att } @attributes = fields . map do | att |", "del_tokens": "bootstrap_admin_config_field = bootstrap_admin_config . send ( \"#{params[:action]}_fields\" ) attributes = if bootstrap_admin_config_field . present? bootstrap_admin_config_field else model_klass . accessible_attributes . reject ( & :blank? ) . map { | att | real_attribute_name att } end @attributes = attributes . map do | att |", "commit_type": "add"}
{"commit_tokens": ["moved", "private", "to", "the", "bottom"], "add_tokens": "view_properties_for ( name , locator ) def view_properties_for ( name , locator ) properties = [ :clickable , :enabled , :focusable , :focused , :selected , :shown ] properties . each do | property | define_method ( \"#{name}_#{property}?\" ) do platform . get_view_by_id ( locator [ :id ] ) do | device | device . send \"is_#{property}\" end platform . last_response . body end end end", "del_tokens": "is ( name , locator , :clickable , :enabled , :focusable , :focused , :selected , :shown ) end def is ( name , locator , * properties ) properties . each do | property | define_method ( \"#{name}_#{property}?\" ) do platform . get_view_by_id ( locator [ :id ] ) do | device | device . send \"is_#{property}\" end platform . last_response . body end end", "commit_type": "move"}
{"commit_tokens": ["fixed", "logic", "error", "with", "admin", "actions", "config"], "add_tokens": "unless blogit_conf . include_admin_actions", "del_tokens": "if blogit_conf . include_admin_actions", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "column", "index", "to", "reduce", "column", "lookup", "time"], "add_tokens": "@column_lookup = { } add_column_index ( column . name , @columns . size ) add_column_index ( name . to_s . downcase , @columns . size ) return nil unless ( index = @column_lookup [ name . to_s . downcase ] ) @columns [ index ] def add_column_index ( name , index ) @column_lookup [ name ] = index end", "del_tokens": "#OPTIMIZE: Possible to add hash with column name, pointing to the index of the @columns array self . columns . find { | col | col . name . downcase == name . downcase }", "commit_type": "add"}
{"commit_tokens": ["use", "shorter", "filenames", "for", "temporary", "files"], "add_tokens": "path = [ @file , $$ . to_s ( 36 ) , Thread . current . object_id . to_s ( 36 ) ] . join", "del_tokens": "path = \"#{@file}-#{$$}-#{Thread.current.object_id}\"", "commit_type": "use"}
{"commit_tokens": ["Update", "for", "2015", "-", "04", "-", "11"], "add_tokens": "class Network", "del_tokens": "module Network", "commit_type": "update"}
{"commit_tokens": ["added", "version", "to", "chipmunk", "in", "readme"], "add_tokens": "attr_accessor :width , :height , :fullscreen , :show_fps , :font , :node_manager , :content_manager , :physics_manager @input_manager = Kawaii :: InputManager . new ( self ) @physics_manager = Kawaii :: PhysicsManager . new", "del_tokens": "attr_accessor :width , :height , :fullscreen , :show_fps , :font , :node_manager , :content_manager @input_manager", "commit_type": "add"}
{"commit_tokens": ["Adding", "CLI", "and", "ENV", "var", "to", "set", "Circle", "CI", "API", "token"], "add_tokens": "@client ||= CircleAPI . new ( @circle_token ) @circle_token = env [ \"CIRCLE_CI_API_TOKEN\" ]", "del_tokens": "@client ||= CircleAPI . new", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "which", "excludes", "fields", "when", "generating", "a", "random", "example"], "add_tokens": "# Return a content item merged with a hash and with the excluded fields removed. # If the resulting content item isn't valid against the schema an error will be raised. # random.customise_and_validate({base_path: \"/foo\"}, [\"withdrawn_notice\"]) # @param [Array] array The array containing fields to exclude def customise_and_validate ( user_defined_values = { } , fields_to_exclude = [ ] ) item_merged_with_user_input . reject! { | k | fields_to_exclude . include? ( k ) } # Return a hash with a random content item # # Example: # # GovukSchemas::RandomExample.for_schema(\"detailed_guide\", schema_type: \"frontend\").payload # # => {\"base_path\"=>\"/e42dd28e\", \"title\"=>\"dolor est...\", \"publishing_app\"=>\"elit\"...} # # @return [Hash] A content item # Support backwards compatibility alias :payload :customise_and_validate alias :merge_and_validate :customise_and_validate", "del_tokens": "# Return a hash with a random content item # # Example: # # GovukSchemas::RandomExample.for_schema(\"detailed_guide\", schema_type: \"frontend\").payload # # => {\"base_path\"=>\"/e42dd28e\", \"title\"=>\"dolor est...\", \"publishing_app\"=>\"elit\"...} # # @return [Hash] A content item def payload item = @random_generator . payload errors = validation_errors_for ( item ) if errors . any? raise InvalidContentGenerated , error_message ( item , errors ) end item end # Return a content item merged with a hash. If the resulting content item # isn't valid against the schema an error will be raised. # random.merge_and_validate(base_path: \"/foo\") def merge_and_validate ( user_defined_values )", "commit_type": "add"}
{"commit_tokens": ["Upgraded", "to", "work", "with", "latest", "data", "tables", "gem"], "add_tokens": ":iTotalRecords => ( unless total_records . kind_of? ( Hash ) total_records . to_i else ( total_records . keys . map ( & :first ) . uniq . count rescue 1 ) end ) , :iTotalDisplayRecords => ( unless display_records . kind_of? ( Hash ) display_records . to_i else ( display_records . keys . map ( & :first ) . uniq . count rescue 1 ) end ) self . total_records = ( c . select ( '*' ) . reorder ( nil ) . count rescue 1 ) self . display_records = search_terms . any? { | k , v | v . present? } ? ( c . select ( '*' ) . reorder ( nil ) . count rescue 1 ) : total_records", "del_tokens": ":iTotalRecords => total_records . to_i , :iTotalDisplayRecords => display_records . to_i , self . total_records = ( c . select ( '*' ) . count rescue c . count ) self . display_records = search_terms . any? { | k , v | v . present? } ? ( c . select ( '*' ) . count rescue c . count ) : total_records", "commit_type": "upgrade"}
{"commit_tokens": ["Make", "sure", "to", "delete", "odd", "slashes", "at", "the", "beginning", "of", "name", "."], "add_tokens": "entry_path = File . join ( path , entry_name ) . gsub ( / ^ \\/ / , '' )", "del_tokens": "entry_path = File . join ( path , entry_name )", "commit_type": "make"}
{"commit_tokens": ["Moves", "the", "controler", "publish", "to", "a", "mixin", "and", "includes", "it", "in", "the", "short", "stack"], "add_tokens": "\"class #{klass} < superclass::#{klass}; end\\n\"", "del_tokens": "\"class #{klass} < #{self}::#{klass}; end\\n\"", "commit_type": "move"}
{"commit_tokens": ["added", "international", "prefix", "for", "phone", "parsing", "and", "some", "refactoring"], "add_tokens": "# Leading digits key LEADING_DIGITS = :leading_digits # International prefix key INTERNATIONAL_PREFIX = :international_prefix # Main country for code key MAIN_COUNTRY_FOR_CODE = :main_country_for_code # Types key TYPES = :types # Formats key FORMATS = :formats # Pattern key PATTERN = :pattern TYPES_DESC = { detected [ Core :: COUNTRY_CODE ] , detected [ Core :: NATIONAL_PREFIX ] )", "del_tokens": "TYPES = { detected [ :country_code ] , detected [ :national_prefix ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "append", "-", "hash", "rule"], "add_tokens": "when 'append-hash' str = \"#{str}##{rand(36**6).to_s(36)}\" when 'append-method-get'", "del_tokens": "when 'method_get'", "commit_type": "add"}
{"commit_tokens": ["update", "README", "and", "calc", "example"], "add_tokens": "start < - ( expr | quit ) EOF quit < - 'quit' { abort \"\\n\" }", "del_tokens": "start < - expr EOF", "commit_type": "update"}
{"commit_tokens": ["Fix", "to", "exit", "after", "3", "unsuccessful", "login", "attempts"], "add_tokens": "tries ||= 0", "del_tokens": "tries = 0", "commit_type": "fix"}
{"commit_tokens": ["changed", "default", "for", "foreground_color", "()", "helper", "and", "added", "tests", "for", "it"], "add_tokens": "color . brightness > 0.5 ? \"black\" : \"white\" else \"black\"", "del_tokens": "return \"black\" if color . brightness > 0.5 return \"white\"", "commit_type": "change"}
{"commit_tokens": ["fixed", "bug", "in", "operation", "added", "site", "alias", "and", "xml", "fixture"], "add_tokens": "attr_accessor :auth_type , :currency , :settlement_day , :callback_url , :site_reference , :site_alias , :merchant_name , # TODO add accessor site alias REXML :: XPath . first ( doc , \"//SiteReference\" ) . text = self . site_reference if self . site_reference root = doc . root ( root . elements [ \"Certificate\" ] || root . add_element ( \"Certificate\" ) ) . text = self . site_alias if self . site_alias", "del_tokens": "attr_accessor :auth_type , :currency , :settlement_day , :callback_url , :site_reference , :merchant_name , REXML :: XPath . first ( doc , \"//SiteReference\" ) . text ( self . site_reference ) if self . site_reference", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "command", "value", "instead", "of", "the", "token", "as", "command", "argument", "s", "parsed", "value"], "add_tokens": "if cmd_inst = arg [ token ] # Merge command's arg set with the current definition @definition = @definition . collapse ( cmd_inst ) # Insert command positional arguments pos_args . insert ( 0 , * cmd_inst . argument_scope . positional_args ) pos_vals << cmd_inst . command_value else self . errors << \" ' #{ token } ' is not a valid value for #{ arg } ; valid values are: #{ arg . commands . keys . join ( ', ' ) } \" end else pos_vals << token", "del_tokens": "pos_vals << token cmd_inst = arg [ token ] # Merge command's arg set with the current definition @definition = @definition . collapse ( cmd_inst ) # Insert command positional arguments pos_args . insert ( 0 , * cmd_inst . argument_scope . positional_args )", "commit_type": "use"}
{"commit_tokens": ["moving", "all", "of", "dm", "-", "mores", "gems", "over", "to", "require", "dm", "-", "core", "instead", "of", "data_mapper"], "add_tokens": "require 'dm-core'", "del_tokens": "require 'data_mapper'", "commit_type": "move"}
{"commit_tokens": ["update", "default", "timeout", "to", "30", "seconds"], "add_tokens": "# Jets.logger.info(\"Should not use scan for production. It's slow and expensive. You should create either a LSI or GSI and use query the index instead. Current environment: #{Jets::Config.env}.\") Aws . config . update ( # region: 'us-east-1', endpoint : endpoint , )", "del_tokens": "Jets . logger . error ( \"Should not use scan for production. It's slow and expensive. You should create either a LSI or GSI and use query the index instead. Current environment: #{Jets::Config.env}.\" ) Aws . config . update ( endpoint : endpoint )", "commit_type": "update"}
{"commit_tokens": ["added", "error", "message", "when", "raising", "errors", "in", "client", ".", "rb"], "add_tokens": "400 => lambda { raise FitgemOauth2 :: BadRequestError , JSON . parse ( response . body ) } , 401 => lambda { raise FitgemOauth2 :: UnauthorizedError , JSON . parse ( response . body ) } , 403 => lambda { raise FitgemOauth2 :: ForbiddenError , JSON . parse ( response . body ) } , 404 => lambda { raise FitgemOauth2 :: NotFoundError , JSON . parse ( response . body ) } ,", "del_tokens": "400 => lambda { raise FitgemOauth2 :: BadRequestError } , 401 => lambda { raise FitgemOauth2 :: UnauthorizedError } , 403 => lambda { raise FitgemOauth2 :: ForbiddenError } , 404 => lambda { raise FitgemOauth2 :: NotFoundError } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "specs", "to", "support", "caching", "single", "security", "tokens", "in", "rack_mauth"], "add_tokens": "require 'bundler/setup' remote_app_uuid = remote_key_pair [ app_uuid ] @cached_secrets [ app_uuid ] = { } @cached_secrets [ app_uuid ] [ :private_key ] = remote_app_uuid [ :private_key ] @cached_secrets [ app_uuid ] [ :last_refresh ] = Time . now headers = { \"Content-Type\" => \"application/json\" } headers = options [ :headers ] . nil? ? headers : headers . merge ( options [ :headers ] ) request = Net :: HTTP :: Get . new ( from_url . path , headers )", "del_tokens": "remote_app_uuid = remote_key_pair [ :app_uuid ] @cached_secrets [ remote_app_uuid ] [ :private_key ] = remote_app_uuid [ :private_key ] @cached_secrets [ remote_app_uuid ] [ :last_refresh ] = Time . now request = options [ :headers ] ? Net :: HTTP :: Get . new ( from_url . path , options [ :headers ] ) : Net :: HTTP :: Get . new ( from_url . path )", "commit_type": "add"}
{"commit_tokens": ["Add", "optional", "html_classes", "option", "to", "Swiper", "List", "Page", "Widget"], "add_tokens": "html_classes : options [ :html_classes ] , slide_view_path : 'integral/shared/record_card' , html_classes : ''", "del_tokens": "html_classes : '' , slide_view_path : 'integral/shared/record_card'", "commit_type": "add"}
{"commit_tokens": ["add", "comments", "and", "make", "Comment", ".", "parents", "return", "Commits"], "add_tokens": "@parents = parents . map { | p | Commit . create ( repo , :id => p ) } # Create an unbaked Commit containing just the specified attributes # +repo+ is the Repo # +atts+ is a Hash of instance variable data # # Returns Grit::Commit (unbaked) # Initializer for Commit.create # +repo+ is the Repo # +atts+ is a Hash of instance variable data # # Returns Grit::Commit (unbaked) # +ref+ is the ref from which to begin (SHA1 or name) # # Returns Grit::Commit[] (baked) # Parse out commit information into an array of baked Commit objects # +repo+ is the Repo # +text+ is the text output from the git command (raw format) # # Returns Grit::Commit[] (baked) # Convert this Commit to a String which is just the SHA1 id", "del_tokens": "@parents = parents # +ref+ is the Ref from which to begin (", "commit_type": "add"}
{"commit_tokens": ["Add", "current_user", "from", "option", "to", "attr_reader"], "add_tokens": "attr_reader :object , :options , :current_user @current_user = options [ :current_user ]", "del_tokens": "attr_reader :object , :options", "commit_type": "add"}
{"commit_tokens": ["Make", "Generator#to_ruby", "accessable", "to", "DynamicInliner"], "add_tokens": "Generator . to_ruby ( str ) [ 1 .. - 2 ]", "del_tokens": "str . inspect [ 1 .. - 2 ] . gsub ( '\\n' , \"\\n\" )", "commit_type": "make"}
{"commit_tokens": ["Making", "the", "plugin", "thread", "safe", "by", "using", "Thread", ".", "current"], "add_tokens": "Thread . current [ \"current_user\" ] || GuestUser . new Thread . current [ \"current_user\" ] = user", "del_tokens": "$current_user || GuestUser . new $current_user = user", "commit_type": "make"}
{"commit_tokens": ["Use", "dup", "to", "ensure", "constant", "isn", "t", "changed"], "add_tokens": "@search_engine_ping_urls ||= SEARCH_ENGINE_PING_URLS . dup", "del_tokens": "@search_engine_ping_urls ||= SEARCH_ENGINE_PING_URLS", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "the", "matte", "method", "also", "resizes"], "add_tokens": "raise \"Geometry of #{opts[:dimensions]} not supported for matte images\" unless opts [ :dimensions ] [ / ^( \\d +)x( \\d +)$ / ] convert ( temp_object , \"-gravity #{opts[:gravity]} -resize #{opts[:dimensions]}^^ -crop #{opts[:dimensions]}+0+0>\\! -background #{opts[:background]} -flatten\" )", "del_tokens": "convert ( temp_object , \"-gravity #{opts[:gravity]} -crop #{opts[:dimensions]}+0+0\\! -background #{opts[:background]} -flatten\" )", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "method", "just", "to", "fully", "validate", "the", "schema", "itself", "."], "add_tokens": "def valid_schema { end def invalid_schema { } end def test_draft03_validation data = { \"b\" => { \"a\" => 5 } } assert ( JSON :: Validator . validate ( valid_schema , data , :validate_schema => true ) ) assert ( ! JSON :: Validator . validate ( invalid_schema , data , :validate_schema => true ) ) end def test_validate_just_schema errors = JSON :: Validator . fully_validate_schema ( valid_schema ) assert_equal [ ] , errors errors = JSON :: Validator . fully_validate_schema ( invalid_schema ) assert_equal 1 , errors . size assert_match / the property .*required.*did not match /i , errors . first", "del_tokens": "def test_draft03_validation data = { \"b\" => { \"a\" => 5 } } schema = { assert ( JSON :: Validator . validate ( schema , data , :validate_schema => true ) ) schema = { } assert ( ! JSON :: Validator . validate ( schema , data , :validate_schema => true ) )", "commit_type": "add"}
{"commit_tokens": ["Updated", "search", "to", "use", "GraphCollection", "and", "updated", "GraphCollection", "tests", "."], "add_tokens": "GraphCollection . new ( graph_call ( \"#{id}/#{connection_name}\" , args ) ) GraphCollection . new ( graph_call ( \"search\" , args . merge ( { :q => search_terms } ) ) )", "del_tokens": "GraphCollection . new graph_call ( \"#{id}/#{connection_name}\" , args ) graph_call ( \"search\" , args . merge ( { :q => search_terms } ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "authorization", "support", "for", "command", "line", "app"], "add_tokens": "module Gemfury :: Command ; end require 'gemfury/command/authorization' require 'gemfury/command/app'", "del_tokens": "module Gemfury class Command < Thor include Gemfury :: Platform desc \"version\" , \"Check whether the gem is up-to-date\" def version client . check_version end desc \"push GEM\" , \"upload a new version of a gem\" def push ( * gems ) gem_files = gems . map do | g | File . exists? ( g ) ? File . new ( g ) : nil end . compact if gem_files . empty? shell . say \"Problem: No valid gems specified\" , :red help ( :push ) return end # Let's get uploading gem_files . each do | gem_file | shell . say \"Uploading #{File.basename(gem_file)}\" client . push_gem ( gem_file ) end end private def client options = { } # Load up the credentials config_path = File . expand_path ( '.gem/gemfury' , home_directory ) if File . exist? ( config_path ) config = YAML . load_file ( config_path ) options [ :user_api_key ] = config [ :gemfury_api_key ] end Gemfury :: Client . new ( options ) end end end", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", ";", "version", "bump"], "add_tokens": "coerce_property :images , collection : ImageItem coerce_property :videos , collection : VideoItem", "del_tokens": "coerce_property :images , class : ImageItem coerce_property :videos , class : VideoItem", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "minor", "bug", "with", "RightLinkLogger", "."], "add_tokens": "@logger = Multiplexer . new ( Nanite :: Log . logger ) @logger . add ( sysloger ) if sysloger", "del_tokens": "@logger = Multiplexer . new ( Nanite :: Log . logger ) @logger . add_logger ( sysloger ) if sysloger", "commit_type": "fix"}
{"commit_tokens": ["use", "hpricot", "helper", "for", "view_helpers"], "add_tokens": "subject { action_view . paginate collection , :class => \"dummy\" } it ( \"should have div with class paginate and dummy\" ) { subject . should have_tag ( 'div[@class=pagination dummy]' , :count => 1 ) } it ( \"should have div with ul\" ) { subject . should have_tag ( 'div > ul' , :count => 1 ) }", "del_tokens": "before { @pagination = action_view . paginate collection , :class => \"dummy\" } subject { @pagination } it { subject . should match ( / <div class=\"pagination dummy\"> / ) }", "commit_type": "use"}
{"commit_tokens": ["Fixed", "infinite", "loop", "bug", "for", "certain", "character", "sets"], "add_tokens": "/ [%-+] / , # This regex is \"supposed to\" match some surprising things!!! / ['-.] / # Test to ensure no \"infinite loop\" on character set expansion", "del_tokens": "/ [%-+] / # This regex is \"supposed to\" match some surprising things!!!", "commit_type": "fix"}
{"commit_tokens": ["use", "newly", "named", "class", "helper", "#source_class"], "add_tokens": "source_klass . instance_methods . map { | m | m . to_s . match ( / response \\_ (?<name> \\w *) / ) } . compact . each do | match |", "del_tokens": "klass_to_decorate . instance_methods . map { | m | m . to_s . match ( / response \\_ (?<name> \\w *) / ) } . compact . each do | match |", "commit_type": "use"}
{"commit_tokens": ["Add", "security", "modules", "phase", "to", "wizard"], "add_tokens": "project = Bebox :: Project . new ( project_name , @hosts , @vbox_uri , @vagrant_box_base_name , \"#{Dir.pwd}/tmp\" , @vagrant_box_provider , environments )", "del_tokens": "project = Bebox :: Project . new ( project_name , @hosts , @vbox_uri , @vagrant_box_base_name , Dir . pwd , @vagrant_box_provider , environments )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "creating", "and", "removing", "subscriptions"], "add_tokens": "resp = raw_post make_subscription_url ( opts . merge ( { :use_subscription_id => true } ) ) , EMPTY_BODY , make_headers ( opts ) resp = raw_delete make_subscription_url ( opts . merge ( { :use_subscription_id => true } ) ) , make_headers ( opts ) headers = { } \"\" else \"/\" + opts [ :type ] . to_s end", "del_tokens": "resp = raw_post make_subscription_url ( opts ) , EMPTY_BODY , make_headers ( opts . merge ( { :use_subscription_id => true } ) ) resp = raw_delete make_subscription_url ( opts ) , make_headers ( opts . merge ( { :use_subscription_id => true } ) ) headers = opts . dup headers . delete :subscriber_id headers . delete :subscription_id if headers [ :subscription_id ] headers . delete :type if headers [ :type ] headers . delete :use_subscription_id if headers [ :use_subscription_id ] \"\" else \"/\" + opts [ :type ] . to_s end", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "weird", "bug", "because", "I", "m", "accidentally", "mutating", "the", "name", "string", "on", "the", "spec", "object", "."], "add_tokens": "entry_point_name += '.rb' unless entry_point_name . end_with? ( '.rb' )", "del_tokens": "entry_point_name << '.rb' unless entry_point_name . end_with? ( '.rb' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "macro", "for", "GoodJob", "adapter"], "add_tokens": "%w[ delayed_job resque sidekiq qu qc bunny que good_job ] . each do | file |", "del_tokens": "%w[ delayed_job resque sidekiq qu qc bunny que ] . each do | file |", "commit_type": "add"}
{"commit_tokens": ["Use", "before_provision", "callback", "instead", "of", "a", "custom", "one"], "add_tokens": "before_provision :wake_up_orchestration", "del_tokens": "define_model_callbacks :built , :only => :after # TODO open Foreman PR and add a check to remove it after migration to Foreman 1.5 after_commit :run_built_hooks after_built :wake_up_orchestration end def run_built_hooks if previous_changes [ :build ] == [ true , false ] && installed_at run_callbacks :built end", "commit_type": "use"}
{"commit_tokens": ["Add", "raw_json", "diff", "symbols", "as", "strings"], "add_tokens": "json = resource . raw_json || { } else old_json = old_json . to_s if old_json . kind_of? ( Symbol ) new_json = new_json . to_s if new_json . kind_of? ( Symbol ) if old_json != new_json if print_values result << \"update #{name} from #{old_json.inspect} to #{new_json.inspect}\" else result << \"update #{name}\" end", "del_tokens": "json = { } elsif old_json != new_json if print_values result << \"update #{name} from #{old_json.inspect} to #{new_json.inspect}\" else result << \"update #{name}\"", "commit_type": "add"}
{"commit_tokens": ["Removed", "casting", "first", "letter", "to", "integer"], "add_tokens": "weighted :first , :letter", "del_tokens": "weighted ( :first , :letter ) . to_i", "commit_type": "remove"}
{"commit_tokens": ["Add", "min", "key", "JSON", "serialization"], "add_tokens": "{ \"$maxKey\" => 1 }", "del_tokens": "{ \"$maxKey\" => GREATER }", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "directory", "resource", "and", "provider"], "add_tokens": ":file => Chef :: Provider :: File , :directory => Chef :: Provider :: Directory", "del_tokens": ":file => Chef :: Provider :: File", "commit_type": "add"}
{"commit_tokens": ["Added", "code", "to", "support", "the", ":", "class_name", "attribute", "on", "object", "associations", "."], "add_tokens": "klass = @object . class . reflect_on_association ( symbol ) . class_name . constantize klass . make ( args . first || { } )", "del_tokens": "symbol . to_s . camelize . constantize . make ( args . first || { } )", "commit_type": "add"}
{"commit_tokens": ["Updated", "changelog", "version", "bump", "[", "ci", "skip", "]"], "add_tokens": "VERSION = \"1.4.0\"", "del_tokens": "VERSION = \"1.3.3\"", "commit_type": "update"}
{"commit_tokens": ["Allow", "for", "concurrent", "notifications", "."], "add_tokens": "each { | subscriber | event . notify subscriber }", "del_tokens": "each { | subscriber | @mutex . synchronize { event . notify subscriber } }", "commit_type": "allow"}
{"commit_tokens": ["Update", "the", "class", "constants", "in", "place", "to", "avoid", "a", "warning", "."], "add_tokens": "FORBIDDEN_IVARS . concat [ :@application , :@application_provider ] HIDDEN_IVARS . concat [ :@application , :@application_provider ]", "del_tokens": "FORBIDDEN_IVARS += [ :@application , :@application_provider ] HIDDEN_IVARS += [ :@application , :@application_provider ]", "commit_type": "update"}
{"commit_tokens": ["updated", "the", "benchmark", "with", "the", "api", "change"], "add_tokens": "Typhoeus . init_easy_object_pool", "del_tokens": "Typhoeus . init_easy_objects", "commit_type": "update"}
{"commit_tokens": ["Change", "inspect", "format", "and", "test", "it", "is", "executable"], "add_tokens": "\"Units::Measure[#{@magnitude.inspect}, #{@units.inspect}]\"", "del_tokens": "\"Measure(#{@magnitude.inspect}, #{@units.inspect})\"", "commit_type": "change"}
{"commit_tokens": ["add", "get_table", "to", "TableService", "and", "update", "serialization", "for", "create_table"], "add_tokens": "body = Azure :: Entity :: Serialization . hash_to_entry_xml ( { \"TableName\" => table_name } ) . to_xml response = call ( :post , collection_uri , body ) # Public: Gets the table. # # table_name - String. The table name # # Returns a Hash of table properties on success # # eg: # { # \"name\" => \"mytable\", # \"url\" => \"http://myaccount.table.core.windows.net/Tables('mytable')\", # \"updated\" => \"2008-10-01 15:26:13 UTC\" # } # def get_table ( table_name ) response = call ( :get , table_uri ( table_name ) ) results = Azure :: Entity :: Serialization . hash_from_entry_xml ( response . body ) { \"name\" => table_name , \"url\" => results [ 'url' ] , \"updated\" => results [ 'updated' ] } end", "del_tokens": "body = Azure :: Tables :: Atom :: Entry . new do | entry | entry . properties [ \"TableName\" ] = table_name end response = call ( :post , collection_uri , body . to_xml )", "commit_type": "add"}
{"commit_tokens": ["added", "bootstrap3", "-", "based", "dashboard", "removed", "www", "class", "moved", "Job", ".", "get", "as", "a", "public", "method"], "add_tokens": "require 'rubygems'", "del_tokens": "# require 'rest-ftp-daemon/api/workers' require 'rest-ftp-daemon/www'", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "creation", "of", "secured", "api", "key"], "add_tokens": "Digest :: HMAC . hexdigest ( \"#{tag_filters}#{user_token.to_s}\" , private_api_key , Digest :: SHA256 )", "del_tokens": "Digest :: SHA256 . hexdigest \"#{private_api_key}#{tag_filters}#{user_token.to_s}\"", "commit_type": "change"}
{"commit_tokens": ["fixed", "build", "errors", "added", "configuration", "stuff"], "add_tokens": "dep_paths = exe . dependencies . map { | dep | get_path_for_lib ( dep ) } . flatten", "del_tokens": "dep_paths = exe . dependencies . map { | dep | get_path_for_lib ( dep ) }", "commit_type": "fix"}
{"commit_tokens": ["improve", "jpeg", "dispatch", "to", "exif", "which", "implementations", "of", "respond_to?", "methods", "and", "instance_methods"], "add_tokens": "# Dispatch to EXIF. When no EXIF data is available but the # +method+ does exist for EXIF data +nil+ will be returned. def respond_to? ( method ) # :nodoc: super || TIFF :: TAGS . map { | m | m . to_s } . include? ( method . to_s ) end def methods # :nodoc: super + TIFF :: TAGS end class << self alias instance_methods_without_jpeg_extras instance_methods def instance_methods ( include_super = true ) # :nodoc: instance_methods_without_jpeg_extras ( include_super ) + TIFF :: TAGS end end", "del_tokens": "# Dispatch to EXIF. When no EXIF data is available but the +method+ does exist # for EXIF data +nil+ will be returned.", "commit_type": "improve"}
{"commit_tokens": ["Add", "to_json", "method", "to", "messages", "don", "t", "freeze", "it", "anymore"], "add_tokens": "alias :as_json :to_s # Messages are implicitly conversible to Strings alias :to_str :to_s def to_json as_json . to_json end", "del_tokens": "# Freeze the newly created message to ensure it can't be changed. # All passed values are also effectively frozen, making the Message an # immutable object. freeze alias_method :to_str , :to_s alias_method :as_json , :to_s", "commit_type": "add"}
{"commit_tokens": ["Make", "primitive?", "an", "utility", "class", "method", "since", "it", "doesn", "t", "depend", "on", "the", "instance", "state"], "add_tokens": "# Returns if the given value's class is an attribute's primitive # # @example # Virtus::Attribute::String.primitive?('String') # => true # # @return [TrueClass, FalseClass] # # @api semipublic def self . primitive? ( value ) value . kind_of? ( primitive ) end if value . nil? || self . class . primitive? ( value )", "del_tokens": "# Returns if the given value's class is an attribute's primitive # # @return [TrueClass, FalseClass] # # @api private def primitive? ( value ) value . kind_of? ( primitive ) end if value . nil? || primitive? ( value )", "commit_type": "make"}
{"commit_tokens": ["move", "DEFAULT_PER_PAGE", "to", "::", "Kaminari", "module"], "add_tokens": "DEFAULT_PER_PAGE = 25 unless defined? :: Kaminari :: DEFAULT_PER_PAGE @_default_per_page || Kaminari :: DEFAULT_PER_PAGE", "del_tokens": "DEFAULT_PER_PAGE = 25 @_default_per_page || Kaminari :: ActiveRecordExtension :: DEFAULT_PER_PAGE", "commit_type": "move"}
{"commit_tokens": ["Remove", "warning", "from", "protocol", "spec"], "add_tokens": "let ( :Protocol ) { Moped :: Protocol }", "del_tokens": "Protocol = Moped :: Protocol", "commit_type": "remove"}
{"commit_tokens": ["Make", "sure", "@service", "is", "a", "Symbol"], "add_tokens": "@service = service . to_sym", "del_tokens": "@service = service", "commit_type": "make"}
{"commit_tokens": ["Make", "Index#entries", "and", "Index#stat", "public", "methods"], "add_tokens": "# A cached version of `Dir.entries` that filters out `.` and # `..`. Returns an empty `Array` if the directory does not exist. def entries ( path ) key = path . to_s @entries [ key ] ||= Pathname . new ( path ) . entries . reject { | entry | entry . to_s =~ / ^ \\. \\. ?$ / } rescue Errno :: ENOENT @entries [ key ] = [ ] end # A cached version of `File.stat`. Returns nil if the file does # not exist. def stat ( path ) key = path . to_s if @stats . key? ( key ) @stats [ key ] else begin @stats [ key ] = File . stat ( path ) rescue Errno :: ENOENT @stats [ key ] = nil end end end", "del_tokens": "# A cached version of `File.stat`. Returns nil if the file does # not exist. def stat ( pathname ) if @stats . key? ( pathname ) @stats [ pathname ] else begin @stats [ pathname ] = pathname . stat rescue Errno :: ENOENT @stats [ pathname ] = nil end end end # A cached version of `Dir.entries` that filters out `.` and # `..`. Returns an empty `Array` if the directory does not exist. def entries ( pathname ) @entries [ pathname ] ||= pathname . entries . reject { | entry | entry . to_s =~ / ^ \\. \\. ?$ / } rescue Errno :: ENOENT @entries [ pathname ] = [ ] end", "commit_type": "make"}
{"commit_tokens": ["Updated", "FCSH", "comments", "and", "preparing", "to", "rework", "due", "to", "sleep", "/", "stderr", "bug"], "add_tokens": "# Unfortunately, LittleLexer did not support streamed input, which # we definitely need. # In fact - this problem actually ruins # the entire implementation, the larger/longer # it takes for errors to be bufferred, the more # likely it is we'll return without displaying them. # The only way to overcome this with the current # implementation, is to increase the timeout so that # FCSH takes a long, long time on every compilation!!! sleep ( 0.2 )", "del_tokens": "# Unfortunately, LittleLexer did not support long-lived Stream input, which # (I think) we needed. sleep ( 0.05 )", "commit_type": "update"}
{"commit_tokens": ["move", "detection", "of", "uncompiled", "packages", "to", "package", "compiler", "from", "update", "deployment", "job"], "add_tokens": "def initialize ( deployment_plan ) def find_uncompiled_packages uncompiled_packages = [ ] release_version = @deployment_plan . release . release @deployment_plan . jobs . each do | job | stemcell = job . resource_pool . stemcell . stemcell template = Models :: Template . find ( :release_version_id => release_version . id , :name => job . template ) . first template . packages . each do | package | job . packages [ package . name ] = package . version compiled_package = Models :: CompiledPackage . find ( :package_id => package . id , :stemcell_id => stemcell . id ) . first unless compiled_package uncompiled_packages << { :package => package , :stemcell => stemcell } end end end uncompiled_packages end uncompiled_packages = find_uncompiled_packages return if uncompiled_packages . empty? uncompiled_packages . each do | uncompiled_package |", "del_tokens": "def initialize ( deployment_plan , uncompiled_packages ) @uncompiled_packages = uncompiled_packages @uncompiled_packages . each do | uncompiled_package |", "commit_type": "move"}
{"commit_tokens": ["Use", "Time", ".", "httpdate", "instead", "of", "Time", ".", "parse", "add", "encoding", "to", "spec", "/", "api_auth_spec", ".", "rb"], "add_tokens": "# encoding: UTF-8 # api-auth is Ruby gem designed to be used both in your client and serve Time . httpdate ( headers . timestamp ) . utc < ( Time . now . utc - 900 )", "del_tokens": "# api-auth is Ruby gem designed to be used both in your client and server # HTTP-based applications. It implements the same authentication methods (HMAC) # used by Amazon Web Services. # The gem will sign your requests on the client side and authenticate that Time . parse ( headers . timestamp ) . utc < ( Time . now . utc - 900 )", "commit_type": "use"}
{"commit_tokens": ["Add", "build", "-", "cache", "command"], "add_tokens": "# LAW103X - http://lancaster.myreadinglists.org/lists/A56880F3-10B3-45EC-FD16-D29D0198AEE3 # LAW102X - http://lancaster.myreadinglists.org/lists/4510B70F-7C50-D726-4A6C-B129F5EABB2C @builder . write_list ( 'http://lancaster.myreadinglists.org/lists/4510B70F-7C50-D726-4A6C-B129F5EABB2C' )", "del_tokens": "@builder . write_list ( 'http://lancaster.myreadinglists.org/lists/A56880F3-10B3-45EC-FD16-D29D0198AEE3' )", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "multi", "-", "line", "attr", "to", "single", "line", "attrs", "instead"], "add_tokens": "attr :page attr :per_page attr :total", "del_tokens": "attr :page , :per_page , :total", "commit_type": "change"}
{"commit_tokens": ["fixed", "delete", "(", "typo", "in", "controller", ")"], "add_tokens": "def delete", "del_tokens": "def destroy", "commit_type": "fix"}
{"commit_tokens": ["remove", "need", "to", "list", "-", "types"], "add_tokens": "if value . is_a? ( Hash ) converted = if value . has_key? ( \"item\" )", "del_tokens": "if Lists . include? ( key ) converted = if value && value . has_key? ( \"item\" )", "commit_type": "remove"}
{"commit_tokens": ["fix", "character", "position", "error", "with", "parselet"], "add_tokens": "source . instance_variable_get ( :@str ) . string [ position . bytepos ]", "del_tokens": "source . instance_variable_get ( :@str ) . string [ position ]", "commit_type": "fix"}
{"commit_tokens": ["upgrade", "to", "rspec", "2", "and", "rm", "debug", "output", "from", "tests"], "add_tokens": "# # lambda { lambda { lambda {", "del_tokens": "# # lambda { lambda { lambda { pp self . methods", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "show_disk_loc", "and", "return_key", "options"], "add_tokens": "require \"origin/optional/return_key\" require \"origin/optional/show_disk_loc\" include ReturnKey include ShowDiskLoc", "del_tokens": "# require \"origin/optional/show_disk_loc\" # require \"origin/optional/return_key\"", "commit_type": "add"}
{"commit_tokens": ["use", "only", "full", "time", "format", "for", "all", "items"], "add_tokens": "@updated = opts [ :updated ] || Time . now # allow only date or time object # use full time and date only! @updated = @updated . to_time if @updated . kind_of? ( Date ) # use UTC only! @updated = @updated . utc", "del_tokens": "@updated = opts [ :updated ] || Time . now . utc", "commit_type": "use"}
{"commit_tokens": ["Allow", "setting", "enforce_ttl", "in", "verifier", "block"], "add_tokens": "def self . verifier ( secret , token , & block ) v . verify ( & block )", "del_tokens": "def self . verifier ( secret , token ) v . verify", "commit_type": "allow"}
{"commit_tokens": ["Added", "missing", "test", "cases", "to", "the", "scanner", "test_all", "file"], "add_tokens": "anchors escapes groups meta properties quantifiers sets types utf8", "del_tokens": "anchors escapes", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "stupid", "mistake", "."], "add_tokens": "def titlecase ( text ) return text . titlecase end", "del_tokens": "def titlecase ( text ) return text . titlecase end", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "specify", "a", "table", "cell", "style", "when", "appending", "creating", "or", "building"], "add_tokens": "style = opts [ :cell_style ] || UITableViewCellStyleDefault klass . alloc . initWithStyle ( style , reuseIdentifier : reuse_identifier ) . tap do | o |", "del_tokens": "klass . alloc . initWithStyle ( UITableViewCellStyleDefault , reuseIdentifier : reuse_identifier ) . tap do | o |", "commit_type": "add"}
{"commit_tokens": ["move", "ErrorResponse", "inside", "Base", "alongside", "BaseResponse"], "add_tokens": "ErrorResponse . from_xml ( e . response . body ) class ErrorResponse < AmazonFlexPay :: Model #:nodoc: # Re-implements the XML parsing because ErrorResponse does not inherit from BaseResponse. def self . from_xml ( xml ) new ( MultiXml . parse ( xml ) [ 'Response' ] ) end # Check response.error? to determine whether Amazon accepted the request. def error? true end attribute :request attribute :request_id attr_reader :errors def errors = ( val ) @errors = [ val [ 'Error' ] ] . flatten . map { | e | Error . new ( e ) } end class Error < AmazonFlexPay :: Model #:nodoc: attribute :code attribute :message end end", "del_tokens": "AmazonFlexPay :: API :: ErrorResponse . from_xml ( e . response . body )", "commit_type": "move"}
{"commit_tokens": ["Use", "const_get", "instead", "of", "constantize", "fix", "login", "system", "spec", "again", "."], "add_tokens": "Registry . const_get ( install_type ) . new ( self ) . install", "del_tokens": "install_type . constantize . new ( self ) . install", "commit_type": "use"}
{"commit_tokens": ["Added", "test", "for", "foundation5", "to", "helper_methods_test", ".", "rb", "."], "add_tokens": "test \"foundation5 style\" do breadcrumb :basic assert_equal %{<ul class=\"breadcrumb\"><li><a href=\"/\">Home</a></li><li class=\"current\">About</li></ol>} , breadcrumbs ( style : :foundation5 ) end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Moving", "over", "the", "PatientImporter", "from", "QME"], "add_tokens": "require_relative 'health-data-standards/import/c32/section_importer' require_relative 'health-data-standards/import/c32/patient_importer'", "del_tokens": "require_relative 'health-data-standards/import/c32/section_importer'", "commit_type": "move"}
{"commit_tokens": ["Make", "String#msub", "inject", "the", "match", "string", "into", "the", "caller", "s", "binding", "."], "add_tokens": "cache [ match ] ||= begin eval ( \"__match__ = #{match.inspect}\" , binding ) subs . find { | key , _ | key =~ match } . last . evaluate ( binding ) end p s . msub ( / [A-Z] / => '#{__match__.downcase}' , :__binding__ => binding )", "del_tokens": "cache [ match ] ||= subs . find { | key , _ | key =~ match } . last . evaluate ( binding )", "commit_type": "make"}
{"commit_tokens": ["Add", "Class", "Registration", "for", "Coercion"], "add_tokens": "VERSION = \"0.5.1\"", "del_tokens": "VERSION = \"0.5.0\"", "commit_type": "add"}
{"commit_tokens": ["Changed", "filename", "from", ".", "env", "to", ".", "env", ".", "example"], "add_tokens": "source \".env.example\"", "del_tokens": "source \".env\"", "commit_type": "change"}
{"commit_tokens": ["Removed", "updated_at", "from", "migration", "template", "because", "events", "are", "immutable"], "add_tokens": "t . datetime :created_at , null : false", "del_tokens": "t . timestamps", "commit_type": "remove"}
{"commit_tokens": ["Removed", "Sys", "from", "split_all", "call", "."], "add_tokens": "split_all ( dir ) . each do | p | file File . join ( path ) do | t | mkdir_p t . name if ! File . exist? ( t . name )", "del_tokens": "Sys . split_all ( dir ) . each do | p | FileTask . define_task ( File . join ( path ) ) do | t | mkdir_p t . name", "commit_type": "remove"}
{"commit_tokens": ["Removed", "a", "puts", "statement", "which", "was", "outputting", "useless", "stuff"], "add_tokens": "# puts \"NODE Count: \" + nodes.length.to_s", "del_tokens": "puts \"NODE Count: \" + nodes . length . to_s", "commit_type": "remove"}
{"commit_tokens": ["Add", "some", "guards", "for", ":", "watir2"], "add_tokens": "not_compliant_on :watir2 do it \"returns false after IE#close\" do b = WatirSpec . new_browser b . close b . should_not exist end not_compliant_on :watir2 do it \"does not raise error on a blank page\" do browser = WatirSpec . new_browser lambda { browser . contains_text ( '' ) } . should_not raise_error end", "del_tokens": "it \"returns false after IE#close\" do b = WatirSpec . new_browser b . close b . should_not exist it \"does not raise error on a blank page\" do browser = WatirSpec . new_browser lambda { browser . contains_text ( '' ) } . should_not raise_error", "commit_type": "add"}
{"commit_tokens": ["adding", "base", "controller", "authenticate_controller?", "method", "layout", "and", "associated", "docs"], "add_tokens": "# encrypted_password 'password' password 'password' trait :without_email do email nil end trait :without_password do password nil encrypted_password nil end", "del_tokens": "encrypted_password 'password'", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "default", "keep", "-", "alive", "time", "for", "a", "MQTT", "::", "Packet", "from", "10", "to", "15", "seconds", "to", "match", "the", "default", "in", "MQTT", "::", "Client"], "add_tokens": ":keep_alive => 15 ,", "del_tokens": ":keep_alive => 10 ,", "commit_type": "change"}
{"commit_tokens": ["add", "status", "--", "unmodified", "mode"], "add_tokens": "count_unmodified = 0 count_unmodified += 1 case @options [ :unmodified ] when \"HIDE\" # do nothing when \"SHOW\" puts \" #{repo.name}: #{repo.path}\" when \"DOTS\" print \".\" . green need_lf = true else raise \"invalid mode '#{@options[:unmodified]}' for '--unmodified' option\" end # summary puts \"no modified repositories, all working folders are clean\" if ( count_unmodified == repos . size ) # numeric return", "del_tokens": "print \".\" . green need_lf = true", "commit_type": "add"}
{"commit_tokens": ["Add", ":", "simplify", "and", ":", "preserve", "variants", "to", "Rounding"], "add_tokens": "# or one of these special values: # * :exact for no rounding at all (to represent the situation where # we want to get an exact numeral result). # * :simplify, which is a variant of :exact where no rounding occurs, but # we want to represent the result as simply (with as few digits) as # possible (mantaining its value within the original precision). # * :preserve, which is another variant of :exact which tries tro preserve # the original precision (i.e. information given by trailing zeros) # :preserve and :simplify are meaningful when applied to approximate # numerals, which have some specific precision. { mode : @mode } \"Rounding[#{@mode.inspect}]\" [ :exact , :simplify , :preserve ] . include? ( @mode ) def simplifying? @mode == :simplify end def preserving? @mode == :preserve end", "del_tokens": "# or :exact for no rounding at all (to represent the situation where # we want to get an exact numeral result). { mode : :exact } \"Rounding[:exact]\" @mode == :exact", "commit_type": "add"}
{"commit_tokens": ["Add", "verbose", "mode", "and", "turn", "off", "disabled", "status", "unless", "in", "verbose", "mode"], "add_tokens": "attr_accessor :name , :display_name , :log_exclude , :base_path , :sv_path , :service_path , :etc_path , :data_path , :log_path , :command_map , :fh_output , :kill_users , :verbose @verbose = false log \"#{service_name} disabled\" if sv_cmd == \"status\" && verbose # Set options. Silently ignore bad options. # This allows the test subcommand to pass on pedant options def parse_options! ( args ) args . each do | option | case option when \"--verbose\" , \"-v\" @verbose = true end end end service = args [ 1 ] options = args [ 2 .. - 1 ] || [ ] log \"Did you mean: #{$0} #{service} #{command_to_run}?\" parse_options! options # Filter args to just command and service. If you are loading # custom commands and need access to the command line argument, # use ARGV directly. actual_args = [ command_to_run , service ] . reject ( & :nil? ) self . send ( method_to_call . to_sym , * actual_args )", "del_tokens": "attr_accessor :name , :display_name , :log_exclude , :base_path , :sv_path , :service_path , :etc_path , :data_path , :log_path , :command_map , :fh_output , :kill_users log \"#{service_name} disabled\" if sv_cmd == \"status\" log \"Did you mean: #{$0} #{args[1]} #{args[0]}?\" self . send ( method_to_call . to_sym , * args )", "commit_type": "add"}
{"commit_tokens": ["use", "ARGV", "for", "default", "parsing", "array"], "add_tokens": "def self . parse ( items , & block ) def parse ( items = ARGV ) def parse! ( items = ARGV )", "del_tokens": "def self . parse ( items = ARGV , & block ) def parse ( items ) def parse! ( items )", "commit_type": "use"}
{"commit_tokens": ["Allow", "user", "micro", "data", "and", "css", "classes"], "add_tokens": "input_attrs [ :class ] = ( input_attrs . fetch ( :class , \"\" ) . split ( \" \" ) << cls ) . join ( \" \" ) opts [ :hd_opts ] ||= { } opts [ :data ] ||= { } input_attrs [ :data ] = opts [ :hd_opts ] . merge ( opts [ :data ] ) #TODO store these defaults somewhere and allow users to override them", "del_tokens": "#binding.pry input_attrs [ :class ] = cls #binding.pry input_attrs [ :data ] = opts [ :data ] ||= { }", "commit_type": "allow"}
{"commit_tokens": ["adding", "support", "for", "linux", "ssh", "keys"], "add_tokens": "option :ssh_key , :long => \"--ssh-key FILENAME\" , :description => \"SSH key\" , :proc => Proc . new { | key | Chef :: Config [ :knife ] [ :ssh_key ] = key } option :ssh_key_passphrase , :long => \"--ssh-key-passphrase PASSWORD\" , :description => \"SSH key passphrase\" , :proc => Proc . new { | pp | Chef :: Config [ :knife ] [ :ssh_key_passphrase ] = pp } :ssh_key => locate_config_value ( :ssh_key ) , :ssh_key_passphrase => locate_config_value ( :ssh_key_passphrase )", "del_tokens": "option :ssh_cert , :long => \"--ssh-cert FILENAME\" , :description => \"SSH Certificate in X509 format\" , :proc => Proc . new { | key | Chef :: Config [ :knife ] [ :ssh_cert ] = key } :ssh_cert => locate_config_value ( :ssh_cert )", "commit_type": "add"}
{"commit_tokens": ["Removing", "hardcoded", "path", "to", "test_site", "for", "Cukes"], "add_tokens": "config . app_host = \"file://\" + File . dirname ( __FILE__ ) + \"/../../test_site/html\"", "del_tokens": "config . app_host = \"file:///Users/nat/github/site_prism/test_site/html\"", "commit_type": "remove"}
{"commit_tokens": ["Move", "ActsAsCiteable", "into", "its", "own", ".", "rb", ";", "move", "Citation", "into", "the", "root", "level", ";", "autoload", "more", "stuff"], "add_tokens": "autoload :ActsAsCiteable , 'gov_kit/acts_as_citeable' autoload :\" SearchEngines::GoogleNews \" , 'gov_kit/search_engines/google_news' autoload :\" SearchEngines::GoogleBlogSearch \" , 'gov_kit/search_engines/google_blog_search' autoload :\" SearchEngines::Technorati \" , 'gov_kit/search_engines/technorati' class Citation attr_accessor :url , :excerpt , :title , :source , :date , :weight", "del_tokens": "require 'gov_kit/search_engines/google_news' require 'gov_kit/search_engines/google_blog_search' require 'gov_kit/search_engines/technorati' module ActsAsCiteable def self . included ( base ) base . extend ActMethods end module ActMethods def acts_as_citeable ( options = { } ) options [ :keywords ] ||= [ ] class_inheritable_accessor :options self . options = options unless included_modules . include? InstanceMethods extend ClassMethods include InstanceMethods end end end module ClassMethods end module InstanceMethods def raw_citations params = self . options [ :keywords ] . clone attributes = self . options [ :with ] . clone attributes . each do | attr | params << self . instance_eval ( \"#{attr}\" ) end { :google_news => SearchEngines :: GoogleNewsSearch . search ( params ) , :google_blogs => SearchEngines :: GoogleBlogSearch . search ( params ) , :technorati => SearchEngines :: TechnoratiSearch . search ( params ) } end end", "commit_type": "move"}
{"commit_tokens": ["fixed", "bug", "with", "Vagrantfile", "template"], "add_tokens": "default_values , ConfigData . real_type_filename ( 'for' , @options [ :___use_template___ ] )", "del_tokens": "default_values", "commit_type": "fix"}
{"commit_tokens": ["Add", "specs", "for", "oauth", "authorization", "fixed", "implementation", "."], "add_tokens": ":site => 'https://github.com' , _verify_client @client . auth_code _verify_client _verify_client private def _verify_client # :nodoc: raise ArgumentError , 'Need to provide client_id and client_secret' unless client_id? && client_secret? end", "del_tokens": "debugger :site => 'https://github.com/login/oauth/authorize' , @client . oauth_code", "commit_type": "add"}
{"commit_tokens": ["add", "api", "auth", "file", "to", "gemspec"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "sample", "code", "to", "include", "concrete", "stubbing", "and", "mocking"], "add_tokens": "require 'hardmock' class MyTest < Test :: Unit :: TestCase def setup create_mocks :garage , :car end def test_the_mocks # Set some expectations @garage . expects . open_door @car . expects . start ( :choke ) @car . expects . drive ( :reverse , 5 . mph ) # Execute the code (normally your own classes do this) @garage . open_door @car . start :choke @car . drive :reverse , 5 . mph end def test_the_concrete_stubbing_and_mocking SchoolBus . stubs! ( :color , \"yellow\" ) Entanglement . expects! ( :new , \"my false entanglement\" ) cat . expects! ( :hungry ) . returns ( \"meow\" ) end end", "del_tokens": "require 'hardmock' class MyTest < Test :: Unit :: TestCase def setup create_mocks :garage , :car end def test_the_mocks # Set some expectations @garage . expects . open_door @car . expects . start ( :choke ) @car . expects . drive ( :reverse , 5 . mph ) # Execute the code (normally your own classes do this) @garage . open_door @car . start :choke @car . drive :reverse , 5 . mph end end", "commit_type": "update"}
{"commit_tokens": ["fix", "experiment", "starting", "point", "test"], "add_tokens": "e = Biopsy :: Experiment . new ( 'target_test' , nil , s )", "del_tokens": "e = Biopsy :: Experiment . new ( 'target_test' , s )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "clean", "tags", "to", "clobber", "(", "more", "consistent", "nomenclature", ")"], "add_tokens": "task :repackage => [ :clobber_package , :package ] task :clobber_package do task :clobber => [ :clobber_package ]", "del_tokens": "task :repackage => [ :clean_package , :package ] task :clean_package do def xdefine # == Package Creation desc \"Force a rebuild of the package files\" task :repackage => [ :clean_package , :package ] desc \"Remove package products\" task :clean_package do rm_r package_dir rescue nil end desc \"Build the distribution package\" task :package => [ # Create a distribution package \"#{package_dir}/#{tgz_file}\" , \"#{package_dir}/#{zip_file}\" , ] file \"#{package_dir}/#{tgz_file}\" => [ package_dir ] do chdir ( package_dir ) do Sys . run %{tar zcvf #{tgz_file} #{package_name}} end end file \"#{package_dir}/#{zip_file}\" => [ package_dir ] do chdir ( package_dir ) do Sys . run %{zip -r #{zip_file} #{package_name}} end end file package_dir do create_package_directory ( package_files ) end end", "commit_type": "change"}
{"commit_tokens": ["removed", "incorrect", ":", "string", "mention", "in", "down", "migration", ".", "remove_column", "only", "needs", "the", "column", "name"], "add_tokens": "remove_column :notifications , :attachment", "del_tokens": "remove_column :notifications , :attachment , :string", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "spaces", "/", "formatting", "in", "client", ".", "rb"], "add_tokens": "log . info \"stream closed\" sock . close end stream . on ( :half_close ) do log . info \"closing client-end of the stream\" end", "del_tokens": "log . info \"stream closed\" sock . close end stream . on ( :half_close ) do log . info \"closing client-end of the stream\" end", "commit_type": "fix"}
{"commit_tokens": ["Use", "tmp", "settings", "file", "for", "specs", "."], "add_tokens": "\"/tmp/#{Lypack::SETTINGS_FILENAME}\"", "del_tokens": "File . join ( $packages_dir , Lypack :: SETTINGS_FILENAME )", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "env_hash", "method", "."], "add_tokens": "env_hash [ 'USER' ] || env_hash [ 'LOGNAME' ]", "del_tokens": "ENV [ 'USER' ] || ENV [ 'LOGNAME' ]", "commit_type": "use"}
{"commit_tokens": ["Fix", "account", "type", "without", "opening", "balances"], "add_tokens": "xml_accessor :opening_balance , :from => 'OpeningBalance' , :as => BigDecimal , :to_xml => Proc . new { | val | val . nil? ? nil : val . to_f }", "del_tokens": "xml_accessor :opening_balance , :from => 'OpeningBalance' , :as => BigDecimal , :to_xml => Proc . new { | val | val . to_f }", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "read", "&", "write", "toml", "format", "files"], "add_tokens": "@extensions = [ '.yaml' , '.yml' , '.json' , '.toml' ] gem_name = nil when '.toml' gem_name = 'toml' require 'toml' TOML . load ( :: File . read ( file ) ) rescue LoadError puts \"Please install `#{gem_name}`\" raise ReadError , \"Gem `#{gem_name}` is missing. Please install it \" \"to read #{ext} configuration format.\" gem_name = nil when '.toml' gem_name = 'toml' require 'toml' :: File . write ( file , TOML :: Generator . new ( data ) . body ) rescue LoadError puts \"Please install `#{gem_name}`\" raise ReadError , \"Gem `#{gem_name}` is missing. Please install it \" \"to read #{ext} configuration format.\"", "del_tokens": "@extensions = [ '.yaml' , '.yml' ]", "commit_type": "add"}
{"commit_tokens": ["make", "query", "string", "construction", "a", "bit", "more", "concise"], "add_tokens": "query_params . each_with_index do | ( k , v ) , i |", "del_tokens": "i = 0 query_params . each do | k , v | i += 1", "commit_type": "make"}
{"commit_tokens": ["removed", "the", "language_method", "option", "from", "the", "blueprint", "config"], "add_tokens": "if XapianDb :: Config . stemmer term_generator . stemmer = XapianDb :: Config . stemmer term_generator . stopper = XapianDb :: Config . stopper if XapianDb :: Config . stopper", "del_tokens": "setup_language_helpers if @stemmer term_generator . stemmer = @stemmer term_generator . stopper = @stopper unless @stopper . nil? # Configure the stemmer and stopper to use def setup_language_helpers # Do we have a language config on the blueprint? if @blueprint . lang_method lang = @obj . send ( @blueprint . lang_method ) if lang && LANGUAGE_MAP . has_key? ( lang . to_sym ) @stemmer = XapianDb :: Repositories :: Stemmer . stemmer_for lang . to_sym @stopper = XapianDb :: Repositories :: Stopper . stopper_for lang . to_sym return end end # Use the global config @stemmer = XapianDb :: Config . stemmer @stopper = XapianDb :: Config . stopper end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "Tilt", "-", "warnings", "and", "fix", "find_dir", "for", "controller", "views"], "add_tokens": "require 'tilt/plain' require 'tilt/erb' using GorillaPatch :: StringExt \"{#{controller_dirs.join(',')},}\" , def controller_dirs ## Build controller_dirs controller_dir = ( self . class . name . underscore . split ( '_' ) - %w( controller ctrl ) ) . join ( '_' ) [ controller_dir , controller_dir . split ( '/' ) . last ] end", "del_tokens": "## Build controller_dir controller_dir = ( self . class . name . split ( / (?=[A-Z]) / ) - [ 'Controller' ] ) . join ( '_' ) . downcase \"{#{controller_dir},}\" ,", "commit_type": "fix"}
{"commit_tokens": ["add", "service", "option", "to", "kontena", "deploy", "command"], "add_tokens": "@services = @services . delete_if { | name , service | ! options . service . include? ( name ) } if options . service create_or_update_service ( name , config ) # skip if service is already created or updated or it's not present return nil if in_deploy_queue? ( name ) || ! services . keys . include? ( name ) create_or_update_service ( linked_service [ :name ] , services [ linked_service [ :name ] ] ) unless in_deploy_queue? ( linked_service [ :name ] ) get_service ( token , prefixed_name ( name ) ) rescue nil name = prefixed_name ( name ) deploy_queue . find { | service | service [ 'id' ] == prefixed_name ( name ) } != nil", "del_tokens": "create_or_update_service ( prefixed_name ( name ) , config ) # skip if service is already created or updated return nil if in_deploy_queue? ( name ) create_or_update_service ( prefixed_name ( linked_service [ :name ] ) , services [ linked_service [ :name ] ] ) unless in_deploy_queue? ( prefixed_name ( linked_service [ :name ] ) ) get_service ( token , name ) rescue nil deploy_queue . find { | service | service [ 'id' ] == name } != nil", "commit_type": "add"}
{"commit_tokens": ["fixed", "documentation", "for", "private", "objects", "/", "methods"], "add_tokens": "# @private 1.8.6 compatibility only # @private # @private 1.8.6 compatibility only # @private no need to explain. Standard ruby 1.9 stuff. # @see http://ruby-doc.org/ruby-1.9/classes/Object.html#M000239", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Added", "documentation", "for", "constant", "variables", "and", "modules"], "add_tokens": "STATUS_URL = \"http://status.vatsim.net/status.txt\" # URL for downloading the Vatsim status file STATUS_DOWNLOAD_INTERVAL = 60 * 60 * 6 # Download status file maximum of once every 6 hours DATA_DOWNLOAD_INTERVAL = 60 * 2 # Download data file maximum of once every 2 minutes STATUS_FILE_PATH = Dir :: tmpdir + \"/vatsim-status.txt\" # Temporary location to store the Vatsim status file DATA_FILE_PATH = Dir :: tmpdir + \"/vatsim-data.txt\" # Temporary location to store the Vatsim data file", "del_tokens": "STATUS_URL = \"http://status.vatsim.net/status.txt\" STATUS_DOWNLOAD_INTERVAL = 60 * 60 * 6 # 6 hours DATA_DOWNLOAD_INTERVAL = 60 * 2 # 2 minutes STATUS_FILE_PATH = Dir :: tmpdir + \"/vatsim-status.txt\" DATA_FILE_PATH = Dir :: tmpdir + \"/vatsim-data.txt\"", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "site", "hooks", ":", "pre_read", "post_read"], "add_tokens": "VERSION = \"2.2.0\"", "del_tokens": "VERSION = \"2.1.0\"", "commit_type": "add"}
{"commit_tokens": ["Use", "Benchmark", ".", "realtime", "to", "directly", "return", "a", "float", "rather", "than", "a", "string", "we", "have", "to", "parse", "."], "add_tokens": "elapsed_time = Benchmark . realtime { result = block_to_benchmark . call }", "del_tokens": "elapsed_time = elapsed_time . to_s . match ( / \\( \\s *([^ \\) ]+) \\) / ) [ 1 ] . to_f elapsed_time = Benchmark . measure { result = block_to_benchmark . call }", "commit_type": "use"}
{"commit_tokens": ["Adding", "options", "to", "disable", "SSL"], "add_tokens": "auth_type : :basic , use_ssl : config . use_ssl ,", "del_tokens": "auth_type : :basic", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "tco_module_method", "using", "class", "keyword", "and", "add", "tests"], "add_tokens": "receiver_class = receiver . is_a? ( Class ) ? :class : :module #{receiver_class} #{receiver.name}", "del_tokens": "class #{receiver.name}", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "plugin", "/", "gem", "Rails", "independent", "."], "add_tokens": "require 'rubygems' require 'yaml' require 'activerecord' $: . unshift File . join ( File . dirname ( __FILE__ ) , '../lib' ) require 'init'", "del_tokens": "ENV [ 'RAILS_ENV' ] = 'test' ENV [ 'RAILS_ROOT' ] ||= File . dirname ( __FILE__ ) + '/../../../..' require File . expand_path ( File . join ( ENV [ 'RAILS_ROOT' ] , 'config/environment.rb' ) )", "commit_type": "make"}
{"commit_tokens": ["Added", "features", "and", "scenarios", "to", "the", "doc", ".", "Right", "now", "the", "templates", "for", "both", "simply", "show", "the", "tags", "titles", "and", "any", "descriptions", "or", "non", "-", "steps", "that", "they", "have", "with", "them"], "add_tokens": "sections . place ( :features ) . after ( :constant_summary ) sections . place ( :scenarios ) . after ( :features ) sections . place ( :steps ) . after ( :scenarios ) sections . place ( :step_transforms ) . after ( :steps ) object . step_definitions . each do | stepdef | stepdef . constants = stepdef . value . scan ( / \\# \\{ ([^ \\} ]+) \\} / ) . flatten . collect do | stepdef_constant | stepdef . constants . each { | constant | stepdef . value_as_link = stepdef . value . gsub ( constant . name . to_s , %{<a href=\"#{url_for(constant)}\">#{constant}</a>} ) } @step_defs = object . step_definitions object . steps . each do | step | # TODO: Should replace the constants with their values as well # TODO: Should handle when has two definitions object . step_definitions . each do | step_def | log . debug \"Looking for a match against #{step_def.value.gsub(/^\\/|\\/$/,'')}\" step . definition = step_def if step =~ / #{ step_def . value } / end end", "del_tokens": "sections . place ( :step_transforms ) . after ( :constant_summary ) sections . place ( :steps ) . after ( :step_definitions ) @step_defs = object . step_definitions . collect do | stepdef | #log.debug \"Step Definition #{stepdef} #{stepdef.value}\" constants = stepdef . constants . collect do | stepdef_constant | #log.debug \"StepDef\\#Constant #{constants}\" constants . each { | constant | stepdef . value . gsub! ( constant . name . to_s , %{<a href=\"#{url_for(constant)}\">#{constant}</a>} ) } stepdef", "commit_type": "add"}
{"commit_tokens": ["Implemented", "geography", "support", "for", "PostGIS"], "add_tokens": "VALID_COLUMN_SPEC_KEYS = [ :name , :limit , :precision , :scale , :default , :null , :srid , :with_z , :with_m , :geographic ] spec [ :geographic ] = 'true' if column . geographic?", "del_tokens": "VALID_COLUMN_SPEC_KEYS = [ :name , :limit , :precision , :scale , :default , :null , :srid , :with_z , :with_m ]", "commit_type": "implement"}
{"commit_tokens": ["Added", "prompt", "for", "install", "task"], "add_tokens": "entry = Hash . new entry [ :domain ] = ask ( 'Domain: ' ) entry [ :db_name ] = ask ( 'Database name: ' ) entry [ :db_server ] = ask ( 'Database server: ' ) { | q | q . default = 'localhost' } entry [ :db_user ] = ask ( 'Database user: ' ) { | q | q . default = 'root' } entry [ :db_password ] = ask ( 'Database password: ' ) { | q | q . default = '' } entry [ :country ] = ask ( 'Country: ' ) { | q | q . default = 'fr' } entry [ :firstname ] = ask ( 'Firstname: ' ) entry [ :lastname ] = ask ( 'Lastname: ' ) entry [ :password ] = ask ( 'Password: ' ) { | q | q . default = '0123456789' } entry [ :email ] = ask ( 'Email: ' ) entry [ :newsletter ] = 0 # the PS default is to 1, but nobody wants spam command = \"php install-dev/index_cli.php \" command << \"--domain=#{entry[:domain]} \" command << \"--db_name=#{entry[:db_name]} \" command << \"--db_server=#{entry[:db_server]} \" command << \"--db_user=#{entry[:db_user]} \" command << \"--db_password=#{entry[:db_password]} \" command << \"--country=#{entry[:country]} \" command << \"--firstname=#{entry[:firstname]} \" command << \"--lastname=#{entry[:lastname]} \" command << \"--password=#{entry[:password]} \" command << \"--email=#{entry[:email]} \" command << \"--newsletter=#{entry[:newsletter]} \"", "del_tokens": "puts \"Preparing installation of PrestaShop\"", "commit_type": "add"}
{"commit_tokens": ["Added", "metascore", "language", "country", "and", "awards"], "add_tokens": ":poster , :imdb_rating , :imdb_votes , :imdb_id , :type , :metascore , :language , :country , :awards @metascore = movie [ \"Metascore\" ] @language = movie [ \"Language\" ] @country = movie [ \"Country\" ] @awards = movie [ \"Awards\" ]", "del_tokens": ":poster , :imdb_rating , :imdb_votes , :imdb_id , :type", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "non", "-", "inheritable", "properties"], "add_tokens": "def get ( property_name , inheritable_only = false ) instance_variable_get ( \"@#{property_name}\" ) value = @this . get ( property_name ) value = instance_variable_get ( \"@#{property_name}\" ) # # set the value of a property # # if the property has a non-nil value set in the @this prop set, then we set it there. # otherwise, it is set in the inheritable set. # def set ( property_name , value ) property_name = property_name . to_s . sub ( / =$ / , '' ) instance_variable = \"@\" + property_name if @this . nil? || @this . get ( property_name ) . nil? instance_variable_set ( instance_variable , value ) else @this . instance_variable_set ( instance_variable , value ) end", "del_tokens": "def get ( var_name , inheritable_only = false ) instance_variable_get ( \"@#{var_name}\" ) value = @this . get ( var_name , false ) value = instance_variable_get ( \"@#{var_name}\" ) def set ( var_name , value ) instance_variable_set ( \"@\" + var_name . to_s . sub ( / =$ / , '' ) , value )", "commit_type": "fix"}
{"commit_tokens": ["Added", "root_dir", "configuration", "and", "logging"], "add_tokens": "require 'logger' require 'sinatra' module Smeg @@root_dir = nil @@config = { :enable_logging => true } class << self def root_dir @@root_dir || Dir . pwd end def root_dir = ( path ) @@root_dir = path log . info \"Exporting to #{path}/output\" Exporter . path = \"#{path}/output\" Page . path = \"#{path}/content\" Template . path = \"#{path}/templates\" end # Log for info, debug, error and warn with: # # Smeg.log.info \"message\" # Smeg.log.debug \"message\" # Smeg.log.error \"message\" # Smeg.log.warn \"message\" def log @@log ||= Logger . new ( config [ :enable_logging ] ? $stdout : \"/dev/null\" ) end def config @@config end def configure ( & block ) yield @@config end end end", "del_tokens": "module Smeg ; end", "commit_type": "add"}
{"commit_tokens": ["Adding", "my", "own", "support", "library", ".", "Written", "from", "scratch", "."], "add_tokens": "# Dependencies require 'wool/support/module_extensions' require 'wool/advice/advice' require 'wool/advice/comment_advice' # Runners # Program logic", "del_tokens": "require 'wool/advice/advice.rb' require 'wool/advice/comment_advice.rb'", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", ";", "rebuilt", "binary"], "add_tokens": "assert_raise ( NoMethodError , \"undefined method `asdf' for class `Duxml::El'\" ) do x . asdf end assert_raise ( NoMethodError ) do x . three end", "del_tokens": "assert_raise ( NameError , \"undefined method `asdf' for class `Duxml::El'\" ) do x . asdf end assert_raise ( NameError ) do x . three end", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "explicit", "check", "for", "MRI", "don", "t", "define", "TS", "::", "Array", "or", "TS", "::", "Hash", "for", "other", "platforms", "."], "add_tokens": "elsif defined? ( RUBY_ENGINE ) && RUBY_ENGINE == 'ruby'", "del_tokens": "else", "commit_type": "add"}
{"commit_tokens": ["Use", "gs", "to", "strip", "passwords", "from", "pdf"], "add_tokens": "require 'tempfile' retried = false while true cmd = pdf_to_text_cmd ( filename ) logger . info ( \"Executing: #{cmd}\" ) stdout , status = Open3 . capture2 ( * cmd ) case status . exitstatus when 0 return cleanup ( stdout ) when 3 return nil if retried retried = true self . remove_pdf_password ( filename ) else return nil end def remove_pdf_password ( filename ) file = Tempfile . new ( 'steno' ) begin logger . info ( \"Trying to remove password from #{filename}\" ) cmd = \"gs -q -dNOPAUSE -dBATCH -sDEVICE=pdfwrite -sOutputFile=#{file.path} -c .setpdfwrite -f #{filename}\" . split ( \" \" ) logger . info ( \"Executing: #{cmd}\" ) Open3 . capture2 ( * cmd ) FileUtils . move ( file . path , filename ) ensure file . close file . unlink end end", "del_tokens": "cmd = pdf_to_text_cmd ( filename ) logger . info ( \"Executing: #{cmd}\" ) stdout , status = Open3 . capture2 ( * cmd ) if status == 0 cleanup ( stdout ) else nil", "commit_type": "use"}
{"commit_tokens": ["Fix", "somewhat", "surprising", "errors", "with", "Webmock"], "add_tokens": "@client . delete ( \"/#{index}\" ) @client . delete ( \"/#{index}/_query?q=*\" ) JSON . parse ( @client . get ( '/_status' ) . body ) [ \"indices\" ] . keys . select { | i |", "del_tokens": "@client . delete ( index ) @client . delete ( \"#{index}/_query?q=*\" ) JSON . parse ( @client . get ( '_status' ) . body ) [ \"indices\" ] . keys . select { | i |", "commit_type": "fix"}
{"commit_tokens": ["Added", "objective", "and", "bound", "values", "accessor"], "add_tokens": "VERSION = \"0.1.6\"", "del_tokens": "VERSION = \"0.1.5\"", "commit_type": "add"}
{"commit_tokens": ["Move", "commands", "to", "a", "command", "directory", "."], "add_tokens": "DBGR_DIR = File . expand_path ( File . dirname ( __FILE__ ) ) ROOT_DIR = DBGR_DIR + \"/..\" require \"#{DBGR_DIR}/debugger/frame\" require \"#{DBGR_DIR}/debugger/commands\" require \"#{DBGR_DIR}/debugger/breakpoint\" require \"#{DBGR_DIR}/debugger/display\" include Debugger :: Display", "del_tokens": "require_relative 'debugger/frame' require_relative 'debugger/commands' require_relative 'debugger/breakpoint' require_relative 'debugger/display' include Debugger :: Display ROOT_DIR = File . expand_path ( File . dirname ( __FILE__ ) + \"/..\" )", "commit_type": "move"}
{"commit_tokens": ["Fixed", "typo", "in", "install", ".", "rb"], "add_tokens": "puts \"Thank you for installing Ancestry. You can visit http://github.com/stefankroes/ancestry to read the documentation.\"", "del_tokens": "puts \"Thank you for install Ancestry. You can visit http://github.com/stefankroes/ancestry to read the documentation.\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "watchdog", "thread", "to", "work", "around", "Net", "::", "IMAP", "deadlock", "issues", "resulting", "from", "unexpected", "disconnects", "."], "add_tokens": "rescue Larch :: WatchdogException => e @log . debug \"#{source.username}@#{source.host}: watchdog exception\" @log . fatal \"#{source.username}@#{source.host}: #{e.class.name}: #{e.message}\" Thread . current [ :last_id ] = msg . id rescue Larch :: WatchdogException => e Thread . current [ :last_id ] = nil @log . debug \"#{dest.username}@#{dest.host}: watchdog exception\" dest . noop retry @log . fatal \"#{dest.username}@#{dest.host}: #{e.class.name}: #{e.message}\" source_flags = 0 dest_flags = 0 dest_lastid = nil if msgq . length == 0 && source_thread [ :fetching ] && ( source_flags += 1 ) > 1 source_flags = 0 source_thread . raise ( WatchdogException ) end if dest_thread [ :last_id ] if dest_lastid == dest_thread [ :last_id ] && ( dest_flags += 1 ) > 2 dest_flags = 0 dest_lastid = nil dest_thread . raise ( WatchdogException ) else dest_lastid = dest_thread [ :last_id ] end", "del_tokens": "rescue Larch :: WatchdogError => e @log . error \"#{source.username}@#{source.host}: server dropped connection unexpectedly\" @log . fatal \"#{e.class.name}: #{e.message}\" @log . fatal \"#{e.class.name}: #{e.message}\" if msgq . length == 0 && source_thread [ :fetching ] source_thread . raise ( WatchdogError )", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "handling", "for", "when", "the", "bot", "emits", "a", "new", "signal", "."], "add_tokens": "begin @scripts . each do | script | if script . respond_to? name script . __send__ name , * args end rescue puts \"Script error #$!\"", "del_tokens": "@scripts . each do | script | if script . respond_to? name script . __send__ name , * args", "commit_type": "add"}
{"commit_tokens": ["added", "type", "column", "plus", "resque", "reloads", "on", "any", "change"], "add_tokens": "Myreplicator :: Export . schedule_in_resque # schedule in resque Myreplicator :: Export . schedule_in_resque # schedule in resque Myreplicator :: Export . schedule_in_resque # schedule in resque", "del_tokens": "@export . schedule # schedule in resque @export . schedule # schedule in resque @export . schedule # schedule in resque", "commit_type": "add"}
{"commit_tokens": ["update", "the", "trunk", "migrations", "to", "latest"], "add_tokens": "version : 12", "del_tokens": "version : 11", "commit_type": "update"}
{"commit_tokens": ["Implemented", "adding", "packages", "to", "repo"], "add_tokens": "@num_packages = info [ 'Number of packages' ] . to_i def add path out , err , status = Aptly :: runcmd \"aptly repo add #{@name} #{path}\" if status != 0 raise AptlyError . new ( \"Failed to add to repo: #{@path}\" , out , err ) end end", "del_tokens": "@num_packages = info [ 'Number of packages' ]", "commit_type": "implement"}
{"commit_tokens": ["Using", "to_s", "instead", "of", "inspect"], "add_tokens": "end . to_s", "del_tokens": "end . inspect", "commit_type": "use"}
{"commit_tokens": ["Fix", "formatting", "of", "segment", "list"], "add_tokens": "segments = [ 'Segments' ] segments . push ( '' )", "del_tokens": "segments = [ ] segments", "commit_type": "fix"}
{"commit_tokens": ["added", "apply_wrapper_options!", "(", "type", "options", "value", ")", "and", "added", "this", "method", "to", "options", "that", "are", "passed", "to", "wrap_with"], "add_tokens": "wrap_with ( :wrapper , label + content ( value , options , false , & block ) , apply_wrapper_options! ( :wrapper , options , value ) ) wrap_with ( :wrapper , content ( value , options , false , & block ) , apply_wrapper_options! ( :wrapper , options , value ) ) def apply_wrapper_options! ( type , options , value ) options [ :\" #{ type } _html \" ] ||= { } options [ :\" #{ type } _html \" ] [ :class ] = [ options [ :\" #{ type } _html \" ] [ :class ] , ShowFor . blank_content_class ] . join ( ' ' ) if value . blank? && value != false options end", "del_tokens": "wrap_with ( :wrapper , label + content ( value , options , false , & block ) , options ) wrap_with ( :wrapper , content ( value , options , false , & block ) , options )", "commit_type": "add"}
{"commit_tokens": ["allow", "connection", "to", "post", "a", "body", "if", "one", "is", "present", "even", "for", "getish", "actions"], "add_tokens": "body = kwords . delete ( :body ) @connection . send ( action , path , params , headers ) do | request | if body request . headers [ :content_type ] = 'application/json' request . body = body end end", "del_tokens": "@connection . send ( action , path , params , headers )", "commit_type": "allow"}
{"commit_tokens": ["Add", "configurable", "X", "-", "Cascade", "header", "support", "."], "add_tokens": "headers = { \"Content-Type\" => \"text/plain\" } if Praxis :: Application . instance . config . praxis . x_cascade headers [ 'X-Cascade' ] = 'pass' end result = [ 404 , headers , [ body ] ]", "del_tokens": "result = [ 404 , { \"Content-Type\" => \"text/plain\" , } , [ body ] ]", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "Num", "of", "selected", "caption", "+", "Select", "All", "checkbox", "."], "add_tokens": "if table . selectable? code << '<th class=\"list-selector\"><input type=\"checkbox\" data-list-selector=\"all\" /></th>' disclaimer = '<caption>\\'+ \"list.selected\".t + \\'</caption>' end code << '</tr></thead>' code << ( disclaimer || '' ) code << \"'\"", "del_tokens": "code << '<th class=\"list-selector\"></th>' if table . selectable? code << \"</tr></thead>'\"", "commit_type": "add"}
{"commit_tokens": ["Added", "id", "to", "address", "and", "phone", "number"], "add_tokens": "attr_reader :city , :country_code , :line1 , :line2 , :postal_code , :province , :id", "del_tokens": "attr_reader :city , :country_code , :line1 , :line2 , :postal_code , :province", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "mistake", "in", "the", "CLI", "options"], "add_tokens": "vim_printer", "del_tokens": "vim_printer print", "commit_type": "fix"}
{"commit_tokens": ["Add", "timer", "and", "counter", "aliases", "."], "add_tokens": "alias_method :timer , :measure def increment ( key , value = 1 , * metric_options ) alias_method :counter , :increment", "del_tokens": "def counter ( key , value = 1 , * metric_options ) alias_method :increment , :counter", "commit_type": "add"}
{"commit_tokens": ["Added", "calls", "to", "newly", "created", "services", "to", "client", "facade"], "add_tokens": "def read_events_forward ( stream_name , start , count ) Actions :: ReadEventsBatch . new ( event_repository ) . call ( stream_name , start , count , :forward ) def read_events_backward ( stream_name , start , count ) Actions :: ReadEventsBatch . new ( event_repository ) . call ( stream_name , start , count , :backward ) def read_all_events_forward ( stream_name ) Actions :: ReadAllEvents . new ( event_repository ) . call ( stream_name , :forward ) def read_all_events_backward ( stream_name ) Actions :: ReadAllEvents . new ( event_repository ) . call ( stream_name , :backward )", "del_tokens": "def read_events_forward #TODO def read_events_backward #TODO def read_all_events_forward #TODO def read_all_events_backward #TODO", "commit_type": "add"}
{"commit_tokens": ["added", "has_any_role", "and", "fixed", "has_roles"], "add_tokens": "# check if all of the roles listed have been assigned to that user compare_roles = extract_roles ( roles_names . flat_uniq ) ( compare_roles - roles_list ) . empty? end # check if any of the roles listed have been assigned to that user def has_any_role? ( * roles_names )", "del_tokens": "# check if a given role has been assigned # if a list of roles: check if ALL of the given roles have been assigned", "commit_type": "add"}
{"commit_tokens": ["fix", "github", "payload", "for", "when", "it", "doesn", "t", "contain", "any", "commits", "at", "all"], "add_tokens": "last_commit . nil? || last_commit . commit . blank?", "del_tokens": "last_commit . commit . blank?", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Backup", "plugin", "to", "work", "with", "Moonshot", "1", ".", "x", "."], "add_tokens": "expect ( subject . backup_parameters ) . to eq true expect ( subject . backup_template ) . to eq true stack : instance_double ( Moonshot :: Stack , name : 'test_name' , parameters : { } ) , ilog : instance_double ( Moonshot :: InteractiveLoggerProxy ) , controller : instance_double ( Moonshot :: Controller , config : instance_double ( Moonshot :: ControllerConfig , app_name : 'test' ) )", "del_tokens": "expect ( subject . files ) . to eq [ 'cloud_formation/%{app_name}.json' , 'cloud_formation/parameters/%{stack_name}.yml' ] stack : instance_double ( Moonshot :: Stack , app_name : 'test_app_name' , name : 'test_name' ) , ilog : instance_double ( Moonshot :: InteractiveLoggerProxy )", "commit_type": "update"}
{"commit_tokens": ["Make", "guid", "column", "name", "to", "be", "configureable"], "add_tokens": "target_name = target_column_name ( method_name ) . to_s + TARGET_ID guid_name = guid_column_name ( method_name ) scope_by_fileupload_guid ( method_name , fileupload_guid ) . update_all ( target_name => @record . id , guid_name = > nil ) def target_column_name ( method_name ) @record_klass . fileupload_options [ method_name . to_sym ] . fetch ( :assetable , Uploader . assetable_column ) end def guid_column_name ( method_name ) @record_klass . fileupload_options [ method_name . to_sym ] . fetch ( :guid , Uploader . guid_column ) target_name = target_column_name ( method_name ) . to_s + TARGET_TYPE guid_name = guid_column_name ( method_name ) klass ( method_name ) . where ( target_name => record_klass_type . to_s , guid_name => guid )", "del_tokens": "DEFAULT_TARGET = 'assetable' . freeze column_name = target_name ( method_name ) . to_s + TARGET_ID scope_by_fileupload_guid ( method_name , fileupload_guid ) . update_all ( column_name => @record . id , Uploader . guid_column = > nil ) def target_name ( method_name ) @record_klass . fileupload_options [ method_name . to_sym ] . fetch ( :target , DEFAULT_TARGET ) column_name = target_name ( method_name ) . to_s + TARGET_TYPE klass ( method_name ) . where ( column_name => record_klass_type . to_s , Uploader . guid_column => guid )", "commit_type": "make"}
{"commit_tokens": ["Fix", "log", "subscribers", "specs", "that", "were", "using", "the", "wrong", "input"], "add_tokens": "\"SELECT AES_ENCRYPT('encrypt_value', 'encrypt_key'), AES_DECRYPT('decrypt_value', 'decrypt_key') FROM DUAL;\" subject . sql ( ActiveSupport :: Notifications :: Event . new ( :sql , 1 , 1 , 1 , { sql : input_query } ) )", "del_tokens": "\"SELECT AES_ENCRYPT('encrypt_value', 'encrypt_key'), AES_ENCRYPT('decrypt_value', 'decrypt_key') FROM DUAL;\" subject . sql ( ActiveSupport :: Notifications :: Event . new ( :sql , 1 , 1 , 1 , { sql : output_query } ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "NotImplementedError", "in", "DirectiveNode", "monkey", "patch"], "add_tokens": "begin additional_children = extract_script_nodes ( value ) rescue NotImplementedError # Directive nodes may not define `value` end concat_expr_lists super , additional_children", "del_tokens": "concat_expr_lists super , extract_script_nodes ( value )", "commit_type": "fix"}
{"commit_tokens": ["update", "net_http_spec", "test", "http", "requests"], "add_tokens": "10 . times . map do expect ( res . code ) . to eq \"200\"", "del_tokens": "0 . times . map do expect ( res . code ) . to eq 200", "commit_type": "update"}
{"commit_tokens": ["Move", "matcher", "fot", "ResponceMismatch", "into", "spec_helper"], "add_tokens": "require \"spec_helper\" include RaiseResponseMatcher \"Function code is mismatch: expected 1, got 2\" , request , response )", "del_tokens": "require \"rmodbus\" class RaiseResponseMismatch include ModBus :: Common def initialize ( message , request , response ) @expected_message , @expected_request , @expected_response = message , request , response end def matches? ( given_block ) begin given_block . call rescue ModBus :: Errors :: ResponseMismatch => e @actual_message = e . message @actual_request = e . request @actual_response = e . response @with_expected_message = verify_message @with_expected_request = @expected_request == @actual_request @with_expected_response = @expected_response == @actual_response end @with_expected_message & @with_expected_request & @with_expected_response end def failure_message unless @with_expected_message return \"Expected message #{@expected_message}, got #{@actual_message}\" end unless @with_expected_request return \"Expected request #{logging_bytes @expected_request}, got #{logging_bytes @actual_request}\" end unless @with_expected_response return \"Expected response #{logging_bytes @expected_response}, got #{logging_bytes @actual_response}\" end end def verify_message case @expected_message when nil true when Regexp @expected_message =~ @actual_message else @expected_message == @actual_message end end end \"Function code is mismatch: expected 1, got 2\" , request , response ) end private def raise_response_mismatch ( message , request , response ) RaiseResponseMismatch . new ( message , request , response )", "commit_type": "move"}
{"commit_tokens": ["Change", "to", "use", "more", "specific", "exit", "error", "."], "add_tokens": "require 'tty/command/exit_error' # @raise [ExitError] cmd_name = nil cmd_name = cmd . to_command raise ExitError . new ( cmd_name , result )", "del_tokens": "FailedError = Class . new ( RuntimeError ) # @raise [FailedError] name = nil name = cmd . to_command raise FailedError , \"Invoking `#{name}` failed with status #{result.exit_status}\"", "commit_type": "change"}
{"commit_tokens": ["Adds", "missing", "Batik", "in", "classpath"], "add_tokens": "Rjb :: load ( ( [ \".\" ] + Beardley :: Core . classpath + Beardley :: Groovy . classpath + Beardley :: Barcode . classpath + Beardley :: Batik . classpath ) . join ( File :: PATH_SEPARATOR ) , [ '-Djava.awt.headless=true' , '-Xms128M' , '-Xmx256M' ] )", "del_tokens": "Rjb :: load ( ( [ \".\" ] + Beardley :: Core . classpath + Beardley :: Groovy . classpath + Beardley :: Barcode . classpath ) . join ( File :: PATH_SEPARATOR ) , [ '-Djava.awt.headless=true' , '-Xms128M' , '-Xmx256M' ] )", "commit_type": "add"}
{"commit_tokens": ["allow", "class", "method", ".", "update", "on", "resources"], "add_tokens": "# @param [Hash] opts The optional parameters to pass. Defaults to {} module Update # Updates a resource given the id passed in. # @param [Client] client The {Client} object to be used # @param [Number] id The id to DELETE. # @param [String] path The optional path to use. Defaults to {DataResource.resource_name}. def update ( client , id , attributes = { } ) attributes = Hashie :: Mash . new ( attributes ) path = self . path % attributes . delete ( self . parent_name ) client . connection . put ( \"#{path}/#{id}.json\" ) do | req | req . body = attributes end true rescue Faraday :: Error :: ClientError => e puts \"#{e.message}\\n\\t#{e.response[:body].inspect}\" false end end", "del_tokens": "# @param [String] path The optional path to use. Defaults to {DataResource.resource_name}. # @param [String] path The optional path to use. Defaults to {DataResource.resource_name}.", "commit_type": "allow"}
{"commit_tokens": ["Adds", "--", "keep", "option", "to", "to", "-", "master", "."], "add_tokens": "def initialize ( dir , opts ) @keep = opts [ :keep ] super end if not @keep close_pull_request remove_feature_branch end", "del_tokens": "close_pull_request remove_feature_branch", "commit_type": "add"}
{"commit_tokens": ["Added", "validation", "of", "CSV", "file", "headers", "and", "schema"], "add_tokens": "else messages [ :errors ] += JSON :: Validator . fully_validate ( @jsontable_schema , resource [ \"schema\" ] , :errors_as_objects => true ) if resource [ \"schema\" ] && resource [ \"schema\" ] [ \"fields\" ] fields = resource [ \"schema\" ] [ \"fields\" ] declared_fields = fields . map { | f | f [ \"name\" ] } headers = headers ( package , resource ) #set algebra to finding fields missing from schema and/or CSV file missing_fields = declared_fields - headers if missing_fields != [ ] messages [ :errors ] << \"Declared schema has fields not present in CSV file (#{missing_fields.join(\",\")})\" end undeclared_fields = headers - declared_fields if undeclared_fields != [ ] messages [ :errors ] << \"CSV file has fields missing from schema (#{undeclared_fields.join(\",\")})\" end end end def headers ( package , resource ) headers = [ ] opts = dialect_to_csv_options ( resource [ \"dialect\" ] ) CSV . open ( package . resolve_resource ( resource ) , \"r\" , opts ) do | csv | headers = csv . shift end return headers end def dialect_to_csv_options ( dialect ) return { } end", "del_tokens": "messages [ :errors ] += JSON :: Validator . fully_validate ( @jsontable_schema , resource [ \"schema\" ] , :errors_as_objects => true ) end", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "with", "parsing", "quotes", "where", "a", "single", "tag", "preceding", "a", "double", "tag", "would", "consume", "the", "start", "tag", "of", "the", "double", "tag", "if", "both", "contained", "attributes", "."], "add_tokens": "def pre_parse ( text ) # :nodoc: re = %r{ < #{ @tag_prefix } :([ \\w :]+?)( \\s +(?: \\w + \\s *= \\s *(?:\"[^\"]*?\"|'[^']*?') \\s *)*|)>|</ #{ @tag_prefix } :([ \\w :]+?) \\s *> } start_tag , attr , end_tag = $1 , $2 , $3 re = %r{ < #{ @tag_prefix } :([ \\w :]+?)( \\s +(?: \\w + \\s *= \\s *(?:\"[^\"]*?\"|'[^']*?') \\s *)*|)/> }", "del_tokens": "def pre_parse ( text ) re = %r{ < #{ @tag_prefix } :([ \\w :]+?)( \\s +(?: \\w + \\s *= \\s *([\"']).*? \\3 \\s *)*|)>|</ #{ @tag_prefix } :([ \\w :]+?) \\s *> } start_tag , attr , end_tag = $1 , $2 , $4 re = %r{ < #{ @tag_prefix } :([ \\w :]+?)( \\s +(?: \\w + \\s *= \\s *([\"']).*? \\3 \\s *)*|)/> }", "commit_type": "fix"}
{"commit_tokens": ["fix", "broken", "CouchRest", ".", "database!", "method"], "add_tokens": "create_db ( name ) rescue nil", "del_tokens": "create_db ( path ) rescue nil", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "bump", "gem", "version", "up"], "add_tokens": "VERSION = '0.3.0' . freeze", "del_tokens": "# encoding: utf-8 # VERSION = \"0.2.1\"", "commit_type": "change"}
{"commit_tokens": ["Fix", "wrong", "configure", "example", "on", "show_for", "template"], "add_tokens": "# config.label_proc = lambda { |l| l + \":\" }", "del_tokens": "# config.label_proc = lambda { |l| c + \":\" }", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "check", "for", "args", "[", ":", "status", "]", "parameter", "to", "ensure", "it", "is", "either"], "add_tokens": "# If status is given, make sure it's profile or gateway unless @status . nil? raise \"status must be profile or gateway\" unless @status =~ / profile|gateway /i end orig_command = \"sofia status #{@status} #{@name}\"", "del_tokens": "orig_command = \"sofia status #{@status} #{@name} #{@originator}\"", "commit_type": "add"}
{"commit_tokens": ["changed", "constants", "in", "primary", "files", "small", "changes"], "add_tokens": "end end", "del_tokens": "end end", "commit_type": "change"}
{"commit_tokens": ["Add", "ability", "to", "parse", "from", "any", "rule"], "add_tokens": "def parse ( rule = nil ) if ! rule _root ? true : false else # This is not shared with code_generator.rb so this can be standalone method = rule . gsub ( \"-\" , \"_hyphen_\" ) __send__ ( \"_#{method}\" ) ? true : false end", "del_tokens": "def parse _root ? true : false", "commit_type": "add"}
{"commit_tokens": ["Adds", "a", "stack", "helper", "to", "assist", "in", "identifying", "the", "stack", "a", "class", "belongs", "to"], "add_tokens": "autoload :Publish , \"pancake/mixins/publish\" autoload :Render , \"pancake/mixins/render\" autoload :StackHelper , \"pancake/mixins/stack_helper\"", "del_tokens": "autoload :Publish , \"pancake/mixins/publish\" autoload :Render , \"pancake/mixins/render\"", "commit_type": "add"}
{"commit_tokens": ["add", "String#ascii1_other2_size", ".", "refactoring", "String#justify_table"], "add_tokens": "diff = column . ascii1_other2_size - column . size line_ret << column . ljust ( max_sizes [ cnt ] - diff ) current_size = column . ascii1_other2_size # current_size = column.size", "del_tokens": "line_ret << column . ljust ( max_sizes [ cnt ] ) current_size = column . size", "commit_type": "add"}
{"commit_tokens": ["remove", "static", "parse", "methods", "from", "ZipCode"], "add_tokens": "zip = ZipCode . new '30306' zip = ZipCode . new '30306-3522' lambda { ZipCode . new ( '303065344' ) } . should raise_error it \"should convert to string\" do ZipCode . new ( '30306-3522' ) . to_s . should == '30306-3522' lambda { ZipCode . new ( '30306-3522' ) . to_s ( :bogus ) } . should raise_error", "del_tokens": "zip = ZipCode . parse '30306' zip = ZipCode . parse '30306-3522' lambda { ZipCode . parse ( '303065344' ) } . should raise_error end it \"should format :base\" do ZipCode . parse ( '30306-3522' ) . to_s ( :base ) . should == '30306' it \"should format :plus_four\" do ZipCode . parse ( '30306-3522' ) . to_s ( :plus_four ) . should == '30306-3522' lambda { ZipCode . parse ( '30306-3522' ) . to_s ( :bogus ) } . should raise_error", "commit_type": "remove"}
{"commit_tokens": ["Remove", "a", "conversation", "from", "a", "Space"], "add_tokens": "def remove Ribose :: Request . delete ( [ resources , conversation_id ] . join ( \"/\" ) ) end def self . remove ( space_id : , conversation_id : ) new ( space_id : space_id , conversation_id : conversation_id ) . remove end attr_reader :space_id , :conversation_id @conversation_id = attributes . delete ( :conversation_id )", "del_tokens": "attr_reader :space_id", "commit_type": "remove"}
{"commit_tokens": ["Made", "Client", ".", "set_api", "a", "public", "method", "."], "add_tokens": "client_class . set_api ( api )", "del_tokens": "client_class . send ( :set_api , api ) private", "commit_type": "make"}
{"commit_tokens": ["added", ".", "seed_many", "method", "to", "allow", "you", "to", "seed", "several", "records", "through", "one", "call"], "add_tokens": "def self . seed_many ( * constraints ) seeds = constraints . pop seeds . each do | seed_data | seed ( * constraints ) do | s | seed_data . each_pair do | k , v | s . send \"#{k}=\" , v end end end end", "del_tokens": "puts \" - #{@model_class} #{condition_hash.inspect}\"", "commit_type": "add"}
{"commit_tokens": ["Removed", "deprecated", "mock", "()", "in", "favor", "of", "double", "()", "."], "add_tokens": "@status = double ( Process :: Status )", "del_tokens": "@status = mock ( Process :: Status )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "help", "-", "a", "documentation"], "add_tokens": "\"to the template or binding directory\" ) do | t |", "del_tokens": "\"to the template directory\" ) do | t |", "commit_type": "fix"}
{"commit_tokens": ["added", "windows", "binary", "bit", "to", "writing", "non", "-", "text", "files"], "add_tokens": "open_bits = 'w' open_bits = 'wb' # open with binary bit for Windows for non text File . open ( file , 'wb' ) { | f | f . write ( content ) }", "del_tokens": "File . open ( file , 'w' ) { | f | f . write ( content ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "initial", "install", "errors", "."], "add_tokens": "begin establish_connection cfg rescue TinyTds :: Error remove_connection end", "del_tokens": "establish_connection cfg", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "sending", "deployment", "notifications", "to", "multiple", "rooms", "."], "add_tokens": "set :hipchat_with_migrations , '' set :hipchat_with_migrations , ' (with migrations)' send ( \"#{human} cancelled deployment of #{deployment_name} to #{env}.\" ) send ( \"#{human} is deploying #{deployment_name} to #{env}#{fetch(:hipchat_with_migrations, '')}.\" ) send ( \"#{human} finished deploying #{deployment_name} to #{env}#{fetch(:hipchat_with_migrations, '')}.\" ) def send ( message ) if hipchat_room_name . is_a? ( String ) rooms = [ hipchat_room_name ] elsif hipchat_room_name . is_a? ( Symbol ) rooms = [ hipchat_room_name . to_s ] else rooms = hipchat_room_name end rooms . each { | room | hipchat_client [ room ] . send ( deploy_user , message , options ) }", "del_tokens": "set :hipchat_with_migrations , false set :hipchat_with_migrations , true hipchat_client [ hipchat_room_name ] . send ( deploy_user , \"#{human} cancelled deployment of #{deployment_name} to #{env}.\" , send_options ) message = \"#{human} is deploying #{deployment_name} to #{env}\" message << \" (with migrations)\" if hipchat_with_migrations message << \".\" hipchat_client [ hipchat_room_name ] . send ( deploy_user , message , send_options ) hipchat_client [ hipchat_room_name ] . send ( deploy_user , \"#{human} finished deploying #{deployment_name} to #{env}.\" , send_options ) def send_options", "commit_type": "add"}
{"commit_tokens": ["Add", "button", "and", "base", "helpers", "."], "add_tokens": "require File . expand_path ( \"../dummy/config/environment\" , __FILE__ ) require \"rspec/rails\" require \"rspec/autorun\" require \"bootstrap-rails-helpers\"", "del_tokens": "require File . expand_path ( \"../external_routes/config/environment\" , __FILE__ ) require 'rspec/rails' require 'rspec/autorun' # Requires supporting ruby files with custom matchers and macros, etc, # in spec/support/ and its subdirectories. config . use_transactional_fixtures = true config . infer_base_class_for_anonymous_controllers = false", "commit_type": "add"}
{"commit_tokens": ["use", "fully", "qualified", "class", "name"], "add_tokens": "before_filter Garage :: HypermediaResponder", "del_tokens": "before_filter HypermediaResponder", "commit_type": "use"}
{"commit_tokens": ["adding", "more", "tests", "to", "io_spec"], "add_tokens": "# NOTE: the String.unpack here can be very inefficient on large files output = output_stream filename begin @workbook . write ( output ) ensure output . close end end def output_stream name java . io . FileOutputStream . new ( name )", "del_tokens": "# NOTE: the String.unpack here can be very inefficient @workbook . write ( java . io . FileOutputStream . new ( filename ) )", "commit_type": "add"}
{"commit_tokens": ["allow", "AdminPassword", "to", "be", "modifiable"], "add_tokens": "echo 'parameter_defaults:' >> openstack - tripleo - heat - templates / environments / deployment_parameters . yaml echo ' AdminPassword: changeme' >> openstack - tripleo - heat - templates / environments / deployment_parameters . yaml", "del_tokens": "echo ' AdminPassword: MjFshnTPgMMExCRDuRcH2XhMQ' >> openstack - tripleo - heat - templates / overcloud - resource - registry - puppet . yaml", "commit_type": "allow"}
{"commit_tokens": ["Move", "dummy", "store", "NAME", "constant", "to", "an", "independent", "class", "&", "file"], "add_tokens": "File . join ( Testing . config . dummy_store_generation_dir , DummyStoreConstants :: NAME )", "del_tokens": "NAME = 'dummy-store' File . join ( Testing . config . dummy_store_generation_dir , NAME )", "commit_type": "move"}
{"commit_tokens": ["Use", "ActiveSupport", "::", "Callbacks", "for", "perform"], "add_tokens": "assert_equal ( { 'counter' => 23 , 'before_event' => 3 , 'after_event' => 3 } , @job . arguments . first )", "del_tokens": "assert_equal ( { 'counter' => 23 , 'before_event' => 2 , 'after_event' => 2 } , @job . arguments . first )", "commit_type": "use"}
{"commit_tokens": ["Moved", "dirty", "check", "before", "pre_save", "because", "pre_save", "dirties", "the", "object", "every", "time", "."], "add_tokens": "# todo: decide whether this should go before pre_save or after pre_save? pre_save dirties \"updated\" and perhaps other items due to callbacks if options [ :dirty ] # Only used in simple_record right now puts '@dirty=' + @dirty . inspect return true if @dirty . size == 0 # Nothing to save so skip it options [ :dirty_atts ] = @dirty end # if options[:dirty] # Only used in simple_record right now # puts '@dirty=' + @dirty.inspect # return true if @dirty.size == 0 # Nothing to save so skip it # options[:dirty_atts] = @dirty # end SimpleRecord . stats . puts += 1 # Query example: # MyModel.find(:all, :conditions=>[\"name = ?\", name], :order=>\"created desc\", :limit=>10)", "del_tokens": "if options [ :dirty ] # Only used in simple_record right now options [ :dirty_atts ] = @dirty end # Query: # MyModel.find(:all, [\"name = ?\", name], :order=>\"created desc\", :limit=>10)", "commit_type": "move"}
{"commit_tokens": ["Updated", "the", "tasks", "using", "the", "new", "Mr", "Bones", "gem"], "add_tokens": "VERSION = '0.7.0' # :nodoc:", "del_tokens": "VERSION = '0.6.0' # :nodoc:", "commit_type": "update"}
{"commit_tokens": ["added", "document_property", "parser", "(", "e", ".", "g", ".", "SET", "DOCUMENT", ")"], "add_tokens": "children [ 0 ] children [ 1 ] end end # AST node representing a document property (e.g. +SET DOCUMENT ...+). class DocumentProperty < Node # AST node type @ast_type = :document_property # DocumentProperty has semantics (what was set?) @has_semantics = true # New DocumentProperty AST node. # # @see Node#initialize Node class for basic properties def initialize ( children = [ ] , properties = { } ) super ( DocumentProperty . ast_type , children , properties ) end # Get what is being set. def name children [ 0 ] end # Get the value of what is being set. def value children [ 1 ] # AST node representing a name. class Name < Node # AST node type @ast_type = :name # Name has semantics (name of property or annotation). @has_semantics = true # New Name AST node. # # @see Node#initialize Node class for basic properties def initialize ( children = [ ] , properties = { } ) super ( Name . ast_type , children , properties ) end def identifier children [ 0 ] end end def name ( * children ) Name . new ( children ) end def set ( * children ) Set . new ( children ) end def document_property ( * children ) DocumentProperty . new ( children ) end", "del_tokens": "# TODO: access children for content # TODO: access children for content", "commit_type": "add"}
{"commit_tokens": ["fixing", "organizations", "controller", "from", "stray", "character"], "add_tokens": "@organizations = Organization . search_for ''", "del_tokens": "@organizations = Organization . search_for '' w", "commit_type": "fix"}
{"commit_tokens": ["Fix", "extending", "a", "blank", "view"], "add_tokens": "@view_flow . get ( :layout ) . replace capture ( & block )", "del_tokens": "content_for ( :layout ) . replace capture ( & block )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "parsing", "of", "deference", "symbol", "in", "template", "expressions"], "add_tokens": "DELIMITER = / ( \\{ [A-Za-z0-9_ \\. ]+ \\} ) / . freeze", "del_tokens": "DELIMITER = / ( \\{ [A-Za-z0-9_]+ \\} ) / . freeze", "commit_type": "fix"}
{"commit_tokens": ["Moved", "the", "reversion", "methods", "to", "their", "own", "module", "."], "add_tokens": "include Reversion", "del_tokens": "def reset_version ( new_version = nil ) @last_version = nil if new_version . nil? @version = new_version end public def version @version ||= last_version end def last_version @last_version ||= versions . maximum ( :number ) || 1 end def reverted? version != last_version end def revert_to ( value ) to_number = versions . number_at ( value ) changes = changes_between ( version , to_number ) return version if changes . empty? changes . each do | attribute , change | write_attribute ( attribute , change . last ) end reset_version ( to_number ) end def revert_to! ( value ) revert_to ( value ) reset_version if saved = save saved end", "commit_type": "move"}
{"commit_tokens": ["Updated", "to", "add", "in", "pin", "...", "for", "Context", "and", "Subject"], "add_tokens": "# We'll add the setters manually with contracts # Stores the Context which encapsulates a Snowplow # event. # We'll add the setters manually with contracts", "del_tokens": "end # Internal helpers defining Ruby Contracts module Internal end", "commit_type": "update"}
{"commit_tokens": ["Moved", "youtube", "-", "dl_test", ".", "rb", "up", "a", "directory"], "add_tokens": "require_relative './test_helper'", "del_tokens": "require_relative '../test_helper'", "commit_type": "move"}
{"commit_tokens": ["Updating", "pools", "to", "use", "bind", "."], "add_tokens": "attach_function :create , :apr_pool_create_ex , [ :pointer , :pool , :abort_function , :pointer ] , :apr_status # use the C module for all bound methods bind_to C # clear all allocated memory in the pool so it can be reused bind :clear", "del_tokens": "# clear all allocated memory in the pool so it can be reused def clear C . clear ( self ) end attach_function :create , :apr_pool_create_ex , [ :pointer , :pool , :abort_function , :pointer ] , :apr_status", "commit_type": "update"}
{"commit_tokens": ["Added", "configurable", "blank_content", "i", ".", "e", ".", "any", "attribute", "content", "tag", "with", "blank", "value", "will", "contain", "this", "value", "instead", "unless", ":", "if_blank", "is", "specified", "."], "add_tokens": "value = options . delete ( :if_blank ) || ShowFor . blank_content if value . blank? && value != false", "del_tokens": "value = options . delete ( :if_blank ) if value . blank? && value != false", "commit_type": "add"}
{"commit_tokens": ["Add", "is_lead_investor", "to", "Investment", "model"], "add_tokens": "attr_reader :money_invested , :money_invested_currency_code , :money_invested_usd , :is_lead_investor , :created_at , :updated_at is_lead_investor end", "del_tokens": "attr_reader :money_invested , :money_invested_currency_code , :money_invested_usd , :created_at , :updated_at end", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "scope", "region", "collections", "both", "using", "regions", "and", "elements"], "add_tokens": "# self.class.new(@browser, region_element, @browser.divs(class: 'for-user').each_slice(1).to_a[1])", "del_tokens": "# self.class.new(@browser, region_element, region_collection.each_slice(1).to_a[1])", "commit_type": "allow"}
{"commit_tokens": ["Removed", "some", "crappy", "documentation", "."], "add_tokens": "module ClassMethods # http_proxy 'http://myProxy', 1080", "del_tokens": "module ClassMethods # http_proxy http://myProxy, 1080 # Warning: This is not thread safe most likely and # only works if you use one set of credentials. I # leave it because it is convenient on some occasions. # Updates the default query string parameters # that should be appended to each request. # TODO: spec out this # TODO: spec out this # TODO: spec out this # TODO: spec out this", "commit_type": "remove"}
{"commit_tokens": ["Change", "the", "default", "config", "file", "path"], "add_tokens": "DEFAULT_CONFIG_PATH = './config.yml'", "del_tokens": "DEFAULT_CONFIG_PATH = './hateblo4ruby.yml'", "commit_type": "change"}
{"commit_tokens": ["fixed", "per", "request", "timeout", "for", "patron"], "add_tokens": "to = ( opts [ :timeout ] || @options [ :timeout ] ) to = to . to_i if to to = nil if to && to < 1 return patron if patron && patron . timeout == to if patron . nil? patron = Patron :: Session . new patron . base_url = \"#{@host}:#{@port}\" end patron . timeout = to", "del_tokens": "return patron if patron patron = Patron :: Session . new patron . base_url = \"#{@host}:#{@port}\" if to = ( opts [ :timeout ] || @options [ :timeout ] ) to = to . to_i patron . timeout = to < 1 ? nil : to #else # patron.timeout = 5 # Patron's default end", "commit_type": "fix"}
{"commit_tokens": ["Move", "all", "constants", "in", "Unparser", "::", "Constants", "module"], "add_tokens": "require 'unparser/constants'", "del_tokens": "UNARY_OPERATORS = %w( ! ~ - @ + @ ) . map ( & :to_sym ) . to_set . freeze BINARY_OPERATORS = %w( + - * / & | && || << >> == === ! = <= < <=> > >= =~ ! ~ ^ * * ) . map ( & :to_sym ) . to_set . freeze", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "of", "case_sensitive", "to", "MissingUniqueIndexChecker"], "add_tokens": "index . unique && extract_index_columns ( index . columns ) . sort == sorted_index_columns # @return [Array<String>] def extract_index_columns ( index_columns ) return index_columns unless index_columns . is_a? ( String ) index_columns . split ( ',' ) . map ( & :strip ) . map { | str | str . gsub ( / lower \\( /i , 'lower(' ) } . map { | str | str . gsub ( / \\( ([^)]+) \\) :: \\w + / , '\\1' ) } end @index_columns ||= ( [ wrapped_attribute_name ] + Array . wrap ( validator . options [ :scope ] ) ) . map ( & :to_s ) # @return [String] def wrapped_attribute_name if validator . options [ :case_sensitive ] . nil? || validator . options [ :case_sensitive ] attribute else \"lower(#{attribute})\" end end", "del_tokens": "index . unique && index . columns . sort == sorted_index_columns @index_columns ||= ( [ attribute ] + Array . wrap ( validator . options [ :scope ] ) ) . map ( & :to_s )", "commit_type": "add"}
{"commit_tokens": ["Improve", "readability", "of", "spec", "output"], "add_tokens": "before ( :each ) { ExampleController . instance_variable_set ( :@authority_action_map , nil ) } it \"is created as a copy of the configured controller action map\" do expect ( ExampleController . authority_action_map ) . to eq ( Authority . configuration . controller_action_map ) expect ( ExampleController . authority_action_map ) . not_to be ( Authority . configuration . controller_action_map ) end it \"is unique per controller\" do child_controller = Class . new ( ExampleController ) child_controller . authority_action :erase => 'delete' expect ( child_controller . authority_action_map [ :erase ] ) . to eq ( 'delete' ) expect ( ExampleController . authority_action_map [ :erase ] ) . to be_nil", "del_tokens": "ExampleController . instance_variable_set ( :@authority_action_map , nil ) expect ( ExampleController . authority_action_map ) . not_to be ( Authority . configuration . controller_action_map ) describe \"when subclassing\" do it \"allows the child class to edit the controller action map without affecting the parent class\" do DummyController . authority_action :erase => 'delete' expect ( ExampleController . authority_action_map [ :erase ] ) . to be_nil end", "commit_type": "improve"}
{"commit_tokens": ["Add", "flusher", "error", "handler", "for", "now", "just", "log", "errors"], "add_tokens": "flusher_error_handler = FlusherErrorHandler . new ( Logger . new ( STDOUT ) ) flusher = Flusher . new ( reporter , authorizer , storage , auth_valid_min , flusher_error_handler )", "del_tokens": "flusher = Flusher . new ( reporter , authorizer , storage , auth_valid_min )", "commit_type": "add"}
{"commit_tokens": ["Updated", "/", "corrected", "documentation", "."], "add_tokens": "VERSION = \"0.2.3\"", "del_tokens": "VERSION = \"0.2.2\"", "commit_type": "update"}
{"commit_tokens": ["Allow", "overriding", "of", "behavior", "for", "<%", "=", "and", "<%", "==", "tags", "to", "depend", "on", "which", "indicator", "was", "used"], "add_tokens": "@escape = escape = properties . fetch ( :escape ) { properties . fetch ( :escape_html , false ) } add_expression ( indicator , code ) # Add the given ruby expression result to the template, # escaping it based on the indicator given and escape flag. def add_expression ( indicator , code ) if ( ( indicator == '=' ) ^ @escape ) add_expression_result ( code ) else add_expression_result_escaped ( code ) end end", "del_tokens": "escape = properties . fetch ( :escape ) { properties . fetch ( :escape_html , false ) } if ( ( indicator == '=' ) ^ escape ) add_expression_result ( code ) else add_expression_result_escaped ( code ) end", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "format", "of", "the", "ci", "skip", "message", "so", "it", "s", "more", "universally", "recognized"], "add_tokens": "commit_message << \" [ci skip]\" unless options [ :run_ci ]", "del_tokens": "commit_message << \" [skip ci]\" unless options [ :run_ci ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "attribute", "to", "client", "for", "getting", "local", "user"], "add_tokens": "# @!attribute [r] me # @return [User] The user associated with the access token. attr_reader :me # @param id [String] The user ID of the token owner. def initialize ( token , id , homeserver : nil ) @me = @users . send ( :get_user , id )", "del_tokens": "def initialize ( token , homeserver : nil )", "commit_type": "add"}
{"commit_tokens": ["added", "on_failure", "handling", ".", "fixed", "on_success", "and", "on_failure", "to", "pass", "their", "returned", "values", "to", "the", "remote_method", "block"], "add_tokens": "def default_on_success ( default_on_success ) @default_on_success = default_on_success end def default_on_failure ( default_on_failure ) @default_on_failure = default_on_failure end klass = self wrapped_block = lambda do | easy | response_code = easy . response_code if response_code > 199 && response_code < 300 if s = m . on_success || @default_on_success block . call ( klass . send ( s , easy ) ) else block . call ( easy ) end else if f = m . on_failure || @default_on_failure block . call ( klass . send ( f , easy ) ) else block . call ( easy ) end end end send ( m . http_method , base_uri + path , options . merge ( m . options ) , & wrapped_block )", "del_tokens": "send ( m . http_method , base_uri + path , options . merge ( m . options ) , & block )", "commit_type": "add"}
{"commit_tokens": ["update", "example", "to", "work", "with", "easy", "-", "serve", "rewrite"], "add_tokens": "ez . start_services do ez . service :seqd , :tcp , bind_host : svhost do | svr | ez . service :cseqd , :tcp , bind_host : svhost do | svr | # For comparison, here's a child process on the same host as the services.", "del_tokens": "ez . start_servers do ez . server :seqd , :tcp , svhost , 0 do | svr | ez . server :cseqd , :tcp , svhost , 0 do | svr | # For comparison, here's a child process on the same host as the servers.", "commit_type": "update"}
{"commit_tokens": ["Added", "examples", "to", "filter", ".", "rb", ";", "created", "insert_paru_version", "filter", "and", "updated", "generating", "documentation"], "add_tokens": "# Number all figures in a document and prefix the caption with \"Figure\". figure_counter = 0 ; figure_counter += 1 image . inner_markdown = \"Figure #{figure_counter}. #{image.inner_markdown}\"", "del_tokens": "current = 0 ; current += 1 image . inner_markdown = \"Figure #{current}. #{image.inner_markdown}\"", "commit_type": "add"}
{"commit_tokens": ["Add", "before", "/", "after", "update", "hooks"], "add_tokens": "before_update before_save dirty_fields = dirty_field_values table . where ( :id => id ) . update ( dirty_fields ) unless dirty_fields . empty? after_update after_save def before_update ; end def after_update ; end", "del_tokens": "table . where ( :id => id ) . update ( dirty_field_values )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "connection", "pool", "in", "the", "Bunny", "dispatcher", "."], "add_tokens": "require 'connection_pool' @pool = new_pool run do | conn | exchange = conn . exchange ( job . exchange_name , :type => :headers ) run do | conn | exchange = conn . direct ( \"woodhouse.progress\" ) conn . queue ( job . job_id , :durable => true ) . bind ( exchange , :routing_key => job . job_id ) rescue = > err Woodhouse . logger . warn ( \"Error when dispatching job update: #{err.class}: #{err.message}\" ) @pool . with do | conn | yield conn private def new_pool @bunny . stop if @bunny bunny = @bunny = Bunny . new ( @config . server_info || { } ) @bunny . start ConnectionPool . new { bunny . create_channel } end", "del_tokens": "@bunny = Bunny . new ( @config . server_info || { } ) @bunny . start @mutex = Mutex . new run do exchange = @bunny . exchange ( job . exchange_name , :type => :headers ) run do exchange = @bunny . direct ( \"woodhouse.progress\" ) @bunny . queue ( job . job_id , :durable => true ) . bind ( exchange , :routing_key => job . job_id ) @mutex . synchronize do yield", "commit_type": "use"}
{"commit_tokens": ["Fix", "an", "off", "-", "by", "-", "one", "error"], "add_tokens": "data . push idx + multiples . size - 1", "del_tokens": "data . push idx + multiples . size", "commit_type": "fix"}
{"commit_tokens": ["Add", "rbx", "specific", "exception", "message", "expectation"], "add_tokens": "message = if Devtools . rbx? %q(undefined method `unknown' on an instance of Ducktrap::Nary::Builder) else %q(undefined method `unknown' for #<Ducktrap::Nary::Builder klass=Ducktrap::Node::Block>) end message", "del_tokens": "%q(undefined method `unknown' for #<Ducktrap::Nary::Builder klass=Ducktrap::Node::Block>)", "commit_type": "add"}
{"commit_tokens": ["add", "allow_blank", "to", "uniqueness", "test"], "add_tokens": "validates_presence_of :email , if : :validate_email_presence? validates_uniqueness_of :email , allow_blank : true , if : :validate_email_uniqueness? validates_format_of :email , with : / \\A ([^@ \\s ]+)@((?:[-a-z0-9]+ \\. )+[a-z]{2,}) \\Z /i , if : :validate_email_format? validates_presence_of :password , if : :password_required? validates_confirmation_of :password , if : :password_required? validates_length_of :password , within : 6 .. 40 , if : :password_required?", "del_tokens": "validates_presence_of :email , :if => :validate_email_presence? validates_uniqueness_of :email , :if => :validate_email_uniqueness? validates_format_of :email , :with => / \\A ([^@ \\s ]+)@((?:[-a-z0-9]+ \\. )+[a-z]{2,}) \\Z /i , :if => :validate_email_format? validates_presence_of :password , :if => :password_required? validates_confirmation_of :password , :if => :password_required? validates_length_of :password , :within => 6 .. 40 , :if => :password_required?", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "limit", "directories", "exceeding", "entries", "limit", "."], "add_tokens": "@file_limit = options . fetch ( :file_limit ) { - 1 } def walk ( parent_path , entries , prefix , level ) if entries . empty? || ( @level != - 1 && @level < level ) return if @file_limit != - 1 && entries . size > @file_limit processed_paths = filter_entries ( entries , @filters ) . sort", "del_tokens": "def walk ( parent_path , files , prefix , level ) if files . empty? || ( @level != - 1 && @level < level ) processed_paths = filter_entries ( files , @filters ) . sort", "commit_type": "add"}
{"commit_tokens": ["Added", "Jim", "::", "Index", "which", "searches", "for", "files"], "add_tokens": "determine_name if ! name determine_version if ! version final_dir = install_path + 'lib' + name + version final_path = final_dir + \"#{name}#{tmp_path.extname}\" tmp_path . cp final_path final_path . expand_path", "del_tokens": "determine_name determine_version final_dir = install_path + name + version tmp_path . cp final_dir + \"#{name}#{tmp_path.extname}\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "client", "to", "try", "next", "IP", "on", "SSL", "connection", "error", "."], "add_tokens": "@connection_errors << ConnectionError . new ( \"SSL Connection error, IP may not be permitted to connect to #{@host}\" , next", "del_tokens": "raise ConnectionError . new ( \"SSL Connection error, IP may not be permitted to connect to #{@host}\" ,", "commit_type": "allow"}
{"commit_tokens": ["update", "cucumber", "tasks", "for", "new", "rspec"], "add_tokens": "require 'rspec/expectations'", "del_tokens": "require 'spec/expectations'", "commit_type": "update"}
{"commit_tokens": ["Implement", "exact", "precision", "mode", "for", "power", "log10", "etc", "."], "add_tokens": "# result in all cases is unchanged unless the context has exact precision, # in which case the result is Nan def self . handle ( context , * args ) Decimal . nan if context . exact? end return context . exception ( InvalidOperation , 'Exact next minus' ) if context . exact? return context . exception ( InvalidOperation , 'Exact next plus' ) if context . exact? return context . exception ( InvalidOperation , 'Exact next_toward' ) if context . exact? return _self if context . exact? if context . exact? if other . adjusted_exponent < 100 test_precision = _self . number_of_digits * other . to_i + 1 else test_precision = _self . number_of_digits + 1 end else test_precision = context . precision + 1 end ans = _self . _power_exact ( other , test_precision ) if ! ans . nil? return ans if context . exact? else return context . exception ( Inexact , \"Inexact power\" ) if context . exact? return ans if context . exact? return context . exception ( Inexact , \"Inexact power\" ) if context . exact?", "del_tokens": "# result in all cases is unchanged. ans = _self . _power_exact ( other , context . precision + 1 ) if ans . nil?", "commit_type": "implement"}
{"commit_tokens": ["fixed", "kill", "to", "use", "INT"], "add_tokens": "Process . kill ( 'INT' , pid )", "del_tokens": "Process . kill ( 9 , pid )", "commit_type": "fix"}
{"commit_tokens": ["add", "Actor#to_s", "as", "alias", "to", "Actor#name"], "add_tokens": "alias_method :to_s , :name end # Grit", "del_tokens": "end # Grit", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "test", "not", "recognizing", "queued", "job", "state", "(", "recent", "Manta", "change?", ")", "."], "add_tokens": "assert [ 'done' , 'running' , 'queued' ] . include? job [ 'state' ]", "del_tokens": "assert [ 'done' , 'running' ] . include? job [ 'state' ]", "commit_type": "fix"}
{"commit_tokens": ["add", "auto", "-", "number", "rounds"], "add_tokens": "## reset cached values ## for auto-number rounds etc. @last_round_pos = nil ##### # fix: move to read and share event/known_teams # for all 1-n fixture files (no need to configure every time!!) ## todo/check/fix: # make sure Round of 16 will not return pos 16 -- how? possible? # add unit test too to verify ## check if pos available; if not auto-number/calculate if pos . nil? pos = ( @last_round_pos || 0 ) + 1 logger . debug ( \" no round pos found; auto-number round - use (#{pos})\" ) end # store pos for auto-number next round if missing # - note: only if greater/bigger than last; use max # - note: last_round_pos might be nil - thus set to 0 @last_round_pos = [ pos , @last_round_pos || 0 ] . max # store pos for auto-number next round if missing # - note: only if greater/bigger than last; use max # - note: last_round_pos might be nil - thus set to 0 @last_round_pos = [ round . pos , @last_round_pos || 0 ] . max", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "specs", "for", "ways", "."], "add_tokens": "# Is this changeset still open? # List of attributes for a Changeset def attribute_list [ :id , :user , :uid , :open , :created_at , :closed_at , :min_lat , :max_lat , :min_lon , :max_lon ] end # Returns a hash of all non-nil attributes of this object. # # Keys of this hash are <tt>:id</tt>, <tt>:user</tt>, # and <tt>:timestamp</tt>. For a Node also <tt>:lon</tt> # and <tt>:lat</tt>. # # call-seq: attributes -> Hash # def attributes attrs = Hash . new attribute_list . each do | attribute | value = self . send ( attribute ) attrs [ attribute ] = value unless value . nil? end attrs end xml . changeset ( attributes ) do", "del_tokens": "xml . changeset do", "commit_type": "add"}
{"commit_tokens": ["add", "minor", "change", "to", "log", "possible", "failure", "in", "travis"], "add_tokens": "$stderr . puts \"#{root} is not in a git root\"", "del_tokens": "# $stderr.puts \"#{root} is not in a git root\"", "commit_type": "add"}
{"commit_tokens": ["Improve", "the", "logic", "to", "resolve", "URI", "Template", "in", "href"], "add_tokens": "path = CGI . unescape ( key ) . gsub ( / [()] / , \"\" ) name = path . split ( \"/\" ) . last if property = JsonPointer . evaluate ( @schema . data , path ) if example = property [ \"example\" ]", "del_tokens": "name = CGI . unescape ( key ) . gsub ( / [()] / , \"\" ) . split ( \"/\" ) . last if property = link . parent . properties [ name ] if example = property . data [ \"example\" ]", "commit_type": "improve"}
{"commit_tokens": ["allow", "updating", "without", "a", "hash"], "add_tokens": "def update ( params = { } )", "del_tokens": "def update ( params )", "commit_type": "allow"}
{"commit_tokens": ["Changing", "instantiation", "of", "Converter", "class"], "add_tokens": "self . newLenghtInstance self . newLenghtInstance def self . newLenghtInstance ( ) if @lengthConverter . nil? @lengthConverter = Length . new ( ) else # do nothing end end def self . newVolumeInstance ( ) if @volumeConverter . nil? @volumeConverter = Volume . new ( ) else # do nothing end end def self . newAreaInstance ( ) if @areaConverter . nil? @areaConverter = Area . new ( ) else # do nothing end end def self . newMassInstance ( ) if @massConverter . nil? @massConverter = Mass . new ( ) else # do nothing end end", "del_tokens": "@lengthConverter = Length . new ( ) @volumeConverter = Volume . new ( ) @areaConverter = Area . new ( ) @massConverter = Mass . new ( )", "commit_type": "change"}
{"commit_tokens": ["Moved", "running", "s", "no", "result", "/", "error", "printing", "into", "format_results"], "add_tokens": "\"|1[0-#{ [9, n - 10].min }]\" if n > 9 } #{ \"|2[0-#{ n - 20 }]\" if n > 19 } ) $/", "del_tokens": "\"|1[0-#{ [9, n - 10].min }]\" if n > 9 } #{ \"|2[0-#{ n - 20 }]\" if n > 19 } ) $/", "commit_type": "move"}
{"commit_tokens": ["add", "support", "for", "getting", "a", "project", "name"], "add_tokens": "require \"name_whisperer\" name = CocoaPodsKeys :: NameWhisperer . get_project_name keyring = CocoaPodsKeys :: Keyring . new ( name , current_dir , [ ] )", "del_tokens": "keyring = CocoaPodsKeys :: Keyring . new ( \"name\" , current_dir , [ ] )", "commit_type": "add"}
{"commit_tokens": ["Use", "gemspec", "in", "Gemfile", "to", "sync", "Gemfile", "with", "Rakefile"], "add_tokens": "Bundler . setup", "del_tokens": "Bundler . setup ( :default , :test )", "commit_type": "use"}
{"commit_tokens": ["added", "another", "test", "for", "issue", "13", "bumped", "up", "the", "version", "and", "updated", "the", "README"], "add_tokens": "VERSION = \"3.3.1\" unless defined? ( :: ClosureTree :: VERSION )", "del_tokens": "VERSION = \"3.3.0\" unless defined? ( :: ClosureTree :: VERSION )", "commit_type": "add"}
{"commit_tokens": ["Use", "Yardstick", "::", "ROOT", "to", "specify", "the", "lib", "folder"], "add_tokens": "require Pathname ( __FILE__ ) . dirname . expand_path . join ( '..' , 'lib' , 'yardstick' ) Pathname . glob ( Yardstick :: ROOT . join ( 'lib' , '**' , '*.rb' ) ) . sort . each do | file |", "del_tokens": "dir = Pathname ( __FILE__ ) . dirname . expand_path . join ( '..' , 'lib' ) require dir + 'yardstick' Pathname . glob ( dir . join ( '**' , '*.rb' ) ) . sort . each do | file |", "commit_type": "use"}
{"commit_tokens": ["add", "autosign", "-", "validator", "executable", "to", "gem"], "add_tokens": "VERSION = '0.0.6'", "del_tokens": "VERSION = '0.0.5'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "horizontal", "."], "add_tokens": "CSI + 'A' + horizontal ( 1 ) CSI + '2K' + horizontal ( 1 )", "del_tokens": "CSI + 'A' + CSI + '1G' CSI + '2K' + CSI + '1G'", "commit_type": "change"}
{"commit_tokens": ["Remove", "the", "dependency", "on", "the", "single", "character", "strings", "x", "and", "o", "and", "just", "match", "against", "the", "constant", "symbols", "XO", "::", "Grid", "::", "X", "and", "XO", "::", "Grid", "::", "O"], "add_tokens": "sym = ch . to_sym sym == X || sym == O ? sym : :e", "del_tokens": "ch == 'x' ? X : ( ch == 'o' ? O : :e )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "typo", "in", "README", "and", "cleaned", "up", "def", "age", "inside", "of", "query_methods", "to", "be", "more", "readable"], "add_tokens": "", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["make", "Page", "enumerable", "make", "hypermedia", "links", "accessible"], "add_tokens": "include Enumerable attr_accessor :links self . links = { } response [ :links ] . each do | link | links [ link [ :rel ] . to_sym ] = link [ :uri ] end end def each ( & blk ) @list . each ( & blk ) # TODO: remove this accum = [ ] each do | elem | accum << elem end accum", "del_tokens": "# rubocop:disable TrivialAccessors @list", "commit_type": "make"}
{"commit_tokens": ["Make", "sharpen", "mask", "on", "image", "reduction", "configurable", "."], "add_tokens": "def self . configure @config ||= begin c = Struct . new ( :sharpen_mask , :sharpen_scale ) . new c . sharpen_mask = [ [ - 1 , - 1 , - 1 ] , [ - 1 , 24 , - 1 ] , [ - 1 , - 1 , - 1 ] ] c . sharpen_scale = 16 c end @config yield @config if block_given? @config image = image . conv ( cwv_sharpen_mask ) if cwv_config . sharpen_mask def cwv_config CarrierWave :: Vips . configure end def cwv_sharpen_mask ( mask = cwv_config . sharpen_mask , scale = cwv_config . sharpen_scale ) :: Vips :: Image . new_from_array ( mask , scale ) end", "del_tokens": "SHARPEN_MASK = begin conv_mask = [ [ - 1 , - 1 , - 1 ] , [ - 1 , 24 , - 1 ] , [ - 1 , - 1 , - 1 ] ] :: Vips :: Image . new_from_array conv_mask , 16 image = image . conv SHARPEN_MASK", "commit_type": "make"}
{"commit_tokens": ["Removed", "stupid", "core", "extension", ".", "It", "was", "stupid", "trust", "me", "."], "add_tokens": "directory = File . dirname ( __FILE__ ) $: . unshift ( directory ) unless $: . include? ( directory ) || $: . include? ( File . expand_path ( directory ) )", "del_tokens": "$: . unshift ( File . dirname ( __FILE__ ) ) unless $: . include? ( File . dirname ( __FILE__ ) ) || $: . include? ( File . expand_path ( File . dirname ( __FILE__ ) ) ) dir = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , 'httparty' ) ) require dir + '/core_ext'", "commit_type": "remove"}
{"commit_tokens": ["Make", "the", "flash", "as", "bright", "as", "possible", "."], "add_tokens": "flash_state = { :xy => xy , :on => true , :bri => 255 } set ( flash_state ) final_state = { :xy => start [ \"xy\" ] , :on => start [ \"on\" ] , :bri => start [ \"bri\" ] } set ( final_state )", "del_tokens": "set ( :xy => xy , :on => true ) set ( :xy => start [ \"xy\" ] , :on => start [ \"on\" ] )", "commit_type": "make"}
{"commit_tokens": ["Allow", "host", "to", "be", "used", "in", "job", "template"], "add_tokens": "render_safe ( @template . template , [ :input ] , :host => @host )", "del_tokens": "render_safe ( @template . template , [ :input ] )", "commit_type": "allow"}
{"commit_tokens": ["fixed", "directory", "structure", "for", "thread_safty_test"], "add_tokens": "ITERATIONS = 19 rescue = > e puts e puts e . backtrace raise e rescue = > e puts e puts e . backtrace raise e", "del_tokens": "ITERATIONS = 1", "commit_type": "fix"}
{"commit_tokens": ["Change", "url", "validation", "to", "make", "coveralls", "happy"], "add_tokens": "raise \"Missing request parameters [#{missing_args}]\" unless missing_args . empty? raise \"Unexpected request parameters [#{extra_args}]\" unless extra_args . empty?", "del_tokens": "return if missing_args . empty? missing_args_string = missing_args . join ( ', ' ) raise \"Missing request parameters [#{missing_args_string}]\" return if extra_args . empty? extra_args_string = extra_args . join ( ', ' ) raise \"Unexpected request parameters [#{extra_args_string}]\"", "commit_type": "change"}
{"commit_tokens": ["make", "chat", "adapter", "registration", "/", "usage", "more", "explicit"], "add_tokens": "desired = ( settings [ \"JANKY_CHAT_SERVICE\" ] || 'campfire' ) . downcase . to_sym @service = @adapters . detect ( lambda { self . invalid_service! ( desired ) } ) { | k , v | k == desired } . last @service . setup ( settings ) attr_accessor :adapters # Called during setup if an invalid chat service is requested def self . invalid_service! ( desired ) raise \"Invalid chat service adapter '#{desired}' requested. Valid values are: #{@adapters.keys.join(',')}\" end", "del_tokens": "s = Janky :: Chat . constants . detect do | chat | chat . to_s . casecmp ( settings [ \"JANKY_CHAT_SERVICE\" ] || 'Campfire' ) == 0 end @service = Janky :: Chat . const_get ( s ) service . setup ( settings )", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "mapping", "fix", "for", "campaign_summary"], "add_tokens": "VERSION = '0.2.2'", "del_tokens": "VERSION = '0.2.1'", "commit_type": "add"}
{"commit_tokens": ["Updating", "whitelabel", "lookup", "to", "use", "new", "non", "-", "url", "identifier", "."], "add_tokens": "# params [String] user_identifier The whitelabel identifier of the user (passed to checkd.in during creation) def whitelabel_user_lookup ( user_identifier ) response = connection . get ( \"users/whitelabel.json?user_identifier=#{id}\" )", "del_tokens": "# params [Integer] id The whitelabel identifier of the user (passed to checkd.in during creation) def whitelabel_user_lookup ( id ) response = connection . get ( \"users/whitelabel/#{id}\" )", "commit_type": "update"}
{"commit_tokens": ["Added", "the", "option", "to", "change", "the", "spacing", "between", "bar", "charts", "."], "add_tokens": "def initialize_ivars super @spacing_factor = 0.9 end # Can be used to adjust the spaces between the bars. # Accepts values between 0.00 and 1.00 where 0.00 means no spacing at all # and 1 means that each bars' width is nearly 0 (so each bar is a simple # line with no x dimension). # # Default value is 0.9. def spacing_factor = ( space_percent ) raise ArgumentError , \"spacing_factor must be between 0.00 and 1.00\" unless ( space_percent >= 0 and space_percent <= 1 ) @spacing_factor = ( 1 - space_percent ) end padding = ( @bar_width * ( 1 - @spacing_factor ) ) / 2 right_x = left_x + @bar_width * @spacing_factor", "del_tokens": "padding = ( @bar_width * ( 1 - spacing_factor ) ) / 2 right_x = left_x + @bar_width * spacing_factor", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "extracting", "effectiveTime", "from", "C32"], "add_tokens": "# birth date, gender and the effectiveTime. effective_date = doc . at_xpath ( '/cda:ClinicalDocument/cda:effectiveTime' ) [ 'value' ] patient . effective_time = HL7Helper . timestamp_to_integer ( effective_date )", "del_tokens": "# birth date and gender.", "commit_type": "add"}
{"commit_tokens": ["fixed", "Server", "to", "set", "@log_stdout", "and", "@log_stderr", "configuration", "parameters"], "add_tokens": "@log_stdout = ! ! @config . fetch ( :log_stdout , true ) @log_stderr = ! ! @config . fetch ( :log_stderr , true ) @log_stdout = false if @config [ :log ] == '-' @log_stderr = false if @config [ :log ] == nil", "del_tokens": "if @logger . same_io? ( io ) return end", "commit_type": "fix"}
{"commit_tokens": ["Adding", "option", "to", "hide", "the", "stamp", "."], "add_tokens": "return nil if ! ! self . class . hide_stamp attr_accessor :sha , :content , :hide_stamp", "del_tokens": "attr_accessor :sha , :content", "commit_type": "add"}
{"commit_tokens": ["add", "--", "pretty", "to", "hc", "to", "prettily", "format", "body"], "add_tokens": "require 'rack' request_body = alter_body_by_content_type ( request_env [ :body ] , request_env [ :request_headers ] [ 'Content-Type' ] ) response_body = alter_body_by_content_type ( response_env [ :body ] , response_env [ :response_headers ] [ 'Content-Type' ] ) def pretty? @options [ :pretty ] . nil? ? true : @options [ :pretty ] end # takes a body and a content type; returns the body, altered according to options. # # - with coloring (ansi colors for terminals) possibly added, if it's a recognized content type and # #color? is true # - formatted prettily if #pretty? is true def alter_body_by_content_type ( body , content_type ) return body unless body . is_a? ( String ) media_type = :: Rack :: Request . new ( { 'CONTENT_TYPE' => content_type } ) . media_type if pretty? case media_type when 'application/json' require 'json' begin body = JSON . pretty_generate ( JSON . parse ( body ) ) rescue JSON :: ParserError end end end if color?", "del_tokens": "request_body = color_body_by_content_type ( request_env [ :body ] , request_env [ :request_headers ] [ 'Content-Type' ] ) response_body = color_body_by_content_type ( response_env [ :body ] , response_env [ :response_headers ] [ 'Content-Type' ] ) # takes a body and a content type; returns the body, with coloring (ansi colors for terminals) # possibly added, if it's a recognized content type and #color? is true def color_body_by_content_type ( body , content_type ) if body && color? # kinda hacky way to get the media_type. faraday should supply this ... require 'rack' media_type = :: Rack :: Request . new ( { 'CONTENT_TYPE' => content_type } ) . media_type", "commit_type": "add"}
{"commit_tokens": ["Remove", "display", "method", "from", "IO", "should", "use", "display_clear", "."], "add_tokens": "def self . display_clear ; super ; end", "del_tokens": "def self . display_clean ; super ; end # Clean Display # # @return [nil] def self . display ( buffer , column = 0 , row = 0 ) ; super ; end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "creation", "of", "abbreviations", "for", "the", "command", "line", "tasks", "."], "add_tokens": "tasks . keys . abbrev . each do | shortcut , command | map shortcut => command . to_sym end", "del_tokens": "tasks . keys . abbrev . each do | shortcut , command | map shortcut => command . to_sym end", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "size", "attribute", "optional", ".", "This", "is", "getting", "tiring", "."], "add_tokens": "size = nil if tempfile . respond_to? ( :size ) size = tempfile . size elsif tempfile . respond_to? ( :stat ) size = tempfile . stat . size end self [ \"#{attachment_file_prefix}_size\" ] = size unless size . nil?", "del_tokens": "self [ \"#{attachment_file_prefix}_size\" ] = tempfile . size", "commit_type": "make"}
{"commit_tokens": ["Use", "Boolean", "instead", "of", "true", "false", "in", "docs", "."], "add_tokens": "# @return [Boolean] # @return [Boolean]", "del_tokens": "# @return [true, false] # @return [true, false]", "commit_type": "use"}
{"commit_tokens": ["Allow", "the", "formatter", "to", "generate", "the", "header"], "add_tokens": "puts formatter . write_header ( formatter . header ( changelog ) )", "del_tokens": "puts formatter . write_header ( changelog . header )", "commit_type": "allow"}
{"commit_tokens": ["Use", "instance", "to_token", "method", "instead", "of", "class", "token_json"], "add_tokens": "categories = Category . where ( \"categories.name like ?\" , \"%#{params[:q]}%\" ) format . json { render :json => categories . map ( & :to_token ) }", "del_tokens": "@categories = Category . where ( \"categories.name like ?\" , \"%#{params[:q]}%\" ) format . json { render :json => Category . token_json ( @categories ) }", "commit_type": "use"}
{"commit_tokens": ["added", "a", "few", "more", "docs"], "add_tokens": "# Returns an array of Post objects representing all posts belonging to the given thread. The arrays is sorted in order of created_at date. end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "to", "set", "parameter", "value", "with", "checking"], "add_tokens": "attr_reader :value # Public # Set the parameter value # @param [Object] value - Value to set the parameter to def set ( value ) case @input_parameters [ parameter ] . type when 'Array' fail ( IOError , ERR [ :param_verify_failed ] ) unless value . is_a? ( Array ) when 'string' fail ( IOError , ERR [ :param_verify_failed ] ) unless value . is_a? ( Array ) when 'number' fail ( IOError , ERR [ :param_verify_failed ] ) unless value . is_a? ( Array ) end @value = value end", "del_tokens": "attr_accessor :value", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Roo", "::", "Excel", "constant"], "add_tokens": "parser = Roo :: Excel . new ( file ) parser = Roo :: Excelx . new ( file )", "del_tokens": "parser = Excel . new ( file ) parser = Excelx . new ( file )", "commit_type": "fix"}
{"commit_tokens": ["Made", "coveralls", "only", "run", "when", "using", "MRI", "ruby"], "add_tokens": "if ENV [ 'TRAVIS' ] && ENV [ 'COVERALLS' ] && RUBY_ENGINE == 'ruby'", "del_tokens": "if ENV [ 'TRAVIS' ] && ENV [ 'COVERALLS' ]", "commit_type": "make"}
{"commit_tokens": ["Improve", "Geometry", "and", "add", "more", "tests"], "add_tokens": "def valid? circle? || closed_shape? end private def circle? @result_array . size == 1 && @result_array . first . is_a? ( AIXM :: Horizontal :: Circle ) end def closed_shape? @result_array . size >= 3 && ! @result_array . any? { | h | h . is_a? ( AIXM :: Horizontal :: Circle ) } &&", "del_tokens": "def closed? @result_array . first . is_a? ( AIXM :: Horizontal :: Point ) &&", "commit_type": "improve"}
{"commit_tokens": ["moved", "mixins", "to", "lib", "/", "neo4j", "/", "mixins", "folder"], "add_tokens": "require 'neo4j/mixins/transactional' require 'neo4j/mixins/relation' require 'neo4j/mixins/dynamic_accessor' require 'neo4j/mixins/dynamic_accessor' require 'neo4j/mixins/node'", "del_tokens": "require 'neo4j/transactional' require 'neo4j/relation' require 'neo4j/dynamic_accessor' require 'neo4j/dynamic_accessor' require 'neo4j/node'", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "relative", "path", "bug", "in", "the", "image_tag", "helper"], "add_tokens": "#{image_tag(\"foo.jpg\", :alt => \"[foo image]\")}", "del_tokens": "#{image_tag(\"/images/foo.jpg\", :alt => \"[foo image]\")}", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "member", "method", "to", "delete", "the", "store", "/", "database", "."], "add_tokens": "VERSION = \"1.1.0\"", "del_tokens": "VERSION = \"1.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Added", "in", "test", "for", "relative", "paths"], "add_tokens": "write_metadata ( name , '1.0.0' ) write_metadata ( name , '2.3.4' ) hg ( 'add' ) hg_commit ( 'More changes' ) end end Given ( / ^a remote mercurial repo with two cookbooks named \"(.*?)\" and \"(.*?)\"$ / ) do | name1 , name2 | project_path = File . join ( tmp_path , 'hg-cookbooks' ) [ name1 , name2 ] . each do | name | cookbook_path = File . join ( project_path , 'site-cookbooks' , name ) FileUtils . mkdir_p ( cookbook_path ) write_metadata ( name , '1.0.1' , cookbook_path ) end Dir . chdir ( project_path ) do hg ( \"init\" ) hg ( 'add' ) hg_commit ( 'adding_cookbooks' ) end end def write_metadata ( name , version , path = \"./\" ) File . open ( File . join ( path , \"metadata.rb\" ) , \"w\" ) do | f | version '#{version}'", "del_tokens": "File . open ( 'metadata.rb' , 'w' ) do | f | f . write <<-EOH name '#{name}' version '1.0.0' EOH end File . open ( 'metadata.rb' , 'w' ) do | f | version '2.3.4' end hg ( 'add' ) hg_commit ( 'More changes' )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "deleting", "active", "record", "sessions"], "add_tokens": "session = Session . where ( session_id : sid ) . delete_all end", "del_tokens": "session = Session . where ( session_id : sid ) . delete end", "commit_type": "fix"}
{"commit_tokens": ["Moved", "version", "into", "Aerogel", "::", "Core", "namespace"], "add_tokens": "module Core VERSION = '1.4.0' end # module Core", "del_tokens": "VERSION = '1.4.0'", "commit_type": "move"}
{"commit_tokens": ["Change", "how", "--", "trace", "is", "handled", "now", "a", "bit", "more", "flexible", "."], "add_tokens": "'dry_run' => false , 'trace' => false fail Exception , \"Unable to the load the file '#{file_path}', are you sure it exists?\" , caller fail Exception , \"Unable to the readthe file '#{file_path}', check it has the right permissions.\" , caller fail Exception , \"An error occured parsing the config file '#{file_path}', please check it uses valid TOML syntax.\" , caller", "del_tokens": "'dry_run' => false raise Exception . new ( \"Unable to the load the file '#{file_path}', are you sure it exists?\" ) raise Exception . new ( \"Unable to the readthe file '#{file_path}', check it has the right permissions.\" ) raise Exception . new ( \"An error occured parsing the config file '#{file_path}', please check it uses valid TOML syntax.\" )", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "more", "helpful", "file", "path", "for", "Tilt", "to", "report"], "add_tokens": "if template_type = Tilt [ filename ] file_path = source_path . to_s . sub ( / ^ #{ Regexp . escape ( Massimo . config . source_path ) } / , '' ) template = template_type . new ( file_path , @line || 1 ) { output } @meta_data [ :title ] ||= filename . chomp ( source_path . extname . to_s ) . titleize @meta_data [ :url ] ||= super . chomp ( 'index.html' ) . sub ( / \\. html$ / , '/' )", "del_tokens": "if template_type = Tilt [ source_path . basename . to_s ] template = template_type . new ( nil , @line || 1 ) { output } @meta_data [ :title ] ||= source_path . basename . to_s . chomp ( source_path . extname . to_s ) . titleize @meta_data [ :url ] ||= begin url = super url . chomp! ( 'index.html' ) url . sub! ( / \\. html$ / , '/' ) url end", "commit_type": "add"}
{"commit_tokens": ["Add", "all", "future", "photos", "methods", "to", "ParamsProcessor"], "add_tokens": "[ \"favorites.getPublicList\" , \"favorites.getList\" , \"galleries.getPhotos\" , \"groups.pools.getPhotos\" , \"panda.getPhotos\" , \"photos.comments.getRecentForContacts\" , \"photos.geo.getLocation\" , \"photos.geo.photosForLocation\" , \"photos.getContactsPhotos\" , \"photos.getContactsPublicPhotos\" , \"photos.getNotInSet\" , \"photos.getRecent\" , \"photos.getWithGeoData\" , \"photos.getUntagged\" , \"photos.getWithoutGeoData\" , \"photos.search\" , \"photos.recentlyUpdated\" , \"photosets.getPhotos\" ] . include? ( flickr_method )", "del_tokens": "[ \"photos.getContactsPhotos\" , \"photos.search\" , \"photos.getNotInSet\" , \"photos.getRecent\" , \"photos.getUntagged\" , \"photos.getWithGeoData\" , \"photos.getWithoutGeoData\" , \"photos.RecentlyUpdated\" , \"photosets.getPhotos\" , \"people.getContactsPublicPhotos\" ] . include? ( flickr_method )", "commit_type": "add"}
{"commit_tokens": ["adding", "tests", "for", "config", "vars", "and", "modifying", "how", "kensa", "did", "it", "before"], "add_tokens": "\"config_vars\" : [ { \"name\" : \"MYSERVICE_URL\" , \"description\" : \"Short config var description\" } ] ,", "del_tokens": "\"config_vars\" : [ \"MYSERVICE_URL\" ] ,", "commit_type": "add"}
{"commit_tokens": ["Fixing", "url_info", "with", "host", "/", "port", "in", "a", "item", "of", "firewall"], "add_tokens": "services . map do | service | host : service . host , port : service . port , scheme : service . uri . scheme || ''", "del_tokens": "services . map do | s | host : s . uri . host , port : s . uri . port , scheme : s . uri . scheme", "commit_type": "fix"}
{"commit_tokens": ["adding", "in", "some", "more", "comments"], "add_tokens": "fattr channel : '#general' # Generate the payload if stuff was provided", "del_tokens": "fattr channel : '#slackdraft' # Send the message! def send! # Send the request request = HTTParty . post ( self . target , :body => { :payload => generate_payload . to_json } ) unless request . code . eql? 200 false end true end", "commit_type": "add"}
{"commit_tokens": ["Fix", "loading", "of", "ruby", "code", "in", "runtime"], "add_tokens": "js = @parser . wrap_with_runtime_helpers ( parsed [ :code ] ) var result = ( #{js})(opal.runtime.top, '#{file}'); src = File . read ( File . join dir , 'opal.js' ) src += @parser . build_parse_data ( data ) @v8 . eval src , '(runtime)' @inspect_id = data [ :methods ] [ :inspect ] . to_s", "del_tokens": "js = parsed [ :code ] var result = ( #{js})(opal.runtime, opal.runtime.top, '#{file}'); src = File . join dir , 'opal.js' @v8 . eval File . read ( src ) , src @v8 . eval @parser . build_parse_data ( data ) @inspect_id = data [ \"methods\" ] [ :inspect ] . to_s", "commit_type": "fix"}
{"commit_tokens": ["Add", "methods", "for", "setting", "and", "getting", "container", "headers"], "add_tokens": "custom = { } response . each_capitalized_name { | name | custom [ name ] = response [ name ] if name [ / \\A X-Container-Meta- / ] } :bytes => response [ \"X-Container-Bytes-Used\" ] . to_i , :custom => custom , # Set metadata headers on the container # # headers = { \"X-Container-Meta-Access-Control-Allow-Origin\" => \"*\" } # container.set_metadata(headers) # # Note: Rackspace requires some headers to begin with 'X-Container-Meta-' or other prefixes, e.g. when setting # 'Access-Control-Allow-Origin', it needs to be set as 'X-Container-Meta-Access-Control-Allow-Origin'. # See: http://docs.rackspace.com/files/api/v1/cf-devguide/content/CORS_Container_Header-d1e1300.html # http://docs.rackspace.com/files/api/v1/cf-devguide/content/POST_updateacontainermeta_v1__account___container__containerServicesOperations_d1e000.html # def set_metadata ( headers ) log \"setting headers for container #{container_path}\" response = storage_client . post ( container_path , '' , headers ) ( 200 .. 299 ) . cover? ( response . code . to_i ) end", "del_tokens": ":bytes => response [ \"X-Container-Bytes-Used\" ] . to_i", "commit_type": "add"}
{"commit_tokens": ["removing", "extraneous", "logger", ".", "debug", "calls"], "add_tokens": "# run text filters (skip if using pandoc-ruby)", "del_tokens": "# run text filters logger . debug ( content )", "commit_type": "remove"}
{"commit_tokens": ["Added", "the", "ability", "to", "override", "the", "threshold", "when", "using", "the", "pagination", "scope", "."], "add_tokens": "def pagination_scope ( search_scope , proto_object , options = { } ) threshold = options . fetch ( :threshold , EMPTY_PAGINATION_ERROR_THRESHOLD ) if count > threshold raise 'Search returns too many results without pagination. %d results found. Threshold is %d' % [ count , threshold ]", "del_tokens": "def pagination_scope ( search_scope , proto_object ) if count > EMPTY_PAGINATION_ERROR_THRESHOLD raise 'Search returns too many results without pagination. %d results found. Threshold is %d' % [ count , EMPTY_PAGINATION_ERROR_THRESHOLD ]", "commit_type": "add"}
{"commit_tokens": ["change", "update", "method", "to", "be", "consistent", "with", "blockscore", "-", "php", "lib"], "add_tokens": "module Update def save begin self . class . patch \"#{self.class.endpoint}#{id}\" , filter_params true rescue false end end # Filters out the non-updateable params def filter_params persistent = %i( id object created_at updated_at livemode class ) @attrs . reject { | k , v | persistent . include? ( k ) } end def method_missing ( method , * args , & block ) if respond_to_missing? method is_setter = method . to_s [ - 1 ] == '=' if is_setter @attrs [ method . to_s . chomp ( '=' ) . to_sym ] = args [ 0 ] else @attrs [ method ] end else super end end def respond_to_missing? ( symbol , include_private = false ) setter = symbol . to_s [ 0 .. - 2 ] . to_sym @attrs && ( @attrs . has_key? ( symbol ) || @attrs . has_key? ( setter ) ) || super", "del_tokens": "module Update def update ( params ) self . class . patch \"#{self.class.endpoint}#{id}\" , params refresh", "commit_type": "change"}
{"commit_tokens": ["remove", "non", "duck", "typing", "behavior"], "add_tokens": "# @param charset [SecretSharing::Charset::DynamicCharset] # @param point [SecretSharing::Point]", "del_tokens": "unless charset . is_a? ( SecretSharing :: Charset :: DynamicCharset ) error_msg = 'Charset must be a SecretSharing::Charset::DynamicCharset' fail ArgumentError , error_msg end unless point . is_a? ( SecretSharing :: Point ) fail ArgumentError , 'Point must be SecretSharing::Point' end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "directory", "source", "for", "new", "arguments", "."], "add_tokens": "Contract ArrayOf [ Solve :: Constraint ] , String , Bool , Or [ String , NilClass ] = > ArrayOf [ Semverse :: Version ] def versions ( * _ )", "del_tokens": "Contract ArrayOf [ Solve :: Constraint ] => ArrayOf [ Semverse :: Version ] def versions ( _ )", "commit_type": "fix"}
{"commit_tokens": ["Added", "base", "object", "and", "tests"], "add_tokens": "require 'active_support/core_ext/kernel' require 'active_support/core_ext/class' require 'active_support/core_ext/hash' require 'active_support/secure_random' require 'active_support/callbacks' require 'yaml' require File . dirname ( __FILE__ ) + \"/yaml_record/base\"", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["use", "Travis", ".", "config", "in", "Travis", "::", "Database"], "add_tokens": "ActiveRecord :: Base . configurations = { env => Travis . config . database } ActiveRecord :: Base . establish_connection ( env ) def env Travis . config . env", "del_tokens": "ActiveRecord :: Base . configurations = configurations ActiveRecord :: Base . establish_connection ( environment ) def configurations @configurations ||= YAML :: load ( ERB . new ( File . read ( 'db/config.yml' ) ) . result ) end def environment @environment ||= options [ :env ] || ENV [ 'ENV' ] || 'production'", "commit_type": "use"}
{"commit_tokens": ["Fix", "json", "file", "writing", "in", "production", "/", "test", "env"], "add_tokens": "write_in_swagger_file . to_json", "del_tokens": "write_inswagger_file . to_json", "commit_type": "fix"}
{"commit_tokens": ["Fix", "stack", "level", "too", "deep", "when", "no", "translations", "found"], "add_tokens": "localized_path = I18n . t ( resource . name , :scope => type , :default => resource . name )", "del_tokens": "localized_path = I18n . t ( resource . name , :scope => type , :default => nil )", "commit_type": "fix"}
{"commit_tokens": ["implemented", "is", "{}", "as", "iteration", "wrote", "some", "examples"], "add_tokens": "b . each do | e | a . rubylog_unify ( e ) { yield } end [ :is , :matches , :in ] . each do | f |", "del_tokens": "yield if b . rubylog_dereference . include? a . rubylog_dereference [ :is , :matches ] . each do | f |", "commit_type": "implement"}
{"commit_tokens": ["Added", "a", "sidekiq_option", "to", "control", "the", "duration", "of", "the", "unique", "check"], "add_tokens": "unique_job_expiration = worker_class . get_sidekiq_options [ 'unique_job_expiration' ] expires_at = unique_job_expiration || HASH_KEY_EXPIRATION", "del_tokens": "expires_at = HASH_KEY_EXPIRATION", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "more", "util", "methods", "."], "add_tokens": "\"Numeric\" , \"Hash\"", "del_tokens": "\"Numeric\"", "commit_type": "add"}
{"commit_tokens": ["add", "parent", "and", "load", "methods"], "add_tokens": "new ( zk , path ) . tap do | node | node . raw_data = opts [ :raw_data ] || '' node . mode = opts . delete ( :mode ) || :persistent node . save end end # instantiates a Znode at path and calls #reload on it to load the data and current stat def self . load ( zk , path ) new ( zk , path ) . reload # the parent of this node, returns nil if path is '/' # # ==== Arguments # * +reload+: if true, reloads the parent object # def parent ( reload = false ) return nil if path == '/' if @parent @parent . reload if reload else @parent = self . class . load ( zk , path ) end end def inspect \"#<#{self.class}:#{self.object_id} @path=#{path.inspect} ...>\" end", "del_tokens": "node = new ( zk , path ) node . mode = opts . delete ( :mode ) || :persistent node . save node", "commit_type": "add"}
{"commit_tokens": ["allow", "api", "response", ":", "errors", "to", "be", "hash", "or", "array"], "add_tokens": "errors = errors . values . flatten if errors . is_a? ( Hash )", "del_tokens": "errors = errors . values . flatten", "commit_type": "allow"}
{"commit_tokens": ["updated", "cancan", "-", "permits", "dependency"], "add_tokens": "rgen \"cancan:permits --roles #{roles} --orm #{orm}\" rgen \"cancan:licenses\"", "del_tokens": "rgen \"permits --roles #{roles} --orm #{orm}\"", "commit_type": "update"}
{"commit_tokens": ["Added", "spec", "for", "uncovered", "code", "in", "the", "DM", "adapter", "."], "add_tokens": "it \"should create an object through a belongs_to association\" do it \"should create an object through a belongs_to association with a class_name attribute\" do it \"should return a regular attribute in the hash\" do Post . blueprint { title \"Test\" } post = Post . plan post [ :title ] . should == \"Test\" end", "del_tokens": "it \"should create an object through belongs_to association\" do it \"should create an object through belongs_to association with a class_name attribute\" do", "commit_type": "add"}
{"commit_tokens": ["changed", "verbosity", "level", "of", "logging"], "add_tokens": "@client . log ( :very_verbose ) { \"ApiOperator: API Response: #{api_response}\" } @client . log ( :very_verbose ) { \"ApiOperator: Response Headers: #{http_response.header.to_yaml}\" }", "del_tokens": "@client . log ( :verbose ) { \"ApiOperator: API Response: #{api_response}\" } @client . log ( :verbose ) { \"ApiOperator: Response Headers: #{http_response.header.to_yaml}\" }", "commit_type": "change"}
{"commit_tokens": ["Improve", "checking", "support", "of", "parsers"], "add_tokens": "module PutText module Parser class Slim < Base def initialize @ruby_parser = PutText :: Parser :: Ruby . new @slim_engine = Engine . new end def strings_from_source ( source , filename : '(string)' , first_line : 1 ) slim_ruby_code = @slim_engine . call ( source ) @ruby_parser . strings_from_source ( slim_ruby_code , filename : filename , first_line : first_line ) end # rubocop:disable Lint/HandleExceptions rescue LoadError # Optional dependency, do not fail if not found # rubocop:enable Lint/HandleExceptions", "del_tokens": "# rubocop:disable Lint/HandleExceptions rescue LoadError # Optional dependency, do not fail if not found end # rubocop:enable Lint/HandleExceptions module PutText module Parser class Slim < Base # Checks if this parser is supported. # @return [Boolean] false when the slim gem is not loaded, true otherwise. def self . supported? defined? :: Slim end def initialize @ruby_parser = PutText :: Parser :: Ruby . new @slim_engine = Engine . new end def strings_from_source ( source , filename : '(string)' , first_line : 1 ) slim_ruby_code = @slim_engine . call ( source ) @ruby_parser . strings_from_source ( slim_ruby_code , filename : filename , first_line : first_line ) end if defined? :: Slim", "commit_type": "improve"}
{"commit_tokens": ["Update", "concurrent", "-", "ruby", "version"], "add_tokens": "fallback_policy : :caller_runs", "del_tokens": "overflow_policy : :caller_runs", "commit_type": "update"}
{"commit_tokens": ["Made", "optional", "cache", "checking", "more", "aggressive"], "add_tokens": "@aggressive_cache_checking = config [ :aggressive_cache_checking ] || false check_cache if @aggressive_cache_checking check_cache if @aggressive_cache_checking", "del_tokens": "@check_cache_on_start = config [ :check_cache_on_start ] || false check_cache if @check_cache_on_start", "commit_type": "make"}
{"commit_tokens": ["add", "more", "fields", "supported", "in", "API"], "add_tokens": "FIELDS_ALL = [ \"alias\" , \"assigned_to\" , \"blocks\" , \"cc\" , \"classification\" , \"component\" , \" creation_time \", \" creator \", \" deadline \" , \"depends_on\" , \" dupe_of \", \" estimated_time \", \" groups \" , \"id\" , \" is_cc_accessible \", \" is_confirmed \", \" is_open \" , \"is_creator_accessible\" , \" keywords \", \" last_change_time \" , \"op_sys\" , \" platform \", \" priority \", \" product \", \" qa_contact \" , \"remaining_time\" , \" resolution \", \" see_also \", \" severity \" , \"status\" , \" summary \", \" target_milestone \", \" update_token \" , \"url\" , \" version \", \" whiteboard \" , \"external_bugs\" , \"internals\" ]", "del_tokens": "FIELDS_ALL = [ \"alias\" , \"assigned_to\" , \"component\" , \"creation_time\" , \"dupe_of\" , \"external_bugs\" , \" groups \", \" id \" , \"internals\" , \"is_open\" , \"last_change_time\" , \" priority \", \" product \" , \"resolution\" , \" severity \", \" status \" , \"summary\" ]", "commit_type": "add"}
{"commit_tokens": ["fix", "makefile", "and", "require", "order"], "add_tokens": "require 'mixlib/log/formatter'", "del_tokens": "require 'mixlib/log/formatter'", "commit_type": "fix"}
{"commit_tokens": ["Remove", "dependency", "on", "Capistrano", "update", "TODO"], "add_tokens": "VERSION = \"0.5.4\"", "del_tokens": "VERSION = \"0.5.3\"", "commit_type": "remove"}
{"commit_tokens": ["Add", "new", "version", "number", "."], "add_tokens": "VERSION = \"1.3.42\"", "del_tokens": "VERSION = \"1.3.41\"", "commit_type": "add"}
{"commit_tokens": ["changed", "coding", "style", "of", "raising", "exceptions"], "add_tokens": "i or raise Exception :: InvalidPropertyValue , v . to_s raise Exception :: InvalidPropertyValue , v if ! [ \"formatted\" , \"free\" ] . include? ( v ) raise Exception :: DuplicateBufferName , name . to_s", "del_tokens": "i or raise Exception :: InvalidPropertyValue . new ( v . to_s ) raise Exception :: InvalidPropertyValue . new ( v ) if ! [ \"formatted\" , \"free\" ] . include? ( v ) raise Exception :: DuplicateBufferName ( name . to_s )", "commit_type": "change"}
{"commit_tokens": ["Added", "active_support", "for", "blank?", "method"], "add_tokens": "raise ArgumentError , \"file and content can not be empty\" if file . blank? || content . blank?", "del_tokens": "raise ArgumentError , \"file and content can not be empty\" if file . strip . empty? || file . strip . nil? || content . strip . empty? || content . strip . nil?", "commit_type": "add"}
{"commit_tokens": ["allow", "for", "active", "record", "mutations", "in", "entered", "/", "exited", "callbacks"], "add_tokens": "transition = pending_transition _run_after_callbacks ( * transition ) transitions = self . uncommitted_transitions . dup transitions . each { | t | run_commit_callbacks ( * t ) }", "del_tokens": "_run_after_callbacks ( * pending_transition ) self . uncommitted_transitions . each { | t | run_commit_callbacks ( * t ) }", "commit_type": "allow"}
{"commit_tokens": ["added", "Flex", "::", "Utils", ".", "load_tasks"], "add_tokens": "def load_tasks load File . expand_path ( '../../tasks/index.rake' , __FILE__ ) end private", "del_tokens": "private", "commit_type": "add"}
{"commit_tokens": ["fixed", "class", "/", "module", "discrep"], "add_tokens": "module EISCP", "del_tokens": "class EISCP", "commit_type": "fix"}
{"commit_tokens": ["Using", "colorize", "for", "printing", "warnings", "within", "the", "simulator", "console"], "add_tokens": "puts \" Warning #{message.gsub(\"\\n\", \"\\n \")}\" . yellow", "del_tokens": "puts \" Warning #{message.gsub(\"\\n\", \"\\n \")}\"", "commit_type": "use"}
{"commit_tokens": ["Added", "options", "to", "selenium", "session", "methods", "to", "better", "handle", "ajax", "operations", ".", "For", "example", ":", "clicks_link", "(", "Foo", ":", "wait", "=", ">", ":", "ajax", ")", ".", "I", "d", "love", "to", "figure", "out"], "add_tokens": "def clicks_button ( button_text = nil , options = { } ) button_text , options = nil , button_text if button_text . is_a? ( Hash ) && options == { } wait_for_result ( options [ :wait ] ) def clicks_link ( link_text , options = { } ) @selenium . click ( \"webratlink=#{link_text}\" ) wait_for_result ( options [ :wait ] ) def wait_for_result ( wait_type ) if wait_type == :ajax wait_for_ajax elsif wait_type == :effects wait_for_effects else wait_for_page_to_load end end def wait_for_page_to_load ( timeout = 15000 ) @selenium . wait_for_page_to_load ( timeout ) end def wait_for_ajax ( timeout = 15000 ) @selenium . wait_for_condition \"window.Ajax.activeRequestCount == 0\" , timeout end def wait_for_effects ( timeout = 15000 ) @selenium . wait_for_condition \"window.Effect.Queue.size() == 0\" , timeout end def wait_for_ajax_and_effects wait_for_ajax wait_for_effects end", "del_tokens": "def clicks_button ( button_text = nil ) @selenium . wait_for_page_to_load ( ) def clicks_link ( link_text ) @selenium . click ( \"webratlink=#{Regexp.escape(link_text)}\" ) @selenium . wait_for_page_to_load ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "sample", "example", "for", "arr_spec"], "add_tokens": "let ( :file_content ) do File . read ( file_path ) . gsub ( / CreationDate.* / , \"\" ) end let ( :fixture_content ) do File . read ( fixture_path ) . gsub ( / CreationDate.* / , \"\" ) end", "del_tokens": "let ( :file_content ) { File . read ( file_path ) } let ( :fixture_content ) { File . read ( fixture_path ) }", "commit_type": "add"}
{"commit_tokens": ["Adding", "validation", "support", "via", "the", "Jay", "Fields", "Validatable", "gem"], "add_tokens": "gem \"activesupport\" , \"2.3.4\" gem \"mongodb-mongo\" , \"0.14.1\" gem \"validatable\" , \"1.7.4\" require \"mongoid/paginator\" require \"validatable\"", "del_tokens": "gem \"activesupport\" gem \"mongodb-mongo\" , \"0.14\"", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "S3", "::", "Object#", "==", "method", "more", "robust", "so", "comparing", "an", "instance", "of", "S3", "::", "Object", "to", "nil", "(", "s3obj", "==", "nil", ")", "doesn", "t", "throw", "a", "NoMethodError", "anymore", "."], "add_tokens": "other . equal? ( self ) || ( other . instance_of? ( self . class ) && self . key == other . key && self . bucket == other . bucket )", "del_tokens": "self . key == other . key and self . bucket == other . bucket", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "use", "new", "codes", "."], "add_tokens": "@marker = options . fetch ( :marker ) { Symbols :: ITEM_SELECTED } selected = @marker + Symbols :: SPACE + choice . name Symbols :: SPACE * 2 + choice . name", "del_tokens": "@marker = options . fetch ( :marker ) { Codes :: ITEM_SELECTED } selected = @marker + Codes :: SPACE + choice . name Codes :: SPACE * 2 + choice . name", "commit_type": "change"}
{"commit_tokens": ["added", "support", "for", "the", "getFile", "operation"], "add_tokens": "# Retrieve a single file or directory def file ( device_id , service_id , file_id ) params = { valtoken : @token , deviceid : device_id , serviceid : service_id , fileid : file_id } response = self . class . get ( '/getFile' , query : params ) File . from_json ( response . parsed_response [ 'file' ] ) end send_file ( device_id , service . id , file_handle , io ) def send_file ( device_id , service_id , file_handle , io ) uri = URI . parse ( \"#{files_url}/#{@token}/#{device_id}/#{service_id}/#{parent}/#{file_handle.name}\" )", "del_tokens": "send_file ( device_id , service , file_handle , io ) def send_file ( device_id , service , file_handle , io ) uri = URI . parse ( \"#{service.api_url}files/#{@token}/#{device_id}/#{service.id}/#{parent}/#{file_handle.name}\" )", "commit_type": "add"}
{"commit_tokens": ["move", "monitor", "&", "state_monitor", "statements", "to", "Monitor", "module", "."], "add_tokens": "attr_reader :manifest", "del_tokens": "attr_reader :state_monitor , :monitors @manifest . load_path . each { | path | $LOAD_PATH . unshift path } @manifest . monitors . values . each { | mon | mon . start } if @manifest . state_monitor @state_monitor = @manifest . state_monitor . new end", "commit_type": "move"}
{"commit_tokens": ["changed", "super", "class", "to", "AppCont", "(", "how", "did", "AC", "::", "Base", "get", "in", "there?", ";", "-", ")"], "add_tokens": "class WidgetsController < ApplicationController", "del_tokens": "class WidgetsController < ActionController :: Base", "commit_type": "change"}
{"commit_tokens": ["add", "another", "migration", "to", "cocoadocs", "adding", "in", "the", "lines", "of", "code", "to", "the", "clocs", "table"], "add_tokens": "version : 2", "del_tokens": "version : 1", "commit_type": "add"}
{"commit_tokens": ["Fix", "capture", "funds", "js", "issue"], "add_tokens": "render :json => response", "del_tokens": "render :json => resp", "commit_type": "fix"}
{"commit_tokens": ["Changing", "the", "name", "format", "of", "the", "table", "names", "."], "add_tokens": "# The name style of the dimension database tables. TABLE_NAME_FORMAT = \"dimension_%s\" # The name style of the key mapping database tables. KEY_TABLE_NAME_FORMAT = \"keys_dimension_%s\" # Return the staging area table name that provides mappings between # original ids and dimension ids. # # This will only be created if an :original_id column is defined # on the dimension. attr_reader :key_table_name @table_name = sprintf ( TABLE_NAME_FORMAT , name ) . to_sym @key_table_name = sprintf ( KEY_TABLE_NAME_FORMAT , name ) . to_sym", "del_tokens": "@table_name = \"#{name}_dimension\" . to_sym def key_table_name \"#{table_name}_keys\" . to_sym end", "commit_type": "change"}
{"commit_tokens": ["Fix", "latest", "backup", "date", "/", "time", "."], "add_tokens": "require 'date' backup = @client . backups . index ( :lineage => @volname , :filter => [ \"latest_before==#{Time.now.utc.strftime('%Y/%m/%d %H:%M:%S %z')}\" , \"committed==true\" , \"completed==true\" ] )", "del_tokens": "backup = @client . backups . index ( :lineage => @volname , :filter => [ \"latest_before==2011/08/05 00:00:00 +0000\" , \"committed==true\" , \"completed==true\" ] )", "commit_type": "fix"}
{"commit_tokens": ["use", "load", "instead", "or", "require", "to", "allow", "reloading"], "add_tokens": "load :: File . expand_path ( File . join ( \"..\" , \"environment.rb\" ) , __FILE__ ) load :: File . expand_path ( File . join ( \"..\" , \"routes.rb\" ) , __FILE__ )", "del_tokens": "require :: File . expand_path ( File . join ( \"..\" , \"environment.rb\" ) , __FILE__ ) require :: File . expand_path ( File . join ( \"..\" , \"routes.rb\" ) , __FILE__ )", "commit_type": "use"}
{"commit_tokens": ["fix", "class", "load", "for", "worker"], "add_tokens": "if other . is_a? ( Spark :: Mllib :: MatrixBase )", "del_tokens": "if other . is_a? ( MatrixBase )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "debug", "code", "m", "("], "add_tokens": "notify_notification_update ( @notification , summary , body , icon_path )", "del_tokens": "p notify_notification_update ( @notification , summary , body , icon_path )", "commit_type": "remove"}
{"commit_tokens": ["add", "simple", "rails", "engine", "for", "configuration", "within", "rails"], "add_tokens": "require 'validation_rage/rails' if defined? ( Rails )", "del_tokens": "require 'rails'", "commit_type": "add"}
{"commit_tokens": ["Added", "301", "code", "to", "permanent", "redirects"], "add_tokens": "page = Page . page_with_uri ( request . host_with_port , File . dirname ( uri ) , false ) if page . nil? || ! page new_url = PermanentRedirect . match ( site_id , request . fullpath ) if new_url redirect_to new_url , :status => 301", "del_tokens": "page = Page . page_with_uri ( request . host_with_port , File . dirname ( uri ) , false ) if ( page . nil? || ! page ) new_url = PermanentRedirect . match ( site_id , request . fullpath ) if new_url Caboose . log ( \"Found a redirect: #{new_url}\" ) redirect_to new_url", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "control", "the", "order", "of", "output"], "add_tokens": "# To control the order of output, add a key of :@inorder with # the value being an array listing the other keys in order. # # # { :find_user => { :name => 'Lucy', :id => 666, :@inorder => [:id,:name] } }.to_soap_xml # => \"<findUser><id>666</id><name>Lucy</name></findUser>\" i = self . delete :@inorder # retrieve the hash element keyed by :@inorder if it exists k = self . keys i = k unless ( i and i . class == Array ) raise \"missing elements in :@inorder #{(k - i).inspect}\" unless ( k - i ) . empty? raise \"spurious elements in :@inorder #{(i - k).inspect}\" unless ( i - k ) . empty? i . each { | key | nested_data_to_soap_xml key , self [ key ] } i = value . delete :@inorder k = value . keys i = k unless ( i and i . class == Array ) raise \"missing elements in :@inorder #{(k - i).inspect}\" unless ( k - i ) . empty? raise \"spurious elements in :@inorder #{(i - k).inspect}\" unless ( i - k ) . empty? i . each { | subkey | nested_data_to_soap_xml subkey , value [ subkey ] }", "del_tokens": "each { | key , value | nested_data_to_soap_xml key , value } value . each { | subkey , subvalue | nested_data_to_soap_xml subkey , subvalue }", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "like", "/", "unlike"], "add_tokens": "require 'groupme/likes' include GroupMe :: Likes def post ( path , data = { } ) if res . status == 200 and ! res . body . nil?", "del_tokens": "def post ( path , data ) if res . status == 200", "commit_type": "add"}
{"commit_tokens": ["create", "mongo", "and", "moped", "adaptors"], "add_tokens": "require 'mongodb_logger/adapters'", "del_tokens": "require 'mongodb_logger/adapters/mongo' require 'mongodb_logger/adapters/moped'", "commit_type": "create"}
{"commit_tokens": ["Fixing", "some", "wrong", "code", "on", "simple", ".", "rb", "to", "give", "access", "colaborator", "Daniel", "Madruga", "."], "add_tokens": ":username => 'USER-HERE' , :password => 'PASSWORD-HERE' , :host => 'HOST_DOMAIN_HERE' , :auth_type => 'TYPE_OF_AUTHENTICATION' puts client . discover_chassis", "del_tokens": ":username => 'admin' , :password => 'pass' , :host => 'http://127.0.0.1:3000' @includeAttributes = %w( accessState activationKeys ) @excludeAttributes = %w( accessState activationKeys ) @uuidArray = client . discover_chassis . map { | node | node . uuid } puts @uuidArray [ 0 ] response = client . fetch_chassis ( @uuidArray , @includeAttributes , nil ) puts response [ 0 ] not_nil = response [ 0 ] . send ( @includeAttributes [ 0 ] ) puts not_nil # puts client.fetch_chassis(@uuidArray, nil, @excludeAttributes) # puts client.discover_nodes[0]", "commit_type": "fix"}
{"commit_tokens": ["Use", "new", "Code", "Climate", "test", "reporter"], "add_tokens": "if ENV . fetch ( 'COVERAGE' , false ) require 'simplecov' SimpleCov . start end", "del_tokens": "require 'codeclimate-test-reporter' CodeClimate :: TestReporter . start", "commit_type": "use"}
{"commit_tokens": ["added", "db", "method", "to", "DSL", "so", "bots", "can", "access", "database"], "add_tokens": "opts . separator \"Specific options:\" end # specify a bot-specific blacklist of users. accepts an array, or a else else end end def db bot . db end", "del_tokens": "opts . separator \"Specific options:\" end # specify a bot-specific blacklist of users. accepts an array, or a else else end end", "commit_type": "add"}
{"commit_tokens": ["Add", "shortcuts", "to", "device", "devicetype", "and", "runtime"], "add_tokens": "Executor . execute ( [ COMMAND , \"'#{name}'\" , device_type . identifier , runtime . identifier ] ) do | identifier |", "del_tokens": "Executor . execute ( [ COMMAND , name , device_type . identifier , runtime . identifier ] ) do | identifier |", "commit_type": "add"}
{"commit_tokens": ["add", "row_filter_spec", "to", "primarilly", "test", "a", "boolean", "filter", "for", "rows", ".", "Determined", "the", "regex", "for", "such", "filter"], "add_tokens": "STDERR . puts \"object = #{object}\" STDERR . puts \"pattern = #{pattern}\" # Match a logical row filter # Example: 1,2,3,4-5:c1=10&&c2<20||c3>4&&c4=word||c5=2014-3-2&&c6=/\\d{3,4}/ # (\\d+(?:,\\d+|-\\d)*):(c\\d+[<=>](?:\\d{4}-\\d{1,2}-\\d{1,2}|\\d+|\\w+|\\/.*?\\/)(?:(?:&&|\\|\\||$)c\\d+[<=>](?:\\d{4}-\\d{1,2}-\\d{1,2}|\\d+|\\w+|\\/.*?\\/))*) # This will match # 1. 1,2,3,4-5 # 2. c1=10&&c2<20||c3>4&&c4=word||c5=2014-3-2&&c6=/\\d{3,4}/", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "specs", "they", "assumed", "an", "internal", "structure", "for", "the", "queue", "that", "had", "changed", "."], "add_tokens": "mixpanel . queue . each do | type , event_hash |", "del_tokens": "mixpanel . queue . each do | event_hash |", "commit_type": "fix"}
{"commit_tokens": ["Use", "Stream#need_resume?", "instead", "of", "ivar", "deferred"], "add_tokens": "send_data send_data def send_data if @stream . pending_send_data . need_resume? @session . resume_data ( @stream . stream_id ) end @session . run_once end", "del_tokens": "@deferred = false resume_if_need resume_if_need @session . run_once @deferred = true unless last def resume_if_need if ! @stream . end_write? && @deferred @session . resume_data ( @stream . stream_id ) end end", "commit_type": "use"}
{"commit_tokens": ["Add", "Conversation", "API", "supporting", ".", "Added", "following", "methods", ":", "Send", ";", "Start", ";", "Get", "(", "List", "&", "By", "ID", ")"], "add_tokens": "CLIENT_VERSION = '1.4.2' ENDPOINT = 'https://rest.messagebird.com/' CONVERSATIONS_ENDPOINT = 'https://conversations.messagebird.com/v1/'", "del_tokens": "CLIENT_VERSION = '1.4.1' ENDPOINT = 'https://rest.messagebird.com'", "commit_type": "add"}
{"commit_tokens": ["Added", "basic", "documentation", "for", "methods", "classes"], "add_tokens": "# Downloads and save status and vatsim data files @@status_url = \"http://status.vatsim.net/status.txt\" # URL to retrieve vatsim status file # Default status file path # Default vatsim data file path # Initialize the system by downloading status and vatsim data files # Download a url to a file path # Return random vatsim data url from status file", "del_tokens": "@@status_url = \"http://status.vatsim.net/status.txt\"", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "compatible", "with", "rails"], "add_tokens": "def self . from ( yml_file ) nbayes = YAML . load_file ( yml_file ) # Load class instance if yml . nil? return NBayes :: Base . new elsif yml [ 0 .. 2 ] == \"---\" nbayes = YAML . load ( yml ) else nbayes = YAML . load_file ( yml_file ) end nbayes . reset_after_import ( ) # yaml does not properly set the defaults on the Hashes nbayes # Dumps class instance to a data file (e.g., yaml) or a string def dump ( arg ) if arg . instance_of? String File . open ( arg , \"w\" ) { | f | YAML . dump ( self , f ) } YAML . dump ( arg )", "del_tokens": "def self . from ( yml ) if yml . nil? return nbayes elsif File . exists? ( yml ) nbayes = YAML . load_file ( yml ) else # Assume that we were given a yaml string nbayes = YAML . load ( yml ) end # Alias for from for the sake of rails self . from ( yml ) # Dumps class instance def dump ( yml_file = nil ) if yml_file . nil? YAML . dump ( self ) File . open ( yml_file , \"w\" ) { | f | YAML . dump ( self , f ) } def inspect ( params = { } ) super ( params ) end", "commit_type": "make"}
{"commit_tokens": ["Added", "more", "char", "group", "tests"], "add_tokens": "init_ranges", "del_tokens": "init_ranges", "commit_type": "add"}
{"commit_tokens": ["Allow", "postambles", "to", "depend", "on", "internal", "state", "of", "engine"], "add_tokens": "add_postamble ( postamble ) # Add the given postamble to the src. Can be overridden in subclasses # to make additional changes to src that depend on the current state. def add_postamble ( postamble ) src << postamble end", "del_tokens": "src << postamble", "commit_type": "allow"}
{"commit_tokens": ["use", "fake", "test", "only", "when", "teardown_once", "exists"], "add_tokens": "if suite . respond_to? ( :final_teardowns ) && suite . final_teardowns . any? final = suite . new ( 'object_id' ) # run fake test final . run self suite . final_teardowns . each do | teardown | begin teardown . run ( final ) rescue puts \"#{$!.class} on #{suite} teardown: #{$!}\" $! . backtrace { | b | puts \">> #{b}\" } end end", "del_tokens": "final = suite . new ( 'object_id' ) final . run self suite . final_teardowns . each do | teardown | begin teardown . run ( final ) rescue puts \"#{$!.class} on #{suite} teardown: #{$!}\" $! . backtrace { | b | puts \">> #{b}\" } end if suite . respond_to? ( :final_teardowns )", "commit_type": "use"}
{"commit_tokens": ["Add", "note", "about", "debugging", "pattern", "extracting"], "add_tokens": "matcher . failure_reason ( other ) . get_or_else { 'It matches' }", "del_tokens": "matcher . failure_reason ( other )", "commit_type": "add"}
{"commit_tokens": ["fix", "gateway", "method", "lambda", "function", "uri", "property"], "add_tokens": "Uri : \"!Sub arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${#{map.lambda_function_logical_id}.Arn}/invocations\"", "del_tokens": "Uri : \"!Sub arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${#{map.logical_id}.Arn}/invocations\"", "commit_type": "fix"}
{"commit_tokens": ["remove", "automatic", "table", "virtual", "linking"], "add_tokens": "raise \"unknown field: #{key}\"", "del_tokens": "require 'doh/mysql/virtual' @cached_virtuals = { } @cached_virtuals = @cached_virtuals . dup retval = get_virtual_field ( key ) raise \"unknown field: #{key}\" unless retval retval def get_virtual_field ( name ) cached = @cached_virtuals [ name ] return cached if cached if idvalue = get ( name + '_id' ) @cached_virtuals [ name ] = DohDb :: LinkedRow . build ( name , idvalue . to_i ) else nil end end", "commit_type": "remove"}
{"commit_tokens": ["fixed", "exception", "when", "server", "returns", "204", "no", "content"], "add_tokens": "super ( response . body . to_s )", "del_tokens": "super ( response . body )", "commit_type": "fix"}
{"commit_tokens": ["Move", "training", "out", "of", "#run", "and", "into", "a", "method"], "add_tokens": "train ( classifier_instance , training_samples ) def train ( classifier_instance , samples ) samples . each do | doc | training . call ( classifier_instance , doc ) end end", "del_tokens": "# train it training_samples . each { | doc | training . call ( classifier_instance , doc ) }", "commit_type": "move"}
{"commit_tokens": ["Make", "tests", "run", "for", "specific", "background", "job"], "add_tokens": "if defined? Sidekiq describe APN :: Jobs :: SidekiqNotificationJob do it { should be_a ( Sidekiq :: Worker ) } it \"has the right queue name\" do expect ( subject . class . instance_variable_get ( :@queue ) ) . to eq ( APN :: Jobs :: QUEUE_NAME ) end if defined? Resque describe APN :: Jobs :: ResqueNotificationJob do it \"has the right queue name\" do expect ( subject . class . instance_variable_get ( :@queue ) ) . to eq ( APN :: Jobs :: QUEUE_NAME ) end", "del_tokens": "describe APN :: Jobs :: SidekiqNotificationJob do it { should be_a ( Sidekiq :: Worker ) } it \"has the right queue name\" do expect ( subject . class . instance_variable_get ( :@queue ) ) . to eq ( APN :: Jobs :: QUEUE_NAME ) describe APN :: Jobs :: ResqueNotificationJob do it \"has the right queue name\" do expect ( subject . class . instance_variable_get ( :@queue ) ) . to eq ( APN :: Jobs :: QUEUE_NAME )", "commit_type": "make"}
{"commit_tokens": ["Allow", "nodes", "to", "have", "policies", "assigned"], "add_tokens": "attribute :name , type : String , primary : true , required : true attribute :automatic , type : Hash , default : { } attribute :default , type : Hash , default : { } attribute :normal , type : Hash , default : { } attribute :override , type : Hash , default : { } attribute :run_list , type : Array , default : [ ] attribute :policy_name , type : String attribute :policy_group , type : String", "del_tokens": "attribute :name , type : String , primary : true , required : true attribute :automatic , type : Hash , default : { } attribute :default , type : Hash , default : { } attribute :normal , type : Hash , default : { } attribute :override , type : Hash , default : { } attribute :run_list , type : Array , default : [ ]", "commit_type": "allow"}
{"commit_tokens": ["Change", "to", "ensure", "that", "directory", "content", "is", "only", "copied"], "add_tokens": ":: File . join ( File . dirname ( __FILE__ ) , \"..\" ) path = :: File . join ( gem_root , * args ) :: FileUtils . mkdir_p ( path ) unless :: File . exist? ( path ) :: File . realpath ( path ) :: File . join ( dir_path ( 'spec' , 'fixtures' ) , filename . to_s ) :: File . join ( dir_path ( 'tmp' ) , filename . to_s ) FileUtils . cp_r ( fixtures_path ( '/.' ) , tmp_path )", "del_tokens": "File . join ( File . dirname ( __FILE__ ) , \"..\" ) path = File . join ( gem_root , * args ) FileUtils . mkdir_p ( path ) unless :: File . exist? ( path ) File . realpath ( path ) File . join ( dir_path ( 'spec/fixtures' ) , filename . to_s ) File . join ( dir_path , 'tmp' , filename . to_s ) FileUtils . cp_r ( fixtures_path , tmp_path )", "commit_type": "change"}
{"commit_tokens": ["Add", "flag", "to", "enable", "readme", "detection"], "add_tokens": "def initialize ( detect_packages : false , detect_readme : false ) @detect_readme = detect_readme end def detect_readme? @detect_readme @matched_file ||= ( license_file || readme || package_file ) def readme return unless detect_readme? return @readme if defined? @readme @readme = begin content , name = find_file { | name | Readme . name_score ( name ) } if content && name Readme . new ( content , name ) end end end def initialize ( repo , revision : nil , ** args ) super ( ** args ) def initialize ( path , ** args ) super ( ** args )", "del_tokens": "def initialize ( detect_packages ) @matched_file ||= ( license_file || package_file ) def initialize ( repo , revision : nil , detect_packages : false ) super ( detect_packages ) def initialize ( path , detect_packages : false ) super ( detect_packages )", "commit_type": "add"}
{"commit_tokens": ["removed", "some", "unnecessary", "spec", "warnings"], "add_tokens": "RAILS_ENV = \"test\" unless defined? RAILS_ENV", "del_tokens": "RAILS_ENV = \"test\"", "commit_type": "remove"}
{"commit_tokens": ["Use", "HTTPMultiParty", "rather", "than", "messing", "with", "Net", "::", "HTTP", "::", "Post", "::", "Multipart"], "add_tokens": "require 'httmultiparty'", "del_tokens": "require 'net/http/post/multipart'", "commit_type": "use"}
{"commit_tokens": ["Implement", "controller", "/", "action", "usage", "for", "parameter", "-", "less", "has_permission?", "filters"], "add_tokens": "klass = self . class . name . underscore . sub ( \"_controller\" , \"\" ) action = \"#{klass}##{action_name}\"", "del_tokens": "# TODO: If not supplied an action, determine the controller name and # action being invoked, and use that to generate an appropriate action # name to check.", "commit_type": "implement"}
{"commit_tokens": ["Added", "another", "spec", "test", ".", "Fixed", "a", "problem", "with", "the", "Dummy", "class", "being"], "add_tokens": "class Dummy2 < ActiveRecord :: Base a . inject ( 0 , :+ ) \" b = Dummy2.call_me_maybe(1, 2, 3, 4)\" ,", "del_tokens": "class Dummy < ActiveRecord :: Base res = a . inject ( 0 , :+ ) puts 'r-' * 80 , res res \" b = Dummy.call_me_maybe(1, 2, 3, 4)\" ,", "commit_type": "add"}
{"commit_tokens": ["remove", "default", "network", "param", "Transaction"], "add_tokens": "def self . data ( data , network : )", "del_tokens": "def self . data ( data , network : :bitcoin )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "a", "deep", "copy", "#clone", "method", "to", "DependencyGraph"], "add_tokens": "# DependencyGraphs contain Packages, which in turn contain # PackageVersions. Packages are created at access-time through # #package # TODO [cw,2010/11/23]: this is a simple but inefficient impl. Do # it for realz. def clone Marshal . load ( Marshal . dump ( self ) ) end", "del_tokens": "# DependencyGraphs contain Packages, which in turn contain # PackageVersions", "commit_type": "add"}
{"commit_tokens": ["Fixing", "coercion", "of", "channels", "into", "users", "or", "group", "chats"], "add_tokens": "# Custom attribute class to handle chat attribute in Telegrammer::DataTypes::Message class Channel < Virtus :: Attribute # Transforms a channel into a User object or GroupChat object", "del_tokens": "class Channel < Telegrammer :: DataTypes :: Base attribute :id , Integer", "commit_type": "fix"}
{"commit_tokens": ["moved", ".", "make_csv_file", "&", ".", "buy_link", "(", "id", ")", "to", "Persistable", "module"], "add_tokens": "CLI . start", "del_tokens": "# CLI.start", "commit_type": "move"}
{"commit_tokens": ["fixing", "a", "search", "-", "and", "-", "replace", "editor", "error"], "add_tokens": "def four_info_ #{attribute} send self . class . #{attribute}_column def four_info_ #{attribute}=(value) send self . class . #{attribute}_column.to_s+'=', value end self . four_info_sms_confirmation_code = response . confirmation_code self . four_info_sms_confirmation_attempted = Time . now self . four_info_sms_confirmed_phone_number = four_info_sms_phone_number self . four_info_sms_blocked = 'false'", "del_tokens": "def four_info_ #{attribute}(value = nil) value ? send ( self . class . #{attribute}_column.to_s+'=', value) : send ( self . class . #{attribute}_column) alias_method :four_info_ #{attribute}=, :four_info_#{attribute} self . four_info_sms_confirmation_code response . confirmation_code self . four_info_sms_confirmation_attempted Time . now four_info_sms_confirmed_phone_number four_info_sms_phone_number four_info_sms_blocked 'false'", "commit_type": "fix"}
{"commit_tokens": ["added", ":", "map_default", "attribute", "to", "delegates", "as", "a", "hook", "to", "prevent", "mapping", "default", "values", "on", "DelegateHash#bind"], "add_tokens": "# map the value; if no value is set in the source then use the # delegate default. if map_default is false, then simply skip... # this ensures each config is initialized to a value when bound # UNLESS map_default is set (indicating manual initialization) value = case when source . has_key? ( key ) then source . delete ( key ) when delegate [ :map_default , true ] then delegate . default else next end", "del_tokens": "value = source . has_key? ( key ) ? source . delete ( key ) : delegate . default", "commit_type": "add"}
{"commit_tokens": ["add", "runtimes", "/", "detection", "attributes", "to", "v1", "Framework"], "add_tokens": "runtimes = meta [ :runtimes ] . collect do | r | Runtime . new ( r [ :name ] , r [ :description ] ) end frameworks << Framework . new ( name . to_s , nil , runtimes , meta [ :detection ] )", "del_tokens": "frameworks << Framework . new ( name . to_s )", "commit_type": "add"}
{"commit_tokens": ["Add", "reference", "when", "input_format", "mentions", "subscribed", "class"], "add_tokens": "# Used for specifying dependencies in input_format # only for the planning phase: action that caused this action # to be triggered. In other words, this action was subscribed to # a class of the trigger. # If trigger present, the implicit plan # method uses the input of the trigger. Otherwise, the attr_accessor :trigger if trigger plan_self ( trigger . input ) add_trigger_reference if trigger @run_step . input = self . input # If triggered with subscription, check if the trigger output is # not reference in input_format. If so, make the reference in the input. def add_trigger_reference trigger_dependencies = self . class . input_format . params . find_all do | description | descriptor = description . descriptor descriptor . is_a? ( Dependency ) && descriptor . action_class == trigger . class end . map { | description | [ description . name , description . descriptor ] } trigger_dependencies . each do | name , dependency | self . input [ name . to_s ] = case dependency . field when :input then trigger . input when :output then trigger . output else raise ArgumentError , \"Unknown dependency field: #{dependency.field}\" end end end self . class . output_format . validate! ( output )", "del_tokens": "# only for the planning phase: flag indicating that the action # was triggered from subscription. If so, the implicit plan # method uses the input of the parent action. Otherwise, the attr_accessor :from_subscription if from_subscription plan_self ( self . input ) @run_step . input = input self . clss . output_format . validate! ( output )", "commit_type": "add"}
{"commit_tokens": ["update", "docs", "to", "describe", "how", "to", "create", "tables", "for", "entry", "implementations"], "add_tokens": "# Implementation of an indexing queue backed by Datamapper. # To create the table, you can use +dm-migrations+ and run +auto_migrate!+ on this class.", "del_tokens": "# Implementation of an indexing queue backed by ActiveRecord. # To create the table, you should have a migration containing the following: # # self.up # Sunspot::IndexQueue::Entry::ActiveRecordImpl.create_table # end # # self.down # drop_table Sunspot::IndexQueue::Entry::ActiveRecordImpl.table_name # end", "commit_type": "update"}
{"commit_tokens": ["add", "unit", "tests", "for", "forceMjsonwp"], "add_tokens": "FORCE_MJSONWP = :forceMjsonwp next if name == FORCE_MJSONWP force_mjsonwp = desired_capabilities [ FORCE_MJSONWP ]", "del_tokens": "next if name == :forceMjsonwp force_mjsonwp = desired_capabilities [ :forceMjsonwp ]", "commit_type": "add"}
{"commit_tokens": ["moved", "chain", "css", "()", ".", "css", "()", "to", "single", "with", "css", "selector", ";", "updated", "up", "readme"], "add_tokens": "# Client for retrieving player and club information from squashmatrix.com. # Returns newly created Client # Returns club info. # Returns player info. SquashOnly : squash_only , RacquetballOnly : racquetball_only }", "del_tokens": "# Client for http interactions with squashmatrix.com website. # Returns newly created Client for making club and player requests # Returns club information. # Returns player information. SquashOnly : false , RacquetballOnly : false }", "commit_type": "move"}
{"commit_tokens": ["make", "sure", "the", "same", "errors", "object", "is", "used", "with", "::", "validate", "validators", "."], "add_tokens": "all_errors = @result . instance_variable_get ( :@results ) all_errors += [ @amv_errors ] if @amv_errors . any? @result = Reform :: Contract :: Result . new ( all_errors ) class ResultErrors < :: Reform :: Contract :: Result :: Errors # to expose via #errors. i hate it.", "del_tokens": "# raise # puts \"errors\" @result = Reform :: Contract :: Result . new ( @result . instance_variable_get ( :@results ) + [ @amv_errors ] ) class ResultErrors < :: Reform :: Contract :: Result :: Errors", "commit_type": "make"}
{"commit_tokens": ["Allow", "report", "to", "codeclimate", "from", "tests", "."], "add_tokens": "require \"codeclimate-test-reporter\" CodeClimate :: TestReporter . start WebMock . disable_net_connect! ( :allow => \"codeclimate.com\" )", "del_tokens": "require 'codeclimate-test-reporter' CodeClimate :: TestReporter . start", "commit_type": "allow"}
{"commit_tokens": ["moved", "TinyMCE", "files", "to", "lib", "/", "tiny_mce", "/", "assets"], "add_tokens": "orig = File . join ( File . dirname ( __FILE__ ) , 'tiny_mce' , 'assets' , 'tiny_mce' )", "del_tokens": "orig = File . join ( File . dirname ( __FILE__ ) , '..' , 'public' , 'javascripts' , 'tiny_mce' )", "commit_type": "move"}
{"commit_tokens": ["Remove", "raw", "attributes", "from", "executable", "bundle", "now", "that", "it", "s", "part", "of", "the", "recipes", "inputs", "."], "add_tokens": "user_attribs = JSON . load ( recipe . json ) rescue { } if recipe . json && ! recipe . json . empty?", "del_tokens": "@attributes = bundle . attributes user_attribs = JSON . load ( @attributes ) rescue { } recipe_attribs = JSON . load ( recipe . json ) rescue { } if recipe . json && ! recipe . json . empty? user_attribs . merge! ( recipe_attribs ) if recipe_attribs", "commit_type": "remove"}
{"commit_tokens": ["Add", "an", "all_occurrences", "method", "to", "return", "all", "possible", "occurrences", "of", "a", "schedule"], "add_tokens": "# Return all possible occurrences # In order to make this call, all rules in the schedule must have # either an until date or an occurrence count def all_occurrences find_occurrences { | head | head . all_occurrences } end # Find all occurrences until a certain date find_occurrences { | head | head . upto ( end_date ) } private # Find all occurrences (following rules and exceptions) from the schedule's start date to end_date. # Use custom methods to say when to end def find_occurrences exclude_dates , include_dates = Set . new ( @exdates ) , SortedSet . new ( @rdates ) # walk through each rule, adding it to dates @rrule_occurrence_heads . each do | rrule_occurrence_head | include_dates . merge ( yield ( rrule_occurrence_head ) ) end # walk through each exrule, removing it from dates @exrule_occurrence_heads . each do | exrule_occurrence_head | exclude_dates . merge ( yield ( exrule_occurrence_head ) ) end #return a unique list of dates include_dates . reject! { | date | exclude_dates . include? ( date ) } include_dates . to_a end", "del_tokens": "# Find all occurrences (following rules and exceptions) from the schedule's start date to end_date. exclude_dates , include_dates = Set . new ( @exdates ) , SortedSet . new ( @rdates ) # walk through each rule, adding it to dates @rrule_occurrence_heads . each do | rrule_occurrence_head | include_dates . merge ( rrule_occurrence_head . upto ( end_date ) ) end # walk through each exrule, removing it from dates @exrule_occurrence_heads . each do | exrule_occurrence_head | exclude_dates . merge ( exrule_occurrence_head . upto ( end_date ) ) end #return a unique list of dates include_dates . reject! { | date | exclude_dates . include? ( date ) } include_dates . to_a", "commit_type": "add"}
{"commit_tokens": ["Removes", "useless", "updates", "and", "adds", "logs"], "add_tokens": "idmap . update_attributes ( connec_id : connec_entity [ 'id' ] , last_push_to_connec : Time . now , message : nil ) Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'error' , \"Error while pushing to Connec!: #{e}\" ) idmap . update_attributes ( external_id : external_id , last_push_to_external : Time . now , message : nil ) Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'error' , \"Error while pushing to #{@@external_name}: #{e}\" )", "del_tokens": "idmap . update_attributes ( connec_id : connec_entity [ 'id' ] , connec_entity : connec_entity_name . downcase , last_push_to_connec : Time . now , message : nil ) idmap . update_attributes ( external_id : external_id , external_entity : external_entity_name . downcase , last_push_to_external : Time . now , message : nil )", "commit_type": "remove"}
{"commit_tokens": ["added", "Triangle", ".", "distance_to_line", "method"], "add_tokens": "def to_s \"Line[point#{@base_point.to_element_s}, vector#{@direction.to_element_s}\" end", "del_tokens": "def to_s \"Line[point#{@base_point.to_element_s}, vector#{@direction.to_element_s}\" end", "commit_type": "add"}
{"commit_tokens": ["Fixed", "ENV_TIER", "constant", ".", "Added", "cascading", "config", "specs", "."], "add_tokens": "# Defaults to Rails.env (or RAILS_ENV) if running in Rails, otherwise, # it checks ENV for 'RACK_ENV', or 'CONFIG_ENV'. If neither is present, it # assumes production. In apps that are not Rails or Rack-based, CONFIG_ENV # can be set to provide RConfig with a environment other than prodution. ENV_TIER = ( ( defined? ( Rails ) && Rails . env ) || ( defined? ( RAILS_ENV ) && RAILS_ENV ) || ENV [ 'RAILS_ENV' ] || ENV [ 'RACK_ENV' ] || ENV [ 'CONFIG_ENV' ] || 'production' ) unless defined? ENV_TIER end", "del_tokens": "# Defaults to RAILS_ENV if running in Rails, otherwise, it checks # if ENV['TIER'] is present. If not, it assumes production. ENV_TIER = ( defined? ( RAILS_ENV ) ? RAILS_ENV : ( ENV [ 'TIER' ] || 'production' ) ) unless defined? ENV_TIER end", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "stub", "(", "with", "times", "called", "expectation", ")", "ordering", "."], "add_tokens": "it \"allows ordering\" do obj = @obj Object . new . instance_eval do stub ( obj ) . to_s { \"value 1\" } . once . ordered end Object . new . instance_eval do stub ( obj ) . to_s { \"value 2\" } . once . ordered end @obj . to_s . should == \"value 1\" @obj . to_s . should == \"value 2\" end", "del_tokens": "it \"allows ordering\" #do # obj = @obj # Object.new.instance_eval do # stub(obj).to_s {\"value 1\"}.ordered # end # # Object.new.instance_eval do # stub(obj).to_s {\"value 2\"}.ordered # end # # @obj.to_s.should == \"value 1\" # @obj.to_s.should == \"value 2\" # end", "commit_type": "implement"}
{"commit_tokens": ["Remove", "pipe", "to", "less", "in", "comment", "so", "as", "not", "to", "confuse", "people", "unfamiliar", "with", "less", "."], "add_tokens": "# ruby -e \"require 'trick_bag'; TrickBag::GemDependencyScript.write_script_for('trick_bag', 'test2')\" && . ./test2", "del_tokens": "# ruby -e \"require 'trick_bag'; TrickBag::GemDependencyScript.write_script_for('trick_bag', 'test2')\" && . ./test2 | less", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "the", "date", "conversion", "middleware"], "add_tokens": "[ body ] . flatten . compact . each do | hash |", "del_tokens": "[ body ] . flatten . each do | hash |", "commit_type": "fix"}
{"commit_tokens": ["Removed", "tests", "until", "rest_api", ".", "rb", "is", "refactored", "."], "add_tokens": "= begin # TODO: Create new rest_call method rather than # overriding api, since it doesn't allow # the REST API module to be included into the # same object as the Graph API module = end \"get\" , hash_including ( :rest_api => true )", "del_tokens": "\"get\"", "commit_type": "remove"}
{"commit_tokens": ["Added", "functions", "to", "open", "and", "close", "certstore"], "add_tokens": "extend Chef :: ReservedNames :: Win32 :: API extend FFI :: Library ffi_lib 'Crypt32' HCERTSTORE = FFI :: TypeDefs [ :pointer ] HCRYPTPROV_LEGACY = FFI :: TypeDefs [ :pointer ] # Ref: https://msdn.microsoft.com/en-us/library/windows/desktop/aa376560(v=vs.85).aspx safe_attach_function :CertOpenSystemStoreW , [ HCRYPTPROV_LEGACY , :LPCTSTR ] , HCERTSTORE # Ref: https://msdn.microsoft.com/en-us/library/windows/desktop/aa376026(v=vs.85).aspx CERT_CLOSE_STORE_CHECK_FLAG = 0 CERT_CLOSE_STORE_FORCE_FLAG = 1 safe_attach_function :CertCloseStore , [ HCERTSTORE , :DWORD ] , :BOOL", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "data", "structures", "immutable"], "add_tokens": "attr_reader :number , # Provider fields :provider_name , :provider_ic , :provider_dic , # Provider address fields :provider_street , :provider_street_number , :provider_postcode , :provider_city , :provider_city_part , :provider_extra_address_line , # Purchaser fields :purchaser_name , :purchaser_ic , :purchaser_dic , # Purchaser address fields :purchaser_street , :purchaser_street_number , :purchaser_postcode , :purchaser_city , :purchaser_city_part , :purchaser_extra_address_line , :issue_date , :due_date , # Account details :subtotal , :tax , :tax2 , :tax3 , :total , :bank_account_number , :account_iban , :account_swift , # Collection of InvoicePrinter::Invoice::Items :items", "del_tokens": "attr_accessor :number , # Provider fields :provider_name , :provider_ic , :provider_dic , # Provider address fields :provider_street , :provider_street_number , :provider_postcode , :provider_city , :provider_city_part , :provider_extra_address_line , # Purchaser fields :purchaser_name , :purchaser_ic , :purchaser_dic , # Purchaser address fields :purchaser_street , :purchaser_street_number , :purchaser_postcode , :purchaser_city , :purchaser_city_part , :purchaser_extra_address_line , :issue_date , :due_date , # Account details :subtotal , :tax , :tax2 , :tax3 , :total , :bank_account_number , :account_iban , :account_swift , # Collection of InvoicePrinter::Invoice::Items :items", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "deletion", "and", "rate", "limit", "objects", "in", "the", "stream", "."], "add_tokens": "Yajl :: Parser . parse ( File . open ( File . dirname ( __FILE__ ) + '/data/statuses.json' , 'r' ) , :symbolize_keys => true ) do | hash |", "del_tokens": "Yajl :: Parser . parse ( File . open ( File . dirname ( __FILE__ ) + '/data/statuses.json' , 'r' ) ) do | hash |", "commit_type": "add"}
{"commit_tokens": ["add", "PUSH", "DUP", "SWAP", "LOG", "opcodes"], "add_tokens": "PREFIX_LOG = 'LOG' . freeze PREFIX_PUSH = 'PUSH' . freeze PREFIX_DUP = 'DUP' . freeze PREFIX_SWAP = 'SWAP' . freeze TABLE [ 0x60 + i ] = [ \"#{PREFIX_PUSH}#{i+1}\" , 0 , 1 , 3 ] TABLE [ 0X80 + i ] = [ \"#{PREFIX_DUP}#{i+1}\" , i + 1 , i + 2 , 3 ] TABLE [ 0x90 + i ] = [ \"#{PREFIX_SWAP}#{i+1}\" , i + 2 , i + 2 , 3 ]", "del_tokens": "TABLE [ 0x60 + i ] = [ \"PUSH#{i+1}\" , 0 , 1 , 3 ] TABLE [ 0X80 + i ] = [ \"DUP#{i+1}\" , i + 1 , i + 2 , 3 ] TABLE [ 0x90 + i ] = [ \"SWAP#{i+1}\" , i + 2 , i + 2 , 3 ]", "commit_type": "add"}
{"commit_tokens": ["allow", "mounting", "assets", "under", "a", "non", "root", "path"], "add_tokens": "\"#{request.env['SCRIPT_NAME']}/assets/#{Assets.instance.find_asset(source).digest_path}\" unless Assets . instance . find_asset ( source ) . nil?", "del_tokens": "\"/assets/#{Assets.instance.find_asset(source).digest_path}\" unless Assets . instance . find_asset ( source ) . nil?", "commit_type": "allow"}
{"commit_tokens": ["Change", "customer_id", "-", ">", "customer"], "add_tokens": "InvoiceItem . create ( params . merge ( :customer => id ) , @api_key ) Invoice . all ( { :customer => id } , @api_key ) InvoiceItem . all ( { :customer => id } , @api_key ) Charge . all ( { :customer => id } , @api_key )", "del_tokens": "InvoiceItem . create ( params . merge ( :customer_id => id ) , @api_key ) Invoice . all ( { :customer_id => id } , @api_key ) InvoiceItem . all ( { :customer_id => id } , @api_key ) Charge . all ( { :customer_id => id } , @api_key )", "commit_type": "change"}
{"commit_tokens": ["updated", "rails", "manifest", "with", "new", "style"], "add_tokens": "#the user to run non-privedged tasks as. #if this user doesn't exist, one will be created for you. user \"rails\"", "del_tokens": "#API Example", "commit_type": "update"}
{"commit_tokens": ["Add", "tests", "for", "version_at", "instance", "method", "(", "and", "fix", "logic", ")", "."], "add_tokens": "def version_at ( timestamp ) return self if self . updated_at <= timestamp :conditions => [ 'created_at > ?' , timestamp ] , :order => 'created_at ASC' )", "del_tokens": "def version_at timestamp return self if self . updated_at < timestamp :conditions => [ 'created_at < ?' , timestamp ] , :order => 'created_at DESC' )", "commit_type": "add"}
{"commit_tokens": ["Moving", "the", "batch", "to", "its", "own", "file", "and", "out", "of", "thread", "pool", "."], "add_tokens": "describe Threadz :: Batch do", "del_tokens": "describe Threadz :: ThreadPool :: Batch do", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "that", "a", "default", "of", "false", "for", "boolean", "flags", "is", "correct", "."], "add_tokens": "if column . last [ :ruby_default ] . nil? default = column . last [ :default ] default =~ / ^\"identity / ? nil : default else default = column . last [ :ruby_default ] end", "del_tokens": "default = column . last [ :ruby_default ] || column . last [ :default ] default =~ / ^\"identity / ? nil : default", "commit_type": "make"}
{"commit_tokens": ["add", "a", "PublicAPI", "spec", "file", "add", "on_conflict", "option", "to", "Borrower", "::", "put"], "add_tokens": "# @param [String] destination path to write contents to # @param [Symbol] on_conflict what to do if the destination exists def put content , destination , on_conflict = :overwrite Borrower :: Content . put content , destination", "del_tokens": "# @param [String] to path to write contents to def put content , to Borrower :: Content . put content , to", "commit_type": "add"}
{"commit_tokens": ["Added", "kaminari", "for", "pagination", "in", "admin", "panel", ".", "Edited", "kaminari", "views", "to", "use", "bootstrap", "style", "."], "add_tokens": "@products = Product . page ( params [ :page ] )", "del_tokens": "@products = Product . all", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "basic", "tests", "and", "fixed", "some", "(", "quite", "serious", ")", "bugs", "."], "add_tokens": "# Creates a token, signing it if specified in the header. def self . encode_token ( header , payload , private_key = nil )", "del_tokens": "# Creates a signed token. def self . signed_token ( header , payload , private_key = nil )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "defaults", ".", "page", ".", "filter", "config", "setting", "for", "setting", "a", "default", "page", "filter", "."], "add_tokens": "page . parts << PagePart . new ( :name => name , :filter_id => config [ 'defaults.page.filter' ] )", "del_tokens": "page . parts << PagePart . new ( :name => name )", "commit_type": "add"}
{"commit_tokens": ["Change", "login", "to", "work", "with", "systems", "that", "have", "the", "same", "endpoint", "for", "web", "and", "api"], "add_tokens": "VERSION = \"0.2.29\"", "del_tokens": "VERSION = \"0.2.28\"", "commit_type": "change"}
{"commit_tokens": ["make", "a", "file", "task", "out", "of", "the", "latest", "file"], "add_tokens": "file manifest_file => ( file latest_file )", "del_tokens": "file manifest_file => latest_file", "commit_type": "make"}
{"commit_tokens": ["added", "mysql2", "first", "migration", "works", "in", "test"], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20121026000720 ) do t . string \"s3_path\" t . string \"cron\"", "del_tokens": "ActiveRecord :: Schema . define ( :version => 20121025191622 ) do t . string \"frequency\" , :default => \"sync\" t . string \"run_at\" , :default => \"-\"", "commit_type": "add"}
{"commit_tokens": ["implement", "and", "use", "file", "exists", "for", "asset", "path", "and", "do", "no", "magic", "if", "not", "exists"], "add_tokens": "@haml . generate project_folder , project_output_folder", "del_tokens": "@haml . generate project_folder , project_output_folder", "commit_type": "implement"}
{"commit_tokens": ["added", "the", "ability", "to", "add", "a", "css", "class", "to", "a", "menu", "level"], "add_tokens": "attr_accessor :renderer , :dom_id , :dom_class", "del_tokens": "attr_accessor :renderer , :dom_id", "commit_type": "add"}
{"commit_tokens": ["add", "error", "handler", "and", "retry", "handlers"], "add_tokens": "retries = 0 retries += 1 response = [ ] response . push c . strip if retries < Lacquer . configuration . retries retry else if Lacquer . configuration . command_error_handler Lacquer . configuration . command_error_handler . call ( { :error_class => \" Varnish Error , retried #{Lacquer.configuration.retries} times\", :error_message => \" Error while trying to connect to #{server[:host]}:#{server[:port]}: #{e}\", :parameters => server , :response => response . join ( \"\\n\" ) } ) else raise VarnishError . new ( \"Error while trying to connect to #{server[:host]}:#{server[:port]} #{e}\" ) end end ensure connection . close rescue nil", "del_tokens": "raise VarnishError . new ( \"Error while trying to connect to #{server[:host]}:#{server[:port]} #{e}\" )", "commit_type": "add"}
{"commit_tokens": ["updated", "changelog", ";", "bumped", "version"], "add_tokens": "VERSION = \"0.5.0\"", "del_tokens": "VERSION = \"0.4.1\"", "commit_type": "update"}
{"commit_tokens": ["Allow", "defining", "factories", "for", "projected", "schemas"], "add_tokens": "Struct . define ( relation . name , relation . schema . project ( * attrs . keys ) ) . new ( attrs )", "del_tokens": "Struct . define ( relation . name , relation . schema ) . new ( attrs )", "commit_type": "allow"}
{"commit_tokens": ["Add", "the", "bitfield_index", "method", "in", "EnumeratedValue"], "add_tokens": "VERSION = '0.1.3'", "del_tokens": "VERSION = '0.1.2'", "commit_type": "add"}
{"commit_tokens": ["Use", "Token", "as", "its", "own", "data", "structure"], "add_tokens": "attr_reader :tag , :value , :lineno , :attrs def initialize ( tag , value , lineno : , attrs : { } ) @value = value return 0 if [ value , lineno , attrs ] == [ other . value , other . lineno , other . attrs ] \"#{tag.inspect} '#{value}'\" green ( \"Token(#{tag.inspect} #{value.inspect} on #{lineno})\" ) @tokens . push Token . new ( tag , value , lineno : @lineno , attrs : attrs ) end #end Line", "del_tokens": "attr_reader :tag , :lineno , :attrs def initialize ( tag , lineno : , attrs : { } ) return 0 if [ tag , lineno , attrs ] == [ other . tag , other . lineno , other . attrs ] \"'#{tag}'\" green ( \"Token(#{tag.inspect} on #{lineno})\" ) @tokens . push [ tag , Token . new ( value , lineno : @lineno , attrs : attrs ) ] end #end Parser", "commit_type": "use"}
{"commit_tokens": ["Use", "an", "explicit", "block", "for", "yielding", "stuff", "back", "to", "#start", "s", "caller"], "add_tokens": "def start & blk # EM.add_periodic_timer(15) do # do_search(@search_target, response_wait_time, ttl, @search_count) # end blk . call ( @device_queue )", "del_tokens": "def start EM . add_periodic_timer ( 15 ) do do_search ( @search_target , response_wait_time , ttl , @search_count ) end yield @device_queue if block_given?", "commit_type": "use"}
{"commit_tokens": ["Added", "specs", "for", "the", "table_builder"], "add_tokens": "class User attr_accessor :first_name , :last_name def initialize ( attributes = { } ) @first_name = attributes [ :first_name ] @last_name = attributes [ :last_name ] end", "del_tokens": "class User < Struct . new ( :first_name , :last_name )", "commit_type": "add"}
{"commit_tokens": ["Add", "user", "keys", "api", "update", "members", "methods", "."], "add_tokens": "_normalize_params_keys ( params ) _normalize_params_keys ( params ) def delete_member ( org_name , member_name , params = { } ) _normalize_params_keys ( params ) _normalize_params_keys ( params ) _normalize_params_keys ( params ) _normalize_params_keys ( params ) _normalize_params_keys ( params )", "del_tokens": "def delete_member ( org_name , member_name )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.2.1\"", "del_tokens": "VERSION = \"0.2.0\"", "commit_type": "change"}
{"commit_tokens": ["Fix", "response", "code", "bug", ":", "move", "status", "element", "into", "the", "propstat", "element", "where", "it", "belongs", "(", "not", "inside", "the", "response", "element", ")"], "add_tokens": "attr_accessor :url , :props def initialize ( url , props ) @url , @props = url , props end def url @url += '/' if self . collection? and @url [ - 1 ] != '/' @url end response_for options [ :href ] do | dav | status_for options [ :status ] def status_for ( status ) code = Rack :: Utils . status_code ( status || :ok ) status = \"HTTP/1.1 #{code} #{Rack::Utils::HTTP_STATUS_CODES[code]}\" @dav . status status end :getcontenttype => hash [ :format ] . to_s response_for ( resource . url ) do | dav | status_for hash [ :status ] def response_for ( href )", "del_tokens": "ResourceDescriptor = Struct . new ( :url , :props ) response_for options [ :href ] , options [ :status ] do | dav | :getcontenttype => hash [ :format ] . to_s , :executable => 0 response_for ( resource . url , hash [ :status ] || :ok ) do | dav | def response_for ( href , status ) code = Rack :: Utils . status_code ( status ) status = \"HTTP/1.1 #{code} #{Rack::Utils::HTTP_STATUS_CODES[code]}\" @dav . status status", "commit_type": "fix"}
{"commit_tokens": ["Added", "duration", "attribute", "to", "WavIn"], "add_tokens": "@playing = true def duration @loaded ? @wav . size / @block_align : 0 end", "del_tokens": "@playing = false", "commit_type": "add"}
{"commit_tokens": ["moved", "Yajl", "::", "[", "Gzip", "Bzip2", "]", "StreamReader", "classes", "into", "their", "own", "modules", "/", "namespaces", "Yajl", "::", "[", "Gzip", "Bzip2", "]", "::", "StreamReader", "for", "better", "organization", "given", "my", "future", "plans"], "add_tokens": "require 'yajl.bundle' require 'yajl/http_stream.rb' unless defined? ( Yajl :: HttpStream ) require 'yajl/gzip/stream_reader.rb' unless defined? ( Yajl :: Gzip :: StreamReader ) require 'yajl/bzip2/stream_reader.rb' unless defined? ( Yajl :: Bzip2 :: StreamReader ) VERSION = \"0.4.3\"", "del_tokens": "require 'yajl.bundle' require 'yajl/http_stream.rb' unless defined? ( Yajl :: HttpStream ) VERSION = \"0.3.4\" # === Yajl::GzipStreamReader # # This is a wrapper around Zlib::GzipReader to allow it's #read method to adhere # to the IO spec, allowing for two parameters (length, and buffer) class GzipStreamReader < :: Zlib :: GzipReader def read ( len = nil , buffer = nil ) buffer . gsub! ( / .* / , '' ) unless buffer . nil? buffer << super ( len ) and return unless buffer . nil? super ( len ) end end # only if bzip2-ruby is installed if defined? ( Bzip2 ) # === Yajl::Bzip2StreamReader # # This is a wrapper around Bzip::Reader to allow it's #read method to adhere # to the IO spec, allowing for two parameters (length, and buffer) class Bzip2StreamReader < :: Bzip2 :: Reader def read ( len = nil , buffer = nil ) buffer . gsub! ( / .* / , '' ) unless buffer . nil? buffer << super ( len ) and return unless buffer . nil? super ( len ) end end end", "commit_type": "move"}
{"commit_tokens": ["Make", "futures", "signal", "safe", "."], "add_tokens": "# The wait can return even if nothing called @conditional.signal, # so we need to check to see if the condition actually changed. # See https://github.com/chadrem/workers/issues/7 loop do @condition . wait ( @lock ) break if @state == :finished end", "del_tokens": "@condition . wait ( @lock )", "commit_type": "make"}
{"commit_tokens": ["Added", "new", "methods", "for", "requiring", "libraries", "and", "gems"], "add_tokens": "require_gem_or_exit \"erubis\"", "del_tokens": "require \"erubis\"", "commit_type": "add"}
{"commit_tokens": ["added", "some", "scd", "debugging", ".", "May", "be", "too", "verbose"], "add_tokens": "ETL :: Engine . logger . debug \"looking for original record\" ETL :: Engine . logger . debug \"Result: #{result.inspect}\" scd_fields ( row ) . any? { | csd_field | ETL :: Engine . logger . debug \"Row: #{row.inspect}\" ETL :: Engine . logger . debug \"Existing Row: #{@existing_row.inspect}\" ETL :: Engine . logger . debug \"comparing: #{row[csd_field].to_s} != #{@existing_row[csd_field].to_s}\" x = row [ csd_field ] . to_s != @existing_row [ csd_field ] . to_s ETL :: Engine . logger . debug x x } Dir [ File . dirname ( __FILE__ ) + \"/destination/*.rb\" ] . each { | file | require ( file ) }", "del_tokens": "#puts \"looking for original record\" #puts \"Result: #{result.inspect}\" scd_fields ( row ) . any? { | csd_field | row [ csd_field ] . to_s != @existing_row [ csd_field ] . to_s } Dir [ File . dirname ( __FILE__ ) + \"/destination/*.rb\" ] . each { | file | require ( file ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "in", "-", "tag", "liquid", "parsing", "in", "loops"], "add_tokens": "render_markup = Liquid :: Template . parse ( @markup ) . render ( context ) . gsub ( / \\\\ \\{ \\\\ \\{ | \\\\ \\{ \\\\ % / , '\\{\\{' => '{{' , '\\{\\%' => '{%' ) markup = / ^(?:(?<preset>[^ \\s .: \\/ ]+) \\s +)?(?<image_src>[^ \\s ]+ \\. [a-zA-Z0-9]{3,4}) \\s *(?<source_src>(?:(source_[^ \\s .: \\/ ]+: \\s +[^ \\s ]+ \\. [a-zA-Z0-9]{3,4}) \\s *)+)?(?<html_attr>[ \\s \\S ]+)?$ / . match ( render_markup )", "del_tokens": "@markup = Liquid :: Template . parse ( @markup ) . render ( context ) . gsub ( / \\\\ \\{ \\\\ \\{ | \\\\ \\{ \\\\ % / , '\\{\\{' => '{{' , '\\{\\%' => '{%' ) markup = / ^(?:(?<preset>[^ \\s .: \\/ ]+) \\s +)?(?<image_src>[^ \\s ]+ \\. [a-zA-Z0-9]{3,4}) \\s *(?<source_src>(?:(source_[^ \\s .: \\/ ]+: \\s +[^ \\s ]+ \\. [a-zA-Z0-9]{3,4}) \\s *)+)?(?<html_attr>[ \\s \\S ]+)?$ / . match ( @markup )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "phantom", "css", "classes", "were", "set", "in", "Composite", "if", "a", "position", "-", "matrix", "was", "of", "size", ">", "2"], "add_tokens": "nkey = key [ 0 , 2 ] nmatrix = resolve_offset ( nkey , offset ) if ( style = css [ key ] ) elsif ( style = css [ nkey ] ) @grid . add_style ( style + suffix , * nmatrix ) if ( cstyle = ccss [ key ] ) elsif ( cstyle = ccss [ nkey ] ) @grid . add_component_style ( cstyle + suffix , * nmatrix )", "del_tokens": "nkey = key [ 0 , 2 ] if ( style = css [ key ] || css [ nkey ] ) if ( cstyle = ccss [ key ] || ccss [ nkey ] )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "an", "Action", "View", "deprecation", "in", "Rails", "6"], "add_tokens": "def self . call ( template , source = nil ) # The interface of template handlers changed in Rails 6.0 and the # source is passed as an argument. This check is here for compatibility # with Rails 5.0+. source ||= template . source source . gsub! ( / ^[^ \\S \\n ]+ / , '' . freeze ) if Maildown . allow_indentation", "del_tokens": "def self . call ( template ) template . source . gsub! ( / ^[^ \\S \\n ]+ / , '' . freeze ) if Maildown . allow_indentation", "commit_type": "remove"}
{"commit_tokens": ["fix", "broken", "CouchRest", ".", "database!", "method"], "add_tokens": "create_db ( name ) rescue nil", "del_tokens": "create_db ( path ) rescue nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "sorbet", "complaint", "about", "untyped", "Hash", "."], "add_tokens": "extra_draw_opts : T :: Hash [ T . untyped , T . untyped ] ,", "del_tokens": "extra_draw_opts : Hash ,", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "way", "object", "masks", "are", "handled", "in", "the", "system", ".", "You", "now", "must", "pass", "root", "object", "mask", "strings", "to", "object_mask", "or", "the", "code", "will", "raise", "an", "error"], "add_tokens": "# Use this as part of a method call chain to add an object mask to # the request. The arguments to object mask should be well formed # Extended Object Mask strings: # # ticket_service.object_mask( # \"mask[createDate, modifyDate]\", # \"mask(SoftLayer_Some_Type).aProperty\").getObject # # The object_mask becomes part of the request sent to the server raise ArgumentError , \"object_mask expects well-formatted root object mask strings\" if args . empty? || ( 1 == args . count && ! args [ 0 ] ) raise ArgumentError , \"object_mask expects well-formatted root object mask strings\" if args . find { | arg | ! ( arg . kind_of? ( String ) ) } raise ArgumentError , \"object_mask expects well-formatted root object mask strings\" if args . find { | arg | ! ( arg . sl_root_property_set? ) && ! ( arg . sl_root_property? ) } object_mask = args . inject ( @parameters [ :object_mask ] || [ ] ) do | collected_items , argument | match_data = argument . match ( / \\A \\[ (.*) \\] \\z /m ) if match_data collected_items = collected_items + match_data [ 1 ] . split ( ',' ) . collect { | mask_element | mask_element . strip } else collected_items . push ( argument ) end collected_items end merged_object . parameters = @parameters . merge ( { :object_mask => object_mask } )", "del_tokens": "# Adds an objectMask to a call so that the amount of information returned will be # limited. For example, if you wanted to get the ids of all the open tickets # for an accoun you might use: # account_service.object_mask(id).getOpenTickets raise ArgumentError , \"Object mask expects mask properties\" if args . empty? || ( 1 == args . count && ! args [ 0 ] ) merged_object . parameters = @parameters . merge ( { :object_mask => args } )", "commit_type": "change"}
{"commit_tokens": ["Add", "explicit", "requires", "for", "Vim", "processors"], "add_tokens": "VERSION = \"0.1.1\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "add"}
{"commit_tokens": ["Adding", "railtie", "to", "load", "helper"], "add_tokens": "require \"octicons_helper/railtie\" if defined? ( Rails )", "del_tokens": "require \"active_support\" ActiveSupport . on_load ( :action_view ) do include OcticonsHelper end", "commit_type": "add"}
{"commit_tokens": ["fix", "broken", "options", "list", "in", "docs"], "add_tokens": "# * <tt>:log_to_stdout</tt> - whether LogBuddy should _also_ log to STDOUT, very helpful for Autotest (default is +true+).", "del_tokens": "# * <tt):log_to_stdout</tt> - whether LogBuddy should _also_ log to STDOUT, very helpful for Autotest (default is +true+).", "commit_type": "fix"}
{"commit_tokens": ["Allows", "to", "render", "without", "page_presenter", ".", "block"], "add_tokens": "events = instance_exec ( context , & page_presenter . block ) unless page_presenter . block . blank?", "del_tokens": "events = instance_exec ( context , & page_presenter . block )", "commit_type": "allow"}
{"commit_tokens": ["Add", "counter", "/", "increment", "logic", "and", "simplify", "options"], "add_tokens": "sidekiq_options throttle : { threshold : 10 , period : 1 . minute , key : Proc . new { | * args | args . join ( '_' ) } }", "del_tokens": "sidekiq_options throttle : { threshold : 10 , period : 1 . minute , key : Proc . new { | * args | args . join ( ':' ) } }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "different", "Nokogiri", "objects"], "add_tokens": "root = case xml when Nokogiri :: XML :: Document xml . root when Nokogiri :: XML :: Element xml when String Nokogiri :: XML ( xml ) . root else fail \"Unexpected argument type: #{xml.class}\" end parse_class = get_parse_class ( root ) def self . get_parse_class ( root ) root_name = root . name", "del_tokens": "doc = Nokogiri :: XML ( xml ) parse_class = get_parse_class ( doc ) def self . get_parse_class ( doc ) root_name = doc . root . name", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "column", "option", "to", "configure", "the", "flags", "column"], "add_tokens": "options = { :named_scopes => true , :column => 'flags' } . update ( options ) @flag_column = options [ :column ] check_flag_column def flag_column @flag_column end def check_flag_column unless columns . any? { | column | column . name == flag_column && column . type == :integer } raise \"Table '#{table_name}' must have an integer column named '#{flag_column}' in order to use FlagShihTzu\" end end \"(#{table_name}.#{flag_column} & #{flag_mapping[flag]} = #{enabled ? '1': '0'})\" self [ self . class . flag_column ] || 0 def flags = ( value ) self [ self . class . flag_column ] = value end", "del_tokens": "unless base . columns . any? { | column | column . name == 'flags' && column . type == :integer } raise \"#{base} must have an integer column named 'flags' in order to use FlagShihTzu\" end options = { :named_scopes => true } . update ( options ) \"(#{table_name}.flags & #{flag_mapping[flag]} = #{enabled ? '1': '0'})\" self [ :flags ] || 0", "commit_type": "add"}
{"commit_tokens": ["Improved", "Salmon", "-", "related", "APIs", "and", "documentation"], "add_tokens": "it 'returns the original body' do expect ( subject . unpack ( envelope ) ) . to eql body end end describe '#verify' do let ( :envelope ) { subject . pack ( body , key ) } it 'returns true if the signature is correct' do expect ( subject . verify ( envelope , key ) ) . to be true it 'returns false if the signature cannot be verified' do expect ( subject . verify ( envelope , OpenSSL :: PKey :: RSA . new ( 2048 ) ) ) . to be false", "del_tokens": "it 'returns the original body if the signature is correct' do expect ( subject . unpack ( envelope , key ) ) . to eql body it 'raises an error if the signature cannot be verified' do expect { subject . unpack ( envelope , OpenSSL :: PKey :: RSA . new ( 2048 ) ) } . to raise_error OStatus :: BadSalmonError", "commit_type": "improve"}
{"commit_tokens": ["Adding", "locale", "to", "container", "list", "responses"], "add_tokens": "it \"should include the id, url and locale for each container\" do expect ( container ) . to have_key \"locale\"", "del_tokens": "it \"should include the id and url for each container\" do", "commit_type": "add"}
{"commit_tokens": ["fixed", "handles", "bug", "so", "that", "order", "Matters"], "add_tokens": "class GemLibrary < Library def self . is_a_gem? ( name ) Gem . searcher . find ( name ) . is_a? ( Gem :: Specification ) end handles { | name | is_a_gem? ( name . to_s ) } def initialize_library_module super if @library [ :module ] end def is_valid_library? ! @library [ :gems ] . empty? || ! @library [ :commands ] . empty? || @library . has_key? ( :module ) end def load_source detect_additions { Util . safe_require @name } end end", "del_tokens": "class GemLibrary < Library def self . is_a_gem? ( name ) Gem . searcher . find ( name ) . is_a? ( Gem :: Specification ) end handles { | name | is_a_gem? ( name . to_s ) } def initialize_library_module super if @library [ :module ] end def is_valid_library? ! @library [ :gems ] . empty? || ! @library [ :commands ] . empty? || @library . has_key? ( :module ) end def load_source detect_additions { Util . safe_require @name } end end", "commit_type": "fix"}
{"commit_tokens": ["Add", "basic_auth", "to", "the", "options", "for", "every", "request"], "add_tokens": "response = self . class . __send__ ( http_method , uri , options . merge ( basic_auth ) )", "del_tokens": "response = self . class . __send__ ( http_method , uri , options . merge! ( basic_auth ) )", "commit_type": "add"}
{"commit_tokens": ["Adds", "some", "more", "short", "descriptions", "."], "add_tokens": "self . description = 'A generic Conjur role.' self . example = %( ! role watchdog ! role ears owner : ! role watchdog ) self . description = 'A generic Conjur resource.' self . example = %( ! resource lib ) self . example = %( ! uidnumber : 1208 public : true can_predict_movement : false self . example = %( self . description = 'Creates a Host record and resource.' self . description = 'Creates a Layer record and resource.' self . description = ''", "del_tokens": "self . example = %Q( movement : unpredictable self . example = %Q(", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "rest", "of", "the", "specs"], "add_tokens": "validate_klass def validate_klass unless klass < Emittance :: Event raise IdentifierGenerationError , \"#{klass.name} is not a subclass of Emittance::Event!\" end end raise Emittance :: IdentifierCollisionError if identifier_reserved? identifier , klass def identifier_reserved? ( identifier , klass ) klass_already_exists_for_identifier? ( identifier , klass ) || ! ! identifier_to_klass_mappings [ identifier ] end def klass_already_exists_for_identifier? ( identifier , klass ) derived_klass_name = klass_name_for identifier Object . const_defined? ( derived_klass_name ) && klass . name != derived_klass_name", "del_tokens": "raise Emittance :: IdentifierCollisionError if identifier_to_klass_mapping_exists? identifier def identifier_to_klass_mapping_exists? ( identifier ) ! ! identifier_to_klass_mappings [ identifier ]", "commit_type": "fix"}
{"commit_tokens": ["add", "download", "instructions", "to", "store", "config", "and", "thank", "you", "page"], "add_tokens": "[ :custom_tax_function , :text ] , [ :download_instructions , :text ] ,", "del_tokens": "[ :custom_tax_function , :text ] ,", "commit_type": "add"}
{"commit_tokens": ["Change", "from", "BoundedSemaphore", "to", "Semaphore", "in", "Mutex", "implementation", "so", "it", "will", "work", "on", "Mac", "OS", "X", "(", "and", "other", "platforms", "with", "out", "sem_getvalue", "()", "."], "add_tokens": "require 'process_shared/semaphore' # This Mutex class is implemented as a Semaphore with a second # internal Semaphore used to track the locking process is tracked. # {ProcessError} is raised if either {#unlock} is called by a # of course (current implementation uses the additional {Semaphore} # and {SharedMemory} segment). # release its {Semaphore} and {SharedMemory} resources. For now, # rely on the object finalizers of those objects... @internal_sem = Semaphore . new @sem = Semaphore . new", "del_tokens": "require 'process_shared/bounded_semaphore' # This Mutex class is implemented as a BoundedSemaphore with a # maximum value of 1. Additionally, the locking process is tracked, # and {ProcessError} is raised if either {#unlock} is called by a # of course (current implementation uses an additional # {BoundedSemaphore} and {SharedMemory} segment). # release its {BoundedSemaphore} and {SharedMemory} resources. For # now, rely on the object finalizers of those objects... @internal_sem = BoundedSemaphore . new ( 1 ) @sem = BoundedSemaphore . new ( 1 )", "commit_type": "change"}
{"commit_tokens": ["Removing", "Minitest", "::", "Reporters", "."], "add_tokens": "puts 'Starting the cloud datastore emulator in test mode.' spawn \"cloud_datastore_emulator start --port=8181 --testing #{data_dir} > /dev/null 2>&1\" loop do begin Net :: HTTP . get ( 'localhost' , '/' , '8181' ) . include? 'Ok' break rescue Errno :: ECONNREFUSED sleep 0.2 end end Minitest . after_run do puts \"\\nShutting down the cloud datastore emulator.\" system 'kill -9 $(lsof -ti tcp:8181)' end", "del_tokens": "require 'minitest/reporters' Minitest :: Reporters . use! Minitest :: Reporters :: SpecReporter . new # Start the test Cloud Datastore Emulator in 'testing' mode (data is stored in memory only). system ( \"cloud_datastore_emulator start --port=8181 --testing #{data_dir} &\" ) sleep 3", "commit_type": "remove"}
{"commit_tokens": ["use", "multiple", "threads", "to", "speed", "up", "download", "/", "upload"], "add_tokens": "in_multiple_threads ( local_info ) do | path , md5 | in_multiple_threads ( remote_info ) do | path , md5 | def in_multiple_threads ( data , & block ) threads = [ @config [ :parallel ] || 10 , data . size ] . min data = data . to_a ( 1 .. threads ) . to_a . map do Thread . new do while chunk = data . pop yield chunk end end end . map ( & :join ) end opts . on ( \"-p\" , \"--parallel COUNT\" , Integer , \"Use COUNT threads for download/upload default: 10\" ) { | c | options [ :parallel ] = c }", "del_tokens": "local_info . each do | path , md5 | remote_info . each do | path , md5 |", "commit_type": "use"}
{"commit_tokens": ["added", "start", "of", "button", "handling"], "add_tokens": "watir_page_object . should respond_to :click_me_button end end context \"watir implementation\" do it \"should be able to click a button\" do watir_browser . should_receive ( :button ) . and_return ( watir_browser ) watir_browser . should_receive ( :click ) watir_page_object . click_me end it \"should retrieve a button element\" do watir_browser . should_receive ( :button ) . and_return ( watir_browser ) element = watir_page_object . click_me_button element . should be_instance_of PageObject :: Elements :: Button end end context \"selenium implementation\" do it \"should be able to click a button\" do selenium_browser . should_receive ( :find_element ) . and_return ( selenium_browser ) selenium_browser . should_receive ( :click ) selenium_page_object . click_me end it \"should retrieve a button element\" do selenium_browser . should_receive ( :find_element ) . and_return ( selenium_browser ) element = selenium_page_object . click_me_button element . should be_instance_of PageObject :: Elements :: Button", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["moved", "bootstrap", "to", "separate", "asset", "group"], "add_tokens": "] js :bootstrap , [ '/javascripts/bootstrap*.js'", "del_tokens": "'/javascripts/vendor/**/*.js'", "commit_type": "move"}
{"commit_tokens": ["Allow", "options", "as", "parameter", "for", "list_link_for", "helper", "."], "add_tokens": "def list_link_for ( action , resource_or_model = nil , options = { } ) path = polymorphic_path ( resource_or_model ) path = polymorphic_path ( resource_or_model ) options . merge! ( :confirm => t_confirm_delete ( resource ) , :method => :delete ) path = polymorphic_path ( resource_or_model , :action => action ) return list_link_to ( action , path , options )", "del_tokens": "def list_link_for ( action , resource_or_model = nil ) return list_link_to ( action , polymorphic_path ( resource_or_model ) ) return list_link_to ( action , polymorphic_path ( resource_or_model ) , :confirm => t_confirm_delete ( resource ) , :method => :delete ) return list_link_to ( action , polymorphic_path ( resource_or_model , :action => action ) )", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "icon", "position", "for", "chip", "icons", "."], "add_tokens": "context : context , * * attribs , & block ) @position = [ :left ] if position . empty?", "del_tokens": "context : context , * * attribs , & block ) attr_reader :position @position = attribs . delete ( :position ) { :left }", "commit_type": "fix"}
{"commit_tokens": ["adding", "poor", "man", "s", "update", "to", "clients"], "add_tokens": "include Paymill :: Operations :: Update include Paymill :: Operations :: Delete", "del_tokens": "include Paymill :: Operations :: Delete", "commit_type": "add"}
{"commit_tokens": ["Fix", "line", "-", "ending", "matching", "bug", "that", "was", "leaving", "markup", "characters", "in", "output"], "add_tokens": "%r+ #{ open } (.*?) #{ close } ( \\r | \\n |$)? +m %r+ #{ open } (.*?) #{ open } ?( \\r | \\n |$) +m", "del_tokens": "%r+ #{ open } (.*?) #{ close } ( \\n |$)? +m %r+ #{ open } (.*?) #{ open } ?( \\n |$) +m", "commit_type": "fix"}
{"commit_tokens": ["added", "image", "conversion", "and", "file", "type", "options", "in", "rich", "initializer"], "add_tokens": "mini : '60x60>' , thumb : '120x120>' , small : '240x240>' , medium : '480x480>' , large : '960x960>' , full : '1480x1480>' , huge : '1920x1920>' , config . convert_options = { all : %{ - unsharp 3 x1 + 0.5 - quality 85 - strip - auto - orient - colorspace sRGB } } config . default_style = :medium config . allowed_document_types = %w[ text / plain application / pdf application / msword application / vnd . openxmlformats - officedocument . wordprocessingml . document ]", "del_tokens": ":thumb => \"100x100#\" # # Example (this will make your image look terrible): # config.convert_options = { # :large => '-quality 1' # } config . default_style = :thumb config . allowed_document_types = [ 'application/pdf' ]", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "attr_reader", ":", "subscription_expires_at", "in", "CloudApp", "::", "Account"], "add_tokens": ":subscribed , :subscription_expires_at , :alpha , :created_at , :updated_at , :activated_at end", "del_tokens": ":subscribed , :alpha , :created_at , :updated_at , :activated_at end", "commit_type": "add"}
{"commit_tokens": ["added", "conference", "application", "fixed", "originate", "when", "you", "send", "an", "extension", "instead", "of", "application", "(", "target_opts", ")"], "add_tokens": "orig_command = \"originate {#{target_opts}}#{@target} #{@originator}\"", "del_tokens": "orig_command = \"originate {#{target_opts.join(',')}}#{@target} #{@originator}\"", "commit_type": "add"}
{"commit_tokens": ["use", "mixins", "instead", "of", "singleton", "methods", "=", ">", "no", "need", "for", "controlled", "marshaling"], "add_tokens": "module InterlacedMixIn def prev_scanline_byte x # When the image is interlaced, each pass of the interlace pattern is # treated as an independent image for filtering purposes image . adam7 . pass_start? ( @idx ) ? 0 : image . scanlines [ @idx - 1 ] . decoded_bytes . getbyte ( x ) end end module NotFirstLineMixIn def prev_scanline_byte x image . scanlines [ @idx - 1 ] . decoded_bytes . getbyte ( x ) end end module FirstLineMixIn def prev_scanline_byte x 0 end end # defining instance methods gives 10-15% speed boost extend InterlacedMixIn extend NotFirstLineMixIn extend FirstLineMixIn", "del_tokens": "# XXX: also add variables here when adding new instance variables def marshal_dump # defining marshal_dump & marshal_load b/c we override some methods with # singleton methods for performance reason and singletons can't be marshaled [ @image , @idx , @filter , @offset , @bpp , @BPP , @decoded_bytes ] end # XXX: also add variables here when adding new instance variables def marshal_load a @image , @idx , @filter , @offset , @bpp , @BPP , @decoded_bytes = a end # def prev_scanline_byte x # if image.interlaced? # # When the image is interlaced, each pass of the interlace pattern is # # treated as an independent image for filtering purposes # image.adam7.pass_start?(@idx) ? 0 : image.scanlines[@idx-1].decoded_bytes.getbyte(x) # elsif @idx > 0 # image.scanlines[@idx-1].decoded_bytes.getbyte(x) # else # 0 # end # end # defining instance methods gives ~10% speed boost def self . prev_scanline_byte x # When the image is interlaced, each pass of the interlace pattern is # treated as an independent image for filtering purposes image . adam7 . pass_start? ( @idx ) ? 0 : image . scanlines [ @idx - 1 ] . decoded_bytes . getbyte ( x ) end def self . prev_scanline_byte x image . scanlines [ @idx - 1 ] . decoded_bytes . getbyte ( x ) end def self . prev_scanline_byte x 0 end", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "with", "feed", "constructor", "not", "returning", "full", "article", "content"], "add_tokens": "# Some feeds use summary for the full article body, other feeds use content. # This prefers content, but falls back to summary. ! entry . content || entry . content . empty? ? entry . summary : entry . content", "del_tokens": "# Atom and RSS Feedjira::Feed objects have different names for the # article body. Returns entry.content if Atom and entry.summary if # RSS. entry . class . to_s . include? ( 'Atom' ) ? entry . content : entry . summary", "commit_type": "fix"}
{"commit_tokens": ["Move", "Aruba", "::", "Process", "into", "its", "own", "file"], "add_tokens": "require 'aruba/process' module Aruba", "del_tokens": "require 'background_process' module Aruba class Process attr_writer :stdout , :stderr def initialize ( cmd ) @cmd = cmd end def stdin @process . stdin end def output stdout + stderr end def stdout if @process @stdout ||= @process . stdout . read else '' end end def stderr if @process @stderr ||= @process . stderr . read else '' end end def run! ( & block ) @process = BackgroundProcess . run ( @cmd ) yield self if block_given? end def stop @process && @process . exitstatus end end", "commit_type": "move"}
{"commit_tokens": ["added", "readme", ".", "markdown", "and", "license"], "add_tokens": "base . helper_method :allowed_to? , :logged_in?", "del_tokens": "base . helper_method :allowed_to?", "commit_type": "add"}
{"commit_tokens": ["add", "NoteAttribute", "class", "and", "tests", "with", "usage"], "add_tokens": "class NoteAttribute < ActiveResource :: Base end class Order < ActiveResource :: Base", "del_tokens": "class Order < ActiveResource :: Base", "commit_type": "add"}
{"commit_tokens": ["Allow", "TCP", "sockets", "to", "work", "on", "Windows"], "add_tokens": "if Fcntl . constants . include? ( :F_SETFD ) && Fcntl . constants . include? ( :FD_CLOEXEC ) sock . fcntl ( Fcntl :: F_SETFD , Fcntl :: FD_CLOEXEC ) end end", "del_tokens": "sock . fcntl ( Fcntl :: F_SETFD , Fcntl :: FD_CLOEXEC ) end", "commit_type": "allow"}
{"commit_tokens": ["Use", "View", "class", "for", "toolbar", "js", "caller"], "add_tokens": "@template ||= WebProfiler :: View . new ( \"async.erb\" )", "del_tokens": "@template ||= ERB . new ( :: File . read ( :: File . expand_path ( \"../../templates/async.erb\" , __FILE__ ) ) )", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "registering", "installers", "for", "barkest", ":", "install", "."], "add_tokens": "VERSION = '0.2.10'", "del_tokens": "VERSION = '0.2.9'", "commit_type": "change"}
{"commit_tokens": ["added", "support", "for", "cache", "warmup"], "add_tokens": "cdn_path += \"/#{Tml.cache.version.to_s}/#{key}.json#{opts[:uncompressed] ? '' : '.gz'}\"", "del_tokens": "cdn_path += \"/#{Tml.cache.version.to_s}/#{key}.json.gz\"", "commit_type": "add"}
{"commit_tokens": ["Updating", "the", "ruby", "project", "name"], "add_tokens": "Roroacms :: Application . configure do config . action_mailer . delivery_method = :smtp config . action_mailer . smtp_settings = { :address => 'smtp.gmail.com' , :domain => APP_CONFIG [ 'domain' ] , :port => 587 , :user_name => APP_CONFIG [ 'email_address' ] , :password => APP_CONFIG [ 'password' ] , :authentication => :plain } config . action_mailer . raise_delivery_errors = true end", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Fix", "specs", "that", "were", "not", "running"], "add_tokens": "module CryptKeeper :: LogSubscriber describe MysqlAes do", "del_tokens": "module CryptKeeperProviders describe MysqlAesLogSubscriber do", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "commits", "swallowed", "exceptions"], "add_tokens": "rescue = > e end_commit ( start_operation ) raise ( e )", "del_tokens": "ensure", "commit_type": "fix"}
{"commit_tokens": ["make", "gcc", "output", "locale", "independent"], "add_tokens": "output = ` echo | LANG=C gcc -v -x #{ language } -E - 2>&1 1>/dev/null `", "del_tokens": "output = ` echo | gcc -v -x #{ language } -E - 2>&1 1>/dev/null `", "commit_type": "make"}
{"commit_tokens": ["move", "aliasing", "to", "command", "modules"], "add_tokens": "ALIASES = { } MODULES = { } def initialize module_name @module_name = module_name super ( ) def rvc_alias cmd , target = nil target ||= cmd RVC :: ALIASES [ target . to_s ] = \"#{@module_name}.#{cmd}\" end RVC :: MODULES . clear RVC :: ALIASES . clear RVC :: MODULES [ 'custom' ] = CmdModule . new 'custom' unless RVC :: MODULES . member? module_name m = CmdModule . new module_name RVC :: MODULES [ module_name ] = m RVC :: MODULES [ module_name ] . instance_eval code , f", "del_tokens": "def initialize super MODULES . clear MODULES [ 'custom' ] = CmdModule . new unless MODULES . member? module_name m = CmdModule . new MODULES [ module_name ] = m MODULES [ module_name ] . instance_eval code , f", "commit_type": "move"}
{"commit_tokens": ["use", "Hash", "not", "Mash", "here"], "add_tokens": "self . load_paths = Hash . new", "del_tokens": "self . load_paths = Mash . new", "commit_type": "use"}
{"commit_tokens": ["fix", "image", "z", "-", "index", "on", "initialization"], "add_tokens": "@z = opts [ :z ] || 0", "del_tokens": "@z = opts [ :x ] || 0", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "functions", "to", "reproduce", "with", "mpg123"], "add_tokens": "play_on_linux if linux? kill_music_in_linux if linux? private def play_on_linux kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg321 &>/dev/null && mpg321 #{nyan_mp3} &>/dev/null &\" ) if kernel . system ( \"type mpg321\" ) kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg123 &>/dev/null && mpg123 #{nyan_mp3} &>/dev/null &\" ) if kernel . system ( \"type mpg123\" ) end def kill_music_on_linux system ( \"killall -9 mpg321 &>/dev/null\" ) if kernel . system ( \"type mpg321\" ) system ( \"killall -9 mpg123 &>/dev/null\" ) if kernel . system ( \"type mpg123\" ) end", "del_tokens": "kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg321 &>/dev/null && mpg321 #{nyan_mp3} &>/dev/null &\" ) if linux? system ( \"killall -9 mpg321 &>/dev/null\" ) if linux?", "commit_type": "add"}
{"commit_tokens": ["Fix", "launching", "Simulator", ".", "app", "with", "custom", "device", "set", "path"], "add_tokens": "} args . merge! ( { '-DeviceSetPath' => SimCtl . device_set_path } ) unless SimCtl . device_set_path . nil? args = args . merge ( opts ) . zip . flatten . join ( ' ' )", "del_tokens": "} . merge ( opts ) . zip . flatten . join ( ' ' )", "commit_type": "fix"}
{"commit_tokens": ["add", "spec", "for", "mark", "all", "as", "read", "manipulations"], "add_tokens": ":items => '/reader/atom' , :item_ids => '/reader/api/0/stream/items/ids' , :rename_tag => '/reader/api/0/rename-tag' , :disable_tag => '/reader/api/0/disable-tag' , :edit_tag => '/reader/api/0/edit-tag' , :mark_all_as_read => '/reader/api/0/mark-all-as-read'", "del_tokens": ":items => '/reader/atom' , :item_ids => '/reader/api/0/stream/items/ids' , :rename_tag => '/reader/api/0/rename-tag' , :disable_tag => '/reader/api/0/disable-tag' , :edit_tag => '/reader/api/0/edit-tag'", "commit_type": "add"}
{"commit_tokens": ["Fix", "kw", "arg", "shared", "context", "name"], "add_tokens": "RSpec . shared_context 'with steps accepting kw args' do", "del_tokens": "RSpec . shared_context 'with steps accepting a kw args' do", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "#release", "to", "#run!", "to", "have", "uniform", "interface", "with", "Server"], "add_tokens": "def run!", "del_tokens": "def release!", "commit_type": "change"}
{"commit_tokens": ["fix", "multi", "-", "columns", "index", "issue", "for", "always", "add", "db", "index", "check"], "add_tokens": "reference_column = eval ( index_node . arguments [ 2 ] . to_ruby ) @index_columns << [ table_name , reference_column ] ! ! @index_columns . find do | reference | reference [ 0 ] == table_name and reference [ 1 ] . class == String ? reference [ 1 ] == column_name : reference [ 1 ] . include? ( column_name ) end", "del_tokens": "reference_column_name = index_node . arguments [ 2 ] . to_ruby_string @index_columns << [ table_name , reference_column_name ] ! ! @index_columns . find { | reference | reference [ 0 ] == table_name and reference [ 1 ] == column_name }", "commit_type": "fix"}
{"commit_tokens": ["changed", "output", "for", "failed", "tests"], "add_tokens": "test_name = underscore ( fault . test_name . match ( / \\( (.*) \\) / ) [ 1 ] ) better_location = fault . location . detect { | line | line . include? ( test_name ) } || fault . location [ 0 ] msg << better_location . to_s << \"\\n\\t\" # Taken from ActiveSupport::Inflector def underscore ( camel_cased_word ) word = camel_cased_word . to_s . dup word . gsub! ( / :: / , '/' ) word . gsub! ( / ([A-Z]+)([A-Z][a-z]) / , '\\1_\\2' ) word . gsub! ( / ([a-z \\d ])([A-Z]) / , '\\1_\\2' ) word . tr! ( \"-\" , \"_\" ) word . downcase! word end", "del_tokens": "msg << fault . location [ 0 ] . to_s << \"\\n\\t\"", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "parameter", "for", "identifying", "log", "streams", "that", "shall", "be", "processed", "independently"], "add_tokens": "desc 'The field which contains the raw message text in the input JSON data.' desc 'Separate log streams by this field in the input JSON data.' config_param :stream , :string , default : '' @thread . join if @multiline_flush_interval log_id = [ tag ] log_id . push ( record . fetch ( @stream , '' ) ) unless @stream . empty? unless @accumulators . key? ( log_id ) out_tag = tag . sub ( / ^ #{ Regexp . escape ( @remove_tag_prefix ) } \\. / , '' ) @accumulators [ log_id ] = Fluent :: TraceAccumulator . new ( @message , @languages , max_lines : @max_lines , max_bytes : @max_bytes ) do | t , r | @accumulators [ log_id ] . push ( time_sec , record ) acc . force_flush if now - acc . buffer_start_time > @multiline_flush_interval if @multiline_flush_interval", "del_tokens": "desc 'The field which contains the raw message text in the input json data.' @thread . join if multiline_flush_interval unless @accumulators . key? ( tag ) out_tag = tag . sub ( / ^ #{ Regexp . escape ( remove_tag_prefix ) } \\. / , '' ) @accumulators [ tag ] = Fluent :: TraceAccumulator . new ( message , @languages , max_lines : max_lines , max_bytes : max_bytes ) do | t , r | @accumulators [ tag ] . push ( time_sec , record ) needs_flush = now - acc . buffer_start_time > multiline_flush_interval acc . force_flush if needs_flush if multiline_flush_interval", "commit_type": "add"}
{"commit_tokens": ["add", "parse", "option", "--", "filter", "-", "pull", "-", "requests"], "add_tokens": "options = { :tag1 => nil , :tag2 => nil , :format => '%d/%m/%y' , :output => 'CHANGELOG.md' , :labels => %w( bug enhancement ) , :pulls => true , :issues => true , :verbose => true , :add_issues_wo_labels => true , :merge_prefix => '*Merged pull-request:* ' , :author => true , :pull_request_labels => %w( bug enhancement ) } opts . on ( '--labels x,y,z' , Array , 'Issues with that labels will be included to changelog. Default is \\'bug,enhancement\\'' ) do | list | opts . on ( '--filter-pull-requests x,y,z' , Array , 'Pull requests with that labels will be included to changelog. pull requests w\\o labels will be included anyway. Default is \\'bug,enhancement\\'' ) do | list | options [ :pull_request_labels ] = list end", "del_tokens": "options = { :tag1 => nil , :tag2 => nil , :format => '%d/%m/%y' , :output => 'CHANGELOG.md' , :labels => %w( bug enhancement ) , :pulls => true , :issues => true , :verbose => true , :add_issues_wo_labels => true , :merge_prefix => '*Merged pull-request:* ' , :author => true } opts . on ( '--labels x,y,z' , Array , 'List of labels. Issues with that labels will be included to changelog. Default is \\'bug,enhancement\\'' ) do | list |", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "spec", "for", "option"], "add_tokens": "def mock ( request_url : 'https://lgtm.in/p/sSuI4hm0q' , actual_image_url : 'https://example.com/image.jpg' ) double ( :[] => request_url , actualImageUrl : actual_image_url end it 'pick random pic from lgtm.in' do it 'pick random pic from lgtm.in with https_image_only option' do allow ( Net :: HTTP ) . to receive ( :start ) . and_return ( mock ) @lgtm . check_lgtm https_image_only : true expect ( @dangerfile . status_report [ :markdowns ] [ 0 ] . message ) . to match ( %r{ https: \\/ \\/ example.com \\/ image.jpg } ) end", "del_tokens": "it 'pick random pic from lgtm.in' do mock = double ( :[] => 'https://lgtm.in/p/sSuI4hm0q' , actualImageUrl : 'https://example.com/image.jpg'", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "more", "flexible", "way", "to", "handle", "404", "."], "add_tokens": "# TODO: many methods here should be private. # Adding default routes to handle page not found (404). for_all_verbs_add_route ( 'notfound' , 'RackStep::ErrorController' , 'not_found' ) verb = @request . request_method path = @request . path route = router . find_route_for ( path , verb ) # Adds new routes to the application, one for each possible http verb (GET, # POST, DELETE and PUT). def for_all_verbs_add_route ( path , controller , method ) @router . add_route ( 'GET' , path , controller , method ) @router . add_route ( 'POST' , path , controller , method ) @router . add_route ( 'DELETE' , path , controller , method ) @router . add_route ( 'PUT' , path , controller , method )", "del_tokens": "# Trying to find what controller should process this request. # This will return a hash with the name of the controller, the # method (action), etc. route = router . find_route_for ( request ) # If no valid route is found, will break the request and return http 404 # (page not found). if ( route == nil ) return page_not_found_response end # Will use this as response when no route is found. def page_not_found_response Rack :: Response . new ( \"404 - Page not found\" , 404 )", "commit_type": "add"}
{"commit_tokens": ["use", "Array#pack", "for", "unknown", "image", "data"], "add_tokens": "elsif defined? Numo :: NArray && @data . kind_of? ( Numo :: NArray ) @data . to_string elsif @data . kind_of? ( Array ) elsif @data . repond_to? ( :to_a ) @data . to_a . pack ( \"d*\" ) else raise TypeError , \"invalid data type: #{@data.class}\"", "del_tokens": "elsif defined? Numo :: NArray if @data . kind_of? ( Numo :: NArray ) @data . to_string else Numo :: DFloat . cast ( @data ) . to_string end else", "commit_type": "use"}
{"commit_tokens": ["Added", "feature", "for", "updating", "patient", "demo", "with", "ruby", "step", "tests"], "add_tokens": "resources :patients , :only => [ :show , :edit , :update ]", "del_tokens": "resources :patients , :only => [ :show ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "class", "attribute", "name", "for", "javascript", "."], "add_tokens": "expect ( response . body . scan ( / <li class=\"resplist-row dynamicScaffoldJs-item-row\"> / ) . size ) . to eq 8", "del_tokens": "expect ( response . body . scan ( / <li class=\"resplist-row js-item-row\"> / ) . size ) . to eq 8", "commit_type": "fix"}
{"commit_tokens": ["Change", "multi", "formatter", "to", "use", "new", "api"], "add_tokens": "SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter . new ( [ ] )", "del_tokens": "SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter [ ]", "commit_type": "change"}
{"commit_tokens": ["make", "sure", "we", "sleep", "long", "enough", ".", "use", "our", "own", "time", "calc"], "add_tokens": "time = 0.0 until ( time >= timeout ) do s = Time . now . to_f sleep ( timeout - time ) time += Time . now . to_f - s end", "del_tokens": "sleep ( timeout )", "commit_type": "make"}
{"commit_tokens": ["implement", "and", "spec", "Config#initialize", "and", "#first_child"], "add_tokens": "# Initializes a new {Config} item. # @param name [String] config item name # @param name [Config] parent # @note If parent is given, the native child will be destroyed when the # native parent is destroyed (and not when the child's corresponding # {Config} object is garbage collected). def initialize ( name = nil , parent = nil ) parent = parent . ffi_delegate if parent . is_a? ( Config ) delegate = :: CZMQ :: FFI :: Zconfig . new ( name , parent ) attach_ffi_delegate ( delegate ) # NOTE: this delegate must not be freed automatically, because the # parent will free it. delegate . __undef_finalizer # Returns the first child or nil. # @return [Config] if there are any children # @return [nil] if there no children # TODO: extract to ChildrenAccessor ptr = ffi_delegate . child return nil if ptr . null? from_ffi_delegate ( ptr ) # TODO: Merge these changes into zproject. class CZMQ :: FFI :: Zconfig def __undef_finalizer ObjectSpace . undefine_finalizer self @finalizer = nil end def __finalizer_defined? ! ! @finalizer end end", "del_tokens": "def initialize ( name , parent = nil ) attach_ffi_delegate :: CZMQ :: FFI :: Zconfig . new ( name , parent ) # TODO", "commit_type": "implement"}
{"commit_tokens": ["Fix", "environment", "so", "simplecov", "will", "not", "abort", "test", "suite", "before", "it", "is", "run"], "add_tokens": "require 'simplecov' require 'coveralls' SimpleCov . formatter = Coveralls :: SimpleCov :: Formatter SimpleCov . start do add_filter '/test/' end", "del_tokens": "require 'coveralls' Coveralls . wear!", "commit_type": "fix"}
{"commit_tokens": ["Uses", "maestrano", "-", "rails", "initialize", "generator", "instead", "of", "install"], "add_tokens": "generate 'maestrano:initializer'", "del_tokens": "generate 'maestrano:install'", "commit_type": "use"}
{"commit_tokens": ["fixed", "activities", "to", "pass", "along", "activity", "results", "to", "the", "fragments"], "add_tokens": "if @fragment && @fragment . respond_to? ( :activity_result )", "del_tokens": "if @fragment && @fragment . respond_to? ( :handle_activity_result )", "commit_type": "fix"}
{"commit_tokens": ["add", "deep", "cloning", "to", "Quantity"], "add_tokens": "return self . clone # Clone self and explicitly clone the associated Unit object located # at @unit. # def initialize_copy ( source ) super instance_variable_set ( \"@unit\" , @unit . clone ) end", "del_tokens": "return self . dup", "commit_type": "add"}
{"commit_tokens": ["Move", "new_child", "to", "pages", "resources", "."], "add_tokens": "resources :pages , except : [ :show ] do get :new_child , on : :member end", "del_tokens": "resources :pages , except : [ :show ] get '/pages/:page/new' => 'pages#new' , as : :new_child_page", "commit_type": "move"}
{"commit_tokens": ["Fix", "extract_comment", "however", "it", "still", "need", "many", "improvements", "."], "add_tokens": "# Here we go again...", "del_tokens": "# Here we go agai...", "commit_type": "fix"}
{"commit_tokens": ["Remove", "code", "that", "was", "causing", "answers", "to", "not", "be", "parsed"], "add_tokens": "return unless data", "del_tokens": "#old head # return if @response.nil? or not ok? # @_data = @response['data'] return unless data && data . class == Hash # Sometimes data is an array, sometimes it is a hash???", "commit_type": "remove"}
{"commit_tokens": ["Added", "fix", "logic", "for", "long", "comments", "on", "a", "line", "by", "themselves"], "add_tokens": "return result if result = fix_long_comment ( self . line ) def fix_long_comment ( text ) # Must have no leading text return text unless text =~ / ^( \\s +) \\# \\s *(.*) \\Z / indent , comment = $1 . size , $2 # The \"+ 2\" is (indent)#(single space) space_for_text_per_line = self . class . line_length_limit - ( indent . size + 2 ) lines = [ '' ] words = comment . split ( / \\s / ) quota = space_for_text_per_line current_line = 0 while words . any? word = word . shift # break on word big enough to make a new line, unless its the first word if quota - ( word . size + 1 ) < 0 && quota < space_for_text_per_line current_line += 1 lines << '' end lines [ current_line ] << ' ' if lines [ current_line ] . any? lines [ current_line ] << word end lines . map { | line | ( \" \" * indent + '# ' + line } . join ( \"\\n\" ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "for", "handling", "undefined", "attributes"], "add_tokens": "def undefined_attributes ( option ) unless %i| raise ignore | . include? ( option ) raise ArgumentError , \"Unknown option `#{option}` for undefined attributes. Options are :raise or :ignore\" end @undef_attr = option end def __undef_attr @undef_attr ||= :raise end set_attributes! ( input ) def set_attributes! ( hash ) hash . each do | k , v | if self . class . __undef_attr == :raise raise ArgumentError , \"Undefined attribute: #{k}\" unless respond_to? ( \"#{k}=\" ) end send \"#{k}=\" , v if respond_to? ( \"#{k}=\" ) end end", "del_tokens": "input . each do | k , v | send \"#{k}=\" , v end", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "option", "to", "append", "versions", "to", "the", "log", "upon", "undo"], "add_tokens": "def undo! ( append : Logidze . append_on_undo ) switch_to! ( version . version , append : append ) def switch_to! ( version , append : Logidze . append_on_undo ) return false unless at_version ( version ) if append && version < log_version update! ( log_data . changes_to ( version : version ) ) else at_version! ( version ) self . class . without_logging { save! } end", "del_tokens": "def undo! switch_to! ( version . version ) def switch_to! ( version ) return false unless at_version! ( version ) self . class . without_logging { save! }", "commit_type": "add"}
{"commit_tokens": ["fixes", "fatal", "bug", "with", "caching"], "add_tokens": "session [ :captcha ] = File . basename ( file . path , '.*' )", "del_tokens": "session [ :captcha ] = File . basename ( file . path )", "commit_type": "fix"}
{"commit_tokens": ["fix", "respec", "tests", "for", "object_id"], "add_tokens": "\"50e26d500000000000000000\"", "del_tokens": "\"50e218f00000000000000000\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "presigned", "posts"], "add_tokens": "define_method \"#{name}_store_backend\" do store define_method \"#{name}_cache_backend\" do cache", "del_tokens": "define_method \"#{name}_store_name\" do store_name define_method \"#{name}_cache_name\" do cache_name", "commit_type": "add"}
{"commit_tokens": ["moved", "#validate_meta", "to", "module", "XMLParsable"], "add_tokens": "require_relative '../helpers/xml_parsable' XMLParsable . validate_meta xml", "del_tokens": "validate_meta xml # Will raise error if the XML file is not valid def validate_meta ( xml ) raise ArgumentError 'Multiple Core nodes' if xml . css ( 'core' ) . size > 1 end", "commit_type": "move"}
{"commit_tokens": ["Added", "more", "vpc", "-", "related", "resource", "types", "and", "added", "support", "for", "SecurityGroupIngress", "array", "in", "EC2", "::", "SecurityGroup"], "add_tokens": "\"Policy\" => \"Policies\" , \"SecurityGroupIngress\" => \"SecurityGroupIngress\" , \"SecurityGroupEgress\" => \"SecurityGroupEgress\"", "del_tokens": "\"Policy\" => \"Policies\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "#", "+", "#", "-", "to", "NAME", "mode"], "add_tokens": "when NAME @name = name_or_rgb @rgb = RGB . new * name2rgb ( @name . to_s ) @mode = @name raise ArgumentError , \"'#{name_or_rgb}' is wrong argument. Colorname, Array of RGB values, RGB object or HSB object or NAME object are acceptable\"", "del_tokens": "raise ArgumentError , \"'#{name_or_rgb}' is wrong argument. Colorname, Array of RGB values, RGB object or HSB object are acceptable\"", "commit_type": "fix"}
{"commit_tokens": ["fix", "comment", "mail", "subject", "was", "wrong", "."], "add_tokens": "tdiary . rb $Revision : 1.16 $ TDIARY_VERSION = '1.4.0.20020318' mail_header = @date . strftime ( mail_header )", "del_tokens": "tdiary . rb $Revision : 1.15 $ TDIARY_VERSION = '1.4.0' mail_header = now . strftime ( mail_header )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "ancestry", "to", "work", "with", "custom", "primary", "keys", "."], "add_tokens": "{ self . base_class . primary_key => ancestor_ids } { self . base_class . primary_key => path_ids } children . all ( :select => self . base_class . primary_key ) . map ( & self . base_class . primary_key . to_sym ) siblings . all ( :select => self . base_class . primary_key ) . collect ( & self . base_class . primary_key . to_sym ) descendants ( depth_options ) . all ( :select => self . base_class . primary_key ) . collect ( & self . base_class . primary_key . to_sym ) [ \"#{self.base_class.primary_key} = ? or #{self.base_class.ancestry_column} like ? or #{self.base_class.ancestry_column} = ?\" , self . id , \"#{child_ancestry}/%\" , child_ancestry ] subtree ( depth_options ) . all ( :select => self . base_class . primary_key ) . collect ( & self . base_class . primary_key . to_sym )", "del_tokens": "{ :id => ancestor_ids } { :id => path_ids } children . all ( :select => :id ) . map ( & :id ) siblings . all ( :select => :id ) . collect ( & :id ) descendants ( depth_options ) . all ( :select => :id ) . collect ( & :id ) [ \"id = ? or #{self.base_class.ancestry_column} like ? or #{self.base_class.ancestry_column} = ?\" , self . id , \"#{child_ancestry}/%\" , child_ancestry ] subtree ( depth_options ) . all ( :select => :id ) . collect ( & :id )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "the", "pricing", "API", "."], "add_tokens": "from_json shipping_rate_json", "del_tokens": "self . from_json shipping_rate_json", "commit_type": "add"}
{"commit_tokens": ["Fix", "get_login_page_wait_until_ready", "raised", "-", "error", "handling", ".", "Update", "log", "messages", "."], "add_tokens": "require 'ruby_aem/error' puts 'Retrieve login page attempt #%d: %s but not ready yet' % [ retries_count , result . message ] puts 'Retrieve login page attempt #%d: %s and ready' % [ retries_count , result . message ] raise StandardError . new ( err . message )", "del_tokens": "puts 'Retrieve login page attempt #%d: Login page does not contain QUICKSTART_HOMEPAGE' % [ retries_count ] puts 'Retrieve login page attempt #%d: %s' % [ retries_count , result . message ] raise StandardError . new ( result . message )", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "list", "test", "idiomatic", "ruby"], "add_tokens": "Clever :: District . all Clever :: School . all @students = Clever :: Student . all Clever :: Section . all @teachers = Clever :: Teacher . all @teachers . each do | teacher |", "del_tokens": "Clever :: District . all ( ) Clever :: School . all ( ) @students = Clever :: Student . all ( ) Clever :: Section . all ( ) @teachers = Clever :: Teacher . all ( ) for teacher in @teachers", "commit_type": "make"}
{"commit_tokens": ["fixed", "bad", "constant", "for", "localhost", "name"], "add_tokens": "@cr = CouchRest . new ( \"http://localhost:5984\" )", "del_tokens": "@cr = CouchRest . new ( \"http://local.grabb.it:5984\" )", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "attribute", "name", "to", "enable", "the", "no", "duplicate", "methods", "rule", "."], "add_tokens": "attr_accessor :app , :env , :meta @log_level = opts [ :level ] || \"INFO\" level : @log_level , @log_level = Resources :: LOG_LEVELS [ value ] @log_level = value @log_level = \"INFO\"", "del_tokens": "attr_accessor :level , :app , :env , :meta @level = opts [ :level ] || \"INFO\" level : @level , @level = Resources :: LOG_LEVELS [ value ] @level = value @level = \"INFO\"", "commit_type": "change"}
{"commit_tokens": ["Adding", "runner", "rack", "adapter", "for", "testing", "and", "script", "runer", "style"], "add_tokens": "adapter = Merb :: Rack :: Irb when \"runner\" adapter = Merb :: Rack :: Runner", "del_tokens": "adapter = Merb :: Rack :: Irb", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "failing", "spec", "for", "the", "multiple", "joins", "to", "the", "same", "table", "scenario", "."], "add_tokens": "context 'with multiple joins to the same table' do it 'should not raise an exception' do expect do 100 . times do persons = Person . joins { [ outgoing_messages . outer , incoming_messages . outer ] } persons = persons . where { ( outgoing_messages . author_id . not_eq 7 ) & ( incoming_messages . author_id . not_eq 7 ) } persons . where { ( outgoing_messages . recipient_id . not_eq 7 ) & ( incoming_messages . recipient_id . not_eq 7 ) } . to_sql end end . to_not raise_exception end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Fix", "spelling", "errors", "in", "test", "descriptions"], "add_tokens": "it 'expect to run with remapping' do it 'expect to run with remapping' do", "del_tokens": "it 'expect to run with remaping' do it 'expect to run with remaping' do", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Amazon", "model", "to", "pull", "images", "from", "#imageBlock"], "add_tokens": "%w{ amazon amazon2 } . each do | name | it \"should fetch valid info for #{name}\" do amazon_check ( FactoryGirl . build ( name . to_sym ) . url ) end", "del_tokens": "it \"should return correct model info for a product\" do amazon_check ( FactoryGirl . build ( :amazon ) . url )", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "whole", "crapload", "of", "threading", "issues", "and", "work", "around", "Net", "::", "IMAP", "deadlocks", "and", "exception", "-", "raising", "shenanigans", "."], "add_tokens": "source_thread = Thread . new do source . scan_mailbox Thread . current [ :fetching ] = true Thread . current [ :fetching ] = false rescue Larch :: WatchdogError => e Thread . current [ :fetching ] = false @log . error \"#{source.username}@#{source.host}: server dropped connection unexpectedly\" source . noop retry @log . fatal \"#{e.class.name}: #{e.message}\" Kernel . abort dest_thread = Thread . new do dest . scan_mailbox rescue Larch :: IMAP :: Error => e rescue = > e @log . fatal \"#{e.class.name}: #{e.message}\" Kernel . abort end end watchdog_thread = Thread . new do loop do sleep 10 if msgq . length == 0 && source_thread [ :fetching ] source_thread . raise ( WatchdogError ) end dest_thread . join", "del_tokens": "source_scan = Thread . new { source . scan_mailbox } dest_scan = Thread . new { dest . scan_mailbox } source_scan . join dest_scan . join source_copy = Thread . new do @log . fatal e . message dest_copy = Thread . new do rescue Larch :: IMAP :: FatalError => e @log . fatal e . message rescue = > e dest_copy . join", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "different", "ssl_version"], "add_tokens": "delegate :endpoint , :timeout , :username , :password , :debug , :insecure_ssl , :ssl_version , :to => \"Exchanger.config\" @client . ssl_config . ssl_version = ssl_version if ssl_version", "del_tokens": "delegate :endpoint , :timeout , :username , :password , :debug , :insecure_ssl , :to => \"Exchanger.config\"", "commit_type": "add"}
{"commit_tokens": ["Add", "package", "installer", "definition", "specs"], "add_tokens": "@dependencies << :rubygems return if meta_package? private def meta_package? @installer == nil end", "del_tokens": "@dependencies << :rubygems # implicit rubygems dependency return unless @installer # meta-packages don't define any installer", "commit_type": "add"}
{"commit_tokens": ["Add", "rails", "3", "generator", "instructions"], "add_tokens": "begin # Run the generator Rails :: Generator :: Scripts :: Generate . new . run ( [ 'blog_assets' ] ) rescue Exception => e puts \"The following error ocurred: \" + e . inspect end puts \"BlogKit is installed, to continue run:\" puts \"rails generate blog_assets\" end", "del_tokens": "# Run the generator Rails :: Generator :: Scripts :: Generate . new . run ( [ 'blog_assets' ] ) puts \"The following error ocurred: \" + e . inspect end", "commit_type": "add"}
{"commit_tokens": ["Add", "efficient", "copy", "if", "uploadable", "has", "a", "path"], "add_tokens": "def copy ( uploadable , destination ) if uploadable . respond_to? ( :path ) FileUtils . cp ( uploadable . path , destination ) else File . open ( destination , \"wb\" ) do | write | read = uploadable . to_io read . each ( \"\" , Defile . read_chunk_size ) do | chunk | write . write ( chunk ) end read . close", "del_tokens": "def copy ( uploadable , path ) File . open ( path , \"wb\" ) do | write | read = uploadable . to_io read . each ( \"\" , Defile . read_chunk_size ) do | chunk | write . write ( chunk ) read . close", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "to", "the", "new", "message_format", "param", "when", "publishing", "messages", "to", "a", "room", "."], "add_tokens": "# @param message_format [String] Determines how the message is treated by HipChat's server and rendered inside HipChat applications. One of \"html\" or \"text\". (default: html) def rooms_message ( room_id , from , message , notify = 0 , color = 'yellow' , message_format = 'html' ) :message => message , :notify => notify , :color => color , :message_format => message_format } )", "del_tokens": "def rooms_message ( room_id , from , message , notify = 0 , color = 'yellow' ) :message => message , :notify => notify , :color => color } )", "commit_type": "add"}
{"commit_tokens": ["Add", "interface", "key", "to", "Fields"], "add_tokens": "key :interface", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "to_h", "methods", "for", "address_standardization", "and", "city_state", "responses"], "add_tokens": "# Returns a single city/state pair given a zip5 # Returns all city/state data from the query results def data @data end # Returns all city/state data as a pure Ruby hash (e.g. no Structs as values) def to_h hash = { } @data . each_pair do | key , value | hash [ key ] = value . to_h end hash end", "del_tokens": "# Returns an address representing the standardized version of the given # address from the results of the query.", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "w", "idle", "and", "stale"], "add_tokens": "def Resque . kill_idle_and_stale_workers", "del_tokens": "def Resque . kill_idle_stale_workers", "commit_type": "fix"}
{"commit_tokens": ["changed", "one", "timestamp", "value", "in", "tests", "to", "string", "to", "ensure", "wider", "test", "coverage"], "add_tokens": "event :deliver , :timestamp => \"dispatched_at\" do", "del_tokens": "event :deliver , :timestamp => :dispatched_at do", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", "jruby", "test"], "add_tokens": "unless defined? JRUBY_VERSION require 'simplecov' SimpleCov . start 'rails' end", "del_tokens": "require 'simplecov' SimpleCov . start 'rails'", "commit_type": "add"}
{"commit_tokens": ["Add", "callback", "accessor", "to", "Protocol", "::", "Query"], "add_tokens": "def execute ( * ops ) buf = \"\" ops . each do | op | op . request_id = @request_id . next op . serialize buf @callbacks [ op . request_id ] = op . callback if op . callback end query = query . dup query . callback = lambda do | error , reply , num , doc | execute ( query )", "del_tokens": "def execute ( op , & callback ) request_id = @request_id . next @callbacks [ request_id ] = callback if callback op . request_id = request_id buf = op . serialize execute ( query ) do | error , reply , num , doc |", "commit_type": "add"}
{"commit_tokens": ["Add", "auto_invite_to_new_rooms", "attribute", "to", "User"], "add_tokens": "User = Struct . new ( :connection , :id , :name , :email_address , :admin , :created_at , :type , :api_auth_token , :avatar_url , :auto_invite_to_new_rooms )", "del_tokens": "User = Struct . new ( :connection , :id , :name , :email_address , :admin , :created_at , :type , :api_auth_token , :avatar_url )", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "domain", "name", "from", "datasift", ".", "net", "to", "datasift", ".", "com", "."], "add_tokens": "API_BASE_URL = 'api.datasift.com/' ; STREAM_BASE_URL = 'stream.datasift.com/' ;", "del_tokens": "API_BASE_URL = 'api.datasift.net/' ; STREAM_BASE_URL = 'stream.datasift.net/' ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "template", "names", "in", "mailers"], "add_tokens": "mail :to => receiver . send ( Mailboxer . email_method , message ) , :subject => t ( 'mailboxer.message_mailer.subject_new' , :subject => subject ) , :template_name => 'new_message_email' mail :to => receiver . send ( Mailboxer . email_method , message ) , :subject => t ( 'mailboxer.message_mailer.subject_reply' , :subject => subject ) , :template_name => 'reply_message_email'", "del_tokens": "mail ( :to => receiver . send ( Mailboxer . email_method , message ) , :subject => t ( 'mailboxer.message_mailer.subject_new' , :subject => subject ) ) mail ( :to => receiver . send ( Mailboxer . email_method , message ) , :subject => t ( 'mailboxer.message_mailer.subject_reply' , :subject => subject ) )", "commit_type": "fix"}
{"commit_tokens": ["using", "alias_method", "instead", "of", "alias", "in", "controller"], "add_tokens": "alias_method :resource_action , :resource_actions", "del_tokens": "alias :resource_action :resource_actions", "commit_type": "use"}
{"commit_tokens": ["allow", "document", "identifier", "+", "year"], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "allow"}
{"commit_tokens": ["Add", "indentation", "to", "generated", "code", "."], "add_tokens": "test_code += \" user = incline_users(#{user.inspect})\\n\" test_code += \" group = Incline::AccessGroup.find_or_create_by(name: #{group.inspect})\\n\" test_code += \" user.groups << group\\n\" test_code += \" log_in_as user\\n\" test_code += \" path = #{url_helper}\\n\" test_code += \" #{method}(path)\\n\" test_code += \" #{method}(path, #{params})\\n\" test_code += \" assert_response #{expected_result.inspect}\\n\" test_code += \" assert_redirected_to #{expected_result}\\n\"", "del_tokens": "test_code += \"user = incline_users(#{user.inspect})\\n\" test_code += \"group = Incline::AccessGroup.find_or_create_by(name: #{group.inspect})\\n\" test_code += \"user.groups << group\\n\" test_code += \"log_in_as user\\n\" test_code += \"path = #{url_helper}\\n\" test_code += \"#{method}(path)\\n\" test_code += \"#{method}(path, #{params})\\n\" test_code += \"assert_response #{expected_result.inspect}\\n\" test_code += \"assert_redirected_to #{expected_result}\\n\"", "commit_type": "add"}
{"commit_tokens": ["Use", "class", "names", "instead", "of", "classes", "for", "role_descriptions"], "add_tokens": "role_descriptions = EffectiveRoles . role_descriptions [ form . object . class . name ]", "del_tokens": "role_descriptions = EffectiveRoles . role_descriptions [ form . object . class ]", "commit_type": "use"}
{"commit_tokens": ["fixes", "tests", "for", "this", "bug"], "add_tokens": "return url unless @paginated", "del_tokens": "return EMPTY_STRING unless @paginated", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "watch", "extensions"], "add_tokens": "migrate_to :stats , version : 3 File . open ( 'migrations/schema.txt' , 'w' ) { | file | file . write ( schema ) }", "del_tokens": "migrate_to :stats , version : 2 File . open ( 'migrations/schema.txt' , 'w' ) { | file | file . write ( schema ) }", "commit_type": "add"}
{"commit_tokens": ["fix", "taxonomy", "when", "multiple", "options", "were", "present", "for", "a", "given", "relation", "in", "the", "hash", "(", "wasn", "t", "parsingn", "approrpiately", ")"], "add_tokens": "[ self . down_taxonomy [ parent . entity_type ] ] . flatten . map { | t | return true if [ child . entity_type , \"*\" ] . include? ( t ) } [ self . up_taxonomy [ child . entity_type ] ] . flatten . map { | t | return true if [ parent . entity_type , \"*\" ] . include? ( t ) }", "del_tokens": "[ self . down_taxonomy [ parent . entity_type ] ] . map { | t | return true if [ child . entity_type , \"*\" ] . include? ( t ) } [ self . up_taxonomy [ child . entity_type ] ] . map { | t | return true if [ parent . entity_type , \"*\" ] . include? ( t ) }", "commit_type": "fix"}
{"commit_tokens": ["remove", "carets", "from", "test", "names", "and", "starting", "ranges", "in", "messages"], "add_tokens": "named_field 3 , :universal_test_id_internal def universal_test_id universal_test_id_internal . gsub ( / \\^ / , \"\" ) end def universal_test_id = ( val ) universal_test_id_internal = \"^^^#{val}\" end named_field 3 , :starting_range_id_internal def starting_range_id starting_range_id_internal . gsub ( / \\^ / , \"\" ) end def starting_range_id = ( val ) starting_range_id_internal = \"^#{val}\" end", "del_tokens": "named_field 3 , :universal_test_id", "commit_type": "remove"}
{"commit_tokens": ["changed", "to", "using", "more", "managed", "app"], "add_tokens": "Bundler . require require \"formula\" module Dummy # Enable the asset pipeline config . assets . enabled = true # Version of your assets, change this if you want to expire all your assets config . assets . version = '1.0'", "del_tokens": "# If you have a Gemfile, require the gems listed there, including any gems # you've limited to :test, :development, or :production. Bundler . require ( :default , Rails . env ) if defined? ( Bundler ) module Formula # JavaScript files you want as :defaults (application.js is always included). # config.action_view.javascript_expansions[:defaults] = %w(jquery rails)", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "couple", "of", "folders", "to", "exclude", "and", "a", "long", "list", "of", "extension", "to", "ignore"], "add_tokens": "unless ignore? ( file ) File . open ( file , \"r\" ) do | f | line_number = 1 while line = f . gets valid_tasks . each do | type , regex | begin result = line . match regex rescue ArgumentError # NOTE: Some files like .DS_Store are not filtered by the ignore? method... return end unless result . nil? task = { file : file , line_number : line_number , task : result . to_a . last } @tasks [ type ] << task end line_number += 1 end # Should a file be ignored? # Some files, like images or SQLite databases, are not meant to be parsed def ignore? ( file ) # Get the list of file extensions to ignore extensions = YAML :: load ( File . open ( @config_folder + \"/excluded_extensions.yml\" ) ) extensions . include? ( File . extname ( file ) ) end", "del_tokens": "File . open ( file , \"r\" ) do | f | line_number = 1 while line = f . gets valid_tasks . each do | type , regex | result = line . match regex unless result . nil? task = { file : file , line_number : line_number , task : result . to_a . last } @tasks [ type ] << task end line_number += 1", "commit_type": "add"}
{"commit_tokens": ["removed", "duplicate", "code", "from", "client", "constructor"], "add_tokens": "", "del_tokens": "oa_uri_with_protocol = Regexp :: new ( '(^https:\\/\\/|http:\\/\\/)\\w+.+\\w+.openasset.(com)$' , true ) oa_uri_without_protocol = Regexp :: new ( '^\\w+.+\\w+.openasset.(com)$' , true ) # unless false && oa_uri_with_protocol =~ client_url #check for valid url and that protocol is specified # if oa_uri_without_protocol =~ client_url #verify correct url format # client_url = \"https://\" + client_url #add the https protocol if one isn't provided # elsif false # msg = \"Error: Invalid url! Expected http(s)://<subdomain>.openasset.com\" + # \"\\nInstead got => #{client_url.inspect}\" # logger.error(msg.red) # abort # end # end", "commit_type": "remove"}
{"commit_tokens": ["Make", "the", "Mash", "lazy", "so", "every", "instance", "get", "its", "own", "."], "add_tokens": "set_or_return ( key , val , kind_of : Hash , default : lazy { Mash . new } )", "del_tokens": "set_or_return ( key , val , kind_of : Hash , default : Mash . new )", "commit_type": "make"}
{"commit_tokens": ["Add", "data", "points", "for", "pod_try", "and", "include", "the", "platform", "in", "the", "data", "sent"], "add_tokens": "# These UUIDs come from the Xcode project # http://danwright.info/blog/2010/10/xcode-pbxproject-files-3/ :pods => pods , :platform => project_target . platform :cocoapods_version => Pod :: VERSION , :pod_try => false", "del_tokens": "# These UUIDs come from the Xcode project. # I generated a new project a few times, and got minor changes # similar to what I'd expect based on a timestamp based UUID # # /* Begin PBXNativeTarget section */ # 6042DA7C1AF34DF600070256 /* Hello */ = { # # /* Begin PBXNativeTarget section */ # 6042DAAE1AF34E3C00070256 /* Hello */ = { # # /* Begin PBXNativeTarget section */ # 6042DAE01AF34F0600070256 /* Hello */ = { # # /* Begin PBXNativeTarget section */ # 6042DB121AF34F4600070256 /* Hello2 */ = { # # /* Begin PBXNativeTarget section */ # 6042DB441AF34F7F00070256 /* Trogdor */ = { # # Multiple days later # /* Begin PBXNativeTarget section */ # 601142661AF7CD3B00F070A5 /* Burninator */ = { # # This means we send nothing remotely confidential. # :pods => pods :cocoapods_version => Pod :: VERSION", "commit_type": "add"}
{"commit_tokens": ["Add", "errors", "to", "submit", "form", "helper"], "add_tokens": "require 'bh/helpers/form/submit_helper' include Form :: SubmitHelper def self . non_textual_field_helpers [ :label , :hidden_field , :range_field , :check_box , :radio_button , :select , :submit ] ( field_helpers - non_textual_field_helpers ) . each do | field_type |", "del_tokens": "def self . textual_field_helpers field_helpers - [ :label , :hidden_field , :range_field , :check_box , :radio_button , :select ] textual_field_helpers . each do | field_type |", "commit_type": "add"}
{"commit_tokens": ["Remove", "invalid", "previously", "-", "cached", "values"], "add_tokens": "res_env = @store [ url ] # previous cached response body = res_env . respond_to? ( :body ) ? res_env . body : nil", "del_tokens": "body = @store [ url ] . body", "commit_type": "remove"}
{"commit_tokens": ["added", "source", "path", "support", "(", "so", "sources", "can", "be", "linked", "to", "each", "other", ")"], "add_tokens": "current_source_path = source_path # Dynamic sources are never registered under the parent source if hash_value ( Tml . session . block_options , :dynamic ) current_source_path = source_key else application . verify_source_path ( source_key , current_source_path ) end # Tml.logger.debug(\"#{params[:label]}, #{source_key}\") application . register_missing_key ( current_source_path , translation_key ) def source_path sp . join ( Tml . config . source_separator )", "del_tokens": "source_path = source_path ( options ) . join ( Tml . config . source_separator ) application . verify_source_path ( source_key , source_path ) application . register_missing_key ( source_path , translation_key ) def source_path ( options ) sp", "commit_type": "add"}
{"commit_tokens": ["Fix", "Scenario", "Outline", "Example", "In", "Step", "Table", "Header"], "add_tokens": "step_instance . table . each { | row | row . each { | col | col . gsub! ( \"<#{key}>\" , text ) } } if step_instance . has_table?", "del_tokens": "step_instance . table [ 1 .. - 1 ] . each { | row | row . each { | col | col . gsub! ( \"<#{key}>\" , text ) } } if step_instance . has_table?", "commit_type": "fix"}
{"commit_tokens": ["Add", "needed", "rake", "-", "tasks", "for", "Rails", "also", "fix", "several", "date", "-", "related", "issues", "and", "schema", "dump", "problems"], "add_tokens": "attr_writer :limit , :precision / mysql /i => lambda { | cfg , col | col . extend ( JdbcSpec :: MySQL :: Column ) } , attr_accessor :adapter def database_name @connection . get_catalog end tps = self . adapter . native_database_types c = ActiveRecord :: ConnectionAdapters :: JdbcColumn . new ( @config , column_name , col [ 'column_def' ] , columns << c if tps [ c . type ] && tps [ c . type ] [ :limit ] . nil? c . limit = nil c . precision = nil end connection . adapter = self def native_database_types #:nodoc: def database_name #:nodoc: @connection . database_name end", "del_tokens": "columns << ActiveRecord :: ConnectionAdapters :: JdbcColumn . new ( @config , column_name , col [ 'column_def' ] , def native_database_types #:nodoc", "commit_type": "add"}
{"commit_tokens": ["make", "code", "very", "slightly", "more", "readable"], "add_tokens": "raise ( ERROR_CODES [ errno ] || PBS :: Error ) , \"#{pbs_strerror(errno)}\"", "del_tokens": "raise ERROR_CODES [ errno ] || PBS :: Error , \"#{pbs_strerror(errno)}\"", "commit_type": "make"}
{"commit_tokens": ["Make", "it", "sing", "with", "Rails", "4", ";"], "add_tokens": "if defined? ( :: Rails ) && defined? ( :: Rails :: Engine ) require 'sanitize_email/engine' elsif :: Rails :: VERSION :: MAJOR == 3 && :: Rails :: VERSION :: MINOR == 0 require 'sanitize_email/railtie' # TODO: This was a mistake I think. Deprecate. proc = SanitizeEmail [ :activation_proc ]", "del_tokens": "# TODO: Prepare this for Rails 4 if defined? ( Rails ) && :: Rails :: VERSION :: MAJOR >= 3 if :: Rails :: VERSION :: MINOR >= 1 require 'sanitize_email/engine' elsif :: Rails :: VERSION :: MINOR == 0 require 'sanitize_email/railtie' end proc = SanitizeEmail . activation_proc", "commit_type": "make"}
{"commit_tokens": ["Added", "authentication", "authorization", "and", "layout", "config"], "add_tokens": "NIL_PROC = proc { } attr_accessor :enabled attr_accessor :authenticate , :authorize attr_accessor :from , :to , :subject , :noreply attr_accessor :layout def authenticate_with ( & blk ) @authenticate = blk if blk @authenticate || NIL_PROC end def authorize_with ( & block ) @authorize = block if block @authorize || NIL_PROC end", "del_tokens": "attr_accessor :enabled , :from , :to , :subject , :noreply", "commit_type": "add"}
{"commit_tokens": ["allow", "creation", "of", "RequestFailed", "without", "response", "to", "play", "nice", "with", "tests", "/", "specs"], "add_tokens": "def initialize ( response = nil ) @response . code . to_i if @response return default unless @response", "del_tokens": "def initialize ( response ) @response . code . to_i", "commit_type": "allow"}
{"commit_tokens": ["Adding", "convenience", "methods", "for", "vo2max", "and", "recovery", "time", "."], "add_tokens": "v1 = instance_variable_get ( ivar_name ) v2 = fdr . instance_variable_get ( ivar_name ) if ( scale = field . opts [ :scale ] ) v1 = ( v1 * scale ) . to_i if v1 v2 = ( v2 * scale ) . to_i if v2 end unless v1 == v2 Log . error \"#{field.name}: #{v1} != #{v2}\"", "del_tokens": "unless instance_variable_get ( ivar_name ) == fdr . instance_variable_get ( ivar_name ) Log . error \"#{field.name}: #{instance_variable_get(ivar_name)} != \" + \"#{fdr.instance_variable_get(ivar_name)}\" exit", "commit_type": "add"}
{"commit_tokens": ["Fix", "SalesforceOrm", "::", "Object", "caching", "issue"], "add_tokens": "VERSION = '1.2.4' . freeze", "del_tokens": "VERSION = '1.2.3' . freeze", "commit_type": "fix"}
{"commit_tokens": ["fix", "elections", "don", "t", "block", "dispatch", "thread", "allow", "for", "following", "either", "leader", "or", "next_node"], "add_tokens": "def election_candidate ( name , data , opts = { } ) opts = opts . merge ( :data => data ) ZK :: Election :: Candidate . new ( self , name , opts ) def election_observer ( name , opts = { } ) ZK :: Election :: Observer . new ( self , name , opts )", "del_tokens": "def election_candidate ( name , data ) ZK :: Election :: Candidate . new ( self , name , data ) def election_observer ( name ) ZK :: Election :: Observer . new ( self , name )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "boolean", "and", "and", "or"], "add_tokens": "define_unary_op :not , :bool define_binary_op :and , :bool_binary define_binary_op :or , :bool_binary", "del_tokens": "define_unary_op :not define_binary_op :and define_binary_op :or", "commit_type": "implement"}
{"commit_tokens": ["Make", "versions", ".", "between", "consistent", "about", "included", "versions"], "add_tokens": "return [ ] if from . nil? || to . nil? :conditions => { :number => ( from == to ) ? to : Range . new ( * [ from , to ] . sort ) } ,", "del_tokens": "return [ ] if from . nil? || to . nil? || ( from == to ) :conditions => { :number => Range . new ( * [ from , to ] . sort ) } ,", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "very", "basic", "Client#build_request", "method", "."], "add_tokens": "@client_class ||= Client . define ( api ) end def client @client ||= client_class . new describe '#build_request' do it 'returns a Request object' do client . build_request ( :operation_name ) . must_be_kind_of ( Client :: Request ) end it 'defaults the request params to {}' do client . build_request ( :operation_name ) . params . must_equal ( { } ) end it 'passes along params' do params = { } req = client . build_request ( :operation_name , params ) req . params . must_be_same_as ( params ) end end", "del_tokens": "Client . define ( api )", "commit_type": "add"}
{"commit_tokens": ["Use", "null", "formatter", "when", "running", "chef", "-", "solo", "in", "show_config", "."], "add_tokens": "status = run_chef ( \"#{base_path}/embedded/cookbooks/show-config.json\" , \"-l fatal -F null\" )", "del_tokens": "status = run_chef ( \"#{base_path}/embedded/cookbooks/show-config.json\" , \"-l fatal\" )", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "explicit", "median"], "add_tokens": "percentile ( 50.0 )", "del_tokens": "# TODO", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "now", "defunced", "Linked#List", "along", "with", "tests"], "add_tokens": "subject { :: Linked } it 'has a version number' do refute_nil subject :: VERSION", "del_tokens": "it 'has a version number' do refute_nil :: Linked :: VERSION end describe '#List' do it 'returns the list back when given one' it 'inserts one or more Items into a new list' it 'converts an array to a List' it 'wraps an arbitrary object in a single Item in a new List'", "commit_type": "remove"}
{"commit_tokens": ["added", "values", "option", "to", "filter"], "add_tokens": "attr_reader :columns , :values @values = opts [ :values ] #sort_hash ordered(driver).group(columns.first).count sort_hash driver . unordered . group ( columns . first ) . count #ordered(driver).distinct_values(columns.first).sort values || driver . unordered . distinct_values ( columns . first ) . sort", "del_tokens": "attr_reader :columns sort_hash ordered ( driver ) . group ( columns . first ) . count ordered ( driver ) . distinct_values ( columns . first ) . sort", "commit_type": "add"}
{"commit_tokens": ["Updated", "engine", "file", "removed", "slim", "from", "engine", ".", "Updated", "gem", "file", "for", "ruby", "gems", "."], "add_tokens": "require 'devise'", "del_tokens": "require 'devise' require 'slim'", "commit_type": "update"}
{"commit_tokens": ["Updated", "data_set", ".", "rb", "to_csv", "to", "use", "lib", "CSV", "too"], "add_tokens": "columns = [ ] columns << [ \"id\" , \"updated\" , \"title\" ] columns << @points . first . dimensions . map { | d | d . key } columns << @points . first . metrics . map { | m | m . key } output = CSV . generate_line ( columns ) + \"\\n\"", "del_tokens": "output = '\"id\",\"updated\",\"title\",' output += @points . first . dimensions . collect do | dimension | \"\\\"#{dimension.key.to_s}\\\"\" end . join ( ',' ) output += ',' output += @points . first . metrics . collect do | metric | \"\\\"#{metric.key.to_s}\\\"\" end . join ( ',' ) output += \"\\n\"", "commit_type": "update"}
{"commit_tokens": ["Make", "rake", "tasks", "interactive", "by", "default", ".", "Add", "ONLY", "option", "for", "docker", ":", "compose", ":", "up", ".", "DRY", "out", "mapping", "code", "."], "add_tokens": "VERSION = \"0.2.0\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "make"}
{"commit_tokens": ["Changed", "from", "/", "read_stream", "to", "read", ".", "Takes", "a", "StringIO", "or", "String", "and", "a", "file", "-", "type", "symbol", "."], "add_tokens": "# Create an instance from the given stream or string, which should be in CSV or TXT format # @param [StringIO] a StringIO stream or String object, with data in CSV or TXT format # @param [Symbol] :csv or :txt, indicating the format of the first parameter def self . read ( stringio_or_string , filetype ) wb . read ( stringio_or_string , filetype ) # @param [Symbol] :csv or :txt, indicating the format of the first parameter def read ( stringio_or_string , filetype ) raise ArgumentError . new ( \"The filetype parameter should be either :csv or :txt\" ) unless [ :csv , :txt ] . include? ( filetype ) send ( :\" parse_ #{ filetype } \" , t )", "del_tokens": "# Create an instance from the given stream or string, which should be in CSV format # @param [StringIO] a StringIO stream or String object, with data in CSV format def self . from_stream ( stringio_or_string ) wb . load_stream ( stringio_or_string ) def load_stream ( stringio_or_string ) load_csv ( t )", "commit_type": "change"}
{"commit_tokens": ["Fix", "continous", "integration", "mime", "type", "parsing", "problem", "."], "add_tokens": "parse ( options [ :resource ] , options [ :mime_type ] || mime_type ) if options [ :mime_type ]", "del_tokens": "parse ( options [ :resource ] , options [ :mime_type ] || mime_type )", "commit_type": "fix"}
{"commit_tokens": ["Use", "Invoice", ".", "all", "instead", "of", "Invoice", ".", "upcoming", "for", "base", "query", "parameter", "tests", "."], "add_tokens": "def test_invoice_customer_array :url => '/v1/invoices?customer=test_customer'", "del_tokens": "def test_invoice_array :url => '/v1/invoices/upcoming?customer=test_customer'", "commit_type": "use"}
{"commit_tokens": ["Create", "query", "to", "always", "assume", "not", "persisted", "."], "add_tokens": "attr_reader :klass , :path , :headers , :params if payload . is_a? ( Hash ) && persisted? && payload . has_key? ( klass . primary_key ) [ klass . path , payload . fetch ( klass . primary_key ) ] . join ( '/' ) def persisted? false end", "del_tokens": "attr_reader :klass , :headers , :path , :params if payload . is_a? ( Hash ) && payload . has_key? ( klass . primary_key ) [ klass . path , payload . delete ( klass . primary_key ) ] . join ( '/' )", "commit_type": "create"}
{"commit_tokens": ["Use", "taken", "instead", "of", "error", "message", "when", "not", "using", "Mongoid"], "add_tokens": "if record . errors . present? error = self . class . name . include? ( \"Mongoid\" ) ? record . errors . first . last : :taken form . errors . add ( property , error ) end", "del_tokens": "form . errors . add ( property , record . errors . first . last ) if record . errors . present?", "commit_type": "use"}
{"commit_tokens": ["added", "commandline", "to", "start", "a", "stickler", "server"], "add_tokens": "require 'stickler/error' require 'stickler/middleware/not_found' class Web # The directory holding all the repositories attr_reader :stickler_root def initialize ( stickler_root ) @stickler_root = File . expand_path ( stickler_root ) raise :: Stickler :: Error , \"Stickler root directory '#{@stickler_root}' must already exist\" unless File . directory? ( @stickler_root ) raise :: Stickler :: Error , \"Stickler root directory '#{@stickler_root}' must be writable\" unless File . writable? ( @stickler_root ) end def app root = self . stickler_root Rack :: Builder . new do use Stickler :: Middleware :: Compression use Stickler :: Middleware :: Gemcutter , :serve_indexes => false , :repo_root => File . join ( root , \"gemcutter\" ) use Stickler :: Middleware :: Mirror , :serve_indexes => false , :repo_root => File . join ( root , \"mirror\" ) use Stickler :: Middleware :: Index , :serve_indexes => true use Stickler :: Middleware :: NotFound run Sinatra :: Base end end end", "del_tokens": "require 'rack/cascade' class Web < :: Sinatra :: Base disable :sessions enable :logging , :dump_errors , :clean_trace use Stickler :: Middleware :: Compression use Stickler :: Middleware :: Gemcutter , :serve_indexes => false use Stickler :: Middleware :: Mirror , :serve_indexes => false use Stickler :: Middleware :: Index , :serve_indexes => true use Stickler :: Middleware :: NotFound end", "commit_type": "add"}
{"commit_tokens": ["Make", "checking", "and", "pulling", "from", "Github", "optional"], "add_tokens": "# @option options [String] :edge # whether to try loading from Github @options [ :edge ] = true elsif ! @options [ :edge ] else raise Fauxhai :: Exception :: InvalidPlatform . new ( \" Could not find platform ' #{ platform } / #{ version } ' in any of the s ources! \" )", "del_tokens": "elsif", "commit_type": "make"}
{"commit_tokens": ["Adding", "support", "for", "running", "tests", "in", "mysql", "to", "show", "problems"], "add_tokens": "ActiveRecord :: Base . establish_connection ( ENV [ \"DATABASE_ADAPTER\" ] || \"sqlite3\" )", "del_tokens": "ActiveRecord :: Base . establish_connection ( \"sqlite3\" )", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "http", "ssl", "options"], "add_tokens": ":tenant => nil , :ssl_ca_file => nil , :verify_ssl => OpenSSL :: SSL :: VERIFY_PEER , :ssl_client_cert => nil , :ssl_client_key => nil options [ :ssl_ca_file ] = @options [ :ssl_ca_file ] options [ :verify_ssl ] = @options [ :verify_ssl ] options [ :ssl_client_cert ] = @options [ :ssl_client_cert ] options [ :ssl_client_key ] = @options [ :ssl_client_key ]", "del_tokens": ":tenant => nil ,", "commit_type": "add"}
{"commit_tokens": ["Adds", "the", "possibility", "to", "supply", "a", "path", "to", "WebSite#url"], "add_tokens": "self . url = site_url . dup # @param [ String ] path Optional path to merge with the uri # def url ( path = '' ) @uri . join ( path ) . to_s", "del_tokens": "self . url = site_url def url @uri . to_s", "commit_type": "add"}
{"commit_tokens": ["Add", "github", "option", "to", "DSL", "."], "add_tokens": "def asset ( name , * args ) group = @current_group || default_group options = Hash === args . last ? args . pop . dup : { } version = args . last || \"latest\" options [ :git ] = \"git://github.com/#{options[:github]}\" if options [ :github ] end", "del_tokens": "def asset ( name , version = \"latest\" , options = { } ) group = @current_group ? @current_group : default_group end", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "checking", "Dry", "::", "Struct", "based", "implementations"], "add_tokens": "@parameters_for_comparison ||= begin return [ ] if present_in_schema? ParameterPairs . new ( parameters ) . for_comparison end @owner ||= begin return @klass if present_in_schema? implementation . owner end def present_in_schema? return false unless schema? @klass . schema . keys . include? ( @method_name ) end def schema? return false unless @klass . respond_to? ( :schema ) @klass . schema . respond_to? ( :keys ) end", "del_tokens": "@parameters_for_comparison ||= ParameterPairs . new ( parameters ) . for_comparison @owner ||= implementation . owner", "commit_type": "add"}
{"commit_tokens": ["fixed", "basic", "image", "resizing", "functionality"], "add_tokens": "message . gsub! ( / :minimum / , number_to_size ( minimum ) ) unless minimum == zero message . gsub! ( / :maximum / , number_to_size ( maximum ) ) unless maximum == infi # number_to_size(1) # 1 byte # number_to_size(2) # 2 bytes # number_to_size(1024) # 1 kilobyte # number_to_size(2048) # 2 kilobytes def number_to_size ( number , options = { } )", "del_tokens": "message . gsub! ( / :minimum / , number_to_human_size ( minimum ) ) unless minimum == zero message . gsub! ( / :maximum / , number_to_human_size ( maximum ) ) unless maximum == infi # number_to_human_size(1) # 1 byte # number_to_human_size(2) # 2 bytes # number_to_human_size(1024) # 1 kilobyte # number_to_human_size(2048) # 2 kilobytes def number_to_human_size ( number , options = { } )", "commit_type": "fix"}
{"commit_tokens": ["Add", "Chainable#merge", "to", "create", "new", "recurrence", "with", "merged", "options"], "add_tokens": "merge ( starts : starts_at ) merge ( until : ends_at ) merge ( between : date_range ) merge ( mday : days ) merge ( day : weekdays ) merge ( yday : days ) merge ( hour : hours ) merge ( month : months ) merge ( total : total ) merge ( week : weeks ) end def merge ( opts = { } ) branch default_options . merge ( opts )", "del_tokens": "branch default_options . merge ( starts : starts_at ) branch default_options . merge ( until : ends_at ) branch default_options . merge ( between : date_range ) branch default_options . merge ( mday : days ) branch default_options . merge ( day : weekdays ) branch default_options . merge ( yday : days ) branch default_options . merge ( hour : hours ) branch default_options . merge ( month : months ) branch default_options . merge ( total : total ) branch default_options . merge ( week : weeks )", "commit_type": "add"}
{"commit_tokens": ["add", "some", "trace", "support", "and", "a", "sensible", "error", "message", "for", "missing", "ids"], "add_tokens": "def trace message if trace_enabled? $stderr . puts \"[trace #{record}] #{message}\" end end def trace_enabled? ENV [ \"DSL_PLANNER_TRACE\" ] || ! ! @trace_enabled end def trace_enabled = enabled @trace_enabled = enabled end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "stub", "name", "in", "the", "specs"], "add_tokens": "before { described_class . stub ( :works? ) { true } }", "del_tokens": "before { described_class . stub ( :work? ) { true } }", "commit_type": "fix"}
{"commit_tokens": ["Adds", "a", "method", "to", "return", "arrays", "of", "homonyms", "at", "some", "rank", "."], "add_tokens": "# Return an Array of Generic \"Homonyms\" def homonyms_at_rank ( rank ) raise if ! RANKS . include? ( rank ) uniques = { } names_at_rank ( rank ) . each do | n | uniques [ n . name ] ||= [ ] uniques [ n . name ] . push n end uniques end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "map", "loading", "from", "xml", "strings", "and", "files"], "add_tokens": "def_delegators :@collection , :empty? , :any? , :length , :first , :[] , :count class << self def from_xml ( xml , strict = false , base_path = \"\" ) map = new ( 640 , 480 , \"\" ) __load_map_string__ ( map , xml , strict , base_path ) map end def from_file ( filename , strict = false ) map = new ( 640 , 480 , \"\" ) __load_map__ ( map , filename , strict ) map end end", "del_tokens": "def_delegators :@collection , :empty? , :any? , :length , :first", "commit_type": "add"}
{"commit_tokens": ["Implemented", "first", "feature", "getting", "the", "number", "of", "pages", "in", "a", "pdf", "."], "add_tokens": "# Slite is a module for reading a pdf and extracting the number of pages, # extracting a page and outputting as a png or jpeg, as well as exctracting # the text from a page in a pdf and returning it as a string. # # Default exception class for Slite. class Exception < :: StandardError end # Exception that is raised if pdf is not found. class PdfNotFound < Slite :: Exception end # Pdf class with instance methods for getting number of pages in a pdf, # extracting a page, and extracting the text from a page. # # For example: # # instance = Slite::Pdf.new(\"/path/to/pdf\") # page_count = instance.page_count # png = instance.page(1).to_png # jpeg = instance.page(2).to_jpeg(\"/path/to/save/jpeg\") # text = instance.page(3).text # class Pdf # initialize is called when a new instance is created and accepts path. def initialize ( path ) raise Slite :: PdfNotFound unless File . exists? ( path ) @path = path end # page_count is an instance method on Slite::Pdf. It uses the memoized # path and shells out to ghostscript to read the pdf with the pdf_info.ps # script as a filter, returning the number of pages in the pdf as an integer. # # For example: # # instance.page_count # => 4 # def page_count puts @path @page_count ||= begin ` gs -dNODISPLAY -q -sFile= #{ @path } ./lib/pdf_info.ps ` . to_i end end end end", "del_tokens": "# Your code goes here... end", "commit_type": "implement"}
{"commit_tokens": ["Added", "timestamp", "as", "default", "metadata", "."], "add_tokens": "@metadata = event_data . fetch ( :metadata , { timestamp : Time . now . utc } )", "del_tokens": "@metadata = event_data . fetch ( :metadata , nil )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "premature", "commit", "32beed0"], "add_tokens": "# Suppress a tooltip if you really want/need to... return if text == false", "del_tokens": "# Suppress a tooltip if you really want/need to... return if text == false", "commit_type": "update"}
{"commit_tokens": ["Use", "fail", "rather", "than", "raise"], "add_tokens": "fail \"Missing general:app_cache\" unless defined? $config [ 'general' ] [ 'app_cache' ] fail \"Missing general:s3_bucket\" unless defined? $config [ 'general' ] [ 's3_bucket' ] fail \"Missing general:gpg_disable\" unless defined? $config [ 'general' ] [ 'gpg_disable' ] fail \"Missing agent:puppetcode\" unless defined? $config [ 'agent' ] [ 'puppetcode' ]", "del_tokens": "raise \"Missing general:app_cache\" unless defined? $config [ 'general' ] [ 'app_cache' ] raise \"Missing general:s3_bucket\" unless defined? $config [ 'general' ] [ 's3_bucket' ] raise \"Missing general:gpg_disable\" unless defined? $config [ 'general' ] [ 'gpg_disable' ] raise \"Missing agent:puppetcode\" unless defined? $config [ 'agent' ] [ 'puppetcode' ]", "commit_type": "use"}
{"commit_tokens": ["Add", "hide", "helper", "to", "quickfields", "definer", ".", "Fix", "hidden", "fields", "rendering", "."], "add_tokens": "attr_accessor :required , :label , :initial , :error_messages , :widget , :hidden_widget , :show_hidden_initial , :help_text", "del_tokens": "attr_accessor :required , :label , :initial , :error_messages , :widget , :show_hidden_initial , :help_text", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "auto", "filters", "and", "some", "improvements", "to", "auto_width", "cell", "calculations", "."], "add_tokens": "assert ( @ws . send ( :auto_width , { :sz => 11 , :longest => \"fish\" } ) < @ws . send ( :auto_width , { :sz => 12 , :longest => \"fish\" } ) , \"larger fonts produce longer with with same string\" ) def test_auto_filter assert ( @ws . auto_filter . nil? ) assert_raise ( ArgumentError ) { @ws . auto_filter = 123 } @ws . auto_filter = \"A1:D9\" assert_equal ( @ws . auto_filter , \"A1:D9\" ) end", "del_tokens": "assert ( @ws . send ( :auto_width , { :sz => 12 , :longest => \"fish\" } ) > @ws . send ( :auto_width , { :sz => 11 , :longest => \"fish\" } ) , \"larger font size gets a longer auto_width using the same text\" )", "commit_type": "add"}
{"commit_tokens": ["use", "more", "modern", "hash", "form", "even", "for", "manifest"], "add_tokens": "manifestFile : 'MANIFEST.MF' # camel case reqd", "del_tokens": "'manifestFile' => 'MANIFEST.MF'", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "GetMedicationByTransId", "0", "."], "add_tokens": "result = magic ( magic_parameters ) if transaction_id == 0 || transaction_id == '0' # When transaction_id is 0 all medications should be # returned and the result should always be an array. if ! result . is_a? ( Array ) && ! result . empty? result = [ result ] elsif result . empty? result = [ ] end end result", "del_tokens": "magic ( magic_parameters )", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplicative", "commentary", "from", "README", "."], "add_tokens": "def self . send_message! ( payload , routing_key , on_error : :raise , delayed : false , delay_by : nil )", "del_tokens": "def self . send_message! ( payload , routing_key , on_error : :raise , delayed : false , delay_by : nil )", "commit_type": "remove"}
{"commit_tokens": ["Change", "target_index", "to", "lower", "-", "case"], "add_tokens": "# Change target_index to lower-case since Elasticsearch doesn't # allow upper-case characters in index names. target_index = target_index . downcase", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["Added", "docs", "and", "bump", "up", "version", "of", "use", "case", "support"], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "INSERT", "queries", "."], "add_tokens": "other . class == self . class && other . name == self . name", "del_tokens": "other . name == self . name", "commit_type": "add"}
{"commit_tokens": ["Improve", "efficiency", "of", "Cbc", "model", "creation"], "add_tokens": "# Store the index which will be used for each constraint constrs . each do | constr | constr . instance_variable_set :@index , @constr_count @constr_count += 1 end var . constraints . each do | constr | index << constr . instance_variable_get ( :@index ) value << constr . expression . terms [ var ] index = constr . instance_variable_get ( :@index )", "del_tokens": "constrs . each_with_index do | constr , row_index | # Find the coefficient for this variable or skip if none coeff = constr . expression . terms [ var ] next unless coeff index << row_index value << coeff index = @constr_count constr . instance_variable_set :@index , index @constr_count += 1", "commit_type": "improve"}
{"commit_tokens": ["Fix", "missing", "gadgets", "when", "two", "gadgets", "are", "too", "close"], "add_tokens": "call_regexp = \"#{call_str}.*<exec[^+]*>$\" cands = [ ] ` #{ objdump_cmd } |egrep ' #{ call_regexp } ' -B 30 ` . split ( '--' ) . each do | cand | lines = cand . lines . map ( & :strip ) . reject ( & :empty? ) # split with call_regexp loop do idx = lines . index { | l | l =~ / #{ call_regexp } / } break if idx . nil? cands << lines . shift ( idx + 1 ) . join ( \"\\n\" ) end", "del_tokens": "cands = ` #{ objdump_cmd } |egrep ' #{ call_str } .*<exec[^+]*>$' -B 30 ` . split ( '--' ) . map do | cand | cand . lines . map ( & :strip ) . reject ( & :empty? ) . join ( \"\\n\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "year", "and", "year", "-", "month"], "add_tokens": "end , 'http://www.w3.org/2001/XMLSchema#gYear' => lambda do | value , constraints | date_pattern = constraints [ \"datePattern\" ] || \"%Y\" d = Date . strptime ( value , date_pattern ) raise ArgumentError unless d . strftime ( date_pattern ) == value d end , 'http://www.w3.org/2001/XMLSchema#gYearMonth' => lambda do | value , constraints | date_pattern = constraints [ \"datePattern\" ] || \"%Y-%m\" d = Date . strptime ( value , date_pattern ) raise ArgumentError unless d . strftime ( date_pattern ) == value d end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Changed", "how", "degree", "(", "number", "of", "children", ")", "is", "calculated", ".", "Now", "it", "should", "be", "much", "faster"], "add_tokens": "include Enumerable attr_accessor :first_child , :last_child , :degree protected :next= , :prev= , :parent= , :first_child= , :last_child= , :degree= @degree = 0 alias arity degree @parent . degree += 1 @parent . degree += 1 @degree = 1 @degree = 1 @parent . degree -= 1 return false unless degree == other . degree", "del_tokens": "attr_accessor :first_child , :last_child protected :next= , :prev= , :parent= , :first_child= , :last_child= # Degree # # Returns the number of children of the node. def degree children . count end alias arity degree return other . leaf? if leaf?", "commit_type": "change"}
{"commit_tokens": ["Added", "enhanced", "to", "method", "and", "class", "definitions"], "add_tokens": "ConnectionAdapters :: OracleEnhancedAdapter . new OCI8EnhancedAutoRecover . new ( config ) , logger after_save :enhanced_write_lobs def enhanced_write_lobs #:nodoc: private :enhanced_write_lobs # RSI: changed select from user_tables to all_tables - much faster in large data dictionaries select_all ( \"select lower(table_name) from all_tables where owner = sys_context('userenv','session_user')\" ) . inject ( [ ] ) do | tabs , t | # RSI: changed select from all_constraints to user_constraints - much faster in large data dictionaries from user_constraints c , all_cons_columns cc # RSI: changed select from user_tables to all_tables - much faster in large data dictionaries select_all ( \"select table_name from all_tables where owner = sys_context('userenv','session_user')\" ) . inject ( s ) do | structure , table | # RSI: changed select from user_tables to all_tables - much faster in large data dictionaries select_all ( \"select table_name from all_tables where owner = sys_context('userenv','session_user')\" ) . inject ( s ) do | drop , table | alias :enhanced_define_a_column_pre_ar :define_a_column else enhanced_define_a_column_pre_ar i class OracleEnhancedConnectionFactory #:nodoc: class OCI8EnhancedAutoRecover < DelegateClass ( OCI8 ) #:nodoc: def initialize ( config , factory = OracleEnhancedConnectionFactory . new )", "del_tokens": "ConnectionAdapters :: OracleEnhancedAdapter . new OCI8AutoRecover . new ( config ) , logger after_save :write_lobs def write_lobs #:nodoc: private :write_lobs select_all ( \"select lower(table_name) from user_tables\" ) . inject ( [ ] ) do | tabs , t | from all_constraints c , all_cons_columns cc select_all ( \"select table_name from user_tables\" ) . inject ( s ) do | structure , table | select_all ( \"select table_name from user_tables\" ) . inject ( s ) do | drop , table | alias :define_a_column_pre_ar :define_a_column else define_a_column_pre_ar i class OracleConnectionFactory #:nodoc: class OCI8AutoRecover < DelegateClass ( OCI8 ) #:nodoc: def initialize ( config , factory = OracleConnectionFactory . new )", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "in", "refund", "method"], "add_tokens": "if order . calculate_net < ( order . amount_discounted || 0 ) || PaymentProcessor . refund ( order )", "del_tokens": "if order . calculate_net < order . amount_discounted || PaymentProcessor . refund ( order )", "commit_type": "fix"}
{"commit_tokens": ["fix", "spec", "to", "use", "relative", "urls"], "add_tokens": "@headlines = [ \"Webinar: How to Use Prescriber Checkup to Power Your Reporting\" , @most_commented_heds = [ [ \"Six Facts Lost in the IRS Scandal\" , \"How the IRSs Nonprofit Division Got So Dysfunctional\", \"Sound, Fury and the IRS Mess\" , \"The Most Important #Muckreads on Rape in the Military\" , \"Congressmen to Hagel: Where Are the Missing War Records?\" , \"As Need for New Flood Maps Rises, Congress and Obama Cut Funding\" , \"A Prosecutor, a Wrongful Conviction and a Question of Justice\" , \"A Prolonged Stay: The Reasons Behind the Slow Pace of Executions\" , @east_timor_prime_ministers = [ [ [ \"#\" , \"Portrait\" , \"Name(BirthDeath)\", \" erm of Office\", \" arty\", @searchResults = [ \"Webinar: How to Use Prescriber Checkup to Power Your Reporting\" , stub_request ( :get , \"www.example.com/discussion.html\" ) . to_return ( :body => File . new ( './spec/data/discussion.html' ) , :status => 200 ) stub_request ( :get , \"www.example.com/prosecutor.html\" ) . to_return ( :body => File . new ( './spec/data/prosecutor.html' ) , :status => 200 ) stub_request ( :get , \"www.example.com/webinar.html\" ) . to_return ( :body => File . new ( './spec/data/webinar.html' ) , :status => 200 ) stub_request ( :get , \"www.example.com/sixfacts.html\" ) . to_return ( :body => File . new ( './spec/data/sixfacts.html' ) , :status => 200 ) it 'should properly handle relative urls' do # Note: this test is a bit quirky, because it passes on the fact that it \"should sleep after uncached requests\" do it \"should be silent if verbose if false\" do", "del_tokens": "@headlines = [ \"Webinar: How to Use Prescriber Checkup to Power Your Reporting\" , @most_commented_heds = [ [ \"Six Facts Lost in the IRS Scandal\" , \"How the IRSs Nonprofit Division Got So Dysfunctional\", \"Sound, Fury and the IRS Mess\" , \"The Most Important #Muckreads on Rape in the Military\" , \"Congressmen to Hagel: Where Are the Missing War Records?\" , \"As Need for New Flood Maps Rises, Congress and Obama Cut Funding\" , \"A Prosecutor, a Wrongful Conviction and a Question of Justice\" , \"A Prolonged Stay: The Reasons Behind the Slow Pace of Executions\" , @east_timor_prime_ministers = [ [ [ \"#\" , \"Portrait\" , \"Name(BirthDeath)\", \" erm of Office\", \" arty\", @searchResults = [ \"Webinar: How to Use Prescriber Checkup to Power Your Reporting\" , it 'should properly handle relative urls' do # Note: this test is a bit quirky, because it passes on the fact that it \"should sleep after uncached requests\" do it \"should be silent if verbose if false\" do", "commit_type": "fix"}
{"commit_tokens": ["changed", "default", "storage", "to", "local"], "add_tokens": ":medium => :local ,", "del_tokens": ":medium => :aws ,", "commit_type": "change"}
{"commit_tokens": ["add", "possibility", "to", "define", "protocol", "when", "exposing", "ports"], "add_tokens": "node_port , container_port , protocol = p . split ( ':' ) node_port : node_port , protocol : protocol || 'tcp'", "del_tokens": "node_port , container_port = p . split ( ':' ) node_port : node_port", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "api", "endpoint", "default", "to", "production", "."], "add_tokens": "property :api_endpoint , :default => \"http://api.buildbox.io/v1\"", "del_tokens": "property :api_endpoint , :default => \"http://api.buildbox.dev/v1\"", "commit_type": "make"}
{"commit_tokens": ["made", "base_gravatar_url", "an", "alias", "shared", "by", "Gravatarify", "::", "Base"], "add_tokens": "base_gravatar_url send ( source || :email ) , options . merge ( params . first || { } ) base_gravatar_url send ( src ) , options . merge ( params . first || { } )", "del_tokens": "alias_method :gravatarify_url , :gravatar_url gravatarify_url send ( source || :email ) , options . merge ( params . first || { } ) gravatarify_url send ( src ) , options . merge ( params . first || { } )", "commit_type": "make"}
{"commit_tokens": ["Moved", "site", "access", "to", "Octopress", "module"], "add_tokens": "Page . new ( Octopress . site ( options ) , options ) . write Post . new ( Octopress . site ( options ) , options ) . write Draft . new ( Octopress . site ( options ) , options ) . write", "del_tokens": "Page . new ( CommandHelpers . site ( options ) , options ) . write Post . new ( CommandHelpers . site ( options ) , options ) . write Draft . new ( CommandHelpers . site ( options ) , options ) . write", "commit_type": "move"}
{"commit_tokens": ["Add", "static", "Bundle", "loading", "test"], "add_tokens": "if format == FHIR :: Formats :: ResourceFormat :: RESOURCE_XML || FHIR :: Formats :: FeedFormat :: FEED_XML elsif format == FHIR :: Formats :: ResourceFormat :: RESOURCE_JSON || FHIR :: Formats :: FeedFormat :: FEED_JSON", "del_tokens": "if format == FHIR :: Formats :: ResourceFormat :: RESOURCE_XML elsif format == FHIR :: Formats :: ResourceFormat :: RESOURCE_JSON elsif format == FHIR :: Formats :: FeedFormat :: FEED_XML || format == FHIR :: Formats :: FeedFormat :: FEED_JSON FHIR :: Bundle . new ( klass , response )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "simple", "plugin", "variable", "so", "I", "can", "track", "what", "s", "available", "at", "runtime", "."], "add_tokens": "App . plugins . push ConfigBlob", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["updated", "google", "wait", "behavior", "to", "avoid", "failures"], "add_tokens": "#wait 10 seconds times number of attempts squared in case of error sleep_time = 10 * ( attempts * attempts )", "del_tokens": "if response . body . downcase . index ( \"rate limit\" ) or response . body . downcase . index ( \"captcha\" ) if sleep_time sleep_time = sleep_time * attempts else sleep_time = ( rand * 100 ) . to_i end else sleep_time = 10 end", "commit_type": "update"}
{"commit_tokens": ["Fixed", "sorting", "to", "real", "line", "number", "not", "string", "sorting"], "add_tokens": "@screenshots = screenshots . sort_by { | i | i . line_number }", "del_tokens": "@screenshots = screenshots . sort_by { | i | i . file_with_line }", "commit_type": "fix"}
{"commit_tokens": ["Adds", "current_revision", "to", "hipchat", "message"], "add_tokens": "name = \"#{application}/#{branch}\" name += \" (revision #{current_revision[0..7]})\" if current_revision name", "del_tokens": "\"#{application}/#{branch}\"", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "configuration", "option", "for", "ebay_api_version", "."], "add_tokens": "'X-EBAY-API-COMPATIBILITY-LEVEL' => \"#{EbayTrading.configuration.ebay_api_version}\" ,", "del_tokens": "API_VERSION = 927 'X-EBAY-API-COMPATIBILITY-LEVEL' => \"#{API_VERSION}\" ,", "commit_type": "create"}
{"commit_tokens": ["Add", "None", "is", "always", "None", "and", "Some", "is", "always", "some", "spec", "examples"], "add_tokens": "it 'Some#to_s is \"Some(value)\"' do Some ( 123 ) . to_s . should == \"Some(123)\" end it 'None#to_s is \"None\"' do it 'None is always empty' do None . empty? . should be_true Maybe ( nil ) . empty? . should be_true end", "del_tokens": "it 'None to_s is \"None\"' do", "commit_type": "add"}
{"commit_tokens": ["use", "Arel", ".", "sql", "shortened", "name", "for", "SqlLiteral", "s"], "add_tokens": "table_name = Arel . sql ( unionized_name )", "del_tokens": "table_name = Arel :: Nodes :: SqlLiteral . new ( unionized_name )", "commit_type": "use"}
{"commit_tokens": ["Fix", "race", "-", "condition", "during", "vips", "load"], "add_tokens": "# allow to skip GI autoload $vips_skip_autoload ||= false def load_gi_module ( * argv ) log \"Vips::load_gi_module: #{argv}\" # Make sure we only get called once. def self . load_gi_module ; false ; end true # Initialize GI Vips :: load_gi_module unless $vips_skip_autoload", "del_tokens": "def const_missing ( name ) log \"Vips::const_missing: #{name}\" init ( ) if const_defined? ( name ) const_get ( name ) else super end end # @private def method_missing ( name , * args , & block ) log \"Vips::method_missing: #{name}, #{args}, #{block}\" init ( ) if respond_to? ( name ) __send__ ( name , * args , & block ) else super end end # @private def init ( * argv ) log \"Vips::init: #{argv}\" class << self remove_method ( :init ) remove_method ( :const_missing ) remove_method ( :method_missing ) end", "commit_type": "fix"}
{"commit_tokens": ["removing", "tempfile", "and", "output", "accessors", "and", "updating", "tests", "likewise", ".", "shouldnt", "affect", "anyone", "...", "hopefully!"], "add_tokens": "return if @tempfile . nil? File . unlink ( @tempfile . path )", "del_tokens": "return if tempfile . nil? File . unlink ( tempfile . path )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "support", "for", "retrieving", "segments", "for", "a", "list", "."], "add_tokens": "should \"get all segments for a client\" do segments . first . SegmentID . should == '46aa5e01fd43381863d4e42cf277d3a9' segments . first . Title . should == 'Segment One'", "del_tokens": "should \"get all segments\" do segments . first . Name . should == 'Segment One'", "commit_type": "add"}
{"commit_tokens": ["make", "whereabouts", "into", "a", "gem"], "add_tokens": "require 'rails' module Whereabouts module Rails class Railtie < :: Rails :: Railtie unless File . exist? ( 'app/models/address.rb' ) puts 'NOTICE: Please run rails generate address for whereabouts gem' end end end end", "del_tokens": "require 'active_record'", "commit_type": "make"}
{"commit_tokens": ["Add", "//", "=", "provide", "directive", "and", "Preprocessor#asset_paths"], "add_tokens": "attr_reader :environment , :output_file , :source_files , :asset_paths @asset_paths = [ ] elsif source_line . provide? provide_from_source_line ( source_line ) def provide ( asset_path ) return if ! asset_path || asset_paths . include? ( asset_path ) asset_paths << asset_path end def provide_from_source_line ( source_line ) provide asset_path_from ( source_line ) end def asset_path_from ( source_line ) source_line . source_file . find ( source_line . provide ) end", "del_tokens": "attr_reader :environment , :output_file , :source_files", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "history", "and", "version", "number", "for", "release"], "add_tokens": "VERSION = '0.0.2'", "del_tokens": "VERSION = '0.0.1'", "commit_type": "update"}
{"commit_tokens": ["Add", "license", "information", "to", "gemspec"], "add_tokens": "VERSION = '1.0.1' VERSION_ARRAY = VERSION . split ( '.' ) . map ( & :to_i ) # :nodoc:", "del_tokens": "VERSION = '1.0.0' VERSION_ARRAY = VERSION . split ( / \\. / ) . map { | x | x . to_i } # :nodoc:", "commit_type": "add"}
{"commit_tokens": ["Allow", "limit", "of", "1", "on", "queries"], "add_tokens": "# allow limit of 1 for has_one and Class.find :id query . where_id ( @index ) && ( query . limit . nil? || query . limit == 1 ) records = @base . record_cache [ :id ] . send ( :fetch_records , :: RecordCache :: Query . new ( { :id => ids } ) ) records = records [ 0 , query . limit ] unless query . limit . nil? || records . nil? records", "del_tokens": "query . where_id ( @index ) && query . limit . nil? @base . record_cache [ :id ] . send ( :fetch_records , :: RecordCache :: Query . new ( { :id => ids } ) )", "commit_type": "allow"}
{"commit_tokens": ["Update", "config", "to", "set", "Google", "as", "fallback"], "add_tokens": "attr_accessor :api_key def api = ( api ) @api = api . new end def api @api || LinkShrink :: Shrinkers :: Google . new end", "del_tokens": "attr_accessor :api_key , :api", "commit_type": "update"}
{"commit_tokens": ["Use", "a", "Symbol", "for", "@markup", "."], "add_tokens": "class_option :markdown , :type => :boolean , :default => false class_option :textile , :type => :boolean , :default => false @markup = if options . yard? if options . markdown? :markdown elsif options . text_tile? :textile else :rdoc end :rdoc", "del_tokens": "class_option :markup , :default => 'rdoc' @markup = if options . rdoc? 'rdoc' options . markup", "commit_type": "use"}
{"commit_tokens": ["update", "tests", "for", "new", "mocha"], "add_tokens": "require 'mocha/setup'", "del_tokens": "require 'mocha'", "commit_type": "update"}
{"commit_tokens": ["remove", "extraneous", "comments", "and", "some", "minor", "tweaks", "to", "reduce", "warnings"], "add_tokens": "attr_writer :aliases \"<#{@name}>\" if ( defined? ( @name ) && @name ) # is this definition for a prefix? # Is this definition the unity definition? # @return [Boolean] self . prefix? && self . scalar == 1", "del_tokens": "attr_accessor :name attr_accessor :aliases \"<#{@name}>\" if @name # display name is the first one in the alias array # @todo make this customizable and used (see issue #28) # @return [String] # def display_name # aliases.first # end self . prefix? && self . numerator == Unit :: UNITY_ARRAY && self . denominator == Unit :: UNITY_ARRAY # Define this unit. Registers it, but won't actually be used until Unit.setup is called # @return (see Unit.define) def define Unit . define ( self ) end # Define and register this unit # @return (see Unit.define!) def define! Unit . define! ( self ) end", "commit_type": "remove"}
{"commit_tokens": ["added", "routes", "and", "gem", "requirements"], "add_tokens": "# gems needed config . gem \"table_fu\" , :version => '>= 0.0.1' config . gem 'mislav-will_paginate' , :version => '>= 2.3.8' , :lib => 'will_paginate' , :source => 'http://gems.github.com'", "del_tokens": "# Be sure to restart your server when you modify this file # Specifies gem version of Rails to use when vendor/rails is not present # Bootstrap the Rails environment, frameworks, and default configuration # Settings in config/environments/* take precedence over those specified here. # Application configuration should go into files in config/initializers # -- all .rb files in that directory are automatically loaded. # Add additional load paths for your own custom dirs # config.load_paths += %W( #{RAILS_ROOT}/extras ) # Specify gems that this application depends on and have them installed with rake gems:install # config.gem \"bj\" # config.gem \"hpricot\", :version => '0.6', :source => \"http://code.whytheluckystiff.net\" # config.gem \"sqlite3-ruby\", :lib => \"sqlite3\" # config.gem \"aws-s3\", :lib => \"aws/s3\" # Only load the plugins named here, in the order given (default is alphabetical). # :all can be used as a placeholder for all plugins not explicitly named # config.plugins = [ :exception_notification, :ssl_requirement, :all ] # Skip frameworks you're not going to use. To use Rails without a database, # you must remove the Active Record framework. # Activate observers that should always be running # config.active_record.observers = :cacher, :garbage_collector, :forum_observer # Set Time.zone default to the specified zone and make Active Record auto-convert to this zone. # Run \"rake -D time\" for a list of tasks for finding time zone names. # The default locale is :en and all translations from config/locales/*.rb,yml are auto loaded. # config.i18n.load_path += Dir[Rails.root.join('my', 'locales', '*.{rb,yml}')] # config.i18n.default_locale = :de", "commit_type": "add"}
{"commit_tokens": ["move", "sablon", "executable", "to", "exe", "/", "."], "add_tokens": "@executable_path = @base_path + '../exe/sablon'", "del_tokens": "@executable_path = @base_path + '../bin/sablon'", "commit_type": "move"}
{"commit_tokens": ["Fixed", "specs", "for", "callable", "default", "value"], "add_tokens": "it \"should be evaluate attribute value every time\" do another_object = model . new object . attribute . should_not be_equal ( another_object . attribute )", "del_tokens": "let ( :another_object ) { model . new } it \"should be evaluate attribute value every time\" do object . attribute . should < another_object . attribute", "commit_type": "fix"}
{"commit_tokens": ["Change", "CharSet", "to", "inherit", "from", "regular", "Set", "."], "add_tokens": "class CharSet < Set", "del_tokens": "class CharSet < SortedSet", "commit_type": "change"}
{"commit_tokens": ["fix", "some", "typos", "in", "ONIX", "::", "APAProduct"], "add_tokens": "if composite . nil? if composite . nil? composite ? composite . imprint_name : nil composite . nil? ? nil : composite . imprint_name composite . nil? ? nil : composite . supplier_name composite . nil? ? nil : composite . telephone_number composite . nil? ? nil : composite . fax_number composite . nil? ? nil : composite . email_address composite . nil? ? nil : composite . supply_to_country", "del_tokens": "if compsite . nil? if compsite . nil? if compsite . nil? nil else composite . imprint_name end compsite . nil? ? nil : composite . imprint_name compsite . nil? ? nil : composite . supplier_name compsite . nil? ? nil : composite . telephone_number compsite . nil? ? nil : composite . fax_number compsite . nil? ? nil : composite . email_address compsite . nil? ? nil : composite . supply_to_country", "commit_type": "fix"}
{"commit_tokens": ["implement", "remove_profile_avatar", "by", "removing", "all", "profile", "pictures"], "add_tokens": "# Warning: it removes all Page's profile pictures # The Marketing API should be enabled for the APP to use this feature # A publish_pages permission is required. profile_pictures = page_client . get_connections ( 'me' , 'photos' , type : 'profile' ) page_client . batch do | batch | profile_pictures . each { | picture | batch . delete_object ( picture [ 'id' ] ) } end", "del_tokens": "raise_not_implemented_error #TODO: implement removing the page's avatar image (aka image/logo/icon)", "commit_type": "implement"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.1.8\"", "del_tokens": "VERSION = \"0.1.7\"", "commit_type": "change"}
{"commit_tokens": ["add", "tests", "for", "the", "Contact", "module"], "add_tokens": "def find ( user_id ) member Podio . connection . get ( \"/contact/#{user_id}\" ) . body", "del_tokens": "def find ( id ) member Podio . connection . get ( \"/space/{id}\" ) . body", "commit_type": "add"}
{"commit_tokens": ["Allow", "storing", "additional", "information", "in", "file", "info"], "add_tokens": "response . headers . update ( info . headers ) info = Tus :: Info . new ( storage . read_info ( uid ) ) response . headers . update ( info . headers ) response . headers . update ( info . headers )", "del_tokens": "response . headers . update ( info . to_h ) info = storage . read_info ( uid ) response . headers . update ( info . to_h ) response . headers . update ( info . to_h )", "commit_type": "allow"}
{"commit_tokens": ["Changed", "to", "||", "=", "where", "needed", "."], "add_tokens": "@lib [ :before ] ||= lambda { | * _args | } @lib [ :after ] ||= lambda { | * _args | }", "del_tokens": "@lib [ :before ] = lambda { | * _args | } unless @lib [ :before ] @lib [ :after ] = lambda { | * _args | } unless @lib [ :after ]", "commit_type": "change"}
{"commit_tokens": ["Fixed", "requires", "for", "a", "couple", "tests"], "add_tokens": "require 'archive/zip/codec/store'", "del_tokens": "require 'archive/zip/codec/deflate'", "commit_type": "fix"}
{"commit_tokens": ["Add", "yard", "-", "activesupport", "-", "concern"], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "add"}
{"commit_tokens": ["Use", "attribute", "instead", "of", "attribute", "in", "errors"], "add_tokens": "\"`#{key}' #{error}\"", "del_tokens": "\"`#{key}` #{error}\"", "commit_type": "use"}
{"commit_tokens": ["Make", "subscriptions", "work", "for", "non", "-", "lowercase", "hexstrings", "."], "add_tokens": "signature . downcase == \"sha1=#{hmac}\"", "del_tokens": "signature == \"sha1=#{hmac}\"", "commit_type": "make"}
{"commit_tokens": ["Add", "streaming", "classes", "Support", "streaming", "of", "zip", "gzip", "encrypted", "files", "user", "define", "-", "able", "formats", "etc", "."], "add_tokens": "autoload :Streams , 'rocket_job/streams'", "del_tokens": "module Reader autoload :Zip , 'rocket_job/reader/zip' end module Writer autoload :Zip , 'rocket_job/writer/zip' end", "commit_type": "add"}
{"commit_tokens": ["move", "file", "logging", "to", "prepare_file"], "add_tokens": "files . flatten . each do | file | update_file ( file ) do | text | text = yield text , @data , file text . sub ( log \"file: #{file}\"", "del_tokens": "files . flatten . each do | f | log \"file: #{file}\" update_file ( f ) do | t | t = yield t , @data , f t . sub (", "commit_type": "move"}
{"commit_tokens": ["added", "a", "way", "to", "generate", "a", "second", "slip", "for", "a", "contribution"], "add_tokens": "class SlipController < CatarsePagarme :: ApplicationController def update transaction = SlipTransaction . new ( permitted_attributes , contribution ) . charge! render text : transaction . boleto_url end", "del_tokens": "class SlipController < ApplicationController", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "automatic", "pagination", "traversal"], "add_tokens": "class Collection include Enumerable # Given a hash and client, will create an Enumerator that will lazily # request Salesforce for the next page of results. @client = client @size = hash [ 'totalSize' ] @pages = Enumerator . new do | ps | ps << hash next_page_url = hash [ 'nextRecordsUrl' ] until next_page_url . nil? response = @client . get ( next_page_url ) ps << response . body next_page_url = response [ 'nextRecordsUrl' ] end end end # Return the size of the Collection without making any additional requests. def size @size alias_method :length , :size # Yeild each value on each page. def each @pages . each do | page | Restforce :: Mash . build ( page [ 'records' ] , @client ) . each do | record | yield record end end # Cache to_a so that we don't have to make the same request twice. def to_a @to_a ||= super end", "del_tokens": "class Collection < Array attr_reader :total_size , :next_page_url @client = client @total_size = hash [ 'totalSize' ] @next_page_url = hash [ 'nextRecordsUrl' ] super ( Restforce :: Mash . build ( hash [ 'records' ] , @client ) ) def next_page response = @client . get next_page_url response . body", "commit_type": "add"}
{"commit_tokens": ["fix", "union", "option", "issue", "on", "select_row_to_json", "and", "varaible", "name", "issue", "on", "pipe_cte_with!"], "add_tokens": "options = json_object_options ( args ) . except ( :values , :value ) build_row_to_json ( ** options , & block ) def build_row_to_json ( from : , key : key_generator , col_alias : nil , cast_to_array : false ) row_to_json = Arel :: Nodes :: RowToJson . new ( double_quote ( key ) ) dummy_table = from_clause_constructor ( from , key ) . select ( row_to_json )", "del_tokens": "build_row_to_json ( args . delete ( :from ) . tap ( & method ( :pipe_cte_with! ) ) , args . delete ( :key ) || key_generator , args . delete ( :as ) , ! ( ! args . delete ( :cast_as_array ) ) , & block ) def build_row_to_json ( from , top_lvl_key , col_alias , cast_to_array ) row_to_json = Arel :: Nodes :: RowToJson . new ( double_quote ( top_lvl_key ) ) dummy_table = from_clause_constructor ( from , top_lvl_key ) . select ( row_to_json )", "commit_type": "fix"}
{"commit_tokens": ["fix", "role", "revocation", "semantis", "and", "finish", "grant", "specs"], "add_tokens": "puts \"planning grant #{record}\" member_role = if grant . member . kind_of? ( Conjur :: DSL2 :: Types :: Member ) grant . member . role else grant . member end given_grants [ scoped_roleid ( role ) ] . push [ scoped_roleid ( member_role ) , grant . admin_option ] puts \"roles are #{roles}\" puts \"replace on #{record} is #{record.replace}\" puts \"grant with replace: #{record}, #{given}, #{requested}\"", "del_tokens": "given_grants [ scoped_roleid ( role ) ] . push [ grant . member . roleid , grant . admin_option ]", "commit_type": "fix"}
{"commit_tokens": ["use", "random", "GUIDs", "when", "sending", "messages"], "add_tokens": "require 'securerandom' :source_guid => SecureRandom . uuid ,", "del_tokens": ":source_guid => Time . now . to_s ,", "commit_type": "use"}
{"commit_tokens": ["Add", "apikey", "to", "notify", "log"], "add_tokens": "Bugsnag . log ( \"Notifying #{endpoint} of #{@exceptions.last.class} from api_key #{@configuration.api_key}\" )", "del_tokens": "Bugsnag . log ( \"Notifying #{endpoint} of #{@exceptions.last.class}\" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "tag_dispatching_name", "at", "instance", "level"], "add_tokens": "include Dialect :: Dispatching :: ClassMethods", "del_tokens": "include Dialect :: Dispatching", "commit_type": "remove"}
{"commit_tokens": ["Adding", "support", "to", "select", "a", "table", "row", "and", "ask", "for", "its", "state"], "add_tokens": "STATE_SYSTEM_SELECTED = 0x00000002 STATE_SYSTEM_CHECKED = 0x00000010", "del_tokens": "STATE_SYSTEM_CHECKED = 0x00000010", "commit_type": "add"}
{"commit_tokens": ["Fixed", "include", "string", "resolution", "."], "add_tokens": "fqns = find_fully_qualified_namespace ( name , root ) unless fqns . nil? nodes = get_namespace_nodes ( fqns ) #nodes.each { |n| get_include_strings_from ( * nodes ) . each { | i | result += yard . get_constants ( i , root ) } #} end return @file_nodes . values if fqns == '' next unless node . kind_of? ( AST :: Node ) #if node.kind_of?(AST::Node) arr . push unpack_name ( node . children [ 2 ] ) if ( node . type == :send and node . children [ 1 ] == :include ) #if n.kind_of?(AST::Node) # arr.push unpack_name(n.children[2]) if (n.type == :send and n.children[1] == :include) arr += get_include_strings_from ( n ) if n . kind_of? ( AST :: Node ) and n . type != :class and n . type != :module #end #end", "del_tokens": "return [ @file_nodes . values ] if fqns == '' if node . kind_of? ( AST :: Node ) if n . kind_of? ( AST :: Node ) arr . push unpack_name ( n . children [ 2 ] ) if ( n . type == :send and n . children [ 1 ] == :include ) arr += get_include_strings_from ( n ) if n . type != :class and n . type != :module end end", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "worker", "middleware", "modules", "."], "add_tokens": "around_perform ( job ) { perform ( job ) } # Allow middleware modules to be mixed in and override the # definition of around_perform while providing a default # implementation so our code can assume the method is present. include Module . new { def around_perform ( job ) yield end }", "del_tokens": "perform ( job )", "commit_type": "add"}
{"commit_tokens": ["Remove", "deprecated", "usages", "of", "has_command!"], "add_tokens": "cmd = Quickl . has_subcommand! ( self . class . super_command , args . first ) end # class Delegator", "del_tokens": "cmd = has_command! ( args . first , self . class . super_command ) end # class Delegator", "commit_type": "remove"}
{"commit_tokens": ["Added", "more", "specs", "for", "JsonValue", "and", "subclasses"], "add_tokens": "describe Jsonify :: JsonTrue do it 'should have a value of true' do Jsonify :: JsonTrue . new . evaluate . should == 'true' end end describe Jsonify :: JsonFalse do it 'should have a value of false' do Jsonify :: JsonFalse . new . evaluate . should == 'false' end end describe Jsonify :: JsonNull do it 'should have a value of true' do Jsonify :: JsonNull . new . evaluate . should == 'null' end end describe Jsonify :: JsonNumber do it 'should accept an integer' do Jsonify :: JsonNumber . new ( 1 ) . evaluate . should == 1 end it 'should accept a float' do Jsonify :: JsonNumber . new ( 1.23 ) . evaluate . should == 1.23 end end describe Jsonify :: JsonString do it 'should quote the value' do Jsonify :: JsonString . new ( 'foo' ) . evaluate . should == \"\\\"foo\\\"\" end it 'should encode unicode' do unicode = 'goober' . concat ( 16 ) Jsonify :: JsonString . new ( unicode ) . evaluate . should == \"\\\"goober\\\\u0010\\\"\" end end", "del_tokens": "# pair.value.should ==", "commit_type": "add"}
{"commit_tokens": ["Remove", "rescue", "of", "loaderror", "in", "ping", "scout", "as", "it", "is", "now", "obsolete"], "add_tokens": "require 'net/ping/external'", "del_tokens": "begin require 'net/ping/external' rescue LoadError => e puts \"Please install net-ping gem: gem install net-ping\" . raise end", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "custom", "to_s", "to", "Region", "and", "Size", "."], "add_tokens": "def to_s \"<GosuEnhanced::Size #{width}x#{height}>\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "more", "error", "types", "in", "fetch", "list"], "add_tokens": "class URLParseError < StandardError ; end class FetchDocError < StandardError ; end rescue Exception => e raise URLParseError , e . message def fetch_doc rescue Exception => e raise FetchDocError , e . message fetch_doc @list += send ( \"parse_#{@type}\" ) def parse_album def parse_showcollect def parse_artist def parse_song [ @uri . to_s ] end", "del_tokens": "rescue raise \"URL parse error\" def get_doc get_doc if type = :song @list << @uri . to_s else @list += \"parse_#{}\" end def parse_album ( doc ) def parse_showcollect ( doc ) def parse_artist ( doc )", "commit_type": "add"}
{"commit_tokens": ["Make", "file", "cleanup", "more", "robust"], "add_tokens": "FileUtils . remove_entry ( directory_path ) if File . exist? ( directory_path )", "del_tokens": "FileUtils . remove_entry ( directory_path )", "commit_type": "make"}
{"commit_tokens": ["Add", "external", "logging", "to", "plugin", "commands"], "add_tokens": "# * options: Hash of options, valid keys: # * version: Particular version to install (optional, # * log: Whether to log the output (optional, defaults # to false) def install ( plugin_name , options = { } ) options = { :log => false , :version => nil } . merge ( options ) version = options [ :version ] log_block = options [ :log ] ? shell_log_block : nil instance . execute! * command , & log_block def uninstall ( plugin_name , options = { } ) options = { :log => false } . merge ( options ) log_block = options [ :log ] ? shell_log_block : nil instance . execute! :plugin , \"uninstall\" , plugin_name , & log_block def update ( plugin_name , options = { } ) options = { :log => false } . merge ( options ) log_block = options [ :log ] ? shell_log_block : nil instance . execute! :plugin , \"update\" , plugin_name , & log_block private # A block that can be passed to #execute to log the output def shell_log_block Proc . new do | line | logger ( :type => :external ) . info line end end memoize :shell_log_block", "del_tokens": "# * version: Particular version to install (optional, def install ( plugin_name , version = nil ) instance . execute! * command def uninstall ( plugin_name ) instance . execute! :plugin , \"uninstall\" , plugin_name def update ( plugin_name ) instance . execute! :plugin , \"update\" , plugin_name", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "specs", "for", "abstract", "parameter"], "add_tokens": "required : 'true' , param = abstract_param_class . new ( { required : 'true' } ) it \"should throw error if repeat is not 'true' or 'false'\" do expect { abstract_param_class . new ( { repeat : 111 } ) } . to raise_error ( Raml :: AttributeMustBeTrueOrFalse ) end it \"should throw error if required is not 'true' or 'false'\" do expect { abstract_param_class . new ( { required : 111 } ) } . to raise_error ( Raml :: AttributeMustBeTrueOrFalse ) end", "del_tokens": "required : true , param = abstract_param_class . new ( { required : true } )", "commit_type": "add"}
{"commit_tokens": ["Making", "associations", "behave", "a", "little", "bit", "more", "like", "one", "would", "expect"], "add_tokens": "@associations ||= { } @associations [ name ] ||= Dynamoid :: Associations . const_get ( type . to_s . camelcase ) . new ( self , name , options ) @associations [ name ] . setter ( objects )", "del_tokens": "self . send ( name ) << objects", "commit_type": "make"}
{"commit_tokens": ["Add", "sorting", "in", "a", "few", "place", "where", "tests", "were", "failing", "using", "postgres"], "add_tokens": "for node in nodes . sort_by { | n | n . left } named_scope :roots , :conditions => { :parent_id => nil } , :order => \"#{nested_set_column(:left)} asc\" has_many :children , :class_name => self . name , :foreign_key => :parent_id , :order => \"#{nested_set_column(:left)} asc\" belongs_to :parent , :class_name => self . name , :foreign_key => :parent_id delegate :nested_set_column , :to => \"self.class\"", "del_tokens": "base . delegate :nested_set_column , :to => \"self.class\" for node in nodes named_scope :roots , :conditions => { :parent_id => nil } has_many :children , :class_name => self . name , :foreign_key => :parent_id belongs_to :parent , :class_name => self . name , :foreign_key => :parent_id", "commit_type": "add"}
{"commit_tokens": ["Update", "spec", "to", "Rspec", "3", "format"], "add_tokens": "require 'aruba/rspec' run_simple ( \"#{yamllint_bin} #{args}\" , fail_on_error : false )", "del_tokens": "require 'aruba/api' run_simple ( \"#{yamllint_bin} #{args}\" , false )", "commit_type": "update"}
{"commit_tokens": ["Add", "autocommit", "prefix", "on", "release", "commits"], "add_tokens": "VERSION = '0.9.16' # Automatically updated by util/create-release.rb", "del_tokens": "VERSION = '0.9.15' # Automatically updated by util/create-release.rb", "commit_type": "add"}
{"commit_tokens": ["Add", "Renderer", "and", "FieldExpander", "."], "add_tokens": "class CollectionView < View def initialize ( name , schema , member_view = nil ) super ( name , schema ) if member_view @contents = member_view . contents . clone collection = 3 . times . collect do | i | subcontext = context + [ \"at(#{i})\" ] self . schema . example ( subcontext ) end self . render ( collection , ** opts ) super . merge ( type : :collection )", "del_tokens": "class CollectionView attr_reader :name , :schema , :using def initialize ( name , schema , using ) @name = name @schema = schema @using = using end def dump ( collection , context : Attributor :: DEFAULT_ROOT_CONTEXT , ** opts ) collection . collect . with_index do | object , i | subcontext = context + [ \"at(#{i})\" ] using . dump ( object , context : subcontext , ** opts ) collection = self . schema . example ( context ) self . dump ( collection , opts ) using . describe . merge ( type : :collection )", "commit_type": "add"}
{"commit_tokens": ["Add", "helper", "functions", "for", "index", "initialization"], "add_tokens": "context = { :page_presenter => page_presenter , :collection => collection , :fullCalendarOptions => nil } render :partial => \"calendar\" , locals : { events : events , options : context [ :fullCalendarOptions ] . to_json . html_safe }", "del_tokens": "context = { :page_presenter => page_presenter , :collection => collection } # Builds default events array for collection if page_presenter.block returns no data if events . blank? events = collection . map do | item | { id : item . id , title : item . to_s , start : item . created_at . blank? ? Date . today . to_s : item . created_at , url : \"#{auto_url_for(item)}\" } end end render :partial => \"calendar\" , locals : { events : events , options : context [ :fullCalendar_options ] . to_json . html_safe }", "commit_type": "add"}
{"commit_tokens": ["change", "version", "to", "reflect", "alpha", "state"], "add_tokens": "VERSION = \"0.1.0.pre.1\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "change"}
{"commit_tokens": ["Add", "picture", ".", "rb", "head", "comments"], "add_tokens": "# Authors: Rob Wierzbowski : @robwierzbowski # Justin Reese : @justinxreese # Welch Canavan : @xiwcx # # Description: # Download: https://github.com/robwierzbowski/jekyll-picture-tag # Documentation: https://github.com/robwierzbowski/jekyll-picture-tag/readme.md # # Syntax: {% picture [preset] path/to/img.jpg [source_key: path/to/alt-img.jpg] [attr=\\\"value\\\"] %} # Example: {% picture tree.jpg alt=\"Banyan tree\" %} # {% picture gallery tree.jpg source_small: tree_portrait.jpg alt=\"Banyan tree\" class=\"gal-img\" data-selected %}", "del_tokens": "# Authors: # Download: # Documentation: # Syntax: # Example: # Output: ### ruby 1.9+", "commit_type": "add"}
{"commit_tokens": ["Fix", "tree", "specs", "for", "quirks", "and", "changed", "tree", "api"], "add_tokens": "expect ( @keytree . include? ( key ) ) . to be_truthy it 'includes key prefixes' do expect ( @keytree . include? ( key ) ) . to be_falsey expect ( @keytree . to_h ( stringify_keys : true ) ) . to eq @str_hash", "del_tokens": "expect ( @keytree ) . to include ( key ) it 'does not include key prefixes' do expect ( @keytree ) . not_to include ( key ) expect ( @keytree . to_h ( string_keys : true ) ) . to eq @str_hash", "commit_type": "fix"}
{"commit_tokens": ["Use", "poise_archive", "for", "the", "unpacking", "."], "add_tokens": "@unpack_archive ||= poise_archive new_resource . cache_path do # Run via notification from #download_archive and #create_directory. destination new_resource . path strip_components new_resource . strip_components", "del_tokens": "install_utils unless node . platform_family? ( 'mac_os_x' , 'windows' , 'aix' ) def install_utils package [ ] . tap { | utils | # If we're using a custom tar, we shouldn't try to install it. utils << node . value_for_platform_family ( default : 'tar' , solaris2 : 'gnu-tar' ) if new_resource . cache_path =~ / \\. t(ar|gz|bz|xz) / && new_resource . tar_path . nil? unless node . platform_family? ( 'solaris2' ) utils << 'bzip2' if new_resource . cache_path =~ / \\. t?bz / # This probably won't work on RHEL? utils << 'xz-utils' if new_resource . cache_path =~ / \\. t?xz / end } end # Build up the unpack command. Someday this will probably need to # support unzip too. cmd = [ new_resource . tar_path || node . value_for_platform_family ( default : 'tar' , solaris2 : '/usr/gnu/bin/tar' ) ] cmd << \"--strip-components=#{new_resource.strip_components}\" if new_resource . strip_components && new_resource . strip_components > 0 cmd << if new_resource . cache_path =~ / \\. t?gz / '-xzvf' elsif new_resource . cache_path =~ / \\. t?bz / '-xjvf' elsif new_resource . cache_path =~ / \\. t?xz / '-xJvf' else '-xvf' end cmd << new_resource . cache_path @unpack_archive ||= execute 'unpack archive' do # Run via notification from #download_archive. command cmd cwd new_resource . path", "commit_type": "use"}
{"commit_tokens": ["Add", "export", "path", "on", "guest", "machine"], "add_tokens": "method_option 'guest_export_dir' , desc : 'Change the ouput directory on the host' , aliases : %w( -i ) , default : nil type : :string , build . run = [ 'sh' , '-e' , '-c' , options . run ] unless options . run . empty? source_export_dir = options . guest_export_dir || build . export_dir fail 'export flag set but no export_dir given' if source_export_dir . nil? target_export_dir = options . export_dir || source_export_dir target_export_dir = File . dirname ( target_export_dir ) guest_export_dir = File . expand_path ( source_export_dir , CIDE_SRC_DIR ) host_export_dir = File . expand_path ( target_export_dir , Dir . pwd )", "del_tokens": "type : :array , export_dir = options . export_dir export_dir ||= File . dirname ( build . export_dir ) if build . export_dir build . run = options . run unless options . run . empty? fail 'export flag set but no export_dir given' if build . export_dir . nil? guest_export_dir = File . expand_path ( build . export_dir , CIDE_SRC_DIR ) host_export_dir = File . expand_path ( export_dir , Dir . pwd )", "commit_type": "add"}
{"commit_tokens": ["Add", "package", "delete_wait_until_ready", "method", "."], "add_tokens": "@package . delete_wait_until_ready ( )", "del_tokens": "@package . delete ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "convenience", "method", "to", "get", "kilometers", "instead", "of", "miles", "."], "add_tokens": "MILE_IN_KM = 1.609 attr_reader :estimated_battery_range_kilometers attr_reader :battery_range_kilometers ## # @method battery_range_kilometers # @return [Float] Rated kilometers for the current charge # @method estimated_battery_range_kilometers # @return [Float] Range estimated from current driving ## # @method estimated_battery_range_miles ## # @method charge_rate_kilometers_per_hour # @return [Float] Kilometers of range being added per hour require 'pry' ivar_from_data ( \"estimated_battery_range_miles\" , \"est_battery_range\" , data ) @battery_range_kilometers = ( battery_range_miles * MILE_IN_KM ) . round ( 2 ) @estimated_battery_range_kilometers = ( estimated_battery_range_miles * MILE_IN_KM ) . round ( 2 ) @ideal_battery_range_kilometers = ( ideal_battery_range_miles * MILE_IN_KM ) . round ( 2 )", "del_tokens": "# @method estimated_battry_range_miles ivar_from_data ( \"estimated_battry_range_miles\" , \"est_battery_range\" , data )", "commit_type": "add"}
{"commit_tokens": ["Improve", "polling", "adapter", "spec", "for", "JRuby"], "add_tokens": "listener . should_receive ( :on_change ) . at_least ( 1 ) . times . with ( listener . directory ) sleep 0.1 listener . should_receive ( :on_change ) . at_least ( 10 ) . times . with ( listener . directory ) sleep 0.1", "del_tokens": "listener . should_receive ( :on_change ) . with ( listener . directory ) sleep 0.001 listener . should_receive ( :on_change ) . exactly ( 7 ) . times . with ( listener . directory ) sleep 0.007", "commit_type": "improve"}
{"commit_tokens": ["making", "security_token", "fetch", "work", "with", "SSL"], "add_tokens": "headers = @mauth_signer . signed_headers ( :app_uuid => @app_uuid , :verb => 'GET' , :request_url => security_tokens_path ) http = Net :: HTTP . new ( security_tokens_url . host , security_tokens_url . port ) http . use_ssl = true request = Net :: HTTP :: Get . new ( security_tokens_url . path , headers ) response = http . start { | h | h . request ( request ) }", "del_tokens": "headers = @mauth_signer . signed_headers ( :app_uuid => @app_uuid , :verb => 'GET' , :request_url => security_tokens_path ) response = Net :: HTTP . start ( security_tokens_url . host , security_tokens_url . port ) { | http | http . get ( security_tokens_url . path , headers ) }", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "be_true", "matchers", "=", ">", "translated"], "add_tokens": "Spec :: Matchers . define matcher_be_true do match do | actual | ! ! actual end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Implement", "a", "more", "consistent", "way", "of", "extending", "database", "libraries"], "add_tokens": "module Tenacity module ClassMethods #:nodoc: def _t_find ( id ) def _t_find_bulk ( ids ) def _t_find_first_by_associate ( property , id ) def _t_find_all_by_associate ( property , id ) def _t_initialize_has_many_association ( association ) def _t_initialize_belongs_to_association ( association ) def _t_delete ( ids , run_callbacks = true ) end module InstanceMethods", "del_tokens": "begin require 'active_record' class Base #:nodoc: def self . _t_find ( id ) def self . _t_find_bulk ( ids ) def self . _t_find_first_by_associate ( property , id ) def self . _t_find_all_by_associate ( property , id ) def self . _t_initialize_has_many_association ( association ) def self . _t_initialize_belongs_to_association ( association ) def self . _t_delete ( ids , run_callbacks = true ) rescue LoadError # ActiveRecord not available", "commit_type": "implement"}
{"commit_tokens": ["Use", "less", "confusing", "naming", "convention", "for", "the", "taskrc", "model"], "add_tokens": "attr_reader :version , :data_location , :taskrc , @taskrc = get_rc", "del_tokens": "attr_reader :version , :data_location , :taskrc , :create_new , @config = get_rc", "commit_type": "use"}
{"commit_tokens": ["Make", "MismatchError", "a", "base", "Exception"], "add_tokens": "class MismatchError < Exception", "del_tokens": "class MismatchError < StandardError", "commit_type": "make"}
{"commit_tokens": ["allow", "additional", "arguments", "to", "be", "submitted", "through", "qsub"], "add_tokens": "params << headers . map do | k , v | param = ATTR . key ( k ) if param && param . length == 1 \" -#{param} '#{v}'\" else \" -W '#{k}=#{v}'\" end end . join ( \"\" )", "del_tokens": "params << headers . map { | k , v | \" -#{ATTR.key(k)} '#{v}'\" } . join ( \"\" )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "useless", "range", "on", "a", "string"], "add_tokens": "Scope . new ( nil , name . split ( '::' ) . last . capitalize , cloud )", "del_tokens": "Scope . new ( nil , name . to_s [ 0 .. - 1 ] . split ( '::' ) . last . capitalize , cloud )", "commit_type": "remove"}
{"commit_tokens": ["add", "information", "about", ":", "entry_mapping", "to", "README"], "add_tokens": "'cat' => Cat", "del_tokens": "'cat' => Cat ,", "commit_type": "add"}
{"commit_tokens": ["Added", "constants", "for", "the", "default", "host", "and", "port", "."], "add_tokens": "def initialize ( remote_host = DEFAULT_HOST , remote_port = DEFAULT_PORT )", "del_tokens": "def initialize ( remote_host = 'localhost' , remote_port = 1883 )", "commit_type": "add"}
{"commit_tokens": ["removing", "some", "files", "pages", "index", "looks", "better", "now"], "add_tokens": "# These also include initialized cms_blocks if present", "del_tokens": "# CmsPage has two collections: cms_tags and cms_blocks # These are two different collections for the same type of objects. # cms_tags derived from Layout content, cms_blocks are tags (subclasses of CmsBlock) # that are stored in the database for a particular page", "commit_type": "remove"}
{"commit_tokens": ["add", "method_missing", "to", "proxy", "all", "dsl", "methods"], "add_tokens": "# dsl methods are handled dynamically by this method_missing block def method_missing ( name , * args , & block ) __getobj__ . set_config name , args [ 0 ] , & block", "del_tokens": "# dsl methods # Set basename for the command line interface # # @param [String] basename # name of the top level command def basename ( basename ) set_config :basename , basename end # Set short description for the base command # # @param [String] description # short description for the base command def description ( description ) set_config :description , description end def handler ( handler ) set_config :handler , handler", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "parameter", "in", "error", "reporting", "for", "checking", "the", "amount"], "add_tokens": "@stderr . must_match / Failures \\( #{ n } \\) / @stderr . must_match / Failures \\( #{ n } \\) /", "del_tokens": "@stderr . must_match / Failures \\( 1 \\) / @stderr . must_match / Failures \\( 1 \\) /", "commit_type": "use"}
{"commit_tokens": ["Fix", "worker", "zombie", "methods", "and", "add", "tests"], "add_tokens": "count = 0 next unless worker . zombie? count += 1 count ( Time . now - heartbeat . updated_at ) >= dead_seconds", "del_tokens": "next unless zombie? ( Time . now - worker . heartbeat . updated_at ) >= dead_seconds", "commit_type": "fix"}
{"commit_tokens": ["Add", "mount", "method", "for", "Flame", "::", "RouteRefine", "(", "make", "recoursion", ")"], "add_tokens": "ctrl_routes = RouteRefine . new ( self , ctrl , path , block ) def initialize ( router , ctrl , path , block ) @router = router def mount ( ctrl , path = nil , & block ) path = path_merge ( @path , ( path || default_controller_path ) ) @router . add_controller ( ctrl , path , block ) end path_merge ( @path , path ) def path_merge ( * parts ) parts . join ( '/' ) . gsub ( %r{ \\/ {2,} } , '/' ) end", "del_tokens": "ctrl_routes = RouteRefine . new ( ctrl , path , block ) def initialize ( ctrl , path , block ) \"#{@path}/#{path}\" . gsub ( %r{ \\/ {2,} } , '/' )", "commit_type": "add"}
{"commit_tokens": ["Use", "accessor", "rather", "than", "direct", "variable", "access"], "add_tokens": "processes [ cmd ] . output processes [ cmd ] . stdout processes [ cmd ] . stderr processes . values . inject ( \"\" ) { | out , ps | out << ps . stdout } processes . values . inject ( \"\" ) { | out , ps | out << ps . stderr }", "del_tokens": "@processes [ cmd ] . output @processes [ cmd ] . stdout @processes [ cmd ] . stderr @processes . values . inject ( \"\" ) { | out , ps | out << ps . stdout } @processes . values . inject ( \"\" ) { | out , ps | out << ps . stderr }", "commit_type": "use"}
{"commit_tokens": ["Fix", "rubocop", "Style", "/", "AlignHash", "cop"], "add_tokens": "disableNotifications : disable_notifications , importUsersAsCollaborators : import_users_as_collaborators , projects : projects )", "del_tokens": "disableNotifications : disable_notifications , importUsersAsCollaborators : import_users_as_collaborators , projects : projects )", "commit_type": "fix"}
{"commit_tokens": ["moved", "library", "subclasses", "to", "separate", "files"], "add_tokens": "# order of library subclasses matters require 'boson/libraries/module_library' require 'boson/libraries/file_library' require 'boson/libraries/gem_library'", "del_tokens": "require 'boson/libraries'", "commit_type": "move"}
{"commit_tokens": ["Improves", "SQL", "write", "query", "parsing", "to", "not", "suppress", "this", "much", "entries", "in", "the", "Write", "table", "."], "add_tokens": "rails_root = options [ :log ] [ :rails_root ] || Rails . root . to_s if @body . blank? file_path = \"#{rails_root}/log/#{env}.log\" @body = nil # free memory return if @route . match ( / \" \\/ rails \\/ info.+\" / ) begin_reg_exp = \"\\\\[[0-9]+m *\" reg_exp = \"#{begin_reg_exp}((INSERT INTO|UPDATE|DELETE FROM)(.)+)$\" table_name = line . match ( \"(INSERT INTO|UPDATE|DELETE FROM) {1}`([a-zA-Z0-9_]+)`\" ) [ 2 ] if line . match ( \"#{begin_reg_exp}INSERT INTO( ){1}`(.{1,})`( ){1}(.)+$\" ) elsif line . match ( \"#{begin_reg_exp}UPDATE( ){1}`(.{1,})`( ){1}(.)+$\" ) elsif line . match ( \"#{begin_reg_exp}DELETE FROM( ){1}`(.{1,})`( ){1}(.)+$\" )", "del_tokens": "path = options [ :log ] [ :path ] || \"#{Rails.root}/log/\" unless @body file_path = \"#{path}#{env}.log\" reg_exp = / ([0-9]+)m( ){2}((INSERT INTO|UPDATE|DELETE FROM)(.)+)$ / table_name = line . match ( / (INSERT INTO|UPDATE|DELETE FROM) {1}`([a-zA-Z0-9_]+)` / ) [ 2 ] if line . match ( / ([0-9]+)m( ){2}INSERT INTO( ){1}`(.{1,})`( ){1}(.)+$ / ) elsif line . match ( / ([0-9]+)m( ){2}UPDATE( ){1}`(.{1,})`( ){1}(.)+$ / ) elsif line . match ( / ([0-9]+)m( ){2}DELETE FROM( ){1}`(.{1,})`( ){1}(.)+$ / )", "commit_type": "improve"}
{"commit_tokens": ["Add", "roles", "to", "client", "spec"], "add_tokens": "id : user_id , roles : [ { id : role_id , name : 'my_role' } ] } \"title\" => \"\" , \"role_ids\" => [ role_id . to_s ] let ( :role_id ) { 42 }", "del_tokens": "id : user_id } \"title\" => \"\"", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "the", "libgit2", "HEAD"], "add_tokens": "def sys ( cmd ) puts \" -- #{cmd}\" unless ret = xsystem ( cmd ) raise \"ERROR: '#{cmd}' failed\" end ret end if ` which make ` . strip . empty? STDERR . puts \"ERROR: GNU make is required to build Rugged\" exit ( 1 ) end CWD = File . expand_path ( File . dirname ( __FILE__ ) ) LIBGIT2_DIST = 'libgit2-libgit2-b0b2dd5.tar.gz' LIBGIT2_DIR = File . basename ( LIBGIT2_DIST , '.tar.gz' ) Dir . chdir ( \"#{CWD}/vendor\" ) do FileUtils . rm_rf ( LIBGIT2_DIR ) if File . exists? ( LIBGIT2_DIR ) sys ( \"tar zxvf #{LIBGIT2_DIST}\" ) Dir . chdir ( LIBGIT2_DIR ) do sys ( \"make -f Makefile.embed\" ) FileUtils . cp \"libgit2.a\" , \"#{CWD}/libgit2_embed.a\" end $INCFLAGS [ 0 , 0 ] = \" -I#{CWD}/vendor/#{LIBGIT2_DIR}/include \" $LDFLAGS << \" -L#{CWD} \" unless have_library 'git2_embed' and have_header 'git2.h' STDERR . puts \"ERROR: Failed to build libgit2\" exit ( 1 ) end", "del_tokens": "dir_config ( \"git2\" ) dir_config ( \"z\" ) def asplode ( missing ) abort <<-error #{missing} is missing, Try installing or compiling it first. You can provide configuration options to alternate places : - - with - git2 - dir = ... - - with - z - dir = ... error asplode ( 'libgit2' ) unless have_library ( \"git2\" ) asplode ( 'zlib' ) unless have_library ( 'z' ) $CFLAGS << ' -g -O0 ' $LDFLAGS << ' -g '", "commit_type": "update"}
{"commit_tokens": ["Adds", "to_external", "and", "to_connec", "support", "for", "complex", "entities"], "add_tokens": "if idmap && ( ( ! idmap . to_external ) || idmap . last_push_to_external && idmap . last_push_to_external > entity [ 'updated_at' ] ) # Not pushing entity to Connec! next nil unless idmap . to_connec", "del_tokens": "if idmap && idmap . last_push_to_external && idmap . last_push_to_external > entity [ 'updated_at' ]", "commit_type": "add"}
{"commit_tokens": ["Using", "bundler", "and", "upgraded", "to", "rspec2", "."], "add_tokens": "require \"rubygems\" require \"net/telnet\" require \"active_support/core_ext\" require \"lacquer/configuration\" require \"lacquer/cache_utils\" require \"lacquer/varnish\"", "del_tokens": "require 'rubygems' require 'net/telnet' require 'active_support/core_ext' require 'lacquer/configuration' require 'lacquer/cache_utils' require 'lacquer/varnish'", "commit_type": "use"}
{"commit_tokens": ["use", "method_source", "instead", "of", "sourcify"], "add_tokens": "require \"method_source\"", "del_tokens": "require \"ruby_parser\" require \"sourcify\"", "commit_type": "use"}
{"commit_tokens": ["Added", "Notifiers", "(", "Mail", ")", "to", "allow", "users", "to", "be", "notified", "by", "email", "when", "a", "backup", "succeeds", "or", "fails", "."], "add_tokens": "NOTIFIERS = [ 'Mail' ]", "del_tokens": "NOTIFIERS = [ ]", "commit_type": "add"}
{"commit_tokens": ["Move", "HTTP", "calls", "into", "separate", "thread", ".", "Include", "flush", "at", "exit", "."], "add_tokens": "puts 'Starting operation...' thread1 = Thread . new do for i in 1 .. 10 sleep ( 0.15 ) puts \"Logging event #{i}...\" span . log_event ( 'hello world' , count : i ) end end thread2 = Thread . new do current = 1 for i in 1 .. 16 child = LightStep . start_span ( 'my_child' , parent : span ) sleep ( 0.1 ) current *= 2 child . log_event ( \"2^#{i}\" , result : current ) child . finish end end [ thread1 , thread2 ] . each ( & :join ) puts span . generate_trace_url", "del_tokens": "span . log_event ( 'hello world' , 'count' => 42 ) sleep ( 0.1 ) child = LightStep . start_span ( 'my_child' , parent : span ) sleep ( 0.2 ) child . finish sleep ( 0.1 )", "commit_type": "move"}
{"commit_tokens": ["updated", "largeimagesreview", "script", "and", "the", "corresponding", "part", "in", "README", ".", "md"], "add_tokens": "[ sub , \"Total: #{group.size}\" , \"Quality: #{good * 100 / group.size}%\" , group . sort_by do | _ , resolution , | x , y = resolution . scan ( / \\d + / ) . map ( & :to_i ) x * y end . map do | status , | { \"approvelink\" => ?, \" emovelink\"=> ? }[st a t us] || ? end . join , ] widths = report . transpose . map { | column | column . map ( & :size ) . max } report . each do | row | puts [ row , widths , %i{ center ljust ljust ljust } ] . transpose . map { | string , width , alignment | \" #{string.send(alignment, width)} \" } . join end", "del_tokens": "[ sub , \"Total: #{group.size}\" , \"Quality: #{good * 100 / group.size}%\" ] require \"mll\" puts MLL :: grid [ report . take ( 20 ) , spacings : [ 3 , 0 ] ]", "commit_type": "update"}
{"commit_tokens": ["fixed", "rdoc", "typo", "for", "Hashie", "::", "Lash"], "add_tokens": "# Lashes are useful when you need to create a very simple", "del_tokens": "# Dashes are useful when you need to create a very simple", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "integration", "test", "too", "."], "add_tokens": "expect ( subject . stdout ) . to include 'Poise Profiler Timing:'", "del_tokens": "expect ( subject . stdout ) . to include 'Poise Profiler:'", "commit_type": "fix"}
{"commit_tokens": ["remove", "dependecy", "on", "Varint", "in", "encode", ".", "rb"], "add_tokens": "encode_varint ( w , v . length )", "del_tokens": "require 'beefcake/varint' require 'beefcake/lendel' Varint . encode ( w , v . length )", "commit_type": "remove"}
{"commit_tokens": ["add", "a", "few", "fixes", "and", "new", "mechanism", "to", "schedule", "periodic", "jobs", "in", "event", "machine"], "add_tokens": "sleep 0.1 until EventMachine . reactor_running? # XXX hack but needed def add_periodic_timer ( seconds , & bl ) @em_lock . synchronize { @em_jobs += 1 } # TODO move into block ? EventMachine . add_periodic_timer ( seconds , & bl ) end #@reactor_thread.join", "del_tokens": "@reactor_thread . join", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "select", "version"], "add_tokens": "def send_with ( email_id , to , data = { } , from = { } , cc = { } , bcc = { } , files = [ ] , esp_account = '' , version_name = '' ) if version_name payload [ :version_name ] = version_name end", "del_tokens": "def send_with ( email_id , to , data = { } , from = { } , cc = { } , bcc = { } , files = [ ] , esp_account = '' )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "clean", "up", "question", "settings", "."], "add_tokens": "if ! question . validation? || ( question . validation? &&", "del_tokens": "if ! question . validation || ( question . validation &&", "commit_type": "change"}
{"commit_tokens": ["add", "test", "for", "resort", "and", "refactor"], "add_tokens": "transaction do export_item_ids . each_with_index do | id , index | find ( id . gsub ( / [^0-9] / , '' ) ) . update_attribute ( :position , index + 1 ) end", "del_tokens": "export_item_ids . each_index do | index | position = index + 1 export_item = find ( export_item_ids [ index ] . gsub ( / [^0-9] / , '' ) ) export_item . update_attribute ( :position , position ) if export_item . position != position ####### #######", "commit_type": "add"}
{"commit_tokens": ["Added", "a", ":", "unique", "option", "to", "Sham", "to", "allow", "generating", "non", "-", "unique", "values", "."], "add_tokens": "@unique = options . has_key? ( :unique ) ? options [ :unique ] : true generate_values ( 12 ) generate_values ( 2 * @values . length ) @values = seeded { ( 1 .. count ) . map ( & @generator ) } @values . uniq! if @unique", "del_tokens": "@values = generate_values ( 12 ) @values = generate_values ( 2 * @values . length ) seeded { ( 1 .. count ) . map ( & @generator ) . uniq }", "commit_type": "add"}
{"commit_tokens": ["Fix", "equality", "bug", "in", "the", "Content", "class", "."], "add_tokens": "self . class :: ELEMENTS . collect { | el | self . instance_variable_get ( \"@#{el}\" ) == other . instance_variable_get ( \"@#{el}\" ) } . all? ) self . body == other . body )", "del_tokens": "self . class :: ELEMENTS . collect { | el | instance_variable_get ( \"@#{el}\" ) == other . instance_variable_get ( \"@#{el}\" ) } . all? ) other . body == other . body )", "commit_type": "fix"}
{"commit_tokens": ["add", "VERSION", "to", ".", "yardopts"], "add_tokens": "# Example format: 0.0.1 # # @return [String] the contents of the version file in #.#.# format", "del_tokens": "# VERSION example format: 0.0.1 # @return [String] version the contents of the version file in #.#.# format", "commit_type": "add"}
{"commit_tokens": ["added", "users", "and", "accounts", "model", "and", "initial", "users", "-", "show", "and", "accounts", "-", "list", "commands"], "add_tokens": "%w{ api servers images types zones cloud_ips users accounts config } . each do | f |", "del_tokens": "%w{ api servers images types zones cloud_ips users config } . each do | f |", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "of", "media_types", "which", "include", "a", "dot"], "add_tokens": "m = media_type . to_s . match ( / ^([a-z*]+) \\/ ([a-z* \\- \\. ]+)(?:;([a-z0-9=;]+))?$ / )", "del_tokens": "m = media_type . to_s . match ( / ^([a-z*]+) \\/ ([a-z*-]+)(?:;([a-z0-9=;]+))?$ / )", "commit_type": "fix"}
{"commit_tokens": ["fix", "rare", "cases", "where", "there", "is", "no", "campaign", "name", "found"], "add_tokens": "if is_campaign campaign ? campaign : \"(campaign) #{host}\" else host end", "del_tokens": "is_campaign ? campaign : host", "commit_type": "fix"}
{"commit_tokens": ["Add", "error", "handling", "for", "out", "-", "of", "-", "date", "versions", "of", "Pandata"], "add_tokens": "# Custom Pandata error class PandataError < StandardError end raise PandataError if Gem :: Version . new ( Pandata :: Version :: STRING ) <= Gem :: Version . new ( config [ 'required_update_for' ] ) raise PandataError , 'Pandora.com has changed something and you need to update Pandata!' end", "del_tokens": "raise error", "commit_type": "add"}
{"commit_tokens": ["Use", "Mistral", "workflows", "for", "node", "create", "and", "introspect"], "add_tokens": "def execute_workflow ( workflow , input , wait_for_complete = true ) connection = service ( 'Workflow' ) response = connection . create_execution ( workflow , input ) state = response . body [ 'state' ] workflow_execution_id = response . body [ 'id' ] return unless wait_for_complete while state == 'RUNNING' sleep 2 response = connection . get_execution ( workflow_execution_id ) state = response . body [ 'state' ] end if state != 'SUCCESS' raise \"Executing workflow #{workflow} on #{input} failed: #{response.body['output']}\" end workflow_execution_id end elsif service_name == 'Workflow' return Fog :: Workflow :: OpenStack . new ( fog_parameters )", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["Allow", "exposures", "to", "depend", "on", "each", "other", "based", "on", "parameter", "names"], "add_tokens": "require 'dry/view/exposures' exposures . add name , & block @exposures ||= Exposures . new self . class . exposures . locals ( options ) . merge ( options . fetch ( :locals , { } ) )", "del_tokens": "exposures << [ name , block ] @exposures ||= [ ] exposed_locals ( options ) . merge ( options . fetch ( :locals , { } ) ) def exposed_locals ( input ) self . class . exposures . each_with_object ( { } ) { | ( name , block ) , memo | memo [ name ] = block ? instance_exec ( input , & block ) : __send__ ( name , input ) } end", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "subresource", "method_missing", "to", "still", "return", "the", "resource", "object", ".", "Also", "allow", "passing", "in", "as", "a", "sub", "name", "to", "get", "just", "the", "parent", "name", "instead", "of", "parent", "::"], "add_tokens": "resource = [ ] # Used to break block context, non-local return sub_name = if name && ! name . empty? \"#{self.name}::#{name}\" else # If you pass in nil or '', you just get the parent name self . name end resource << super ( method_symbol , sub_name ) do parent ( self_ ) if respond_to? ( :parent ) # Return whatever we have resource . first", "del_tokens": "super ( method_symbol , \"#{self.name}::#{name}\" ) do parent ( self_ )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "problem", "with", "attributes", ":", "for", "and", "not", "safe", "join", "on", "attributes"], "add_tokens": "end . join . html_safe", "del_tokens": "end . join", "commit_type": "fix"}
{"commit_tokens": ["added", "new", "flags", "to", "plugsrv", "for", "tls"], "add_tokens": "VERSION = '0.6.10'", "del_tokens": "VERSION = '0.6.9'", "commit_type": "add"}
{"commit_tokens": ["Add", "comment", "for", "the", "LoggerMiddleware"], "add_tokens": "# # Unused for now, this is how a rack middleware looks like. # This should be used later to normalize logging message format # class LoggerMiddleware", "del_tokens": "#:nodoc: class MyLoggerMiddleware", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "default", "for", "flash_now", "enabling", "it", "to", "be", "set", "to", "false", "."], "add_tokens": "@flash_now = options . delete ( :flash_now ) { :on_failure }", "del_tokens": "@flash_now = options . delete ( :flash_now ) || :on_failure", "commit_type": "use"}
{"commit_tokens": ["Moving", "map", "functions", "to", "consistent", "api"], "add_tokens": "def self . find_feature input , args input . find { | feature | feature [ 'name' ] == args [ 'feature' ] } input = find_feature input , 'feature' => args [ 'feature' ] input = [ find_feature ( input , 'feature' => args [ 'feature' ] ) ] if args . has_key? ( 'feature' )", "del_tokens": "def self . find_feature input , feature_to_find input . find { | feature | feature [ 'name' ] == feature_to_find } input = find_feature input , args [ 'feature' ] input = [ find_feature ( input , args [ 'feature' ] ) ] if args . has_key? ( 'feature' )", "commit_type": "move"}
{"commit_tokens": ["Fix", "tests", "on", "Travis", "."], "add_tokens": "FileUtils . mkdir_p File . expand_path ( '../../../tmp/files' , __FILE__ ) # This needs to happen after the fixture files are created. class ActiveSupport :: TestCase include ActiveRecord :: TestFixtures self . fixture_path = File . expand_path ( '../../../tmp' , __FILE__ ) self . use_transactional_tests = true self . use_instantiated_fixtures = false self . pre_loaded_fixtures = false fixtures :all end", "del_tokens": "class ActiveSupport :: TestCase include ActiveRecord :: TestFixtures self . fixture_path = File . expand_path ( '../../../tmp' , __FILE__ ) self . use_transactional_tests = true self . use_instantiated_fixtures = false self . pre_loaded_fixtures = false fixtures :all end FileUtils . mkdir_p File . expand_path ( '../../../tmp' , __FILE__ ) FileUtils . mkdir_p File . expand_path ( '../../../tmp/files' , __FILE__ )", "commit_type": "fix"}
{"commit_tokens": ["Add", "code", "to", "read", "query", "prefixes", "from", "env", "var", "containing", "CSV", "list", "of", "prefixes", "to", "use", "in", "matching", "gRPC", "method", "names", "to", "be", "included", "in", "the", "GraphQL", "Query", "type", "."], "add_tokens": "name_str = name_sym . to_s prefixes . each { | prefix | return true if name_str . start_with? ( prefix ) } rpc_desc . rpc_desc . input == Google :: Protobuf :: Empty private def prefixes @prefixes ||= ( ENV [ 'GRAPHQL_GRPC_QUERY_PREFIXES' ] . strip . split ( ',' ) || [ 'get' , 'find' ] ) end", "del_tokens": "name_sym . to_s . start_with? ( 'get' ) || name_sym . to_s . start_with? ( 'find' ) || rpc_desc . rpc_desc . input == Google :: Protobuf :: Empty", "commit_type": "add"}
{"commit_tokens": ["Creates", "the", "parent", "directory", "if", "required", "when", "OptPath", "and", ":", "create"], "add_tokens": "return if File . exist? ( path ) FileUtils . mkdir_p ( path . parent . to_s ) unless Dir . exist? ( path . parent . to_s ) FileUtils . touch ( path . to_s )", "del_tokens": "FileUtils . touch ( path . to_s ) unless File . exist? ( path )", "commit_type": "create"}
{"commit_tokens": ["Create", "a", "same_as?", "method", "that", "can", "be", "used", "to", "compare", "two", "cards", "for", "rank", "/", "suit", "."], "add_tokens": "deck . draw . same_as? ( first_card ) . should == true", "del_tokens": "deck . draw . to_s . should == first_card . to_s", "commit_type": "create"}
{"commit_tokens": ["added", "method", "for", "saving", "the", "result", "back", "to", "the", "database"], "add_tokens": "def save_result ( result ) if check = Check . get ( result . id ) check . status = result . retval check . save else @log . error ( \"Got result for check #{result.id}, but it doesn't exist!\" ) end end save_result ( result )", "del_tokens": "check = Check . get ( result . id ) check . status = result . retval check . save", "commit_type": "add"}
{"commit_tokens": ["add", "aliases", "for", "multiplot", "methods"], "add_tokens": "alias_method :update , :update_plot alias_method :replace , :replace_plot # Create new Multiplot with given plot added (at the tail). alias_method :add , :add_plot alias_method :remove , :remove_plot", "del_tokens": "# Create new Multiplot with given plot added (at the front).", "commit_type": "add"}
{"commit_tokens": ["Add", "<kbd", ">", "to", "list", "of", "whitelisted", "HTML", "attributes", "."], "add_tokens": "blockquote pre code kbd", "del_tokens": "blockquote pre code", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "set_config", "options", "update", "readme"], "add_tokens": "require 'json' :insert_js_last => false , :config => { } mixpanel . set_config ( #{@options[:config].to_json});", "del_tokens": ":insert_js_last => false", "commit_type": "add"}
{"commit_tokens": ["changed", "path", "building", "to", "use", "File", ".", "join", "for", "better", "cross", "-", "platform", "support"], "add_tokens": "Dir . glob ( File . join loldir , \"*\" ) . max_by { | f | File . mtime ( f ) } loldir = File . join LOLBASEDIR , basename loldir = File . join LOLBASEDIR , \"test\" snapshot_loc = File . join loldir , \"tmp_snapshot.jpg\" draw . font = File . join ( LOLCOMMITS_ROOT , \"fonts\" , \"Impact.ttf\" ) canvas . write ( File . join loldir , \"#{commit_sha}.jpg\" ) FileUtils . rm ( snapshot_loc ) Launchy . open ( File . join loldir , \"#{commit_sha}.jpg\" )", "del_tokens": "Dir . glob ( \"#{loldir}/*\" ) . max_by { | f | File . mtime ( f ) } loldir = \"#{LOLBASEDIR}/#{basename}\" loldir = \"#{LOLBASEDIR}/test\" snapshot_loc = \"#{loldir}/tmp_snapshot.jpg\" draw . font = File . join ( File . dirname ( __FILE__ ) , \"..\" , \"fonts\" , \"Impact.ttf\" ) canvas . write ( \"#{loldir}/#{commit_sha}.jpg\" ) FileUtils . rm ( \"#{snapshot_loc}\" ) Launchy . open ( \"#{loldir}/#{commit_sha}.jpg\" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "problem", "with", "empty", "_numbers", "array"], "add_tokens": "if _numbers . empty? @ticks = [ ] else @original_numbers = _numbers numbers = normalize_numbers ( _numbers ) one_step = step_height ( numbers ) @ticks = numbers . map do | n | index = ( n / one_step ) . to_i TICKS [ index ] end", "del_tokens": "@original_numbers = _numbers numbers = normalize_numbers ( _numbers ) one_step = step_height ( numbers ) @ticks = numbers . map do | n | index = ( n / one_step ) . to_i TICKS [ index ]", "commit_type": "fix"}
{"commit_tokens": ["changing", "the", "dates", "on", "the", "copyright"], "add_tokens": "# Copyright:: Copyright (c) 2013 Sander Botman.", "del_tokens": "# Copyright:: Copyright (c) 2012 Sander Botman.", "commit_type": "change"}
{"commit_tokens": ["Fix", "vocab", "(", "Rule", "=", ">", "Operator", "rule", "=", ">", "op", ")"], "add_tokens": "assert_kind_of KPeg :: Tag , tag . op assert_equal action . op . action , \"b + c\"", "del_tokens": "assert_kind_of KPeg :: Tag , tag . rule assert_equal action . rule . action , \"b + c\"", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "typo", "around", "meta", "information"], "add_tokens": "< meta http - equiv = \"Content-Style-Type\" content = \"text/css\" / >", "del_tokens": "< meta http - equiv = \"Content-Style-Tyle\" content = \"text/css\" / >", "commit_type": "fix"}
{"commit_tokens": ["Adds", "the", "ability", "to", "print", "PDF417", "bar", "codes"], "add_tokens": "label_data . push ( 'Y,' + Integer ( options [ :height ] * printer_dpi ) . to_s + ',N,N^FN' + variable_fields_count . to_s + '^FS' ) # This creates a PDF417 bar code, which is very common in the automotive # industry. The format is as follows: # ^B7o,h,s,c,r,t # o = Orientation # N - normal, R rotated 90 degrees clockwise, I inverted 180 degrees # B - Read from bottom up 270 degrees # h = height for individual rows in dots def variable_bar_code_pdf417 ( x , y , params = { } ) x = 0 unless numeric? ( x ) y = 0 unless numeric? ( y ) options = { height : 0.1 , width : 0.1 } . merge ( params ) # update the variable field count self . variable_fields_count += 1 label_data . push ( '^FO' + Integer ( x * printer_dpi ) . to_s + ',' + Integer ( y * printer_dpi ) . to_s ) if params [ :orientation ] == :landscape label_data . push ( '^B7B,' ) else label_data . push ( '^B7N,' ) end label_data . push ( ( printer_dpi / 5 ) . to_s + ',0,' + 5 . to_s + ',' + 8 . to_s + ',N^FN' + variable_fields_count . to_s + '^FS' ) end", "del_tokens": "label_data . push ( 'Y,' + Integer ( options [ :height ] * printer_dpi ) . to_s + ',N,N^FN' + variable_fields_count . to_s + '^FS' )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "bundler", "stuff", "to", "get", "latest", "looker", "-", "sdk"], "add_tokens": "require 'netrc' require 'rubygems' require 'rubygems/package' require 'bundler/setup' say_ok \"check for connectivity: #{@sdk.alive?}\" if @options [ :debug ] say_ok \"verify authentication: #{@sdk.authenticated?}\" if @options [ :debug ] say_warning \"verify authentication: #{@sdk.authenticated?}\" if @options [ :debug ]", "del_tokens": "require 'netrc' say_ok \"check for connectivity: #{@sdk.alive}\" if @options [ :debug ] # say_ok \"verify authentication: #{@sdk.authenticated?}\" if @options[:debug] #say_warning \"verify authentication: #{@sdk.authenticated?}\" if @options[:debug]", "commit_type": "fix"}
{"commit_tokens": ["Add", "warning", "message", "to", "command_output", "."], "add_tokens": "if result_cmd . nil? || ! ( result_cmd =~ command_regex ) STDERR . puts \"SHELL WARNING: Failed to match #{command_regex.inspect}.\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "more", "Object", "shortcuts", "(", "adapted", "from", "Utility", "Belt", ")", "."], "add_tokens": "alias_method :x , :exit def cgrep ( needle ) needle = %r{ #{ Regexp . escape ( needle ) } }i unless needle . is_a? ( Regexp ) res = [ ] ObjectSpace . each_object { | obj | if obj . is_a? ( Class ) && obj <= self name = obj . name res << name if name =~ needle end } res end def mgrep ( needle ) methods . grep ( needle . is_a? ( Regexp ) ? needle : %r{ #{ Regexp . escape ( needle ) } }i ) end def aorta ( obj = self , editor = nil ) if editor ||= File . which_command ( %W[ #{ENV['VISUAL']} #{ENV['EDITOR']} / usr /bin / sensible - editor / usr /bin / xdg - open open vi ] ) system ( editor , path = tempfile . path ) return obj unless File . exists? ( path ) else warn 'No suitable editor found. Please specify.' return obj end", "del_tokens": "def aorta ( obj = self ) path = tempfile . path system ( ENV [ 'VISUAL' ] || ENV [ 'EDITOR' ] || 'vi' , path ) return obj unless File . exists? ( path )", "commit_type": "add"}
{"commit_tokens": ["fix", "table", "schema", "syntax", "with", "collection", "sep"], "add_tokens": "LINES TERMINATED BY '#{@line_sep}'", "del_tokens": "LINES TERMINATED BY '#{@line_sep}'", "commit_type": "fix"}
{"commit_tokens": ["Use", "protocol", "-", "relative", "URLs"], "add_tokens": "def protocol_relative_url url . sub ( / ^http: / , '' ) end protocol_relative_url + 'media/?size=l' protocol_relative_url + 'media/?size=m' protocol_relative_url + 'media/?size=t'", "del_tokens": "url + 'media/?size=l' url + 'media/?size=m' url + 'media/?size=t'", "commit_type": "use"}
{"commit_tokens": ["Use", "block", "map", "for", "configuration", "methods"], "add_tokens": "@configuration_methods_block_map ||= ConfigurableBlockMap . new @configuration_methods_block_map . add ( block , [ method ] ) methods_block_map : @configuration_methods_block_map ,", "del_tokens": "@configuration_methods ||= { } method_hash = if method . is_a? ( Hash ) ingest_configuration_block! ( method , & block ) else { method => block } end @configuration_methods . merge! method_hash methods : @configuration_methods ,", "commit_type": "use"}
{"commit_tokens": ["add", "spec", "for", "preference", "manipulations"], "add_tokens": "# @param [String] s stream id. 'root' or folder name", "del_tokens": "# @param [String] s stream id. root or folder name", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "editing", "and", "canceling", "bookings"], "add_tokens": "# Make a HTTP PUT request # # @param path [String] The path, relative to {#api_endpoint} # @param options [Hash] Body params for the request # @return [Array<Sawyer::Resource>] def put ( path , options = { } ) request :put , path , options end # Make a HTTP DELETE request # # @param path [String] The path, relative to {#api_endpoint} # @param options [Hash] Body params for the request # @return [Array<Sawyer::Resource>] def delete ( path , options = { } ) request :delete , path , options end when 204 ; [ ] # update/destroy response # fetch objects from outer hash # {rentals => [{rental}, {rental}]} # will return [{rental}, {rental}]", "del_tokens": "# fetch objects from outer hash # {rentals => [{rental}, {rental}]} # will return [{rental}, {rental}]", "commit_type": "add"}
{"commit_tokens": ["fix", "timing", "issue", "with", "button", "scenario"], "add_tokens": "RAutomation :: Window . new ( :title => window_title ) . wait_until_exists", "del_tokens": "RAutomation :: Window . new ( :title => window_title ) . should exist", "commit_type": "fix"}
{"commit_tokens": ["Fix", "how", "we", "run", "the", "block", "to", "use", "the", "class", "context", ".", "Really", "infuriating", "to", "track", "this", "one", "down", "."], "add_tokens": "class_exec ( & block ) if block class_exec ( & block ) if block", "del_tokens": "instance_exec ( & block ) instance_exec ( & block ) if block", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "of", "array", "of", "attributes"], "add_tokens": "self_closing = options . delete ( :self_closing ) if self_closing xml . tag! ( key , attrs ) else case item when :: Hash then xml . tag! ( key , attrs ) { xml << Hash . to_xml ( item , options ) } when NilClass then xml . tag! ( key , \"xsi:nil\" => \"true\" ) else xml . tag! ( key , attrs ) { xml << XMLValue . create ( item , escape_xml ) } end if item . respond_to? ( :keys ) attrs = item . reduce ( { } ) do | st , v | k = v [ 0 ] . to_s st [ k [ 1 .. - 1 ] ] = v [ 1 ] . to_s if k =~ / ^@ / st end else attrs = { } end yield xml , item , tag_attributes ( attributes , index ) . merge ( attrs ) , index", "del_tokens": "case item when :: Hash then xml . tag! ( key , attrs ) { xml << Hash . to_xml ( item , options ) } when NilClass then xml . tag! ( key , \"xsi:nil\" => \"true\" ) else xml . tag! ( key , attrs ) { xml << XMLValue . create ( item , escape_xml ) } yield xml , item , tag_attributes ( attributes , index ) , index", "commit_type": "add"}
{"commit_tokens": ["fix", "mongoid", "-", "history", "spelling"], "add_tokens": "require 'mongoid-history'", "del_tokens": "require 'mongoid_history'", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.5.1\"", "del_tokens": "VERSION = '0.5.0'", "commit_type": "change"}
{"commit_tokens": ["Move", "Tuple", "coercion", "into", "Body#each", "block"], "add_tokens": "@header , @tuples = header , tuples @tuples . each { | tuple | yield Tuple . coerce ( header , tuple ) }", "del_tokens": "@header = header @tuples = tuples . map { | tuple | Tuple . coerce ( @header , tuple ) } . to_set @tuples . each ( & block )", "commit_type": "move"}
{"commit_tokens": ["fix", "version", "initializer", "to", "accept", "Array", "or", "#to_s", "as", "advertised"], "add_tokens": "if args . first . is_a? ( Array ) else", "del_tokens": "args . first . is_a? ( Array ) case args . first when Array when String", "commit_type": "fix"}
{"commit_tokens": ["implement", "a", "fetch", "that", "stores", "the", "value"], "add_tokens": "fetch ( \"mlb_stats_api:teams:#{team_id}\" ) do", "del_tokens": "@cache . fetch ( \"mlb_stats_api:teams:#{team_id}\" ) do", "commit_type": "implement"}
{"commit_tokens": ["added", "site", "parameter", "to", "consumer", "oauth", "options"], "add_tokens": "consumer . site . should == 'https://api.linkedin.com' consumer . site . should == 'https://api.josh.com' consumer . site . should == 'https://api.linkedin.com' consumer . site . should == 'https://api.linkedin.com' consumer . site . should == 'https://api.josh.com'", "del_tokens": "consumer . site . should == ''", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "reduce", "memory", "consumption", "on", "jruby"], "add_tokens": "numbers = Benchmark :: Trend . range ( 1 , 1_000 ) numbers = Benchmark :: Trend . range ( 1 , 500 )", "del_tokens": "numbers = Benchmark :: Trend . range ( 1 , 5_000 ) numbers = Benchmark :: Trend . range ( 1 , 1_000 )", "commit_type": "change"}
{"commit_tokens": ["Added", "tests", "that", "errors", "raised", "while", "preparing", "a", "request", "stop", "lifecycle", "events", "."], "add_tokens": "def setup # keep track of emitted events @emitted = [ ] request . on ( event_name ) { | * args | @emitted << event_name } end it 'emits a sequence of standard events as a result of #send' do @emitted . must_equal ( events ) end it 'stops emitting and raises if a :validate listener raises' do request . on ( :validate ) { | * args | raise 'error' } assert_raises ( RuntimeError ) { request . send } @emitted . must_equal ( [ :validate ] ) end it 'stops emitting and raises if a :build listener raises' do request . on ( :build ) { | * args | raise 'error' } assert_raises ( RuntimeError ) { request . send } @emitted . must_equal ( [ :validate , :build ] ) end it 'stops emitting and raises if a :sign listener raises' do request . on ( :sign ) { | * args | raise 'error' } assert_raises ( RuntimeError ) { request . send } @emitted . must_equal ( [ :validate , :build , :sign ] )", "del_tokens": "it 'emits a sequence of standard events as a result of #send' do emitted = [ ] request . on ( event_name ) { | * args | emitted << event_name } emitted . must_equal ( events )", "commit_type": "add"}
{"commit_tokens": ["Fixing", ".", "get_auth_token", "and", "writing", "a", "releated", "rspec", "test", ".", "Don", "t", "failing", "if", "no", "AUTH_TOKEN", "USERNAME", "or", "PASSWORD", "is", "set", "but", "setting", "the", "tests", "to", "pending", "with", "a", "useful", "help", "message", "."], "add_tokens": "@auth_token = self . get_auth_token ( username , password ) if username and password # This method returns an authentication token. If the auth_token # exists it is returned, otherwise a new one is created. # # @param [String] username The username (email) that is used for the basic authentication # @param [String] password The password that is used for the basic authentication # @return [String] The authentication token as string def self . get_auth_token ( username , password ) basic_hash = Base64 . strict_encode64 ( \"#{username}:#{password}\" ) client = Sigimera :: Client . new response = client . post ( \"/v1/tokens.json\" , basic_hash ) json = JSON . parse response . body if response json [ 'auth_token' ] . to_s if json end", "del_tokens": "@auth_token = get_auth ( username , password ) if username and password # This method returns an authentication token. If the auth_token # exists it is returned, otherwise a new one is created. # # @param [String] username The username (email) that is used for the basic authentication # @param [String] password The password that is used for the basic authentication # @return [String] The authentication token as string def self . get_auth_token ( username , password ) basic_hash = Base64 . strict_encode64 ( \"#{username}:#{password}\" ) response = self . post ( \"/v1/tokens.json\" , basic_hash ) response . body [ 'auth_token' ] . to_s if response and response . body end", "commit_type": "fix"}
{"commit_tokens": ["add", "bundler", "support", "to", "gem_dependency_checker"], "add_tokens": ":bundler => false , opts . on ( '--bundler' , 'Use bundler to process the gemfile (note this eval\\'s the Gemfile' ) do $conf [ :bundler ] = true end def check_bundler ( ) end elsif $conf [ :bundler ] require 'bundler' $gems = [ ] # override bundler's gem registration module Bundler class Dsl alias :old_gem :gem def gem ( name , * args ) $gems << [ name , args . first ] # name,version old_gem ( name , * args ) end end end path , g = File . split ( $conf [ :gemfile ] ) Dir . chdir ( path ) { Bundler :: Definition . build ( g , nil , false ) } $gems . each { | n , v | check_gem ( n , v ) } require 'gemnasium/parser'", "del_tokens": "require 'gemnasium/parser'", "commit_type": "add"}
{"commit_tokens": ["allow", "for", "different", "remote", "hosts"], "add_tokens": "system ( \"scp pkg/dist/* #{@configuration.remote_host}:#{@configuration.remote_installation_path}\" )", "del_tokens": "system ( \"scp pkg/dist/* lukeredpath.co.uk:#{@configuration.remote_installation_path}\" )", "commit_type": "allow"}
{"commit_tokens": ["Add", "error", "handling", "for", "sending", "data"], "add_tokens": "require 'logger' # Send message to Sumologic begin logger ( tag ) . log ( severity , format ( tag , time , record ) , time : Time . at ( time ) ) do | header | # Map syslog headers from record @mappings . each do | name , record_key | header . send ( \"#{name}=\" , record [ record_key ] ) unless record [ record_key ] . nil? end rescue = > e log . error e . to_s end", "del_tokens": "# Send message to Sumo logger ( tag ) . log ( severity , format ( tag , time , record ) , time : Time . at ( time ) ) { | header | # Map syslog headers from record @mappings . each do | name , record_key | header . send ( \"#{name}=\" , record [ record_key ] ) unless record [ record_key ] . nil? }", "commit_type": "add"}
{"commit_tokens": ["Changed", "collections", "to", "resources", "which", "also", "index", "the", "index", "action", "."], "add_tokens": "def resources ( type , options = { } ) path ( type ) unless options [ :skip_index ]", "del_tokens": "def collection ( type , options = { } )", "commit_type": "change"}
{"commit_tokens": ["Use", "full", "constant", "names", "for", "Tus", "components"], "add_tokens": "uid = SecureRandom . hex info = Tus :: Info . new ( info = Tus :: Info . new ( storage . read_info ( uid ) ) info = Tus :: Info . new ( storage . read_info ( uid ) ) input = Tus :: Input . new ( request . body ) validate_upload_checksum! ( input ) if request . headers [ \"Upload-Checksum\" ] storage . patch_file ( uid , input ) expirator = Tus :: Expirator . new ( storage , interval : expiration_interval ) def validate_upload_checksum! ( input ) unless Tus :: Checksum . new ( algorithm ) . match? ( checksum , input )", "del_tokens": "uid = SecureRandom . hex info = Info . new ( info = Info . new ( storage . read_info ( uid ) ) info = Info . new ( storage . read_info ( uid ) ) validate_upload_checksum! if request . headers [ \"Upload-Checksum\" ] storage . patch_file ( uid , Input . new ( request . body ) ) expirator = Expirator . new ( storage , interval : expiration_interval ) def validate_upload_checksum! unless Checksum . new ( algorithm ) . match? ( checksum , Input . new ( request . body ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "markdown", "strong", "to", "explanation_introduction_phrase", "in", "narrator"], "add_tokens": "\"**#{explanation_introduction_phrase}**\\n\\n#{explanation_paragraphs(tips).join(\"\\n\\n\")}\\n\\n#{retry_phrase}\\n\"", "del_tokens": "\"#{explanation_introduction_phrase}\\n\\n#{explanation_paragraphs(tips).join(\"\\n\\n\")}\\n\\n#{retry_phrase}\\n\"", "commit_type": "add"}
{"commit_tokens": ["Add", "license", "to", "all", "of", "the", "source", "files"], "add_tokens": "# -*- encoding: utf-8 -*- # frozen_string_literal: true # # Copyright (c) 2016 Mark Lee and contributors # # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and # associated documentation files (the \"Software\"), to deal in the Software without restriction, # including without limitation the rights to use, copy, modify, merge, publish, distribute, # sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is # furnished to do so, subject to the following conditions: # # The above copyright notice and this permission notice shall be included in all copies or # substantial portions of the Software. # # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT # NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND # NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, # DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT # OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. # Helpers to package the Rust library, using FPM.", "del_tokens": "# Helpers to package the Rust library", "commit_type": "add"}
{"commit_tokens": ["allow", "condition", "options", "for", "param_protected", "and", "param_accessible", "(", ":", "if", ":", "unless", ")"], "add_tokens": "@params_protected = Protector . instance ( self . class ) . protect ( self , params_without_protection , action_name )", "del_tokens": "@params_protected = Protector . instance ( self . class ) . protect ( params_without_protection , action_name )", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "loading", "in", "Linux"], "add_tokens": "ffi_lib [ \"libftdi\" , \"libftdi.so.1\" ]", "del_tokens": "ffi_lib \"libftdi\"", "commit_type": "add"}
{"commit_tokens": ["Fixing", "visibility", "of", "private", "methods"], "add_tokens": "private # @return [Hash(String, AMQP::Exchange)] # @api private def producer_exchanges @producer_exchanges ||= { } end # @return [AMQP::Connection] # @api private def producer_connection @producer_connection ||= open_connection ( config . publish_to ) end # @return [AMQP::Channel] # @api private def producer_channel @producer_channel ||= open_channel ( producer_connection ) end", "del_tokens": "# @return [Hash(String, AMQP::Exchange)] # @api private def producer_exchanges @producer_exchanges ||= { } end # @return [AMQP::Connection] # @api private def producer_connection @producer_connection ||= open_connection ( config . publish_to ) end # @return [AMQP::Channel] # @api private def producer_channel @producer_channel ||= open_channel ( producer_connection ) end", "commit_type": "fix"}
{"commit_tokens": ["Added", "initial", "Manifest", "implementation", "with", "manifest", "validation"], "add_tokens": "require_relative 'core/core_ext' require_relative 'core/manifest'", "del_tokens": "require_relative 'core/core_ext'", "commit_type": "add"}
{"commit_tokens": ["Move", "required", "field", "*", "from", "element", "to", "label", "(", "pass", "option", "to", "both", "methods", "so", "a", "custom", "element", "template", "could", "use", "it", "if", "desired", ")", "."], "add_tokens": "@@custom_label_options = [ :required , :colon , :label_for ] colon = false if options [ :colon ] . nil? required = options [ :required ] # remove special options options . delete :colon options . delete :required text = text . blank? ? method . to_s . humanize : text . to_s text += ' <span class=\"required\">*</span>' if required #{l[:label]}<br /> #{l[:element]} #{l[:label]}<br />", "del_tokens": "@@custom_label_options = [ :colon , :label_for ] colon = options [ :colon ] . nil? ? false : options [ :colon ] options . delete :colon if text . blank? text = method . to_s . humanize else text = text . to_s end #{l[:label]} #{' <span class=\"required\">*</span>' if l[:required]}<br /> #{l[:element]} #{l[:label]}#{' <span class=\"required\">*</span>' if l[:required]}<br />", "commit_type": "move"}
{"commit_tokens": ["add", "c_call", "test", "and", "fix", "it"], "add_tokens": "# see event description in TracePoint API Doc return : [ :defined_class , :method_id , :return_value ] , c_call : [ :defined_class , :method_id ] , line : [ :path , :lineno ] , # following are not tested yet class : [ :defined_class ] , end : [ :defined_class ] , c_return : [ :defined_class , :method_id , :return_value ] , raise : [ :raised_exception ] , b_call : [ :binding , :defined_class , :method_id ] , b_return : [ :binding , :defined_class , :method_id ] , thread_begin : [ :defined_class , :method_id ] , thread_end : [ :defined_class , :method_id ] when :test , :silence", "del_tokens": "return : [ :defined_class , :method_id , :return_value ] when :test", "commit_type": "add"}
{"commit_tokens": ["changed", "local", "name", "to", "be", "more", "expressive"], "add_tokens": "login_template = options . twitter_oauth_config [ :login_template ] engine = login_template . keys . first login_template [ :text ] render engine , login_template [ engine ]", "del_tokens": "login_config = options . twitter_oauth_config [ :login_template ] engine = login_config . keys . first login_config [ :text ] render engine , login_config [ engine ]", "commit_type": "change"}
{"commit_tokens": ["Updated", "Restriction#body", "to", "use", "Body#restrict"], "add_tokens": "@body ||= relation . body . restrict ( predicate )", "del_tokens": "@body ||= relation . body . class . new ( header , restrict_body ) end private def restrict_body relation . select { | tuple | predicate . call ( tuple ) }", "commit_type": "update"}
{"commit_tokens": ["fixed", "html_safe", "in", "the", "tr8n_translated", "values"], "add_tokens": "self . html_safe", "del_tokens": "self", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "specs", "to", "stop", "writing", "foo", "/", "directory"], "add_tokens": "before ( :all ) { FakeFS . activate! } after ( :all ) { FakeFS . deactivate! }", "del_tokens": "before :all do FakeFS . activate! end after :all do FakeFS . deactivate! end", "commit_type": "fix"}
{"commit_tokens": ["Remove", "include_unset", "option", "from", "View", "rendering", "."], "add_tokens": "@include_nil = options . fetch ( :include_nil , false )", "del_tokens": "attr_reader :include_unset @include_unset = options . fetch ( :include_unset , false ) # implicitly set include_nil to true when include_unset is true @include_nil = options . fetch ( :include_nil , @include_unset ) if @include_unset && ! @include_nil msg = \"Error while defining view with name #{name.inspect} for schema #{schema.inspect}.\" msg += \" include_nil may not be false if include_unset is true\" raise ArgumentError , msg end unless @include_unset if object . respond_to? ( :key? ) next unless object . key? ( name ) else msg = \"WARNING: #{object} does not respond to :key? during rendering for #{Attributor.humanize_context(context)}. \" msg += \"Can not check key #{name.inspect} is set, but include_unset option is true.\" warn msg end end", "commit_type": "remove"}
{"commit_tokens": ["Moving", "finders", "into", "their", "own", "module"], "add_tokens": "# # # require \"mongoid/finders\"", "del_tokens": "# # #", "commit_type": "move"}
{"commit_tokens": ["Added", "tests", "for", "recovering", "a", "destroyed", "object", "."], "add_tokens": "setup do @fluxor = @widget . fluxors . create :name => 'flux' @widget . destroy @reified_widget = @widget . versions . last . reify end should 'record the correct event' do assert_match / destroy /i , @widget . versions . last . event end assert_equal @widget . id , @reified_widget . id assert_equal @widget . attributes , @reified_widget . attributes should 'be re-creatable from its previous version' do assert @reified_widget . save end should 'restore its associations on its previous version' do @reified_widget . save assert_equal 1 , @reified_widget . fluxors . length # Test the serialisation and deserialisation.", "del_tokens": "setup { @widget . destroy } widget = @widget . versions . last . reify assert_equal @widget . id , widget . id assert_equal @widget . attributes , widget . attributes should 'record the correct event' do assert_match / destroy /i , @widget . versions . last . event # Test the serialisation and unserialisation.", "commit_type": "add"}
{"commit_tokens": ["Add", "minitest", "equivalents", "for", "the", "commented", "out", "rspec", "tests", "."], "add_tokens": "@stack_modules = { }", "del_tokens": "@stack_modules ||= { }", "commit_type": "add"}
{"commit_tokens": ["Use", "Base64", ".", "encode", "/", "decode", "after", "/", "befor", "encrypting"], "add_tokens": "Base64 . encode64 escape_and_execute_sql ( [ \"SELECT AES_ENCRYPT(?, ?)\" , value , key ] ) . first escape_and_execute_sql ( [ \"SELECT AES_DECRYPT(?, ?)\" , Base64 . decode64 ( value ) , key ] ) . first", "del_tokens": "escape_and_execute_sql ( [ \"SELECT AES_ENCRYPT(?, ?)\" , value , key ] ) . first escape_and_execute_sql ( [ \"SELECT AES_DECRYPT(?, ?)\" , value , key ] ) . first", "commit_type": "use"}
{"commit_tokens": ["Improve", "process", "script", ";", "add", "fix", "/", "check", "to", "LadderHelper", "::", "dynamic", "chunk"], "add_tokens": "return 1000 if 0 == mem_total_bytes mem_used_bytes = ` ps -Ao rss= ` mem_free_bytes = mem_total_bytes - mem_used_bytes . split . map ( & :to_i ) . inject ( & :+ ) . to_i * 1024", "del_tokens": "mem_used_bytes = ` ps -Ao rss= ` . split . map ( & :to_i ) . inject ( & :+ ) . to_i * 1024 mem_free_bytes = mem_total_bytes - mem_used_bytes num_chunks = ( klass_or_collection . size ( true ) . to_f / chunk_size . to_f ) . ceil", "commit_type": "improve"}
{"commit_tokens": ["Changed", "base", "module", "for", "database", "inserter", "activerecord", "classes"], "add_tokens": "file_format . const_get ( class_name ) . create! ( attributes ) file_format . const_set ( class_name , Class . new ( ActiveRecord :: Base ) ) unless file_format . const_defined? ( class_name )", "del_tokens": "RequestLogAnalyzer :: Aggregator :: Database . const_get ( class_name ) . create! ( attributes ) unless RequestLogAnalyzer :: Aggregator :: Database . const_defined? ( class_name ) RequestLogAnalyzer :: Aggregator :: Database . const_set ( class_name , Class . new ( ActiveRecord :: Base ) ) end", "commit_type": "change"}
{"commit_tokens": ["add", "proper", "parsing", "of", "recurse", "responses"], "add_tokens": "@raw = JSON . parse ( @raw . body ) if @raw . count == 1 @value = @raw . first [ \"Value\" ] @value = Base64 . decode64 ( @value ) unless @value . nil? else @value = @raw . map do | e | { key : e [ \"Key\" ] , value : e [ \"Value\" ] . nil? ? e [ \"Value\" ] : Base64 . decode64 ( e [ \"Value\" ] ) } end end", "del_tokens": "@raw = JSON . parse ( @raw . body ) . first @value = @raw [ \"Value\" ] @value = Base64 . decode64 ( @value ) unless @value . nil?", "commit_type": "add"}
{"commit_tokens": ["Allow", "stubbing", "of", "a", "specific", "edtion", "."], "add_tokens": "def publication_exists ( details , options = { } ) if options [ :edition ] uri += \"?edition=#{options[:edition]}\" end", "del_tokens": "def publication_exists ( details )", "commit_type": "allow"}
{"commit_tokens": ["Updated", "inclusion", "of", "active", "support"], "add_tokens": "require 'active_support/all'", "del_tokens": "require 'activesupport'", "commit_type": "update"}
{"commit_tokens": ["Fix", "initialization", "of", "Ribbit", "::", "Commit"], "add_tokens": "obj = Ribbit :: Commit . new ( @repo , sha )", "del_tokens": "obj = Ribbit :: Commit . new ( sha , @repo )", "commit_type": "fix"}
{"commit_tokens": ["Added", "pop", "shift", "and", "unshift", "to", "lists"], "add_tokens": "# @param value [#to_s] Pushes value to the tail of the list. # @return [String] Return and remove the last element of the list. def pop db . rpop ( key ) end # @return [String] Return and remove the first element of the list. def shift db . lpop ( key ) end # @param value [#to_s] Pushes value to the head of the list. def unshift ( value ) db . lpush ( key , value ) end # @return [Array] Elements of the list.", "del_tokens": "# @param value [#to_s] Pushes value to the list.", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "migration", "to", "setup", "the", "test", "database"], "add_tokens": "require 'generators/delayed_job/templates/migration' CreateDelayedJobs . up", "del_tokens": "create_table :delayed_jobs , force : true do | table | table . integer :priority , default : 0 table . integer :attempts , default : 0 table . text :handler table . text :last_error table . datetime :run_at table . datetime :locked_at table . datetime :failed_at table . string :locked_by table . string :queue table . timestamps end add_index :delayed_jobs , [ :priority , :run_at ] , name : \"delayed_jobs_priority\"", "commit_type": "use"}
{"commit_tokens": ["implement", "#set_error_handler", "(", ":", "traceback", ")"], "add_tokens": "elsif lua_code == :traceback stack_load_path ( 'debug.traceback' ) @error_handler = stack_top else # TODO ##stack_load_global('debug') ##stack_load_field('traceback') ##Lib.lua_remove(@pointer, -2) #stack_load_path('debug.traceback') ##print_stack #@error_handler = stack_top", "del_tokens": "return #stack_load_global('debug') #stack_load_field('traceback') #Lib.lua_remove(@pointer, -2) stack_load_path ( 'debug.traceback' ) #print_stack @error_handler = stack_top", "commit_type": "implement"}
{"commit_tokens": ["create", "directory", "for", "the", "new", "program"], "add_tokens": "path = File . dirname ( __FILE__ ) + '/mock' cli = SimpleCommander :: CLI . new cli . init ( path ) cli . new ( 'ex_program' ) expect ( File . directory? ( './spec/mock/ex_program' ) ) . to eq ( true ) FileUtils . remove_dir ( './spec/mock/ex_program' )", "del_tokens": "SimpleCommander :: CLI . new ( 'test_program' ) expect ( File . directory? ( './spec/mock/test_program' ) ) . to eq ( true )", "commit_type": "create"}
{"commit_tokens": ["Fixing", "dtk", "common", "to", "be", "proper", "gem"], "add_tokens": "VERSION = \"0.1.4\"", "del_tokens": "VERSION = \"0.1.3\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "resource?", "helper", "for", "testing", "if", "resource", "has", "been", "loaded"], "add_tokens": "helper_method :can? , :resource , :resource? # Returns true if resource has been loaded def resource? ! @resource . nil? end", "del_tokens": "helper_method :can? , :resource", "commit_type": "add"}
{"commit_tokens": ["Added", "transactional", "module", "that", "makes", "it", "easier", "to", "wrap", "method", "in", "a", "transaction"], "add_tokens": "require 'neo4j/transactional' extend Transactional transactional :set_property , :get_property , :delete # puts \"Relation #{event} clazz #{event.node.to_s} #{rel_name} empty: #{event.node.relations.outgoing(rel_name.to_sym).empty?.to_s}\"", "del_tokens": "Transaction . run { } Transaction . run { } Transaction . run { } # puts \"Relation #{event} clazz #{event.node.to_s} #{rel_name} empty: #{event.node.relations.outgoing(rel_name.to_sym).empty?.to_s}\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "the", "token", "to", "be", "set", "either", "in", "the", "middleware", "setup", "or", "in", "the", "query", "values", "during", "connection", "execution", "."], "add_tokens": "env [ :url ] . query_values = { 'access_token' => @token } . merge ( params ) token = env [ :url ] . query_values [ 'access_token' ] env [ :request_headers ] . merge! ( 'Authorization' => \"Token token=\\\"#{token}\\\"\" )", "del_tokens": "env [ :url ] . query_values = params . merge ( 'access_token' => @token ) env [ :request_headers ] . merge! ( 'Authorization' => \"Token token=\\\"#{@token}\\\"\" )", "commit_type": "allow"}
{"commit_tokens": ["Added", "preemption", "-", "inserting", "pass", "."], "add_tokens": "@preemption = false opts . on ( \"--[no-]preemptive\" , \"Preemptive concurrency? (default #{@preemption})\" ) do | p | @preemption = p end require_relative 'bpl/analysis/preemption' timed 'Preemption addition' do Bpl :: Analysis :: add_preemptions! program end if @preemption", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["adding", "some", "documentation", "to", "the", "accessors", "...", "not", "complete!"], "add_tokens": ":status => :unprocessable_entity )", "del_tokens": ":status => :unprocessable_entity )", "commit_type": "add"}
{"commit_tokens": ["use", "mkmf", "find_executable", "to", "check", "if", "gnuchess", "is", "installed"], "add_tokens": "require 'mkmf' unless find_executable0 ( 'gnuchesss' ) raise 'You must install Gnuchess to use the module Chess::Gnuchess!'", "del_tokens": "# Return true if Gnuchess is installed, false otherwise. def self . gnuchess_installed? system ( 'which gnuchess >& /dev/null' ) $? . exitstatus == 0 end unless gnuchess_installed? raise 'You need to install Gnuchess to use the module Chess::Gnuchess.'", "commit_type": "use"}
{"commit_tokens": ["add", "extension", "accessor", "to", "handlebars"], "add_tokens": "attr_accessor :timeline_item , :template , :extension", "del_tokens": "attr_accessor :timeline_item , :template", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "additional", "requests", "and", "documentation"], "add_tokens": "DEFAULT_ENDPOINT = 'https://demo.docusign.net/restapi'", "del_tokens": "DEFAULT_ENDPOINT = 'https://demo.docusign.net/restapi/'", "commit_type": "add"}
{"commit_tokens": ["fixing", "bug", "in", "activation", "where", "activate!", "didn", "t", "actually", "save", "to", "db"], "add_tokens": "activation_code = @user . activation_code @user2 = User . find ( @user . id ) # go to db to make sure it was saved and not just in memory @user2 . activation_code . should be_nil @user2 . activation_state . should == \"active\" User . find_by_activation_code ( activation_code ) . should be_nil", "del_tokens": "@user . activation_code . should be_nil @user . activation_state . should == \"active\"", "commit_type": "fix"}
{"commit_tokens": ["fixed", "syntax", "error", "in", "spec_helper", ".", "rb"], "add_tokens": "require 'simplecov-console' SimpleCov . start", "del_tokens": "require ' simplecov - console", "commit_type": "fix"}
{"commit_tokens": ["add", "say", "helper", "method", "to", "send", "a", "normal", "message"], "add_tokens": "#TODO: pub, sub, etc. def say ( body ) msg = connection . message_stanza ( :to => jid ) do | x | x . body body end connection . send_stanza msg end", "del_tokens": "#TODO: say, pub, sub, etc.", "commit_type": "add"}
{"commit_tokens": ["Added", "file", "settings", "check", "."], "add_tokens": "@settings [ :file ] = @file unless @settings [ :file ]", "del_tokens": "@settings [ :file ] = @file", "commit_type": "add"}
{"commit_tokens": ["adding", "references", "as", "a", "field", "type"], "add_tokens": "def initialize ( name , type ) name = match . captures [ 1 ] . sub ( / _id$ / , '' ) type = $& . nil? ? match . captures [ 0 ] : \"references\" Attribute . new ( name , type )", "del_tokens": "def initialize ( type , name ) Attribute . new ( * match . captures )", "commit_type": "add"}
{"commit_tokens": ["Make", "community", "site", "interaction", "into", "a", "plugin"], "add_tokens": "autoload :Base , 'stove/plugins/base' autoload :Community , 'stove/plugins/community' autoload :Git , 'stove/plugins/git' autoload :GitHub , 'stove/plugins/github' autoload :JIRA , 'stove/plugins/jira'", "del_tokens": "autoload :Base , 'stove/plugins/base' autoload :Git , 'stove/plugins/git' autoload :GitHub , 'stove/plugins/github' autoload :JIRA , 'stove/plugins/jira'", "commit_type": "make"}
{"commit_tokens": ["Remove", "immaterial", "test_target", "block", "."], "add_tokens": "def test_target verify_target ( :registration , :target => CaTissue :: SpecimenCollectionGroup ) end", "del_tokens": "# def test_target # verify_target(:registration, :target => CaTissue::SpecimenCollectionGroup) do |scg| # cpe = scg.collection_event # assert_not_nil(cpe, \"#{scg} missing CPE\") # pcl = cpe.protocol # assert_not_nil(pcl, \"#{scg} CPE #{cpe} missing protocol\") # assert_not_nil(pcl.short_title, \"#{scg} protocol #{pcl} missing short title\") # end # end", "commit_type": "remove"}
{"commit_tokens": ["Use", "synchronous", "-", "style", "calls", "when", "em", "-", "synchrony", "is", "available", "for", "publishing", "asynchronously", "."], "add_tokens": "if defined? ( EM :: Synchrony ) if http . error Keen . logger . warn ( \"Couldn't connect to Keen IO: #{http.error}\" ) raise \"Couldn't connect ot Keen IO: #{http.error}\" else process_response ( http . response_header . status , http . response . chomp ) end else http . callback { begin response = process_response ( http . response_header . status , http . response . chomp ) deferrable . succeed ( response ) rescue Exception => e deferrable . fail ( e ) end } http . errback { Keen . logger . warn ( \"Couldn't connect to Keen IO: #{http.error}\" ) deferrable . fail ( Error . new ( \"Couldn't connect to Keen IO: #{http.error}\" ) ) } deferrable end", "del_tokens": "http . callback { begin response = process_response ( http . response_header . status , http . response . chomp ) deferrable . succeed ( response ) rescue Exception => e deferrable . fail ( e ) end } http . errback { Keen . logger . warn ( \"Couldn't connect to Keen IO: #{http.error}\" ) deferrable . fail ( Error . new ( \"Couldn't connect to Keen IO: #{http.error}\" ) ) } deferrable", "commit_type": "use"}
{"commit_tokens": ["Added", "Sinatra", "::", "Base", ".", "reset_routes!"], "add_tokens": "class Sinatra :: Base class << self def reset_routes! @routes = { } @filters = { :before => [ ] , :after => [ ] } @errors = { } end end end # class Sinatra::Base reset! ( app ) app . reset_routes!", "del_tokens": "app . routes = { } app . filters = { :before => [ ] , :after => [ ] } app . errors = { }", "commit_type": "add"}
{"commit_tokens": ["Remove", "destructive", "VIPS", "processing", "methods"], "add_tokens": "File . open ( fixture_path ( name ) , \"rb\" ) end def fixture_path ( name ) \"test/fixtures/#{name}\" def copy_to_tempfile ( path ) tempfile = Tempfile . new ( [ \"test\" , File . extname ( path ) ] , binmode : true ) IO . copy_stream ( path , tempfile )", "del_tokens": "File . open ( \"test/fixtures/#{name}\" ) def copy_to_tempfile ( file ) extension = File . extname ( file . path ) if file . respond_to? ( :path ) tempfile = Tempfile . new ( [ \"test\" , extension . to_s ] , binmode : true ) IO . copy_stream ( file , tempfile . path ) file . rewind", "commit_type": "remove"}
{"commit_tokens": ["Added", "files", "for", "compute", "v2", "extensions", "."], "add_tokens": "require 'ropenstack/identity'", "del_tokens": "require 'ropenstack/identity/identity' require 'ropenstack/compute/computeExtension'", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "output", "of", "splits"], "add_tokens": "end . concat ( @splits . collect { | s | s . to_s } ) . flatten . compact . join ( \"\\n\" )", "del_tokens": "end . flatten . compact . join ( \"\\n\" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "few", "minor", "issues", "with", "and", "document", "the", "POST", "_method", "hack", "."], "add_tokens": "# Set of request method names allowed via the _method parameter hack. By default, # all request methods defined in RFC2616 are included, with the exception of # TRACE and CONNECT. POST_TUNNEL_METHODS_ALLOWED = %w( PUT DELETE OPTIONS HEAD ) # Return the HTTP request method with support for method tunneling using the POST # _method parameter hack. If the real request method is POST and a _method param is # given and the value is one defined in +POST_TUNNEL_METHODS_ALLOWED+, return the value # of the _method param instead. if post_tunnel_method_hack? private # Return truthfully if and only if the following conditions are met: 1.) the # *actual* request method is POST, 2.) the request content-type is one of # 'application/x-www-form-urlencoded' or 'multipart/form-data', 3.) there is a # \"_method\" parameter in the POST body (not in the query string), and 4.) the # method parameter is one of the verbs listed in the POST_TUNNEL_METHODS_ALLOWED # list. def post_tunnel_method_hack? @env [ 'REQUEST_METHOD' ] == 'POST' && POST_TUNNEL_METHODS_ALLOWED . include? ( self . POST . fetch ( '_method' , '' ) . upcase ) end", "del_tokens": "if @env [ 'REQUEST_METHOD' ] == 'POST' && %w( PUT DELETE ) . include? ( params [ '_method' ] )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "compatibility", "of", "cache", "versions"], "add_tokens": "# Raise an exception if the cache isn't compatible with the current library version minimum_version = '0.4.0' Gem :: Version . new ( cache_version ) < Gem :: Version . new ( minimum_version ) raise \"OSRM API error: Incompatible cache version #{cache_version}, \" + \"expected #{minimum_version} or higher\"", "del_tokens": "# Raise an exception if major and minor versions of the cache and library are different Gem :: Version . new ( cache_version ) . bump != Gem :: Version . new ( OSRM :: VERSION ) . bump raise \"OSRM API error: Incompatible cache version #{cache_version}, expected #{OSRM::VERSION}\"", "commit_type": "improve"}
{"commit_tokens": ["Add", "login", "&", "logout", "commands"], "add_tokens": "require 'xcode-download/commands/list' require 'xcode-download/commands/login' require 'xcode-download/commands/logout'", "del_tokens": "require 'xcode-download/commands/list'", "commit_type": "add"}
{"commit_tokens": ["Added", "work", "on", "alarm", "features"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "for", "bitmap", "to", "come", "in", "as", "string", "data", "."], "add_tokens": "def self . bitmap ( bmp , width = nil , height = nil , map = 'RGB' , & block ) width ||= bmp . map { | r | r . length } . max height ||= bmp . length unless bmp . is_a? String bmp . map! { | r | r . fill ( 0 , r . length , width - r . length ) } end bits = Potracer :: Bitmap . new ( width , height , bmp , map )", "del_tokens": "def self . bitmap ( bmp , & block ) height = bmp . length width = bmp . map { | r | r . length } . max bmp . map! { | r | r . fill ( 0 , r . length , width - r . length ) } bits = Potracer :: Bitmap . new ( width , height , bmp )", "commit_type": "add"}
{"commit_tokens": ["Allow", "changing", "logger", "level", "from", "the", "command", "line"], "add_tokens": "task :environment do logger . level = Logger :: DEBUG if ENV [ 'DEBUG' ] end file @target => [ :environment , scoped_task ( :compile ) , * @target_prerequisites ] do | t | task :compile => [ :environment , @makedepend_file , scoped_task ( :load_makedepend ) , * object_files ] @logger . add ( Logger :: DEBUG , \"Compiling '#{ source }'\" )", "del_tokens": "file @target => [ scoped_task ( :compile ) , * @target_prerequisites ] do | t | task :compile => [ @makedepend_file , scoped_task ( :load_makedepend ) , * object_files ] @logger . add ( Logger :: INFO , \"Compiling '#{ source }'\" )", "commit_type": "allow"}
{"commit_tokens": ["Make", "sure", "the", "memory", "pointer", "is", "of", "the", "right", "length", "."], "add_tokens": "ary = FFI :: MemoryPointer . new ( :pointer , inner . length )", "del_tokens": "ary = FFI :: MemoryPointer . new ( :pointer )", "commit_type": "make"}
{"commit_tokens": ["remove", "around", "filters", "and", "client", "filters"], "add_tokens": "subscription . each do | client_id | client = @clients [ client_id ] if client && client . allowed? ( msg ) begin client . synchronize do client << msg rescue # pipe may be broken, move on # turns out you can delete from a set while itereating remove_client ( client ) if client . closed?", "del_tokens": "around_filter = @bus . around_client_batch ( msg . channel ) work = lambda do subscription . each do | client_id | client = @clients [ client_id ] if client && client . allowed? ( msg ) if copy = client . filter ( msg ) begin client . synchronize do client << copy end rescue # pipe may be broken, move on end # turns out you can delete from a set while itereating remove_client ( client ) if client . closed? if around_filter user_ids = subscription . map do | s | c = @clients [ s ] c && c . user_id end . compact if user_ids && user_ids . length > 0 around_filter . call ( msg , user_ids , work ) end else work . call end", "commit_type": "remove"}
{"commit_tokens": ["Allow", "for", "binaries", "and", "directories"], "add_tokens": "require 'rbbt/util/misc' case when get == :directory FileUtils . mkdir_p File . dirname ( path ) unless File . exists? File . dirname ( path ) subdir = Misc . path_relative_to File . dirname ( path ) , opt_dir source = File . join ( sharedir , 'install/software' , subdir , pkg ) FileUtils . cp_r File . join ( sharedir , 'install/software' , subdir , pkg ) , path when get == :binary FileUtils . mkdir_p File . dirname ( path ) unless File . exists? File . dirname ( path ) subdir = Misc . path_relative_to File . dirname ( path ) , opt_dir source = File . join ( sharedir , 'install/software' , subdir , pkg ) ddd source FileUtils . cp File . join ( sharedir , 'install/software' , subdir , pkg ) , path when ( get . nil? or get . empty? )", "del_tokens": "if get . nil? or get . empty?", "commit_type": "allow"}
{"commit_tokens": ["Updated", "history", "version", "and", "gemspec", "."], "add_tokens": "TINY = 1", "del_tokens": "TINY = 0", "commit_type": "update"}
{"commit_tokens": ["Added", "simple", "syntax", "highlighting", "with", "ugly", "styles"], "add_tokens": "it \"converts code snippets\" do content . should include ( 'class=\"highlight\"' ) end", "del_tokens": "it \"converts code snippets\"", "commit_type": "add"}
{"commit_tokens": ["Added", "testing", "methods", "to", "get", "a", "node", "list", "attrs", "by", "node", "and", "params", "by", "node"], "add_tokens": "# enumerate all nodes def enumerate_nodes n = SortedSet . new @node_attrs . keys . each { | k | n . add ( k ) } n end # enumerate qualified list of all attrs enumerate_attrs_by_node ( nil ) end # enumerate qualified list of attrs by node (or all if nil is passed in) def enumerate_attrs_by_node ( node ) } if node == n || node . nil? # enumerate all params # enumerate params by a single node def enumerate_params_by_node ( node ) attrs = enumerate_attrs_by_node ( node ) ps = Set . new attrs . each_value { | v | v . map { | p | ps . add ( p ) if @param_set . include? ( p . to_s ) } } ps end", "del_tokens": "# enumerate qualified list of all attrs. }", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "user", "data"], "add_tokens": "require 'ostruct' # OpenStruct it holds users defined data attr_accessor :user_data @user_data = OpenStruct . new 'fetched' => @fetched , 'user_data' => @user_data . nil? ? { } : @user_data . marshal_dump } '@fetched' => hash [ 'fetched' ] , '@user_data' => hash [ 'user_data' ] ? OpenStruct . new ( hash [ 'user_data' ] ) : nil", "del_tokens": "'fetched' => @fetched } '@fetched' => hash [ 'fetched' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "slack", "-", "notifier", "versions", "conflict"], "add_tokens": "slack_options = { username : Xcov . config [ :slack_username ] } channel = Xcov . config [ :slack_channel ] if channel . to_s . length > 0 channel = ( '#' + channel ) unless [ '#' , '@' ] . include? ( channel [ 0 ] ) slack_options [ :channel ] = channel notifier = Slack :: Notifier . new ( Xcov . config [ :slack_url ] , options : slack_options )", "del_tokens": "notifier = Slack :: Notifier . new ( Xcov . config [ :slack_url ] ) notifier . username = Xcov . config [ :slack_username ] if Xcov . config [ :slack_channel ] . to_s . length > 0 notifier . channel = Xcov . config [ :slack_channel ] notifier . channel = ( '#' + notifier . channel ) unless [ '#' , '@' ] . include? ( notifier . channel [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["made", "jig", "/", "patron", "thread", "-", "safe"], "add_tokens": "VERSION = '0.1.4'", "del_tokens": "VERSION = '0.1.3'", "commit_type": "make"}
{"commit_tokens": ["Remove", "internal", "version", "variable", ".", "Always", "use", "verison", ".", "rb"], "add_tokens": "require_relative './version.rb' :lightstep_tracer_version => Lightstep :: Tracer :: VERSION ,", "del_tokens": "LIGHTSTEP_VERSION = '0.1.0' :lightstep_tracer_version => LIGHTSTEP_VERSION ,", "commit_type": "remove"}
{"commit_tokens": ["Changed", "Yardstick", "::", "CLI", ".", "run", "to", "be", "part", "of", "the", "public", "API"], "add_tokens": "# @api public", "del_tokens": "# @api private", "commit_type": "change"}
{"commit_tokens": ["use", "an", "array", "instead", "of", "a", "hash", "to", "store", "scouts", "so", "you", "can", "use", "more", "than", "one", "kind", "in", "an", "application"], "add_tokens": "@scouts = [ ] @scouts << [ scout , :description => description , :config => config ]", "del_tokens": "@scouts = Hash . new { | h , k | h [ k ] = { } } @scouts [ scout ] [ :description ] = description @scouts [ scout ] [ :config ] = config", "commit_type": "use"}
{"commit_tokens": ["Improved", "UI", "output", "added", "a", "few", "more", "tests"], "add_tokens": "UI . puts \"PROGRAM HALT: #{message}\" Kernel . abort message", "del_tokens": "UI . puts message abort", "commit_type": "improve"}
{"commit_tokens": ["Fix", "custom", "exception", "loading", "."], "add_tokens": "require 'goalie/exceptions' 'Goalie::Forbidden' => :forbidden , 'Goalie::NotFound' => :not_found", "del_tokens": "'Goalie::Forbidden' => :forbidden", "commit_type": "fix"}
{"commit_tokens": ["Add", "backward", "compatibility", "with", "strings", "as", "color", "names", "in", ".", "colorize"], "add_tokens": "# Backward compatibility with string color names color_code = case ActiveRecordQueryTrace . colorize when Symbol then COLORS [ ActiveRecordQueryTrace . colorize ] when String then COLORS [ ActiveRecordQueryTrace . colorize . tr ( \"\\s\" , '_' ) . to_sym ] end", "del_tokens": "color_code = COLORS [ ActiveRecordQueryTrace . colorize ]", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "stop", "mutating", "strings", "in", "truncator"], "add_tokens": "# frozen_string_literal: true content , @prefix = append ( content , @prefix ) content , @suffix = append ( content , @suffix ) @prefix + \"\\n... omitting #{@skipped} bytes ...\\n\" + @suffix remain = @max_size - dst . bytesize remaining = '' remaining = value . byteslice ( 0 ... offset ) [ value , dst + remaining ]", "del_tokens": "content = append ( content , @prefix ) content = append ( content , @suffix ) res = '' res << @prefix res << \"\\n... omitting #{@skipped} bytes ...\\n\" res << @suffix res remain = @max_size - dst . bytesize dst << value . byteslice ( 0 ... offset ) value", "commit_type": "change"}
{"commit_tokens": ["Fixing", "expectation", "in", "spec", "."], "add_tokens": "Delayed :: Job . should_receive ( :find_available ) . at_least ( :once ) . and_return ( [ @job ] )", "del_tokens": "Delayed :: Job . should_receive ( :find_available ) . any_number_of_times . at_least ( :once ) . and_return ( [ @job ] )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "migration", "to", "use", "integer", "for", "user_id"], "add_tokens": "t . integer \"user_id\"", "del_tokens": "t . string \"user_id\"", "commit_type": "fix"}
{"commit_tokens": ["updating", "subjects", "to", "ignore", "case", "added", "subject", "filter", "for", "AT&T"], "add_tokens": "VERSION = '1.1.5'", "del_tokens": "VERSION = '1.1.4'", "commit_type": "update"}
{"commit_tokens": ["Add", "colored", "to", "pastel", "."], "add_tokens": ":enabled? , :colored? , :alias_color", "del_tokens": ":enabled? , :alias_color", "commit_type": "add"}
{"commit_tokens": ["Adding", "subject", "to", "create", "case", "form", "(", "since", "it", "is", "displayed", "in", "the", "list", ")", "."], "add_tokens": "source_id = #{get_source_id} \\ and update_type = 'query' order by object \" values ( #{self.get_inst_source_id}, '#{obj}', 'delete')\" ( #{self.get_inst_source_id}, \\ '#{obj}' , '#{method}' , '#{val}' , 'create' ) \"", "del_tokens": "source_id = #{get_source_id} \\ and update_type = 'query' order by object \" values ( #{self.get_inst_source_id}, '#{obj}', 'delete')\" puts \"self is: #{self.inspect}\" puts \"method, value: #{method.inspect}, #{val.inspect}\" ( #{self.get_inst_source_id}, \\ '#{obj}' , '#{method}' , '#{val}' , 'create' ) \" puts \"SOURCE_ATTRIBS: #{SOURCE_ATTRIBS[self.class.name.to_s]}\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "segfaults", "and", "strange", "memory", "errors", "by", "storing", "handle", "return", "values", "."], "add_tokens": "Thread . current [ :ffi_geos_handle ] or Thread . current [ :ffi_geos_handle ] = FFIGeos . initGEOS_r ( Thread . current [ :ffi_geos_notice_handler ] = self . method ( :notice_handler ) , Thread . current [ :ffi_geos_error_handler ] = self . method ( :error_handler ) ) . tap { | handle | Kernel . at_exit { FFIGeos . finishGEOS_r ( handle ) } }", "del_tokens": "Thread . current [ :ffi_geos_handle ] ||= FFIGeos . initGEOS_r ( self . method ( :notice_handler ) , self . method ( :error_handler ) ) #Kernel.at_exit { # FFIGeos.finishGEOS #}", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "use", "multiple", "transliterators", "."], "add_tokens": "def transliterate! ( * kinds ) kinds = [ :latin ] if kinds . empty? kinds . each do | kind | transliterator = Transliterator . get ( kind ) . instance @wrapped_string = transliterator . transliterate ( @wrapped_string ) end @wrapped_string", "del_tokens": "def transliterate! ( kind = nil ) transliterator = Transliterator . get ( kind || :latin ) . instance @wrapped_string = transliterator . transliterate ( @wrapped_string )", "commit_type": "allow"}
{"commit_tokens": ["Added", "tests", "for", "Manifest", "::", "DataONE"], "add_tokens": "METADATA_FILE = 'dom:scienceMetadataFile' . freeze METADATA_FORMAT = 'dom:scienceMetadataFormat' . freeze DATA_FILE = 'dom:scienceDataFile' . freeze MIME_TYPE = 'mrt:mimeType' . freeze rows = files . to_a . product ( METADATA_FILES . to_a ) . map ( & :flatten )", "del_tokens": "METADATA_FILE = 'dom:scienceMetadataFile' METADATA_FORMAT = 'dom:scienceMetadataFormat' DATA_FILE = 'dom:scienceDataFile' MIME_TYPE = 'mrt:mimeType' rows = files . to_a . product ( METADATA_FILES . to_a ) . map { | p | p . flatten }", "commit_type": "add"}
{"commit_tokens": ["Implemented", "to_s", "with", "formatters", "."], "add_tokens": "# Remove double white spaces. # Remove any duplicate \"/-,\" chars and replace with the single char. # Anything else - the user is on their own ;-)", "del_tokens": "# Remove duplicate white spaces # Remove any duplicate \"/-,\" chars", "commit_type": "implement"}
{"commit_tokens": ["Added", "the", "ability", "to", "pass", "a", "block", "to", "the", "familytree_v2", ".", "person", "method", ".", "If", "requesting", "an", "array", "of", "person", "ids", "the", "block", "will", "be", "passed", "an", "array", "of", "person", "objects", "immediately", "after", "each", "HTTP", "call", ".", "For", "example", "if", "25", "person", "ids", "are", "requested", "the", "block", "will", "be", "executed", "3", "times", "once", "with", "the", "first", "10", "persons", "again", "with", "the", "next", "10", "and", "the", "next", "time", "with", "the", "last", "5", "."], "add_tokens": "def person ( id_or_ids , options = { } , & block ) persons = persons + person ( ids_slice , options , & block ) yield ( familytree . persons ) if block yield ( person ) if block", "del_tokens": "def person ( id_or_ids , options = { } ) persons = persons + person ( ids_slice , options )", "commit_type": "add"}
{"commit_tokens": ["Removed", "a", "few", "unneccessary", "conditions", "."], "add_tokens": "# Now handles positive and negative values gracefully.", "del_tokens": "if max_value > 0 and min_value == 0 bar_height = ( height - y ) elsif max_value == 0 and min_value < 0 bar_height = - 1 * y else # here's where we handle graphs with positive and negative values end", "commit_type": "remove"}
{"commit_tokens": ["Make", "hive", "daemon", "name", "configurable"], "add_tokens": "ENV [ 'HIVE_ENVIRONMENT' ] = 'test' expect ( ` ps aux | grep TEST_HIVE | grep -v grep | wc -l ` . to_i ) . to be 1 expect ( ` ps aux | grep TEST_HIVE | grep -v grep | wc -l ` . to_i ) . to be 0 f . puts ' daemon_name: TEST_HIVE'", "del_tokens": "expect ( ` ps aux | grep HIVE | grep -v grep | wc -l ` . to_i ) . to be 1 expect ( ` ps aux | grep HIVE | grep -v grep | wc -l ` . to_i ) . to be 0", "commit_type": "make"}
{"commit_tokens": ["Add", "so", "far", "blank", "class", "for", "generating", "TableData", ".", "Added", "column", "name", "inits", "to", "script"], "add_tokens": "concat \"chartData['#{id}'] = new google.visualization.DataTable();\" # TODO: how to make this work when columns not explic if options [ :columns ] options [ :columns ] . each do | col , name | concat \"chartData['#{id}'].addColumn('#{kind}', '#{name}');\" end end def col_type ( data ) case data . class when String \"string\" when Fixnum \"number\" when Float \"number\" when Date \"date\" when Time \"datetime\" end end", "del_tokens": "chartData [ '#{id}' ] = new google . visualization . DataTable ( ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "Sawyer", "::", "Serializer", "to", "be", "configurable", "to", "other", "formats", "(", "like", "MessagePack", ")"], "add_tokens": "def initialize ( format , dump_method_name = nil , load_method_name = nil ) @dump = @format . method ( dump_method_name || :dump ) @load = @format . method ( load_method_name || :load ) @dump . call ( encode_object ( data ) ) decode_object ( @load . call ( data ) )", "del_tokens": "def initialize ( format ) @format . dump ( encode_object ( data ) ) decode_object ( @format . load ( data ) )", "commit_type": "update"}
{"commit_tokens": ["Make", "delayed_job", "honor", "ActiveRecord", "default", "table", "name", "prefix", "when", "setting", "table", "name", "of", "Job", "class", "because", "migrations", "will", "prepend", "it", "by", "default", "."], "add_tokens": "delayed_job_table_name = \"#{::ActiveRecord::Base.table_name_prefix}delayed_jobs\" self . table_name = delayed_job_table_name set_table_name delayed_job_table_name", "del_tokens": "require 'active_record' self . table_name = 'delayed_jobs' set_table_name :delayed_jobs", "commit_type": "make"}
{"commit_tokens": ["fixed", "multiple", "column", "names", "in", "csv", "export"], "add_tokens": "codes = @survey . versions . map ( & :question_codes ) . flatten . uniq", "del_tokens": "codes = @survey . versions . map ( & :question_codes ) . flatten", "commit_type": "fix"}
{"commit_tokens": ["Make", "is_true", "validator", "check", "for", "empty", "strings", "false", "and", "0"], "add_tokens": "if ! value || [ 'false' , '0' , '' ] . include? ( value ) fail_with ( :required ) end", "del_tokens": "fail_with ( :required ) unless value", "commit_type": "make"}
{"commit_tokens": ["added", "the", "rest", "of", "the", "key", "maps", ".", "fixed", "connection", "bug", "."], "add_tokens": "SEARCH_QUERY_DEFAULTS = { :listing_status => \"ER,EA,C\" , :idx_display => \"Y\" , :internet_display => \"Y\" } # Returns an array of all of the properties. Same as calling where() with no options # TODO: figure out why it limits to 5,000 records. # Returns an array of property results. A Property is defined as [\"Single Family Residential\", \"Manufactured Home\", \"Condominium\", \"Townhouse\"] # {:limit => limit_number} # {:count_mode => :only} # Look for one of the mapped keys, and return the value or throw method missing error. mapped_key = key_map [ method_name . to_sym ] if attributes . has_key? ( mapped_key ) attributes [ mapped_key ] super", "del_tokens": "SEARCH_QUERY_DEFAULTS = { :active_properties => \"ER,EA,C\" , :idx_display => \"Y\" , :internet_display => \"Y\" } # Returns an array of all of the properties # Returns an array of property results. # SEARCH_CONFIG_DEFAULTS.merge!(:limit => limit_number) # SEARCH_CONFIG_DEFAULTS.merge!(:count_mode => :only) val = attributes [ key_map [ method_name . to_sym ] ] if val . nil? super return val", "commit_type": "add"}
{"commit_tokens": ["Add", "flash", "messages", "when", "components", "are", "destroyed"], "add_tokens": "require_dependency 'para/application_controller' flash_message :success , @component else flash_message :error , @component redirect_to component_path ( @component )", "del_tokens": "require_dependency \"para/application_controller\"", "commit_type": "add"}
{"commit_tokens": ["Move", "native", "load", "attempt", "into", "ext", "module"], "add_tokens": "NO_VALUE = \"\" . freeze NULL_BYTE = 0 . chr . freeze", "del_tokens": "# Determin if we are using JRuby or not. # # @example Are we running with JRuby? # jruby? # # @return [ true, false ] If JRuby is our vm. # # @since 2.0.0 def jruby? RUBY_ENGINE == \"jruby\" end # If we are using JRuby, attempt to load the Java extensions, if we are using # MRI or Rubinius, attempt to load the C extenstions. If either of these fail, # we revert back to a pure Ruby implementation of the Buffer class. # # @since 2.0.0 begin if jruby? # Java extenstions would be packaged in a native.jar with a Java Buffer # implementation. require \"bson/native.jar\" else # C extensions would be packed in a bundle called native with a C buffer # implementation. require \"bson/native\" end rescue LoadError $stderr . puts ( \"BSON is using the pure Ruby buffer implementation.\" ) end NO_VALUE = \"\" . freeze unless defined? ( NO_VALUE ) NULL_BYTE = 0 . chr . freeze unless defined? ( NULL_BYTE )", "commit_type": "move"}
{"commit_tokens": ["update", "ransack", "gem", "and", "fix", "sti", "problem"], "add_tokens": "begin @model ||= name . classify . constantize rescue @model ||= create_model ( name ) end end", "del_tokens": "@model ||= create_model ( name ) end", "commit_type": "update"}
{"commit_tokens": ["Allow", "config", "hash", "to", "be", "passed", "on", "initialization"], "add_tokens": "def initialize ( app , config = nil ) config ||= app . config . zipkin_tracer # if not specified, try on app (e.g. Rails 3+)", "del_tokens": "def initialize ( app ) config = app . config . zipkin_tracer", "commit_type": "allow"}
{"commit_tokens": ["Upgrade", "to", "new", "auto", "-", "generated", "files"], "add_tokens": "require 'simulator' require 'support/matchers/give_the_outcome' RSpec . describe 'Simulator' do", "del_tokens": "require 'spec_helper' describe Simulator do", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "compiler", "discovery", "in", "steps", "for", "macports", "mingw"], "add_tokens": "compilers = %w( i586-mingw32msvc-gcc i386-mingw32-gcc ) paths = ENV [ 'PATH' ] . split ( File :: PATH_SEPARATOR ) compiler = compilers . find do | comp | paths . find do | path | File . exist? File . join ( path , comp ) end raise \"Cannot locate '#{compiler}' in the PATH.\" unless compiler", "del_tokens": "compiler = 'i586-mingw32msvc-gcc' found = false ENV [ 'PATH' ] . split ( File :: PATH_SEPARATOR ) . each do | path | next unless File . exist? ( File . join ( path , compiler ) ) found = true raise \"Cannot locate '#{compiler}' in the PATH.\" unless found", "commit_type": "fix"}
{"commit_tokens": ["Add", "manpage", "for", "help", "."], "add_tokens": "# A S S E M B L Y S T A T I O N S # Attach document method to assembly station. def station_document document end # Attach reset method to assembly station. def station_reset reset end # Attach purge method to assembly station. def station_purge purge end public def self . man_page File . dirname ( __FILE__ ) + '/../man/detroit-dnote.5' end", "del_tokens": "# A S S E M B L Y S T A T I O N S # Attach document method to assembly station. def station_document document end # Attach reset method to assembly station. def station_reset reset end # Attach purge method to assembly station. def station_purge purge end", "commit_type": "add"}
{"commit_tokens": ["Added", "scheme", "name", "in", "coverage", "title"], "add_tokens": "line = \"## #{@project.scheme} code coverage\\n\"", "del_tokens": "line = \"## Code coverage\\n\"", "commit_type": "add"}
{"commit_tokens": ["use", "a", "shorter", "threshold", "for", "tests"], "add_tokens": "before do @controller = TopicsController . new InvisibleCaptcha . timestamp_threshold = 1 . seconds end it 'allow custom on_timestamp_spam callback' do", "del_tokens": "before { @controller = TopicsController . new } it 'allow custom on_timestamp_spam callback' , focus : true do", "commit_type": "use"}
{"commit_tokens": ["Add", "executable", "to", "user", "path"], "add_tokens": "$LOAD_PATH << './lib/'", "del_tokens": "$LOAD_PATH << '.'", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "missing", "copyright", "header", ";", "added", "code", "to", "compute", "an", "agent", "identity", "token", "verifier", "."], "add_tokens": "# # Copyright (c) 2009 RightScale Inc # # Permission is hereby granted, free of charge, to any person obtaining # a copy of this software and associated documentation files (the # \"Software\"), to deal in the Software without restriction, including # without limitation the rights to use, copy, modify, merge, publish, # distribute, sublicense, and/or sell copies of the Software, and to # permit persons to whom the Software is furnished to do so, subject to # the following conditions: # # The above copyright notice and this permission notice shall be # included in all copies or substantial portions of the Software. # # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, # EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF # MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND # NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE # LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION # WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. # def self . create_verifier ( base_id , auth_token , timestamp ) hmac = OpenSSL :: HMAC . new ( auth_token , OpenSSL :: Digest :: SHA1 . new ) hmac . update ( base_id . to_s ) hmac . update ( ID_SEPARATOR ) hmac . update ( timestamp . to_s ) return hmac . hexdigest end", "del_tokens": "# Copyright (c) 2009 RightScale, Inc, All Rights Reserved Worldwide.", "commit_type": "add"}
{"commit_tokens": ["Change", "crumb", "to", "poro", "."], "add_tokens": "class Crumb attr_reader :name attr_reader :url attr_reader :force def initialize ( name , url , options = { } ) @name = name @url = url @force = options . fetch ( :force ) { false } end end", "del_tokens": "Crumb = Struct . new ( :name , :url , :force )", "commit_type": "change"}
{"commit_tokens": ["Allow", "delete", "on", "append", "-", "only", "records"], "add_tokens": "VERSION = \"0.0.39\"", "del_tokens": "VERSION = \"0.0.38\"", "commit_type": "allow"}
{"commit_tokens": ["Add", "port", "to", "MySQL", "connect"], "add_tokens": "@@mysql_port = ENV [ \"MYSQL_PORT\" ] @@DB = Sequel . connect ( adapter : \"mysql2\" , host : @@mysql_host , port : @@mysql_port , database : @@mysql_database , user : @@mysql_user , password : @@mysql_password )", "del_tokens": "@@DB = Sequel . connect ( adapter : \"mysql2\" , host : @@mysql_host , database : @@mysql_database , user : @@mysql_user , password : @@mysql_password )", "commit_type": "add"}
{"commit_tokens": ["Make", "client_spec", "wrap", "to", "80", "character", "limit"], "add_tokens": "expect { described_class . create ( name : 'bacon' ) } . to raise_error ( Error :: ResourceAlreadyExists )", "del_tokens": "expect { described_class . create ( name : 'bacon' ) } . to raise_error ( Error :: ResourceAlreadyExists )", "commit_type": "make"}
{"commit_tokens": ["Use", "readpartial", "instead", "of", "each_line", "for", "non", "blocking", "read", "of", "commands", "output"], "add_tokens": "MAX_READ = 2 ** 16 read_stream ( @out , & block ) def read_stream ( io , & block ) loop do yield io . readpartial ( MAX_READ ) end rescue EOFError end", "del_tokens": "@out . each_line ( & block ) if block", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "ensure", "no", "strings", "mutation"], "add_tokens": "# frozen_string_literal: true styles = \"#{options[:style_classes]}\"", "del_tokens": "styles << \"#{options[:style_classes]}\"", "commit_type": "change"}
{"commit_tokens": ["adds", "test", "cases", "for", "custom", "messages"], "add_tokens": "context \"with default message\" do before do klass . send ( disabler , :the_method ) end it_should_behave_like \"disabled method\" context \"with custom message\" do let ( :message ) { \"Custom Message\" } before do klass . send ( disabler , :the_method , message ) end it \"should raise NoMethodError with custom message\" do expect { object . the_method } . to raise_error ( NoMethodError , message ) end end context \"with default message\" do before do klass . send ( disabler , :the_method ) klass . send ( restorer , :the_method ) klass . send ( disabler , :the_method ) end it_should_behave_like \"disabled method\" context \"with custom message\" do let ( :message ) { \"Custom Message\" } before do klass . send ( disabler , :the_method , message ) klass . send ( restorer , :the_method ) klass . send ( disabler , :the_method ) end it \"should raise NoMethodError with custom message\" do expect { object . the_method } . to raise_error ( NoMethodError , message ) end end", "del_tokens": "before do klass . send ( disabler , :the_method ) it_should_behave_like \"disabled method\" before do klass . send ( disabler , :the_method ) klass . send ( restorer , :the_method ) klass . send ( disabler , :the_method ) it_should_behave_like \"disabled method\"", "commit_type": "add"}
{"commit_tokens": ["Changed", "<", "=", ">", "to", "cascade", "from", "year", "to", "day", "."], "add_tokens": "# Public: Spaceship operator for date comparisons. Comparisons start # with year, then month, then day - which are bitmask functions and # faster than 'self.value' which requires math to produce the integer. if self . year < other_date . year - 1 elsif self . year > other_date . year 1 else if self . month < other_date . month - 1 elsif self . month > other_date . month 1 else if self . day < other_date . day - 1 elsif self . day > other_date . day 1 else 0 end end end", "del_tokens": "# Public: Spaceship operator for date comparisons. self . value <=> other_date . value", "commit_type": "change"}
{"commit_tokens": ["Add", "as", ":", ":", "authenticatable", "to", "sessions", "association"], "add_tokens": "has_many :passwordless_sessions , class_name : 'Passwordless::Session' , as : :authenticatable", "del_tokens": "has_many :passwordless_sessions , class_name : 'Passwordless::Session'", "commit_type": "add"}
{"commit_tokens": ["Use", "more", "descriptive", "interaction", "names"], "add_tokens": "class InteractionWithAttribute < described_class class InteractionWithFilter < described_class class InteractionWithFilters < described_class describe InteractionWithAttribute do let ( :described_class ) { InteractionWithAttribute } class InteractionWithInvalidFilter < described_class describe InteractionWithFilter do let ( :described_class ) { InteractionWithFilter } describe InteractionWithFilters do let ( :described_class ) { InteractionWithFilters } describe InteractionWithFilter do let ( :described_class ) { InteractionWithFilter }", "del_tokens": "class TestInteraction1 < described_class class TestInteraction2 < described_class class TestInteraction3 < described_class describe TestInteraction1 do let ( :described_class ) { TestInteraction1 } class TestInteraction < described_class describe TestInteraction2 do let ( :described_class ) { TestInteraction2 } describe TestInteraction3 do let ( :described_class ) { TestInteraction3 } describe TestInteraction2 do let ( :described_class ) { TestInteraction2 }", "commit_type": "use"}
{"commit_tokens": ["Changed", "the", "implementation", "of", "resultset", ".", "size", "to", "get", "more", "accurate", "results"], "add_tokens": "# To get more accurate results, we pass the doc count to the mset method @size = enquiry . mset ( 0 , options [ :db_size ] ) . matches_estimated", "del_tokens": "# By passing 0 as the max parameter to the mset method, # we only get statistics about the query, no results @size = enquiry . mset ( 0 , 0 ) . matches_estimated", "commit_type": "change"}
{"commit_tokens": ["add", "context", "help", "to", "index", "actions"], "add_tokens": "def show_help end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "Version#index", "use", "more", "Rails", "3", "idioms", "."], "add_tokens": "sibling_versions . select ( :id ) . order ( \"id ASC\" ) . map ( & :id ) . index ( self . id )", "del_tokens": "sibling_versions . all ( :select => :id , :order => \"id ASC\" ) . map ( & :id ) . index ( self . id )", "commit_type": "make"}
{"commit_tokens": ["implementing", "CliCommand", ".", "server", "to", "get", "a", "Server", "object", "which", "basically", "represents", "a", "server", "state", "reported", "by", "barman"], "add_tokens": "server = parse_show_server_lines ( name , lines ) lines = run_barman_command ( \"check #{name}\" ) parse_check_lines ( server , lines ) return server", "del_tokens": "return parse_show_server_lines ( name , lines )", "commit_type": "implement"}
{"commit_tokens": ["remove", "usage", "of", "broken", "deprecation", "Identity", ".", "new"], "add_tokens": ":: ActiveRecord :: Type :: Value . new", "del_tokens": "OID :: Identity . new", "commit_type": "remove"}
{"commit_tokens": ["Improving", "error", "message", "when", "using", "proxy"], "add_tokens": "error_message = \"connection refused on: #{service.host}:#{service.port}\" if service . proxy proxy_uri = URI ( service . proxy ) error_message << \" via proxy: #{proxy_uri.host}:#{proxy_uri.port}\" end @errors << error_message", "del_tokens": "@errors << \"connection refused on: #{service.host}:#{service.port}\"", "commit_type": "improve"}
{"commit_tokens": ["Use", "the", "correct", "file", "."], "add_tokens": "set output '#{png_file}'", "del_tokens": "set output 'issues-per-label.png'", "commit_type": "use"}
{"commit_tokens": ["removed", "unused", "per", "-", "request", "options", "argument", "for", "http_clients"], "add_tokens": "def request ( method , path , data = nil ) options = Configuration . http_client_options", "del_tokens": "def request ( method , path , data = nil , options = { } ) options = Utils . deep_merge_hashes ( Configuration . http_client_options , options )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "a", "major", "bug", "crashing", "with", "empty", "exceptionlists"], "add_tokens": "start_at = match_end + 1 unless @exceptionlist . empty? start_at = match_end + 1 unless @exceptionlist . empty? start_at = match_end + 1 unless @exceptionlist . empty? start_at = match_end + 1 unless @exceptionlist . empty?", "del_tokens": "start_at = match_end + 1 start_at = match_end + 1 start_at = match_end + 1 start_at = match_end + 1", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "more", "concise", "search", "syntax", "in", "IndexType", "specs"], "add_tokens": "res = type . search ( :query => { :match => { :message => @doc [ :message ] } } ) res = type . search ( query : { match_all : { } } , fields : [ 'message' ] ) res = type . search ( query : { match_all : { } } , fields : [ '_id' ] ) res = type . search ( :query => { :match => { :message => 'hello' } } , :highlight => { :fields => { :message => { } } } )", "del_tokens": "res = type . search ( { } , { :query => { :match => { :message => @doc [ :message ] } } } ) res = type . search ( { } , { query : { match_all : { } } , fields : [ 'message' ] } ) res = type . search ( { } , { query : { match_all : { } } , fields : [ '_id' ] } ) res = type . search ( { } , { :query => { :match => { :message => 'hello' } } , :highlight => { :fields => { :message => { } } } } )", "commit_type": "use"}
{"commit_tokens": ["add", "ability", "to", "search", "a", "ticket", "by", "id"], "add_tokens": "ticket = @project . ticket ( 65845 ) it \"should be\"", "del_tokens": "ticket = @project . tickets ( 65845 )", "commit_type": "add"}
{"commit_tokens": ["Make", "recursive", "search", "work", "for", "dir", "and", "fix", "double", "leading", "slashes"], "add_tokens": "basepath = \"/\" if path [ 0 .. 8 ] == \"/uncached\" path = path [ 9 .. - 1 ] basepath = \"/uncached\" end if ( ret . nil? or ret == [ ] ) and serial =~ / [0-9A-Z]{2,2} \\. [0-9A-Z]{12,12} / if newbasepath = find_recursive ( serial , basepath ) def find_recursive ( serial , path ) [ 'main' , 'aux' ] . each do | side | split = path . split ( \"/\" ) split . delete ( \"\" ) split += [ dir , side ] newpath = \"/\" + split . join ( \"/\" ) ret = find_recursive ( serial , newpath )", "del_tokens": "if ret . nil? and serial =~ / [0-9A-Z]{2,2} \\. [0-9A-Z]{12,12} / if newbasepath = find_recursive ( serial ) def find_recursive ( serial , path = '/' ) [ 'main' , 'aux' ] . each do | side | ret = find_recursive ( serial , \"/\" + ( path . split ( \"/\" ) + [ dir , side ] ) . join ( \"/\" ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "query", "options", "to", "album", "and", "photos"], "add_tokens": "web_albums . albums options . except ( :google_user ) web_albums . photos ( options [ :album_id ] , options . except ( :album_id ) )", "del_tokens": "web_albums . albums web_albums . photos ( options [ :album_id ] )", "commit_type": "add"}
{"commit_tokens": ["Changes", "some", "files", "in", "order", "to", "test", "Compass", "Sprites"], "add_tokens": "module ActiveList #:nodoc: def self . assets_path File . join ( File . dirname ( __FILE__ ) , \"assets\" , \"images\" ) end", "del_tokens": "module List #:nodoc:", "commit_type": "change"}
{"commit_tokens": ["add", "exception", "helper", "for", "ZMQ", "context", "shutdown"], "add_tokens": "# really incredible how many exceptions a simple shutdown can throw all over # the place. if it's one thing ZMQ did never get right it is the shutdown # logic ... DestroyExceptions = [ Java :: JavaNioChannels :: AsynchronousCloseException , Java :: JavaNioChannels :: ClosedChannelException , Java :: JavaNioChannels :: ClosedSelectorException , ] Exceptions = DestroyExceptions + [ Java :: OrgZeromq :: ZMQException , Java :: Zmq :: ZError :: IOException , ] def self . destroy_exception? ( e ) return true if e . is_a? ( Java :: OrgZeromq :: ZMQException ) && ZMQ :: Error :: ETERM . getCode == e . getErrorCode return true if e . is_a? ( Java :: Zmq :: ZError :: IOException ) && DestroyExceptions . include? ( e . cause . class ) return true if DestroyExceptions . include? ( e . class ) return false end", "del_tokens": "java_import \"java.nio.channels.AsynchronousCloseException\" java_import \"java.nio.channels.ClosedChannelException\" java_import \"java.nio.channels.ClosedSelectorException\"", "commit_type": "add"}
{"commit_tokens": ["use", "Mohawk", ".", "stop", "in", "features"], "add_tokens": "@which_screen = on ( MainScreen , :pid => Mohawk . app . pid )", "del_tokens": "@which_screen = on ( MainScreen , :pid => @process . pid )", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "with", "new", "version", "of", "faye"], "add_tokens": ":engine => nil , :server => 'thin' Faye :: WebSocket . load_adapter ( options . delete ( :server ) )", "del_tokens": ":engine => nil", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "in", "XmlMarkup", "class", "docs", "(", "from", "Martin", "Fowler", ")", "."], "add_tokens": "# xm = Builder.new(:indent=>2)", "del_tokens": "# xm = Builder.new(:ident=>2)", "commit_type": "fix"}
{"commit_tokens": ["Move", "some", "code", "from", "ClassBuilder", "to", "ObjectBase"], "add_tokens": "klass = Class . new ( super_metaobj ? super_metaobj . update_class : ObjectBase )", "del_tokens": "klass = Class . new ( super_metaobj ? super_metaobj . update_class : ObjectBase ) do include Ropework :: PropertyDef include Ropework :: SignalDef class << self attr_accessor :meta_object private :meta_object= end end", "commit_type": "move"}
{"commit_tokens": ["Fix", "bundler", "+", "gemspec", "configuration"], "add_tokens": "require 'nestive' require 'rspec/rails'", "del_tokens": "require 'bundler/setup' require File . expand_path ( '../../lib/nestive' , __FILE__ ) require 'rspec/rails'", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "matcher", "for", "checking", "against", "a", "fixture", "."], "add_tokens": "require 'rspec_command/match_fixture' # Matcher to compare files or folders from the temporary directory to a # fixture. def match_fixture ( fixture_path , local_path = nil ) MatchFixture . new ( find_fixture ( self . class . file_path ) , temp_path , fixture_path , local_path || fixture_path ) end # Find a fixture file or the fixture base folder. def find_fixture ( example_path , path = nil ) @fixture_base ||= find_file ( example_path , fixture_root , find_gem_base ( example_path ) ) path ? File . join ( @fixture_base , path ) : @fixture_base", "del_tokens": "# Find a fixture file. def find_fixture ( example_path , path ) find_file ( example_path , File . join ( fixture_root , path ) , find_gem_base ( example_path ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "Arch", "/", "icu44"], "add_tokens": "lib = ffi_lib ( [ \"libicui18n.so.42\" , \"libicui18n.so.44\" , ] ) . first # find a better way to do this! suffix = '' if lib . find_function ( \"ucsdet_open_4_2\" ) elsif lib . find_function ( \"ucsdet_open_44\" ) suffix = '_44' class << self ; self end . instance_eval do", "del_tokens": "lib = ffi_lib [ \"libicui18n.so.42\" , # linux ] if lib . first . find_function ( \"ucsdet_open_4_2\" ) else suffix = '' class << self", "commit_type": "fix"}
{"commit_tokens": ["Create", "an", "invoice", "on", "the", "bitpay", "site", "through", "the", "Spree", "order"], "add_tokens": "PAYMENT_ID = \"123PAYMENTID\" ORDER_ID = \"123ORDERID\" INVOICE_ID = \"123BitPayInvoiceID\" factory :bit_payment , class : Spree :: PaymentMethod :: BitPayment do name 'BPAY' end factory :bitpay_invoice , class : Spree :: BitPayInvoice do end factory :abstract_btc_payment , class : Spree :: Payment do association :payment_method , factory : :bit_payment association :source , factory : :bitpay_invoice amount { order . total } response_code 'BTC' after ( :create ) do | payment | payment . number = n_random_alpha_nums ( 8 ) payment . save! payment . order . update! end factory :invalid_payment do state 'invalid' end factory :processing_bp_payment do state 'processing' end end end def n_random_alpha_nums n alpha_nums = ( ( \"0\" .. \"9\" ) . to_a << ( \"A\" .. \"Z\" ) . to_a << ( \"a\" .. \"z\" ) . to_a ) . flatten ( 0 .. n ) . to_a . reduce ( \"\" ) { | a , b | a << alpha_nums . sample }", "del_tokens": "# Define your Spree extensions Factories within this file to enable applications, and other extensions to use and override them. # # Example adding this to your spec_helper will load these Factories for use: # require 'spree_bitpay/factories'", "commit_type": "create"}
{"commit_tokens": ["remove", "version", "restriction", "on", "byebyg", "dev", "dependency", "update", "README"], "add_tokens": "@token @user_id ||= @token . params [ 'user_id' ] @token @user_id = opts [ :user_id ]", "del_tokens": "return @token @user_id = opts [ :user_id ]", "commit_type": "remove"}
{"commit_tokens": ["Update", "everything", "to", "CastingConfigHelpers", "for", "consistency"], "add_tokens": "module CastingConfigHelpers", "del_tokens": "module TypedConfigHelpers", "commit_type": "update"}
{"commit_tokens": ["fix", "issues", "with", "the", "verbosity", "option", "this", "displayed", "less", "than", "intented"], "add_tokens": "puts options [ :verbosity ] puts \"latest revisions:\" if options [ :verbosity ] == :verbose", "del_tokens": "puts \"latest revisions:\" if options [ :verbosity ] == :verbose", "commit_type": "fix"}
{"commit_tokens": ["Adding", "support", "for", "remaining", "FIT", "record", "types"], "add_tokens": "require 'fit4ruby/FileCreator' require 'fit4ruby/DeviceInfo' require 'fit4ruby/Event' require 'fit4ruby/UserProfile' attr_accessor :device_info , :sessions , :laps , :records , :events @file_creators = [ ] @device_infos = [ ] @user_profiles = [ ] @events = [ ] @personal_records = [ ] ( @file_creators + @device_infos + @user_profiles + @sessions + @events + @personal_records ) . each do | s | def new_file_creator @file_creators << ( file_creator = FileCreator . new ) file_creator end def new_device_info @device_infos << ( device_info = DeviceInfo . new ) device_info end def new_event @events << ( event = Event . new ) event end def new_user_profile @user_profiles << ( user_profile = UserProfile . new ) user_profile end def new_personal_record @personal_records << ( personal_record = PersonalRecords . new ) personal_record end @events == a . events", "del_tokens": "attr_accessor :sessions , :laps , :records @sessions . each do | s | @laps == a . laps && @records == a . records", "commit_type": "add"}
{"commit_tokens": ["Make", "datagrid_header", "and", "datagrid_rows", "call", "explicit"], "add_tokens": "@template . render :partial => \"datagrid/table\" , :locals => { :grid => grid , :options => options , :assets => assets }", "del_tokens": "header = header ( grid , options ) rows = rows ( grid , assets , options ) @template . render :partial => \"datagrid/table\" , :locals => { :grid => grid , :header => header , :rows => rows , :options => options }", "commit_type": "make"}
{"commit_tokens": ["Updating", "drafts", "functionality", "to", "include", "preview", "urls", "."], "add_tokens": "class CampaignTest < Test :: Unit :: TestCase summary . WebVersionURL . should == \"http://clientone.createsend.com/t/ViewEmail/r/3A433FC72FFE3B8B/C67FD2F38AC4859C/\"", "del_tokens": "class ClientTest < Test :: Unit :: TestCase summary . WebVersionURL . should == \"http://clientone.createsend.com//t/ViewEmail/r/3A433FC72FFE3B8B/C67FD2F38AC4859C/\"", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "Aptly", "::", "Publishable", "module", "to", "indicate", "features", "for", "things", "that", "are", "publishable"], "add_tokens": "require_relative 'publishable' include Publishable", "del_tokens": "# @return [Boolean] def published? ! published_in . empty? end # Lists all PublishedRepositories self is published in. Namely self must # be a source of the published repository in order for it to appear here. # This method always returns an array of affected published repositories. # If you use this method with a block it will additionally yield each # published repository that would appear in the array, making it a shorthand # for {Array#each}. # @yieldparam pub [PublishedRepository] # @return [Array<PublishedRepository>] def published_in Aptly :: PublishedRepository . list ( connection ) . select do | pub | next false unless pub . Sources . any? do | src | src . Name == self . Name end yield pub if block_given? true end end", "commit_type": "add"}
{"commit_tokens": ["Use", "better", "exception", "message", "for", "zero", "arity", "assertion"], "add_tokens": "raise ArgumentError , 'Cannot memoize method with nonzero arity'", "del_tokens": "raise ArgumentError , 'Cannot memoize method with unzero arity'", "commit_type": "use"}
{"commit_tokens": ["Use", "Rails", ".", "root", "as", "base", "for", "location", "of", "browserify", "cache", "file"], "add_tokens": "def tmp_path @tmp_path ||= Rails . root . join ( \"tmp\" , \"browserify-rails\" ) . freeze end FileUtils . mkdir_p ( rails_path ( tmp_path ) ) cache_file_path = rails_path ( tmp_path , \"browserifyinc-cache.json\" ) output_file = Tempfile . new ( \"output\" , rails_path ( tmp_path ) )", "del_tokens": "TMP_PATH = File . join ( \"tmp/browserify-rails\" ) . freeze FileUtils . mkdir_p ( rails_path ( TMP_PATH ) ) cache_file_path = rails_path ( TMP_PATH , \"browserifyinc-cache.json\" ) output_file = Tempfile . new ( \"output\" , rails_path ( TMP_PATH ) )", "commit_type": "use"}
{"commit_tokens": ["fix", "documentation", "and", "rename", "Spy#spies", "to", "Spy#all"], "add_tokens": "all << spy all . delete_if do | spy | def all @all ||= [ ] all . each ( & :unhook ) @all = nil", "del_tokens": "spies << spy spies . delete_if do | spy | def spies @spies ||= [ ] spies . each ( & :unhook ) @spies = nil", "commit_type": "fix"}
{"commit_tokens": ["add", "metadata", "method", "to", "page", "model"], "add_tokens": "attr_accessor :id , :parent_id , :title , :children , :slug , :redirect , :layout , :metadata @metadata = options [ :metadata ] . each_with_object ( { } ) { | ( k , v ) , h | h [ k . to_sym ] = v } if options [ :metadata ]", "del_tokens": "attr_accessor :id , :parent_id , :title , :children , :slug , :redirect , :layout", "commit_type": "add"}
{"commit_tokens": ["Allow", "holidays", "to", "be", "configured", "with", "array", "-", "like", "objects"], "add_tokens": "if not holidays . respond_to? ( :to_a ) raise InvalidConfiguration . new \"Invalid type for holidays: #{holidays.class} - must act like an array\" holidays . to_a . each do | day |", "del_tokens": "if not holidays . is_a? Array raise InvalidConfiguration . new \"Invalid type for holidays: #{holidays.class} - must be Array\" holidays . each do | day |", "commit_type": "allow"}
{"commit_tokens": ["Add", "parens", "around", "tagged", "rules", "properly"], "add_tokens": "if parens? ( rule . rule ) io . print \"(\" render_rule io , rule . rule io . print \")\" else render_rule io , rule . rule end", "del_tokens": "render_rule io , rule . rule", "commit_type": "add"}
{"commit_tokens": ["Removed", "dependency", "with", "Active", "support", "and", "other", "minor", "fixes", ".", "Code", "is", "now", "tested"], "add_tokens": "# See README.rdoc for usage info", "del_tokens": "# See README.textile for usage info", "commit_type": "remove"}
{"commit_tokens": ["Updated", "resource_itis", ".", "rb", "to", "use", "both", "rank_id", "and", "kingdom_id", "for", "rank", "determination", "(", "see", "https", ":", "//", "github", ".", "com", "/", "GlobalNamesArchitecture", "/", "dwca", "-", "hunter", "/", "issues", "/", "1", ")", "."], "add_tokens": "@ranks [ row [ 0 ] . strip + '/' + row [ 1 ] . strip ] = row [ 2 ] . strip kingdom_id = data [ 20 ] rank = @ranks [ kingdom_id + '/' + rank_id ] ? @ranks [ kingdom_id + '/' + rank_id ] : ''", "del_tokens": "@ranks [ row [ 1 ] . strip ] = row [ 2 ] . strip rank = @ranks [ rank_id ] ? @ranks [ rank_id ] : ''", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "listing", "the", "services", "when", "there", "are", "several", "nodes", "configured"], "add_tokens": "if line = connection . read_line != \".\" line . split else connection . read_line . split end # Get the raw output of the config for a givens erver # def raw_config ( service ) cache ( service ) do begin connection . send_data ( \"config #{service}\" ) lines = connection . read_packet . join ( \"\\n\" ) rescue UnknownService , BadExit # TODO end lines end end", "del_tokens": "connection . read_line . split", "commit_type": "add"}
{"commit_tokens": ["Add", "space", "before", "equals", "sign"], "add_tokens": "self . current_tenant = old_tenant", "del_tokens": "self . current_tenant = old_tenant", "commit_type": "add"}
{"commit_tokens": ["Allow", "minus", "sign", "in", "string", "to", "set", "year", "."], "add_tokens": "if value =~ / \\A \\- ? \\d {1,7} \\z / raise YearError , \"Year must be an integer from -1048576 to 1048576\"", "del_tokens": "if value =~ / \\A \\d {1,7} \\z / raise YearError , \"Year must be an integer integer from -1048576 to 1048576\"", "commit_type": "allow"}
{"commit_tokens": ["remove", "dependency", "on", "simple", "-", "form"], "add_tokens": "answer . answer_text = text . is_a? ( Array ) ? strip_checkbox_answers ( text ) . join ( ',' ) : text def strip_checkbox_answers ( text ) text . reject ( & :blank? ) . reject { | t | t == \"0\" } end", "del_tokens": "answer . answer_text = text . is_a? ( Array ) ? text . reject ( & :blank? ) . join ( ',' ) : text", "commit_type": "remove"}
{"commit_tokens": ["added", "custom", "conditions", "-", "see", "user", "filter", "example"], "add_tokens": "next if custom_condition? ( condition ) # overload this method to indicate which conditions are custom def custom_conditions [ ] end # overload this method to evaluate a custom condition on an object def custom_condition_met? ( condition , object ) false end def custom_condition? ( condition ) custom_conditions . include? ( condition . key ) end def custom_conditions? return if custom_conditions . empty? conditions . each do | condition | return true if custom_condition? ( condition ) end end def process_custom_conditions ( objects ) filtered = [ ] objects . each do | obj | condition_flags = [ ] 0 . upto ( size - 1 ) do | index | condition = condition_at ( index ) next unless custom_condition? ( condition ) condition_flags << custom_condition_met? ( condition , obj ) end if condition_flags . size > 0 next if match . to_s == \"all\" and condition_flags . include? ( false ) next unless condition_flags . include? ( true ) end filtered << obj end filtered end if custom_conditions? recs = process_custom_conditions ( recs . all ) recs = Kaminari . paginate_array ( recs ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["allow", "empty", "bibitem", "/", "relation", "/", "docidentifier"], "add_tokens": "identifier : r &. at ( './bibitem/formattedref | ./bibitem/docidentifier' ) &. text )", "del_tokens": "identifier : r . at ( 'bibitem/formattedref' ) . text )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "a", "copy", "-", "paste", "error", "and", "handle", "git", "cookbooks", "repos", "with", "a", "blank", "tag", "name", "(", "assume", "master", ")", "."], "add_tokens": "if repo . tag && ! repo . tag . empty? && repo . tag != 'master' && success res += ` #{ ssh_cmd } git fetch origin master --depth #{ 2 ** 31 - 1 } 2>&1 ` success = $? == 0", "del_tokens": "if repo . tag && success res += ` git fetch origin master --depth #{ 2 ** 31 - 1 } 2>&1 ` @errors << res if $? != 0", "commit_type": "fix"}
{"commit_tokens": ["fix", "tests", "after", "setting", ":", "ssl", "=", ">", "true", "by", "default"], "add_tokens": "connect_stream :auth => \"username:password\" , :ssl => false connect_stream :oauth => oauth , :ssl => false port . should == 443 opts [ :port ] . should == 443 $data_to_send = http_response ( 200 , \"OK\" , { } , $body ) connect_stream :ssl => false connect_stream :params => { :name => 'test' } , :ssl => false connect_stream :ssl => false connect_stream :ssl => false connect_stream :user_agent => 'TEST_USER_AGENT' , :ssl => false connect_stream :headers => { 'From' => 'twitter-stream' } , :ssl => false connect_stream :ssl => false do connect_stream :ssl => false do connect_stream :ssl => false , :auto_reconnect => false do connect_stream :ssl => false do connect_stream :ssl => false do connect_stream :ssl => false do connect_stream :ssl => false do", "del_tokens": "connect_stream :auth => \"username:password\" connect_stream :oauth => oauth port . should == 80 opts [ :port ] . should == 80 $data_to_send = http_response ( 200 , \"OK\" , { } , $body ) connect_stream connect_stream :params => { :name => 'test' } connect_stream connect_stream connect_stream :user_agent => 'TEST_USER_AGENT' connect_stream :headers => { 'From' => 'twitter-stream' } connect_stream do connect_stream do connect_stream ( :auto_reconnect => false ) do connect_stream do connect_stream do connect_stream do connect_stream do", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "extend", "with", "type", "read", "."], "add_tokens": ":read_text , :read_type", "del_tokens": ":read_text", "commit_type": "change"}
{"commit_tokens": ["Add", "ability", "to", "create", "and", "edit", "vendors"], "add_tokens": "@products = Product . active @vendors = Vendor . active", "del_tokens": "@products = Product . active @vendors = Vendor . active @categories = Category . all", "commit_type": "add"}
{"commit_tokens": ["Use", "bundler", "for", "managing", "gems", "and", "rspec", "for", "testing"], "add_tokens": "#", "del_tokens": "gem 'oauth' , '~> 0.4.1' gem 'hashie' gem 'httparty' , '>= 0.5.2' #", "commit_type": "use"}
{"commit_tokens": ["Make", "derived", "data", "detection", "more", "robust", "by", "using", "the", "build", "Validate", "line", "."], "add_tokens": "reference = output . split ( \"\\n\" ) . grep ( / ^Validate(.*) \\/ Xcode \\/ DerivedData \\/ (.*)-(.*) / ) . first . split ( \" \" ) . last", "del_tokens": "reference = output . split ( \"\\n\" ) . grep ( / Xcode \\/ DerivedData \\/ (.*)-(.*) / ) . first . split ( \" \" ) . last", "commit_type": "make"}
{"commit_tokens": ["Added", "methods", "to", "set", "the", "resource", "name", "for", "configuration"], "add_tokens": "class_inheritable_accessor :active_admin_config self . active_admin_config = { } # # Naming # def resource_name ( name ) if name . nil? get_resource_name else set_resource_name ( name ) end end def set_resource_name ( name ) self . active_admin_config [ :resource_name ] = name end def get_resource_name self . active_admin_config [ :resource_name ] ||= resource_class . human_name . titleize end def resource_name self . class . get_resource_name end helper_method :resource_name", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "changes", "file", "bump", "version"], "add_tokens": "VERSION = \"0.0.4\"", "del_tokens": "VERSION = \"0.0.3\"", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "ajax", "requests"], "add_tokens": "core_js = <<-EOJS var options , chart ; options = { #{options_collection.join(',')} }; #{capture(&block) if block_given?} chart = new Highcharts . #{type}(options); if defined? ( request ) && request . xhr? graph = <<-EOJS < script type = \"text/javascript\" > ( function ( ) { #{core_js} } ) ( ) < / script > EOJS else graph = <<-EOJS < script type = \"text/javascript\" > ( function ( ) { var onload = window . onload ; window . onload = function ( ) { if ( typeof onload == \"function\" ) onload ( ) ; #{core_js} } ; } ) ( ) < / script > EOJS end", "del_tokens": "graph = <<-EOJS < script type = \"text/javascript\" > ( function ( ) { var onload = window . onload ; window . onload = function ( ) { if ( typeof onload == \"function\" ) onload ( ) ; var options , chart ; options = { #{options_collection.join(',')} }; #{capture(&block) if block_given?} chart = new Highcharts . #{type}(options); } ; } ) ( ) < / script >", "commit_type": "add"}
{"commit_tokens": ["updating", "tests", "to", "reflext", "_dt", "/", "_date", "fix"], "add_tokens": "@mapper . solr_names_and_values ( 'foo' , 'bar' , :date , [ ] ) . should == { 'foo_dt' => [ 'bar' ] }", "del_tokens": "@mapper . solr_names_and_values ( 'foo' , 'bar' , :date , [ ] ) . should == { 'foo_date' => [ 'bar' ] }", "commit_type": "update"}
{"commit_tokens": ["removed", "the", "condition", "while", "the", "parsing", "(", "the", "help", "if", "no", "input", "case", ")"], "add_tokens": "args [ 0 ] ||= '-h'", "del_tokens": "if args . length == 0 args [ 0 ] = '-h' end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "ASG", "doctor", "check", "."], "add_tokens": "@asg_logical_ids . each do | asg_logical_id | if stack . template . resource_names . include? ( asg_logical_id ) success ( \"Resource '#{asg_logical_id}' exists in the CloudFormation template.\" ) # rubocop:disable LineLength else critical ( \"Resource '#{asg_logical_id}' does not exist in the CloudFormation template!\" ) # rubocop:disable LineLength end", "del_tokens": "if stack . template . resource_names . include? ( @asg_logical_id ) success ( \"Resource '#{@asg_logical_id}' exists in the CloudFormation template.\" ) # rubocop:disable LineLength else critical ( \"Resource '#{@asg_logical_id}' does not exist in the CloudFormation template!\" ) # rubocop:disable LineLength", "commit_type": "fix"}
{"commit_tokens": ["add", "Users", "/", "Account", "API"], "add_tokens": ":User => 'user' , :Users => 'users'", "del_tokens": ":User => 'user'", "commit_type": "add"}
{"commit_tokens": ["Update", "documents", "and", "rspec", "."], "add_tokens": "@bonnie = User . create @clyde = User . create @alec = User . create @gang = Group . create", "del_tokens": "@bonnie = User . new @bonnie . save @clyde = User . new @clyde . save @alec = User . new @alec . save @gang = Group . new @gang . save", "commit_type": "update"}
{"commit_tokens": ["Remove", "unary", "plus", "operator", "from", "message", "string", "."], "add_tokens": "message = \"### SwiftLint found issues\\n\\n\"", "del_tokens": "message = + \"### SwiftLint found issues\\n\\n\"", "commit_type": "remove"}
{"commit_tokens": ["added", "documentation", "and", "updated", "2&3", "-", "level", "domain", "suffixes"], "add_tokens": "module DNSBL # :nodoc: # Current version of the dnsbl-client gem VERSION = \"1.0.2\"", "del_tokens": "module DNSBL VERSION = \"1.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Use", "coverage", "kit", "to", "enforce", "maximum", "coverage", "and", "bump", "coverage"], "add_tokens": "require 'simplecov-rcov' require 'coveralls' require 'coverage/kit' Coverage :: Kit . setup ( minimum_coverage : 85.2 )", "del_tokens": "MINIMUM_COVERAGE = 40 unless ENV [ 'COVERAGE' ] == 'off' require 'simplecov' require 'simplecov-rcov' require 'coveralls' Coveralls . wear! SimpleCov . formatters = [ SimpleCov :: Formatter :: RcovFormatter , Coveralls :: SimpleCov :: Formatter ] SimpleCov . start do add_filter '/vendor/' add_filter '/spec/' add_group 'lib' , 'lib' end SimpleCov . at_exit do SimpleCov . result . format! percent = SimpleCov . result . covered_percent unless percent >= MINIMUM_COVERAGE puts \"Coverage must be above #{MINIMUM_COVERAGE}%. It is #{\"%.2f\" % percent}%\" Kernel . exit ( 1 ) end end end", "commit_type": "use"}
{"commit_tokens": ["improved", "logging", "format", "and", "usage"], "add_tokens": "# Logger #@logger = ActiveSupport::Logger.new APP_LOGTO, 'daily' info \"Job.process starting\" info \"Job.process failed [Net::FTPPermError]\" info \"Job.process failed [RestFtpDaemonException::#{exception.class}]\" info \"Job.process finished\"", "del_tokens": "\"process [#{@id}] starting\"", "commit_type": "improve"}
{"commit_tokens": ["Fix", "canonical", "URL", "for", "homepage"], "add_tokens": "if Settings [ :homepage_id ] &. to_i == @page . id \"#{Rails.application.routes.default_url_options[:host]}\" else \"#{Rails.application.routes.default_url_options[:host]}#{@page.path}\" end", "del_tokens": "\"#{Rails.application.routes.default_url_options[:host]}#{@page.path}\"", "commit_type": "fix"}
{"commit_tokens": ["Adds", "accept", "header", "detection", "to", "formatter", "."], "add_tokens": "def mime_types CONTENT_TYPES . invert end def headers env . dup . inject ( { } ) { | h , ( k , v ) | h [ k . downcase ] = v ; h } end mime_array . each do | t | if mime_types . key? ( t ) return mime_types [ t ] end end nil end def mime_array accept = headers [ 'accept' ] if accept accept . gsub ( / \\b / , '' ) . scan ( / ( \\w + \\/ [ \\w +]+)(?:;[^,]*q=([0-9.]+)[^,]*)? /i ) . sort_by { | a | - a [ 1 ] . to_f } . map { | a | a [ 0 ] } else [ ] end", "del_tokens": "# TODO: Implement Accept header parsing.", "commit_type": "add"}
{"commit_tokens": ["make", "agent", "client", "timeout", "mandatory", "defaults", "to"], "add_tokens": "@timeout = options [ :timeout ] || 30 timeout_time = Time . now . to_f + @timeout timeout = timeout_time - Time . now . to_f unless timeout > 0 @pubsub_redis . unsubscribe ( message_id ) raise TimeoutException", "del_tokens": "@timeout = options [ :timeout ] timeout_time = Time . now . to_f + @timeout if @timeout timeout = nil if @timeout timeout = timeout_time - Time . now . to_f unless timeout > 0 @pubsub_redis . unsubscribe ( message_id ) raise TimeoutException end", "commit_type": "make"}
{"commit_tokens": ["using", "a", "counter", "for", "results", "instead", "of", "checking", "for", "EOS"], "add_tokens": "# FIXME: librdf is messed up here, is seems: # librdf_query_results_finished crashes occasionally, # librdf_query_results_get_count returns 0 for non-empty result list # while Redland.librdf_query_results_finished(@rdf_results).zero? n = Redland . librdf_query_results_get_count ( @rdf_results ) while n > - 1 n -= 1", "del_tokens": "while Redland . librdf_query_results_finished ( @rdf_results ) . zero?", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "few", "bugs", "started", "commenting"], "add_tokens": "# WebPurify::Client # # The WebPurify::Client class maintains state of the request parameters like api_key, endpoint, etc., # and provides easy methods for accessing WebPurify # Initialize the class # # @param options [String, Hash] Either an API key string, or a hash of options @api_key = options @endpoint = :us @enterprise = false", "del_tokens": "@api_key = options", "commit_type": "fix"}
{"commit_tokens": ["removed", "html", "file", "extension", "from", "fixture"], "add_tokens": "File . read ( \"test/data/articles/#{domain.tr('.', '_')}_raw\" )", "del_tokens": "File . read ( \"test/data/articles/#{domain.tr('.', '_')}_raw.html\" )", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "name", "method", "to", "server", "published", "objects", "that", "discribe", "object", "more", "than", "path"], "add_tokens": "dbus_method :value , \"out return:v\" do end dbus_method :name , \"out return:s\" do return @meas . name end dbus_method :getConfig , \"out return:a{sv}\" do dbus_method :getConfig , \"out return:a{sv}\" do dbus_interface 'org.openplacos.server.actuator' do dbus_method :value , \"out return:v\" do return @meas . get_value end end", "del_tokens": "dbus_method :value , \"out return:v\" do end dbus_method :getConfig , \"out return:a{sv}\" do dbus_method :getConfig , \"out return:a{sv}\" do", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "truncator", "for", "error", "output", "handling", "."], "add_tokens": "require 'tty/command/truncator' stderr_data = Truncator . new [ stdout_data , stderr_data . read ]", "del_tokens": "stderr_data = '' [ stdout_data , stderr_data ]", "commit_type": "change"}
{"commit_tokens": ["Added", "ability", "to", "pass", "method", "name", "as", "second", "argument", "to", "update_elasticsearch", "instead", "of", "block"], "add_tokens": "def update_elasticsearch ( type_name , method = nil , & block ) backreference = if method && method . to_s == 'self' self elsif method send ( method ) else instance_eval ( & block ) end Chewy . derive_type ( type_name ) . update_index ( backreference )", "del_tokens": "def update_elasticsearch ( type_name , & block ) Chewy . derive_type ( type_name ) . update_index ( instance_eval ( & block ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "full", "english", "date", "format"], "add_tokens": "DEFAULT_REGEXP = Regexp . new ( '^#{0,3} ?([\\w\\d\\.-]+\\.[\\w\\d\\.-]+[a-zA-Z0-9])(?: \\/ (\\w+ \\d{1,2}(?:st|nd|rd|th)?,\\s\\d{4}|\\d{4}-\\d{2}-\\d{2}|\\w+))?\\n?[=-]*' ) # Defaults to /^#{0,3} ?([\\w\\d\\.-]+\\.[\\w\\d\\.-]+[a-zA-Z0-9])(?: \\/ (\\w+ \\d{1,2}(?:st|nd|rd|th)?,\\s\\d{4}|\\d{4}-\\d{2}-\\d{2}|\\w+))?\\n?[=-]*/", "del_tokens": "DEFAULT_REGEXP = Regexp . new ( '^#{0,3} ?([\\w\\d\\.-]+\\.[\\w\\d\\.-]+[a-zA-Z0-9])( \\/ (\\d{4}-\\d{2}-\\d{2}|\\w+))?\\n?[=-]*' ) # Defaults to /^#{1,2} ([\\w\\d\\.-]+\\.[\\w\\d\\.-]+) ?\\/? ?(\\d{4}-\\d{2}-\\d{2}|\\w+)?/", "commit_type": "add"}
{"commit_tokens": ["changed", "default", "connection", "to", "localhost", "orcl", "database"], "add_tokens": "DATABASE_NAME = ENV [ 'DATABASE_NAME' ] || 'orcl' DATABASE_HOST = ENV [ 'DATABASE_HOST' ] || 'localhost' DATABASE_PORT = ENV [ 'DATABASE_PORT' ] || 1521 DATABASE_USER = ENV [ 'DATABASE_USER' ] || 'hr' DATABASE_PASSWORD = ENV [ 'DATABASE_PASSWORD' ] || 'hr' DATABASE_SYS_PASSWORD = ENV [ 'DATABASE_SYS_PASSWORD' ] || 'admin' :database => DATABASE_NAME , :host => DATABASE_HOST , :username => DATABASE_USER , :password => DATABASE_PASSWORD :url => \"jdbc:oracle:thin:@#{DATABASE_HOST}:#{DATABASE_PORT}:#{DATABASE_NAME}\" , :username => DATABASE_USER , :password => DATABASE_PASSWORD :database => DATABASE_NAME , :host => DATABASE_HOST , :password => DATABASE_SYS_PASSWORD ,", "del_tokens": ":database => \"xe\" , :host => \"ubuntu810\" , :username => \"hr\" , :password => \"hr\" :url => \"jdbc:oracle:thin:@ubuntu810:1521:XE\" , :username => \"hr\" , :password => \"hr\" :database => \"xe\" , :host => \"ubuntu810\" , :password => \"manager\" ,", "commit_type": "change"}
{"commit_tokens": ["Add", "status", "method", "with", "default", "BlackHole", "status"], "add_tokens": "# Note that the parent may neglect to call super, leading to this method never being called. # Do not perform any initialization here that cannot be safely skipped @status = status def status @status ||= Lev :: BlackHoleStatus . new end", "del_tokens": "@status = status || Lev :: BlackHoleStatus . new attr_reader :status", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "FayeRails", "::", "Filter", "and", "made", "exception", "catching", "optional", "."], "add_tokens": "attr_writer :logger def logger if defined? ( :: Rails ) @logger ||= Rails . logger end end def incoming_with_exception_handling ( message , callback ) incoming_without_exception_handling ( message , callback ) logger . warn ( \"Exception in filter #{@in_filter.inspect}:, #{e.inspect}\" ) def outgoing_with_exception_handling ( message , callback ) incoming_without_exception_handling ( message , callback ) logger . warn ( \"Exception in filter #{@out_filter.inspect}:, #{e.inspect}\" ) def incoming_without_exception_handling ( message , callback ) @in_filter . new ( @block , message , channel , callback , :incoming ) if @in_filter end def outgoing_without_exception_handling ( message , callback ) @out_filter . new ( @block , message , channel , callback , :outgoing ) if @out_filter end def self . catch_exceptions! alias :incoming :incoming_with_exception_handling alias :outgoing :outgoing_with_exception_handling end def self . dont_catch_exceptions! alias :incoming :incoming_without_exception_handling alias :outgoing :outgoing_without_exception_handling end if defined? ( :: Rails ) && [ 'test' , 'development' ] . member? ( :: Rails . env ) catch_exceptions! else dont_catch_exceptions! end", "del_tokens": "def incoming ( message , callback ) @in_filter . new ( @block , message , channel , callback , :incoming ) if @in_filter Rails . logger . warn ( \"Exception in filter #{@in_filter.inspect}:, #{e.inspect}\" ) def outgoing ( message , callback ) @out_filter . new ( @block , message , channel , callback , :outgoing ) if @out_filter Rails . logger . warn ( \"Exception in filter #{@out_filter.inspect}:, #{e.inspect}\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "overrides", "from", "actionpack", "/", "sprockets"], "add_tokens": "Dir [ File . expand_path ( '../turbo-sprockets/sprockets_overrides/**/*.rb' , __FILE__ ) ] . each do | f | require 'turbo-sprockets/railtie'", "del_tokens": "Dir [ File . expand_path ( '../turbo-sprockets/sprockets_overrides/*.rb' , __FILE__ ) ] . each do | f | #require 'turbo-sprockets/railtie'", "commit_type": "add"}
{"commit_tokens": ["added", "file_path", "to", "use", "when", "accepting", "file", "like", "objects", "that", "use"], "add_tokens": "input = quote_paths ( files ) output = quote_paths ( output ) def quote_paths ( * files ) paths = Array ( files . flatten . compact ) . map { | f | file_path ( f ) } paths . map { | p | %Q(\"#{p}\") } end def file_path ( path ) path = path . to_path if path . respond_to? :to_path path . to_str end", "del_tokens": "input = files . map { | f | %Q(\"#{f}\") }", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "tag", "id", "with", "syntax", "#id_name", "or", "tag_name#id_name"], "add_tokens": "ID_TAG_RE = / \\A # #{ NAME_RE_STRING } / parse_tag 'div' when / \\A # / # Found id name -> implicit div parse_tag 'div' when ID_TAG_RE # Id name attr_node = append_node :tag_attribute attr_node . name = 'id' attr_node . value = $1 @line = $' parse_tag tag_node", "del_tokens": "parse_tag ( 'div' ) puts @line", "commit_type": "add"}
{"commit_tokens": ["fix", "Beam", ".", "join", "&", "Timeout", ".", "timeout"], "add_tokens": "# return to current beam if beam done within time limit origin_parent = parent self . parent = Beam . current timer . set_callback do if alive? caller_beam = parent # resume to origin parent self . parent = origin_parent caller_beam . transfer end end", "del_tokens": "parent = Beam . current timer . set_callback { parent . transfer }", "commit_type": "fix"}
{"commit_tokens": ["allow", "custom", "mesage", "for", "invalid_request"], "add_tokens": "def self . invalid_request ( msg = nil ) new ( \"fail\" , ( msg || \"invalid request\" ) , nil , 400 )", "del_tokens": "def self . invalid_request new ( \"fail\" , \"invalid request\" , nil , 400 )", "commit_type": "allow"}
{"commit_tokens": ["removed", "unneccessary", "options", "in", "meta_parser"], "add_tokens": "# def parse_meta(xml) # end def self . parse_meta ( meta_xml )", "del_tokens": "def self . parse_meta ( meta_xml , options = { col_lengths : false } )", "commit_type": "remove"}
{"commit_tokens": ["create", "a", "Sync", "class", "that", "pushes", "files", "from", "local", "to", "remote"], "add_tokens": "require 'closync/version' require 'closync/config' require 'closync/storage' require 'closync/sync' def push! Sync . new ( config ) . push! end", "del_tokens": "require \"closync/version\" require \"closync/config\" require \"closync/storage\"", "commit_type": "create"}
{"commit_tokens": ["Make", "header", "name", "matching", "case", "sensitive", "to", "match", "tabular", "data", "syntax"], "add_tokens": "build_warnings ( :header_name , :schema , nil , i + 1 ) if fields [ i ] . name != name", "del_tokens": "build_warnings ( :header_name , :schema , nil , i + 1 ) if fields [ i ] . name . downcase != name . downcase", "commit_type": "make"}
{"commit_tokens": ["added", "support", "for", "media", "types", "with", "multiple", "range", "parameters"], "add_tokens": "t == type && ( s == '*' || s == subtype ) && ( p == '' || params_match? ( params , p ) ) private # Returns true if all parameters and values in +match+ are also present in # +params+. def params_match? ( params , match ) return true if params == match parsed = parse_range_params ( params ) parsed == parsed . merge ( parse_range_params ( match ) ) end", "del_tokens": "t == type && ( s == subtype || s == '*' ) && ( p == params || p == '' )", "commit_type": "add"}
{"commit_tokens": ["Use", "sinatra", "to", "serve", "the", "public", "folder"], "add_tokens": "require \"jekyll/admin/static_server\"", "del_tokens": "def self . public_path File . expand_path \"./admin/public/dist\" , File . dirname ( __FILE__ ) end", "commit_type": "use"}
{"commit_tokens": ["Fix", "error", "handlers", "being", "called", "incorrectly"], "add_tokens": "raise handler . first . new ( response . parsed_response ) , handler . last", "del_tokens": "raise handler . first . new response . parsed_response , handler . last", "commit_type": "fix"}
{"commit_tokens": ["using", "the", "same", "logic", "for", "string", "emitting", "and", "parsing"], "add_tokens": "require 'psych/scalar_scanner' return ScalarScanner . new ( o . value ) . tokenize . last unless o . quoted", "del_tokens": "return nil if o . tag == 'tag:yaml.org,2002:null' return Integer ( o . value ) if o . tag == 'tag:yaml.org,2002:int' unless o . quoted return 0.0 / 0.0 if o . value =~ / ^ \\. nan$ /i return 1 / 0.0 if o . value =~ / ^ \\. inf$ /i return - 1 / 0.0 if o . value =~ / ^ \\- \\. inf$ /i return Float ( o . value ) if o . tag == 'tag:yaml.org,2002:float' return Integer ( o . value ) rescue ArgumentError return Float ( o . value ) rescue ArgumentError return nil if o . value =~ / ^(null|~)$ /i or o . value . empty? return o . value . sub ( / ^: / , '' ) . to_sym if o . value =~ / ^: / end", "commit_type": "use"}
{"commit_tokens": ["Fix", "seconds", "formatter", "to", "work", "with", "nil", "values"], "add_tokens": "data = { views : { Safari : 45.20001 , Firefox : 33.3999 , Chrome : nil } } chart data , format : :percentage , label : true", "del_tokens": "data = { views : { Safari : 45.20001 , Firefox : 33.3999 , Chrome : 21.4 } } chart data , format : :percentage", "commit_type": "fix"}
{"commit_tokens": ["moved", "to", "the", "lib", "/", "structure", "so", "warbler", "would", "work", "better"], "add_tokens": "@config = config || { } command = git_command ( \"#{@rpc} --stateless-rpc #{@dir}\" ) IO . popen ( command , File :: RDWR ) do | pipe | def git_command ( command ) git_bin = @config [ :git_path ] || 'git' puts command = \"#{git_bin} #{command}\" command end cmd = git_command ( \"#{service_name} --stateless-rpc --advertise-refs .\" ) refs = ` #{ cmd } ` path = path . sub ( @config [ :server_prefix ] , '' ) if @config [ :server_prefix ]", "del_tokens": "@config = config print \"f: #{@reqfile}\" IO . popen ( \"git --git-dir=#{@dir} #{@rpc} --stateless-rpc #{@dir}\" , File :: RDWR ) do | pipe | refs = ` git #{ service_name } --stateless-rpc --advertise-refs . `", "commit_type": "move"}
{"commit_tokens": ["Use", "new", "max", "job", "id", "to", "monitor", "for", "server", "reset"], "add_tokens": "def clear_cache @cache = nil @min_climbed_job_id = Float :: INFINITY @max_climbed_job_id = 0 end clear_cache update_climbed_job_ids_from_max_id ( id ) def update_climbed_job_ids_from_max_id ( new_max_id ) if @max_climbed_job_id > 0 && @max_climbed_job_id == new_max_id - 1 @max_climbed_job_id = new_max_id elsif new_max_id < @max_climbed_job_id # In case server reset since last climb clear_cache end end", "del_tokens": "@min_climbed_job_id = Float :: INFINITY @max_climbed_job_id = 0 @max_climbed_job_id = id if @max_climbed_job_id == id - 1", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "extend", "keyboard", "codes", "."], "add_tokens": "KEY_UP = \"\\e[A\" KEY_DOWN = \"\\e[B\" KEY_RIGHT = \"\\e[C\" KEY_LEFT = \"\\e[D\" KEY_CLEAR = \"\\e[E\" KEY_END = \"\\e[F\" KEY_HOME = \"\\e[H\" KEY_DELETE = \"\\e[3\" KEY_UP_ALT = \"\\eOA\" KEY_DOWN_ALT = \"\\eOB\" KEY_RIGHT_ALT = \"\\eOC\" KEY_LEFT_ALT = \"\\eOD\" KEY_CLEAR_ALT = \"\\eOE\" KEY_END_ALT = \"\\eOF\" KEY_HOME_ALT = \"\\eOH\" KEY_DELETE_ALT = \"\\eO3\" F1 = \"\\eOP\" F2 = \"\\eOQ\" F3 = \"\\eOR\" F4 = \"\\eOS\" F1_ALT = \"\\e[11~\" F2_ALT = \"\\e[12~\" F3_ALT = \"\\e[13~\" F4_ALT = \"\\e[14~\" F5 = \"\\e[15~\" F6 = \"\\e[17~\" F7 = \"\\e[18~\" F8 = \"\\e[19~\" F9 = \"\\e[20~\" F10 = \"\\e[21~\" F11 = \"\\e[23~\" F12 = \"\\e[24~\"", "del_tokens": "KEY_UP = \"\\e[A\" KEY_DOWN = \"\\e[B\" KEY_RIGHT = \"\\e[C\" KEY_LEFT = \"\\e[D\" KEY_DELETE = \"\\e[3\"", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "ZipCodes#by_code", "and", "#by_name", "where", "empty", "sets", "would", "cause", "a", "broken", "return", "value", "."], "add_tokens": "ZipCodes . new ( @by_code [ code ] || [ ] ) ZipCodes . new ( @by_name [ name ] || [ ] )", "del_tokens": "ZipCodes . new ( @by_code [ code ] ) ZipCodes . new ( @by_name [ name ] )", "commit_type": "fix"}
{"commit_tokens": ["allow", "file", ":", "instead", "of", "files", ":", "and", "ensure", "that", "value", "is", "an", "array", "."], "add_tokens": "opts [ :files ] = opts [ :file ] if opts [ :file ] rc = open_journal ( ptr , opts , flags ) def open_journal ( ptr , opts , flags ) case when opts [ :path ] Native . sd_journal_open_directory ( ptr , opts [ :path ] , 0 ) when opts [ :files ] Native . sd_journal_open_files ( ptr , array_to_ptrs ( Array ( opts [ :files ] ) ) , 0 ) when opts [ :container ] Native . sd_journal_open_container ( ptr , opts [ :container ] , flags ) else Native . sd_journal_open ( ptr , flags ) end end exclusive = [ :path , :files , :container , :file ]", "del_tokens": "rc = case when opts [ :path ] Native . sd_journal_open_directory ( ptr , opts [ :path ] , 0 ) when opts [ :files ] Native . sd_journal_open_files ( ptr , array_to_ptrs ( opts [ :files ] ) , 0 ) when opts [ :container ] Native . sd_journal_open_container ( ptr , opts [ :container ] , flags ) else Native . sd_journal_open ( ptr , flags ) end exclusive = [ :path , :files , :container ]", "commit_type": "allow"}
{"commit_tokens": ["Update", "subTree", "variable", "flag", "to", "qdmVariable", "to", "align", "with", "MAT"], "add_tokens": "if @entry . parent && @entry . parent . attributes && @entry . parent . attributes [ 'qdmVariable' ] handle_variable if @entry . parent . attributes [ 'qdmVariable' ] . value", "del_tokens": "if @entry . parent && @entry . parent . attributes && @entry . parent . attributes [ 'variable' ] handle_variable if @entry . parent . attributes [ 'variable' ] . value", "commit_type": "update"}
{"commit_tokens": ["allow", "path", "to", "be", "nil"], "add_tokens": "attr_accessor :contents def initialize ( path = nil )", "del_tokens": "def initialize ( path )", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "debug", "log", "option", "to", "show", "step", "-", "by", "-", "step", "action", "logs", "for", "debugging"], "add_tokens": "@debug_log = attributes [ :debug_log ] || false puts \"** EPP - Sending frame...\" if @debug_log puts \"** EPP - Attempting login...\" if @debug_log puts \"** EPP - Successfully logged in.\" if @debug_log puts \"** EPP - Attempting logout...\" if @debug_log puts \"** EPP - Successfully logged out.\" if @debug_log frame = get_frame if frame puts \"EPP - Connection opened.\" if @debug_log return frame end if @connection . nil? and @socket . nil? puts \"EPP - Connection closed.\" if @debug_log return true end", "del_tokens": "get_frame return true if @connection . nil? and @socket . nil?", "commit_type": "add"}
{"commit_tokens": ["added", "encryption", "to", "google", "password"], "add_tokens": "Gdriver . config [ 'password' ] . decrypt", "del_tokens": "Gdriver . config [ 'owner_password' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "for", "activerecord", "4", "-", "load", "can", "accept", "time", "instead", "of", "string", "object"], "add_tokens": "if time . respond_to? ( :to_time_of_day ) time . to_time_of_day else TimeOfDay . parse ( time ) if time && ! time . empty? end", "del_tokens": "TimeOfDay . parse ( time ) if time && ! time . empty?", "commit_type": "fix"}
{"commit_tokens": ["allow", "for", "parsing", "of", "number", "w", "/", "E"], "add_tokens": "match = / \\A n:([-0-9E \\- \\. ]*)( .*)* \\z / . match str_value", "del_tokens": "match = / \\A n:([-0-9 \\. ]*)( .*)* \\z / . match str_value", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "the", "no", "-", "bootstrap", "option", "so", "that", "it", "works"], "add_tokens": ":long => \"--[no-]bootstrap\" , :default => true", "del_tokens": ":long => \"--no-bootstrap\" , :default => false", "commit_type": "fix"}
{"commit_tokens": ["Added", "hash", "for", "not_translated_fields", "into", "block", "model"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20150709132202 ) do t . text \"non_translated_fields_info\"", "del_tokens": "ActiveRecord :: Schema . define ( version : 20140618150651 ) do", "commit_type": "add"}
{"commit_tokens": ["added", "code", "for", "handling", "advanced", "association", "setups"], "add_tokens": "# f.association(:category_id, Category.all, :id, :name, :association => { :prompt => \"Category?\" }) # f.association(:category_id, Category.all, :id, :name, :association => { :html => { :class => \"category\" } }) # <div class=\"association\"> # <%= f.collection_select(:category_id, Category.all, :id, :name) %> # </div> # <div> # <div class=\"association\"> # <%= f.label(:category_id) # <div class=\"association\"> # <%= f.collection_select(:category_id, Category.all, :id, :name, { :prompt => \"Category\") } %> # </div> # </div> # </div> # <div> # <div class=\"association\"> # <%= f.label(:category_id) # <div class=\"association\"> # <%= f.collection_select(:category_id, Category.all, :id, :name, {}, { :class => \"category\" } %> # </div> # </div> # </div> when :select then collection_select ( method , collection , value , text , options [ :association ] , options [ :association ] . delete ( :html ) ) # Generates a wrapper around fields_form with :builder set to FormulaFormBuilder. # # Supports: # # * f.formula_fields_for(@user.company) # * f.fieldsula_for(@user.company) # # Equivalent: # # * f.fields_for(@user.company, :builder => Formula::FormulaFormBuilder)) # # Usage: # # <% f.formula_fields_for(@user.company) do |company_f| %> # <%= company_f.input :url %> # <%= company_f.input :phone %> # <% end %> alias :fieldsula_for :formula_fields_for # Generates a wrapper around fields_for with :builder set to FormulaFormBuilder. # <% f.formula_fields_for(@user.company) do |company_f| %>", "del_tokens": "# <div class=\"association\"><%= f.collection_select(:category_id, Category.all, :id, :name) %></div> when :select then collection_select ( method , collection , value , text , options [ :association ] ) # Generates a wrapper around fields_form with :builder set to FormulaFormBuilder. # <% f.formula_form_for(@user.company) do |company_f| %>", "commit_type": "add"}
{"commit_tokens": ["Fix", "#get_channels", "in", "scenario", "where", "there", "are", "no", "channels"], "add_tokens": "channels = [ channels ] . compact unless channels . is_a? ( Array )", "del_tokens": "channels = channels unless channels . is_a? ( Array )", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "optional", "second", "parameter", "to", "easily", "match", "inner", "html", "using", "string", "or", "regexp"], "add_tokens": "# @param [String, Regexp] inner_html Contents of element to match against # # @example Matching inner html # it { should have_tag(:a, \"my site\") } # def have_tag ( name , inner_html = nil ) matcher = HasTag . new ( name ) if inner_html matcher . with_criteria { | element | element . inner_html == inner_html } if inner_html . is_a? String matcher . with_criteria { | element | element . inner_html =~ inner_html } if inner_html . is_a? Regexp end matcher", "del_tokens": "def have_tag ( name ) HasTag . new ( name )", "commit_type": "add"}
{"commit_tokens": ["allow", "from_json", "to", "accept", "a", "string", "or", "hash"], "add_tokens": "def from_json ( json ) json = JSON . parse ( json ) if json . kind_of? String", "del_tokens": "def from_json ( str ) json = JSON . parse ( str )", "commit_type": "allow"}
{"commit_tokens": ["Use", "TCP", "Sockets", "instead", "of", "Unix", "Domain", "Sockets"], "add_tokens": "require 'socket' server_port = start! client = DRbObject . new_with_uri ( \"druby://127.0.0.1:#{server_port}\" ) port = find_available_port remote_client = IO . popen ( \"#{Akephalos::BIN_DIR + 'akephalos'} #{port}\" ) until responsive? ( port ) at_exit { Process . kill ( :INT , remote_client . pid ) } port end private # @api private # @param [Integer] port the port to check for responsiveness # @return [true, false] whether the port is responsive def self . responsive? ( port ) socket = TCPSocket . open ( \"127.0.0.1\" , port ) true rescue Errno :: ECONNREFUSED false ensure socket . close if socket end # @api private # @return [Integer] the next available port def self . find_available_port server = TCPServer . new ( '127.0.0.1' , 0 ) server . addr [ 1 ] ensure server . close if server", "del_tokens": "@socket_file = \"/tmp/akephalos.#{Process.pid}.sock\" start! client = DRbObject . new_with_uri ( \"drbunix://#{@socket_file}\" ) remote_client = IO . popen ( \"#{Akephalos::BIN_DIR + 'akephalos'} #{@socket_file}\" ) until File . exists? ( @socket_file ) at_exit { Process . kill ( :INT , remote_client . pid ) ; File . unlink ( @socket_file ) }", "commit_type": "use"}
{"commit_tokens": ["Fix", "readme", "generator", "rake", "task"], "add_tokens": "NUMBER_OF_ISSUES_INLINE = 3 # You can see the default implementation at # inspector.search_exception an_error, ArtsyUI.new # ``` # # or # # ``` ruby # require 'gh_inspector' # inspector = GhInspector::Inspector.new \"fastlane\", \"fastlane\" # inspector.search_query \"Someone set us up the bomb\", FastlaneUI.new # Deprecated: Please use `inspector_successfully_received_report` instead. # Deprecated: Please use `inspector_received_empty_report` instead.", "del_tokens": "# You can see the default implmentation at # inspector.search_query \"Someone set us up the bomb\", ArtsyUI.new NUMBER_OF_ISSUES_INLINE = 3 # Deprecated: Please use `inspector_successfully_received_report` instead # Deprecated: Please use `inspector_received_empty_report` instead", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "project", "name", "to", "vlc", "-", "client"], "add_tokens": "require File . expand_path ( '../../lib/vlc-client' , __FILE__ )", "del_tokens": "require File . expand_path ( '../../lib/vlc' , __FILE__ )", "commit_type": "change"}
{"commit_tokens": ["Implementing", "tests", "for", "ping", "scout"], "add_tokens": "def execute ( pinger = Net :: Ping :: External . new ) @response_time = pinger . duration * 1000", "del_tokens": "def execute # FIXME Apply Dependency Injection Principle here pinger = Net :: Ping :: External . new @response_time = pinger . duration * 100", "commit_type": "implement"}
{"commit_tokens": ["Fix", "handling", "of", "result_makers", "in", "dashboard", "elements", "handle", "nil", "text", "elements"], "add_tokens": "if existing_element [ :result_maker_id ] && ! new_element [ :result_maker_id ] element [ :result_maker ] = nil element [ :result_maker_id ] = nil elsif new_element [ :result_maker ] result_maker = copy_result_maker_filterables ( new_element ) element [ :result_maker ] = result_maker if result_maker end query = dash_elem [ :result_maker ] &. fetch ( :query , false ) || dash_elem [ :query ] return [ create_fetch_query ( query ) . id , nil , nil ] if query merge_result = dash_elem [ :result_maker ] &. fetch ( :merge_result , false ) || dash_elem [ :merge_result ] return [ nil , nil , create_merge_result ( merge_result ) . id ] if merge_result", "del_tokens": "result_maker = copy_result_maker_filterables ( new_element ) element [ :result_maker ] = result_maker if result_maker return [ create_fetch_query ( dash_elem [ :query ] ) . id , nil , nil ] if dash_elem [ :query ] return [ nil , nil , create_merge_result ( dash_elem [ :merge_result ] ) . id ] if dash_elem [ :merge_result ]", "commit_type": "fix"}
{"commit_tokens": ["added", "unit", "tests", "for", "SLF4J", "logger"], "add_tokens": "def #{severity}? # def debug? ! ! java_logger . is_ #{severity}_enabled(java_marker) # !!java_logger.is_debug_enabled(java_marker) end # end", "del_tokens": "def #{severity}? # def debug? ! ! java_logger . is_ #{severity}_enabled(java_marker) # !!java_logger.is_debug_enabled(java_marker) end # end", "commit_type": "add"}
{"commit_tokens": ["fix", "CLIENT_ID_VAR", "reference", "in", "DefaultCredentials"], "add_tokens": "warn_if_cloud_sdk_credentials ENV [ CredentialsLoader :: CLIENT_ID_VAR ]", "del_tokens": "warn_if_cloud_sdk_credentials ENV [ CLIENT_ID_VAR ]", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unused", "fixed", "Annotation", "work", "-", "around", "."], "add_tokens": "ownr = dependent . owner", "del_tokens": "# kludge for annotation proxy nonsense (cf. Annotation#owner) ownr = Annotation === dependent ? ( dependent . hook or dependent . owner ) : dependent . owner", "commit_type": "remove"}
{"commit_tokens": ["Add", "rspec", "test", "for", "LetsEncrypt", "::", "RenewCertificatesJob"], "add_tokens": "let! ( :certificate ) do end", "del_tokens": "let! ( :certificate ) { }", "commit_type": "add"}
{"commit_tokens": ["Make", "Series", ".", "name", "writable"], "add_tokens": "pos = @index . index ( arg ) def to_html ( threshold = 3 ) def name ( new_name = nil ) if new_name . nil? @name else @name = new_name self end end", "del_tokens": "pos = @arg . index ( arg ) def to_html ( threshold = 50 ) attr_reader :name", "commit_type": "make"}
{"commit_tokens": ["Added", "alarm", "methods", "to", "CLI"], "add_tokens": "desc 'list_alarms' , 'List all alarms.' def list_alarms puts speakers [ 0 ] . list_alarms desc 'is_alarm_enabled? [alarm_id]' , 'Check if an alarm is enabled.' def is_alarm_enabled? ( alarm_id ) puts speakers [ 0 ] . is_alarm_enabled? ( alarm_id ) end desc 'enable_alarm [alarm_id]' , 'Enable an alarm.' def enable_alarm ( alarm_id ) speakers [ 0 ] . enable_alarm ( alarm_id ) end desc 'disable_alarm [alarm_id]' , 'Disable an alarm.' def disable_alarm ( alarm_id ) speakers [ 0 ] . disable_alarm ( alarm_id ) end desc 'set_alarm_volume [alarm_id] [volume]' , 'Set the volume for an alarm.' def set_alarm_volume ( alarm_id , volume ) speakers [ 0 ] . set_alarm_volume ( alarm_id , volume ) end desc 'destroy_alarm [alarm_id]' , 'Destroy an alarm.' def destroy_alarm ( alarm_id ) speakers [ 0 ] . destroy_alarm ( alarm_id )", "del_tokens": "def listAlarms speakers [ 0 ] . list_alarms def enableAlarm ( alarmID ) speakers [ 0 ] . enable_alarm ( alarmID )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "TestFlight", "distribution", "lists", "."], "add_tokens": ":api_token => @configuration . api_token , :team_token => @configuration . team_token , :file => File . new ( @configuration . ipa_path , 'rb' ) , :notes => get_notes , :distribution_lists => @configuration . distribution_lists . join ( \",\" ) , :notify => false", "del_tokens": ":api_token => @configuration . api_token , :team_token => @configuration . team_token , :file => File . new ( @configuration . ipa_path , 'rb' ) , :notes => get_notes , :notify => false", "commit_type": "add"}
{"commit_tokens": ["Make", "not", "-", "required", "path", "argument", "for", "view", "method", "of", "Flame", "::", "Controller", "(", "take", "caller", "method", "name", ")"], "add_tokens": "def view ( path = nil , options = { } ) Flame :: Render . new ( self , ( path || caller_locations ( 1 , 1 ) [ 0 ] . label . to_sym ) , options ) . render", "del_tokens": "def view ( path , options = { } ) Flame :: Render . new ( self , path , options ) . render", "commit_type": "make"}
{"commit_tokens": ["using", "mongoid", "/", "tree", "to", "organize", "the", "whole", "shit"], "add_tokens": "source_version = @survey . newest_version @version . parent = source_version @version = build_version @version . update_attributes ( version_params ) params . require ( :version ) . permit ( :parent , :notes , :session_report , :active , settings : [ :display_progressbar ] , survey_detail_attributes : [ :title , :description ] ) @version = if version_params [ :parent ] . present? Helena :: VersionPublisher . publish ( @survey . versions . find ( version_params [ :parent ] ) ) else @survey . versions . build version : ( @survey . newest_version . version + 1 ) end", "del_tokens": "build_version && @version . update_attributes ( version_params ) params . require ( :version ) . permit ( :notes , :session_report , :active , settings : [ :display_progressbar ] , survey_detail_attributes : [ :title , :description ] ) if source_version @version = Helena :: VersionPublisher . publish ( source_version ) else @version = @survey . versions . build end end def source_version @survey . newest_version", "commit_type": "use"}
{"commit_tokens": ["Added", "pry", "launchy", "and", "spec", "running", "advice", "to", "the", "Readme"], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "to", "comparison", "runner"], "add_tokens": "validate_files ( \"simple_properties\" , :json_model ) validate_files ( \"complex_properties\" , :json_model ) validate_files ( \"defs_and_refs\" , :json_model ) end def test_mantle validate_files ( \"mantle\" , :mantle ) def validate_files ( example_name , type ) run_generate ( example_name , type ) def run_generate ( example_name , type ) cmd = \"bundle exec nidyx \" << example_schema_path ( example_name ) << \" #{PREFIX} #{TMP_PATH} -n \" case type when :json_model cmd << \"--json-model\" when :mantle cmd << \"--mantle\" end assert ( false ) unless system ( cmd )", "del_tokens": "validate_files ( \"simple_properties\" ) validate_files ( \"complex_properties\" ) validate_files ( \"defs_and_refs\" ) def validate_files ( example_name ) run_generate ( example_name ) def run_generate ( example_name ) res = system ( \"bundle exec nidyx \" + example_schema_path ( example_name ) + \" #{PREFIX} #{TMP_PATH} -j -n\" ) assert ( false ) unless res", "commit_type": "add"}
{"commit_tokens": ["added", "Ooor", ".", "loaded?", "feature", "as", "requested", "by", "Homecinesolutions", ".", "fr", ";", "allows", "to", "test", "if", "Ooor", "is", "already", "loaded", ".", "Else", "reload", "using", "Ooor", ".", "reload!", "(", "lambda", "{}", ")"], "add_tokens": "def self . loaded? OpenObjectResource . all_loaded_models . is_a? Array and OpenObjectResource . all_loaded_models . size > 0 end Ooor . load_core_classes", "del_tokens": "self . load_core_classes", "commit_type": "add"}
{"commit_tokens": ["Move", "to", "using", "constants", "file"], "add_tokens": "require 'minicron/constants'", "del_tokens": "DEFAULT_CONFIG_FILE = '/etc/minicron.toml'", "commit_type": "move"}
{"commit_tokens": ["Using", "clone", "to", "make", "sure", "that", "complex", "objects", "can", "be", "used", "as", "defaults"], "add_tokens": "if value . blank? && options [ :default ] default = clone_attribute ( options [ :default ] ) self . instance_variable_set ( \"@#{name}\" , default ) default else value end", "del_tokens": "default = options [ :default ] value . blank? ? default : value", "commit_type": "use"}
{"commit_tokens": ["use", "auth_object", "for", "third", "party", "registry", "authentication"], "add_tokens": "require 'hyperb/auth_object' additional_headers [ :x_registry_auth ] = Hyperb :: AuthObject . new ( params [ :x_registry_auth ] ) . encode if params . has_key? ( :x_registry_auth )", "del_tokens": "additional_headers [ :x_registry_auth ] = Base64 . urlsafe_encode64 ( params [ :x_registry_auth ] . to_json ) if params . has_key? ( :x_registry_auth )", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "Binary", "and", "Text", "inherit", "from", "the", "String", "attribute"], "add_tokens": "class Binary < String", "del_tokens": "class Binary < Object", "commit_type": "make"}
{"commit_tokens": ["Add", "HighLine", "for", "platform", "independant", "shell", "width"], "add_tokens": "require 'highline/system_extensions' CLR = \"#{(2..HighLine::SystemExtensions.terminal_size[0]).map{' '}.join}\\r\" HighLine :: SystemExtensions . terminal_size . first", "del_tokens": "require 'curses' CLR = \" \\r\" Curses . init_screen cols = Curses . cols Curses . close_screen cols", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "everything", "dies", "if", "there", "s", "no", "attached", "file", "."], "add_tokens": "if self . valid? attrs = self . attributes uploads = build_draft_uploads ( attrs ) self . build_draft ( :data => attrs ) self . draft . save! self . draft . draft_uploads << uploads self . draft end file = File . new ( cw_uploader . file . path ) if cw_uploader . file", "del_tokens": "attrs = self . attributes uploads = build_draft_uploads ( attrs ) self . build_draft ( :data => attrs ) self . draft . save! self . draft . draft_uploads << uploads self . draft file = File . new ( cw_uploader . file . path )", "commit_type": "fix"}
{"commit_tokens": ["Added", "octopress", "-", "multilingual", "to", "list", "of", "gems", "which", "can", "extend", "the", "CLI"], "add_tokens": "VERSION = \"3.0.0.rc.32\"", "del_tokens": "VERSION = \"3.0.0.rc.31\"", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "root", "to", "the", "testcase", "."], "add_tokens": "desc \"Document root\" get do end \"XAuthToken\" => { description : \"A required header.\" , required : true } ,", "del_tokens": "\"XAuthToken\" => { description : \"A required header.\" , required : true } ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "#hex", "to", "set", "HEX", "class"], "add_tokens": "@hex ||= HEX . new rgb . to_hex", "del_tokens": "@hex ||= rgb . to_hex", "commit_type": "fix"}
{"commit_tokens": ["change", "test", "order", "so", "delete", "user", "now", "run", "correctly"], "add_tokens": "describe '#change_people_status' do it_should_behave_like 'an api request' do let ( :command ) { :change_people_status } let ( :args ) { [ 'Terminated' , DATA_COLLECTOR [ :new_user_ids ] ] } end end", "del_tokens": "describe '#change_people_status' do it_should_behave_like 'an api request' do let ( :command ) { :change_people_status } let ( :args ) { [ USER_STATUSES . sample , DATA_COLLECTOR [ :new_user_ids ] ] } end end", "commit_type": "change"}
{"commit_tokens": ["Moving", "over", "the", "PatientImporter", "from", "QME"], "add_tokens": "require_relative 'health-data-standards/import/c32/section_importer' require_relative 'health-data-standards/import/c32/patient_importer'", "del_tokens": "require_relative 'health-data-standards/import/c32/section_importer'", "commit_type": "move"}
{"commit_tokens": ["update", "README", "about", "config", ".", "cache_classes"], "add_tokens": "models . each do | clazz | clazz . send :acts_as_audited unless clazz . respond_to? ( :disable_auditing ) # disable ActiveRecord callbacks, which are replaced by the AuditSweeper clazz . send :disable_auditing end", "del_tokens": "models . each do | clazz | clazz . send :acts_as_audited unless clazz . respond_to? ( :disable_auditing ) # disable ActiveRecord callbacks, which are replaced by the AuditSweeper clazz . send :disable_auditing end", "commit_type": "update"}
{"commit_tokens": ["Added", "basic", "spec", "for", "Price", "class"], "add_tokens": "xml_name \"Price\" xml_accessor :price_type_code , :from => \"PriceTypeCode\" , :as => Fixnum , :to_xml => ONIX :: Formatters . two_digit xml_accessor :price_type_qualifier , :from => \"PriceTypeQualifier\" , :as => Fixnum , :to_xml => ONIX :: Formatters . two_digit xml_accessor :price_per , :from => \"PricePer\" , :as => Fixnum , :to_xml => ONIX :: Formatters . two_digit xml_accessor :minimum_order_qty , :from => \"MinimumOrderQuantity\" , :as => Fixnum xml_accessor :price_status , :from => \"PriceStatus\" , :as => Fixnum , :to_xml => ONIX :: Formatters . two_digit xml_accessor :price_amount , :from => \"PriceAmount\" , :as => BigDecimal , :to_xml => ONIX :: Formatters . decimal", "del_tokens": "xml_accessor :price_type_code , :from => \"PriceTypeCode\" , :as => Fixnum # should be a 2 digit num xml_accessor :price_type_qualifier , :from => \"PriceTypeQualifier\" xml_accessor :price_per , :from => \"PricePer\" xml_accessor :minimum_order_qty , :from => \"MinimumOrderQuantity\" xml_accessor :price_status , :from => \"PriceStatus\" xml_accessor :price_amount , :from => \"PriceAmount\"", "commit_type": "add"}
{"commit_tokens": ["fix", "to_schema", "method", "for", "booleang"], "add_tokens": "klass . attribute ( attribute_name , :: Trax :: Model :: Attributes :: Types :: Boolean :: TypeCaster . new ) { :name => attribute_name , :type => type . to_s , :source => name , :values => values } end private def self . attribute_name name . demodulize . underscore end def self . values [ true , false ]", "del_tokens": "klass . attribute ( attribute_name , :: Trax :: Model :: Attributes :: Types :: Boolean . new ( target_klass : attributes_klass ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "tautology", "instance", "to", "simplify", "VeritasMapper", ".", "find"], "add_tokens": "TAUTOLOGY = Veritas :: Function :: Proposition :: Tautology . instance restriction = relation . restrict do | r | conditions . inject ( TAUTOLOGY ) do | predicate , ( attribute , value ) | predicate . and ( r . send ( field ) . eq ( value ) ) new ( restriction ) def self . relation @relation ||= DataMapper [ model ] . relation end", "del_tokens": "relation = DataMapper [ model ] . relation conditions . each do | attribute , value | relation = relation . restrict do | r | r . send ( field ) . eq ( value ) new ( relation )", "commit_type": "use"}
{"commit_tokens": ["Make", "cache", "constants", "private", "in", "QueryModel"], "add_tokens": "Cache = Struct . new ( :block_index , :items ) CACHE_SIZE = 256 CACHE_COUNT = 4", "del_tokens": "Cache = Struct . new ( :block_index , :items ) CACHE_SIZE = 256 CACHE_COUNT = 4", "commit_type": "make"}
{"commit_tokens": ["Add", "grande", "to", "supported", "image", "size", "variants", "."], "add_tokens": "[ :pico , :icon , :thumb , :small , :compact , :medium , :large , :grande , :original ] . each do | m |", "del_tokens": "[ :pico , :icon , :thumb , :small , :compact , :medium , :large , :original ] . each do | m |", "commit_type": "add"}
{"commit_tokens": ["adds", "ability", "to", "set", "a", "global", "table", "so", "as", "to", "not", "have", "to", "specify", "a", "table", "name", "with", "every", "new", "instance"], "add_tokens": "@table = Tables . current", "del_tokens": "@table = { }", "commit_type": "add"}
{"commit_tokens": ["improved", "factory", "-", "now", "takes", "args", "even", "for", "proc", "or", "lambda"], "add_tokens": "factory_method = @factory ? :call_factory : :default_factory send ( factory_method , obj , opts ) end def call_factory obj = nil , opts = { } @factory . respond_to? ( :call ) ? @factory . call ( obj , opts ) : @factory", "del_tokens": "@factory || default_factory ( obj , opts )", "commit_type": "improve"}
{"commit_tokens": ["Improved", "DataSet#print_rt", "to", "include", "more", "info"], "add_tokens": "# Prints the nested structure of patient - study - series - images that # have been loaded in the DataSet instance. # Prints the nested structure of the DataSet from a radiotherapy point of # view, where the various series beneath the patient-study level in a # hiearchy of image series, structure set, rt plan, rt dose and rt image, # in accordance with the object hiearchy used by RTKIT. puts \" Study (UID: #{st.uid})\" puts \" #{is.modality} (#{is.images.length} images - UID: #{is.uid})\" puts \" StructureSet (#{struct.rois.length} ROIs - UID: #{struct.uid})\" puts \" RTPlan (#{plan.beams.length} beams - UID: #{plan.uid})\" puts \" RTDose (#{rt_dose.volumes.length} volumes - UID: #{rt_dose.uid})\" puts \" RTImage (#{rt_image.images.length} images - UID: #{rt_image.uid})\"", "del_tokens": "# Prints the nested structure of patient - study - series - images that have been loaded to the dataset instance. # Prints the nested structure of patient - study - modalities from # a RT point of view, with image_series - ss - plan, etc. puts \" #{st.uid}\" puts \" #{is.modality} (#{is.images.length} images)\" puts \" StructureSet\" puts \" RTPlan\" puts \" RTDose\" puts \" RTImage\"", "commit_type": "improve"}
{"commit_tokens": ["Implement", "mirrored", "values", "inside", "namespaces", "declared", "as", "hashes", "."], "add_tokens": "result . concat process_tree ( \"#{property}:#{key}\" , value . is_a? ( Symbol ) ? meta_tags [ value ] : value )", "del_tokens": "result . concat process_tree ( \"#{property}:#{key}\" , value )", "commit_type": "implement"}
{"commit_tokens": ["Update", "ChangeLog", "and", "bump", "version", "."], "add_tokens": "VERSION = '1.2.11.3'", "del_tokens": "VERSION = '1.2.11.2'", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "sinatra", "application", "to", "test", "Pony", "support"], "add_tokens": "When / ^I run \"([^ \\\" ]*)\" in the rails root$ / do | cmd |", "del_tokens": "When / ^I run \"([^ \\\" ]*)\"$ / do | cmd | Then / ^I should see the following summary report:$ / do | expected_report | @output . should include ( expected_report ) end", "commit_type": "add"}
{"commit_tokens": ["Allow", "reading", "channel", "cleanup", "to", "timeout", "silently"], "add_tokens": "2 . times { read ( 0.4 ) rescue nil } #Clean the reading channel", "del_tokens": "2 . times { read ( 0.4 ) } #Clean the reading channel", "commit_type": "allow"}
{"commit_tokens": ["Make", "track", "description", "and", "comment", "attr_accessor"], "add_tokens": "# array of the segments that comprise it, but additionally each track holds attr_reader :points , :bounds , :lowest_point , :highest_point , :distance , :moving_duration attr_accessor :segments , :name , :gpx_file , :description , :comment", "del_tokens": "# array of the segments that copmrise it, but additionally each track holds attr_reader :points , :bounds , :lowest_point , :highest_point , :distance , :moving_duration , :comment , :description attr_accessor :segments , :name , :gpx_file", "commit_type": "make"}
{"commit_tokens": ["Add", "get_metadata", "get_temporary_link", "and", "list_revisions", "methods"], "add_tokens": "def get_metadata ( path ) resp = request ( '/get_metadata' , path : path ) object_from_response ( resp ) end def get_temporary_link ( path ) resp = request ( '/get_temporary_link' , path : path ) return object_from_response ( resp [ 'metadata' ] , 'file' ) , resp [ 'link' ] end def list_revisions ( path ) resp = request ( '/list_revisions' , path : path ) entries = resp [ 'entries' ] . map { | e | object_from_response ( e , 'file' ) } return entries , resp [ 'is_deleted' ] end def object_from_response ( resp , tag = resp [ '.tag' ] ) case tag", "del_tokens": "def object_from_response ( resp ) case resp [ '.tag' ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "Config#method_missing", "that", "was", "swallowing", "errors"], "add_tokens": "rescue NoMethodError", "del_tokens": "rescue = > e", "commit_type": "fix"}
{"commit_tokens": ["Improve", "the", "hash", "collision", "resistance", "test", "."], "add_tokens": "keys = ( 0 .. 1000 ) . map { | i | ThreadSafe :: Test :: HashCollisionKey . new ( i , 1 ) } 10 . times do | i | size = keys . size while i < size k = keys [ i ] assert ( k . key == @cache . delete ( k ) && ! @cache . key? ( k ) && ( @cache [ k ] = k . key ; @cache [ k ] == k . key ) ) i += 10 end assert ( keys . all? { | k | @cache [ k ] == k . key } )", "del_tokens": "keys = ( 0 .. 100 ) . map { | i | ThreadSafe :: Test :: HashCollisionKey . new ( i , 1 ) } keys . each do | k | assert_equal k . key , @cache [ k ]", "commit_type": "improve"}
{"commit_tokens": ["Make", "the", "files_x", "functions", "via", "metaprogramming"], "add_tokens": "# Create files_added? methods from rugged's git API [ :added , :deleted , :modified , :renamed , :copied , :ignored , :untracked , :typechange ] . each do | symbol | question_symbol = ( symbol . to_s + \"?\" ) . to_sym define_method ( \"files_#{symbol}\" ) do @diff . deltas . select ( & question_symbol ) . map ( & :new_file ) . map { | hash | hash [ :path ] } end", "del_tokens": "# TODO: metaprogram `files_x` to be anything that rugged supports as a status? def files_modified @diff . deltas . select ( & :modified? ) . map ( & :new_file ) . map { | hash | hash [ :path ] } end def files_deleted @diff . deltas . select ( & :deleted? ) . map ( & :new_file ) . map { | hash | hash [ :path ] } end def files_added @diff . deltas . select ( & :added? ) . map ( & :new_file ) . map { | hash | hash [ :path ] }", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "subject", "example", "for", "spec", "examples", "and", "updating", "year", "License"], "add_tokens": "# :ser_matcher == :be_matcher end", "del_tokens": "# :ser_verdade == :be_verdade end", "commit_type": "add"}
{"commit_tokens": ["Fix", "HTML", "to", "pass", "in", "W3C", "tests", ".", "(", "again", ")", "."], "add_tokens": "\"#{mount_table(@parsed_routes.unshift([:path, :name, :options, :requirements]))}\"", "del_tokens": "\"<pre>#{mount_table(@parsed_routes.unshift([:path, :name, :options, :requirements]))}</pre>\"", "commit_type": "fix"}
{"commit_tokens": ["Make", "MultiFlattener", "consistent", "with", "the", "other", "filters"], "add_tokens": "exp . first == :multi ? on_multi ( * exp [ 1 .. - 1 ] ) : exp end def on_multi ( * exps ) return compile ( exps . first ) if exps . length == 1 exps . each do | exp | exp = compile ( exp ) if exp . first == :multi result . concat ( exp [ 1 .. - 1 ] ) result << exp end", "del_tokens": "return exp unless exp . first == :multi return compile ( exp [ 1 ] ) if exp . length == 2 exp [ 1 .. - 1 ] . each do | e | e = compile ( e ) if e . first == :multi result . concat ( e [ 1 .. - 1 ] ) result << e end", "commit_type": "make"}
{"commit_tokens": ["adding", "ability", "to", "run", "as", "pre", "-", "commit", "hook"], "add_tokens": "RakeCommandFilter :: RubocopCommandDefinition . failure_msg ( 2 , 1 ) )", "del_tokens": "RakeCommandFilter :: RubocopCommandDefinition . failure_msg ( 3 , 1 ) )", "commit_type": "add"}
{"commit_tokens": ["remove", "[", "Alipay", "]", "label", "in", "raise", "message", "exception", "info", "is", "enough"], "add_tokens": "raise ArgumentError , \"invalid sign_type #{sign_type}, allow value: 'MD5', 'RSA', 'DSA'\"", "del_tokens": "raise ArgumentError , \"[Alipay] Invalid sign_type #{sign_type}, allow value: 'MD5', 'RSA', 'DSA'\"", "commit_type": "remove"}
{"commit_tokens": ["Fix", "alternative", "fields", "when", "selection", "field", "has", "higher", "field", "number", "."], "add_tokens": "# It's important to ensure that alternative fields processed after the # regular fields so that the decision field is already set. f1alt = is_alt_field? ( f1 ) f2alt = is_alt_field? ( f2 ) f1alt == f2alt ? f1 . field_definition_number . snapshot <=> f2 . field_definition_number . snapshot : f1alt ? 1 : - 1 def is_alt_field? ( field ) return false unless @gfm field_def_number = field . field_definition_number . snapshot field_def = @gfm . fields_by_number [ field_def_number ] field_def . is_a? ( GlobalFitMessage :: AltField ) end", "del_tokens": "# It's important to ensure that fields are sorted by their definition # number so that alternative fields are always processed after their # selection fields have been processed. f1 . field_definition_number . snapshot <=> f2 . field_definition_number . snapshot", "commit_type": "fix"}
{"commit_tokens": ["Remove", "deploy", "from", "project", "create"], "add_tokens": "VERSION = \"0.0.12\"", "del_tokens": "VERSION = \"0.0.11\"", "commit_type": "remove"}
{"commit_tokens": ["Using", "binmode", "for", "reading", "and", "writing", "files", "to", "preserve", "carriage", "returns", "on", "windows", "native", "files", "."], "add_tokens": "gsub ( / \\r \\n / , \"\\n\" ) . gsub ( / \\r / , \"\\n\" ) @f = @f . binmode if @f . respond_to? ( :binmode ) @cap_end_lineno = nil x = @f . readline . end_with? \"\\r\\n\" @f . lineno = 0 @cap_end_lineno = @f . lineno @f . lineno = 0 tmp . write @f . read ( opt [ :once ] ? @mark : @cap_begin_pos ) tmp . write value @f . lineno = @cap_end_lineno tmp . write @f . read @f . lineno = 0 tmp . write @f . read ( @mark ) tmp . write value tmp . write @f . read unless @tmp @tmp = File . open ( tmp_filename , 'w' ) @tmp = @tmp . binmode if @tmp . respond_to? ( :binmode ) end @tmp", "del_tokens": "gsub / ( \\r | \\n | \\r \\n ) / , \"\\n\" x = @f . readline . end_with? '\\r\\n' tmp . write @f . read ( opt [ :once ] ? @mark : @cap_begin_pos ) . normalize_eol tmp . write value . normalize_eol tmp . write @f . read . normalize_eol tmp . write @f . read ( @mark ) . normalize_eol tmp . write value . normalize_eol tmp . write @f . read . normalize_eol @tmp ||= File . open ( tmp_filename , 'w' )", "commit_type": "use"}
{"commit_tokens": ["Remove", "TODO", "-", "using", "http", ":", "//", "github", ".", "com", "/", "jarib", "/", "watirspec", "/", "issues", "/", "instead"], "add_tokens": "Process . kill 0 , pid", "del_tokens": "Process :: kill 0 , pid", "commit_type": "remove"}
{"commit_tokens": ["Added", "clean", "method", "which", "joins", "arrays", "and", "removes", "the", "initial", "colon", "."], "add_tokens": "message = words [ 3 .. - 1 ] . clean { :nick => nick . clean , :hostname => hostname }", "del_tokens": "message = words [ 3 .. - 1 ] . join ( \" \" ) . gsub ( / ^: / , '' ) { :nick => nick . gsub ( / ^: / , '' ) , :hostname => hostname }", "commit_type": "add"}
{"commit_tokens": ["added", "more", "tests", "for", "enumerations"], "add_tokens": "( ( regex . as ( :member_regex ) | q_string . as ( :member_name ) ) >> spcCmnt? >> rule ( :array_def ) { array_repetition . maybe >> spcCmnt? >> ( value_rule | group_rule | array_rule | object_rule | rule_name . as ( :target_rule_name ) ) } rule ( :array_rule ) { ( str ( '[' ) >> spcCmnt? >> array_def >> ( spcCmnt? >> ( str ( ',' ) | str ( '|' ) ) >> spcCmnt? >> array_def ) . repeat >> spcCmnt? >> str ( ']' ) ) . as ( :array_rule )", "del_tokens": "( str ( '^' ) . as ( :any_member ) . maybe >> q_string . as ( :member_name ) >> spcCmnt? >> rule ( :array_def ) { array_repetition . maybe >> spcCmnt? >> ( group_rule | array_rule | object_rule | value_rule | rule_name . as ( :target_rule_name ) ) } rule ( :array_rule ) { ( str ( '[' ) >> spcCmnt? >> array_def >> spcCmnt? >> ( ( str ( ',' ) | str ( '|' ) ) >> spcCmnt? >> array_def ) . repeat >> spcCmnt? >> str ( ']' ) ) . as ( :array_rule )", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "configure", "database", "mapping", "for", "an", "application"], "add_tokens": "require 'lotus/config/mapper' class Routes < Mapper def error_message 'You must specify a block or a file for routes definitions.'", "del_tokens": "require 'lotus/utils/kernel' class Routes EXTNAME = '.rb' def initialize ( path , & blk ) @path , @blk = path , blk end def to_proc return @blk if @blk code = realpath . read Proc . new { eval ( code ) } end def realpath Utils :: Kernel . Pathname ( \"#{ @path }#{ EXTNAME }\" ) . realpath rescue Errno :: ENOENT raise ArgumentError , 'You must specify a block or a file for routes definitions.'", "commit_type": "allow"}
{"commit_tokens": ["Use", "xdg", "-", "open", "on", "linux", "."], "add_tokens": "if RUBY_PLATFORM =~ / linux / command = 'xdg-open' else command = 'open' end ` #{ command } #{ filename } `", "del_tokens": "` open #{ filename } `", "commit_type": "use"}
{"commit_tokens": ["remove", "elimination", "of", "terms", "it", "doesn", "t", "seem", "to", "have", "helped", "with", "anything", "but", "did", "add", "enough", "complexity", "to", "introduce", "an", "odd", "bug", "."], "add_tokens": "require 'bundler' Bundler . setup ( :development )", "del_tokens": "require 'bundler/setup'", "commit_type": "remove"}
{"commit_tokens": ["change", "the", "redirect", "status", "after", "creates", "to", "201"], "add_tokens": "redirect code , 201", "del_tokens": "redirect code", "commit_type": "change"}
{"commit_tokens": ["Allow", "hostname", "to", "be", "excluded", "."], "add_tokens": "# :hostname - Optional String hostname. Set to nil # to exclude. prefix = [ options [ :stats_prefix ] || :rack ] if options . has_key? ( :hostname ) prefix << options [ :hostname ] unless options [ :hostname ] . nil? else prefix << ` hostname -s ` . chomp end @stats_prefix = prefix . join ( \".\" )", "del_tokens": "# :hostname - Optional String hostname. @hostname = options [ :hostname ] || ` hostname -s ` . chomp @stats_prefix = \"#{options[:stats_prefix] || :rack}.#{@hostname}\"", "commit_type": "allow"}
{"commit_tokens": ["Implemented", "PrimeField#square_root", "for", "primes", "that", "are", "3", "mod", "4", ".", "It", "was", "easy", "."], "add_tokens": "# This is equivalent to ec_GFp_simple_oct2point in OpenSSL: # https://github.com/openssl/openssl/blob/a898936218bc279b5d7cdf76d58a25e7a2d419cb/crypto/ec/ecp_oct.c", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Created", "an", "ability", "to", "work", "with", "the", "SoftLayer", "Model", "objects", "efficently", "in", "the", "code", ".", "Renamed", "some", "files", "to", "bring", "them", "in", "-", "line", "with", "conventions", "and", "added", "tests", "for", "new", "code"], "add_tokens": "expect { SoftLayer :: ModelBase . new ( nil , { :id => \"someID\" } ) } . not_to raise_error", "del_tokens": "expect { SoftLayer :: ModelBase . new ( nil , { :id => \"someID\" } ) } . to_not raise_error ( ArgumentError )", "commit_type": "create"}
{"commit_tokens": ["Change", "table", "rendering", "and", "add", "accessors", "for", "column", "properties", "."], "add_tokens": "# The table enforced column widths # # @return [Array] # # @api public attr_accessor :column_widths # The table column alignments # # @return [Array] # # @api public attr_reader :column_aligns # Array of Arrays expressing the rows # @option options [String] :column_aligns # @return [TTY::Table] # TODO: assert that row_size is the same as column widths & aligns render ( self ) render ( self )", "del_tokens": "# Array of Arrays expressin the rows # @option options [String] :alignments # @return [Table] extract_column_widths ( rows ) render ( rows , :column_widths => @column_widths , :column_aligns => @column_aligns )", "commit_type": "change"}
{"commit_tokens": ["Add", "more", "detail", "about", "the", "object", "being", "cached", "to", "log", "messages"], "add_tokens": "# update the collection only if this is a subset of it object && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} READ #{object.class}:#{object.send(primary_key)} #{key}\" ) result && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} WRITE #{object.class}:#{object.send(primary_key)} #{key}\" )", "del_tokens": "object && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} READ #{key}\" ) result && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} WRITE #{key}\" )", "commit_type": "add"}
{"commit_tokens": ["allow", "passing", "options", "to", "respond_with", "and", "consume!", "which", "are", "propagated", "to", "the", "representer", "."], "add_tokens": "representer . send ( compute_parsing_method ( format ) , incoming_string , options ) # e.g. from_json(\"...\")", "del_tokens": "representer . send ( compute_parsing_method ( format ) , incoming_string ) # e.g. from_json(\"...\")", "commit_type": "allow"}
{"commit_tokens": ["Add", "links", "to", "JSON", "reports", "."], "add_tokens": "issues_with_label : with_label_links ( num_with_label ( issues ) , data . repository ) , issues_with_no_label : { link : nil , total : num_with_no_label ( issues ) } , def with_label_links ( labels , repository ) labels . map do | label , num_issues | label_link = \"https://github.com/#{repository}/issues?q=\" + CGI . escape ( \"is:open is:issue label:\\\"#{label}\\\"\" ) [ label , { link : label_link , total : num_issues } ] end . to_h end", "del_tokens": "issues_with_label : num_with_label ( issues ) , issues_with_no_label : num_with_no_label ( issues ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "test", "for", "some", "params", "and", "all", "params"], "add_tokens": "test \"should respond with ok status with some params\" do test \"should respond with ok status with all params\" do params = { \"message\" : \"A message\" , \"file_or_page\" : \"A file or page\" , \"line_number\" : \"A line number\" , \"user_agent\" : \"A user agent\" , \"current_page\" : \"A current page\" , \"column_number\" : \"A column number\" , \"stack_trace\" : \"A stack trace\" } xhr :post , :create , params assert_response :ok end", "del_tokens": "test \"should respond with ok status with params\" do", "commit_type": "add"}
{"commit_tokens": ["Fixed", "small", "typesig", "logic", "error"], "add_tokens": "def typeToCtc #TODO: Implement this end prmctc = ( ( prmctc && typ . is_a? PreCtc ) ? AandCtc . new ( \"User Precondition\" , typ , prmctc ) : typ ) retctc = ( ( retctc && typ . is_a? PostCtc ) ? AandCtc . new ( \"User Postcondition\" , typ , prmctc ) : typ ) unless typ . is_a? Hash raise RDL :: InvalidParameterException , \"Invalid input to typesig. Expecting Contract received #{typ.class}!\" end prmctc = AandCtc . new ( \"Input Parameters\" , typeToCtc ( typ ) , prmctc ) prmctc = typeToCtc ( typ ) #TODO: Return Type", "del_tokens": "prmctc = ( prmctc ? AandCtc . new ( \"User Precondition\" , typ , prmctc ) : typ ) raise RDL :: InvalidParameterException , \"Invalid input to typesig. Expecting Contract received #{typ.class}!\" unless typ . is_a? Hash prmctc = AandCtc . new ( \"Input Parameter Type\" , typ , prmctc ) prmctc = RootCtc . new ( \"Input Parameter Type\" ) { typ } #TODO: Output Parameter Type and Post conditions", "commit_type": "fix"}
{"commit_tokens": ["Fix", "review", "issues", ":", "any", "and", "utf8", "declaration"], "add_tokens": "if missing_keys . any?", "del_tokens": "if ! missing_keys . empty?", "commit_type": "fix"}
{"commit_tokens": ["create", "CardTable", ".", "buy_link", "(", "id", ")", "that", "works", "w", "/", "CLI", "&", "Parser", "class"], "add_tokens": "def self . buy_link ( id ) name = self . find ( id ) word = name . card + \" \" + name . sets word . gsub! ( / \\s + /m , '%20' ) buy = \"http://www.ebay.com/sch/?_nkw=#{word}&_sacat=0\" puts buy end date = \"#{Time.now}\" [ 0 .. 9 ] . gsub! ( \"-\" , \"_\" ) fname = \"#{date}.csv\" #naming the csv file with today's date value . each { | find | find . gsub! ( \", \" , \"_\" ) if find . is_a? ( String ) } #iterates through the row's values to replace commas so as to avoid line breaking errors", "del_tokens": "fname = \"cards.csv\" #naming the csv file value . each { | find | find . sub! ( \", \" , \"_\" ) if find . is_a? ( String ) } #iterates through the row's values to replace commas so as to avoid line breaking errors", "commit_type": "create"}
{"commit_tokens": ["moved", "request", "methods", "from", "HTTPI", "::", "Client", "to", "the", "HTTPI", "module", "itself"], "add_tokens": "describe HTTPI do let ( :client ) { HTTPI }", "del_tokens": "describe HTTPI :: Client do let ( :client ) { HTTPI :: Client }", "commit_type": "move"}
{"commit_tokens": ["Added", "execution_time", "to", "iterates", "when", "an", "error", "happens"], "add_tokens": "require 'time' start = Time . now log . info ( \"#{Rainbow(\"#{r[:host]}:#{r[:port]}\").red}: #{e.message}; \" \"errors=#{errors}; \" \"execution_time=#{Time.now - start} seconds\" )", "del_tokens": "log . info ( \"#{Rainbow(\"#{r[:host]}:#{r[:port]}\").red}: #{e.message}; errors=#{errors}\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "RAILS_GEM_VERSION", "back", "in", "since", "I", "was", "getting", "this", "error", "when", "I"], "add_tokens": "RAILS_GEM_VERSION = '2.3.5' unless defined? RAILS_GEM_VERSION", "del_tokens": "#RAILS_GEM_VERSION = '2.3.2' unless defined? RAILS_GEM_VERSION", "commit_type": "add"}
{"commit_tokens": ["Updated", "gemspec", "information", "and", "development", "dependencies", "."], "add_tokens": "VERSION = \"0.2.3\"", "del_tokens": "VERSION = \"0.2.2\"", "commit_type": "update"}
{"commit_tokens": ["Fix", "problem", "with", "sub", "versions", "of", "TW"], "add_tokens": "std_ver = raw . chomp . gsub ( ' ' , '.' ) . delete ( '(' ) . delete ( ')' ) p std_ver", "del_tokens": "private std_ver = raw . chomp . gsub ( ' ' , '.' ) . delete ( '(' , ')' )", "commit_type": "fix"}
{"commit_tokens": ["Added", "simple", "graceful", "error", "output"], "add_tokens": "if @settings [ :raise_errors ] raise $! else puts \"Error:\\n #{$!.message}\" exit 1 end", "del_tokens": "raise $! if @settings [ :raise_errors ] exit 1", "commit_type": "add"}
{"commit_tokens": ["Use", "absolute", "URL", "in", "Location", "header"], "add_tokens": "file_url = \"#{request.url.chomp(\"/\")}/#{uid}\"", "del_tokens": "file_url = \"/#{base_path}/#{uid}\"", "commit_type": "use"}
{"commit_tokens": ["Implemented", "/", "on", "Ldaptor", "classes", "and", "instances"], "add_tokens": "if dn . kind_of? ( :: LDAP :: DN ) if source dn = dn . dup dn . source = source end return dn end", "del_tokens": "return dn if dn . kind_of? ( :: LDAP :: DN )", "commit_type": "implement"}
{"commit_tokens": ["Remove", "internal", "methods", "from", "doc"], "add_tokens": "def self . build ( h , type ) # :nodoc: def initialize ( h , type ) # :nodoc:", "del_tokens": "def self . build ( h , type ) def initialize ( h , type )", "commit_type": "remove"}
{"commit_tokens": ["Added", "some", "tests", "for", "[]", "and", "[]", "="], "add_tokens": "m = M . new O , 3 , 2 for j in 0 ... 2 for i in 0 ... 3 assert_equal i + j * 3 + 1 , m [ j ] [ i ] = i + j * 3 + 1 end end for j in 0 ... 2 for i in 0 ... 3 assert_equal i + j * 3 + 1 , m [ j ] [ i ] end end assert_equal [ 4 , 5 , 6 ] , m [ 1 ] . to_a assert_equal 7 , m [ 1 ] = 7 assert_equal [ [ 1 , 2 , 3 ] , [ 7 , 7 , 7 ] ] , m . to_a", "del_tokens": "# !!!", "commit_type": "add"}
{"commit_tokens": ["Adding", "method", "to", "get", "an", "embedded", "flow", "url", "for", "a", "token"], "add_tokens": "require File . dirname ( __FILE__ ) + '/test_helper' def test_redirect_url_for assert response = @gateway . setup_purchase ( fixtures ( :pay_options ) ) refute_nil key = response [ \"pay_key\" ] url = @gateway . redirect_url_for ( key ) assert_match / #{ key } $ / , url , \"Could not generate the proper redirect_url_for URL\" end def test_embedded_flow_url_for assert response = @gateway . setup_purchase ( fixtures ( :pay_options ) ) refute_nil key = response [ \"pay_key\" ] url = @gateway . embedded_flow_url_for ( key ) assert_match / #{ key } $ / , url , \"Could not generate the proper embedded_flow_url_for URL\" end", "del_tokens": "require './test_helper'", "commit_type": "add"}
{"commit_tokens": ["Use", "hash", "in", "config", "for", "repositories", "."], "add_tokens": "# # uses repository at https://github.com/razor-x/my_app # # and installs to apps/my_app # - :name: my_app # :path: apps/my_app # # # uses repository at https://bitbucket.org/razorx/sub_app # # and installs to apps/my_app from git reference v1.0.0 # - :name: sub_app # :path: apps/my_app/sub_app # :reference: v1.0.0 # :server: apps/my_app e . name = repo [ :name ] e . source = repo [ :server ] . nil? ? config [ :externals ] [ :server ] : repo [ :server ] e . reference = repo [ :reference ] unless repo [ :reference ] . nil? e . install_path = File . join directory , repo [ :path ]", "del_tokens": "# #- [ name, install_path, reference (optional), server (optional) ] # - [ my_app, apps/my_app ] # - [ sub_app, apps/my_app/sub_app, my_feature, \"https://bitbucket.org/razorx\" ] e . name = repo [ 0 ] e . source = repo [ 3 ] . nil? ? config [ :externals ] [ :server ] : repo [ 3 ] e . reference = repo [ 2 ] unless repo [ 2 ] . nil? e . install_path = File . join directory , repo [ 1 ]", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "in", "Auditable#last_change_of", "method"], "add_tokens": "index = audits . count index -= 1 prev_audit = audits [ index - 1 ] if index > 0", "del_tokens": "prev_audit = nil prev_audit = audit", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "interpolation", "to", "SingleLinePerSelectorLinter"], "add_tokens": "add_lint ( node ) if invalid_comma_placement? node private # A comma is invalid if it starts the line or is not the end of the line def invalid_comma_placement? ( node ) normalize_spacing ( condense_to_string ( node . rule ) ) =~ / \\n ,|,[^ \\n ] / end # Since RuleNode.rule returns an array containing both String and # Sass::Script::Nodes, we need to condense it into a single string that we # can run a regex against. def condense_to_string ( sequence_list ) sequence_list . inject ( '' ) do | combined , string_or_script | combined + ( string_or_script . is_a? ( String ) ? string_or_script : string_or_script . to_sass ) end end # Removes extra spacing between lines in a comma-separated sequence due to # comments being removed in the parse phase. This makes it easy to check if # a comma is where belongs. def normalize_spacing ( string_sequence ) string_sequence . gsub ( / ,[^ \\S \\n ]* \\n \\s * / , \",\\n\" ) end", "del_tokens": "add_lint ( node ) unless node . rule . grep ( / ,[^ \\n ] / ) . empty?", "commit_type": "add"}
{"commit_tokens": ["Fix", "ssh", "command", "when", "using", "multiple", "ASGs"], "add_tokens": "parser . on ( '-s' , '--instance INSTANCE_ID' , 'Specific AWS EC2 ID to connect to' ) do | v |", "del_tokens": "parser . on ( '-s' , '--instance INSTANCE_ID' , 'Specific AWS EC2 ID to connect through' ) do | v |", "commit_type": "fix"}
{"commit_tokens": ["Use", "nil", "instead", "of", "@user", ".", "id", "in", "the", "text", "for", "a", "logged", "-", "out", "user"], "add_tokens": "expected_value = nil", "del_tokens": "expected_value = @user . id", "commit_type": "use"}
{"commit_tokens": ["Add", "mapping", "for", "export_affiliate_bills", "and", "export_advertiser_bills"], "add_tokens": "VERSION = '0.2.8'", "del_tokens": "VERSION = '0.2.7'", "commit_type": "add"}
{"commit_tokens": ["Updating", "the", "name", "from", "the", "migration", "template"], "add_tokens": "migration_template 'create_apicasso_tables.rb' , end", "del_tokens": "migration_template 'create_something.rb' , end", "commit_type": "update"}
{"commit_tokens": ["Fixed", "Iord", "::", "OutputHelper", ".", "image", "and", "its", "call", "in", "Iord", "::", "Field"], "add_tokens": "o . image resource . public_send ( * attr [ :image ] ) , attr [ :params ]", "del_tokens": "o . image_tag resource . public_send ( * attr [ :image ] ) , attr [ :params ]", "commit_type": "fix"}
{"commit_tokens": ["added", "some", "helper", "methods", "for", "web", "scraping"], "add_tokens": "p k d = Dummy . new 1 , 2 , :name => 'Bartolo' , :email => 'j'", "del_tokens": "puts k d = Dummy . new 1 , 2 , :name => 'Bartolo' , :j => 2 , :i => 3", "commit_type": "add"}
{"commit_tokens": ["Added", "to", "readme", ".", "Minor", "parameter", "swap", "in", "GenericFolder", "::", "get_folder"], "add_tokens": "def self . get_folder ( folder_id , act_as = nil , folder_shape = { :base_shape => 'Default' } )", "del_tokens": "def self . get_folder ( folder_id , folder_shape = { :base_shape => 'Default' } , act_as = nil )", "commit_type": "add"}
{"commit_tokens": ["Fix", "method", "typo", ":", "validate", "-", ">", "validates"], "add_tokens": "validates :commenter , presence : true validates :commentable , presence : true validates :comment , presence : true", "del_tokens": "validate :commenter , presence : true validate :commentable , presence : true validate :comment , presence : true", "commit_type": "fix"}
{"commit_tokens": ["add", "liblist", "and", "naming", "support"], "add_tokens": "@connection . execute_update \"CALL qsys.qcmdexc('QSYS/CHGJOB INQMSGRPY(*SYSRPYL)', 0000000031.00000)\" @connection . execute_update \"CALL qsys.qcmdexc('ADDRPYLE SEQNBR(9876) MSGID(CPA32B2) RPY(''I'')', 0000000045.00000)\" @connection . execute_update \"CALL qsys.qcmdexc('QSYS/CHGJOB INQMSGRPY(*DFT)', 0000000027.00000)\" @connection . execute_update \"CALL qsys.qcmdexc('RMVRPYLE SEQNBR(9876)', 0000000021.00000)\" # Disable all schemas browsing @connection . table_exists? ( name , db2_schema ) end def indexes ( table_name , name = nil ) @connection . indexes ( table_name , name , db2_schema ) # Do not return *LIBL as schema def schema system_naming? ? nil : db2_schema # If naming is really in system mode CURRENT_SCHEMA is *LIBL def system_naming? @db2_schema == '*LIBL' end # SET SCHEMA statement put connection in sql naming def set_schema ( schema ) execute ( \"SET SCHEMA #{schema}\" ) unless system_naming? end return @db2_schema if defined? @db2_schema else result [ '00001' ]", "del_tokens": "@connection . execute_update \"call qsys.qcmdexc('QSYS/CHGJOB INQMSGRPY(*SYSRPYL)',0000000031.00000)\" @connection . execute_update \"call qsys.qcmdexc('ADDRPYLE SEQNBR(9876) MSGID(CPA32B2) RPY(''I'')',0000000045.00000)\" @connection . execute_update \"call qsys.qcmdexc('QSYS/CHGJOB INQMSGRPY(*DFT)',0000000027.00000)\" @connection . execute_update \"call qsys.qcmdexc('RMVRPYLE SEQNBR(9876)',0000000021.00000)\" # disable all schemas browsing when default schema is specified schema ? @connection . table_exists? ( name , schema ) : @connection . table_exists? ( name ) # @private # @deprecated no longer used def as400? true @db2_schema = false unless defined? @db2_schema return @db2_schema if @db2_schema != false elsif config [ :jndi ] . present? schema = result [ '00001' ] # If the connection uses the library list schema name will be nil if schema == '*LIBL' schema = nil end schema else # AS400 implementation takes schema from library name (last part of URL) # jdbc:as400://localhost/schema;naming=system;libraries=lib1,lib2 schema = nil split = config [ :url ] . split ( '/' ) # Return nil if schema isn't defined schema = split . last . split ( ';' ) . first . strip if split . size == 4 schema", "commit_type": "add"}
{"commit_tokens": ["fix", "all", "method", "to", "properly", "get", "all", "results"], "add_tokens": "def all ( filters = { } ) accum = [ ] Clever :: APIOperations :: PageList . new ( url , filters ) . each do | page | accum += page . all end accum", "del_tokens": "def all ( filters = { } ) response = Clever . request ( :get , url , filters ) Util . convert_to_clever_object ( response [ :data ] )", "commit_type": "fix"}
{"commit_tokens": ["Added", "comment", "tag", "to", "line", "21"], "add_tokens": "# for the UI.", "del_tokens": "for the UI .", "commit_type": "add"}
{"commit_tokens": ["use", "thread", "to", "support", "longtime", "job", "while", "provisioning"], "add_tokens": "EM . defer { on_provision ( msg , reply ) }", "del_tokens": "on_provision ( msg , reply )", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "bug", "where", "the", "resources", "/", "folder", "was", "not", "being", "uploaded"], "add_tokens": "'resources/*.rb' ,", "del_tokens": "'resources/.*.rb' ,", "commit_type": "fix"}
{"commit_tokens": ["move", "slide", "to", "its", "own", "file"], "add_tokens": "require 'slideshow/slide' VERSION = '0.9'", "del_tokens": "VERSION = '0.8.5'", "commit_type": "move"}
{"commit_tokens": ["make", "spec", "work", "cross", "platform"], "add_tokens": "build_content . reject! { | c | %w{ . .. } . include? c } expect ( build_content ) . to eq [ \"file\" ]", "del_tokens": "expect ( build_content ) . to eq [ \".\" , \"..\" , \"file\" ]", "commit_type": "make"}
{"commit_tokens": ["adds", "basic", "full", "match", "test", ";", "whitespace", "change"], "add_tokens": "damage = ( shell . fire_power ** RTanque :: Shell :: RATIO )", "del_tokens": "damage = ( shell . fire_power ** RTanque :: Shell :: RATIO )", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "entry", "XML", "generating", "method"], "add_tokens": "xml % [ title , author_name , content , categories_tag , draft ]", "del_tokens": "xml % [ title , @user_id , content , categories_tag , draft ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "in", "excel", "to", "report", "last", "calculated", "val", "for", "formulas"], "add_tokens": "next if cell . class == Spreadsheet :: Formula && cell . value . nil? # skip empty formla cells cell = cell . value if cell . class == Spreadsheet :: Formula", "del_tokens": "next if cell . class == Spreadsheet :: Formula", "commit_type": "add"}
{"commit_tokens": ["Added", "csv", "and", "text", "formats"], "add_tokens": "# List of formats supported by SmartAdapters FORMATS = %i[ json html js xml text csv ] FORMATS . each do | format_name | # Verify if the request format is valid. # @return [Boolean] define_method \"#{format_name}?\" do request_format . try ( :\" #{ format_name } ? \" ) end # Check if the request has a valid format. def valid_format? FORMATS . map { | format | send ( \"#{format}?\" ) } . any?", "del_tokens": "# Is json request? # @return [Boolean] def json? request_format . json? end # Is html request? # @return [Boolean] def html? request_format . html? end # Is js request? # @return [Boolean] def js? request_format . js? # Is xml request? def xml? request_format . xml? # Check if the request has a valid format. # @return [Boolean] def valid_format? json? || html? || js? || xml? end", "commit_type": "add"}
{"commit_tokens": ["implement", "joining", "on", "multiple", "columns", "with", "Join"], "add_tokens": "@insert_cols = ( options [ :insert ] || \"\" ) . split ( / ,|; / )", "del_tokens": "@insert_cols = ( options [ :insert ] || \"\" ) . split ( ',' )", "commit_type": "implement"}
{"commit_tokens": ["Added", "options", "comments", "and", "removed", "selectors", "cache"], "add_tokens": "@weights = { count : { } , first : { } , next : { } , last : { } } self . word = Unicode . downcase ( stripped_word ) unless stripped_word == '' string = word_count . times . map { word } . join ( ' ' ) selector = WeightedSelect :: Selector . new @weights [ type ] [ group ] selector . select", "del_tokens": "@selectors = { count : { } , first : { } , next : { } , last : { } } @weights = { count : { } , first : { } , next : { } , last : { } } self . word = Unicode . downcase ( stripped_word ) unless stripped_word == '' string = word_count . times . map { word } . join ( ' ' ) @selectors [ type ] [ group ] ||= WeightedSelect :: Selector . new @weights [ type ] [ group ] @selectors [ type ] [ group ] . select", "commit_type": "add"}
{"commit_tokens": ["Use", "index", "if", "perform", "caching"], "add_tokens": "if config . action_controller . perform_caching @assets = @assets . index end @assets", "del_tokens": "if app . config . assets . digest app . assets = app . assets . index end", "commit_type": "use"}
{"commit_tokens": ["Fix", "specs", "to", "test", "prefixes", "for", "non", "-", "base", "units"], "add_tokens": "es = Unitwise :: Unit :: Expression . new ( \"kN/cm2\" ) . expressions es . map ( & :prefix ) . must_equal [ 'k' , 'c' ]", "del_tokens": "es = Unitwise :: Unit :: Expression . new ( \"N/cm2\" ) . expressions es . map ( & :prefix ) . must_equal [ nil , 'c' ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "to", "use", "label", ":", "false", "when", "you", "don", "t", "want", "a", "label"], "add_tokens": "require 'test_helper' it \"should make a text_field with no label\" do out = %Q|<input type=\"text\" id=\"a-nil\" name=\"builder_tester[a_nil]\">| assert_equal out , @form . text_field ( :a_nil , label : false ) end # Consolidated test runs so setup can be shared it \"should make an association select with various options\" do assert_equal out , @form . association_select ( Sample ) , \"default output is wrong\" out2 = %Q|<label for=\"sample-id\">Custom Label</label>| + %Q|<select id=\"sample-id\" name=\"builder_tester[sample_id]\">| + %Q|<option></option>| + %Q|<option value=\"1\" selected>Tester</option>| + %Q|<option value=\"2\">Foobar</option>| + %Q|</select>| assert_equal out2 , @form . association_select ( Sample , label : \"Custom Label\" ) , \"custom label output is wrong\" out3 = %Q|<select id=\"sample-id\" name=\"builder_tester[sample_id]\">| + %Q|<option></option>| + %Q|<option value=\"1\" selected>Tester</option>| + %Q|<option value=\"2\">Foobar</option>| + %Q|</select>| assert_equal out3 , @form . association_select ( Sample , label : false ) , \"no label output is wrong\"", "del_tokens": "'test_helper' it \"should make an association select\" do assert_equal out , @form . association_select ( Sample )", "commit_type": "add"}
{"commit_tokens": ["Updated", "WSOC", "::", "Specs", "."], "add_tokens": "def Specs . all @@wsoc_specs_all ||= [ ] def Specs . << ( spec ) Specs . all << spec Specs . all . map do | spec | link = URI :: HTTP . build ( :host => host , :port => port , :path => spec [ :link ] ) . to_s url = URI :: HTTP . build ( :host => host , :port => port , :path => spec [ :url ] ) . to_s spec . merge ( :link => link , :url => url )", "del_tokens": "def Specs . behaviors @@wsoc_specs_behaviors ||= [ ] def Specs . add ( path , options = { } ) Specs . behaviors << options . merge ( :link => URI . expand_path ( path ) ) url = URI :: HTTP . build ( :host => host , :port => port ) return Specs . behaviors . map do | behavior | behavior . merge ( :link => url . merge ( behavior ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "backoff", "options", "to", "bucket", "create", "/", "delete"], "add_tokens": "# # bucket.delete # # The API call to delete the bucket may be retried under certain # conditions. See Gcloud::Backoff to control this behavior, or # specify the wanted behavior in the call: # # bucket.delete retries: 5 def delete options = { } resp = connection . delete_bucket name , options", "del_tokens": "def delete resp = connection . delete_bucket name", "commit_type": "add"}
{"commit_tokens": ["Add", "transaction", "output", "cache", "."], "add_tokens": "attr_reader :cache @cache = { } # Returns the balance in both bitcoin and colored coin assets for all of the addresses available in your Bitcoin Core wallet. # @param [String] address The open assets address. if unspecified nil. def get_balance ( address = nil ) outputs = get_unspent_outputs ( address . nil? ? [ ] : [ address ] ) end result = unspent . map { | item | result cached_output = @cache [ txid + output_index . to_s ] return cached_output if cached_output colored_outputs . each_with_index { | o , index | @cache [ txid + index . to_s ] = o } output_asset_quantity = ( i <= asset_quantities . length ) ? asset_quantities [ i - 1 ] : 0 unless current_input . asset_id . nil? if asset_id . nil? return nil", "del_tokens": "unspent . map { | item | output_asset_quantity = i <= asset_quantities . length ? asset_quantities [ i - 1 ] : 0 if current_input . asset_id . nil? if asset_id . ni? return nil", "commit_type": "add"}
{"commit_tokens": ["add", ":", "preserve_input", "option", "to", "uglify", "filter"], "add_tokens": "@preserve_input = options . delete :preserve_input def should_skip_minify? ( input , output ) ( @preserve_input && input . path == output . path ) || input . path =~ %r{ .min.js$ } end if should_skip_minify? ( input , output ) def output_paths ( input ) paths = super ( input ) if @preserve_input raise 'cannot preserve unminified input if output path is not different' if paths . include? ( input . path ) paths . unshift ( input . path ) end paths end", "del_tokens": "if input . path =~ %r{ .min.js$ }", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "mecab", "option", "input", "-", "buffer", "-", "size", "."], "add_tokens": "# output = mecab.parse('').split # # output.each do |token| # puts token # end # =>  #  #  #  #  #  # :input_buffer_size , :allocate_sentence , :nbest , :theta , :cost_factor ] . freeze # - :input_buffer_size -- set input buffer size (default 8192) while @dicts . last . next . address != 0x0 @dicts << Natto :: DictionaryInfo . new ( @dicts . last . next ) return self [ member_sym ] if self . members . include? ( member_sym ) raise ( NoMethodError . new ( \"undefined method '#{attr_name}' for #{self}\" ) )", "del_tokens": "# puts m.parse('') # =>       :allocate_sentence , :nbest , :theta , :cost_factor ] . freeze while @dicts . last [ :next ] . address != 0x0 @dicts << Natto :: DictionaryInfo . new ( @dicts . last [ :next ] ) if self . members . include? ( member_sym ) self [ member_sym ] else raise ( NoMethodError . new ( \"undefined method '#{attr_name}' for #{self}\" ) ) end", "commit_type": "add"}
{"commit_tokens": ["updated", "docs", "added", "service", "filtering"], "add_tokens": "attr_reader :version , :services attr_reader :timestamp # Setup a new node # host - Server hostname or IP address # port - Server port (default to 4949) # list - List of services to request. Empty array if need to fetch all def initialize ( host , port = 4949 , list = [ ] ) @host = host @port = port @stats = { } @services = [ ] @version = '' @only_services = list || [ ] # Get service stats def service ( name ) if @stats . key? ( name ) @stats [ name ] else raise Munin :: NoSuchService , \"Service with name #{name} does not exist.\" end # Fetch node information and stats @timestamp = Time . now # Fetch node server version # Fetch list of services and its stats services = @socket . readline . split ( ' ' ) . map { | s | s . strip } . sort services = services . select { | s | @only_services . include? ( s ) } unless @only_services . empty? # Fetch service information", "del_tokens": "attr_reader :stats , :version , :services def initialize ( host , port = 4949 ) @host = host @port = port @stats = { } @services = [ ] @version = '' def service ( s ) @stats [ s ] services = @socket . readline . split ( ' ' ) . map { | s | s . strip }", "commit_type": "update"}
{"commit_tokens": ["make", "contrib_test", "of", "sys", "work"], "add_tokens": "require 'rbconfig' return [ tail ] if head == '.' || tail == '/'", "del_tokens": "return [ tail ] if head == '.'", "commit_type": "make"}
{"commit_tokens": ["Adding", "support", "for", "linking", "payments", "to", "an", "invoice"], "add_tokens": "require 'quickbooks/model/linked_transaction'", "del_tokens": "require 'quickbooks/model/linked_transaction'", "commit_type": "add"}
{"commit_tokens": ["Change", "string", "to", "array", "conversion", "to", "remove", "numeric", "type", "coercion"], "add_tokens": "# converter.call(\"1 - 2 - 3\") # => [\"1\", \"2\", \"3\"] return [ ] if value . to_s . empty? if match = value . to_s . match ( / ^(.+?( \\s *(?<sep>(,|-)) \\s *))+ / ) value . to_s . split ( match [ :sep ] )", "del_tokens": "# converter.call(\"1 - 2 - 3\") # => [1, 2, 3] case value . to_s when / ^ \\s *?(( \\d +)( \\s *(,|-) \\s *)?)+ \\s *?$ / value . to_s . split ( $4 ) . map ( & :to_i ) when / ^(( \\w )( \\s *(,|-) \\s *)?)+$ / value . to_s . split ( $4 )", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "grouping", "by", "multiple", "properties", "."], "add_tokens": "if params . key? ( :group_by ) && params [ :group_by ] . is_a? ( Array ) params [ :group_by ] = MultiJson . encode ( params [ :group_by ] ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["making", "Rails", "not", "a", "required", "dependency"], "add_tokens": "@logger = ( defined? ( RAILS_ENV ) and RAILS_ENV != \"development\" ? Rails . logger : Logger . new ( STDOUT ) )", "del_tokens": "@logger = ( RAILS_ENV == \"development\" ? Logger . new ( STDOUT ) : Rails . logger )", "commit_type": "make"}
{"commit_tokens": ["fix", "some", "indentation", "on", "install"], "add_tokens": "< %= javascript_include_tag * webpack_asset_paths ( 'application' ) % > < % if Rails . env . development? %> < script src = \"http://localhost:3808/webpack-dev-server.js\" > < / script > < % end %> puts \"\\n\\n***WARNING*** HAML NOT SUPPORTED YET additional steps required\\n\\n\"", "del_tokens": "< %= javascript_include_tag * webpack_asset_paths ( 'application' ) % > < % if Rails . env . development? %> < script src = \"http://localhost:3808/webpack-dev-server.js\" > < / script > < % end %> puts \"\\n\\n***WARNING*** HAML NOT SUPPORTED IN applictaion.html additional steps required\\n\\n\"", "commit_type": "fix"}
{"commit_tokens": ["Adding", "WaveFileBuffer", "which", "encapsulates", "a", "list", "of", "samples", "with", "information", "about", "their", "format", "(", "channels", "bits", "per", "sample", "etc", ".", ")"], "add_tokens": "class WaveFileBuffer def initialize ( samples , format ) @samples = samples @channels = format . channels @bits_per_sample = format . bits_per_sample @sample_rate = format . sample_rate end def convert ( format ) return self end attr_reader :samples , :channels , :bits_per_sample , :sample_rate end def write ( buffer ) converted_buffer = buffer . convert ( @format ) samples = converted_buffer . samples @file . syswrite ( samples . pack ( @pack_code ) ) @sample_count += samples . length", "del_tokens": "def write ( sample_data ) # TODO: Implement this. #sample_data = convert(sample_data, format) @file . syswrite ( sample_data . pack ( @pack_code ) ) @sample_count += sample_data . length", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "for", "Methods#term", "."], "add_tokens": "describe \"#term\" do it \"should determine the current TERM\" do expect ( subject . term ) . to eq ( term ) expect ( subject . term ) . to eq ( 'gnome-terminal' ) describe \"#terminal\" do it \"should be an alias to #term\" do expect ( subject . terminal ) . to be == subject . term end end", "del_tokens": "describe \"#terminal\" do it \"should determine the current Terminal\" do expect ( subject . terminal ) . to eq ( term ) expect ( subject . terminal ) . to eq ( 'gnome-terminal' )", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "constant", "stubbing", "api"], "add_tokens": "if base_module . is_a? ( Hash ) || base_module . is_a? ( Symbol ) if base_module . is_a? ( Hash ) || base_module . is_a? ( Symbol ) constant_names . unshift ( base_module ) base_module = Object end if base_module . is_a? ( Hash ) || base_module . is_a? ( Symbol ) constant_names . unshift ( base_module ) base_module = Object end", "del_tokens": "if base_module . is_a? Symbol", "commit_type": "fix"}
{"commit_tokens": ["Updated", "CHANGELOG", "and", "version", "."], "add_tokens": "MINOR = 2 TINY = 0", "del_tokens": "MINOR = 1 TINY = 1", "commit_type": "update"}
{"commit_tokens": ["Remove", "future", "feature", ".", "Fix", "tests", "."], "add_tokens": "expect ( shell ) . to receive ( :command ) . with ( 'docker-compose' , { file : 'foo.yml' } , anything , anything , anything ) expect ( shell ) . to receive ( :command ) . with ( 'docker-compose' , anything , 'up' , anything , anything ) expect ( shell ) . to receive ( :command ) . with ( 'docker-compose' , anything , 'up' , hash_including ( d : true ) , anything )", "del_tokens": "expect ( shell ) . to receive ( :command ) . with ( array_including ( '--file=foo.yml' ) , anything ) expect ( shell ) . to receive ( :command ) . with ( array_including ( 'up' ) , anything ) expect ( shell ) . to receive ( :command ) . with ( array_including ( 'up' ) , hash_including ( d : true ) ) describe '#run!' do it 'emulates docker-compose 1.5 ${ENV} substitution' do expect ( session ) . to receive ( :run_without_substitution! ) session . up end end", "commit_type": "remove"}
{"commit_tokens": ["Add", "spec", "for", "Yardstick", "::", "Rule#hash"], "add_tokens": "let ( :object ) { described_class . new ( description ) { true } } let ( :description ) { 'test rule' } subject { object . eql? ( other ) } let ( :other ) { described_class . new ( description ) { true } } it 'is true' do should be ( true ) let ( :other ) { described_class . new ( 'other rule' ) { true } } it 'is false' do should be ( false ) describe '#hash' do subject { object . hash } it 'is the expected hash' do should == description . hash end end", "del_tokens": "before do @rule = Yardstick :: Rule . new ( 'test rule' ) { true } @other = Yardstick :: Rule . new ( 'test rule' ) { true } end it 'should return true' do @rule . eql? ( @other ) . should be_true before do @rule = Yardstick :: Rule . new ( 'test rule' ) { true } @other = Yardstick :: Rule . new ( 'other rule' ) { true } end it 'should return false' do @rule . eql? ( @other ) . should be_false", "commit_type": "add"}
{"commit_tokens": ["Use", "Certificate", "abstraction", "and", "add", "convenience", "methods", "."], "add_tokens": "def initialize ( uri , ssl_context ) @uri , @ssl_context = URI ( uri ) , ssl_context @main_queue = Threading :: DispatchQueue . new @work_queue = Threading :: DispatchQueue . new @requests = Threading :: Counter . new @exceptions = Queue . new @worker_thread = start_worker_thread! end def open? ! @ssl . nil? && ! @ssl . closed? flush @socket = @ssl = @http = @main_queue = @work_queue = @requests = @exceptions = @worker_thread = nil Thread . new do", "del_tokens": "def initialize ( uri , certificate , key ) @uri = URI ( uri ) @ssl_context = OpenSSL :: SSL :: SSLContext . new @ssl_context . key = key @ssl_context . cert = certificate @main_queue = Threading :: DispatchQueue . new @work_queue = Threading :: DispatchQueue . new @requests = Threading :: Counter . new @exceptions = Queue . new start_worker_thread! @worker_thread = Thread . new do", "commit_type": "use"}
{"commit_tokens": ["Remove", "text", "gem", "and", "put", "our", "own", "Levenshtein", "implementation"], "add_tokens": "Levenshtein . distance ( method . to_s , target_method ) <= threshold module Levenshtein # This code is based directly on the Text gem implementation # Returns a value representing the \"cost\" of transforming str1 into str2 def distance ( str1 , str2 ) n = str1 . length m = str2 . length return m if n . zero? return n if m . zero? d = ( 0 .. m ) . to_a x = nil str1 . each_char . each_with_index do | char1 , i | e = i + 1 str2 . each_char . each_with_index do | char2 , j | cost = ( char1 == char2 ) ? 0 : 1 x = min3 ( d [ j + 1 ] + 1 , # insertion e + 1 , # deletion d [ j ] + cost # substitution ) d [ j ] = e e = x end d [ m ] = x end x end module_function :distance private def min3 ( a , b , c ) # :nodoc: if a < b && a < c a elsif b < a && b < c b else c end end module_function :min3 end", "del_tokens": "require \"text\" :: Text :: Levenshtein . distance ( method . to_s , target_method ) <= threshold", "commit_type": "remove"}
{"commit_tokens": ["Removed", "unused", "config", "options", "and", "spec", "support", "files"], "add_tokens": "When I run \"rm -f vendor/plugins/copycopter\" And I run \"ln -s #{PROJECT_ROOT} vendor/plugins/copycopter\"", "del_tokens": "When I run \"ln -s #{PROJECT_ROOT} vendor/plugins/copycopter\"", "commit_type": "remove"}
{"commit_tokens": ["Add", "the", "configuration", "file", "to", ".", "gitignore", "on", "installation"], "add_tokens": "in_current_dir { FileUtils . rm_rf ( \"example\" ) } run_simple ( \"bundle exec rails new example --skip-bundle --skip-active-record --skip-sprockets --skip-javascript --skip-test-unit\" )", "del_tokens": "run_simple ( \"bundle exec rails new example --skip-bundle --skip-git --skip-active-record --skip-sprockets --skip-javascript --skip-test-unit\" )", "commit_type": "add"}
{"commit_tokens": ["Made", "it", "so", "and", "nil", "values", "are", "grouped", "by", "SQL", "sort", "."], "add_tokens": "code << \" null_pos = 'first' if #{var_name(:params)}[:dir] == 'asc'\\n\" code << \" null_pos = 'last' if #{var_name(:params)}[:dir] == 'desc'\\n\" code << \" #{var_name(:order)} = #{var_name(:col)} + ' ' + #{var_name(:params)}[:dir] + ' NULLS ' + null_pos \\n\"", "del_tokens": "code << \" #{var_name(:order)} = #{var_name(:col)} + ' ' + #{var_name(:params)}[:dir]\\n\"", "commit_type": "make"}
{"commit_tokens": ["Fix", "the", "last", "YARD", "warning"], "add_tokens": "# @overload new_element(tree) # @param [AugeasTree] tree # @return [AugeasElement,Hash] the new element; it is empty! # Note that the return value is actually a Hash; {AugeasElement} # documents its structure.", "del_tokens": "# @param [AugeasTree] tree # @return [AugeasElement,Hash] the new element; it is empty! # Note that the return value is actually a Hash; {AugeasElement} # documents its structure.", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "replace", "all", "streams"], "add_tokens": "def replace_streams ( * streams ) originals = [ $stdout , $stdin , $stderr ] $stdout , $stdin , $stderr = output , output , output yield ensure $stdout , $stdin , $stderr = * originals end replace_streams do expect ( screen . size_from_ioctl ) . to eq ( [ 51 , 211 ] ) end", "del_tokens": "original_stdout = $stdout $stdout = output expect ( screen . size_from_ioctl ) . to eq ( [ 51 , 211 ] ) $stdout = original_stdout", "commit_type": "change"}
{"commit_tokens": ["Change", "global", "methods", "to", "module", "methods"], "add_tokens": "module CommandHelpers def simple_command ( v , opts = { } ) Expeditor :: Command . new ( opts ) do v end def sleep_command ( n , v , opts = { } ) Expeditor :: Command . new ( opts ) do sleep n v end def error_command ( e , opts = { } ) Expeditor :: Command . new ( opts ) do raise e end RSpec . configure do | c | c . include CommandHelpers end", "del_tokens": "def simple_command ( v , opts = { } ) Expeditor :: Command . new ( opts ) do v end def sleep_command ( n , v , opts = { } ) Expeditor :: Command . new ( opts ) do sleep n v end def error_command ( e , opts = { } ) Expeditor :: Command . new ( opts ) do raise e", "commit_type": "change"}
{"commit_tokens": ["add", "support", "to", "return", "message", "params", "by", "type"], "add_tokens": "class BasicLTILaunchRequest < Message add_required_params :resource_link_id add_recommended_params :context_id , :launch_presentation_return_url , :tool_consumer_instance_guid add_optional_params :context_type , :role_scope_mentor , :user_image add_deprecated_params :context_title , :context_label , :resource_link_title , :resource_link_description ,", "del_tokens": "class BasicLTILaunchRequest < IMS :: LTI :: Models :: Messages :: Message required_params :resource_link_id recommended_params :context_id , :launch_presentation_return_url , :tool_consumer_instance_guid optional_params :context_type , :role_scope_mentor , :user_image deprecated_params :context_title , :context_label , :resource_link_title , :resource_link_description ,", "commit_type": "add"}
{"commit_tokens": ["Use", "prepend", "for", "extension", "routes"], "add_tokens": "Archangel :: Engine . routes . prepend do", "del_tokens": "Archangel :: Engine . routes . draw do", "commit_type": "use"}
{"commit_tokens": ["Use", "Kernel#BigDecimal", "instead", "of", "deprecated", "BigDecimal", ".", "new"], "add_tokens": "@multiple_of = BigDecimal ( multiple_of . to_s ) number = BigDecimal ( instance . to_s )", "del_tokens": "@multiple_of = BigDecimal . new ( multiple_of . to_s ) number = BigDecimal . new ( instance . to_s )", "commit_type": "use"}
{"commit_tokens": ["adding", "basic", "documentation", "for", "attribute", "methods"], "add_tokens": "# @raise [NotImplementedError] This must be overridden in a custom ActiveInteraction # class. # # @macro attribute_method_params # @param block [Proc] Apply attribute methods to specific values in the hash. # @!macro [new] attribute_method_params # @param *attributes [Symbol] A list of attribute names. # @param options [Hash] A hash of options. # @option options [Boolean] :allow_nil Allow a nil value to be passed in. # @method self.array(*attributes, options = {}, &block) # # @macro attribute_method_params # @param block [Proc] Apply attribute methods to each entry in the array. # @method self.boolean(*attributes, options = {}) # # @macro attribute_method_params # @method self.date(*attributes, options = {}) # # @macro attribute_method # @method self.date_time(*attributes, options = {}) # # @macro attribute_method_params # @method self.float(*attributes, options = {}) # # @macro attribute_method_params # @method self.integer(*attributes, options = {}) # # @macro attribute_method_params # @method self.model(*attributes, options = {}) # # @macro attribute_method_params # @method self.string(*attributes, options = {}) # # @macro attribute_method_params # @method self.time(*attributes, options = {}) # # @macro attribute_method_params", "del_tokens": "# @method self.array(:attributes, options = {}, &block) # @method self.boolean(:attributes, options = {}) # @method self.date(:attributes, options = {}) # @method self.date_time(:attributes, options = {}) # @method self.float(:attributes, options = {}) # @method self.integer(:attributes, options = {}) # @method self.model(:attributes, options = {}) # @method self.string(:attributes, options = {}) # @method self.time(:attributes, options = {})", "commit_type": "add"}
{"commit_tokens": ["Update", "version", "and", "streamline", "#get_page", "method"], "add_tokens": "# considered page 0. id . between? ( 1 , Problem . total - 10 ) ? ( id - 1 ) / Page :: LENGTH + 1 : 0", "del_tokens": "# considered page 0, invalid pages return -1. if id . between? ( Problem . total - 9 , Problem . total ) 0 elsif id . between? ( 1 , Problem . total - 10 ) ( id - 1 ) / Page :: LENGTH + 1 else - 1 end", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "buffer_size", "option", "to", "session", "and", "request", ".", "It", "ll", "only", "be", "set", "if", "it", "s", "non", "-", "nil", ".", "This", "commit", "is", "still", "lacking", "a", "spec", "for", "session_spec", ".", "rb"], "add_tokens": "attr_reader :action , :timeout , :connect_timeout , :max_redirects , :headers , :buffer_size def buffer_size = ( buffer_size ) if buffer_size != nil && buffer_size . to_i < 1 raise ArgumentError , \"Buffer size must be a positive integer greater than 0 or nil\" end @buffer_size = buffer_size . to_i end", "del_tokens": "attr_reader :action , :timeout , :connect_timeout , :max_redirects , :headers", "commit_type": "add"}
{"commit_tokens": ["Added", "SLE", "federation", "and", "upgraded", "gems"], "add_tokens": "VERSION = \"1.6.5\"", "del_tokens": "VERSION = \"1.6.4\"", "commit_type": "add"}
{"commit_tokens": ["Added", "Pling", ".", "_convert", "helper", "method", "to", "ensure", "correct", "interfaces", "for", "Pling", "objects"], "add_tokens": "message = Pling . _convert ( message , :message )", "del_tokens": "raise \"The given object #{message.inspect} does not implement #to_pling_message\" unless message . respond_to? ( :to_pling_message ) message &&= message . to_pling_message", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "::", "Enumerable", "is", "used"], "add_tokens": "return Maybe ( @value . map ( & block ) ) if @value . is_a? ( :: Enumerable ) return Maybe ( @value . select ( & block ) ) if @value . is_a? ( :: Enumerable )", "del_tokens": "return Maybe ( @value . map ( & block ) ) if @value . is_a? ( Enumerable ) return Maybe ( @value . select ( & block ) ) if @value . is_a? ( Enumerable )", "commit_type": "make"}
{"commit_tokens": ["use", "RSpec", "constant", "for", "rspec2"], "add_tokens": "RSpec . configure do | config |", "del_tokens": "Rspec . configure do | config |", "commit_type": "use"}
{"commit_tokens": ["Add", "ability", "to", "handle", "exploded", "wars", "for", "Spring", "/", "Java", "/", "Lift", "/", "Grails", "apps", "."], "add_tokens": "elsif Dir . glob ( '*.war' ) . first || File . exist? ( 'WEB-INF/web.xml' ) if war_file contents = ZipUtil . entry_lines ( war_file ) else contents = Dir [ '**/*' ] . join ( \"\\n\" ) end", "del_tokens": "elsif Dir . glob ( '*.war' ) . first contents = ZipUtil . entry_lines ( war_file )", "commit_type": "add"}
{"commit_tokens": ["Removed", "whitespace", "from", "ActiveRecord", "adapter", "."], "add_tokens": "", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Moved", "remaining", "specs", "to", "the", "protobuf", "serializer", "."], "add_tokens": "# TODO: Create proto messages & endpoints specifically for these tests. # They will be more robust if they don't rely on proto messages in Atlas. # require 'atlas/abacus/tag_service' context \"when building messages\" do let ( :records ) { [ { :name => 'Foo' } , { :name => 'Bar' } ] } let ( :attributes ) { records . first } xit \"creates a message\" do pending described_class . service_class Abacus :: TagService expected_message = Abacus :: Tag . new ( attributes ) package = subject . request ( :create , attributes ) package . should be_similar_to ( expected_message ) end xit \"creates a bulk message\" do pending described_class . service_class Abacus :: TagService expected_message = Abacus :: Tags . new package = described_class . request ( :create_all , records , :bulk => true ) package . should be_similar_to ( expected_message ) end xit \"creates a message with nested messages\" do pending described_class . service_class Abacus :: TransactionService records_hash = { :status => { :status => 7 } , :guid => 'GUID' } expected_message = Abacus :: Transaction . new expected_message . guid = records_hash [ :guid ] expected_message . status = Status . new ( records_hash . fetch ( :status ) ) # status => HIDDEN message = subject . request ( :update , records_hash ) message . should be_similar_to ( expected_message ) end end", "del_tokens": "pending \"Write specs for this!\"", "commit_type": "move"}
{"commit_tokens": ["adding", "back", "full", "path", "to", "ifconfig", "command"], "add_tokens": "popen4 ( \"/sbin/ifconfig -a\" ) do | pid , stdin , stdout , stderr |", "del_tokens": "popen4 ( \"ifconfig -a\" ) do | pid , stdin , stdout , stderr |", "commit_type": "add"}
{"commit_tokens": ["Add", "json", "-", "schema", "to", "test", "JSON", "response", "schema"], "add_tokens": "format . json do render ( template : \"archangel/frontend/pages/show\" , layout : false ) end", "del_tokens": "format . json { render ( action : :show , layout : false ) }", "commit_type": "add"}
{"commit_tokens": ["make", "password", "optional", "when", "creating", "a", "keychain"], "add_tokens": "# @param [optional, String] password The password to use for the keychain. if not supplied, the user will be prompted for a password def create ( path , password = nil ) if password password = password . encode ( Encoding :: UTF_8 ) status = Sec . SecKeychainCreate ( path , password . bytesize , FFI :: MemoryPointer . from_string ( password ) , 0 , else status = Sec . SecKeychainCreate ( path , 0 , nil , 1 , nil , out_buffer ) end", "del_tokens": "# @param [String] password The password to use for the keychain def create ( path , password ) password = password . encode ( Encoding :: UTF_8 ) status = Sec . SecKeychainCreate ( path , password . bytesize , FFI :: MemoryPointer . from_string ( password ) , 0 ,", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "ensure", "value", "or", "block", "provided", "when", "setting", "key"], "add_tokens": "if value . nil? && block . nil? raise ArgumentError , \"Need to set either value or block\" elsif ! ( value . nil? || block . nil? ) raise ArgumentError , \"Can't set both value and block\" end", "del_tokens": "return if value . nil? || block . nil? raise ArgumentError , \"Can't set both value and block\"", "commit_type": "change"}
{"commit_tokens": ["added", "audio", "&", "input", "in", "main", "game", "class"], "add_tokens": "@root = \"/Users/ILab/Documents/ruby/kawaii/spec/kawaii/content\" @content . root . should == @root", "del_tokens": "@root = \"content\" @content . root . should == \"content\"", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "id", "method", "instead", "of", "knowing", "that", "it", "is", "the", "start_id"], "add_tokens": "CommitEntry . where ( :id => @start_id .. @end_id ) . where ( :commit_id => id )", "del_tokens": "CommitEntry . where ( :id => @start_id .. @end_id ) . where ( :commit_id => @start_id )", "commit_type": "use"}
{"commit_tokens": ["Add", "action", "getter", "to", "RedSnow", "::", "TransactionExample"], "add_tokens": "attr_reader :action def initialize ( sc_transaction_example_handle , action ) @action = action @examples << TransactionExample . new ( sc_transaction_example_handle , self )", "del_tokens": "def initialize ( sc_transaction_example_handle ) @examples << TransactionExample . new ( sc_transaction_example_handle )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "handling", "of", "quotes", "under", "haml", "3", "which", "lead", "to", "a", "problem", "with", "the", "jQuery", "UI", "themes", "."], "add_tokens": "# Quote most things capture = \"\\\"#{capture}\\\"\" if capture =~ / [^#%0-9a-fptxm \\- ] / and ! ( capture =~ / ^image_url / ) and ! ( capture =~ / ^[A-Za-z]+ / )", "del_tokens": "# Quote most things capture = \"\\\"#{capture}\\\"\" if capture =~ / [^#%0-9a-fptxm \\- ] / and ! ( capture =~ / ^image_url / )", "commit_type": "fix"}
{"commit_tokens": ["add", "group_results", "and", "counts", "to", "VoteEvent"], "add_tokens": "attr_accessor :identifier , :motion_id , :organization_id , :legislative_session_id , :start_date , :end_date , :result , :group_results , :counts dump :identifier , :motion_id , :organization_id , :legislative_session_id , :start_date , :end_date , :result , :group_results , :counts def initialize ( * args ) @group_results = [ ] @counts = [ ] super end # Sets the group results. # # @param [Array] group_results a list of group results def group_results = ( group_results ) @group_results = symbolize_keys ( group_results ) end # Sets the counts. # # @param [Array] counts a list of counts def counts = ( counts ) @counts = symbolize_keys ( counts ) end # Adds a group result. # # @param [String] result the result of the vote event within a group of voters # @param [String] group a group of voters def add_group_result ( result , group : nil ) data = { result : result } if group data [ :group ] = group end if result . present? @group_results << data end end # Adds a count. # # @param [String] option an option in a vote event # @param [String] value the number of votes for an option # @param [String] group a group of voters def add_count ( option , value , group : nil ) data = { option : option , value : value } if group data [ :group ] = group end if option . present? && value . present? @counts << data end end", "del_tokens": "attr_accessor :identifier , :motion_id , :organization_id , :legislative_session_id , :start_date , :end_date , :result dump :identifier , :motion_id , :organization_id , :legislative_session_id , :start_date , :end_date , :result", "commit_type": "add"}
{"commit_tokens": ["updated", "code", "documentation", "have", "specs", "log", "to", "a", "test", "log", "file"], "add_tokens": "# Wait for a single fork to finish. # # If a fork successfully finishes, it's return value from the *process* # block is stored into the main result set. # # @return [Array<pid, status, data>] An array containing the pid, # status and data returned from the process block. If wait2() fails nil # is returned. log ( :debug ) { \"wait\" } # Waits for all forks to finish. # # @return [Array<Object>] The results from all of the *process* blocks. log ( :debug ) { \"waitall\" } self . wait @results", "del_tokens": "data = Array . new result = self . wait result and data << result data", "commit_type": "update"}
{"commit_tokens": ["moving", "hook", "setup", "to", "well", "guess", "#setup_hook", "."], "add_tokens": "setup_hook ( name ) def setup_hook ( name ) accessor_name = \"_#{name}_callbacks\" setup_hook_accessors ( accessor_name ) define_hook_writer ( name , accessor_name ) end", "del_tokens": "accessor_name = \"_#{name}_callbacks\" setup_hook_accessors ( accessor_name ) define_hook_writer ( name , accessor_name )", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "continuous", "queries", "are", "scoped", "by", "database", "."], "add_tokens": "def continuous_queries ( database ) get full_url ( \"db/#{database}/continuous_queries\" )", "del_tokens": "def continuous_queries get full_url ( \"continuous_queries\" )", "commit_type": "make"}
{"commit_tokens": ["use", "hash", "values", "instead", "of", "explicit", "access"], "add_tokens": "soap = Savon :: SOAP . new UserFixture . soap_actions . keys . first ,", "del_tokens": "soap = Savon :: SOAP . new UserFixture . soap_actions [ :find_user ] ,", "commit_type": "use"}
{"commit_tokens": ["Change", "behavior", "of", "capture", "tag", "to", "use", "existing", "variables", "if", "they", "already", "have", "been", "initialized", "in", "an", "outer", "scope", "."], "add_tokens": "context . scopes . last [ @to . to_s ] = output . join", "del_tokens": "context [ @to ] = output . join", "commit_type": "change"}
{"commit_tokens": ["Adding", "ability", "to", "flag", "a", "mutation", "as", "isDelete", "based", "on", "if", "the", "value", "is", "nil"], "add_tokens": "mutations = mutations . map { | k , v | Apache :: Hadoop :: Hbase :: Thrift :: Mutation . new ( :column => k , :value => v , :isDelete => v . nil? ) }", "del_tokens": "mutations = mutations . map { | k , v | Apache :: Hadoop :: Hbase :: Thrift :: Mutation . new ( :column => k , :value => v ) }", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "game", "with", "a", "current", "board", "game", "knows", "whose", "turn", "it", "is"], "add_tokens": "DEFAULT_BOARD = '0' * 9 attr_accessor :board def initialize ( board = DEFAULT_BOARD ) self . board = board end def turn board . scan ( '1' ) . size - board . scan ( '2' ) . size + 1", "del_tokens": "def board '0' * 9", "commit_type": "create"}
{"commit_tokens": ["Fix", "a", "couple", "of", "@return", "types", "in", "YARD"], "add_tokens": "# @return [Symbol] The type of the IRC message. # @return [Symbol] The type of the CTCP message.", "del_tokens": "# @return [String] The type of the IRC message. # @return [String] The type of the CTCP message.", "commit_type": "fix"}
{"commit_tokens": ["Move", "Regulation", "instanciation", "in", "parse_config", "method", "for", "Measure"], "add_tokens": "if config_ [ \"regul\" ] @regul = Regulation . new ( config_ [ \"regul\" ] , self ) end", "del_tokens": "if meas_ [ \"regul\" ] @regul = Regulation . new ( meas_ [ \"regul\" ] , self ) end #for each keys of config", "commit_type": "move"}
{"commit_tokens": ["fix", "mongodb", "update", "to", "not", "send", "_id"], "add_tokens": "query . update ( @object . to_h ( persist : true ) . except ( :_id ) )", "del_tokens": "query . update ( @object . to_h ( persist : true ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "default", "filename", "when", "exporting", "one", "-", "off", "queries"], "add_tokens": "send_data csv_data ( @rows ) , type : \"text/csv; charset=utf-8; header=present\" , disposition : \"attachment; filename=\\\"#{@query.try(:name).try(:parameterize).presence || 'query'}.csv\\\"\"", "del_tokens": "send_data csv_data ( @rows ) , type : \"text/csv; charset=utf-8; header=present\" , disposition : \"attachment; filename=\\\"#{@query ? @query.name.parameterize : 'query'}.csv\\\"\"", "commit_type": "use"}
{"commit_tokens": ["Remove", "specs", "that", "no", "longer", "apply"], "add_tokens": "@renderer = described_class . new", "del_tokens": "@renderer = Gmail . new it \"should raise error when unprepared\" do expect { @renderer . send :param_name } . to raise_error end it \"should prepare with collection and options\" do prepare ( { } , :param_name => 'mypage' ) @renderer . send ( :current_page ) . should eql ( 1 ) @renderer . send ( :param_name ) . should eql ( 'mypage' ) end", "commit_type": "remove"}
{"commit_tokens": ["Allow", "non", "-", "competing", "players", "in", "rating", "period"], "add_tokens": "if games . length > 0 p << player . generate_next ( * games . transpose ) else p << player . generate_next ( [ ] , [ ] ) end", "del_tokens": "p << player . generate_next ( * games . transpose )", "commit_type": "allow"}
{"commit_tokens": ["Improve", "error", "reporting", "and", "help"], "add_tokens": "include ConsoleMethods @parser = OptionParser . new do | opts | @parser . parse! ( @arguments ) print_help @parser . help , ex warning 'You must supply at least one directory to install into.' puts @parser . help error \"Installation failed: #{ex}\" error ex , '' if ex", "del_tokens": "parser = OptionParser . new do | opts | parser . parse! ( @arguments ) print_help parser . help , ex puts 'You must supply at least one directory to install into.' puts 'For example:' , '' puts \" #{File.basename($0)} <target directory>\" puts \"Installation failed: #{ex}\" puts ex , '' if ex", "commit_type": "improve"}
{"commit_tokens": ["Added", "missing", "parenthesis", "to", "a", "method", "definition", "."], "add_tokens": "def determine_region ( options )", "del_tokens": "def determine_region options", "commit_type": "add"}
{"commit_tokens": ["fixing", "a", "typo", "and", "adding", "a", "test", "to", "see", "if", "nested", "attributes", "are", "initialised"], "add_tokens": "self . instance_variable_set ( \"@#{reflection.name}_attributes\" , { } )", "del_tokens": "self . instance_variable_set ( \"@#{reflection.name}_attribtues\" , { } )", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "define", "stopword", "list"], "add_tokens": "def initialize ( stop_word_list = nil ) if list . nil? @stopwords = YAML . load_file ( File . join ( File . dirname ( __FILE__ ) , '..' , 'config' , 'stopwords.yml' ) ) else @stopwords = YAML . load_file ( stop_word_list ) end", "del_tokens": "def initialize @stopwords = YAML . load_file ( File . join ( File . dirname ( __FILE__ ) , '..' , 'config' , 'stopwords.yml' ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "some", "game", "specs", "and", "updated", "readme"], "add_tokens": "def initialize width , height , fullscreen , content_root , debug = true @node_manager = Kawaii :: NodeManager . new @debug = debug if @debug puts \"Game settings:\" puts \"\\tResolution: #{width}:#{height}\" puts \"\\tFullscreen: #{fullscreen}\" puts \"\\tContent root: #{content_root}\" print_stats end def add_child node def remove_child node 1000.0 / delta if @debug", "del_tokens": "def initialize width , height , fullscreen , content_root @node_manager = Kawaii :: NodeManager . new ( self ) @show_fps = true puts \"Starting game with settings:\" puts \"\\tResolution: #{width}:#{height}\" puts \"\\tFullscreen: #{fullscreen}\" puts \"\\tContent root: #{content_root}\" print_stats def add_node node def remove_node node \"60\" # TODO: real fps, fix delta if @show_fps", "commit_type": "fix"}
{"commit_tokens": ["Use", "refinements", "to", "convert", "external", "data", "to", "woods"], "add_tokens": "contents . to_key_wood contents . to_key_wood . with_meta_data do | meta_data |", "del_tokens": "case contents when Tree , Forest contents when Hash Tree [ contents ] when Array Forest [ * contents ] else raise ArgumentError , \"can't load #{contents.class} into a KeyTree\" end self [ contents ] . with_meta_data do | meta_data |", "commit_type": "use"}
{"commit_tokens": ["updated", "readme", "with", "entities", "supported"], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "update"}
{"commit_tokens": ["Using", "RR", "s", "Rspec", "adapter", "for", "the", "Examples", "."], "add_tokens": "require \"rr/adapters/rspec\" Spec :: Runner . configure do | config | config . mock_with RR :: Adapters :: Rspec end", "del_tokens": "#require \"rr/adapters/rspec\"", "commit_type": "use"}
{"commit_tokens": ["Fix", "date", "parsing", "in", "press", ".", "rb", ".", "Issue", ":", "https", ":", "//", "github", ".", "com", "/", "openfoodfacts", "/", "openfoodfacts", "-", "ruby", "/", "issues", "/", "27"], "add_tokens": "'uk' => '%d/%m/%Y' , 'us' => '%d/%m/%Y' , 'world' => '%d/%m/%Y'", "del_tokens": "'uk' => '%m/%d/%Y' , 'us' => '%m/%d/%Y' , 'world' => '%m/%d/%Y'", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "concern", "that", "sets", "the", "password", "for", "a", "user", "on", "create"], "add_tokens": "include ThinkFeelDoDashboard :: Concerns :: Password", "del_tokens": "before_create :set_password private def set_password random_eight = SecureRandom . urlsafe_base64 ( nil , false ) . first ( 8 ) self . password = random_eight self . password_confirmation = random_eight end", "commit_type": "add"}
{"commit_tokens": ["Fix", "camelizing", "of", "jsonable", "keys", "."], "add_tokens": "style_options = Hash . new if options [ :style_options ] && ! options [ :style_options ] . empty? options [ :style_options ] . each do | k , v | style_options [ k . to_s . camelize ( :lower ) ] = v end end :options => style_options", "del_tokens": ":options => options [ :style_options ] . then { camelize_keys ( :lower ) }", "commit_type": "fix"}
{"commit_tokens": ["allow", "glob", "patterns", "for", "file", "paths", "install", "task", "for", "gem"], "add_tokens": "Compiler . create_object_file ( lib , File . basename ( s ) ) base_dir = File . dirname ( p ) cd base_dir do building_block = c . define_project building_block . base = base_dir ALL_BUILDING_BLOCKS [ building_block . name ] = building_block if ( building_block . instance_of? ( SourceLibrary ) ) then build_source_lib ( building_block ) elsif ( building_block . instance_of? ( Exe ) ) then build_exe ( building_block ) else raise 'unknown building_block' end", "del_tokens": "Compiler . create_object_file ( lib , s ) building_block = c . define_project building_block . base = File . dirname ( p ) ALL_BUILDING_BLOCKS [ building_block . name ] = building_block if ( building_block . instance_of? ( SourceLibrary ) ) then build_source_lib ( building_block ) elsif ( building_block . instance_of? ( Exe ) ) then build_exe ( building_block ) else raise 'unknown building_block'", "commit_type": "allow"}
{"commit_tokens": ["Move", "model", "to", "spec", "support", "."], "add_tokens": "require Bundler . environment . specs . detect { | s | s . name == 'jinx' } . full_gem_path + '/spec/support/model'", "del_tokens": "require Bundler . environment . specs . detect { | s | s . name == 'jinx' } . full_gem_path + '/test/helpers/model'", "commit_type": "move"}
{"commit_tokens": ["change", "checkps", "to", "do", "asynchronous", "pulls", "from", "poker", "-", "edge"], "add_tokens": "# open(\"foo.html\", \"w+\") do |file| # file.write(response) # end # `open foo.html` end", "del_tokens": "open ( \"foo.html\" , \"w+\" ) do | file | file . write ( response ) end ` open foo.html ` end", "commit_type": "change"}
{"commit_tokens": ["Make", "verify_parameters", "private", "call", "in", "execute"], "add_tokens": "# Execute the workflow. workflow . execute wftoken = workflow . token", "del_tokens": "# Make sure we didn't miss any required input parameters workflow . verify_parameters # Execute the workflow. This gives us a `VcoWorkflows::WorkflowToken` object # back, which has the information we need to check up on this execution later. wftoken = workflow . execute wftoken = worflow_service . get_execution ( workflow . id , wftoken . id )", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "Mongoid", "5"], "add_tokens": "VERSION = '1.2.0'", "del_tokens": "VERSION = '1.1.3'", "commit_type": "add"}
{"commit_tokens": ["Added", "workaround", "for", "the", "fact", "that", "the", "Validatable", "library", "will", "silently", "erase", "errors", "set", "in", "before_validation", "hooks", "."], "add_tokens": "run_callbacks :before_validation before_validation_errors = errors . errors . dup before_validation_errors . each do | k , v | v . each { | message | errors . add ( k , message ) } end errors . empty?", "del_tokens": "self . run_callbacks :before_validation", "commit_type": "add"}
{"commit_tokens": ["changing", "client", "to", "use", "email_id", "isntead", "of", "email_name"], "add_tokens": "def send_with ( email_id , to , data = { } ) payload = { email_id : email_id , email_to : to , email_data : data } . to_json", "del_tokens": "def send_with ( email_name , to , data = { } ) payload = { email_name : email_name , email_to : to , email_data : data } . to_json", "commit_type": "change"}
{"commit_tokens": ["Make", "Verifying", "Host", "s", "SSL", "Certificates", "Optional"], "add_tokens": "@verify_ssl = params [ :verify_ssl_cert ] if @verify_ssl http . verify_mode = OpenSSL :: SSL :: VERIFY_PEER else http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE end", "del_tokens": "http . verify_mode = OpenSSL :: SSL :: VERIFY_PEER", "commit_type": "make"}
{"commit_tokens": ["Added", "error", "handling", "for", "C2DM", "responses", "in", "Pling", "::", "Gateway", "::", "C2DM"], "add_tokens": "if ! response . success? || response . body =~ / ^Error=(.+)$ / raise ( Pling :: DeliveryFailed , \"C2DM Delivery failed: [#{response.status}] #{response.body}\" ) end", "del_tokens": "raise ( Pling :: DeliveryFailed , \"C2DM Delivery failed: [#{response.status}] #{response.body}\" ) unless response . success?", "commit_type": "add"}
{"commit_tokens": ["changed", "rest_for", "to", "more", "precise", "rest_controller_for"], "add_tokens": "def rest_controller_for ( collection_name , options = { } )", "del_tokens": "def rest_for ( collection_name , options = { } )", "commit_type": "change"}
{"commit_tokens": ["add", "change", "password", "by", "name"], "add_tokens": "delete user_id_from_name ( username ) end def change_password_by_name ( username , new_password ) change_password ( user_id_from_name ( username ) , new_password ) end private def user_id_from_name ( name ) qinfo = query_by_value ( :id , :username , name ) qinfo [ :resources ] [ 0 ] [ :id ]", "del_tokens": "qinfo = query_by_value ( :id , :username , username ) delete qinfo [ :resources ] [ 0 ] [ :id ]", "commit_type": "add"}
{"commit_tokens": ["Added", "validations", "for", "demo", "fields"], "add_tokens": "validates :nhs_number , presence : true , length : { minimum : 10 , maximum : 10 } validates :local_patient_id , presence : true validates :sex , presence : true validates :dob , presence : true", "del_tokens": "validates :nhs_number , presence : true", "commit_type": "add"}
{"commit_tokens": ["Make", "AMQP", ".", "cleanup_state", "more", "thorough"], "add_tokens": "Thread . list . each { | thread | thread [ :mq ] = nil } Thread . list . each { | thread | thread [ :mq_id ] = nil }", "del_tokens": "Thread . current [ :mq ] = nil Thread . current [ :mq_id ] = nil", "commit_type": "make"}
{"commit_tokens": ["changed", "rule", "syntax", "and", "code", "to", "support", "an", "empty", "object"], "add_tokens": "elsif node . is_a? Hash", "del_tokens": "else", "commit_type": "change"}
{"commit_tokens": ["Add", "sample", "MemoryFileStore", "implementation", "for", "FileStore"], "add_tokens": "require 'vcs_toolkit/repository' require 'vcs_toolkit/utils/memory_file_store'", "del_tokens": "require 'vcs_toolkit/repository'", "commit_type": "add"}
{"commit_tokens": ["Create", "temporary", "file", "if", "not", "exist", "[", "ci", "skip", "]"], "add_tokens": "VERSION = '0.3.2'", "del_tokens": "VERSION = '0.3.1'", "commit_type": "create"}
{"commit_tokens": ["Fix", "for", "optional", "parents", "."], "add_tokens": "parent . subresources . lookup ( self ) if parent", "del_tokens": "parent . subresources . lookup ( self )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "exit", "condition", "for", "Subprocess"], "add_tokens": "# If the process has exited and we're not waiting to read anything # other than the self pipe, then we're done. break if poll && ( wait_r . length == 0 || wait_r == [ self_read ] )", "del_tokens": "# If the child exits, we still have to be sure to read any data left # in the pipes. So we poll the child, drain all the pipes, and *then* # check @status. # # It's very important that we do not call poll between draining the # pipes and checking @status. If we did, we open a race condition # where the child writes to stdout and exits in that brief window, # causing us to lose that data. poll break if @status # If there's nothing left to wait for, we're done! break if wait_r . length == 0 && wait_w . length == 0", "commit_type": "fix"}
{"commit_tokens": ["Change", "aliases", "and", "inline", "status", "logging", "."], "add_tokens": "log_status ( :prepend , relative_path , options . fetch ( :verbose , true ) , :green ) log_status ( :append , relative_path , options . fetch ( :verbose , true ) , :green ) alias add_to_file append_to_file log_status ( :inject , relative_path , options . fetch ( :verbose , true ) , :green ) alias insert_into_file inject_into_file log_status ( :replace , relative_path , options . fetch ( :verbose , true ) , :green ) alias gsub_file replace_in_file", "del_tokens": "log_status ( :prepend , \"#{relative_path}\" , options . fetch ( :verbose , true ) , :green ) log_status ( :append , \"#{relative_path}\" , options . fetch ( :verbose , true ) , :green ) alias_method :add_to_file , :append_to_file log_status ( :inject , \"#{relative_path}\" , options . fetch ( :verbose , true ) , :green ) alias_method :insert_into_file , :inject_into_file log_status ( :replace , \"#{relative_path}\" , options . fetch ( :verbose , true ) , :green )", "commit_type": "change"}
{"commit_tokens": ["Added", "certificate", "signature", "and", "fingerprint", "verification"], "add_tokens": "# @param [Hash] options The network options. # @option options [String] :hostname The hostname or IP-address we want to # connect to. # @option options [String] :nickname The nickname to use. # @option options [optional, String] :username (Copies :nickname) # The username to use. This is also known as the ident. # @option options [optional, String] :realname (Copies :username) # The real name that we want to use. This is usually what shows up # as \"Name\" when you whois a user. # @option options [optional, String] :password The password for the network. # This is sometimes needed for private networks. # @option options [optional, Fixnum] :port (6697 if ssl, otherwise 6667) # The remote port we want to connect to. # @option options [optional, Boolean] :secure Set whether this is a secure # (SSL-encrypted) connection. # @option options [optional, String] :ssl_cert_file Local path of a # readable file that contains a X509 CA certificate to validate against. # @option options [optional, String] :ssl_fingerprint Validate that the # remote certificate matches the specified fingerprint. # @option options [optional, Boolean] :ssl_no_verify Disable verification # alltogether.", "del_tokens": "# @param [Hash] options the network options. # @option options [String] :hostname the remote hostname. # @option options [String] :nickname the nickname to represent. # @option options [optional, String] :username the username to represent. # @option options [optional, String] :realname the real name to represent. # @option options [optional, String] :password the password for the network. # @option options [optional, Fixnum] :port the remote port. # @option options [optional, Boolean] :secure use a secure connection.", "commit_type": "add"}
{"commit_tokens": ["Added", "CVE", "-", "2013", "-", "1802"], "add_tokens": "it \"must have test for CVE-2013-1802\" do sc = kb . find ( \"CVE-2013-1802\" ) sc . should_not be_nil sc . class . should == Codesake :: Dawn :: Kb :: CVE_2013_1802 end", "del_tokens": "it \"must have test for CVE-2013-1802\"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "xrail", "-", "rails", "typo", "in", "asset", "pipeline", "exception"], "add_tokens": "Either convert your application to use the asset pipeline , or remove xray - rails from your Gemfile . \"", "del_tokens": "Either convert your application to use the asset pipeline , or remove xrail - rails from your Gemfile . \"", "commit_type": "fix"}
{"commit_tokens": ["Made", "all", "tracker", "methods", "chainable"], "add_tokens": "Net :: HTTP . get_response ( destination ) nil", "del_tokens": "r = Net :: HTTP . get_response ( destination ) if @@http_errors . include? r . code return false , \"Host [#{r.host}] not found (possible connectivity error)\" elsif r . code . to_i < 0 or 400 <= r . code . to_i return false , r . code . to_i else return true , r . code . to_i end", "commit_type": "make"}
{"commit_tokens": ["Change", "back", "to", "detect", "strings", "mutation"], "add_tokens": "# frozen_string_literal: true", "del_tokens": "# frozen_string_literals: true", "commit_type": "change"}
{"commit_tokens": ["added", "nogui", "option", "for", "build"], "add_tokens": "options = { \"force\" => false , \"format\" => \"vagrant\" , \"nogui\" => true } . merge ( options ) if ( options [ \"nogui\" ] == true ) start_vm ( boxname , \"vrdp\" ) else start_vm ( boxname , \"gui\" ) end", "del_tokens": "options = { \"force\" => false , \"format\" => \"vagrant\" } . merge ( options ) #vm.start(\"vrdp\") start_vm ( boxname , \"gui\" )", "commit_type": "add"}
{"commit_tokens": ["improved", "iteration", "and", "epsilon", "printing"], "add_tokens": "puts \"iteration = #{iterations}; diff = #{max_diff}\" puts", "del_tokens": "puts 'Iteration ' puts iterations puts max_diff puts ''", "commit_type": "improve"}
{"commit_tokens": ["add", "to", "spec", "that", "user", "is", "updated", "from", "post", "when", "one", "exists"], "add_tokens": "it \"returns 201 if user already exists and updates user\" do givenName : \"Not New\" , expect ( company . users . first . first_name ) . to eq \"Not New\"", "del_tokens": "it \"returns 201 if user already exists\" do givenName : \"New\" ,", "commit_type": "add"}
{"commit_tokens": ["Move", "test", ".", "csv", "to", "directory", "and", "rename"], "add_tokens": "importer = HappyPathImporter . new ( \"test/csv/happy_path.csv\" )", "del_tokens": "importer = HappyPathImporter . new ( \"test/test.csv\" )", "commit_type": "move"}
{"commit_tokens": ["fix", "push", "s", "call", "to", "add"], "add_tokens": "result = add ( io )", "del_tokens": "opts = { :name => spec . name , :version => spec . version . to_s , :platform => spec . platform } result = add ( opts . merge ( :body => io ) )", "commit_type": "fix"}
{"commit_tokens": ["Make", "options", "and", "daemon", "code", "load", "more", "lazily", "."], "add_tokens": "# this one to replace. # Everything else is a daemon implementation detail, and will not # be executed if +Task+ also happens to have a method by the same name. @options [ :pid_file ] ||= File . join ( \"/tmp\" , \"#{@name}.pid\" ) def log_file @options [ :log_file ] @options [ :script ] ||= File . expand_path ( $0 ) daemon_signals def daemon_signals shutdown_soon restart_soon", "del_tokens": "# this one to override. @pid_file ||= File . join ( \"/tmp\" , \"#{@name}.pid\" ) def pid_file = ( val ) @pid_file = val @script ||= File . expand_path ( $0 ) def script = ( path ) @script = path end attr_accessor :log_file # Everything else is a daemon implementation detail setup_signals def setup_signals @shutdown = true @restart = false @shutdown = true @restart = true module Revenant class Task remove_method :startup remove_method :shutdown include :: Revenant :: Daemon end end", "commit_type": "make"}
{"commit_tokens": ["Fix", "append", "to", "file", "alias", "."], "add_tokens": "TTY :: File . add_to_file ( file , \"gem 'tty'\" )", "del_tokens": "TTY :: File . append_to_file ( file , \"gem 'tty'\" )", "commit_type": "fix"}
{"commit_tokens": ["Moved", "examples", "into", "a", "new", "directory"], "add_tokens": "require \"../ruck\"", "del_tokens": "require \"ruck\"", "commit_type": "move"}
{"commit_tokens": ["Added", "documentation", "and", "licensing", "information"], "add_tokens": "#-- # BibTeX-Ruby # Copyright (C) 2010 Sylvester Keil <sylvester.keil.or.at> # # This program is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation, either version 3 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program. If not, see <http://www.gnu.org/licenses/>. #++ # auxiliary classes to model the individual VERSION = '0.0.1'", "del_tokens": "# auxiliary classes and structs to model the individual VERSION = '1.0.1'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "accept", "padding", "."], "add_tokens": "attr_reader :padding def initialize ( column_widths , padding , options = nil ) @padding = Padder . parse ( padding )", "del_tokens": "def initialize ( column_widths , options = nil ) protected", "commit_type": "change"}
{"commit_tokens": ["Change", "initialization", "and", "document", "."], "add_tokens": "@rates = [ ] # @param [Time] at # @param [Integer] value #", "del_tokens": "@rates = Array . new", "commit_type": "change"}
{"commit_tokens": ["Added", "compression", "and", "refactored", "some", "code", "."], "add_tokens": "return destroy_without_trash if @acts_as_trashable_disabled return destroy_without_trash end end # Call this method to temporarily disable the trash feature within a block. def disable_trash save_val = @acts_as_trashable_disabled begin @acts_as_trashable_disabled = true yield if block_given? ensure @acts_as_trashable_disabled = save_val", "del_tokens": "destroy_without_trash", "commit_type": "add"}
{"commit_tokens": ["improve", "the", "hijack", "response", "callback"], "add_tokens": "Hijack = Struct . new ( :socket , :env ) unlink # unlink the management of the socket # Pass the hijack response to the captor using the promise # This forwards the socket and environment as well as moving # continued execution onto the event loop. @request . hijacked . resolve ( Hijack . new ( @socket , @request . env ) ) # If a file, stream the body in a non-blocking fashion # it seems not to matter that we do this here # body.close if body.respond_to?(:close)", "del_tokens": "unlink # unlink the management of the socket @request . hijacked . resolve ( [ @socket ] ) # passes the socket to the captor in an array to prevent chaining # Stream the file if a file # it seems not to matter #body.close if body.respond_to?(:close)", "commit_type": "improve"}
{"commit_tokens": ["Fix", "audit", "logger", "unit", "test"], "add_tokens": "it 'should append info and debug text' do @auditor . should_receive ( :append_info ) . exactly ( 4 ) . times", "del_tokens": "it 'should discard debug text' do @auditor . should_not_receive ( :append_info ) end it 'should append info text' do @auditor . should_receive ( :append_info ) . exactly ( 3 ) . times @auditor . should_not_receive ( :append_error )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "README", "for", "xcode11", "image"], "add_tokens": "# Select the iOS 12.1 runtime runtime = SimCtl . runtime ( name : 'iOS 12.1' ) device = SimCtl . create_device 'Unit Tests @ iPhone 6 - 12.1' , devicetype , runtime", "del_tokens": "# Select the iOS 12.4 runtime runtime = SimCtl . runtime ( name : 'iOS 12.4' ) device = SimCtl . create_device 'Unit Tests @ iPhone 6 - 12.4' , devicetype , runtime", "commit_type": "fix"}
{"commit_tokens": ["Add", "api", "calls", "for", "creating", "and", "updating", "panopticon", "metadata", "."], "add_tokens": "def test_put_json_does_put_with_json_encoded_packet url = \"http://some.endpoint/some.json\" payload = { a : 1 } stub_request ( :put , url ) . with ( body : payload . to_json ) . to_return ( :body => \"{}\" , :status => 200 ) assert_equal ( { } , put_json ( url , payload ) ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "warden", "cookies", "."], "add_tokens": "it \"should set warden cookies\" do env = env_with_params app = lambda do | env | env [ 'warden' ] . warden_cookies [ :foo ] = { :value => \"bar\" } env [ 'warden' ] . warden_cookies [ :baz ] = nil valid_response end cookies = setup_rack ( app ) . call ( env ) [ 1 ] [ \"Set-Cookie\" ] . to_s cookies . should match ( / ^foo=bar$ / ) cookies . should match ( / ^baz=; / ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["removing", "all", "the", "older", "model", "code", ".", "New", "model", "is", "establish", "though", "not", "finished", "enough", "that", "there", "is", "nothing", "more", "to", "learn", "from", "the", "old", "model", "."], "add_tokens": "require 'limelight/java_couplings'", "del_tokens": "#require 'limelight/java_couplings' require 'limelight/java_couplings2' #require 'limelight/alt_couplings'", "commit_type": "remove"}
{"commit_tokens": ["Add", "hashie", "as", "runtime", "dependency"], "add_tokens": "require 'hashie' def self . register_on_complete ( env ) env [ :response ] . on_complete do | response | json = response [ :body ] if json . is_a? ( Hash ) response [ :body ] = Hashie :: Mash . new ( json ) elsif json . is_a? ( Array ) and json . first . is_a? ( Hash ) response [ :body ] = json . map { | item | Hashie :: Mash . new ( item ) }", "del_tokens": "begin require 'hashie' def self . register_on_complete ( env ) env [ :response ] . on_complete do | response | json = response [ :body ] if json . is_a? ( Hash ) response [ :body ] = Hashie :: Mash . new ( json ) elsif json . is_a? ( Array ) and json . first . is_a? ( Hash ) response [ :body ] = json . map { | item | Hashie :: Mash . new ( item ) } end rescue LoadError , NameError => e self . load_error = e", "commit_type": "add"}
{"commit_tokens": ["Updating", "gemspec", "to", "pull", "in", "dependencies", "correctly", "."], "add_tokens": "VERSION = \"0.2.1\"", "del_tokens": "VERSION = \"0.2.0\"", "commit_type": "update"}
{"commit_tokens": ["updated", "alias", "naming", "to", "fields", "and", "form", "generators", "for", "users", "who", "do", "not", "want", "to", "append", "the", "prefix"], "add_tokens": "alias :fieldsula_for :formula_fields_for", "del_tokens": "alias :fieldula_for :formula_fields_for", "commit_type": "update"}
{"commit_tokens": ["improve", "on_cx_switch_block", "by", "not", "using", "unnecessary", "scope"], "add_tokens": "if self == ActiveRecord :: Base || ! switch_to_slave with_scope ( { :find => { :readonly => true } } , & block )", "del_tokens": "if self == ActiveRecord :: Base with_scope ( { :find => { :readonly => on_slave? } } , :merge , & block )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "some", "Hash", "issues", "probably", "related", "to", "Ruby", "version", "differences", "."], "add_tokens": "vars = variables . map do | k , v | end Hash [ vars ] vars = Hash [ kwargs . map { | k , v | [ k , { default : v } ] } ]", "del_tokens": "variables . map do | k , v | end . to_h vars = kwargs . map { | k , v | [ k , { default : v } ] } . to_h", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "skip", "curses", "check", "on", "windowz", "."], "add_tokens": "return NoValue if TTY :: Color . windows? return has_color NoValue", "del_tokens": "has_color else NoValue", "commit_type": "change"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "Yajl", "parser", "being", "given", "OAuth2", "response", "body", "rather", "than", "a", "JSON", "string", "."], "add_tokens": "result = Skittles :: Utils . parse_json ( response . body )", "del_tokens": "result = Skittles :: Utils . parse_json ( response )", "commit_type": "fix"}
{"commit_tokens": ["Use", "temporary", "variable", "to", "avoid", "dynamic", "string", "warning", "from", "rdoc", "."], "add_tokens": "# Use a temporary variable to avoid an rdoc warning file = \"tzinfo/definitions/#{identifier}\" require file", "del_tokens": "require \"tzinfo/definitions/#{identifier}\"", "commit_type": "use"}
{"commit_tokens": ["Add", "QVariant", "s", "void", "*", "support"], "add_tokens": "def self . new ( val , raw : nil ) return super ( raw ) if raw when FFI :: Pointer CLib . qvariant_from_voidp ( val ) when MetaType :: VOID_STAR CLib . qvariant_to_voidp ( self ) variant = self . new ( variant ) unless variant . is_a? ( Variant ) self . new ( nil , raw : ptr )", "del_tokens": "def self . new ( val ) when FFI :: Pointer super ( val ) variant = Variant . new ( variant ) unless variant . is_a? ( Variant ) self . new ( ptr )", "commit_type": "add"}
{"commit_tokens": ["Changed", "how", "params", "are", "accepted"], "add_tokens": "# @param key [Symbol] the parameter to add. # @param value_klass [Class] the value type of the parameter. # @param default [Object] the default value of the parameter. def param ( key , value_klass , default : nil ) @_params = { } unless defined? @_params @_params [ key ] = [ value_klass , default ] . freeze @_params . each_with_object ( { } ) { | ( k , v ) , h | h [ k ] = Parameter . new ( * v ) }", "del_tokens": "# @param hash [Hash] the parameter(s) to add. def param ( ** hash ) @_params ||= { } @_params . merge! hash @_params . each_with_object ( { } ) { | ( k , v ) , h | h [ k ] = Parameter . new v }", "commit_type": "change"}
{"commit_tokens": ["change", "exception", "to", "look", "only", "at", "pagarme", "exception"], "add_tokens": "rescue PagarMe :: PagarMeError => e render json : { boleto_url : nil , payment_status : 'failed' , message : e . message } end", "del_tokens": "rescue Exception => e Rails . logger . info e . inspect render json : { boleto_url : nil , payment_status : 'failed' }", "commit_type": "change"}
{"commit_tokens": ["Add", "new", "self", ".", "create_ignore_rules", "method"], "add_tokens": "def self . create_ignore_rules ( rep , file ) current_articles = NanocConrefFS :: Variables . fetch_data_file ( file , rep ) current_articles = current_articles . values . flatten current_articles = fix_nested_content ( current_articles ) basic_yaml = NanocConrefFS :: Variables . data_files [ \"data/#{file.tr!('.', '/')}.yml\" ] basic_yaml . gsub! ( / \\{ %.+ / , '' ) full_file = YAML . load ( basic_yaml ) full_user_articles = full_file . values . flatten full_user_articles = fix_nested_content ( full_user_articles ) blacklisted_articles = full_user_articles - current_articles blacklisted_articles . map do | article | \"**/#{article.parameterize}.md\" end end def self . fix_nested_content ( articles ) articles . delete_if do | i | if i . is_a? Hash articles . concat ( i . keys . concat ( i . values ) . flatten ) true else false articles", "del_tokens": "content", "commit_type": "add"}
{"commit_tokens": ["add", "requre", "helper", "to", "test", "files"], "add_tokens": "$LOAD_PATH . unshift ( File . dirname ( __FILE__ ) ) require 'helper'", "del_tokens": "require 'box'", "commit_type": "add"}
{"commit_tokens": ["adding", "ASSET_HOST", "config", "and", "a", "staging", "environment", "file"], "add_tokens": "config . assets . initialize_on_precompile = false", "del_tokens": "config . assets . initialize_on_precompile = false", "commit_type": "add"}
{"commit_tokens": ["Add", "pending", "spec", "for", "error", "objects", "."], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "add", "hook", "for", "default", "value", "setup", "."], "add_tokens": "@default = Array [ options . fetch ( :default ) { 1 } ] @active = @default . first def default ( * default_values ) @default = default_values setup_defaults # Setup default option and active selection # # @api private def setup_defaults @active = @default . first end", "del_tokens": "@active = options . fetch ( :default ) { 1 } def default ( value ) @active = value", "commit_type": "change"}
{"commit_tokens": ["Use", "root", ".", "bowerrc", "as", "starting", "point", "rather", "than", "creating", "one", "from", "scratch", "."], "add_tokens": "def generate_dotbowerrc contents = JSON . parse ( File . read ( File . join ( @root_path , '.bowerrc' ) ) ) rescue { } contents [ \"directory\" ] = \"bower_components\" end f . write ( JSON . pretty_generate ( generate_dotbowerrc ) )", "del_tokens": "f . write ( JSON . pretty_generate ( { :directory => \"bower_components\" } ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "authentication", "for", "ActiveResource", "/", "Rails", "."], "add_tokens": "body = @request . raw_post", "del_tokens": "body = @request . body . read", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "way", "to", "compare", "signatures"], "add_tokens": "class ValidationException < TypeError ; end secure_compare ( calculatedSignature , expectedSignature ) def secure_compare ( a , b ) return false if a . empty? || b . empty? || a . bytesize != b . bytesize l = a . unpack \"C#{a.bytesize}\" res = 0 b . each_byte { | byte | res |= byte ^ l . shift } res == 0 end", "del_tokens": "class ValidationException < TypeError ; end calculatedSignature == expectedSignature", "commit_type": "change"}
{"commit_tokens": ["Fix", "tests", "for", "deleting", "nodes", "from", "osm", "."], "add_tokens": "into . instance_methods ( false ) . select { | method_name | [ :save , :create , :update , :destroy ] . include? ( method_name . to_sym ) } . each do | m | if [ :save , :create , :update , :destroy ] . include? ( m . to_sym )", "del_tokens": "into . instance_methods ( false ) . select { | method_name | [ :save , :create , :update , :delete ] . include? ( method_name . to_sym ) } . each do | m | if [ :save , :create , :update , :delete ] . include? ( m . to_sym )", "commit_type": "fix"}
{"commit_tokens": ["make", "select", "an", "optional", "argument", "to", "wait", "."], "add_tokens": "def wait ( timeout_usec = - 1 , opts = { } ) if opts [ :select ] wait_select ( timeout_usec ) else rc = Native . sd_journal_wait ( @ptr , timeout_usec ) raise JournalError . new ( rc ) if rc . is_a? ( Fixnum ) && rc < 0 rc == :nop ? nil : rc end # Determine if calls to {#wait} with `select: true` will reliably wake # when a change occurs. If it returns false, there might be some (unknown) # latency involved between when an change occurs and when {#wait} returns. def wait_select ( timeout_usec ) timeout_sec = ( timeout_usec == - 1 ? nil : timeout_usec / 1e6 ) r , * _ = IO . select ( [ io_object ] , [ ] , [ ] , timeout_sec ) r ? reason_for_wakeup : nil end", "del_tokens": "def wait ( timeout_usec = - 1 ) rc = Native . sd_journal_wait ( @ptr , timeout_usec ) raise JournalError . new ( rc ) if rc . is_a? ( Fixnum ) && rc < 0 rc == :nop ? nil : rc end # Block until the journal is changed. # This function differs from {#wait} in the following ways: # * the timeout parameter is defined in seconds, not microseconds. # * this function can be interrupted and woken prior to completion. # @param timeout_sec [Fixnum] the maximum number of seconds to wait # or `nil` to wait indefinitely. # @example Wait for an event for a maximum of 3 seconds # j = Systemd::Journal.new # j.seek(:tail) # if j.select(3) # # event occurred # end # @return [Nil] if the wait time was reached (no events occured). # @return [Symbol] :append if new entries were appened to the journal. # @return [Symbol] :invalidate if journal files were added/removed/rotated. def wait_select ( timeout_sec = nil ) r , * _ = IO . select ( [ io_object ] , [ ] , [ ] , timeout_sec ) r ? reason_for_wakeup : nil # Determine if calls to {#select} will reliably wake when a change occurs. # If it returns false, there might be some (unknown) latency involved # between when an change occurs and when {#select} returns.", "commit_type": "make"}
{"commit_tokens": ["moved", "default", "styles", "to", "styles", "/", "folder", "added", "an", "html", "-", "like", "stylesheet", "which", "uses", "tags", "for", "styling", "."], "add_tokens": "@defaults = load 'default' styles += '.yml' unless styles =~ / \\. ya?ml$ / styles = File . join ( File . dirname ( __FILE__ ) , \"styles\" , styles ) unless File . exist? styles", "del_tokens": "@defaults = load File . dirname ( __FILE__ ) + \"/styles\" styles += '.yml' unless styles =~ / \\. ya?ml /", "commit_type": "move"}
{"commit_tokens": ["Use", "correct", "textile", "string", "for", "conversion", "tests", "."], "add_tokens": "%Q|h1(#this-is-a-title). This is a Title\\n\\nSome _emphasized text_ and \\\"a link\\\":http://daringfireball.net/projects/markdown/|", "del_tokens": "%Q|h1. This is a Title\\n\\nSome _emphasized text_ and \\\"a link\\\":http://daringfireball.net/projects/markdown/|", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "Patron", "with", "basic", "HTTP", "functionality"], "add_tokens": "require 'patron' unless RUBY_PLATFORM =~ / java / :response_body => \"<title>example</title>\" }", "del_tokens": ":response_body => \"<title>Google fake response</title>\" }", "commit_type": "add"}
{"commit_tokens": ["Allow", "the", "scanner", "/", "tokenizer", "to", "be", "swapped", "out", "."], "add_tokens": "# The class that performs tokenization of the input string attr_accessor :scanner self . scanner = options [ :scanner ] || Radius :: Scanner . new @tokens = scanner . operate ( tag_prefix , string )", "del_tokens": "@tokens = Scanner . new . operate ( tag_prefix , string )", "commit_type": "allow"}
{"commit_tokens": ["Added", "date", "argument", "when", "retrieving", "campaign", "bounces", "."], "add_tokens": "def bounces ( date = \"1900-01-01\" , page = 1 , page_size = 1000 , order_field = \"date\" , order_direction = \"asc\" ) :date => date ,", "del_tokens": "def bounces ( page = 1 , page_size = 1000 , order_field = \"date\" , order_direction = \"asc\" )", "commit_type": "add"}
{"commit_tokens": ["fix", "incorrect", "parse", "escaped", "chars", "like", "\\\\", "path", "\\", "to", "in", "V8iFile"], "add_tokens": "inifile . each_section do | caption | IniFile . new ( content : \"#{escape_content(content)}\" , comment : '' ) def self . escape_content ( content ) content . gsub! ( BOM , '' ) content . gsub! ( / \\\\ \\\\ / , '\\\\\\\\\\\\\\\\\\\\' ) %w( r n t 0 ) . each do | l | content . gsub! ( / \\\\ #{ l } / , \"\\\\\\\\\\\\#{l}\" ) content", "del_tokens": "inifile . each_section do | caption | fix_file_connect ( inifile [ caption ] ) content . gsub! ( BOM , '' ) IniFile . new ( content : \"#{content}\" , comment : '' ) #TODO Is bad fix duble backslash path like: # \\\\bla\\bla\\bla parsing IniFile as \\bla\\bla\\bla def self . fix_file_connect ( hash ) if hash [ 'Connect' ] =~ / File=\" \\\\ (?=[^ \\\\ ]) /i hash [ 'Connect' ] . gsub! ( 'File=\"\\\\' , 'File=\"\\\\\\\\\\\\' ) end if hash [ 'AdmConnect' ] =~ / File=\" \\\\ (?=[^ \\\\ ]) /i hash [ 'AdmConnect' ] . gsub! ( 'File=\"\\\\' , 'File=\"\\\\\\\\\\\\' )", "commit_type": "fix"}
{"commit_tokens": ["use", "Request", ".", "new", "instead", "of", "Request", ".", "post", "/", "get", "/", "put", "/", "etc"], "add_tokens": "build ( request . klass , ( Request . new ( request . request_uri , request . options ) . run ) ) Request . new ( save_request . request_uri , save_request . options ) . run Request . new ( delete_request . request_uri , delete_request . options ) . run", "del_tokens": "method = request . http_method build ( request . klass , ( Request . send method , request . request_uri , request . options ) ) Request . send save_http_method ( method ) , save_request . request_uri , save_request . options Request . delete ( delete_request . request_uri , delete_request . options )", "commit_type": "use"}
{"commit_tokens": ["Fixing", "comment", "and", "added", "TODO", "."], "add_tokens": "# TODO: Code Climate says this method is too big. # A singleton class with a settings hash attribute wich may be used to", "del_tokens": "# A singleton class with a settings hash attribute wich may be user to", "commit_type": "fix"}
{"commit_tokens": ["Allow", "ignore_paths", "to", "contain", "either", "strings", "or", "procs"], "add_tokens": "config . ignore_paths . any? do | p | if p . is_a? Proc p . call ( @file ) else @file . index ( p ) end end", "del_tokens": "config . ignore_paths . any? { | p | @file . index ( p ) }", "commit_type": "allow"}
{"commit_tokens": ["Add", "belong_to_vpc", "matcher", "for", "elasticache"], "add_tokens": "@matchers = %w( belong_to_vpc belong_to_replication_group belong_to_cache_subnet_group )", "del_tokens": "@matchers = %w( belong_to_replication_group belong_to_cache_subnet_group )", "commit_type": "add"}
{"commit_tokens": ["Updated", "exception", "message", "to", "be", "more", "helpful", "."], "add_tokens": "raise ArgumentError . new ( \"The http stubbing adapter is not configured correctly. You should set it to :webmock or :fakeweb.\" )", "del_tokens": "raise ArgumentError . new ( \"The http stubbing adapter is not configured correctly.\" )", "commit_type": "update"}
{"commit_tokens": ["add", "support", "for", "optional", "ssh", "command"], "add_tokens": "arg :cmd , \"Optional command\" , :required => false , :default => nil def ssh vm , cmd ssh_cmd << \" #{cmd}\" if cmd", "del_tokens": "def ssh vm", "commit_type": "add"}
{"commit_tokens": ["Changed", "log", "level", "requrmnt", "for", "target", "host", "output"], "add_tokens": "ChefApply :: Log . info ( c . stdout )", "del_tokens": "ChefApply :: Log . debug ( c . stdout )", "commit_type": "change"}
{"commit_tokens": ["Make", "subqueries", "wrappers", "around", "query", "objects", "."], "add_tokens": "attr_reader :relation , :parent , :table_ref , :conditions , :subquery_count , :query_columns unless parent @literals = { } @singular_table_refs = { relation => self } @subquery_count = 0 end return parent . add_singular_table_ref ( relation , table_ref ) if parent def singular_table_refs parent . try ( :singular_table_refs ) || @singular_table_refs end return parent . add_subquery ( relation ) if parent def resolve_derived_column ( column , alias_name = nil , qualified = false )", "del_tokens": "attr_reader :relation , :parent , :table_ref , :conditions , :singular_table_refs , :subquery_count , :query_columns @literals = { } @singular_table_refs = { relation => self } @subquery_count = 0 def resolve_derived_column ( column , alias_name , qualified = false )", "commit_type": "make"}
{"commit_tokens": ["Allow", "arrays", "as", "a", "value", "of", "custom", "meta", "tags"], "add_tokens": "subject . meta_tags . should eq ( 'title' => 'title' , 'keywords' => 'key1, key2, key3' , 'description' => 'description' )", "del_tokens": "subject . meta_tags . should == { 'title' => 'title' , 'keywords' => 'key1, key2, key3' , 'description' => 'description' }", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "dependencies", "-", "was", "previously", "causing", "errors", "on", "valid", "string", "dependencies"], "add_tokens": "if dependency_value . is_a? ( String ) if ! data . has_key? ( dependency_value ) message = \"The property '#{build_fragment(fragments)}' has a property '#{property}' that depends on a missing property '#{dependency_value}'\" raise ValidationError . new ( message , fragments , current_schema ) end", "del_tokens": "if dependency_value . is_a? ( String ) && ! data . has_key? ( dependency_value ) message = \"The property '#{build_fragment(fragments)}' has a property '#{property}' that depends on a missing property '#{dependency_value}'\" raise ValidationError . new ( message , fragments , current_schema )", "commit_type": "fix"}
{"commit_tokens": ["fix", "stupid", "error", "in", "date", "conversion"], "add_tokens": "@date1904 = date1904 > 0 date . ajd + 1 - compare_date . ajd # subtract one day to compare date for erroneous 1900 leap year compatibility compare_date - 1 + num", "del_tokens": "@date1904 = date1904 date . ajd - ( compare_date . ajd + 1 ) # add one day to compare date for erroneous 1900 leap year compatibility compare_date + 1 + num", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "Windows", "groks", "the", "newlines", "in", "there", "."], "add_tokens": "file 'msg' , \"first branch commit\\n\\nSigned-off-by: Commiter McCommiterface <other@example.com>\\n\" command 'echo three > testing && git commit -a -F msg'", "del_tokens": "command \"echo three > testing && git commit -a -m \\\"first branch commit\\n\\nSigned-off-by: Commiter McCommiterface <other@example.com>\\n\\\"\"", "commit_type": "make"}
{"commit_tokens": ["Updated", "version", "and", "gem", "dependencies"], "add_tokens": "VERSION = '0.9.9'", "del_tokens": "VERSION = '0.9.8'", "commit_type": "update"}
{"commit_tokens": ["added", "specs", "for", "friends_for", "and", "followers"], "add_tokens": "describe \"friends and followers\" do it \"should be able to get friends for another user\" do data = open ( File . dirname ( __FILE__ ) + '/fixtures/friends_for.xml' ) . read @base . should_receive ( :request ) . and_return ( Hpricot :: XML ( data ) ) timeline = @base . friends_for ( 20 ) timeline . size . should == 100 timeline . first . name . should == 'Jack Dorsey' end it \"should be able to get followers\" do data = open ( File . dirname ( __FILE__ ) + '/fixtures/followers.xml' ) . read @base . should_receive ( :request ) . and_return ( Hpricot :: XML ( data ) ) timeline = @base . followers timeline . size . should == 100 timeline . first . name . should == 'Blaine Cook' end", "del_tokens": "describe \"friends\" do", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "TheBigDB", ".", "api_key", "=", "accessors", "and", "behaviour", "+", "normalised", "hash", "styles"], "add_tokens": "if TheBigDB . api_key . is_a? ( String ) and ! TheBigDB . api_key . empty? params . merge! ( \"api_key\" => TheBigDB . api_key ) end \"publisher\" => \"thebigdb\" , \"version\" => TheBigDB :: VERSION :: STRING , \"language\" => \"ruby\" , \"language_version\" => \"#{RUBY_VERSION} p#{RUBY_PATCHLEVEL} (#{RUBY_RELEASE_DATE})\" ,", "del_tokens": ":publisher => \"thebigdb\" , :version => TheBigDB :: VERSION :: STRING , :language => \"ruby\" , :language_version => \"#{RUBY_VERSION} p#{RUBY_PATCHLEVEL} (#{RUBY_RELEASE_DATE})\" ,", "commit_type": "add"}
{"commit_tokens": ["add", "location", "of", "gcc", "binary", "to", "installation"], "add_tokens": "osx_root = \"/Applications/Arduino.app/Contents\" osx_place = \"#{osx_root}/MacOS\" \"-cp\" , \"#{osx_root}/Java/*\" , \"-DAPP_DIR=#{osx_root}/Java\" , ret . gcc_cmd = [ File . join ( osx_root , \"Java\" , \"hardware\" , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ] ret . gcc_cmd = Host . which ( \"avr-gcc\" ) ret . gcc_cmd = [ File . join ( force_install_location , \"hardware\" , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ] ret . gcc_cmd = Host . which ( \"avr-gcc\" ) ret . gcc_cmd = [ File . join ( force_install_location , \"hardware\" , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ]", "del_tokens": "osx_root = \"/Applications/Arduino.app\" osx_place = \"#{osx_root}/Contents/MacOS\" \"-cp\" , \"#{osx_root}/Contents/Java/*\" , \"-DAPP_DIR=#{osx_root}/Contents/Java\" ,", "commit_type": "add"}
{"commit_tokens": ["Implement", "index", "checking", ".", "Improve", "decomposition", "and", "tests", "."], "add_tokens": "FIELDS = [ FIELD_COLUMNS , FIELD_INDEXES ] DEFAULT_INDEX = { :columns => nil , :name => nil , :type => nil , :unique => nil , :where => nil , }", "del_tokens": "FIELD_CONSTRAINTS = :constraints FIELDS = [ FIELD_COLUMNS , FIELD_INDEXES , FIELD_CONSTRAINTS ]", "commit_type": "implement"}
{"commit_tokens": ["add", "syntax", "conversion", "basics", "not", "yet", "perfect", "nor", "bugfree", "updated", "gitignore"], "add_tokens": "require 'optparse' require 'wikka2markdown_converter' # if original_wiki . convert_syntax? puts \"latest revisions:\" # take each latest revision for rev in original_wiki . latest_revisions puts \"Updated syntax: #{rev.title} #{rev.time}\" # parse syntax # convert to new syntax body_new = original_wiki . convert2markdown rev . body unless body_new == rev . body rev . body = body_new rev . author_name = \"Caramelize\" rev . time = Time . now rev . author = nil # commit as latest page revision output_wiki . commit_revision rev end end end #lemma = wiki.revisions_by_title \"dahie\" #for page in lemma # puts page.time #end puts \"Time required: #{time_end - time_start} s\"", "del_tokens": "#lemma = wiki.revisions_by_title \"dahie\" #for page in lemma # puts page.time #end # take latest revisions # parse syntax # convert to new syntax # commit as latest page revision puts \"Time required: #{time_end - time_start} s\"", "commit_type": "add"}
{"commit_tokens": ["added", "homepage", "and", "updated", "description"], "add_tokens": "VERSION = '0.1.0'", "del_tokens": "VERSION = '0.0.2'", "commit_type": "add"}
{"commit_tokens": ["Add", "report", "phrase_organic", "+", "display_sort", "&", "display_filter", "parameters"], "add_tokens": "require 'cgi' API_REPORT_URL = \"http://%DB%.api.semrush.com/?action=report&type=%REPORT_TYPE%&%REQUEST_TYPE%=%REQUEST%&key=%API_KEY%&display_limit=%LIMIT%&display_offset=%OFFSET%&export=api&export_columns=%EXPORT_COLUMNS%&display_sort=%DISPLAY_SORT%&display_filter=%DISPLAY_FILTER%\"", "del_tokens": "API_REPORT_URL = \"http://%DB%.api.semrush.com/?action=report&type=%REPORT_TYPE%&%REQUEST_TYPE%=%REQUEST%&key=%API_KEY%&display_limit=%LIMIT%&display_offset=%OFFSET%&export=api&export_columns=%EXPORT_COLUMNS%\"", "commit_type": "add"}
{"commit_tokens": ["use", "tty", "-", "command", "again"], "add_tokens": "require 'tty-command' runner = TTY :: Command . new return runner . run ( * cmd )", "del_tokens": "require 'open3' stdout_s , stderr_s , status = Open3 . capture3 ( * cmd ) if not status . success? raise StandardError , \"Failed to run command: #{stderr_s}\" end return { :out => stdout_s , :err => stderr_s , :status => status }", "commit_type": "use"}
{"commit_tokens": ["removed", "buffer", "instance", "variables", "from", "em_client"], "add_tokens": "response_buffer = :: Protobuf :: Rpc :: Buffer . new ( :read ) response_buffer << data @response_data = response_buffer . data parse_response if response_buffer . flushed? request_buffer = :: Protobuf :: Rpc :: Buffer . new ( :read ) request_buffer . set_data ( request_wrapper ) log_debug { \"[#{log_signature}] sending data: #{request_buffer.inspect}\" } super ( request_buffer . write )", "del_tokens": "@response_buffer << data parse_response if @response_buffer . flushed? log_debug { \"[#{log_signature}] sending data: #{@request_buffer.inspect}\" } super ( @request_buffer . write )", "commit_type": "remove"}
{"commit_tokens": ["added", "proper", "code", "for", "handling", "removal", "of", "media", "and", "bumped", "version"], "add_tokens": "VERSION = \"0.2.5\"", "del_tokens": "VERSION = \"0.2.4\"", "commit_type": "add"}
{"commit_tokens": ["Add", "access", "token", "scopes", "check", "to", "integration", "test"], "add_tokens": "authorization_code_exists ( :client => @client , :scopes => \"public\" ) token . scopes . should == [ :public ]", "del_tokens": "authorization_code_exists ( :client => @client )", "commit_type": "add"}
{"commit_tokens": ["Added", "F", "(", "Float", ")", "field", "type", ";", "modified", "tests"], "add_tokens": "when 'N' , 'F' # number when 'F' # float unpack_float ( value ) # Decode a float value # # @param [String] value # @return [Float] def unpack_float ( value ) value . to_f end when \"N\" , \"F\"", "del_tokens": "when 'N' # number when \"N\"", "commit_type": "add"}
{"commit_tokens": ["Updating", "README", "and", "gem", "version"], "add_tokens": "VERSION = \"1.0.0\"", "del_tokens": "VERSION = \"0.8.1\"", "commit_type": "update"}
{"commit_tokens": ["Removes", "unneccessary", "Layer", "::", "Ruby", "module"], "add_tokens": "require 'layer'", "del_tokens": "require \"layer\" module Layer module Ruby # Your code goes here... end end", "commit_type": "remove"}
{"commit_tokens": ["use", "Enumerable#count", "when", "getting", "the", "size", "of", "a", "non", "-", "countable", "storage"], "add_tokens": "s < 0 ? count : s", "del_tokens": "if s < 0 raise RedlandError . new ( \"Attempt to get size when using non-countable storage\" ) else s end", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "extract", "filename", "and", "extension", "setup"], "add_tokens": "set_file_metadata ( file ) ext = ( format == :auto ? extname : \".#{format}\" ) set_file_metadata ( file ) ext = ( format == :auto ? extname : \".#{format}\" ) # Set file name and extension # # @param [File] file # # @api public def set_file_metadata ( file ) self . extname = :: File . extname ( file ) self . filename = :: File . basename ( file , extname ) end", "del_tokens": "file_ext = :: File . extname ( file ) ext = ( format == :auto ? file_ext : \".#{format}\" ) self . extname = file_ext self . filename = :: File . basename ( file , file_ext ) file_ext = :: File . extname ( file ) ext = ( format == :auto ? file_ext : \".#{format}\" ) self . extname = file_ext self . filename = :: File . basename ( file , file_ext )", "commit_type": "change"}
{"commit_tokens": ["Fix", "singleton", "exception", "name", "bug"], "add_tokens": "self . ignore_classes . include? ( self . exception . class . name ) :errorClass => self . exception . class . name ,", "del_tokens": "self . ignore_classes . include? ( self . exception . class . to_s ) :errorClass => self . exception . class . to_s ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "Ink", "plugin", "back", ".", "Oops", "."], "add_tokens": "Octopress :: Ink . register_plugin ( Ink )", "del_tokens": "#Octopress::Ink.register_plugin(Ink)", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", ">", "1", "caching", "type"], "add_tokens": "ContentfulModel :: Base . send ( :include , ContentfulRails :: Caching :: Timestamps ) if types . include? ( :timestamp ) ContentfulModel :: Base . send ( :include , ContentfulRails :: Caching :: Objects ) if types . include? ( :object )", "del_tokens": "case ContentfulRails . configuration . caching_type when :timestamp ContentfulModel :: Base . send ( :include , ContentfulRails :: Caching :: Timestamps ) when :object ContentfulModel :: Base . send ( :include , ContentfulRails :: Caching :: Objects ) end", "commit_type": "allow"}
{"commit_tokens": ["Added", "proxy", "support", "and", "configuration", "of", "timeouts"], "add_tokens": "attr_accessor :host , :port , :secure , :api_key , :http_open_timeout , :http_read_timeout , :proxy_host , :proxy_port , :proxy_user , :proxy_pass # The HTTP open timeout (defaults to 2 seconds). def http_open_timeout @http_open_timeout ||= 2 end # The HTTP read timeout (defaults to 5 seconds). def http_read_timeout @http_read_timeout ||= 5 end Net :: HTTP :: Proxy ( HoptoadNotifier . proxy_host , HoptoadNotifier . proxy_port , HoptoadNotifier . proxy_user , HoptoadNotifier . proxy_pass ) . start ( url . host , url . port ) do | http | http . read_timeout = HoptoadNotifier . http_read_timeout http . open_timeout = HoptoadNotifier . http_open_timeout", "del_tokens": "attr_accessor :host , :port , :secure , :api_key Net :: HTTP . start ( url . host , url . port ) do | http | http . read_timeout = 5 # seconds http . open_timeout = 2 # seconds", "commit_type": "add"}
{"commit_tokens": ["Remove", "more", "empty", "()", "parens"], "add_tokens": "@transportFactory = transportFactory ? transportFactory : Thrift :: TransportFactory . new @protocolFactory = protocolFactory ? protocolFactory : Thrift :: BinaryProtocolFactory . new def serve ; nil ; end def serve @serverTransport . listen client = @serverTransport . accept trans . close @serverTransport . close def serve @serverTransport . listen client = @serverTransport . accept t . close @serverTransport . close @serverTransport . listen client = @serverTransport . accept trans . close @thread_q . pop # thread died! @serverTransport . close", "del_tokens": "@transportFactory = transportFactory ? transportFactory : Thrift :: TransportFactory . new ( ) @protocolFactory = protocolFactory ? protocolFactory : Thrift :: BinaryProtocolFactory . new ( ) def serve ( ) ; nil ; end def serve ( ) @serverTransport . listen ( ) client = @serverTransport . accept ( ) trans . close ( ) @serverTransport . close ( ) def serve ( ) @serverTransport . listen ( ) client = @serverTransport . accept ( ) t . close ( ) @serverTransport . close ( ) @serverTransport . listen ( ) client = @serverTransport . accept ( ) trans . close ( ) @thread_q . pop ( ) # thread died! @serverTransport . close ( )", "commit_type": "remove"}
{"commit_tokens": ["Updated", "to", "support", "V1", "/", "V2", "url", "split"], "add_tokens": "@api_endpoint = api_endpoint @api_version = api_version @api_token = api_token @api_secret = api_secret @configure_connection = configure_connection Faraday . new ( @api_endpoint ) { | faraday | faraday . basic_auth ( @api_token , @api_secret ) @configure_connection . call ( faraday ) if @configure_connection def make_request ( method , path , data = { } , api_version = 'v1' , api_endpoint = '' ) # Not so ideal solution to the V1/V2 endpoint split # If no endpoint is defined, use previously created connection if api_endpoint . length == 0 create_connection = @create_connection # Else create a new temporary connection using the new endpoint else create_connection = lambda { | | Faraday . new ( api_endpoint ) { | faraday | faraday . basic_auth ( @api_token , @api_secret ) faraday . headers [ 'Accept' ] = 'application/json' faraday . headers [ 'User-Agent' ] = \"ruby-bandwidth/v#{Bandwidth::VERSION}\" @set_adapter . call ( faraday ) @configure_connection . call ( faraday ) if @configure_connection } } end connection = create_connection . call ( )", "del_tokens": "Faraday . new ( api_endpoint ) { | faraday | faraday . basic_auth ( api_token , api_secret ) configure_connection . call ( faraday ) if configure_connection @api_endpoint = api_endpoint @api_version = api_version def make_request ( method , path , data = { } , api_version = 'v1' ) connection = @create_connection . call ( )", "commit_type": "update"}
{"commit_tokens": ["Adds", "Backticks", "Backend", "Shakey", "Support", "for", "JRuby"], "add_tokens": "start_time = Time . now time : ( start_time - end_time ) . abs , env : env ,", "del_tokens": "start = Time . now time : ( start - end_time ) . abs , env : env ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "(", "was", "not", "setting", "custom", "error", "message", "for", "RegexFields", "correctly", ")"], "add_tokens": "options [ :error_messages ] [ :invalid ] = error_message", "del_tokens": "options [ :error_messages ] [ :invalid ] = error_messages", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "CLI", "help"], "add_tokens": "installed ( created if nonexistent )", "del_tokens": "installed ( created if non existent )", "commit_type": "fix"}
{"commit_tokens": ["updated", "requires", "for", "name", "change"], "add_tokens": "require 'richunits/multipliers' require 'richunits/bytes' require 'richunits/times' require 'richunits/weekdays' require 'richunits/duration'", "del_tokens": "require 'rich_units/multipliers' require 'rich_units/bytes' require 'rich_units/times' require 'rich_units/weekdays' require 'rich_units/duration'", "commit_type": "update"}
{"commit_tokens": ["fixing", "args", "for", "lint", "method", "in", "cli"], "add_tokens": "# option :directory, required: false, type: :string # option :quiet, required: false, type: :string def lint ( directory = nil , quiet = nil )", "del_tokens": "option :directory , required : false , type : :string option :quiet , required : false , type : :string def lint dir = options [ :directory ] quiet = options [ :quiet ]", "commit_type": "fix"}
{"commit_tokens": ["use", "root", "user", "class", "for", "operation_template_decorator", "as", "well"], "add_tokens": ":: User . role_text ( object . role ) if object . role :: User . group_text ( object . group ) if object . group", "del_tokens": "User . role_text ( object . role ) if object . role User . group_text ( object . group ) if object . group", "commit_type": "use"}
{"commit_tokens": ["Change", "node", "to", "provide", "file", "stat", "."], "add_tokens": "require 'forwardable' require 'pathname' extend Forwardable # The base name for the directory or file attr_reader :name # The parent directory path attr_reader :parent # The require path prefix attr_reader :prefix # The directory depth attr_reader :level # The file stat attr_reader :stat def_delegators :@path , :directory? , :executable? , :file? , :symlink? , :socket? , :pipe? def initialize ( path , parent , prefix , level ) @path = Pathname . new ( path ) @name = @path . basename", "del_tokens": "attr_reader :name , :parent , :prefix , :level def initialize ( name , parent , prefix , level ) @name = name", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "simple", "rake", "tests", "for", "loading", "to", "and", "pulling", "from", "test", "queues"], "add_tokens": "min = guess_min_peek_range ( guess_tubes ) if @min == 0 max = guess_max_peek_range ( min ) if @max == 0 for i in min .. max #puts \"Ignoring NotFoundError: #{ex.class}: #{ex}\"", "del_tokens": "@min = guess_min_peek_range ( guess_tubes ) if @min == 0 @max = guess_max_peek_range ( @min ) if @max == 0 for i in @min .. @max puts e", "commit_type": "add"}
{"commit_tokens": ["Implemented", "the", "recording", "API", "."], "add_tokens": "require 'crack' tmp = YAML :: load ( File . open ( File . join ( File . dirname ( __FILE__ ) , 'testdata.yml' ) ) ) @testdata = { } tmp . each_pair do | k , v | if k . end_with? ( '_json' ) @testdata [ k [ 0 .. - 6 ] ] = Crack :: JSON . parse ( v ) else @testdata [ k ] = v end end", "del_tokens": "@testdata = YAML :: load ( File . open ( File . join ( File . dirname ( __FILE__ ) , 'testdata.yml' ) ) )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "scanning", "issue", "with", ".", "ca", "when", "keys", "have", "no", "value"], "add_tokens": "if ! @input . match? ( / ^ \\s / ) && @input . scan ( / ^(.+?): \\n / )", "del_tokens": "if @input . scan ( / ^(.+?): \\n / )", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "behavior", "of", "Row#method_missing", "and", "enable", "to", "define", "variable", "in", "the", "received", "block"], "add_tokens": "_check_if_valid def _check_if_valid _check_if_valid pos . nil? ? super : @arr [ pos ]", "del_tokens": "_check_is_valid def _check_is_valid _check_is_valid raise \"InvalidBlockError\" if pos . nil? @arr [ pos ]", "commit_type": "change"}
{"commit_tokens": ["Fix", "to", "deal", "with", "undefined", "paths"], "add_tokens": "@resource_paths ||= { } if self . class . resource_paths [ path ] send \"#{self.class.resource_paths[path]}_path\" , * args", "del_tokens": "@resource_paths if path = self . class . resource_paths [ path ] send \"#{path}_path\" , * args", "commit_type": "fix"}
{"commit_tokens": ["Update", "version", "and", "changelog", "for", "release"], "add_tokens": "VERSION = '3.1.2' end", "del_tokens": "VERSION = '3.1.1' end", "commit_type": "update"}
{"commit_tokens": ["updating", "revision", "number", "and", "history"], "add_tokens": "VERSION = '0.5.3' # :nodoc:", "del_tokens": "VERSION = '0.5.2' # :nodoc:", "commit_type": "update"}
{"commit_tokens": ["Add", "#inject", "convenience", "method", "to", "explicitly", "resolve", "dependencies", "on", "a", "Scorpion", "::", "Object"], "add_tokens": "scorpion . inject self", "del_tokens": "hunt = Scorpion :: Hunt . new scorpion , nil , nil hunt . inject self", "commit_type": "add"}
{"commit_tokens": ["Remove", "optional", "domain", "from", "Inspector", "."], "add_tokens": "def domain_links ( user_domain )", "del_tokens": "def domain_links ( user_domain = @page . host )", "commit_type": "remove"}
{"commit_tokens": ["Implement", "project", "-", "specific", "config"], "add_tokens": "CONFIG_FILE = \".xrayconfig\" def config_file if File . exists? ( \"#{Dir.pwd}/#{CONFIG_FILE}\" ) \"#{Dir.pwd}/#{CONFIG_FILE}\" else \"#{Dir.home}/#{CONFIG_FILE}\" end end File . open ( config_file , 'w' ) { | f | f . write ( config . to_yaml ) } YAML . load_file ( config_file )", "del_tokens": "CONFIG_FILE = \"#{Dir.home}/.xrayconfig\" File . open ( CONFIG_FILE , 'w' ) { | f | f . write ( config . to_yaml ) } YAML . load_file ( CONFIG_FILE )", "commit_type": "implement"}
{"commit_tokens": ["Update", "the", "semaphore", "example", "so", "it", "runs", "with", "dev", "-", "consul", "."], "add_tokens": ":: Dev :: Consul . run :: Dev :: Consul . wait # Get a new semaphore @semaphore = DaemonRunner :: Semaphore . lock ( @service , @lock_count ) # Spawn a thread to handle renewing the lock @renew_thread = @semaphore . renew # Do whatever kind of work you want puts 'Working...' sleep 1 # Kill the thread when you're done @renew_thread . kill # Explicitly release the semaphore when you're done @semaphore . release :: Dev :: Consul . stop", "del_tokens": "@semaphore = DaemonRunner :: Semaphore . start ( @service ) DaemonRunner :: Semaphore . lock ( @lock_count )", "commit_type": "update"}
{"commit_tokens": ["Changed", "CONTENT", "flag", "so", "that", "test", "content", "is", "not", "readonly", "."], "add_tokens": "TEXT_CONTENT = 8", "del_tokens": "TEXT_CONTENT = 5", "commit_type": "change"}
{"commit_tokens": ["Remove", "extraneous", "methods", "from", "ApiDocumentation", "."], "add_tokens": "delegate :docs_dir , :public_docs_dir , :private_index_extension , :public_index_extension , :to => :configuration", "del_tokens": "delegate :docs_dir , :public_docs_dir , :template_path , :template_extension , :private_index_extension , :public_index_extension , :example_extension , :to => :configuration", "commit_type": "remove"}
{"commit_tokens": ["Use", "remove_method", "instead", "of", "undef_method", "in", "redefine_method"], "add_tokens": "# Use remove_method instead of undef_method. The difference is minor, # but remove_method doesn't replace the method with a fake method. mod . __send__ ( :remove_method , name )", "del_tokens": "mod . __send__ ( :undef_method , name )", "commit_type": "use"}
{"commit_tokens": ["Moves", "the", "app", "/", "inside", "the", "lib", "/"], "add_tokens": "VERSION = '0.0.2'", "del_tokens": "VERSION = '0.0.1'", "commit_type": "move"}
{"commit_tokens": ["Fix", "intercept", "article", "body", "parsing"], "add_tokens": "story_body = html_doc . css ( 'div.PostContent div p, article div.ti-body p' ) . collect do | p | if date_span = html_doc . css ( 'span.PostByline-date' ) date_string = date_span . text . strip @date = DateTime . parse ( date_string ) rescue nil end return @date if @date", "del_tokens": "story_body = html_doc . css ( 'article div.ti-body p' ) . collect do | p |", "commit_type": "fix"}
{"commit_tokens": ["Make", "Rails", "4", "compatible", "and", "add", "localization"], "add_tokens": "options . delete ( :object ) if options [ :object ] input_tag = JqueryDatepick :: InstanceTag . new ( object_name , method , self , options ) html = if defined? ( ActionView :: Helpers :: InstanceTag ) && ActionView :: Helpers :: InstanceTag . instance_method ( :initialize ) . arity != 0 input_tag . to_input_field_tag ( \"text\" , tf_options ) else ActionView :: Helpers :: Tags :: TextField . new ( object_name , method , tf_options ) . render end html += javascript_tag ( \"jQuery(document).ready(function(){jQuery('##{input_tag.get_name_and_id[\"id\"]}').datepick($.extend(#{dp_options.to_json},$.datepick.regional['#{I18n.locale}']))});\" ) module JqueryDatepick_instance end if defined? ( ActionView :: Helpers :: InstanceTag ) && ActionView :: Helpers :: InstanceTag . instance_method ( :initialize ) . arity != 0 class JqueryDatepick :: InstanceTag < ActionView :: Helpers :: InstanceTag include JqueryDatepick_instance end else class JqueryDatepick :: InstanceTag < ActionView :: Helpers :: Tags :: Base include JqueryDatepick_instance end end", "del_tokens": "input_tag = JqueryDatepick :: InstanceTag . new ( object_name , method , self , options . delete ( :object ) ) html = input_tag . to_input_field_tag ( \"text\" , tf_options ) html += javascript_tag ( \"jQuery(document).ready(function(){jQuery('##{input_tag.get_name_and_id[\"id\"]}').datepick(#{dp_options.to_json})});\" ) class JqueryDatepick :: InstanceTag < ActionView :: Helpers :: InstanceTag end", "commit_type": "make"}
{"commit_tokens": ["move", "NULL", "queue", "checks", "into", "dequeue", "and", "peek"], "add_tokens": "puts ( cmd = \"env CC=gcc CXX=g++ CFLAGS='-fPIC #{$CFLAGS}' LDFLAGS='-fPIC #{$LDFLAGS}' ./configure --prefix=#{HERE} --without-cppunit --disable-dependency-tracking #{$EXTRA_CONF} 2>&1\" )", "del_tokens": "puts ( cmd = \"env CFLAGS='-fPIC #{$CFLAGS}' LDFLAGS='-fPIC #{$LDFLAGS}' ./configure --prefix=#{HERE} --without-cppunit --disable-dependency-tracking #{$EXTRA_CONF} 2>&1\" )", "commit_type": "move"}
{"commit_tokens": ["Fix", "spelling", "of", "visibility", "."], "add_tokens": "def toggle_visibility ( component_id , ** params , & block )", "del_tokens": "def toggle_visiblity ( component_id , ** params , & block )", "commit_type": "fix"}
{"commit_tokens": ["changed", "auto_rename", "to", "false", "per", "default", "it", "s", "broken"], "add_tokens": ":auto_rename => false end", "del_tokens": ":auto_rename => true end", "commit_type": "change"}
{"commit_tokens": ["Remove", "url", "encode", "monkey", "patch", "and", "move", "to", "Utils", "module", "instead"], "add_tokens": "# # * +:create_time+ data_string = OpenTok :: Utils . urlencode_hash ( data_params ) meta_string = OpenTok :: Utils . urlencode_hash ( :partner_id => @partner_id , :sig => sig )", "del_tokens": "# # * +:create_time+ data_string = data_params . urlencode meta_string = { :partner_id => @partner_id , :sig => sig } . urlencode", "commit_type": "remove"}
{"commit_tokens": ["Remove", "explicit", "GC", "from", "memory", "tests"], "add_tokens": "FEW = 10 MANY = 200 # No GC is explicitly done, because: # - large inputs forces it anyway # - it greatly slows tests # - GCing should not change the complexity of the system # GC.start", "del_tokens": "FEW = 1 MANY = 100 GC . start", "commit_type": "remove"}
{"commit_tokens": ["Updated", "to", "use", "spec", "/", "autorun", "so", "metric_fu", "will", "generate", "rcov", "reports"], "add_tokens": "require 'rubygems' require 'spec/autorun'", "del_tokens": "require 'rubygems' require 'spec'", "commit_type": "update"}
{"commit_tokens": ["Fix", "bad", "function", "blank?", ".", "This", "is", "not", "RoR!!!"], "add_tokens": "fail DoSnapshot :: NoTokenError , \"You must have #{key} in environment or set it via options.\" if ENV [ key ] . nil? || ENV [ key ] . empty?", "del_tokens": "fail DoSnapshot :: NoTokenError , \"You must have #{key} in environment or set it via options.\" if ENV [ key ] . blank?", "commit_type": "fix"}
{"commit_tokens": ["add", "cli", "that", "supports", "subscribers"], "add_tokens": "queue : controller . queue_resource_name def subscribe_to ( topic_name , queue_name : nil , queue_resource_name : nil , & block ) @queue_resource_name = queue_resource_name if queue_resource_name def queue_resource_name @queue_resource_name ||= Maitredee . queue_resource_name ( topic_name , queue_name ) end", "del_tokens": "queue : Maitredee . queue_resource_name ( controller . topic_name , controller . queue_name ) def subscribe_to ( topic_name , queue_name : nil , & block )", "commit_type": "add"}
{"commit_tokens": ["Fix", "model", "to", "string", "method"], "add_tokens": ":override , :override_str , :create_new , :taskrc def initialize rc = \"#{Dir.home}/.taskrc\" , override_h = DEFAULT_CONFIG override_h = override_h . merge ( { data_location : data_location } ) @override = Rtasklib :: Taskrc . new ( DEFAULT_CONFIG . merge ( override_h ) ) @override_str = override . model_to_s", "del_tokens": ":override , :create_new , :taskrc def initialize rc = \"#{Dir.home}/.taskrc\" , override = DEFAULT_CONFIG @override = Rtasklib :: Taskrc . new ( DEFAULT_CONFIG . merge ( override ) )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "constants", "in", "Finder", "for", "common", "found_by", "values"], "add_tokens": "found_by : DIRECT_FILE_ACCESS )", "del_tokens": "found_by : 'Direct File Access (aggressive detection)' )", "commit_type": "add"}
{"commit_tokens": ["Add", "probability", "calculations", "for", "roll", "N", "keep", "K"], "add_tokens": "@probabilities = @single_die . probabilities . repeat_sum ( @ndice )", "del_tokens": "@probabilities = GamesDice :: Probabilities . repeat_distribution ( @single_die . probabilities , @ndice )", "commit_type": "add"}
{"commit_tokens": ["Add", "response", "error", "handling", "."], "add_tokens": ":API => 'api' , :Client => 'client' , :Repos => 'repos' , :Request => 'request' , :Response => 'response' , :Error => 'error'", "del_tokens": ":API => 'api' , :Client => 'client' , :Repos => 'repos' , :Request => 'request' , :Response => 'response'", "commit_type": "add"}
{"commit_tokens": ["Add", "spec", "for", "creating", "account"], "add_tokens": "describe 'POST /budgets/{budget_id}/accounts' do it \"creates an account\" do VCR . use_cassette ( \"create_account\" ) do response = instance . create_account ( budget_id , { account : { name : 'New Checking Account' , type : 'checking' , balance : 215000 } } ) expect ( client . last_request . response . options [ :code ] ) . to be 201 expect ( response . data . account ) . to be expect ( response . data . account . balance ) . to eq 215000 end", "del_tokens": "it \"foobar\" do VCR . use_cassette ( \"accounts\" ) do client = YnabApi :: Client . new ( access_token , 'api.localhost:3000' , false ) response = client . accounts . get_accounts ( budget_id ) expect ( client . last_request . response . options [ :code ] ) . to be 200 expect ( response . data . accounts . length ) . to be 1", "commit_type": "add"}
{"commit_tokens": ["Update", "for", "2015", "-", "04", "-", "04"], "add_tokens": "request ( :get_service_resources , Array [ Softlayer :: Container :: Resource :: Metadata :: ServiceResource ] )", "del_tokens": "request ( :get_service_resources , Array [ Softlayer :: Network :: Service :: Resource ] )", "commit_type": "update"}
{"commit_tokens": ["Make", "redirect", "status", "code", "configurable"], "add_tokens": "opts = { :secure => true , :status_code => 301 } . merge ( opts ) @redirect_status_code = opts [ :status_code ]", "del_tokens": "opts = { :secure => true } . merge ( opts ) @redirect_status_code = 301", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "a", "new", "layout", "of", "BookmarkList"], "add_tokens": "node = at! ( '.column-label .count-badge' )", "del_tokens": "node = at! ( 'a[href=\"/bookmark.php?type=illust_all\"]' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "SharedMemory#write_object", "and", "#read_object", ";", "add", "SharedMemoryIO", "helper", "."], "add_tokens": "require 'process_shared/shared_memory_io' 0 ) . slice ( 0 , size ) # slice to get FFI::Pointer that knows its size # (and thus does bounds checking) # Write the serialization of +obj+ (using Marshal.dump) to this # shared memory object at +offset+ (in bytes). # # Raises IndexError if there is insufficient space. def put_object ( offset , obj ) io = SharedMemoryIO . new ( self ) io . seek ( offset ) Marshal . dump ( obj , io ) end # Read the serialized object at +offset+ (in bytes) using # Marshal.load. # # @return [Object] def get_object ( offset ) io = to_shm_io io . seek ( offset ) Marshal . load ( io ) end # Equivalent to {#put_object(0, obj)} def write_object ( obj ) Marshal . dump ( obj , to_shm_io ) end # Equivalent to {#read_object(0, obj)} # # @return [Object] def read_object Marshal . load ( to_shm_io ) end private def to_shm_io SharedMemoryIO . new ( self ) end", "del_tokens": "0 )", "commit_type": "add"}
{"commit_tokens": ["Use", "dedicated", "Window", "for", "drawing", "borders"], "add_tokens": "# bordered Window class SubWindow < Window def initialize ( * ) border_window = Curses . stdscr . subwin @win . maxy + 2 , @win . maxx + 2 , @win . begy - 1 , @win . begx - 1 border_window . box ?| , ?- , ?* end end class MainWindow < SubWindow @win = Curses . stdscr . subwin Curses . stdscr . maxy - 9 , Curses . stdscr . maxx - 2 , 8 , 1 super", "del_tokens": "@win . setpos 2 , 2 class MainWindow < Window @win = Curses . stdscr . subwin Curses . stdscr . maxy - 6 , Curses . stdscr . maxx , 6 , 0 @win . box ?| , ?- , ?*", "commit_type": "use"}
{"commit_tokens": ["Fixing", "CSV", "parsing", "errors", "."], "add_tokens": ". map { | line | CSV . parse ( line , quote_char : \"\\x00\" ) . first }", "del_tokens": ". map { | line | CSV . parse ( line ) . first }", "commit_type": "fix"}
{"commit_tokens": ["implemented", "classic", "simulator", "strategy", "in", "c"], "add_tokens": "# @return [Array<Messages>] messages = [ ] msg = Message . new ( value , port ) yield ( msg ) if ! value . nil? && block_given? messages << msg messages", "del_tokens": "# @return [void] yield ( Message . new ( value , port ) ) unless value . nil? nil", "commit_type": "implement"}
{"commit_tokens": ["make", "service", "path", "setters", "act", "like", "getters"], "add_tokens": "klass :: Mock . send ( :extend , Cistern :: Data ) def collection_path ( collection_path = nil ) if collection_path @collection_path = collection_path else @collection_path end def model_path ( model_path = nil ) if model_path @model_path = model_path else @model_path end def request_path ( request_path = nil ) if request_path @request_path = request_path else @request_path end", "del_tokens": "klass :: Mock . send ( :extend , Cistern :: Data ) def collection_path ( collection_path ) @collection_path = collection_path def model_path ( model_path ) @model_path = model_path def request_path ( request_path ) @request_path = request_path", "commit_type": "make"}
{"commit_tokens": ["fix", "default", "options", "merging", "into", "use", "options"], "add_tokens": "debug \"search: #{query} #{default_opts.merge(opts)}\" default_opts . merge ( opts )", "del_tokens": "debug \"search: #{query} #{opts.merge(default_opts)}\" opts . merge ( default_opts )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "the", "compulsory", ".", "configure", "call"], "add_tokens": "attr_writer :config def config @config ||= Config . new end", "del_tokens": "attr_accessor :config self . config ||= Config . new", "commit_type": "remove"}
{"commit_tokens": ["Adding", "to_s", "methods", "and", "removing", "dead", "code", "."], "add_tokens": "def to_s packages . keys . sort . map { | name | packages [ name ] . to_s } . join ( \"\\n\" )", "del_tokens": "# TODO [cw,2010/11/21]: See TODO in ObjectiveFunction def gecode_model_var_values packages . inject ( { } ) { | acc , elt | acc [ elt . first ] = elt . last . gecode_model_var . max ; acc } end def assignments_as_string_hash packages . inject ( { } ) do | acc , elt | densely_packed_version = elt . last . gecode_model_var . max acc [ elt . first ] = package ( elt . first ) . version_from_densely_packed_version ( densely_packed_version ) acc end", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "QUIT", "and", "PING"], "add_tokens": "require \"rufka/generic_commands\" require \"rufka/consumer\" require \"rufka/producer\"", "del_tokens": "require \"rufka/consumer\" require \"rufka/producer\"", "commit_type": "add"}
{"commit_tokens": ["implemented", "query", ".", "pk_only", "and", ".", "no_pk"], "add_tokens": "@opts = { } # # When set to true, only the primary keys of the matching records will # be returned. # def pk_only ( on = true ) @opts [ :pk_only ] = on end # # When set to true, the :pk (primary key) is not inserted in the record # (hashes) returned # def no_pk ( on = true ) @opts [ :no_pk ] = on end TableResultSet . new ( @table , lib . tctdbqrysearch ( @query ) , @opts ) def initialize ( table , list_pointer , query_opts ) @opts = query_opts if @opts [ :pk_only ] yield ( pk ) else val = @table [ pk ] val [ :pk ] = pk unless @opts [ :no_pk ] yield ( val ) end", "del_tokens": "TableResultSet . new ( @table , lib . tctdbqrysearch ( @query ) ) def initialize ( table , list_pointer ) yield @table [ pk ]", "commit_type": "implement"}
{"commit_tokens": ["improve", ":", "since", "no", "instance", "variable", "will", "be", "used", "in", "block", "instance_eval", "is", "better", "than", "instance_exec", "accoding", "to", "the", "semantic", "."], "add_tokens": "config . instance_eval ( & block )", "del_tokens": "config . instance_exec ( & block )", "commit_type": "improve"}
{"commit_tokens": ["Move", "SubclassAware", "out", "of", "Testify", "module"], "add_tokens": "module SubclassAware def self . extended ( klass ) #nodoc; klass . class_exec { class_variable_set ( :@@subclasses , Set . new ) } end # TODO: Find a way for self.inherited on the extended class not to blow # this away without requiring a bunch of alias chain hoops to be jumped # through. def inherited ( sub ) #nodoc; class_exec { class_variable_get ( :@@subclasses ) . add sub } end ## # Return an array of all known subclasses (and sub-subclasses, etc) of this # class. # def subclasses class_exec { class_variable_get ( :@@subclasses ) . to_a } end ## # Clear all info about known subclasses. Usefull for testing, but it is # unlikely you would use it for much else. # def forget_subclasses class_exec { class_variable_get ( :@@subclasses ) . clear }", "del_tokens": "module Testify module SubclassAware def self . extended ( klass ) #nodoc; klass . class_exec { class_variable_set ( :@@subclasses , Set . new ) } end # TODO: Find a way for self.inherited on the extended class not to blow # this away without requiring a bunch of alias chain hoops to be jumped # through. def inherited ( sub ) #nodoc; class_exec { class_variable_get ( :@@subclasses ) . add sub } end ## # Return an array of all known subclasses (and sub-subclasses, etc) of this # class. # def subclasses class_exec { class_variable_get ( :@@subclasses ) . to_a } end ## # Clear all info about known subclasses. Usefull for testing, but it is # unlikely you would use it for much else. # def forget_subclasses class_exec { class_variable_get ( :@@subclasses ) . clear } end", "commit_type": "move"}
{"commit_tokens": ["Make", "Connection", "act", "enough", "like", "Builder", "to", "pass", "a", "Connection", "in", "to", "the"], "add_tokens": "@builder = Builder . new @builder . build { block . call ( self ) } def use ( klass , * args , & block ) @builder . use ( klass , * args , & block ) end def request ( key , * args , & block ) @builder . request ( key , * args , & block ) end def response ( key , * args , & block ) @builder . response ( key , * args , & block ) end def adapter ( key , * args , & block ) @builder . adapter ( key , * args , & block ) end", "del_tokens": "@builder = Builder . create ( & block )", "commit_type": "make"}
{"commit_tokens": ["Add", "note", "about", "the", "possiblity", "of", "a", "circular", "dependency"], "add_tokens": "%{Couldn't resolve references (possible circular dependency): #{refs}.}", "del_tokens": "%{Couldn't resolve references: #{refs}.}", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "build", "a", "library", "with", "mock", "arduino", "headers"], "add_tokens": "hardware_dir = File . join ( osx_root , \"Java\" , \"hardware\" ) ret . gcc_cmd = [ File . join ( hardware_dir , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ] forced_avr = File . join ( force_install_location , \"hardware\" , \"tools\" , \"avr\" ) ret . gcc_cmd = [ Host . which ( \"avr-gcc\" ) ] ret . gcc_cmd = [ File . join ( forced_avr , \"bin\" , \"avr-gcc\" ) ] ret . gcc_cmd = [ Host . which ( \"avr-gcc\" ) ] ret . gcc_cmd = [ File . join ( forced_avr , \"bin\" , \"avr-gcc\" ) ]", "del_tokens": "ret . gcc_cmd = [ File . join ( osx_root , \"Java\" , \"hardware\" , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ] ret . gcc_cmd = Host . which ( \"avr-gcc\" ) ret . gcc_cmd = [ File . join ( force_install_location , \"hardware\" , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ] ret . gcc_cmd = Host . which ( \"avr-gcc\" ) ret . gcc_cmd = [ File . join ( force_install_location , \"hardware\" , \"tools\" , \"avr\" , \"bin\" , \"avr-gcc\" ) ]", "commit_type": "add"}
{"commit_tokens": ["moved", "mf", "chapter", "specifics", "to", "properties"], "add_tokens": "uri_str = @properties . build_page_uri ( uri , @manga , @chapter , num ) uri : @properties . page_image_src ( doc ) , name : @properties . page_image_name ( doc ) ,", "del_tokens": "uri_str = uri . sub ( / \\d + \\. html / , \"#{num}.html\" ) image = doc . css ( 'img' ) [ 0 ] uri : image [ :src ] , name : image [ :src ] . sub ( / .+ \\/ / , '' ) ,", "commit_type": "move"}
{"commit_tokens": ["Add", "serialization", "by", "example", "and", "update", "README"], "add_tokens": "when :serialized , :serialize then ( @example ) ? @example : Hash . default_mock klass_name = ( @example ) ? @example . class . to_s : \"Hash\" klass_name . constantize", "del_tokens": "when :serialized , :serialize then Hash . default_mock :: Hash", "commit_type": "add"}
{"commit_tokens": ["using", "Dir", ".", "tmpdir", "for", "test"], "add_tokens": "@dir1_dirname = File . join ( TEST_DIR , \"dir1\" ) @dir2_dirname = File . join ( TEST_DIR , \"dir2\" ) @tmp_output_dirname = Dir . tmpdir cat_expect = Cat . from_file ( expect_filename ) cat_result = Cat . from_file ( result_filename )", "del_tokens": "@dir1_dirname = File . join ( TEST_DIR , \"dir1\" ) @dir2_dirname = File . join ( TEST_DIR , \"dir2\" ) @tmp_output_dirname = File . join ( TEST_DIR , \"tmp\" ) cat_expect = Cat . from_file ( expect_filename ) cat_result = Cat . from_file ( result_filename )", "commit_type": "use"}
{"commit_tokens": ["Changed", "structure", "of", "AmberbitConfig", "module", "."], "add_tokens": "class HashStruct < :: OpenStruct def [] ( key ) self . send key unless key == nil end def self . create ( object ) Object . const_set 'AppConfig' , HashStruct . create ( config . data )", "del_tokens": "class HashStruct < OpenStruct def [] ( key ) self . send key unless key == nil end end class DeepHashStruct def create ( object ) # config = process_config(default_file) # if File.exist? config_file # config = process_config(config_file, config) # end Object . const_set 'AppConfig' , DeepHashStruct . create ( config . data )", "commit_type": "change"}
{"commit_tokens": ["Fix", "default", "path", "to", "be", "in", "spec", "folder"], "add_tokens": "File . join ( rootpath , 'spec' , '.validation' )", "del_tokens": "File . join ( rootpath , '.validation' )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "encode", "with", "force_encoding", "so", "it", "doesn", "t", "raise", "when", "conversion", "isn", "t", "possible"], "add_tokens": "reply = @sock . read ( bulklen ) . force_encoding ( \"UTF-8\" )", "del_tokens": "reply = @sock . read ( bulklen ) . encode ( \"UTF-8\" )", "commit_type": "change"}
{"commit_tokens": ["Added", "configuration_method", "stuff", "to", "enable", "more", "than", "just", "configurable", "attributes"], "add_tokens": "raise NothingToConfigure , \"You called configure but there are no configurable attributes\" if configuration_methods . empty? yield ConfigurationProxy . new ( self ) def configuration_methods self . class . configuration_methods end def has_configuration_method? ( method_name ) configuration_methods . include? ( method_name . to_sym ) end def configuration_methods @configuration_methods ||= [ ] end default_configuration [ attribute ] = blk || default configuration_method attribute configuration_method \"#{attribute}=\" def configuration_method ( method_name ) configuration_methods << method_name . to_sym end end class ConfigurationProxy def initialize ( owner ) @owner = owner end def method_missing ( method_name , * args , & block ) if owner . has_configuration_method? ( method_name ) owner . send ( method_name , * args , & block ) else raise BadConfigAttribute , \"You tried to configure using '#{method_name.inspect}', but the valid config attributes are #{owner.configuration_methods.map{|a| %('#{a.inspect}') }.sort.join(', ')}\" end end private attr_reader :owner", "del_tokens": "raise NothingToConfigure , \"You called configure but there are no configurable attributes\" if configuration_hash . empty? config_attributes = configuration_hash . keys struct_class = Struct . new ( * config_attributes ) struct = struct_class . new ( * configuration_hash . values ) begin yield ( struct ) rescue NoMethodError => e raise BadConfigAttribute , \"You tried to configure using '#{e.name}', but the valid config attributes are #{config_attributes.map{|a| %('#{a}') }.sort.join(', ')}\" end struct . each_pair { | k , v | configuration_hash [ k ] = v } default_configuration [ attribute ] = blk ? blk : default", "commit_type": "add"}
{"commit_tokens": ["Implementing", "static", "methods", "for", "get", "api", "version", "get", "public", "crises", "and", "get", "public", "rss", "feed", ".", "Using", "for", "the", "RSS", "feed", "the", "nokogiri", "library", "."], "add_tokens": "require \"nokogiri\" # This method returns current API version. For this purpose # the X-API-Version HTTP header is read out. # # @return [String] The first found version string of the API def self . get_api_version client = Sigimera :: Client . new response = client . head ( \"/public/crises\" ) response . get_fields ( \"X-API-Version\" ) . first . to_s if response . key? ( \"X-API-Version\" ) end # This method returns the latest 10 crises, but needs no # authentication token. # # @return [Array] Returns an array of crises objects in JSON def self . get_public_crises client = Sigimera :: Client . new response = client . get ( \"/public/crises\" ) JSON . parse response . body if response end # This method returns the latest 10 crises as RSS feed, # but needs no authentication token. # # @return [Nokogiri::XML::Document] Returns an a nokogiri xml document def self . get_public_rss_feed client = Sigimera :: Client . new response = client . get ( \"/public/crises.rss\" ) Nokogiri :: XML ( response . body ) if response end # @params [String] type The crises type, e.g. earthquake, flood, cyclone, volcanoe response = self . get ( endpoint )", "del_tokens": "response = get ( endpoint )", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "for", "prepared", "input"], "add_tokens": "# # with_args '--orm', 'active_record' do # it \"should use activerecord\" do # # . . . # end # end # # with_args '--size', 5, :object => true do # # . . . # end # # Sets the input stream for this generator. # # Ex: # # with_input <<-end_input do # y # n # a # end_input # it \"should overwrite, then skip, then overwrite all\" do # # . . . # end # end # def with_input ( string , & block ) if block_given? context \"with input string #{string.inspect}\" do with_input string instance_eval & block end else metadata [ :generator_input ] = string end end def generator_input return metadata [ :generator_input ] if metadata [ :generator_input ] metadata [ :generator_input ] = if genspec_subclass? superclass . generator_input else nil end end :args => generator_args , :input => generator_input", "del_tokens": "# :args => generator_args", "commit_type": "add"}
{"commit_tokens": ["Use", "types", "in", "agreement", "with", "the", "event", ".", "h", "of", "native", "operating", "systems", "."], "add_tokens": "if FFI :: Platform :: IS_FREEBSD layout ( :ident , :uintptr_t , :filter , :short , :flags , :u_short , :fflags , :u_int , :data , :intptr_t , :udata , :pointer ) elsif FFI :: Platform :: IS_NETBSD layout ( :ident , :uintptr_t , :filter , :uint32_t , :flags , :uint32_t , :fflags , :uint32_t , :data , :int64_t , :udata , :pointer ) elsif FFI :: Platform :: IS_OPENBSD layout ( :ident , :__uintptr_t , :filter , :short , :flags , :u_short , :fflags , :u_int , :data , :quad_t , :udata , :pointer ) else layout ( :ident , :uintptr_t , :filter , :int16 , :flags , :uint16 , :fflags , :uint32 , :data , :intptr_t , :udata , :pointer ) end", "del_tokens": "layout ( :ident , :uintptr_t , :filter , :int16 , :flags , :uint16 , :fflags , :uint32 , :data , :intptr_t , :udata , :pointer )", "commit_type": "use"}
{"commit_tokens": ["Use", "exceptional", "versions", "of", "#update_attributes"], "add_tokens": "update_attributes! ( :state => 'approved' ) update_attributes! ( :state => 'rejected' , :reason => reason )", "del_tokens": "update_attributes ( :state => 'approved' ) update_attributes ( :state => 'rejected' , :reason => reason )", "commit_type": "use"}
{"commit_tokens": ["Use", "Puppet", "::", "Resource", "::", "Catalog#resource"], "add_tokens": "resource = catalogue . resource ( @referenced_type , @title ) if resource . nil? unless resource . send ( :parameters ) [ name . to_sym ] . to_s == value . to_s", "del_tokens": "resources = catalogue . resources . select { | r | r . type == @referenced_type } . select { | r | r . title == @title if r . respond_to? :title } unless resources . length == 1 unless resources . first . send ( :parameters ) [ name . to_sym ] . to_s == value . to_s", "commit_type": "use"}
{"commit_tokens": ["Change", "transition", "to", "use", "states", "parser", "and", "add", "states", "map", "."], "add_tokens": "let ( :attrs ) { { name : :start , :foo => :bar , :baz => :daz } } expect ( transition . inspect ) . to eql ( \"<#FiniteMachine::Transition @name=start, @transitions=foo -> bar, baz -> daz, @when=[]>\" )", "del_tokens": "let ( :attrs ) { { name : :start , :foo => :bar } } expect ( transition . inspect ) . to eql ( \"<FiniteMachine::Transition name: start, transitions: [:foo] => bar, when: []>\" )", "commit_type": "change"}
{"commit_tokens": ["Added", "tests", "for", "timestamp", "and", "satisfied", "tests"], "add_tokens": "attr_reader :name , :success , :timestamp # Update timestamps on obj if a timestamp has been defined update_event_timestamp ( obj , next_state ) if timestamp_defined? # Has the timestamp option been specified for this event? def timestamp_defined? ! @timestamp . nil? end @success = options [ :success ] if options . key? ( :success ) self . timestamp = options [ :timestamp ] if options [ :timestamp ] # update the timestamp attribute on obj def update_event_timestamp ( obj , next_state ) obj . send \"#{timestamp_attribute_name(obj, next_state)}=\" , Time . now end # Set the timestamp attribute. # @raise [ArgumentError] timestamp should be either a String, Symbol or true def timestamp = ( value ) case value when String , Symbol , TrueClass @timestamp = value else raise ArgumentError , \"timestamp must be either: true, a String or a Symbol\" end end # Returns the name of the timestamp attribute for this event # If the timestamp was simply true it returns the default_timestamp_name # otherwise, returns the user-specified timestamp name def timestamp_attribute_name ( obj , next_state ) timestamp == true ? default_timestamp_name ( obj , next_state ) : @timestamp end # If @timestamp is true, try a default timestamp name def default_timestamp_name ( obj , next_state ) at_name = \"%s_at\" % next_state on_name = \"%s_on\" % next_state case when obj . respond_to? ( at_name ) then at_name when obj . respond_to? ( on_name ) then on_name else raise NoMethodError , \" Couldn't find a suitable timestamp field for event: #{ @name } . Please define #{at_name} or #{on_name} in #{obj.class}\" end end", "del_tokens": "attr_reader :name , :success @success = options [ :success ] if options . key? ( :success )", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "types", "methods"], "add_tokens": "[ 'IL' , 'il' , :il ] . each do | country | [ 'US' , 'us' , :us ] . each do | country | [ 'IL' , 'il' , :il ] . each do | country | [ 'US' , 'us' , :us ] . each do | country | context 'types' do setup { @phone = Phonelib . parse ( '972541234567' ) } should 'return :mobile type' do assert_equal :mobile , @phone . type end should 'return Mobile human type' do assert_equal 'Mobile' , @phone . human_type end should 'return [:mobile] as all types' do assert_equal [ :mobile ] , @phone . types end should 'return [Mobile] as all human types' do assert_equal %w( Mobile ) , @phone . human_types end end", "del_tokens": "[ 'IL' , :il ] . each do | country | [ 'US' , :us ] . each do | country | [ 'IL' , :il ] . each do | country | [ 'US' , :us ] . each do | country |", "commit_type": "add"}
{"commit_tokens": ["made", "the", "data", "markers", "slightly", "longer"], "add_tokens": "svg . line ( :x1 => x_coord , :y1 => 0 , :x2 => x_coord , :y2 => - 3 , :style => \"stroke:#{(options[:theme].marker || 'white').to_s}; stroke-width:1\" )", "del_tokens": "svg . line ( :x1 => x_coord , :y1 => 0 , :x2 => x_coord , :y2 => - 2 , :style => \"stroke:#{(options[:theme].marker || 'white').to_s}; stroke-width:1\" )", "commit_type": "make"}
{"commit_tokens": ["Fix", "operation", "view", "assignment", "text", "bug"], "add_tokens": "assignment_by_role , assignment_by_group", "del_tokens": "assignment_by_role , assignment_by_group , 'Not assigned' # TODO: fix with localization", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "tzdata", "version", "2006d", "."], "add_tokens": "add_period ( 1996 , 10 ) { TimezonePeriod . new ( 846266400 , 1145039400 , 21600 , 0 , :LKT ) } add_period ( 2006 , 4 ) { TimezonePeriod . new ( 1145039400 , nil , 19800 , 0 , :IST ) }", "del_tokens": "add_period ( 1996 , 10 ) { TimezonePeriod . new ( 846266400 , 1144951200 , 21600 , 0 , :LKT ) } add_period ( 2006 , 4 ) { TimezonePeriod . new ( 1144951200 , nil , 19800 , 0 , :IST ) }", "commit_type": "update"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "the", "none", "signing", "method", "was", "not", "set", "in", "the", "token", "header", "."], "add_tokens": "header [ 'alg' ] = signer . name", "del_tokens": "header [ 'alg' ] = signer . name if signer . name != Sandal :: Sig :: NONE . name", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "use", "rouge", "-", "style", "as", "alias", "for", "rouge", "-", "theme"], "add_tokens": "# 'rouge-style' is alternative name for compatibility with # asciidoctor-pdf (see #3). opts [ :inline_theme ] = document . attr ( 'rouge-theme' ) || document . attr ( 'rouge-style' ) || DEFAULT_THEME", "del_tokens": "opts [ :inline_theme ] = document . attr ( 'rouge-theme' , DEFAULT_THEME )", "commit_type": "allow"}
{"commit_tokens": ["add", ".", "test", "method", "to", "subscriber"], "add_tokens": "VERSION = \"0.8.4\"", "del_tokens": "VERSION = \"0.8.3\"", "commit_type": "add"}
{"commit_tokens": ["Adding", "basic", "support", "for", "addresses"], "add_tokens": "append = options . delete ( :append_to_endpoint ) append = append . nil? ? \"\" : \"/#{append}\" get ( \"/#{endpoint}/#{identifiers.join(',')}#{append}\" , options )", "del_tokens": "get ( \"/#{endpoint}/#{identifiers.join(',')}\" , options )", "commit_type": "add"}
{"commit_tokens": ["Add", "temporary", "skip", "for", "hanging", "test"], "add_tokens": "VERSION = '2.2.0' . freeze", "del_tokens": "VERSION = '2.1.1'", "commit_type": "add"}
{"commit_tokens": ["implement", "the", "top", "resources", "dropdown", "item", "links"], "add_tokens": "begin # global helpers def model_classes @model_classes ||= begin classes = Wallaby . configuration . model_finder . new . available_model_classes classes . map do | klass | Wallaby . configuration . model_decorator . new klass end end end helper_method :model_classes", "del_tokens": "begin # global callbacks", "commit_type": "implement"}
{"commit_tokens": ["Add", "conditional", "statements", "README", ".", "md", "and", "LICENSE"], "add_tokens": "r def to_regex self . start_with? ( ?/ ) && self . end_with? ( ?/ ) ? / #{ self [ 1 .. - 2 ] } / : self end", "del_tokens": "return r", "commit_type": "add"}
{"commit_tokens": ["add", "retry", "logic", "with", "exponential", "backoff", "for", "RestClient", "fetch", "()"], "add_tokens": "include Helpers retries = 0 max_retries = 5 sleep_time = 5 exp_backoff = 2 result = nil loop do begin resp = send_signed_request ( request [ 'method' ] , \"#{endpoint.strip}#{request['path']}\" , body ) result = JSON . parse ( resp . body ) message = \"status: #{resp.code}, message: #{result['message']}\" raise message unless resp . code == '200' break rescue Exception => e break if retries >= max_retries retries += 1 msg ( \"RequestFailed: #{e} - Waiting #{sleep_time}s then retrying... (#{retries} of #{max_retries})\" ) sleep sleep_time sleep_time *= exp_backoff # use an exponential backoff when retrying requests end end # if request has 'outfile' param, write response body to file to_file ( result , request [ 'outfile' ] ) if request [ 'outfile' ] # return response body obj result", "del_tokens": "resp = send_signed_request ( request [ 'method' ] , \"#{endpoint.strip}#{request['path']}\" , body ) # if request has 'outfile' param, write response to file to_file ( resp , request [ 'outfile' ] ) if request [ 'outfile' ] # return response obj resp JSON . parse ( response . body )", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "spec", "and", "update", "travis", "config"], "add_tokens": "let ( :result ) { rgeo_factory . linear_ring ( [ rgeo_point ( 0.0 , 0.0 ) , rgeo_point ( 2.0 , 1.0 ) , rgeo_point ( 3.0 , 2.0 ) , rgeo_point ( 0.0 , 0.0 ) ] ) }", "del_tokens": "let ( :result ) { rgeo_factory . linear_ring ( [ rgeo_point ( 0 , 0 ) , rgeo_point ( 2 , 1 ) , rgeo_point ( 3 , 2 ) , rgeo_point ( 0 , 0 ) ] ) }", "commit_type": "fix"}
{"commit_tokens": ["Added", "helper", "to", "PBXFileReference", "to", "get", "the", "absolute_path", "by", "traversing", "the", "tree", "upwards"], "add_tokens": "# Monkey-patch PBXFileReference by a helper to get class Xcodeproj :: Project :: Object :: PBXFileReference def absolute_path parents . map ( & :path ) . reverse . reduce { | p1 , p2 | File . join p1 || '' , p2 || '' } + path end end strings_file_paths = filter_exclusions strings_files . map & :absolute_path", "del_tokens": "strings_file_paths = filter_exclusions strings_files . map & :path", "commit_type": "add"}
{"commit_tokens": ["Added", "--", "port", "command", "line", "option"], "add_tokens": "def init ( options ) def build ( options ) def clear ( options ) def clean ( options ) def rebuild ( options ) def server ( options ) Amber :: Server . start ( :port => ( options [ :port ] || 8000 ) , :site => site )", "del_tokens": "def init def build def clear def clean def rebuild def server Amber :: Server . start ( :port => 8000 , :site => site )", "commit_type": "add"}
{"commit_tokens": ["update", "custom", "search", "and", "catch", "connection", "refused", "error"], "add_tokens": "# TODO: Find a way to get ideal results in the custom search ENDPOINT = \"http://hidemyass.com/proxy-list/search-750598\" . freeze Errno :: ECONNREFUSED ,", "del_tokens": "ENDPOINT = \"http://hidemyass.com/proxy-list/search-291666\" . freeze", "commit_type": "update"}
{"commit_tokens": ["added", "a", "space", "after", "tab", "to", "work", "with", "new", "uniform_tabs", "implementation"], "add_tokens": "\"#{a[:pattern].inspect}\\t #{list}\"", "del_tokens": "\"#{a[:pattern].inspect}\\t#{list}\"", "commit_type": "add"}
{"commit_tokens": ["added", "in", "spec", "coverage", "for", "the", "behaviour", "of", "the", "required", "option", "when", "the", "validation_reflection", "plugin", "is", "available"], "add_tokens": "if @object . class . method_defined? ( :reflect_on_all_validations )", "del_tokens": "if @object . class . respond_to? ( :reflect_on_all_validations )", "commit_type": "add"}
{"commit_tokens": ["Removed", "awesome", "print", "gem", "dependency", "."], "add_tokens": "@logger . error \"Error ocurred in mock service: #{e.class} - #{e.message}\" @logger . error e . backtrace . join ( \"\\n\" ) @logger . error \"Exception ocurred in mock service: #{e.class} - #{e.message}\" @logger . error e . backtrace . join ( \"\\n\" )", "del_tokens": "require 'awesome_print/core_ext/logger' #For some reason we get an error indicating that the method 'ap' is private unless we load this specifically @logger . error 'Error ocurred in mock service:' @logger . ap e , :error @logger . ap e . backtrace @logger . error 'Exception ocurred in mock service:' @logger . ap e , :error @logger . ap e . backtrace", "commit_type": "remove"}
{"commit_tokens": ["allow", "passing", "of", "load", "paths", "to", "compiler"], "add_tokens": "# @return [Hash] a hash of options to pass to Sass # when compiling. attr_reader :options @options = options parser = Less :: Parser . new :paths => Array ( options [ :additional_load_paths ] ) output . write parser . parse ( input . read ) . to_css", "del_tokens": "output . write Less :: Parser . new . parse ( input . read ) . to_css", "commit_type": "allow"}
{"commit_tokens": ["Fix", "issue", "on", "initial", "upload"], "add_tokens": "return unless logo_crop_x && avatar_tmp_file?", "del_tokens": "return unless avatar_tmp_file?", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "the", "newest", "qless", "-", "core", "."], "add_tokens": "@get . call ( [ ] , [ ] ) . each_slice ( 2 ) do | field , value | else return JSON . parse ( @get . call ( [ ] , [ option ] ) )", "del_tokens": "return JSON . parse ( @get . call ( [ ] , [ option ] ) ) else JSON . parse ( @get . call ( [ ] , [ ] ) ) . each_slice ( 2 ) do | field , value |", "commit_type": "update"}
{"commit_tokens": ["add", "nibbler", "/", "json", "as", "experimental", "JSON", "nibbler"], "add_tokens": "require 'nibbler/json' class Twitter < NibblerJSON elements :tweets , :with => NibblerJSON do element :created_at , :with => lambda { | time | Time . parse ( time ) } element 'user' => :author , :with => NibblerJSON do puts \"@%s: %s\" % [ tweet . author . username , tweet . created_at . inspect ]", "del_tokens": "require 'scraper' # a wrapper for JSON data that provides `at` and `search` class JsonDocument def initialize ( obj ) @data = String === obj ? JSON . parse ( obj ) : obj end def self . [] ( obj ) self . class === obj ? obj : new ( obj ) end def search ( selector ) @data . to_a end def at ( selector ) @data [ selector ] end end # a scraper that works with JsonDocument class JsonScraper < Scraper def self . convert_document ( doc ) JsonDocument [ doc ] end end class Twitter < JsonScraper elements :tweets , :with => JsonScraper do element :created_at element 'user' => :author , :with => JsonScraper do puts \"@%s: %s\" % [ tweet . author . username , tweet . text ]", "commit_type": "add"}
{"commit_tokens": ["update", "rubocop", "and", "apply", "recommendations"], "add_tokens": "# frozen_string_literal: true ARTIFACT_PREFIX = \"coverage\"", "del_tokens": "ARTIFACT_PREFIX = \"coverage\" . freeze", "commit_type": "update"}
{"commit_tokens": ["Use", "strict", "Base64", "encoding", "."], "add_tokens": "Base64 . strict_encode64 ( string )", "del_tokens": "# Remove the ending new line character added by default Base64 . encode64 ( string ) . strip", "commit_type": "use"}
{"commit_tokens": ["Add", "more", "complete", "error", "handling"], "add_tokens": "response_body = JSON . parse response . body response_body fail \"Failed with #{response.status_type} error from server. Received error: #{response_body['errors'][0]['message']}\"", "del_tokens": "JSON . parse response . body fail \"Failed with #{response.status_type} error from server. Received error #{response.status_code}.\"", "commit_type": "add"}
{"commit_tokens": ["Remove", "broken", "assert_validate!", "helper", "."], "add_tokens": "assert s . validate! ( doc )", "del_tokens": "assert_validate! s , doc", "commit_type": "remove"}
{"commit_tokens": ["Added", "source", ".", "rb", "class"], "add_tokens": "module Source", "del_tokens": "class Source attr_reader :items # Transform items in some way # Not sure how to do this def transform ( collection , & block ) end # Rename properties in each item def rename end # Permit or restrict items based on filter results def filter end # Re-sort items def sort end", "commit_type": "add"}
{"commit_tokens": ["Use", "attr_writer", "since", "we", "override", "the", "getter", "method", ".", "Eliminate", "warnings", "(", "yey", ")", "."], "add_tokens": "attr_writer :namespace attr_writer :following_key attr_writer :followers_key attr_writer :blocked_key attr_writer :reciprocated_key attr_writer :pending_key attr_writer :pending_follow attr_writer :page_size", "del_tokens": "attr_accessor :namespace attr_accessor :following_key attr_accessor :followers_key attr_accessor :blocked_key attr_accessor :reciprocated_key attr_accessor :pending_key attr_accessor :pending_follow attr_accessor :page_size", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "snapshot", "#size", ";", "start", "work", "on", "percentiles", "."], "add_tokens": "# This class does only read-only work and should be treated as immutable. # attr_reader :data , :size @size = @data . length end # @return [Float/Integer] median of the data set. def median # TODO end # Generate a percentile for the data set. # @example # snapshot.percentile(95) # snapshot.percentile(99.9) # def percentile ( perc ) if perc > 100.0 || perc < 0.0 raise InvalidPercentile , \"percentile must be between 0.0 and 100.0\" end class InvalidPercentile < StandardError ; end", "del_tokens": "attr_reader :data", "commit_type": "add"}
{"commit_tokens": ["add", "the", "vips", "-", "benchmark", "example"], "add_tokens": "# the convolution will break sequential access: we need to cache a few # scanlines", "del_tokens": "# the convolution will break sequential access: we need to cache a few # scanlines", "commit_type": "add"}
{"commit_tokens": ["Fixing", "for", "Update", "with", "RestClient"], "add_tokens": "RestClient . get ( url + url_params . join ( \"&\" ) ) . body", "del_tokens": "RestClient . get ( url + url_params . join ( \"&\" ) )", "commit_type": "fix"}
{"commit_tokens": ["added", "ability", "to", "chain", "calls", "on", "context"], "add_tokens": "class LookupOrMethodCall < Struct . new ( :receiver_expr , :expression ) if receiver = receiver_expr . evaluate ( context ) expression . split ( \".\" ) . inject ( receiver ) do | local , m | ( local [ m . to_sym ] || local [ m . to_s ] if local . respond_to? ( :[] ) ) || ( local . public_send ( m . to_sym ) if local . respond_to? ( m . to_sym ) ) end \"#{receiver_expr.name}.#{expression}\" LookupOrMethodCall . new ( Variable . new ( parts . shift ) , parts . join ( \".\" ) )", "del_tokens": "class LookupOrMethodCall < Struct . new ( :receiver_expr , :method ) receiver = receiver_expr . evaluate ( context ) case receiver when Hash ; receiver [ method ] else ; receiver . public_send method \"#{receiver_expr.name}.#{method}\" LookupOrMethodCall . new ( Variable . new ( parts . first ) , parts . last )", "commit_type": "add"}
{"commit_tokens": ["Implement", "the", "code", "portion", "of", "passing", "extras", "to", "the", "expose", "call", "."], "add_tokens": "context = lookup_error_context exception context . fetch :extras , { }", "del_tokens": "{ }", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "to", "sanitize", "wrapped", "rack", ".", "input"], "add_tokens": "env [ 'rack.input' ] = StringIO . new ( cleaned_value ) if cleaned_value", "del_tokens": "env [ 'rack.input' ] . reopen ( cleaned_value ) if cleaned_value", "commit_type": "add"}
{"commit_tokens": ["Adding", "comment", "for", "new", ":", "path", "option"], "add_tokens": "# (optional) a list of values in the doc fields to generate short cuts for (ie: [:scores, :id], you will be able to call <tt>rsp.scores</tt> and have it return an array of scores, likewise for <tt>ids</tt>.) Defaults to [:id, :unique_id, :score] # # [<b><tt>:path</tt></b>] # (optional) the path of the solr install (defaults to \"/solr\")", "del_tokens": "# (options) a list of values in the doc fields to generate short cuts for (ie: [:scores, :id], you will be able to call <tt>rsp.scores</tt> and have it return an array of scores, likewise for <tt>ids</tt>.) Defaults to [:id, :unique_id, :score]", "commit_type": "add"}
{"commit_tokens": ["Add", "proper", "tags", "to", "public", "interface", "specs"], "add_tokens": "it 'responds to :acts_as_token_authenticatable' , public : true do it 'ensures its instances have an authentication token before being saved' , public : true do it 'ensures its authentication token is unique' , public : true do", "del_tokens": "it 'responds to :acts_as_token_authenticatable' do it 'ensures its instances have an authentication token before being saved' do it 'ensures its authentication token is unique' do", "commit_type": "add"}
{"commit_tokens": ["Added", "create", "value", "for", "selectize", "input"], "add_tokens": "# Valore che indica il massimo se il create  attivo nel caso di input select # * *default*: nil attr_accessor :create multiple_files : false , birthdate : false , min : nil , max : nil , create : nil ) @select_class = create == true ? 'select-create' : 'select'", "del_tokens": "multiple_files : false , birthdate : false , min : nil , max : nil )", "commit_type": "add"}
{"commit_tokens": ["add", "(", "missing?", ")", "class", ":", "KeyError"], "add_tokens": "class KeyError < CompileError ; end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["remove", "name", "param", "from", "cert", "subject"], "add_tokens": "\"emailAddress=#{@email}\" ) end", "del_tokens": "\"name=#{@id}/emailAddress=#{@email}\" ) end", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "to", "run", "the", "mock", "service", "on", "SSL", ".", "Important", "for", "browser", "-", "based", "consumers", "."], "add_tokens": "require 'webrick/https' method_option :ssl , desc : \"Use a self-signed SSL cert to run the service over https\" cert_name = webbrick_opts = { :Port => options [ :port ] || FindAPort . available_port , :AccessLog => [ ] } webbrick_opts . merge! ( { :SSLEnable => true , :SSLCertName => [ %w[ CN localhost ] ] } ) if options [ :ssl ] puts options Rack :: Handler :: WEBrick . run ( mock_service , webbrick_opts )", "del_tokens": "port = options [ :port ] || FindAPort . available_port Rack :: Handler :: WEBrick . run ( mock_service , :Port => port , :AccessLog => [ ] )", "commit_type": "add"}
{"commit_tokens": ["using", "#send", "to", "overcome", "private", "#new", "method", "of", "the", "Net", "class"], "add_tokens": "self . class . send ( :new ) . tap do | net | self . class . send ( :new ) . tap do | net |", "del_tokens": "self . class . new . tap do | net | self . class . new . tap do | net |", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "stop", "detecting", "ruby", "version"], "add_tokens": "# frozen_string_literal: true if ENV [ 'COVERAGE' ] || ENV [ 'TRAVIS' ]", "del_tokens": "# encoding: utf-8 if RUBY_VERSION > '1.9' and ( ENV [ 'COVERAGE' ] || ENV [ 'TRAVIS' ] )", "commit_type": "change"}
{"commit_tokens": ["Move", "Country", "under", "Resources", "::", "Public"], "add_tokens": "%w[ fax_recipient fax account callback phax_code phone_number public ] . each do | filename |", "del_tokens": "%w[ fax_recipient country fax account callback phax_code phone_number public ] . each do | filename |", "commit_type": "move"}
{"commit_tokens": ["Adds", "bunny", "mock", "queue", "spec"], "add_tokens": "def initialize ( channel , name = '' , opts = { } ) # Store messages @messages = Array . new check_queue_deleted! check_queue_deleted! check_queue_deleted! # @option opts [String] :routing_key Routing key from binding def bound_to? ( exchange , opts = { } ) check_queue_deleted! def message_count @messages . shift end ## # Clear all messages in queue # # @api public # def purge @messages = [ ] ## # Deletes this queue # @api public def delete @deleted = true end def check_queue_deleted! raise 'Queue has been deleted' if @deleted", "del_tokens": "def initialize ( channel , name = AMQP :: Protocol :: EMPTY_STRING , opts = { } ) # @option opts [String] :routing_key Custom routing key def bound_to? ( exchange ) def count @messages . pop # Implementation def publish ( payload , props = { } ) @messages << { message : payload , properties : props }", "commit_type": "add"}
{"commit_tokens": ["Added", "timestamp", "at", "end", "of", "tests", "."], "add_tokens": "at_exit { puts Dir . pwd ( ) puts Time . now }", "del_tokens": "at_exit { puts Dir . pwd ( ) }", "commit_type": "add"}
{"commit_tokens": ["Use", "mime_type", "insted", "of", "content_type", "to", "check", "the", "mail", "type", "versions"], "add_tokens": "mail . mime_type == 'text/html' ? true : false mail . mime_type == 'text/plain' ? true : false", "del_tokens": "mail . content_type =~ %r{ \\b text/html \\b } ? true : false mail . content_type =~ %r{ \\b text/plain \\b } ? true : false", "commit_type": "use"}
{"commit_tokens": ["removed", "constraints", "on", "versions", "of", "gems"], "add_tokens": "# rather than load the ginormous activesupport library entirely, # pull in some individual objects and utility methods from activesupport # active_support 5 moved deep_dup, # so this trick is in place to support all activesupport versions begin # deep_dup is here in active_support 5 require 'active_support/core_ext/object/deep_dup' rescue LoadError # and here in active_support < 5 require 'active_support/core_ext/hash/deep_dup' end", "del_tokens": "require 'active_support/core_ext/hash/deep_dup'", "commit_type": "remove"}
{"commit_tokens": ["add", "additional", "net", "and", "connection", "errors", "to", "rescue"], "add_tokens": "Errno :: ECONNRESET , Errno :: EHOSTUNREACH , Timeout :: Error , EOFError , Net :: HTTPMethodNotAllowed , Zlib :: BufError , OpenSSL :: X509 :: CertificateError ]", "del_tokens": "Net :: HTTPMethodNotAllowed ]", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Math", "module", "/", "class", "issue"], "add_tokens": "module Math # :nodoc:", "del_tokens": "class Math # :nodoc:", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "to", "account", "for", "new", "functionality"], "add_tokens": "assert_raise_with_message ( ArgumentError , \"project_root and build_path cannot be the same\" ) { precompiler . build_path = @project_root } assert_raise_with_message ( ArgumentError , \"project_root and build_path cannot be the same\" ) { precompiler = MicroservicePrecompiler :: Builder . new ( \".\" , \"./\" ) } assert ( ( File . exists? \"#{@project_root}/dist/javascripts/sample.js\" ) , \"Compiled javascript not found, sprockets build failed\" ) assert ( ( File . size ( \"#{@project_root}/javascripts/sample.js.coffee\" ) < File . size ( \"#{@project_root}/dist/javascripts/sample.js\" ) ) , \"Javascripts were not minimized.\" )", "del_tokens": "#TODO", "commit_type": "add"}
{"commit_tokens": ["Added", "YAML", "as", "an", "output", "format"], "add_tokens": "# Output your items in a range of formats (:ruby, :json and :yaml currently) when :yaml return YAML . dump ( @items )", "del_tokens": "# Output your items in a range of formats (ruby and json currently)", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "where", "children", "are", "not", "cached", "correctly"], "add_tokens": "def children @cached_children || uncached_children end @cached_children . push ( * nodes ) has_many :uncached_children , :class_name => self . name , :foreign_key => :parent_id , :order => \"#{nested_set_column(:left)} asc\" protected :uncached_children , :uncached_children=", "del_tokens": "children . target = @cached_children . push ( * nodes ) has_many :children , :class_name => self . name , :foreign_key => :parent_id , :order => \"#{nested_set_column(:left)} asc\"", "commit_type": "fix"}
{"commit_tokens": ["adding", "logging", "for", "persisting", "value", "to", "DB"], "add_tokens": "def persist_role_changes! puts \"TroleGroups::Storage::BaseMany.persist_role_changes!\" if Troles :: Common :: Config . log_on? if ! rolegroup_subject . respond_to? :save puts \"could not save since no #save method on subject: #{rolegroup_subject}\" if Troles :: Common :: Config . log_on? return false else puts \"#{rolegroup_subject}.save\" if Troles :: Common :: Config . log_on? rolegroup_subject . save rolegroup_subject . publish_change :role_groups end", "del_tokens": "def persist_role_changes! return false if ! rolegroup_subject . respond_to? :save rolegroup_subject . save rolegroup_subject . publish_change :role_groups", "commit_type": "add"}
{"commit_tokens": ["add", "Folio", "::", "Ordinal", "::", "Page#out_of_bounds?"], "add_tokens": "raise :: Folio :: InvalidPage if page . out_of_bounds?", "del_tokens": "raise :: Folio :: InvalidPage if page . current_page < page . first_page raise :: Folio :: InvalidPage if page . last_page && page . current_page > page . last_page", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "property", "helper", "method", "for", "defining", "custom", "type", "conversions", "when", "serializing", "."], "add_tokens": "assert_equal Related :: Node . new . send ( :load_attributes , 'test' , { } ) , Related :: Node . new . send ( :load_attributes , 'test' , { } )", "del_tokens": "assert_equal Related :: Node . new ( 'test' , { } ) , Related :: Node . new ( 'test' , { } )", "commit_type": "add"}
{"commit_tokens": ["Move", "all", "platforms", "logic", "to", "Core", "."], "add_tokens": "options += Platform . all . map do | platform | [ \"--#{platform.name.to_s}\" , \"Restricts the search to Pods supported on #{Platform.string_name(platform.to_sym)}\" ] @platform_filters = Platform . all . map do | platform | argv . flag? ( platform . name . to_s ) ? platform . to_sym : nil", "del_tokens": "def self . all_platforms Specification :: PLATFORMS . map do | platform | platform . to_s end end def all_platforms self . class . all_platforms end options += all_platforms . map do | platform | [ \"--#{platform}\" , \"Restricts the search to Pods supported on #{platform}\" ] @platform_filters = all_platforms . map do | platform | argv . flag? ( platform ) ? platform . to_sym : nil", "commit_type": "move"}
{"commit_tokens": ["Adds", "a", ":", "create", "attribute", "for", "OptPath"], "add_tokens": "# :create if set to true, will create the path # %i[ create file directory executable readable writable ] # check_create is implemented in the file_path and directory_path opts", "del_tokens": "%i[ file directory executable readable writable ]", "commit_type": "add"}
{"commit_tokens": ["use", "assert_kind_of", "instead", "of", "is_a?"], "add_tokens": "assert_kind_of MachO :: MachOFile , file assert_kind_of MachO :: FatFile , file", "del_tokens": "assert file . is_a? MachO :: MachOFile assert file . is_a? MachO :: FatFile", "commit_type": "use"}
{"commit_tokens": ["upgraded", "celluloid", "-", "websocket", "-", "client"], "add_tokens": "@client = CelluloidPubsub :: Client . new ( { actor : Actor . current , channel : 'test_channel' } . merge ( options ) ) @client = CelluloidPubsub :: Client . new ( { actor : Actor . current , channel : 'test_channel2' } . merge ( options ) )", "del_tokens": "@client = CelluloidPubsub :: Client . connect ( { actor : Actor . current , channel : 'test_channel' } . merge ( options ) ) @client = CelluloidPubsub :: Client . connect ( { actor : Actor . current , channel : 'test_channel2' } . merge ( options ) )", "commit_type": "upgrade"}
{"commit_tokens": ["Allow", "escaping", "more", "than", "one", "string"], "add_tokens": "PGconn . quote_ident ( * args . map ( & :to_s ) )", "del_tokens": "PGconn . quote_ident ( * args )", "commit_type": "allow"}
{"commit_tokens": ["Add", "constraints", "and", "fully", "working", "example"], "add_tokens": "model . add_var 0 , 1 , 1 , GRB_BINARY , 'x' model . add_var 0 , 1 , 1 , GRB_BINARY , 'y' model . add_var 0 , 1 , 2 , GRB_BINARY , 'z' model . update model . add_constraint [ 0 , 1 , 2 ] , [ 1 , 2 , 3 ] , GRB_LESS_EQUAL , 4.0 , 'c0' model . add_constraint [ 0 , 1 ] , [ 1 , 1 ] , GRB_GREATER_EQUAL , 1.0 , 'c1' model . update model . write '/tmp/test.lp' model . optimize", "del_tokens": "model . add_var 0 , 1 , 0 , GRB_INTEGER , 'var' model . update", "commit_type": "add"}
{"commit_tokens": ["Fix", "caching", "issues", "with", "ssh", "keys"], "add_tokens": "# Dockerfile ADD compares content and mtime, we don't want that File . utime ( 1_286_701_800 , 1_286_701_800 , destination )", "del_tokens": "create_tmp_file SSH_CONFIG_FILE , File . read ( SSH_CONFIG_PATH )", "commit_type": "fix"}
{"commit_tokens": ["added", "vwap", "field", "to", "ticker"], "add_tokens": "attr_accessor :buy , :sell , :high , :low , :volume , :vwap", "del_tokens": "attr_accessor :buy , :sell , :high , :low , :volume", "commit_type": "add"}
{"commit_tokens": ["added", "docs", "a", "little", "more", "english", "added", "tests", "so", "we", "reach", "the", "100%", "test", "coverage", ":", "-", ")"], "add_tokens": "@text = text ? convert_text ( text ) : text raise \"Gimme a value as a String or Numeric. You gave me a #{value.class}\" raise \"A booking of 0.00  makes no sence\" @value = value @pos = true @value = - value @pos = false", "del_tokens": "@text = text ? convert_text ( text ) : text raise \"bergabefehler: Betrag ist kein String/Numeric\" raise \"Booking Value is 0\" @value = value @pos = true @value = - value @pos = false", "commit_type": "add"}
{"commit_tokens": ["Using", "create", "methods", "from", "Node", "mixin"], "add_tokens": "include GoogleApps :: Atom :: Node @document . root << create_node ( type : 'apps:property' , attrs : [ [ 'name' , 'memberId' ] , [ 'value' , member ] ] )", "del_tokens": "@document . root << build_node ( member ) # build_node creates an apps:property element # for memberId with the provided argument as # the value. # # build_node 'test_user@cnm.edu' # # build_node returns an apps:property XML Node. def build_node ( member ) node = Atom :: XML :: Node . new ( 'apps:property' ) node . attributes [ 'name' ] = 'memberId' node . attributes [ 'value' ] = member node end", "commit_type": "use"}
{"commit_tokens": ["update", "support", "to", "new", "jwt", "gem", "version"], "add_tokens": "JWT . encode ( payload , Rails . application . secrets . secret_key_base , 'HS256' ) body = JWT . decode ( token , Rails . application . secrets . secret_key_base , true , algorithm : 'HS256' ) [ 0 ] end", "del_tokens": "return JWT . encode ( payload , Rails . application . secrets . secret_key_base ) body = JWT . decode ( token , Rails . application . secrets . secret_key_base ) [ 0 ] end", "commit_type": "update"}
{"commit_tokens": ["added", "processing", "of", "remote", "errors"], "add_tokens": "# TODO: spec the ActiveRecord behaviour # - processing of remote errors # - response parsing (using data: [] format) # - save methods if perform_validations ( options ) ret = super ( ) process_response_errors ret else false end if perform_validations ( options ) ret = super ( ) process_response_errors raise_record_invalid else false end end # Emulate ActiveRecord for Her def reload ( options = nil ) @attributes . update ( self . class . find ( self . id ) ) . instance_variable_get ( '@attributes' ) ) # Process errors from the servers and add them to the # model # Servers are returned using the jsonapi format # E.g.: # errors: [ # { # :id=>\"f720ca10-b104-0132-dbc0-600308937d74\", # :href=>\"http://maestrano.github.io/enterprise/#users-users-list-post\", # :status=>\"400\", # :code=>\"name-can-t-be-blank\", # :title=>\"Name can't be blank\", # :detail=>\"Name can't be blank\" # } # ] def process_response_errors if self . response_errors && self . response_errors . any? self . response_errors . each do | error | self . errors [ :base ] << error [ :title ] end end end", "del_tokens": "perform_validations ( options ) ? super ( ) : false perform_validations ( options ) ? super ( ) : raise_record_invalid", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "few", "more", "ruby", "functions", "."], "add_tokens": "member? : [ Array , [ Fixnum , String ] ] , compact : [ Array ] , split : [ String , String ] , raise \"bad arg #{i} to method #{method}: #{args[i]}/#{args[i].class}\" unless ok", "del_tokens": "raise \"bad argument #{args[i]} at position #{i} to method #{method}\" unless ok", "commit_type": "add"}
{"commit_tokens": ["adding", "a", "spec", "for", "forwarding", "to", "a", "partial", "application"], "add_tokens": "values . keys . each do | k | attr_accessor k end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "compare_by_identity", "for", "hashes", "with", "Fixnum", "keys"], "add_tokens": "@location_cache = Hash . new ( { } . compare_by_identity )", "del_tokens": "@location_cache = Hash . new ( { } )", "commit_type": "use"}
{"commit_tokens": ["remove", "white", "space", "at", "the", "end", "of", "comment", "if", "any"], "add_tokens": "string << \"#{COMMENTS_LABELS[@type]} #{str}\\n\" . gsub ( / [^ \\S \\n ]+$ / , '' ) # removes the space but not newline at the end \"#{COMMENTS_LABELS[@type]} #{@str}\\n\" . gsub ( / [^ \\S \\n ]+$ / , '' )", "del_tokens": "string << \"#{COMMENTS_LABELS[@type]} #{str}\\n\" \"#{COMMENTS_LABELS[@type]} #{@str}\\n\"", "commit_type": "remove"}
{"commit_tokens": ["Use", ".", "empty?", "instead", "==", "[]"], "add_tokens": "( access_token . scopes - scope . split ( \" \" ) . map ( & :to_sym ) ) . empty?", "del_tokens": "access_token . scopes - scope . split ( \" \" ) . map ( & :to_sym ) == [ ]", "commit_type": "use"}
{"commit_tokens": ["Made", "if", "statement", "more", "readable"], "add_tokens": "else # otherwise use fallback CDN img_src = \"https://github.global.ssl.fastly.net/images/icons/emoji/#{name}.png\"", "del_tokens": "img_src = \"https://github.global.ssl.fastly.net/images/icons/emoji/#{name}.png\"", "commit_type": "make"}
{"commit_tokens": ["upgraded", "version", "preparing", "for", "release"], "add_tokens": "VERSION = \"1.6.0\"", "del_tokens": "VERSION = \"1.5.0\"", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "where", "the", "default", "setup_foreign_grammar", "method", "lives"], "add_tokens": "# Must be outside the STANDALONE block because a standalone # parser always injects it's own version of this method. def setup_foreign_grammar end", "del_tokens": "def setup_foreign_grammar end", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "flay", "run", "to", "the", "source", "quality", "tests"], "add_tokens": "def self . smelly_calls ( method ) # :nodoc: method . calls . select { | key , val | val > 1 and key [ 2 ] != :new } . map { | call_exp | call_exp [ 0 ] } end smelly_calls ( method ) . each do | call | report << new ( method , call ) smell_found = true", "del_tokens": "method . calls . select { | key , val | val > 1 } . each do | call_exp | call = call_exp [ 0 ] unless call [ 2 ] == :new report << new ( method , call ) smell_found = true end", "commit_type": "add"}
{"commit_tokens": ["Added", "indices", "to", "database", "for", "faster", "queries"], "add_tokens": "# to the same request. It will also create an index in the request_id field to speed up queries. ActiveRecord :: Migration . add_index ( \"#{name}_lines\" , [ :request_id ] )", "del_tokens": "# to the same request.", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Natto", "::", "DictionaryInfo#method_missing", "to", "provide", "accesors", "to", "members", "."], "add_tokens": ":next , :pointer # Provide accessor methods for the members of the <tt>DictionaryInfo</tt> # structure. # # Note that since <tt>Object#type</tt> is deprecated, <tt>dictype</tt> is used # instead. # @param [String] methName # @return member values for the <tt>mecab</tt> dictionary def method_missing ( methName ) member_sym = methName . id2name . to_sym if member_sym == :dictype return self [ :type ] else return self [ member_sym ] if self . members . include? ( member_sym ) end end", "del_tokens": ":next , :pointer", "commit_type": "implement"}
{"commit_tokens": ["Make", "implementation", "more", "modular", "."], "add_tokens": "set_flash_message! if set_flash_message? end protected def set_flash_message! if has_errors? controller . flash [ :alert ] ||= @alert if @alert status = Responders :: FlashResponder . flash_keys . last else controller . flash [ :notice ] ||= @notice if @notice status = Responders :: FlashResponder . flash_keys . first return if controller . flash [ status ] . present? options = mount_i18n_options ( status ) message = :: I18n . t options [ :default ] . shift , options controller . flash [ status ] = message unless message . blank? end def set_flash_message? #:nodoc:", "del_tokens": "if set_i18n_flash? if has_errors? controller . flash [ :alert ] ||= @alert if @alert status = Responders :: FlashResponder . flash_keys . last else controller . flash [ :notice ] ||= @notice if @notice status = Responders :: FlashResponder . flash_keys . first end return if controller . flash [ status ] . present? options = mount_i18n_options ( status ) message = :: I18n . t options [ :default ] . shift , options controller . flash [ status ] = message unless message . blank? end protected def set_i18n_flash? #:nodoc:", "commit_type": "make"}
{"commit_tokens": ["changed", "the", "view", "that", "is", "rendered", "after", "file", "upload", "and", "default", "view"], "add_tokens": "apply_depositor_metadata ( generic_file )", "del_tokens": "def process_files @file_assets = create_and_save_file_assets_from_params notice = [ ] @file_assets . each do | file_asset | apply_depositor_metadata ( file_asset ) notice << render_to_string ( :partial => 'file_assets/asset_saved_flash' , :locals => { :file_asset => file_asset } ) if ! params [ :container_id ] . nil? associate_file_asset_with_container ( file_asset , 'info:fedora/' + params [ :container_id ] ) end ## Apply any posted file metadata unless params [ :asset ] . nil? logger . debug ( \"applying submitted file metadata: #{@sanitized_params.inspect}\" ) apply_file_metadata end # If redirect_params has not been set, use {:action=>:index} logger . debug \"Created #{file_asset.pid}.\" end notice end", "commit_type": "change"}
{"commit_tokens": ["Updated", "version", "and", "gem", "dependencies"], "add_tokens": "gem 'dm-core' , '~>0.9.9'", "del_tokens": "gem 'dm-core' , '~>0.9.8'", "commit_type": "update"}
{"commit_tokens": ["Add", "functionality", "for", "Percolate", "::", "Adapter", "::", "BaseAdapter"], "add_tokens": "# @param block [Proc] the configuration block. def self . create ( adapter_name , & block ) percolator = Percolator . new ( Adapter . const_get ( const_str ) . new ) percolator . load ( & block ) percolator attr_reader :adapter , :entities # Configures and loads the underlying adapter's entities. # # @param block [Proc] the configuration block. def load ( & block ) @adapter . instance_eval ( & block ) if ! block . nil? @entities = @adapter . load_entities nil end", "del_tokens": "def self . create ( adapter_name ) Percolator . new ( Adapter . const_get ( const_str ) . new ) attr_reader :adapter", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "we", "create", "@encoding", "before", "setting", "encoding"], "add_tokens": "self . charset_name = opts [ :encoding ] || 'utf8'", "del_tokens": "self . charset_name = opts [ :encoding ] || 'utf8'", "commit_type": "make"}
{"commit_tokens": ["Add", "string", "cron", "expression", "interval", "support"], "add_tokens": "parts , interval = split_parts_and_interval ( expression_str ) ! value . nil? expression_parts . merge! ( :interval => interval ) unless interval . nil? ## # Split a cron string and extract the LAST interval that appears # def split_parts_and_interval ( expression_str ) interval = nil parts = expression_str . split ( / + / ) . map do | part | part , part_interval = part . split ( '/' ) interval = part_interval unless part_interval . blank? next nil if part . blank? || part == '*' part end [ parts , interval ] end", "del_tokens": "parts = expression_str . split ( / + / ) next false if value . nil? next false if value == '*' true", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "fix", "binary?", "on", "windows"], "add_tokens": "bytes = :: File . new ( relative_path ) . size", "del_tokens": "bytes = :: File . stat ( relative_path ) . blksize", "commit_type": "change"}
{"commit_tokens": ["Add", "email", "information", "to", "user", "entity", "object"], "add_tokens": ":default_currency , :name , :avatar , :default_avatar , :email , :emails", "del_tokens": ":default_currency , :name , :avatar , :default_avatar", "commit_type": "add"}
{"commit_tokens": ["Updating", "changelog", "and", "bumping", "version", "."], "add_tokens": "VERSION = '0.3.2'", "del_tokens": "VERSION = '0.3.1'", "commit_type": "update"}
{"commit_tokens": ["Add", "more", "documentation", "to", "the", "command", "class", "."], "add_tokens": "# This is used under the hood within an Application's DSL run or block: # ==  Application Build Block", "del_tokens": "# This is used under the hood within an Application's DSL block: # ==  Application Run Block", "commit_type": "add"}
{"commit_tokens": ["removing", "all", "traces", "of", "RAILS_ENV"], "add_tokens": "VERSION = \"0.3.1\" package_env = ! defined? ( Rails ) || ! Rails . env . development? Jammit . load_configuration ( Jammit :: DEFAULT_CONFIG_PATH ) if defined? ( Rails ) if defined? ( Rails )", "del_tokens": "VERSION = \"0.3.0\" package_env = ! defined? ( RAILS_ENV ) || RAILS_ENV != 'development' Jammit . load_configuration ( Jammit :: DEFAULT_CONFIG_PATH ) if defined? ( RAILS_ENV ) if defined? ( RAILS_ENV )", "commit_type": "remove"}
{"commit_tokens": ["Add", "config", "file", "loader", "for", "the", "gem", "."], "add_tokens": "require \"sapience/config_loader\"", "del_tokens": "require \"sapience/configuration/rails\"", "commit_type": "add"}
{"commit_tokens": ["Moved", "rails_context", "to", "be", "defined", "on", "Object"], "add_tokens": "def rails_context ( description , context_class = Riot :: Context , & definition ) Object . instance_eval { include RiotRails :: TopLevel }", "del_tokens": "def rails_context ( description , context_class = Context , & definition ) Riot . extend ( RiotRails :: TopLevel )", "commit_type": "move"}
{"commit_tokens": ["Add", "example", "for", "using", "associations"], "add_tokens": "ACCOUNT_ID = '4e1e9c234250712eba000052' # your account id APPLICATION_API_KEY = 'fgK8Di4FYuRKtk2Xd12A' # your application's API key with read/write access StorageRoom . server = \"api.lvh.me:3000\" # StorageRoom.server = \"api.storageroomapp.com\"", "del_tokens": "ACCOUNT_ID = '4dda7761b65245fde1000051' # your account id APPLICATION_API_KEY = 'kCWTmS1wxYnxzJyteuIn' # your application's API key with read/write access StorageRoom . server = \"api.lvh.me:3000\"", "commit_type": "add"}
{"commit_tokens": ["change", "inspect", "str", "fix", "doc"], "add_tokens": "# Exponentiation. self . class . to_s + \"[\" + Unit :: Utils . num_inspect ( @value ) + expr + \"] \" + @unit . inspect", "del_tokens": "# Power of a quantity. \"#<\" + self . class . to_s + \" \" + Unit :: Utils . num_inspect ( @value ) + expr + \", \" + @unit . inspect + \">\"", "commit_type": "change"}
{"commit_tokens": ["Added", "tracking", "of", "more", "information", "about", "browsers", "for", "Mobile", "/", "Tablet", "and", "Desktops", "."], "add_tokens": "'ratio_country' , ' ratio_referrers ', ' unqiue_mobile_browser_info ' , 'unqiue_desktop_browser_info' , 'total_mobile_browser_info' , 'total_desktop_browser_info' ]", "del_tokens": "'ratio_country' , 'ratio_referrers' ]", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "GC", ".", "start", "call", "."], "add_tokens": "# * +:disable_gc+ - disables garbage collection for the duration of the # block and then renables it immediately afterwards. This allows you to # control when GC is run and see the results. # * +:title+ - a title to use for logging.", "del_tokens": "GC . start # * :disable_gc - disables garbage collection for the duration of the # block and then renables it immediately afterwards and runs GC.start. # This ensures that GC is run at least once for the block so that you # can see what the block itself is doing. If you want to leave GC # running on its own without any interference, set this value to false. # The default value is false. # * :title - a title to use for logging.", "commit_type": "remove"}
{"commit_tokens": ["Improving", "the", "handling", "of", "partially", "successful", "subscriber", "imports", "."], "add_tokens": "extra = self . data . ResultData ? \"\\nExtra result data: #{self.data.ResultData}\" : \"\" super \"The CreateSend API responded with the following error - #{@data.Code}: #{@data.Message}#{extra}\"", "del_tokens": "super \"The CreateSend API responded with the following error - #{@data.Code}: #{@data.Message}\"", "commit_type": "improve"}
{"commit_tokens": ["Use", "app", "-", "transfer", "JSON", "from", "schema", ".", "json"], "add_tokens": "before do data = MultiJson . decode ( File . read ( \"./test/schema.json\" ) ) @link_schema = data [ \"definitions\" ] [ \"app-transfer\" ] [ \"links\" ] [ 0 ] end Rack :: Committee :: ParamValidator . new ( params , @link_schema ) . call Rack :: Committee :: ParamValidator . new ( { } , @link_schema ) . call Rack :: Committee :: ParamValidator . new ( params , @link_schema ) . call", "del_tokens": "Rack :: Committee :: ParamValidator . new ( params , link_schema ) . call Rack :: Committee :: ParamValidator . new ( { } , link_schema ) . call Rack :: Committee :: ParamValidator . new ( params , link_schema ) . call def link_schema { \"description\" => \"Create a new app transfer.\" , \"href\" => \"/account/app-transfers\" , \"method\" => \"POST\" , \"rel\" => \"create\" , \"schema\" => { \"properties\" => { \"app\" => { \" $ref \" => \" / schema / app #/definitions/identity\" }, \"recipient\" => { \" $ref \" => \" / schema / account #/definitions/identity\" } } , \"required\" => [ \"app\" , \"recipient\" ] } , \"title\" => \"Create\" } end", "commit_type": "use"}
{"commit_tokens": ["Allow", "arbitrary", "tags", "to", "be", "attached", "to", "a", "changeset", "."], "add_tokens": "def find_or_create_open_changeset ( id , comment = nil , tags = { } ) find_open_changeset ( id ) || create_changeset ( comment , tags ) def create_changeset ( comment = nil , tags = { } ) tags . merge! ( :comment => comment ) { | key , v1 , v2 | v1 } changeset = Changeset . new ( :tags => tags )", "del_tokens": "def find_or_create_open_changeset ( id , comment = nil ) find_open_changeset ( id ) || create_changeset ( comment ) def create_changeset ( comment = nil ) changeset = Changeset . new ( :tags => { :comment => comment } )", "commit_type": "allow"}
{"commit_tokens": ["added", "json", "parser", ".", "Moved", "more", "test", "configuration", "into", "muck", "engine"], "add_tokens": "require 'rspec/core' require 'rspec/mocks' require 'rspec/expectations' require 'rspec/rails' # Requires supporting ruby files with custom matchers and macros, etc, # in spec/support/ and its subdirectories. Dir [ Rails . root . join ( \"spec/support/**/*.rb\" ) ] . each { | f | require f } config . mock_with :rspec config . color_enabled = true config . include ( RSpec :: Mocks :: Methods ) config . fixture_path = \"#{::Rails.root}/spec/fixtures\" config . use_transactional_fixtures = true end", "del_tokens": "# require File.join(File.dirname(__FILE__), 'test', 'shoulda_macros', 'controller.rb') # require File.join(File.dirname(__FILE__), 'test', 'shoulda_macros', 'forms.rb') # require File.join(File.dirname(__FILE__), 'test', 'shoulda_macros', 'models.rb') # require File.join(File.dirname(__FILE__), 'test', 'shoulda_macros', 'pagination.rb') # require File.join(File.dirname(__FILE__), 'test', 'shoulda_macros', 'plugins.rb') # require File.join(File.dirname(__FILE__), 'test', 'shoulda_macros', 'scopes.rb') end", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "use", "bundler", "/", "rspec", "."], "add_tokens": "require 'byebug'", "del_tokens": "require 'ruby-debug'", "commit_type": "update"}
{"commit_tokens": ["Change", "shoulda", "macros", "implementation", "to", "follow", "the", "shoulda", "documentation"], "add_tokens": "class Test :: Unit :: TestCase def self . should_be_authentic klass = model_class should \"acts as authentic\" do assert klass . respond_to? ( :acts_as_authentic_config ) end end", "del_tokens": "require \"test/unit\" def should_be_authentic klass = model_class should \"acts as authentic\" do assert klass . respond_to? ( :acts_as_authentic_config ) end Test :: Unit :: TestCase . extend Authlogic :: ShouldaMacros", "commit_type": "change"}
{"commit_tokens": ["Allow", "choosing", "HTTP", "over", "WebSockets", "when", "loading", "the", "dispatcher", "."], "add_tokens": "VERSION = \"0.1.5\"", "del_tokens": "VERSION = \"0.1.4\"", "commit_type": "allow"}
{"commit_tokens": ["change", "single", "quote", "to", "double", "quotes", "where", "necessary"], "add_tokens": "[ 'game' , 'platform' , 'company' , 'character' , 'franchise' , 'concept' , 'object' , 'location' , 'person' , 'video' ] . each do | inc |", "del_tokens": "[ 'game' , 'company' , 'character' , 'franchise' , 'concept' , 'object' , 'location' , 'person' , 'video' ] . each do | inc |", "commit_type": "change"}
{"commit_tokens": ["Removed", "<caption", ">", "to", "have", "the", "text", "be", "between", "thead", "and", "tbody", "instead", "."], "add_tokens": "disclaimer = '<tr class=\"selected-count\" style=\"display: none;\"><th colspan=\"1000\">\\'+ \"list.selected\".t + \\'</th></tr>' code << '</tr>' code << \"</thead>'\"", "del_tokens": "disclaimer = '<caption>\\'+ \"list.selected\".t + \\'</caption>' code << '</tr></thead>' code << \"'\"", "commit_type": "remove"}
{"commit_tokens": ["Add", "cache", "handler", "(", "does", "nothing", "for", "now", ")"], "add_tokens": "ret = cache . call ( request ) { | request | adapter . call ( request ) } ret . then do | response | def cache options [ :cache ] || Restify . cache end", "del_tokens": "adapter . call ( request ) . then do | response |", "commit_type": "add"}
{"commit_tokens": ["fixed", "crash", "in", "reply_with_mentions", "where", "it", "tried", "to", "run", "no_bot?", "on", "a", "mention"], "add_tokens": "\"@#{m.acct}\" unless m . acct == @username or @client . account ( m . id ) . no_bot?", "del_tokens": "\"@#{m.acct}\" unless m . acct == @username or m . no_bot?", "commit_type": "fix"}
{"commit_tokens": ["Added", "hash", "wrapper", "to", "pass", "request", "to", "the", "ruby", "framework"], "add_tokens": "def respond ( req ) # @test_string = string puts \"Passed parameter: \" + req . to_s + \"\\n\"", "del_tokens": "def respond", "commit_type": "add"}
{"commit_tokens": ["Add", "--", "verbose", "option", "and", "use", "to", "control", "output", "of", "download", "command"], "add_tokens": "attr_accessor :username , :password , :verbose puts \"\\n>>> Login response >>>\" if @verbose if @verbose puts \"status code: #{response.code}\\n\" pp response puts cookie_jar . jar end puts \"\\n>>> Submit Login Form >>>\" if @verbose if @verbose puts \"status code: #{response.code}\\n\" pp response puts cookie_jar . jar end puts \"\\n>>> Downloads >>>\" if @verbose if @verbose puts \"status code: #{response.code}\\n\" pp response puts cookie_jar . jar end puts \"\\n>>> Xcode >>>\" if @verbose if @verbose puts \"status code: #{response.code}\\n\" pp response else puts \"filename: #{response.filename}\" puts \"size: #{response.header['content-length']}\" puts \"last-modified: #{response.header['last-modified']}\" end", "del_tokens": "attr_accessor :username , :password , :team puts 'Made it into the download method!' puts \"\\n>>> Login response >>>\" puts \"status code: #{response.code}\\n\" pp response puts cookie_jar . jar puts \"\\n>>> Submit Login Form >>>\" puts \"status code: #{response.code}\\n\" pp response puts cookie_jar . jar puts \"\\n>>> Downloads >>>\" puts \"status code: #{response.code}\\n\" pp response puts cookie_jar . jar puts \"\\n>>> Xcode >>>\" puts \"status code: #{response.code}\\n\" pp response", "commit_type": "add"}
{"commit_tokens": ["Add", "rdoc", "to", "selectable", "remove", "require", "all"], "add_tokens": "require \"origin/selectable/all\" require \"origin/selectable/and\" require \"origin/selectable/between\" require \"origin/selectable/elem_match\" require \"origin/selectable/exists\" require \"origin/selectable/gt\" require \"origin/selectable/gte\" require \"origin/selectable/in\" require \"origin/selectable/key\" require \"origin/selectable/lt\" require \"origin/selectable/lte\" require \"origin/selectable/max_distance\" require \"origin/selectable/mod\" require \"origin/selectable/ne\" require \"origin/selectable/near\" require \"origin/selectable/near_sphere\" require \"origin/selectable/nin\" require \"origin/selectable/nor\" require \"origin/selectable/or\" require \"origin/selectable/size\" require \"origin/selectable/strategies\" require \"origin/selectable/type\" require \"origin/selectable/where\" require \"origin/selectable/within_box\" require \"origin/selectable/within_circle\" require \"origin/selectable/within_polygon\" require \"origin/selectable/within_spherical_circle\" # An origin queryable is selectable, in that it has the ability to select # document from the database. The selectable module brings all functionality # to the queryable that has to do with building MongoDB selectors. # @attribute [r] selector The query selector. # Take the provided criterion and store it as a selection in the query # selector. # # @example Store the selection. # selectable.selection({ field: \"value\" }) # # @param [ Hash ] criterion The selection to store. # # @return [ Queryable ] The cloned queryable. # # @since 1.0.0", "del_tokens": "require_all __FILE__ , \"selectable\"", "commit_type": "add"}
{"commit_tokens": ["Add", "title", "retrieval", "by", "IMDb", "ID", "."], "add_tokens": "def title ( title , year = nil ) def find_by_id ( imdb_id ) return get '/' , { i : imdb_id } if imdb_id . start_with? ( 'tt' ) puts \"Invalid IMDb ID.\" end def find ( title ) ( get '/' , { s : title } ) . search", "del_tokens": "def title ( title ) def search ( query ) ( get '/' , { s : query } ) . search", "commit_type": "add"}
{"commit_tokens": ["Added", "Producer#connected", "\\", "?", "and", "refactored", "tests", "a", "bit"], "add_tokens": "set_speedy_connection_timeouts! it 'should return true when nsqd is up and false when nsqd is down' do wait_for { @connection . connected? }", "del_tokens": "stub_const ( 'Nsq::Connection::RECEIVE_FRAME_TIMEOUT' , 0.1 ) allow_any_instance_of ( Nsq :: Connection ) . to receive ( :snooze ) . and_return ( 0.01 ) wait_for { @connection . connected? } it 'should return false when nsqd is down' do end it 'should return true when nsqd is back' do expect ( @connection . connected? ) . to eq ( true ) @nsqd . stop wait_for { ! @connection . connected? }", "commit_type": "add"}
{"commit_tokens": ["Add", "logic", "for", "obtaining", "channel", "metadata"], "add_tokens": "@channel = bot . channel ( data [ 'channel_id' ] . to_i )", "del_tokens": "# TODO: Channel", "commit_type": "add"}
{"commit_tokens": ["Make", "tests", "run", "successfully", "under", "JRuby"], "add_tokens": "ENV [ 'DB' ] ||= 'pg' require \"erb\" ActiveRecord :: Base . configurations = YAML :: load ( ERB . new ( IO . read ( File . join ( test_dir , 'db' , config_file ) ) ) . result ) ActiveRecord :: Base . establish_connection ( ENV [ 'DB' ] )", "del_tokens": "ActiveRecord :: Base . configurations = YAML :: load ( IO . read ( File . join ( test_dir , 'db' , config_file ) ) ) ActiveRecord :: Base . establish_connection ( ENV [ 'DB' ] || \"pg\" )", "commit_type": "make"}
{"commit_tokens": ["Move", "appraisal", "to", "a", "development", "dep"], "add_tokens": "VERSION = \"0.13.1\"", "del_tokens": "VERSION = \"0.13.0\"", "commit_type": "move"}
{"commit_tokens": ["Move", "Frequency", "subclasses", "to", "separate", "files"], "add_tokens": "require \"montrose/frequency/daily\" require \"montrose/frequency/hourly\" require \"montrose/frequency/minutely\" require \"montrose/frequency/monthly\" require \"montrose/frequency/weekly\" require \"montrose/frequency/yearly\"", "del_tokens": "class Minutely < Frequency def include? ( time ) matches_interval? ( ( time - @starts ) / 1 . minute ) end end class Hourly < Frequency def include? ( time ) matches_interval? ( ( time - @starts ) / 1 . hour ) end end class Daily < Frequency def include? ( time ) matches_interval? time . to_date - @starts . to_date end end class Weekly < Frequency def include? ( time ) weeks_since_start ( time ) % @interval == 0 end private def weeks_since_start ( time ) ( ( time . beginning_of_week - base_date ) / 1 . week ) . round end def base_date @starts . beginning_of_week end end class Monthly < Frequency def include? ( time ) matches_interval? ( ( time . month - @starts . month ) + ( time . year - @starts . year ) * 12 ) end end class Yearly < Frequency def include? ( time ) matches_interval? time . year - @starts . year end end", "commit_type": "move"}
{"commit_tokens": ["Use", "Sprockets", "::", "Context", "to", "compile", "SASS"], "add_tokens": "@context = context @context . evaluate ( path )", "del_tokens": "require \"sass\" content = read_file ( path ) Sass :: Engine . new ( content , syntax : :scss ) . render", "commit_type": "use"}
{"commit_tokens": ["Allow", "key", "also", "on", "DtoCollections", "built", "from", "the", "DB"], "add_tokens": "found = dto_collection . find ( to_s ) if found . present? if found . try ( :data ) . present? found . data [ key ] || default else found . public_send ( key ) end else default end", "del_tokens": "( dto_collection . find ( to_s ) . try ( :data ) || { } ) [ key ] || default", "commit_type": "allow"}
{"commit_tokens": ["Move", "control", "options", "to", "the", "bottom"], "add_tokens": "# Control options attribute :complete , :kind_of => [ TrueClass , FalseClass ]", "del_tokens": "attribute :complete , :kind_of => [ TrueClass , FalseClass ]", "commit_type": "move"}
{"commit_tokens": ["Change", "is_const", "line", "to", "better", "handle", "the", "call", "to", "const_defined?", "."], "add_tokens": "is_const = if m . to_s =~ / ^[A-Z][a-zA-Z0-9_]*$ / # must start with uppercase and contain only letters, numbers, and underscores. begin const_defined? ( m ) rescue NameError # if for some reason we still get a NameError, it's obviously not a constant. false end else false end", "del_tokens": "is_const = const_defined? ( m ) rescue nil", "commit_type": "change"}
{"commit_tokens": ["Remove", "autoslash", "feature", "from", "Top", ".", "rb"], "add_tokens": "object_list . push ( obj ) @measure [ device ] . plug ( @driver [ card [ \"name\" ] ] . objects [ obj ] ) @actuator [ device ] . plug ( @driver [ card [ \"name\" ] ] . objects [ obj ] ) exported_obj = Dbus_debug . new ( device , @driver [ card [ \"name\" ] ] . objects [ obj ] )", "del_tokens": "object_list . push ( \"/\" + obj ) @measure [ device ] . plug ( @driver [ card [ \"name\" ] ] . objects [ \"/\" + obj ] ) @actuator [ device ] . plug ( @driver [ card [ \"name\" ] ] . objects [ \"/\" + obj ] ) exported_obj = Dbus_debug . new ( device , @driver [ card [ \"name\" ] ] . objects [ \"/\" + obj ] )", "commit_type": "remove"}
{"commit_tokens": ["Make", "company", "optional", "because", "it", "is", "not", "yet", "known", "on", "first", "logon"], "add_tokens": "def initialize ( username , password , organisation , company = nil ) end", "del_tokens": "def initialize ( username , password , organisation , company ) end", "commit_type": "make"}
{"commit_tokens": ["Fixed", "/", "improved", "Factory", ".", "debug", "test"], "add_tokens": "expect { Factory . debug ( :user ) } . to raise_error ( 'Oops, the User created by the Factory has the following errors: {:required_attr=>[\"can\\'t be blank\"]}' ) Factory . debug ( :user , required_attr : true ) . class . should == User Factory . debug ( :user , required_attr : true ) . saved? . should == false Factory . debug! ( :user , required_attr : true ) . saved? . should == true crank ( :user_attrs ) . size . should == 5", "del_tokens": "error = false begin Factory . debug ( :user , :valid => false ) rescue error = true end error . should == true Factory . debug ( :user ) . class . should == User Factory . debug ( :user ) . saved? . should == false Factory . debug! ( :user ) . saved? . should == true crank ( :user_attrs ) . size . should == 6", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "to", "retry", "certain", "requests", "to", "the", "validator"], "add_tokens": "class RequestError < StandardError ; end perform_request ( method , path , arguments , 3 ) end def perform_request ( method , path , arguments , tries = 3 ) rescue RequestError => e if tries > 0 perform_request ( method , path , arguments , tries - 1 ) else raise end raise raise RequestError . new ( \"Rescource conflict\" ) raise RequestError . new ( \"Resource invalid\" ) raise RequestError . new ( \"Server error\" )", "del_tokens": "raise raise \"Rescource conflict\" raise \"Resource invalid\" raise \"Server error\"", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "activity_copy_limit", "on", "follow_many"], "add_tokens": "def follow_many ( follows , activity_copy_limit = nil ) query_params = { } unless activity_copy_limit . nil? query_params [ 'activity_copy_limit' ] = activity_copy_limit end make_signed_request ( :post , \"/follow_many/\" , query_params , follows )", "del_tokens": "def follow_many ( follows ) make_signed_request ( :post , \"/follow_many/\" , { } , follows )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "final", "default", "if", "a", "resource", "has", "no", "actions", "."], "add_tokens": "@default_action || ( superclass . respond_to? ( :default_action ) && superclass . default_action ) || actions . first || :nothing", "del_tokens": "@default_action || ( superclass . respond_to? ( :default_action ) && superclass . default_action ) || actions . first", "commit_type": "add"}
{"commit_tokens": ["use", "delete_if", "over", "select", "with", "assignment"], "add_tokens": "@tokens . delete_if { | token | ! token . tagged? }", "del_tokens": "@tokens = @tokens . select { | token | token . tagged? }", "commit_type": "use"}
{"commit_tokens": ["Fix", "method", "signature", "for", "#create_orders_shipments", "."], "add_tokens": "def create_orders_shipments ( id , options = { } ) @connection . post ( \"/orders/#{id}/shipments\" , options )", "del_tokens": "def create_orders_shipments ( id ) @connection . post ( \"/orders/#{id}/shipments\" , { } )", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "Tree", "class", "and", "changed", "how", "#subtree", "and", "#subtree!", "works", "to", "match", "the", "addition"], "add_tokens": "return self if root? # Extract def extract extract . children . map do | child | # Tree # # Wraps the entire tree in a Tree object If this node is a child the root # will be found and passed to Tree.new. def tree Tree . new root end # Subtree! # # Extracts this node from the larger tree and wraps it in a Tree object. def subtree! Tree . new extract end # Subtree # # Duplicates this node and its descendants and wraps them in a Tree object. def subtree Tree . new dup end", "del_tokens": "# Subtree! def subtree! alias subtree dup subtree! . children . map do | child |", "commit_type": "add"}
{"commit_tokens": ["Fix", "specs", "and", "capture", "global", "scorpion", "during", "specs"], "add_tokens": "VERSION_NUMBER = \"0.6.1\"", "del_tokens": "VERSION_NUMBER = \"0.6.0\"", "commit_type": "fix"}
{"commit_tokens": ["Change", "unknown", "line", "break", "message", "back", "to", "error"], "add_tokens": "build_errors ( :line_breaks , :structure )", "del_tokens": "build_info_messages ( :line_breaks , :structure )", "commit_type": "change"}
{"commit_tokens": ["updating", "semaphore", "with", "code", "needed", "for", "TJS", "integration", ".", "Updating", "gemspec", "so", "I", "can", "install", "it", "on", "TJS", "and", "test", "it"], "add_tokens": "def available? count < @max_leases end set_watch if available? unset_watch ensure_connection! @zk . stat ( @resource_path ) . num_children end def set_watch ensure_connection! @zk . children ( @resource_path , :watch => true ) end def unset_watch ensure_connection! @zk . children ( @resource_path , :watch => false ) ensure_connection! ensure_connection! def ensure_connection! unless @zk . connected? raise ZK :: Exceptions :: ConnectionLoss unless @zk . reopen == :connected end end", "del_tokens": "if count < @max_leases # gotta set that watch every time or our handler # might not fire which would be such a bummer man # yeah whoa @zk . children ( @resource_path , watch : true ) . length", "commit_type": "update"}
{"commit_tokens": ["added", "tests", "for", "basic", "auth", "and", "oauth", "request", "headers"], "add_tokens": "context \"authentiation\" do it \"should connect with basic auth credentials\" do connect_stream :auth => \"username:password\" $recieved_data . should include ( 'Authorization: Basic' ) end it \"should connect with oauth credentials\" do oauth = { :consumer_key => '1234567890' , :consumer_secret => 'abcdefghijklmnopqrstuvwxyz' , :access_key => 'ohai' , :access_secret => 'ohno' } connect_stream :oauth => oauth $recieved_data . should include ( 'Authorization: OAuth' ) end end end stream . should_receive ( :reconnect ) end # This is to make it so the network failure specs which call connect_stream # can be reused. This way calls to connect_stream won't actually create a end end", "del_tokens": "end stream . should_receive ( :reconnect ) end # This is to make it so the network failure specs which call connect_stream # can be reused. This way calls to connect_stream won't actually create a end end", "commit_type": "add"}
{"commit_tokens": ["Add", "safe", "level", "and", "trim", "mode", "for", "ERb"], "add_tokens": "# @option options [Object, nil] :safe_level (nil) A valid value for $SAFE for use with ERb # @option options [String] :trim_mode (\"\") A valid ERb trim mode safe_level = options [ :safe_level ] || PatternPatch . safe_level trim_mode = options [ :trim_mode ] || PatternPatch . trim_mode patch_text = ERB . new ( text , safe_level , trim_mode ) . result options [ :binding ] # @option options [Object, nil] :safe_level (nil) A valid value for $SAFE for use with ERb # @option options [String] :trim_mode (\"\") A valid ERb trim mode safe_level = options [ :safe_level ] || PatternPatch . safe_level trim_mode = options [ :trim_mode ] || PatternPatch . trim_mode patch_text = ERB . new ( text , safe_level , trim_mode ) . result options [ :binding ]", "del_tokens": "patch_text = ERB . new ( text ) . result options [ :binding ] patch_text = ERB . new ( text ) . result options [ :binding ]", "commit_type": "add"}
{"commit_tokens": ["Add", "group", "api", "removed", "user_teams", "api"], "add_tokens": "describe \".group_members\" do before do stub_get ( \"/groups/3/members\" , \"group_members\" ) @members = Gitlab . group_members ( 3 ) end it \"should get the correct resource\" do a_get ( \"/groups/3/members\" ) . should have_been_made end it \"should return information about a group members\" do @members . should be_an Array @members . size . should == 2 @members [ 1 ] . name . should == \"John Smith\" end end describe \".add_group_member\" do before do stub_post ( \"/groups/3/members\" , \"group_member\" ) @member = Gitlab . add_group_member ( 3 , 1 , 40 ) end it \"should get the correct resource\" do a_post ( \"/groups/3/members\" ) . with ( :body => { :user_id => '1' , :access_level => '40' } ) . should have_been_made end it \"should return information about an added member\" do @member . name . should == \"John Smith\" end end describe \".remove_group_member\" do before do stub_delete ( \"/groups/3/members/1\" , \"group_member_delete\" ) @group = Gitlab . remove_group_member ( 3 , 1 ) end it \"should get the correct resource\" do a_delete ( \"/groups/3/members/1\" ) . should have_been_made end it \"should return information about the group the member was removed from\" do @group . group_id . should == 3 end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "allow", "color", "disabling", "."], "add_tokens": "color = options . fetch ( :color ) { true } @printer = Printer . new ( @output , color : color )", "del_tokens": "@color = options . fetch ( :color ) { true } @printer = Printer . new ( @output )", "commit_type": "change"}
{"commit_tokens": ["Fix", "a", "require", "in", "tests"], "add_tokens": "require File . expand_path ( '../test_helper' , __FILE__ )", "del_tokens": "require File . dirname ( __FILE__ ) + '/test_helper.rb'", "commit_type": "fix"}
{"commit_tokens": ["fixing", "bug", "in", "nested", "set", "."], "add_tokens": "def adjust ( attributes = { } , preload = true )", "del_tokens": "def adjust ( attributes = { } , preload = true )", "commit_type": "fix"}
{"commit_tokens": ["updates", "version", "to", "correct", "number"], "add_tokens": "VERSION = '0.26.0' . freeze", "del_tokens": "VERSION = '0.25.0' . freeze", "commit_type": "update"}
{"commit_tokens": ["Add", "tests", "for", "log", "delegation"], "add_tokens": "def outfile output end # validcolors = Rainbow::X11ColorNames::NAMES validcolors = Rainbow :: Color :: Named :: NAMES", "del_tokens": "validcolors = Rainbow :: X11ColorNames :: NAMES clsmeth = Array . new clsmeth << \"def #{color}(msg = \\\"\\\", lvl = DEBUG, depth = 1, cname = nil, &blk)\" clsmeth << \" logger.#{color}(\\\"\\\\e[#{code}m\\#{msg\\}\\\\e[0m\\\", lvl, depth + 1, cname, &blk)\" clsmeth << \"end\" class_eval clsmeth . join ( \"\\n\" )", "commit_type": "add"}
{"commit_tokens": ["Make", "blog", "posts", "ordered", "by", "published", "at", "date", "by", "default"], "add_tokens": "has_many :posts , :class_name => \"BlogPost\" , :conditions => { :published => true } , :order => \"published_at desc\"", "del_tokens": "has_many :posts , :class_name => \"BlogPost\" , :conditions => { :published => true }", "commit_type": "make"}
{"commit_tokens": ["Remove", "require", "font", "-", "awesome", "-", "rails"], "add_tokens": "# require 'font-awesome-rails'", "del_tokens": "require 'font-awesome-rails'", "commit_type": "remove"}
{"commit_tokens": ["Improved", "CryptBuffer", "LanguageAnalyzers", "and", "VigenereXor", "classes", "to", "solve", "CryptoPals", "Challanges"], "add_tokens": "def [] ( * things ) CryptBuffer ( bytes [ * things ] )", "del_tokens": "def [] ( anything ) CryptBuffer ( bytes [ anything ] )", "commit_type": "improve"}
{"commit_tokens": ["Allow", "for", "SRID", "=", "default", "when", "using", "geospatial", "scopes", "."], "add_tokens": "column_name = self . connection . quote_table_name ( options [ :column ] ) geom = if args . first . is_a? ( String ) && args . first =~ / ^SRID=default; / args . first . sub ( / default / , ( column_srid || - 1 ) . to_s ) else args . first end geos = Geos . read ( geom ) geom_srid = if geos . srid == 0 geos . srid geos . to_ewkb", "del_tokens": "geom = Geos . read ( args . first ) column_name = :: ActiveRecord :: Base . connection . quote_table_name ( options [ :column ] ) geom_srid = if geom . srid == 0 geom . srid geom . to_ewkb", "commit_type": "allow"}
{"commit_tokens": ["Update", "version", "for", "method_missing", "removal"], "add_tokens": "VERSION = \"0.7\"", "del_tokens": "VERSION = \"0.6\"", "commit_type": "update"}
{"commit_tokens": ["Add", "missing", "descriptions", "to", "the", "README", "."], "add_tokens": "class_option :summary , :default => 'TODO: Summary' , :aliases => '-s' class_option :description , :default => 'TODO: Description' , :aliases => '-D' @summary = options . summary @description = options . description", "del_tokens": "class_option :summary , :default => 'TODO: Summary' , :aliases => '-s' class_option :description , :default => 'TODO: Summary' , :aliases => '-D'", "commit_type": "add"}
{"commit_tokens": ["moved", "check", "from", "Redis", "into", "Channel"], "add_tokens": "# Pusher channel. Relay events received from Redis into the def self . from channel channel [ / ^presence- / ] ? PresenceChannel : Channel end", "del_tokens": "# Pusher channel. Relay events received from Redis into the", "commit_type": "move"}
{"commit_tokens": ["Added", ":", "new_many", "to", "Aerospike", "::", "Client"], "add_tokens": "list . any? { | node | node . name == name }", "del_tokens": "list . any? { | name | node . name == name }", "commit_type": "add"}
{"commit_tokens": ["Updated", "to_tsv", "to", "use", "the", "standard", "CSV", "library", "for", "field", "encoding", "this", "fixes", "issues", "around", "escaping", "results", "properly", "(", "example", "keywords", "from", "google", "that", "have", "quotes", "in", "them", "aren", "t", "scaped", "properly"], "add_tokens": "require 'csv' columns = [ ] columns << [ @id , @updated , @title ] columns << @dimensions . map { | d | d . value } columns << @metrics . map { | m | m . value } output = CSV . generate_line ( columns )", "del_tokens": "output = \"\\\"#{@id}\\\",\\\"#{@updated.to_s}\\\",\\\"#{@title}\\\",\" output += @dimensions . collect do | dimension | \"\\\"#{dimension.value}\\\"\" end . join ( ',' ) output += ',' output += @metrics . collect do | metric | \"\\\"#{metric.value}\\\"\" end . join ( ',' )", "commit_type": "update"}
{"commit_tokens": ["moving", "common", "src", "and", "spec", "files", "refactoring"], "add_tokens": "Dir [ \"#{@config.dir.base}/specs/*.spec\" ] . each do | spec_file |", "del_tokens": "Dir [ \"#{@config.dir.base}/src/spec/*.spec\" ] . each do | spec_file |", "commit_type": "move"}
{"commit_tokens": ["implement", "$", "(", "nid", ")"], "add_tokens": "def exid ; @execution [ 'exid' ] ; end def nid ; @node [ 'nid' ] ; end def parent ; @node [ 'parent' ] ; end def from ; @message [ 'from' ] ; end def attributes ; tree [ 1 ] ; end def payload ; @message [ 'payload' ] ; end def lookup ( k ) return @node . nid if k == 'nid' @node . lookup ( k ) end", "del_tokens": "def lookup ( k ) ; @node . lookup ( k ) ; end def exid ; @message [ 'exid' ] ; end def nid ; @message [ 'nid' ] ; end def from ; @message [ 'from' ] ; end def attributes ; tree [ 1 ] ; end def payload ; @message [ 'payload' ] ; end def parent ; @node [ 'parent' ] ; end", "commit_type": "implement"}
{"commit_tokens": ["Updated", "cassettes", "again", "all", "tests", "green"], "add_tokens": "query = { cpt_code : '87799' , zip_code : '32218' }", "del_tokens": "query = { cpt_code : '12345' , zip_code : '75201' }", "commit_type": "update"}
{"commit_tokens": ["adding", "the", "final", "test", "api", "-", "key", "and", "secret", "fixing", "a", "typo"], "add_tokens": "@api_key = 459782 p token p token . size", "del_tokens": "@api_key = 394281", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "default", "stroke_width", "for", "the", "Standard", "renderer", "to", "be", "1"], "add_tokens": "graph << Scruffy :: Components :: Grid . new ( :grid , :position => [ 20 , 0 ] , :size => [ 80 , 89 ] , :stroke_width => 1 )", "del_tokens": "graph << Scruffy :: Components :: Grid . new ( :grid , :position => [ 20 , 0 ] , :size => [ 80 , 89 ] )", "commit_type": "make"}
{"commit_tokens": ["Added", ":", "set", "option", "to", "auto_validate", "added", "support", "for", "infinite", "ranges", "in", "within_validator"], "add_tokens": "PROPERTY_OPTIONS << :message << :messages << :set # :set => [\"foo\", \"bar\", \"baz\"] # Setting the :set option causes a validates_within # validator to be automatically created on the property # # within validator if property . options . has_key? ( :set ) validates_within property . name , options_with_message ( { :set => property . options [ :set ] } , property , :within ) end", "del_tokens": "PROPERTY_OPTIONS << :message << :messages", "commit_type": "add"}
{"commit_tokens": ["Added", "pending", "cancelled", "accepted", "and", "declined", "to", "RecurringApplicationCharge"], "add_tokens": "class << self def current all . find { | c | c . status == 'active' } end def pending all . find { | c | c . status == 'pending' } end def cancelled all . find { | c | c . status == 'cancelled' } end def accepted all . find { | c | c . status == 'accepted' } end def declined all . find { | c | c . status == 'declined' } end", "del_tokens": "def self . current find ( :all ) . find { | charge | charge . status == 'active' }", "commit_type": "add"}
{"commit_tokens": ["add", "method", "to", "retrieve", "last", "rate", "info", "per", "action", "/", "method"], "add_tokens": "@rate_info = { } # params # endpoint, String a e.g. \"user\" or \"send\" # method, String \"GET\" or \"POST\" # returns # Hash rate info # Get rate info for a particular endpoint/method, as of the last time a request was sent to the given endpoint/method # Includes the following keys: # limit: the per-minute limit for the given endpoint/method # remaining: the number of allotted requests remaining in the current minute for the given endpoint/method # reset: unix timestamp of the top of the next minute, when the rate limit will reset def get_last_rate_info ( endpoint , method ) rate_info_key = get_rate_info_key ( endpoint , method ) @rate_info [ rate_info_key ] end _result = http_request ( action , data , request_type , binary_key ) def http_request ( action , data , method = 'POST' , binary_key = nil ) uri = \"#{@api_uri}/#{action}\" save_rate_info ( action , method , response ) def save_rate_info ( action , method , response ) limit = response [ 'x-rate-limit-limit' ] . to_i remaining = response [ 'x-rate-limit-remaining' ] . to_i reset = response [ 'x-rate-limit-reset' ] . to_i if limit . nil? or remaining . nil? or reset . nil? return end rate_info_key = get_rate_info_key ( action , method ) @rate_info [ rate_info_key ] = { limit : limit , remaining : remaining , reset : reset } end def get_rate_info_key ( endpoint , method ) :\" #{ endpoint } _ #{ method . downcase } \" end", "del_tokens": "_result = http_request ( \"#{@api_uri}/#{action}\" , data , request_type , binary_key ) def http_request ( uri , data , method = 'POST' , binary_key = nil )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "way", "to", "just", "run", "the", "rails", "server", "fixed", "the", "NPM", "setup", "task"], "add_tokens": "from_root { NPM . setup } when 'rails' from_rails \"rails s\"", "del_tokens": "from_root NPM . setup", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "impossible", "to", "create", "a", "relationship", "without", "a", "label", "start_node", "or", "end_node", "."], "add_tokens": "class Like < Related :: Entity", "del_tokens": "class Like < Related :: Relationship", "commit_type": "make"}
{"commit_tokens": ["Add", "integration", "test", "for", "component", "guide"], "add_tokens": "mount GovukPublishingComponents :: Engine , at : \"/component-guide\"", "del_tokens": "mount GovukPublishingComponents :: Engine => \"/govuk_publishing_components\"", "commit_type": "add"}
{"commit_tokens": ["Adds", "hook", "to", "create", "the", "application"], "add_tokens": "Dir [ File . join ( File . dirname ( __FILE__ ) , \"pancake/**/*.rb\" ) ] . each { | f | require f } module Pancake # A simple rack application OK_APP = lambda { | e | [ 200 , { \"Content-Type\" => \"text/plain\" } , \"OK\" ] } end # Panckae", "del_tokens": "Dir [ File . join ( File . dirname ( __FILE__ ) , \"pancake/**/*.rb\" ) ] . each { | f | require f }", "commit_type": "add"}
{"commit_tokens": ["Moving", "CountryInfo", "class", "into", "a", "separate", "file", "."], "add_tokens": "require 'tzinfo/country_info' # us.zone_identifiers # us.zones # us.zone_info # Gets a Country by its ISO 3166 code. Raises an InvalidCountryCode # exception if it couldn't be found. # Dump this Country for marshalling. # Load a marshalled Country. country = CountryInfo . new ( code , name , & block ) end", "del_tokens": "require 'tzinfo/country_timezone' # puts us.zone_identifiers # puts us.zones # Gets a Country by its ISO 3166 code. Raising an exception if it couldn't # be found. country = CountryInfo . new ( code , name , block ) end # Class to store the data loaded from the country index. Instances of this # class are passed to the blocks in the index that define timezones. class CountryInfo #:nodoc: attr_reader :code attr_reader :name # Constructs a new CountryInfo with an ISO 3166 country code, name and # block. The block will be evaluated to obtain the timezones for the country # (when they are first needed). def initialize ( code , name , block ) @code = code @name = name @block = block @zones = nil @zone_identifiers = nil end # Called by the index data to define a timezone for the country. def timezone ( identifier , latitude , longitude , description = nil ) # Currently only store the identifiers. @zones << CountryTimezone . new ( identifier , latitude , longitude , description ) end # Returns a frozen array of all the zone identifiers for the country. These # are in an order that # (1) makes some geographical sense, and # (2) puts the most populous zones first, where that does not contradict (1). def zone_identifiers unless @zone_identifiers @zone_identifiers = zones . collect { | zone | zone . identifier } @zone_identifiers . freeze end @zone_identifiers end # Returns a frozen array of all the timezones for the for the country as # CountryTimezone instances. These are in an order that # (1) makes some geographical sense, and # (2) puts the most populous zones first, where that does not contradict (1). def zones unless @zones @zones = [ ] @block . call ( self ) @block = nil @zones . freeze end @zones end end", "commit_type": "move"}
{"commit_tokens": ["Add", "refetch", "logic", "on", "Conflict"], "add_tokens": "class VersionMismatchError < StandardError ; end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", "per", "-", "target", "overrides", "for", ":", "http_prefix"], "add_tokens": "# The `build_dir`, 'http_prefix', and `features` keys in a target have special # meanings; other keys can be added arbitrarily and helpers can fetch these # for you. A best practice is to assign the same features to _all_ of your # targets and toggle them `on` or `off` on a target-specific basis. # :http_prefix => '/free', # :http_prefix => '/pro', # @!attribute [rw] config[:http_prefix]= # Default prefix for building paths. Used by HTML helpers. # # If the `http_prefix` key is present for any of the `config[:targets]`, # they will override this setting. # @return [String] Indicate the HTTP prefix that will be used by # HTML helpers. # @note This is a Middleman application level config option. if ( http_prefix = app . config [ :targets ] [ app . config [ :target ] ] [ :http_prefix ] ) app . config [ :http_prefix ] = http_prefix say \"Using http_prefix \\\"#{app.config[:http_prefix]}\\\".\" , :blue end", "del_tokens": "# The `build_dir` and `features` keys in a target have special meanings; # other keys can be added arbitrarily and helpers can fetch these for you. # A best practice is to assign the same features to _all_ of your targets and # toggle them `on` or `off` on a target-specific basis.", "commit_type": "add"}
{"commit_tokens": ["Move", "caching", "to", "internal", "model", "."], "add_tokens": "@_lazer_model . merge! ( attributes ) @_lazer_loaded = false @_lazer_model . to_h @_lazer_model . merge! ( new_attributes ) @_lazer_model . fetch ( key ) @_lazer_loaded", "del_tokens": "@_lazer_model . source_hash . merge! ( attributes ) @_lazer_cache = { } todo = self . class . lazer_metadata . keys - @_lazer_cache . keys todo . each { | key | @_lazer_cache [ key ] = @_lazer_model . load_key ( key ) } @_lazer_cache . merge ( @_lazer_writethrough ) @_lazer_model . source_hash . merge! ( new_attributes ) @_lazer_cache . clear return @_lazer_cache [ key ] if @_lazer_cache . key? ( key ) value = @_lazer_model . load_key ( key ) @_lazer_cache [ key ] = value value @_lazer_loaded ||= false", "commit_type": "move"}
{"commit_tokens": ["Allow", "to", "pass", "config", "to", "everything", "to", "avoid", "recomputing", "or", "recalculating", "difference"], "add_tokens": "it 'Calls precompiled only once' do precompiled = WorkingHours :: Config . precompiled expect ( WorkingHours :: Config ) . to receive ( :precompiled ) . once . and_return ( precompiled ) # in_config_zone and add_seconds time = Time . utc ( 1991 , 11 , 15 , 16 , 59 , 42 ) # Friday add_seconds ( time , 120 ) end end", "del_tokens": "end", "commit_type": "allow"}
{"commit_tokens": ["Made", "library", "more", "secure", "by", "default", "."], "add_tokens": "# signature_policy:: # The policy for requiring signatures in tokens. The possible values are: # - :strict (default) - The innermost token must be signed. This is the recommended policy. # - :none - No signature is required. This _really_ isn't recommended. signature_policy : :strict , if options [ :signature_policy ] == :strict && ! is_signed? ( parts ) raise Sandal :: UnsupportedTokenError , \"The innermost token is not signed.\" end raise UnsupportedTokenError , \"Unsupported signature method.\" if validator . nil? raise InvalidTokenError , \"Invalid signature.\" raise InvalidTokenError , \"Invalid token encoding.\"", "del_tokens": "validator ||= Sandal :: Sig :: NONE raise TokenError , \"Invalid signature.\" raise TokenError , \"Invalid token encoding.\"", "commit_type": "make"}
{"commit_tokens": ["Allow", "fill_in_fields", "to", "work", "with", "checkboxes", "and", "dropdowns"], "add_tokens": "# Select a value from a dropdown or listbox, or fill in a text field, # depending on what kind of form field is available. If `field` is a # dropdown or listbox, select `value` from that; otherwise, assume # `field` is a text box. def select_or_fill ( field , value ) begin select ( value , :from => field ) rescue fill_in ( field , :with => value ) end end # Check a checkbox, select from a dropdown or listbox, or fill in a text # field, depending on what kind of form field is available. If value # is `checked` or `unchecked`, assume `field` is a checkbox; otherwise, # fall back on `select_or_fill`. def check_or_select_or_fill ( field , value ) # If value is \"checked\" or \"unchecked\", assume # field is a checkbox if value == \"checked\" begin check ( field ) rescue select_or_fill ( field , value ) end elsif value == \"unchecked\" begin uncheck ( field ) rescue select_or_fill ( field , value ) end else select_or_fill ( field , value ) end end fields . each do | field , value | check_or_select_or_fill ( field , value )", "del_tokens": "fields . each do | name , value | fill_in name , :with => value", "commit_type": "allow"}
{"commit_tokens": ["Add", "attributes", "to", "store", "information", "endpoint"], "add_tokens": "property :logo property :domain property :address property :currency property :features property :language property :timezone property :plan_name property :plan_level property :secure_url property :weight_units property :decimal_places property :dimension_units property :dimension_decimal_places property :dimension_thousands_token property :is_price_entered_with_tax", "del_tokens": "property :domain property :address property :language property :currency property :decimal_places property :dimension_decimal_places property :dimension_thousands_token property :is_price_entered_with_tax property :weight_units property :dimension_units property :plan_name property :logo", "commit_type": "add"}
{"commit_tokens": ["Fixed", "nested", "Widget#widget", "method", "invocations", "."], "add_tokens": "child = widget_class . new ( helpers , assigns , doc . output , & block )", "del_tokens": "child = widget_class . new ( helpers , assigns , doc , & block )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "for", "the", "sending", "of", "nil", "payloads", "."], "add_tokens": "res = http . request ( req , payload )", "del_tokens": "res = http . request ( req , payload || \"\" )", "commit_type": "allow"}
{"commit_tokens": ["Move", "at_exit", "into", "global", "space"], "add_tokens": "VERSION = \"0.11.1\"", "del_tokens": "VERSION = \"0.11.0\"", "commit_type": "move"}
{"commit_tokens": ["Fixed", "documentation", "for", "VCS", "::", "ClassMethods#const_missing"], "add_tokens": "# @param [Symbol] const The symbolic name of the missing constant", "del_tokens": "# @param [Symbol] The symbolic name of the missing constant", "commit_type": "fix"}
{"commit_tokens": ["moved", "auditor", ".", "rb", "from", "lib", "/", "auditing", "/", "auditing", "to", "lib", "/", "auditing"], "add_tokens": "require 'auditing/auditor'", "del_tokens": "require 'auditing/auditing/auditor'", "commit_type": "move"}
{"commit_tokens": ["Updated", "centos", "and", "ubuntu", "definitions", "to", "take", "advantage", "of", "sudo", "and", "shutdown", "cmd"], "add_tokens": ":sudo_cmd => \"echo '%p'|sudo -S sh '%f'\" ,", "del_tokens": ":sudo_cmd => \"echo %p|sudo -S sh %f\" ,", "commit_type": "update"}
{"commit_tokens": ["Added", "XGen", "::", "Mongo", "::", "Driver", "::", "DB", ".", "master?"], "add_tokens": "ok = doc [ 'ok' ] return Collection . new ( self , name ) if ok . kind_of? ( Numeric ) && ( ok . to_i == 1 || ok . to_i == 0 ) ok? ( db_command ( :drop => name ) ) end # Returns true if this database is a master (or is not paired with any # other database), false if it is a slave. def master? doc = db_command ( :ismaster => 1 ) is_master = doc [ 'ismaster' ] ok? ( doc ) && is_master . kind_of? ( Numeric ) && is_master . to_i == 1 return doc [ 'n' ] . to_i if ok? ( doc ) raise \"Error with drop_index command: #{doc.inspect}\" unless ok? ( doc ) def ok? ( doc ) ok = doc [ 'ok' ] ok . kind_of? ( Numeric ) && ok . to_i == 1 end", "del_tokens": "o = doc [ 'ok' ] return Collection . new ( self , name ) if o . kind_of? ( Numeric ) && ( o . to_i == 1 || o . to_i == 0 ) doc = db_command ( :drop => name ) o = doc [ 'ok' ] return o . kind_of? ( Numeric ) && o . to_i == 1 o = doc [ 'ok' ] return doc [ 'n' ] . to_i if o . to_i == 1 o = doc [ 'ok' ] raise \"Error with drop_index command: #{doc.inspect}\" unless o . kind_of? ( Numeric ) && o . to_i == 1", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bugs", "in", "both", "#first", "and", "#last"], "add_tokens": "assert_nil list . first { | item | item . value == :c } assert_equal [ item_a , item_b ] , list . first ( 2 ) { | item | item . value == :a } it 'returns nil when given 0' do assert_nil list . last ( 0 ) end it 'returns an empty array for empty lists when n > 0' do assert_equal [ ] , list . last ( 2 ) it 'returns the first item' do list . push item assert_same item , list . last it 'accepts a block for selecting which item to start at' do list . push item_a list . push item_b assert_nil list . last { | item | item . value == :c } assert_same item_a , list . last { | item | item . value == :a } assert_equal [ item_a , item_b ] , list . last ( 2 ) { | item | item . value == :b } assert_equal [ item_a ] , list . last ( 2 ) { | item | item . value == :a } assert_equal [ ] , list . last ( 2 ) { | item | item . value == :c } end", "del_tokens": "it 'returns the first item' do assert_same item , list . last it 'returns an empty array when given 0' do assert_equal [ ] , list . last ( 0 )", "commit_type": "fix"}
{"commit_tokens": ["move", "stuff", "around", "tweak", "regex", "used", "to", "recognize", "numbers", "so", "that", "it", "will", "handle", "units", "with", "only", "one", "character", "right", "."], "add_tokens": "# returns next unit in a range. '1 mm'.unit.succ #=> '2 mm'.unit # only works when the scalar is an integer def succ raise ArgumentError , \"Non Integer Scalar\" unless @scalar == @scalar . to_i Unit . new ( @scalar . to_i . succ , @numerator , @denominator ) end alias :next :succ # returns next unit in a range. '1 mm'.unit.succ #=> '2 mm'.unit # only works when the scalar is an integer def pred raise ArgumentError , \"Non Integer Scalar\" unless @scalar == @scalar . to_i Unit . new ( @scalar . to_i . pred , @numerator , @denominator ) end anynumber = %r{ (?:( #{ complex } | #{ rational } | #{ sci } ) \\b )? \\s ?([ \\D ].*)? }", "del_tokens": "# returns next unit in a range. '1 mm'.unit.succ #=> '2 mm'.unit # only works when the scalar is an integer def succ raise ArgumentError , \"Non Integer Scalar\" unless @scalar == @scalar . to_i Unit . new ( @scalar . to_i . succ , @numerator , @denominator ) end alias :next :succ # returns next unit in a range. '1 mm'.unit.succ #=> '2 mm'.unit # only works when the scalar is an integer def pred raise ArgumentError , \"Non Integer Scalar\" unless @scalar == @scalar . to_i Unit . new ( @scalar . to_i . pred , @numerator , @denominator ) end anynumber = %r{ (?:( #{ complex } | #{ rational } | #{ sci } ) \\b )? \\s ?([ \\D ].+)? }", "commit_type": "move"}
{"commit_tokens": ["Fix", "missing", "prec_max", "instance", "var", "and", "check", "for", "nil", "in", "wanted", "data", "bags", "during", "upload"], "add_tokens": "attr_accessor :prec_max @prec_max += 1 s = { v => @prec_max }", "del_tokens": ":: Chef :: Knife . prec_max += 1 s = { v => :: Chef :: Knife . prec_max }", "commit_type": "fix"}
{"commit_tokens": ["Use", "EoTime", "for", "cron", "#next_time", "and", "#previous_time"], "add_tokens": "f = :: EtOrbi . make_time ( from )", "del_tokens": "f = Time . parse ( from )", "commit_type": "use"}
{"commit_tokens": ["Remove", "common", "Layout", "methods", "now", "included", "in", "NavControls", "mixin"], "add_tokens": "reactivate!", "del_tokens": "@deactivate = false # Decactivates layout by disabling further input def deactivate! @deactivate = true end def deactivate? ! ! @deactivate end", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "description", "of", "DelegationController", "to", "the", "comments", "."], "add_tokens": "module WebsocketRails # This class provides a means for accessing the Rails # controller helper methods defined in a user's application # or in gems that the user has added to the project. # # Each active connection creates and stores it's own # instance with the correct @_request and @_env objects # set. WebsocketRails::BaseController sends missing # methods to the active connection's delegation controller # instance. class DelegationController < ApplicationController end", "del_tokens": "class WebsocketRails :: DelegationController < ApplicationController", "commit_type": "add"}
{"commit_tokens": ["Changed", ":", "You", "can", "break", "long", "experiment", "descriptions", "into", "multiple", "paragraphs"], "add_tokens": "description <<-TEXT Testing new registration form that asks for age and zipcode . Option A presents the existing form , and option B adds age and zipcode fields . We know option B will convert less , but higher quality leads . If we lose less than 20 % conversions , we ' re going to switch to option B . TEXT complete_if do alternatives . all? { | alt | alt . participants > 100 } end outcome_is do one_field = alternative ( false ) three_fields = alternative ( true ) three_fields . conversion_rate >= 0.8 * one_field . conversion_rate ? three_fields : one_field end", "del_tokens": "description \"Testing new registration form that asks for age and zipcode.\"", "commit_type": "change"}
{"commit_tokens": ["improve", "wikka", "parsing", "and", "wikka", "support"], "add_tokens": "body . gsub! ( / ( \\/ \\/ )(.*?)( \\/ \\/ ) / , '*\\2*' ) #italic # markdown: ![Tux, the Linux mascot](/assets/images/tux.png) # url body . gsub! ( / [ \\[ ]{2}(( \\w +):[ \\S ][^ \\| ]*)[ \\| ](.*)[ \\] ]{2} / , '[\\3](\\1)' ) body . gsub! ( / [ \\[ ]{2}(( \\w +):.*)[ \\] ]{2} / , '<\\1>' ) body . gsub! ( / [ \\[ ]{2}( \\w +) \\s (.+?)[ \\] ]{2} / , '[[\\2|\\1]]' ) #body.gsub!(/[]{2}(\\w+)\\s(.+)\\]\\]/, ' [[\\1 | \\2]] ')", "del_tokens": "body . gsub! ( / ( \\/ \\/ )(.*?)( \\/ \\/ ) / ) { | s | '_' + $2 + '_' } #italic #str.gsub!(/(----)/) {|s| '~~~~'} #seperator body . gsub! ( / ( \\[ \\[ )( \\w +) \\s (.+?)( \\] \\] ) / , '[[\\3|\\2]]' ) #body.gsub!(/\\[\\[(\\w+)\\s(.+)\\]\\]/, ' [[\\1 | \\2]] ') # TODO more syntax conversion for links and images", "commit_type": "improve"}
{"commit_tokens": ["Remove", "the", "need", "to", "append", "to", "the", "buffer", "for", "every", "character"], "add_tokens": "bench \"Parser.parse with headers and large body\" , \"CONNECT\\ncontent-length:#{large_body.bytesize}\\n\\n#{large_body}\\x00\" do | message |", "del_tokens": "large_binary = \"b\\x00\" * ( ( Stompede :: Stomp :: Parser . max_message_size / 2 ) - 50 ) # make room for headers bench \"Parser.parse with headers and large body\" , \"CONNECT\\ncontent-length:#{large_binary.bytesize}\\n\\n#{large_binary}\\x00\" do | message |", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "round?", "/", "beginning?", "dichotomy"], "add_tokens": "def round? ( tm )", "del_tokens": "def round? ( tm ) round ( tm ) == tm end def beginning? ( tm )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ERB", "to", "benchmark", "comparison"], "add_tokens": "require 'erb' max = 20000 scope = { :range => ( 1 .. max ) . map { | i | { :i => i } } } x . report ( :erb ) { tpl = ERB . new ( %Q{<% (1..max).each do |i| %><%= i %>, <% end %>} ) tpl . result }", "del_tokens": "max = 50000 scope = { :range => ( 1 .. max ) . map { | i | { :i => i } } }", "commit_type": "add"}
{"commit_tokens": ["Fix", "array", "except!", "method", "to", "modify", "self"], "add_tokens": "self . reject! { | item | items . include? item }", "del_tokens": "# TODO except! should moodify self not a copy copy = self . dup copy . reject! { | item | items . include? item } copy", "commit_type": "fix"}
{"commit_tokens": ["Moving", "perishable", "inclusion", "to", "active_record", "devise", "to", "include", "just", "once", ".", "Also", "refactor", "confirm!", "method", "."], "add_tokens": "before_create :reset_perishable_token unless_confirmed do # Checks whether the record is confirmed or not, yielding to the block if # it's already confirmed, otherwise adds an error to email. # def unless_confirmed unless confirmed? yield else errors . add ( :email , :already_confirmed , :default => 'already confirmed' ) false end end", "del_tokens": "require 'devise/models/perishable' include :: Devise :: Models :: Perishable unless confirmed? else errors . add ( :email , :already_confirmed , :default => 'already confirmed' ) false", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "force", "browserifying", "all", "assets", "with", "a", "config", "var"], "add_tokens": "config . force || ( in_path? && ! browserified? && commonjs_module? )", "del_tokens": "in_path? && ! browserified? && commonjs_module?", "commit_type": "add"}
{"commit_tokens": ["Add", "txn_type", "field", "to", "Request"], "add_tokens": ":order_currency , :avs_result , :cvv_result , :txn_type :cvv_result => @cvv_result , :txn_type => @txn_type", "del_tokens": ":order_currency , :avs_result , :cvv_result :cvv_result => @cvv_result", "commit_type": "add"}
{"commit_tokens": ["move", "creds", "over", "to", "xml", "builder"], "add_tokens": "if opts [ k ] != nil xml . attributes [ k ] = \"#{opts[k]}\" end end", "del_tokens": "xml . attributes [ k ] = \"#{opts[k]}\" end", "commit_type": "move"}
{"commit_tokens": ["Changed", "add_deploy", "to", "add", "-", "deploy"], "add_tokens": "c . command ( :' add-bucket ' ) do | c | c . syntax 'add-bucket [options]'", "del_tokens": "c . command ( :add_bucket ) do | c | c . syntax 'add_bucket [options]'", "commit_type": "change"}
{"commit_tokens": ["removed", "some", "cruft", "specific", "to", "my", "personal", "host"], "add_tokens": "@socket . puts ( \"USER #{nick} #{nick} servername :TestUser\\n\" ) elsif data =~ / PING ( \\S +) / @socket . puts ( \":#{$1} PONG #{$1} :#{$1}\\n\" )", "del_tokens": "@socket . puts ( \"USER #{nick} #{nick} ec2a-live.jasonantman.com :Jason Antman\\n\" ) elsif data =~ / PING / @socket . puts ( \":ec2a-live.jasonantman.com PONG ec2a-live.jasonantman.com :ec2a-live.jasonantman.com\\n\" )", "commit_type": "remove"}
{"commit_tokens": ["Use", "full", "lexer", "name", "in", "config", "file"], "add_tokens": "@lexer = Lexer . find_by_name ( attributes [ :lexer ] || name ) ||", "del_tokens": "@lexer = Lexer . find_by_alias ( attributes [ :lexer ] || default_alias_name ) ||", "commit_type": "use"}
{"commit_tokens": ["added", "formatting", "to", "comments", "too"], "add_tokens": "", "del_tokens": "# Format content using the {Blogit::Configuration#default_parser_class default_parser_class} def format_content ( content = nil , & block ) content = capture ( & block ) if block_given? parser = Blogit :: configuration . default_parser_class . new ( content ) parser . parsed . html_safe end", "commit_type": "add"}
{"commit_tokens": ["Add", "total", "time", "to", "profile", "report", "."], "add_tokens": "total_time = records . reduce ( :+ ) average = total_time / total_calls :total_calls => total_calls , :total_time => total_time", "del_tokens": "average = records . reduce ( :+ ) / total_calls :total_calls => total_calls", "commit_type": "add"}
{"commit_tokens": ["add", "thread", "mngr", "to", "socket", "srvr", "and", "java", "specific", "stuff"], "add_tokens": "@socket . closed? @socket . flush log_debug \"[client-#{self.class}] write closed\"", "del_tokens": "@socket . closed? log_debug \"[client-#{self.class}] Write closed.\"", "commit_type": "add"}
{"commit_tokens": ["Make", "classes", "go", "back", "to", "strings", "for", "rails", "2", "compatibility"], "add_tokens": "let ( :date ) { Date . new ( 2000 , 12 , 25 ) } before { Timely . stub ( :current_date ) . and_return ( date ) } :class => 'datepicker input-small' ,", "del_tokens": "before { Timely . stub ( :current_date ) . and_return ( Date . new ( 2000 , 12 , 25 ) ) } :class => %w( datepicker input-small ) ,", "commit_type": "make"}
{"commit_tokens": ["add", "test", "support", "for", "stripe", "customer", "id"], "add_tokens": "client_id : PlaidRails . client_id , secret : PlaidRails . secret , public_key : PlaidRails . public_key ) } expect ( assigns ( :plaid_accounts ) . size ) . to eq 5 describe \"stripe token\" do let ( :plaid_account ) { client . accounts . get ( access_token ) . accounts . find { | a | a . subtype = 'checking' } } let ( :account ) { create ( :account , access_token : access_token , plaid_id : plaid_account . account_id ) } it \"get stripe_token\" do get :stripe_token , id : account . id expect ( response ) . to be_successful json = JSON . parse ( response . body ) expect ( json [ 'id' ] ) . to_not be_nil end end", "del_tokens": "client_id : PlaidRails . client_id , secret : PlaidRails . secret , public_key : PlaidRails . public_key ) } expect ( assigns ( :plaid_accounts ) . size ) . to eq 4", "commit_type": "add"}
{"commit_tokens": ["Remove", "fakeredis", "gem", "start", "to", "fix", "urls"], "add_tokens": "let ( :redis_url ) { 'redis://localhost' } expect ( redis . client . options [ :url ] ) . to eq ( redis_url )", "del_tokens": "let ( :redis_url ) { 'redis://redis.example.com' } expect ( redis . options [ :url ] ) . to eq ( redis_url )", "commit_type": "remove"}
{"commit_tokens": ["Add", "sensible", "nameOverride", "for", "objects"], "add_tokens": "assert_equal ( \"DKOtherSubObjectModel\" , class_name_from_path ( \"DK\" , path , schema ) )", "del_tokens": "assert_equal ( \"DKOtherObjectOtherSubObjectModel\" , class_name_from_path ( \"DK\" , path , schema ) )", "commit_type": "add"}
{"commit_tokens": ["Allow", "toolbar", "tabs", "to", "be", "configurable"], "add_tokens": "def assets_toolbar ( tabs = nil ) tabs = AmpleAssets . tabs if tabs . nil? script += \"ample_assets.pages = #{tabs.to_json}\" content_tag :script , script . html_safe , :type => \"text/javascript\"", "del_tokens": "def assets_toolbar ( pages = nil ) pages = ample_assets_pages if pages . nil? script += pages content_tag :script , script , :type => \"text/javascript\" end # TODO: move this to YAML def ample_assets_pages \" \\n ample_assets . pages = [ { id : 'recent-assets' , title : 'Recently Viewed' , url : '#{ample_assets.recent_files_path}' , panels : true , data_type : 'json' } , { id : 'image-assets' , title : 'Images' , url : '#{ample_assets.images_files_path}' , panels : true , data_type : 'json' } , { id : 'document-assets' , title : 'Documents' , url : '#{ample_assets.documents_files_path}' , panels : true , data_type : 'json' } , { id : 'upload' , title : 'Upload' , url : '#{ample_assets.new_file_path}' } ] ; \".gsub(/\\s+/, \" \" )", "commit_type": "allow"}
{"commit_tokens": ["added", "tests", "and", "fixed", "rake", "task", "for", "test", "environment"], "add_tokens": "\"(cd #{Base.root};rake MOBILIZE_ENV=#{Base.env} mobilize:work) >> #{Resque.log_path} 2>&1 &\" . bash", "del_tokens": "\"(cd #{Base.root};rake mobilize:work) >> #{Resque.log_path} 2>&1 &\" . bash", "commit_type": "add"}
{"commit_tokens": ["remove", "explicit", "local", "variable", "assignment"], "add_tokens": "entity . pluralize . camelize ( :lower ) entity . pluralize . downcase", "del_tokens": "entity_name = entity . pluralize . camelize ( :lower ) entity_name = entity . pluralize . downcase entity_name", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "issues", "with", "streaming", "responses", "."], "add_tokens": "out_type = begin streaming? ? rpc_desc . output . type : rpc_desc . output streaming? ? \"[#{out_type}]\" : out_type arrayify_hashes normalize_result @service_stub . send ( * args ) def normalize_result ( result ) if result . is_a? ( Enumerator ) [ ] . tap { | arr | result . each { | e | arr << e } } else result . to_hash end end def streaming? rpc_desc . output . is_a? ( GRPC :: RpcDesc :: Stream ) end", "del_tokens": "begin rpc_desc . output . is_a? ( GRPC :: RpcDesc :: Stream ) ? rpc_desc . output . type : rpc_desc . output result_hash = @service_stub . send ( * args ) . to_hash arrayify_hashes ( result_hash )", "commit_type": "fix"}
{"commit_tokens": ["Add", "doc", "for", "built", "-", "in", "tools", "module"], "add_tokens": "module BuiltInTools module Basic", "del_tokens": "module Tools module BasicTool", "commit_type": "add"}
{"commit_tokens": ["remove", "usage", "of", "env", "var", "because", "it", "isn", "t", "a", "requirement"], "add_tokens": "cmd = \"java -jar #{@jarpath} --update #{api_id} #{swagger_file}\"", "del_tokens": "cmd = \"java -jar #{@jarpath} --update #{api_id} --region #{ENV['AWS_REGION']} #{swagger_file}\"", "commit_type": "remove"}
{"commit_tokens": ["Updated", "page_links", "to", "allow", "for", "innter", "and", "outer", "spreads"], "add_tokens": "attr_accessor :any , :relationship_name , :sql def any? any == true end next if association . conditions . blank? def sanitize conditions = merge_conditions ( * ( objects . collect { | object | object . sanitize } << { :any => any } ) ) merged_conditions = merge_conditions ( conditions , sql , :any => any ) if object . class < Searchgasm :: Conditions :: Base", "del_tokens": "attr_accessor :relationship_name , :sql def sanitize ( any = false ) conditions = merge_conditions ( * objects . collect { | object | object . sanitize } ) merged_conditions = merge_conditions ( conditions , sql ) case object when self . class", "commit_type": "update"}
{"commit_tokens": ["fix", "Repository", ".", "published_in", "and", "add", "more", "expansive", "test", "case", "for", "it"], "add_tokens": "next false unless pub . Sources . any? do | src | src . Name == self . Name yield pub if block_given? true", "del_tokens": "pub . Sources . each do | src | next false unless src . Name == self . Name yield repo if block_given? true", "commit_type": "fix"}
{"commit_tokens": ["allow", "params", "to", "it", "()"], "add_tokens": "def it ( * , & spec )", "del_tokens": "def it ( & spec )", "commit_type": "allow"}
{"commit_tokens": ["Change", "#delete", "to", "accept", "only", "params"], "add_tokens": "def delete ( params = { } ) request :delete , params end", "del_tokens": "def delete ( data = { } , params = { } ) request :delete , params . merge ( data : data ) end", "commit_type": "change"}
{"commit_tokens": ["Adds", "placeholder", "integration", "test", "task", ".", "Removes", "requirement", "for", "linting", "to", "pass", "for", "a", "successful", "build", ".", "Will", "add", "it", "back", "on", "major", "release", "."], "add_tokens": "unless vpc_subnet_ids . empty? && vpc_security_group_ids . empty? vpc_configuration = { subnet_ids : vpc_subnet_ids , security_group_ids : vpc_security_group_ids } end a = if ! func_alias @client . create_alias ( function_name : function_name , name : alias_name , function_version : func_version , description : 'created by an automated script' ) . data else @client . update_alias ( function_name : function_name , name : alias_name , function_version : func_version , description : 'updated by an automated script' ) . data end", "del_tokens": "vpc_configuration = { subnet_ids : vpc_subnet_ids , security_group_ids : vpc_security_group_ids } unless vpc_subnet_ids . empty? && vpc_security_group_ids . empty? if ! func_alias a = @client . create_alias ( function_name : function_name , name : alias_name , function_version : func_version , description : 'created by an automated script' ) . data else a = @client . update_alias ( function_name : function_name , name : alias_name , function_version : func_version , description : 'updated by an automated script' ) . data end", "commit_type": "add"}
{"commit_tokens": ["add", "specs", "for", "option", "passing", "strip", "failover", "options"], "add_tokens": "client_options = options . dup client_options . delete_if { | k , _ | self . class . config_attributes . keys . include? ( k ) } @client_pool = pool . new hosts , client_options", "del_tokens": "@client_pool = pool . new hosts , options", "commit_type": "add"}
{"commit_tokens": ["Adding", "ability", "to", "set", "the", "session", "key", "per", "call", "to", "the", "log_action", "method", "."], "add_tokens": "session_key = opts . delete ( :session_key ) if session_key or @session params [ :sessionKey ] = session_key ? session_key : ( @session ? @session : nil ) end", "del_tokens": "params [ :sessionKey ] = @session if @session", "commit_type": "add"}
{"commit_tokens": ["Add", "disabled_roles", "support", "and", "testing"], "add_tokens": "# config.disabled_roles # Which roles should be displayed as disabled # config.disabled_roles = { config . disabled_roles = { 'User' => [ :member ] }", "del_tokens": "# config.unassignable_roles # Which roles should be prevented from being assigned at all # config.assignable_roles = {", "commit_type": "add"}
{"commit_tokens": ["Added", "alternative", "way", "to", "display", "temps", "..", "as", "i", "find", "it", "easier", "to", "read", "when", "aligned", "..", "also", "added", "rounding"], "add_tokens": "display = sensors [ 'AltDisplay' ] t = SMC . is_key_supported ( key ) . round ( 2 ) ; thresholds = sensors [ key ] [ 'thresholds' ] [ 1 .. - 2 ] . split ( / , / ) . map { | s | s . to_i } if ( display ) puts \"#{key} #{t}#{Symbols.degree}C \\t\" + Printer . gen_sparkline ( t , thresholds ) + \" #{sensors[key]['name']}\" else puts \"#{key} #{sensors[key]['name']} temp: #{t}#{Symbols.degree}C \" + Printer . gen_sparkline ( t , thresholds ) end", "del_tokens": "t = SMC . is_key_supported ( key ) ; thresholds = sensors [ key ] [ 'thresholds' ] [ 1 .. - 2 ] . split ( / , / ) . map { | s | s . to_i } puts \"#{key} #{sensors[key]['name']} temp: #{t}#{Symbols.degree}C \" + Printer . gen_sparkline ( t , thresholds )", "commit_type": "add"}
{"commit_tokens": ["Allow", "whendelivered", "to", "be", "passed", "to", "SMS"], "add_tokens": "# * :whendelivered - Callback URL that will receive a POST after delivery if parameters . fetch ( :flash ) { false } arguments [ :flashsms ] = \"yes\" end if parameters . key? ( :whendelivered ) arguments [ :whendelivered ] = parameters . fetch ( :whendelivered ) end", "del_tokens": "arguments [ :flashsms ] = \"yes\" if parameters . fetch ( :flash ) { false }", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "the", "new", "OTP", "(", "One", "-", "Time", "-", "Password", ")", "endpoint", "."], "add_tokens": "CLIENT_VERSION = '1.2.0' require 'messagebird/otp'", "del_tokens": "CLIENT_VERSION = '1.1.0'", "commit_type": "add"}
{"commit_tokens": ["Add", "docs", "about", "what", "happens", "when", "a", "mount", "does", "not", "exist"], "add_tokens": "# Unmount the thing at the given path. If the mount does not exist, an error # will be raised.", "del_tokens": "# Unmount the thing at the given path.", "commit_type": "add"}
{"commit_tokens": ["fix", "parsing", "alias", "/", "define_method", "with", "dynamic", "symbol"], "add_tokens": "[ :alias , lhs [ 0 ] , rhs [ 0 ] , rhs [ 1 ] ] if lhs && rhs def on_dyna_symbol ( * args ) if args . length == 1 && args [ 0 ] [ args [ 0 ] , lineno ] end end def on_tstring_content ( str ) str end def on_xstring_add ( first , arg ) arg if first . nil? end [ :alias , args [ 1 ] [ 0 ] , args [ 2 ] [ 0 ] , line ] if args [ 1 ] && args [ 2 ] def on_module ( name , body = nil )", "del_tokens": "[ :alias , lhs [ 0 ] , rhs [ 0 ] , rhs [ 1 ] ] [ :alias , args [ 1 ] [ 0 ] , args [ 2 ] [ 0 ] , line ] def on_module ( name , body )", "commit_type": "fix"}
{"commit_tokens": ["fix", "random", "tests", "failing", "due", "to", "randomness"], "add_tokens": "describe Pluginator do it :test_loads_plugins_automatically_for_group do it :test_loads_plugins_automatically_for_group_type do it :test_loads_existing_extensions_symbol do it :test_loads_nested_plugins do", "del_tokens": "class PluginatorTest < MiniTest :: Unit :: TestCase def test_loads_plugins_automatically_for_group def test_loads_plugins_automatically_for_group_type def test_loads_existing_extensions_symbol def test_loads_nested_plugins", "commit_type": "fix"}
{"commit_tokens": ["add", "name", "for", "arg", "and", "blockarg", "node"], "add_tokens": "when :class , :module , :def , :arg , :blockarg", "del_tokens": "when :class , :module , :def", "commit_type": "add"}
{"commit_tokens": ["Remove", "GELF", "::", "Message", "fix", "a", "bug", "in", "deprecated", "wrapper", "."], "add_tokens": "@message = { } GELF :: Notifier . notify ( @message ) @message [ a ] @message [ a ] = value", "del_tokens": "@message = GELF :: Message . new GELF :: Notifier . notify @message . __send__ ( a ) @message . __send__ ( \"#{a}=\" , value )", "commit_type": "remove"}
{"commit_tokens": ["Add", "Mobility", "::", "Backend", "::", "ActiveRecord", "::", "QueryMethods", "module"], "add_tokens": "autoload :Columns , 'mobility/backend/active_record/columns' autoload :Table , 'mobility/backend/active_record/table' autoload :QueryMethods , 'mobility/backend/active_record/query_methods'", "del_tokens": "autoload :Columns , 'mobility/backend/active_record/columns' autoload :Table , 'mobility/backend/active_record/table'", "commit_type": "add"}
{"commit_tokens": ["Use", "protocol", "-", "relative", "URL", "when", ":", "ssl", "is", "false"], "add_tokens": "RECAPTCHA_API_SERVER_URL = '//www.google.com/recaptcha/api'", "del_tokens": "RECAPTCHA_API_SERVER_URL = 'http://www.google.com/recaptcha/api'", "commit_type": "use"}
{"commit_tokens": ["Adding", "negative", "stylesheet", "tests", "and", "fixing", "them", ".", "Thanks", "to", "Niko", "for", "finding", "problems", "when", "a", "pattern", "is", "not", "matched", ".", "Duh", "to", "me!"], "add_tokens": "end # when caching on for javascript # Stylesheet end # when caching on for stylesheets context \"minifying a non-existent pattern in a stylesheet\" do setup { @himom = \"hi{mom:super-awesome}\" } should \"succeed when no spaces to compress\" do actual = @himom assert_equal @himom , Smurf :: Stylesheet . new ( actual ) . minified end # Thanks to someone named Niko for finding this should \"succeed for removing comments\" do actual = \"hi { mom: super-awesome; } \" assert_equal @himom , Smurf :: Stylesheet . new ( actual ) . minified end should \"succeed when no spaces to compress\" do actual = @himom assert_equal @himom , Smurf :: Stylesheet . new ( actual ) . minified end should \"succeed when no outside or inside blocks\" do # nothing outside, means nothing inside. they are complementary actual = \"how-did: this-happen; typo: maybe;}\" expected = \"how-did: this-happen; typo: maybe}\" assert_equal expected , Smurf :: Stylesheet . new ( actual ) . minified end should \"succeed when no last semi-colon in block\" do actual = \"hi { mom: super-awesome } \" assert_equal @himom , Smurf :: Stylesheet . new ( actual ) . minified end should \"succeed across all parsers when no content provided\" do actual = \"\" assert_equal \"\" , Smurf :: Stylesheet . new ( actual ) . minified end should \"succeed if nil provided\" do assert_nil Smurf :: Stylesheet . new ( nil ) . minified end end # minifying a non-existent pattern", "del_tokens": "end end", "commit_type": "add"}
{"commit_tokens": ["Allow", ".", "txt", "files", "in", "source", "directory", "."], "add_tokens": "Dir [ root . join ( \"source/**/*.{html,erb,md,builder,xml,txt}\" ) . to_s ]", "del_tokens": "Dir [ root . join ( \"source/**/*.{html,erb,md,builder,xml}\" ) . to_s ]", "commit_type": "allow"}
{"commit_tokens": ["use", "assert_match", "and", "update", "bz", "version"], "add_tokens": "# https://bugzilla.gnome.org/ is at 4.4.12 as of Jun/2016 assert_match ( / 4.4 / , ret ) # https://bugzilla.suse.com is at 4.4.6 as of Jan/2015 assert_match ( / 4.4 / , ret )", "del_tokens": "assert ret =~ / 3.4 / # https://bugzilla.gnome.org/ is at 3.4.13 as of Jan/2015 assert ret =~ / 4.4 / # https://bugzilla.suse.com is at 4.4.6 as of Jan/2015", "commit_type": "use"}
{"commit_tokens": ["improve", "tests", "and", "time", "methods"], "add_tokens": "# @param ms [Boolean] whether to return epoch milliseconds def parse_time ( t , ms = false ) # Numbers, or things that look like numbers, pass straight # through. No validation, because maybe the user means one # second past the epoch, or the year 2525. # if t . is_a? ( String ) return t . to_i if t . match ( / ^ \\d +$ / ) begin t = DateTime . parse ( \"#{t} #{Time.now.getlocal.zone}\" ) rescue raise Wavefront :: Exception :: InvalidTimestamp end end ms ? t . to_datetime . strftime ( '%Q' ) . to_i : t . strftime ( '%s' ) . to_i # Convert an epoch timestamp into epoch milliseconds. If the # timestamp looks like it's already epoch milliseconds, return # it as-is. return t if t . to_s . size == 13", "del_tokens": "def parse_time ( t ) return t . to_i if t . is_a? ( Time ) return t . to_i if t . is_a? ( String ) && t . match ( / ^ \\d +$ / ) DateTime . parse ( \"#{t} #{Time.now.getlocal.zone}\" ) . to_time . utc . to_i rescue raise Wavefront :: Exception :: InvalidTimestamp # Convert an epoch timestamp into epoch milliseconds.", "commit_type": "improve"}
{"commit_tokens": ["Fix", "bug", "for", "when", "max_expansions", "is", "not", "respected"], "add_tokens": "if ( new_tokens . size >= max_expansions ) break end", "del_tokens": "if ( per_word_greeklish . size >= max_expansions ) break end", "commit_type": "fix"}
{"commit_tokens": ["Added", "caching", "for", "converting", "YAML", "strings", "to", "MetaMap", "metadata", "nodes"], "add_tokens": "require_relative \"../metadata.rb\" Paru :: Metadata . from_yaml yaml_string", "del_tokens": "json_string = Pandoc . new do from \"markdown\" to \"json\" end << yaml_string meta_doc = PandocFilter :: Document . from_JSON json_string meta_doc . meta . to_meta_map", "commit_type": "add"}
{"commit_tokens": ["Add", "retry", "logic", "to", "pubsub", "pull"], "add_tokens": "events = pull_with_retry subscription def pull_with_retry sub events = [ ] retries = 0 while retries <= 5 do events = sub . pull break if events . any? retries += 1 puts \"the subscription does not have the message yet. sleeping for #{retries*retries} second(s) and retrying.\" sleep retries * retries end events end", "del_tokens": "events = subscription . pull", "commit_type": "add"}
{"commit_tokens": ["Implemented", "a", "mock", "ApiClient", "object", "for", "testing", "purposes", "."], "add_tokens": "initUser ( ) initUser ( ) initUser ( ) initUser ( ) @user . api_client . setResponse ( 200 , { 'hash' => @testdata [ 'definition_hash' ] , 'created_at' => Time . now . strftime ( '%Y-%m-%d %H:%M:%S' ) , 'cost' => 10 , } , 200 , 150 ) assert @user . rate_limit == 200 assert @user . rate_limit_remaining == 150", "del_tokens": "@user = DataSift :: User . new ( @config [ 'username' ] , @config [ 'api_key' ] ) @user = DataSift :: User . new ( @config [ 'username' ] , @config [ 'api_key' ] ) @user = DataSift :: User . new ( @config [ 'username' ] , @config [ 'api_key' ] ) @user = DataSift :: User . new ( @config [ 'username' ] , @config [ 'api_key' ] ) assert @user . rate_limit != - 1 assert @user . rate_limit_remaining != - 1", "commit_type": "implement"}
{"commit_tokens": ["Move", "sha", "from", "Reporter", "to", "Checkout"], "add_tokens": "\"https://github.com/#{config.reponame}/compare/#{checkout.sha}...master\" version = checkout . sha body << \"version #{checkout.sha} ([compare to master](#{compare_url})).\"", "del_tokens": "\"https://github.com/#{config.reponame}/compare/#{sha}...master\" def sha Dir . chdir ( config . repodir ) { ` git rev-parse HEAD ` . strip } end version = sha body << \"version #{sha} ([compare to master](#{compare_url})).\"", "commit_type": "move"}
{"commit_tokens": ["Add", "has_many", "with", "class", "name", "and", "order", "by", "options"], "add_tokens": "describe \"#==\" do it \"defines equality semantically\" do Blog . order_by ( :user_id . asc , :title . desc ) . should == Blog . order_by ( :user_id . asc , :title . desc ) end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["remove", "printer", "to", "make", "perf", "a", "little", "better"], "add_tokens": "opts . on ( \"-o\" , \"--output CSV\" , \"output path to csv file. if omit, print to output.csv\" ) do | output | out_file_name = options . has_key? ( :output ) ? options [ :output ] : 'output.csv' puts \"printing to file: #{out_file_name} ...\" File . open ( out_file_name , 'w' ) do | file | generator . print_to file", "del_tokens": "opts . on ( \"-o\" , \"--output CSV\" , \"output path to csv file. if omit, print to STDOUT\" ) do | output | printer = FakedCSV :: Printer . new ( generator . headers , generator . rows ) s = printer . print unless options . has_key? :output puts s return end begin File . open options [ :output ] , 'w' do | f | f . write s end rescue Exception => e puts \"error writing to csv file: #{e.to_s}\" exit 2", "commit_type": "remove"}
{"commit_tokens": ["Add", "cursor", "to", "the", "results", "of", "a", "query"], "add_tokens": "run_query = new_run_query_request query . to_proto results = Array ( response . batch . entity_result ) . map do | result | Gcloud :: Datastore :: List . new results , encode_cursor ( response . batch . end_cursor ) def new_run_query_request query_proto Proto :: RunQueryRequest . new . tap do | rq | rq . query = query_proto end end def encode_cursor cursor Array ( cursor ) . pack ( \"m\" ) . chomp end ## # List is a special case Array with cursor. # # entities = Gcloud::Datastore::List.new [entity1, entity2, entity3] # entities.cursor = \"c3VwZXJhd2Vzb21lIQ\" class List < DelegateClass ( :: Array ) attr_accessor :cursor def initialize arr = [ ] , cursor = nil super arr @cursor = cursor end end", "del_tokens": "run_query = Proto :: RunQueryRequest . new run_query . query = query . to_proto Array ( response . batch . entity_result ) . map do | result |", "commit_type": "add"}
{"commit_tokens": ["added", "some", "quoting", "to", "keep", "mysql", "from", "barfing"], "add_tokens": "@ancestors ||= base_class . find :all , :conditions => [ \"`left` < ? AND `right` > ?\" , left , right ] , :order => '`left` DESC' base_class . count :conditions => [ \"`left` < ? AND `right` > ?\" , left , right ]", "del_tokens": "@ancestors ||= base_class . find :all , :conditions => [ \"left < ? AND right > ?\" , left , right ] , :order => 'left DESC' base_class . count :conditions => [ \"left < ? AND right > ?\" , left , right ]", "commit_type": "add"}
{"commit_tokens": ["add", "a", "preview?", "()", "helper", "method", "for", "controllers", "and", "views"], "add_tokens": "helper_method :preview? expire_fragment ( %r{ .*/preview/.* } ) end def preview? ContentfulModel . use_preview_api == true", "del_tokens": "expire_fragment ( %r{ ^preview/.* } )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", ":", "Referee#check_status", "was", "incorrectly", "reporting", "a", "winner", "on", "the", "2nd", "diagonal"], "add_tokens": "if board [ 1 , 3 ] == board [ 2 , 2 ] && board [ 2 , 2 ] == board [ 3 , 1 ]", "del_tokens": "if board [ 1 , 3 ] == board [ 2 , 2 ] && board [ 2 , 2 ] == board [ 1 , 3 ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "Cursor#to_a", "and", "more", "tests", "and", "docs", "."], "add_tokens": "@cache = [ ] o = @cache . shift # # If #to_a has already been called then this method uses the array # that we store internally. In that case, #each can be called multiple # times because it re-uses that array. if @rows # Already turned into an array @rows . each { | row | yield row } else num_returned = 0 while more? && ( @num_to_return <= 0 || num_returned < @num_to_return ) yield next_object ( ) num_returned += 1 end end end # Return all of the rows as an array. Calling this multiple times will # work fine; it always returns the same array. # # You can call #each after calling #to_a (multiple times even, because # it will use the internally-stored array), but you can't call #to_a # after calling #ach. def to_a return @rows if @rows @rows = [ ] @rows << next_object ( ) @rows @cache = [ ] @cache << doc refill_via_get_more if @cache . length == 0 @cache . length", "del_tokens": "@objects_returned = 0 @objects = [ ] o = @objects . shift yield next_object ( ) @objects = [ ] @objects << doc refill_via_get_more if @objects . length == 0 @objects . length", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "PHP", "errors", "to", "guess_status"], "add_tokens": "# extract response status from PHP 'failed to open stream' errors elsif head =~ / failed to open stream: / # HTTP request failed! HTTP/[version] [code] [message] if head =~ / failed to open stream: HTTP request failed! HTTP \\/ (0 \\. 9|1 \\. 0|1 \\. 1) ([ \\d ]+) / result [ \"code\" ] = \"#{$2}\" result [ \"message\" ] = '' if head =~ / failed to open stream: HTTP request failed! HTTP \\/ (0 \\. 9|1 \\. 0|1 \\. 1) [ \\d ]+ ([a-zA-Z ]+) / result [ \"message\" ] = \"#{$2}\" end # No route to host elsif head =~ / failed to open stream: No route to host in / result [ \"status\" ] = 'fail' result [ \"code\" ] = 502 result [ \"message\" ] = 'Bad Gateway' # Connection refused elsif head =~ / failed to open stream: Connection refused in / result [ \"status\" ] = 'fail' result [ \"code\" ] = 502 result [ \"message\" ] = 'Bad Gateway'", "del_tokens": "# extract response status from PHP error: # failed to open stream: HTTP request failed! HTTP/[version] [code] [message] elsif head =~ / failed to open stream: HTTP request failed! HTTP \\/ (0 \\. 9|1 \\. 0|1 \\. 1) ([ \\d ]+) / result [ \"code\" ] = $2 . to_s result [ \"message\" ] = '' if head =~ / failed to open stream: HTTP request failed! HTTP \\/ (0 \\. 9|1 \\. 0|1 \\. 1) [ \\d ]+ ([a-zA-Z ]+) / result [ \"message\" ] = $2 . to_s", "commit_type": "add"}
{"commit_tokens": ["Made", "friendly_id", "raise", "an", "error", "with", "an", "informative", "message", "if", "the", "method", "used"], "add_tokens": "base = self . send ( friendly_id_options [ :method ] . to_sym ) if base . blank? raise SlugGenerationError . new ( \"The method or column used as the base of friendly_id's slug text returned a blank value\" ) end Slug :: normalize ( strip_diacritics ( base ) ) Slug :: normalize ( base )", "del_tokens": "Slug :: normalize ( strip_diacritics ( send ( self . friendly_id_options [ :method ] . to_sym ) ) ) Slug :: normalize ( send ( self . friendly_id_options [ :method ] . to_sym ) )", "commit_type": "make"}
{"commit_tokens": ["fixed", "a", "problem", "with", "the", "ssh", "loop", "this", "should", "done", "within", "a", "transaction", "and", "not", "before"], "add_tokens": "#versionfile=File.join(@tmp_dir,\".vbox_version\") #File.open(versionfile, 'w') {|f| f.write(\"#{VirtualBox::Global.global.lib.virtualbox.version}\") } #Veewee::Ssh.transfer_file(\"localhost\",versionfile,ssh_options) Veewee :: Ssh . when_ssh_login_works ( \"localhost\" , ssh_options ) do end counter += 1 puts \"Current step: #{current_step_nr}\"", "del_tokens": "Veewee :: Ssh . when_ssh_login_works ( \"localhost\" , ssh_options ) do versionfile = File . join ( @tmp_dir , \".vbox_version\" ) File . open ( versionfile , 'w' ) { | f | f . write ( \"#{VirtualBox::Global.global.lib.virtualbox.version}\" ) } Veewee :: Ssh . transfer_file ( \"localhost\" , versionfile , ssh_options ) counter += 1 end", "commit_type": "fix"}
{"commit_tokens": ["remove", "redundant", "require", "and", "use", "let"], "add_tokens": "let ( :client ) { test_person . extend ( Casting :: Client , Casting :: MissingMethodClient ) } let ( :client ) { test_person . extend ( Casting :: Client , Casting :: MissingMethodClient ) }", "del_tokens": "require 'casting/client' def client @client ||= test_person . extend ( Casting :: Client , Casting :: MissingMethodClient ) end def client @client ||= test_person . extend ( Casting :: Client , Casting :: MissingMethodClient ) end", "commit_type": "remove"}
{"commit_tokens": ["add", "test", "case", "for", "objects", "that", "return", "non", "-", "Class", "objects", "for", "class"], "add_tokens": "@class_name_cache [ klass ] ||= ( klass . is_a? ( Class ) && klass . name ) || '<<Unknown>>'", "del_tokens": "@class_name_cache [ klass ] ||= ( klass && klass . respond_to? ( :name ) && klass . name ) || '<<Unknown>>'", "commit_type": "add"}
{"commit_tokens": ["Makes", "Rack", "::", "Rescue", "layout", "aware"], "add_tokens": "it \"should wrap the error in a layout if there's one present\" do endpoint = raise_endpoint ( RuntimeError , \"Bad Error\" ) layout_dir = File . join ( File . expand_path ( File . dirname ( __FILE__ ) ) , 'rack' , 'rescue' , 'fixtures' , 'layouts' ) File . exists? ( File . join ( layout_dir , \"error.html.erb\" ) ) . should be_true app = Rack :: Builder . new do use Wrapt do | wrapt | wrapt . layout_dirs << layout_dir end use Rack :: Rescue run endpoint end env = Rack :: MockRequest . env_for ( \"/foo.html\" ) r = app . call ( env ) r [ 0 ] . should == 500 body = r [ 2 ] . body . to_s body . should include ( \"<h1>Error Layout</h1>\" ) end", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Add", "pooled", "Redis", "connection", "and", "setup", "specs"], "add_tokens": "RSpec . describe Attention do describe '.redis' do subject { Attention . redis } it { is_expected . to be_a Proc } its ( :call ) { is_expected . to be_a Redis :: Namespace } end describe '.options' do subject { Attention . options } its ( [ :namespace ] ) { is_expected . to eql 'attention' } its ( [ :ttl ] ) { is_expected . to eql 60 } its ( [ :redis_url ] ) { is_expected . to eql 'redis://localhost:6379/0' } its ( [ :pool_size ] ) { is_expected . to eql 5 } its ( [ :timeout ] ) { is_expected . to eql 5 } end", "del_tokens": "describe Attention do", "commit_type": "add"}
{"commit_tokens": ["Adds", "support", "for", "Google", "Apps", "for", "the", "domain", "."], "add_tokens": "autoload :GoogleApps , 'omniauth/strategies/google_apps'", "del_tokens": "autoload :Google , 'omniauth/strategies/google'", "commit_type": "add"}
{"commit_tokens": ["Add", "Awspec", "::", "Generator", "::", "Spec", "::", "SecurityGroup", ".", "generate_from_vpc"], "add_tokens": "route_tables = select_route_table_by_vpc_id ( @vpc_id ) network_acls = select_network_acl_by_vpc_id ( @vpc_id )", "del_tokens": "route_tables = select_route_table_by_vpc_id ( vpc_id ) network_acls = select_network_acl_by_vpc_id ( vpc_id )", "commit_type": "add"}
{"commit_tokens": ["Make", "this", "variable", "name", "actually", "make", "sense"], "add_tokens": "using_binding = File . exist? ( File . join ( HUBS [ :binding ] , binding_string ) ) if using_binding", "del_tokens": "using_template = File . exist? ( File . join ( HUBS [ :binding ] , binding_string ) ) if using_template", "commit_type": "make"}
{"commit_tokens": ["Use", "in", "-", "memory", "sqlite", "DB", "for", "ActiveRecord", "tests", "."], "add_tokens": "ActiveRecord :: Base . establish_connection ( :adapter => \"sqlite3\" , :database => \":memory:\" )", "del_tokens": "config = YAML :: load ( IO . read ( File . dirname ( __FILE__ ) + \"/db/database.yml\" ) ) ActiveRecord :: Base . establish_connection ( config [ 'test' ] )", "commit_type": "use"}
{"commit_tokens": ["Move", "current", "path", "transformation", "to", "links_for_render"], "add_tokens": "id : nil , transform_current_path : true # Set current link to actual path if options [ :transform_current_path ] && out . any? && request out . last . url = request . fullpath end", "del_tokens": "id : nil # Set current link to actual path if links . any? && request links . last . url = request . fullpath end", "commit_type": "move"}
{"commit_tokens": ["fixed", "return", "of", "status", "code"], "add_tokens": "return [ status . exitstatus , stdout , stderr ]", "del_tokens": "return [ status , stdout , stderr ]", "commit_type": "fix"}
{"commit_tokens": ["made", ".", "*", "greedy", "so", "it", "continues", "to", "match", "the", "whole", "repo", "name"], "add_tokens": "if m = / github \\. com.(.*?) \\/ (.*) \\. git / . match ( u )", "del_tokens": "if m = / github \\. com.(.*?) \\/ (.*?) \\. git / . match ( u )", "commit_type": "make"}
{"commit_tokens": ["Fix", "key", "in", "hash", "of", "__coercers__"], "add_tokens": "{ :\" option_ #{ source } \" => value }", "del_tokens": "{ :\" option_ #{ target } \" => value }", "commit_type": "fix"}
{"commit_tokens": ["removed", "old", "seed", "files", "."], "add_tokens": "let ( :file_path ) { './lib/utf8_sanitizer/csv/seed.csv' }", "del_tokens": "let ( :file_path ) { './lib/utf8_sanitizer/csv/seeds_dirty_1.csv' }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "geometry", "column", "nonsense", "."], "add_tokens": "GEOMETRY_COLUMN_OUTPUT_FORMATS = %w{ geos wkt wkb ewkt ewkb wkb_bin ewkb_bin } . freeze GEOMETRY_COLUMN_OUTPUT_FORMATS . reject { | f | f == 'geos' } . each do | f |", "del_tokens": "GEOMETRY_COLUMN_OUTPUT_FORMATS = %{ geos wkt wkb ewkt ewkb wkb_bin ewkb_bin } . freeze GEOMETRY_COLUMN_OUTPUT_FORMATS . reject { | f | f == :geos } . each do | f |", "commit_type": "fix"}
{"commit_tokens": ["Added", "accessor", "to", "aid", "unit", "testing"], "add_tokens": "@uri = 'https://vcoserver.example.com:8281' vs = VcoWorkflows :: VcoSession . new ( @uri , user : @username , password : @password ) api_url = '/vco/api' expect ( vs . rest_resource . url ) . to eql ( @uri << api_url ) vs = VcoWorkflows :: VcoSession . new ( @uri , user : @username , password : @password ) expect ( vs . rest_resource . user ) . to eql ( @username ) vs = VcoWorkflows :: VcoSession . new ( @uri , user : @username , password : @password ) expect ( vs . rest_resource . password ) . to eql ( @password )", "del_tokens": "@url = 'https://vcoserver.example.com:8281/' vs = VcoWorkflows :: VcoSession . new ( @url , user : @username , password : @password ) expect ( vs . url ) . to eql ( @url ) vs = VcoWorkflows :: VcoSession . new ( @url , user : @username , password : @password ) expect ( vs . user ) . to eql ( @username ) vs = VcoWorkflows :: VcoSession . new ( @url , user : @username , password : @password ) expect ( vs . password ) . to eql ( @password )", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "default", "date", "to", "a", "time", "based", "value", "."], "add_tokens": "todays_date = ActiveRecord :: Base . default_timezone == :utc ? Time . now . utc : Time . now self . date ||= todays_date", "del_tokens": "self . date ||= Date . today", "commit_type": "change"}
{"commit_tokens": ["make", "sure", "queries", "run", "through", "the", "Sequel", "logger"], "add_tokens": "r = log_yield ( sql ) { conn . query ( sql ) }", "del_tokens": "# r = log_yield(sql){conn.query(sql)} r = conn . query ( sql )", "commit_type": "make"}
{"commit_tokens": ["Remove", "some", "duplication", "in", "specs", "."], "add_tokens": "before do @object = Object . new Looksee . stubs ( :lookup_modules ) . with ( @object ) . returns ( [ C , D ] ) end it \"should only include methods matching the given regexp\" do lookup_path = Looksee :: LookupPath . new ( @object , :public => true , :overridden => true ) . grep ( / x.y / ) lookup_path = Looksee :: LookupPath . new ( @object , :public => true , :overridden => true ) . grep ( 'xx' )", "del_tokens": "it \"should only include methods matching the given regexp\" do object = Object . new Looksee . stubs ( :lookup_modules ) . with ( object ) . returns ( [ C , D ] ) lookup_path = Looksee :: LookupPath . new ( object , :public => true , :overridden => true ) . grep ( / x.y / ) temporary_class :C temporary_class :D object = Object . new Looksee . stubs ( :lookup_modules ) . with ( object ) . returns ( [ C , D ] ) lookup_path = Looksee :: LookupPath . new ( object , :public => true , :overridden => true ) . grep ( 'xx' )", "commit_type": "remove"}
{"commit_tokens": ["add", "single", "param", "to", "source_route", ".", "add", "test", "for", "it"], "add_tokens": "def enable ( match = nil , & block ) wrapper . method_id ( match ) if match wrapper . instance_eval ( & block ) if block_given? trace = TracePoint . new wrapper . conditions [ :event ] do | tp | end trace . enable trace . enabled?", "del_tokens": "def enable ( & block ) wrapper . instance_eval ( & block ) TracePoint . new wrapper . conditions [ :event ] do | tp | end . enable", "commit_type": "add"}
{"commit_tokens": ["Allow", "numbers", "in", "column", "names", "."], "add_tokens": "if m = order . match ( / (([a-zA-Z._:][a-zA-Z._:0-9]*) \\s ([asc|ASC|desc|DESC]+)|[a-zA-Z._:][a-zA-Z._:0-9]*) / )", "del_tokens": "if m = order . match ( / (([a-zA-Z._:]+) \\s ([asc|ASC|desc|DESC]+)|[a-zA-Z._:]+) / )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "type", "of", "key", "in", "page", "object", "from", "symbol", "to", "string"], "add_tokens": "if page . key? ( \"chapters\" ) config [ :episode ] [ :chaptermarks ] = page [ \"chapters\" ] . map { | chapter | { start : chapter [ 0 .. 12 ] , title : chapter [ 13 .. 255 ] } }", "del_tokens": "if page . key? ( \"chapters\" . to_sym ) config [ \"episode\" ] [ \"chaptermarks\" ] = page [ \"chapters\" ] . map { | chapter | { start : chapter [ 0 .. 12 ] , title : chapter [ 13 .. 255 ] } }", "commit_type": "fix"}
{"commit_tokens": ["Added", "README", "with", "instructions", "that", "will", "displayed", "after", "the", "generator", "copies", "all", "files"], "add_tokens": "m . file \"app/controllers/application.rb\" , \"app/controllers/application.rb\" , :collision => :skip m . file 'app/models/user.rb' , 'app/models/user.rb' , :collision => :skip m . readme \"README\"", "del_tokens": "file = \"app/controllers/application.rb\" application_controller_exists = File . exists? ( destination_path ( file ) ) m . file file , file , :collision => :skip file = \"app/models/user.rb\" user_model_exists = File . exists? ( destination_path ( file ) ) m . file file , file , :collision => :skip m . readme \"USER_MODEL_EXISTS\" if user_model_exists m . readme \"APPLICATION_CONTROLLER_EXISTS\" if application_controller_exists", "commit_type": "add"}
{"commit_tokens": ["Added", "I18n", "KeyTracker", "example", "."], "add_tokens": "base_key = 'runtime_metrics:tracker:benchmarks'", "del_tokens": "base_key = 'runtime_metrics:key_tracker:benchmarks' # puts ex.inspect", "commit_type": "add"}
{"commit_tokens": ["Fixed", "commands", "to", "manager", "synx", "should", "invoke", "gem", "instead", "of", "brew"], "add_tokens": "` gem install synx ` ` gem update synx `", "del_tokens": "` brew install synx ` ` brew upgrade synx `", "commit_type": "fix"}
{"commit_tokens": ["Add", "accesors", "for", "min_width", "and", "min_height"], "add_tokens": "attr_accessor :folder , :filename , :user_agent , :max_wait , :delay , :output , :cutycapt_path , :min_width , :min_height", "del_tokens": "attr_accessor :folder , :filename , :user_agent , :max_wait , :delay , :output , :cutycapt_path", "commit_type": "add"}
{"commit_tokens": ["removed", "api", "call", "in", "generator"], "add_tokens": "puts \"Please manually configure your API keys in config/initializers/omniauth.rb\"", "del_tokens": "if @client_id == CLIENT_ID_DEFAULT get_info end", "commit_type": "remove"}
{"commit_tokens": ["Make", "sure", "the", "lenght", "of", "batch_no", "is", "24"], "add_tokens": "t = Time . now batch_no = t . strftime ( '%Y%m%d%H%M%S' ) + t . nsec . to_s batch_no . ljust ( 24 , Random . new . rand ( 1 .. 9 ) . to_s )", "del_tokens": "time = Time . now time . strftime ( '%Y%m%d%H%M%S' ) + time . nsec . to_s + Random . new . rand ( 1 .. 9 ) . to_s", "commit_type": "make"}
{"commit_tokens": ["fix", "cloning", "of", "compoundbaseunit", "bug"], "add_tokens": "# a denominator unit renderable in cases where there are no numerator units, # Physical quantity represented by self. This refers only to the unit, rather # than the unit together with the index. Is used to match base units with # similar units of same physical quantity # def deep_clone new = self . clone new . instance_variable_set ( \"@unit\" , unit . deep_clone ) return new end end", "del_tokens": "# a denominator unit renerable in case where there are no numerator units, end", "commit_type": "fix"}
{"commit_tokens": ["Fix", "documentation", "for", "nbsp", "."], "add_tokens": "# Returns a copy of value with spaces replaced by non-breaking space characters. # The output uses the entity-escaping format '&#160;' since that works", "del_tokens": "# Returns a non-breaking space character, using the entity-escaping format '&#160;' since that works", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "more", "tests", "."], "add_tokens": "test \"#{brand}should NOT post create #{awil_title(options)} and #{m_key} save fails\" do test \"#{brand}should NOT get edit #{awil_title(options)} and an invalid id\" do test \"#{brand}should NOT put update #{awil_title(options)} and an invalid id\" do test \"#{brand}should NOT get show #{awil_title(options)} and an invalid id\" do test \"#{brand}should NOT delete destroy #{awil_title(options)} and an invalid id\" do", "del_tokens": "test \"#{brand}should post create #{awil_title(options)} and #{m_key} save fails\" do test \"#{brand}should NOT get edit #{awil_title(options)} and invalid id\" do test \"#{brand}should NOT put update #{awil_title(options)} and invalid id\" do test \"#{brand}should NOT get show #{awil_title(options)} and invalid id\" do test \"#{brand}should NOT delete destroy #{awil_title(options)} and invalid id\" do", "commit_type": "add"}
{"commit_tokens": ["Added", "better", "error", "handling", "."], "add_tokens": "if response and response . respond_to? ( :response ) case response . response when Net :: HTTPClientError , Net :: HTTPServerError error = \"#{response.response.code} #{response.response.message}\" if response . is_a? ( Hash ) error = response [ 'error' ] end raise Taskrabbit :: Error . new ( error ) end", "del_tokens": "if response . is_a? ( Hash ) and ( error = response [ 'error' ] ) raise Taskrabbit :: Error . new ( error )", "commit_type": "add"}
{"commit_tokens": ["Fix", "default", "value", "for", "new", "item"], "add_tokens": "@@stock [ item ] = { 'total' => total . to_i , 'min' => options [ :minimum ] . to_i , 'url' => options [ :url ] , 'checked' => Time . now }", "del_tokens": "@@stock [ item ] = { 'total' => total . to_i , 'min' => options [ :min ] . to_i , 'url' => options [ :url ] , 'checked' => Time . now }", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "latest", "Rails", "and", "setup", "DB"], "add_tokens": "# https://github.com/rails/rails/commit/f9d23b3848ab81cfb5207e14ccabca3d2e9b3182 Pgcharmer :: Application . config . session_store :cookie_store , key : '_pgcharmer_session'", "del_tokens": "Pgcharmer :: Application . config . session_store :encrypted_cookie_store , key : '_pgcharmer_session'", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "remove", "padding", "adjustment", "."], "add_tokens": "# Measure total padding size for a table # # @return [Integer] # # @api public def padding_size padding = renderer . padding ( padding . left + padding . right ) * ( table . columns_size - 1 ) end renderer . column_widths . inject ( 0 , & :+ ) + border_size + padding_size # TODO - add padding size to fully check extra width", "del_tokens": "renderer . column_widths . inject ( 0 , & :+ ) + border_size unless renderer . padding . empty? renderer . column_widths = adjust_padding end # Adjust column widths to account for padding whitespace # # @api private def adjust_padding padding = renderer . padding column_size = table . columns_size ( 0 ... column_size ) . reduce ( [ ] ) do | lengths , col | lengths + [ padding . left + renderer . column_widths [ col ] + padding . right ] end end", "commit_type": "change"}
{"commit_tokens": ["fixed", "tests", "in", "inventory", "builder"], "add_tokens": "it 'should not add any dependencies of the cookbook to the local store' do it 'should not add any dependencies of the cookbook to the local store' do it 'should not add any resolved dependencies to the local store' do expect ( subject . local_store . installed? ( 'yum' , '3.5.1' ) ) . to_not eq true expect ( subject . local_store . installed? ( 'yum-mysql-community' , '0.1.10' ) ) . to_not eq true it 'should actually not add the dependent cookbooks to the local inventory' do expect ( Dir . exists? ( File . join ( test_directory , 'yum-3.5.1' ) ) ) . to_not eq true expect ( Dir . exists? ( File . join ( test_directory , 'yum-mysql-community-0.1.10' ) ) ) . to_not eq true", "del_tokens": "it 'should add any dependencies of the cookbook to the local store' do it 'should add any dependencies of the cookbook to the local store' do it 'should add any resolved dependencies to the local store' do expect ( subject . local_store . installed? ( 'yum' , '3.5.1' ) ) . to eq true expect ( subject . local_store . installed? ( 'yum-mysql-community' , '0.1.10' ) ) . to eq true it 'should actually add the dependent cookbooks to the local inventory' do expect ( Dir . exists? ( File . join ( test_directory , 'yum-3.5.1' ) ) ) . to eq true expect ( Dir . exists? ( File . join ( test_directory , 'yum-mysql-community-0.1.10' ) ) ) . to eq true", "commit_type": "fix"}
{"commit_tokens": ["fixed", "(", "hacked", ")", "error", ":", "can", "t", "add", "a", "new", "key", "into", "hash", "during", "iteration"], "add_tokens": "@after_nested_form_callbacks ||= [ ] fields = @after_nested_form_callbacks . map do | callback | @associations ||= [ ] @after_nested_form_callbacks ||= [ ] unless @associations . include? ( association ) @associations << association @after_nested_form_callbacks << block end", "del_tokens": "@after_nested_form_callbacks ||= { } fields = @after_nested_form_callbacks . map do | key , callback | @after_nested_form_callbacks ||= { } @after_nested_form_callbacks [ association ] = block", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "filtering", "of", "packets", "."], "add_tokens": "# Class for implementing a proxy to filter/mangle MQTT packets. # Create a new MQTT Proxy instance. # # Possible argument keys: # # :local_host Address to bind listening socket to. # :local_port Port to bind listening socket to. # :broker_host Address of upstream broker to send packets upstream to. # :broker_port Port of upstream broker to send packets upstream to. # :select_timeout Time in seconds before disconnecting a connection. # :logger Ruby Logger object to send informational messages to. # # Setup a logger @logger = args [ :logger ] if @logger . nil? @logger = Logger . new ( STDOUT ) @logger . level = Logger :: INFO end # Default is not to have any filters @client_filter = nil @broker_filter = nil @logger . info \"MQTT::Proxy listening on #{@local_host}:#{@local_port}\" # Set a filter Proc for packets coming from the client (to the broker). def client_filter = ( proc ) @client_filter = proc # Set a filter Proc for packets coming from the broker (to the client). def broker_filter = ( proc ) @broker_filter = proc # Start accepting connections and processing packets. logger . debug \"client -> <#{packet.type}>\" packet = @client_filter . call ( packet ) unless @client_filter . nil? unless packet . nil? broker_socket . write ( packet ) logger . debug \"<#{packet.type}> -> broker\" end logger . debug \"broker -> <#{packet.type}>\" packet = @broker_filter . call ( packet ) unless @broker_filter . nil? unless packet . nil? client_socket . write ( packet ) logger . debug \"<#{packet.type}> -> client\" end", "del_tokens": "# Class for implementing a MQTT proxy # Create a new MQTT Proxy instance @listen_queue = args [ :listen_queue ] || 1 @logger = args [ :logger ] || Logger . new ( STDOUT ) def add_downstream_proc def add_upstream_proc broker_socket . write ( packet ) logger . debug \"client->broker (#{packet.type})\" client_socket . write ( packet ) logger . debug \"broker->client (#{packet.type})\"", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "an", "exception", "when", "trying", "to", "fetch", "stats", "for", "a", "commit", "without", "them"], "add_tokens": "it \"should not die when trying to return stats for a commit without stats\" do commit = @repository . commits . by_hash_id ( '8173f122b0d0' ) commit . stats . must_equal { } end", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["add", "empty", "anchor", "to", "make", "TOC"], "add_tokens": "if anchor . empty? a_id = \"<a id=\\\"h\\\" />\" else", "del_tokens": "unless anchor . empty?", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "single", "log", "rather", "than", "every", "time", "its", "called"], "add_tokens": "class << self @@log ||= Logger . new ( $stdout )", "del_tokens": "class << self @logger ||= Logger . new ( $stdout )", "commit_type": "create"}
{"commit_tokens": ["Adds", "the", "specs", "for", "Finders", "::", "XMLRPC"], "add_tokens": "# @return [ Array<XMLRPC> ] # @return [ XMLRPC ] url = Browser . get ( target . url ) . headers [ 'X-Pingback' ] return unless target . in_scope? ( url ) # @return [ XMLRPC ] next unless target . in_scope? ( url ) # @return [ XMLRPC ] next unless target . in_scope? ( potential_url ) next unless res && res . body =~ / XML-RPC server accepts POST requests only /i found_by : 'Direct File Access (aggressive detection)' ) nil", "del_tokens": "# ## TODO: Ensure that the potential URLs found are in scope !!! # headers = Browser . get ( target . url ) . headers return unless headers . key? ( 'X-Pingback' ) url = headers [ 'X-Pingback' ] return unless url && url . length > 0 next unless url && url . length > 0 # @return [ InterestingFile ] next unless res && res . body =~ / XML-RPC server accepts POST requests onl /i found_by : 'Direct File Access (agressive detection)' )", "commit_type": "add"}
{"commit_tokens": ["make", "offset", "limit", "signature", "more", "consistent"], "add_tokens": "def followers ( offset = 0 , limit = 25 ) def following ( offset = 0 , limit = 25 , filter = [ ] )", "del_tokens": "def followers ( limit = 25 , offset = 0 ) def following ( limit = 25 , offset = 0 , filter = [ ] )", "commit_type": "make"}
{"commit_tokens": ["Remove", "Term", "::", "ANSIcolor", "from", "String", "scope", "class"], "add_tokens": "io . puts raw Kernel . exit ( 0 ) if options [ :exit ]", "del_tokens": "String . class_eval do include Term :: ANSIColor end io . puts raw . to_s . send ( options [ :color ] || :green ) . bold Kernel . exit ( 0 ) if options [ :exit ]", "commit_type": "remove"}
{"commit_tokens": ["Allow", "migration", "versions", "to", "be", "any", "length", "of", "number", "and", "add", "error", "messages", "surrounding", "migration", "names"], "add_tokens": "migration_name = filename . match ( / [0-9]+_(.+) \\. rb$ / ) . captures . first . camelize migration_name . constantize rescue NameError => e raise Errors :: MigrationNamingError , \"Migration file names must match the class name in the migrationcould not find class #{migration_name}.\" def self . get_version_from_migration_name ( filename ) filename . match ( / \\/ ([0-9]+)_.+ \\. rb$ / ) . captures . first . to_i rescue raise Errors :: MigrationNamingError , \"Migration file names must start with a numeric version prefix.\"", "del_tokens": "filename . match ( / [0-9]{14}_(.+) \\. rb$ / ) . captures . first . camelize . constantize def self . get_version_from_migration_name ( migration_name ) migration_name . match ( / ([0-9]{14})_.+ \\. rb$ / ) . captures . first . to_i", "commit_type": "allow"}
{"commit_tokens": ["Fix", "a", ":", "bug", ":", "with", "filtering", "logic", "and", "pure", "file", "predictions"], "add_tokens": "configuration . filter_manager . inclusions [ :ids ] &. delete ( path )", "del_tokens": "configuration . filter_manager . inclusions [ :ids ] . delete ( path )", "commit_type": "fix"}
{"commit_tokens": ["Added", "coffeescript", "js", "python", "and", "fixed", "scala"], "add_tokens": "` scalac #{ Euler . root } /lib/*.scala && scalac -cp .: #{ Euler . root } /lib ./*.scala && scala Main ` \"#{File.dirname(__FILE__)}/templates/scala.scala\"", "del_tokens": "` scalac -classpath .: #{ Euler . root } /lib *.scala && scala Main ` \"#{File.dirname(__FILE__)}/templates/scala.rb\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "with", "error", "name"], "add_tokens": "fail ApiError . new ( proto_method , response ) unless response . success?", "del_tokens": "fail ConnectionError , proto_method , response unless response . success?", "commit_type": "fix"}
{"commit_tokens": ["Removes", "empty", "test", "generated", "by", "Swagger"], "add_tokens": "#DocRaptor #A native client library for the DocRaptor HTML to PDF/XLS service. OpenAPI spec version : 2.0 . 0 Swagger Codegen version : 2.4 . 14 # require 'URI' # uri = URI.parse(\"https://docraptor.com\") # DocRaptor.configure do |c| # c.host = uri.host # c.base_path = uri.path # end # expect(config.base_url).to eq(\"https://docraptor.com\") # expect(config.base_url).to eq(\"https://docraptor.com\")", "del_tokens": "#DocRaptor v1 #No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen) OpenAPI spec version : 1.2 . 0 Swagger Codegen version : 2.2 . 3 #require 'URI' #uri = URI.parse(\"https://docraptor.com\") #DocRaptor.configure do |c| # c.host = uri.host # c.base_path = uri.path #end #expect(config.base_url).to eq(\"https://docraptor.com\") #expect(config.base_url).to eq(\"https://docraptor.com\")", "commit_type": "remove"}
{"commit_tokens": ["add", "support", "for", "public", "google", "spreadsheets"], "add_tokens": "class GoogleHTTPError < RuntimeError ; end class GoogleReadError < RuntimeError ; end class GoogleWriteError < RuntimeError ; end def visibility @headers ? \"private\" : \"public\" end def projection @headers ? \"full\" : \"values\" end path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/#{visibility}/#{projection}/#{cell}\" path = \"/feeds/worksheets/#{@spreadsheet_id}/#{visibility}/#{projection}\" if result . size == 0 if ( doc / \"h2\" ) . inner_html =~ / Error / raise GoogleHTTPError , \"#{(doc/'h2').inner_html}: #{(doc/'title').inner_html} [key '#{@spreadsheet_id}']\" else raise GoogleReadError , \"#{doc} [key '#{@spreadsheet_id}']\" end end raise GoogleWriteError , \"unable to write to public spreadsheets\" if visibility == 'public' path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/#{visibility}/#{projection}\" <<-XML XML path = \"/feeds/cells/#{@spreadsheet_id}/1/#{visibility}/#{projection}\" path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/#{visibility}/#{projection}\" path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/#{visibility}/#{projection}\" @gs . authenticate ( user , password ) unless user . empty? || password . empty? if @formula . size > 0 && @formula [ sheet ] [ \"#{row},#{col}\" ] if val . nil? || val [ 0 , 1 ] == '='", "del_tokens": "path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/#{@headers ? \"private\" : \"public\"}/basic/#{cell}\" path = \"/feeds/worksheets/#{@spreadsheet_id}/private/basic\" path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/#{@headers ? 'private' : 'public'}/full\" <<XML XML path = \"/feeds/cells/#{@spreadsheet_id}/1/private/full\" path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/private/full\" path = \"/feeds/cells/#{@spreadsheet_id}/#{sheet_no}/private/full\" @default_sheet = nil @gs . authenticate ( user , password ) #-- ---------------------------------------------------------------------- #-- TODO: Behandlung von Berechtigungen hier noch einbauen ??? #-- ---------------------------------------------------------------------- if @formula [ sheet ] [ \"#{row},#{col}\" ] if val [ 0 , 1 ] == '='", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "atom", "and", "prefix", "search", "."], "add_tokens": "liner :names , :primary_code , :secondary_code , :symbol , :scale def self . search ( term ) self . all . select do | i | i . search_strings . any? { | string | string =~ / #{ term } /i } end end def search_strings [ primary_code , secondary_code , names , slugs , symbol ] . flatten . compact end", "del_tokens": "liner :primary_code , :secondary_code , :symbol , :names , :scale", "commit_type": "add"}
{"commit_tokens": ["Change", "gem", "name", "from", "itcss_cli", "to", "itcsscli"], "add_tokens": "require \"itcsscli/version\" \"itcss init | | Initiates itcsscli configuration with a itcss.yml file. [start here]\" , \"itcss version | v, -v | Shows itcsscli gem version installed.\" puts \"itcsscli available commmands:\" . yellow", "del_tokens": "require \"itcss_cli/version\" \"itcss init | | Initiates itcss_cli configuration with a itcss.yml file. [start here]\" , \"itcss version | v, -v | Shows itcss_cli gem version installed.\" puts \"itcss_cli available commmands:\" . yellow", "commit_type": "change"}
{"commit_tokens": ["Changed", "performance", "testing", "to", "quicky", "gem", "."], "add_tokens": "require 'quicky' times = 10 quicky = Quicky :: Timer . new to_run = [ :typhoeus , :rest_client , :net_http_persistent ] to_run . each do | gem | run_perf ( quicky , times , gem ) end quicky . results . each_pair do | k , v | puts \"#{k}: #{v.duration}\" def run_perf ( quicky , times , gem ) quicky . loop ( gem , times ) do", "del_tokens": "times = 100 collector = [ ] collector << run_perf ( times , :typhoeus ) collector << run_perf ( times , :rest_client ) collector << run_perf ( times , :net_http_persistent ) collector . each do | c | p c def run_perf ( times , gem ) t = Time . now times . times do | i | duration = Time . now . to_f - t . to_f puts \"#{times} posts took #{duration}\" { :gem => gem , :duration => duration }", "commit_type": "change"}
{"commit_tokens": ["Updated", "README", "and", "bumped", "version"], "add_tokens": "VERSION = \"0.3.0\"", "del_tokens": "VERSION = \"0.2.0\"", "commit_type": "update"}
{"commit_tokens": ["improve", "documentation", "and", "adopt", "method", "names", "to", "bibsonomy", "-", "python"], "add_tokens": "post = @api . get_post ( \"jaeschke\" , \"c9437d5ec56ba949f533aeec00f571e3\" ) result = @api . get_posts_for_user ( \"jaeschke\" , \"publication\" , nil , 0 , 20 )", "del_tokens": "post = @api . find ( \"jaeschke\" , \"c9437d5ec56ba949f533aeec00f571e3\" ) result = @api . all ( \"jaeschke\" , nil , 20 )", "commit_type": "improve"}
{"commit_tokens": ["adding", "user", "API", "call", "wrapper", "call", "with", "examples"], "add_tokens": "data [ :email ] = email # Get user by Sailthru ID def get_user_by_sid ( id , fields = { } ) api_get ( :user , { 'id' => id , 'fields' => fields } ) end # Get user by specified key def get_user_by_key ( id , key , fields = { } ) data = { 'id' => id , 'key' => key , 'fields' => fields } api_get ( :user , data ) end # Creates new user def create_new_user ( options = { } ) options . delete ( 'id' ) api_post ( :user , options ) end # Save existing user def save_user ( id , options = { } ) data = options data [ 'id' ] = id api_post ( :user , data ) end", "del_tokens": "data [ :email ] = email", "commit_type": "add"}
{"commit_tokens": ["add", "text", "-", "cleaning", "example", "move", "pinger", "/", "ponger", "to", "chap1"], "add_tokens": "raise BloomError , \"Attempt to put Non-Array type into BloomCollection\" unless o . class <= Array @storage [ [ i ] ] = [ line . strip ]", "del_tokens": "@storage [ [ i ] ] = [ line ]", "commit_type": "add"}
{"commit_tokens": ["Add", "logic", "for", "index", "action", "and", "remove", "cruft", "from", "Action", "class"], "add_tokens": "class IndexAction < Action def perform_action ( params ) model . all end end", "del_tokens": "def resources model . all end def aasdresource model . find params [ :id ] end def resource_params params [ controller_name . singularize ] end class IndexAction < Action ; end", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "per", "Maeve", "s", "request"], "add_tokens": "VERSION = '0.5.0'", "del_tokens": "VERSION = '0.4.0'", "commit_type": "add"}
{"commit_tokens": ["changed", "numerical_value", "=", ">", "weight"], "add_tokens": "out << %( weight: #{@weight})", "del_tokens": "out << %( numerical_value: #{@numerical_value})", "commit_type": "change"}
{"commit_tokens": ["Removing", "all", "persistance", "/", "environment", "attributes"], "add_tokens": "MISSING_PEM = 'No pem file specified. Pass pem string'", "del_tokens": "MISSING_KEY = 'No Private Key specified. Pass priv_key or set ENV variable PRIV_KEY' MISSING_PEM = 'No pem file specified. Pass pem or set ENV variable BITPAY_PEM'", "commit_type": "remove"}
{"commit_tokens": ["Remove", "variable", "part", "of", "objects", "for", "hash", "inspection"], "add_tokens": "o = { } options . each do | k , v | if v . inspect =~ / :0x0 / o [ k ] = v . inspect . sub ( / :0x[a-f0-9]+@ / , '' ) else o [ k ] = v end end", "del_tokens": "o = options . dup o = o . delete_if { | k , v | Proc === v }", "commit_type": "remove"}
{"commit_tokens": ["Adding", "more", "examples", "of", "subcommand", "process", "."], "add_tokens": "describe \"backticks can be used as part of an argument: git branch `git cbranch`.bak\" do let ( :str ) { \"git branch `git cbranch`.bak\" } it { should eq [ t ( :Command , \"git\" , lineno : 0 ) , t ( :Argument , \"branch\" , lineno : 0 ) , t ( :BeginSubcommand , '`' , lineno : 0 ) , t ( :Command , 'git' , lineno : 0 ) , t ( :Argument , 'cbranch' , lineno : 0 ) , t ( :EndSubcommand , '`' , lineno : 0 ) , t ( :Argument , '.bak' , lineno : 0 ) ] } end let ( :str ) { \"$(ls -al && foo bar || baz)\" } t ( :BeginSubcommand , \"$(\" , lineno : 0 ) , t ( :EndSubcommand , \")\" , lineno : 0 )", "del_tokens": "let ( :str ) { \"`ls -al && foo bar || baz`\" } t ( :BeginSubcommand , \"`\" , lineno : 0 ) , t ( :EndSubcommand , \"`\" , lineno : 0 )", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "sourcemap", "bindings"], "add_tokens": "@sourcemap = RedSnow :: Sourcemap :: Blueprint . new ( sourcemap_handle )", "del_tokens": "@sourcemap = Sourcemap . new ( sourcemap_handle )", "commit_type": "add"}
{"commit_tokens": ["Allow", "overriding", "any", "service", "params", "via", "options", "."], "add_tokens": "# Sigh scoping. options = self . options command : options [ 'command' ] || new_resource . command , directory : options [ 'directory' ] || new_resource . directory , environment : options [ 'environment' ] || new_resource . environment , reload_signal : options [ 'reload_signal' ] || new_resource . reload_signal , stop_signal : options [ 'stop_signal' ] || new_resource . stop_signal , user : options [ 'user' ] || new_resource . user ,", "del_tokens": "command : new_resource . command , directory : new_resource . directory , environment : new_resource . environment , reload_signal : new_resource . reload_signal , stop_signal : new_resource . stop_signal , user : new_resource . user ,", "commit_type": "allow"}
{"commit_tokens": ["Use", "TTT", ".", "other_player", "instead"], "add_tokens": "TTT . other_player ( player )", "del_tokens": "TTT . other_token ( player )", "commit_type": "use"}
{"commit_tokens": ["Update", "the", "way", "to", "get", "to", "the", "dynflow", "logger"], "add_tokens": "ForemanTasks . dynflow . world . logger . error ( 'Error on on_execution_plan_save event' ) ForemanTasks . dynflow . world . logger . error ( e . message ) ForemanTasks . dynflow . world . logger . error ( e . backtrace . join ( \"\\n\" ) )", "del_tokens": "ForemanTasks . world . logger . error ( 'Error on on_execution_plan_save event' ) ForemanTasks . world . logger . error ( e . message ) ForemanTasks . world . logger . error ( e . backtrace . join ( \"\\n\" ) )", "commit_type": "update"}
{"commit_tokens": ["added", "verification", "of", "mark", "of", "call", "nodes", "generated", "in", "EvalHook", "context", "to", "avoid", "infinite", "recursion", "on", "hooking"], "add_tokens": "if tree . respond_to? ( :is_marked? ) return super ( tree ) super marked ( s ( :call , secondcall , :call , tree [ 3 ] ) )", "del_tokens": "if ( method_name == :local_hooked_method or method_name == :hooked_method or method_name == :set_hook_handler or method_name == :binding ) return super tree super marked s ( :call , secondcall , :call , tree [ 3 ] )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "accept", "options", "."], "add_tokens": "def initialize ( string_a , string_b , options = { } ) @format = options . fetch ( :format , :unified ) @context_lines = options . fetch ( :context_lines , 3 )", "del_tokens": "def initialize ( string_a , string_b , format , context_lines ) @format = format @context_lines = context_lines", "commit_type": "change"}
{"commit_tokens": ["Allow", "parameters", "on", "ActiveJob", "enqueues"], "add_tokens": "VERSION = '2.0.5'", "del_tokens": "VERSION = '2.0.4'", "commit_type": "allow"}
{"commit_tokens": ["added", "base_url", "for", "wallet", "requests"], "add_tokens": "response = resp = Blockchain :: call_api ( \"merchant/#{@identifier}/balance\" , method : 'get' , data : build_basic_request ( ) , base_url : @url ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/list\" , method : 'get' , data : params , base_url : @url ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/address_balance\" , method : 'get' , data : params , base_url : @url ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/new_address\" , method : 'post' , data : params , base_url : @url ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/archive_address\" , method : 'post' , data : params , base_url : @url ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/unarchive_address\" , method : 'post' , data : params , base_url : @url )", "del_tokens": "response = resp = Blockchain :: call_api ( \"merchant/#{@identifier}/balance\" , method : 'get' , data : build_basic_request ( ) ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/list\" , method : 'get' , data : params ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/address_balance\" , method : 'get' , data : params ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/new_address\" , method : 'post' , data : params ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/archive_address\" , method : 'post' , data : params ) response = Blockchain :: call_api ( \"merchant/#{@identifier}/unarchive_address\" , method : 'post' , data : params )", "commit_type": "add"}
{"commit_tokens": ["Fix", "naming", "bug", "in", "the", "role", "-", "based", "checks"], "add_tokens": "# @param [String] args an argument list of one or more roles to check for. def has_role? ( * args ) throw Exception . new ( \"Must supply at least one role.\" ) if args . empty? roles . where ( name : args ) . count > 0 # @param [String] args an argument list of one or more roles to check for. def has_roles? ( * args ) throw Exception . new ( \"Must supply at least one role.\" ) if args . empty? roles . where ( name : args ) . count == args . count", "del_tokens": "# @param [String] roles an argument list of one or more roles to check for. def has_role? ( * roles ) throw Exception . new ( \"Must supply at least one role.\" ) if roles . empty? roles . where ( name : roles ) . count > 0 # @param [String] roles an argument list of one or more roles to check for. def has_roles? ( * roles ) throw Exception . new ( \"Must supply at least one role.\" ) if roles . empty? roles . where ( name : roles ) . count == roles . count", "commit_type": "fix"}
{"commit_tokens": ["add", "separator", "to", "retrieving", "attributes", "and", "add", "group", "links", "on", "individualized", "multiple", "attributes"], "add_tokens": "# Groups the links on the provided attribute. If no links array is provided # the links from self are used def links_group_by ( attribute , linkz = links ) linkz . map { | link | { key : link . send ( attribute ) , link : link } } # Groups the links on the provided attribute. If the attribute's value # contains the provided separator, the value is split up and each of the # values is used as group key def links_group_by_separated ( attribute , separator ) links_group_by ( attribute , links_duplicate_on ( attribute , separator ) ) end def link_attribute_list ( attribute , separator = nil ) links . map { | link | link . send ( attribute ) . split ( separator ) } . flatten . uniq . sort", "del_tokens": "# Groups the links on the provided attribute def links_group_by ( attribute ) links . map { | link | { key : link . send ( attribute ) , link : link } } def link_attribute_list ( attribute ) links . map { | link | link . send ( attribute ) } . uniq . sort", "commit_type": "add"}
{"commit_tokens": ["Added", "CVE", "-", "2013", "-", "0277"], "add_tokens": "it \"must have test for CVE_2013_0277\" do sc = kb . find ( \"CVE-2013-0277\" ) sc . should_not be_nil sc . class . should == Codesake :: Dawn :: Kb :: CVE_2013_0277 end", "del_tokens": "it \"must have test for CVE_2013_0277\"", "commit_type": "add"}
{"commit_tokens": ["Adding", "fat", "gem", "compatible", "loader", "set", "the", "default", "RUBY_CC_VERSION"], "add_tokens": "create_makefile ( \"pkcs11_ext\" ) ;", "del_tokens": "create_makefile ( \"pkcs11\" ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "delayed", "job", "is", "loaded"], "add_tokens": "require 'delayed_job'", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["changing", "the", "way", "of", "delegation"], "add_tokens": "singleton_class . instance_variable_get :@YPetriManipulator or singleton_class . instance_variable_set :@YPetriManipulator , Manipulator . new", "del_tokens": "receiver . instance_variable_set :@YPetriManipulator , Manipulator . new self . class . instance_variable_get :@YPetriManipulator", "commit_type": "change"}
{"commit_tokens": ["Made", "respect", "baseurl", "and", "now", "exports", "windows", "friendly", "names"], "add_tokens": "instance [ key ] [ :generated_src ] = generate_image ( source , site . source , site . dest , settings [ 'source' ] , settings [ 'output' ] , site . config [ \"baseurl\" ] ) def generate_image ( instance , site_source , site_dest , image_source , image_dest , baseurl ) gen_name = \"#{basename}-#{gen_width.round}by#{gen_height.round}-#{digest}#{ext}\" Pathname . new ( File . join ( baseurl , image_dest , image_dir , gen_name ) ) . cleanpath", "del_tokens": "instance [ key ] [ :generated_src ] = generate_image ( source , site . source , site . dest , settings [ 'source' ] , settings [ 'output' ] ) def generate_image ( instance , site_source , site_dest , image_source , image_dest ) gen_name = \"#{basename}-#{gen_width.round}*#{gen_height.round}-#{digest}#{ext}\" Pathname . new ( File . join ( '/' , image_dest , image_dir , gen_name ) ) . cleanpath", "commit_type": "make"}
{"commit_tokens": ["added", "edit", "for", "table", "content"], "add_tokens": "VERSION = \"0.9\"", "del_tokens": "VERSION = \"0.8\"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Procs", ":"], "add_tokens": "def resolve ( options , & endpoint ) result = endpoint || options . delete ( :to )", "del_tokens": "def resolve ( options ) result = options . delete ( :to )", "commit_type": "add"}
{"commit_tokens": ["Changed", "Resource", "::", "klass", "and", "updated", "version"], "add_tokens": "if self . is_standard_resource? @controller . camelize . constantize else ( @namespace . camelize + \"::\" + @controller . camelize ) . constantize end", "del_tokens": "( @namespace . camelize + \"::\" + @controller . camelize ) . constantize unless self . is_standard_resource? @controller . camelize . constantize if self . is_standard_resource?", "commit_type": "change"}
{"commit_tokens": ["changed", "version", "and", "added", "testing"], "add_tokens": "VERSION = \"0.3.0\"", "del_tokens": "VERSION = \"0.2.4\"", "commit_type": "change"}
{"commit_tokens": ["Use", "rspec", "as", "default", "rake", "task", "."], "add_tokens": "require File . dirname ( __FILE__ ) + '/spec_helper'", "del_tokens": "require 'spec_helper'", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "specifically", "read", "as", "utf", "-", "8", "encoded", "file"], "add_tokens": "expect ( File . open ( file , 'r:UTF-8' , & :read ) ) . to eq ( [", "del_tokens": "expect ( File . read ( file ) ) . to eq ( [", "commit_type": "change"}
{"commit_tokens": ["Changed", "the", "SpecParser", "to", "record", "the", "source", "dest", "path", "pairs", "."], "add_tokens": "include SpecParser", "del_tokens": "extend SpecParser", "commit_type": "change"}
{"commit_tokens": ["change", "documentation", "to", "deprecate", "values_for_", "...", "and", "added", "finder", "example", "code", "to", "documentation"], "add_tokens": "values_inverted = values . invert enum_definitions [ enum_cd ] = enum_definitions [ options [ :column ] ] = { :name => enum_cd , :column => options [ :column ] , :options => options } values_inverted [ id ] class_eval ( <<-EOM , __FILE__ , __LINE__ + 1 ) def self . #{enum_cd.to_s.pluralize}(sym = nil) return class_variable_get ( :@@SE_ #{enum_cd.to_s.pluralize.upcase}) if sym.nil? class_variable_get ( :@@SE_ #{enum_cd.to_s.pluralize.upcase})[sym] end EOM values . each do | sym , code | define_method ( \"#{prefix}#{sym}?\" ) do code == read_attribute ( options [ :column ] ) define_method ( \"#{prefix}#{sym}!\" ) do write_attribute options [ :column ] , code sym unless send ( enum_def [ :name ] . to_s . pluralize ) . values . include? ( value )", "del_tokens": "enum_definitions [ enum_cd ] = { :name => enum_cd , :values => values , :column => options [ :column ] , :options => options } enum_definitions [ options [ :column ] ] = enum_definitions [ enum_cd ] values . invert [ id ] class_eval \"def self.#{enum_cd.to_s.pluralize}; class_variable_get(:@@SE_#{enum_cd.to_s.pluralize.upcase}); end\" values . each do | k , cd | define_method ( \"#{prefix}#{k}?\" ) do cd == read_attribute ( options [ :column ] ) define_method ( \"#{prefix}#{k}!\" ) do write_attribute options [ :column ] , cd k unless enum_def [ :values ] . values . include? ( value )", "commit_type": "change"}
{"commit_tokens": ["Add", "Moodle", "::", "Backup", "class"], "add_tokens": "module Moodle autoload :Backup , 'moodle2cc/moodle/backup' end", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["Add", "mocked", "test", "for", "sheets"], "add_tokens": "require 'smartsheet/smartsheet' require 'mocha/mini_test'", "del_tokens": "require 'smartsheet/sdk'", "commit_type": "add"}
{"commit_tokens": ["Added", "validations", "and", "error", "notices"], "add_tokens": "def new @patient = Patient . new end @patient = Patient . new ( allowed_params ) if @patient . save redirect_to patients_path ( @patient ) , :notice => \"You have successfully added a new patient.\" else render :new end redirect_to patients_path ( @patient )", "del_tokens": "@patient = Patient . create! ( allowed_params ) redirect_to patients_path ( @patient ) redirect_to patient_path ( @patient )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "when", "partitioning", "context", "args", "into", "players", "and", "settings", ".", "Failed", "when", "a", "value", "was", "an", "empty", "Array"], "add_tokens": "players , noplayers = args . partition { | key , * | roles . has_key? ( key ) } . map { | group | Hash [ * group . flatten ( 1 ) ] }", "del_tokens": "players , noplayers = args . partition { | key , * | roles . has_key? ( key ) } . map { | group | Hash [ * group . flatten ] }", "commit_type": "fix"}
{"commit_tokens": ["Added", "initializer", "for", "Mailboxer", "tests", "and", "working", "mailers"], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20110427123542 ) do", "del_tokens": "ActiveRecord :: Schema . define ( :version => 20110407111612 ) do", "commit_type": "add"}
{"commit_tokens": ["Add", "noop", "and", "logging", "to", "file", "diffing", "."], "add_tokens": "diff = TTY :: File . diff ( file_a , file_b , verbose : false ) expect ( TTY :: File . diff ( src_a , src_a , verbose : false ) ) . to eq ( '' ) diff = TTY :: File . diff ( src_a , src_b , verbose : false ) diff = TTY :: File . diff ( file_a , file_b , verbose : false ) it \"logs status\" do file_a = tmp_path ( 'diff/file_a' ) file_b = tmp_path ( 'diff/file_b' ) expect { TTY :: File . diff ( file_a , file_b , verbose : true ) } . to output ( / diff(.*) \\/ diff \\/ file_a(.*) \\/ diff \\/ file_b / ) . to_stdout_from_any_process end it \"doesn't diff files when :noop option is given\" do file_a = tmp_path ( 'diff/file_a' ) file_b = tmp_path ( 'diff/file_b' ) diff = TTY :: File . diff ( file_a , file_b , verbose : false , noop : true ) expect ( diff ) . to eq ( '' ) end", "del_tokens": "diff = TTY :: File . diff ( file_a , file_b ) expect ( TTY :: File . diff ( src_a , src_a ) ) . to eq ( '' ) diff = TTY :: File . diff ( src_a , src_b ) diff = TTY :: File . diff ( file_a , file_b )", "commit_type": "add"}
{"commit_tokens": ["Add", "no", "methods", "to", "ActionController"], "add_tokens": "controller . instance_variable_get ( SCRIPT_TAG_HELPER_CALLED_INSTANCE_VARIABLE )", "del_tokens": "controller . instance_variable_get ( :@intercom_script_tag_called )", "commit_type": "add"}
{"commit_tokens": ["make", "class", "methods", "instance", "methods"], "add_tokens": "self . send ( :define_method , \"handles_#{action.to_s.underscore}\" ) do", "del_tokens": "self . class . send ( :define_method , \"handles_#{action.to_s.underscore}\" ) do", "commit_type": "make"}
{"commit_tokens": ["Add", "helper", "methods", "to", "pause", "/", "resume", "servers"], "add_tokens": "# Stop all running, paused, or starting servers each { | server | server . stop! if server . running? || server . paused? || server . starting? } end # Pause all running servers def self . pause_all each { | server | server . pause! if server . running? } end # Resume all paused servers def self . resume_all each { | server | server . resume! if server . paused? }", "del_tokens": "# Stop all running servers each { | s | s . stop! if s . running? || s . paused? }", "commit_type": "add"}
{"commit_tokens": ["added", "a", "method", "to", "sign", "a", "url"], "add_tokens": "def sign_url ( url , secret , token = \"token\" , extra_params = { } ) uri = Addressable :: URI . parse ( url ) query_values = ( uri . query_values || { } ) . merge ( extra_params ) uri . query_values = query_values signature = generate_signature ( uri . to_s , secret , token ) uri . query_values = query_values . merge ( { token => signature } ) uri . to_s end \"%{key}=%{value}\" % { :key => CGI . escape ( key . to_s ) , :value => CGI . escape ( value . to_s ) }", "del_tokens": "\"%{key}=%{value}\" % { :key => CGI . escape ( key ) , :value => CGI . escape ( value ) }", "commit_type": "add"}
{"commit_tokens": ["move", "files", "into", "ext", "/"], "add_tokens": "$CFLAGS << ' -O0 -ggdb3'", "del_tokens": "# $CFLAGS << ' -O0 -ggdb'", "commit_type": "move"}
{"commit_tokens": ["updated", "specs", "for", "input", "option"], "add_tokens": "file_dir = file_dir . sub ( @input_dir , '' ) if @input_dir", "del_tokens": "@input_dir += '/' if @input_dir && @input_dir [ @input_dir . length - 1 ] != '/' file_dir = file_dir . sub! ( @input_dir , '' ) if @input_dir", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "check", "if", "file", "exists", "before", "removing"], "add_tokens": "return if options [ :noop ] || ! :: File . exist? ( relative_path )", "del_tokens": "return if options [ :noop ]", "commit_type": "change"}
{"commit_tokens": ["Added", "feature", "to", "support", "pdf", "template"], "add_tokens": "template_class : nil , } , chart : { height : 160 , width : 200 }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["add", "table", "output", "for", "multiple", "records"], "add_tokens": "if data . kind_of? Gitlab :: ObjectifiedHash puts single_table_output ( data , cmd , arguments ) elsif data . kind_of? Array puts multiple_table_output ( data , cmd , arguments ) end def self . multiple_table_output ( data , cmd , args ) return 'No data' if data . empty? arr = data . map ( & :to_h ) keys = arr . first . keys . sort { | x , y | x . to_s <=> y . to_s } table do | t | t . title = \"Gitlab.#{cmd} #{args.join(', ')}\" t . headings = keys arr . each_with_index do | hash , index | values = [ ] keys . each do | key | case value = hash [ key ] when Array # TODO next when Hash # TODO next when nil value = 'null' end values << value end t . add_row values t . add_separator unless arr . size - 1 == index end end end def self . single_table_output ( data , cmd , args ) hash = data . to_h", "del_tokens": "puts table_output ( data . to_h , cmd , arguments ) def self . table_output ( hash , cmd , args )", "commit_type": "add"}
{"commit_tokens": ["Add", "recursive", "serialization", "to", "convert", "associated", "models", "."], "add_tokens": "result = self . serializable_hash # Try to serialize every object received result . each { | k , v | result [ k ] = recursive_serialization ( v ) } end private # Method to try to recursively seralize the objects received def recursive_serialization object if ( object . is_a? ( Array ) ) # If it's an array, try to serialize each element return object . map { | o | recursive_serialization ( o ) } elsif ( object . respond_to? ( :serializable_hash ) ) return object . serializable_hash else return object end", "del_tokens": "self . serializable_hash", "commit_type": "add"}
{"commit_tokens": ["fix", "any", "which", "did", "not", "include", "max"], "add_tokens": "any [ rand ( any . size ) ]", "del_tokens": "any [ rand ( any . size - 1 ) ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "scoping", "issue", "with", "Rails", "3", "."], "add_tokens": "result = CopycopterClient . copy_for ( scope_copycopter_key_by_partial ( key ) , default ) def scope_copycopter_key_by_partial ( key )", "del_tokens": "result = CopycopterClient . copy_for ( scope_key_by_partial ( key ) , default ) def scope_key_by_partial ( key )", "commit_type": "fix"}
{"commit_tokens": ["Add", "starred", "property", "to", "Message"], "add_tokens": "Message = Struct . new ( :connection , :id , :room_id , :user_id , :body , :created_at , :type , :starred )", "del_tokens": "Message = Struct . new ( :connection , :id , :room_id , :user_id , :body , :created_at , :type )", "commit_type": "add"}
{"commit_tokens": ["create", "@allow_files", "regex", "in", "initializer", "and", "inline", "checks"], "add_tokens": "@allow_files = opts [ :allow_files ] && / #{ Array ( opts [ :allow_files ] ) . join ( '|' ) } / next if @ignore_files && @ignore_files =~ file next if @allow_files && ! @allow_files =~ file", "del_tokens": "@allow_files = Array ( opts [ :allow_files ] ) def ignore_file? ( file ) @ignore_files && @ignore_files =~ file end def allow_file? ( file ) return true if @allow_files . empty? ! / #{ @allow_files . join ( '|' ) } / . match ( file ) . to_s . empty? end next if ! allow_file? ( file ) || ignore_file? ( file )", "commit_type": "create"}
{"commit_tokens": ["adding", "some", "documentation", "for", "run", "run!", "execute", "and", "response"], "add_tokens": "# Returns the output from {#execute} if there are no errors or nil otherwise. # # @return [Nil] if there are validation errors. # @return [Object] if there are no validation errors. # This must be overridden in a custom ActiveInteraction # # @raise [NotImplementedError] if the method is not defined. # @!macro [new] run_attributes # @param options [Hash] A hash of attributes values to set. # @return [ActiveInteraction::Base] An instance of the class run is called on. # Runs validations and if there are no errors it will call {#execute}. # # @macro run_attributes # Same as {.run} except that an exception is raised if there are any validation # errors. # # @macro run_attributes # @raise [InteractionInvalid] if there are any errors on the model.", "del_tokens": "# @raise [NotImplementedError] This must be overridden in a custom ActiveInteraction", "commit_type": "add"}
{"commit_tokens": ["remove", ":", "timedout", "from", "the", "session", "hash", "(", "https", ":", "//", "github", ".", "com", "/", "plataformatec", "/", "devise", "/", "issues", "/", "1777", ")"], "add_tokens": "javascript_tag \"window.flashes = #{raw(Hash[flash].except!(:timedout).to_json)};\" , defer : 'defer'", "del_tokens": "javascript_tag \"window.flashes = #{raw(Hash[flash].to_json)};\" , defer : 'defer'", "commit_type": "remove"}
{"commit_tokens": ["fixed", "EISCP", "::", "Receiver", ".", "new"], "add_tokens": "if first_discovered = self . class . discover [ 0 ]", "del_tokens": "if first_discovered == self . class . discover [ 0 ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "dispatcher", "monkeypatch", "for", "older", "Chef", "."], "add_tokens": "if defined? ( call_subscribers ) call_subscribers ( :recipe_loaded , * args ) else @subscribers . each { | s | s . recipe_loaded ( * args ) } end", "del_tokens": "call_subscribers ( :recipe_loaded , * args )", "commit_type": "fix"}
{"commit_tokens": ["changed", "spec", "to", "remove", "confusion", "about", "what", "its", "doing"], "add_tokens": "run 'some_command'", "del_tokens": "run 'cd ~' run 'touch test.txt'", "commit_type": "change"}
{"commit_tokens": ["Added", ":", "set", "option", "to", "auto_validate", "added", "support", "for", "infinite", "ranges", "in", "within_validator"], "add_tokens": "PROPERTY_OPTIONS << :message << :messages << :set # :set => [\"foo\", \"bar\", \"baz\"] # Setting the :set option causes a validates_within # validator to be automatically created on the property # # within validator if property . options . has_key? ( :set ) validates_within property . name , options_with_message ( { :set => property . options [ :set ] } , property , :within ) end", "del_tokens": "PROPERTY_OPTIONS << :message << :messages", "commit_type": "add"}
{"commit_tokens": ["Update", "validation", "to", "check", "that", "app_id", "key", "and", "secret", "all", "supplied"], "add_tokens": "raise ArgumentError , 'Missing configuration: please check that Pusher.app_id, Pusher.key, and Pusher.secret are all configured' unless @app_id && @key && @secret", "del_tokens": "raise ArgumentError , 'You must configure both Pusher.key in order to authenticate your Pusher app' unless @key", "commit_type": "update"}
{"commit_tokens": ["Fix", "one", "offense", "get", "a", "brand", "new", "one", "."], "add_tokens": "process_pipeline ( hash , pipeline ) private def process_pipeline ( hash , pipeline ) pipeline . assets . each do | asset | puts \"Saved '#{asset.filename}' to \" \"'#{pipeline.destination}/#{asset.output_path}'\" end # Add processed pipeline to cache cache [ hash ] = pipeline # Return newly processed pipeline and cached status [ pipeline , false ] end attr_reader :assets , :html , :destination", "del_tokens": "# Create and process new pipeline pipeline . assets . each do | asset | puts \"Saved '#{asset.filename}' to \" \"'#{destination}/#{asset.output_path}'\" end # Add processed pipeline to cache cache [ hash ] = pipeline # Return newly processed pipeline and cached status return pipeline , false attr_reader :assets , :html", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "issues", "with", "iCal", "output", "and", "added", "cal2ical", ".", "rb", "in", "the", "examples"], "add_tokens": "# You can get all events by passing 'nil, nil', but you should really consider using synchronization then. # If we pass nil, force times to be: # start: 1 years ago # end: 1 years from now if ( start_time == nil or end_time == nil ) cal_span . xmlattr_StartDate = DateTime . parse ( ( Date . today - 365 ) . to_s ) . to_s cal_span . xmlattr_EndDate = DateTime . parse ( ( Date . today + 365 ) . to_s ) . to_s find_item_t . calendarView = cal_span else cal_span . xmlattr_StartDate = DateTime . parse ( Date . today . to_s ) . to_s cal_span . xmlattr_EndDate = DateTime . parse ( Date . today . next . to_s ) . to_s find_item_t . calendarView = cal_span end events = get_events ( nil , nil ) events . each do | ev |", "del_tokens": "cal_span . xmlattr_StartDate = DateTime . parse ( Date . today . to_s ) . to_s cal_span . xmlattr_EndDate = DateTime . parse ( Date . today . next . to_s ) . to_s find_item_t . calendarView = cal_span today = get_todays_events today . each do | ev |", "commit_type": "fix"}
{"commit_tokens": ["Improved", "MotionBundler", "::", "Require", "::", "Tracer", "::", "Log", ".", "register"], "add_tokens": "def register ( file ) return unless file . match ( / ^(.* \\. rb) \\b / ) dependencies = ( @log [ $1 ] ||= [ ] )", "del_tokens": "def register ( caller ) dependencies = ( @log [ caller ] ||= [ ] )", "commit_type": "improve"}
{"commit_tokens": ["Move", "Punctuations", "in", "to", "languages", "common"], "add_tokens": "@punct_arr ||= Languages :: Common :: Punctuations", "del_tokens": "require 'pragmatic_segmenter/punctuation' @punct_arr ||= PragmaticSegmenter :: Punctuations", "commit_type": "move"}
{"commit_tokens": ["Add", "interface", "to", "active", "a", "user", "account"], "add_tokens": "options [ :query ] = extract_config_option ( :query ) || { } def ribose_host Ribose . configuration . api_host end def extract_config_option ( key ) data . delete ( key . to_sym ) def require_auth_headers? auth_header = extract_config_option ( :auth_header ) auth_header == false ? false : true if require_auth_headers? http . headers [ \"X-Indigo-Token\" ] = Ribose . configuration . api_token http . headers [ \"X-Indigo-Email\" ] = Ribose . configuration . user_email end", "del_tokens": "options [ :query ] = extract_query_options def extract_query_options data . delete ( :query ) || { } def ribose_host Ribose . configuration . api_host http . headers [ \"X-Indigo-Token\" ] = Ribose . configuration . api_token http . headers [ \"X-Indigo-Email\" ] = Ribose . configuration . user_email", "commit_type": "add"}
{"commit_tokens": ["Added", "http", ":", "//", "lccn", ".", "loc", ".", "gov", "/", "<lccn", ">", "syntax", "and", "more", "LCCN", "tests"], "add_tokens": "rv . gsub! ( 'http://lccn.loc.gov/' , '' ) # remove URI prefix return false", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "serialize", "consumer", "when", "it", "uses", "SSL", "previously", "that", "would"], "add_tokens": "# Unset cached http instance because it cannot be marshalled when # it has already been used and use_ssl is set to true def marshal_dump ( * args ) @http = nil self end", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Added", "tests", "for", "numeric", "."], "add_tokens": "abs abs . flip_sign", "del_tokens": "return self if self >= 0 flip_sign return self if self < 0 flip_sign", "commit_type": "add"}
{"commit_tokens": ["added", "node_id", "method", "and", "some", "more", "specs"], "add_tokens": "@@meta_nodes = MetaNodes . new #(@@neo.getReferenceNode) def self . find_node ( id ) neo_node = @@neo . findNodeById ( id ) load_node ( neo_node ) end def self . load_node ( neo_node ) classname = neo_node . get_property ( 'classname' ) # get the class that might exist in a module clazz = classname . split ( \"::\" ) . inject ( Kernel ) do | container , name | container . const_get ( name . to_s ) end clazz . new ( neo_node ) end #puts \"Create new for #{self.class.to_s}: #{@internal_node.hasProperty('classname')}\" Neo . transaction { self . classname = self . class . to_s } unless @internal_node . hasProperty ( \"classname\" ) #puts \"DONE\" # # Returns a unique id # Calls getId on the neo node java object # def neo_node_id @internal_node . getId ( ) end yield Neo :: load_node ( iter . next )", "del_tokens": "@@meta_nodes = MetaNodes . new Neo . transaction { self . classname = self . class . to_s } inode = iter . next classname = inode . get_property ( 'classname' ) # get the class that might exist in a module clazz = classname . split ( \"::\" ) . inject ( Kernel ) do | container , name | container . const_get ( name . to_s ) end yield clazz . new ( inode )", "commit_type": "add"}
{"commit_tokens": ["Fix", "unnecessary", "dependency", "to", "test", "framework", "if", "no", "tests", "defined", "."], "add_tokens": "if ( @settings [ 'TEST_FRAMEWORK' ] . nil? or @settings [ 'TEST_FRAMEWORK' ] . empty? ) @test_fw = @tc . default_test_framework else @test_fw = @tc . test_framework ( @settings [ 'TEST_FRAMEWORK' ] ) end if has_tests? @test_objs = @test_srcs . map { | file | source_to_obj ( file , @src_dir , @build_dir ) } @test_deps = @test_objs . map { | obj | obj . ext ( '.d' ) } load_deps ( @test_deps ) @test_inc_dirs = @settings [ 'TEST_SOURCE_DIRS' ] . empty? ? '' : @test_fw . include . join ( ' ' ) else @test_objs = [ ] @test_deps = [ ] @test_inc_dirs = '' end", "del_tokens": "@test_objs = @test_srcs . map { | file | source_to_obj ( file , @src_dir , @build_dir ) } @test_deps = @test_objs . map { | obj | obj . ext ( '.d' ) } load_deps ( @test_deps ) if ( @settings [ 'TEST_FRAMEWORK' ] . nil? or @settings [ 'TEST_FRAMEWORK' ] . empty? ) @test_fw = @tc . default_test_framework else @test_fw = @tc . test_framework ( @settings [ 'TEST_FRAMEWORK' ] ) end @test_inc_dirs = @settings [ 'TEST_SOURCE_DIRS' ] . empty? ? '' : @test_fw . include . join ( ' ' )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "IN", "and", "NOT", "IN", "expressions", "."], "add_tokens": "AND OR NOT AS ON IS NULL BY LIKE ILIKE BETWEEN IN } [ SQLTree :: Token :: IN , SQLTree :: Token :: IS , SQLTree :: Token :: BETWEEN , SQLTree :: Token :: LIKE , SQLTree :: Token :: ILIKE , SQLTree :: Token :: NOT ]", "del_tokens": "AND OR NOT AS ON IS NULL BY LIKE ILIKE BETWEEN } [ SQLTree :: Token :: IS , SQLTree :: Token :: BETWEEN , SQLTree :: Token :: LIKE , SQLTree :: Token :: ILIKE , SQLTree :: Token :: NOT ]", "commit_type": "add"}
{"commit_tokens": ["added", "some", "strategy", "override", "modified", "client", "structure", "to", "make", "it", "clearer"], "add_tokens": "VERSION = \"0.1.0\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "scope", "of", "Vcard", ".", "configure", "and", "Vcard", ".", "configuration", "methods"], "add_tokens": "def self . configuration def self . configure", "del_tokens": "def configuration def configure", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "configure", "block", "create", "ApiDocumentation", "instances", "and", "implement", "Enumerable", "over", "them", "."], "add_tokens": "include Enumerable configurations [ selector ] = ApiDocumentation . new ( configuration ) def each ( & block ) configurations . each_value & block end", "del_tokens": "configurations [ selector ] = configuration", "commit_type": "make"}
{"commit_tokens": ["Added", "methods", "to", "process", "selected", "nodes", "using", "a", "Ruby", "block"], "add_tokens": "attr_reader :nodesets # @param nodesets [Array<Nokogiri::XML::NodeSet>] Selected nodes def initialize ( nodesets ) @nodesets = nodesets each_node do | nodeset | nodeset . remove end def replace ( template ) each_node do | node | value = template . evaluate ( node ) def append ( template ) each_node do | node | value = template . evaluate ( node ) each_node do | node | each_node do | node | protected # Execute a block for each node # # @yield Block to execute for each node # @yieldparam node [Nokogiri::XML::Node] Current node def each_node @nodesets . each do | nodeset | nodeset . each do | node | yield node end end end", "del_tokens": "attr_reader :nodes # @param nodes [Nokogiri::XML::NodeSet] Selected nodes def initialize ( nodes ) @nodes = nodes @nodes . remove def replace ( template = nil , & block ) @nodes . each do | node | value = template . evaluate ( node , & block ) def append ( template = nil , & block ) @nodes . each do | node | value = template . evaluate ( node , & block ) @nodes . each do | node | @nodes . each do | node |", "commit_type": "add"}
{"commit_tokens": ["Remove", "checks", "on", "constants", "that", "are", "true", "."], "add_tokens": "b = revert_byte ( b ) crc ^= FINAL_XOR crc = revert_bits ( crc )", "del_tokens": "REVERSE_CRC_RESULT = true REVERSE_DATA = true b = revert_byte ( b ) if REVERSE_DATA crc ^= FINAL_XOR if FINAL_XOR crc = revert_bits ( crc ) if REVERSE_CRC_RESULT", "commit_type": "remove"}
{"commit_tokens": ["use", "correct", "class", "name", "for", "adding", "to", "client", "to", "log"], "add_tokens": "nc = new_client HotTub . logger . info \"Adding HotTub client: #{nc.class.name} to pool\" @pool << nc", "del_tokens": "HotTub . logger . info \"Adding HotTub client: #{@client.class.name} to pool\" @pool << new_client", "commit_type": "use"}
{"commit_tokens": ["Updated", "the", "search_for", "to", "parse", "the", "-", "OR", "-", "param", ".", "Added", "more", "unit", "tests", "."], "add_tokens": "elsif search_condition . length == 2 && search_condition . last == :or word1 , word2 = query_params [ keyword_name ] . split ( ' OR ' ) query_params . delete ( keyword_name ) keyword_name_a = \"#{keyword_name.to_s}a\" . to_sym keyword_name_b = \"#{keyword_name.to_s}b\" . to_sym query_params [ keyword_name_a ] = word1 query_params [ keyword_name_b ] = word2 keyword_conditions = self . scoped_search_fields . map do | field | field_name = connection . quote_table_name ( table_name ) + \".\" + connection . quote_column_name ( field ) \"(#{field_name} LIKE :#{keyword_name_a.to_s} OR #{field_name} LIKE :#{keyword_name_b.to_s})\" end conditions << \"(#{keyword_conditions.join(' OR ')})\" end return { :conditions => [ conditions . join ( ' AND ' ) , query_params ] }", "del_tokens": "end return { :conditions => [ conditions . join ( ' AND ' ) , query_params ] }", "commit_type": "update"}
{"commit_tokens": ["Changing", "to", "use", "autoload", "for", "better", "performance"], "add_tokens": "autoload :Socket , 'socket' autoload :YAML , 'yaml' autoload :Hash , 'active_support/core_ext/hash/conversions' autoload :HashWithIndifferentAccess , 'active_support/core_ext/hash/indifferent_access' autoload :Hash , 'rconfig/core_ext/hash' autoload :ConfigHash , 'rconfig/config_hash' autoload :PropertiesFileParser , 'rconfig/properties_file_parser'", "del_tokens": "require 'socket' require 'yaml' require 'active_support' require 'active_support/core_ext' require 'active_support/core_ext/hash/conversions' require 'active_support/core_ext/hash/indifferent_access' require 'rconfig/core_ext/hash' require 'rconfig/config_hash' require 'rconfig/properties_file_parser'", "commit_type": "change"}
{"commit_tokens": ["Updated", "root", "path", "of", "engine"], "add_tokens": "return request . env [ 'omniauth.origin' ] || stored_location_for ( resource ) || hicube_pages_path", "del_tokens": "return request . env [ 'omniauth.origin' ] || stored_location_for ( resource ) || pages_path", "commit_type": "update"}
{"commit_tokens": ["FIXED", ":", "RedisObject#db", "does", "not", "set", "@db"], "add_tokens": "@opts [ :class ] . db elsif parent? parent . db self . class . db || @db || 0", "del_tokens": "return @db if @db @db = @opts [ :class ] . db @db = parent? ? parent . db : self . class . db @db ||= 0 @db", "commit_type": "fix"}
{"commit_tokens": ["Add", "rake", "task", "for", "test", "execution"], "add_tokens": "require 'awesome_print' class TranslationFileExportTest < Test :: Unit :: TestCase def dtest_load_language def dtest_flatten_translations_hash def dtest_load_translations def dtest_write_to_csv", "del_tokens": "class TranslationsTest < Test :: Unit :: TestCase def test_load_language def test_flatten_translations_hash def test_load_translations def test_write_to_csv", "commit_type": "add"}
{"commit_tokens": ["Improves", "test", "setup", "for", "APN", "Feedback", "class"], "add_tokens": "describe Pling :: APN :: Feedback do let ( :connection ) { double ( Pling :: APN :: Connection , :closed? => false ) . as_null_object } before do Pling :: APN :: Connection . stub ( :new ) . and_return ( connection ) it { should respond_to ( :get ) }", "del_tokens": "module Pling module APN describe Feedback do it { should respond_to ( :get ) } end", "commit_type": "improve"}
{"commit_tokens": ["Added", "PostGIS", "to", "the", "available", "addapters", "for", "reserve_with_scope", "method"], "add_tokens": "when \"PostgreSQL\" , \"PostGIS\"", "del_tokens": "when \"PostgreSQL\"", "commit_type": "add"}
{"commit_tokens": ["Make", "Mongoid", "::", "Tree", "::", "Traversal", "an", "ActiveSupport", "::", "Concern"], "add_tokens": "extend ActiveSupport :: Concern", "del_tokens": "## # Extend ClassMethods into the class that's including Traversal. # def self . included ( base ) base . extend ClassMethods end", "commit_type": "make"}
{"commit_tokens": ["fix", "diff", "nothing", "case", "for", "google", "translate"], "add_tokens": "Hash [ keys . zip ( translated_texts || [ ] ) ]", "del_tokens": "Hash [ keys . zip ( translated_texts ) ]", "commit_type": "fix"}
{"commit_tokens": ["Removed", "backward", "from", "reading", "events", "in", "batch"], "add_tokens": "repository . load_events_batch ( stream_name , start , count ) end", "del_tokens": "unless direction != :forward repository . load_events_batch ( stream_name , start , count ) else repository . load_events_batch ( stream_name , start , count ) . reverse end end", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "the", ":", "hide_documentation_path", "option", "for", "prefixed", "APIs"], "add_tokens": "unless @@hide_documentation_path and route . route_path . include? @@mount_path @combined_routes [ resource ] << route end", "del_tokens": "@combined_routes [ resource ] << route", "commit_type": "fix"}
{"commit_tokens": ["Added", "pure", "options", "to", "builder"], "add_tokens": "opt :build_tokyo , \"Build the tokyo dataset?\" , :default => false opt :build_pure , \"Build the pure ruby dataset?\" , :default => false Trollop :: die :build_tokyo , \"Either tokyo dataset or pure ruby dataset are required\" . red if ! opts [ :build_tokyo ] && ! opts [ :build_pure ]", "del_tokens": "require 'pstore'", "commit_type": "add"}
{"commit_tokens": ["Add", "#stream", "for", "streaming", "chunks", "of", "remote", "files"], "add_tokens": "def stream ( url , options = { } ) uri = URI . parse ( url ) http = Net :: HTTP . new ( uri . host , uri . port ) # taken from open-uri implementation if uri . is_a? ( URI :: HTTPS ) require \"net/https\" http . use_ssl = true http . verify_mode = options [ :ssl_verify_mode ] || OpenSSL :: SSL :: VERIFY_PEER store = OpenSSL :: X509 :: Store . new if options [ :ssl_ca_cert ] Array ( options [ :ssl_ca_cert ] ) . each do | cert | File . directory? ( cert ) ? store . add_path ( cert ) : store . add_file ( cert ) end else store . set_default_paths end http . cert_store = store end http . start do req = Net :: HTTP :: Get . new ( uri . to_s ) http . request ( req ) do | response | content_length = response [ \"Content-Length\" ] . to_i if response [ \"Content-Length\" ] response . read_body { | chunk | yield chunk , content_length } end end end", "del_tokens": "require \"uri\"", "commit_type": "add"}
{"commit_tokens": ["Add", "Channel#ad_impressions", "(", "no", "options", "no", "errors", ")"], "add_tokens": "\"#<#{self.class} @refresh_token=#{@refresh_token[0..2]}...>\"", "del_tokens": "\"#<#{self.class} @id=#{@id}>\"", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "simpler", "way", "to", "exclude", "inappropriate", "tests", "."], "add_tokens": "describe Lazily do end if defined? ( :: Enumerator )", "del_tokens": "describe Lazily , :needs_enumerators => true do end", "commit_type": "use"}
{"commit_tokens": ["Updated", "gem", "information", "files", "."], "add_tokens": "VERSION = \"0.2.0\"", "del_tokens": "VERSION = \"0.1.5\"", "commit_type": "update"}
{"commit_tokens": ["Add", "option", "for", "absolute", "paths"], "add_tokens": "def asset_path ( asset , options = { } ) graph_starter . asset_path ( { id : asset , model_slug : asset . class . model_slug } . merge ( options ) )", "del_tokens": "def asset_path ( asset ) graph_starter . asset_path ( id : asset , model_slug : asset . class . model_slug )", "commit_type": "add"}
{"commit_tokens": ["Add", "drain", ".", "rb", "which", "calls", "dr", ".", "rb"], "add_tokens": "module DR", "del_tokens": "module Drain", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "clients", "with", "the", "new", "API", "perspective"], "add_tokens": "When 'I update the client named \"$1\" with the following:' do | name , table | client . attributes = table . rows_hash Then 'the client named \"$1\" should have the following attributes:' do | name , table | table . rows_hash . each do | key , value | client . send ( key ) . should == value end", "del_tokens": "When 'I update the client named \"$1\" with the following details \"$2\"' do | name , details | client . details = details Then 'the details of \"$1\" should be \"$2\"' do | name , details | client . details . should == details", "commit_type": "fix"}
{"commit_tokens": ["Add", "convert", "for", "USD", "in", "api"], "add_tokens": "def validate_first_unit ( firstUnit ) if @data == false || return_hash_currency ( firstUnit ) == false return false else return true end end def validate_second_unit ( secondUnit ) if secondUnit == \"USD\" return true ; else return false end end dictionary_api if validate_second_unit ( secondUnit ) == true if validate_first_unit ( firstUnit ) == true finalValue = valueToConvert / @hash [ firstUnit ] else return 0 end else if data_validate_api ( firstUnit , secondUnit ) finalValue = ( valueToConvert / @hash [ firstUnit ] ) * @hash [ secondUnit ] return finalValue else return 0 end", "del_tokens": "if dictionary_api ( firstUnit , secondUnit ) == false return 0 else finalValue = ( valueToConvert / @hash [ firstUnit ] ) * @hash [ secondUnit ] return finalValue", "commit_type": "add"}
{"commit_tokens": ["removing", "#connectivity", "alias", "(", "only", "arc", "keyword", "remains", ")", "-", "connectivity", "is", "now", "a", "zz", "structure", "technical", "term"], "add_tokens": "# Returns names of the (places connected to) arcs. def aa ; arcs . map & :name end", "del_tokens": "alias :connectivity :arcs # Returns connectivity as names. def cc ; connectivity . map & :name end # Returns connectivity as name symbols. # def cc_sym ; cc . map & :to_sym end alias :cc cc_sym", "commit_type": "remove"}
{"commit_tokens": ["Fix", "db", "method", "for", "add", "sources"], "add_tokens": "Farmstead :: DB . add_source ( module_name , module_type , suby )", "del_tokens": "Farmstead :: DB . setup ( module_name , module_type , suby )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "traking", "change", "of", "fileupload", "guid"], "add_tokens": "@fileupload_changed = ( @fileupload_guid != value ) if @fileupload_changed . nil?", "del_tokens": "@fileupload_changed = ( @fileupload_guid != value )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "dependency", "on", "a", "Rails", "application", "to", "run", "tests", "."], "add_tokens": "require 'rubygems' require 'active_record' # Mock out the required environment variables. RAILS_ENV = 'test' RAILS_ROOT = Dir . pwd", "del_tokens": "begin require File . dirname ( __FILE__ ) + '/../../../../config/boot' require 'active_record' rescue LoadError require 'rubygems' require_gem 'activerecord' end", "commit_type": "remove"}
{"commit_tokens": ["Added", "more", "type", "lookups", ";", "Addressed", "PR", "comments"], "add_tokens": "'list<QDM.Component>' : 'Array' , 'System.String' : 'String' , 'list<QDM.Id>' : 'Array' , 'list<QDM.ResultComponent>' : 'Array' , 'list<QDM.FacilityLocation>' : 'Array' , 'list<System.Code>' : 'Array' , 'QDM.Id' : 'String' 'list<QDM.Component>' : '[]' , 'System.String' : 'String' , 'list<QDM.Id>' : '[]' , 'list<QDM.ResultComponent>' : '[]' , 'list<QDM.FacilityLocation>' : '[]' , 'list<System.Code>' : '[]' , 'QDM.Id' : 'String' attribute_name = attribute &. attributes [ 'name' ] &. value attribute_type = attribute &. attributes [ 'type' ] &. value next if attribute_name . blank? || attribute_type . blank? # Do a quick sanity check on attribute types datatypes . each do | datatype , attributes | attributes . each do | attribute | raise 'Unsupported type from modelinfo file: ' + attribute [ :type ] if MODELINFO_RUBY_LOOKUP [ attribute [ :type ] ] . blank? end end", "del_tokens": "'list<QDM.Component>' : 'Array' 'list<QDM.Component>' : '[]' attribute_name = attribute . attributes [ 'name' ] . value attribute_type = attribute . attributes [ 'type' ] . value", "commit_type": "add"}
{"commit_tokens": ["Added", "configurable", "writer", "(", "so", "don", "t", "only", "have", "to", "use", "configure", "to", "configure", "something", ")"], "add_tokens": "# Define the reader # Define the writer define_method ( \"#{attribute}=\" ) do | value | configuration_hash [ attribute ] = value end", "del_tokens": "# Define the reader method on the instance", "commit_type": "add"}
{"commit_tokens": ["Making", "the", "output", "path", "for", "IPAs", "configurable", ";", "defaults", "to", "the", "working", "directory", "."], "add_tokens": ":ipa_destination_path => \" . / \" , File . join ( File . expand_path ( ipa_destination_path ) , ipa_name )", "del_tokens": "def dist_path File . join ( derived_build_dir_from_build_output , \"pkg\" ) end File . join ( dist_path , ipa_name ) FileUtils . rm_rf ( \"#{@configuration.dist_path}\" ) FileUtils . mkdir_p ( \"#{@configuration.dist_path}\" )", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "HTML", "encoding", "of", "JavaScript", "quotes"], "add_tokens": "xhtml . script ( :type => \"text/javascript\" ) { \"var RecaptchaOptions = #{options[:display].to_json};\\n\" }", "del_tokens": "xhtml . script ( :type => \"text/javascript\" ) { xhtml . text! \"var RecaptchaOptions = #{options[:display].to_json};\\n\" }", "commit_type": "fix"}
{"commit_tokens": ["updated", "acts_as_taggable_on", "gem", "and", "corrected", "migrations", "+", "tests"], "add_tokens": "VERSION = \"0.1.0\"", "del_tokens": "VERSION = \"0.0.4\"", "commit_type": "update"}
{"commit_tokens": ["Added", "yard", "gem", "and", "exit", "code", "messages"], "add_tokens": "# A list of messages of what the process exit code might indicate. ExitCodeMessages = { 0 => 'Successful operation.' , 1 => 'Non fatal error(s) occurred.' , 2 => 'A fatal error occurred.' , 3 => 'Invalid checksum. Data is damaged.' , 4 => 'Attempt to modify an archive locked by \\'k\\' command.' , 5 => 'Write error.' , 6 => 'File open error.' , 7 => 'Wrong command line option.' , 8 => 'Not enough memory.' , 9 => 'File creation error.' , 10 => 'No files matching the specified mask and options were found.' , 11 => 'Wrong password.' , 255 => 'User stopped the process.' } # @return [Array] the list of files. # @return [Hash] the list of options. # # @param [String] filename The archive's file name. # @param [CommandLineOptions, optional] options The options to pass to the # command line. # # @option options [String] :extra A string of command line options that will # be passed directly to the command line. # @option options [Boolean] :force Assume Yes on all queries. # @option options [Boolean] :old_format Use the old style volume naming # scheme. # @option options [Fixnum, String] :volume_size The volume size in case of # multiple volumes. # @option options [Fixnum] :compression Set compression level. # (0-store...3-default...5-maximal) # @option options [Boolean] :exclude_path Exclude paths from names. def initialize filename , options = { } @filename = filename # @return [Array] the list of files. ` #{ command_line } ` case $? when 2 .. 11 raise else return true end if $? == 0 return true else puts \"RAR command failed!\" private # @return [String] the concatenated list of command-line switches. def command_line_options Shellwords . join @options . to_a end # @return [String] the concatenated command-line with all the switches. %{#{RAR.executable} a #{command_line_options} #{Shellwords.escape @filename} #{Shellwords.join @files}}", "del_tokens": "# @return [Array] The list of files. # @return [Hash] The list of options. def initialize options = { } # @return [Array] The list of files. result = IO . popen command_line Open3 . popen3 command_line do | stdin , stdout , stderr , wait_thread | private # @return [String] The concatenated command-line with all the switches. %{#{RAR.executable} a -idcd output.rar #{Shellwords.join @files}}", "commit_type": "add"}
{"commit_tokens": ["change", "layout", "method", "to", "avoid", "collisions"], "add_tokens": "write_file ( File . join ( site_path , 'app/views/layouts/application.html.erb' ) , \"<%= render_layout do %>\\n<% end %>\" )", "del_tokens": "write_file ( File . join ( site_path , 'app/views/layouts/application.html.erb' ) , \"<%= layout do %>\\n<% end %>\" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "assigning", "a", "unique", "client", "identifier", "."], "add_tokens": "elsif @clientid . nil?", "del_tokens": "elsif clientid . nil?", "commit_type": "fix"}
{"commit_tokens": ["remove", "annoying", "prompt", "on", "bad", "configuration"], "add_tokens": "# jdbc:as400://[host];database name=[database] # jdbc:as400://[host];proxy server=[proxy:port] # jdbc:as400://[host];proxy server=[proxy:port];prompt=false url << ';prompt=false'", "del_tokens": "# jdbc:as400://myiSeries;database name=IASP1 # jdbc:as400://[host];proxy server=HODServerName:proxyServerPort", "commit_type": "remove"}
{"commit_tokens": ["Add", "fully_paid_on", "amount_due", "amount_paid", "and", "amount_credited", "to", "XeroGateway", "::", "Invoice", "."], "add_tokens": "attr_accessor :invoice_id , :invoice_number , :invoice_type , :invoice_status , :date , :due_date , :reference , :tax_inclusive , :includes_tax , :line_items , :contact , :payments , :fully_paid_on , :amount_due , :amount_paid , :amount_credited when \"FullyPaidOn\" then invoice . fully_paid_on = parse_date_time ( element . text ) when \"AmountDue\" then invoice . amount_due = BigDecimal . new ( element . text ) when \"AmountPaid\" then invoice . amount_paid = BigDecimal . new ( element . text ) when \"AmountCredited\" then invoice . amount_credited = BigDecimal . new ( element . text )", "del_tokens": "attr_accessor :invoice_id , :invoice_number , :invoice_type , :invoice_status , :date , :due_date , :reference , :tax_inclusive , :includes_tax , :line_items , :contact , :payments", "commit_type": "add"}
{"commit_tokens": ["Add", "acknowledge", "method", "to", "Realex", "::", "Notification", "and", "change", "production", "Realex", "url"], "add_tokens": "self . production_url = 'https://epage.payandshop.com/epage.cgi' def acknowledge ( authcode = nil ) verified? end", "del_tokens": "self . production_url = 'https://hpp.realexpayments.com/pay'", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "I", "missed", "when", "rebasing", "7833af96b0"], "add_tokens": "inlineTemplates : get_inline_signers ( signers , idx )", "del_tokens": "inlineTemplates : get_inline_signers ( signers , idx ) , document : document_hash", "commit_type": "fix"}
{"commit_tokens": ["Allowed", "a", "mouse", "-", "click", "on", "the", "ScrollBar", "runner", "to", "scroll", "the", "view", "by", "one", "screen", "."], "add_tokens": "scroll_window ( width : WIDTH , height : HEIGHT , background_color : Gosu :: Color . rgb ( 0 , 100 , 0 ) ) do scroll_window ( width : 300 , height : 150 ) do scroll_window ( width : 300 , height : 150 ) do", "del_tokens": "scroller = scroll_window ( width : WIDTH , height : HEIGHT , background_color : Gosu :: Color . rgb ( 0 , 100 , 0 ) ) do slider ( width : WIDTH ) do | sender , value | scroller . offset_x = ( scroller . content_width - scroller . view_width ) * value scroller . offset_y = ( scroller . content_height - scroller . view_height ) * value end text_scroller = scroll_window ( width : 300 , height : 150 ) do slider ( width : 300 ) do | sender , value | text_scroller . offset_y = ( text_scroller . content_height - text_scroller . view_height ) * value end buttons_scroller = scroll_window ( width : 300 , height : 150 ) do slider ( width : 300 ) do | sender , value | buttons_scroller . offset_y = ( buttons_scroller . content_height - buttons_scroller . view_height ) * value end", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "little", "typo", "in", "test"], "add_tokens": "it \"should translate the scope too\" do", "del_tokens": "it \"should translate the routes too\" do", "commit_type": "fix"}
{"commit_tokens": ["Add", ".", "query_type", "option", "to", "display", "the", "trace", "only", "for", "DB", "read", "or", "write", "queries"], "add_tokens": "attr_accessor :query_type ActiveRecordQueryTrace . query_type = :all && ! ( ActiveRecordQueryTrace . ignore_cached_queries && payload [ :cached ] ) && display_backtrace_for_query_type? ( payload ) end def display_backtrace_for_query_type? ( payload ) invalid_type_msg = 'Invalid ActiveRecordQueryTrace.query_type value ' \"#{ActiveRecordQueryTrace.level}. Should be :all, :read, or :write.\" case ActiveRecordQueryTrace . query_type when :all then true when :read then db_read_query? ( payload ) when :write then ! db_read_query? ( payload ) else raise ( invalid_type_msg ) end end def db_read_query? ( payload ) payload [ :name ] &. match ( / Load \\Z / )", "del_tokens": "&& ! ( ActiveRecordQueryTrace . ignore_cached_queries && payload [ :cached ] )", "commit_type": "add"}
{"commit_tokens": ["add", "team", "and", "organization", "models"], "add_tokens": "require 'dalli' require 'digest' autoload :Helpers , \"squad_goals/helpers\" autoload :App , \"squad_goals/app\" autoload :Team , \"squad_goals/team\" autoload :Organization , \"squad_goals/organization\" class << self def root File . expand_path './squad_goals' , File . dirname ( __FILE__ ) end def views_dir @views_dir ||= File . expand_path 'views' , SquadGoals . root end def views_dir = ( dir ) @views_dir = dir end def public_dir @public_dir ||= File . expand_path 'public' , SquadGoals . root end def public_dir = ( dir ) @public_dir = dir end", "del_tokens": "require 'squad_goals/helpers' require 'squad_goals/app' def self . root File . expand_path './squad_goals' , File . dirname ( __FILE__ ) end def self . views_dir @views_dir ||= File . expand_path 'views' , SquadGoals . root end def self . views_dir = ( dir ) @views_dir = dir end def self . public_dir @public_dir ||= File . expand_path 'public' , SquadGoals . root end def self . public_dir = ( dir ) @public_dir = dir end end unless SquadGoals :: App . production? Dotenv . load stack = Faraday :: RackBuilder . new do | builder | builder . response :logger builder . use Octokit :: Response :: RaiseError builder . adapter Faraday . default_adapter Octokit . middleware = stack", "commit_type": "add"}
{"commit_tokens": ["move", "ssh_port", "to", "be", "a", "constant"], "add_tokens": "DEFAULT_SSH_PORT = '22' if ssh_port . empty? ssh_port = DEFAULT_SSH_PORT end \"ssh\" => { \" ssh_user \" => ssh_user, \" ssh_key_path \" => ssh_key_path , \" ssh_port \" => ssh_port } }", "del_tokens": "\"ssh\" => { \" ssh_user \" => ssh_user, \" ssh_key_path \" => ssh_key_path , \" ssh_port \" => \" 22 \" } }", "commit_type": "move"}
{"commit_tokens": ["Added", "basic", "Shop", "model", "&", "association", ";", "Refactoring", "of", "attributes", "and", "tests"], "add_tokens": "include Etsy :: Model def shop Shop . find_by_user_id ( id )", "del_tokens": "def self . attribute ( name , options = { } ) from = options . fetch ( :from , name ) class_eval <<-CODE def #{name} @result [ '#{from}' ] end CODE end def initialize ( result ) # :nodoc: @result = result", "commit_type": "add"}
{"commit_tokens": ["Added", "required", "properties", "to", "Production", "/", "LRItem", "for", "table", "generation"], "add_tokens": "attr_reader :prod , :name , :usyms", "del_tokens": "attr_reader :prod", "commit_type": "add"}
{"commit_tokens": ["Move", "DNS", "resolver", "s", "send_request", "method", "under", "protected"], "add_tokens": "# Send a request to the DNS server def send_request @socket . connect @nameservers . first , DNS_PORT @socket . send request_message , 0 end return @resolver . __send__ ( :send_request ) if @attempts <= RETRIES end", "del_tokens": "# Send a request to the DNS server def send_request @socket . connect @nameservers . first , DNS_PORT @socket . send request_message , 0 end return @resolver . send_request if @attempts <= RETRIES end", "commit_type": "move"}
{"commit_tokens": ["Add", "spec", "for", "Record#save", ".", "Execute", "before", "/", "after", "create", "hooks", "."], "add_tokens": "it \"builds and saves an instance, sets its id, and ensures it is present in the session's identity map\" do blog . should equal ( Blog . find ( blog . id ) ) describe \"#save\" do before do Blog . create_table end describe \"when the record has not yet been inserted into the database\" do attr_reader :blog before do @blog = Blog . new ( { :title => \"Unsaved Blog\" } ) blog . id . should be_nil end it \"inserts the record, sets its id, and ensures it is present in the session's identity map\" do blog . save blog . id . should_not be_nil blog . should equal ( Blog . find ( blog . id ) ) end it \"executes before_create and after_create hooks at the appropriate moments\" do mock ( blog ) . before_create { blog . id . should be_nil } mock ( blog ) . after_create { blog . id . should_not be_nil } blog . save end end end", "del_tokens": "it \"builds and saves an instance, ensuring it is present in the identity map\" do blog . should == Blog . find ( blog . id )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "spec", "for", "order", "with", "no", "stock"], "add_tokens": "context '' do let ( :add_to_cart ) do customer . reset_cart_item ( product , quantity : stock . quantity ) stock . update_attributes ( quantity : 0 ) end its ( :response ) { should redirect_to ( controller . comable . cart_path ) } end", "del_tokens": "context '' do let ( :add_to_cart ) { customer . add_cart_item ( product , quantity : stock . quantity + 1 ) } let ( :request ) { post :create , order_params } its ( :response ) { should redirect_to ( controller . comable . cart_path ) } end", "commit_type": "fix"}
{"commit_tokens": ["fix", "another", "typo", "in", "the", "AR", "adapter"], "add_tokens": "when :integer then \"#{var_name}.to_i rescue #{var_name} ? 1 : 0\"", "del_tokens": "when :integer then \"#{var_name}.to_i rescue value ? 1 : 0\"", "commit_type": "fix"}
{"commit_tokens": ["Updated", "asunit", "library", "to", "pull", "latest", "revision"], "add_tokens": "t . version = '3.2.6' url : http : / /projectsprouts . googlecode . com / files / asunit3 - 1.6 . zip md5 : 7 f7181c7e34087ec6d5aef806867eec5", "del_tokens": "t . version = '3.2.5' url : http : / /projectsprouts . googlecode . com / files / asunit3 - 1.5 . zip md5 : 7 eca594553fc9613523f554b8a1a6a5c", "commit_type": "update"}
{"commit_tokens": ["add", "frame", "number", "and", "checksum", "when", "sending", "messages"], "add_tokens": "when :begin then @frame_number = 0 ENQ @frame_number = ( @frame_number + 1 ) % 8 self . class . wrap_message ( data , @frame_number ) expected_checksum = ( frame_number + data ) . each_byte . def self . wrap_message ( string , frame_number ) frame_number = ( frame_number % 8 ) . to_s checksum = ( frame_number + string ) . each_byte . inject ( 16 ) { | a , b | ( a + b ) % 0x100 } checksum = checksum . to_s ( 16 ) . upcase . rjust ( 2 , \"0\" ) \"\\002#{frame_number}#{string}\\015\\003#{checksum}\\015\\012\"", "del_tokens": "when :begin then ENQ expected_checksum = ( frame_number + data ) . to_enum ( :each_byte ) . def self . wrap_message ( string , sequence_number )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "distinguish", "value", "."], "add_tokens": "fail ConversionTypeError , \"'#{value}' could not be converted \" \"from `#{source}` into `#{target}` \"", "del_tokens": "fail ConversionTypeError , \"#{value} could not be converted \" \"from `#{source}` into `#{target}`\"", "commit_type": "change"}
{"commit_tokens": ["add", "documentation", "and", "rename", "destroy_jobs", "to", "the", "more", "descriptive", "destroy_failed_jobs"], "add_tokens": "# By default failed jobs are destroyed after too many attempts. # If you want to keep them around (perhaps to inspect the reason # for the failure), set this to false. cattr_accessor :destroy_failed_jobs self . destroy_failed_jobs = true destroy_failed_jobs ? destroy : update_attribute ( :failed_at , Time . now )", "del_tokens": "cattr_accessor :destroy_jobs self . destroy_jobs = true destroy_jobs ? destroy : update_attribute ( :failed_at , Time . now )", "commit_type": "add"}
{"commit_tokens": ["update", "spec", "to", "test", "users", "count"], "add_tokens": "expect ( company . users . count ) . to eq 0", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Adds", "update", "volume", "with", "tests"], "add_tokens": "param :id , required : true param :display_name , required : false param :display_description , required : false p = { volume : { } } [ :display_name , :display_description ] . each do | key | p [ :volume ] [ key ] = params [ key ] if params [ key ]", "del_tokens": "param :id , required : true param :name , required : false param :description , required : false p = { server : { } } [ :name , :description ] . each do | key | p [ :server ] [ key ] = params [ key ] if params [ key ]", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "store", "all", "keys", "as", "strings", "to", "ease", "writing", "/", "reading", "files", "and", "parsing", "command", "line", "applications", "options"], "add_tokens": "return unless deep_find ( @settings , keys . last . to_s ) . nil? merge ( unmarshal ( file ) ) alias to_h to_hash keys . map ( & :to_s ) value = settings . fetch ( key . to_s , settings [ key . to_sym ] )", "del_tokens": "return unless deep_find ( @settings , keys . last ) . nil? merge ( self . class . normalize_hash ( unmarshal ( file ) ) ) keys value = settings [ key ] || settings [ key . to_sym ]", "commit_type": "change"}
{"commit_tokens": ["fixed", "lev", "cleaned", "up", "dev", "users", "controller"], "add_tokens": "def index ; end success : lambda { redirect_to dev_users_path , notice : 'Success!' } , success : lambda { redirect_to dev_users_path , notice : 'Success!' } ,", "del_tokens": "def index end success : lambda { redirect_to 'index' , notice : 'Success!' } , success : lambda { redirect_to 'index' , notice : 'Success!' } ,", "commit_type": "fix"}
{"commit_tokens": ["making", "sure", "psych", "defines", "to_yaml", "on", "object"], "add_tokens": "# FIXME: remove this when syck is removed o = Object . new a = o . method ( :psych_to_yaml ) b = o . method ( :to_yaml ) raise \"psych should define to_yaml\" unless a == b", "del_tokens": "o = Object . new if o . respond_to? ( :to_yaml ) if o . method ( :to_yaml ) . source_location . first !~ / psych / Object . send :alias_method , :old_to_yaml , :to_yaml Object . send :remove_method , :to_yaml end end", "commit_type": "make"}
{"commit_tokens": ["Removed", "dev", "logging", "(", "how", "embarrassing", ")"], "add_tokens": "VERSION = \"2.3.1\"", "del_tokens": "VERSION = \"2.3.0\"", "commit_type": "remove"}
{"commit_tokens": ["remove", "skip", "tests", "from", "unit", "tests"], "add_tokens": "# only for Selendroid", "del_tokens": "skip ( 'Because only for Selendroid' )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "result", "of", "delete", "."], "add_tokens": "return false unless exists? fail StackUpdateError , \"stack delete failed\" unless status . nil? true", "del_tokens": "fail StackUpdateError , \"stack delete failed\" unless status == \"DELETE_COMPLETE\" true false", "commit_type": "fix"}
{"commit_tokens": ["Add", "Fast", ".", "ast", "method"], "add_tokens": "def ast ( content ) Parser :: CurrentRuby . parse ( content ) end ast ( IO . read ( file ) )", "del_tokens": "Parser :: CurrentRuby . parse ( IO . read ( file ) )", "commit_type": "add"}
{"commit_tokens": ["use", "physical", "spaces", "rather", "than", "tab", "character"], "add_tokens": "out = \" \"", "del_tokens": "out = \"\\t\"", "commit_type": "use"}
{"commit_tokens": ["added", "tests", "for", ":", "as", "=", ">", "Array"], "add_tokens": "def option_with_argument ( * args , & block ) options = args . shift slop = Slop . new option = slop . opt ( * args ) slop . parse ( options ) slop . find { | opt | opt . key == option . key } end test 'splits argument_value with :as => array' do assert_equal %w/ lee john bill / , option_with_argument ( %w/ --people lee,john,bill / , :people , true , :as => Array ) . argument_value assert_equal %w/ lee john bill / , option_with_argument ( %w/ --people lee:john:bill / , :people , true , :as => Array , :delimiter => ':' ) . argument_value assert_equal [ 'lee' , 'john,bill' ] , option_with_argument ( %w/ --people lee,john,bill / , :people , true , :as => Array , :limit => 2 ) . argument_value assert_equal [ 'lee' , 'john:bill' ] , option_with_argument ( %w/ --people lee:john:bill / , :people , true , :as => Array , :limit => 2 , :delimiter => ':' ) . argument_value end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "initialize", "var", "and", "remove", "warnings"], "add_tokens": "@top_level_spinner = nil", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["Add", "accessors", "to", "BuildTarget", "domain", "model"], "add_tokens": "get ( HTTP_PATH ) . map do | target_h | BuildTarget . new ( self , target_h )", "del_tokens": "get ( HTTP_PATH ) . map do | attributes | build_target ( attributes )", "commit_type": "add"}
{"commit_tokens": ["updated", "node", ".", "rb", "and", "cluster", ".", "rb", "so", "that", "they", "are", "compatible", "with", "es6", ".", "Tested", "in", "a", "es6", "cluster", "and", "it", "was", "able", "to", "drain", ".", "I", "will", "next", "need", "to", "test", "with", "different", "versions", "of", "ES", "and", "confirm", "that", "all", "es", "versions", "are", "compatible"], "add_tokens": "wait_for_status : 'green'", "del_tokens": "wait_for_status : 'green' , timeout : 60", "commit_type": "update"}
{"commit_tokens": ["Move", "request", "classes", "into", "separate", "files", "/", "specs"], "add_tokens": "headers = options [ :headers ] || { 'HTTP_ACCEPT_VERSION' => '1.0.0' } Struct . new ( :headers , :path ) . new ( headers , options [ :path ] ) ,", "del_tokens": "Struct . new ( :headers , :path ) . new ( options [ :headers ] , options [ :path ] ) ,", "commit_type": "move"}
{"commit_tokens": ["fix", "client", "behavior", "with", "modified", "global", "behavior"], "add_tokens": "attr_reader :name , :callbacks , :user_data PusherClient . logger . debug \"Binding #{event_name} to #{name}\" logger . debug ( \"Dispatching #{global ? 'global ' : ''}callbacks for #{event_name}\" ) logger . debug \"No #{global ? 'global ' : ''}callbacks to dispatch for #{event_name}\"", "del_tokens": "attr_reader :name , :callbacks , :global_callbacks , :user_data @global_callbacks = { } dispatch_global_callbacks ( event_name , data ) logger . debug ( \"Dispatching callbacks for #{event_name}\" ) logger . debug ( \"No callbacks to dispatch for #{event_name}\" ) end end def dispatch_global_callbacks ( event_name , data ) if @global_callbacks [ event_name ] logger . debug ( \"Dispatching global callbacks for #{event_name}\" ) @global_callbacks [ event_name ] . each do | callback | callback . call ( data ) end else logger . debug ( \"No global callbacks to dispatch for #{event_name}\" )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "make", "vars", "a", "bit", "clearer"], "add_tokens": "column_width = widths [ col ] || field . width Strings . truncate ( field . content , column_width )", "del_tokens": "width = widths [ col ] || field . width Strings . truncate ( field . content , width )", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "precondition", "and", "postcondition", "handlers", "."], "add_tokens": "@raw [ :headers ] ||= { } def to_s description end", "del_tokens": "@raw [ :headers ] || { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "author", "s", "XPath", "."], "add_tokens": "VERSION = '0.0.6'", "del_tokens": "VERSION = '0.0.5'", "commit_type": "fix"}
{"commit_tokens": ["moved", "start", "and", "added", "Boson", ".", "invoke"], "add_tokens": "def invoke ( * args ) main_object . send ( * args )", "del_tokens": "def start ( args = ARGV ) if Boson :: Manager . bin_init :discover => args [ 0 ] [ / \\w + / ] , :verbose => true if args [ 0 ] . include? ( '.' ) meth1 , meth2 = args . shift . split ( '.' , 2 ) dispatcher = main_object . send ( meth1 ) args . unshift meth2 else dispatcher = main_object end output = dispatcher . send ( * args ) puts Hirb :: View . render_output ( output ) || output . inspect else $stderr . puts \"Error: No command found to execute\" end", "commit_type": "move"}
{"commit_tokens": ["fix", "even", "more", "ruby", "2", ".", "x", "encoding", "clusterness"], "add_tokens": "s . force_to_binary . gsub ( opts [ :rx ] ) do | c |", "del_tokens": "s . gsub ( opts [ :rx ] ) do | c |", "commit_type": "fix"}
{"commit_tokens": ["update", "version", "and", "update", "changelog"], "add_tokens": "VERSION = '0.2.22'", "del_tokens": "VERSION = '0.2.21'", "commit_type": "update"}
{"commit_tokens": ["changed", ":", "retweet", "callback", "a", "bit"], "add_tokens": "do_callbacks :retweet , object if object . retweet? and object . retweeted_tweet . user . screen_name == $bot [ :config ] [ :screen_name ]", "del_tokens": "do_callbacks :retweet , object if object . retweet?", "commit_type": "change"}
{"commit_tokens": ["Add", "ability", "to", "set", "knockout", "prefix", "from", "command", "line", "."], "add_tokens": "current_template = current_template . deep_merge! ( template , { :knockout_prefix => @options [ :knockout ] } )", "del_tokens": "current_template = current_template . deep_merge! ( template , { :knockout_prefix => '--' } )", "commit_type": "add"}
{"commit_tokens": ["Fix", "task", "reading", "initializer", "file"], "add_tokens": "@config = SwaggerDocsGenerator . configuration def attributes { info : @config . attribute . merge! ( version : @config . version_api ) } end", "del_tokens": "@config = SwaggerDocsGenerator . config", "commit_type": "fix"}
{"commit_tokens": ["updated", "gemspec", "to", "new", "git", "location"], "add_tokens": "VERSION = \"0.1.9\"", "del_tokens": "VERSION = \"0.1.8\"", "commit_type": "update"}
{"commit_tokens": ["Fix", "update", "command", ".", "Move", "requires", "."], "add_tokens": "$: . unshift dir = File . dirname ( __FILE__ ) require 'open4' require 'yaml' require 'yaml/store' require 'braid/command' Dir [ \"#{dir}/braid/commands/*\" ] . each do | file | require file end", "del_tokens": "$: . unshift File . dirname ( __FILE__ ) require 'braid/commands'", "commit_type": "fix"}
{"commit_tokens": ["Remove", "mvn", "rubyWorker", "is", "not", "fixed", "thor", "cli"], "add_tokens": "autoload :Build , \"spark/build\" # Cannot load before CLI::install def self . load_lib require \"java\" java_import org . apache . spark . SparkConf java_import org . apache . spark . api . java . JavaSparkContext java_import org . apache . spark . api . ruby . RubyRDD end def self . default_target @default_target ||= File . expand_path ( File . dirname ( __FILE__ ) + '/../target' ) end def self . ruby_worker @ruby_worker ||= File . expand_path ( File . dirname ( __FILE__ ) + '/spark/worker.rb' ) end", "del_tokens": "require \"java\" java_import org . apache . spark . SparkConf java_import org . apache . spark . api . java . JavaSparkContext java_import org . apache . spark . api . ruby . RubyRDD", "commit_type": "remove"}
{"commit_tokens": ["Added", "ability", "to", "pass", "an", "array", "of", "methods", "to", "on_transition", "callback"], "add_tokens": "when Array @on_transition . each { | m | obj . send ( m , * args ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "specify", "CustomDocument", "through", "rake", "task", ";", "Added", "env", "var", "to", "WEBSOLR_URL", "to", "pass", "in", "as", "well"], "add_tokens": "if ENV [ 'WEBSOLR_URL' ] url = ENV [ 'WEBSOLR_URL' ] elsif defined? ( Rails . root ) url = YAML . load ( ERB . new ( File . read ( File . join ( Rails . root , \"config\" , \"solr.yml\" ) ) ) . result ) [ Rails . env ] [ 'url' ] url = YAML . load ( ERB . new ( File . read ( File . join ( Rails . root , \"config\" , \"solr.yml\" ) ) ) . result ) [ ENV [ 'RAILS_ENV' ] ] [ 'url' ] url = YAML . load ( ERB . new ( File . read ( \"config/solr.yml\" ) ) . result ) [ 'development' ] [ 'url' ]", "del_tokens": "if defined? ( Rails . root ) url = YAML . load_file ( File . join ( Rails . root , \"config\" , \"solr.yml\" ) ) [ Rails . env ] [ 'url' ] url = YAML . load_file ( File . join ( Rails . root , \"config\" , \"solr.yml\" ) ) [ ENV [ 'RAILS_ENV' ] ] [ 'url' ] url = YAML . load_file ( \"config/solr.yml\" ) [ 'development' ] [ 'url' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "poster", "to", "the", "movie", "information"], "add_tokens": "VERSION = \"1.0.3\"", "del_tokens": "VERSION = \"1.0.2\"", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "latest", "bundler", "best", "practices", "."], "add_tokens": "require 'bundler/setup'", "del_tokens": "require 'bundler' Bundler . setup", "commit_type": "update"}
{"commit_tokens": ["Use", "new", "assembly", "interface", "."], "add_tokens": "# A S S E M B L Y # def assemble? ( station , options = { } ) destination = options [ :destination ] case station when :prepare then ( destination == :promote ) when :promote then true else false end # Attach #approve to prepare and #announce to promote assembly stations. def assemble ( station , options = { } ) destination = options [ :destination ] case station when :prepare approve if destination == :promote when :promote announce end", "del_tokens": "# A S S E M B L Y S T A T I O N S # Attach announce method to promote assembly station. def station_prepare ( destination ) approve if destination == :promote # Attach announce method to promote assembly station. def station_promote announce", "commit_type": "use"}
{"commit_tokens": ["Added", "the", "ability", "for", "custom", "variable", "tracking", "to", "Google", "Analytics"], "add_tokens": "self . env [ \"google_analytics.custom_vars\" ] ||= [ ] self . env [ \"google_analytics.custom_vars\" ] . push ( var )", "del_tokens": "self . env [ \"google_analytics.custom_vars\" ] = var", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "the", "build", "command"], "add_tokens": "build statically build tables in the . / out / directory return if ! table . live", "del_tokens": "build statically build tables in the . / out /", "commit_type": "add"}
{"commit_tokens": ["Add", "endpoint", "prefixes", "and", "fix", "ports"], "add_tokens": "attr_accessor :endpoint_prefix ( options [ :object_id ] ? url ( \"#{@endpoint_prefix}/#{endpoint_name.to_s}/#{options[:object_id]}\" ) : url ( \"#{@endpoint_prefix}/#{endpoint_name.to_s}\" ) ) puts request_url @endpoint_prefix = options [ :endpoint_prefix ] @port = options [ :port ] [ :uri , :endpoints , :headers , :debug , :ssl , :schemas , :extension , :endpoint_prefix , :port ] . each { | v | options . delete ( v ) } opts = port? ? { host : @uri , path : endpoint , port : @port } : { host : @uri , path : endpoint }", "del_tokens": "( options [ :object_id ] ? url ( \"/#{endpoint_name.to_s}/#{options[:object_id]}\" ) : url ( \"/#{endpoint_name.to_s}\" ) ) [ :uri , :endpoints , :headers , :debug , :ssl , :schemas , :extension ] . each { | v | options . delete ( v ) } opts = port? ? { host : @uri , path : endpoint , port : port } : { host : @uri , path : endpoint }", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "meta", "rendering", "param"], "add_tokens": "def index_meta @users = @user_model . all meta_hash = { :page => 1 , :total => 999 } respond_to do | format | format . xml { render_for_api params [ :api_template ] . to_sym , :xml => @users , :root => :users , :meta => meta_hash } format . json { render_for_api params [ :api_template ] . to_sym , :json => @users , :root => :users , :meta => meta_hash } end end def show_meta @user = @user_model . find ( params [ :id ] ) meta_hash = { :page => 1 , :total => 999 } respond_to do | format | # :root => :user is only used here because we need it for the node name of the MongoUser model format . xml { render_for_api params [ :api_template ] . to_sym , :xml => @user , :root => :user } format . json { render_for_api params [ :api_template ] . to_sym , :json => @user , :root => :user , :meta => meta_hash } end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "RESTful", "resources"], "add_tokens": "require 'lotus/utils/string' controller , action = result . split ( / # / ) . map { | token | Utils :: String . titleize ( token ) } Utils :: String . titleize ( result )", "del_tokens": "controller , action = result . split ( / # / ) . map { | token | titleize ( token ) } titleize ( result ) # FIXME extract def titleize ( string ) string . split ( '_' ) . map { | token | token . slice ( 0 ) . upcase + token . slice ( 1 .. - 1 ) } . join end", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "threading", "related", "issue", "that", "occurs", "because", "is", "not", "thread", "-", "safe", "when", "used", "from", "lambdas", "."], "add_tokens": "CAMELCASE = lambda { | key | key . split ( / [|_]+ / ) . map { | s | s [ 0 ] = s [ 0 ] . upcase ; s } . join }", "del_tokens": "CAMELCASE = lambda { | key | key . gsub ( / \\/ (.?) / ) { \"::#{$1.upcase}\" } . gsub ( / (?:^|_)(.) / ) { $1 . upcase } }", "commit_type": "fix"}
{"commit_tokens": ["Update", "simple", "callers", "of", "numvcpus", "to", "cpu_sockets"], "add_tokens": "hardware [ :cpu_sockets ] = props [ :PhysicalCPUCount ] hardware [ :cpu_total_cores ] = hardware [ :cpu_cores_per_socket ] . to_i * hardware [ :cpu_sockets ] . to_i", "del_tokens": "hardware [ :numvcpus ] = props [ :PhysicalCPUCount ] hardware [ :cpu_total_cores ] = hardware [ :cpu_cores_per_socket ] . to_i * hardware [ :numvcpus ] . to_i", "commit_type": "update"}
{"commit_tokens": ["Fix", "doc", "comment", "syntax", "."], "add_tokens": "# @param label [String, Symbol] (human-readable version of +field_name+) Text for the +<label>+ element # @param type [Symbol] (type inferred by #infer_type) Type of field to render. # @param values [Array] Name-value pairs for +<option>+ elements. Only meaningful with +type: :select+. # @param field [Hash] Options to pass through to the underlying Rails form helper. For +type: :time_zone+, +:priority_zones+ is also understood.", "del_tokens": "# @option options [Hash] :field Options to pass through to the underlying Rails form helper. For +type: :time_zone+, +:priority_zones+ is also understood. # @option options [String, Symbol] :label (human-readable version of +field_name+) Text for the +<label>+ element # @option options [Symbol] :type (type inferred by #infer_type) Type of field to render. # @option options [Array] :values Name-value pairs for +<option>+ elements. Only meaningful with +type: :select+.", "commit_type": "fix"}
{"commit_tokens": ["Remove", "body", "from", "page", "translations", "."], "add_tokens": "remove_column :wafflemix_page_translations , :body add_column :wafflemix_page_translations , :body , :text", "del_tokens": "remove_column :pages , :body add_column :pages , :body , :text", "commit_type": "remove"}
{"commit_tokens": ["Use", "#public_method", "instead", "of", "#method"], "add_tokens": "if e . public_method ( :\" #{ k } ? \" ) . arity == 0", "del_tokens": "if e . method ( :\" #{ k } ? \" ) . arity == 0", "commit_type": "use"}
{"commit_tokens": ["Add", "folder", "example", "to", "generated", "sitemap", "config", "file"], "add_tokens": "# sitemap_for Page.scoped # sitemap_for Product.published, name: :published_products do |product| # url product, last_mod: product.updated_at, priority: (product.featured? ? 1.0 : 0.7) # url product_comments_url(product) # end # If you want to generate multiple sitemaps in different folders (for example if you have # more than one domain, you can specify a folder before the sitemap definitions: # # Site.all.each do |site| # folder \"sitemaps/#{site.domain}\" # host site.domain # # sitemap :site do # url root_url # end # # sitemap_for site.products.scoped # end # ping_with \"http://#{host}/sitemap.xml\"", "del_tokens": "# sitemap_for Page.scoped # sitemap_for Product.published, name: :published_products do |product| # url product, last_mod: product.updated_at, priority: (product.featured? ? 1.0 : 0.7) # url product_comments_url(product) # end # ping_with \"http://#{host}/sitemap.xml\"", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "all", "adapters", "slf4j", "requires", "jruby"], "add_tokens": "@adapter = Loggr :: Adapter :: AbstractAdapter . new assert_raise ( RuntimeError ) { @adapter . logger ( \"logger\" ) }", "del_tokens": "@subject = Loggr :: Adapter :: AbstractAdapter . new assert_raise ( RuntimeError ) { @subject . logger ( \"logger\" ) } end def test_mdc_uses_a_thread_local_hash_as_store", "commit_type": "add"}
{"commit_tokens": ["Added", "higher", "AR", "dependency", "for", "CLI"], "add_tokens": "gem 'activerecord' , '>= 2.2'", "del_tokens": "gem 'activerecord' , '>= 2.1'", "commit_type": "add"}
{"commit_tokens": ["make", "block", "configurable", "as", "well", "as", "adding", "main", "module", "functions", "and", "basic", "tests"], "add_tokens": "expect ( CpMgmt . configuration . mgmt_server_url ) . not_to be nil expect ( CpMgmt . configuration . mgmt_user ) . not_to be nil expect ( CpMgmt . configuration . mgmt_pass ) . not_to be nil", "del_tokens": "expect ( ENV . fetch ( 'mgmt_server_url' ) ) . not_to be nil expect ( ENV . fetch ( 'mgmt_user' ) ) . not_to be nil expect ( ENV . fetch ( 'mgmt_pass' ) ) . not_to be nil", "commit_type": "make"}
{"commit_tokens": ["add", "initial", "new", "mixin", "for", "ASG"], "add_tokens": "require 'stax/mixin/asg' # require 'stax/asg'", "del_tokens": "require 'stax/asg'", "commit_type": "add"}
{"commit_tokens": ["fixed", "provider", "performance", "dates", "for", "null", "dates"], "add_tokens": "{ 'provider_performances' => { '$elemMatch' => { 'provider_id' => provider_id , '$and' => [ '$or' => [ 'start_date' => nil , 'start_date' => { '$lt' => start_before } ] , '$or' => [ 'end_date' => nil , 'end_date' => { '$gt' => end_after } ] ] } } }", "del_tokens": "{ 'provider_performances' => { '$elemMatch' => { 'provider_id' => provider_id , 'start_date' => { '$lt' => start_before } , 'end_date' => { '$gt' => end_after } } } }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "delete", "for", "destroy", "in", "delete", "ImportProducts"], "add_tokens": "products . destroy_all product_hash . each do | field , value | #add_translations(product, params_hash)", "del_tokens": "products . delete_all params_hash . each do | field , value | add_translations ( product , params_hash )", "commit_type": "change"}
{"commit_tokens": ["Created", "an", "images", "class", "and", "image", "class", "to", "allow", "for", "convenience", "methods", "such", "as", "#landscape?", "."], "add_tokens": "Images . new @headline [ \"images\" ]", "del_tokens": "@headline [ \"images\" ]", "commit_type": "create"}
{"commit_tokens": ["Make", "version", "beta", "for", "rubygems", ".", "org"], "add_tokens": "VERSION = '0.3.12.beta.1'", "del_tokens": "VERSION = '0.3.12'", "commit_type": "make"}
{"commit_tokens": ["Change", "Form", "::", "Eelment", "to", "FormSingle", "."], "add_tokens": "class Single < Base", "del_tokens": "class Element < Base", "commit_type": "change"}
{"commit_tokens": ["Add", "tests", "for", "methods", "asg", "attributes"], "add_tokens": "# TODO: Figure out how to recode this... disable_vcr do end # TODO: Figure out how to recode this... def test_describe_asg_desired_capacity_equals disable_vcr do asg = @asg . describe_autoscaling_group assert_equal 16 , asg . desired_capacity end end # TODO: Figure out how to recode this... def test_describe_asg_has_min_size disable_vcr do asg = @asg . describe_autoscaling_group assert_respond_to asg , :min_size end end # TODO: Figure out how to recode this... def test_describe_asg_has_min_size_equals disable_vcr do asg = @asg . describe_autoscaling_group assert_equal 16 , asg . min_size end", "del_tokens": "VCR . eject_cassette WebMock . allow_net_connect! VCR . turned_off do WebMock . disable_net_connect!", "commit_type": "add"}
{"commit_tokens": ["update", "Column#header", "to", "use", "datagrid", "as", "scope", "instead", "of", "reports"], "add_tokens": "I18n . translate ( self . name , :scope => \"datagrid.#{self.grid.param_name}.columns\" , :default => self . name . to_s . humanize )", "del_tokens": "I18n . translate ( self . name , :scope => \"reports.#{self.grid.param_name}.columns\" , :default => self . name . to_s . humanize )", "commit_type": "update"}
{"commit_tokens": ["Use", "exclude?", "method", "for", "authentication"], "add_tokens": "unless exclude? @store . authenticate ( user ) end true", "del_tokens": "@store . authenticate ( user )", "commit_type": "use"}
{"commit_tokens": ["adding", "some", "umm", "missing", "args", "on", "numeric_input"], "add_tokens": "def numeric_input ( method , options )", "del_tokens": "def numeric_input", "commit_type": "add"}
{"commit_tokens": ["added", "test", "to", "check", "state"], "add_tokens": "VERSION = \"0.9.63\"", "del_tokens": "VERSION = \"0.9.62\"", "commit_type": "add"}
{"commit_tokens": ["added", "fourth", "digit", "to", "useragent", "version"], "add_tokens": "name , v1 , v2 , v3 , v4 = match [ 1 ] , match [ 2 ] , match [ 3 ] , match [ 4 ] , match [ 5 ] if pattern [ \"v4_replacement\" ] v4 = pattern [ \"v4_replacement\" ] . sub ( '$1' , v4 || '' ) end version = version_from_segments ( v1 , v2 , v3 , v4 )", "del_tokens": "name , v1 , v2 , v3 = match [ 1 ] , match [ 2 ] , match [ 3 ] , match [ 4 ] version = version_from_segments ( v1 , v2 , v3 )", "commit_type": "add"}
{"commit_tokens": ["Move", "worker", "and", "processor", "to", "framework"], "add_tokens": "# config.name = :vertica # config.processor_class = Triglav::Agent::Vertica::Processor # config.monitor_class = Triglav::Agent::Vertica::Monitor # config.connection_class = Triglav::Agent::Vertica::Connection def self . processor_class @processor_class ||= Triglav :: Agent :: Base :: Processor end def self . monitor_class @monitor_class ||= Triglav :: Agent :: Base :: Monitor end def self . connection_class @connection_class ||= Triglav :: Agent :: Base :: Connection end def self . processor_class = ( processor_class ) @processor_class = processor_class end def self . monitor_class = ( monitor_class ) @monitor_class = monitor_class end def self . connection_class = ( connection_class ) @connection_class = connection_class end", "del_tokens": "# config.name = :vertica", "commit_type": "move"}
{"commit_tokens": ["Use", "Forwardable", "in", "Petrovich", "::", "Inflected"], "add_tokens": "extend Forwardable def_delegator :@name , :lastname , :lastname def_delegator :@name , :firstname , :firstname def_delegator :@name , :middlename , :middlename def initialize ( name ) @name = name", "del_tokens": "def initialize ( name ) @name = name end def lastname @name . lastname end def firstname @name . firstname end def middlename @name . middlename", "commit_type": "use"}
{"commit_tokens": ["Add", "#prompts", "and", "#appearance", "attributes"], "add_tokens": "## # @!attribute prompts [r] # @return [Hash] a hash of prompts available for use in +Input.prompt+ @@prompts = { :default => '>' } ## # @!attribute appearance # @return [Symbol] the symbol name of the prompt appearance to use from +Input.prompts+ @@appearance = nil ## # @return [Symbol] the symbol name of the current prompt appearance def self . appearance @@appearance end ## # Set the default appearance for the prompt # # @param value [Symbol] the symbol name of the appearance to use from +Input.prompts+ def self . appearance = ( value ) @@appearance = value end @@prompts = { :default => '>' } @@appearance = nil # Prompts the user for input using +gets.strip+ # # @param appearance [Symbol] the symbol name of the prompt the use from +Input.prompts+ # - If an appearance is not specified it uses +:default+ def self . prompt ( appearance = nil ) if appearance appearance = @@prompts [ appearance ] elsif @@appearance appearance = @@prompts [ @@appearance ] else appearance = @@prompts [ :default ] end print \"\\n#{appearance} \" @@data = $stdin . gets . strip end ## # @return [Hash] a hash of the currently available prompt appearances def self . prompts @@prompts", "del_tokens": "# Prompts the user for input using +gets.chomp+ def self . prompt print \"\\n> \" @@data = gets . chomp", "commit_type": "add"}
{"commit_tokens": ["Removed", "model", "/", "class", "mixins"], "add_tokens": "Sunspot . setup ( Post ) do text :title , :body string :title integer :blog_id integer :category_ids , :multiple => true float :average_rating time :published_at string :sort_title do title . downcase . sub ( / ^(a|an|the) \\W + / , '' ) if title end end", "del_tokens": "is_searchable do text :title , :body string :title integer :blog_id integer :category_ids , :multiple => true float :average_rating time :published_at string :sort_title do title . downcase . sub ( / ^(a|an|the) \\W + / , '' ) if title end end", "commit_type": "remove"}
{"commit_tokens": ["add", "#as_json", "alias", "for", "#to_json"], "add_tokens": "# @option options [Boolean] :symbolize_keys # @option options [Class, Symbol, String] :adapter alias_method :as_json , :to_json", "del_tokens": "# @param [Hash] options # an options hash to pass to MultiJson.encode", "commit_type": "add"}
{"commit_tokens": ["Use", "default", "locale", "as", "cmtool", "default"], "add_tokens": "I18n . locale = Rails . configuration . i18n . default_locale", "del_tokens": "I18n . locale = :en", "commit_type": "use"}
{"commit_tokens": ["add", "tests", "for", "Target", "check_constructor"], "add_tokens": "self . instance_variable_set ( '@' + key . to_s , value ) raise \"constructor path is not defined for this target\" if @constructor_path . nil? return false unless :: File . exists? file result = ` ruby -c #{ file } &> /dev/null `", "del_tokens": "if self . instance_variable_defined? '@' + key . to_s self . instance_variable_set ( '@' + key . to_s , value ) end result = ` ruby -c #{ file } `", "commit_type": "add"}
{"commit_tokens": ["fix", "time", "rspec", "for", "refactored", "pack", "directives"], "add_tokens": "[ ( time . to_f * 1000 ) . to_i ] . pack ( BSON :: INT64_PACK ) [ ( time . to_f * 1000 ) . to_i ] . pack ( BSON :: INT64_PACK )", "del_tokens": "[ ( time . to_f * 1000 ) . to_i ] . pack ( Integer :: INT64_PACK ) [ ( time . to_f * 1000 ) . to_i ] . pack ( Integer :: INT64_PACK )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "gem", "so", "that", "it", "can", "be", "required", "properly"], "add_tokens": "require 'ruote-mongodb'", "del_tokens": "#require \"spec_helper\" require 'rubygems' require 'mongo' require 'lib/mongodb_storage'", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "test", "to", "check", "for", "the", "count", "of", "the", "data"], "add_tokens": "assert_equal 1 , fields . data . count", "del_tokens": "assert_equal 1 , fields . data", "commit_type": "fix"}
{"commit_tokens": ["add", "hot", "module", "for", "redux", "router", "option"], "add_tokens": "VERSION = \"1.0.7\"", "del_tokens": "VERSION = \"1.0.6\"", "commit_type": "add"}
{"commit_tokens": ["moving", "channel", "unsubscription", "stuff", "onto", "Channel"], "add_tokens": "class << self def from channel_id klass = channel_id [ / ^presence- / ] ? PresenceChannel : Channel klass . find_or_create_by_channel_id channel_id end def unsubscribe channel_id , subscription_id from ( channel_id ) . try :unsubscribe , subscription_id end", "del_tokens": "def self . from channel_id klass = channel_id [ / ^presence- / ] ? PresenceChannel : Channel klass . find_or_create_by_channel_id channel_id", "commit_type": "move"}
{"commit_tokens": ["Allow", "optional", "attribute", "to", "be", "left", "undefined"], "add_tokens": "def optional? default? || settings . key? ( :optional ) end case [ param? , optional? ]", "del_tokens": "case [ param? , default? ]", "commit_type": "allow"}
{"commit_tokens": ["Make", "sure", "the", "right", "capture", "method", "is", "called", "even", "if", "ActiveSupport", "is", "loaded", "(", "by", "capistrano_mailer", "for", "example", ")", "."], "add_tokens": "'true' == top . capture ( \"if [ #{filetest} #{full_path} ]; then echo 'true'; fi\" ) . strip Digest :: MD5 . hexdigest ( content ) == top . capture ( \"md5sum #{full_path} | awk '{ print $1 }'\" ) . strip end", "del_tokens": "'true' == capture ( \"if [ #{filetest} #{full_path} ]; then echo 'true'; fi\" ) . strip Digest :: MD5 . hexdigest ( content ) == capture ( \"md5sum #{full_path} | awk '{ print $1 }'\" ) . strip end", "commit_type": "make"}
{"commit_tokens": ["Updated", "spec", "to", "new", "FactoryGirl", "syntax"], "add_tokens": "let ( :coupon_1 ) { Factory . build ( :coupon , :product_family_id => 6 ) }", "del_tokens": "let ( :coupon_1 ) { build ( :coupon , :product_family_id => 6 ) }", "commit_type": "update"}
{"commit_tokens": ["move", "gen", "directory", "into", "ext", "/", "numo", "/", "narray", "move", "depend", "to", "depend", ".", "erb", "run", "cogen", ".", "rb", "in", "Makefile", "."], "add_tokens": "system ( \"rm -f depend; erb depend.erb > depend\" ) create_makefile ( 'numo/narray' )", "del_tokens": "create_makefile ( 'numo/narray' ) system ( \"cd ../../../gen; rake\" )", "commit_type": "move"}
{"commit_tokens": ["Make", "ability", "file", "type", "agnostic"], "add_tokens": "can :manage , Pageflow . config . file_types . map ( & :model ) do | record | can :manage , Pageflow . config . file_types . map ( & :model )", "del_tokens": "can :manage , [ ImageFile , VideoFile , AudioFile ] do | record | can :manage , [ ImageFile , VideoFile , AudioFile ]", "commit_type": "make"}
{"commit_tokens": ["Add", "backslashes", "for", "<", "/", ">"], "add_tokens": "text = preserve_keychars_within_backticks ( text ) text = preserve_tags ( text ) text def preserve_tags ( text ) text . gsub ( / [<>] / , '>' => '\\>' , '<' => '\\<' ) end", "del_tokens": "preserve_keychars_within_backticks ( text )", "commit_type": "add"}
{"commit_tokens": ["Using", "#snake_case", "instead", "of", "repetition"], "add_tokens": "key = key . gsub ( / - / , '_' ) . snake_case common_name = model . to_s . snake_case", "del_tokens": "key . gsub! ( / - / , '_' ) key . gsub! ( / ([A-Z \\d ]+)([A-Z][a-z]) / , '\\1_\\2' ) key . gsub! ( / ([a-z \\d ])([A-Z]) / , '\\1_\\2' ) common_name = model . to_s . gsub ( / ([A-Z \\d ]+)([A-Z][a-z]) / , '\\1_\\2' ) common_name . gsub! ( / ([a-z \\d ])([A-Z]) / , '\\1_\\2' ) common_name . downcase!", "commit_type": "use"}
{"commit_tokens": ["Use", "composition", "instead", "of", "inheritance"], "add_tokens": "require 'forwardable' class Polygon extend Forwardable def initialize ( * args ) @points = Array . new ( args ) def_delegators :@points , :size , :each , :first , :include? , :[] , :index first , second = first ( 2 ) @points . inject ( 0 ) { | sum , point | sum += point . x + point . y }", "del_tokens": "class Polygon < Array def initialize ( * args ) super ( args ) first , second = self . first ( 2 ) inject ( 0 ) { | sum , point | sum += point . x + point . y }", "commit_type": "use"}
{"commit_tokens": ["Move", "force_bind", "rbx", "support", "out", "and", "use", "an", "extension", "to", "install", "the", "correct", "gem", "."], "add_tokens": "require 'force_bind' bound = method . force_bind ( delegator )", "del_tokens": "bound = force_bind ( delegator , method )", "commit_type": "move"}
{"commit_tokens": ["added", "name", "-", "rev", "support", "for", "commit", "objects"], "add_tokens": "def namerev ( string ) command ( 'name-rev' , string ) . split [ 1 ] end", "del_tokens": "puts $? . exitstatus", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "for", "kaminari", "if", "the", "page", "method", "changed", "for", "willpaginage"], "add_tokens": "page_method_name = Kaminari . config . page_method_name @query_cache = @query_without_pagination_cache . send ( page_method_name , @params [ :page ] )", "del_tokens": "@query_cache = @query_without_pagination_cache . page ( @params [ :page ] )", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "Seen", "module", "in", "Light"], "add_tokens": "require 'lifx/seen' include Seen", "del_tokens": "attr_reader :last_seen def seen! @last_seen = Time . now end", "commit_type": "use"}
{"commit_tokens": ["Created", "Pidfile", "to", "manage", "processes"], "add_tokens": "require 'find_a_port'", "del_tokens": "", "commit_type": "create"}
{"commit_tokens": ["Add", "stale?", "method", "to", "spatial", "cache"], "add_tokens": "return false if cache . stale? # cache must be for current features", "del_tokens": "return false if has_spatial_features_hash? && features_hash != cache . features_hash # cache must be for current features", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "number", "provisioning", "and", "DRY", "up", "the", "option", "merging"], "add_tokens": "# Public: Provision a phone number that you can use to receive faxes in # your Phaxio account. # # options - The Hash options used to refine the selection (default: {}): # area_code - The integer area code of the number you'd like # to provision (required). # callback_url - A callback URL that Phaxio will post to when a # fax is received by this number. This will # override the global receive callback URL, if you # have one set (optional). # # Examples # # Phaxio.provision_number(area_code: 802) # # Returns a HTTParty::Response object containing a success bool, a string # message, and data containing the phone number, city, state, cost, # last_billed_at, and the date the number was provisioned at. def provision_number ( options ) send_post ( \"/provisionNumber\" , options ) end", "del_tokens": "options . merge! ( { api_key : api_key , api_secret : api_secret } ) options . merge! ( { api_key : api_key , api_secret : api_secret } ) options . merge! ( { api_key : api_key , api_secret : api_secret } ) options . merge! ( { api_key : api_key , api_secret : api_secret } )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "index", "pagination"], "add_tokens": "@allowed_subactions = [ ] if params [ :page ] && ! allowed? ( :paging ) return { status : :bad_request } end def allows ( * subactions ) @allowed_subactions = subactions end def allowed? ( subaction ) @allowed_subactions . include? subaction end all_records = model . all if allowed? ( :paging ) && params [ :page ] page = params [ :page ] per_page = params [ :per_page ] || 10 lower_bound = ( per_page - 1 ) * page upper_bound = lower_bound + per_page - 1 return all_records [ lower_bound .. upper_bound ] end all_records", "del_tokens": "model . all", "commit_type": "add"}
{"commit_tokens": ["update", "multipart", "stubs", "to", "handle", "uid", "in", "header"], "add_tokens": ". with ( headers : { 'Content-Type' => / multipart \\/ form-data; boundary=-----------RubyMultipartPost.* / } )", "del_tokens": ". with ( headers : { 'Content-Type' => 'multipart/form-data; boundary=-----------RubyMultipartPost' } )", "commit_type": "update"}
{"commit_tokens": ["Added", "regexp", "filter", "options", "and", "flags"], "add_tokens": "Nodes :: Regexp . new @name , value , * @options Nodes :: Regexp . new @name , value , * @options self . class . new [ @name , method ] . join ( ?. ) , * args", "del_tokens": "Nodes :: Regexp . new @name , value Nodes :: Regexp . new @name , value self . class . new [ @name , method ] . join ( ?. )", "commit_type": "add"}
{"commit_tokens": ["Allow", "commands", "to", "output", "if", "specified"], "add_tokens": "# Don't ouput to /dev/null if in debug mode # or if a command supplies its own ouput if ! ENV [ 'DEBUG' ] && ! ( cmd =~ / > / ) cmd += \" > /dev/null\" end", "del_tokens": "cmd += \" > /dev/null\" unless ENV [ 'DEBUG' ]", "commit_type": "allow"}
{"commit_tokens": ["change", "behavior", "of", "audit_tag_with", "and", "snap", ".", "this", "is", "better"], "add_tokens": "last_saved_audit = audits . last # build new audit audit = audits . build ( :modifications => snap ) audit . attributes = audit . attributes . merge options # only save if it's different from before if ! audit . same_audited_content? ( last_saved_audit ) audit . save end", "del_tokens": "if last_audit . nil? || last_audit . modifications != snap # build new audit audit = audits . build ( :modifications => snap ) else # no changes on modifications, but have to update the latest record audit = audits . last end audit . update_attributes ( options )", "commit_type": "change"}
{"commit_tokens": ["Allow", "nil", "values", "in", "Figaro", "configuration"], "add_tokens": "hash . inject ( { } ) { | h , ( k , v ) | h [ k . to_s ] = v && v . to_s ; h }", "del_tokens": "hash . inject ( { } ) { | h , ( k , v ) | h [ k . to_s ] = v . to_s ; h }", "commit_type": "allow"}
{"commit_tokens": ["Add", "bug", "guards", "for", "WTR", "-", "336"], "add_tokens": "bug \"WTR-336\" , :watir do it \"is able to set a file path in the field and click the upload button and fire the onchange event\" do browser . goto ( \"#{WatirSpec.host}/forms_with_input_elements.html\" ) path = File . expand_path ( __FILE__ ) browser . file_field ( :name , \"new_user_portrait\" ) . set path browser . file_field ( :name , \"new_user_portrait\" ) . value . should == path messages . first . should == path browser . button ( :name , \"new_user_submit\" ) . click end", "del_tokens": "it \"is able to set a file path in the field and click the upload button and fire the onchange event\" do browser . goto ( \"#{WatirSpec.host}/forms_with_input_elements.html\" ) path = File . expand_path ( __FILE__ ) browser . file_field ( :name , \"new_user_portrait\" ) . set path browser . file_field ( :name , \"new_user_portrait\" ) . value . should == path messages . first . should == path browser . button ( :name , \"new_user_submit\" ) . click", "commit_type": "add"}
{"commit_tokens": ["Added", "README", "for", "templates", "generator"], "add_tokens": "create_file job_template_dir ( template_name ) def job_template_dir ( path ) File . join ( \"jobs\" , job_name , \"templates\" , path ) end", "del_tokens": "create_file job_dir ( template_name )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "git", "tag", "via", "version", "property"], "add_tokens": "attr_reader :version @version = software . version to_update = true # No update needed if we're cloning to_update = false if to_update puts \"updating source from git\" update_cmd = \"git pull\" shell = Mixlib :: ShellOut . new ( update_cmd , :live_stream => STDOUT ) shell . run_command shell . error! end to_checkout = version != nil checkout_cmd = \"git checkout #{version}\" shell = Mixlib :: ShellOut . new ( checkout_cmd , :live_stream => STDOUT ) shell . run_command shell . error! end rescue Exception => e", "del_tokens": "# # clone needed? # # # checkout needed? # to_checkout = true # TODO: checkout the most up to date version end rescue Exception", "commit_type": "add"}
{"commit_tokens": ["Add", "all", "of", "owner", "s", "shard", "keys", "to", "specify", "shards", "when", "association", "preloading"], "add_tokens": "if should_use_shard_key? returning_scope = returning_scope . where ( klass . turntable_shard_key => owners . map ( & foreign_shard_key ) . uniq )", "del_tokens": "if should_use_shard_key? && owners_have_same_shard_key? returning_scope = returning_scope . where ( klass . turntable_shard_key => owners . first . send ( foreign_shard_key ) ) def owners_have_same_shard_key? owners . map ( & foreign_shard_key ) . uniq . size == 1 end", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "way", "we", "use", "RMagick", "to", "draw", "horizontal", "line", "markers", "."], "add_tokens": "@d = @d . fill ( @marker_color )", "del_tokens": "@d = @d . stroke ( @marker_color ) @d = @d . stroke_width 1", "commit_type": "change"}
{"commit_tokens": ["Added", "ability", "to", "load", "username", "/", "password", "from", "file", "and", "then", "decided", "not", "to", "use", "it", "(", "for", "now", ")", "."], "add_tokens": "@url = ( config [ 'secure' ] ) ? 'https://' : 'http://' @url = \"#{@url}#{config['base_url']}\" # @creds_path = config['credentials_path'] # creds = YAML.load File.new(@creds_path).read # user.username = creds['username'] # user.password = creds['password'] authorize user def authorize user Rails . logger . debug \"Attempting Scram authentication\" auth_conv = ProjectHaystack :: Auth :: Scram :: Conversation . new ( user , @url ) auth_conv . authorize @auth_token = auth_conv . auth_token raise \"scram authorization failed\" unless @auth_token . present? end # if @credentials.nil? && @auth_token.nil? # authorize #will either set auth token or raise error # end @connection ||= Faraday . new ( :url => @url ) do | faraday | ! ( @name . nil? || @haystack_version . nil? || @url . nil? ) private # def persist_creds # creds = {username: @username, password: @password, auth_token: @auth_token} # File.open(@creds_path,'w') do |h| # h.write creds.to_yaml # end # end", "del_tokens": "@base_url = config [ 'base_url' ] @secure = config [ 'secure' ] # TODO load auth token from a user database and only initiate scram conversation if necessary auth_conv = ProjectHaystack :: Auth :: Scram :: Conversation . new ( user ) auth_conv . authorize @auth_token = auth_conv . auth_token url = ( @secure ) ? 'https://' : 'http://' url = \"#{url}#{@base_url}\" @connection ||= Faraday . new ( :url => url ) do | faraday | ! ( @name . nil? || @haystack_version . nil? || @base_url . nil? )", "commit_type": "add"}
{"commit_tokens": ["Add", "rescue_from", "StandardError", "to", "ApiController", "generator", "file", "to", "create", "Stitches", "error", "objects"], "add_tokens": "# # The order of the rescue_from blocks is important - ActiveRecord::RecordNotFound must come after StandardError, # otherwise ActiveRecord::RecordNotFound exceptions will get rescued in the StandardError block. # See the documentation for rescue_from for further explanation: # https://apidock.com/rails/ActiveSupport/Rescuable/ClassMethods/rescue_from # Specifically, this part: \"Handlers are inherited. They are searched from right to left, from bottom to top, and up # the hierarchy.\" # rescue_from StandardError do | exception | render json : { errors : Stitches :: Errors . from_exception ( exception ) } , status : :internal_server_error end render json : { errors : Stitches :: Errors . from_exception ( exception ) } , status : :not_found", "del_tokens": "respond_to do | type | type . json { render json : { errors : Stitches :: Errors . new ( [ Stitches :: Error . new ( code : \"not_found\" , message : exception . message ) ] ) } , status : 404 } type . all { render :nothing => true , :status => 404 } end", "commit_type": "add"}
{"commit_tokens": ["Improves", "Rules", "::", "Summary", "readability"], "add_tokens": "! summary_text . empty? MAXIMUM_LINE_LENGTH = 80 summary_text . split ( / / ) . length <= MAXIMUM_LINE_LENGTH summary_text [ - 1 ] != '.' LINE_BREAK_CHARACTER = \"\\n\" ! summary_text . include? ( LINE_BREAK_CHARACTER )", "del_tokens": "summary_text != '' summary_text . split ( / / ) . length <= 80 summary_text [ - 1 , 1 ] != '.' ! summary_text . include? ( \"\\n\" )", "commit_type": "improve"}
{"commit_tokens": ["Added", "a", "mode", "for", "Xcode4", "-", "style", "archives"], "add_tokens": ":project_file_path => nil , :xcode4_archive_mode => false", "del_tokens": ":project_file_path => nil", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "static", "factory", "to", "blog_entry", ".", "rb"], "add_tokens": "def self . load_xml ( xml ) BlogEntry . new ( xml ) def initialize ( xml ) @document = REXML :: Document . new ( xml ) parse_document end", "del_tokens": "def initialize ( xml ) @document = REXML :: Document . new ( xml ) parse_document", "commit_type": "add"}
{"commit_tokens": ["Updated", ".", "travis", ".", "yml"], "add_tokens": "VERSION = \"1.3.0\"", "del_tokens": "VERSION = \"1.2.0\"", "commit_type": "update"}
{"commit_tokens": ["fixed", "bug", "if", "it", "don", "t", "config", "token", "model"], "add_tokens": "return nil if WeixinRailsMiddleware . config . token_string . present?", "del_tokens": "return nil if WeixinRailsMiddleware . config . token_string . blank?", "commit_type": "fix"}
{"commit_tokens": ["Added", "unary", "operators", "to", "Point"], "add_tokens": "it \"must have +@\" do ( + left ) . must_equal Point [ 1 , 2 ] ( + left ) . must_be_instance_of ( Point ) end it \"must have unary negation\" do ( - left ) . must_equal Point [ - 1 , - 2 ] ( - left ) . must_be_instance_of ( Point ) end describe \"when monkeypatching Vector\" do let ( :left ) { Vector [ 1 , 2 ] } let ( :right ) { Vector [ 3 , 4 ] } it \"must have +@\" do ( + left ) . must_equal Vector [ 1 , 2 ] end it \"must have unary negation\" do ( - left ) . must_equal Vector [ - 1 , - 2 ] end end", "del_tokens": "#Point = Geometry::Point", "commit_type": "add"}
{"commit_tokens": ["added", "support", "of", "SSL", "Certificate", "handshake"], "add_tokens": "Given / ^a not verified test client certificate file$ / do puts \"*******************************\" puts \"!!! PEM pass phrase: foobar !!!\" puts \"*******************************\" @client_cert_file = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"..\" , \"..\" , \"spec/ca/ca.crt\" ) ) end Given / ^a not verified test client key file$ / do @client_key_file = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"..\" , \"..\" , \"spec/ca/ca.key\" ) ) end Given / ^a test client certificate file$ / do @client_cert_file = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"..\" , \"..\" , \"spec/client/cert.pem\" ) ) end Given / ^a test client key file$ / do @client_key_file = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"..\" , \"..\" , \"spec/client/key.pem\" ) ) end end", "del_tokens": "Given \"a really dumb SSL enabled web server\" end", "commit_type": "add"}
{"commit_tokens": ["Fixing", "bug", "with", "Bundler", "in", "spec", "helper"], "add_tokens": "Bundler . require ( :default , :development )", "del_tokens": "Bundler . require ( :default , :test )", "commit_type": "fix"}
{"commit_tokens": ["Use", "simpler", "initialization", "syntax", "for", "Java", "NIO", "Selectors"], "add_tokens": "java_import \"java.nio.channels.Selector\" @java_selector = Selector . open", "del_tokens": "java_import \"java.nio.channels.spi.SelectorProvider\" @java_selector = SelectorProvider . provider . openSelector", "commit_type": "use"}
{"commit_tokens": ["Made", "modifications", "to", "parser", "and", "lexer", "to", "support", "singleton", "methods", "syntax", "."], "add_tokens": "context \".compile\" do context \"Black Box testing\" do", "del_tokens": "context \".compile\" , focus : true do context \"Black Box testing\" , focus : true do", "commit_type": "make"}
{"commit_tokens": ["added", "yet", "another", "special", "case", ":", "block", "args"], "add_tokens": "working_line = ignore_to_proc_args working_line line . gsub ( / ( \\( |(, )|([a-zA-Z0-9_] \\s +)) \\& ([a-z][A-Za-z0-9_]*)(,| \\) | \\Z ) / , '\\\\1' ) end def self . ignore_to_proc_args ( line ) line . gsub ( / ( \\( |(, )|([a-zA-Z0-9_] \\s +)) \\* ([a-z][A-Za-z0-9_]*)(,| \\) | \\Z ) / , '\\\\1' )", "del_tokens": "line . gsub ( / ( \\( |(, )) \\* ([a-z][A-Za-z0-9]*)(,| \\) ) / , '\\\\1' )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "w", "/", "Rails", "5", "support", "."], "add_tokens": "next if model . respond_to? ( :abstract_class ) && model . abstract_class", "del_tokens": "next if model . respond_to? :abstract_class && model . abstract_class", "commit_type": "fix"}
{"commit_tokens": ["Changed", "default", "behaviour", "when", "IPv4#new", "is", "called", "with", "no", "prefix", "specified", ":", "it", "now", "defaults", "to", "/", "32", "like", "IPAddr", ".", "A", "new", "method", "IPv4", "::", "parse_cassful", "has", "been", "written", "to", "parse", "a", "new", "IPv4", "address", "with", "calssful", "netmasks"], "add_tokens": "@prefix = Prefix32 . new ( 32 ) def self . parse_classful ( ip ) if IPAddress . valid_ipv4? ( ip ) address = ip . strip else raise ArgumentError , \"Invalid IP #{ip.inspect}\" end prefix = CLASSFUL . find { | h , k | h === ( \"%.8b\" % address . to_i ) } . last self . new \"#{address}/#{prefix}\" end", "del_tokens": "@prefix = prefix_from_ip ( @address )", "commit_type": "change"}
{"commit_tokens": ["Remove", "force", "flag", "from", "migration"], "add_tokens": "create_table :delayed_jobs do | table |", "del_tokens": "create_table :delayed_jobs , force : true do | table |", "commit_type": "remove"}
{"commit_tokens": ["allow", "just", "an", "element_id", "in", "root", "return", "method", "value", "from", "apply"], "add_tokens": "raise ApplyError . new ( \"No context defined in Styleable#apply(#{method_name.inspect})\" ) unless @styleable_context raise ApplyError . new ( \"Cannot apply #{method_name.inspect} to instance of #{target.class.name}\" ) if method_name . length == 0 raise ApplyError . new ( \"Cannot apply #{method_name.inspect} to instance of #{target.class.name}\" ) return target . send ( setter , * args ) return target . send ( assign , * args ) return target . send ( setter , * args ) raise ApplyError . new ( \"Cannot apply #{method_name.inspect} to instance of #{target.class.name}\" ) begin return self . apply ( method_name , * args , & block ) rescue ApplyError", "del_tokens": "raise ( \"No context defined in Styleable#apply(#{method_name.inspect})\" ) unless @styleable_context return false if method_name . length == 0 return false target . send ( setter , * args ) return true target . send ( assign , * args ) return true target . send ( setter , * args ) return true return false unless self . apply ( method_name , * args , & block )", "commit_type": "allow"}
{"commit_tokens": ["changed", "channels", "/", "modes", "structure", "for", "whois"], "add_tokens": "whois [ :channels ] = { } channels_with_mode . each do | c | whois [ :channels ] [ c . scan ( / (.)?(# \\S +) / ) [ 0 ] [ 1 ] ] = c . scan ( / (.)?(# \\S +) / ) [ 0 ] [ 0 ] end", "del_tokens": "whois [ :channels ] = channels_with_mode . map { | c | { :mode => c . scan ( / (.)?(# \\S +) / ) [ 0 ] [ 0 ] , :channel => c . scan ( / (.)?(# \\S +) / ) [ 0 ] [ 1 ] } }", "commit_type": "change"}
{"commit_tokens": ["Updating", "ruby", "wrapper", "with", "improvements", "for", "Team", "Management"], "add_tokens": "warn \"[DEPRECATION] Use person.add or person.update to set the name on a particular person in a client. For now, we will create a default person with the name provided.\" unless contact_name . to_s == '' warn \"[DEPRECATION] Use person.add or person.update to set the email on a particular person in a client. For now, we will create a default person with the email provided.\" unless email . to_s == '' # THIS METHOD IS DEPRECATED. It should only be used with existing integrations. # Sets the access settings for this client. def set_access ( username , password , access_level ) warn \"[DEPRECATION] `set_access` is deprecated. Use Person.update to set access on a particular person in a client.\" options = { :body => { :Username => username , :Password => password , :AccessLevel => access_level } . to_json } put 'setaccess' , options end", "del_tokens": "warn \"[DEPRECATION] Use Person.add or person.update to set name on a particular person in a client. For now, will create a default person with name.\" unless contact_name . to_s == '' warn \"[DEPRECATION] Use Person.add or person.update to set email on a particular person in a client. For now, will create a default person with email.\" unless email . to_s == '' # Sets the access settings for this client. def set_access ( username , password , access_level ) warn \"[DEPRECATION] `set_access` is deprecated. Use Person.update to set access on a particular person in a client.\" options = { :body => { :Username => username , :Password => password , :AccessLevel => access_level } . to_json } put 'setaccess' , options end", "commit_type": "update"}
{"commit_tokens": ["add", "CardTable", ".", "sql_columns_to_update", "&", "revised", "CardTable", ".", "find", "(", "id", ")"], "add_tokens": "def destroy sql = <<-SQL DELETE FROM #{self.class.table_name} WHERE id=(?) SQL DB [ :conn ] . execute ( sql , self . id ) end if row . first #if a row is actually returned i.e. the id actually exists self . reify_from_row ( row . first ) #using .first array method to return only the first nested array #that is taken from self.reify_from_row(row) which is the resulting id of the query else \"this card doesn't exist\" end def self . sql_columns_to_update columns = ATTRS . keys [ 1 .. - 1 ] #returns the number of keys in the hash minus one for the 'id' columns . collect { | attr | \"#{attr}=(?)\" } . join ( \", \" ) #converts them into 'attribute=(?)' array that is then turned into comma separated string end UPDATE #{self.class.table_name} SET #{self.class.sql_columns_to_update} WHERE id=(?) DB [ :conn ] . execute ( sql , * attribute_values_for_sql_check , self . id ) #using splat operator to signify that there may be more than one argument in terms of attr_readers puts CardTable . find ( 2 )", "del_tokens": "self . reify_from_row ( row . first ) #using .first array method to return only the first nested array #that is taken from self.reify_from_row(row) which is the resulting id of the query UPDATE #{self.class.table_name} SET card=(?), sets=(?), market_price=(?), price_fluctuate=(?), image=(?) WHERE id=(?) DB [ :conn ] . execute ( sql , * attribute_values_for_sql_check ) #using splat operator to signify that there may be more than one argument in terms of attr_readers", "commit_type": "add"}
{"commit_tokens": ["added", "ability", "to", "search", "records", "not", "only", "by", "Salesforce", "ID", "but", "also", "by", "custom", "mappings"], "add_tokens": "VERSION = \"2.1.0\"", "del_tokens": "VERSION = \"2.0.2\"", "commit_type": "add"}
{"commit_tokens": ["Remove", "number", "from", "on_pull_request", "arguments"], "add_tokens": "on_pull_request ( owner , repo_name , json [ 'action' ] , json [ 'pull_request' ] )", "del_tokens": "on_pull_request ( owner , repo_name , json [ 'number' ] , json [ 'action' ] , json [ 'pull_request' ] )", "commit_type": "remove"}
{"commit_tokens": ["Changed", "the", "to_s", "alias", "so", "that", "the", "generated", "path", "for", "multi", "-", "word", "channels", "would", "be", "correct", "."], "add_tokens": "alias_method :to_s , :name", "del_tokens": "alias_method :to_s , :display_name", "commit_type": "change"}
{"commit_tokens": ["Make", "_request", "helper", "for", "Nucleus"], "add_tokens": "require_relative './_request' include Atom :: Request", "del_tokens": "## Helpers for request variables def status ( value = nil ) @status ||= 200 value ? @status = value : @status end def headers @headers ||= { 'Content-Type' => 'text/html' } end def params @request . params end def request ( env = nil ) env ? @request = Rack :: Request . new ( env ) : @request end", "commit_type": "make"}
{"commit_tokens": ["Moved", "tests", "to", "just", "semaphore", "and", "fixed", "thread", "joining"], "add_tokens": "it 'allows other threads in a process to continue while waiting' do sem = Semaphore . new was_set = false t2 = nil sem . synchronize do t1 = Thread . new do # give t2 a chance to wait on the lock, then set the flag sleep 0.01 was_set = true end t2 = Thread . new do sem . synchronize { } end # t1 should set the flag and die while t2 is still waiting on the lock t1 . join end was_set . must_equal true t2 . join end sem = Semaphore . new t2 = nil sem . synchronize do begin sem . try_wait ( 10.0 ) rescue Errno :: ETIMEDOUT # success end # t1 should set the flag and die while t2 is still waiting on the lock t2 . join", "del_tokens": "# NOTE: A similar test in LockBehavior tests Semaphore#wait, # Mutex#lock, etc. Necessary only to test #try_wait here. Semaphore . open ( 0 ) do | sem | sem . try_wait ( 10.0 )", "commit_type": "move"}
{"commit_tokens": ["added", "have_subject", "matcher", "and", "moved", "the", "example", "rails", "app", "to", "make", "autotest", "happy"], "add_tokens": "subject { @email } should deliver_to ( \"jojo@yahoo.com\" ) it { should have_subject ( / Account confirmation / ) }", "del_tokens": "@email . should deliver_to ( \"jojo@yahoo.com\" ) it \"should have the correct subject\" do @email . subject . should =~ / Account confirmation / end", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Fixnum", "automocking", "and", "add", "attribute", "override", "option", "for", "Model", ".", "mock", "(", "like", "Fabricator", ")"], "add_tokens": "def mock ( attributes = { } , recursive = true ) ( association . klass . respond_to? ( :mock ) ) ? [ association . name , association . klass . mock ( { } , false ) ] : nil", "del_tokens": "def mock ( recursive = true ) ( association . klass . respond_to? ( :mock ) ) ? [ association . name , association . klass . mock ( false ) ] : nil", "commit_type": "add"}
{"commit_tokens": ["Add", "writeable_on", "flag", "for", "attributes"], "add_tokens": "attribute :composite , Boolean , writeable_on : :create attribute :initial_stock_level , BigDecimal , writeable_on : :create attribute :initial_cost_price , BigDecimal , writeable_on : :create", "del_tokens": "attribute :composite , Boolean", "commit_type": "add"}
{"commit_tokens": ["Add", "MongoDB", "storage", "connector", "."], "add_tokens": "mongo resolv vines / storage / mongodb", "del_tokens": "resolv - replace", "commit_type": "add"}
{"commit_tokens": ["Remove", "warnings", "and", "bump", "version", "."], "add_tokens": "VERSION = '0.1.2' . freeze", "del_tokens": "VERSION = '0.1.1' . freeze", "commit_type": "remove"}
{"commit_tokens": ["adding", "a", "warning", "for", "bad", "file", "formats"], "add_tokens": "key = accept ( k ) if key == '<<' && Nodes :: Alias === v # FIXME: remove this when \"<<\" syntax is deprecated if $VERBOSE where = caller . find { | x | x !~ / psych / } warn where warn \"\\\"<<: *#{v.anchor}\\\" is no longer supported, please switch to \\\"*#{v.anchor}\\\"\" end return accept ( v ) else hash [ key ] = accept ( v ) end", "del_tokens": "hash [ accept ( k ) ] = accept ( v )", "commit_type": "add"}
{"commit_tokens": ["Fix", "_for_select", "to", "return", "correct", "k", "v"], "add_tokens": "[ block_given? ? yield ( k , v ) : self . human_enum_name ( #{attr_name.inspect}, k), v]", "del_tokens": "[ block_given? ? yield ( k , v ) : self . human_enum_name ( #{attr_name.inspect}, k), k]", "commit_type": "fix"}
{"commit_tokens": ["add", "-", "a", "option", "for", "references"], "add_tokens": "UniprotEntry . includes ( :ec_cross_references , :go_cross_references ) .", "del_tokens": "UniprotEntry . #includes(:refseq_cross_references, :ec_cross_references, :go_cross_references).", "commit_type": "add"}
{"commit_tokens": ["Added", "status", "update", "line", "for", "all", "pages"], "add_tokens": "@log . puts \"Scanning: \" + url . to_s", "del_tokens": "#@log.puts \"Received message for \" + url.to_s", "commit_type": "add"}
{"commit_tokens": ["fixing", "the", "mass", "assign", "issue", "and", "changing", "api", "names"], "add_tokens": "pass . check_for_updates if pass . respond_to? :check_for_updates", "del_tokens": "pass . update_from_api if pass . respond_to? :update_from_api", "commit_type": "fix"}
{"commit_tokens": ["Implement", "specs", "for", "inlining", "<link", ">", "elements"], "add_tokens": "all_link_elements_to_be_inlined_with_url . each do | link , url | # Joining on an \"absolute\" path ignores everything before the absoluted path # so we have to remove the starting slash url_path = url . path . sub ( %r{ ^/ } , '' ) file_path = Rails . root . join ( 'public' , url_path ) raise CSSFileNotFound . new ( file_path , link [ 'href' ] ) unless file_path . file? @inline_css << file_path . read def all_link_elements_with_url document . css ( \"link\" ) . map { | link | [ link , URI . parse ( link [ 'href' ] ) ] } end def all_link_elements_to_be_inlined_with_url all_link_elements_with_url . reject do | link , url | absolute_path_url = ( url . host or url . path . nil? ) blacklisted_element = ( link [ 'media' ] == 'print' or link [ 'data-immutable' ] ) absolute_path_url or blacklisted_element end end", "del_tokens": "document . css ( \"link\" ) . each do | link | next if link [ 'media' ] == 'print' or link [ 'data-immutable' ] @inline_css << File . new ( File . join ( Rails . root , 'public' , link [ 'href' ] . split ( / \\? / , 2 ) . first ) ) . read", "commit_type": "implement"}
{"commit_tokens": ["moved", "#update_schema", "from", "schema", "to", "dwcr", "module"], "add_tokens": "DwCR . update_schema ( @archive , schema_options )", "del_tokens": "update_schema ( schema_options ) # Updates all MetaAttribute instances # with parameters from files in ContentFile # _schema_options_: a Hash with attribute names as keys and boolean values # <tt>{ :type => true, :length => true }</tt> # updates any attribute given as key where value is _true_ def update_schema ( options ) return if options . empty? # FIXME: throw an error if schema is not built options . select! { | _k , v | v == true } @archive . meta_entities . each { | entity | entity . update_meta_attributes! ( * options . keys ) } end", "commit_type": "move"}
{"commit_tokens": ["move", "submitter", "initialization", "to", "an", "initializer", "duh", "."], "add_tokens": "VERSION = \"0.12.0\"", "del_tokens": "VERSION = \"0.11.6\"", "commit_type": "move"}
{"commit_tokens": ["Use", "ActiveRecord", "::", "Base", ".", "logger", ".", "silence", "to", "silence", "when", "using", "CryptKeeper", ".", "silence_logs?"], "add_tokens": "# Private: Sanitize an sql query and then execute it. # # query - the sql query # new_transaction - if the query should run inside a new transaction # # Returns the ActiveRecord response. def escape_and_execute_sql ( query , new_transaction : false ) if CryptKeeper . silence_logs? :: ActiveRecord :: Base . logger . silence do execute_sql ( query , new_transaction : new_transaction ) end else execute_sql ( query , new_transaction : new_transaction ) end end # Private: Executes the query. # # query - the sql query # new_transaction - if the query should run inside a new transaction # # Returns an Array. def execute_sql ( query , new_transaction : false ) if new_transaction :: ActiveRecord :: Base . transaction ( requires_new : true ) do :: ActiveRecord :: Base . connection . execute ( query ) . first end else :: ActiveRecord :: Base . connection . execute ( query ) . first end", "del_tokens": "# Private: Sanitize an sql query and then execute it def escape_and_execute_sql ( query ) :: ActiveRecord :: Base . connection . execute ( query ) . first", "commit_type": "use"}
{"commit_tokens": ["add", "to_json", "method", "to", "archive", "and", "correct", "docs"], "add_tokens": "# @attr [int] created_at # @attr [string] partner_id # @attr [string] session_id # A JSON encoded string representation of the archive def to_json @json . to_json end", "del_tokens": "# @attr [int] createdAt # @attr [string] partnerId # @attr [string] sessionId", "commit_type": "add"}
{"commit_tokens": ["adding", "some", "fixes", "to", "integrate", "the", "underlying", "framework", "better", "."], "add_tokens": "print \"\\n#{ui.color(\"Waiting for sshd on: #{public_ip}\", :magenta)}\" elsif print \"\\n#{ui.color(\"Waiting for winrm to be active on: #{public_ip}\", :magenta)}\" bootstrap . config [ :environment ] = locate_config_value ( :environment )", "del_tokens": "print \"\\n#{ui.color(\"Waiting for sshd\", :magenta)}\" else print \"\\n#{ui.color(\"Waiting for winrm to be active\", :magenta)}\" bootstrap . config [ :environment ] = locate_config_value ( :environment ) bootstrap . config [ :environment ] = locate_config_value ( :environment )", "commit_type": "add"}
{"commit_tokens": ["Use", "conditions", "to", "filter", "on", "translation", "key", "values"], "add_tokens": "conditions : { translatable_type : self . to_s , key : association_attributes } , class : translations_class", "del_tokens": "conditions : { translatable_type : self . to_s } , class : translations_class do | ds | ds . where key : association_attributes end", "commit_type": "use"}
{"commit_tokens": ["Make", "Response#request", "part", "of", "the", "public", "API"], "add_tokens": "# The request that lead to this response # # @example # # response = dispatcher.call(:successful_action, :some_input) # response.request # => request passed to action named :successful_action # # @return [Request] # # @api public attr_reader :request", "del_tokens": "protected # The request that lead to this response # # @return [Request] # # @api private attr_reader :request", "commit_type": "make"}
{"commit_tokens": ["added", "normal", "(", "escaped", ")", "and", "not", "-", "escaped", "output", "for", "after", "tag", "code"], "add_tokens": "when / \\A (&?)= / @line = $' output_node = append_node :output output_node . escaped = $1 . length == 0 output_node . data = parse_ruby_code ( \"\\n\" )", "del_tokens": "when / \\A = / @line = $' block = [ :multi ] tag << [ :slim , :output , $1 != '=' , parse_broken_line , block ] @stacks << block", "commit_type": "add"}
{"commit_tokens": ["moved", "watch", "method", "to", "Mutter", "class"], "add_tokens": "end ; nil", "del_tokens": "end ; nil # # Utility function, to make a block interruptible # def watch begin yield rescue Interrupt puts exit 0 end end alias :oo watch", "commit_type": "move"}
{"commit_tokens": ["Added", "post", "API", "methods", "for", "getContext", "listPopular", "and", "update"], "add_tokens": "before do stub_get ( \"posts/getContext.json\" , :query => { :post => \"3\" } ) . to_return ( :body => fixture ( \"posts/getContext.json\" ) , :headers => { :content_type => \"application/json; charset=utf-8\" } ) end it \"Returns the hierarchal tree of a post (all parents)\" do @client . getContext ( 3 ) a_get ( \"posts/getContext.json\" , :query => { :post => \"3\" } ) . should have_been_made end before do stub_get ( \"posts/listPopular.json\" , :query => { :forum => \"bobross\" } ) . to_return ( :body => fixture ( \"posts/listPopular.json\" ) , :headers => { :content_type => \"application/json; charset=utf-8\" } ) end it \"Returns a list of posts ordered by the number of likes recently.\" do @client . listPopular ( :forum => \"bobross\" ) a_get ( \"posts/listPopular.json\" , :query => { :forum => \"bobross\" } ) . should have_been_made end describe \".update\" do before do stub_post ( \"posts/update.json\" , :body => { :post => \"12345678\" , :message => \"Hello\" } ) . to_return ( :body => fixture ( \"posts/update.json\" ) , :headers => { :content_type => \"application/json; charset=utf-8\" } ) end it \"Updates information on a post\" do @client . update ( 12345678 , \"Hello\" ) a_post ( \"posts/update.json\" , :body => { :post => \"12345678\" , :message => \"Hello\" } ) . should have_been_made end end", "del_tokens": "pending pending", "commit_type": "add"}
{"commit_tokens": ["Add", "RAILS_ROOT", "so", "that", "vendored", "rails", "can", "also", "be", "found", "and", "booted", "."], "add_tokens": "require \"#{RAILS_ROOT}/vendor/rails/railties/lib/initializer\"", "del_tokens": "require 'vendor/rails/railties/lib/initializer'", "commit_type": "add"}
{"commit_tokens": ["adding", "factories", "generator", "more", "docs", "from", "trial", "run"], "add_tokens": "m . directory File . join ( \"app\" , \"controllers\" ) m . directory File . join ( \"app\" , \"models\" ) m . directory File . join ( \"app\" , \"views\" ) m . directory File . join ( \"app\" , \"views\" , \"passwords\" ) m . directory File . join ( \"app\" , \"views\" , \"sessions\" ) m . directory File . join ( \"app\" , \"views\" , \"user_mailer\" ) m . directory File . join ( \"app\" , \"views\" , \"users\" ) m . directory File . join ( \"test\" , \"functional\" ) m . directory File . join ( \"test\" , \"unit\" ) [ \"test/factories.rb\" ] . each do | file | m . file file , file end", "del_tokens": "system ` mkdir app/controllers ` system ` mkdir app/models ` system ` mkdir app/views ` system ` mkdir app/views/passwords ` system ` mkdir app/views/sessions ` system ` mkdir app/views/user_mailer ` system ` mkdir app/views/users ` system ` mkdir test/functional ` system ` mkdir test/unit `", "commit_type": "add"}
{"commit_tokens": ["Allow", "request", "buffer", "to", "accept", "mixed", "encodings"], "add_tokens": "@s = '' . encode ( Encoding :: BINARY ) string = string . dup . force_encoding ( Encoding :: BINARY ) @s", "del_tokens": "@s = '' ensure_ascii ensure_ascii ensure_ascii ensure_ascii ensure_ascii end private def ensure_ascii @s . force_encoding ( Encoding :: BINARY )", "commit_type": "allow"}
{"commit_tokens": ["fix", "#new", "spec", "nested", "within", "#created"], "add_tokens": "describe \"#new\" do it \"assigns an user\" do get :new , use_route : 'landing_page' expect ( assigns [ :user ] ) . to be_instance_of LandingPage :: User end describe \"#create\" do", "del_tokens": "describe \"#create\" do describe \"#new\" do it \"assigns an user\" do get :new , use_route : 'landing_page' expect ( assigns [ :user ] ) . to be_instance_of LandingPage :: User end", "commit_type": "fix"}
{"commit_tokens": ["Added", "cucumber", "scenario", "that", "demonstrates", "the", "use", "of", "a", "regex", "for", "a", "URI", "in", "a", "cassette", "."], "add_tokens": "selector = case url when String then lambda { | r | URI . parse ( r . uri ) == URI . parse ( url ) } when Regexp then lambda { | r | r . uri == url } else raise ArgumentError . new ( \"Unexpected url: #{url.class.to_s}: #{url.inspect}\" ) end responses = responses . select ( & selector ) Given / ^the \"([^ \\\" ]*)\" library file has a response for \\/ ( \\S +) \\/ that matches \\/ (.+) \\/ $ / do | cassette_name , url_regex , body_regex | recorded_interactions_for ( cassette_name ) . should have_expected_response ( / #{ url_regex } / , body_regex ) end", "del_tokens": "responses = responses . select { | r | URI . parse ( r . uri ) == URI . parse ( url ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "Parse", "::", "Object#pointer", "to", "include", "class", "name", ".", "Added", "test", "to", "document", "prior", "bug"], "add_tokens": "Parse :: Pointer . new self . merge ( Parse :: Protocol :: KEY_CLASS_NAME => class_name )", "del_tokens": "Parse :: Pointer . new self", "commit_type": "fix"}
{"commit_tokens": ["update", "reason1", "field", "per", "sofort", "request"], "add_tokens": "mapping :order , 'reason_1'", "del_tokens": "add_field ( 'user_variable_0' , order ) mapping :description , 'reason_1'", "commit_type": "update"}
{"commit_tokens": ["Improving", "configuration", "support", "to", "prepare", "for", "Geppetto", "integration"], "add_tokens": "options = options . dup if environment = options . delete ( :environment ) File . open ( 'config/database.yml' , 'r' ) do | f | raise \"no configuration for environment: #{environment}\" unless env_config = all_db_config [ environment ] db_config . merge! ( env_config ) #args take precedent over config db_config . merge! options . delete ( :connection ) if options [ :connection ]", "del_tokens": "if defined? Rails File . open ( File . join ( Rails . root , 'config/database.yml' ) , 'r' ) do | f | db_config . merge! ( all_db_config [ Rails . env ] ) if all_db_config #args take precedent over config db_config . merge! options . delete ( :connection ) if options [ :connection ]", "commit_type": "improve"}
{"commit_tokens": ["fix", "task", "to", "actually", "upload", "default", "email", "templates"], "add_tokens": "VERSION = '0.2.1'", "del_tokens": "VERSION = '0.2.0'", "commit_type": "fix"}
{"commit_tokens": ["Added", "method", "missing", "to", "default", "to", "getting", "and", "setting", "keyvalues"], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "MongoDB", "/", "Serialization", "issue"], "add_tokens": "# encoding: utf-8 res ? res [ 'data' ] : nil { '_id' => key , 'data' => value } ,", "del_tokens": "res && deserialize ( res [ 'data' ] . to_s ) buffer = BSON :: ByteBuffer . new serialize ( value ) { '_id' => key , 'data' => buffer . to_s } ,", "commit_type": "fix"}
{"commit_tokens": ["Allow", "spaces", "in", "filenames", "but", "strip", "them"], "add_tokens": "content_disposition = meta [ \"content-disposition\" ] . to_s filename = content_disposition [ / filename=\"([^\"]+)\" / , 1 ] || content_disposition [ / filename=(.+) / , 1 ] filename && filename . strip", "del_tokens": "meta [ \"content-disposition\" ] . to_s [ / filename=\"?([^ \"]+)\"? / , 1 ]", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "-", "up", "require", "statements", "."], "add_tokens": "require 'partial-date/version' require 'partial-date/error'", "del_tokens": "require File . expand_path ( '../partial-date/version' , __FILE__ ) require File . expand_path ( '../partial-date/error' , __FILE__ ) # require 'partial-date/version' # require 'partial-date/error'", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "file", "flags", "(", "that", "they", "bind", "correctly", ")"], "add_tokens": "end def test_flags f = RPM :: File . new ( \"path\" , \"md5sum\" , nil , 42 , 1 , \"owner\" , \"group\" , 43 , 0777 , 44 , 45 ) f . config? f . doc? f . donotuse? f . is_missingok? f . is_noreplace? f . is_specfile? f . ghost? f . license? f . readme? f . exclude? f . replaced? f . notinstalled? f . netshared? end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "recursive", "hash", "handling", "."], "add_tokens": "reduce ( { } ) do | new_hash , ( key , value ) | if value . respond_to? ( :force_encoding! ) value . force_encoding! ( encoding , & block ) elsif value . is_a? ( Enumerable ) value . each do | val | next unless val . respond_to? ( :force_encoding! ) val . force_encoding! ( encoding , & block ) end elsif value . is_a? ( String ) # force encoding then strip all non ascii chars if block_given? self [ key ] = yield ( value . force_encoding ( encoding ) ) else self [ key ] = value . force_encoding ( encoding ) end elsif value . is_a? ( Enumerable ) value . each do | val | next unless val . respond_to? ( :adjust_values! ) val . adjust_values! ( & block ) end elsif value . is_a? ( Enumerable ) value . each do | val | next unless val . respond_to? ( :cast_values! ) val . cast_values! end", "del_tokens": "inject ( { } ) do | new_hash , ( key , value ) | case value when String # force encoding then strip all non ascii chars if block_given? self [ key ] = yield ( value . force_encoding ( encoding ) ) else self [ key ] = value . force_encoding ( encoding ) end when Hash then value . force_encoding! ( encoding , & block )", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "format", "for", "storing", "maps", "now", "supports", ".", "rb", "files", "(", "loosely", ")", ".", "Added", "some", "more", "improvements"], "add_tokens": "class FiletypeError < StandardError end locale_files = Dir . glob ( \"#{directory}/*\" ) # set up the file arguments to be passed into the diff engine diff_files = self . get_file_info ( locale_files ) LocaleDiff :: Diff . new ( diff_files ) . begin! # TODO Also perform this operation for any locale files directly inside of the locale directory private def self . skip_directories [ \".\" , \"..\" ] + LocaleDiff . skip_directories end def self . get_file_info ( locale_files ) # Then get the language it represents # Then get store it all in a hash accepted_formats = [ \".yml\" , \".rb\" ] diff_files = [ ] locale_files . each do | file | # ensure a good filetype before we go reading this in unless accepted_formats . include? ( File . extname ( file ) ) raise FiletypeError ( file , \"Locale file is not one of the accepted formats. Pleasure ensure you are using .rb or .yml to store your locales.\" ) end # otherwise get all of the information diff_files << { lang : File . basename ( file , File . extname ( file ) ) , type : File . extname ( file ) , path : file } end diff_files end", "del_tokens": "locales = Dir . glob ( \"#{directory}/*\" ) # run the diff on this directory # then loop through every sub directory and do the same thing def self . skip_directories [ \".\" , \"..\" ] + LocaleDiff . skip_directories end", "commit_type": "add"}
{"commit_tokens": ["fix", "param", "access", "when", "there", "are", "no", "params", "in", "uri"], "add_tokens": "@params ||= CGI :: parse ( query )", "del_tokens": "@params ||= CGI :: parse ( URI ( uri ) . query )", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "bug", "in", "the", "previous", "commit", "we", "need", "to", "re", "-", "vendor", "the", "pods", "project", "every", "time", "regardless", "if", "the", "podfile", "changed"], "add_tokens": "@pods . install! ( podfile_changed ) VERSION = '1.1.2' def install! ( podfile_changed ) pods_installer . install! if podfile_changed", "del_tokens": "if podfile_changed @pods . install! end VERSION = '1.1.1' def install! pods_installer . install!", "commit_type": "fix"}
{"commit_tokens": ["Add", "private", "accessor", ".", "model", "method"], "add_tokens": "def model @model end self . allowed || ( model . public_methods - denied ) model . send method , * args , & block", "del_tokens": "self . allowed || ( @model . public_methods - denied ) @model . send method , * args , & block", "commit_type": "add"}
{"commit_tokens": ["Updated", "several", "gems", "and", "gemlock", "file", ".", "Fixed", "version", "file", "."], "add_tokens": "module Subengine VERSION = \"0.5.0\" end", "del_tokens": "module subengine VERSION = '0.0.014' end", "commit_type": "update"}
{"commit_tokens": ["Adds", "Device", "::", "PRODUCT_IDS", "8", "for", "Electron"], "add_tokens": "6 => \"Photon\" . freeze , 8 => \"Electron\" . freeze", "del_tokens": "6 => \"Photon\" . freeze", "commit_type": "add"}
{"commit_tokens": ["Added", "/", "greened", "some", "foreign", "key", "checks", "to", "global_data_test", "refactored", "test", "setup", "a", "bit"], "add_tokens": "create_testing_system_state_and_groups online_test \"global data is writable and destroyable\" do offline_test \"global data is not writable or destroyable\" do online_test \"global data can hold a foreign key to other global data\" do another_global_record = GlobalRecord . create ( :title => \"Yet Another\" ) assert_nothing_raised do @global_record . friend = another_global_record @global_record . save! end end online_test \"global data cannot hold a foreign key to group data\" do assert_raise RuntimeError do @global_record . some_group = @offline_group @global_record . save! end end online_test \"global data cannot hold a foreign key to unmirrored data\" do unmirrored_data = UnmirroredRecord . create ( :content => \"Some Unmirrored Data\" ) assert_raise RuntimeError do @global_record . unmirrored_record = unmirrored_data @global_record . save! end end", "del_tokens": "if OfflineMirror :: app_offline? opts = { :offline_group_id => 1 , :current_mirror_version => 1 } OfflineMirror :: SystemState :: create ( opts ) or raise \"Unable to create offline-mode testing SystemState\" @offline_group = Group . new ( :name => \"An Offline Group\" ) @offline_group . bypass_offline_mirror_readonly_checks @offline_group . save! @offline_group_data = GroupOwnedRecord . create ( :description => \"Some Offline Data\" , :group => @offline_group ) raise \"Test id mismatch\" unless @offline_group . id == OfflineMirror :: SystemState :: current_mirror_version end online_test \"global data is savable and destroyable\" do offline_test \"global data is not savable or destroyable\" do", "commit_type": "add"}
{"commit_tokens": ["move", "refute_equal", "0", "above", "OCTION_SYMBOLS", "access"], "add_tokens": "x_icon = Octicons :: OCTICON_SYMBOLS [ \"x\" ]", "del_tokens": "x_icon = Octicons :: OCTICON_SYMBOLS [ \"x\" ]", "commit_type": "move"}
{"commit_tokens": ["Use", "rugged", "for", "a", "better", "git", "discovery"], "add_tokens": "require 'rubygems' require 'rugged' Rugged :: Repository . discover ( ENV [ 'PWD' ] ) . gsub ( '.git/' , '' ) rescue Rugged :: RepositoryError ''", "del_tokens": "require 'rubygems' %x{ git rev-parse --show-toplevel } . strip", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "newlines", "floatin", "around", "."], "add_tokens": "it \"should allow me to put blocks right after text and a newline\" do html = @parser . parse ( \"check out this f*ckin block:\\n\\\\begin{itemize} \\\\item hey \\\\end{itemize}\" ) . html html . should == \"<div class='entry'><p>check out this f*ckin block:<ul><li>hey </li></ul></p></div>\"", "del_tokens": "it \"should parse blocks with no preceeding whitespace\" do html = @parser . parse ( \"check out this f*cking block:\\\\begin{itemize} \\\\item hey \\\\end{itemize}\" ) . html html . should == \"<div class='entry'><p>check out this f*cking block:<ul><li>hey </li></ul></p></div>\"", "commit_type": "add"}
{"commit_tokens": ["Changing", "transition_state", "s", "flash", "when", "transitioning", "from", "pending"], "add_tokens": "@initiative = resource . initiative @user = resource . user initial_state = resource . state_name if initial_state == :pending flash [ :success ] = \"Apoio realizado com sucesso!\" else flash [ :success ] = \"Status do apoio alterado com sucesso!\" end redirect_to initiative_contribution_path ( resource . initiative . id , resource )", "del_tokens": "@initiative = @contribution . initiative @user = @contribution . user flash [ :success ] = \"Status do apoio alterado com sucesso!\" redirect_to initiative_contribution_path ( @contribution . initiative . id , @contribution )", "commit_type": "change"}
{"commit_tokens": ["Fix", "deprecation", "warning", "for", "Mocha"], "add_tokens": "require 'mocha/setup'", "del_tokens": "require 'mocha'", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "minor", "issues", "with", "similarity", "."], "add_tokens": "attr_accessor :case_sensitive , :remove_symbols , :move_articles , :convert_roman , :a , :b return 100.0 if @a == @b score , total_weight = 0 , @algorithms . map { | alg , v | v [ :weight ] } . inject { | sum , w | sum += w }", "del_tokens": "attr_accessor :case_sensitive , :remove_symbols , :move_articles , :convert_roman return 100.0 if a == b score , total_weight = 0 , @algorithms . map { | a , v | v [ :weight ] } . inject { | sum , w | sum += w }", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "spawn", "a", "telegram", "-", "cli", "and", "polling", "from", "it"], "add_tokens": "@on_disconnect = nil messages = messages . map { | m | escape ( m ) } . join << \"\\n\" send_data ( messages ) def on_disconnect = ( block ) @on_disconnect = block @on_connect . call unless @on_connect . nil? end def unbind @connected = false @on_disconnect . call unless @on_disconnect . nil? end def connected? @connected p data result = _receive_data ( data ) result = nil @callback . call ( ! result . nil? , result ) unless @callback . nil? data", "del_tokens": "messages = messages . map { | m | escape ( m ) } . join messages << \"\\n\" send_data ( messages ) def connected? @connected @on_connect . call _receive_data ( data ) p data", "commit_type": "add"}
{"commit_tokens": ["Add", "spaces", "for", "better", "readability"], "add_tokens": "File . open ( path , 'w' ) do | f | f . write ( lines . flatten . join ( \"\\n\" ) ) end hash . each_pair do | k , v | hash [ k ] = v . first if v . size == 1 end", "del_tokens": "File . open ( path , 'w' ) { | f | f . write ( lines . flatten . join ( \"\\n\" ) ) } hash . each_pair { | k , v | hash [ k ] = v . first if v . size == 1 }", "commit_type": "add"}
{"commit_tokens": ["Add", "conversion", "from", "string", "to", "hash", "of", "integer", "float", "or", "boolean", "values"], "add_tokens": "it \"converts hash to hash\" do conversion = converter . convert ( { a : 1 , b : 2 , c : 3 } ) . to ( :hash ) expect ( conversion ) . to eq ( { a : 1 , b : 2 , c : 3 } ) end it \"converts string to integer hash\" do conversion = converter . convert ( \"a:1 b:2 c:3\" ) . to ( :int_hash ) it \"converts string to float hash\" do conversion = converter . convert ( \"a:1 b:2 c:3\" ) . to ( :float_hash ) expect ( conversion ) . to eq ( { a : 1.0 , b : 2.0 , c : 3.0 } ) end it \"converts string to boolean hash\" do conversion = converter . convert ( \"a:t b:f c:t\" ) . to ( :boolean_hash ) expect ( conversion ) . to eq ( { a : true , b : false , c : true } ) end it \"converts string to bool hash\" do conversion = converter . convert ( \"a:t b:f c:t\" ) . to ( :bool_hash ) expect ( conversion ) . to eq ( { a : true , b : false , c : true } ) end", "del_tokens": "it \"converts hash to hash\" do conversion = converter . convert ( { a : 1 , b : 2 , c : 3 } ) . to ( :hash )", "commit_type": "add"}
{"commit_tokens": ["fixed", "Rack", "::", "Accept", "::", "Header#parse_media_type", "to", "correctly", "parse", "media", "types", "with", "more", "than", "one", "media", "-", "range", "parameter"], "add_tokens": "m = media_type . to_s . match ( / ^([a-z*]+) \\/ ([a-z*-]+)(?:;([a-z0-9=;]+))?$ / )", "del_tokens": "m = media_type . to_s . match ( / ^([a-z*]+) \\/ ([a-z*-]+)(?:;([a-z0-9=]+))?$ / )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "for", "specifying", "a", "logfile", "when", "daemonizing", "a", "process"], "add_tokens": ":log_path => false , redirect_output! opts . on ( \"-l\" , \"--log FILE\" , String , \"Logfile for output\" ) do | v | options [ :log_path ] = v end # Redirect output based on log settings (reopens stdout/stderr to specified logfile) # If log_path is nil, redirect to /dev/null to quiet output def redirect_output! if log_path = options [ :log_path ] FileUtils . touch log_path File . open ( log_path , 'a' ) do | f | $stdout . reopen ( f ) $stderr . reopen ( f ) end else # redirect to /dev/null STDIN . reopen \"/dev/null\" STDOUT . reopen \"/dev/null\" , \"a\" STDERR . reopen STDOUT end log_path = options [ :log_path ] ? options [ :log_path ] : \"/dev/null\" end", "del_tokens": "STDIN . reopen \"/dev/null\" STDOUT . reopen \"/dev/null\" , \"a\" STDERR . reopen STDOUT", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "asset", "migration", "into", "the", "dummy", "test", "app"], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20120106192233 ) do", "del_tokens": "ActiveRecord :: Schema . define ( :version => 20120105034123 ) do", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "recursive", "comments", "."], "add_tokens": "{ # beginning of comment ( [ [ :print : ] && [ ^ \\\\ { } ] ] | # printing characters except brace and backslash n | \\\\\\ | # escaped backslashes \\\\ { | \\\\ } | # escaped braces n | # newlines g < 1 > # recursive ) * # zero or more of the above } # end of comment )", "del_tokens": "{ # beginning of comment [ [ :print : ] && [ ^ \\\\ } ] ] | # printing characters except closing brace and backslash n | \\\\\\ | # escaped backslashes \\\\ } | \\\\ } | # escaped braces n # newlines ) * # zero or more of the above } # end of comment", "commit_type": "add"}
{"commit_tokens": ["allows", "other", "form", "builder", "just", "use", "foundation", "if", "nothing", "is", "set"], "add_tokens": "options [ :builder ] ||= FoundationRailsHelper :: FormBuilder options [ :builder ] ||= FoundationRailsHelper :: FormBuilder", "del_tokens": "options [ :builder ] = FoundationRailsHelper :: FormBuilder options [ :builder ] = FoundationRailsHelper :: FormBuilder", "commit_type": "allow"}
{"commit_tokens": ["Updating", "tests", "to", "reflect", "salt", "and", "password", "changes", "."], "add_tokens": "test 'should generate salt while setting password' do assert_present new_user . password_salt assert_present new_user ( :password => nil ) . password_salt assert_present new_user ( :password => '' ) . password_salt test 'should generate a base64 hash using SecureRandom for password salt' do ActiveSupport :: SecureRandom . expects ( :base64 ) . with ( 15 ) . returns ( 'friendly_token' ) assert_equal 'friendly_token' , new_user . password_salt test 'should generate encrypted password while setting password' do assert_present new_user . encrypted_password assert_present new_user ( :password => nil ) . encrypted_password assert_present new_user ( :password => '' ) . encrypted_password", "del_tokens": "test 'should not generate salt while setting password' do assert_nil new_user . password_salt assert_nil new_user ( :password => nil ) . password_salt assert_nil new_user ( :password => '' ) . password_salt end test 'should generate password salt while saving' do test 'should generate a sha1 hash for password salt' do now = Time . now Time . stubs ( :now ) . returns ( now ) User . any_instance . stubs ( :random_string ) . returns ( 'random_string' ) user = create_user expected_salt = :: Digest :: SHA1 . hexdigest ( \"--#{now.utc}--random_string--123456--\" ) assert_equal expected_salt , user . password_salt test 'should not generate encrypted password while setting password' do assert_nil new_user . encrypted_password assert_nil new_user ( :password => nil ) . encrypted_password assert_nil new_user ( :password => '' ) . encrypted_password end test 'should generate encrypted password while saving' do", "commit_type": "update"}
{"commit_tokens": ["Added", "documentation", "to", "Quickl", "module", "."], "add_tokens": "# # A fresh new builder is created if not already done. # # This method is part of Quickl's private interface. # # # The current command builder is considered consumed # and removed as a side effect. A RuntimeError is raised # if no builder is currently installed. # # Returns the command itself. # # This method is part of Quickl's private interface. # command", "del_tokens": "# A new builder is created if required # The builder is considered consumed and removed as # a side effect.", "commit_type": "add"}
{"commit_tokens": ["use", "puts", "instead", "of", "write"], "add_tokens": "# To use this module, extend a game object with Chess::Gnuchess. # Gnuchess binary have to be installed. # g.gnuchess_move! moves = [ ] pipe . puts ( 'depth 1' ) pipe . puts ( 'manual' ) pipe . puts ( m ) pipe . puts ( 'go' ) match = line . match ( / My move is : ([a-h][1-8][a-h][1-8][rkbq]?) / ) return match [ 1 ] if match pipe . puts ( 'quit' ) return moves end # Make a move using Gnuchess engine. This add a new Board in the Game. # Return the next move calculated by Gnuchess. # Gnuchess must be installed! def gnuchess_move! next_move = self . gnuchess_move self . move ( next_move ) if next_move end # :nodoc: def self . included ( mod ) raise_if_gnuchess_is_not_installed end # :nodoc: def self . extended ( mod ) raise_if_gnuchess_is_not_installed # Raise an exception if Gnuchess is not installed def self . raise_if_gnuchess_is_not_installed unless gnuchess_installed? raise 'You need to install Gnuchess to use the module Chess::Gnuchess.' end end", "del_tokens": "# To use this module, extend a game object with Chess::Gnuchess # g.gnuchess_move pipe . write ( \"depth 1\\n\" ) pipe . write ( \"force\\n\" ) pipe . write ( m + \"\\n\" ) pipe . write ( \"go\\n\" ) match = line . match ( / My move is : ([a-h][1-8][a-h][1-8]) / ) return self . move ( match [ 1 ] ) if match pipe . write ( \"quit\\n\" )", "commit_type": "use"}
{"commit_tokens": ["Add", "simple", "test", "for", "Rack", "middleware"], "add_tokens": "Raven . send ( evt )", "del_tokens": "Raven . send ( evt ) if evt", "commit_type": "add"}
{"commit_tokens": ["Allow", "formatters", "to", "return", "nil"], "add_tokens": "message . format . to_a . each do | msg |", "del_tokens": "message . format . each do | msg |", "commit_type": "allow"}
{"commit_tokens": ["adding", "file", "appium_server_spec", ".", "rb", "and", "initial", "commit"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Remove", "from", "initializer", "and", "add", "it", "as", "method", "on", "newsletter", "sender"], "add_tokens": "SES = AWS :: SES :: Base . new ( access_key_id : ENV [ 'SES_ACCESS_KEY_ID' ] , secret_access_key : ENV [ 'SES_SECRET_ACCESS_KEY' ] ) SES . send_raw_email ( mail )", "del_tokens": ":: SES . send_raw_email ( mail )", "commit_type": "remove"}
{"commit_tokens": ["Added", "explicit", "html", "format", "option", "."], "add_tokens": "AllowedFormats = { :xml => 'text/xml' , :json => 'application/json' , :html => 'text/html' }", "del_tokens": "AllowedFormats = { :xml => 'text/xml' , :json => 'application/json' }", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "config", "option", "for", "setting", "a", "redirect", "prefix", "that", "is", "added", "to", "every", "redirect", "URI"], "add_tokens": "redirect_page . generate_redirect_content ( redirect_url ( site , item ) ) def redirect_url ( site , item ) File . join redirect_prefix ( site ) , item . url end def redirect_prefix ( site ) config_github_url ( site ) || config_baseurl ( site ) || \"\" end def config_github_url ( site ) site . config . fetch ( 'github' , Hash . new ) . fetch ( 'url' , nil ) end def config_baseurl ( site ) site . config . fetch ( 'baseurl' , nil ) end", "del_tokens": "redirect_page . generate_redirect_content ( item . url )", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "symbol", "Chef", "really", "does", "declare", "this", "globally", ".", "Sigh", "."], "add_tokens": "@options ||= Mash . new . tap do | opts |", "del_tokens": "@options ||= Chef :: Mash . new . tap do | opts |", "commit_type": "fix"}
{"commit_tokens": ["added", "query", "fail", "to", "the", "ruby", "template"], "add_tokens": "query_success_message = { send_message ( 'MSG_QUERY_SUCCESS' , query_success_message ) end def query_fail ( id , message ) query_fail_message = { id : id , message : message } send_message ( 'MSG_QUERY_FAIL' , query_fail_message )", "del_tokens": "query_success = { send_message ( 'MSG_QUERY_SUCCESS' , query_success )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "#valid?", "and", "#parse", "consider", "URIs", "as", "valid", "domains", "(", "closes", "GH", "-", "15", ")"], "add_tokens": "def test_self_parse_raises_with_invalid_domain def test_self_parse_raises_with_unallowed_domain def test_self_raises_with_uri error = assert_raise ( PublicSuffix :: DomainInvalid ) { PublicSuffix . parse ( \"http://google.com\" ) } assert_match %r{ http://google \\. com } , error . message end", "del_tokens": "def test_self_parse_should_raise_with_invalid_domain def test_self_parse_should_raise_with_unallowed_domain", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "ActiveFedora", "objects", "were", "loading", "2", "extra", "times"], "add_tokens": "if obj . kind_of? ActiveFedora :: Base", "del_tokens": "if obj . instance_of? ActiveFedora :: Base", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "stuff", "to", "rm", ".", "app", "and", "rm", ".", "device"], "add_tokens": "class RMQApp < PMApplication def home_screen_class PMApplication . home_screen_class end def current_fragment # TODO end alias :current_screen :current_fragment # @return [Symbol] Environment the app is running it def environment @_environment ||= RUBYMOTION_ENV . to_sym end # @return [Boolean] true if the app is running in the :release environment def release? environment == :release end alias :production? :release? # @return [Boolean] true if the app is running in the :test environment def test? environment == :test end # @return [Boolean] true if the app is running in the :development environment def development? environment == :development end", "del_tokens": "class RMQApp", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "arrays", "are", "references", "not", "direct"], "add_tokens": "dic << ( pos [ ( i * 2 ) + 1 ] . is_a? ( Array ) ? ( { referenced_object : ( { pos [ ( i * 2 ) + 1 ] } ) } ) : pos [ ( i * 2 ) + 1 ] )", "del_tokens": "dic << pos [ ( i * 2 ) + 1 ]", "commit_type": "make"}
{"commit_tokens": ["Fix", "missing", "set", "of", "sync_close", "."], "add_tokens": "@sock . sync_close = true", "del_tokens": "@sock . sync_close", "commit_type": "fix"}
{"commit_tokens": ["Add", "functions", "to", "add", "vars", "and", "update", "model"], "add_tokens": "model . add_var 0 , 1 , 0 , GRB_INTEGER , 'var' model . update", "del_tokens": "Gurobi . GRBaddvar model . ptr , 0 , nil , nil , 0 , 0 , 1 , 'I' . ord , 'var'", "commit_type": "add"}
{"commit_tokens": ["use", "a", "Factory", "instead", "of", "hash", "to", "allow", "validates_presence_of", "in", "User", "model"], "add_tokens": "post :create , :user => Factory . build ( :user ) . attributes . merge ( { :password => 'skerit' , :password_confirmation => 'skerit' } )", "del_tokens": "post :create , :user => { :email => Factory . next ( :email ) , :password => 'skerit' , :password_confirmation => 'skerit' }", "commit_type": "use"}
{"commit_tokens": ["added", "Acclaim", "association", "to", "dummy", "app"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20140902233505 ) do create_table \"acclaims\" , force : true do | t | t . string \"score\" t . string \"publication\" t . text \"description\" t . boolean \"on_stage\" , default : true t . boolean \"on_prod\" , default : false t . integer \"position\" t . integer \"release_id\" t . datetime \"created_at\" t . datetime \"updated_at\" end", "del_tokens": "ActiveRecord :: Schema . define ( version : 20140902231710 ) do", "commit_type": "add"}
{"commit_tokens": ["Remove", "dependency", "on", "the", "HTTP", "gem"], "add_tokens": "class ClientHandshake attr_reader :verb , :uri , :headers , :proxy , :body , :version def initialize ( verb , uri , headers = { } , proxy = { } , body = nil , version = '1.1' ) @verb , @uri , @headers , @proxy , @body , @version = verb , uri , headers , proxy , body , version end if websocket_version_header . to_i != PROTOCOL_VERSION errors << \"Protocol version not supported '#{websocket_version_header}'\" 'Sec-WebSocket-Accept' => ClientHandshake . accept_token_for ( websocket_key_header ) def websocket_version_header headers [ 'Sec-WebSocket-Version' ] || headers [ 'Sec-Websocket-Version' ] end def websocket_key_header headers [ 'Sec-Websocket-Key' ] || headers [ 'Sec-WebSocket-Key' ] end", "del_tokens": "class ClientHandshake < Http :: Request # Careful: Http gem changes header capitalization, # so Sec-WebSocket-Version becomes Sec-Websocket-Version if headers [ 'Sec-Websocket-Version' ] . to_i != PROTOCOL_VERSION errors << \"Protocol version not supported '#{headers['Sec-Websocket-Version']}'\" websocket_key = headers [ 'Sec-Websocket-Key' ] 'Sec-WebSocket-Accept' => ClientHandshake . accept_token_for ( websocket_key )", "commit_type": "remove"}
{"commit_tokens": ["Add", "option", "to", "disable", "the", "automatic", "reporting", "of", "queue", "depth", "metrics", "and", "also", "a", "method", "that", "can", "be", "used", "to", "report", "them", "manually", "."], "add_tokens": "attr_reader :namespace , :logger , :disabled_metrics @disabled_metrics = options . fetch ( :disabled_metrics , [ ] )", "del_tokens": "attr_reader :namespace , :logger", "commit_type": "add"}
{"commit_tokens": ["add", "method", "for", "generating", "timetable", "to", "html", "via", "root", "module"], "add_tokens": "require 'json' require 'tableau/timetable' require 'tableau/parser' def generate ( module_codes ) timetable = Tableau :: Timetable . new ( modules : module_codes ) builder = Tableau :: TableBuilder . new ( timetable ) builder . to_html end parser = Tableau :: Parser . new ( module_code , semester ) parser . get_info", "del_tokens": "parser = Tableau :: Timetable . new ( module_code , semester ) return parser . get_info", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.6.0\"", "del_tokens": "VERSION = \"0.5.0\"", "commit_type": "change"}
{"commit_tokens": ["Added", "conversion", "method", "for", "time", "column", "types"], "add_tokens": "def _protobuf_time_column? ( key ) _protobuf_column_types [ :time ] && _protobuf_column_types [ :time ] . include? ( key ) end when _protobuf_datetime_column? ( key ) then _convert_int64_to_datetime ( value ) when _protobuf_timestamp_column? ( key ) then _convert_int64_to_datetime ( value ) when _protobuf_time_column? ( key ) then", "del_tokens": "when _protobuf_datetime_column? ( key ) || _protobuf_timestamp_column? ( key ) then", "commit_type": "add"}
{"commit_tokens": ["Fix", "net", "-", "http", "-", "persistent", "keepalive"], "add_tokens": "# for net-http-persistent 2.X, alternative is for 3.X if http . respond_to? :keep_alive_timeout http . keep_alive_timeout = 60 else http . keep_alive = 60 end", "del_tokens": "http . keep_alive_timeout = 60", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "below", "two", "helper", "methods", "to", "Invoice", "class", "."], "add_tokens": "end # Helper method to check if the invoice is accounts payable. def accounts_payable? invoice_type == 'ACCPAY' end # Helper method to check if the invoice is accounts receivable. def accounts_receivable? invoice_type == 'ACCREC' end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["added", "a", "note", "about", "DESCRIBE", "queries", "in", "librdf"], "add_tokens": "let ( :q ) { \"PREFIX doap: <http://usefulinc.com/ns/doap#> DESCRIBE ?gem WHERE { ?gem a doap:Project }\" } it { pending \"Not implemented. See: http://bugs.librdf.org/mantis/view.php?id=135\" }", "del_tokens": "it { pending \"Not implemented in librdf?\" }", "commit_type": "add"}
{"commit_tokens": ["Use", "double", "instead", "of", "mock"], "add_tokens": "described_class . prepare ( key , double , options ) described_class . prepare ( :a_constant_that_does_not_exist , double ) described_class . prepare ( :key , double , class : 'NotARealClass' )", "del_tokens": "described_class . prepare ( key , mock , options ) described_class . prepare ( :a_constant_that_does_not_exist , mock ) described_class . prepare ( :key , mock , class : 'NotARealClass' )", "commit_type": "use"}
{"commit_tokens": ["fixed", "the", "MIDI", "example", "which", "also", "made", "it", "more", "interesting"], "add_tokens": "note_on note , 100 note_off note spork { play ( rand ( 30 ) + 40 , rand * 1 . quarter_note + 1 . quarter_note ) } wait 0.5 . quarter_note", "del_tokens": "note_on 60 , 100 note_off 60 spork { play ( rand ( 30 ) + 40 ) } wait 1 . quarter_note", "commit_type": "fix"}
{"commit_tokens": ["added", "some", "callback", "types", "modified", "random_reply", "template"], "add_tokens": "when Twitter :: Streaming :: FriendList do_callbacks :friend_list , object is_mention = ( object . user . screen_name != $bot [ :config ] [ :screen_name ] and object . text . include? ( \"@\" + $bot [ :config ] [ :screen_name ] ) and not object . retweet? ) do_callbacks :retweet , object if object . retweet? do_callbacks :mention , object if is_mention do_callbacks :tweet , object , mention : is_mention , retweet : object . retweet? when Twitter :: Streaming :: Event case object . name when :favorite do_callbacks :favorite , object else puts \"no handler for #{object.class.to_s}/#{object.name}\\n -- object data:\" require 'pp' pp object end puts \"no handler for #{object.class.to_s}\\n -- object data:\" require 'pp' pp object def do_callbacks ( callback_type , object , options = { } ) $bot [ :callbacks ] [ callback_type ] [ :block ] . call object , options unless $bot [ :callbacks ] [ callback_type ] . nil?", "del_tokens": "do_callbacks :tweet , object puts \"no handler for #{object.class.to_s}\" def do_callbacks ( callback_type , object ) $bot [ :callbacks ] [ callback_type ] [ :block ] . call object", "commit_type": "add"}
{"commit_tokens": ["add", "encoding", "and", "frozen_string_literal", "comments"], "add_tokens": "# encoding: utf-8 # frozen_string_literal: false", "del_tokens": "# -*- encoding : utf-8 -*-", "commit_type": "add"}
{"commit_tokens": ["use", "boolean", "false", "insead", "of", "symbol", ":", "false"], "add_tokens": "config . scim_user_prevent_update_on_create = false", "del_tokens": "config . scim_user_prevent_update_on_create = :false", "commit_type": "use"}
{"commit_tokens": ["make", "use", "of", "mm", "query"], "add_tokens": "min_score = opts . delete ( :min_score ) || 0.0 select = opts . delete ( :select ) || self . keys . keys criteria , options = to_query ( opts ) results = self . database . eval ( \"function(collection, q, config) { return filter(collection, q, config); }\" , self . collection_name , criteria . merge ( { \"_keywords\" => { :$in => regex } } ) , { :words => original_words . to_a , :stemmed => stemmed . to_a , :limit => limit , :min_score => min_score , :select => select } )", "del_tokens": "min_score = opts . delete ( :min_score ) || 1.0 select = opts . delete ( :select ) results = self . database . eval ( \"function(collection, q, config) { return filter(collection, q, config); }\" , self . collection_name , opts . merge ( { \"_keywords\" => { :$in => regex } } ) , { :words => original_words . to_a , :stemmed => stemmed . to_a , :limit => limit , :min_score => min_score , :select => select } )", "commit_type": "make"}
{"commit_tokens": ["fixed", "reference", "to", "ec2", "credentials", "key"], "add_tokens": "@params [ :credentials_key ]", "del_tokens": "@params [ :credentials_keys ]", "commit_type": "fix"}
{"commit_tokens": ["use", "specific", "filepaths", "for", "spec", "loggers"], "add_tokens": "$logger = ZTK :: Logger . new ( File . join ( \"/tmp\" , \"test.log\" ) )", "del_tokens": "$logger = ZTK :: Logger . new ( Tempfile . new ( \"test\" ) . path )", "commit_type": "use"}
{"commit_tokens": ["fixing", "up", "the", "gem", "cutter", "api", "libs"], "add_tokens": "require 'stickler/middleware' module Stickler :: Middleware # A rack middleware for implementing the gemcutter api class Gemcutter < :: Stickler :: Middleware :: Index include Stickler :: Middleware :: Helpers :: Compression include Stickler :: Middleware :: Helpers :: Specs super ( app , options )", "del_tokens": "module Stickler # A piece of middle ware to implement a small section of the gem cutter api class GemCutterApiServer < :: Sinatra :: Base @app = app super ( app )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "after_create", "/", "update", "/", "destroy", "callbacks", "with", "plsql", "custom", "methods", "(", "they", "were", "not", "called", "at", "all", ")"], "add_tokens": "if private_instance_methods . include? ( 'create_without_callbacks' ) || private_instance_methods . include? ( :create_without_callbacks ) alias_method :create_without_custom_method , :create_without_callbacks alias_method :create_without_callbacks , :create_with_custom_method else alias_method_chain :create , :custom_method end elsif private_instance_methods . include? ( 'update_without_callbacks' ) || private_instance_methods . include? ( :update_without_callbacks ) alias_method :update_without_custom_method , :update_without_callbacks alias_method :update_without_callbacks , :update_with_custom_method if public_instance_methods . include? ( 'destroy_without_callbacks' ) || public_instance_methods . include? ( :destroy_without_callbacks ) alias_method :destroy_without_custom_method , :destroy_without_callbacks alias_method :destroy_without_callbacks , :destroy_with_custom_method else alias_method_chain :destroy , :custom_method end", "del_tokens": "alias_method_chain :create , :custom_method alias_method_chain :destroy , :custom_method", "commit_type": "fix"}
{"commit_tokens": ["fix", "provider", "order", "/", "priority", "bug", "with", "#add_scoped"], "add_tokens": "( data [ :provider_args ] || [ ] ) . reverse . each do | definition |", "del_tokens": "( data [ :provider_args ] || [ ] ) . each do | definition |", "commit_type": "fix"}
{"commit_tokens": ["Use", "Enumerable", "::", "Enumerator", "to", "create", "Arrays", "from", "enumerator", "methods", "."], "add_tokens": "# @yield [static_file] # If a block is given, it will be passed every found path. # # @yieldparam [String] static_file # The path of a file within a static directory. # def each_static_file ( path , & block ) block . call ( full_path ) if File . file? ( full_path ) # def all_static_files ( path ) Enumerable :: Enumerator . new ( self , :each_static_file ) . to_a # @yield [static_dir] # If a block is given, it will be passed every found path. # # @yieldparam [String] static_dir # The path of a directory within a static directory. # def each_static_dir ( path , & block ) block . call ( full_path ) if File . directory? ( full_path ) def all_static_dirs ( path ) Enumerable :: Enumerator . new ( self , :each_static_dir ) . to_a", "del_tokens": "# def all_static_files ( path ) paths = [ ] paths << full_path if File . file? ( full_path ) return paths # @yield [static_file] # If a block is given, it will be passed every found path. # # @yieldparam [String] static_file # The path of a file within a static directory. # def each_static_file ( path , & block ) all_static_files ( path ) . each ( & block ) def all_static_dirs ( path ) paths = [ ] paths << full_path if File . directory? ( full_path ) return paths # @yield [static_dir] # If a block is given, it will be passed every found path. # # @yieldparam [String] static_dir # The path of a directory within a static directory. # def each_static_dir ( path , & block ) all_static_dirs ( path ) . each ( & block )", "commit_type": "use"}
{"commit_tokens": ["Add", "bytes", "written", "to", "benchmark", "log"], "add_tokens": "stats = { } logger . benchmark_debug ( \"#write ==> complete\" , stats ) do stats [ :bytes_sent ] = @socket . write ( data )", "del_tokens": "logger . benchmark_debug ( \"#write ==> sent #{data.length} bytes\" ) do @socket . write ( data )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Gravity", "compile", "error", "."], "add_tokens": "def initialize ; super ( Vector . new ( 9.8 , 270 ) ) ; end", "del_tokens": "def initialize ; super ( Vector ( 9.8 , 270 ) ) ; end", "commit_type": "fix"}
{"commit_tokens": ["fix", "ssh", "rspec", "for", "travis", "-", "ci"], "add_tokens": "# this stuff doesn't work as is under travis-ci if ! ENV [ 'CI' ] && ! ENV [ 'TRAVIS' ] it \"should be able to connect to 127.0.0.1 as the current user\" do subject . config do | config | config . ssh . user = ENV [ \"USER\" ] config . ssh . host = \"127.0.0.1\" end hostname = %x( hostname -f ) . chomp subject . exec ( \"hostname -f\" ) . chomp . should == hostname", "del_tokens": "it \"should be able to connect to 127.0.0.1 as the current user\" do subject . config do | config | config . ssh . user = ENV [ \"USER\" ] config . ssh . host = \"127.0.0.1\" hostname = %x( hostname -f ) . chomp subject . exec ( \"hostname -f\" ) . chomp . should == hostname", "commit_type": "fix"}
{"commit_tokens": ["changed", "default", "port", "to", "3001", "removed", "hint", "for", "using", "port", "80", "I", "should", "(", "not", ")", "see", "works", "with", "pages", "manipulated", "via", "JavaScript", "I", "wait", "for", "the", "AJAX", "call", "to", "finish", "is", "working", "now"], "add_tokens": "@host = 'http://localhost:3001' When / I select \"(.*)\" from \"(.*)\" / do | value , field | $browser . select_list ( :id , find_label ( field ) . for ) . select value end assert_successful_response When / I wait for the AJAX call to finish / do $browser . wait # if we simply check for the browser.html content we don't find content that has been added dynamically, e.g. after an ajax call div = $browser . div ( :text , / #{ text } / ) begin div . html rescue #puts $browser.html raise ( \"div with '#{text}' not found\" ) end div = $browser . div ( :text , / #{ text } / ) . html rescue nil div . should be_nil assert_successful_response tmp = Tempfile . new 'culerity_results' tmp << $browser . html tmp . close ` open -a /Applications/Safari.app #{ tmp . path } `", "del_tokens": "$browser . close @host = 'http://localhost' When \"I wait for the AJAX call to finish\" do $browser . page . getEnclosingWindow ( ) . getThreadManager ( ) . joinAll ( 10000 ) $browser . html . should =~ / #{ text } /m $browser . html . should_not =~ / #{ text } /m", "commit_type": "change"}
{"commit_tokens": ["changing", "rich", "text", "editor", "to", "tinymce"], "add_tokens": "'comfortable_mexican_sofa/tiny_mce/tiny_mce' , 'comfortable_mexican_sofa/tiny_mce/jquery.tinymce' , 'comfortable_mexican_sofa/cms'", "del_tokens": "'comfortable_mexican_sofa/cms' , 'comfortable_mexican_sofa/plupload/plupload.full.min' , 'comfortable_mexican_sofa/uploader'", "commit_type": "change"}
{"commit_tokens": ["make", "hash", "accessible", "with", "indifferent", "access"], "add_tokens": "opts [ :as_hash ] ? retval . map ( & :to_hash ) . map ( & :with_indifferent_access ) : retval", "del_tokens": "opts [ :as_hash ] ? retval . map ( & :to_hash ) : retval", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "generic", "interface", "for", "email", "messages"], "add_tokens": "register_message_type :email , Outbox :: Messages :: Email audience = Outbox :: Accessor . new ( audience ) recipient = audience [ message_type ]", "del_tokens": "recipient = get_recipient_for_message_type ( audience , message_type ) protected def get_recipient_for_message_type ( audience , message_type ) if audience . respond_to? ( message_type ) audience . public_send ( message_type ) elsif audience . respond_to? ( :[] ) audience [ message_type ] end end", "commit_type": "add"}
{"commit_tokens": ["change", "MessagingClient#sync_request", "()", "to", "wait", "until", "it", "gets", "response", "and", "return", "its", "result", "."], "add_tokens": "rpc . sync_request ( endpoint , key , args ) . wait", "del_tokens": "rpc . sync_request ( endpoint , key , args )", "commit_type": "change"}
{"commit_tokens": ["add", "untranslated?", "method", "to", "entry"], "add_tokens": "def untranslated? @msgstr . nil? || @msgstr == '' end alias_method :incomplete? , :untranslated? not untranslated?", "del_tokens": "@msgstr != nil", "commit_type": "add"}
{"commit_tokens": ["Implement", "basic", "scoped_attr_accessible", "model", "and", "spec", "."], "add_tokens": "require 'spec_helper' require 'active_model' describe ScopedAttrAccessible do it 'should automatically mix it in when hijacked' do ScopedAttrAccessible . mixin! klass = Class . new { include ActiveModel :: MassAssignmentSecurity } klass . ancestors . include? ( ActiveModel :: MassAssignmentSecurity ) . should be_true klass . ancestors . include? ( ScopedAttrAccessible :: ActiveModelMixin ) . should be_true klass . should respond_to ( :with_sanitizer_scope ) klass . new . should respond_to ( :current_sanitizer_scope ) end", "del_tokens": "require File . expand_path ( File . dirname ( __FILE__ ) + '/spec_helper' ) describe \"ScopedAttrAccessible\" do it \"fails\" do fail \"hey buddy, you should probably rename this file and start specing for real\" end", "commit_type": "implement"}
{"commit_tokens": ["add", "travis", "badge", "and", "bump", "version"], "add_tokens": "VERSION = \"0.1.0\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["make", "a", "note", "of", "a", "bug"], "add_tokens": "data . delete ( key ) if ! is_required && data . has_key? ( key ) && filterer . discard_empty? && data_element == \"\" # BUG: this doesn't account for data_elem being \" \"", "del_tokens": "data . delete ( key ) if ! is_required && data . has_key? ( key ) && filterer . discard_empty? && data_element == \"\"", "commit_type": "make"}
{"commit_tokens": ["Fixed", "documentation", "for", "search", "and", "filter"], "add_tokens": "# Event.filter(public: true) do |filter_results| # @events = filter_results.all # end # # # You can also combine search and filter # search_results.filter(public: true) do |filter_results| # @events = filter_results.all # end # events = search_results.all", "del_tokens": "# events = search_results.all # search_results.filter(public: true) do |filter_results| # events = filter_results.all # end", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "up", "gem", "for", "test", "-", "only", "install"], "add_tokens": "end ActiveRecord :: Base . class_eval do include ActiveRecordExtensions :: ValidationReflection ActiveRecordExtensions :: ValidationReflection . load_config ActiveRecordExtensions :: ValidationReflection . install ( self ) end", "del_tokens": "end", "commit_type": "fix"}
{"commit_tokens": ["Add", "another", "failing", "test", "."], "add_tokens": "trunk_prefix = \"(#{trunk_prefix}) \" if intl_prefix", "del_tokens": "trunk_prefix = \"(#{trunk_prefix})\" if intl_prefix", "commit_type": "add"}
{"commit_tokens": ["Add", "with_tags", "method", "and", "delegate", "more", "array", "methods", "to", "lights"], "add_tokens": "self def with_tags ( * tag_labels ) self . class . new ( scope : scope , tags : tag_labels ) alias_method :with_tag , :with_tags alias_method :inspect , :to_s def_delegators :lights , :length , :count , :to_a , :[] , :find , :each , :first , :last , :map", "del_tokens": "def with_tag ( tag_label ) self . class . new ( scope : scope , tags : [ tag_label ] ) def_delegators :lights , :to_a , :[] , :find , :each , :first , :last , :map", "commit_type": "add"}
{"commit_tokens": ["added", "as", "to", "prep", "list"], "add_tokens": "PREPOSITION_REGEX = / ^(the|to|and|a|in|that|it|if|is|was|for|on|as)$ / while words . length < max_words && words [ - 1 ] && words [ - 1 ] [ PREPOSITION_REGEX ]", "del_tokens": "while words . length < max_words && words [ - 1 ] && words [ - 1 ] [ / ^(the|to|and|a|in|that|it|if|is|was|for|on)$ / ]", "commit_type": "add"}
{"commit_tokens": ["Updated", "app", "version", "and", "history"], "add_tokens": "BUGFIX = 5", "del_tokens": "BUGFIX = 4", "commit_type": "update"}
{"commit_tokens": ["Changing", "the", "way", "that", "conf", "parameters", "are", "defined", "to", "spec", "files", "."], "add_tokens": ":username => ENV [ 'username_value' ] , :password => ENV [ 'password_value' ] , :host => ENV [ 'host_value' ] , :auth_type => ENV [ 'auth_type_value' ]", "del_tokens": ":username => '' , :password => '' , :host => '' , :auth_type => ''", "commit_type": "change"}
{"commit_tokens": ["Change", "referer_params", "to", "text", "as", "it", "could", "be", "longer", "than", "256", "chars"], "add_tokens": "t . text :referer_params", "del_tokens": "t . string :referer_params", "commit_type": "change"}
{"commit_tokens": ["Move", "require", "statements", "around", "and", "prepare", "for", "new", "rewindable", "test", "."], "add_tokens": "require 'mizuno/server'", "del_tokens": "require 'mizuno'", "commit_type": "move"}
{"commit_tokens": ["Allow", "tenant", "to", "be", "set", "if", "it", "is", "presently", "nil", "."], "add_tokens": "raise ActsAsTenant :: Errors :: TenantIsImmutable unless new_record? || send ( ActsAsTenant . fkey ) . nil? write_attribute ( \"#{ActsAsTenant.fkey}\" , integer ) define_method \"#{ActsAsTenant.tenant_klass.to_s}=\" do | model | raise ActsAsTenant :: Errors :: TenantIsImmutable unless new_record? || send ( ActsAsTenant . fkey ) . nil? super ( model )", "del_tokens": "raise ActsAsTenant :: Errors :: TenantIsImmutable unless new_record? write_attribute ( \"#{ActsAsTenant.fkey}\" , integer ) define_method \"#{ActsAsTenant.tenant_klass.to_s}=\" do | model | raise ActsAsTenant :: Errors :: TenantIsImmutable unless new_record? super ( model )", "commit_type": "allow"}
{"commit_tokens": ["Add", "Object", "::", "Commit", "and", "spec", "for", "it"], "add_tokens": "require 'vcs_toolkit/objects/tree' require 'vcs_toolkit/objects/commit'", "del_tokens": "require 'vcs_toolkit/objects/tree'", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "typo", "in", "description", "of", "pry", "-", "theme", "command"], "add_tokens": "e . g . : pry - theme - - all - colors 8", "del_tokens": "e . g . : pry - theme - - all - colors", "commit_type": "fix"}
{"commit_tokens": ["Use", "Travis", "rubygems", "deployment", "pushing", "git", "tag", "after", "gem", "pushed", "."], "add_tokens": "VERSION = '0.4.0.pre' . freeze", "del_tokens": "VERSION = '0.4.0.edge3' . freeze", "commit_type": "use"}
{"commit_tokens": ["updated", "oj", "themes", "braintree", "and", "byebugs", "deps", "."], "add_tokens": "VERSION = \"16.1.0\"", "del_tokens": "VERSION = \"16.0.0\"", "commit_type": "update"}
{"commit_tokens": ["Updated", "test", "harness", "for", "fdb"], "add_tokens": "# Sleep until some 'str' String is sent to the output,", "del_tokens": "# Sleep until some 'str' String is sent to the output", "commit_type": "update"}
{"commit_tokens": ["updated", "get", "specs", "and", "implementation", "with", "new", "api"], "add_tokens": "def get ( url , options = { } ) Typhoeus :: RemoteProxyObject . new ( base_easy_object ( url , :get , options ) , :on_success => options [ :on_success ] , :on_failure => options [ :on_failure ] ) def base_easy_object ( url , method , options )", "del_tokens": "def get ( url , options = { } , & block ) if Typhoeus . multi_running? Typhoeus . add_easy_request ( base_easy_object ( url , :get , options , filter_wrapper_block ( :get , block ) ) ) else Typhoeus . service_access do get ( url , options , & block ) end end def base_easy_object ( url , method , options , block ) easy . on_success = block easy . on_failure = block", "commit_type": "update"}
{"commit_tokens": ["Add", "purchased_download_url", "functionality", "and", "use", "in", "order", "receipt"], "add_tokens": "if ( user = Effective :: Customer . find ( seller_id ) . try ( :user ) ) [ link_to ( user , admin_user_path ( user ) ) , order . payment [ seller_id ] ] else [ seller_id , order . payment [ seller_id ] ] end", "del_tokens": "user = Effective :: Customer . for_user ( seller_id ) . user [ link_to ( user , admin_user_path ( user ) ) , order . payment [ seller_id ] ]", "commit_type": "add"}
{"commit_tokens": ["Add", "stop!", ".", "Set", "videoOrientation", ".", "Use", "localizedDescription", "for", "error", "."], "add_tokens": "def stop! session . stopRunning remove_outputs remove_inputs @_still_image_output = nil @_session = nil @_capture_preview_view = nil end still_image_connection = still_image_output . connectionWithMediaType ( AVMediaTypeVideo ) if still_image_connection . isVideoOrientationSupported still_image_connection . setVideoOrientation ( UIDevice . currentDevice . orientation ) end p \"Error capturing image: #{error.localizedDescription}\"", "del_tokens": "still_image_connection = still_image_output . connections . first p \"Error capturing image: #{error[0].description}\"", "commit_type": "add"}
{"commit_tokens": ["Change", "Rakefile", "to", "run", "all", "specs", "and", "features", "as", "well", "as", "prepare", "the", "db"], "add_tokens": "t . string \"email\" t . string \"name\"", "del_tokens": "t . string \"email\" t . string \"name\" t . string \"confirm_code\" t . datetime \"confirmed_at\"", "commit_type": "change"}
{"commit_tokens": ["added", "code", "to", "remove", "duplicates"], "add_tokens": "puts \"crawling finished\" puts \"remove duplicates...\" DB . run \"update points_of_interest set flag = 1 where id in (select min(id) FROM points_of_interest group by lat, lng)\" DB . run \"delete from points_of_interest where flag is null\" puts \"removed duplicates\"", "del_tokens": "puts \"crawling finished\"", "commit_type": "add"}
{"commit_tokens": ["Use", "Array#sample", "for", "better", "Ruby", "compatibility", "."], "add_tokens": "experiment . alternatives . sample", "del_tokens": "experiment . alternatives . choice", "commit_type": "use"}
{"commit_tokens": ["add", "network", "to", "estimate", "fee"], "add_tokens": "@fee_override || self . estimate_fee ( network : @network )", "del_tokens": "@fee_override || self . estimate_fee", "commit_type": "add"}
{"commit_tokens": ["update", "required", "ruby", "and", "activerecord", "versions"], "add_tokens": "if ActiveRecord :: VERSION :: MAJOR < 4 || ( ActiveRecord :: VERSION :: MAJOR == 4 && ActiveRecord :: VERSION :: MINOR == 0 )", "del_tokens": "if ActiveRecord :: VERSION :: MAJOR < 3 || ( ActiveRecord :: VERSION :: MAJOR == 4 && ActiveRecord :: VERSION :: MINOR == 0 )", "commit_type": "update"}
{"commit_tokens": ["Remove", "usage", "of", "method_missing", "which", "does", "not", "work", "with", "multiple", "superclasses"], "add_tokens": "class TwoSuperClasses include Comparable include Logue :: Loggable attr_reader :name def initialize name @name = name end def <=> other @name <=> other . name end end end def test_dual x = TwoSuperClasses . new \"abc\" y = TwoSuperClasses . new \"def\" begin assert_equal x , y rescue Test :: Unit :: AssertionFailedError => e # this is okay ... we are testing for a method missing, from :encoding invoked in assert_equal end end", "del_tokens": "end", "commit_type": "remove"}
{"commit_tokens": ["fix", "retry", "/", "raise", "arrangment", "&", "report", "error", "message", "only"], "add_tokens": "@logger . warn ( error . message ) ( tries_count -= 1 ) . zero? ? raise : retry", "del_tokens": "@logger . warn ( error ) retry unless ( tries_count -= 1 ) . zero?", "commit_type": "fix"}
{"commit_tokens": ["Adding", "support", "for", "start", "and", "end", "keys", "on", "queries"], "add_tokens": "def create_scanner_with_filter ( start_row = nil , end_row = nil , filter = nil , * columns , & block ) :startRow => start_row . to_s , :stopRow => end_row . to_s , :columns => columns )", "del_tokens": "def create_scanner_with_filter ( row = nil , filter = nil , * columns , & block ) :startRow => row . to_s , :stopRow => row . to_s , :columns => columns )", "commit_type": "add"}
{"commit_tokens": ["Added", "without_permission", "(", "user", "permission", ")", "method", ".", "Modified", "with_permission_sql", "so", "it", "can", "also", "accept", "a", "user_id", "as", "a", "first", "argument"], "add_tokens": "user_id = user . is_a? ( ActiveRecord :: Base ) ? user . id : user", "del_tokens": "case user when String user_id = user when user_id = user . id end", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "JSON", "#list_of", "."], "add_tokens": "if block_given? && ! current_subject . nil?", "del_tokens": "if block_given?", "commit_type": "fix"}
{"commit_tokens": ["Added", "class", "macro", "to", "create", "handlers", "for", "all", "HTTP", "verbs", ".", "Metaprogramming", "FTW"], "add_tokens": "def self . define_http_verb ( http_verb ) define_method http_verb do | * args | request = args [ 0 ] || \"/\" params = args [ 1 ] || { } @request = request sanitize_request method = @conn . method ( http_verb ) @response = method . call ( Instamojo :: PREFIX + @request , params ) return sanitize_response end define_http_verb :get define_http_verb :post define_http_verb :patch define_http_verb :delete def upload_file end", "del_tokens": "def get ( request = \"/\" , params = { } ) @request = request sanitize_request @response = @conn . get ( Instamojo :: PREFIX + @request , params ) return sanitize_response end def post ( request , params = { } ) @request = request sanitize_request @response = @conn . post ( Instamojo :: PREFIX + @request , params ) sanitize_response", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "Matcher", "docs"], "add_tokens": "# and {Matcher.valid_pattern?}. Override {#compile!} if a pattern compiler is", "del_tokens": "# and {Matcher.valid_pattern?}Override {#compile!} if a pattern compiler is", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "csrf_token_field", "which", "were", "using", "helper", "from", "a", "different", "module"], "add_tokens": "tag :input , type : 'hidden' , name : csrf_field_name , value : csrf_token", "del_tokens": "input_hidden_tag csrf_field_name , csrf_token", "commit_type": "fix"}
{"commit_tokens": ["add", "the", "marked_for_destruction", "class", "on", "the", "div", "if", "the", "object", "is", "marked", "for", "destruction"], "add_tokens": "classes = 'fields' classes << ' marked_for_destruction' if object . marked_for_destruction? @template . content_tag ( :div , super , :class => classes )", "del_tokens": "@template . content_tag ( :div , super , :class => 'fields' )", "commit_type": "add"}
{"commit_tokens": ["Move", "client", "side", "validations", "initializer", "code", "from", "initializers", ".", "rb", "to", "gem"], "add_tokens": "initializer 'require \"tiny-rails/app/initializers/client_side_validations\"'", "del_tokens": "initializer_code = <<-CODE ActionView :: Base . field_error_proc = Proc . new do | html_tag , instance | unless html_tag =~ / ^<label / %{<div class=\"field_with_errors\">\\#{html_tag}<label for=\"\\#{instance.send(:tag_id)}\" class=\"message\">\\#{instance.error_message.first}</label></div>} . html_safe else %{<div class=\"field_with_errors\">\\#{html_tag}</div>} . html_safe end end CODE initializer initializer_code", "commit_type": "move"}
{"commit_tokens": ["Allow", "loading", "multiple", "files", "at", "once"], "add_tokens": "# Load one or more javascript files in page's context # @param [#to_s, #to_s, ...] paths # paths to js file def load ( * paths ) paths . flatten . each do | path | window . load ( path . to_s ) end", "del_tokens": "# Load a javascript file in page's context # # @param [String] path # path to js file def load ( path ) window . load ( path . to_s )", "commit_type": "allow"}
{"commit_tokens": ["allow", "passing", "of", "GET", "options", "to", ".", "all", "in", "collections"], "add_tokens": "def all ( get_options = nil ) find_all_by_url ( klass . endpoint , get_options ) def find_all_by_url ( url , get_options = nil ) next_page = fetch_more_results ( next_page , get_options ) if @collection . empty? get_options = nil def fetch_more_results ( next_page , get_options ) body = parse_response ( api . get ( next_page , get_options ) )", "del_tokens": "def all find_all_by_url ( klass . endpoint ) def find_all_by_url ( url ) next_page = fetch_more_results ( next_page ) if @collection . empty? def fetch_more_results ( next_page ) body = parse_response ( api . get ( next_page ) )", "commit_type": "allow"}
{"commit_tokens": ["Add", "error", "handling", "to#", "[]"], "add_tokens": "when :name , :rgb , :hsb , :hsv else raise ArgumentError , \"First argument '#{order}' is inappropriate.\" raise ArgumentError , \"Second argument must ':+' or ':-'.\"", "del_tokens": "else raise ArgumentError , \"it must ':+' or ':-'\"", "commit_type": "add"}
{"commit_tokens": ["Added", "options", "support", "to", "Quickl#help"], "add_tokens": "def self . documentation ( cmd , opts = { } ) command_class ( cmd ) . documentation ( opts ) def self . help ( cmd , opts = { } ) command_class ( cmd ) . help ( opts )", "del_tokens": "def self . documentation ( cmd ) command_class ( cmd ) . documentation def self . help ( cmd ) command_class ( cmd ) . help", "commit_type": "add"}
{"commit_tokens": ["Added", "--", "http", "-", "proxy", "switch", "to", "command"], "add_tokens": "if @options [ :http_proxy ] conn_hash [ :connection_options ] ||= { } conn_hash [ :connection_options ] [ :proxy ] = { :uri => @options [ :http_proxy ] } end conn_hash [ :connection_options ] ||= { } conn_hash [ :connection_options ] [ :ssl ] = { :verify => true , :verify_mode => ( OpenSSL :: SSL :: VERIFY_PEER | OpenSSL :: SSL :: VERIFY_FAIL_IF_NO_PEER_CERT ) conn_hash [ :connection_options ] [ :ssl ] = { :verify => false", "del_tokens": "conn_hash [ :connection_options ] = { :ssl => { :verify => true , :verify_mode => ( OpenSSL :: SSL :: VERIFY_PEER | OpenSSL :: SSL :: VERIFY_FAIL_IF_NO_PEER_CERT ) } conn_hash [ :connection_options ] = { :ssl => { :verify => false }", "commit_type": "add"}
{"commit_tokens": ["added", "roodi", "config", "file", "corrected", "some", "roodi", "warnings"], "add_tokens": "warn \"roodi not installed...will not be checked!\" RoodiTask . new 'roodi' , PKG_FILES , 'roodi.yml'", "del_tokens": "RoodiTask . new", "commit_type": "add"}
{"commit_tokens": ["Add", "Header", "::", "UDP", "and", "its", "specs"], "add_tokens": "# Setter for source port def sport = ( port ) self [ :sport ] . read port alias :source_port= :sport=", "del_tokens": "# Setter for destination port def dport = ( port ) self [ :dport ] . read port alias :destination_port= :dport=", "commit_type": "add"}
{"commit_tokens": ["fixing", "some", "bugs", "...", ":", ")"], "add_tokens": "libver = '1.1' puts \"load_auto_conf('#{confname}') v#{libver} start..\" if verbose puts \"load_auto_conf('#{confname}', v#{libver}) found: #{green yaml}\" if verbose return yaml # in the future u can have a host based autoconf! Yay!", "del_tokens": "puts \"load_auto_conf('#{confname}') start..\" if verbose deb \"load_auto_conf('#{confname}') found: #{green yaml}\" return yaml", "commit_type": "fix"}
{"commit_tokens": ["fix", "param", "generation", "with", "cfn", "preview", "when", "stack", "name", "is", "different", "from", "param", "name"], "add_tokens": "@template_name = options [ :template ] || @stack_name @param_name = options [ :param ] || @template_name @template_path = get_source_path ( @template_name , :template ) @param_path = get_source_path ( @param_name , :param ) generator = Lono :: Param :: Generator . new ( @param_name , generator_options )", "del_tokens": "template_name = options [ :template ] || @stack_name param_name = options [ :param ] || template_name @template_path = get_source_path ( template_name , :template ) @param_path = get_source_path ( param_name , :param ) generator = Lono :: Param :: Generator . new ( @stack_name , generator_options )", "commit_type": "fix"}
{"commit_tokens": ["Add", "link", "check", "for", "invalid", "hyperlinks"], "add_tokens": "require_relative 'lint/ext_missing' @rules = [ ExtMissing , H1Missing , H1Multiple , H1Invalid , H2Invalid , H456Invalid , LineBreakInvalid ]", "del_tokens": "@rules = [ H1Missing , H1Multiple , H1Invalid , H2Invalid , H456Invalid , LineBreakInvalid ]", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "broadcasting", "events", "from", "operations"], "add_tokens": "require 'wisper' def method_missing ( name , * args , & block ) if steps . include? ( name ) steps [ name ] else super end end end class Publisher include Wisper :: Publisher attr_reader :name attr_reader :op def initialize ( name , op ) @name = name @op = op end def call ( * args ) result = op . call ( * args ) broadcast ( :\" #{ name } _success \" , result ) result end alias_method :[] , :call attr_reader :publish @publish = options . fetch ( :publish , false ) operation = container [ handler ] step = if publish Publisher . new ( name , operation ) else operation end steps [ name ] = step", "del_tokens": "steps [ name ] = container [ handler ]", "commit_type": "add"}
{"commit_tokens": ["Improve", "error", "messages", "when", "generating", "content"], "add_tokens": "raise InvalidContentGenerated , error_message_custom ( item , hash , errors ) An invalid content item was generated . This probably means there ' s a bug in the generator that causes it to output invalid values . Below you ' ll find the generated payload , the validation errors and the schema that was used . Validation errors : def error_message_custom ( item , custom_values , errors ) error_messages = errors . map { | e | \"- #{e[:message]}\\n\" } . join The content item you are trying to generate is invalid against the schema . Validation errors : #{error_messages} Custom values provided : #{JSON.pretty_generate(custom_values)} Generated payload : #{JSON.pretty_generate([item])}", "del_tokens": "raise InvalidContentGenerated , error_message_custom ( item , errors ) An invalid content item was generated by ` RandomExample ` . This probably means that either you 've merged the content item with invalid values, or there' s a bug in the generator that causes it to output invalid values . Below you ' ll find the generated payload , the validation errors and the schema that was used . Together these should be sufficient to debug the issue . Errors : def error_message_custom ( item , errors ) An invalid content item was generated by ` RandomExample ` . This probably means you ' ve merged the content item with invalid values . Errors : #{JSON.pretty_generate(errors)} Generated payload : #{JSON.pretty_generate([item])} Schema : #{JSON.pretty_generate(@schema)}", "commit_type": "improve"}
{"commit_tokens": ["Making", "max", "subscription", "priority", "configurable", "."], "add_tokens": "def _symbol_to_priority ( sym ) ( @__symbol_to_priority_map ||= _generate_priority_shortcut_map ) [ sym ] end def _generate_priority_shortcut_map ( max_priority = config . max_priority ) { } . tap { | map | map . merge! ( highest : 1 , lowest : max_priority ) map [ :medium ] = ( map [ :lowest ] / 2.0 ) . ceil map [ :high ] = ( map [ :medium ] / 2.0 ) . ceil map [ :low ] = ( ( map [ :lowest ] + map [ :medium ] ) / 2.0 ) . ceil } . freeze end raise Errors :: InvalidPriorityError , int unless int > 0 && int <= config . max_priority if ( priority = _symbol_to_priority ( sym ) )", "del_tokens": "PRIORITY_SYMBOL_TO_INTEGER_MAP = { highest : 1 , high : 3 , medium : 5 , low : 7 , lowest : 10 } . freeze raise Errors :: InvalidPriorityError , int unless int > 0 && int <= 10 if ( priority = PRIORITY_SYMBOL_TO_INTEGER_MAP [ sym ] )", "commit_type": "make"}
{"commit_tokens": ["Fix", "the", "default", "caching", "enabled", "setting"], "add_tokens": "self . caching_enabled = false", "del_tokens": "self . caching_enabled = true", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "JSON", "manifests", "(", "Rails", "4", ")"], "add_tokens": "manifest . append ( logical_path ( file ) , file ) def logical_path ( file ) file . relative_path_from ( ASSETS . parent ) . to_s end FileUtils . mv ( src , dest , :force => true ) if src != dest && File . exists? ( src )", "del_tokens": "relative_path = file . relative_path_from ( ASSETS . parent ) . to_s manifest . append ( relative_path ) FileUtils . mv ( src , dest ) if File . exists? ( src )", "commit_type": "add"}
{"commit_tokens": ["Use", "VCR", "to", "test", "requests"], "add_tokens": "let ( :hook ) { 'https://hooks.slack.com/services/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' } let ( :poster ) { described_class . new ( hook ) } let ( :with_options ) { described_class . new ( hook , options ) } VCR . use_cassette ( 'default_post' ) do message = Slack :: Message . new ( 'Hello world' ) response = poster . send_message ( message ) expect ( response ) . to_not be_nil expect ( response . code ) . to eq ( 200 ) end VCR . use_cassette ( 'default_post' ) do response = poster . send_message ( 'Hello world' ) expect ( response ) . to_not be_nil expect ( response . code ) . to eq ( 200 ) end", "del_tokens": "let ( :poster ) { described_class . new ( SecureRandom . base64 ) } let ( :with_options ) { described_class . new ( SecureRandom . base64 , options ) }", "commit_type": "use"}
{"commit_tokens": ["added", "Proxy", ".", "get_model", "."], "add_tokens": "# DISCUSS: ove .get to ActiveResourceLikeModelMethods ? it \"responds to .get_model\" do @o = @klass . get_model ( \"http://localhost:9999/test/1\" , TestModel ) assert_kind_of TestModel , @o assert_equal ( { \"id\" => \"1\" } , @o . attributes ) end it \"responds to .from_attributes and responds to #original_attributes\" do assert_equal ( { :urn => \"urn:item\" } , @proxy_class . from_attributes ( :urn => \"urn:item\" ) . send ( :original_attributes ) ) describe \"#finalize!\" do before do @o = @proxy_class . from_attributes ( \"uri\" => \"http://localhost:9999/test/1\" ) end it \"responds to #proxied_resource\" do assert_nil @o . send ( :proxied_resource ) end it \"#finalize! retrieves proxied resource\" do @o . finalize! assert_kind_of TestModel , @o . send ( :proxied_resource ) end # delegation: it \"#attributes are delegated\" do @o . finalize! assert_equal ( { \"id\" => \"1\" } , @o . attributes ) end it \"#to_xml renders the unproxied entity\" do assert_equal \"<test>\\n <uri>http://localhost:9999/test/1</uri>\\n</test>\\n\" , @o . to_xml end it \"#attributes_for_xml returns the unfinalized EntityProxy#attributes hash\" do assert_equal ( { \"uri\" => \"http://localhost:9999/test/1\" } , @o . attributes_for_xml ) end", "del_tokens": "it \"responds to .from_attributes and responds to #attributes\" do assert_equal ( { :urn => \"urn:item\" } , @proxy_class . from_attributes ( :urn => \"urn:item\" ) . attributes ) it \"responds to #finalize! and enriches its attributes from the proxied response\" do assert_equal ( { :uri => \"http://localhost:9999/test/1\" , \"id\" => \"1\" } , @proxy_class . from_attributes ( :uri => \"http://localhost:9999/test/1\" ) . finalize! . attributes )", "commit_type": "add"}
{"commit_tokens": ["add", "external", "service", "supporting", "hooks", "and", "pre", "/", "post", "hooks"], "add_tokens": "VERSION = \"0.4.0\"", "del_tokens": "VERSION = \"0.3.6\"", "commit_type": "add"}
{"commit_tokens": ["Move", "button_to", "helper", "into", "core_ext", "/", "rails"], "add_tokens": "require 'bh/core_ext/rails/button_to_helper'", "del_tokens": "require 'bh/helpers/button_to_helper'", "commit_type": "move"}
{"commit_tokens": ["remove", "unnecessary", "absolute", "path", "requires"], "add_tokens": "require 'daybreak/version' require 'daybreak/locking' require 'daybreak/record' require 'daybreak/writer' require 'daybreak/reader' require 'daybreak/db'", "del_tokens": "# Daybreak, a simple dimple key value store for ruby. module Daybreak # The root path for Daybreak ROOT = File . expand_path ( File . dirname ( __FILE__ ) ) end require 'zlib' require \"#{Daybreak::ROOT}/daybreak/version\" require \"#{Daybreak::ROOT}/daybreak/locking\" require \"#{Daybreak::ROOT}/daybreak/record\" require \"#{Daybreak::ROOT}/daybreak/writer\" require \"#{Daybreak::ROOT}/daybreak/reader\" require \"#{Daybreak::ROOT}/daybreak/db\"", "commit_type": "remove"}
{"commit_tokens": ["Moving", "temp", "file", "assignment", "out", "of", "begin", "...", "end"], "add_tokens": "tmp_file = Tempfile . new ( 'pandoc-conversion' )", "del_tokens": "tmp_file = Tempfile . new ( 'pandoc-conversion' )", "commit_type": "move"}
{"commit_tokens": ["Fix", "the", "circular", "dependency", "between", "equivalent", "-", "xml", "and", "matchers", "."], "add_tokens": "require 'equivalent-xml' unless defined? ( :: EquivalentXml )", "del_tokens": "require 'equivalent-xml'", "commit_type": "fix"}
{"commit_tokens": ["Improve", "activity", "message", "in", "Connection#open_channel", "."], "add_tokens": "Util . error_check :\" opening a new channel \" ,", "del_tokens": "Util . error_check :\" reopening channel after server-initated closure \" ,", "commit_type": "improve"}
{"commit_tokens": ["fixed", "catching", "cut", "in", "queries"], "add_tokens": "catch :cut do goal . prove { block . call_with_rubylog_variables ( goal . rubylog_variables ) } end catch :cut do goal . prove { return true } end", "del_tokens": "goal . prove { block . call_with_rubylog_variables ( goal . rubylog_variables ) } goal . prove { return true }", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "bug", "caused", "when", "assign", "a", "time", "object", "to", "an", "event"], "add_tokens": "@start_time = ( time . is_a? String ) ? Time . parse ( time ) : time . dup @end_time = ( ( time . is_a? String ) ? Time . parse ( time ) : time . dup )", "del_tokens": "@start_time = ( time . is_a? String ) ? Time . parse ( time ) : time @end_time = ( ( time . is_a? String ) ? Time . parse ( time ) : time )", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "new", "preview_link", "endpoint"], "add_tokens": ":sha1 , :shared_link , :version_number , :comment_count , :lock , :extension , :is_package , :expiring_embed_link , :can_non_owners_invite ]", "del_tokens": ":sha1 , :shared_link , :version_number , :comment_count , :lock , :extension , :is_package , :can_non_owners_invite ]", "commit_type": "add"}
{"commit_tokens": ["updated", "evercookie", ".", "js", "file", "and", "gem", "code", "according", "to", "changes", "added", "basic", "auth", "request", "for", "ec"], "add_tokens": "before_filter :basic_auth , only : [ :ec_auth ] puts \"cache value (#{Evercookie.cookie_etag}): #{cookies[Evercookie.cookie_etag]}\" puts \"cache value (#{Evercookie.cookie_cache}): #{cookies[Evercookie.cookie_cache]}\" # Renders evercookie value for basic authentication if it was set def ec_auth render text : @username end def basic_auth authenticate_with_http_basic do | username , password | @username = username true end end puts \"png value (#{Evercookie.cookie_png}): #{value}\"", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Adds", "support", "for", "not", "specifying", "any", "source", "files", "."], "add_tokens": "it 'handles no files' do allow ( @swiftlint ) . to receive ( :modified_files ) . and_return ( 'spec/fixtures/SwiftFile.swift' ) allow ( @swiftlint ) . to receive ( :` ) . with ( 'swiftlint lint --quiet --reporter json --path spec/fixtures/SwiftFile.swift' ) . and_return ( @swiftlint_response ) @swiftlint . lint_files ( \"spec/fixtures/*.swift\" ) expect ( @swiftlint . status_report [ :markdowns ] . first ) . to_not be_empty end expect ( @swiftlint . status_report [ :markdowns ] . first ) . to_not be_empty", "del_tokens": "# Do it", "commit_type": "add"}
{"commit_tokens": ["added", "#next!", "#each_page", "and", "#reset!"], "add_tokens": "reset! def next! self . exec! unless @_loaded next_page = @_definition [ '_links' ] [ 'next' ] if next_page @_definition = self . class . build_self_link ( next_page ) self . reset! end end def all ( & block ) raise ArgumentError , \"Block must be given for #all\" unless block_given? each_page do | page | page . entries . each { | resource | block . call ( resource ) } end end def each_page raise ArgumentError , \"Block must be given for #each_page\" unless block_given? page = self . first . per_page ( self . query_params [ 'per_page' ] || 1000 ) begin yield page , page . page end while page . next! end def reset! @_links , @_embedded , @_changed , @_loaded = { } , { } , { } , false self end", "del_tokens": "@_changed , @_embedded , @_links = { } , { } , { }", "commit_type": "add"}
{"commit_tokens": ["Removed", "appraisals", "in", "favour", "of", "the", "kaminari", "s", "approach"], "add_tokens": "require \"rails\" require 'hungryform' require 'app/app'", "del_tokens": "require \"hungryform\"", "commit_type": "remove"}
{"commit_tokens": ["added", "a", "couple", "command", "shortcuts"], "add_tokens": "add_desc | ad | dd desc Adds a description for the test in the log add_test | at | tt Adds a test in the log , checking the last value ( _ ) add_test | at | tt desc Like add_test but adds a 'desc' directive first '", "del_tokens": "add_desc | dd desc Adds a description for the test in the log add_test | tt Adds a test in the log , checking the last value ( _ ) add_test | tt desc Like add_test but adds a 'desc' directive first '", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "scalar", "types"], "add_tokens": "resolved = ScalarTypes . registered_type ( type ) || types . String resolved . is_a? ( Proc ) ? resolved . call : resolved", "del_tokens": "types . String", "commit_type": "add"}
{"commit_tokens": ["Added", "MySQL", "Query", "Analyzer", "(", "check", "it", "in", "your", "logs", ")"], "add_tokens": "# Footnotes is divided in five files: # * textmate_analyzer.rb: Append explain queries in log when using MySQL. # require 'textmate_analyzer'", "del_tokens": "# Footnotes is divided in four files:", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "issues", "with", "install", "generator", "."], "add_tokens": "# config.log_formatter = ::Logger::Formatter.new # Incline::JsonLogFormatter also includes the PID and timestamp, plus it makes the log easier to parse. # If you want to revert to using the standard formatter above, uncomment that line and comment out this line instead. config . log_formatter = :: Incline :: JsonLogFormatter . new", "del_tokens": "config . log_formatter = :: Logger :: Formatter . new", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "gem", "configuration", "example", "to", "exploring", "."], "add_tokens": "require 'skn_utils/exploring/configuration' # config.disable_monkey_patching! # -- breaks rspec runtime", "del_tokens": "config . disable_monkey_patching! # -- breaks rspec runtime", "commit_type": "add"}
{"commit_tokens": ["use", "Readline", ".", "completion_append_character", "for", "leaves"], "add_tokens": "candidates = child_candidates ( word ) + cmd_candidates ( word ) if candidates . length == 1 && candidates [ 0 ] [ - 1 ] != '/' Readline . completion_append_character = ' ' end candidates map { | k , v | v == VIM :: Folder ? \"#{k}/\" : k } .", "del_tokens": "child_candidates ( word ) + cmd_candidates ( word ) map { | k , v | v == VIM :: Folder ? \"#{k}/\" : \"#{k} \" } .", "commit_type": "use"}
{"commit_tokens": ["Remove", "the", "public", "keywords", "and", "reshuffle", "organization"], "add_tokens": "############################################################################################### private # Given a URI path, determine whether or no it looks like a directory path # # @param [String] uri_path # @return [Boolean] `true` if the path is empty or has a trailing `/`, otherwise `false` # def directory_path? ( uri_path ) uri_path . empty? || uri_path [ - 1 ] == \"/\" end ############################################################################################### ############################################################################################### ###############################################################################################", "del_tokens": "############################################################################################### private ############################################################################################### private public ############################################################################################### private ############################################################################################### private ############################################################################################### private # Given a URI path, determine whether or no it looks like a directory path # # @param [String] uri_path # @return [Boolean] `true` if the path is empty or has a trailing `/`, otherwise `false` # def directory_path? ( uri_path ) uri_path . empty? || uri_path [ - 1 ] == \"/\" end", "commit_type": "remove"}
{"commit_tokens": ["Change", "to", "fix", "average", "calcualtion", "on", "old", "rubies"], "add_tokens": "times << measurements . reduce ( & :+ ) . to_f / measurements . size", "del_tokens": "times << measurements . sum . to_f / measurements . size", "commit_type": "change"}
{"commit_tokens": ["Changed", "to", "handle", "filter", "type", "names"], "add_tokens": "@io << [ Filter . guess ( @filter_type ) ] . pack ( 'C' )", "del_tokens": "@io << [ @filter_type ] . pack ( 'C' )", "commit_type": "change"}
{"commit_tokens": ["Add", "id", "to", "the", "list", "of", "permanent", "attributes"], "add_tokens": "@@permanent_attributes = Set . new ( [ :api_key , :id ] )", "del_tokens": "@@permanent_attributes = Set . new ( [ :api_key ] )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Monkey#patch_kernel", "check", "and", "raise", "error", "when", "raw", "io", "objects", "in", "IO#select"], "add_tokens": "patch_method! ( Kernel , :sleep , LightIO . method ( :sleep ) )", "del_tokens": "patch_method! ( Kernel , :sleep , LightIO :: Library :: KernelExt . method ( :sleep ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "special", "layout", "for", "devise"], "add_tokens": "VERSION = \"0.6.3\" . freeze", "del_tokens": "VERSION = \"0.6.2\" . freeze", "commit_type": "add"}
{"commit_tokens": ["Added", "subscribers", "for", "open", "and", "click", "events"], "add_tokens": "mattr_accessor :secret_token , :options , :subscribers self . subscribers = [ ]", "del_tokens": "mattr_accessor :secret_token , :options", "commit_type": "add"}
{"commit_tokens": ["Added", "layouts", "to", "quorum", ":", "views", "generator", ".", "Increased", "Capybara", "default"], "add_tokens": "source_root File . expand_path ( \"../../../../app/views\" , __FILE__ ) DIRECTORIES = [ \"quorum/jobs\" , \"layouts/quorum\" def copy_directories DIRECTORIES . each do | d | directory d . to_s , \"app/views/#{d.to_s}\"", "del_tokens": "source_root File . expand_path ( \"../../../../app/views/quorum\" , __FILE__ ) VIEW_DIRECTORIES = [ \"jobs\" def copy_views VIEW_DIRECTORIES . each do | d | directory d . to_s , \"app/views/quorum/#{d.to_s}\"", "commit_type": "add"}
{"commit_tokens": ["adding", "tests", "for", "running", "ratchetio", "in", "the", "context", "of", "a", "rails", "app"], "add_tokens": "config . logger = :: Rails . logger config . environment = :: Rails . env config . root = :: Rails . root", "del_tokens": "it 'report_message in the context of a request' it 'report_exception in the context of a request' config . logger ||= :: Rails . logger config . environment ||= :: Rails . env config . root ||= :: Rails . root", "commit_type": "add"}
{"commit_tokens": ["Use", "correct", "name", "for", "initializer", "key"], "add_tokens": "initializer \"action_controller.caching.sweepers\" do", "del_tokens": "initializer \"action_controller.caching.sweppers\" do", "commit_type": "use"}
{"commit_tokens": ["add", "test", "for", "i386", "striped", "and", "PIE", "binary"], "add_tokens": "filepath = File . join ( __dir__ , 'files' , 'amd64.elf' )", "del_tokens": "filepath = File . join ( __dir__ , 'files' , 'amd64' )", "commit_type": "add"}
{"commit_tokens": ["add", "#save", "\\", "nrefactoring", "for", "template"], "add_tokens": "attr_reader :meta @converted = nil @converted = apply_template ( :epub ) { @engine . call ( text ) } alias :convert :run def save ( path = \"out.xhtml\" ) @converted ||= run File . write ( path , @converted ) end def set_meta ( meta ) def apply_template ( template , & blk ) case template when :epub then epub_template ( & blk ) else raise \"Only :epub template available so far.\" end end def epub_template ( & blk ) < html xmlns = \"http://www.w3.org/1999/xhtml\" xml : lang = \"#{meta[:language]}\" > < title > #{meta[:title]}</title> #{meta[:css]} [ header , blk . call , footer ] . join", "del_tokens": "apply_template { @engine . call ( text ) } def meta ( meta ) def apply_template < html xmlns = \"http://www.w3.org/1999/xhtml\" xml : lang = \"#{@meta[:language]}\" > < title > #{@meta[:title]}</title> #{@meta[:css]} [ header , yield , footer ] . join", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "provide", "default", "values", "to", "get_variant"], "add_tokens": "def get_variant ( experiment_name , override = nil ) # allows us to override and get back a variant # easily that conforms to the api if override . nil? self . get_variant_value ( experiment_name ) else Ostruct . new ( :name => override , :index => - 1 , :experiment_id => nil ) end", "del_tokens": "def get_variant ( experiment_name ) self . get_variant_value ( experiment_name )", "commit_type": "add"}
{"commit_tokens": ["moved", "matasato", "challanges", "into", "dedicated", "directories"], "add_tokens": "require 'crypto-toolbox/matasano/solver.rb'", "del_tokens": "require 'crypto-toolbox/crypto_challanges/solver.rb'", "commit_type": "move"}
{"commit_tokens": ["Added", "a", "viewby", "for", "md5", "and", "cleaned", "up", "some", "noise", "."], "add_tokens": "view_by :md5sum", "del_tokens": "puts ErnieBrodeur :: Couch :: DB", "commit_type": "add"}
{"commit_tokens": ["move", "fonts", "into", "vendor", "dir"], "add_tokens": "draw . font = File . join ( Configuration :: LOLCOMMITS_ROOT , \"vendor\" , \"fonts\" , \"Impact.ttf\" )", "del_tokens": "draw . font = File . join ( Configuration :: LOLCOMMITS_ROOT , \"fonts\" , \"Impact.ttf\" )", "commit_type": "move"}
{"commit_tokens": ["Add", "Dotenv", "and", "bump", "version"], "add_tokens": "VERSION = \"0.5.0\"", "del_tokens": "VERSION = \"0.4.1\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "problems", "with", "setting", "enumeration", "attributes", "to", "nil"], "add_tokens": "# Finds the enumerated value indicated by id or returns nil if nothing # was found def find_enum ( id ) case id when Symbol value = find_by_name ( id . id2name ) when String value = find_by_name ( id ) when Fixnum value = find_by_id ( id ) when nil value = nil else raise TypeError , \"#{self.name}[]: id should be a String, Symbol or Fixnum but got a: #{id.class.name}\" value end", "del_tokens": "private def find_enum ( id ) case id when Symbol value = find_by_name ( id . id2name ) when String value = find_by_name ( id ) when Fixnum value = find_by_id ( id ) when nil value = nil else raise TypeError , \"#{self.name}[]: id should be a String, Symbol or Fixnum but got a: #{id.class.name}\" end value", "commit_type": "fix"}
{"commit_tokens": ["implemented", ":", "log_stdout", "and", ":", "log_stderr", "options", "to", "Server"], "add_tokens": "path = log_path_from_config ( @config ) unless path . is_a? ( IO ) @logger . path = io @logger = @logger_class . new ( log_path_from_config ( @config ) , @config ) end def log_path_from_config ( config ) case c = @config [ :log ] when nil # default return STDERR when \"-\" return STDOUT else return c end", "del_tokens": "case c = @config [ :log ] when nil # default @log_dev = STDERR when \"-\" @log_dev = STDOUT else @log_dev = c end if @log_dev . is_a? ( String ) @logger . path = @log_dev @logger = @logger_class . new ( @log_dev , @config )", "commit_type": "implement"}
{"commit_tokens": ["added", "easy", "in", "place", "editing", "of", "backtraced", "files"], "add_tokens": "command = case when args . empty? process_cmd cmd , * IRB . CurrentContext . file_line_pointers when args . first . to_s . match ( / ^ \\d +$ / ) process_cmd cmd , * IRB . CurrentContext . backtrace_map [ args . first ] def process_cmd ( cmd , file , line ) cmd_format = IRT . send ( \"#{cmd}_command_format\" . to_sym ) raise NotImplementedError unless cmd_format sprintf cmd_format , file , line end", "del_tokens": "command = if args . empty? cmd_format = IRT . send ( \"#{cmd}_command_format\" . to_sym ) raise NotImplementedError unless cmd_format f , l = IRB . CurrentContext . file_line_pointers sprintf cmd_format , f , l", "commit_type": "add"}
{"commit_tokens": ["Add", "input", "types", "to", "IO", ":", "letters", "numbers", "or", "secret", "."], "add_tokens": "CANCEL = 0x1B . chr ENTER = 0x0D . chr BACK = 0x08 . chr F1 = 0x01 . chr F2 = 0x02 . chr IO_INPUT_NUMBERS = :numbers IO_INPUT_LETTERS = :letters IO_INPUT_SECRET = :secret", "del_tokens": "CANCEL = 0x1B . chr ENTER = 0x0D . chr BACK = 0x08 . chr F1 = 0x01 . chr F2 = 0x02 . chr", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "testing", "for", "the", "base", "parser"], "add_tokens": "@pt . keywords . keys . should be_include ( keyword )", "del_tokens": "pending", "commit_type": "add"}
{"commit_tokens": ["Allow", "application", "modifications", "of", "database", "query", "values"], "add_tokens": "binds [ bindvar ] = attribute_value ( value ) def attribute_value ( value ) value . respond_to? ( :descends_from_active_record? ) && value . descends_from_active_record? && value . id || value . is_a? ( Array ) && value [ 0 ] . respond_to? ( :descends_from_active_record? ) && value [ 0 ] . descends_from_active_record? && value . map ( & :id ) || value end", "del_tokens": "attribute_value = value . respond_to? ( :descends_from_active_record? ) && value . descends_from_active_record? && value . id || value . is_a? ( Array ) && value [ 0 ] . respond_to? ( :descends_from_active_record? ) && value [ 0 ] . descends_from_active_record? && value . map ( & :id ) || value binds [ bindvar ] = attribute_value", "commit_type": "allow"}
{"commit_tokens": ["updated", "manifest", "added", "behavior", "tests"], "add_tokens": "def test_generate_should_return_an_object_corresponding_to_the_given_type assert_equal Behaviors :: FakeBehavior , Behavior . generate ( :fake_behavior ) . class def test_generate_should_raise_on_invalid_type assert_raise NoSuchBehaviorError do Behavior . generate ( :foo ) end end", "del_tokens": "def setup @behavior = Behavior . new", "commit_type": "update"}
{"commit_tokens": ["Add", "json", "support", "to", "clients"], "add_tokens": "require 'json' require_relative 'encoding' require_relative 'error' require_relative 'service_dsl' env [ :content_type ] ||= Encoding :: PROTO if ! Encoding . valid_content_type? ( content_type ) return bad_route_error ( \"Unexpected Content-Type: #{content_type.inspect}. Content-Type header must be one of #{Encoding.valid_content_types.inspect}\" , rack_request ) input = Encoding . decode ( rack_request . body . read , env [ :input_class ] , content_type ) resp_body = Encoding . encode ( output , env [ :output_class ] , env [ :content_type ] ) # Twirp errors are always JSON, even if the request was protobuf { 'Content-Type' => Encoding :: JSON }", "del_tokens": "require \"json\" require_relative \"error\" require_relative \"service_dsl\" env [ :content_type ] ||= \"application/protobuf\" if content_type != \"application/json\" && content_type != \"application/protobuf\" return bad_route_error ( \"unexpected Content-Type: #{content_type.inspect}. Content-Type header must be one of application/json or application/protobuf\" , rack_request ) input = decode_input ( rack_request . body . read , env [ :input_class ] , content_type ) def decode_input ( bytes , input_class , content_type ) case content_type when \"application/protobuf\" then input_class . decode ( bytes ) when \"application/json\" then input_class . decode_json ( bytes ) end end def encode_output ( obj , output_class , content_type ) case content_type when \"application/protobuf\" then output_class . encode ( obj ) when \"application/json\" then output_class . encode_json ( obj ) end end resp_body = encode_output ( output , env [ :output_class ] , env [ :content_type ] ) { 'Content-Type' => 'application/json' }", "commit_type": "add"}
{"commit_tokens": ["Moving", "AR", "specific", "tests", "into", "AR", "test", "directory"], "add_tokens": "hookup { topic . rails_context ( Object ) { } }", "del_tokens": "context \"for an ActiveRecord class\" do setup do situation = Riot :: Situation . new topic . rails_context ( Room ) do hookup { topic . email = \"i.am@chee.se\" } end . local_run ( Riot :: SilentReporter . new , situation ) situation . topic end asserts_topic . kind_of ( Room ) asserts ( :new_record? ) asserts ( :email ) . equals ( \"i.am@chee.se\" ) end # for an ActiveRecord class hookup { topic . rails_context ( Room ) { } }", "commit_type": "move"}
{"commit_tokens": ["fixed", "an", "overlay", "-", "related", "memory", "leak"], "add_tokens": "@raw_wmes = Hash . new { | h , k | h [ k ] = [ ] } @raw_tokens = Hash . new { | h , k | h [ k ] = [ ] } @raw_tokens . values . each do | tokens | tokens . each ( & :dispose! ) end @raw_tokens . clear", "del_tokens": "@raw_wmes ||= Hash . new { | h , k | h [ k ] = [ ] } @raw_tokens ||= Hash . new { | h , k | h [ k ] = [ ] }", "commit_type": "fix"}
{"commit_tokens": ["Added", "stats", "to", "the", "api"], "add_tokens": "class DirectApi def get_app_stats_kpis ( application_id , range ) return get_response ( \"app/#{application_id}/stats/kpis/#{range}\" , :json ) end def get_stats_query ( k , d , c = nil , r = nil ) q_params = QueryParams . new . merge ( { :k => k , :d => d } ) if c # c are the conditions and they are supplied like so: # [ {:field => \"fieldname\", :value => \"value\"}, ...] c . each do | condition | q_params [ \"where_#{condition[:field]}\" . to_sym ] = condition [ :value ] end end q_params [ :r ] = r if r return get_response ( \"stats/query\" + q_params . to_params , :json ) end def get_stats_interface return get_response ( \"stats/interface\" , :json ) end def get_stats_logging ( application_id , range ) return get_response ( \"app/#{application_id}/stats/logging/#{range}\" , :json ) end class QueryParams < Hash def to_params return \"\" if self . empty? p = \"?\" self . each { | k , v | p += \"#{CGI::escape k.to_s}=#{CGI::escape v.to_s}&\" } return p . chop end end end", "del_tokens": "class DirectApi end", "commit_type": "add"}
{"commit_tokens": ["fixed", "url", "encoding", "of", "request", "params", "to", "be", "oauth", "compliant"], "add_tokens": "RESERVED_CHARACTERS = / [^a-zA-Z0-9 \\- \\. \\_ \\~ ] / query = api_request . parameters . map { | k , v | \"#{escape(k)}=#{escape(v)}\" } . join ( \"&\" ) def escape ( value ) URI :: escape ( value . to_s , RESERVED_CHARACTERS ) rescue ArgumentError URI :: escape ( value . to_s . force_encoding ( Encoding :: UTF_8 ) , RESERVED_CHARACTERS ) end", "del_tokens": "query = api_request . parameters . map { | k , v | \"#{CGI::escape(k.to_s)}=#{CGI::escape(v.to_s)}\" } . join ( \"&\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "and", "tasks", "as", "resources"], "add_tokens": ":workflows , :tasks , :comments", "del_tokens": ":workflows", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "accept", "multiples", "in", "the", "form", "of", "a", "[", "3", "]", "which", "will", "be", "resolved", "to", "a", "[", "3", "3", "]"], "add_tokens": "VERSION = \"0.7.2\"", "del_tokens": "VERSION = \"0.7.1\"", "commit_type": "add"}
{"commit_tokens": ["improved", "README", "and", "moved", "generator"], "add_tokens": "module RolesGeneric def apply_role_strategy roles ? \"valid_roles_are #{roles.join(',')}\" : ''", "del_tokens": "module RolesModel # TODO: Should detect ORM from file content instead! class_option :orm , :type => :string , :aliases => \"-o\" , :default => nil , :desc => \"ORM of model\" def apply_role_strategy self . class . use_orm orm if orm def orm @orm ||= options [ :orm ] . to_s . to_sym end roles ? \"valid_roles #{roles.join(',')}\" : ''", "commit_type": "improve"}
{"commit_tokens": ["Change", "to", "require", "relative", "file"], "add_tokens": "require_relative \"tty/color\"", "del_tokens": "require \"tty/color\"", "commit_type": "change"}
{"commit_tokens": ["Add", "tests", "for", "Sapience", "spec"], "add_tokens": "self . appenders = [ { file : { io : STDOUT , formatter : :color } } ]", "del_tokens": "self . appenders = [ { io : STDOUT , formatter : :color } ]", "commit_type": "add"}
{"commit_tokens": ["Removes", "export", "file", "deletion", "just", "after", "a", "send_file"], "add_tokens": "# code << \"File.delete(file)\\n\" # Removes tmp files before they explode the disk", "del_tokens": "code << \"File.delete(file)\\n\" # Removes tmp files before they explode the disk", "commit_type": "remove"}
{"commit_tokens": ["Add", "!", "=", "to", "Compare"], "add_tokens": "[ String , :values => %w{ > >= <= < != } ] , when '!=' record_1 [ @name_1 ] != record_2 [ @name_2 ]", "del_tokens": "[ String , :values => %w{ > >= <= < } ] ,", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Cargo", "workspaces"], "add_tokens": "# # The absolute path to the `Cargo.toml` file. The path depends on the existence of the # `cargo_workspace_member` configuration option. # def cargo_toml_path @cargo_toml_path ||= begin components = if ( member_path = @options [ :cargo_workspace_member ] ) [ member_path , 'Cargo.toml' ] else [ 'Cargo.toml' ] end rust_path ( * components ) end end @toml ||= Tomlrb . load_file ( cargo_toml_path , symbolize_keys : true )", "del_tokens": "@toml ||= Tomlrb . load_file ( rust_path ( 'Cargo.toml' ) , symbolize_keys : true )", "commit_type": "add"}
{"commit_tokens": ["Change", "memoization", "to", "use", "a", "thread", "-", "safe", "Hash"], "add_tokens": "require 'thread_safe' Memory = Class . new ( ThreadSafe :: Hash )", "del_tokens": "Memory = Class . new ( :: Hash )", "commit_type": "change"}
{"commit_tokens": ["Fix", "an", "issue", "where", "winning_strategy", "was", "not", "cleaned", "allowing", "multiple", "scopes", "to", "sign", "in", "even", "when", "the", "second", "one", "should", "not", "."], "add_tokens": "it \"should not authenticate other scopes just because the first is authenticated\" do app = lambda do | env | env [ 'warden' ] . authenticate ( :pass , :scope => :foo ) env [ 'warden' ] . authenticate ( :invalid , :scope => :bar ) env [ 'warden' ] . should be_authenticated ( :foo ) env [ 'warden' ] . should_not be_authenticated ( :bar ) valid_response end env = env_with_params setup_rack ( app ) . call ( env ) end", "del_tokens": "env [ 'warden' ] . authenticate ( :pass , :scope => :foo ) env [ 'warden' ] . authenticate ( :pass , :scope => :bar ) env [ 'warden' ] . authenticate ( :password )", "commit_type": "fix"}
{"commit_tokens": ["adding", "Resource", "class", "as", "a", "means", "to", "perform", "requests"], "add_tokens": "parse_domain = URI . extract ( domain ) raise ArgumentError , 'The domain must be a URL.' if parse_domain . empty? @path = resource options [ :via ] = :get if options [ :via ] . nil? class Resource # This might be instantiated in the Base.declare_resource method. # Looking to Routing in ActionController for inspiration def get ( action , options = { } ) end def post ( action , options = { } ) end def put ( action , options = { } ) end def delete ( action , options = { } ) end def head ( action , options = { } ) end end", "del_tokens": "raise ArgumentError , 'The domain must be a URL.' unless domain . is_a? ( String ) options [ :via ] = :get if options [ :via ] . nil? #do something_else", "commit_type": "add"}
{"commit_tokens": ["added", "XMLReader", "for", "reading", "MARCXML"], "add_tokens": "class XMLWriterTest < Test :: Unit :: TestCase", "del_tokens": "class WriterTest < Test :: Unit :: TestCase", "commit_type": "add"}
{"commit_tokens": ["fixing", "tests", "broken", "because", "of", "last", "change", "."], "add_tokens": "@request . env [ \"Authorization\" ] = %Q{Token token=\"bogus\"} get :index", "del_tokens": "get :index , :access_token => 'bogus'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "rubocop", "offenses", "for", "configuration", "and", "specs"], "add_tokens": "resource_path . to_s . split ( 'adminable/' ) . last . sub ( / _controller \\. rb$ / , '' )", "del_tokens": "resource_path . to_s . split ( 'adminable/' ) . last . sub ( / _controller \\. rb$ / , '' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "a", "system", "default", "credentials", "file", "."], "add_tokens": "DefaultCredentials . from_well_known_path ( scope ) || DefaultCredentials . from_system_default_path ( scope )", "del_tokens": "DefaultCredentials . from_well_known_path ( scope )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "work", "with", "the", "latest", "version", "of", "kaminari"], "add_tokens": "require 'kaminari/actionview/action_view_extension'", "del_tokens": "require 'kaminari/helpers/action_view_extension'", "commit_type": "update"}
{"commit_tokens": ["add", "test", "for", "resetting", "staging", "to", "last_known_good_staging"], "add_tokens": "reset_branch ( \"last_known_good_#{bad_branch}\" , good_branch ) unless \"last_known_good_#{bad_branch}\" == good_branch", "del_tokens": "reset_branch ( \"last_known_good_#{bad_branch}\" , good_branch )", "commit_type": "add"}
{"commit_tokens": ["Make", "all", "RAML", "exceptions", "descend", "from", "RamlError", "."], "add_tokens": "class RamlError < StandardError ; end class UnsupportedRamlVersion < RamlError ; end class CantIncludeFile < RamlError ; end class InvalidParameterType < RamlError ; end class InapplicableParameterAttribute < RamlError ; end class InvalidParameterAttribute < RamlError ; end class RootTitleMissing < RamlError ; end class RootBaseUriMissing < RamlError ; end class ProtocolMustBeArrayOfStrings < RamlError ; end class ProtocolMustBeHTTPorHTTPS < RamlError ; end class FormParametersMissing < RamlError ; end class FormCantHaveSchema < RamlError ; end", "del_tokens": "class UnsupportedRamlVersion < StandardError ; end class CantIncludeFile < StandardError ; end class InvalidParameterType < StandardError ; end class InapplicableParameterAttribute < StandardError ; end class InvalidParameterAttribute < StandardError ; end class RootTitleMissing < StandardError ; end class RootBaseUriMissing < StandardError ; end class ProtocolMustBeArrayOfStrings < StandardError ; end class ProtocolMustBeHTTPorHTTPS < StandardError ; end class FormParametersMissing < StandardError ; end class FormCantHaveSchema < StandardError ; end", "commit_type": "make"}
{"commit_tokens": ["Improve", "safe_copy", "/", "frozen_copy", "refinement", "."], "add_tokens": "def safe_copy IceNine . deep_freeze ( try_dup ) end alias frozen_copy safe_copy alias frozen_copy try_dup alias frozen_copy try_dup alias frozen_copy try_dup alias frozen_copy try_dup alias frozen_copy try_dup frozen? ? self : dup . freeze alias frozen_copy safe_copy frozen? ? self : dup . freeze alias frozen_copy safe_copy def safe_copy frozen? ? self : deep_dup . deep_freeze end alias frozen_copy safe_copy def safe_copy frozen? ? self : deep_dup . deep_freeze end alias frozen_copy safe_copy def safe_copy frozen? ? self : deep_dup . deep_freeze end alias frozen_copy safe_copy", "del_tokens": "alias safe_copy try_dup frozen? ? self : dup frozen? ? self : dup", "commit_type": "improve"}
{"commit_tokens": ["Removed", "the", "freezing", "of", "validations", "-", "it", "s", "only", "causing", "troubles", "anyway", "(", "tests", "etc", ".", ")", ".", "Commenting", "the", "code", "to", "make", "the", "life", "easier", "for", "newly", "introduced", "developers", ".", ";", ")"], "add_tokens": "# Look for config/initalizer here in: CORE_VALIDATONS = [ ] . freeze @@reflected_validations = CORE_VALIDATONS . dup # Load config/initializer on load, where ValidationReflection defaults # (such as which validations to reflect upon) cane be overridden/extended. # # Iterate through all validations and store/cache the info # for later easy access. # alias :reload :install", "del_tokens": "@@reflected_validations = [ ] @@reflected_validations . freeze", "commit_type": "remove"}
{"commit_tokens": ["Updated", "error", "messages", "for", "column_properties"], "add_tokens": "raise \"Column property 'format' expected to be a non-empty string\" unless v . is_a? ( String ) && ! v . empty? raise \"Unknown column property '#{k}'\"", "del_tokens": "validate_column_exist ( * columns ) raise \"Meta tag 'format' expected to be a non-empty string\" unless v . is_a? ( String ) && ! v . empty? raise \"Unknown meta data tag '#{k}'\"", "commit_type": "update"}
{"commit_tokens": ["Making", "ouput", "cleaner", "and", "better"], "add_tokens": ":ruby_platform => \"darwin\" :ruby_platform : darwin presenter = Chatterbox :: ExceptionNotification :: Presenter . new it \"should strip leading --- from to_yaml\" do hash = { \"my-key\" => \"some string value\" , \"my-other-key\" => \"something\" } presenter = Chatterbox :: ExceptionNotification :: Presenter . new output = presenter . inspect_value ( hash ) expected = <<EOL my - key : some string value my - other - key : something EOL output . should == expected . rstrip end it \"should strip leading --- from strings\" do presenter = Chatterbox :: ExceptionNotification :: Presenter . new output = presenter . inspect_value ( \"just a simple string\" ) output . should == \"just a simple string\"", "del_tokens": "presenter = Chatterbox :: ExceptionNotification :: Presenter . new ( { } ) fit \"should strip leading --- from to_yaml\" do presenter = Chatterbox :: ExceptionNotification :: Presenter . new ( { } ) yml = { :foo => \"bar\" } . to_yaml output = presenter . prettyify_output ( yml ) puts output output . should == \"\"", "commit_type": "make"}
{"commit_tokens": ["removed", "prepend", "in", "favor", "of", "alias_method", "to", "increase", "compatibility", "to", "jruby"], "add_tokens": "def self . included base base . class_eval do alias_method :minus_without_working_hours , :- alias_method :- , :minus_with_working_hours alias_method :plus_without_working_hours , :+ alias_method :+ , :plus_with_working_hours end end def plus_with_working_hours ( other ) if WorkingHours :: Duration === other plus_without_working_hours ( other ) def minus_with_working_hours ( other ) if WorkingHours :: Duration === other minus_without_working_hours ( other ) include WorkingHours :: CoreExt :: DateAndTime include WorkingHours :: CoreExt :: DateAndTime include WorkingHours :: CoreExt :: DateAndTime include WorkingHours :: CoreExt :: DateAndTime", "del_tokens": "def + ( other ) if ( other . is_a? ( WorkingHours :: Duration ) ) super ( other ) def - ( other ) if ( other . is_a? ( WorkingHours :: Duration ) ) super ( other ) prepend WorkingHours :: CoreExt :: DateAndTime prepend WorkingHours :: CoreExt :: DateAndTime prepend WorkingHours :: CoreExt :: DateAndTime prepend WorkingHours :: CoreExt :: DateAndTime", "commit_type": "remove"}
{"commit_tokens": ["Make", "RSocket#write", "to", "be", "nonblocking"], "add_tokens": "# @option opts [Float] :timeout (1.0) socket read/write timeout", "del_tokens": "# @option opts [Float] :timeout (1.0) socket read timeout", "commit_type": "make"}
{"commit_tokens": ["Make", "aspect", "more", "readable", "by", "defining", "constants", "for", "all", "methods", "pattern"], "add_tokens": "ALL_METHODS = / .* / around ALL_METHODS , :except => :class , :context_arg => true do | context , * args , & block |", "del_tokens": "around / .* / , :except => [ :class ] , :context_arg => true do | context , * args , & block |", "commit_type": "make"}
{"commit_tokens": ["Add", "component", "flag", "allowing", "specification", "of", "activatable", "attribute"], "add_tokens": "self . activatable = args [ :activatable ] if args . key? ( :activatable ) attr_writer :activatable defined? ( @activatable ) && @activatable", "del_tokens": "false", "commit_type": "add"}
{"commit_tokens": ["Remove", "verbose", "command", "add", "version", "command"], "add_tokens": "o . on_tail ( \"-v\" , \"--version\" , \"Display the version\" ) do puts VERSION exit end", "del_tokens": "o . on_tail ( \"--verbose\" , \"Run verbosely\" ) do | v | @verbose = true end", "commit_type": "remove"}
{"commit_tokens": ["Use", "autoload", "to", "reduce", "bloat"], "add_tokens": "autoload :Delegation , \"rink/delegation\" autoload :Namespace , \"rink/namespace\" autoload :Lexer , \"rink/lexer\" autoload :IOMethods , \"rink/io_methods\" autoload :LineProcessor , \"rink/line_processor\" autoload :Console , \"rink/console\" autoload :Version , \"rink/version\"", "del_tokens": "#require 'sc-ansi' require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"rink/delegation\" ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , 'rink/namespace' ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"rink/lexer\" ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , 'rink/io_methods' ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"rink/line_processor/base\" ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"rink/line_processor/pure_ruby\" ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"rink/console\" ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"rink/version\" ) )", "commit_type": "use"}
{"commit_tokens": ["Implemented", "exponential", "backoff", "when", "polling", "for", "new", "Cfn", "events"], "add_tokens": "# @option options [Boolean] :no_sleep Don't pause between polling. This is used for tests, and shouldn't be when polling the AWS API. # @option options [Fixnum] :backoff The exponential backoff factor (default 1.5) # @option options [Fixnum] :backoff_max_wait The maximum amount of time that exponential backoff will wait before polling agian (default 15s) sleep_time = 1 sleep_time = [ sleep_time * ( options [ :backoff ] || 1 ) , options [ :backoff_max_wait ] || 15 ] . min sleep_time = 1 sleep sleep_time if running unless options [ :no_sleep ]", "del_tokens": "sleep 1 if running unless options [ :no_sleep ]", "commit_type": "implement"}
{"commit_tokens": ["Make", "help", "available", "everywhere", "."], "add_tokens": "if command and self . respond_to? ( command ) @user , @repo = repo_info @args = args configure_github_access unless command . nil? or command . empty? or %w( help -h --help ) . include? ( command ) # Show a quick reference of available commands. def help puts 'Usage: git review <command>' puts 'Manage review workflow for projects hosted on GitHub (using pull requests).' puts puts 'Available commands:' puts ' list [--reverse] List all pending requests.' puts ' show <number> [--full] Show details of a single request.' puts ' browse <number> Open a browser window and review a specified request.' puts ' checkout <number> Checkout a specified request\\'s changes to your local repository.' puts ' merge <number> Accept a specified request by merging it into master.' puts ' close <number> Close a specified request.' puts ' create Create a new request.' end", "del_tokens": "# Default command to show a quick reference of available commands. def help puts 'Usage: git review <command>' puts 'Manage review workflow for projects hosted on GitHub (using pull requests).' puts puts 'Available commands:' puts ' list [--reverse] List all pending requests.' puts ' show <number> [--full] Show details of a single request.' puts ' browse <number> Open a browser window and review a specified request.' puts ' checkout <number> Checkout a specified request\\'s changes to your local repository.' puts ' merge <number> Accept a specified request by merging it into master.' puts ' close <number> Close a specified request.' puts ' create Create a new request.' end @user , @repo = repo_info @args = args configure_github_access if command && self . respond_to? ( command ) unless command . nil? or command . empty? or %w( -h --help ) . include? ( command )", "commit_type": "make"}
{"commit_tokens": ["fix", "diffs", "for", "mode", "only", "changes"], "add_tokens": "assert_equal '100644' , diffs . first . b_mode assert_equal '100644' , diffs . first . b_mode assert_equal nil , diffs . first . b_mode def test_diffs_with_mode_only_change Git . any_instance . expects ( :diff ) . returns ( fixture ( 'diff_mode_only' ) ) @c = Commit . create ( @r , :id => '91169e1f5fa4de2eaea3f176461f5dc784796769' ) diffs = @c . diffs assert_equal 23 , diffs . size assert_equal '100644' , diffs [ 0 ] . a_mode assert_equal '100755' , diffs [ 0 ] . b_mode end", "del_tokens": "assert_equal '100644' , diffs . first . mode assert_equal '100644' , diffs . first . mode assert_equal nil , diffs . first . mode", "commit_type": "fix"}
{"commit_tokens": ["Changed", "documentation", "to", "use", "yard", "rather", "than", "rdoc"], "add_tokens": "# \\@repeats_on is an array of day indices. For example, # \\@repeats_on is an array of arrays: Each sub array has the format # \\@repeats_on == [[1,5], [2,5]] # \\@repeats_on is an array of datemonthly indices. For example,", "del_tokens": "# @repeats_on is an array of day indices. For example, # @repeats_on is an array of arrays: Each sub array has the format # @repeats_on == [[1,5], [2,5]] # @repeats_on is an array of datemonthly indices. For example,", "commit_type": "change"}
{"commit_tokens": ["Change", "to", "fix", "color", "detection", "to", "fail", "gracefully", "on", "non", "-", "unix", "systems", "."], "add_tokens": "cmd = %q(tput colors 2>/dev/null) return NoValue unless system ( cmd ) ` #{ cmd } ` . to_i > 2", "del_tokens": "` tput colors 2>/dev/null ` . to_i > 2", "commit_type": "change"}
{"commit_tokens": ["Implemented", "clicks_link_within", "for", "selenium", "session", "."], "add_tokens": "def fills_in ( field_identifier , options ) locator = \"webrat=#{Regexp.escape(field_identifier)}\" @selenium . type ( locator , \"#{options[:with]}\" ) def clicks_link_within ( selector , link_text , options = { } ) @selenium . click ( \"webratlinkwithin=#{selector}|#{link_text}\" ) wait_for_result ( options [ :wait ] ) end @selenium . add_location_strategy ( 'webratlinkwithin' , <<-JS ) var locatorParts = locator . split ( '|' ) ; var cssAncestor = locatorParts [ 0 ] ; var linkText = locatorParts [ 1 ] ; var matchingElements = cssQuery ( cssAncestor , inDocument ) ; var candidateLinks = matchingElements . collect ( function ( ancestor ) { var links = ancestor . getElementsByTagName ( 'a' ) ; return $A ( links ) . select ( function ( candidateLink ) { return PatternMatcher . matches ( linkText , getText ( candidateLink ) ) ; } ) ; } ) . flatten ( ) . compact ( ) ; if ( candidateLinks . length == 0 ) { return null ; } candidateLinks = candidateLinks . sortBy ( function ( s ) { return s . length * - 1 ; } ) ; / /reverse length sort return candidateLinks . first ( ) ; JS", "del_tokens": "def fills_in ( label_text , options ) @selenium . type ( \"webrat=#{Regexp.escape(label_text)}\" , \"#{options[:with]}\" )", "commit_type": "implement"}
{"commit_tokens": ["Make", "configure", "still", "return", "underlying", "hash"], "add_tokens": "block . call ( self . configuration )", "del_tokens": "block . call ( self )", "commit_type": "make"}
{"commit_tokens": ["Added", "conditional", "blocks", "to", "table", "columns"], "add_tokens": "def conditional_block @options [ :if ] end :sortable => true , :if => lambda { true }", "del_tokens": ":sortable => true", "commit_type": "add"}
{"commit_tokens": ["Added", "options", "into", "the", "API", "model", "."], "add_tokens": "# Specify the format for error messages. # May be `:json` or `:txt` (default). def error_format ( new_format = nil ) new_format ? set ( :error_format , new_format . to_sym ) : settings [ :error_format ] end # Specify the default status code for errors. def default_error_status ( new_status = nil ) new_status ? set ( :default_error_status , new_status ) : settings [ :default_error_status ] end # Specify whether to rescue all errors. def rescue_all_errors ( new_value = true ) set ( :rescue_all_errors , new_value ) end b . use Grape :: Middleware :: Error , :default_status => settings [ :default_error_status ] || 403 , :rescue => settings [ :rescue_all_errors ] , :format => settings [ :error_format ] || :txt", "del_tokens": "b . use Grape :: Middleware :: Error", "commit_type": "add"}
{"commit_tokens": ["use", "pretty", "print", "for", "debugger", "output"], "add_tokens": "default_options [ :debug_pretty ] = true def initialize ( opts = { } ) super require 'pp' if options [ :debug_pretty ] end puts options [ :debug_prefix ] if options [ :debug_prefix ] if options [ :debug_pretty ] pp exp else p exp end", "del_tokens": "puts options [ :prefix ] if options [ :prefix ] puts exp . inspect", "commit_type": "use"}
{"commit_tokens": ["Add", "decorator", "for", "each", "hit"], "add_tokens": "require 'elasticsearch/hit' require 'elasticsearch/hit_set'", "del_tokens": "require 'elasticsearch/hits'", "commit_type": "add"}
{"commit_tokens": ["Allow", "auto", "-", "archiving", "from", "namespaces", "other", "than", "beta"], "add_tokens": "Rake :: Task [ \"#{@namespace}:archive\" ] . invoke", "del_tokens": "Rake :: Task [ 'beta:archive' ] . invoke", "commit_type": "allow"}
{"commit_tokens": ["created", "browse_everything", ":", "config", "generator", "updated", "test", "generator", "to", "use", "it"], "add_tokens": "def run_config_generator generate \"browse_everything:config\" end", "del_tokens": "mount BrowseEverything :: Engine => '/browse' def create_bev_configuration create_file \"config/browse_everything_providers.yml\" do YAML . dump ( { 'file_system' => { :home => Rails . root . to_s } } ) end end def copy_example_config copy_file \"config/browse_everything_providers.yml.example\" , \"config/browse_everything_providers.yml.example\" end", "commit_type": "create"}
{"commit_tokens": ["Fix", "path", "to", "certs", "."], "add_tokens": "File . join ( File . dirname ( File . expand_path ( __FILE__ ) ) , '../../certs/cacert.pem' )", "del_tokens": "File . join ( File . dirname ( File . expand_path ( __FILE__ ) ) , '../certs/cacert.pem' )", "commit_type": "fix"}
{"commit_tokens": ["fix", "jruby", "build", "use", "Nokogiri", "::", "HTML", "intead", "of", "Nokogiri", "::", "XML"], "add_tokens": "@errors = Nokogiri :: HTML ( res . body ) . css ( 'ol li.error' ) . map ( & :content )", "del_tokens": "@errors = Nokogiri :: XML . parse ( res . body ) . css ( 'ol li.error' ) . map ( & :content )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "pull_request", "events"], "add_tokens": "pull_request", "del_tokens": "# TODO: Support for pull_request", "commit_type": "add"}
{"commit_tokens": ["fixed", "HookHandler", "method", "call", "and", "set_class"], "add_tokens": "self if method_handler ret = method_handler . handle_method ( klass , recv , method_name ) end", "del_tokens": "if method_handler ret = method_handler . handle_method ( @recv . method ( @m ) . owner , @recv , @m ) end", "commit_type": "fix"}
{"commit_tokens": ["fix", "config", "detection", "if", "passed", "as", "cl", "argument"], "add_tokens": "possible_files = [ ] possible_files |= KNOWN_CONFIG_LOCATIONS", "del_tokens": "possible_files = KNOWN_CONFIG_LOCATIONS", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "skip", "auto", "content_type", "discovery", "for", "alternate", "format", "parsing", "(", "simple", "-", "rss", ")"], "add_tokens": "def initialize ( uri , options = { } ) @options = options parse! unless @options . has_key? :raw_response", "del_tokens": "def initialize ( uri ) parse!", "commit_type": "add"}
{"commit_tokens": ["moved", "app", "in", "the", "cli", "namespace"], "add_tokens": "%w( template command ccu_cp_code ccu_arl ccu eccu app ) . each do | file |", "del_tokens": "%w( template command ccu_cp_code ccu_arl ccu eccu ) . each do | file |", "commit_type": "move"}
{"commit_tokens": ["Updated", "specs", "and", "error", "to", "include", "object"], "add_tokens": "\"Could not find system_code of '#{system_code_name}' or '#{form.object_name}_#{system_code_name}'\"", "del_tokens": "\"Invalid system_code of '#{system_code_name}'\"", "commit_type": "update"}
{"commit_tokens": ["Added", ":", "nodoc", ":", "for", "OData", "::", "Railtie", ".", "[", "ci", "skip", "]"], "add_tokens": "module OData # :nodoc:", "del_tokens": "module OData", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "actual", "dev", "version"], "add_tokens": "javascript 'i18n/jqgrid/locale-gl.js' javascript 'i18n/jqgrid/locale-gl.min.js'", "del_tokens": "javascript 'i18n/jqgrid/locale-dk.js' javascript 'i18n/jqgrid/locale-dk.min.js' javascript 'i18n/jqgrid/locale-sp.js' javascript 'i18n/jqgrid/locale-sp.min.js'", "commit_type": "update"}
{"commit_tokens": ["Added", "more", "render", "regions", "to", "layout", "snippet", "user", "and", "extension", "views", "."], "add_tokens": "attr_accessor :page , :snippet , :layout , :user , :extension @extension = load_default_extension_regions user . index = RegionSet . new do | index | index . thead . concat %w{ title_header roles_header modify_header } index . tbody . concat %w{ title_cell roles_cell modify_cell } index . bottom . concat %w{ new_button } end snippet . index = RegionSet . new do | index | index . top . concat %w{ help_text } index . thead . concat %w{ title_header modify_header } index . tbody . concat %w{ title_cell modify_cell } index . bottom . concat %w{ new_button } end layout . index = RegionSet . new do | index | index . top . concat %w{ help_text } index . thead . concat %w{ title_header modify_header } index . tbody . concat %w{ title_cell modify_cell } index . bottom . concat %w{ new_button } end end end def load_default_extension_regions returning OpenStruct . new do | extension | extension . index = RegionSet . new do | index | index . thead . concat %w{ title_header website_header version_header } index . tbody . concat %w{ title_cell website_cell version_cell } end", "del_tokens": "attr_accessor :page , :snippet , :layout , :user", "commit_type": "add"}
{"commit_tokens": ["Using", "Public", "and", "PrivateKeys", "for", "the", "Box", "class"], "add_tokens": "@public_key = PublicKey === public_key ? public_key : PublicKey . new ( public_key , encoding ) @private_key = PrivateKey === private_key ? private_key : PrivateKey . new ( private_key , encoding ) raise IncorrectPrimitiveError unless @public_key . primitive == primitive && @private_key . primitive == primitive NaCl . crypto_box_curve25519_xsalsa20_poly1305_beforenm ( k , @public_key . to_s , @private_key . to_s ) || raise ( CryptoError , \"Failed to derive shared key\" )", "del_tokens": "@public_key = Encoder [ encoding ] . decode ( public_key ) if public_key @private_key = Encoder [ encoding ] . decode ( private_key ) if private_key Util . check_length ( @public_key , PublicKey :: BYTES , \"Public key\" ) Util . check_length ( @private_key , PrivateKey :: BYTES , \"Private key\" ) NaCl . crypto_box_curve25519_xsalsa20_poly1305_beforenm ( k , @public_key , @private_key ) || raise ( CryptoError , \"Failed to derive shared key\" )", "commit_type": "use"}
{"commit_tokens": ["Fixing", "globalize", "tests", "as", "data", "was", "not", "being", "corretly", "set", "up"], "add_tokens": "if const_defined? ( 'Globalize' ) translates :translated_title accepts_nested_attributes_for :translations end", "del_tokens": "translates :translated_title if const_defined? ( 'Globalize' )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "use", "tmp", "paths"], "add_tokens": "file = tmp_path ( 'Gemfile' )", "del_tokens": "file = fixtures_path ( 'Gemfile' )", "commit_type": "change"}
{"commit_tokens": ["fix", "no", "database", ".", "yml", "warning", "to", "not", "crash"], "add_tokens": "warn \"No database configuration in #{yaml_config_path}, using defaults: #{adapter_config.inspect}\"", "del_tokens": "warn \"No database configuration in #{yaml_config_path}, using defaults: #{adapter_config.inspect}\"", "commit_type": "fix"}
{"commit_tokens": ["use", "search_result", "initializer", "to", "well", "initialize", "it"], "add_tokens": "search_result = Vagalume :: SearchResult . new ( result_json )", "del_tokens": "search_result = Vagalume :: SearchResult . fetch ( result_json )", "commit_type": "use"}
{"commit_tokens": ["uses", "ERB", "comments", "in", "demo", "section"], "add_tokens": "< %# This file contains the HTML for the 'hello world' section . % >", "del_tokens": "< ! - - This file contains the HTML for the 'hello world' section . - - >", "commit_type": "use"}
{"commit_tokens": ["add", "context", "to", "the", "DSL"], "add_tokens": "require 'aw' require 'defi' # Add context method to the DSL, to build an isolated scope. # # @api public # # @example Context when logged in. # context 'when logged in' do # it { MUST Equal: 200 } # end # # @param block [Proc] A block of specs to test in isolation. # # @return [Array] List of results. def context ( * , & block ) o = On . new ( front_object , results , challenges , helpers . dup , configuration ) Aw . fork! { o . instance_eval ( & block ) } end", "del_tokens": "require 'defi'", "commit_type": "add"}
{"commit_tokens": ["use", "static", ".", "intercomcdn", ".", "com", "/", "intercom", ".", "v1", ".", "js", "-", "instead", "of", "api", ".", "intercom", ".", "io", "/", "js", "/", "library", ".", "js", "as", "the", "default"], "add_tokens": "VERSION = \"0.2.21\"", "del_tokens": "VERSION = \"0.2.20\"", "commit_type": "use"}
{"commit_tokens": ["Updated", "generated", "game", "to", "use", "controls"], "add_tokens": "event :confirmation do", "del_tokens": "event :on_up , KbEscape , KbSpace , Gosu :: GpButton0 do", "commit_type": "update"}
{"commit_tokens": ["Add", "VersionChecker#should_check?", "helper", "and", "use"], "add_tokens": "def self . should_check? ( target ) @check_list ||= ALL_TARGETS @check_list . include? ( target ) end if should_check? ( GEM_TARGET ) if should_check? ( FEDORA_TARGET ) if should_check? ( KOJI_TARGET ) if should_check? ( GIT_TARGET ) if should_check? ( YUM_TARGET ) if should_check? ( BODHI_TARGET )", "del_tokens": "@check_list ||= ALL_TARGETS if @check_list . include? ( GEM_TARGET ) if @check_list . include? ( FEDORA_TARGET ) if @check_list . include? ( KOJI_TARGET ) if @check_list . include? ( GIT_TARGET ) if @check_list . include? ( YUM_TARGET ) if @check_list . include? ( BODHI_TARGET )", "commit_type": "add"}
{"commit_tokens": ["added", "method", "and", "tests", "for", "specifying", "queue", "namespace"], "add_tokens": "# Supply an optional queue namespace to avoid queue naming conflicts and # allow easy identification of queues. It will prefix the queue name with # the namesapce followed by a colon, e.g. \"service:module:consumer_class\". # The namespace will be forced to lower case and stripped of any non # word or \":\" characters def queue_namespace ( namespace ) @_queue_namespace = namespace . to_s . downcase . gsub ( / \\W |: / , \"\" ) + \":\" end queue_name . gsub! ( / ([^A-Z:])([A-Z]) / ) { \"#{$1}_#{$2}\" } queue_name = queue_name . prepend ( @_queue_namespace ) if @_queue_namespace return queue_name . downcase", "del_tokens": "queue_name . gsub ( / ([^A-Z:])([A-Z]) / ) { \"#{$1}_#{$2}\" } . downcase", "commit_type": "add"}
{"commit_tokens": ["Move", "with_self", "open", "-", "with", "-", "block", "helper", "to", "common", "module", "from", "posix", "semaphore", "implementation", "."], "add_tokens": "require 'process_shared/semaphore' include ProcessShared :: Semaphore", "del_tokens": "require 'process_shared/with_self' include ProcessShared :: WithSelf # With no associated block, open is a synonym for # Semaphore.new. If the optional code block is given, it will be # passed +sem+ as an argument, and the Semaphore object will # automatically be closed when the block terminates. In this # instance, Semaphore.open returns the value of the block. # # @param [Integer] value the initial semaphore value def self . open ( value = 1 , & block ) new ( value ) . with_self ( & block ) end", "commit_type": "move"}
{"commit_tokens": ["Added", "root_dir", "method", "and", "fixed", "a", "minor", "bug", "with", "the", "file", "scanner", "that", "caused", "/", "s", "to", "be", "duplicated", "."], "add_tokens": "filter = ( path . to_s + ( recursive ? '/**/*' : '/*' ) ) . gsub ( '//' , '/' ) # A mostly platform agnostic call to get root volumes def self . root_dirs begin ` wmic logicaldisk get name ` . split ( \"\\n\" ) . map { | m | m . strip } [ 1 .. - 1 ] . reject { | r | r == '' } rescue ` ls / ` end end FILE_SIZES = {", "del_tokens": "filter = path . to_s + ( recursive ? '/**/*' : '/*' ) FILE_SIZES = {", "commit_type": "add"}
{"commit_tokens": ["Add", "Inet", "module", "to", "Arel", "Nodes", "to", "capsulate", "inet", "functionality"], "add_tokens": "module Inet class ContainsEquals < Arel :: Nodes :: Binary def operator :\" >>= \" end class ContainedWithin < Arel :: Nodes :: Binary def operator :<< end class ContainedWithinEquals < Arel :: Nodes :: Binary def operator :\" <<= \" end", "del_tokens": "class ContainsEquals < Arel :: Nodes :: Binary def operator :\" >>= \" end class ContainedWithin < Arel :: Nodes :: Binary def operator :<< end class ContainedWithinEquals < Arel :: Nodes :: Binary def operator :\" <<= \"", "commit_type": "add"}
{"commit_tokens": ["fix", "wording", "of", "dependencies", "specs"], "add_tokens": "it \"raises an ArgumentError if a name argument is provided but it is nil\" do it \"raises an ArgumentError if a name and constraint argument are provided but the name is nil\" do", "del_tokens": "it \"raises an ArgumentError if one argument is provided\" do it \"raises an ArgumentError if one of the arguments provided is nil\" do", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "error", "catching", "logic", "to", "the", "version", "checking", "call"], "add_tokens": "attr_reader :taskrc , :version , :rc_location , :data_location @rc_location = rc # TODO: use taskrc @data_location = rc . chomp ( 'rc' ) # Check TW version, and throw warning begin @version = check_version rescue warn \"Couldn't find the task version\" private def check_version raw_version = Open3 . capture2 ( \"task rc.data.location=#{@data_location} _version\" ) gem_version = Gem :: Version . new ( raw_version [ 0 ] . chomp ) if gem_version < Gem :: Version . new ( '2.4.0' ) warn \"#{@version} is untested\" end gem_version end", "del_tokens": "attr_reader :taskrc , :version # Check TW version, and throw warning raw_version = Open3 . capture2 ( \"task _version\" ) @version = Gem :: Version . new ( raw_version [ 0 ] . chomp ) # @version = Gem::Version.new(`task _version`.chomp) if @version < Gem :: Version . new ( '2.4.0' ) warn \"#{@version} is untested\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "unwrite", "cache", "op", "for", "transactions"], "add_tokens": "unless @transaction_stack . last . include? ( obj ) @transaction_stack . last . delete ( obj ) # Don't include the cache buffers in output of other objects that # reference Cache.", "del_tokens": "unless @transaction_stack . last . pop == obj", "commit_type": "fix"}
{"commit_tokens": ["use", "common", "helpers", "from", "test_guard"], "add_tokens": "require 'test_guard' TestGuard . load_simplecov ( )", "del_tokens": "require 'minitest/unit' require 'turn' require 'turn/reporter' require 'turn/reporters/outline_reporter' Turn . config . framework = :minitest Turn . config . format = :outline module Turn class OutlineReporter < Reporter def start_test ( test ) @stdout = StringIO . new @stderr = StringIO . new name = naturalized_name ( test ) io . print \" %-57s\" % name @stdout . rewind @stderr . rewind $stdout = @stdout $stderr = @stderr unless $DEBUG end end end begin require 'simplecov' SimpleCov . start do add_filter \"/test/\" end rescue Exception => ex end class MiniTest :: Unit :: TestCase # minitest assert_throws doesn't seem to work properly def assert_throws ( clazz , msg = nil , & block ) begin yield rescue Exception => ex puts \"#{ex.class}: #{ex.message}\" puts ex . backtrace . join ( \"\\n\" ) if clazz . to_s == ex . class . name then if msg . nil? return elsif msg == ex . message then return end end end flunk ( \"Expected #{mu_pp(clazz)} to have been thrown\" ) end end", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "fix", "for", "Ambiguous", "attribute", "id", "on", "update", "."], "add_tokens": "klass = relation_klass ( first ) value = klass . where ( \"#{klass.table_name}.#{relation_primary_key(first)} = ?\" , foreign_key_value ) . first if foreign_key_value", "del_tokens": "value = relation_klass ( first ) . where ( \"#{relation_primary_key(first)} = ?\" , foreign_key_value ) . first if foreign_key_value", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "remove", "#default_size", "call", "and", "replace", "with", "constant"], "add_tokens": "# Default terminal size # # @api public DEFAULT_SIZE = [ 27 , 80 ] . freeze size || DEFAULT_SIZE # @return [nil, Array[Integer, Integer]] size = output . winsize size if nonzero_column? ( size [ 1 ] )", "del_tokens": "size || default_size # @return [Array[Integer, Integer]] try_io_console { | size | size if nonzero_column? ( size [ 1 ] ) } end # Attempts to load native console extension # # @return [Boolean, Array] # # @api private def try_io_console yield output . winsize # Default terminal size # # @api public def default_size [ @env [ 'LINES' ] . to_i . nonzero? || 27 , @env [ 'COLUMNS' ] . to_i . nonzero? || 80 ] end", "commit_type": "change"}
{"commit_tokens": ["Moved", "version", "string", "to", "separate", "file", "."], "add_tokens": "require 'bibtex/version'", "del_tokens": "# The current library version. VERSION = '1.1.0'", "commit_type": "move"}
{"commit_tokens": ["Adds", "more", "headers", "to", "ignore"], "add_tokens": "location last - modified pragma set - cookie strict - transport - security transfer - encoding vary x - cache x - content - security - policy x - content - type - options x - frame - options x - language x - permitted - cross - domain - policies x - pingback x - varnish x - webkit - csp x - xss - protection", "del_tokens": "location last - modified pragma set - cookie vary x - cache x - content - type - options x - language x - pingback x - varnish", "commit_type": "add"}
{"commit_tokens": ["Allowing", "you", "to", "pass", "a", "range", "option", "to", "column", "definition", "."], "add_tokens": "normalize_opts ( opts ) def normalize_opts ( opts ) raise DefinitionError . new ( \"A column must have a name.\" ) unless opts [ :name ] raise DefinitionError . new ( \"A column must have a type.\" ) unless opts [ :type ] if opts [ :range ] opts [ :min ] = opts [ :range ] . min opts [ :max ] = opts [ :range ] . max opts . delete ( :range ) end", "del_tokens": "check_opts def check_opts raise DefinitionError . new ( \"A column must have a name.\" ) unless @name raise DefinitionError . new ( \"A column must have a type.\" ) unless @column_type", "commit_type": "allow"}
{"commit_tokens": ["Add", "test", "for", "component", "fixture", "pages"], "add_tokens": "expect ( page ) . to have_selector ( 'h3 a[href=\"/component-guide/test-component-with-params/another_fixture\"]' , text : 'Another fixture' ) it 'creates a page for each fixture' do visit '/component-guide/test-component-with-params/another_fixture' expect ( body ) . to include ( 'How to call this example' ) expect ( body ) . to include ( 'How it looks' ) expect ( body ) . to include ( 'test_component_parameter: &quot;A different value&quot;' ) expect ( page ) . to have_selector ( '.component-guide-preview .test-component-with-params' , text : 'A different value' ) end", "del_tokens": "expect ( page ) . to have_selector ( 'h3' , text : 'Another fixture' )", "commit_type": "add"}
{"commit_tokens": ["created", "specification", "tests", "for", "Contributor", "and", "NormalContributor"], "add_tokens": "# @param [String] pretty_name pretty name of contributor # @param [String] file_as file as of contributor # @param [String] role contributor role # @return [Contributor] #", "del_tokens": "# @param [String] pretty_name pretty name of contributor # @param [String] file_as file as of contributor # TODO add tests # # TODO add tests #", "commit_type": "create"}
{"commit_tokens": ["Adding", "support", "for", "passing", "procs", "or", "strings", "to", "graphql_enum"], "add_tokens": "class EnumTypeHash extend Forwardable attr_accessor :hash def initialize @hash = { } . with_indifferent_access end def [] ( attribute ) type = hash [ attribute ] type = type . call if type . is_a? ( Proc ) type = type . constantize if type . is_a? ( String ) type end def_delegators :@hash , :[]= , :include? , :keys end @_graphql_enum_types ||= EnumTypeHash . new", "del_tokens": "@_graphql_enum_types ||= { } . with_indifferent_access", "commit_type": "add"}
{"commit_tokens": ["FIXED", ":", "Classes", "that", "include", "Familia", "now", "use", "the", "suffix", "defined", "for", "that", "class", "."], "add_tokens": "# idx can be a value or an Array of values used to create the index. # We don't enforce a default suffix; that's left up to the instance. # A nil +suffix+ will not be included in the key. def rediskey idx , suffix = self . suffix # +suffix+ is the value to be used at the end of the redis key # + ignored+ is literally ignored. It's around to maintain # consistency with the class version of this method. # (RedisObject#rediskey may call against a class or instance). def rediskey ( suffix = nil , ignored = nil ) Familia . info \"[#{self.class}] something was ignored\" unless ignored . nil?", "del_tokens": "opts [ :suffix ] ||= nil # idx can be a value or an Array of values used to create the index. def rediskey idx , suffix = nil def rediskey ( suffix = nil )", "commit_type": "fix"}
{"commit_tokens": ["Add", "errors", "and", "refresh", "to", "data", "tables", "request", "."], "add_tokens": "# TODO: Fill in once user model is defined.", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "Cheffish", ".", "get_private_key", "typo"], "add_tokens": "def self . get_private_key ( name , config = profiled_config )", "del_tokens": "def self . get_private_key ( name , config = profiled_chef_config )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "noisy", "nil", "in", "arel", "construction", "for", "report"], "add_tokens": "@selects . push column_option . custom_select if column_option . present? && column_option . custom_select . present?", "del_tokens": "@selects . push column_option . custom_select if column_option . present?", "commit_type": "fix"}
{"commit_tokens": ["add", "to_chunk", "(", "s", ")", "methods", "to", "String"], "add_tokens": "def initialize ( size_t , chunk_ptr , dumper , head : false ) # head: if fake chunk in main_arena @head = head if head # create var only if need if head # no need to read size if is bin return @data = dump ( @base + size_t * 2 , size_t * 4 )", "del_tokens": "def initialize ( size_t , chunk_ptr , dumper , head : false ) # if fake chunk in main_arena @head = head if head # no need to read if is bin @data = dump ( @base + size_t * 2 , size_t * 4 ) return", "commit_type": "add"}
{"commit_tokens": ["added", "require", "and", "use", "explicit", "namespace", "for", "Bunny"], "add_tokens": "require 'bunny' @connection ||= :: Bunny . new ( url ) . tap ( & :start )", "del_tokens": "@connection ||= Bunny . new ( url ) . tap ( & :start )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "libgit2", "development", "HEAD"], "add_tokens": "require 'rugged/objects'", "del_tokens": "require 'rugged/tree'", "commit_type": "update"}
{"commit_tokens": ["move", "IPN", "to", "a", "notifications_controller"], "add_tokens": "post :ipn , to : 'notifications#create'", "del_tokens": "post :ipn", "commit_type": "move"}
{"commit_tokens": ["Add", "error", "handling", "for", "feeds", "that", "return", "status", "other", "than", "200"], "add_tokens": "@feed_requester404 = Mako :: FeedRequester . new ( feed_url : 'https://jonathanpike.net/noop' ) def test_fetch_failure_faraday_error assert_includes Mako . errors . messages , \"Could not complete request to #{@not_ok_feed_requester.feed_url}.\" end end def test_fetch_failure_404 VCR . use_cassette ( 'feed_404' ) do @feed_requester404 . fetch refute @feed_requester404 . ok? assert_includes Mako . errors . messages , \"Request to #{@feed_requester404.feed_url} returned 404.\"", "del_tokens": "def test_fetch_failure_faraday_object", "commit_type": "add"}
{"commit_tokens": ["Allow", "passing", "access", "token", "details", "to", "example", ".", "rb"], "add_tokens": "if ARGV . length == 0 # If not passed any command line arguments, open a browser and prompt the # user for the OAuth verifier. request_token = client . request_token puts \"Opening #{request_token.authorize_url}\" system \"open #{request_token.authorize_url}\" puts \"Enter the oauth_verifier: \" oauth_verifier = gets . strip access_token = client . init_access_token ( :oauth_verifier => oauth_verifier ) puts \"Access token: #{access_token.token} secret: #{access_token.secret}\" elsif ARGV . length == 2 # Otherwise assume the arguments are a previous access token and secret. access_token = client . set_access_token ( ARGV [ 0 ] , ARGV [ 1 ] ) else # Script must be passed 0 or 2 arguments raise \"Usage: #{$0} [ token secret ]\" end", "del_tokens": "request_token = client . request_token puts \"Opening #{request_token.authorize_url}\" system \"open #{request_token.authorize_url}\" puts \"Enter the oauth_verifier: \" oauth_verifier = gets . strip client . init_access_token ( :oauth_verifier => oauth_verifier )", "commit_type": "allow"}
{"commit_tokens": ["make", "get_properties", "return", "all", "properties", "instead", "of", "the", "first", "100"], "add_tokens": "properties_response = get_all_properties ( properties_request ) properties_response . each do | object_content | properties = { :obj => object_content . obj } object_specs = get_all_properties ( retrieve_properties_request ) def get_all_properties ( request ) response = @service . retrievePropertiesEx ( request ) . returnval result = [ ] loop do response . objects . each { | object_content | result << object_content } break if response . token . nil? request = ContinueRetrievePropertiesExRequestType . new ( @service_content . propertyCollector , response . token ) response = @service . continueRetrievePropertiesEx ( request ) . returnval end result end", "del_tokens": "properties_response = @service . retrievePropertiesEx ( properties_request ) properties_response . returnval . objects . each do | object_content | properties = { :obj => object_content . obj } retrieve_properties_response = @service . retrievePropertiesEx ( retrieve_properties_request ) object_specs = retrieve_properties_response . returnval . objects", "commit_type": "make"}
{"commit_tokens": ["adding", ":", "verify_peer", "and", ":", "ca_path", "for", "handling", "SSL", "configuration", ";", "also", "added", "individual", "methods", "for", "configuration", "options"], "add_tokens": "def initialize ( configuration = { } ) def store_url = ( store_url ) @connection . store_url = store_url end def username = ( username ) @connection . username = username end def api_key = ( api_key ) @connection . api_key = api_key end def verify_peer = ( verify = true ) @connection . verify_peer = verify end def ca_file = ( path ) @connection . ca_file = path end def get_resource ( result ) end def get_collection ( result ) end", "del_tokens": "def initialize ( configuration )", "commit_type": "add"}
{"commit_tokens": ["removing", "use", "of", "%i", "to", "create", "an", "array", "of", "symbols"], "add_tokens": "READ_ONLY_ATTRIBUTES = [ :uuid , :etag , :uri , :token ] ATTRIBUTES = [ :supplier_name , :address , :city_state , :zipcode , :national_identifier , :description ]", "del_tokens": "READ_ONLY_ATTRIBUTES = %i[ uuid etag uri token ] ATTRIBUTES = %i[ supplier_name address city_state zipcode national_identifier description ]", "commit_type": "remove"}
{"commit_tokens": ["Fix", "backwards", "-", "compatibility", "when", "caching", "empty", "arrays"], "add_tokens": "# Return true if the result is an array and it is empty. @result . is_a? ( Array ) && @result . empty? elsif is_empty? && ! AridCache . raw_with_options # deprecated behaviour lazy_cache . ids = @result lazy_cache . count = 0 lazy_cache . klass = result_klass lazy_cache", "del_tokens": "# Return true if the result is an enumerable and it is empty. is_enumerable? && @result . empty?", "commit_type": "fix"}
{"commit_tokens": ["moved", "schema", "validation", "into", "it", "s", "own", "test", ".", "Added", "warning", "for", "when", "schema", "validation", "is", "not", "taking", "place"], "add_tokens": "def test_schema_validation #this will only run if there is an environment variable set to point to the #schema location. Cant be pushing the schema to github ya know . if ENV [ 'CCR_SCHEMA' ] collection_fixtures ( 'records' , '_id' ) Record . all . each do | record | doc = Nokogiri :: XML ( HealthDataStandards :: Export :: CCR . export ( record ) ) xsd = Nokogiri :: XML :: Schema ( open ( ENV [ 'CCR_SCHEMA' ] ) ) assert_equal [ ] , xsd . validate ( doc ) end else warn \"warning: CCR schema validation not taking place. Set CCR_SCHEMA environment variable to location of CCR schema for this to take place\" end end", "del_tokens": "#this will only run if there is an environment variable set to point to the #schema location. Cant be pushing the schema to github ya know . if ENV [ 'CCR_SCHEMA' ] xsd = Nokogiri :: XML :: Schema ( open ( ENV [ 'CCR_SCHEMA' ] ) ) assert_equal [ ] , xsd . validate ( doc ) end", "commit_type": "move"}
{"commit_tokens": ["Remove", "spurious", "require", "of", "AR", "."], "add_tokens": "#require 'active_record'", "del_tokens": "require 'active_record'", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "simple", "example", "file", "and", "read", "me"], "add_tokens": "SYMBOL_TO_POS . keys . each do | pos |", "del_tokens": "Relation :: SYMBOL_TO_POS . keys . each do | pos |", "commit_type": "add"}
{"commit_tokens": ["added", "ability", "to", "get", "OOF", "settings"], "add_tokens": "# Gets a mailbox user's Out of Office (OOF) settings and messages. # @see http://msdn.microsoft.com/en-us/library/aa563465.aspx def get_user_oof_settings ( mailbox ) resp = invoke ( \"#{NS_EWS_MESSAGES}:GetUserOofSettingsRequest\" , :soap_action => action ) do | root | build! ( root ) do mailbox! ( root , mailbox [ :mailbox ] , NS_EWS_TYPES ) end parse! ( resp ) # Sets a mailbox user's Out of Office (OOF) settings and message. # @see http://msdn.microsoft.com/en-us/library/aa580294.aspx def set_user_oof_settings ( mailbox , oof_state , ext_audience , dt_start , dt_end , int_msg , ext_mg ) resp = invoke ( \"#{NS_EWS_MESSAGES}:SetUserOofSettings\" , :soap_action => action ) do | root | build! ( root ) parse! ( resp )", "del_tokens": "def get_user_oof_settings resp = invoke ( \"#{NS_EWS_MESSAGES}:GetUserOofSettings\" , :soap_action => action ) do | get_user_oof_settings | build_get_user_oof_settings! ( get_user_oof_settings ) parse_get_user_oof_settings ( resp ) def set_user_oof_settings resp = invoke ( \"#{NS_EWS_MESSAGES}:SetUserOofSettings\" , :soap_action => action ) do | set_user_oof_settings | build_set_user_oof_settings! ( set_user_oof_settings ) parse_set_user_oof_settings ( resp )", "commit_type": "add"}
{"commit_tokens": ["moved", "specs", "so", "the", "autotest", "filemapping", "works", "better"], "add_tokens": "require File . dirname ( __FILE__ ) + '/../../spec_helper'", "del_tokens": "require File . dirname ( __FILE__ ) + '/spec_helper'", "commit_type": "move"}
{"commit_tokens": ["Add", "configurable", "answer", "timeout", "for", "fast", "UT", "-", "ability"], "add_tokens": "# @option opts [Fixnum] timeout (60) # The number of seconds to wait for an answer before notifying # the caller of a timeout and forgetting about the request. def initialize ( host , realm , opts = { } ) @answer_timeout = opts . fetch ( :timeout , 60 ) # Time this request out if no answer is received Concurrent :: timer ( @answer_timeout ) do", "del_tokens": "def initialize ( host , realm ) # Time this request out after 60 seconds Concurrent :: timer ( 60 ) do", "commit_type": "add"}
{"commit_tokens": ["making", "it", "possible", "to", "pass", "the", "full", "path", "to", "the", "yaml", "file", "."], "add_tokens": "require \"yaml\" rules = \"#{options[:report]}.yml\" end", "del_tokens": "rules = \"report-#{options[:report]}.yml\" end", "commit_type": "make"}
{"commit_tokens": ["moved", "constants", "to", "lib", "/", "twittbot", "/", "defaults", ".", "rb"], "add_tokens": "require 'twittbot/defaults' method_option :template_dir , type : :string , aliases : '-t' , desc : 'Specifies the template directory to use' , default : Twittbot :: TEMPLATE_DIR require 'twittbot/generators/twittbot/app/app_generator'", "del_tokens": "require 'twittbot/generators/twittbot/app/app_generator' method_option :template_dir , type : :string , aliases : '-t' , desc : 'Specifies the template directory to use' , default : Twittbot :: Generators :: AppGenerator :: TEMPLATE_DIR", "commit_type": "move"}
{"commit_tokens": ["Improve", "method", "to", "initialize", "metadata", "objects", "."], "add_tokens": "# TODO: Add test coverage for this class. class << self attr_reader :fields def field ( name , type , * options ) @fields ||= { } @fields [ name ] = DropboxApi :: Metadata :: Field . new ( type , options ) attr_reader name # Takes in a hash containing all the attributes required to initialize the # object. # # Each hash entry should have a key which identifies a field and its value, # so a valid call would be something like this: # # DropboxApi::Metadata::File.new({ # \"name\" => \"a.jpg\", # \"path_lower\" => \"/a.jpg\", # \"path_display\" => \"/a.jpg\", # \"id\" => \"id:evvfE6q6cK0AAAAAAAAB2w\", # \"client_modified\" => \"2016-10-19T17:17:34Z\", # \"server_modified\" => \"2016-10-19T17:17:34Z\", # \"rev\" => \"28924061bdd\", # \"size\" => 396317 # }) # # @raise [ArgumentError] If a required attribute is missing. # @param metadata [Hash] self . class . fields . keys . each do | field_name | self [ field_name ] = metadata [ field_name . to_s ] private def []= ( name , value ) instance_variable_set \"@#{name}\" , self . class . fields [ name ] . cast ( value ) rescue ArgumentError raise ArgumentError , \"Invalid value for `#{name}`: #{value.inspect}.\" end", "del_tokens": "def self . field ( name , type , * options ) @fields ||= { } @fields [ name ] = DropboxApi :: Metadata :: Field . new ( type , options ) attr_reader name end def self . each_field @fields . each do | name , field | yield name , field self . class . each_field do | name , field | instance_variable_set \"@#{name}\" , field . cast ( metadata [ name . to_s ] )", "commit_type": "improve"}
{"commit_tokens": ["Added", "a", "new", "path", "to", "the", "view_path", "relative", "to", "the", "client", "app", "."], "add_tokens": "view_matcher_format = \":action{.:locale,}{.:formats,}{.:handlers,}\" bootstrap_admin_app_viewpath = \"#{Rails.root}/app/views/#{BootstrapAdmin.admin_namespace}/defaults\" self . view_paths << ActionView :: FileSystemResolver . new ( bootstrap_admin_app_viewpath , view_matcher_format ) self . view_paths << ActionView :: FileSystemResolver . new ( bootstrap_admin_viewpath , view_matcher_format )", "del_tokens": "self . view_paths << ActionView :: FileSystemResolver . new ( bootstrap_admin_viewpath , \":action{.:locale,}{.:formats,}{.:handlers,}\" )", "commit_type": "add"}
{"commit_tokens": ["Change", "search_type", "to", "make", "per_page", "work", "correctly", "."], "add_tokens": "search_type = count ? 'count' : 'query_then_fetch'", "del_tokens": "search_type = count ? 'count' : 'dfs_query_and_fetch' puts @options . body", "commit_type": "change"}
{"commit_tokens": ["Uses", "more", "robust", "class", "loading", "everywhere", "."], "add_tokens": "result_class = class_name . constantize", "del_tokens": "result_class = Kernel . const_get class_name", "commit_type": "use"}
{"commit_tokens": ["Move", "ellipsis", ".", "rb", "into", "rules", "directory"], "add_tokens": "require 'pragmatic_segmenter/rules/ellipsis'", "del_tokens": "require 'pragmatic_segmenter/ellipsis'", "commit_type": "move"}
{"commit_tokens": ["Added", "listen", "for", "auto", "-", "reload", "in", "dev", "mode"], "add_tokens": "class << self ; attr_accessor :mode , :path , :cache , :favicon , :robots , :manifest , :bundle , :images , :listener , :debug ; end # Reset the assets on change in development mode @listener = true :: Asset :: Util . setup! # Run a listener to automatically reload the assets on change if :: Asset . listener and :: Asset . mode == 'development' autoload :Listen , 'listen' if defined? ( Listen ) # Reload assets on change listener = Listen . to ( :: Asset . path ) do | modified , added , removed | :: Asset :: Util . setup! end listener . start end end", "del_tokens": "class << self ; attr_accessor :mode , :path , :cache , :favicon , :robots , :manifest , :bundle , :images , :debug ; end # Load the manifest :: Asset . manifest = :: Asset :: Util . load_manifest # Load the bundle :: Asset . bundle = YAML . load_file ( File . join ( :: Asset . path , 'manifest.yml' ) ) # Load the images :: Asset . images = :: Asset :: Util . load_images", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "provider_spec", "to", "actually", "test", "if", "the", "subscriptions", "called", "the", "right", "thing", "in", "candlepin"], "add_tokens": "Rails . logger . error error . backtrace . join ( \"\\n\" ) render :partial => \"subscriptions\" , :locals => { :provider => @provider } , :status => :bad_request and return", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "double", "click", "user", "action"], "add_tokens": "def double_click_at ( x , y ) scroll_to_visible @driver . sc_double_click_at action_target , x , y , * action_locator_args stall :double_click end # # Used to perform a double click on this view in the remote application # def double_click ( ) double_click_at :center , :center end", "del_tokens": "# # Used to perform a double click on this view in the remote application # def double_click ( ) scroll_to_visible @driver . sc_double_click action_target , * action_locator_args stall :double_click end", "commit_type": "fix"}
{"commit_tokens": ["Updated", "spec", "helper", "to", "use", "codeclimate"], "add_tokens": "require \"codeclimate-test-reporter\" CodeClimate :: TestReporter . start", "del_tokens": "require 'coveralls' Coveralls . wear!", "commit_type": "update"}
{"commit_tokens": ["moving", "the", "gem", "to", "using", "bundler"], "add_tokens": "require 'bundler' Bundler . setup require 'activesupport' require 'active_support/test_case' require 'mysql' require 'activerecord' require 'ruby-debug' :: Debugger . start :: Debugger . settings [ :autoeval ] = true if :: Debugger . respond_to? ( :settings ) require 'logger'", "del_tokens": "require 'test/unit'", "commit_type": "move"}
{"commit_tokens": ["removed", "pagify_pager", "cache", "don", "t", "make", "it", "be", "so", "complicated", "."], "add_tokens": "pagify_pager_create ( self , opts ) . page ( page )", "del_tokens": "attr_reader :pagify_pager def pagify_cache @pagify_cache ||= false end # cleanup cache if turn off cache # NOTE: you would face thread-safety problem if you turn on cache def pagify_cache = bool @pagify_pager = nil unless bool @pagify_cache = bool end pager = if pagify_cache @pagify_pager ||= pagify_pager_create ( self , opts ) pagify_pager . opts = opts pagify_pager else pagify_pager_create ( self , opts ) end pager . page ( page )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "cleanup", "for", "cleanly", "terminated", "actors"], "add_tokens": "__cleanup ExitEvent . new ( @proxy ) rescue ExitEvent => exit_event __handle_exit_event exit_event def __handle_exit_event ( exit_event ) __cleanup ExitEvent . new ( @proxy , exception ) # Handle cleaning up this actor after it exits def __cleanup ( exit_event ) @mailbox . cleanup @links . send_event exit_event end", "del_tokens": "@links . send_event ExitEvent . new ( @proxy ) rescue ExitEvent => event __handle_exit ( event ) def __handle_exit ( exit_event ) @mailbox . cleanup # Report the exit event to all actors we're linked to exit_event = ExitEvent . new ( @proxy , exception ) @links . send_event exit_event", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "we", "always", "have", "a", "minimum", "number", "of", "threads", ".", "resize", "pool", "properly", "."], "add_tokens": "create_thread pt = nil ( ( min - size ) > 0 ? ( min - size ) : 1 ) . times do pt = ActionPool :: Thread . new ( :pool => self , :respond_thread => @respond_to , :a_timeout => @action_timeout , :t_timeout => @thread_timeout , :logger => @logger ) @threads << pt end while ( t = @threads . pop ) do t . stop ( force ) resize if m < size @logger . info ( \"Pool is being resized to stated maximum: #{max}\" ) until ( size <= max ) do t = nil t = @threads . find { | t | t . waiting? } t = @threads . shift unless t", "del_tokens": "@min_threads . times { create_thread } pt = ActionPool :: Thread . new ( :pool => self , :respond_thread => @respond_to , :a_timeout => @action_timeout , :t_timeout => @thread_timeout , :logger => @logger ) @threads << pt @threads . each { | t | t . stop ( force ) } until ( size < 1 ) do @queue << lambda { } sleep ( 0.1 ) resize if m < size @logger . info ( \"Pool is being resized to stated minimum: #{min}\" ) size - min . times do t = @threads . shift", "commit_type": "make"}
{"commit_tokens": ["Add", "basic", "overview", "to", "the", "README", "."], "add_tokens": "\"#{names.first} (#{primary_code})\"", "del_tokens": "\"#{primary_code} (#{names.join('|')})\"", "commit_type": "add"}
{"commit_tokens": ["use", "the", "PLUGIN_NAME", "in", "the", "plugin", "when", "loading", "."], "add_tokens": "capnotify . load_plugin Capnotify :: Plugin :: Message capnotify . load_plugin Capnotify :: Plugin :: Overview capnotify . load_plugin Capnotify :: Plugin :: Details def load_plugin ( mod ) Capistrano . plugin mod :: PLUGIN_NAME , mod get_plugin ( mod :: PLUGIN_NAME ) . init", "del_tokens": "capnotify . load_plugin :capnotify_message , Capnotify :: Plugin :: Message capnotify . load_plugin :capnotify_overview , Capnotify :: Plugin :: Overview capnotify . load_plugin :capnotify_details , Capnotify :: Plugin :: Details def load_plugin ( name , mod ) Capistrano . plugin name , mod get_plugin ( name ) . init", "commit_type": "use"}
{"commit_tokens": ["Updated", "edit", "form", "view", "."], "add_tokens": "VERSION = \"0.4.8\"", "del_tokens": "VERSION = \"0.4.7c\"", "commit_type": "update"}
{"commit_tokens": ["add", "specs", "and", "a", "bunch", "of", "extensions"], "add_tokens": "#require 'madvertise-ext'", "del_tokens": "require 'fileutils' ROOT = \"#{File.dirname(__FILE__)}/../tmp\" require 'madvertise-ext' # setup a fake root config . before ( :all ) { File . directory? ( ROOT ) ? FileUtils . rm_rf ( \"#{ROOT}/*\" ) : FileUtils . mkdir_p ( ROOT ) } config . after ( :all ) { FileUtils . rm_rf ( \"#{ROOT}/*\" ) }", "commit_type": "add"}
{"commit_tokens": ["use", "to_datetime", ";", "fix", "for", "windows", "rss"], "add_tokens": "if debug? ## turn on logging for sql too ActiveRecord :: Base . logger = Logger . new ( STDOUT ) end ## fix: ## weird rss exception error on windows w/ dates # e.g. /lib/ruby/1.9.1/rss/rss.rb:37:in `w3cdtf': wrong number of arguments (1 for 0) (ArgumentError) # # move to_datetime to feedutils!! if it works published_at : feed . published? ? feed . published . to_datetime : nil , touched_at : feed . updated? ? feed . updated . to_datetime : nil , built_at : feed . built? ? feed . built . to_datetime : nil , if debug? ## puts \"*** dump feed_attribs:\" ## pp feed_attribs puts \"*** dump feed_attribs w/ class types:\" feed_attribs . each do | key , value | puts \" #{key}: >#{value}< : #{value.class.name}\" end end published_at : item . published? ? item . published . to_datetime : nil , touched_at : item . updated? ? item . updated . to_datetime : nil , if debug? puts \"*** dump item_attribs w/ class types:\" item_attribs . each do | key , value | next if [ :summary , :content ] . include? ( key ) # skip summary n content puts \" #{key}: >#{value}< : #{value.class.name}\" end end", "del_tokens": "published_at : feed . published? ? feed . published : nil , touched_at : feed . updated? ? feed . updated : nil , built_at : feed . built? ? feed . built : nil , published_at : item . published? ? item . published : nil , touched_at : item . updated? ? item . updated : nil ,", "commit_type": "use"}
{"commit_tokens": ["Adding", "Skydrive", "support", "to", "browse_everything"], "add_tokens": "\"gem 'bootstrap-sass'\\ngem 'font-awesome-rails' \\ngem 'skydrive', github:'psu-stewardship/skydrive' ,ref:'e2822df9631598db3782b0a47f49993090c9be02'\" end", "del_tokens": "\"gem 'bootstrap-sass'\\ngem 'font-awesome-rails'\" end", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "possible", "to", "change", "the", "timeout"], "add_tokens": "class << self attr_accessor :timeout end self . timeout = 30 Timeout . timeout ( self . class . timeout ) do", "del_tokens": "TIMEOUT = 30 Timeout . timeout ( TIMEOUT ) do", "commit_type": "make"}
{"commit_tokens": ["Added", "rudimentary", "support", "for", "rotations"], "add_tokens": "To create a transformation with an origin and an X - axis aligned with the parent coordinate system ' s Y - axis ( the Y and Z axes will be chosen arbitrarily ) : translate = Geometry :: Transformation . new ( :origin => [ 4 , 2 ] , :x => [ 0 , 1 , 0 ] ) To create a transformation with an origin , an X - axis aligned with the parent coordinate system ' s Y - axis , and a Y - axis aligned with the parent coordinate system ' s X - axis : translate = Geometry :: Transformation . new ( :origin => [ 4 , 2 ] , :x => [ 0 , 1 , 0 ] , :y => [ 1 , 0 , 0 ] ) attr_reader :x_axis , :y_axis , :z_axis # @option options [Point] :origin Same as :translate # @option options [Point] :move Same as :translate # @option options [Point] :translate Linear displacement # @option options [Rotation] :rotate Rotation # @option options [Vector] :scale Scaling # @option options [Vector] :x X-axis # @option options [Vector] :y Y-axis # @option options [Vector] :z Z-axis if options . key? ( :rotate ) and ( options . key? ( :x ) or options . key? ( :y ) or options . key? ( :z ) ) raise ArgumentError , \"Can't specify rotation and axes at the same time\" end @x_axis = options [ :x ] @y_axis = options [ :y ] @z_axis = options [ :z ] # Returns true if the {Transformation} is the identity transformation", "del_tokens": "# @option options [Point,Array] :translate Linear displacement # @option options [Rotation,Array] :rotate Rotation # @option options [Vector,Array] :scale Scaling", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "separate", "context", "for", "status", "test"], "add_tokens": "context '.status' do it 'returns STOPPED' do stub_lxc ( 'info' , '-n' , 'app' ) { fixture ( 'lxc-info-stopped.txt' ) } subject . status . should eq ( { :state => 'STOPPED' , :pid => '-1' } ) end it 'returns RUNNING' do stub_lxc ( 'info' , '-n' , 'app' ) { fixture ( 'lxc-info-running.txt' ) } subject . status . should eq ( { :state => 'RUNNING' , :pid => '2125' } ) end", "del_tokens": "it 'returns STOPPED status' do stub_lxc ( 'info' , '-n' , 'app' ) { fixture ( 'lxc-info-stopped.txt' ) } subject . status . should eq ( { :state => 'STOPPED' , :pid => '-1' } ) end it 'returns RUNNING status' do stub_lxc ( 'info' , '-n' , 'app' ) { fixture ( 'lxc-info-running.txt' ) } subject . status . should eq ( { :state => 'RUNNING' , :pid => '2125' } )", "commit_type": "use"}
{"commit_tokens": ["made", "associations", "homogenous", "(", "one", "class", "type", "only", ")"], "add_tokens": "def filterClass ( nodes , klass ) wrap ( nodes . select { | node | klass . nil? || node . type == klass . name . underscore } , klass ) end related ( :incoming , types , klass ) related ( :outgoing , types , klass ) def related ( direction , types , klass ) node && self . class . filterClass ( node . send ( direction , types ) , klass ) end", "del_tokens": "node && self . class . wrap ( node . incoming ( types ) , klass ) node && self . class . wrap ( node . outgoing ( types ) , klass )", "commit_type": "make"}
{"commit_tokens": ["use", "access", "denied", "page", "instead", "of", "404", "on", "unpermitted"], "add_tokens": "@pages = @pages . published if params [ :edit ] . to_s != 'true' @page = @pages . find ( params [ :id ] ) if defined? ( EffectiveRoles ) raise Effective :: AccessDenied unless @page . roles_permit? ( current_user )", "del_tokens": "if defined? ( EffectiveRoles ) && ( current_user . respond_to? ( :roles ) rescue false ) @pages = @pages . for_role ( current_user . roles ) end if params [ :edit ] . to_s != 'true' @pages = @pages . published @page = @pages . find ( params [ :id ] ) raise ActiveRecord :: RecordNotFound unless @page", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "where", "a", "nil", "polymorphic", "association", "is", "not", "caught", "when", "checking", "cache"], "add_tokens": "if target_id . nil? mark_association_loaded ( association , nil ) return true end", "del_tokens": "mark_association_loaded ( association , nil ) and return true if target_id . nil?", "commit_type": "fix"}
{"commit_tokens": ["added", "#sub", "and", "#mod_sub", "to", "cryptbuffer", ".", "added", "sample", "implementation", "of", "the", "caesar", "cipher"], "add_tokens": "require 'openssl' tmp = bytes . map do | byte | val = byte . to_bn . mod_sub ( n , mod ) . to_i end CryptBuffer ( tmp ) CryptBuffer ( bytes . map { | byte | byte - n } ) val >= offset ? val : val + offset", "del_tokens": "require 'rubygems' require 'pry' require 'pp' val > offset ? val : val + offset", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "way", "to", "specify", "if", "an", "attribute", "should", "be", "treated", "like", "a", "key"], "add_tokens": "map :id , :key => true , :type => Integer", "del_tokens": "map :id , :type => Integer", "commit_type": "add"}
{"commit_tokens": ["improve", "intra", "-", "wiki", "-", "link", "reformatting", "support"], "add_tokens": "migrated_body . gsub! ( / \\[ \\[ ([ \\w \\s \\. ]*) \\] \\] / ) do | s | if $1 s = $1 t = $1 . dup t . gsub! ( ' ' , '_' ) t . gsub! ( / \\. / , '' ) s = \"[[#{s}|#{t}]]\" end end", "del_tokens": "#migrated_body.gsub!(/\\[\\[([\\w\\s]*)\\]\\]/) do |s| # if $1 # s = \"[[#{$1}|#{$1.gsub(' ', '_')}]]\" # end #end", "commit_type": "improve"}
{"commit_tokens": ["Use", "nokogiri", "because", "it", "deals", "with", "external", "entities", "and", "oga", "doesn", "t"], "add_tokens": "require 'nokogiri' @xmldoc = Nokogiri . XML ( @core . raw_get_content ( 'admin/file' , { :file => 'schema.xml' } ) ) do | config | config . noent # allow parsing of external entitity definitions end", "del_tokens": "require 'oga' @xmldoc = Oga . parse_xml ( @core . raw_get_content ( 'admin/file' , { :file => 'schema.xml' } ) )", "commit_type": "use"}
{"commit_tokens": ["made", "timeout", "in", "client", "optional", "bumped", "version"], "add_tokens": "# some versions of ruby + thrift cause an error if the following is called @client . setInactivityTimeoutPeriod ( timeout ) unless timeout . nil?", "del_tokens": "@client . setInactivityTimeoutPeriod ( timeout )", "commit_type": "make"}
{"commit_tokens": ["Use", "path", "(", "URL", ")", "to", "identify", "pages", "rather", "than", "controller#action"], "add_tokens": "page_identifier = request . path . sub ( / ^ \\/ emulator / , '' ) if ( session [ :_mxit_rails_page ] != page_identifier ) || ( params [ :_mxit_reset ] ) session [ :_mxit_rails_page ] = page_identifier", "del_tokens": "if ( session [ :_mxit_rails_page ] != \"#{controller_name}##{action_name}\" ) || ( params [ :_mxit_reset ] ) session [ :_mxit_rails_page ] = \"#{controller_name}##{action_name}\"", "commit_type": "use"}
{"commit_tokens": ["Use", "built", "in", "faraday", "error", "handling", "."], "add_tokens": "faraday . response :raise_error connection . post ( path ) do | request | request . body = body end . body connection . put ( path ) do | request | request . body = body end . body connection . get ( path ) . body", "del_tokens": "class Error < StandardError ; end parse_response connection . post ( path ) { | request | request . body = body } parse_response connection . put ( path ) { | request | request . body = body } parse_response connection . get ( path ) end def parse_response ( response ) body = response . body raise Error . new ( body . error ) if body . error", "commit_type": "use"}
{"commit_tokens": ["change", "APIFormatter", "to", "ApiFormatter", "for", "autoload"], "add_tokens": "class ApiFormatter < RSpec :: Core :: Formatters :: BaseFormatter", "del_tokens": "class APIFormatter < RSpec :: Core :: Formatters :: BaseFormatter", "commit_type": "change"}
{"commit_tokens": ["Create", "available", "codes", "for", "taxonomy"], "add_tokens": "# Callbacks after_create :set_root # Constants AVAILABLE_CODES = %w( pages )", "del_tokens": "after_create :set_root", "commit_type": "create"}
{"commit_tokens": ["Add", "#clear", "and", "#empty?", "methods", "to", "repository"], "add_tokens": "clear def empty? @repository . empty? end def clear @repository = Hash . new { | hash , key | raise Chewy :: UndefinedAnalysisUnit . new ( @type_name , key ) } end", "del_tokens": "@repository = Hash . new { | hash , key | raise Chewy :: UndefinedAnalysisUnit . new ( type_name , key ) }", "commit_type": "add"}
{"commit_tokens": ["Added", "tolerance", "to", "sqlite3", "concurrent", "updates"], "add_tokens": "parent1 , parent2 = node1 . parent , node2 . parent -> { node1 . move_to_child_with_index ( parent2 , i1 . to_i ) } , -> { node2 . move_to_child_with_index ( parent1 , i2 . to_i ) }", "del_tokens": "-> { node1 . move_to_child_with_index ( node2 . parent , i1 . to_i ) } , -> { node2 . move_to_child_with_index ( node1 . parent , i2 . to_i ) }", "commit_type": "add"}
{"commit_tokens": ["Use", "it", "only", "in", "development"], "add_tokens": "config . mongoid . logger = MongoidColoredLogger :: LoggerDecorator . new ( Rails . logger ) if Rails . env . development?", "del_tokens": "config . mongoid . logger = MongoidColoredLogger :: LoggerDecorator . new ( Rails . logger )", "commit_type": "use"}
{"commit_tokens": ["Add", "the", "#warn?", "method", "to", "the", "logger"], "add_tokens": "false end def warn? return @logger . warn? if @logger false", "del_tokens": "return false", "commit_type": "add"}
{"commit_tokens": ["changed", "can?", "to", "permits?", "in", "records"], "add_tokens": "def permits? ( action , parent = nil )", "del_tokens": "def can? ( action , parent = nil )", "commit_type": "change"}
{"commit_tokens": ["add", "some", "docs", "to", "server", ".", "rb"], "add_tokens": "# Server encapsulates the management of merb daemons # Start a merb server, in either foreground, daemonized or cluster mode # Check to see if there is already a merb running on this port # Killa merb process with a certain signal. # Daemonize a merb server running on a specified port # Remove PID file from the filesystem # Store PID file on the filesystem # if you only specify user, group # will be the same as user.", "del_tokens": "# DOC: Ezra Zygmuntowicz FAILED # DOC: Ezra Zygmuntowicz FAILED # DOC: Ezra Zygmuntowicz FAILED # DOC: Ezra Zygmuntowicz FAILED # DOC: Ezra Zygmuntowicz FAILED # DOC: Ezra Zygmuntowicz FAILED # DOC: Ezra Zygmuntowicz FAILED # DOC # DOC", "commit_type": "add"}
{"commit_tokens": ["Fix", "specs", "for", "Node", "::", "Identity"], "add_tokens": "let ( :object ) { described_class . instance }", "del_tokens": "let ( :object ) { described_class . new }", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "cell", "comparison", "bug", "."], "add_tokens": "self . class == other . class &&", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Allow", "for", "empty", "block", "collects", "in", "TCHash"], "add_tokens": "self . each { | k , v | if block_given? res << yield ( k , v ) else res << [ k , v ] end }", "del_tokens": "self . each { | k , v | res << yield ( k , v ) }", "commit_type": "allow"}
{"commit_tokens": ["Move", "http_connection", "logic", "to", "Util", "refactor", "WebTranslateIt", "::", "Configuration"], "add_tokens": "self . ignore_locales = configuration [ 'ignore_locales' ] . to_a . map { | locale | locale . to_s } WebTranslateIt :: Util . http_connection do | http | request = Net :: HTTP :: Get . new ( api_url ( locale ) ) request . add_field ( 'If-Modified-Since' , last_modification ( file_path ) ) if File . exist? ( file_path ) and ! force response = http . request ( request ) response . body . split end def api_url \"/api/projects/#{api_key}/locales\" end", "del_tokens": "self . ignore_locales = configuration [ 'ignore_locales' ] . to_a . map { | l | l . to_s } http = Net :: HTTP . new ( 'webtranslateit.com' , 443 ) http . use_ssl = true http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE http . read_timeout = 10 request = Net :: HTTP :: Get . new ( \"/api/projects/#{api_key}/locales\" ) response = http . request ( request ) response . body . split", "commit_type": "move"}
{"commit_tokens": ["fix", "header", "test", "and", "add", "notice", "for", "event", "unavailability", "when", "using", "god", "binary"], "add_tokens": "f . puts \"install:\" puts puts unless have_header ( 'linux/netlink.h' ) puts unless have_header ( 'linux/connector.h' ) && have_header ( 'linux/cn_proc.h' ) puts puts puts", "del_tokens": "unless have_header ( 'netlink.h' ) unless have_header ( 'connector.h' ) && have_header ( 'cn_proc.h' )", "commit_type": "fix"}
{"commit_tokens": ["changed", "require_trust", "so", "behavior", "is", "similar", "to", "1", ".", "x", "gem"], "add_tokens": "render :text => \"<body onload=\\\"CCPEVE.requestTrust('http://#{request.host_with_port}')\\\">\" , :layout => false trust_uri = \"http://#{request.host_with_port}/\" head :unauthorized , 'Eve.trustme' => \"#{trust_uri}::#{trust_message}\"", "del_tokens": "deliver_trust_message ( trust_message ) return false trust_uri = \"http://#{request.host}/\" headers [ 'Eve.trustme' ] = \"#{trust_uri}::#{trust_message}\"", "commit_type": "change"}
{"commit_tokens": ["allow", "text", "string", "as", "data"], "add_tokens": "DATA_FORMAT = \"%.7g\" @text = true @n . times { | i | s << line_str ( i ) + \"\\n\" } s + \"e\" def line_str ( i ) @data . map do | a | v = a [ i ] case v when Float , Rational s = data_format % v when Numeric s = v . to_s else s = v . to_s if / \" / =~ s kernel_raise GnuplotError , \"should not include double quotation in data\" elsif / / =~ s s = '\"' + s + '\"' end end s end . join ( \" \" ) end", "del_tokens": "DATA_FORMAT = \"%.5g\" @text = false f = ( [ data_format ] * @data . size ) . join ( \" \" ) + \"\\n\" @n . times { | i | s << f % @data . map { | a | a [ i ] } } s + \"\\ne\"", "commit_type": "allow"}
{"commit_tokens": ["Fix", "collection", "ofresources", "inside", "ResourceGroup"], "add_tokens": "@resources << Resource . new ( sc_resource_handle )", "del_tokens": "res = Resource . new ( sc_resource_handle ) @resources << res", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "close", "to", "previous", "screen", "if", "you", "provide", "a", "custom", "activity"], "add_tokens": "intent = Potion :: Intent . new ( self . activity , activity_class ) intent . setFlags ( Potion :: Intent :: FLAG_ACTIVITY_CLEAR_TOP ) if options . delete ( :close ) if options [ :to_screen ] mp \"You must provide a custom activity if you want to use `close to_screen:`. Open your screen with a custom activity and then `close to_screen: <screen>, activity: <activity>`.\" unless options [ :to_activity ] open options [ :to_screen ] , activity : options [ :activity ] , close : true else self . activity . finish end intent = Potion :: Intent . new ( self . activity , activity_class )", "del_tokens": "intent = Android :: Content :: Intent . new ( self . activity , activity_class ) self . activity . finish intent = Android :: Content :: Intent . new ( self . activity , activity_class )", "commit_type": "add"}
{"commit_tokens": ["changed", "persistant", "index", "to", "create", "an", "index", "directory", "if", "one", "is", "missing", "by", "default"], "add_tokens": "rescue Exception => e @write_lock . release ( ) # obtain write lock raise e", "del_tokens": "rescue IOError => ioe raise ioe", "commit_type": "change"}
{"commit_tokens": ["Fix", "initialization", "when", "not", "running", "inside", "Passenger"], "add_tokens": "# Copyright (c) 2015-2016 Phusion Holding B.V. false", "del_tokens": "# Copyright (c) 2015 Phusion Holding B.V. true", "commit_type": "fix"}
{"commit_tokens": ["fix", "conversion", "of", "keys", "to", "strings"], "add_tokens": "JSON :: Validator . validate! ( self . class . json_schema , stringify_keys ( to_h ) ) private def stringify_keys ( object ) case object when Hash { } . tap do | hash | object . each do | key , value | hash [ key . to_s ] = stringify_keys ( value ) end end when Array object . map do | value | stringify_keys ( value ) end else object end end", "del_tokens": "JSON :: Validator . validate! ( self . class . json_schema , to_h . deep_stringify_keys )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "whitespace", "between", "punctuation", "char", "and", "tag"], "add_tokens": "result = remove_inner_whitespaces ( string ) result = remove_newlines ( result ) result = remove_leading_newlines ( result ) result = clean_tag_borders ( result ) clean_punctuation_characters ( result ) string . gsub ( / \\A \\n + / , '' ) # more asterisks. Ensure that only one whitespace occurs def clean_punctuation_characters ( string ) string . gsub ( / ( \\* \\* |~~|__) \\s ([ \\. ! \\? '\"]) / , \"\\\\1\" . strip + \"\\\\2\" ) end", "del_tokens": "clean_tag_borders ( remove_leading_newlines ( remove_newlines ( remove_inner_whitespaces ( string ) ) ) ) string . gsub ( / \\A \\n \\n ? / , '' ) # more asterisks. Ensure that only one whitespace occur", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "-", "&", "and", "grep", "for", "method", "arrays"], "add_tokens": "alias_method :\" original_ #{ name } \" , name methods = self . send ( :\" original_ #{ name } \" , * args ) methods . instance_variable_set ( '@__awesome_methods__' , self ) # Evil?!", "del_tokens": "methods = super ( * args ) # And now the evil part :-) methods . instance_variable_set ( '@__awesome_methods__' , self )", "commit_type": "implement"}
{"commit_tokens": ["Make", "sure", "proselint", "success", "results", "are", "filtered", "out"], "add_tokens": "proses = result_jsons . select { | _ , prose | prose [ 'data' ] [ 'errors' ] . count > 0 }", "del_tokens": "proses = result_jsons . select { | _ , prose | prose [ 'data' ] [ 'errors' ] . count }", "commit_type": "make"}
{"commit_tokens": ["Using", "AMQPExample", "/", "EMExample", "instead", "of", "generic", "EventedExample", "instance", "now"], "add_tokens": "@_em_spec_exception = SpecTimeoutExceededError . new \"Example timed out\" #noinspection RubyArgCount @opts , @spec_timeout , @example_group_instance , @block = opts , spec_timeout , example_group_instance , block", "del_tokens": "# noinspection RubyArgCount @_em_spec_exception = SpecTimeoutExceededError . new \"Spec timed out\" @opts , @spec_timeout , @example_group_instance , @block = type , opts , spec_timeout , example_group_instance , block", "commit_type": "use"}
{"commit_tokens": ["add", "force", "option", "to", "generator", "template"], "add_tokens": "generate 'curation_concerns:install' , '-f' generate 'geo_concerns:install' , '-f'", "del_tokens": "generate 'curation_concerns:install' generate 'geo_concerns:install'", "commit_type": "add"}
{"commit_tokens": ["Update", "simple", "callers", "of", "cores_per_socket", "to", "cpu_cores_per_socket"], "add_tokens": "hardware [ :numvcpus ] = props [ :PhysicalCPUCount ] hardware [ :cpu_cores_per_socket ] = props [ :CoresPerCPU ] hardware [ :logical_cpus ] = hardware [ :cpu_cores_per_socket ] . to_i * hardware [ :numvcpus ] . to_i", "del_tokens": "hardware [ :numvcpus ] = props [ :PhysicalCPUCount ] hardware [ :cores_per_socket ] = props [ :CoresPerCPU ] hardware [ :logical_cpus ] = hardware [ :cores_per_socket ] . to_i * hardware [ :numvcpus ] . to_i", "commit_type": "update"}
{"commit_tokens": ["changed", "FS_ROOT", "to", "standard", "/", "usr", "/", "local", "/", "freeswitch", "location"], "add_tokens": "FS_ROOT = \"/usr/local/freeswitch\" . freeze # Location of the freeswitch $${base_dir} FS_CONFIG_PATH = File . join ( FS_ROOT , \"conf\" ) . freeze # Freeswitch conf dir FS_DB_PATH = File . join ( FS_ROOT , \"db\" ) . freeze # Freeswitch db dir", "del_tokens": "FS_ROOT = \"/opt/freeswitch\" . freeze # Location of the freeswitch $${base_dir} FS_CONFIG_PATH = \"/opt/freeswitch/conf\" . freeze # Freeswitch conf dir FS_DB_PATH = \"/opt/freeswitch/db\" . freeze # Freeswitch db dir", "commit_type": "change"}
{"commit_tokens": ["added", "constants", "for", "four", "week", "and", "five", "week", "months"], "add_tokens": "FOUR_WEEK_MONTHS = [ 2 , 5 , 8 , 11 ] FIVE_WEEK_MONTHS = [ 3 , 6 , 9 , 12 ] when * FOUR_WEEK_MONTHS when * FIVE_WEEK_MONTHS", "del_tokens": "when 2 , 5 , 8 , 11 when 3 , 6 , 9 , 12", "commit_type": "add"}
{"commit_tokens": ["Use", "migration", "helpers", ".", "Mark", "version", "explicitly", "."], "add_tokens": "require_relative 'migration_helpers' migrate_to :trunk , version : 13 # These next few lines mark the current production migration versions. # Important: # Update and push only just before you are going to migrate in production. migrate_to :metrics , version : 5 migrate_to :cocoadocs , version : 10 migrate_to :stats , version : 1 # Write the resulting schema into a file.", "del_tokens": "# Helper method def foreign_key_delete_cascade source_table , target_table , foreign_key <<-SQL ALTER TABLE #{source_table} DROP CONSTRAINT #{source_table}_#{foreign_key}_fkey; ALTER TABLE #{source_table} ADD FOREIGN KEY (#{foreign_key}) REFERENCES #{target_table} (id) ON DELETE CASCADE ; SQL end # NOTE Set the versions to the ones you want to migrate to. # Trunk migrations. Sequel :: Migrator . run ( DB , File . join ( ROOT , 'migrations/trunk' ) , table : 'schema_info' , version : 13 ) [ \"metrics\" , \"cocoadocs\" , \"stats\" ] . each do | db | Sequel :: Migrator . run ( DB , File . join ( ROOT , \"migrations/#{db}\" ) , # This enables us to have separate migrations # for each app. table : \"schema_info_#{db}\" , version : Dir . glob ( \"migrations/#{db}/*\" ) . count + 1 ) end", "commit_type": "use"}
{"commit_tokens": ["Added", "ShipConfirmResponse", "for", "returning", "shipping", "digest"], "add_tokens": "xml = REXML :: Document . new ( response ) success = response_success? ( xml ) message = response_message ( xml ) if success xml . elements . each ( '/*/ShipmentConfirmResponse' ) do | confirm_response | digest = confirm_response . get_text ( 'ShipmentDigest' ) . to_s end end", "del_tokens": "#rates = [] #xml = REXML::Document.new(response) #success = response_success?(xml) #message = response_message(xml) #if success # rate_estimates = [] # xml.elements.each('/*/RatedShipment') do |rated_shipment| # service_code = rated_shipment.get_text('Service/Code').to_s # days_to_delivery = rated_shipment.get_text('GuaranteedDaysToDelivery').to_s.to_i # delivery_date = days_to_delivery >= 1 ? days_to_delivery.days.from_now.strftime(\"%Y-%m-%d\") : nil # rate_estimates << RateEstimate.new(origin, destination, @@name, # service_name_for(origin, service_code), # :total_price => rated_shipment.get_text('TotalCharges/MonetaryValue').to_s.to_f, # :currency => rated_shipment.get_text('TotalCharges/CurrencyCode').to_s, # :service_code => service_code, # :packages => packages, # :delivery_range => [delivery_date]) # end #end", "commit_type": "add"}
{"commit_tokens": ["add", "specs", "around", "equivalence", "equality", "and", "comparisons", "."], "add_tokens": "raise ArgumentError , \"No Unit Specified\" raise ArgumentError , \"Temperatures must not be less than absolute zero\" if self . is_temperature? && self . base_scalar < 0 raise NoMethodError , \"undefined method `<=>' for #{self.base_scalar.inspect}\" raise ArgumentError , \"Incompatible Units (#{self.units} !~ #{other.units})\" unless self =~ other # Units of incompatible types are not equal, except when they are both zero and neither is a temperature # Equality checks can be tricky since round off errors may make essentially equivalent units # appear to be different. return false unless self =~ other raise ArgumentError , \"Power out of range (-20 < net power of a unit < 20)\" if vector . any? { | x | x . abs >= 20 } raise ( ArgumentError , \"'#{passed_unit_string}' Unit not recognized\" ) unless us . empty?", "del_tokens": "raise ArgumentError , \"No Unit Specified (#{options.first})\" raise ArgumentError , \"Temperature out of range\" if self . is_temperature? && self . base_scalar < 0 raise NoMethodError , \"undefined method `<=>' for #{self.base_scalar.inspec}\" raise ArgumentError , \"Incompatible Units (#{self.units} !=~ #{other.units})\" unless self =~ other raise ArgumentError , \"Incompatible Units\" unless self =~ other raise ( ArgumentError , \"'#{passed_unit_string}' Unit not recognized #{us.inspect}\" ) unless us . empty?", "commit_type": "add"}
{"commit_tokens": ["Use", "invalid?", "instead", "of", "!", "...", "valid?"], "add_tokens": "raise InteractionInvalid if outcome . invalid?", "del_tokens": "unless outcome . valid? raise InteractionInvalid end", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "we", "wait", "for", "the", "process", "to", "return"], "add_tokens": "env = { 'PS4' => Xtrace . ps4 } stdin , stdout , stderr , wait_thr = Open3 . popen3 ( env , @filename ) exit_status = wait_thr . value # block until process returns @output = stderr . dup", "del_tokens": "command = \"PS4='#{Xtrace.ps4}' #{@filename}\" _ , _ , @output = Open3 . popen3 ( command )", "commit_type": "make"}
{"commit_tokens": ["upgrade", "to", "use", "new", "redis"], "add_tokens": "@redis = Redis . new ( :host => host , :port => port , :namespace => :resque ) @redis ||= Redis . new ( :host => 'localhost' , :port => 6379 , :namespace => :resque ) redis . keys ( \"*\" ) queue . join ( ':' )", "del_tokens": "@redis = Redis . new ( :host => host , :port => port ) @redis ||= Redis . new ( :host => 'localhost' , :port => 6379 ) redis . keys ( \"resque:*\" ) \"resque:#{queue.join(':')}\"", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "favorite", "/", "unfavorite", "when", "used", "with", "cache"], "add_tokens": "inc_cache ( favoritable , scope ) if ActsAsFavoritor . configuration . cache dec_cache ( favoritable , scope ) if ActsAsFavoritor . configuration . cache def inc_cache ( favoritable , scope ) def dec_cache ( favoritable , scope )", "del_tokens": "inc_cache ( scope ) if ActsAsFavoritor . configuration . cache dec_cache ( scope ) if ActsAsFavoritor . configuration . cache def inc_cache ( scope ) def dec_cache ( scope )", "commit_type": "fix"}
{"commit_tokens": ["add", "clean", "version", "of", "agarrow", "s", "mandrill_valid", "branch"], "add_tokens": "recognizes :spamassassin_threshold , :mandrill_webhook_key , :mandrill_webhook_url @mandrill_webhook_key = options [ :mandrill_webhook_key ] @mandrill_webhook_url = options [ :mandrill_webhook_url ] end # Returns whether a request originates from Mandrill. # # @param [Hash] params the content of Mandrill's webhook # @return [Boolean] whether the request originates from Mailgun # @raise [IndexError] if the request is missing parameters # @see http://help.mandrill.com/entries/23704122-Authenticating-webhook-requests def valid? ( params ) if @mandrill_webhook_url && @mandrill_webhook_key params . fetch ( 'env' ) . fetch ( 'HTTP_X_MANDRILL_SIGNATURE' ) == signature ( params ) else super end private def signature ( params ) data = @mandrill_webhook_url params . sort . each do | key , value | unless key == 'env' data += \"#{key}#{value}\" end end Base64 . encode64 ( OpenSSL :: HMAC . digest ( 'sha1' , @mandrill_webhook_key , data ) ) . strip end", "del_tokens": "recognizes :spamassassin_threshold", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "extract", "the", "headers", "from", "a", "document", "including", "their", "id"], "add_tokens": "test \"extracts headers with text, level and generated id\" do document = Govspeak :: Document . new %{ # Big title ### Small subtitle ## Medium title } assert_equal [ Govspeak :: Header . new ( 'Big title' , 1 , 'big-title' ) , Govspeak :: Header . new ( 'Small subtitle' , 3 , 'small-subtitle' ) , Govspeak :: Header . new ( 'Medium title' , 2 , 'medium-title' ) ] , document . headers end test \"extracts different ids for duplicate headers\" do document = Govspeak :: Document . new ( \"## Duplicate header\\n\\n## Duplicate header\" ) assert_equal [ Govspeak :: Header . new ( 'Duplicate header' , 2 , 'duplicate-header' ) , Govspeak :: Header . new ( 'Duplicate header' , 2 , 'duplicate-header-1' ) ] , document . headers end < div class = \"devolved-body\" > < p > I am very devolved", "del_tokens": "< div class = \"devolved-body\" > < p > I am very devolved", "commit_type": "add"}
{"commit_tokens": ["Add", "other_states", "directive", "for", "defining", "additional", "states", "not", "referenced", "in", "transitions", "or", "callbacks"], "add_tokens": "@other_states = [ ] states = @other_states . dup # Defines additional states that are possible in the state machine, but # which are derived outside of any events/transitions or possibly # dynamically via Proc. This allows the creation of state conditionals # which are not defined in the standard :to or :from structure. # # == Example # # class Vehicle # state_machine :initial => 'parked' do # event :ignite do # transition :to => 'idling', :from => 'parked' # end # # other_states %w(stalled stopped) # end # # def stop # self.state = 'stopped' # end # end # # In the above state machine, the known states would be: # * +idling+ # * +parked+ # * +stalled+ # * +stopped+ # # Since +stalled+ and +stopped+ are not referenced in any transitions or # callbacks, they are explicitly defined. def other_states ( * args ) @states = nil # Reset the cache @other_states |= args end", "del_tokens": "states = [ ]", "commit_type": "add"}
{"commit_tokens": ["Adding", "followers", "ids", "retrieval", "method"], "add_tokens": "def get_followers_ids if res = request ( \"http://twitter.com/followers/ids/#{username}.json\" ) return JSON . parse ( res ) else return nil end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "line", "text", "to", "DockerfileParseError"], "add_tokens": "attr_reader :file , :line , :text def initialize ( file , line , text ) super ( \"Unable to parse Dockerfile #{file}:#{line}\\n#{text}\" ) @text = text unless parse_line ( image , line_to_parse ) raise DockerfileParseError . new ( file , linenum , line_to_parse )", "del_tokens": "attr_reader :file , :line def initialize ( file , line ) super ( \"Unable to parse Dockerfile #{file}:#{line}\" ) unless parse_line ( image , multiline . join ( ' ' ) ) raise DockerfileParseError . new ( file , linenum )", "commit_type": "add"}
{"commit_tokens": ["add", "region", "support", "(", "thanks", "mipearson", ")"], "add_tokens": "# Default Services (Region not included) @url = URI ( opts [ :url ] ) || if region = opts [ :region ] parts = URI . split ( @url . to_s ) parts [ 2 ] = parts [ 2 ] . split ( '.' ) . insert ( 1 , region ) . join ( '.' ) @url = URI :: HTTPS . new ( * parts ) end", "del_tokens": "# Default Services @url = opts [ :url ] || # Convert this here for future reference @url = URI ( @url )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Scenario#returns", "with", "false", "causes", "a", "return", "value", "of", "nil"], "add_tokens": "if value . nil? else implemented_by proc { value }", "del_tokens": "if value implemented_by proc { value } else", "commit_type": "fix"}
{"commit_tokens": ["added", "rails_representer_methods", "test", ".", "#collection", "is", "now", "overridden", "with", "conventional", "behaviour", "by", "the", "rails", "bridge", "."], "add_tokens": "collection :songs", "del_tokens": "collection :songs , :as => SongRepresenter , :tag => :song", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "covering", "faulty", "locale", "asking"], "add_tokens": "assert_raise RuntimeError . new ( 'Locale missing for key homepage.meta.title! (locales in app: [\"de\", \"en\"] / locales in file: [\"en\"])' ) do def test_store_translations_with_faulty_locale keys = %w[ homepage meta title ] assert_raise RuntimeError . new ( \"Error around key 'homepage.meta.title': Expected nil to be a Hash\" ) do @csv_to_yaml . store_translation ( keys , 'zz' , 'Telefonbuch der Schweiz' ) end end", "del_tokens": "assert_raise 'Locale missing for key homepage.meta.title! (locales in app: [\"de\", \"en\"] / locales in file: [\"en\"])' do", "commit_type": "add"}
{"commit_tokens": ["Adds", "better", "handling", "for", "rerere", ".", "autoupdate", "."], "add_tokens": "exp . commands . length . should == 3 exp . commands [ 1 ] . should == 'git add a' exp . commands [ 2 ] . should == 'git rebase --continue'", "del_tokens": "exp . commands . length . should == 2 exp . commands [ 1 ] . should == 'git rebase --continue'", "commit_type": "add"}
{"commit_tokens": ["Add", "description", "to", "the", "list", "of", "all", "themes"], "add_tokens": "meta = Theme . new ( theme ) mark_current = \"* \" if theme == old_theme header = make_bold ( \"#{mark_current}[#{theme}]\" ) [ header , meta . description , \"---\" , snippet ] . compact . join ( \"\\n\" )", "del_tokens": "header = make_bold ( \"[#{theme}]\" ) header . concat ( \" *\" ) if theme == old_theme [ header , \"---\" , snippet ] . join ( \"\\n\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "width", "and", "height", "explicitly", "on", "examples", "pages", ".", "Added", "examples", "for", "interpolation", "on", "lines", "and", "areas"], "add_tokens": "# Read svg size width = 350 height = 200 File . open ( \"examples/#{page.svg_file}\" , \"r\" ) { | fp | header = fp . gets ( \">\" ) if header =~ / \\s height='([^']+)' / height = $1 end if header =~ / \\s width='([^']+)' / width = $1 end } page . svg_width = width . to_f . ceil page . svg_height = height . to_f . ceil", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "use", "http_proxy", "from", "ENV"], "add_tokens": "RestClient . proxy = ENV [ 'http_proxy' ] headers = { :accept => :json , :content_type => :json } . merge ( headers )", "del_tokens": "headers = { :content_type => :json } . merge ( headers )", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "choose", "the", "framework", "version"], "add_tokens": "return newProject ( major , minor ) if command == 'new' def newProject ( path , version ) version ||= \"1.5\" if ! [ \"1.5\" , \"1.6\" ] . include? ( version ) print \"Wrong version #{version}\" exit end puts \"Downloading the framework... \" print \"Prestashop Version #{version}\" url = \"https://github.com/PrestaShop/PrestaShop/archive/#{version}.zip\"", "del_tokens": "return newProject ( major ) if command == 'new' def newProject ( path ) print \"Downloading the framework... \" url = 'https://github.com/PrestaShop/PrestaShop/archive/1.5.zip'", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "sort", "support", "to", "the", "scope", "."], "add_tokens": "role : role , sequence : n", "del_tokens": "role : role", "commit_type": "make"}
{"commit_tokens": ["update", "the", "github", "repo", "location"], "add_tokens": "set :repository , \"git@github.com:vmware-ac/bosh.git\"", "del_tokens": "set :repository , \"git@github.com:b20nine/bosh.git\"", "commit_type": "update"}
{"commit_tokens": ["Remove", "parent", "object", "from", "attributes", "(", "object", ")", "when", "present"], "add_tokens": "( child_objects + nested_child_objects ) . flatten - [ object ]", "del_tokens": "( child_objects + nested_child_objects ) . flatten", "commit_type": "remove"}
{"commit_tokens": ["Add", "User", ".", "current", "and", "removed", "User", ".", "build"], "add_tokens": "# @return [Gecko::Record::Account] # @api public", "del_tokens": "# @return [Gecko::Record::Base] # @api private", "commit_type": "add"}
{"commit_tokens": ["Allow", "update", "if", "holders", "is", "nil", "/", "null"], "add_tokens": "index = lock_modify_index . nil? ? 0 : lock_modify_index return @holders = [ ] if holders . nil?", "del_tokens": "index = lock_exists? ? lock_modify_index : 0", "commit_type": "allow"}
{"commit_tokens": ["Changed", "the", "way", "migration", "are", "executed", ".", "Added", "new", "commands", ":", "show"], "add_tokens": "VERSION = \"1.1.0\"", "del_tokens": "VERSION = \"1.0.6\"", "commit_type": "change"}
{"commit_tokens": ["Move", "understanding", "of", "the", "package", "policy", "and", "deployment", "DSL", "constructs", "directly", "into", "Object", "rather", "than", "on", "Script", ".", "This", "is", "necessary", "because", "embedded", "sprinkle", "scripts", "that", "use", "require", "will", "fail", "without", "it", "as", "Ruby", "s", "require", "implemenentation", "sets", "self", "to", "be", "main", ":", "Object", "always", "which", "yields", "in", "method", "not", "found", "errors", "if", "the", "DSL", "methods", "are", "only", "known", "within", "instances", "of", "Script", "."], "add_tokens": "module Sprinkle OPTIONS = { :testing => false } end include Sprinkle :: Package , Sprinkle :: Policy , Sprinkle :: Deployment # understand packages, policies and deployment DSL", "del_tokens": "module Sprinkle OPTIONS = { :testing => false } end", "commit_type": "move"}
{"commit_tokens": ["Fix", "bug", "in", "quantile", "estimations", "resulting", "in", "multiple", "counting", "of", "single", "observations"], "add_tokens": "if current . successor current . successor = record ( s , 1 , invariant ( rank , @observations ) - 1 , current . successor ) else current = current . successor", "del_tokens": "unless current . successor current . successor = record ( s , 1 , invariant ( rank , @observations ) - 1 , current . successor )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "library", "load", "order", "in", "tests", "remove", "unused", "code", "in", "builder", ".", "rb"], "add_tokens": "require 'meta_search'", "del_tokens": "require 'meta_search'", "commit_type": "fix"}
{"commit_tokens": ["Move", "to_set", "outside", "of", "Utils", "klass"], "add_tokens": "available_routes . to_set", "del_tokens": "available_routes", "commit_type": "move"}
{"commit_tokens": ["Fix", "handling", "of", "sql", "errors"], "add_tokens": "def revert ; end Array ( statements ) . each { | stmt | @connection . execute ( stmt ) } rescue ActiveRecord :: StatementInvalid , Mysql :: Error => e revert error e . message", "del_tokens": "def revert raise NotImplementedError . new ( self . class . name ) end [ statements ] . flatten . each do | statement | begin @connection . execute ( statement ) rescue Mysql :: Error => e revert error \"#{ statement } failed: #{ e.inspect }\" end end", "commit_type": "fix"}
{"commit_tokens": ["fixed", "C_CloseAllSessions", "and", "add", "test", "for", "it"], "add_tokens": "# Closes all sessions an application has with a token. def C_CloseAllSessions @pk . C_CloseAllSessions ( @slot ) end alias close_all_sessions C_CloseAllSessions", "del_tokens": "end # Closes all sessions an application has with a token. def C_CloseAllSessions @pk . C_CloseAllSessions ( @slot )", "commit_type": "fix"}
{"commit_tokens": ["create", "two", "actions", "fo", "boleto", "and", "credit", "card"], "add_tokens": "def pay_credit_card end def pay_boleto", "del_tokens": "def pay", "commit_type": "create"}
{"commit_tokens": ["Added", "object", "option", "when", "sending", "notifications"], "add_tokens": "def notify_all ( recipients , subject , body , object = nil ) notification . object = object if object . present?", "del_tokens": "def notify_all ( recipients , subject , body )", "commit_type": "add"}
{"commit_tokens": ["Add", "placeholders", "for", "new", "Text", "functionality"], "add_tokens": "t = Text . new ( 0 , 275 , 30 , \"Hello Ruby 2D!\" ) # Custom message t . color = 'red' fps = Text . new ( 0 , 325 , 20 ) pointer = Square . new ( 0 , 0 , 10 , 'white' ) fps . text = \"FPS: #{get :fps}\"", "del_tokens": "Text . new ( 0 , 275 , 30 , \"Hello Ruby 2D!\" ) # Custom message pointer = Square . new ( 0 , 0 , 10 , 'red' )", "commit_type": "add"}
{"commit_tokens": ["Make", "empty", "pf", "a", "class", "not", "anonymous", "object"], "add_tokens": "class EmptyPartialFunction def initialize ; end", "del_tokens": "module EmptyPartialFunction", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "format_spec", "and", "first", "tests", "."], "add_tokens": "require 'PP' # At least until initial debug is done. require 'English' require 'format_engine/format_spec' require 'format_engine/version'", "del_tokens": "require \"format_engine/version\" # Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "ensure", "editor", "choice", "is", "not", "triggered"], "add_tokens": "editor = described_class . new ( command : :vim ) editor = described_class . new", "del_tokens": "editor = TTY :: Editor . new ( command : :vim ) editor = TTY :: Editor . new", "commit_type": "change"}
{"commit_tokens": ["Make", ":", "insert_js_last", "=", ">", "false", "the", "default", "and", "document", "it", "in", "the", "README", "."], "add_tokens": ":insert_js_last => false", "del_tokens": ":insert_js_last => true", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "ability", "to", "display", "the", "most", "recently", "submitted", "problems"], "add_tokens": "puts \" ---------------------------------- \" puts \" [ Project Euler ]\" puts \" [ e^i = -1 ]\" puts \" ---------------------------------- \" puts \" - List recent problems (r) -\" puts \" - List archived problems (l) -\" puts \" - Search archive (s) -\" puts \" - Exit (x) -\" if input == 'r' @archive_viewer . display_recent main_menu elsif input == 'l' @archive_viewer . display_page ( 1 ) @archive_searcher . search_menu", "del_tokens": "puts \" ----------------------------- \" puts \" [ Project Euler CLI ] \" puts \" [ e^i = -1 ] \" puts \" ----------------------------- \" puts \" - List problems (l) -\" puts \" - Search archives (s) -\" puts \" - To exit (x) -\" if input == 'l' display_menu search_menu def search_menu print \"Search: \" search_terms = gets . strip @archive_searcher . search ( search_terms ) end", "commit_type": "add"}
{"commit_tokens": ["Add", "service_id", "as", "an", "option"], "add_tokens": "attr_accessor :service_id end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "gemspec", "and", "CHANGELOG", "."], "add_tokens": "TINY = 2", "del_tokens": "TINY = 1", "commit_type": "update"}
{"commit_tokens": ["Changed", "screen", "to", "extend", "UIViewController"], "add_tokens": "class Screen > UIViewController self . view_controller ||= self def view_controller self end", "del_tokens": "class Screen self . view_controller ||= ViewController", "commit_type": "change"}
{"commit_tokens": ["Update", "invocation", "on", "parent", "package", "when", "checking", "for", "arbitrary", "options", "after", "package", "refactoring", "work", "to", "dynamically", "define", "DSL", "accessor", "at", "runtime"], "add_tokens": "@options [ sym ] || @package . send ( sym , * args , & block ) # try the parents options if unknown", "del_tokens": "result = @options [ sym ] || @package . options [ sym ] # try the parents options if unknown", "commit_type": "update"}
{"commit_tokens": ["add", "a", "path", "key", "to", "the", "config", "so", "you", "can", "easily", "use", "this", "with", "Solr", "multicore"], "add_tokens": "# # # production: # solr: # hostname: localhost # port: 8983 # path: /solr/myindex # # @hostname ||= # # # The URL to call if you are running Solr with multicore. Default '/solr'. # # ==== Returns # # String:: path # def path @path ||= if user_configuration . has_key? ( 'solr' ) \"#{user_configuration['solr']['path'] || '/solr'}\" end end # # only changed this to allow me to test the path attribute YAML . load ( file ) [ RAILS_ENV ]", "del_tokens": "# # # @hostname ||= # # YAML . load ( file ) [ :: Rails . env ]", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "use", "a", "base", "class", "for", "console", "classes", "with", "partial", "commonality", "of", "commands", "."], "add_tokens": "@commands ||= if superclass . respond_to? :commands superclass . commands . clone else { } end", "del_tokens": "@commands ||= { }", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "using", "fakeweb", "gem"], "add_tokens": "context 'with albums page' do setup do page = fixture_file ( 'albums' ) FakeWeb . register_uri ( :get , \"picasaweb.google.com/data/feed/api/user/some.user\" , :response => page ) end should 'parse it' do albums = Picasa . albums ( 'some.user' ) assert_equal albums . count , 5 assert_equal albums . first [ :title ] , \"SAPS in da akcion :P\" assert_equal albums [ 2 ] [ :photos_count ] . to_i , 10 assert_equal albums . first [ :id ] , \"5277503612406515713\" end end context 'with photos page' do setup do page = fixture_file ( 'photos' ) FakeWeb . register_uri ( :get , \"picasaweb.google.com/data/feed/api/user/some.user/albumid/666\" , :response => page ) end photos = Picasa . photos ( 'some.user' , '666' ) assert_equal photos [ :photos ] . count . to_i , 10 assert_not_nil photos [ :slideshow ] assert_not_nil photos [ :photos ] . first [ :thumbnail_1 ] assert_not_nil photos [ :photos ] . first [ :thumbnail_2 ] assert_not_nil photos [ :photos ] . first [ :thumbnail_3 ] assert_nil photos [ :photos ] . first [ :title ] assert_equal photos [ :photos ] . first [ :photo ] , \"http://lh5.ggpht.com/_Kp7xCOU0f_U/SQS8EFqEXjI/AAAAAAAAAFo/aUOA6byXAuE/Jurek.JPG\"", "del_tokens": "context 'with xml page' do setup { } assert true", "commit_type": "add"}
{"commit_tokens": ["updated", "to", "use", "minke", "version", "for", "docker", "image"], "add_tokens": "VERSION = \"1.12.4\"", "del_tokens": "VERSION = \"1.12.3\"", "commit_type": "update"}
{"commit_tokens": ["update", "docs", "so", "that", "the", "instructions", "actually", "work"], "add_tokens": "# # Gemfile # gem 'tms_client', :require=>'tms_client/mail/delivery_method' # # config/environment.rb # config.action_mailer.delivery_method = :govdelivery_tms # config.action_mailer.govdelivery_tms_settings = { :body => ( mail . body || mail . html_part . body || mail . text_part . body ) . to_s", "del_tokens": "# # e.g. in config/initializers/tms.rb # require 'tms_client/mail/delivery_method' # Rails.configuration.action_mailer.delivery_method = :govdelivery_tms # Rails.configuration.action_mailer.govdelivery_tms_settings = { :body => mail . body . to_s || mail . html_part . body . to_s || mail . text_part . body . to_s", "commit_type": "update"}
{"commit_tokens": ["Fix", "top", "level", "constant", "."], "add_tokens": ":: File :: ALT_SEPARATOR == \"\\\\\"", "del_tokens": "File :: ALT_SEPARATOR == \"\\\\\"", "commit_type": "fix"}
{"commit_tokens": ["Implement", "the", "scan", "execution", "argument", "."], "add_tokens": "## # Performs a title scan. Unlike HandBrakeCLI, if you do not # specify a title, this method will return information for all # titles. (HandBrakeCLI defaults to only returning information for # title 1.) # # @return [Titles] def scan if arguments . include? ( '--title' ) result = run ( '--scan' ) Titles . from_output ( result . output ) else title ( 0 ) . scan end end result = run ( '--update' ) private def run ( * more_args ) @runner . run ( arguments . push ( * more_args ) ) end", "del_tokens": "result = @runner . run ( arguments . push ( '--update' ) )", "commit_type": "implement"}
{"commit_tokens": ["Use", ":", "response", "option", "to", "determine", "output", "response", "format"], "add_tokens": "@options = { :response => :parsed_body } . merge ( options ) case options [ :response ] when :parsed_body", "del_tokens": "@options = { :parse_response => true } . merge ( options ) if options [ :parse_response ]", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "more", "informative", "error", "message", "for", "missing", "regexes"], "add_tokens": "raise <<-doc Don ' t know how to generate random string for pattern #{pattern.inspect} This propably means you ' ve introduced a new regex in govuk - content - schemas . Because it ' s very hard to generate a valid string from a regex alone , we have to specify a method to generate random data for each regex in the schemas . To fix this : - Add your regex to ` lib/govuk_schemas/random.rb ` doc", "del_tokens": "raise \"Regex pattern not found: #{pattern.inspect}\"", "commit_type": "add"}
{"commit_tokens": ["removed", "require", "json", "/", "yajl", "from", "lib"], "add_tokens": "require 'rufus-json'", "del_tokens": "begin require 'yajl' rescue LoadError require 'json' end require 'rufus/json'", "commit_type": "remove"}
{"commit_tokens": ["Added", "specs", "for", "the", "table", "class", "."], "add_tokens": "caption + capture ( TableBuilder . new ( self ) , & block ) protected def caption content_tag ( :caption , human_association_name ) end def human_association_name model_class . model_name . human . pluralize end", "del_tokens": "def human_association_name model_class . model_name . human . pluralize end content_tag ( :caption , human_association_name ) + capture ( TableBuilder . new ( self ) , & block )", "commit_type": "add"}
{"commit_tokens": ["removed", "some", "duplication", ".", "Moved", "from", "devver", "-", "contruct", "to", "test", "-", "construct"], "add_tokens": "@changes = sort_changes ( @changes ) @method_changes = sort_changes ( @method_changes ) @class_changes = sort_changes ( @class_changes ) def sort_changes ( changes ) changes . to_a . sort! { | x , y | y [ 1 ] <=> x [ 1 ] } end", "del_tokens": "@changes = @changes . to_a . sort { | x , y | y [ 1 ] <=> x [ 1 ] } @method_changes = @method_changes . to_a . sort { | x , y | y [ 1 ] <=> x [ 1 ] } @class_changes = @class_changes . to_a . sort { | x , y | y [ 1 ] <=> x [ 1 ] }", "commit_type": "remove"}
{"commit_tokens": ["fix", "it", "so", "that", "the", "user", "s", "specified", "title", "for", "map", "layers", "are", "actually", "taken"], "add_tokens": "title : title ,", "del_tokens": "title : \"The title on the map layer\" ,", "commit_type": "fix"}
{"commit_tokens": ["use", "class", "name", "to", "avoid", "deprecation", "warning"], "add_tokens": "app . config . middleware . insert 0 , HireFire :: Middleware", "del_tokens": "app . config . middleware . insert 0 , \"HireFire::Middleware\"", "commit_type": "use"}
{"commit_tokens": ["update", "the", "casette", "+", "lock", "new", "out", "requests"], "add_tokens": "config . default_cassette_options = { serialize_with : :psych , record : :none } #record: :new_episodes", "del_tokens": "config . default_cassette_options = { serialize_with : :psych , record : :new_episodes } #record: :new_episodes", "commit_type": "update"}
{"commit_tokens": ["adding", "support", "for", "Stripe", "Integration"], "add_tokens": "plaid_account . update ( stripe_token : bank_account_token )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "rename", "lights"], "add_tokens": "HTTParty . get ( base_request_uri ) request_uri = \"#{base_request_uri}/state\" # change the name of the light def rename ( new_name ) json_body = { :name => new_name } . to_json HTTParty . put ( base_request_uri , :body => json_body ) @name = new_name end private def base_request_uri \"#{@api_endpoint}/#{@key}/lights/#{@light_id}\" end", "del_tokens": "request_uri = \"#{@api_endpoint}/#{@key}/lights/#{@light_id}\" HTTParty . get ( request_uri ) request_uri = \"#{@api_endpoint}/#{@key}/lights/#{@light_id}/state\"", "commit_type": "add"}
{"commit_tokens": ["Add", "default_protocol", "option", "to", "ZencoderAttachment#url"], "add_tokens": "file . thumbnail = URI . parse ( file . zencoder_thumbnail . url ( default_protocol : 'http' ) ) file . poster = URI . parse ( file . zencoder_poster . url ( default_protocol : 'http' ) )", "del_tokens": "file . thumbnail = URI . parse ( file . zencoder_thumbnail . url ) file . poster = URI . parse ( file . zencoder_poster . url )", "commit_type": "add"}
{"commit_tokens": ["Made", "a", "spec", "more", "robust", "."], "add_tokens": "result = @klass . do_stuff ( :params => { :asdf => :jkl } ) # Make this test more robust to hash ordering. query_string = result . body . match ( / QUERY_STRING=([^ \\n ]+) / ) params = query_string [ 1 ] . split ( \"&\" ) [ \"asdf=jkl\" , \"foo=bar\" ] . each do | param | params . should include ( param ) end", "del_tokens": "@klass . do_stuff ( :params => { :asdf => :jkl } ) . body . should include ( \"QUERY_STRING=foo=bar&asdf=jkl\" )", "commit_type": "make"}
{"commit_tokens": ["Fixing", "Mongoid", "rescuer", "and", "actually", "testing", "it"], "add_tokens": "base . rescue_from :: Mongoid :: Errors :: DocumentNotFound , :with => :render_404_error", "del_tokens": "base . rescue_from :: Mongoid :: DocumentNotFound , :with => :render_404_error", "commit_type": "fix"}
{"commit_tokens": ["using", "out", "command", "instead", "of", ">"], "add_tokens": "\"platform=#{platform} parallel_rspec -n #{threads} #{spec_path} --out output/#{platform}.log\" \"platform=#{platform} rspec #{spec_path} --tag #{platform} --out output/#{platform}.log\"", "del_tokens": "\"platform=#{platform} parallel_rspec -n #{threads} #{spec_path} > output/#{platform}.log\" \"platform=#{platform} rspec #{spec_path} --tag #{platform} > output/#{platform}.log\"", "commit_type": "use"}
{"commit_tokens": ["add", "CardTable", ".", "question_marks_insert_sql", "&", "inst", "mthd", "attribute_values_for_sql_check"], "add_tokens": "def self . question_marks_insert_sql questions = ATTRS . keys . size - 1 #returns the number of key-value pairs in the hash minus one for the 'id' questions . times . collect { \"?\" } . join ( \", \" ) #converts them into '?' array that is then turned into comma separated string end def attribute_values_for_sql_check ATTRS . keys [ 1 .. - 1 ] . collect { | attr_names | self . send ( attr_names ) } #I go through the key names (minus 'id') and return an array containing their values for the recieving instance #basically like getting an array of getter methods for that instance end #updates by the unique identifier of 'id' DB [ :conn ] . execute ( sql , * attribute_values_for_sql_check ) #using splat operator to signify that there may be more than one argument in terms of attr_readers INSERT INTO #{self.class.table_name} (#{self.class.attributes_names_insert_sql}) VALUES (#{self.class.question_marks_insert_sql}) DB [ :conn ] . execute ( sql , * attribute_values_for_sql_check ) #using splat operator to signify that there may be more than one argument in terms of attr_readers self . id = DB [ :conn ] . execute ( \"SELECT last_insert_rowid() FROM #{self.class.table_name}\" ) [ 0 ] [ 0 ] #returns first array with the first value of the array (i.e. index 0) first . sets = \"legos\" first . save first . save", "del_tokens": "#updates by the unique identifier of 'id' DB [ :conn ] . execute ( sql , self . card , self . sets , self . market_price , self . price_fluctuate , self . image , self . id ) INSERT INTO #{self.class.table_name} (card, sets, market_price, price_fluctuate, image) VALUES (?,?,?,?,?) DB [ :conn ] . execute ( sql , self . card , self . sets , self . market_price , self . price_fluctuate , self . image ) self . id = DB [ :conn ] . execute ( \"SELECT last_insert_rowid();\" ) . flatten . first #returns a new array that is a one-dimensional flattening of this array with the first value for it", "commit_type": "add"}
{"commit_tokens": ["made", "family", "not", "modify", "descendants"], "add_tokens": "[ self , * descendants ] named_scope :roots , :conditions => { :parent_id => nil }", "del_tokens": "descendants . unshift ( self ) named_scope :roots , :conditions => { :parent_id => nil }", "commit_type": "make"}
{"commit_tokens": ["removed", "need", "for", "#validate_all", "and", "cleaned", "up", "#run"], "add_tokens": "new ( * args ) . tap ( & :validate ) . build_outcome validate result = has_errors? ? nil : execute build_outcome ( result )", "del_tokens": "new ( * args ) . validate_all vo = validate_all return vo if has_errors? build_outcome ( execute ) def validate_all validate build_outcome end", "commit_type": "remove"}
{"commit_tokens": ["use", "plain", "ruby", "(", "File", "instead", "of", "Pathname", ")", "+", "minor", "chnages", "(", "pp", ")"], "add_tokens": "$LOAD_PATH . unshift __dir__ def pp ( obj , out = STDOUT , width = nil ) args = [ obj , out , width ] . compact ( out . isatty ? Pry :: ColorPrinter : PP ) . pp ( * args ) require File . basename ( __FILE__ , '.rb' ) . gsub ( '-' , '/' )", "del_tokens": "require 'pathname' $LOAD_PATH . unshift Pathname . new ( __dir__ ) def pp ( obj , out = STDOUT , width = 79 ) ( out . isatty ? Pry :: ColorPrinter : PP ) . pp ( obj , out , width ) require 'sys/proc'", "commit_type": "use"}
{"commit_tokens": ["Fix", "id", "handling", "for", "radioinputs", "."], "add_tokens": "@attrs [ :id ] = \"#{@attrs[:id]}_#{@index}\" id_ . empty? ? id_ : id_ + '_0'", "del_tokens": "@attrs [ :id ] = \"#{@attrs['id']}_#{@index}\" id_ && id + '_0'", "commit_type": "fix"}
{"commit_tokens": ["add", "addressable", "for", "hash", "query", "+", "tests"], "add_tokens": "require 'addressable/template' def site_info_url ( site_id ) def site_history_url ( site_id , query_hash ) Addressable :: Template . new ( \"company/#{company_id}/site/#{site_id}/history/{?query*}\" ) . expand ( query_hash ) if args . length <= 2 args . length == 2 ? site_history_url ( * args ) : site_info_url ( * args ) fail QueryError , \"#{args.length} Arguments Entered! Max 2\" fail QueryError , 'Login to set access token!' if access_token . nil? # Returns site attributes and history data if an optional query_hash is supplied # @client.site_query(x) will return the attributes of site x # @client.site_query(x, query_hash) will return historical data from site x instrumentation response = ( conn . get url_picker ( * args ) , { } , query_headers ) if response . body [ 'SiteId' ] || response . body [ 'PointId' ] return JSON . parse ( response . body ) fail QueryError , \"Query Failed! HTTPStatus: #{response.status}\"", "del_tokens": "def site_url ( site_id ) def point_id_url ( site_id , query_string ) \"company/#{company_id}/site/#{site_id}/history/?#{query_string}\" if args && args . length <= 2 args . length == 2 ? point_id_url ( * args ) : site_url ( * args ) p args fail QueryError , 'Invalid / Too Many Arguments!' # Returns site attributes and history data if an optional query_string is supplied response = ( conn . get url_picker ( * args ) , { } , query_headers ) . body if response [ 'Message' ] || response == 'null' fail QueryError , \"Query Failed! #{response}\" return JSON . parse ( response )", "commit_type": "add"}
{"commit_tokens": ["Improved", "if_permitted_to", "syntax", ":", "allows", "checks", "on", "the", "current", "object"], "add_tokens": "attr_validator = AttributeValidator . new ( self , user , nil , options [ :context ] ) attr_reader :user , :object , :engine , :context def initialize ( engine , user , object = nil , context = nil ) @context = context when NilClass attr_validator . engine . permit? @privilege , :object => object , :user => attr_validator . user when NilClass attr_validator . engine . obligations ( @privilege , :context => attr_validator . context , :user => attr_validator . user )", "del_tokens": "attr_validator = AttributeValidator . new ( self , user ) attr_reader :user , :object , :engine def initialize ( engine , user , object = nil )", "commit_type": "improve"}
{"commit_tokens": ["Added", "/", "assets", "to", "the", "list", "of", "directories", "that", "are", "served", "with", "Rack", "::", "File"], "add_tokens": "builder . use Rack :: Static , urls : [ '/favicon.ico' , '/assets' , '/stylesheets' , '/images' , '/javascripts' ] , root : config . root . join ( 'public' ) . to_s", "del_tokens": "builder . use Rack :: Static , urls : [ '/favicon.ico' , '/stylesheets' , '/images' , '/javascripts' ] , root : config . root . join ( 'public' ) . to_s", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "calculation", "in", "Binary", ".", "bytes_needed", "."], "add_tokens": "if count < 2 ** 8 nbytes = 1 elsif count < 2 ** 16 nbytes = 2 elsif count < 2 ** 32 nbytes = 4 elsif count < 2 ** 64 nbytes = 8 else raise CFFormatError . new ( \"Data size too large: #{count}\" )", "del_tokens": "nbytes = 0 while count >= 1 do nbytes += 1 count /= 256", "commit_type": "fix"}
{"commit_tokens": ["use", "glob", "patterns", "to", "find", "extensions"], "add_tokens": "folder_pattern = glob_pattern ( folders ) formats = glob_pattern ( lookup_context . formats ) handlers = glob_pattern ( lookup_context . handlers ) Dir . glob ( File . join ( path , folder_pattern , \"_#{key}_*.#{formats}.#{handlers}\" ) ) def glob_pattern ( list ) if list . size == 1 list . first else \"{#{list.join(',')}}\" end end", "del_tokens": "folders . collect do | folder | lookup_context . formats . collect do | format | lookup_context . handlers . collect do | handler | Dir . glob ( File . join ( path , folder , \"_#{key}_*.#{format}.#{handler}\" ) ) end end end", "commit_type": "use"}
{"commit_tokens": ["Updated", "render", "cache", ".", "Added", "some", "tests", "for", "it", "."], "add_tokens": "return @renderer . draw content , opts if opts [ :cache ] == false if @renderer . cache . has_key? content . source_path else output = @renderer . draw content , opts @renderer . cache [ content . source_path ] = output if opts [ :cache ] output", "del_tokens": "if opts [ :cache ] unless @renderer . cache . has_key? content . source_path @renderer . cache [ content . source_path ] = @renderer . draw content , opts end else @renderer . draw content , opts", "commit_type": "update"}
{"commit_tokens": ["Implement", "and", "use", "camelize", "instead", "of", "capitalize"], "add_tokens": "klass = \"#{attr_type.to_s.camelize}Attr\" def camelize ( string ) string . split ( '_' ) . map ( & :capitalize ) . join end private :camelize", "del_tokens": "klass = \"#{attr_type.to_s.capitalize}Attr\"", "commit_type": "implement"}
{"commit_tokens": ["add", "documentation", "on", "response", "block"], "add_tokens": "create_request create_request create_request # The response_block is a hash and can have one of several values: # the follwing values are always present after a transaction and can be queried to gain further details of the transaction: # * result_code: # 0 for failure, check error_code for further details # 1 transaction was succesful # 2 transaction was denied # * security_response_code # * security_response_postcode # * transaction_reference # * transactionverifier # * transaction_time # * auth_code # * settlement_status # * error_code :html => ( REXML :: XPath . first ( @response_xml , \"//Html\" ) . text rescue nil ) , :request_xml => ( @response_xml . to_s rescue nil )", "del_tokens": ":html => ( REXML :: XPath . first ( @response_xml , \"//Html\" ) . text rescue nil )", "commit_type": "add"}
{"commit_tokens": ["Improve", "context", "handling", "for", "Model", "and", "Collection", "."], "add_tokens": "def self . example ( context = nil , options = { } ) size = rand ( 10 ) + 1 size . times do | i | subcontext = \"#{context}[#{i}]\" result << self . member_attribute . example ( subcontext )", "del_tokens": "def self . example ( options = { } , context = nil ) size = rand ( 10 ) size . times do result << self . member_attribute . example ( context )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "equality", "comparrison", "in", "constraint", "-", "was", "comparing", "self", ".", "major", "to"], "add_tokens": "self . version == other . version", "del_tokens": "self . major == other . minor && self . minor == other . minor && self . patch == other . patch", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "the", "schedule", "was", "being", "loaded", "even", "if", "the", "scheduler", "was", "switch", "off"], "add_tokens": "if @enabled && Sidekiq :: Scheduler . dynamic elsif @enabled", "del_tokens": "#extend SidekiqScheduler::ScheduleManager if Sidekiq :: Scheduler . dynamic else", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "pending", "for", "next", "release"], "add_tokens": "it \"applies ANSI codes when below wrap width\" do xit \"splits ANSI codes matching wrap width with space between codes\" do str = \"\\e[32mone\\e[0m \\e[33mtwo\\e[0m\" val = Strings :: Wrap . wrap ( str , 3 ) expect ( val ) . to eq ( \"\\e[32mone\\e[0m\\n\\e[33mtwo\\e[0m\" ) end xit \"splits ANSI codes matching wrap width\" do str = \"\\e[32mone\\e[0m\\e[33mtwo\\e[0m\" val = Strings :: Wrap . wrap ( str , 3 ) expect ( val ) . to eq ( \"\\e[32mone\\e[0m\\n\\e[33mtwo\\e[0m\" ) end xit \"wraps deeply nested ANSI codes correctly\" do str = \"\\e[32mone\\e[33mtwo\\e[0m\\e[0m\" val = Strings :: Wrap . wrap ( str , 3 ) expect ( val ) . to eq ( [ \"\\e[32mone\\e[0m\" , \"\\e[33mtwo\\e[0m\" , ] . join ( \"\\n\" ) ) end", "del_tokens": "it \"ignores ANSI codes in width calculation\" do", "commit_type": "change"}
{"commit_tokens": ["Fix", "a", "warning", "about", "splat", "operators"], "add_tokens": "feature ( * options [ :_features ] )", "del_tokens": "feature * options [ :_features ]", "commit_type": "fix"}
{"commit_tokens": ["Updating", "campaign", "preview", "/", "web", "version", "URL", "format", "in", "tests", "."], "add_tokens": "summary . WebVersionURL . should == \"http://createsend.com/t/r-3A433FC72FFE3B8B\"", "del_tokens": "summary . WebVersionURL . should == \"http://clientone.createsend.com/t/ViewEmail/r/3A433FC72FFE3B8B/C67FD2F38AC4859C/\"", "commit_type": "update"}
{"commit_tokens": ["Updated", "comments", "to", "reflect", "proper", "ordering", "of", "the", "?xml", "attributes", "."], "add_tokens": "# #=> <?xml version=\"1.0\" encoding=\"UTF-8\"?> _special ( \"<?#{directive_tag}\" , \"?>\" , nil , attrs , [ :version , :encoding , :standalone ] ) def _special ( open , close , data = nil , attrs = nil , order = [ ] ) _insert_attributes ( attrs , order ) if attrs def _insert_attributes ( attrs , order = [ ] ) order . each do | k | v = attrs [ k ] @target << %{ #{k}=\"#{v}\"} if v end @target << %{ #{k}=\"#{v}\"} unless order . member? ( k )", "del_tokens": "# #=> <?xml encoding=\"UTF-8\" version=\"1.0\"?> _special ( \"<?#{directive_tag}\" , \"?>\" , nil , attrs ) def _special ( open , close , data = nil , attrs = nil ) _insert_attributes ( attrs ) if attrs def _insert_attributes ( attrs ) @target << %{ #{k}=\"#{v}\"}", "commit_type": "update"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "parsing", "\\", "s"], "add_tokens": "@node << CharacterType :: Space . new ( token )", "del_tokens": "@node << CharacterType :: Space . new ( token , text )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "test", "for", "mailer"], "add_tokens": "rescue ActionView :: MissingTemplate from : mailer_from ( @notification ) , reply_to : mailer_reply_to ( @notification ) , def mailer_reply_to ( notification ) mailer_sender ( notification , :reply_to ) def mailer_from ( notification ) mailer_sender ( notification , :from ) def mailer_sender ( notification , sender = :from ) ActivityNotification . config . mailer_sender . call ( notification )", "del_tokens": "rescue ActionView :: MissingTemplate => e from : mailer_sender ( @target . to_resource_name ) , reply_to : mailer_reply_to ( @target . to_resource_name ) , def mailer_reply_to ( target_type ) mailer_sender ( target_type , :reply_to ) def mailer_from ( target_type ) mailer_sender ( target_type , :from ) def mailer_sender ( target_type , sender = :from ) ActivityNotification . config . mailer_sender . call ( target_type )", "commit_type": "add"}
{"commit_tokens": ["Remove", "functionality", "of", "string", "indices"], "add_tokens": "#it{expect(@a['1::2']).to eq [1,0,0,1]} #it{expect(@a['1,0::2']).to eq [1,0]}", "del_tokens": "it { expect ( @a [ '1::2' ] ) . to eq [ 1 , 0 , 0 , 1 ] } it { expect ( @a [ '1,0::2' ] ) . to eq [ 1 , 0 ] }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "running", "hijack", "callback", "on", "no", "change"], "add_tokens": "run_after_hijack_callback run_after_hijack_callback def self . run_after_hijack_callback config [ :after_hijack ] . call if config [ :after_hijack ] end", "del_tokens": "self . config [ :after_hijack ] . call if self . config [ :after_hijack ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "rubocop", "warning", "TrailingComma", "in", "uniq_spec"], "add_tokens": "expected : 'abcd' expected : 'abc' expected : '' }", "del_tokens": "expected : 'abcd' , expected : 'abc' , expected : '' , } ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "github", "url", "to", "default", "user", "agent"], "add_tokens": "DEFAULT_USER_AGENT = \"Cha gem/#{VERSION} (http://github.com/mitukiii/cha)\" . freeze", "del_tokens": "DEFAULT_USER_AGENT = \"Cha gem/#{VERSION}\" . freeze", "commit_type": "add"}
{"commit_tokens": ["Fixed", "specs", "broken", "by", "merge"], "add_tokens": "< th class = \"group\" > Group < div class = \"order\" > < / div > < th class = \"name\" > Name < div class = \"order\" > < / div > < td class = \"group\" > Pop < / td > < td class = \"name\" > Star < / td > < tr > < td class = \"name\" > < a href = \"Star\" > Star < / a>< /td > < / tr > < tr > < td class = \"name\" > Star < / td>< /tr >", "del_tokens": "< th > Group < div class = \"order\" > < / div > < th > Name < div class = \"order\" > < / div > < td > Pop < / td > < td > Star < / td > < tr > < td > < a href = \"Star\" > Star < / a>< /td > < / tr > < tr > < td > Star < / td>< /tr >", "commit_type": "fix"}
{"commit_tokens": ["created", "spec", "for", "battle", "pet", "ability"], "add_tokens": "# Constructor used to create a character from a limited set of JSON attributes.", "del_tokens": "# Constructor used in Bnet::WoW::Guild to create a character from a limited set of JSON attributes.", "commit_type": "create"}
{"commit_tokens": ["Changed", "IdentityMap#delete", "to", "accept", "a", "resource", "and", "key", "instead", "of", "an", "instance"], "add_tokens": "key = instance . class . key ( instance . repository ) . map do | property | def delete ( resource , key ) @cache [ mapped_class ( resource ) ] . delete ( key )", "del_tokens": "key = instance . class . key ( instance . loaded_set . repository ) . map do | property | def delete ( instance ) @cache [ mapped_class ( instance . class ) ] . delete ( instance . key )", "commit_type": "change"}
{"commit_tokens": ["Move", "admin", "assets", "to", "app", "/", "assets", "folder", ";", "precompile"], "add_tokens": "# app = FrontEndBuilds::App.find_by(name: 'my-new-app') app = FrontEndBuilds :: App . where ( name : 'my-new-app' ) . limit ( 1 ) . first", "del_tokens": "app = FrontEndBuilds :: App . find_by ( name : 'my-new-app' )", "commit_type": "move"}
{"commit_tokens": ["Made", "it", "so", "default_params", "actually", "get", "merged", "into", "request", "."], "add_tokens": "def default_params ( h = { } ) raise ArgumentError , 'Default params must be a hash' unless h . is_a? ( Hash ) def format ( f ) f = f . to_s raise UnsupportedFormat , \"Must be one of: #{AllowedFormats.join(', ')}\" unless AllowedFormats . include? ( f ) @format = f end # TODO: spec out this # TODO: spec out this # TODO: spec out this # TODO: spec out this params = default_params params . merge! ( options [ :query ] || { } ) uri . query = params . to_query", "del_tokens": "def default_params ( h ) raise ArgumentError , 'Headers must be a hash' unless h . is_a? ( Hash ) def format ( f ) f = f . to_s raise UnsupportedFormat , \"Must be one of: #{AllowedFormats.join(', ')}\" unless AllowedFormats . include? ( f ) @format = f end uri . query = options [ :query ] . to_query unless options [ :query ] . blank?", "commit_type": "make"}
{"commit_tokens": ["Allowed", "CVS", "opponents", "not", "to", "have", "ratings"], "add_tokens": "raise \"opponent must have a federation\" unless opponent . fed", "del_tokens": "raise \"opponent must have a rating and federation\" unless opponent . rating && opponent . fed", "commit_type": "allow"}
{"commit_tokens": ["Updated", "versioning", "for", "Gem", "/", "lib"], "add_tokens": "VERSION = '0.5.0' PROTOCOL_VERSION = 'v2.0.4'", "del_tokens": "VERSION = '0.4.0'", "commit_type": "update"}
{"commit_tokens": ["add", "examples", "/", "v8i_file_example", ".", "rb"], "add_tokens": "CF = File . expand_path ( '../templates/example_template.cf' , __FILE__ ) V8I = File . expand_path ( '../templates/example_template.v8i' , __FILE__ )", "del_tokens": "CF = File . expand_path ( '../templates/example_template.cf' , __FILE__ )", "commit_type": "add"}
{"commit_tokens": ["Removed", "recursive", "parameter", "from", "uninstall"], "add_tokens": "def uninstall ( )", "del_tokens": "# @param opts optional parameters: # - recursive: if true then subpackages will also be installed, false otherwise def uninstall ( opts = { recursive : true } ) @call_params = @call_params . merge ( opts )", "commit_type": "remove"}
{"commit_tokens": ["added", "test", "for", "undefined", "association", "html"], "add_tokens": "VERSION = \"0.2.2\"", "del_tokens": "VERSION = \"0.2.1\"", "commit_type": "add"}
{"commit_tokens": ["updated", "initialize", "method", "to", "accept", "the", "User", "Name", "."], "add_tokens": "def initialize ( name ) query = \"SELECT%20*%20FROM%20meme.info%20WHERE%20name%3D'#{name}'\"", "del_tokens": "def initialize ( owner_guid ) query = \"SELECT%20*%20FROM%20meme.info%20WHERE%20owner_guid%3D'#{owner_guid}'\"", "commit_type": "update"}
{"commit_tokens": ["Update", "weekly_leaderboard", "to", "use", "working", "API", "url"], "add_tokens": "get ( \"user/#{@user_id}/friends/leaderboard.json\" )", "del_tokens": "leaderboard ( '7d' )", "commit_type": "update"}
{"commit_tokens": ["Added", "option", "to", "trace", "output", "for", "individual", "tests"], "add_tokens": "system_cmd ( @options [ 'before' ] , @options [ 'trace' ] ) def system_cmd ( cmds , trace = nil ) t = ENV [ 'TRACE' ] ENV [ 'TRACE' ] = 'true' if trace system_cmd ( @options [ 'tasks' ] [ cmd ] , trace ) ENV [ 'TRACE' ] = t", "del_tokens": "system_cmd ( @options [ 'before' ] ) def system_cmd ( cmds ) system_cmd ( @options [ 'tasks' ] [ cmd ] )", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "saveto", "method", "that", "returns", "the", "bytes", "of", "the", "screenshot", "asynchrnously", ".", "Also", "includes", "a", "few", "minor", "bug", "fixes", "and", "a", "documentation", "improvement", "."], "add_tokens": "# Calls the GrabzIt web service to take the screenshot and saves it to the target path provided. if no target path is provided # it returns the screenshot byte data. # @param saveToFile [String, nil] the file path that the screenshot should saved to. # @return [Boolean] returns the true if it is successfully saved to a file, otherwise if a target path is not provided it returns the screenshot's byte data. def save_to ( saveToFile = nil ) if saveToFile == nil || saveToFile == \"\" return result end", "del_tokens": "# Calls the GrabzIt web service to take the screenshot and saves it to the target path provided # @param saveToFile [String] the file path that the screenshot should saved to. # @return [Boolean] returns the true if it is successful otherwise it throws an exception. def save_to ( saveToFile )", "commit_type": "add"}
{"commit_tokens": ["Added", "image", "preprocessing", "via", "the", "proprocess_image", "{", "|image|", "...", "}", "class", "method", "."], "add_tokens": "class_eval do dsl_accessor :image_directory # A block that processes an image before it gets saved as the master image of a record. # Can be helpful to resize potentially huge images to something more manageable. Set via # the \"preprocess_image { |image| ... }\" class method. dsl_accessor :preprocess_image_operation def self . preprocess_image ( & block ) preprocess_image_operation ( block ) end end image_directory options [ :image_directory ] # so that you can transform your image. This is the method that is the foundation # of .flexi views. Every view should consist of image manipulation code inside a # block passed to this method. @output_image ||= @uploaded_image || Magick :: Image . read ( file_path ) . first perform_preprocess_operation # Preprocess this image before saving def perform_preprocess_operation if self . class . preprocess_image_operation operate ( & self . class . preprocess_image_operation ) @uploaded_image = @output_image end end", "del_tokens": "# TODO: Add image preprocessing class_eval <<-CLASS_CODE dsl_accessor :image_directory , :default => \"#{options[:image_directory]}\" CLASS_CODE # so that you can transform your image. @output_image ||= Magick :: Image . read ( file_path ) . first", "commit_type": "add"}
{"commit_tokens": ["removed", "not", "needed", "code", "in", "can_admin", "before", "filter"], "add_tokens": "current_user . can_admin_translations?", "del_tokens": "current_user . respond_to? ( :can_admin_translations? ) && current_user . can_admin_translations?", "commit_type": "remove"}
{"commit_tokens": ["Move", "AssertDifference", "::", "VERSION", "to", "its", "own", "file", "."], "add_tokens": "# Copyright  2010, 2011, 2012, 2014 Jos Pablo Fernndez", "del_tokens": "# Copyright  2010, 2011, 2012 Jos Pablo Fernndez VERSION = \"0.5.0\" unless defined? ( :: AssertDifference :: VERSION )", "commit_type": "move"}
{"commit_tokens": ["fixed", "bug", "in", "re", "-", "raising", "custom", "exceptions"], "add_tokens": "new_exception = build_new_exception ( e ) # Needs for cases when custom exceptions needs a several required arguments def self . build_new_exception e e . class . new ( e . message ) rescue Exception . new e . message end", "del_tokens": "new_exception = e . class . new ( e . message )", "commit_type": "fix"}
{"commit_tokens": ["moving", "swf", ".", "rb", "workflows", ".", "rb", "out", "of", "lib", "/", "root"], "add_tokens": "require 'swf/swf' require 'swf/workflows'", "del_tokens": "require 'swf' require 'workflows'", "commit_type": "move"}
{"commit_tokens": ["Adding", "@cert", "Acessor", "And", "Rewriting", "file", "If", "Exists"], "add_tokens": "attr_reader :cert @cert = @client . new_certificate ( Acme :: Client :: CertificateRequest . new ( names : domains ) ) save_certificate ( @cert ) @cert = certificate", "del_tokens": "save_certificate ( @client . new_certificate ( Acme :: Client :: CertificateRequest . new ( names : domains ) ) )", "commit_type": "add"}
{"commit_tokens": ["updated", "data", "and", "bumped", "version"], "add_tokens": "VERSION = '0.2.8'", "del_tokens": "VERSION = '0.2.7'", "commit_type": "update"}
{"commit_tokens": ["make", "RelativeTime#new", "a", "bit", "more", "readable", "as", "well"], "add_tokens": "units = count @seconds = units [ :seconds ] || 0 @months = units [ :months ] || 0", "del_tokens": "@seconds = count [ :seconds ] || 0 @months = count [ :months ] || 0", "commit_type": "make"}
{"commit_tokens": ["fixed", "bug", "for", "freeze", "VERSION", "when", "bundle", "update"], "add_tokens": "VERSION = \"1.0.5\"", "del_tokens": "VERSION = \"1.0.5\" . freeze", "commit_type": "fix"}
{"commit_tokens": ["Removing", "concept", "of", "interleaving", "from", "this", "version", "."], "add_tokens": "def initialize ( channels , bits_per_sample , sample_rate ) attr_accessor :channels , :bits_per_sample , :sample_rate", "del_tokens": "def initialize ( channels , bits_per_sample , sample_rate , interleaving ) @interleaving = interleaving attr_accessor :channels , :bits_per_sample , :sample_rate , :interleaving", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "getter", "for", "channels", "callbacks", "conversations", "settings", "and", "scripts"], "add_tokens": "attr_reader :channels , :callbacks , :conversations , :settings , :scripts", "del_tokens": "attr_accessor :scripts", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "show", "error", "if", "jruby", "not", "installed", "scenario", "as", "I", "don", "t", "know", "how", "to", "construct", "the", "test", "."], "add_tokens": "raise \"Need to setup @jruby_cmd to test jruby environment\" if @jruby_cmd . blank?", "del_tokens": "end Given / ^I do not have jruby installed$ / do @jruby_cmd = \"\"", "commit_type": "remove"}
{"commit_tokens": ["Added", "first", "batch", "of", "tests", ".", "Improved", "error", "handling", "with", "custom", "Errors", ".", "Added", "reset", "function", "to", "graph"], "add_tokens": "class SelfDependencyError < StandardError ; end class CircularDependencyError < StandardError ; end attr_accessor :dependee reset raise SelfDependencyError , \"An object's dependencies cannot contain itself\" if dependencies . include? key def reset @resolved = [ ] @seen_this_pass @nodes = [ ] end raise CircularDependencyError , \"Circular reference detected: #{node.key.to_s} - #{edge.key.to_s}\"", "del_tokens": "@resolved = [ ] @seen_this_pass @nodes = [ ] raise \"Circular reference detected: #{node.key.to_s} - #{edge.key.to_s}\"", "commit_type": "add"}
{"commit_tokens": ["Moving", "extensions", "to", "namespaced", "path"], "add_tokens": "require 'dropbox/extensions/array' require 'dropbox/extensions/hash' require 'dropbox/extensions/module' require 'dropbox/extensions/object' require 'dropbox/extensions/string' require 'dropbox/extensions/to_bool'", "del_tokens": "require 'extensions/array' require 'extensions/hash' require 'extensions/module' require 'extensions/object' require 'extensions/string' require 'extensions/to_bool'", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "the", "config", "argument"], "add_tokens": "config_path = config [ :config ] files_to_report = rubocop ( files_to_lint , force_exclusion , config_path : config_path ) def rubocop ( files_to_lint , force_exclusion , config_path : nil ) base_command = [ \"rubocop\" , \"-f\" , \"json\" ] base_command . concat ( [ \"--force-exclusion\" ] ) if force_exclusion base_command . concat ( [ \"--config\" , config_path . shellescape ] ) unless config_path . nil? rubocop_output = ` #{ 'bundle exec ' if File . exist? ( 'Gemfile' ) } #{ base_command . join ( ' ' ) } #{ files_to_lint } `", "del_tokens": "files_to_report = rubocop ( files_to_lint , force_exclusion ) def rubocop ( files_to_lint , force_exclusion ) base_command = 'rubocop -f json' base_command << ' --force-exclusion' if force_exclusion rubocop_output = ` #{ 'bundle exec ' if File . exist? ( 'Gemfile' ) } #{ base_command } #{ files_to_lint } `", "commit_type": "add"}
{"commit_tokens": ["Update", "spec", "for", "datatype", "and", "add", "in", "headers", "."], "add_tokens": "{ \"paramType\" => \"header\" , \"name\" => \"XAuthToken\" , \"description\" => \"A required header.\" , \"type\" => \"String\" , \"dataType\" => \"String\" , \"required\" => true } , { \"paramType\" => \"header\" , \"name\" => \"XOtherHeader\" , \"description\" => \"An optional header.\" , \"type\" => \"String\" , \"dataType\" => \"String\" , \"required\" => false } \"parameters\" => [ { \"paramType\" => \"form\" , \"name\" => \"items[]\" , \"description\" => \"array of items\" , \"type\" => \"String\" , \"dataType\" => \"String\" , \"required\" => false } ] \"parameters\" => [ { \"paramType\" => \"query\" , \"name\" => \"custom\" , \"description\" => \"array of items\" , \"type\" => \"CustomType\" , \"dataType\" => \"CustomType\" , \"required\" => false } ]", "del_tokens": "{ \"paramType\" => \"header\" , \"name\" => \"XAuthToken\" , \"description\" => \"A required header.\" , \"type\" => \"String\" , \"required\" => true } , { \"paramType\" => \"header\" , \"name\" => \"XOtherHeader\" , \"description\" => \"An optional header.\" , \"type\" => \"String\" , \"required\" => false } \"parameters\" => [ { \"paramType\" => \"form\" , \"name\" => \"items[]\" , \"description\" => \"array of items\" , \"type\" => \"String\" , \"required\" => false } ] \"parameters\" => [ { \"paramType\" => \"query\" , \"name\" => \"custom\" , \"description\" => \"array of items\" , \"type\" => \"CustomType\" , \"required\" => false } ]", "commit_type": "update"}
{"commit_tokens": ["Removed", "weird", "miles", "and", "kilometers", "."], "add_tokens": "@itudes_other = Geo :: Itudes . new lat , lon expect ( ( @itudes_other - @itudes ) . to_i ) . to eq ( dist_km . to_i ) expect ( ( @itudes_other . distance ( @itudes , :mi ) ) . to_i ) . to eq ( dist_mi . to_i )", "del_tokens": "@itudes_other_km = Geo :: Itudes . new lat , lon @itudes_other_mi = Geo :: Itudes . new ( lat , lon ) . miles! expect ( ( @itudes_other_km - @itudes ) . to_i ) . to eq ( dist_km . to_i ) expect ( ( @itudes_other_mi - @itudes ) . to_i ) . to eq ( dist_mi . to_i )", "commit_type": "remove"}
{"commit_tokens": ["Use", "locale", "in", "url", "parts", "of", "human_url"], "add_tokens": "\"/#{Humpyard::config.parsed_www_prefix(options)}#{(self.ancestors.reverse + [self]).collect{|p| p.title_for_url(options[:locale].to_sym)} * '/'}.html\" . gsub ( / ^index \\/ / , '' )", "del_tokens": "\"/#{Humpyard::config.parsed_www_prefix(options)}#{(self.ancestors.reverse + [self]).collect{|p| p.title_for_url} * '/'}.html\" . gsub ( / ^index \\/ / , '' )", "commit_type": "use"}
{"commit_tokens": ["fixes", "stub", "for", "cases", "with", "no", "parameters", "and", "adds", "an", "additional", "parameter", "to", "indicate", "what", "value", "the", "call", "returns"], "add_tokens": "def stub_trello_request! ( http_method , path , data , returning = '' ) uri . query_values = data . kind_of? ( String ) ? JSON . parse ( data ) : data if data to_return ( :status => 200 , :headers => { } , :body => returning )", "del_tokens": "def stub_trello_request! ( http_method , path , data ) uri . query_values = data . kind_of? ( String ) ? JSON . parse ( data ) : data to_return ( :status => 200 , :headers => { } , :body => '' )", "commit_type": "fix"}
{"commit_tokens": ["Use", "nicer", "rspec", "matcher", "for", "testing", "inclusion"], "add_tokens": "object . should include ( subject . first )", "del_tokens": "object . include? ( subject . first ) . should be ( true )", "commit_type": "use"}
{"commit_tokens": ["Allow", "referer", "to", "search", "engine", "without", "query", "params"], "add_tokens": "self . referer_params = '' if referer_params . blank? params = CGI :: parse ( referer_params )", "del_tokens": "self . referer_params = nil if referer_params . blank? params = CGI :: parse ( referer_params ) unless referer_params . blank?", "commit_type": "allow"}
{"commit_tokens": ["Use", "relation", "actual", "name", "for", "structs"], "add_tokens": "Struct . define ( relation . name . relation , relation . schema . project ( * attrs . keys ) ) . new ( attrs )", "del_tokens": "Struct . define ( relation . name , relation . schema . project ( * attrs . keys ) ) . new ( attrs )", "commit_type": "use"}
{"commit_tokens": ["add", "check", "for", "a", "merged", "requests"], "add_tokens": "if $oauth_token @github = Github . new oauth_token : $oauth_token else @github = Github . new end issues = @github . pull_requests . list $github_user , $github_repo_name , :state => 'closed' def is_megred ( number ) @github . pull_requests . merged? $github_user , $github_repo_name , number end def get_all_merged_pull_requests json = self . get_all_closed_pull_requests puts 'Check if the requests is merged' json . delete_if { | req | merged = self . is_megred ( req [ :number ] ) if @options [ :verbose ] puts \"##{req[:number]} merged #{merged}\" end ! merged } end end if __FILE__ == $0 log_generator = LogGenerator . new ( { :verbose => true } ) pull_requests = log_generator . get_all_closed_pull_requests p pull_requests . count json = log_generator . get_all_merged_pull_requests p json . count # json.each { |dict| # # print_json dict # p \"##{dict[:number]} - #{dict[:title]} (#{dict[:closed_at]})\" # }", "del_tokens": "if $oauth_token github = Github . new oauth_token : $oauth_token else github = Github . new end issues = github . pull_requests . list $github_user , $github_repo_name , :state => 'closed'", "commit_type": "add"}
{"commit_tokens": ["Move", "Windows", "-", "encoded", "characters", "cleaning", "into", "Middleware", "."], "add_tokens": "require 'active_support/multibyte/unicode' include ActiveSupport :: Multibyte :: Unicode value = tidy_bytes ( value ) if value && ! value . ascii_only? value = URIString . new ( value ) . cleaned if value . include? ( '%' ) value", "del_tokens": "if ! value . ascii_only? || value . include? ( '%' ) URIString . new ( value ) . cleaned else value end", "commit_type": "move"}
{"commit_tokens": ["made", "sure", "cached", "bodies", "are", "copies"], "add_tokens": "@cache [ path ] = [ et , marshal_copy ( body ) ] def marshal_copy ( o ) Marshal . load ( Marshal . dump ( o ) ) end", "del_tokens": "@cache [ path ] = [ et , body ]", "commit_type": "make"}
{"commit_tokens": ["Add", "more", "node", ".", "kind_of?", "(", "Ox", "::", "Element", ")", "checks", "to", "prevent", "crashing"], "add_tokens": "@tests = suite_root . nodes . map ( & :nodes ) . flatten . select { | node | node . kind_of? ( Ox :: Element ) && node . value == 'testcase' } failed_tests = failed_suites . map ( & :nodes ) . flatten . select { | node | node . kind_of? ( Ox :: Element ) && node . value == 'testcase' }", "del_tokens": "@tests = suite_root . nodes . map ( & :nodes ) . flatten . select { | node | node . value == 'testcase' } failed_tests = failed_suites . map ( & :nodes ) . flatten . select { | node | node . value == 'testcase' }", "commit_type": "add"}
{"commit_tokens": ["added", "#each", "and", "Enumerable", "to", "OrderedList"], "add_tokens": "eles = list_items # # Return the number of items contained in the ordered list # def items list_items . size end private def list_items element . find_elements ( :xpath , child_xpath ) end", "del_tokens": "eles = @element . find_elements ( :xpath , child_xpath )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "double", "-", "quoted", "strings"], "add_tokens": "require \"tty-prompt\" require \"tty-which\" require \"tempfile\" require \"fileutils\" require \"shellwords\" require_relative \"editor/version\" [ ENV [ \"VISUAL\" ] , ENV [ \"EDITOR\" ] ] . compact [ \"vim\" , \"vi\" , \"emacs\" , \"nano\" , \"nano-tiny\" , \"pico\" , \"mate -w\" ] [ \"notepad\" ] # TTY::Editor.open(\"filename.rb\") :: File . open ( @filename , \"a\" ) { | f | f . write ( options [ :content ] ) } \"Could not find editor to use. Please specify $VISUAL or $EDITOR\" prompt . enum_select ( \"Select an editor?\" , execs ) tempfile = Tempfile . new ( \"tty-editor\" ) raise CommandInvocationError , \"`#{command_path}` failed with status: #{$? ? $?.exitstatus : nil}\"", "del_tokens": "require 'tty-prompt' require 'tty-which' require 'tempfile' require 'fileutils' require 'shellwords' require_relative 'editor/version' [ ENV [ 'VISUAL' ] , ENV [ 'EDITOR' ] ] . compact [ 'vim' , 'vi' , 'emacs' , 'nano' , 'nano-tiny' , 'pico' , 'mate -w' ] [ 'notepad' ] # TTY::Editor.open('filename.rb') :: File . open ( @filename , 'a' ) { | f | f . write ( options [ :content ] ) } 'Could not find editor to use. Please specify $VISUAL or $EDITOR' prompt . enum_select ( 'Select an editor?' , execs ) tempfile = Tempfile . new ( 'tty-editor' ) fail CommandInvocationError , \"`#{command_path}` failed with status: #{$? ? $?.exitstatus : nil}\"", "commit_type": "change"}
{"commit_tokens": ["Adds", "EmailAddress", "methods", "for", "normal", "canonical", "valid?"], "add_tokens": "def normal alias :normalize :normal alias :canonicalize :canonical def canonical_md5 Digest :: MD5 . hexdigest ( self . canonical ) end", "del_tokens": "def normalize", "commit_type": "add"}
{"commit_tokens": ["Changed", "example", "to", "not", "use", "block", "."], "add_tokens": "topic , message = client . get puts \"#{topic}: #{message}\"", "del_tokens": "client . get do | topic , message | puts \"#{topic}: #{message}\" end", "commit_type": "change"}
{"commit_tokens": ["Fixing", "bug", "with", "text", "columns", "and", "parsing", "the", "size", "."], "add_tokens": "match [ 1 ] . to_i if match && match [ 1 ]", "del_tokens": "match [ 1 ] . to_i if match [ 1 ]", "commit_type": "fix"}
{"commit_tokens": ["add", "new", "dispatching", "structure", "for", "both", "RPC", "and", "Job", "."], "add_tokens": "RpcChannel . new ( node ) . register_endpoint ( \"job-stats.#{node.node_id}\" , proc { | req , res | case res . command when 'get' res . response ( { :active_jobs => @active_jobs . map { | j | j . to_hash } } ) else raise Rack :: UnknownMethodError end", "del_tokens": "RpcChannel . new ( node ) . register_endpoint ( \"job-stats.#{node.node_id}\" , RpcChannel :: ProcDispatcher . new { | d | d . add ( 'get' ) { { :active_jobs => @active_jobs . map { | j | j . to_hash } } } class JobDispatcher < RpcChannel :: Dispatcher :: Decorator include Logger def initialize ( dispatcher , job_worker ) super ( dispatcher ) @job_worker = job_worker end def dispatch ( resctx , key , args = [ ] ) job = @job_worker . run ( ) { begin dispatcher . dispatch ( reqctx , key , args ) resctx . response ( 1 ) unless resctx . responded ensure end } resctx . progress ( { :job_id => job . job_id } ) end end", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "stdin", "/", "stdout", "/", "stderr", "redirects", "."], "add_tokens": "stdin = File . open ( stdin , \"rb\" ) if stdin . is_a? ( String ) stdout = File . open ( stdout , \"wb\" ) if stdout . is_a? ( String ) stderr = File . open ( stderr , \"wb\" ) if stderr . is_a? ( String ) stdout = stderr if stdout == :stderr stderr = stdout if stderr == :stdout if stdout != $stdout && stdout . is_a? ( IO ) && ! stdout . closed? then stdout . close end if stderr != $stderr && stderr . is_a? ( IO ) && ! stderr . closed? then stderr . close end stderr . flush stdout . close if stdout != $stdout && ! stdout . closed? stderr . close if stderr != $stderr && ! stderr . closed?", "del_tokens": "if stdout != $stdout && ! stdout . closed? then stdout . close end if stderr != $stderr && ! stderr . closed? then stderr . close end stdout . close unless stdout == $stdout stderr . close unless stderr == $stderr", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "non", "-", "blocking", "equivalent", "to", "get"], "add_tokens": "alias_method :_original_get , :get response = _original_get ( * args ) ## # will return the next item or nil def fetch ( * args ) _original_get ( * args ) end", "del_tokens": "response = super ( * args )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "favour", "constant", "fit"], "add_tokens": "residual_sq = 1 # doesn't exist", "del_tokens": "residual_sq = 0 # doesn't exist", "commit_type": "change"}
{"commit_tokens": ["updated", "boilerplate", "for", "moving", "to", "GCP", "from", "AWS"], "add_tokens": "require \"net_http_utils\" require_relative \"#{Dir.home}/beat.rb\" unless Gem :: Platform . local . os == \"darwin\"", "del_tokens": "require_relative File . join \"../..\" , * ( \"../download_with_retry\" if ENV [ \"LOGNAME\" ] == \"nakilon\" ) , \"download_with_retry\" RedditBot . init * File . read ( \"secrets\" ) . split , ignore_captcha : true if RedditBot :: VERSION <= \"0.1.3\" require_relative File . join \"../..\" , * ( \"..\" if ENV [ \"LOGNAME\" ] == \"nakilon\" ) , \"awsstatus/2.rb\"", "commit_type": "update"}
{"commit_tokens": ["removed", "load", "path", "statements", "since", "Rake", "test", "task", "automatically", "appends"], "add_tokens": "require 'twilio'", "del_tokens": "$LOAD_PATH . unshift ( File . join ( File . dirname ( __FILE__ ) , '..' , 'lib' ) ) $LOAD_PATH . unshift ( File . dirname ( __FILE__ ) ) require 'twilio'", "commit_type": "remove"}
{"commit_tokens": ["added", "explicit", "load", "+", "execute", "options", "cleaner", "load", "options"], "add_tokens": "@original_command = @command if init || @options [ :execute ] execute_command else $stderr . puts \"Error: Command #{@command} not found.\" end end def execute_command if @options [ :execute ] Boson . main_object . instance_eval \"#{@original_command} #{@args.join(' ')}\" else Library . load boson_libraries , load_options @options [ :load ] ? load_command_by_option : ( @options [ :discover ] ? load_command_by_discovery : load_command_by_index ) def load_command_by_option Library . load @options [ :load ] . split ( / \\s *, \\s * / ) , load_options end def load_command_by_index Library . load_library found . lib , load_options def load_options @load_options ||= { :verbose => @options [ :verbose ] } end index_commands ( load_options ) { :discover => false , :verbose => false , :index_create => false , :execute => false , :load => false } Library . load [ e ] , load_options", "del_tokens": "if init else $stderr . puts \"Error: Command #{@command} not found.\" Library . load boson_libraries , @options @options . delete ( :discover ) ? load_command_by_discovery : load_command_from_index def load_command_from_index Library . load_library found . lib , @options index_commands ( @options ) { :discover => false , :verbose => false , :index_create => false } Library . load [ e ] , @options", "commit_type": "add"}
{"commit_tokens": ["fixed", "every", "to", "work", "with", "variables", "in", "deep", "procs", "in", "b"], "add_tokens": "# a block that makes a snapshot of b snapshot = nil snapshot = proc do | subterm | case subterm when Proc proc do subterm . call_with_rubylog_variables vars when Rubylog :: Variable if subterm . bound? subterm . rubylog_dereference . rubylog_clone ( & snapshot ) else subterm end else subterm end # collect resolved b's in an array resolved_bs = [ ] a . prove do resolved_bs << b . rubylog_clone ( & snapshot ) # chain resolved b's together goal = resolved_bs . empty? ? :true : resolved_bs . inject { | a , b | a . and b } # match variables in the resolved b's together with variables in a goal = [ a . rubylog_variables , goal ] . rubylog_match_variables [ 1 ] # prove b's goal . prove { yield } primitives_for_clause . send ( fct , * args , & block )", "del_tokens": "c = [ ] a . prove do if b . is_a? Proc b_resolved = proc do b . call_with_rubylog_variables vars else b_resolved = b . rubylog_deep_dereference c << b_resolved c . inject ( :true ) { | a , b | a . and b } . solve { yield } primitives_for_clause . send ( fct , * args , & block )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "couple", "remaining", "references", "to", "mattock", "expand", "documentation", "with", "examples", "of", "run", "/", "execute", "etc", "."], "add_tokens": "# Run the command, wait for termination, and collect the results. # Returns an instance of CommandRunResult that contains the output # and exit code of the command. # # This version adds some information to STDOUT to document that the # command is running. For a terser version, call #execute directly def run report string_format + \" \" , false result = execute report \"=> #{result.exit_code}\" report result . format_streams if verbose return result ensure report \"\" if verbose end def run_as_replacement alias replace_us run_as_replacement def run_detached alias spin_off run_detached # def run_in_background alias background run_in_background # Given a process ID for a running command and a pair of stdout/stdin # streams, records the results of the command and returns them in a # CommandRunResult instance.", "del_tokens": "def replace_us def spin_off def background def run report string_format + \" \" , false result = execute report \"=> #{result.exit_code}\" report result . format_streams if verbose return result ensure report \"\" if verbose end", "commit_type": "fix"}
{"commit_tokens": ["move", "erb", "filters", "to", "textutils", "gem", "for", "reuse"], "add_tokens": "require 'textutils' # text filters and helpers VERSION = '1.1.0.beta3'", "del_tokens": "VERSION = '1.1.0.beta2'", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "javascript", "requests", "to", "be", "redirected", "properly"], "add_tokens": "authenticate_request unless logged_in? authenticate_request unless registered_user? authenticate_request unless in_group authenticate_request unless user_has_id? ( id ) authenticate_request # redirects the user to (re)authenticate with # the Idp or a 403 forbidden page def authenticate_request url = logged_in? ? shibbolite . access_denied_url : shibbolite . login_url # redirect to the selected url respond_to do | format | format . html { redirect_to url } format . js { render js : \"window.location.assign('#{url}');\" } end", "del_tokens": "redirect_to login_or_access_denied unless logged_in? redirect_to login_or_access_denied unless registered_user? redirect_to login_or_access_denied unless in_group redirect_to login_or_access_denied unless user_has_id? ( id ) redirect_to login_or_access_denied # a handy redirect target def login_or_access_denied logged_in? ? shibbolite . access_denied_url : shibbolite . login_url", "commit_type": "add"}
{"commit_tokens": ["Added", "handling", "for", "multiple", "@", "in", "id_right", "of", "message", "id"], "add_tokens": "", "del_tokens": "require 'ruby-debug'", "commit_type": "add"}
{"commit_tokens": ["Changed", "method", "names", "and", "arguments", "to", "more", "closely", "map", "to", "jquery"], "add_tokens": "def attr ( selector , attributes_or_attribute_name , value = nil ) attributes = attributes_or_attribute_name . to_effigy_attributes ( value ) def replace_each ( selector , collection , & block ) def add_class ( selector , * class_names ) def remove_class ( selector , * class_names ) def html ( selector , xml ) def replace_with ( selector , xml ) if block_given? old_context = @current_context @current_context = select ( selector ) yield @current_context = old_context else Selection . new ( self , selector ) end find ( item_element ) { yield ( item ) }", "del_tokens": "def attributes ( selector , attributes ) def replace_with_each ( selector , collection , & block ) def context ( new_context ) old_context = @current_context @current_context = select ( new_context ) yield @current_context = old_context end def add_class_names ( selector , * class_names ) def remove_class_names ( selector , * class_names ) def inner ( selector , xml ) def outer ( selector , xml ) Selection . new ( self , selector ) context ( item_element ) { yield ( item ) }", "commit_type": "change"}
{"commit_tokens": ["fix", "bug", "with", "loading", "a", "different", "procfile"], "add_tokens": "@procfile_path = procfile", "del_tokens": "@procfile = procfile", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "get_file", "put_file", "post_file", "and", "copy", "methods", "in", "Patron"], "add_tokens": "handle_file_name ( req , webmock_response ) def handle_file_name ( req , webmock_response ) if req . action == :get && req . file_name File . open ( req . file_name , \"w\" ) do | f | f . write webmock_response . body end end end uri . user = req . username if req . file_name && [ :put , :post ] . include? ( req . action ) request_body = File . read ( req . file_name ) else request_body = req . upload_data end :body => request_body ,", "del_tokens": "uri . user = req . username :body => req . upload_data ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "some", "bugs", "repaired", "tests", "and", "added", "some", "test", "classes"], "add_tokens": "add_p add_q bookings . each { | b | add_t ( b ) } add_y ( 1 ) puts dta_string", "del_tokens": "# TODO CHANGE THIS", "commit_type": "fix"}
{"commit_tokens": ["fixing", "URI", "appearing", "where", "it", "didn", "t", "belong"], "add_tokens": "def gateway require 'net/http' URI . parse 'http://gateway.4info.net/msg' end", "del_tokens": "Gateway = URI . parse 'http://gateway.4info.net/msg'", "commit_type": "fix"}
{"commit_tokens": ["Add", "active", "record", "4", "support"], "add_tokens": "VERSION = '0.1.0' def has_one_with_protect ( * args ) #:nodoc: reflection = if active_record_4? association_id , options , scope , extension = * args create_reflection ( :has_one , association_id , options , scope ||= { } , self ) else association_id , options , extension = * args create_reflection ( :has_one , association_id , options , self ) end has_one_without_protect ( * args ) #association_id, options, &extension) reflection = if active_record_4? create_reflection ( :has_many , association_id , options , scope ||= { } , self ) else create_reflection ( :has_many , association_id , options , self ) end dependent_type = active_record_4? ? options [ :dependent ] : reflection . options [ :dependent ] method_name = \"dependent_#{dependent_type}_for_#{reflection.name}\" case dependent_type when :rollback , :restrict_with_error when :restrict , :restrict_with_exception def active_record_4? :: ActiveRecord :: VERSION :: MAJOR == 4 end", "del_tokens": "VERSION = '0.0.6' def has_one_with_protect ( association_id , options = { } , & extension ) #:nodoc: reflection = create_reflection ( :has_one , association_id , options , self ) has_one_without_protect ( association_id , options , & extension ) reflection = create_reflection ( :has_many , association_id , options , self ) case reflection . options [ :dependent ] when :rollback method_name = \"dependent_rollback_for_#{reflection.name}\" . to_sym when :restrict method_name = \"dependent_restrict_for_#{reflection.name}\" . to_sym", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "simpify", "color", "resolution", "."], "add_tokens": "# Resolve uncolored string # # @api private color . decorate ( unprocessed_string , * base )", "del_tokens": "base . reduce ( unprocessed_string ) do | component , decorator | color . decorate ( component , decorator ) end", "commit_type": "change"}
{"commit_tokens": ["Updating", ":", "format", "to", "take", "params", "-", "e", ".", "g", ".", "mogrify", "-", "format", "jpg", "-", "density", "300", "sample", ".", "pdf"], "add_tokens": "c = CommandBuilder . new ( 'mogrify' , '-format' , format ) yield c if block_given? c << @path run ( c )", "del_tokens": "run_command ( \"mogrify\" , \"-format\" , format , @path )", "commit_type": "update"}
{"commit_tokens": ["add", "references", "for", "column", "and", "references", "message", "in", "migration"], "add_tokens": "[ :integer , :column , :references ] . each do | message | node . grep_nodes ( { :node_type => :call , :message => message } ) . each do | integer_node | column_name = eval ( integer_node . arguments [ 1 ] . to_ruby ) . to_s column_name += \"_id\" if :references == message @references [ table_name ] ||= [ ] @references [ table_name ] << column_name end", "del_tokens": "node . grep_nodes ( { :node_type => :call , :message => :integer } ) . each do | integer_node | column_name = eval ( integer_node . arguments [ 1 ] . to_ruby ) . to_s @references [ table_name ] ||= [ ] @references [ table_name ] << column_name", "commit_type": "add"}
{"commit_tokens": ["Changed", "expected", "response", "for", "test_command", "to", "reflect", "previous", "changes", "(", "tests", "receive", "-", "pack", "instead", "of", "status", "))"], "add_tokens": "GIT_RECEIVE_RESPONSE = \"0078cb067e06bdf6e34d4abebf6cf2de85d65a52c65e refs/heads/master\\u0000 report-status delete-refs side-band-64k quiet ofs-delta\" assert_equal GIT_RECEIVE_RESPONSE , @test_git . command ( \"receive-pack --advertise-refs\" , { :args => [ example ] } ) . split ( \"\\n\" ) . first end", "del_tokens": "GIT_STATUS_RESPONSE = \"00788aea0b0551a2f89151033760d135a7ac338adb79 refs/heads/master\\u0000 report-status delete-refs side-band-64k quiet ofs-delta\" assert_equal GIT_STATUS_RESPONSE , @test_git . command ( \"receive-pack --advertise-refs\" , { :args => [ example ] } ) . split ( \"\\n\" ) . first end", "commit_type": "change"}
{"commit_tokens": ["Update", "rdoc", "documentation", "in", "source", "files"], "add_tokens": "# = typed-array - Gemp provides enforced-type functionality to Arrays # # Copyright (c) 2011 Ryan Biesemeyer # See LICENSE.txt for details # # Ryan Biesemeyer mailto:ruby-dev@yaauie.com # # == Example # === Create Standard Class # require 'typed-array' # class Things < Array # extend TypedArray # restrict_types Thing1,Thing2 # end # # === Generate Class using Factory # # require 'typed-array' # things = TypedArray(Thing1,Thing2) # === Adding items to the Array # # # All standard Array interfaces are implemented, including block-processing # # and variable-number of arguments. For methods that would usually return an # # Array, they instead return an instance of the current class (except to_a). # # # # The difference is that if the method would generate an Array including the # # wrong types, TypedArray::UnexpectedTypeException is raised and the call is # # aborted before modifying the enforced TypedArray instance. # # require 'typed-array' # symbols = TypedArray(Symbol).new([:foo,:bar,:baz,:bingo]) # begin # integers = TypedArray(Integer).new([1,3,7,2,:symbol]) # rescue TypedArray::UnexpectedTypeException # puts \"An error occured: #{$!}\" # end # require \"typed-array/functions\" # Provides TypedArray functionality to a subclass of Array # when extended in the class's definiton # The exception that is raised when an Unexpected Type is reached during validation # Provide access to the types of objects expected and the class of the object received # Provide a factory method. Takes any number of types to accept as arguments # and returns a class that behaves as a type-enforced array.", "del_tokens": "require \"typed-array/functions\" # This module is useful for creating Array subclasses that enforce # the types of objects it acepts. # There are two general forms: # # class Things < Array # extend TypedArray # restricted_types Thing1, Thing2 # # ... # end # things = Things.new() # or # things = TypedArray(Thing1,Thing2).new # # We attempt to ensure that validation occurs *before* any changes are made # to the TypedArray in question. # If validation fails, TypedArray::UnexpectedTypeException is raised. # Provide a factory #", "commit_type": "update"}
{"commit_tokens": ["moved", "datepicker", "over", "to", "acclaims", "so", "that", "it", "didn", "t", "interfere", "with", "date", "range"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20141027234702 ) do t . boolean \"on_stage\" , default : true t . boolean \"on_prod\" , default : false t . date \"publication_date\"", "del_tokens": "ActiveRecord :: Schema . define ( version : 20141021184641 ) do t . boolean \"on_stage\" , default : true t . boolean \"on_prod\" , default : false", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "to", "emulate", "the", "OracleAdapter", ".", "This", "is", "useful", "when", "trying", "to", "get", "rails", "tests", "to", "pass", "since", "there", "are", "still", "conditionals", "in", "the", "code", "that", "check", "for", "the", "current", "adapter", "being", ":", "OracleAdapter", ".", "It", "emulates", "the", "OracleAdapter", "in", "the", "sense", "that", "its", "class", "is", "that", "of", "the", "OracleAdapter", ".", "This", "is", "only", "turned", "on", "for", "a", "connection", "that", "defines", ":", "emulate_oracle_adapter", "=", ">", "true", "during", "connection", "establishment", "."], "add_tokens": "if config [ :emulate_oracle_adapter ] == true # allows the enhanced adapter to look like the OracleAdapter. Useful to pick up # conditionals in the rails activerecord test suite require 'active_record/connection_adapters/emulation/oracle_adapter' ConnectionAdapters :: OracleAdapter . new ( ConnectionAdapters :: OracleEnhancedConnection . create ( config ) , logger ) else ConnectionAdapters :: OracleEnhancedAdapter . new ( ConnectionAdapters :: OracleEnhancedConnection . create ( config ) , logger ) end", "del_tokens": "ConnectionAdapters :: OracleEnhancedAdapter . new ( ConnectionAdapters :: OracleEnhancedConnection . create ( config ) , logger )", "commit_type": "add"}
{"commit_tokens": ["Add", "changelog", "support", "remove", "cloc", "metrics"], "add_tokens": "migrate_to :cocoadocs , version : 15", "del_tokens": "migrate_to :cocoadocs , version : 13", "commit_type": "add"}
{"commit_tokens": ["adding", "the", "request", ":", "method", "to", "the", "instrumentation", "payload"], "add_tokens": "response = self . post '{/index}{/type}/_bulk' , params . merge ( :body => body , :action => 'bulk' )", "del_tokens": "response = self . post '{/index}{/type}/_bulk' , params . merge ( :body => body )", "commit_type": "add"}
{"commit_tokens": ["fix", "specs", "to", "work", "with", "latest", "gems", "and", "ruby"], "add_tokens": "ActiveRecord :: Base . establish_connection ( \"adapter\" => \"sqlite3\" , \"database\" => \":memory:\" ) Sunspot :: IndexQueue :: Entry . implementation = :active_record Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . create_table ping_uri = URI . parse ( \"http://127.0.0.1:18983/solr/admin/ping\" ) Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . connection . drop_table ( Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . table_name ) if Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . table_exists?", "del_tokens": "ping_uri = URI . parse ( \"http://127.0.0.1:18983/solr/ping\" ) ActiveRecord :: Base . establish_connection ( \"adapter\" => \"sqlite3\" , \"database\" => \":memory:\" ) Sunspot :: IndexQueue :: Entry . implementation = :active_record Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . create_table Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . connection . drop_table ( Sunspot :: IndexQueue :: Entry :: ActiveRecordImpl . table_name )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "simultaneous", "versions", "of", "Ruby", "to", "compile", "extensions", "."], "add_tokens": "Dir . glob ( \"#{folder}/**/#{name}/#{RUBY_VERSION}\" ) . should be_empty", "del_tokens": "Dir . glob ( \"#{folder}/**/#{name}\" ) . should be_empty", "commit_type": "allow"}
{"commit_tokens": ["add", "support", "for", "sending", "CF", "logs", "to", "rabbitmq"], "add_tokens": "VERSION = \"0.0.13\"", "del_tokens": "VERSION = \"0.0.12\"", "commit_type": "add"}
{"commit_tokens": ["added", "more", "test", "for", "the", "client", "and", "worker", "code"], "add_tokens": "@tmp_path = File . join ( File . dirname ( __FILE__ ) , \"tmp\" )", "del_tokens": "@tmp_path = File . join ( File . dirname ( __FILE__ ) , \"..\" , \"tmp\" )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "make", "sure", "color", "decorate", "doesn", "t", "apply", "to", "non", "-", "string", "."], "add_tokens": "ANSI_REGEX = / ( \\[ )? \\033 ( \\[ )?[:;? \\d ]*[ \\d A-Za-z]( \\] )? /o . freeze BLANK_REGEX = / \\A [[:space:]]* \\z /o . freeze @enabled = options . fetch ( :enabled ) { TTY :: Screen . color? } return string if blank? ( string ) || ! enabled # Check if value contains anything to style # # @return [Boolean] # # @api private def blank? ( value ) value . nil? || value . respond_to? ( :empty? ) && value . empty? || BLANK_REGEX =~ value end", "del_tokens": "ANSI_REGEX = / ( \\[ )? \\033 ( \\[ )?[:;? \\d ]*[ \\d A-Za-z]( \\] )? / . freeze @enabled = options . fetch ( :enabled ) { TTY :: Screen . color? } return string if string . empty? || ! enabled", "commit_type": "change"}
{"commit_tokens": ["Made", "all", "methods", "take", "multiple", "ids", "."], "add_tokens": "def get_entries * summoner_ids perform_request ( api_url ( \"league/by-summoner/#{summoner_ids.join(',')}/entry\" ) ) . map { | e | LeagueEntry . new e } def by_team * team_ids perform_request ( api_url ( \"league/by-team/#{team_ids.join(',')}\" ) ) . map { | l | League . new l } def entries_by_team * team_ids perform_request ( api_url ( \"league/by-team/#{team_ids.join(',')}/entry\" ) ) . map { | e | LeagueEntry . new e }", "del_tokens": "def get_entries summoner_id perform_request ( api_url ( \"league/by-summoner/#{summoner_id}/entry\" ) ) . map { | e | LeagueEntry . new e } def by_team team_id perform_request ( api_url ( \"league/by-team/#{team_id}\" ) ) . map { | l | League . new l } def entries_by_team team_id perform_request ( api_url ( \"league/by-team/#{team_id}/entry\" ) ) . map { | e | LeagueEntry . new e }", "commit_type": "make"}
{"commit_tokens": ["added", "food", "goals", ";", "scope", "option", "can", "be", "passed", "in", "as", "array"], "add_tokens": "@scope = options [ :scope ] . join ( \" \" ) || \"activity nutrition profile settings sleep social weight\"", "del_tokens": "@scope = options [ :scope ] || \"profile weight nutrition sleep\"", "commit_type": "add"}
{"commit_tokens": ["fixed", "incorrect", "name", "of", "marker", "channel", "image", "getting", "function"], "add_tokens": "f . setReferenceImage ( input_images . getMarkerImage ) mask = ImageFactory . createWritable ( input_images . getMarkerImage )", "del_tokens": "f . setReferenceImage ( input_images . reference ) mask = ImageFactory . createWritable ( input_images . reference )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "race", "condition", "that", "caused", "improper", "painting", "on", "windows"], "add_tokens": "Gems . install_gems_in_production ( @production )", "del_tokens": "Gems . install_gems_in_production ( @production )", "commit_type": "fix"}
{"commit_tokens": ["Add", "mime", "type", "to", "javascript", "tags"], "add_tokens": "%Q(<script src=\"#{path}\" type=\"text/javascript\"></script>)", "del_tokens": "%Q(<script src=\"#{path}\"></script>)", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "integration", "test", "for", "HiveJob", "."], "add_tokens": "describe \"integration happy path\" do use_vcr_cassette \"hive_job/hive_ads\" , :record => :none it \"should kick off the sample Amazion EMR Hive application\" do hive = Elasticity :: HiveJob . new ( AWS_ACCESS_KEY_ID , AWS_SECRET_KEY ) hive . ec2_key_name = \"sharethrough_dev\" jobflow_id = hive . run ( \"s3n://elasticmapreduce/samples/hive-ads/libs/model-build.q\" , { \"LIBS\" => \"s3n://elasticmapreduce/samples/hive-ads/libs\" , \"INPUT\" => \"s3n://elasticmapreduce/samples/hive-ads/tables\" , \"OUTPUT\" => \"s3n://slif-elasticity/hive-ads/output/2011-04-19\" } ) jobflow_id . should == \"j-1UUVYMHBLKEGN\" end end", "del_tokens": "# describe \"integration happy path\" do # use_cassette \"hive_job/hive_ads\", :record => all # xit \"should kick off the sample Amazion EMR Hive application\" do # # end # end", "commit_type": "add"}
{"commit_tokens": ["add", "extra", "arg", "in", "all", "run", "()", "methods"], "add_tokens": "def run ( redis , arg ) def run ( redis , arg ) def run ( redis , arg ) def run ( redis , arg ) redis . get ( arg ) def run ( redis , arg ) redis . exists ( arg )", "del_tokens": "def run ( redis ) def run ( redis ) def run ( redis ) def run ( redis ) redis . get ( @arg ) def run ( redis ) redis . exists ( @arg )", "commit_type": "add"}
{"commit_tokens": ["moved", "unit", "tests", "to", "test", "/", "unit"], "add_tokens": "class GravatarifyArDmTest < Test :: Unit :: TestCase", "del_tokens": "class GravatarifyIntegrationTest < Test :: Unit :: TestCase", "commit_type": "move"}
{"commit_tokens": ["Added", "attribute", "handling", "to", "liquid", "tag", "and", ".", "yml", "files"], "add_tokens": "attr_reader :context , :source_images , :html_attributes # [preset] img.jpg [source_key: alt.jpg] [--(element || alt) attr=\\\"value\\\"] build_html_attributes params . join ( ' ' ) def build_html_attributes ( params ) @html_attributes = preset [ 'attributes' ] . transform_keys ( & :to_sym ) # Example input: # --picture class=\"awesome\" --alt stumpy --img data-attribute=\"value\" params . split ( ' --' ) . map ( & :strip ) . each do | param | # ['picture class=\"awesome\"', 'alt stumpy', 'img data-attribute=\"value\"'] a = param . split # Splits on spaces, the first word will be our key. @html_attributes [ a . shift . to_sym ] = a . join ( ' ' ) end", "del_tokens": "attr_reader :context , :source_images # [preset] img.jpg [source_key: alt-img.jpg] [attr=\\\"value\\\"] parse_html_attributes params def parse_html_attributes ( params ) # Dealing with custom attributes, as well as the alt text", "commit_type": "add"}
{"commit_tokens": ["fixing", "version", "number", "(", "no", "reserve_number", "anymore", ")", "[", "will", "create", "a", "branch", "for", "that", "]"], "add_tokens": "VERSION = \"0.3.1\"", "del_tokens": "VERSION = \"0.4.0\"", "commit_type": "fix"}
{"commit_tokens": ["Remove", "auth", "from", "Repo", "."], "add_tokens": "attr_accessor :source , :cache , :local_clone def initialize source : nil , cache : \"#{Dir.tmpdir}/palimpsest\" # Path to place the local clone of the repository. # If not set, a unique path will be used under the {#cache}.", "del_tokens": "# # @!attribute auth # @return [Hash] any information required for authentication attr_accessor :source , :cache , :auth , :local_clone def initialize source : nil , cache : \"#{Dir.tmpdir}/palimpsest\" , auth : { } self . auth = auth", "commit_type": "remove"}
{"commit_tokens": ["Added", "some", "argument", "errors", "and", "specs", "."], "add_tokens": "raise ArgumentError , 'only get, post, put and delete methods are supported' unless %w[ get post put delete ] . include? ( method . to_s ) raise ArgumentError , ':query must be a hash' if options [ :query ] && ! options [ :query ] . is_a? ( Hash ) raise ArgumentError , ':headers must be a hash' if options [ :headers ] && ! options [ :headers ] . is_a? ( Hash ) path = path . starts_with? ( '/' ) ? path : \"/#{path}\" @format ||= format_from_path ( path ) uri . query = default_params . merge ( options [ :query ] || { } ) . to_query", "del_tokens": "path = path . starts_with? ( '/' ) ? path : \"/#{path}\" @format = format_from_path ( path ) unless @format params = default_params params . merge! ( options [ :query ] || { } ) uri . query = params . to_query", "commit_type": "add"}
{"commit_tokens": ["added", "api", "context", "logging", "support", "result", "code"], "add_tokens": "require 'action_command/log_parser' require 'action_command/pretty_print_log_action' # Used as a root element when the command is executed from an API context CONTEXT_API = :api # Used if a result has had no failures RESULT_CODE_OK = 0 # Used as a generic result code for failure, if you do not provide # a more specific one through {ActionCommand::Result#failed_with_code} RESULT_CODE_FAILED = 1 # log entry for the input to a commmand LOG_KIND_COMMAND_INPUT = :command_input # log entry for the output from a command LOG_KIND_COMMAND_OUTPUT = :command_output # info message from within a command LOG_KIND_INFO = :info # debug message from within a command LOG_KIND_DEBUG = :debug # error message from within a command LOG_KIND_ERROR = :error return ActionCommand :: Result . new # Execute a command at the root level of an api context # @param cls [ActionCommand::Executable] The class of an Executable subclass # @param params [Hash] parameters used by the command. # @return [ActionCommand::Result] def self . execute_api ( cls , params = { } ) result = create_result return ActionCommand . create_and_execute ( cls , params , CONTEXT_API , result ) end result . push ( result_key , cls ) check_params ( cls , params ) params [ :parent ] = parent result . logger = params [ :logger ] result . logger = @@logger unless params [ :logger ] result . root_command ( cls ) if parent . is_a? Symbol action = cls . new ( params ) result . log_input ( params ) action . execute ( result ) result . log_output return result end def self . check_params ( cls , params )", "del_tokens": "return ActionCommand :: Result . new ( @@logger ) result . push ( result_key ) params [ :parent ] = parent action = cls . new ( params ) return action . execute ( result )", "commit_type": "add"}
{"commit_tokens": ["Add", "strong", "type", "check", "to", "ensure", "that", "filters", "do", "not", "accept", "hashes", "(", "which", "can", "perform", "inner", "joins", "in", "the", "model", ")", ".", "Supply", ":", "type", "=", ">", ":", "hash", "to", "specify", "you", "expect", "a", "hash", "."], "add_tokens": "has_scope :only_tall , :type => :boolean , :only => :index , :if => :restrict_to_only_tall_trees? has_scope :paginate , :type => :hash has_scope :categories , :type => :array def test_scope_of_type_hash hash = { \"page\" => \"1\" , \"per_page\" => \"1\" } Tree . expects ( :paginate ) . with ( hash ) . returns ( Tree ) Tree . expects ( :all ) . returns ( [ mock_tree ] ) get :index , :paginate => hash assert_equal ( [ mock_tree ] , assigns ( :trees ) ) assert_equal ( { :paginate => hash } , current_scopes ) end def test_scope_of_type_array array = %w( book kitchen sport ) Tree . expects ( :categories ) . with ( array ) . returns ( Tree ) Tree . expects ( :all ) . returns ( [ mock_tree ] ) get :index , :categories => array assert_equal ( [ mock_tree ] , assigns ( :trees ) ) assert_equal ( { :categories => array } , current_scopes ) end def test_invalid_type_hash_for_default_type_scope assert_raise RuntimeError do get :index , :color => { :blue => :red } end end def test_invalid_type_string_for_hash_type_scope assert_raise RuntimeError do get :index , :paginate => \"1\" end end", "del_tokens": "has_scope :only_tall , :boolean => true , :only => :index , :if => :restrict_to_only_tall_trees?", "commit_type": "add"}
{"commit_tokens": ["Add", "rake", "retrieve", "task", "and", "make", "rubyzip", "overwrite", "files"], "add_tokens": "zip . extract ( f , path ) { true }", "del_tokens": "zip . extract ( f , path )", "commit_type": "add"}
{"commit_tokens": ["Use", "instance_variable_defined", "instead", "of", "defined?"], "add_tokens": "settings = instance_variable_defined? ( :@namespace ) ? @settings . get_value ( @namespace ) : @settings", "del_tokens": "settings = defined? ( @namespace ) ? @settings . get_value ( @namespace ) : @settings", "commit_type": "use"}
{"commit_tokens": ["Change", "command", "profile", "remove", "to", "choose", "from", "profiles", "list"], "add_tokens": "# profile_command.arg_name \"[name]\" # help_now!(error('You did not supply a profile name')) if args.count == 0 Bebox :: ProfileWizard . new . remove_profile ( project_root )", "del_tokens": "profile_command . arg_name \"[name]\" help_now! ( error ( 'You did not supply a profile name' ) ) if args . count == 0 Bebox :: ProfileWizard . new . remove_profile ( project_root , args . first )", "commit_type": "change"}
{"commit_tokens": ["fix", "typo", "in", "error", "name"], "add_tokens": "class CounterTooLowError < Error ; end", "del_tokens": "class CounterToLowError < Error ; end", "commit_type": "fix"}
{"commit_tokens": ["improve", "error", "display", "when", "inspecting", "in", "the", "console"], "add_tokens": "class Error \"<Twirp::Error code:#{code} msg:#{msg.inspect} meta:#{meta.inspect}>\" end def inspect to_s", "del_tokens": "class Error \"<Twirp::Error code:#{code.inspect} msg:#{msg.inspect} meta:#{meta.inspect}>\"", "commit_type": "improve"}
{"commit_tokens": ["use", "listen", "gem", "to", "watch", "for", "calendar", "file", "changes", "."], "add_tokens": "require 'listen' # Read in calendar files, fill global cal var. def load_global_cal $cal = EventCalendar . new ( $conf [ 'calendar_files' ] ) end load_global_cal # Watch for calendar file changes. [ * $conf [ 'calendar_files' ] ] . each do | file | path = Pathname . new ( file ) . realpath dir = path . dirname . to_s base = path . basename . to_s listener = Listen . to ( dir , only : / #{ base } / ) { load_global_cal } listener . start end ( DateTime . now .. DateTime . now + 2 ) . each do | day | #@events = @events.values.flatten.sort_by {|e| e.start_time} @today = Date . today @tomorrow = @today + 1", "del_tokens": "$cal = EventCalendar . new ( $conf [ 'calendar_files' ] ) puts $conf [ 'calendar_colors' ] ( DateTime . now .. DateTime . now + 30 ) . each do | day | @events = @events . values . flatten . sort_by { | e | e . start_time }", "commit_type": "use"}
{"commit_tokens": ["Use", "benchmark", "/", "ips", "instead", "of", "custom", "-", "built", "solution"], "add_tokens": "require \"benchmark/ips\" reports = Benchmark . ips ( time = 2 ) do | x | benchname = \"#{info[:file]}:#{info[:line]} #{info[:name]}\" x . report ( benchname , & info [ :block ] )", "del_tokens": "require \"benchmark\" iterations = 100_000 iterations : iterations , reports = Benchmark . bmbm do | x | benchname = \"#{info[:file]}:#{info[:line]} #{info[:name]} (x#{info[:iterations]})\" x . report ( benchname ) { info [ :iterations ] . times ( & info [ :block ] ) } width = reports . map { | r | r . label . length } . max + 3 puts puts \"Results \" . ljust ( width , \"-\" ) reports . zip ( $__benchmarks__ ) . each do | report , bench | speed = \"#{(bench[:iterations] / report.total).round(2)} / s\" padding = \" \" * ( width - report . label . length ) puts report . label + padding + speed end puts \"\" . ljust ( width , \"-\" )", "commit_type": "use"}
{"commit_tokens": ["Adds", "an", "error", "handling", "flag", "so", "that", "error", "handling", "in", "the", "short", "stack", "can", "be", "turned", "on", "and", "off"], "add_tokens": "after do it \"should have a Controller\" do it \"should raise an exception if pancake has told it not to handle errors\" do Pancake . should_receive ( :handle_errors? ) . and_return ( false ) @controller . params [ \"action\" ] = \"a_private_method\" lambda do @controller . do_dispatch! end . should raise_error end", "del_tokens": "after do it \"should have a Controller\" do", "commit_type": "add"}
{"commit_tokens": ["Added", "chips", "to", "cards", "."], "add_tokens": "super ( type : :list , ** attribs_ , & block )", "del_tokens": "super ( type : :list , context : context , * * attribs_ , & block )", "commit_type": "add"}
{"commit_tokens": ["add", "package_update", ":", "false", "on", "user", ".", "user", "-", "data"], "add_tokens": "VERSION = \"0.4.1\"", "del_tokens": "VERSION = \"0.4.0\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "verbs", "to", "take", "a", "block", "."], "add_tokens": "define_method verb do | * args , & block | connection . send ( verb , * args , & block ) define_method :\" api_ #{ verb } \" do | * args , & block | send ( verb , * args , & block )", "del_tokens": "define_method verb do | * args | connection . send ( verb , * args ) define_method :\" api_ #{ verb } \" do | * args | send ( verb , * args )", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "so", "that", "currentInvoiceHandle", "is", "sent", "instead", "of", "CurrentInvoice_Book"], "add_tokens": "soap . body = { \"currentInvoiceHandle\" => handle . to_hash }", "del_tokens": "soap . body = { \"CurrentInvoice_Book\" => handle . to_hash }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "to", "plist4r", "instead", "of", "plist", "gem"], "add_tokens": "require 'plist4r' # @plist_data = Plist::parse_xml(@plist_file) @plist_data = Plist4r . open @plist_file", "del_tokens": "require 'plist' @plist_data = Plist :: parse_xml ( @plist_file )", "commit_type": "change"}
{"commit_tokens": ["Fix", "fuzzy", "search", "for", "Station", "name", "with", "saint", "or", "st"], "add_tokens": "# List of keywords to ignore while searching IGNORE_KEYWORDS = [ \"ST\" ] keywords = @query . split ( \" \" ) . select { | keyword | ! IGNORE_KEYWORDS . include? ( keyword ) } station . name . to_ascii =~ / #{ keywords . join ( \".*\" ) } /i", "del_tokens": "station . name . to_ascii =~ / #{ @query . split ( \" \" ) . join ( \".*\" ) } /i", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "use", "custom", "clock"], "add_tokens": "require_relative \"trend/clock\" require_relative \"trend/version\" measurements << Clock . measure { work . ( input , i ) }", "del_tokens": "require 'benchmark' require_relative 'trend/version' if defined? ( Process :: CLOCK_MONOTONIC ) # Object representing current time def time_now Process . clock_gettime Process :: CLOCK_MONOTONIC end module_function :time_now else # Object represeting current time def time_now Time . now end module_function :time_now end # Measure time elapsed with a monotonic clock # # @public def clock_time before = time_now yield after = time_now after - before end module_function :clock_time measurements << clock_time { work . ( input , i ) }", "commit_type": "change"}
{"commit_tokens": ["Add", "usage", "instructions", "to", "README", "file", "."], "add_tokens": "# optional_bool :friendly, true", "del_tokens": "# optional_bool :balding, true", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "generate", "download", "links", "for", "files"], "add_tokens": "@options = integration_options || fake_options @nsisam = NSISam :: Client . new ( @options ) it \"can generate a direct link to download any file\" do link = @nsisam . download_link_for_file ( 'some_key' ) link . should == \"http://#{@options[:host]}:#{@options[:port]}/file/some_key\" end", "del_tokens": "@nsisam = NSISam :: Client . new ( integration_options || fake_options )", "commit_type": "add"}
{"commit_tokens": ["add", "auth", "-", "key", "authentication"], "add_tokens": "class Operator < Thor desc 'create_auth_key' , 'list auth keys' def list_auth_keys client = Soracom :: Client . new data = client . list_auth_keys ( ) puts JSON . pretty_generate ( data ) end desc 'create_auth_key' , 'create new auth key' def create_auth_key client = Soracom :: Client . new data = client . create_auth_key ( ) puts JSON . pretty_generate ( data ) end desc 'delete_auth_key' , 'delete existing auth key' option :auth_key_id , type : :string , required : true , desc : 'auth key id starting \"keyId-\"' def delete_auth_key client = Soracom :: Client . new data = client . delete_auth_key ( options . auth_key_id ) puts JSON . pretty_generate ( data ) end end register ( Operator , 'operator' , 'operator <command>' , 'Operator related operations' )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "Awspec", "::", "Generator", "::", "Spec", "::", "CloudwatchAlarm#generate_all"], "add_tokens": "unit : 'Seconds' ,", "del_tokens": "unit : nil ,", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "the", "rest", "of", "the", "features"], "add_tokens": "attr_reader :board , :passes @passes = 0 end def view puts @board . to_s def pass @moves << { stone : NullStone . new ( ) , captures : [ ] , pass : true } end class NullStone < Stone def initialize ( * args ) @x , @y = nil , nil end def remove_from_board ( board ) end end", "del_tokens": "attr_reader :board", "commit_type": "add"}
{"commit_tokens": ["Use", "FailedRequest#not_found?", "instead", "of", "checking", "HTTP", "code", "."], "add_tokens": "raise e unless e . not_found?", "del_tokens": "raise unless e . code . to_i == 404", "commit_type": "use"}
{"commit_tokens": ["added", "ability", "to", "use", "each_pair", "on", "theory"], "add_tokens": "if block_given? @database . each_pair { | * a | yield * a } else @database . each_pair end", "del_tokens": "@database . each_pair { | * a | yield * a }", "commit_type": "add"}
{"commit_tokens": ["fixing", "no", "application", "found", "error"], "add_tokens": "if klass then klass . run ( * params ) else $stderr . puts \"Unable to launch #{params.join(' ')}\" end", "del_tokens": "klass . run ( * params )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "bug", "where", "password_archivable", "failed", "to", "validate", "against", "current", "password", "."], "add_tokens": "old_passwords_including_cur_change = self . old_passwords . order ( :id ) . reverse_order . limit ( self . class . deny_old_passwords ) old_passwords_including_cur_change << OldPassword . new ( old_password_params ) # include most recent change in list, but don't save it yet! old_passwords_including_cur_change . each do | old_password | def password_changed_to_same? pass_change = encrypted_password_change pass_change && pass_change . first == pass_change . last end self . old_passwords . create! old_password_params def old_password_params salt_change = if self . respond_to? ( :password_salt_change ) and not self . password_salt_change . nil? self . password_salt_change . first end { :encrypted_password => self . encrypted_password_change . first , :password_salt => salt_change } end", "del_tokens": "self . old_passwords . order ( :id ) . reverse_order . limit ( self . class . deny_old_passwords ) . each do | old_password | if self . respond_to? ( :password_salt_change ) and not self . password_salt_change . nil? self . old_passwords . create! :encrypted_password => self . encrypted_password_change . first , :password_salt => self . password_salt_change . first else self . old_passwords . create! :encrypted_password => self . encrypted_password_change . first end", "commit_type": "fix"}
{"commit_tokens": ["remove", "deprecated", "use", "of", "ActiveSupport", "::", "Memoizable"], "add_tokens": "def memoized_igb_variables ( method_name = nil ) @memoized_igb_variables ||= { } @memoized_igb_variables [ method_name ] ||= { } end memoized_igb_variables ( method_name ) [ warning ] ||= begin return_value = ( v = headers [ \"HTTP_EVE_#{method_name.to_s.camelize.upcase}\" ] || nil v = ( YAML :: load ( v ) rescue v ) unless v . nil? v ) warn warning if return_value . nil? && warning return_value end", "del_tokens": "extend ActiveSupport :: Memoizable return_value = ( v = headers [ \"HTTP_EVE_#{method_name.to_s.camelize.upcase}\" ] || nil v = ( YAML :: load ( v ) rescue v ) unless v . nil? v ) warn warning if return_value . nil? && warning return_value memoize :igb_variable_get", "commit_type": "remove"}
{"commit_tokens": ["Update", "README", "no", "more", "a", "work", "in", "progress", "."], "add_tokens": "POLLING_FALLBACK_MESSAGE = \"WARNING: Listen fallen back to polling, learn more at https://github.com/guard/listen#fallback.\"", "del_tokens": "POLLING_FALLBACK_MESSAGE = \"WARNING: Listen fallen back to polling, learn more at https://github.com/guard/listen.\"", "commit_type": "update"}
{"commit_tokens": ["Use", "relative", "path", "for", "node", "check", "key", "in", "S3", "files", "."], "add_tokens": "# The key is relative path from dir. key = node . path [ ( dir || \"\" ) . length , node . path . length - 1 ] nodes [ key ] = node", "del_tokens": "nodes [ node . path ] = node", "commit_type": "use"}
{"commit_tokens": ["Changed", "netrc", "from", "dev", "dependency", "to", "runtime", "dependency", "."], "add_tokens": "VERSION = \"3.0.2\"", "del_tokens": "VERSION = \"3.0.1\"", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", "removing", "all", "tags", "in", "a", "block"], "add_tokens": "def context ( & block ) if block use_context ( Context . new ( current_context ) , & block ) # Set the context to use within a block. def use_context ( context , & block ) current_context = Thread . current [ :lumberjack_context ] begin Thread . current [ :lumberjack_context ] = ( context || Context . new ) yield ensure Thread . current [ :lumberjack_context ] = current_context end end", "del_tokens": "def context if block_given? Thread . current [ :lumberjack_context ] = Context . new ( current_context ) begin yield ensure Thread . current [ :lumberjack_context ] = current_context end", "commit_type": "add"}
{"commit_tokens": ["added", "Deployment", "to", "headers", "in", "components"], "add_tokens": "c . header = 'Deployment Details'", "del_tokens": "c . header = 'Details'", "commit_type": "add"}
{"commit_tokens": ["fix", "errors", "when", "windows", "excel", "opens", "a", "file", "due", "to", "blank", "xml", "attributes"], "add_tokens": "if @workbook . date1904 . nil? || @workbook . date1904 . to_s == '' xml . workbookPr ( 'showInkAnnotation' => '0' , 'autoCompressPictures' => '0' ) else xml . workbookPr ( 'date1904' => @workbook . date1904 . to_s , 'showInkAnnotation' => '0' , 'autoCompressPictures' => '0' ) end # nokogiri builder creates CDATA tag around content,", "del_tokens": "xml . workbookPr ( 'date1904' => @workbook . date1904 . to_s , 'showInkAnnotation' => '0' , 'autoCompressPictures' => '0' ) # nokogiri builder creates CDATA tag around content,", "commit_type": "fix"}
{"commit_tokens": ["Use", "assert_throws", "instead", "of", "assert_raises"], "add_tokens": "push . expects ( :exit ) . with ( 1 ) . throws ( :exited ) assert_throws ( :exited ) { push . call }", "del_tokens": "push . expects ( :exit ) . with ( 1 ) . raises ( \"exited\" ) assert_equal ( \"exited\" , assert_raises { push . call } . message )", "commit_type": "use"}
{"commit_tokens": ["fixed", "bug", "where", "redirect", "was", "relative"], "add_tokens": "\"0.0.30\" ap uri . host ap uri . inferred_port ap uri . request_uri ap \"redirecting to #{response['location']}\" url = Addressable :: URI . join ( uri , response [ 'location' ] ) . to_s ap url", "del_tokens": "\"0.0.29\" url = Addressable :: URI . parse ( response [ 'location' ] ) . to_s", "commit_type": "fix"}
{"commit_tokens": ["Add", "spec", "for", "queue", "attribute", "accessor", "methods"], "add_tokens": "describe \"#reserve\" do context \"when there are messages in the queue to be received\" do it \"returns a message from the queue\" do expected_message = BetterSqs :: Message . new queue_client : better_client , queue : queue_name , sqs_message : encoded_message subject . push encoded_message expect ( subject . reserve ) . to eq expected_message end end context \"when there are no messages in the queue to be received\" do it \"is nil\" do expect ( subject . reserve ) . to be_nil end end end described_class :: QUEUE_ATTRIBUTES . each do | queue_attribute | describe \"##{queue_attribute}\" do it \"gets the queue attribute: '#{queue_attribute}' from SQS\" do expect ( subject . public_send queue_attribute ) . to eq SqsMocks :: MockClient :: FAUX_ATTRIBUTES [ queue_attribute . to_s . camelize ] end end end", "del_tokens": "# # describe \"#reserve\" do # it \"does stuff\" # end # # described_class::QUEUE_ATTRIBUTES.each do |queue_attribute| # describe \"##{queue_attribute}\" do # it \"does stuff\" # end # end", "commit_type": "add"}
{"commit_tokens": ["Add", "reset", "registration", ";", "update", "specs", "for", "registration"], "add_tokens": "not_implemented :get_registration_list_results , def get_registration_list ( options = { } ) xml = connection . call ( \"rustici.registration.getRegistrationList\" , options ) xml . elements [ \"/rsp/registrationlist\" ] . map { | e | Registration . from_xml ( e ) } end def get_registration_result ( reg_id , format = \"course\" ) raise \"Illegal format argument: #{format}\" unless [ \"course\" , \"activity\" , \"full\" ] . include? ( format ) connection . call_raw ( \"rustici.registration.getRegistrationResult\" , { :regid => reg_id , :format => format } ) end def reset_registration ( reg_id ) xml = connection . call ( \"rustici.registration.resetRegistration\" , { :regid => reg_id } ) ! xml . elements [ \"/rsp/success\" ] . nil?", "del_tokens": "not_implemented :reset_registration , :get_registration_list_results , def get_registration_result ( reg_id , format = \"course\" ) raise \"Illegal format argument: #{format}\" unless [ \"course\" , \"activity\" , \"full\" ] . include? ( format ) connection . call_raw ( \"rustici.registration.getRegistrationResult\" , { :regid => reg_id , :format => format } ) end def get_registration_list ( options = { } ) xml = connection . call ( \"rustici.registration.getRegistrationList\" , options ) xml . elements [ \"/rsp/registrationlist\" ] . map { | e | Registration . from_xml ( e ) }", "commit_type": "add"}
{"commit_tokens": ["added", "isimud", ":", "sync", "rake", "task"], "add_tokens": "VERSION = '0.3.0'", "del_tokens": "VERSION = '0.2.17'", "commit_type": "add"}
{"commit_tokens": ["fix", "issues", "with", "watching", "all", "the", "files", "putting", "the", "guard", "in", "infinite", "loop", "rerun", "prev", "specs", "if", "no", "specs", "given"], "add_tokens": "specs = Inspector . clean ( paths ) ( paths - specs ) . each { | path | reload_file ( path ) } # RSpec reloads the files, dont't do it twice passed = Runner . run ( specs , cli )", "del_tokens": "watchers << :: Guard :: Watcher . new ( %r{ ^.*$ } ) clean_paths = Inspector . clean ( paths ) paths . each { | path | reload_file ( path ) } return unless clean_paths . any? # TODO: Maybe bug in guard: watches files not actualy matching, like stuff in db/ passed = Runner . run ( clean_paths , cli )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "on", "the", "Windows", "platform", "when", "attempting", "to", "load", "the", "syslog", "library", "."], "add_tokens": "VERSION = '0.5.1' # :nodoc:", "del_tokens": "VERSION = '0.5.0' # :nodoc:", "commit_type": "fix"}
{"commit_tokens": ["Use", "local", "variable", "instead", "of", "instance", "one", "."], "add_tokens": "# lib_path lib_path = lib_dir CLOBBER . include ( \"#{lib_path}/#{binary(platf)}\" ) task \"copy:#{@name}:#{platf}:#{ruby_ver}\" => [ lib_path , \"#{tmp_path}/#{binary(platf)}\" ] do cp \"#{tmp_path}/#{binary(platf)}\" , \"#{lib_path}/#{binary(platf)}\" file \"#{lib_path}/#{binary(platf)}\" => [ \"copy:#{name}:#{platf}:#{ruby_ver}\" ] # lib_path lib_path = lib_dir file \"#{lib_path}/#{File.basename(ext)}\" => [ \"copy:#{File.basename(ext).ext('')}:#{platf}:#{ruby_ver}\" ] # lib_path lib_path = lib_dir if Rake :: Task . task_defined? ( \"#{lib_path}/#{binary(for_platform)}\" ) then Rake :: Task [ \"#{lib_path}/#{binary(for_platform)}\" ] . prerequisites . clear", "del_tokens": "CLOBBER . include ( \"#{@lib_dir}/#{binary(platf)}\" ) task \"copy:#{@name}:#{platf}:#{ruby_ver}\" => [ lib_dir , \"#{tmp_path}/#{binary(platf)}\" ] do cp \"#{tmp_path}/#{binary(platf)}\" , \"#{@lib_dir}/#{binary(platf)}\" file \"#{@lib_dir}/#{binary(platf)}\" => [ \"copy:#{name}:#{platf}:#{ruby_ver}\" ] file \"#{@lib_dir}/#{File.basename(ext)}\" => [ \"copy:#{File.basename(ext).ext('')}:#{platf}:#{ruby_ver}\" ] if Rake :: Task . task_defined? ( \"#{@lib_dir}/#{binary(for_platform)}\" ) then Rake :: Task [ \"#{@lib_dir}/#{binary(for_platform)}\" ] . prerequisites . clear", "commit_type": "use"}
{"commit_tokens": ["fix", "spec", "to", "pass", "array", "of", "command", "line", "args"], "add_tokens": "h = CommandLineArgsToHash . parse ( [ '--hello' ] ) end", "del_tokens": "h = CommandLineArgsToHash . parse ( '--hello' ) end", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "request", "call", "counter", "callback", "."], "add_tokens": "VERSION = '0.8.8'", "del_tokens": "VERSION = '0.8.7'", "commit_type": "add"}
{"commit_tokens": ["adds", "configuration", "option", "to", "ignore", "stdin", "processing", ".", "This", "solves", "problems", "when", "trying", "to", "daemonize", "mailman"], "add_tokens": "if ! Mailman . config . ignore_stdin && $stdin . fcntl ( Fcntl :: F_GETFL , 0 ) == 0 # we have stdin", "del_tokens": "if $stdin . fcntl ( Fcntl :: F_GETFL , 0 ) == 0 # we have stdin", "commit_type": "add"}
{"commit_tokens": ["Added", "accept", "parameter", "to", "allow", "downloading", "MIME"], "add_tokens": "def get ( resource_path , params = nil , accept = \"*/*\" ) response = http_client [ resource_path ] . get ( :params => params , :accept => accept ) response = @http_client [ resource_path ] . get ( :accept => accept )", "del_tokens": "def get ( resource_path , params = nil ) response = @http_client [ resource_path ] . get ( :params => params ) response = @http_client [ resource_path ] . get ( )", "commit_type": "add"}
{"commit_tokens": ["added", "option", "to", "refresh", "tokens"], "add_tokens": "# POST /oauth/token HTTP/1.1 # Makes a request to Plangrade server that will swap your refresh token for an access # token and new refresh token # # @see http://docs.plangrade.com/#refresh-authorization # # @opts [Hash] may include scope and other parameters # # >> client = PlangradeClient.new(config) # >> client.refresh!('G3Y6jU3a', { # :scope => 'abc, xyz', # }) # # POST /oauth/token HTTP/1.1 # Host: www.plangrade.com # Content-Type: application/x-www-form-urlencoded # client_id={client_id}&refresh_token=G3Y6jU3a&grant_type=refresh_token& # client_secret={client_secret} def refresh! ( ref_token , opts = { } ) opts [ :authenticate ] ||= :body token = refresh_token . get_token ( ref_token , opts ) return token end", "del_tokens": "# POST /oauth2/access_token HTTP/1.1", "commit_type": "add"}
{"commit_tokens": ["added", "ugly", "fix", "to", "FKChapter", "problem"], "add_tokens": "script = @doc . css ( 'script' ) . text if script . include? ( \" + x + \" ) s = / (http: \\/ \\/ t \\. fakku \\. net)(.+?)(' \\s \\+ \\s x \\s \\+ \\s ')( \\. jpg) / else s = / (http: \\/ \\/ t \\. fakku \\. net)(.+?)(' \\+ x \\+ ')( \\. jpg) / end image = script . slice ( s ) image . sub! ( / ' \\s \\+ \\s x \\s \\+ \\s ' / , page ) #s = /(http:\\/\\/t\\.fakku\\.net)(.+?)('\\+x\\+')(\\.jpg)/ #image = @doc.css('script').text.slice(s) #image.sub!(/'\\+x\\+'/, page)", "del_tokens": "# s = /(http:\\/\\/t\\.fakku\\.net)(.+?)('\\s\\+\\sx\\s\\+\\s')(\\.jpg)/ # image.sub!(/'\\s\\+\\sx\\s\\+\\s'/, page) s = / (http: \\/ \\/ t \\. fakku \\. net)(.+?)(' \\+ x \\+ ')( \\. jpg) / image = @doc . css ( 'script' ) . text . slice ( s ) image . sub! ( / ' \\+ x \\+ ' / , page )", "commit_type": "add"}
{"commit_tokens": ["Move", "error", "display", "attributes", "into", "translation", "yml"], "add_tokens": "# error metadata.", "del_tokens": "# formatting metadata.", "commit_type": "move"}
{"commit_tokens": ["Adds", "name", "tests", "and", "features", "."], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Made", "default", "scope", "database", "-", "agnostic"], "add_tokens": "return scoped . where ( false )", "del_tokens": "return scoped . where ( 'false' )", "commit_type": "make"}
{"commit_tokens": ["Added", "space", "ls", "and", "space", "tree", "commands"], "add_tokens": "desc 'tree STARTING_SPACE' , 'Command description...' def tree ( starting_space = nil ) Lkr :: Commands :: Space :: Tree . new ( options ) . execute ( starting_space ) desc 'ls FILTER_SPEC' , 'Command description...' method_option :fields , type : :string , default : 'parent_id,id,name,looks(id,title),dashboards(id,title)' , desc : 'Fields to display' method_option :plain , type : :boolean , default : false , desc : 'print without any extra formatting' def ls ( filter_spec = nil ) Lkr :: Commands :: Space :: Ls . new ( options ) . execute ( filter_spec )", "del_tokens": "desc 'tree' , 'Command description...' def tree ( * ) Lkr :: Commands :: Space :: Tree . new ( options ) . execute desc 'ls' , 'Command description...' def ls ( * ) Lkr :: Commands :: Space :: Ls . new ( options ) . execute", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "Gemfile", "and", "updated", "TravisCI", "build", "targets", "."], "add_tokens": "assert_equal obj . __id__ , ref . object . __id__", "del_tokens": "assert_equal obj , ref . object", "commit_type": "add"}
{"commit_tokens": ["Use", "Icalendar", "gem", "instead", "of", "specific", "commit"], "add_tokens": "VERSION = '0.1.8'", "del_tokens": "VERSION = '0.1.7'", "commit_type": "use"}
{"commit_tokens": ["use", "new", "salt", "whenever", "rehashing", "password"], "add_tokens": "self . salt = self . class . make_token", "del_tokens": "self . salt = self . class . make_token if new_record?", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "method", "for", "running", "the", "specs", "on", "different", "database", "adapters"], "add_tokens": "ENV [ \"DB\" ] ||= 'sqlite3' puts \"Using #{ENV[\"DB\"]} to run the tests.\" require File . dirname ( __FILE__ ) + \"/connections/#{ENV[\"DB\"]}.rb\" RSpec . configure do | config | config . before do SeededModel . delete_all end end", "del_tokens": "RSpec . configure do | config | config . before do SeededModel . delete_all end end ActiveRecord :: Base . establish_connection ( :adapter => \"sqlite3\" , :database => File . dirname ( __FILE__ ) + \"/test.sqlite3\" )", "commit_type": "add"}
{"commit_tokens": ["Change", "dependency", "to", "aeden", "-", "moneta", "since", "wycats", "left", "out", "some", "libs", "in", "his", "fork"], "add_tokens": "entry . content ] . join )", "del_tokens": "entry . content ] . join )", "commit_type": "change"}
{"commit_tokens": ["Fixed", "hookup", "/", "unhook", "of", "events", "in", "model", "spec", "."], "add_tokens": "@notification_id = NSNotificationCenter . defaultCenter . addObserver ( self , selector : 'dataDidChange:' , name : 'MotionModelDataDidChangeNotification' , object : nil ) NSNotificationCenter . defaultCenter . removeObserver @notification_id", "del_tokens": "NSNotificationCenter . defaultCenter . addObserver ( self , selector : 'dataDidChange:' , name : 'MotionModelDataDidChangeNotification' , object : nil ) NSNotificationCenter . defaultCenter . removeObserver self", "commit_type": "fix"}
{"commit_tokens": ["added", "Class", ".", "callbacks_for_hook", "to", "cleanly", "access", "callbacks", ".", "version", "bump", "."], "add_tokens": "VERSION = \"0.1.2\" callbacks_for_hook ( name ) . each do | callback | # Returns the callbacks for +name+. Handy if you want to run the callbacks yourself, say when # they should be executed in another context. # # Example: # # def initialize # self.class.callbacks_for_hook(:after_eight).each do |callback| # instance_exec(self, &callback) # end # # would run callbacks in the object _instance_ context, passing +self+ as block parameter. def callbacks_for_hook ( name ) send ( \"_#{name}_callbacks\" ) end", "del_tokens": "VERSION = \"0.1.1\" send ( \"_#{name}_callbacks\" ) . each do | callback |", "commit_type": "add"}
{"commit_tokens": ["added", "some", "doc", "to", "transaction", "removed", "unused", "code", "from", "module"], "add_tokens": "# The transaction class is the parent class of all Transaction be it Payment, Refund or Paypal etc. # it provides underlying methods which all transactions have in common # It should not be instantiated by itself @request_method ||= REXML :: XPath . first ( @request_xml , \"//Request\" ) . attributes [ \"Type\" ]", "del_tokens": "@request_method ||= REXML :: XPath . first ( @request_xml , \"//Request\" ) . attributes [ \"Type\" ] rescue \"not set\"", "commit_type": "add"}
{"commit_tokens": ["use", "reveal", "for", "planning", "if", "the", "user", "has", "elevate", "take", "2"], "add_tokens": "plan_api = if api . privilege == \"elevate\" # Check if the user has 'reveal' # In order to do this, the 'elevate' privilege must be removed, otherwise the permission # check always returns 'true' naked_api = api . dup naked_api . privilege = nil if naked_api . global_privilege_permitted? ( \"reveal\" ) api . with_privilege ( \"reveal\" ) else api end", "del_tokens": "naked_api = api . dup naked_api . privilege = nil plan_api = if api . privilege == \"elevate\" && naked_api . global_privilege_permitted? ( \"reveal\" ) api . with_privilege ( \"reveal\" )", "commit_type": "use"}
{"commit_tokens": ["Added", "Linked", "Lists", "to", "gemfile", "."], "add_tokens": "VERSION = \"1.1.4\"", "del_tokens": "VERSION = \"1.1.3\"", "commit_type": "add"}
{"commit_tokens": ["create", "content", "and", "open", "-", "write"], "add_tokens": "s = DataType . new ( erb_path , type_file ) . result open ( $output , \"w\" ) . write ( s )", "del_tokens": "open ( $output , \"w\" ) . write DataType . new ( erb_path , type_file ) . result", "commit_type": "create"}
{"commit_tokens": ["Changing", "comment", "to", "include", ":", "warning", "."], "add_tokens": "# @return [Symbol] the current status of the Scout (:up, :down, :warning) # status is the status (:up, :down or :warning, for example) that will be returned", "del_tokens": "# @return [Symbol] the current status of the Scout (:up, :down) # status is the status (:up or :down, for example) that will be returned", "commit_type": "change"}
{"commit_tokens": ["Allow", "configuration", "methods", "with", "partial", "arguments", "based", "on", "their", "arity"], "add_tokens": "# see #__send_to_base return v . call ( * ( ( [ * args , base ] [ 0 , v . arity ] ) ) ) if proc_expected v . call ( * ( args [ 0 , v . arity ] ) ) # It might happen that the given method name does not accept all of the given # arguments, most likely because they are not needed to make the necessary # decisions anyway. # Therefore, only the correct amount of arguments is passed to the function, e.g. # args[0,2] for a method with arity 2 base . send ( method . to_sym , * ( __args_for_arity ( base , method , args ) ) ) end def __args_for_arity ( base , method , args ) args [ 0 , base . method ( method . to_sym ) . arity ]", "del_tokens": "# TODO: We might need the base class here as a configuration # is passed on to a class's descendents. When initializing an object, the actual class IS needed. v . call ( * args ) base . send ( method . to_sym , * args )", "commit_type": "allow"}
{"commit_tokens": ["add", "singleton_resource?", "method", "to", "factory"], "add_tokens": "describe 'singleton_definition?' do it 'true when no methods defined' do definition = { statics : [ ] } result = ResourceFactory . singleton_definition? definition expect ( result ) . to eql ( true ) end it 'true when no methods are empty' do definition = { methods : [ ] } result = ResourceFactory . singleton_definition? definition expect ( result ) . to eql ( true ) end it 'false when methods are in definition' do definition = { methods : [ :find ] } result = ResourceFactory . singleton_definition? definition expect ( result ) . to eql ( false ) end end it 'raises if resource not defined' do", "del_tokens": "it 'test' do", "commit_type": "add"}
{"commit_tokens": ["allow", "filepaths", "to", "be", "set", "at", "instantiation", "time", "for", "ConfigBase", "subclasses"], "add_tokens": "def initialize ( * paths ) read_files ( paths )", "del_tokens": "def initialize", "commit_type": "allow"}
{"commit_tokens": ["Remove", "describe", "method", "only", "when", "defined"], "add_tokens": "remove_method :describe if method_defined? :describe", "del_tokens": "remove_method :describe", "commit_type": "remove"}
{"commit_tokens": ["Change", "unknown_attribute_name", "-", ">", "attribute_name"], "add_tokens": "attr_reader :columns , :attribute_name def initialize ( attribute_name , columns ) @attribute_name , @columns = attribute_name , columns @similar_columns ||= MethodMatcher . new ( column_names , attribute_name ) . similar_methods", "del_tokens": "attr_reader :columns , :unknown_attribute_name def initialize ( unknown_attribute_name , columns ) @unknown_attribute_name , @columns = unknown_attribute_name , columns @similar_columns ||= MethodMatcher . new ( column_names , unknown_attribute_name ) . similar_methods", "commit_type": "change"}
{"commit_tokens": ["Fix", "a", "typo", "[", "ci", "skip", "]"], "add_tokens": "# Expanding is supported by almost all patterns (notable exceptions are {Mustermann::Shell},", "del_tokens": "# Expanding is supported by almost all patterns (notable execptions are {Mustermann::Shell},", "commit_type": "fix"}
{"commit_tokens": ["Allow", "aliasing", "inside", "functions", "(", "for", "PostgreSQL", "cast", ")"], "add_tokens": "when Nodes :: Function , Nodes :: KeyPath , Nodes :: As when Nodes :: Function , Nodes :: KeyPath , Nodes :: As", "del_tokens": "when Nodes :: Function , Nodes :: KeyPath when Nodes :: Function", "commit_type": "allow"}
{"commit_tokens": ["implement", "binary", "operators", "and", "to_proc"], "add_tokens": "require 'mustermann/composite' # @param [String, Pattern, Regexp, #to_pattern, Array<String, Pattern, Regexp, #to_pattern>] # input The representation of the new pattern # @raise [TypeError] if the passed object cannot be converted to a pattern def self . new ( * input , type : :sinatra , ** options ) input = input . first if input . size < 2 when Array then Composite . new ( input , type : type , ** options ) else pattern = input . to_pattern ( type : type , ** options ) if input . respond_to? :to_pattern raise TypeError , \"#{input.class} can't be coerced into Mustermann::Pattern\" if pattern . nil? pattern", "del_tokens": "# @param [String, Pattern, Regexp, #to_pattern] input The representation of the new pattern def self . new ( input , type : :sinatra , ** options ) else input . to_pattern ( type : type , ** options )", "commit_type": "implement"}
{"commit_tokens": ["Added", "sync", "command", "test", "for", "adding", "changes", "to", "existing", "branch"], "add_tokens": "@work_dir = arg . has_key? ( :work_dir ) ? arg [ :work_dir ] : \".\" @git_dir = arg . has_key? ( :git_dir ) ? arg [ :git_dir ] : @work_dir + \"/.git\" options = ( @work_dir . empty? ? \"\" : \" --work-tree=#{File.expand_path(@work_dir)}\" ) + ( @git_dir . empty? ? \"\" : \" --git-dir=#{File.expand_path(@git_dir)}\" ) cmd = \"git#{options} #{cmd} 2>&1\"", "del_tokens": "@work_dir = arg [ :work_dir ] || \".\" @git_dir = arg [ :git_dir ] || @work_dir + \"/.git\" cmd = \"git --git-dir=#{File.expand_path(@git_dir)} --work-tree=#{File.expand_path(@work_dir)} #{cmd} 2>&1\"", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "URL", "builder", "class", ".", "Give", "it", "a", "matrix", "get", "url", "back", "."], "add_tokens": "subject { described_class . new }", "del_tokens": "subject { described_class . new }", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "orders", "on", "taxonomy", "/", "taxons"], "add_tokens": "scope :available_for , -> ( code ) { where ( 'available_codes ? :code' , code : code ) . or ( where ( 'available_codes = ? OR available_codes IS NULL' , '[\"\"]' ) ) . order ( :name ) } has_many :taxons , -> { order ( 'name ASC' ) } , dependent : :destroy", "del_tokens": "scope :available_for , -> ( code ) { where ( 'available_codes ? :code' , code : code ) . or ( where ( 'available_codes = ? OR available_codes IS NULL' , '[\"\"]' ) ) } has_many :taxons , dependent : :destroy", "commit_type": "add"}
{"commit_tokens": ["adding", "mandatory", "to", "send", "message", "and", "updating", "documentation"], "add_tokens": "# The entire body is a JSON string with the keys: # Request Information: # Call information: # # Authentication information: expiration : @options [ :timeout ] , mandatory : true", "del_tokens": "# This format is defined by Alchemy framework HTTP message # The entire body will be a JSON string with the keys: # # Keys for # Custom keys for authentication expiration : @options [ :timeout ]", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "configuration", "option", "for", "contribution", "definition", "id"], "add_tokens": "attr_writer :shared_secret , :app_id , :contribution_definition_id def contribution_definition_id if @contribution_definition_id . nil? then raise ConfigurationError . new ( 'No contribution_definition_id provided in configuration. ' 'Please set this to make the request, you\\'ll need to contact JohnDeere support to get this value.' ) end return @contribution_definition_id end", "del_tokens": "attr_writer :shared_secret , :app_id", "commit_type": "add"}
{"commit_tokens": ["Fix", "telnet", "communication", "so", "Varnish#purge", "doesn", "t", "return", "false"], "add_tokens": "connection . cmd ( 'String' => command , 'Match' => / \\n \\n / ) { | r | response = r . split ( \"\\n\" ) . first . strip }", "del_tokens": "connection . cmd ( command + \"\\nquit\\n\" ) { | r | response = r . strip }", "commit_type": "fix"}
{"commit_tokens": ["add", "test", "for", "these", "commits", "."], "add_tokens": "assert_equal ( d . from , 'gitsearch1' ) assert_equal ( d . to , 'v2.5' ) end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["add", "a", "manifest", "that", "can", "add", "files", "directories", "and", "lookup", "files", "in", "them"], "add_tokens": "require 'borrower' require 'fileutils' TMP = File . join ( Dir . pwd , \"tmp\" ) def given_files list FileUtils . mkdir_p TMP Array ( list ) . each do | f | file_path = File . join ( TMP , f ) FileUtils . mkdir_p ( file_path ) FileUtils . touch ( file_path ) end end def given_file name , content File . open ( File . join ( TMP , name ) , 'w' ) do | file | file . write content end end def given_config contents File . open ( File . join ( TMP , '.borrower' ) , 'w' ) do | file | file . write content end end def cleanup_tmp ` rm -rf #{ TMP } ` end", "del_tokens": "require 'borrower'", "commit_type": "add"}
{"commit_tokens": ["Remove", "root_path", "dependencies", "from", "dsl"], "add_tokens": "def self . evalute ( root_path , filename ) new . tap { | dsl | dsl . eval_file ( File . join ( root_path , filename ) ) } attr_reader :dependencies , :root_path def initialize ( root_path ) @root_path = root_path contents = JSON . parse ( File . read ( File . join ( root_path , '.bowerrc' ) ) ) rescue { } File . join ( root_path , loc . to_s , assets_path )", "del_tokens": "def self . evalute ( filename ) new . tap { | dsl | dsl . eval_file ( File . join ( BowerRails . root_path , filename ) ) } attr_reader :dependencies def initialize contents = JSON . parse ( File . read ( File . join ( BowerRails . root_path , '.bowerrc' ) ) ) rescue { } File . join ( BowerRails . root_path , loc . to_s , assets_path )", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "tag", "date", "and", "versions", ".", "Minor", "cleanup", "of", "unit", "test", "."], "add_tokens": "# # Symbol keys tend to indicate categories such as :lookup_types. Additionally, # there are corresponding _date and _version keys for each category. # e.g. :lookup_types, :lookup_types_date, and :lookup_types_version # # The reason these are symbols is to help distinguish them from the parsed data. # # All categories are pluralized snakecase except for :search_help. # :objects => {<Object Type> => {...}}, # :objects_date => ..., # :objects_version => ..., apply_tag_attributes # Adds the tag attributes date and version to the top level tag # if it corresponds to a container. def apply_tag_attributes tag , attrs = @stack . last container = container_for ( tag , attrs ) base = category_sym_from_tag ( tag ) if container && base container [ \"#{base}_date\" . to_sym ] = attrs [ 'Date' ] container [ \"#{base}_version\" . to_sym ] = attrs [ 'Version' ] end container end def container_for ( tag , attrs ) resource = attrs [ 'Resource' ] case tag when 'METADATA-TABLE' @metadata . resource_class ( resource , attrs [ 'Class' ] ) when 'METADATA-FOREIGNKEYS' @metadata . foreign_keys else @metadata . resource ( resource ) end end def category_sym_from_tag ( tag ) case tag when 'METADATA-CLASS' then :classes when 'METADATA-TABLE' then :tables when 'METADATA-OBJECT' then :objects when 'METADATA-LOOKUP' then :lookups when 'METADATA-LOOKUP_TYPE' then :lookup_types when 'METADATA-FOREIGNKEYS' then :foreign_keys when 'METADATA-SEARCH_HELP' then :search_help when 'METADATA-EDITMASK' then :edit_masks else nil end end", "del_tokens": "# Symbol keys are used to indicate categories such as :lookup_types. All are pluralized # except for :search_help, and have are snakecase. # :objects => {<Object Type> => {...}}, # # TODO add version and date supplied by a tag's attributes to the relevant metadata results.", "commit_type": "add"}
{"commit_tokens": ["Added", "feature", "so", "that", "comments", "aren", "t", "parsed", "when", "a", "#", "shows", "up", "in", "a", "string", "/", "regex", "literal", ".", "95%", "effort", "."], "add_tokens": "code , comment = split_on_char_outside_literal ( line , '#' ) return nil unless comment . any? indent , code = code . match ( / ^( \\s *)(.*)$ / ) [ 1 .. 2 ] hashes , comment = comment . match ( / ^(#+)(.*)$ / ) [ 1 .. 2 ]", "del_tokens": "working_line = line . gsub ( / '(( \\\\ .)|[^'])*' / , \"\" ) . gsub ( / \"(( \\\\ .)|[^\"])*\" / , '' ) result = working_line . match ( / ^( \\s *)([^#\"']*)(#*)(.*) \\Z / ) return nil unless result indent , code , hashes , comment = result [ 1 ] , result [ 2 ] , result [ 3 ] , result [ 4 ]", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "infinite", "connection", "timeout", "that", "bypasses", "the", "async", "connect", "api"], "add_tokens": "# A value of -1 will cause the connect wait time to be infinite if @connect_timeout == - 1 # Timeout of -1 means wait forever for a connection @socket . connect ( socket_address ) else rescue Errno :: EINPROGRESS end if IO . select ( nil , [ @socket ] , nil , @connect_timeout ) begin @socket . connect_nonblock ( socket_address ) rescue Errno :: EISCONN end else raise ( ConnectionTimeout . new ( \"Timedout after #{@connect_timeout} seconds trying to connect to #{server}\" ) )", "del_tokens": "begin @socket . connect_nonblock ( socket_address ) rescue Errno :: EINPROGRESS end if IO . select ( nil , [ @socket ] , nil , @connect_timeout ) rescue Errno :: EISCONN else raise ( ConnectionTimeout . new ( \"Timedout after #{@connect_timeout} seconds trying to connect to #{server}\" ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "attributes", "include", "ones", "from", "parent", "classes"], "add_tokens": "@attributes ||= if superclass && superclass . respond_to? ( :attributes ) superclass . attributes . dup else [ ] end", "del_tokens": "@attributes ||= [ ]", "commit_type": "make"}
{"commit_tokens": ["Fixed", "for", "Rails", "versions", "that", "don", "t", "support", "Rails", ".", "version", "method"], "add_tokens": "if Rails . respond_to? ( :version ) && Rails . version =~ / ^2 \\. 2 \\. /", "del_tokens": "if Rails . version =~ / ^2 \\. 2 \\. /", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "reconnecting", "to", "a", "network", "."], "add_tokens": "Version = \"1.7.3\"", "del_tokens": "Version = \"1.7.2\"", "commit_type": "add"}
{"commit_tokens": ["Add", "background", "and", "page_size", "opt", "to", "server"], "add_tokens": "labels = params [ :labels ] document = params [ :document ] stamp = params [ :stamp ] logo = params [ :logo ] font = params [ :font ] page_size = params [ :page_size ] background = params [ :background ] file_name : filename , background : background , page_size : page_size , end", "del_tokens": "labels = params [ :labels ] document = params [ :document ] stamp = params [ :stamp ] logo = params [ :logo ] font = params [ :font ] file_name : filename end", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "@config", "ivar", "in", "Project#initialize", "."], "add_tokens": "unless SCMS . has_key? ( @config . scm ) raise ( InvalidConfig , \"Unknown SCM #{@config.scm} given for the :scm option\" , caller ) extend SCMS [ @config . scm ]", "del_tokens": "unless SCMS . has_key? ( config . scm ) raise ( InvalidConfig , \"Unknown SCM #{config.scm} given for the :scm option\" , caller ) extend SCMS [ config . scm ]", "commit_type": "use"}
{"commit_tokens": ["Update", "hash", "reference", "to", "avoid", "private", "sends"], "add_tokens": "# Pass Mixlib::Config.configure() a block, and it will yield itself # <block>:: A block that is called with self as the arugment. block . call ( self ) config_option = config_option . to_sym if private_method_defined? ( config_option ) nil else send ( config_option . to_sym ) end", "del_tokens": "# Pass Mixlib::Config.configure() a block, and it will yield self.configuration. # <block>:: A block that is sent self.configuration as its argument block . call ( self . configuration ) self . configuration [ config_option . to_sym ]", "commit_type": "update"}
{"commit_tokens": ["Add", "Mapper", ".", "has", "as", "a", "shortcut", "for", "defining", "relationship", "mappings"], "add_tokens": "User :: Mapper . has ( 1 , :address , :mapper => address_mapper )", "del_tokens": "User :: Mapper . map :address , :type => DataMapper :: Mapper :: Relationship :: OneToOne , :mapper => address_mapper", "commit_type": "add"}
{"commit_tokens": ["Added", "dependencies", "on", "octopress", "-", "ink", "and", "octopres", "-", "codefence", "to", "make", "fancy", "Ink", "docs", "work"], "add_tokens": "abort \"No #{@options['type']} template found at #{file}\" unless File . exist? file", "del_tokens": "abort \"No template found at #{file}\" unless File . exist? file", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "command", "-", "line", "error", "checks", "."], "add_tokens": "@dictionary . parse_string \"The cat likes pie and chainsaws!\"", "del_tokens": "@dictionary . parse_string \"The cat likes pie and chainsaws!\"", "commit_type": "add"}
{"commit_tokens": ["Use", "home_", "instead", "of", "friends_timeline"], "add_tokens": "home_timeline = @client . home_timeline home_timeline . reverse! # We want the latest tweets at the bottom on a CLI home_timeline . each do | tweet |", "del_tokens": "friends_timeline = @client . friends_timeline friends_timeline . reverse! # We want the latest tweets at the bottom on a CLI friends_timeline . each do | tweet |", "commit_type": "use"}
{"commit_tokens": ["removed", "debugging", "code", "improved", "error", "message", ".", "specs", "passing", "."], "add_tokens": "error = Echonest :: Error . new ( response_code , response ) raise error , \"Error code #{response_code}: #{error.description}\"", "del_tokens": "binding . pry error_message = \"Error code #{response_code}: #{Echonest::Error::ERRORS[response_code]}\" raise Echonest :: Error . new ( response_code , response , error_message )", "commit_type": "remove"}
{"commit_tokens": ["removing", "dynamic", "root", "method", "definition", "stuff"], "add_tokens": "require 'ns-options/root_methods' require 'ns-options/helper' receiver . class_eval { extend NsOptions :: DSL } end module DSL # This is the main DSL method for creating a namespace of options for your # class/module. This will define a class method for classes/modules and # an additional instance method for classes. def options ( name , & block ) NsOptions :: Helper . advisor . is_this_namespace_ok? ( name , caller ) NsOptions :: RootMethods . new ( self , name ) . define self . send ( name , & block ) end alias_method :opts , :options alias_method :namespace , :options alias_method :ns , :options", "del_tokens": "require 'ns-options/has_options' require 'ns-options/helper' require 'ns-options/namespace' require 'ns-options/namespaces' require 'ns-options/option' require 'ns-options/options' require 'ns-options/version' if ! defined? ( NsOptions :: VERSION ) receiver . send ( :include , HasOptions )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "small", "gotcha", "in", "JSON", "reference", "for", "when", "there", "is", "a", "URL", "but", "no", "pointer"], "add_tokens": "require_relative \"json_pointer\" @pointer ||= \"\"", "del_tokens": "require \"json_pointer\"", "commit_type": "fix"}
{"commit_tokens": ["Updated", "code", "/", "comment", "style", "."], "add_tokens": "require 'acts_as_enumerated/acts/enumerated' require 'acts_as_enumerated/associations/has_enumerated'", "del_tokens": "require File . join ( 'acts_as_enumerated' , 'acts' , 'enumerated' ) require File . join ( 'acts_as_enumerated' , 'associations' , 'has_enumerated' )", "commit_type": "update"}
{"commit_tokens": ["Improves", "the", "error", "message", "when", "we", "get", "an", "HTTP", "error", "response", "."], "add_tokens": "raise \"Error #{raw_response.status}: #{raw_response.body}\"", "del_tokens": "raise raw_response . body", "commit_type": "improve"}
{"commit_tokens": ["Fix", "minor", "bug", "accessing", "array"], "add_tokens": "if ! reportsrows [ 1 ] . nil? && reportsrows [ 1 ] . match ( / ^ \\{ code \\: .* \\} $ / )", "del_tokens": "if reportsrows [ 1 ] . match ( / ^ \\{ code \\: .* \\} $ / )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "no", "cache_classes", "to", "be", "passed"], "add_tokens": "Array ( options [ :cache_classes ] ) . each { | klass | SpatialFeatures . cache_record_proximity ( model , klass ) }", "del_tokens": "options [ :cache_classes ] . each { | klass | SpatialFeatures . cache_record_proximity ( model , klass ) }", "commit_type": "allow"}
{"commit_tokens": ["Changes", "some", "methods", "to", "be", "class", "methods"], "add_tokens": "def self . connec_entities_names allow ( Entities :: ContactAndLead ) . to receive ( :external_entities_names ) . and_return ( %w( ) ) def self . connec_entity_name", "del_tokens": "def connec_entities_names allow_any_instance_of ( Entities :: ContactAndLead ) . to receive ( :external_entities_names ) . and_return ( %w( ) ) def connec_entity_name", "commit_type": "change"}
{"commit_tokens": ["Allow", "global", "solr", "options", "to", "be", "provided", "to", "the", "SolrWrapper", "::", "Instance"], "add_tokens": "# @option options [Hash] :solr_options args = [ solr_binary , cmd ] + solr_options . merge ( options ) . map { | k , v | [ \"-#{k}\" , \"#{v}\" ] } . flatten def solr_options options . fetch ( :solr_options , { } ) end", "del_tokens": "args = [ solr_binary , cmd ] + options . map { | k , v | [ \"-#{k}\" , \"#{v}\" ] } . flatten", "commit_type": "allow"}
{"commit_tokens": ["Update", "ChangeLog", "and", "bump", "version", "."], "add_tokens": "VERSION = '1.2.11.2'", "del_tokens": "VERSION = '1.2.11.1'", "commit_type": "update"}
{"commit_tokens": ["update", "bundler", "remove", "to", "phatworx"], "add_tokens": "$LOAD_PATH . unshift ( File . dirname ( __FILE__ ) ) require 'simplecov' SimpleCov . start 'rails' require 'rspec' # Requires supporting files with custom matchers and macros, etc, # in ./support/ and its subdirectories. Dir [ \"#{File.dirname(__FILE__)}/support/**/*.rb\" ] . each { | f | require f } RSpec . configure do | config |", "del_tokens": "$LOAD_PATH . unshift ( File . dirname ( __FILE__ ) ) require 'spec' require 'spec/autorun' Spec :: Runner . configure do | config |", "commit_type": "update"}
{"commit_tokens": ["moved", "to", "AWS", "S3", "gem", ".", "all", "tests", "pass"], "add_tokens": "require File . expand_path ( '../../buzzcore/lib/buzzcore_dev.rb' , File . dirname ( __FILE__ ) ) require_paths_first '../lib' # prefer local yore over installed gem require 'yore/AWSS3Client' require 'yore/yore_core' require 'fileutils'", "del_tokens": "require 'yore'", "commit_type": "move"}
{"commit_tokens": ["Added", "a", "pre", "-", "connect", "queue", "for", "messages", "that", "are", "sent", "before", "the", "connection", "is", "ready"], "add_tokens": "@queue = [ ] if established? connection . send_data ( @encoder . encode ( data ) ) else @queue << data end while ! @queue . empty? send_data @queue . shift end", "del_tokens": "connection . send_data ( @encoder . encode ( data ) )", "commit_type": "add"}
{"commit_tokens": ["added", "configuration", "option", "to", "allow", "lazy", "loading", "to", "be", "ignorant", "to", "potential", "sevendigital", "errors"], "add_tokens": "puts \"but the response is out of date\" if @client . verbose? && api_response && api_response . out_of_date?", "del_tokens": "puts \"but the response is out of date\" if @client . verbose? && api_response . out_of_date?", "commit_type": "add"}
{"commit_tokens": ["Move", "email", "and", "auth", "to", "SystemConfig", "only", "."], "add_tokens": "# # As a feature during testing +config/key_name.yml+ will be used if it exists and the database # value is missing. # if record value = record . value if value . is_a? ( Hash ) && value . keys . include? ( :encrypted_value ) value = value [ :encrypted_value ] value = YAML . load ( crypto_cipher . decrypt ( value ) ) unless value . nil? || value == '' end elsif Rails . env . test? yml_file = \"#{BarkestCore.app_root}/config/#{key_name}.yml\" value = File . exist? ( yml_file ) ? YAML . load_file ( yml_file ) : nil else value = nil", "del_tokens": "value = record ? record . value : nil if value . is_a? ( Hash ) && value . keys . include? ( :encrypted_value ) value = value [ :encrypted_value ] value = YAML . load ( crypto_cipher . decrypt ( value ) ) unless value . nil? || value == ''", "commit_type": "move"}
{"commit_tokens": ["Added", "destroy", "to", "bounces", "and", "some", "doc"], "add_tokens": "# # @param options [Hash] options to populate to mailgun find # @option options limit (100) [Integer] limit of results # @option options skip (0) [Integer] number of results to skip # # @returns [Array<Hash>] array of bouces # # @returns [<Hash>] found bouce # Creates a bounce for an email address # # @param email [String] email address to bounce # @param options [Hash] options to populate to mailgun bounce creation # @option options code (550) [Integer] Error code # @option options error ('') [String] Error description # # @returns [<Hash>] created bouce def add ( email , options = { } ) Mailgun . submit :post , bounce_url , { :address => email } . merge ( options ) end # Cleans the bounces for an email address def destroy ( email ) Mailgun . submit :delete , bounce_url ( email ) end", "del_tokens": "def add ( email ) Mailgun . submit :post , bounce_url , :address => email end", "commit_type": "add"}
{"commit_tokens": ["Add", "configuration", "and", "move", "code", "into", "sub", "modules", "."], "add_tokens": "# module ProjectHaystack # require 'faraday' # # took this from mongoid # # def configure # # block_given? ? yield(Config) : Config # # end # # # For now, just make it work # # BASE_URL = 'skyspark-ops.nrel.gov' # # headers = ['Accept: application/json','Authorization: Basic YmVuOg==\\n'] # # def ops # # # ops_url = \"https://#{CREDENTIALS}@#{BASE_URL}/api/#{PROJECT}/ops\" # # # puts \"checking ops path at #{ops_url}\" # # c = Config.connection('demo') # # response = c.get(\"/ops\") # # end # end require 'faraday' require 'project_haystack/config' require 'project_haystack/point'", "del_tokens": "module ProjectHaystack require 'faraday' # took this from mongoid # def configure # block_given? ? yield(Config) : Config # end # For now, just make it work BASE_URL = 'skyspark-ops.nrel.gov' PROJECT = 'demo' # CREDENTIALS = 'ben:' # CREDENTIALS_ENCODED = 'YmVuOg==\\n' # headers = ['Accept: application/json','Authorization: Basic YmVuOg==\\n'] def ops # ops_url = \"https://#{CREDENTIALS}@#{BASE_URL}/api/#{PROJECT}/ops\" # puts \"checking ops path at #{ops_url}\" c = conn response = c . get ( \"/api/#{PROJECT}/ops\" ) end def conn url = \"https://#{BASE_URL}\" puts \"faraday url #{url}\" conn = Faraday . new ( :url => url ) do | faraday | faraday . request :url_encoded # form-encode POST params faraday . response :logger # log requests to STDOUT faraday . adapter Faraday . default_adapter # make requests with Net::HTTP faraday . headers [ 'Authorization' ] = 'Basic YmVuOg==\\n' faraday . headers [ 'Accept' ] = 'application/json' end end end", "commit_type": "add"}
{"commit_tokens": ["Remove", "oj", "gem", "from", "dependency"], "add_tokens": "require 'json'", "del_tokens": "require 'oj'", "commit_type": "remove"}
{"commit_tokens": ["move", "jeremy", "s", "fixes", "into", "HookSet", "itself", "."], "add_tokens": "_hooks [ name ] . run ( scope , * args ) _hooks [ name ] _hooks [ name ] = Hook . new ( options ) def [] ( name ) super ( name . to_sym ) end def []= ( name , values ) super ( name . to_sym , values ) end", "del_tokens": "callbacks_for_hook ( name ) . run ( scope , * args ) _hooks [ name . to_sym ] _hooks [ name . to_sym ] = Hook . new ( options )", "commit_type": "move"}
{"commit_tokens": ["Add", "Capture#stop", "to", "ease", "writing", "specs", "."], "add_tokens": "@cap_thread = Thread . new do @cap_thread . join ( @timeout ) end # Stop capture. Should be used from another thread, as {#start} blocs. # # BEWARE: multiple capture should not be started in different threads. No effort # has been made to make Capture nor PacketGen thread-safe. # @return [void] def stop @cap_thread . kill", "del_tokens": "cap_thread = Thread . new do cap_thread . join ( @timeout )", "commit_type": "add"}
{"commit_tokens": ["Allows", "you", "to", "include", "Ebayr", "::", "User", "into", "your", "models", "."], "add_tokens": "autoload :User , 'ebayr/user' arguments = process_args ( arguments ) def self . process_args ( args ) result = { } args . each do | k , v | result [ k ] = case v when Date , Time then v . to_time . utc . iso8601 else v end end result", "del_tokens": "require \"ebayr/version\" # Shorthand for call(call, arguments.merge(:auth_token => this.ebay_token)) # Allows objects which mix in this module to use their own token. def ebay_call ( call , arguments = { } ) raise \"#{self} has no eBay token\" unless ebay_token Ebay . call ( call , arguments . merge ( :auth_token => ebay_token ) )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "lookups", "of", "formatted", "IDs", "with", "more", "than", "10", "digits"], "add_tokens": "# Remove any non-digit formatting characters, and only consider the first 10 digits obfuscated_id = original . to_s . delete ( '^0-9' ) . first ( 10 )", "del_tokens": "if acts_as_obfuscated_opts [ :format ] obfuscated_id = original . to_s . delete ( '^0-9' ) else obfuscated_id = original . to_s end", "commit_type": "fix"}
{"commit_tokens": ["Added", "duplicate", "value", "detection", "to", "the", "deep_merge", "overwrite_vals", "value", "collisions", "."], "add_tokens": "merger = proc { | k , v1 , v2 | v1 . is_a? ( Hash ) && v2 . is_a? ( Hash ) ? v1 . merge ( v2 , & merger ) : ( merge_arrays && v1 . is_a? ( Array ) && v2 . is_a? ( Array ) ? ( v1 + v2 ) : ( overwrite_vals || v1 == v2 ? v2 : [ v1 , v2 ] . flatten ) ) }", "del_tokens": "merger = proc { | k , v1 , v2 | v1 . is_a? ( Hash ) && v2 . is_a? ( Hash ) ? v1 . merge ( v2 , & merger ) : ( merge_arrays && v1 . is_a? ( Array ) && v2 . is_a? ( Array ) ? ( v1 + v2 ) : ( overwrite_vals ? v2 : [ v1 , v2 ] . flatten ) ) }", "commit_type": "add"}
{"commit_tokens": ["added", "rspec", "tests", "and", "changelog"], "add_tokens": "scanner = system ( 'clamscan -V' )", "del_tokens": "scanner = system ( 'clamscan' )", "commit_type": "add"}
{"commit_tokens": ["removing", "rspec", "target", "from", "defaults"], "add_tokens": "config . filter_run_excluding :requires_beanstalkd , :requires_two_beanstalkd", "del_tokens": "config . filter_run_excluding :requires_beanstalkd", "commit_type": "remove"}
{"commit_tokens": ["Add", "ability", "to", "listen", "for", "bar", "events", "such", "as", "completion", "state"], "add_tokens": "@formatter = TTY :: ProgressBar :: Formatter . new @meter = TTY :: ProgressBar :: Meter . new ( interval ) @callbacks = Hash . new { | h , k | h [ k ] = [ ] } ensure emit ( :done ) ensure emit ( :stopped ) # Register callback with this bar # # @param [Symbol] name # the name for the event to listen for, e.i. :complete # # @return [self] # # @api public def on ( name , & callback ) synchronize do @callbacks [ name ] << callback end self end # Emit callback by name # # @param [Symbol] # the event name # # @api private def emit ( name , * args ) @callbacks [ name ] . each do | callback | callback . call ( * args ) end end", "del_tokens": "@formatter = TTY :: ProgressBar :: Formatter . new @meter = TTY :: ProgressBar :: Meter . new ( interval )", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "actual", "rack", "app", "deal", "with", "bad", "params"], "add_tokens": "params = Imagetastic . url_handler . query_to_params ( env [ 'QUERY_STRING' ] ) [ 200 , { \"Content-Type\" => \"text/html\" } , [ \"This is imagetastic!\" ] ] rescue UrlHandler :: BadParams => e [ 400 , { \"Content-Type\" => \"text/plain\" } , [ e . message ] ]", "del_tokens": "[ 200 , { \"Content-Type\" => \"text/html\" } , \"This is imagetastic!\" ]", "commit_type": "make"}
{"commit_tokens": ["Added", "feature", "to", "sanitize", "the", "pdf", "content"], "add_tokens": "report_columns . collect { | h | fix_content h . humanize } item_values << fix_content ( item [ column ] . to_s ) def fix_content ( content ) content end", "del_tokens": "report_columns . collect ( & :humanize ) item_values << item [ column ] . to_s", "commit_type": "add"}
{"commit_tokens": ["Added", "at_exit", "hook", "to", "flush", "the", "cache"], "add_tokens": "@@cache = nil unless @@cache @@cache = MeterCat :: Cache . new at_exit { @@cache . flush_all } end return @@cache", "del_tokens": "return @@cache ||= MeterCat :: Cache . new", "commit_type": "add"}
{"commit_tokens": ["fixed", "server", "exceptions", "to", "also", "have", "tags"], "add_tokens": "class ExceptionMail < Struct . new ( :tag , :exception )", "del_tokens": "class ExceptionMail < Struct . new ( :exception )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "increase", "rage", "for", "jruby"], "add_tokens": "numbers = Benchmark :: Trend . range ( 1 , 2_000 )", "del_tokens": "numbers = Benchmark :: Trend . range ( 1 , 1_000 )", "commit_type": "change"}
{"commit_tokens": ["fixed", "up", "option", "a", "bit", "more"], "add_tokens": "blank? ? nil : @content blank? ? raise ( exception ) : @content @content . respond_to? ( :empty? ) ? empty? : ! self", "del_tokens": "@content blank? ? @content : exception . call @content . nil? || @content . empty?", "commit_type": "fix"}
{"commit_tokens": ["Add", "multipart?", "function", "and", "improve", "translit", "."], "add_tokens": "include ActiveSupport :: Inflector before_update :remove_fields_values after_update :create_fields_values def published? ; active? end # Return true if there is a file upload field in page def multipart? fields . each { | f | return true if f . type_value == 'image' } false end self . url = ( ( auto_url || url . empty? ) ? transliterate ( name , '' ) : url ) . parameterize", "del_tokens": "def published? ; active end alias_method :active? , :published? self . url = ( ( auto_url || url . empty? ) ? translit ( name ) : url ) . parameterize # TODO: add more languages # translit to english def translit ( str ) ; Russian . translit ( str ) end", "commit_type": "add"}
{"commit_tokens": ["Fix", "Rails", "initializer", "without", "Sprockets"], "add_tokens": "begin require 'sprockets/railtie' module AutoprefixedRails class Railtie < :: Rails :: Railtie rake_tasks do | app | require 'rake/autoprefixer_tasks' Rake :: AutoprefixerTasks . new ( browsers ( app ) ) end initializer :setup_autoprefixer do | app | AutoprefixerRails . install ( app . assets , browsers ( app ) ) end # Read browsers requirements from application config def browsers ( app ) file = app . root . join ( 'config/autoprefixer.yml' ) config = file . exist? ? YAML . load_file ( file ) : { 'browsers' => nil } config [ 'browsers' ] end rescue LoadError", "del_tokens": "require 'sprockets/railtie' module AutoprefixedRails class Railtie < :: Rails :: Railtie rake_tasks do | app | require 'rake/autoprefixer_tasks' Rake :: AutoprefixerTasks . new ( browsers ( app ) ) end initializer :setup_autoprefixer do | app | AutoprefixerRails . install ( app . assets , browsers ( app ) ) end # Read browsers requirements from application config def browsers ( app ) file = app . root . join ( 'config/autoprefixer.yml' ) config = file . exist? ? YAML . load_file ( file ) : { 'browsers' => nil } config [ 'browsers' ]", "commit_type": "fix"}
{"commit_tokens": ["fixed", "requirement", "for", "image", "processing", "by", "creating", "exception", "cases", "and", "moving", "out", "of", "gem", "specification"], "add_tokens": "begin require 'rmagick' rescue LoadError require 'RMagick' rescue LoadError raise \"Installation of 'rmagick' is required before using the 'image' processor\" end", "del_tokens": "require 'rmagick'", "commit_type": "fix"}
{"commit_tokens": ["Add", "specs", "around", "shortcuts", "."], "add_tokens": ":http_post , :put , :http_get , :nobody , :upload , :custom_request ,", "del_tokens": ":post , :put , :http_get , :nobody ,", "commit_type": "add"}
{"commit_tokens": ["Added", "Model#set", "with", "specs", "."], "add_tokens": "def reset_data dir = File . dirname ( __FILE__ ) File . read ( \"#{dir}/test-data.sql\" ) . split ( / ; / ) . each do | command | $dbh . do ( command ) end end $dbh = DBI . connect ( \"DBI:Pg:m4dbi\" , \"m4dbi\" , \"m4dbi\" ) reset_data reset_data it 'should provide multi-column writability via Model#set' do p = @m_post [ 1 ] the_new_text = 'The 3rd post.' p . set ( :author_id => 2 , :text => the_new_text ) p_ = @m_post [ 1 ] p_ . author_id . should . equal 2 p_ . text . should . equal the_new_text reset_data end", "del_tokens": "$dbh = DBI . connect ( \"DBI:Pg:m4dbi\" , \"m4dbi\" , \"m4dbi\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "route", "patch", "if", "put", "present"], "add_tokens": "verb = extract . verb path = extract . path verb . eql? ( 'put' ) ? route_update ( path , verb ) : route ( path , verb ) def route ( path , verb ) { \"#{path}\" : { \"#{verb}\" : super_hash } } end def route_update ( path , verb ) { \"#{path}\" : { \"#{verb}\" : super_hash } . merge! ( patch : super_hash ) } end", "del_tokens": "{ \"#{extract.path}\" : { \"#{extract.verb}\" : super_hash } }", "commit_type": "add"}
{"commit_tokens": ["Add", "absolute", "path", "for", "output", "results"], "add_tokens": "path = @file . include? ( '/' ) ? @file : \"../../../data/#{@file}\" File . expand_path ( path , __FILE__ )", "del_tokens": "File . expand_path ( \"../../../data/#{@file}\" , __FILE__ )", "commit_type": "add"}
{"commit_tokens": ["Adds", "the", "configuration", "to", "the", "rack", "env", "on", "each", "request", "and", "then", "a", "url", "helper", "for", "the", "current", "request"], "add_tokens": "CONFIGURATION_KEY = \"pancake.request.configuration\" . freeze def add ( path , opts = { } , & block ) route = super ( path , opts ) if block_given? route . to ( block ) end route def call ( env ) orig_config = env [ CONFIGURATION_KEY ] env [ CONFIGURATION_KEY ] = configuration super ( env ) ensure env [ CONFIGURATION_KEY ] = orig_config end", "del_tokens": "def add ( path , opts = { } ) super ( path , opts )", "commit_type": "add"}
{"commit_tokens": ["Make", "fedora_to_rof", "generate", "json", "all", "at", "once"], "add_tokens": "result = [ ] result << ROF :: FedoraToRof . GetFromFedora ( pid , fedora , config ) outfile . write ( JSON . pretty_generate ( result ) )", "del_tokens": "outfile . write ( \"[\\n\" ) first = true outfile . write ( ',' ) unless first fedora_data = ROF :: FedoraToRof . GetFromFedora ( pid , fedora , config ) outfile . write ( JSON . pretty_generate ( fedora_data ) ) first = false outfile . write ( \"]\\n\" )", "commit_type": "make"}
{"commit_tokens": ["Updated", "jar", "ver", "and", "date"], "add_tokens": "VERSION = \"1.2.2\"", "del_tokens": "VERSION = \"1.2.1\"", "commit_type": "update"}
{"commit_tokens": ["Add", "hostname", "to", "log", "prefix", "using", "IO", ".", "pipe"], "add_tokens": "require 'frontkick' output_with_hostname ( host ) do | out , err | result = Frontkick . exec ( env , command , out : out , err : err ) return false unless result . successful? end output_with_hostname ( host ) do | out , err | result = Frontkick . exec ( env , command , out : out , err : err ) return false unless result . successful? end def output_with_hostname ( host , & block ) out_r , out_w = IO . pipe out_w . sync = true err_r , err_w = IO . pipe err_w . sync = true $stdout . sync = true $stderr . sync = true out_thr = Thread . new do while r = out_r . gets $stdout . write \"#{host} | #{r}\" end end err_thr = Thread . new do while r = err_r . gets $stderr . write \"#{host} | #{r}\" end end yield ( out_w , err_w ) ensure out_r . close rescue nil out_w . close rescue nil err_r . close rescue nil err_w . close rescue nil out_thr . exit rescue nil err_thr . exit rescue nil end", "del_tokens": "return false unless system ( env , command ) return false unless system ( env , command )", "commit_type": "add"}
{"commit_tokens": ["Changing", "where", "the", "fields_info", "attribute", "is", "initialized"], "add_tokens": "self . fields_info = fields_info . nil? ? { field . to_sym => value } : fields_info . merge ( field . to_sym => value )", "del_tokens": "self . fields_info = fields_info . merge field . to_sym => value", "commit_type": "change"}
{"commit_tokens": ["Fixed", "yielder", "incorrectly", "transcribing", "symbol", "args"], "add_tokens": "\"yield(#{@arg.inspect})\" # usually a symbol but may be string", "del_tokens": "\"yield(#{@arg})\"", "commit_type": "fix"}
{"commit_tokens": ["update", "the", "version", "test", "...", "doh!"], "add_tokens": "assert_equal ( '1.2.0' , Unit :: VERSION )", "del_tokens": "assert_equal ( '1.2.0.b' , Unit :: VERSION )", "commit_type": "update"}
{"commit_tokens": ["Use", "Rubydora", "::", "Repository", ".", "search", "to", "find", "objects", "(", "avoid", "a", "potential", "timout"], "add_tokens": "connections . each do | conn | conn . search ( nil ) do | object | solrize ( object . pid , opts ) end end", "del_tokens": "objects = find_objects ( :limit => num_docs ) puts \"Shelving #{objects.length} Fedora objects\" objects . each do | object | solrize ( object , opts ) end def find_objects ( * args ) raise ArgumentError , \"Missing query string\" unless args . length >= 1 options = args . last . is_a? ( Hash ) ? args . pop : { } params = { } params [ :query ] = '' params [ :maxResults ] = options [ :limit ] if options [ :limit ] params [ :pid ] = true pids = [ ] connections . each do | conn | response = Hash . from_xml ( conn . find_objects ( params ) ) pids << response [ \"result\" ] [ \"resultList\" ] [ \"objectFields\" ] . map { | x | x [ \"pid\" ] } end pids . flatten end", "commit_type": "use"}
{"commit_tokens": ["Changed", "first", "day", "of", "the", "week", "to", "0", "in", "the", "replacers", "constant", "."], "add_tokens": "0 => [ :sunday , :sun ] , 1 => [ :monday , :mon , :january , :jan ] , 2 => [ :tuesday , :tues , :february , :feb ] , 3 => [ :wednesday , :wednes , :tue , :march , :mar ] , 4 => [ :thursday , :thurs , :wed , :april , :apr ] , 5 => [ :friday , :fri , :thu , :may ] , 6 => [ :saturday , :sat , :june , :jun ] , 7 => [ :july , :jul ] ,", "del_tokens": "1 => [ :sunday , :sun , :january , :jan ] , 2 => [ :monday , :mon , :february , :feb ] , 3 => [ :tuesday , :tues , :tue , :march , :mar ] , 4 => [ :wednesday , :wednes , :wed , :april , :apr ] , 5 => [ :thursday , :thurs , :thu , :may ] , 6 => [ :friday , :fri , :june , :jun ] , 7 => [ :saturday , :sat , :july , :jul ] ,", "commit_type": "change"}
{"commit_tokens": ["Use", "has_key?", "to", "check", "for", "existing", "key"], "add_tokens": "if hash . has_key? ( key ) fail ValueOverwriteError , \"Key #{key.inspect} is defined more than once\" end", "del_tokens": "fail ValueOverwriteError , \"Key #{key.inspect} is defined more than once\" if hash [ key ]", "commit_type": "use"}
{"commit_tokens": ["Updating", "the", "ruby", "project", "name"], "add_tokens": "Roroacms :: Application . configure do config . action_mailer . delivery_method = :smtp config . action_mailer . smtp_settings = { :address => 'smtp.gmail.com' , :domain => APP_CONFIG [ 'domain' ] , :port => 587 , :user_name => APP_CONFIG [ 'email_address' ] , :password => APP_CONFIG [ 'password' ] , :authentication => :plain } config . action_mailer . raise_delivery_errors = true end", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["fix", "configs", "in", "p2p", "protocol"], "add_tokens": "client_version_string : proto . config [ :client_version_string ] , listen_port : proto . config [ :p2p ] [ :listen_port ] , remote_pubkey : proto . config [ :node ] [ :id ] } if data [ 'remote_pubkey' ] == proto . config [ :node ] [ :id ]", "del_tokens": "client_version_string : proto . config [ 'client_version_string' ] , listen_port : proto . config [ 'p2p' ] [ 'listen_port' ] , remote_pubkey : proto . config [ 'node' ] [ 'id' ] } if data [ 'remote_pubkey' ] == proto . config [ 'node' ] [ 'id' ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "NSEC3", "RR", "."], "add_tokens": "REGEX_TYPE = / (?<type>A|AAAA|CDNSKEY|CDS|CNAME|DLV|DNSKEY|DS|HINFO|MX|NAPTR|NS|NSEC|NSEC3|RRSIG|SOA|SPF|SRV|SSHFP|TXT|PTR) \\s {1} /i when 'NSEC3' then NSEC3 . new . load ( string , options ) autoload :NSEC3 , 'dns/zone/rr/nsec3'", "del_tokens": "REGEX_TYPE = / (?<type>A|AAAA|CDNSKEY|CDS|CNAME|DLV|DNSKEY|DS|HINFO|MX|NAPTR|NS|NSEC|RRSIG|SOA|SPF|SRV|SSHFP|TXT|PTR) \\s {1} /i", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "Celluloid", "::", "Task", "API"], "add_tokens": "set [ socket ] = Task . current Task . suspend :zmqwait task = @readers . delete sock if task task . resume task = @writers . delete sock if task task . resume", "del_tokens": "set [ socket ] = Fiber . current Fiber . yield fiber = @readers . delete sock if fiber fiber . resume fiber = @writers . delete sock if fiber fiber . resume", "commit_type": "use"}
{"commit_tokens": ["Add", "readme", "and", "fix", "docs", "line"], "add_tokens": "# on_retry proc { |error, tries| puts \"#{self.name} - Retrying.. #{tries} of #{self.retriable_configuration[:retries]} (#{error})\" }", "del_tokens": "# on_retry proc do |error, tries| # puts \"#{self.class.name} - Retrying.. #{tries} of #{self.class.retriable_configuration[:retries]} (#{error})\" # end", "commit_type": "add"}
{"commit_tokens": ["add", "fail_for_todos", "to", "fail", "instead", "of", "warn"], "add_tokens": "call_method_for_todos ( :warn ) end # # Adds an error if there are todos found in the modified code # # @return [void] # def fail_for_todos call_method_for_todos ( :fail ) def call_method_for_todos ( method ) @todos = [ ] return if files_of_interest . empty? @todos = DiffTodoFinder . new . find_diffs_containing_todos ( diffs_of_interest ) public_send ( method , message , sticky : false ) unless @todos . empty? end", "del_tokens": "@todos = [ ] return if files_of_interest . empty? @todos = DiffTodoFinder . new . find_diffs_containing_todos ( diffs_of_interest ) warn ( message , sticky : false ) unless @todos . empty?", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "for", "uploading", "and", "creating", "solr", "collections"], "add_tokens": "def self . default_instance options @default_instance ||= SolrWrapper :: Instance . new options def self . wrap options = { } , & block default_instance ( options ) . wrap & block", "del_tokens": "def self . default_instance @default_instance ||= SolrWrapper :: Instance . new def self . wrap & block default_instance . wrap & block", "commit_type": "add"}
{"commit_tokens": ["adds", "the", "ability", "for", "a", "page", "to", "redirect", "immediately", "to", "its", "first", "child", "if", "it", "has", "a", "child", "that", "is", "not", "a", "draft", "page", "if", "that", "option", "is", "set", "in", "refinery", "/", "admin", "/", "pages", "/", "page", "/", "edit", "."], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20090822092032 ) do t . boolean \"skip_to_first_child\" , :default => false", "del_tokens": "ActiveRecord :: Schema . define ( :version => 20090618044141 ) do", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "missing", "nested", "keys"], "add_tokens": "value = key . split ( '.' ) . reduce ( json ) { | j , k | j . fetch ( k , { } ) } value == { } ? nil : value", "del_tokens": "key . split ( '.' ) . reduce ( json ) { | j , k | j [ k ] }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "NilClass#^", "and", "NilClass#|", ".", "Fixes", "2", "specs"], "add_tokens": "` other !== false && other != null ` ` other !== false && other != null `", "del_tokens": "` other != false && other != null ` ` other != false && other != null `", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "client", "cli", "handling", ".", "client", "needed", "to", "to_s", "the", "table", "name", "when", "giving", "it", "to", "progressbar"], "add_tokens": "progress = ProgressBar . new ( table_name . to_s , count )", "del_tokens": "progress = ProgressBar . new ( table_name , count )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "StepError", "to", "simply", "accept", "either", "a", "msg", "or", "a", "wrapped", "error"], "add_tokens": "def initialize ( input ) if input . kind_of? ( StandardError ) @original_error = input super ( @original_error . message ) set_backtrace ( original_error . backtrace ) else super ( input ) end", "del_tokens": "def initialize ( msg , original_error = nil ) super ( msg ) @original_error = original_error", "commit_type": "allow"}
{"commit_tokens": ["Add", "#to_raw_h", "method", "to", "SPOT", "::", "Resources", "::", "Message"], "add_tokens": "@hidden = object . fetch ( 'hidden' ) == 1 @show_custom_message = object . fetch ( 'showCustomMsg' ) == \"Y\" @content = object . fetch ( 'messageContent' ) @messenger_id = object . fetch ( 'messengerId' ) @messenger_name = object . fetch ( 'messengerName' ) @messenger_model = object . fetch ( 'modelId' ) @object = object attribute_ivars = ( instance_variables - [ :@response , :@object , :@hash ] ) def to_raw_h @object end", "del_tokens": "@hidden = object [ 'hidden' ] == 1 @show_custom_message = object [ 'showCustomMsg' ] == \"Y\" @content = object [ 'messageContent' ] @messenger_id = object [ 'messengerId' ] @messenger_name = object [ 'messengerName' ] @messenger_model = object [ 'modelId' ] attribute_ivars = ( instance_variables - [ :@response , :@hash ] )", "commit_type": "add"}
{"commit_tokens": ["Updated", "#view", "helper", "now", "accepts", "extra", "args"], "add_tokens": "def view ( name , * args ) erb ( \"#{name}.html\" . to_sym , * args )", "del_tokens": "def view ( name ) erb \"#{name}.html\" . to_sym", "commit_type": "update"}
{"commit_tokens": ["Change", "arg", "from", "binding", "to", "bound"], "add_tokens": "renderer = Mako :: HTMLRenderer . new ( template : @template , bound : binding_klass )", "del_tokens": "renderer = Mako :: HTMLRenderer . new ( template : @template , binding : binding_klass )", "commit_type": "change"}
{"commit_tokens": ["use", "jeweler", "sync", "up", "with", "latest", "naether"], "add_tokens": "require 'rubygems' Naether . bootstrap_dependencies naether_jars = [ Naether :: Bootstrap . naether_jar ] naether_jars = naether_jars + Buildr . artifacts ( resolver_dependencies ) . each ( & :invoke ) . map ( & :to_s ) naether = Naether . create_from_jars ( naether_jars )", "del_tokens": "Naether . bootstrap_dependencies . to_a naether_classpath = Buildr . artifacts ( resolver_dependencies ) . each ( & :invoke ) . map ( & :to_s ) naether_classpath . each do | jar | require jar end naether = Naether . new", "commit_type": "use"}
{"commit_tokens": ["Remove", "all", "support", "for", "raw", "/", "unmapped", "data"], "add_tokens": "return internal_groups", "del_tokens": "# Container for raw RDF data stored as an array of hashes for easy use on forms (currently used # for statements which didn't match the digital object's subject) attr_reader :raw_statements @raw_statements = [ ] return internal_groups + [ \"unmapped_association\" ] # Check for unknown data @raw_statements = attributes . delete ( \"raw_statements\" ) if attributes [ \"raw_statements\" ] # Attaches the given raw statement data to the list of unknown raw statement data. `statement` # is expected to act like RDF::Statement - responds to #subject, #predicate, and #object. def add_raw_statement ( statement ) @raw_statements . push ( { :subject => statement . subject . to_s , :predicate => statement . predicate . to_s , :object => statement . object . to_s } ) end", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "leaf", "boundary", "bug", "with", "DICOM", "conversion"], "add_tokens": "Array . new ( nr_leaves + 1 ) { | i | ( i * 400 / nr_leaves . to_f - 200 ) . to_i } Array . new ( nr_leaves + 1 ) { | i | ( i * 400 / nr_leaves . to_f - 200 ) . to_i }", "del_tokens": "Array . new ( nr_leaves ) { | i | ( i * 400 / nr_leaves . to_f - 200 ) . to_i } Array . new ( nr_leaves ) { | i | ( i * 400 / nr_leaves . to_f - 200 ) . to_i }", "commit_type": "fix"}
{"commit_tokens": ["Add", "Decoder#decode", "for", "decoding", "raw", "audio", "files", "+", "docs", "/", "specs"], "add_tokens": "typedef :pointer , :decoder typedef :pointer , :configuration attach_function :ps_init , [ :configuration ] , :decoder attach_function :ps_decode_raw , [ :decoder , :pointer , :string , :long ] , :int attach_function :ps_process_raw , [ :decoder , :pointer , :size_t , :int , :int ] , :int attach_function :ps_start_utt , [ :decoder , :string ] , :int attach_function :ps_end_utt , [ :decoder ] , :int attach_function :ps_get_in_speech , [ :decoder ] , :uint8 attach_function :ps_get_hyp , [ :decoder , :pointer , :pointer ] , :string", "del_tokens": "attach_function :ps_init , [ :pointer ] , :pointer attach_function :ps_process_raw , [ :pointer , :pointer , :size_t , :int , :int ] , :int attach_function :ps_start_utt , [ :pointer , :string ] , :int attach_function :ps_end_utt , [ :pointer ] , :int attach_function :ps_get_in_speech , [ :pointer ] , :uint8 attach_function :ps_get_hyp , [ :pointer , :pointer , :pointer ] , :string", "commit_type": "add"}
{"commit_tokens": ["Add", "content", "-", "available", "key", "to", "notification", "json"], "add_tokens": "badge : 1 , 'content-available' : 1", "del_tokens": "badge : 1", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "subject", "and", "its", "keyword"], "add_tokens": "subject_and_its_keywords = language . subject_keywords . merge ( language . its_keywords ) subject_and_its_keywords . each do | key , values |", "del_tokens": "language . subject_keywords . each do | key , values |", "commit_type": "add"}
{"commit_tokens": ["moved", "default", "flags", "column", "name", "to", "a", "constant"], "add_tokens": "DEFAULT_COLUMN_NAME = 'flags' :column => DEFAULT_COLUMN_NAME , def flags ( colmn = DEFAULT_COLUMN_NAME ) return DEFAULT_COLUMN_NAME if self . class . flag_mapping . nil?", "del_tokens": ":column => 'flags' , def flags ( colmn = 'flags' ) return 'flags' if self . class . flag_mapping . nil?", "commit_type": "move"}
{"commit_tokens": ["Added", "storing", "of", "external", "files", "inside", "the", "package", "for", "upload"], "add_tokens": "app_screenshot . store_file_inside_package ( @package_path ) File . write ( \"#{@package_path}/#{METADATA_FILE_NAME}\" , @data . to_xml ) @package_path = path @data ||= Nokogiri :: XML ( File . read ( \"#{path}/#{METADATA_FILE_NAME}\" ) )", "del_tokens": "File . write ( @metadata_path , @data . to_xml ) @metadata_path = \"#{path}/#{METADATA_FILE_NAME}\" @data ||= Nokogiri :: XML ( File . read ( @metadata_path ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "and", "bumped", "version"], "add_tokens": "lut_keys . each { | k | lut_reload ( k ) }", "del_tokens": "@@lut . keys . each { | k | lut_reload ( k ) }", "commit_type": "fix"}
{"commit_tokens": ["added", "missing", "child", "output", "port", "name"], "add_tokens": "add_external_output_coupling ( :random , :output , :output )", "del_tokens": "add_external_output_coupling ( :random , :output )", "commit_type": "add"}
{"commit_tokens": ["fixed", "invalid", "media", "-", "type"], "add_tokens": "{ :id => 'foo' , :href => 'foo.html' , :media_type => 'application/xhtml+xml' } , { :id => 'bar' , :href => 'bar.html' , :media_type => 'application/xhtml+xml' } ,", "del_tokens": "{ :id => 'foo' , :href => 'foo.html' , :media_type => 'text/html' } , { :id => 'bar' , :href => 'bar.html' , :media_type => 'text/html' } ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "Linked", "List", "info", "to", "the", "readme"], "add_tokens": "VERSION = \"1.1.3\"", "del_tokens": "VERSION = \"1.1.2\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "and", "docs", "."], "add_tokens": "", "del_tokens": "# Your model: # # class Graduation < ActiveRecord::Base # named_scope :featured, :conditions => { :featured => true } # named_scope :by_degree, proc {|degree| { :conditions => { :degree => degree } } } # end # # Your controller: # # class GraduationsController < InheritedResources::Base # has_scope :featured, :boolean => true, :only => :index # has_scope :by_degree, :only => :index # end # # Then for each request: # # /graduations # #=> acts like a normal request # # /graduations?featured=true # #=> calls the named scope and bring featured graduations # # /graduations?featured=true&by_degree=phd # #=> brings featured graduations with phd degree # # You can retrieve the current scopes in use with <tt>current_scopes</tt> # method. In the last case, it would return: { :featured => \"true\", :by_degree => \"phd\" } #", "commit_type": "update"}
{"commit_tokens": ["Add", "forward", "slash", "to", "random", "post", "and", "post", "content", "paths"], "add_tokens": "RANDOM_POST_PATH = '/g/' . freeze POST_CONTENT_PATH = '/p/' . freeze # @param [Boolean] reject_insecure_url Return only secure url post_id = fetch_random_post_id # fetch_random_post_id Fetch random LGTM post url from https://www.lgtm.app def fetch_random_post_id # @return [Boolean] Should be image url requested again", "del_tokens": "RANDOM_POST_PATH = '/g' . freeze POST_CONTENT_PATH = '/p' . freeze # @param [Boolean] reject_insecure_url Eeturn only secure url post_id = fetch_randon_post_id # fetch_randon_post_id Fetch renadon LGTM post url from https://www.lgtm.app def fetch_randon_post_id # @return [Boolean] should be image url requested again", "commit_type": "add"}
{"commit_tokens": ["Adds", "support", "for", "references", "and", "refactor", "complex", "map_to"], "add_tokens": "# { 'External Entity' => LalaMapper, 'Other external entity' => LiliMapper } # or { 'Connec Entity' => LalaMapper, 'Other connec entity' => LiliMapper } def mapper_classes { } end # { # 'External Entity' => [{reference_class: Entities::.., connec_field: '', external_field: ''}], # 'Other external entity' => [{reference_class: Entities::.., connec_field: '', external_field: ''}] # } def references { } end mapper = self . class . mapper_classes [ name ] raise \"Impossible mapping from #{self.class.entity_name} to #{name}\" unless mapper ref_hash = { } if self . class . references [ name ] self . class . references [ name ] . each do | ref | field = self . class . external? ? ref [ :connec_field ] : ref [ :external_field ] ref_hash . merge! field . split ( '/' ) . reverse . inject ( Maestrano :: Connector :: Rails :: Entity . id_from_ref ( entity , ref , false , organization ) ) { | a , n | { n . to_sym => a } } end end if self . class . external? mapped_entity = mapper . denormalize ( entity ) else mapped_entity = mapper . normalize ( entity ) end mapped_entity . merge ( ref_hash )", "del_tokens": "raise \"Not implemented\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "passing", "in", "settings", "through", "the", "constructor"], "add_tokens": "def initialize ( locals : { } , ivars : { } , scope : nil ) @locals = locals @ivars = ivars @scope = scope", "del_tokens": "def initialize @locals = { } @ivars = { } @scope = nil", "commit_type": "allow"}
{"commit_tokens": ["fixed", "parser_failure_info", "output", "double", "-", "inspect"], "add_tokens": "\"#{a[:pattern]}\\t #{list}\"", "del_tokens": "\"#{a[:pattern].inspect}\\t #{list}\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "for", "sending", "blocks", "to", "part", "methods"], "add_tokens": "Dry :: View :: NullPart . new ( renderer , { user : nil } ) part . form ( & block )", "del_tokens": "Dry :: View :: NullPart . new ( renderer , data ) let ( :name ) { :user } let ( :data ) { { user : nil } } part . form ( block )", "commit_type": "fix"}
{"commit_tokens": ["use", "absolute_url", "to", "generate", "the", "feed_meta", "url"], "add_tokens": "# Use Jekyll's native relative_url filter include Jekyll :: Filters :: URLFilters :href => absolute_url ( path ) ,", "del_tokens": ":href => \"#{url}/#{path}\" , def url if config [ \"url\" ] URI . join ( config [ \"url\" ] , config [ \"baseurl\" ] ) elsif config [ \"github\" ] && config [ \"github\" ] [ \"url\" ] config [ \"github\" ] [ \"url\" ] end end", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "docker", "()", "util", "everywhere"], "add_tokens": "x = docker ( 'images' , '--no-trunc' , capture : true ) x = docker ( 'inspect' , * cide_image_ids , capture : true ) docker ( 'rmi' , * old_cide_images )", "del_tokens": "x = run ( 'docker images --no-trunc' , capture : true ) x = run ( \"docker inspect #{cide_image_ids.join(' ')}\" , capture : true ) run ( \"docker rmi #{old_cide_images.join(' ')}\" )", "commit_type": "use"}
{"commit_tokens": ["Add", "missing", "parameters", "to", "check_box", "methods"], "add_tokens": "def check_box ( attribute , options = { } , checked_value = \"1\" , unchecked_value = \"0\" ) super ( attribute , options , checked_value , unchecked_value )", "del_tokens": "def check_box ( attribute , options = { } ) super ( attribute , options )", "commit_type": "add"}
{"commit_tokens": ["Add", "#map", "spec", "to", "all", "Monads"], "add_tokens": "end end describe '#map functor' do add100 = -> ( value ) { value + 100 } it 'on value types, returns the transformed value, wrapped in the Monad' do res = monad . unit ( 1 ) . map { | v | add100 . ( v ) } res . should == monad . unit ( 101 ) res = monad . unit ( 1 ) . map { | v | monad . unit ( v + 100 ) } res . should == monad . unit ( 101 ) end it 'on enumerables, returns the transformed collection, wrapped in the Monad' do res = monad . unit ( [ 1 , 2 , 3 ] ) . map { | v | add100 . ( v ) } res . should == monad . unit ( [ 101 , 102 , 103 ] ) # The following does not work... not sure whether it should # res = monad.unit([1,2,3]).map {|v| monad.unit(v + 100) } # res.should == monad.unit([101,102,103]) end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Updated", "all", "to", "newest", "Rspec", "syntax", "and", "a", "bundle", "update"], "add_tokens": "allow_any_instance_of ( Capybara :: Node :: Element ) . to receive ( :click ) . # TODO: Find out why should_receive doesn't work allow_any_instance_of ( Capybara :: Node :: Element ) . to receive ( :click ) . # TODO: Find out why should_receive doesn't work", "del_tokens": "Capybara :: Node :: Element . any_instance . stub ( :click ) . # TODO: Find out why should_receive doesn't work Capybara :: Node :: Element . any_instance . stub ( :click ) . # TODO: Find out why should_receive doesn't work", "commit_type": "update"}
{"commit_tokens": ["Added", "tests", "to", "inherited", "controllers", "that", "inherit", "from", "inherited", "resources", "."], "add_tokens": "class AccountsController < InheritedResources :: Base end class UsersController < AccountsController", "del_tokens": "class UsersController < InheritedResources :: Base", "commit_type": "add"}
{"commit_tokens": ["added", "ignore", "file", "feature", "to", "churn", "need", "to", "add", "a", "config", "file", "yml", "or", "ENV", "var", "to", "make", "it", "easy", "to", "reuse", "."], "add_tokens": "@ignore_files = ( options . fetch ( :ignore_files ) { \"\" } ) . split ( ',' ) . map ( & :strip ) @source_control = set_source_control ( start_date ) self . emit @changes = parse_log_for_changes . reject { | file , change_count | change_count < @minimum_churn_count || @ignore_files . include? ( file ) } @revisions = parse_log_for_revision_changes end result = seperator result += seperator files = @source_control . get_updated_files_change_info ( revision , revisions ) files . select { | file | ! @ignore_files . include? ( file . first ) }", "del_tokens": "@source_control = set_source_control ( start_date ) self . emit @changes = parse_log_for_changes . reject { | file , change_count | change_count < @minimum_churn_count } @revisions = parse_log_for_revision_changes end result = seperator result += seperator @source_control . get_updated_files_change_info ( revision , revisions )", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "M", "/", "F"], "add_tokens": "Gender = { \"male\" => \"M\" , \"female\" => \"F\" } patient [ 'gender' ] = Gender [ gender_string . downcase ]", "del_tokens": "Gender = { \"Male\" => \"M\" , \"Female\" => \"F\" } patient [ 'gender' ] = Gender [ gender_string ]", "commit_type": "fix"}
{"commit_tokens": ["Adding", "cache_control", "setting", "on", "S3", "Object"], "add_tokens": "attr_accessor :content_type , :content_disposition , :content_encoding , :cache_control headers [ :cache_control ] = options [ :cache_control ] if options [ :cache_control ] object . cache_control = response [ \"cache-control\" ] self . cache_control = options [ :cache_control ] headers [ :cache_control ] = @cache_control if @cache_control self . cache_control = response [ \"cache-control\" ]", "del_tokens": "attr_accessor :content_type , :content_disposition , :content_encoding", "commit_type": "add"}
{"commit_tokens": ["Add", "=", "lines", "to", "logging", "to", "help", "separate", "requests"], "add_tokens": "self . logger . verbose . info ( \"===== Received request =====\" ) self . logger . verbose . info \"===== Completed in #{processed_service.time_taken}ms \" \"#{processed_service.response.status} =====\"", "del_tokens": "self . logger . verbose . info ( \"Received request\" ) self . logger . verbose . info \"Completed in #{processed_service.time_taken}ms \" \"#{processed_service.response.status}\\n\"", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "getting", "the", "metadata", "about", "the", "attributes"], "add_tokens": "VERSION = \"0.2.0\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "Ruby", "/", "YAML", "format", "detector"], "add_tokens": "'YAML' 'Ruby' mod = Conjur :: DSL2 . const_get syntax", "del_tokens": "'yaml' 'ruby' mod = Conjur :: DSL2 . const_get syntax . capitalize", "commit_type": "fix"}
{"commit_tokens": ["Add", "proxy", "to", "#add", "method"], "add_tokens": "require 'spec_helper' it 'has a version number' do it 'add log message to log' do log_content = StringIO . new logger = Logger . new ( log_content ) optional_logger = OptionalLogger :: Logger . new ( logger ) optional_logger . add ( Logger :: INFO , 'my message' , 'my prog' ) log_content . rewind expect ( log_content . read ) . to match ( / INFO -- my prog: my message$ / ) end", "del_tokens": "require \"spec_helper\" it \"has a version number\" do", "commit_type": "add"}
{"commit_tokens": ["Make", "Lexer", ".", "find", "case", "insensitive"], "add_tokens": "@index [ lexer . name . downcase ] = @name_index [ lexer . name ] = lexer @index [ name . downcase ] = @alias_index [ name ] = lexer @index [ name . downcase ]", "del_tokens": "@index [ lexer . name ] = @name_index [ lexer . name ] = lexer @index [ name ] = @alias_index [ name ] = lexer @index [ name ]", "commit_type": "make"}
{"commit_tokens": ["Move", "not", "configured", "default", "block", "into", "block", "map"], "add_tokens": "@not_configured_blocks . add_default ( block ) not_configured_blocks : @not_configured_blocks", "del_tokens": "@not_configured_default_callback = block not_configured_blocks : @not_configured_blocks , not_configured_default_callback : @not_configured_default_callback", "commit_type": "move"}
{"commit_tokens": ["add", "emails", "in", "comma", "separated", "values", "for", "admin", "notification", "emails"], "add_tokens": "# for an invite in a comma separated value. config . admin_emails = 'email_1@example.org, email_2@example.org'", "del_tokens": "# for an invite in an array. config . admin_emails = [ ]", "commit_type": "add"}
{"commit_tokens": ["added", "comments", "for", "attr", ".", "rb"], "add_tokens": "attr_reader :accessor , :setter , :from , :as , :procs , :tag_proc , :tag # Named Procs for use in :as option. # Creates a new instance of Attr to be used as a template for converting # XML to objects and from objects to XML # @param [Symbol,String] name Sets the accessor methods for this attr. # It is also used to guess defaults for :from and :as. # For example if it ends with '?' and :as isn't set # it will treat it as a boolean. # @param [Hash] o the options for the new attr definition # @option o [Symbol,String] :from (tag_proc.call(name)) # Tells OxMlk what the name of the XML attribute is. # It defaults to name processed by the tag_proc. # @option o [Symbol,String,Proc,Array<Symbol,String,Proc>] :as # Tells OxMlk how to translate the XML. # The argument is coerced into a Proc and applied to the string found in the XML attribute. # If an Array is passed each Proc is applied in order with the results # of the first being passed to the second and so on. If it isn't set # and name ends in '?' it processes it as if :bool was passed otherwise # it treats it as a string with no processing. # Includes the following named Procs: Integer, Float, String, Symbol and :bool. # @option o [Proc] :tag_proc (proc {|x| x}) Proc used to guess :from. # The Proc is applied to name and the results used to find the XML attribute # if :from isn't set. # @yield [String] Adds anothe Proc that is applied to the value. private # Finds @tag in data and applies procs. # Converts a value to a Boolean. # @param [Symbol,String,Integer] value Value to convert # @return [Boolean] Returns true if value is 'true', 'yes', 't' or 1. # Returns false if value is 'false', 'no', 'f' or 0. # If can't be convertet to a Boolean then the value is returned.", "del_tokens": "attr_reader :accessor , :setter , :from , :as , :procs , :tag_proc , :tag", "commit_type": "add"}
{"commit_tokens": ["added", "new", "default", "scrub", "params"], "add_tokens": "@scrub_fields = [ :passwd , :password , :password_confirmation , :secret , :confirm_password , :password_confirmation ]", "del_tokens": "@scrub_fields = [ :passwd , :password , :password_confirmation , :secret ]", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "URI", "parser", "using", "URI", ".", "encode", "for", "[", "and", "]"], "add_tokens": "attr_reader :filename , :uri file . write ( open ( URI . encode ( @uri , '[]' ) ) . read )", "del_tokens": "attr_reader :filename file . write ( open ( @uri ) . read )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "tests", "to", "run", "in", "different", "timezones"], "add_tokens": "time = @user . time . strftime ( \"%a, %d %b %Y %H:%M:%S %z\" ) < span class = \"value\" > #{time}</span> < span class = \"value\" > #{@user.time}</span>", "del_tokens": "< span class = \"value\" > Sat , 01 Jan 2000 06 :00 :00 + 0100 < / span > < span class = \"value\" > 2000 - 01 - 01 06 :00 :00 + 0100 < / span >", "commit_type": "allow"}
{"commit_tokens": ["added", "support", "for", "Altmetric", "badges"], "add_tokens": "VERSION = \"0.4.10\"", "del_tokens": "VERSION = \"0.4.9\"", "commit_type": "add"}
{"commit_tokens": ["Add", "order", "limit", "and", "offset", "options", "to", "nearby_mysql_query", "method", "."], "add_tokens": "# # Options hash may include: # # +latitude+ :: name of column storing latitude data # +longitude+ :: name of column storing longitude data # +order+ :: column(s) for ORDER BY SQL clause # +limit+ :: number of records to return (for LIMIT SQL clause) # +offset+ :: number of records to skip (for LIMIT SQL clause) options [ :order ] ||= 'distance ASC' # Build limit clause. limit = \"\" if options [ :limit ] or options [ :offset ] options [ :offset ] ||= 0 limit = \"LIMIT #{options[:offset]},#{options[:limit]}\" end \"FROM #{table} WHERE #{where} HAVING distance <= #{radius} \" + \"ORDER BY #{options[:order]} #{limit}\"", "del_tokens": "\"FROM #{table} WHERE #{where} HAVING distance <= #{radius}\"", "commit_type": "add"}
{"commit_tokens": ["Use", "#public_send", "instead", "of", "unsafe", "#send"], "add_tokens": "faraday . public_send ( request_method , path , params , headers )", "del_tokens": "faraday . send ( request_method , path , params , headers )", "commit_type": "use"}
{"commit_tokens": ["added", "test", "to", "make", "sure", "the", "correct", "number", "of", "items", "are", "being", "returned", "by", "named", "scopes"], "add_tokens": "#require File.expand_path(File.join(ENV['RAILS_ROOT'], 'config/environment.rb'))", "del_tokens": "require File . expand_path ( File . join ( ENV [ 'RAILS_ROOT' ] , 'config/environment.rb' ) )", "commit_type": "add"}
{"commit_tokens": ["Making", "group", "membership", "calculations", "work"], "add_tokens": "patch = 4 # Fixes to existing features", "del_tokens": "patch = 3 # Fixes to existing features", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "timout", "to", "the", "validator"], "add_tokens": "recaptcha = nil Timeout :: timeout ( options [ :timeout ] || 3 ) do recaptcha = Net :: HTTP . post_form URI . parse ( \"http://#{RECAPTCHA_VERIFY_SERVER}/verify\" ) , { \"privatekey\" => private_key , \"remoteip\" => request . remote_ip , \"challenge\" => params [ :recaptcha_challenge_field ] , \"response\" => params [ :recaptcha_response_field ] } end model . errors . add :base , options [ :message ] || \"Captcha response is incorrect, please try again.\" rescue Timeout :: Error session [ :recaptcha_error ] = \"recaptcha-not-reachable\" if model model . valid? model . errors . add :base , options [ :message ] || \"Oops, we failed to validate your Captcha. Please try again.\" end return false", "del_tokens": "recaptcha = Net :: HTTP . post_form URI . parse ( \"http://#{RECAPTCHA_VERIFY_SERVER}/verify\" ) , { \"privatekey\" => private_key , \"remoteip\" => request . remote_ip , \"challenge\" => params [ :recaptcha_challenge_field ] , \"response\" => params [ :recaptcha_response_field ] } if Rails :: VERSION :: MAJOR == 2 and Rails :: VERSION :: MINOR >= 2 model . errors . add :base , I18n . translate ( \"#{model.class.name.underscore}.captcha\" , :scope => %w( errors models ) , :default => ( options [ :message ] || \"Captcha response is incorrect, please try again.\" ) ) else model . errors . add :base , options [ :message ] || \"Captcha response is incorrect, please try again.\" end", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "header", "instead", "of", "cookie", "for", "the", "token"], "add_tokens": "# The name of the header used to hold the Vault token. TOKEN_HEADER = \"X-Vault-Token\" . freeze # Get a list of headers # Add the Vault token header - users could still override this on a # per-request basis if ! token . nil? request . add_field ( TOKEN_HEADER , token ) end # Add headers", "del_tokens": "require \"cgi/cookie\" # Add headers # Create the cookie for the request. cookie = CGI :: Cookie . new cookie . name = \"token\" cookie . value = token cookie . path = \"/\" cookie . expires = Time . now + ( 60 * 60 * 24 * 365 ) # Turn on secure cookies cookie . secure = true # Add the cookie to the request if a token was given. if ! token . nil? request [ \"Cookie\" ] = cookie . to_s end", "commit_type": "use"}
{"commit_tokens": ["Fixing", "indentation", "that", "sourcetree", "messed", "up"], "add_tokens": "# Get the Job ID host = ` hostname -s ` . strip job_id = Minicron :: Transport . get_job_id ( args . first , host ) execution_id = faye . setup ( job_id , args . first , host )", "del_tokens": "# Get the Job ID host = ` hostname -s ` . strip job_id = Minicron :: Transport . get_job_id ( args . first , host ) execution_id = faye . setup ( job_id , args . first , host )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "command", "model", "relationship", ";", "added", "path", "helper"], "add_tokens": "belongs_to :repo def path File . join ( repo . path , bundle , command ) end", "del_tokens": "belongs_to :org", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "sound", "in", "the", "Effect", "constructor", "."], "add_tokens": "# [sound] The id of a sound to be played when the effect is created (id must # be given in the format specified for the +Res.sound+ method). # [sound_ext] Extension of the sound file, if a sound is given. Default is # '.wav'. # [sound_volume] The volume (from 0 to 1) to play the sound, if any. Default # is 1. def initialize ( x , y , img , sprite_cols = nil , sprite_rows = nil , interval = 10 , indices = nil , lifetime = nil , sound = nil , sound_ext = '.wav' , sound_volume = 1 ) Res . sound ( sound , false , sound_ext ) . play ( sound_volume ) if sound", "del_tokens": "def initialize ( x , y , img , sprite_cols = nil , sprite_rows = nil , interval = 10 , indices = nil , lifetime = nil )", "commit_type": "add"}
{"commit_tokens": ["Add", "boolean", "native", "datatype", "support"], "add_tokens": "VERSION = '1.2.3' . freeze", "del_tokens": "VERSION = '1.2.2' . freeze", "commit_type": "add"}
{"commit_tokens": ["Adding", "copyright", "headers", "to", "Ruby", "files", "."], "add_tokens": "#!/usr/bin/env ruby -w # encoding: UTF-8 # # = Lap.rb -- Fit4Ruby - FIT file processing library for Ruby # # Copyright (c) 2014 by Chris Schlaeger <cs@taskjuggler.org> # # This program is free software; you can redistribute it and/or modify # it under the terms of version 2 of the GNU General Public License as # published by the Free Software Foundation. #", "del_tokens": "# Message: lap # timestamp: 2014-05-29 19:19:57 # start_time: 2014-05-29 19:16:41 # start_position_lat: 52.51550791785121 # start_position_long: 13.36703228764236 # end_position_lat: 52.51583841629326 # end_position_long: 13.373064072802663 # total_elapsed_time: 124.717 s # total_timer_time: 124.717 s # total_distance: 416.35 m # total_strides: 171 strides # field27: [626538455] # field28: [159546869] # field29: [626534414] # field30: [159474907] # message_index: 5 # total_calories: 31 kcal # avg_speed: 3.338 m/s # max_speed: 3.359 m/s # total_ascent: 7 m # total_descent: 9 m # field71: [] # avg_vertical_oscillation: 92.2 mm # avg_stance_time_percent: 32.24 percent # avg_stance_time: 235.6 ms # event: lap # event_type: stop # avg_heart_rate: 189 bpm # max_heart_rate: 192 bpm # avg_running_cadence: 82 strides # max_running_cadence: 85 strides # intensity: [no value] # lap_trigger: 7 # sport: 1 # event_group: [no value] # field39: [] # field72: [] # avg_fractional_cadence: 0.0234375 # max_fractional_cadence: 0.5 # total_fractional_cycles: [no value]", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "array", "converters", "."], "add_tokens": "subject ( :converter ) { described_class . new ( :array , :numeric ) }", "del_tokens": "subject ( :converter ) { described_class . new }", "commit_type": "add"}
{"commit_tokens": ["Added", "partial", "implementations", "of", "payment", "retrieval", "methods", "."], "add_tokens": "PENDING = \"PE\" . freeze WAITING = \"WA\" . freeze COMPLETED = \"CO\" . freeze PARTIALLY_PAID = \"PP\" . freeze retrieve_transactions ( nil , transaction_id ) retrieve_transactions ( COMPLETED ) retrieve_transactions ( WAITING ) retrieve_transactions ( PENDING ) retrieve_transactions ( PARTIALLY_PAID )", "del_tokens": "retrieve_transactions", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "log", "messages", "."], "add_tokens": "@start_at = Time . now # Log message above the current progress bar # # @param [String] message # the message to log out def log ( message ) sanitized_message = message . gsub ( / \\r | \\n / , ' ' ) if @done write ( sanitized_message + \"\\n\" , false ) return end sanitized_message = padout ( sanitized_message ) write ( sanitized_message + \"\\n\" , true ) render # Pad message out with spaces # # @api private def padout ( message ) if @last_render_width > message . length remaining_width = @last_render_width - message . length message += ' ' * remaining_width end message end", "del_tokens": "# Terminates the progress bar def terminate @done = true", "commit_type": "add"}
{"commit_tokens": ["updated", "docs", "and", "fixed", "create_eq_users", ".", "rb"], "add_tokens": "# @note user_id, initial_balance, user_name, department_name, and primary_pin required # @param attributes [Hash] this attribute MUST include { user_id: \"userid\", init_bal: 0, username: \"Test USER\", dept_name: \"Testdept\", primary_pin: \"99999\"} # @return [String] Formatted for EQCmd.exe command execution", "del_tokens": "#@note user_id, initial_balance, user_name, department_name, and primary_pin required #@param attributes [Hash] this attribute MUST include { user_id: \"userid\", init_bal: 0, username: \"Test USER\", dept_name: \"Testdept\", primary_pin: \"99999\"} #@return [String] Formatted for EQCmd.exe command execution", "commit_type": "update"}
{"commit_tokens": ["Add", "fork", "detection", "code", ";", "re", "-", "announce", "sensor", "if", "so"], "add_tokens": ":: Instana :: Collector . interval = 3 # Check if we forked (unicorn, puma) and # if so, re-announce the process sensor if :: Instana . pid_change? :: Instana . logger . debug \"Detected a fork (old: #{::Instana.pid} new: #{::Process.pid}). Re-announcing sensor.\" :: Instana . pid = Process . pid Instana . agent . announce_sensor end", "del_tokens": ":: Instana :: Collector . interval = 5", "commit_type": "add"}
{"commit_tokens": ["Removed", "reference", "to", "PBXGroup", "from", "Group"], "add_tokens": "# @return [Array<Group>] the groups with the same matching name. This", "del_tokens": "# @return [Array<PBXGroup>] the groups with the same matching name. This", "commit_type": "remove"}
{"commit_tokens": ["move", "parser", "package", "out", "of", "cli"], "add_tokens": "require 'cliqr/parser/argument_parser'", "del_tokens": "require 'cliqr/cli/parser/argument_parser'", "commit_type": "move"}
{"commit_tokens": ["Add", "new", "spec", "for", "deprecate_class!"], "add_tokens": "deprecate_class! :ThriftStruct => Struct", "del_tokens": "deprecate_class! :ThriftStruct => Struct", "commit_type": "add"}
{"commit_tokens": ["added", "venuegroups", "and", "campaign", "get", "method", "to", "client"], "add_tokens": "return_error_or_body ( response , response . body . response . venueGroup ) # Create a venue group. If the venueId parameter is specified, # then the endpoint will add the specified venues to the venue group. # If it is not possible to add all of the specified venues to the group, # then creation of the venue group will fail entirely. # @param [Hash] options # @option options String :name - Required. The name to give the group. # @option options String :venueId - Comma-delimited list of venue IDs to add to the group. If this parameter is not specified, then the venue group will initially be empty. return_error_or_body ( response , response . body . response . venueGroup ) # Updates a venue group. At least one of the name and venueId parameters must be specified. # @param [String] group_id - required The ID of the venue group to modify # @option options String :name - If specified, the new name to give to the group. return_error_or_body ( response , response . body . response . venueGroup ) end # List all venue groups owned by the user. def list_venuegroup response = connection . get do | req | req . url \"venuegroups/list\" end return_error_or_body ( response , response . body . response . venueGroups ) end # Delete a venue group. # param [String] group_id - The ID of the venuegroup to delete. def delete_venuegroup ( group_id ) response = connection . post do | req | req . url \"venuegroups/#{group_id}/delete\" end return_error_or_body ( response , response . body . response )", "del_tokens": "return_error_or_body ( response , response . body . response . venuegroup ) # Add a venuegroup # @option options String :name - Required # @option options String :venueId - If specified, a comma-delimited list of venue IDs that will become the new set of venue IDs for the group. return_error_or_body ( response , response . body . response . venuegroup ) # Update a venuegroup # @param [String] group_id - The Id of the venuegroup you're updating (required) # @option options String :name return_error_or_body ( response , response . body . response . venuegroup )", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "back", "in", ".", "Attempt", "to", "disembowl", "eval", "code", ".", "I", "think", "some", "bugs", "were", "fixed", "."], "add_tokens": "# From reference debugger @proc . dbgr . current_frame . run ( str )", "del_tokens": "# Sort of from reference debugger @proc . frame . instance_eval ( str )", "commit_type": "add"}
{"commit_tokens": ["Add", "timeout", "option", "to", "Request", "."], "add_tokens": "attr_reader :method , :url , :payload , :headers , :user , :password , :timeout @timeout = args [ :timeout ] net . write_timeout = net . read_timeout = @timeout if @timeout", "del_tokens": "attr_reader :method , :url , :payload , :headers , :user , :password", "commit_type": "add"}
{"commit_tokens": ["remove", "old", "options", "-", "s5", "/", "-", "fullerscreen"], "add_tokens": "puts \" slideshow microformats.textile\" # Process slides using Textile puts \" slideshow microformats.text\" # Process slides using Markdown puts \" slideshow -g # Generate slide show templates using built-in S6 pack\" puts \" slideshow -t s5blank microformats # Use your own slide show templates (e.g. s5blank)\"", "del_tokens": "# shortcut: same as -t s5.txt cmd . on ( '--s5' , 'S5-Compatible Slide Show (same as -t s5.txt)' ) { opts . put ( 's5' , true ) ; opts . put ( 'manifest' , 's5.txt' ) } # shortcut: same as -t fullerscreen.txt cmd . on ( '--fullerscreen' , 'FullerScreen-Compatible Slide Show (same as -t fullerscreen.txt)' ) { opts . put ( 'fuller' , true ) ; opts . put ( 'manifest' , 'fullerscreen.txt' ) } puts \" slideshow microformats.textile\" puts \" slideshow --s5 microformats # Use S5-compatible slide show templates\" puts \" slideshow --fullerscreen microformats # Use FullerScreen-compatible slide show templates\" puts \" slideshow -g # Generate slide show templates\" puts \" slideshow -g --s5 # Generate S5 compatible slide show templates\" puts \" slideshow -g --fullerscreen # Generate FullerScreen compatible slide show templates\" puts \" slideshow -t s5blank.txt microformats # Use your own slide show templates (e.g. s5blank.txt)\"", "commit_type": "remove"}
{"commit_tokens": ["use", "an", "options", "hash", "with", "fetch"], "add_tokens": "# Public: Creates a new instance of BlockScore::InvalidRequestError. # # Optional parameters: # # message - The String error message to report. # http_status - The Fixnum HTTP status code (usually 4xx or 5xx). # http_body - The body of the HTTP request. # json_body - The JSON body of the HTTP request. # param - The parameter which was invalid. # # While BlockScoreError can be instantiated, the more meaningful # error classes are its subclasses: # InvalidRequestError - Indicates a malformed request (HTTP 400 or 404) # APIError - Indicates an error on the server side (HTTP 5xx) # AuthenticationError - Indicates an authentication error (HTTP 401) def initialize ( options = { } ) @message = options . fetch :message , nil @http_status = options . fetch :http_status , nil @http_body = options . fetch :http_body , nil @json_body = options . fetch :json_body , nil", "del_tokens": "def initialize ( message = nil , http_status = nil , http_body = nil , json_body = nil ) @message = message @http_status = http_status @http_body = http_body @json_body = json_body", "commit_type": "use"}
{"commit_tokens": ["Fix", "NRSER", ".", "slice_keys", "to", "work", "in", "Rails"], "add_tokens": "keys . map! { | key | hash . send :convert_key , key }", "del_tokens": "keys . map! { | key | hash . convert_key ( key ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "api", "/", "users", "not", "supplying", "an", "error", "object", "to", "errors"], "add_tokens": "rescue NotFoundError => e raise UserNotFoundError . new ( user , e . error ) , rescue NotFoundError => e raise AvatarNotFoundError . new ( user , e . error ) , 'Avatar or user could not be found' rescue NotFoundError => e raise UserNotFoundError . new ( user , e . error ) ,", "del_tokens": "rescue NotFoundError raise UserNotFoundError . new ( user ) , rescue NotFoundError raise AvatarNotFoundError . new ( user ) , 'Avatar or user could not be found' rescue NotFoundError raise UserNotFoundError . new ( user ) ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "MultipleChoiceField", "."], "add_tokens": "new_value", "del_tokens": "# TODO: tests new_value", "commit_type": "add"}
{"commit_tokens": ["implemented", "validate_syntax", "method", "using", "RubyParser"], "add_tokens": "require \"ruby_parser\" def self . validate_syntax ( code ) RubyParser . new . parse ( code ) true", "del_tokens": "def self . validate_syntax raise \"999\"", "commit_type": "implement"}
{"commit_tokens": ["Create", "a", "new", "XML", "parser", "on", "stream", "restarts", "so", "Empathy", "and", "Psi", "can", "complete", "stream", "negotiation", "properly", "."], "add_tokens": "create_parser log . info { \"%s %21s -> %s\" % [ 'Stream connected:' . ljust ( PAD ) , @remote_addr , @local_addr ] } end # Initialize a new XML parser for this connection. This is called when the # stream is first connected as well as for stream restarts during # negotiation. Subclasses can override this method to provide a different # type of parser (e.g. HTTP). def create_parser # Reset the connection's XML parser when a new <stream:stream> header # is received. def reset create_parser end", "del_tokens": "log . info { \"%s %21s -> %s\" % [ 'Stream connected:' . ljust ( PAD ) , @remote_addr , @local_addr ] }", "commit_type": "create"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.3.0\"", "del_tokens": "VERSION = \"0.2.0\"", "commit_type": "change"}
{"commit_tokens": ["move", "VERSION", "to", "Sailthru", "module"], "add_tokens": "Version = VERSION = '1.0.2'", "del_tokens": "VERSION = '1.01'", "commit_type": "move"}
{"commit_tokens": ["move", "error", "definitions", "to", "errors", ".", "rb"], "add_tokens": "require 'double_entry/errors'", "del_tokens": "class UnknownAccount < RuntimeError ; end class TransferNotAllowed < RuntimeError ; end class TransferIsNegative < RuntimeError ; end class RequiredMetaMissing < RuntimeError ; end class DuplicateAccount < RuntimeError ; end class DuplicateTransfer < RuntimeError ; end class UserAccountNotLocked < RuntimeError ; end class AccountWouldBeSentNegative < RuntimeError ; end", "commit_type": "move"}
{"commit_tokens": ["Fix", "callable", "to", "correctly", "forward", "arguments", "."], "add_tokens": "lambda { | * args , & block | ! call ( * args , & block ) } target . public_send ( object . to_sym , * args , & block ) string = args . empty? ? \"-> { #{object} }\" : \"-> { #{object}(*#{args}) }\" value = eval string raise ArgumentError , \"Unknown callable #{object}\"", "del_tokens": "lambda { | * args , & block | ! self . call ( * args , & block ) } target . __send__ ( @object . to_sym ) value = eval \"lambda { #{@object} }\" raise ArgumentError , \"Unknown callable #{@object}\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "integration", "spec", "for", "Comment", "POST"], "add_tokens": "let ( :attributes_for_post ) { { \"body\" => \"new comment\" } } let ( :expected_attributes_from_post ) { { \"id\" => \"10001\" , \"body\" => \"new comment\" } } it_should_behave_like \"a resource with a POST endpoint\"", "del_tokens": "#let(:attributes_for_post) { # {\"name\" => \"Test component\", \"project\" => \"SAMPLEPROJECT\" } #} #let(:expected_attributes_from_post) { # { \"id\" => \"10001\", \"name\" => \"Test component\" } #} # it_should_behave_like \"a resource with a POST endpoint\"", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "CSS3", "and", "vendor", "-", "specific", "styles"], "add_tokens": "SpecHelpers . styling_of_node ( node )", "del_tokens": "parse_styles ( element_style ( document ) ) end def element_style ( document ) node && node [ 'style' ] end def parse_styles ( styles ) return [ ] if styles . blank? styles . split ( ';' ) . inject ( [ ] ) do | array , item | array << item . split ( ':' , 2 ) . map ( & :strip ) end", "commit_type": "add"}
{"commit_tokens": ["Added", "DVD", "to", "list", "all", "DVDs", ".", "Similar", "enough", "to", "hard", "drive", "that", "I", "abstracted", "out", "a", "parent", "class", "Image", "."], "add_tokens": "class HardDrive < Image parse_raw ( raw )", "del_tokens": "class HardDrive < AbstractModel attribute :uuid , :readonly => true attribute :location , :readonly => true attribute :accessible , :readonly => true raw . split ( / \\n \\n / ) . collect { | v | create_from_block ( v ) } . compact # Parses a hard drive from the VBoxManage list format # given. def create_from_block ( block ) return nil unless block =~ / ^UUID: /i hd = { } # Parses each line which should be in the format: # KEY: VALUE block . lines . each do | line | next unless line =~ / ^(.+?): \\s +(.+?)$ / hd [ $1 . downcase . to_sym ] = $2 . to_s end # Make sure we got all the required keys return nil unless ( attributes . keys - hd . keys ) . empty? # Create the object new ( hd ) end end def initialize ( info ) super ( ) populate_attributes ( info )", "commit_type": "add"}
{"commit_tokens": ["add", "pending", "to", "one", "pending", "spec"], "add_tokens": "pending ( \"currently there is no way to read PROPERTY_OPTIONS and aliases from DataMapper::Property\" ) do DataMapper :: Type :: PROPERTY_OPTIONS . should == DataMapper :: Property :: PROPERTY_OPTIONS end", "del_tokens": "DataMapper :: Type :: PROPERTY_OPTIONS . should == DataMapper :: Property :: PROPERTY_OPTIONS", "commit_type": "add"}
{"commit_tokens": ["Adding", "arguments", "to", "the", "expanding", "of", "statements", "in", "the", "REPL", "."], "add_tokens": "statements = Yap :: Line :: Parser . parse ( \"#{str} #{statement.args.join(' ')}\" )", "del_tokens": "statements = Yap :: Line :: Parser . parse ( str )", "commit_type": "add"}
{"commit_tokens": ["makes", "mounting", "of", "doc", "more", "secure"], "add_tokens": "if Api :: Base . recognize_path ( env [ 'REQUEST_PATH' ] ) elsif env [ 'REQUEST_PATH' ] == '/doc' else [ 403 , { 'Content-Type' : 'text/plain' } , [ '403 Forbidden' ] ]", "del_tokens": "if env [ 'REQUEST_PATH' ] . start_with? ( \"/#{Api::Base.prefix}\" ) else", "commit_type": "make"}
{"commit_tokens": ["fix", "a", "bug", "in", "the", "destroy", "callback"], "add_tokens": "after_destroy :remove_cache! if respond_to? ( :after_destroy )", "del_tokens": "after_destroy :expire_cache! if respond_to? ( :after_destroy )", "commit_type": "fix"}
{"commit_tokens": ["removed", "two", "-", "legged", "auth", "for", "all", "methods", "added", "tests", "...", "seems", "stable", "now"], "add_tokens": "SITE = 'http://api.rdio.com' def access_token ( requires_auth = false ) requires_auth ? access_token_auth : access_token_no_auth end private def access_token_no_auth consumer = OAuth :: Consumer . new @key , @secret , { :site => SITE } consumer . http . read_timeout = 600 OAuth :: AccessToken . new consumer end def access_token_auth OAuth :: Consumer . new ( @key , @secret , { :site => SITE , request_token . get_access_token ( { :oauth_verifier => oauth_verifier } )", "del_tokens": "def access_token consumer_key = @key consumer_secret = @secret OAuth :: Consumer . new ( consumer_key , consumer_secret , { :site => 'http://api.rdio.com' , request_token . get_access_token ( { :oauth_verifier => oauth_verifier } )", "commit_type": "remove"}
{"commit_tokens": ["Changed", "the", "Process", ".", "spawn", "to", "specify", "what", "to", "do", "with", "each", "stream", "(", "IN", "OUT", "and", "ERR", ")"], "add_tokens": "pid = Process . spawn @env_secure , \"#{@path}\" , pgroup : true , in : '/dev/null' , out : \"#{@log_path}/stdout.log\" , err : \"#{@log_path}/stderr.log\"", "del_tokens": "pid = Process . spawn @env_secure , \"#{@path} > #{@log_path}/stdout.log 2> #{@log_path}/stderr.log\" , pgroup : true", "commit_type": "change"}
{"commit_tokens": ["Update", "to", "use", "IO", "::", "WaitWritable"], "add_tokens": "rescue IO :: WaitWritable", "del_tokens": "rescue IO :: WaitWriteable", "commit_type": "update"}
{"commit_tokens": ["Fixed", "ScanConfig", "Construct", "in", "SiteConfig", "parse", "-", "Per", "Jon", "Hart"], "add_tokens": "c . attributes [ 'templateID' ] , c . attributes [ 'configVersion' ] )", "del_tokens": "c . attributes [ 'configVersion' ] , c . attributes [ 'templateID' ] )", "commit_type": "fix"}
{"commit_tokens": ["Added", "http_proxy", "based", "on", "the", "ENV"], "add_tokens": "puts \"\\n  by @#{username}\" puts \"  stars\" remember_username ( STDIN . gets . chomp ) selection = STDIN . gets . chomp end", "del_tokens": "puts \"\\n  by @#{username}\" puts \"  stars.\" remember_username ( gets . chomp ) selection = gets . chomp end", "commit_type": "add"}
{"commit_tokens": ["Added", "city", "-", "state", "gem", "for", "fetching", "country", "state", "and", "city"], "add_tokens": "require 'country_state_select/cst_data' include CountryStateSelect :: CstData CountryStateSelect :: CstData . countries CountryStateSelect :: CstData . states ( \"IN\" ) CountryStateSelect :: CstData . states ( \"US\" ) CountryStateSelect :: CstData . states ( \"CA\" ) CountryStateSelect :: CstData . states ( \"GB\" ) self . countries . each do | country |", "del_tokens": "require 'country_state_select/constant' include CountryStateSelect :: Constant COUNTRIES INDIAN_STATES . merge ( INDIAN_TERRIOTORY ) USA_STATE_LIST CANADIAN_STATES UK_STATES end def self . all_states INDIAN_STATES . merge ( INDIAN_TERRIOTORY ) . merge ( USA_STATE_LIST ) . merge ( CANADIAN_STATES ) . merge ( UK_STATES ) COUNTRIES . each do | country |", "commit_type": "add"}
{"commit_tokens": ["Add", "default", "entry", "on", "payload", "for", "SNS", "Topic"], "add_tokens": "json = notification ( text , options ) . to_json default : json APNS : json", "del_tokens": "APNS : notification ( text , options ) . to_json", "commit_type": "add"}
{"commit_tokens": ["Fix", "improper", "deferral", "of", "network", "overhead", "to", "Query", "layer", "with", "large", "data", "sets"], "add_tokens": "fog_collection = @account_tracker . connection . send ( @type ) || Array . new @log . info \"Fetching #{fog_collection.count} #{@type} on #{@account_name}.\" new_collection = Array . new # Here's where most of the network overhead is actually incurred fog_collection . each do | resource | @log . debug \"Fetching resource: #{resource.class} #{resource.identity}\" new_collection << resource @log . debug \"Got resource: #{resource.inspect}\" end @collection = new_collection", "del_tokens": "@collection = @account_tracker . connection . send ( @type ) @log . info \"Discovered #{@collection.count} #{@type} on #{@account_name}.\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "omniauth", "hash", "to", "test"], "add_tokens": "# branch. if request . env [ \"omniauth.auth\" ] @user = User . from_omniauth_hash ( request . env [ \"omniauth.auth\" ] ) elsif accept_auth @user = @auth_user", "del_tokens": "# branch. TODO: verify this. if env [ \"omniauth.auth\" ] @user = User . from_omniauth ( env [ \"omniauth.auth\" ] ) elsif @auth_user @user = get_user ( )", "commit_type": "use"}
{"commit_tokens": ["Change", "some", "styling", "and", "rendering", "to", "match", "what", "mingle", "uses", "."], "add_tokens": "assert_select \"tr##{token1.access_token}\" do assert_select \"a[href='#{@controller.url_for(:action=>:revoke, :only_path => true, :token_id => token1.id, :controller => 'oauth2/provider/oauth_user_tokens')}']\" assert_select \"tr##{token2.access_token}\" do assert_select \"a[href='#{@controller.url_for(:action=>:revoke, :only_path => true, :token_id => token2.id, :controller => 'oauth2/provider/oauth_user_tokens')}']\"", "del_tokens": "assert_select 'tr' do assert_select \"td\" , token1 . access_token assert_select \"a[href='#{@controller.url_for(:action=>:revoke, :only_path => true, :token_id => token1.id, :controller => 'Oauth2::Provider::OauthUserTokens')}']\" assert_select 'tr' do assert_select \"td\" , token2 . access_token assert_select \"a[href='#{@controller.url_for(:action=>:revoke, :only_path => true, :token_id => token2.id, :controller => 'Oauth2::Provider::OauthUserTokens')}']\"", "commit_type": "change"}
{"commit_tokens": ["fixed", "language", "case", "rule", "descriptions"], "add_tokens": "[ [ \"replace with\" , \"replace\" ] , [ \"prepand\" , \"prepand\" ] , [ \"append\" , \"append\" ] ]", "del_tokens": "[ [ \"then replace with\" , \"replace\" ] , [ \"then prepand\" , \"prepand\" ] , [ \"then append\" , \"append\" ] ]", "commit_type": "fix"}
{"commit_tokens": ["Move", "block", "documents", "to", "spec", "directory", "."], "add_tokens": "Dir [ File . dirname ( __FILE__ ) + \"/block_docs/**/*.md\" ] . each do | md | pending if md =~ Regexp . new ( \"^\" + Regexp . quote ( File . dirname ( __FILE__ ) + \"/block_docs/red_tests\" ) )", "del_tokens": "Dir [ File . dirname ( __FILE__ ) + \"/unittest/**/*.md\" ] . each do | md | pending if md =~ Regexp . new ( \"^\" + Regexp . quote ( File . dirname ( __FILE__ ) + \"/unittest/red_tests\" ) )", "commit_type": "move"}
{"commit_tokens": ["Make", "header", "rules", "work", "in", "files", "without", "headers"], "add_tokens": "[ first_header [ :location ] ] if first_header and first_header [ :level ] != 1 if headers . empty? nil else doc_style = doc . header_style ( headers . first ) headers . map { | h | doc . element_linenumber ( h ) if doc . header_style ( h ) != doc_style } . compact end", "del_tokens": "[ first_header [ :location ] ] unless first_header [ :level ] == 1 doc_style = doc . header_style ( headers . first ) headers . map { | h | doc . element_linenumber ( h ) if doc . header_style ( h ) != doc_style } . compact", "commit_type": "make"}
{"commit_tokens": ["Add", "slug", "&", "path", "to", "post", "&", "page", "searching", "(", "respectively", ")"], "add_tokens": "scope :search , -> ( query ) { where ( 'lower(title) LIKE ? OR lower(path) LIKE ?' , \"%#{query.downcase}%\" , \"%#{query.downcase}%\" ) }", "del_tokens": "scope :search , -> ( search ) { where ( 'lower(title) LIKE ?' , \"%#{search.downcase}%\" ) }", "commit_type": "add"}
{"commit_tokens": ["adding", "primary", "key", "after", "table", "creation", "is", "postgresql", "specific"], "add_tokens": "execute ( \"ALTER TABLE seeded_model_no_sequences ADD PRIMARY KEY (id)\" ) if ENV [ 'DB' ] == 'postgresql'", "del_tokens": "execute ( \"ALTER TABLE seeded_model_no_sequences ADD PRIMARY KEY (id)\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "specs", "for", "try", "calling", "chdir"], "add_tokens": "Executable . expects ( :execute_command ) . with ( 'bash' , [ '-ec' , 'pod install' ] , true ) Executable . expects ( :execute_command ) . with ( 'bash' , [ '-ec' , 'git submodule init' ] , true )", "del_tokens": "Executable . expects ( :execute_command ) . with ( 'bash' , [ '-e' , 'pod install' ] , true ) Executable . expects ( :execute_command ) . with ( 'bash' , [ '-e' , 'git submodule init' ] , true )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "multiple", "-", "of", "validator", "for", "rubinius"], "add_tokens": "@multiple_of = BigDecimal . new ( multiple_of . to_s )", "del_tokens": "@multiple_of = multiple_of", "commit_type": "fix"}
{"commit_tokens": ["added", "csv", "export", "for", "a", "patient", "object", "method", "takes", "second", "argument", "of", "true", "/", "false", "on", "whether", "to", "add", "headers", "-", "this", "is", "in", "case", "a", "collection", "is", "iterated", "over"], "add_tokens": "csv = header ? [ generate_header , extract_patient_data ( patient ) ] : extract_patient_data ( patient ) def generate_header [ \"patient_id\" , \"first name\" , \"last name\" , \"gender\" , \"race\" , \"ethnicity\" , \"birthdate\" ] end def extract_patient_data ( patient ) [ patient . patient_id , patient . first , patient . last , patient . gender , patient . race , patient . ethnicity , patient . birthdate ] end", "del_tokens": "csv_string = header ? [ [ \"row\" , \"of\" , \"CSV\" , \"data\" ] , [ \"another\" , \"row\" ] ] : [ \"another\" , \"row\" ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "nidyx", "/", "pointer"], "add_tokens": "require \"pry\" REF_KEY = \"$ref\" if value [ REF_KEY ] ptr = Nidyx :: Pointer . new ( value [ REF_KEY ] ) binding . pry", "del_tokens": "if value [ \"$ref\" ] ptr = Nidyx :: Pointer . new ( value [ \"$ref\" ] ) def object_at_path ( path , schema ) obj = schema path . each { | p | obj = obj [ p ] } obj end", "commit_type": "fix"}
{"commit_tokens": ["Add", "scenario", "for", "user", "removal", "."], "add_tokens": "Given 'a Chef cookbook with a recipe that creates a user resource' do recipe_creates_user Given 'a Chef cookbook with a recipe that removes a user resource' do recipe_removes_user Given / ^the recipe has a spec example that expects the user to be ([a-z]+)d$ / do | action | spec_expects_user_action ( action . to_sym ) Then 'the user will not have been created' do end", "del_tokens": "Given 'a Chef cookbook with a recipe that creates an user resource' do recipe_create_user Given 'the recipe has a spec example that expects the user to be declared' do spec_expects_user_action ( :create ) Then / ^the user will not have been created$ / do", "commit_type": "add"}
{"commit_tokens": ["Allow", "Host#os", "to", "accept", "a", "block", "."], "add_tokens": "# @yield [os] # If a block is given, it will be passed the OS guessing information. # # @yieldparam [OS] os # The OS guessing information. # def os ( & block ) return OS . new ( os , & block ) if os", "del_tokens": "def os return OS . new ( os ) if os", "commit_type": "allow"}
{"commit_tokens": ["added", "new", "base", "class", "for", "ActiveResource", "client", "classes", "as", "proposed", "by", "grosser"], "add_tokens": "require 'sk_sdk/base' # TODO deprecated obj_scope . const_set ( class_name , Class . new ( SK :: SDK :: Base ) )", "del_tokens": "require 'active_resource' require 'active_resource/version' # patches are for specific AR version if ActiveResource :: VERSION :: MAJOR == 3 require 'sk_sdk/ar_cli/patches/ar3/base' require 'sk_sdk/ar_cli/patches/ar3/validations' elsif ActiveResource :: VERSION :: MAJOR < 3 require 'sk_sdk/ar_cli/patches/ar2/validations' require 'sk_sdk/ar_cli/patches/ar2/base' end klass = obj_scope . const_set ( class_name , Class . new ( ActiveResource :: Base ) ) klass . class_eval do self . extend ( ClassMethods ) self . send ( :include , InstanceMethods ) # include is private end klass . format = :json # bug in AR must be set here module ClassMethods # Define the connection to be used when talking to a salesking server def set_connection ( opts ) self . site = opts [ :site ] self . user = opts [ :user ] self . password = opts [ :password ] self . format = opts [ :format ] . to_sym end end module InstanceMethods # hook before init in activeresource base because json comes in nested: # {client={data} def initialize ( attributes = { } ) attr = attributes [ self . class . element_name ] || attributes super ( attr ) end def save ; save_with_validation ; end end", "commit_type": "add"}
{"commit_tokens": ["make", "method_id", "and", "event_id", "public", "methods"], "add_tokens": "private def logger @logger ||= Logger . new 'eth.abi.contract_translator' end", "del_tokens": "private def logger @logger ||= Logger . new 'eth.abi.contract_translator' end", "commit_type": "make"}
{"commit_tokens": ["added", "first", "/", "all", "method", "to", "objects", "so", "you", "can", "now", "do", "basic", "searches", "without", "calling", "the", "finder", "directly"], "add_tokens": "require File . dirname ( __FILE__ ) + '/persistence/find' base . send :extend , ClassMethods , Find", "del_tokens": "base . send :extend , ClassMethods", "commit_type": "add"}
{"commit_tokens": ["Add", "firstname", "and", "lastname", "to", "contact"], "add_tokens": "attr_accessor :contact_id , :contact_number , :status , :name , :firstname , :lastname , :email , :addresses , :phones , :updated_at b . FirstName self . firstname b . LastName self . lastname when \"FirstName\" then contact . firstname = element . text when \"LastName\" then contact . lastname = element . text [ :contact_number , :status , :name , :firstname , :lastname , :email , :addresses , :phones ] . each do | field |", "del_tokens": "attr_accessor :contact_id , :contact_number , :status , :name , :email , :addresses , :phones , :updated_at [ :contact_number , :status , :name , :email , :addresses , :phones ] . each do | field |", "commit_type": "add"}
{"commit_tokens": ["fixed", "add_options", "and", "added", "a", "test", "for", "add_options"], "add_tokens": "return if options . empty? opt_args = [ ] opt_args << 'flatten' opt_args . concat [ 'encrypt_128bit' , 'owner_pw' , pwd , options [ :encrypt_options ] ] opt_args", "del_tokens": "options = [ ] options << [ 'flatten' ] options . concat [ 'encrypt_128bit' , 'owner_pw' , pwd , options [ :encrypt_options ] ] return options unless optons . empty?", "commit_type": "fix"}
{"commit_tokens": ["Add", "specific", "types", "of", "exceptions", "."], "add_tokens": "# TODO # Will need to detect if all attribute names fit inside the terminal # width, if not then rotate the table to display on each row. Try to # create view like hirb. # Finally all this needs to be moved to terminal class. # output can take first parameter of type, whether :show, :table, :status # status - would be a format to show only response from the request # table - used for listing more than one returned element # show - shows details for a single resource def self . output ( type = :show , & block ) response = block . call case response when Array response . each do | item | GithubCLI :: Terminal . render_output item , :horizontal => true puts end else GithubCLI :: Terminal . render_output response , :vertical => true end end def initialize ( params ) puts Github :: Repos . new . all params", "del_tokens": "def initialize github_api", "commit_type": "add"}
{"commit_tokens": ["add", "an", "ETag", "header", "to", "all", "cloud", "files", "uploads"], "add_tokens": "headers [ 'Etag' ] = md5_io ( io ) def md5_io ( io ) io . seek ( 0 ) # read in 128K chunks io . each ( 1024 * 128 ) do | chunk | digest << chunk io . seek ( 0 )", "del_tokens": "headers [ 'Etag' ] = md5 ( io . path ) def md5 ( path ) File . open ( path , 'rb' ) do | f | # read in 128K chunks f . each ( 1024 * 128 ) do | chunk | digest << chunk end", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "in", "the", "tests"], "add_tokens": "before do class FunnyRecord < PageRecord :: Base host_class Team end end", "del_tokens": "before do class FunnyRecord < PageRecord :: Base host_class Team end end", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "more", "general", "ValidationError", "."], "add_tokens": "raise ValidationError , e . message", "del_tokens": "raise e", "commit_type": "add"}
{"commit_tokens": ["add", "correct", "error", "message", "if", "portal", "not", "warmup", "during", "several", "requests"], "add_tokens": "rescue TimeoutError => timeout_exception raise \"Can't #{type} to #{url} because of TimeoutError: #{timeout_exception}\"", "del_tokens": "rescue TimeoutError raise 'Can\\'t ' + type . to_s + ' ' + url . to_s", "commit_type": "add"}
{"commit_tokens": ["Add", ":", "is", "guard", "and", "use", "it", "in", "recursion"], "add_tokens": "IF_ARRAY = -> fn { Transproc ( :is , Array , fn ) } IF_HASH = -> fn { Transproc ( :is , Hash , fn ) } guarded = IF_ARRAY [ -> v { Transproc ( :array_recursion , fn ) [ v ] } ] guarded = IF_HASH [ -> v { Transproc ( :hash_recursion , fn ) [ v ] } ]", "del_tokens": "guarded = Transproc ( :guard , -> v { v . is_a? ( :: Array ) } , -> v { Transproc ( :array_recursion , fn ) [ v ] } ) guarded = Transproc ( :guard , -> v { v . is_a? ( :: Hash ) } , -> v { Transproc ( :hash_recursion , fn ) [ v ] } )", "commit_type": "add"}
{"commit_tokens": ["Added", "#sort", "and", "#sort_by", "on", "ZipCodes", "Communities", "and", "Cantons", "removed", "#replace", "on", "the", "same", "where", "implemented", "(", "immutable", "collections", "don", "t", "need", "#replace", ")", "."], "add_tokens": "# @return [SwissMatch::Cantons] # A SwissMatch::Cantons collection with all SwissMatch::Canton objects for which the block # returned true (or a trueish value) def select ( * args , & block ) Cantons . new ( @cantons . select ( * args , & block ) ) end # @return [SwissMatch::Cantons] # A SwissMatch::Cantons collection with all SwissMatch::Canton objects for which the block # returned false (or a falseish value) def reject ( * args , & block ) Cantons . new ( @cantons . reject ( * args , & block ) ) end # @see Enumerable#sort # # @return [SwissMatch::Cantons] # A SwissMatch::Cantons collection sorted by the block def sort ( * args , & block ) Cantons . new ( @cantons . sort ( * args , & block ) ) end # @see Enumerable#sort_by # # @return [SwissMatch::Cantons] # A SwissMatch::Cantons collection sorted by the block def sort_by ( * args , & block ) Cantons . new ( @cantons . sort_by ( * args , & block ) ) end", "del_tokens": "# @return [SwissMatch::Cantons] # A SwissMatch::Cantons collection with all SwissMatch::Canton objects for which the block # returned true (or a trueish value) def select ( * args , & block ) Cantons . new ( @cantons . select ( * args , & block ) ) end # @return [SwissMatch::Cantons] # A SwissMatch::Cantons collection with all SwissMatch::Canton objects for which the block # returned false (or a falseish value) def reject ( * args , & block ) Cantons . new ( @cantons . reject ( * args , & block ) ) end", "commit_type": "add"}
{"commit_tokens": ["Use", "short", "method", "aliases", "in", "documentation", "for", "Client#open"], "add_tokens": "# call {#check}, {#ham}, or {#spam}, which call {#open} for you if # necessary.", "del_tokens": "# call {#comment_check}, {#submit_ham}, or {#submit_spam}, which call # {#open} for you if necessary.", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "name", "to", "generated", "namespace"], "add_tokens": "@namespace = TestProvisioner . claim_namespace ( test_name : self . name ) def self . claim_namespace ( test_name : ) test_name = test_name . gsub ( / [^-a-z0-9] / , '-' ) . slice ( 0 , 36 ) # namespace name length must be <= 63 chars ns = \"k8sdeploy-#{test_name}-#{SecureRandom.hex(8)}\" raise", "del_tokens": "@namespace = TestProvisioner . claim_namespace def self . claim_namespace ns = SecureRandom . hex ( 8 )", "commit_type": "add"}
{"commit_tokens": ["adds", "base", "storing", "of", "configuration"], "add_tokens": "require 'starter/config' require 'starter/builder/orms'", "del_tokens": "require 'starter/builder/orms'", "commit_type": "add"}
{"commit_tokens": ["Fix", "radiant", ":", "update", ":", "configs", "task", "to", "properly", "evaluate", "environment", ".", "rb", "."], "add_tokens": ":secret => < % require 'digest/sha1' %>'<%= Digest::SHA1.hexdigest(\"--#{app_name}--#{Time.now.to_s}--#{rand(10000000)}--\") %> '", "del_tokens": ":secret => < % require 'digest/sha1' - %>'<%= Digest::SHA1.hexdigest(\"--#{app_name}--#{Time.now.to_s}--#{rand(10000000)}--\") %> '", "commit_type": "fix"}
{"commit_tokens": ["Allows", "an", "array", "of", "path", "keys", "for", "the", ":", "within", "option", "for", "response", "filters"], "add_tokens": "if namespace . is_a? ( Array ) fetch_path ( hash , * namespace ) elsif namespace . nil? hash [ key ] else hash [ namespace ] [ key ] end end def fetch_path ( hash , * parts ) parts . reduce ( hash ) do | memo , key | memo [ key ] if memo end", "del_tokens": "namespace ? hash [ namespace ] [ key ] : hash [ key ]", "commit_type": "allow"}
{"commit_tokens": ["Add", "utc_index", "option", "and", "corresponding", "testcase", "modify", "runtime", "dependencies"], "add_tokens": "require 'typhoeus' config_param :utc_index , :bool , :default => true if @utc_index target_index = \"#{@logstash_prefix}-#{Time.at(time).getutc.strftime(\"#{@logstash_dateformat}\")}\" else target_index = \"#{@logstash_prefix}-#{Time.at(time).strftime(\"#{@logstash_dateformat}\")}\" end", "del_tokens": "target_index = \"#{@logstash_prefix}-#{Time.at(time).strftime(\"#{@logstash_dateformat}\")}\"", "commit_type": "add"}
{"commit_tokens": ["move", "gen", "templates", "to", "attic"], "add_tokens": "###### # add command :g,:gen,:generate ??? why? why not? better just git clone repos # or use command copy? # # cmd.on( '-g', '--generate', 'Generate Slide Show Templates (using built-in S6 Pack)' ) { opts.generate = true } # # GenTemplates.new( opts, config ).run ### todo: remove opts module Slideshow", "del_tokens": "module Slideshow #### fix: # move to attic - no longer used/needed - old code ?? # just clone template repos or use zip or use ~/.slideshow folder", "commit_type": "move"}
{"commit_tokens": ["added", "block", "yields", "to", "db", ".", "view"], "add_tokens": "@streamer = Streamer . new ( self ) def view name , params = { } , & block if block_given? @streamer . view ( name , params , & block ) else CouchRest . get url end", "del_tokens": "def view name , params = { } CouchRest . get url", "commit_type": "add"}
{"commit_tokens": ["Allow", "tests", "to", "just", "be", "required", "for", "certification", "."], "add_tokens": "require 'usps'", "del_tokens": "require 'rubygems'", "commit_type": "allow"}
{"commit_tokens": ["Update", "ChangeLog", "and", "bump", "version", "."], "add_tokens": "VERSION = '1.2.11.7'", "del_tokens": "VERSION = '1.2.11.6'", "commit_type": "update"}
{"commit_tokens": ["Removed", "default", "rails", "field_with_error", "wrapper", ".", "Added", "block_error_class", "."], "add_tokens": "# Default class assigned to block with errors (<div class=\"block with_errors\">...</div>). mattr_accessor :block_error_class @@block_error_class = 'with_errors' options [ :container ] [ :class ] << :: Formula . block_error_class if options [ :error ] @@default_field_error_proc = nil FIELD_ERROR_PROC = proc do | html_tag , instance_tag | html_tag end with_formula_field_error_proc do form_for ( record_or_name_or_array , * ( args << options ) , & proc ) end with_formula_field_error_proc do fields_for ( record_or_name_or_array , * ( args << options ) , & block ) end private def with_formula_field_error_proc @@default_field_error_proc = :: ActionView :: Base . field_error_proc :: ActionView :: Base . field_error_proc = FIELD_ERROR_PROC result = yield :: ActionView :: Base . field_error_proc = @@default_field_error_proc result end", "del_tokens": "form_for ( record_or_name_or_array , * ( args << options ) , & proc ) fields_for ( record_or_name_or_array , * ( args << options ) , & block )", "commit_type": "remove"}
{"commit_tokens": ["use", "manifest", "instead", "of", "input", ".", "1", "more", "--", "extract", "issue", "to", "fix"], "add_tokens": "puts JSON . pretty_generate ( manifest ) puts manifest . to_yaml", "del_tokens": "puts JSON . pretty_generate ( input ) puts input . to_yaml", "commit_type": "use"}
{"commit_tokens": ["Added", "the", "support", "for", "annotations", "through", "comments", "or", "test", "names"], "add_tokens": "# Called for each comment line def comment_line ( comment ) @annotation = ProbeDockProbe :: Annotation . new ( comment ) end # Annotation detected in the comments if @annotation result_options [ :annotation ] = @annotation @annotation = nil end @test_run . add_result ( result_options )", "del_tokens": "@test_run . add_result result_options", "commit_type": "add"}
{"commit_tokens": ["Fixed", "another", "missing", "block", "parameter", "when", "calling", "compare_nodesets", "()"], "add_tokens": "result = self . compare_nodesets ( nodeset_1 , nodeset_2 , opts , & block )", "del_tokens": "result = self . compare_nodesets ( nodeset_1 , nodeset_2 , opts )", "commit_type": "fix"}
{"commit_tokens": ["improve", "support", "for", "BasicObject", "and", "other", "corner", "case", "scenarios"], "add_tokens": "found = allocated [ obj . __id__ ] retained [ obj . __id__ ] = found if found ObjectSpace . each_object do | obj | next unless ObjectSpace . allocation_generation ( obj ) == generation klass = obj . class rescue nil unless Class === klass # attempt to determine the true Class when .class returns something other than a Class klass = Kernel . instance_method ( :class ) . bind ( obj ) . call end next if @trace && ! trace . include? ( klass ) result [ obj . __id__ ] = MemoryProfiler :: Stat . new ( class_name , gem , file , location , memsize , string )", "del_tokens": "begin found = allocated [ obj . __id__ ] retained [ obj . __id__ ] = found if found rescue # __id__ is not defined on BasicObject, skip it # we can probably transplant the object_id at this point, # but it is quite rare end objs = [ ] ObjectSpace . each_object do | obj | next unless ObjectSpace . allocation_generation ( obj ) == generation begin if ! trace || trace . include? ( obj . class ) objs << obj end rescue # may not respond to class so skip end end objs . each do | obj | klass = obj . class rescue nil object_id = obj . __id__ result [ object_id ] = MemoryProfiler :: Stat . new ( class_name , gem , file , location , memsize , string ) # Although `objs` will go out of scope, clear the array so objects can definitely be GCd objs . clear", "commit_type": "improve"}
{"commit_tokens": ["use", "optional", "dependency", "injection", "for", "api", "keys", "handler", "for", "glass", "client"], "add_tokens": ":mirror_content_type , :timeline_item , :has_expired_token , :api_keys self . api_keys ||= :: Glass :: ApiKeys . new google_client . authorization . send ( \"#{meth}=\" , self . api_keys . send ( meth ) )", "del_tokens": ":mirror_content_type , :timeline_item , :has_expired_token api_keys = Glass :: ApiKeys . new google_client . authorization . send ( \"#{meth}=\" , api_keys . send ( meth ) )", "commit_type": "use"}
{"commit_tokens": ["Move", "Enrolled3DError", "to", "its", "own", "file"], "add_tokens": "require \"spree/adyen/enrolled_3d_error\"", "del_tokens": "module Spree module Adyen class Enrolled3DError < StandardError attr_reader :response , :issuer_url , :pa_request , :md def initialize ( response ) @response = response @issuer_url = response . issuer_url @pa_request = response . pa_request @md = response . md end def messsage response . to_s end end end end", "commit_type": "move"}
{"commit_tokens": ["allow", "for", "@templatePath", "to", "find", "templates"], "add_tokens": "if @templatePath templateFileName = @templatePath + templateFileName end fullTemplateFilePath = relative_path ( templateFileName ) File . open ( fullTemplateFilePath , \"r\" ) do | input |", "del_tokens": "File . open ( relative_path ( templateFileName ) , \"r\" ) do | input |", "commit_type": "allow"}
{"commit_tokens": ["moved", "event", "message", "types", "from", "constant", "to", "a", "method"], "add_tokens": "attr_reader :type , :time , :message # # @return [Array<Symbol>] the message types def self . types [ :i , :x , :* , :y ] end if Event . types . include? ( type ) raise ArgumentError , \"type attribute must be either one in #{Event.types}\" # Comparison - Returns an integer (-1, 0 or +1) if this event is less than, # equal to, or greater than <i>other</i>. The comparison is based on the # time of each event (descending). # # @param other [Event] the event to compare to # @return [Integer]", "del_tokens": "TYPES = [ :i , :x , :* , :y ] attr_reader :type , :time , :message if TYPES . include? ( type ) raise ArgumentError , \"type attribute must be either one in #{TYPES}\"", "commit_type": "move"}
{"commit_tokens": ["Add", "up", "and", "down", "commands", ".", "Renstatate", "more", "of", "trepan", "s", "CmdProcessor"], "add_tokens": "attr_reader :locations , :history_io , :debugee_thread", "del_tokens": "attr_reader :locations , :history_io", "commit_type": "add"}
{"commit_tokens": ["allow", "for", "False", "class", "as", "filter", "value"], "add_tokens": "unless value . nil?", "del_tokens": "if value", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "Travis", "build", "failure", "and", "badging", "up", "the", "readme"], "add_tokens": "VERSION = '0.0.7'", "del_tokens": "VERSION = '0.0.6'", "commit_type": "fix"}
{"commit_tokens": ["Move", "require", "outside", "of", "class", "method"], "add_tokens": "require \"method_source\"", "del_tokens": "require \"method_source\"", "commit_type": "move"}
{"commit_tokens": ["Allow", "an", "array", "to", "be", "passed", "to", "roles_mask_for"], "add_tokens": "( Array ( roles ) . flatten . map ( & :to_sym ) & EffectiveRoles . roles ) . map { | r | 2 ** EffectiveRoles . roles . index ( r ) } . sum", "del_tokens": "( Array ( roles ) . map ( & :to_sym ) & EffectiveRoles . roles ) . map { | r | 2 ** EffectiveRoles . roles . index ( r ) } . sum", "commit_type": "allow"}
{"commit_tokens": ["added", "api", "spec", "for", "using", "categories", "if", "no", "stores", "are", "present"], "add_tokens": "raise Newegg :: ApiError if store_index . nil?", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "more", "Lint", "/", "EndAlignment", "offenses"], "add_tokens": "if mode . nil? || mode =~ / production /i yml_cfg . jira . each do | k , v | instance_variable_set ( \"@#{k}\" , v ) end else yml_cfg . send ( mode ) . each do | k , v | instance_variable_set ( \"@#{k}\" , v ) end", "del_tokens": "if mode . nil? || mode =~ / production /i yml_cfg . jira . each do | k , v | instance_variable_set ( \"@#{k}\" , v ) else yml_cfg . send ( mode ) . each do | k , v | instance_variable_set ( \"@#{k}\" , v ) end end", "commit_type": "fix"}
{"commit_tokens": ["fix", "mistake", "direction", "indicators", "reversed"], "add_tokens": ":current_sort_direction_indicator => ( current_sorting =~ / _desc \\z / ? opts [ :descending_indicator ] : opts [ :ascending_indicator ] ) ,", "del_tokens": ":current_sort_direction_indicator => ( current_sorting =~ / _desc \\z / ? opts [ :ascending_indicator ] : opts [ :descending_indicator ] ) ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "attribute", "binding", "updating", "problem"], "add_tokens": "if @value . reactive? || @value . is_a? ( ReactiveTemplate )", "del_tokens": "if @value . reactive?", "commit_type": "fix"}
{"commit_tokens": ["Add", "custom", "RSpec", "formatter", "."], "add_tokens": "# Picks a random pending message. # # @return [String] a pending message # def pending pick [ 'Almost there!' , 'Final spurt!' , 'One more please!' ] end 'Ups, you did it again.' ,", "del_tokens": "'Ups, I did it again.' ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "each", "on", "option", "to", "in", "turn", "fix", "flat_map"], "add_tokens": "block . call ( @content ) # def entries # [] # end #", "del_tokens": "@content . each ( & block )", "commit_type": "fix"}
{"commit_tokens": ["Using", "JasperRails", ".", "config", "[", ":", "report_params", "]"], "add_tokens": "self . config = { :report_params => { \"REPORT_LOCALE\" => Locale . new ( 'en' , 'US' ) , \"XML_LOCALE\" => Locale . new ( 'en' , 'US' ) , \"XML_DATE_PATTERN\" => 'yyy-MM-dd' } } JasperRails . config [ :report_params ] . each do | k , v | jasper_params . put ( k , v ) end", "del_tokens": "self . config = { :language => 'en' , :country => 'US' } jasper_params . put ( \"REPORT_LOCALE\" , Locale . new ( JasperRails . config [ :language ] , JasperRails . config [ :country ] ) )", "commit_type": "use"}
{"commit_tokens": ["add", "app", "crypto", "and", "utils"], "add_tokens": "app = App . new config evt_exit = Concurrent :: Event . new do_exit = proc do puts \"exit.\" exit 0 end Signal . trap ( \"INT\" , & do_exit ) Signal . trap ( \"TERM\" , & do_exit ) Signal . trap ( \"QUIT\" , & do_exit ) app . async . start Thread . new { evt_exit . wait } . join", "del_tokens": "Celluloid . boot app = BaseApp . new config app . start app . join #app.stop", "commit_type": "add"}
{"commit_tokens": ["change", "ies_demo", ".", "rb", "to", "default", "to", "localhost"], "add_tokens": "EventMachine :: connect ( \"localhost\" , 8021 , IesDemo )", "del_tokens": "EventMachine :: connect ( \"esther\" , 8021 , IesDemo )", "commit_type": "change"}
{"commit_tokens": ["Fix", "issue", "in", "generator", "where", "RSpec", ".", "configuration", "is", "nil"], "add_tokens": "if defined? ( RSpec ) && Dir . exist? ( Rails . root . join ( 'spec' ) ) Rails . root . join ( 'spec' , 'callbacks' , \"#{name.underscore}_callback_spec.rb\" )", "del_tokens": "if defined? ( RSpec ) \"#{RSpec.configuration.default_path}/callbacks/#{name.underscore}_callback_spec.rb\"", "commit_type": "fix"}
{"commit_tokens": ["add", "options", "param", "for", "array", "elements"], "add_tokens": "item . as_api_response ( api_template , options )", "del_tokens": "item . as_api_response ( api_template )", "commit_type": "add"}
{"commit_tokens": ["Add", "inner", "ring", "for", "rgeo", "polygon", "to", "georuby"], "add_tokens": "GeoRuby :: SimpleFeatures :: Polygon . from_linear_rings [ exterior_ring . to_georuby ] + interior_rings . map ( & :to_georuby ) , srid GeoRuby :: SimpleFeatures :: Polygon . from_linear_rings [ exterior_ring . to_georuby ] + interior_rings . map ( & :to_georuby ) , srid", "del_tokens": "GeoRuby :: SimpleFeatures :: Polygon . from_linear_rings [ exterior_ring . to_georuby ] , srid GeoRuby :: SimpleFeatures :: Polygon . from_linear_rings [ exterior_ring . to_georuby ] , srid", "commit_type": "add"}
{"commit_tokens": ["Add", "label", "component", "which", "is", "revealed", "over", "time"], "add_tokens": "# @option args [String] :text text of the label", "del_tokens": "# @option args [String] :text text of button", "commit_type": "add"}
{"commit_tokens": ["Moved", "the", "arguments", "of", "assert_equal", "around", "."], "add_tokens": "assert_equal 1 , Dir . glob ( TEST_GLOB ) . length assert_equal 2 , Dir . glob ( TEST_GLOB ) . length assert_equal 2 , Dir . glob ( 'test_' + TEST_GLOB ) . length", "del_tokens": "assert_equal Dir . glob ( TEST_GLOB ) . length , 1 assert_equal Dir . glob ( TEST_GLOB ) . length , 2 assert_equal Dir . glob ( 'test_' + TEST_GLOB ) . length , 2", "commit_type": "move"}
{"commit_tokens": ["fixed", "Rakefile", "to", "use", "new", "rspec", "tasks"], "add_tokens": "require 'rspec' RSpec . configure do | config | config . color_enabled = true", "del_tokens": "require 'spec' require 'spec/autorun' Spec :: Runner . configure do | config |", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "ensure", "that", "keys", "are", "always", "written", "as", "strings"], "add_tokens": ":: File . write ( file , YAML . dump ( self . class . normalize_hash ( data , :to_s ) ) )", "del_tokens": ":: File . write ( file , YAML . dump ( data ) )", "commit_type": "change"}
{"commit_tokens": ["Add", "connect", "/", "connected", "semantics"], "add_tokens": "require \"securerandom\" if message . command == \"CONNECT\" @app . on_connect ( session , message ) headers = { \"version\" => \"1.2\" , \"server\" => \"Stompede/#{Stompede::VERSION}\" , \"session\" => SecureRandom . uuid } socket . write ( Stomp :: Message . new ( \"CONNECTED\" , headers , \"\" ) . to_str ) end rescue = > e raise unless e . is_a? ( EOFError )", "del_tokens": "rescue", "commit_type": "add"}
{"commit_tokens": ["Add", "rename", "and", "change", "topic", "room", "api"], "add_tokens": "connection . post ( \"/room/#{@id}.json\" , :body => { :room => { :name => name } } ) connection . post ( \"/room/#{@id}.json\" , :body => { :room => { :topic => name } } )", "del_tokens": "raise NotImplementedError raise NotImplementedError", "commit_type": "add"}
{"commit_tokens": ["adding", "text", "support", "in", "text_corpus"], "add_tokens": "@filename = filename begin docs = YAML . load_file ( @filename ) rescue puts \"File not available, adding this as text\" end if ( ! docs . nil? ) docs . each do | doc | add_document ( TextDocument . new ( self , doc ) ) end else add_document ( TextDocument . new ( self , @filename ) )", "del_tokens": "@filename = filename docs = YAML . load_file ( @filename ) docs . each do | doc | add_document ( TextDocument . new ( self , doc ) )", "commit_type": "add"}
{"commit_tokens": ["Allow", "column", "patterns", "to", "have", "comma", "inside", "and", "add", "precision", "for", "number", "values", "with", "default", "2", "in", "Table"], "add_tokens": "# Regex to split parameters COL_SPLITTER = / ,(?=[ \\w +]*:) / # pr: \"2\", # # infile:: csv file to operate on # outfile:: csv file with the result # df:: date format # nf:: number format of number values. \"DE\" e.g. is 1.000,00 where as # US is 1,000.00 # pr:: precision of number values. Default 2 # rows: rows to consider for operation. Rows that don't match the pattern # will be skipped for operation # header:: Header of the csv file # key:: Values located at value 0 and subsequent columns # cols:: Values added to columns base on a operation or assignment # sum:: sum row at specified position top or eof @cols = options [ :cols ] . split ( COL_SPLITTER ) @precision = options [ :pr ] || 2 if value = eval ( \"#{row[:cols][column]}#{formula}\" ) row [ :cols ] [ column ] = value . round ( @precision ) add_to_sum_row ( row [ :cols ] [ column ] - previous_value , column ) end", "del_tokens": "@cols = options [ :cols ] . split ( ',' ) row [ :cols ] [ column ] = eval ( \"#{row[:cols][column]}#{formula}\" ) add_to_sum_row ( row [ :cols ] [ column ] - previous_value , column )", "commit_type": "allow"}
{"commit_tokens": ["Make", "sure", "a", "package", "name", "override", "is", "used", "everywhere", "equally", "."], "add_tokens": "poise_languages_system system_package_name do # If we have an override, just use that. return options [ 'package_name' ] if options [ 'package_name' ]", "del_tokens": "poise_languages_system options [ 'package_name' ] || system_package_name do", "commit_type": "make"}
{"commit_tokens": ["moved", "inline", "helper", "methods", "from", "dashboard", ".", "rb", "over", "to", "helpers", ".", "rb"], "add_tokens": "helpers Rack :: RedisAnalytics :: Helpers", "del_tokens": "helpers do include Rack :: RedisAnalytics :: Helpers def realistic ( n , r = 1000 ) return n n + r + rand ( r ) end def parse_float ( float ) float . nan? ? '0.0' : float end def with_benchmarking @t0 = Time . now yield @t1 = Time . now @t = @t1 - @t0 puts \"Time Taken: #{@t} seconds\" end end", "commit_type": "move"}
{"commit_tokens": ["Move", "login", "and", "downloads", "index", "URLs", "into", "AppleDeveloperCenter", "module"], "add_tokens": "adc_login_url = XcodeDownload :: AppleDeveloperCenter :: LOGIN_URL downloads_url = XcodeDownload :: AppleDeveloperCenter :: DOWNLOADS_URL", "del_tokens": "adc_login_url = 'https://daw.apple.com/cgi-bin/WebObjects/DSAuthWeb.woa/wa/login?appIdKey=d4f7d769c2abecc664d0dadfed6a67f943442b5e9c87524d4587a95773750cea&path=%2F%2Fdownloads%2Findex.action' downloads_url = 'https://developer.apple.com/downloads/index.action'", "commit_type": "move"}
{"commit_tokens": ["moved", "track", "digestor", "to", "nokogiri"], "add_tokens": "releases = @release_digestor . list_from_xml_nokogiri ( xml_response , :results )", "del_tokens": "releases = @release_digestor . list_from_xml ( xml_response , :results )", "commit_type": "move"}
{"commit_tokens": ["updated", "version", "[", "ci", "skip", "]"], "add_tokens": "GEM_VERSION = \"1.1.2\"", "del_tokens": "GEM_VERSION = \"1.1.1\"", "commit_type": "update"}
{"commit_tokens": ["Add", "test", "for", "nested", "transaction", "support", "in", "MySQL", "&", "PostgreSQL", "."], "add_tokens": "supported_by :postgres , :mysql do before do @user_model . destroy! end it 'should support nested transactions' do # can't assume dm-aggregates begin @user_model . all . length . should == 0 @user_model . transaction do # txn 1 @user_model . create ( :name => 'jpr5' ) @user_model . all . length . should == 1 begin @user_model . transaction do # savepoint 1 @user_model . create ( :name => 'dkubb' ) @user_model . all . length . should == 2 raise end rescue = > e @user_model . all . length . should == 1 end raise end rescue = > e @user_model . all . length . should == 0 end end end it 'should rollback when an error is raised in a transaction' do", "del_tokens": "it 'should rollback when an error is thrown in a transaction' do", "commit_type": "add"}
{"commit_tokens": ["Use", "credentials", "in", "Confirmation", "class"], "add_tokens": "# @param crds [Credentials] Api access credentials object def initialize ( crds , params ) @secret = crds . secret", "del_tokens": "def initialize ( secret , params ) @secret = secret", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "make", "ranges", "a", "little", "less", "dense"], "add_tokens": "numbers = Benchmark :: Trend . range ( 1 , 5_000 ) numbers = Benchmark :: Trend . range ( 1 , 20_000 ) numbers = Benchmark :: Trend . range ( 1 , 1_000 )", "del_tokens": "numbers = Benchmark :: Trend . range ( 1 , 5_000 , ratio : 2 ) numbers = Benchmark :: Trend . range ( 1 , 10_000 , ratio : 2 ) numbers = Benchmark :: Trend . range ( 1 , 1_000 , ratio : 2 )", "commit_type": "change"}
{"commit_tokens": ["Add", "specs", "to", "oauth", "client"], "add_tokens": "attr_writer :consumer", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Move", "CAR_CODES", "out", "to", "a", "Lookups", "class"], "add_tokens": "@lookups = Lookups . instance . lookups @lookups [ 'car_codes' ] . map { | code | \"memoryAddress:#{code}\" } . join ( ' OR ' ) \"memoryAddress:#{@lookups['car_codes'][@car]}\"", "del_tokens": "CAR_CODES = { A : '2E64930W' , B : '2E64932W' , C : '2E64934W' , D : '2E64936W' } CAR_CODES . map { | code | \"memoryAddress:#{code}\" } . join ( ' OR ' ) \"memoryAddress:#{CAR_CODES[@car]}\"", "commit_type": "move"}
{"commit_tokens": ["fix", "deprecation", "warnings", "about", "Config", "/", "RbConfig"], "add_tokens": "LIBDIR = RbConfig :: CONFIG [ 'libdir' ] INCLUDEDIR = RbConfig :: CONFIG [ 'includedir' ]", "del_tokens": "LIBDIR = Config :: CONFIG [ 'libdir' ] INCLUDEDIR = Config :: CONFIG [ 'includedir' ]", "commit_type": "fix"}
{"commit_tokens": ["changed", "dependencies", "added", "metric_fu", "for", "Rcov", "and", "reduced", "duplication", "."], "add_tokens": "class_churn = collect_items ( hash [ :churn ] [ :class_churn ] , 'klass' ) method_churn = collect_items ( hash [ :churn ] [ :method_churn ] , 'method' ) def collect_items ( collection , match ) collection . map { | item | ( item . delete ( match ) || { } ) . merge ( item ) } end", "del_tokens": "class_churn = hash [ :churn ] [ :class_churn ] . map { | e | ( e . delete ( 'klass' ) || { } ) . merge ( e ) } method_churn = hash [ :churn ] [ :method_churn ] . map { | e | ( e . delete ( 'method' ) || { } ) . merge ( e ) }", "commit_type": "change"}
{"commit_tokens": ["improve", "legibility", "of", "chars", "/", "codepoints", "methods"], "add_tokens": "extras = self . all_with_variants . map { | c | c . render ( { variant_encoding : true } ) } normals = EMOJI_CHARS . map ( & :unified ) extras = self . all_with_variants . map { | c | c . variant } return normals + extras normals", "del_tokens": "extras = self . all_with_variants . map { | c | c . render ( { variant_encoding : true } ) } return EMOJI_CHARS . map ( & :unified ) + self . all_with_variants . map { | c | c . variant } EMOJI_CHARS . map ( & :unified )", "commit_type": "improve"}
{"commit_tokens": ["use", "a", "hexdigest", "of", "post", "params", "to", "avoid", "filenames", "that", "are", "too", "long"], "add_tokens": "require 'openssl' url . scheme + '://' + url . host + url . request_uri + OpenSSL :: Digest :: MD5 . hexdigest ( env [ :body ] . to_s ) # XXX add for POST requests", "del_tokens": "url . scheme + '://' + url . host + url . request_uri + env [ :body ] . to_s # XXX add for POST requests", "commit_type": "use"}
{"commit_tokens": ["Fix", "external", "link", "syntax", "with", "x", "in", "the", "body"], "add_tokens": "# FIXME: these surrounded_by arguments look dodgy extension ( 'external' , surrounded_by ( \"x[\" , \")x\" ) ) { | body | Kramdown :: Document . new ( \"[#{body.strip}){:rel='external'}\" ) . to_html", "del_tokens": "extension ( 'external' , surrounded_by ( \"x[\" , \"x\" ) ) { | body | Kramdown :: Document . new ( \"[#{body.strip}{:rel='external'}\" ) . to_html", "commit_type": "fix"}
{"commit_tokens": ["updated", "chapter", "spec", "and", "fixed", "bugs"], "add_tokens": "Mangdown :: Uri . new ( \"/#{@manga.gsub(' ', '-')}/#{@chapter}/#{num}\" Mangdown :: Uri . new ( \"/manga/#{@manga.gsub(' ', '_')}/c#{@chapter}/\" +", "del_tokens": "def log ( object ) puts object object end ( \"/#{@manga.sub(' ', '-')}/#{@chapter}/#{num}\" ( \"/manga/#{@manga.sub(' ', '_')}/c#{@chapter}/\" +", "commit_type": "update"}
{"commit_tokens": ["fix", "specs", "on", "passing", "from", "inner", "controller", "filter"], "add_tokens": "effects = [ ] effects . push 1 response . body << 'x' app . get ( '/sub' ) { effects . push 2 response . body << 'y' } rt . get ( '/sub' ) . body . should == 'y' effects . should == [ 1 , 2 ]", "del_tokens": "response . body << 'hello' app . get ( '/sub' ) { response . body << ' there' } rt . get ( '/sub' ) . body . should == 'hello there'", "commit_type": "fix"}
{"commit_tokens": ["remove", "debug", "info", "and", "stub", "some", "stuff", "..."], "add_tokens": "# Requires and autoloads are inherited by the sudo process. # If you don't call stop! explicitly, the corresponding process and file # cleanup will be done when su gets garbage-collected. su . stop!", "del_tokens": "# i you don't call stop! explicitly, the corresponding process and file # cleanup will be done automatically, when the object gets out of scope # su.stop!", "commit_type": "remove"}
{"commit_tokens": ["Add", "tests", "for", "sub", "-", "departments", "."], "add_tokens": "departments . entries . count . should == 3 department1 = departments . entries [ 0 ] department2 = departments . entries [ 1 ] department3 = departments . entries [ 2 ] department3 . name . should == 'QA Department' department3 . parent_ref . to_i . should == 2", "del_tokens": "departments . entries . count . should == 2 department1 = departments . entries . first department2 = departments . entries . last", "commit_type": "add"}
{"commit_tokens": ["Fix", "deprecation", "warning", "in", "Rails", "4"], "add_tokens": "session = if ActiveRecord . version >= Gem :: Version . new ( '4.0.0' ) Session . where ( session_id : sid ) . first_or_initialize else Session . find_or_initialize_by_session_id ( sid ) end", "del_tokens": "session = Session . find_or_initialize_by_session_id ( sid )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "sequence", "of", "return", "data"], "add_tokens": "return { status : status , params : @params , response : response }", "del_tokens": "return { status : status , response : response , params : @params }", "commit_type": "change"}
{"commit_tokens": ["Fixed", "some", "implementation", "problems", "with", "+", "/", "-", ".", "Issues", "still", "remain", "..."], "add_tokens": "#!/usr/bin/env ruby", "del_tokens": "#!/usr/bin/env ruby #~ require 'runt/dateprecision' #~ require 'runt/timepoint' def test_plus year_prec = DatePrecision . year ( 2010 , 8 ) puts year_prec . ctime puts ( year_prec + 12 ) . ctime #Year precision will truncate month #FIXME!!!! assert ( DatePrecision . year ( 2022 , 12 ) == ( year_prec + 12 ) ) month_prec = DatePrecision . month ( 2004 , 8 ) assert ( DatePrecision . month ( 2005 , 1 ) == ( month_prec + 6 ) ) #11:59 (:04 - ignored) December 31st, 1999 prec = DatePrecision . minute ( 1999 , 12 , 31 , 23 , 59 , 4 ) end def test_new date = TimePoint . new ( 2004 , 2 , 29 ) assert ( ! date . date_precision . nil? ) date_time = TimePoint . new ( 2004 , 2 , 29 , 22 , 13 ) assert ( ! date_time . date_precision . nil? ) end", "commit_type": "fix"}
{"commit_tokens": ["Improved", "handling", "exceptions", "in", "Patron", "adapter", "to", "reflect", "error", "handling", "in", "Patron", "."], "add_tokens": "if [ :put , :post ] . include? ( req . action ) if req . file_name if ! File . exist? ( req . file_name ) || ! File . readable? ( req . file_name ) raise ArgumentError . new ( \"Unable to open specified file.\" ) end request_body = File . read ( req . file_name ) elsif req . upload_data request_body = req . upload_data else raise ArgumentError . new ( \"Must provide either data or a filename when doing a PUT or POST\" )", "del_tokens": "if req . file_name && [ :put , :post ] . include? ( req . action ) if ! File . exist? ( req . file_name ) || ! File . readable? ( req . file_name ) raise ArgumentError . new ( \"Unable to open specified file.\" ) request_body = File . read ( req . file_name ) else request_body = req . upload_data", "commit_type": "improve"}
{"commit_tokens": ["Add", "tests", "for", "the", "CLI", "interface"], "add_tokens": "# @!attribute [r] site_generator # @return [Usmu::SiteGenerator] attr_reader :site_generator @site_generator = Usmu :: SiteGenerator . new ( @configuration ) @site_generator . generate", "del_tokens": "Usmu :: SiteGenerator . new ( @configuration ) . generate", "commit_type": "add"}
{"commit_tokens": ["Use", "Monitor", "instead", "of", "Mutex", "to", "allow", "for", "reentrant", "methods"], "add_tokens": "require 'monitor' @copied = 0 @failed = 0 @total = 0 @copied = 0 @failed = 0 @total = 0", "del_tokens": "require 'thread' require 'larch/util' @copied = 0 @failed = 0 @total = 0 @copied = 0 @failed = 0 @total = 0", "commit_type": "use"}
{"commit_tokens": ["move", "assets", "into", "their", "own", "folder"], "add_tokens": "copy_from = File . join ( asset_dir , asset_type ) copy_to = File . join ( public_dir , asset_type , 'resque' ) FileUtils . mkdir ( copy_to ) unless File . exists? copy_to Dir . entries ( copy_from ) . each do | f | new_file = File . join ( copy_to , f ) from_file = File . join ( copy_from , f ) FileUtils . cp ( from_file , new_file ) unless File . exist? ( new_file ) || File . directory? ( from_file )", "del_tokens": "current_dir = File . join ( asset_dir , asset_type ) Dir . entries ( current_dir ) . each do | f | path = File . join ( public_dir , asset_type , f ) FileUtils . cp ( File . join ( asset_dir , asset_type , f ) , path ) unless File . exist? ( path ) || File . directory? ( path )", "commit_type": "move"}
{"commit_tokens": ["Fix", "integer", "conversion", "in", "masks"], "add_tokens": "return Mask128 . new ( Integer ( mask ) ) rescue ArgumentError raise ValidationError , \"#{mask} is not valid integer.\"", "del_tokens": "return Mask128 . new ( mask . to_i )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "it", "to", "use", "hex", "for", "chunk", "lengths", "rather", "than", "decimal", "."], "add_tokens": "ChunkSizeLineMatch = %r{ ^[0-9a-fA-F]+ \\r ? \\n } @chunk_remain = scanner [ 0 ] . to_i ( 16 )", "del_tokens": "ChunkSizeLineMatch = %r{ ^[0-9]+ \\r ? \\n } @chunk_remain = scanner [ 0 ] . to_i", "commit_type": "fix"}
{"commit_tokens": ["Create", "a", "separate", "index", "for", "lookup"], "add_tokens": "@index = { } @index [ language . name ] = @name_index [ language . name ] = language @index [ name ] = @alias_index [ name ] = language # TODO: Consider returning nil instead of Text # # Returns the Language or Text if none was found. @index [ name ] || self [ 'Text' ]", "del_tokens": "@name_index [ language . name ] = language @alias_index [ name ] = language # Returns the Language or nil if none was found. find_by_name ( name ) || find_by_alias ( name ) || self [ 'Text' ]", "commit_type": "create"}
{"commit_tokens": ["allow", "for", "JSON", "ENV", "options"], "add_tokens": "kv = k . split ( ':' ) h [ kv [ 0 ] . to_sym ] = kv [ 1 ] ? JSON . parse ( kv [ 1 ] ) : true", "del_tokens": "h [ k . to_sym ] = true", "commit_type": "allow"}
{"commit_tokens": ["Updated", "app", "version", "and", "history"], "add_tokens": "BUGFIX = 6", "del_tokens": "BUGFIX = 5", "commit_type": "update"}
{"commit_tokens": ["fix", "bug", "in", "avilability_zone", "setting"], "add_tokens": "launch_options . merge ( { :availability_zone => opts [ 'availability_zone' ] } ) if opts [ 'availability_zone' ]", "del_tokens": "@zone = opts . include? ( 'availability_zone' ) ? opts [ 'availability_zone' ] : nil opts [ :availability_zone ] = opts [ 'zone' ] if opts [ 'zone' ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "initial", "subscriptions", "would", "be", "sent", "twice"], "add_tokens": "on ( :reconnected ) {", "del_tokens": "on ( :connected ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "tag", "option", "to", "panel", "helper"], "add_tokens": "# @option options [#to_s] :tag (:div) the HTML tag to wrap the panel in. tag = options . fetch :tag , :div content_tag tag , content , class : panel_class ( options [ :context ] )", "del_tokens": "content_tag :div , content , class : panel_class ( options [ :context ] )", "commit_type": "add"}
{"commit_tokens": ["upgrade", "routes", "for", "rails", "3"], "add_tokens": "Rails . application . routes . draw do resource :export_item_sorting , :only => [ :update ] resources :export_items , :only => [ :edit , :update , :destroy ] resources :export_filters , :only => [ :edit , :update , :destroy ] resources :exports do resources :export_filters , :only => [ :new ]", "del_tokens": "ActionController :: Routing :: Routes . draw do | map | map . resource :export_item_sorting , :only => [ :update ] map . resources :export_items , :only => [ :edit , :update , :destroy ] map . resources :export_filters , :only => [ :edit , :update , :destroy ] map . resources :exports do | exports | exports . resources :export_filters , :only => [ :new ]", "commit_type": "upgrade"}
{"commit_tokens": ["Moving", "scouts", "to", "a", "submodule"], "add_tokens": "require 'outpost/scouts/http' using Outpost :: Scouts :: Http => 'master http server' do using Outpost :: Scouts :: Http => 'master http server' do using Outpost :: Scouts :: Http => 'master http server' do using Outpost :: Scouts :: Http => 'master http server' do", "del_tokens": "require 'outpost/http_scout' using Outpost :: HttpScout => 'master http server' do using Outpost :: HttpScout => 'master http server' do using Outpost :: HttpScout => 'master http server' do using Outpost :: HttpScout => 'master http server' do", "commit_type": "move"}
{"commit_tokens": ["Use", "ruby", "stlib", "Set", "class", "where", "possible"], "add_tokens": "require 'set' @inserts . add ( object ) @deletes . add ( object ) @updates . add ( object ) @updates . member? ( object ) @inserts . member? ( object ) @deletes . member? ( object ) @track . member? ( object ) @track = { } @inserts = Set . new @updates = Set . new @deletes = Set . new @deletes . each do | object | @inserts . each do | object | @updates . each do | object |", "del_tokens": "@inserts [ object ] = true @deletes [ object ] = true @updates [ object ] = true # TODO add some tsorting to do actions on domain objects in # correct order. Dependency source? @updates . key? ( object ) @inserts . key? ( object ) @deletes . key? ( object ) @track . key? ( object ) @track = { } @inserts = { } @updates = { } @deletes = { } @deletes . keys . each do | object | @inserts . each_key do | object | @updates . each_key do | object |", "commit_type": "use"}
{"commit_tokens": ["use", "constants", "for", "success", "/", "fail"], "add_tokens": "SUCCESS = \"success\" FAIL = \"fail\" @status && @status == SUCCESS @status && @status == FAIL", "del_tokens": "@status && @status == \"success\" @status && @status == \"fail\"", "commit_type": "use"}
{"commit_tokens": ["Remove", "ca_file", "require_cert", "and", "truststore", "options", "to", "X509", "middleware"], "add_tokens": "# Extracts X.509 client certificates and adds credential objects to the # rack environment as env[\"rails-auth.credentials\"][\"x509\"] # @param [Object] app next app in the Rack middleware chain # @param [Hash] cert_filters maps Rack environment names to cert extractors # @param [Logger] logger place to log certificate extraction issues def initialize ( app , cert_filters : { } , logger : nil ) return Rails :: Auth :: X509 :: Certificate . new ( cert )", "del_tokens": "# Raised when certificate verification is mandatory CertificateVerifyFailed = Class . new ( NotAuthorizedError ) # Validates X.509 client certificates and adds credential objects for valid # clients to the rack environment as env[\"rails-auth.credentials\"][\"x509\"] # @param [Object] app next app in the Rack middleware chain # @param [String] ca_file path to the CA bundle to verify client certs with # @param [Hash] cert_filters maps Rack environment names to cert extractors # @param [Logger] logger place to log verification successes & failures # @param [Boolean] require_cert causes middleware to raise if certs are unverified # @param [OpenSSL::X509::Store] truststore (optional) provide your own truststore (for e.g. CRLs) def initialize ( app , ca_file : nil , cert_filters : { } , logger : nil , require_cert : false , truststore : nil ) raise ArgumentError , \"no ca_file or truststore given\" unless ca_file || truststore @require_cert = require_cert @truststore = truststore || OpenSSL :: X509 :: Store . new . add_file ( ca_file ) if @truststore . verify ( cert ) log ( \"Verified\" , cert ) return Rails :: Auth :: X509 :: Certificate . new ( cert ) else log ( \"Verify FAILED\" , cert ) raise CertificateVerifyFailed , \"verify failed: #{subject(cert)}\" if @require_cert end raise CertificateVerifyFailed , \"no client certificate in request\" if @require_cert def log ( message , cert ) @logger . debug ( \"rails-auth: #{message} (#{subject(cert)})\" ) if @logger end", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "source", "filename", "(", "dash", "not", "allowed", ")", "."], "add_tokens": "create_makefile \"dbusglue\"", "del_tokens": "create_makefile \"dbus-glue\"", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "FastTCPN#add_marking_for", "to", "work", "for", "not", "timed", "places"], "add_tokens": "find_place ( name ) . add token , timestamp else token = m find_place ( name ) . add token", "del_tokens": "token = m timestamp = nil find_place ( name ) . add token , timestamp", "commit_type": "fix"}
{"commit_tokens": ["add", "remote", "option", "on", "form", "input"], "add_tokens": "method : 'post' , remote : false", "del_tokens": "method : 'post'", "commit_type": "add"}
{"commit_tokens": ["Use", "#abort_on_exception", "thread", "instance", "method"], "add_tokens": "return if running? @thread = Thread . new do Thread . current . abort_on_exception = true run ( arg ) end", "del_tokens": "Thread . abort_on_exception = true @thread = Thread . new { run ( arg ) } unless running?", "commit_type": "use"}
{"commit_tokens": ["Added", "some", "sleeps", "to", "make", "sure", "we", "don", "t", "hammer", "the", "cluster", "when", "draining", "."], "add_tokens": "unless active_nodes . empty? say_status 'Drain Nodes' , \"#{active_nodes.length} nodes remaining\" , :green sleep_time = wait_sleep_time say_status 'Waiting' , \"Sleeping for #{sleep_time} seconds before the next iteration\" , :green sleep sleep_time end sleep_time = wait_sleep_time sleep sleep_time", "del_tokens": "say_status 'Drain Nodes' , \"#{active_nodes.length} nodes remaining\" , :green unless active_nodes . empty? sleep 2", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "for", "LL", "::", "SourceLine", "."], "add_tokens": "return data . lines [ line - 1 ]", "del_tokens": "return data . lines [ line - 1 ] [ ( column - 1 ) .. - 1 ]", "commit_type": "add"}
{"commit_tokens": ["added", "more", "fields", "to", "the", "GetHitResponse"], "add_tokens": ":auto_approval_delay => 'AutoApprovalDelayInSeconds' , :description => 'Description' , :reward => 'Reward' , :lifetime => 'LifetimeInSeconds' , :annotation => 'RequesterAnnotation' , :similar_hits_count => 'NumberOfSimilarHITs' , :assignments_pending_count => 'NumberofAssignmentsPending' , :assignments_available_count => 'NumberofAssignmentsAvailable' , :assignments_completed_count => 'NumberofAssignmentsCompleted'", "del_tokens": ":auto_approval_delay => 'AutoApprovalDelayInSeconds'", "commit_type": "add"}
{"commit_tokens": ["added", "methods", "to", "get", "the", "key", "for", "the", "converted", "video", "audio", "and", "thumbnail"], "add_tokens": "request = prepare_request :GET , { :video_key => video_key , :grains => true } . to_json execute_request ( request ) . select { | key | [ 'images' , 'files' ] . include? key } end def thumbnail_key_for ( video_key ) request = prepare_request :GET , { :video_key => video_key , :grains => true } . to_json execute_request ( request ) . select { | key | 'thumbnail' == key } end def audio_key_for ( video_key ) request = prepare_request :GET , { :video_key => video_key , :grains => true } . to_json execute_request ( request ) . select { | key | 'audio' == key } end def converted_video_key_for ( video_key ) request = prepare_request :GET , { :video_key => video_key , :grains => true } . to_json execute_request ( request ) . select { | key | 'converted_video' == key }", "del_tokens": "request = prepare_request :GET , { :video_key => video_key } . to_json execute_request ( request )", "commit_type": "add"}
{"commit_tokens": ["Add", "party", "mode", "to", "CLI"], "add_tokens": "desc 'pause_all' , 'Pause all speaker groups.' desc 'play_all' , 'Resume playing all speaker groups.' desc 'party_mode' , 'Start a party! Put all speakers in the same group.' def party_mode system . party_mode end desc 'party_over' , 'No more party :( Put all speakers in their own group.' def party_over system . party_over end desc 'groups' , 'List all groups'", "del_tokens": "desc 'pause_all' , 'Pauses all Sonos speaker groups' desc 'play_all' , 'Resumes playing all Sonos speaker groups' desc 'groups' , 'List all Sonos groups'", "commit_type": "add"}
{"commit_tokens": ["use", "digest", "/", "md5", "instead", "of", "alternate", "form", "for", "compatibility"], "add_tokens": "require 'digest/md5' hash [ filename ] = Digest :: MD5 . hexdigest ( File . read ( filename ) )", "del_tokens": "begin require 'md5' rescue Object => error require 'digest/md5' end hash [ filename ] = begin MD5 . new ( File . read ( filename ) ) rescue Object => error Digest :: MD5 . new ( File . read ( filename ) ) end . to_s", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "yard", "task", "."], "add_tokens": "task :docs => :yard", "del_tokens": "task :docs => :yardoc", "commit_type": "use"}
{"commit_tokens": ["Add", "an", "options", "hash", "to", ".", "retrieve", "DSL", "method"], "add_tokens": "require 'tempfile' require 'zip/zip' # Deploy the contents of _dir_ to the target organization # Retrieve the metadata specified in the manifest file. If _options_ # contains a key _:to_, the resulting zip file that is retrieved is # unzipped to the directory specified. def retrieve ( manifest , options = { } ) zip_contents = retrieval . zip_file unzip ( zip_contents , options [ :to ] ) if options . has_key? ( :to ) yield result , zip_contents if block_given? end # Unzips _zip_contents_ to _destination_ def unzip ( zip_contents , destination ) file = Tempfile . new ( \"retrieve\" ) file . write ( zip_contents ) path = file . path file . close Zip :: ZipFile . open ( path ) do | zip_file | zip_file . each do | f | path = File . join ( destination , f . name ) FileUtils . mkdir_p ( File . dirname ( path ) ) zip_file . extract ( f , path ) end end", "del_tokens": "def retrieve ( manifest ) zip = retrieval . zip_file yield result , zip if block_given?", "commit_type": "add"}
{"commit_tokens": ["added", "bg", "color", "to", "params", "in", "embed", "."], "add_tokens": "wmode : \" opaque \" , bgcolor : \" #000000\\\"", "del_tokens": "wmode : \" opaque \"", "commit_type": "add"}
{"commit_tokens": ["Improve", "feed_spec", ".", "rb", "."], "add_tokens": "let ( :feed_type ) { double ( :type ) } let ( :category_id ) { 1 } WalmartOpen :: Requests :: Feed . new ( feed_type , category_id ) } . to raise_error ( ArgumentError ) WalmartOpen :: Requests :: Feed . new ( feed_type , category_id ) WalmartOpen :: Requests :: Feed . new ( feed_type , category_id ) } . to raise_error ( ArgumentError ) let ( :feed_request ) { WalmartOpen :: Requests :: Feed . new ( feed_type , category_id ) } before do WalmartOpen :: Requests :: Feed :: TYPES . stub ( :include? ) . with ( feed_type ) . and_return ( true ) WalmartOpen :: Requests :: Feed :: CATEGORY_REQUIRED_TYPES . stub ( :include? ) . with ( feed_type ) . and_return ( true ) end", "del_tokens": "let ( :feed_type ) { double ( :type ) } WalmartOpen :: Requests :: Feed . new ( feed_type , 1 ) } . to raise_error WalmartOpen :: Requests :: Feed . new ( feed_type , 1 ) WalmartOpen :: Requests :: Feed . new ( feed_type , 1 ) } . to raise_error let ( :feed_request ) { WalmartOpen :: Requests :: Feed . new ( :bestsellers , 1 ) }", "commit_type": "improve"}
{"commit_tokens": ["Added", "ability", "to", "pass", "force", "option", "to", "repo", "deletion"], "add_tokens": "# # == Parameters: # force:: # When true, forces repo deletion # def drop kwargs = { } force = kwargs . arg :force , false cmd = 'aptly repo drop' cmd += ' -force' if force cmd += \" #{@name.quote}\" Aptly :: runcmd cmd", "del_tokens": "def drop Aptly :: runcmd \"aptly repo drop #{@name.quote}\"", "commit_type": "add"}
{"commit_tokens": ["Fixing", "documentation", "for", "Client#get_latest_crises", "."], "add_tokens": "# @param [String] params A hash that contains the http parameters for the call, e.g. { :type => \"earthquake\", :level => \"red\", :output => \"short\" }", "del_tokens": "# @param [String] type The crises type, e.g. earthquake, flood, cyclone, volcanoe", "commit_type": "fix"}
{"commit_tokens": ["added", "controllers", "generator", "routes", "enable", "/", "disable"], "add_tokens": "if Invitation . configuration . routes_enabled? Rails . application . routes . draw do resources :invites , controller : 'invitation/invites' , only : [ :new , :create ] end", "del_tokens": "Rails . application . routes . draw do resources :invites , controller : 'invitation/invites' , only : [ :new , :create ]", "commit_type": "add"}
{"commit_tokens": ["make", "yes", "prompt", "with", "regex"], "add_tokens": "if gets . strip . downcase =~ / y(es)? / if gets . strip . downcase =~ / y(es)? /", "del_tokens": "if gets . strip . downcase == 'yes' if gets . strip . downcase == 'yes'", "commit_type": "make"}
{"commit_tokens": ["Add", "Lotus", "::", "Application", ".", "load!", "to", "eager", "load", "configuration", "and", "allow", "one", "file", "architecture"], "add_tokens": "self . class . load! ( self ) # Eager load the application configuration, by activating the framework # duplication mechanisms. # # @since 0.1.1 # # @example # require 'lotus' # # module OneFile # class Application < Lotus::Application # configure do # routes do # get '/', to: 'dashboard#index' # end # end # # load! # end # # module Controllers::Dashboard # include Bookshelf::Controller # # action 'Index' do # def call(params) # self.body = 'Hello!' # end # end # end # end def self . load! ( recipient = self ) Lotus :: Loader . new ( recipient ) . load! end # Return the application name # # @since 0.1.1 # @api private def name self . class . name end", "del_tokens": "@loader = Lotus :: Loader . new ( self ) @loader . load!", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "interceptor", "in", "order", "to", "know", "which", "use", "case", "that", "raises", "an", "error"], "add_tokens": "intercept_exceptions = options . fetch ( :intercept_exceptions ) { false } begin if transactional handler = self . transaction_handler unless handler raise NoTransactionMethodError , \"This action should be executed inside a transaction. But no transaction handler was configured.\" end handler . transaction { use_case . send ( use_case_name , * args ) } else use_case . send ( use_case_name , * args ) end rescue = > e if intercept_exceptions raise \"#{use_case_class}: #{e.message}\" else raise e end", "del_tokens": "if transactional handler = self . transaction_handler unless handler raise NoTransactionMethodError , \"This action should be executed inside a transaction. But no transaction handler was configured.\" end handler . transaction { use_case . send ( use_case_name , * args ) } else use_case . send ( use_case_name , * args )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "to", "Rails", "4"], "add_tokens": "scope :roots , -> { where ( nested_interval_foreign_key => nil ) } scope :preorder , -> { order ( 'rgt DESC, lftp ASC' ) } scope :preorder , -> { order ( '1.0 * rgtp / rgtq DESC, lftp ASC' ) } scope :preorder , -> { order ( 'nested_interval_rgt(lftp, lftq) DESC, lftp ASC' ) }", "del_tokens": "scope :roots , where ( nested_interval_foreign_key => nil ) scope :preorder , order ( 'rgt DESC, lftp ASC' ) scope :preorder , order ( '1.0 * rgtp / rgtq DESC, lftp ASC' ) scope :preorder , order ( 'nested_interval_rgt(lftp, lftq) DESC, lftp ASC' )", "commit_type": "add"}
{"commit_tokens": ["adding", "an", "indentation", "in", "the", "README", "file", "and", "remove", "the", "argument", "from", "distinct", "-", "since", "it", "s", "already", "initialized", "to", "false", "distinct", "method", "should", "only", "be", "used", "to", "turn", "it", "to", "true"], "add_tokens": "# Turn on select distinct option in the CTE. def distinct @distinct_value = true", "del_tokens": "# Turn on/off select distinct option in the CTE. # @param [true, false] value def distinct ( value = true ) @distinct_value = value", "commit_type": "add"}
{"commit_tokens": ["Adding", "respond_to", "override", "to", "the", "ObjectifiedHash", "class", "so", "it", "properly", "responds", "to", "respond_to?", "calls"], "add_tokens": "@hash = { a : 1 , b : 2 , 'string' => 'string' , symbol : :symbol } describe \"#respond_to\" do it \"should return true for methods this object responds to through method_missing as sym\" do expect ( @oh . respond_to? ( :a ) ) . to be_truthy end it \"should return true for methods this object responds to through method_missing as string\" do expect ( @oh . respond_to? ( 'string' ) ) . to be_truthy end it \"should not care if you use a string or symbol to reference a method\" do expect ( @oh . respond_to? ( :string ) ) . to be_truthy end it \"should not care if you use a string or symbol to reference a method\" do expect ( @oh . respond_to? ( 'symbol' ) ) . to be_truthy end end", "del_tokens": "@hash = { a : 1 , b : 2 }", "commit_type": "add"}
{"commit_tokens": ["Move", "read_multi", "short", "circuit", "down", "within", "method"], "add_tokens": "return { } if keys . empty?", "del_tokens": "return { } if keys . empty?", "commit_type": "move"}
{"commit_tokens": ["make", "changes", "as", "@tpitale", "requested"], "add_tokens": "options = options . pop if options . last . is_a? ( Hash ) fields , ( options || { } ) end", "del_tokens": "options = fields . find { | field | field . is_a? ( Hash ) } return fields , options || { } end", "commit_type": "make"}
{"commit_tokens": ["Move", "mime", "types", "to", "separate", "yaml", "file"], "add_tokens": "require 'yaml' # Register additional mime type extensions YAML . load_file ( File . expand_path ( \"../mimes.yml\" , __FILE__ ) ) . each do | mime_type , exts | mime = MIME :: Types [ mime_type ] . first exts . each { | ext | mime . extensions << ext } MIME :: Types . index_extensions ( mime ) end", "del_tokens": "# Register additional binary extensions binary = MIME :: Types [ 'application/octet-stream' ] . first binary . extensions << 'dmg' binary . extensions << 'dll' MIME :: Types . index_extensions ( binary ) # Register 'ear' and 'war' as java java = MIME :: Types [ 'application/java-archive' ] . first java . extensions << 'ear' java . extensions << 'war' MIME :: Types . index_extensions ( java )", "commit_type": "move"}
{"commit_tokens": ["Moving", "jackpot", "config", "file", "to", "config", "/", "directory"], "add_tokens": "raw_config = File . read ( File . dirname ( __FILE__ ) + \"/../../config/jackpot.yml\" )", "del_tokens": "raw_config = File . read ( File . dirname ( __FILE__ ) + \"/../../jackpot.yml\" )", "commit_type": "move"}
{"commit_tokens": ["Add", "passcode", "to", "email", "subject", "line"], "add_tokens": "mail ( to : administrator . email , subject : \"#{@passcode} is your #{Tolaria.config.company_name} passcode\" )", "del_tokens": "mail ( to : administrator . email , subject : \"#{Tolaria.config.company_name} Passcode\" )", "commit_type": "add"}
{"commit_tokens": ["fix", "resetting", "branch", "if", "not", "tracked"], "add_tokens": "run_cmd \"git branch -D #{branch}\" rescue nil", "del_tokens": "run_cmd \"git branch -D #{branch}\"", "commit_type": "fix"}
{"commit_tokens": ["updated", "variables", "to", "NOT", "clear", "specific", "occurrence", "informantion", "from", "source", "data", "criteria"], "add_tokens": "simple_xml_model . source_data_criteria [ 6 ] . specific_occurrence . must_equal 'A' simple_xml_model . source_data_criteria [ 6 ] . specific_occurrence_const . must_equal 'VARIABLE'", "del_tokens": "simple_xml_model . source_data_criteria [ 6 ] . specific_occurrence . must_equal nil simple_xml_model . source_data_criteria [ 6 ] . specific_occurrence_const . must_equal nil", "commit_type": "update"}
{"commit_tokens": ["Added", "default", "name", "for", "forks"], "add_tokens": "@query = Blazer :: Query . new ( statement : params [ :statement ] , data_source : params [ :data_source ] , name : params [ :name ] )", "del_tokens": "@query = Blazer :: Query . new ( statement : params [ :statement ] , data_source : params [ :data_source ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "curve", "+", "N", "commands"], "add_tokens": "raise InvalidCurveError , \"Curve expression should start with a 'curve' command\" unless cmd =~ / ^curve / # Compute the curve increment or decrement. It looks like a modifier: # \"curve+5\" means we have to add 5 to every value on the curve xformer = lambda { | v | v } # Identity if cmd =~ / ^(curve)([+-])([ \\d \\. ]+)$ / operator = $2 [ 0 .. 1 ] # Ensure only one character gets through modifier = $3 . to_f xformer = lambda { | v | v . send ( operator , modifier ) } end expand_curve ( curve_expression , & xformer ) def expand_curve ( curve_expression , & post_lambda ) # Nuke saves curves very efficiently. x(keyframe_number) means that an # uninterrupted sequence of values will start, after which values follow. # When the curve is interrupted in some way a new x(keyframe_number) will # signify that we skip to that specified keyframe and the curve continues # from there, in gap size defined by the last fragment. That is, # x1 1 x3 2 3 4 will place 2, 3 and 4 at 2-frame increments. @tuples << [ last_processed_keyframe , yield ( $1 . to_f ) ]", "del_tokens": "raise InvalidCurveError , \"Curve expression should start with a 'curve' command\" unless cmd == 'curve' expand_curve ( curve_expression ) def expand_curve ( curve_expression ) # Nuke saves curves very efficiently. x(keyframe_number) means that an uninterrupted sequence of values will start, # after which values follow. When the curve is interrupted in some way a new x(keyframe_number) will signifu that we # skip to that specified keyframe and the curve continues from there, in gap size defined by the last fragment. # That is, x1 1 x3 2 3 4 will place 2, 3 and 4 at 2-frame increments. @tuples << [ last_processed_keyframe , $1 . to_f ]", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "where", "it", "could", "not", "install", "the", "resource", "files"], "add_tokens": "if matched = line . match ( / install_resource \\s +(.*) / ) path = ( matched [ 1 ] . strip ) [ 1 .. - 2 ] resources << Pathname . new ( @config . project_dir ) + PODS_ROOT + path", "del_tokens": "if matched = line . match ( / install_resource \\s +'(.*)' / ) resources << Pathname . new ( @config . project_dir ) + PODS_ROOT + matched [ 1 ]", "commit_type": "fix"}
{"commit_tokens": ["Adding", "test", "for", "chassi", "with", "uuid"], "add_tokens": "@uuidArray = client . discover_chassis . map { | node | node . uuid } puts @uuidArray [ 0 ] # response = client.fetch_chassis(@uuidArray, @includeAttributes, nil) # puts response[0] # not_nil = response[0].send(@includeAttributes[0])", "del_tokens": "# @uuidArray = client.discover_nodes.map { |node| node.uuid } # puts client.discover_chassis puts client . fetch_chassis ( @uuidArray , @excludeAttributes , nil )", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "documentation", "of", "Span#log", "and", "Span#log_kv", "methods"], "add_tokens": "# @param fields [Hash{Symbol=>Object}] Additional information to log # @param fields [Hash{Symbol=>Object}] Additional information to log", "del_tokens": "# @param fields [Hash] Additional information to log # @param fields [Hash] Additional information to log", "commit_type": "fix"}
{"commit_tokens": ["Removing", "Hour", "from", "output", "to", "fix", "time", "zone", "issues", "on", "test"], "add_tokens": "assert_equal '2008-10-12 00:00' , model . timestamp . strftime ( '%Y-%m-%d %M:%S' ) assert_equal '2007-11-01 25:00' , model . timestamp . strftime ( '%Y-%m-%d %M:%S' ) model . merge_attributes ( :timestamp => DateTime . new ( 2007 , 11 , 1 , 15 , 25 , 0 ) ) assert_equal '2007-11-01 25:00' , model . timestamp . strftime ( '%Y-%m-%d %M:%S' )", "del_tokens": "assert_equal '2008-10-12 00:00:00' , model . timestamp . strftime ( '%Y-%m-%d %H:%M:%S' ) assert_equal '2007-11-01 15:25:00' , model . timestamp . strftime ( '%Y-%m-%d %H:%M:%S' ) model . merge_attributes ( :timestamp => DateTime . new ( 2007 , 11 , 1 , 15 , 25 , 0 , \"+09:00\" ) ) assert_equal '2007-11-01 02:25:00' , model . timestamp . strftime ( '%Y-%m-%d %H:%M:%S' )", "commit_type": "remove"}
{"commit_tokens": ["Add", "coupon", "and", "link", "locator", "APIs"], "add_tokens": "require 'linkshare/strategy' require 'linkshare/coupon' require 'linkshare/link_locator' coupon : \"https://api.rakutenmarketing.com/coupon/1.0\" , link_locator : \"https://api.rakutenmarketing.com/linklocator/1.0\" def self . token @token ||= Linkshare :: Strategy . new ( client ) . get_token ( Linkshare . username , Linkshare . password , Linkshare . sid ) ; end def self . coupon @coupon ||= Linkshare :: Coupon . new end def self . linkLocator @coupon ||= Linkshare :: LinkLocator . new", "del_tokens": "require 'linkshare/linkshare_strategy' coupon : \"https://api.rakutenmarketing.com/coupon/1.0\" # def initialize # @consumer_key = \"LDvfRMkdy0jVskoXQs7UBd_LyeIa\" # @consumer_secret = \"43fak5CCPakMrv5Hu0fqls3Wrwka\" # @sid = \"3279068\" # @username = \"rudie123\" # @password = \"password123\" # @oauth_callback_url = 'http://263b4d92.ngrok.io' # @redirect_url = 'http://263b4d92.ngrok.io' # end # def self.client () # OAuth2::Client.new(Linkshare.consumer_key, Linkshare.consumer_secret, :site => SITE) # end # def self.authorize() # # Linkshare.token_request_authorization = \"Basic \"+ Base64.encode64(Linkshare.consumer_key + \":\" +Linkshare.consumer_secret) # # client = OAuth2::Client.new(Linkshare.consumer_key, Linkshare.consumer_secret, :site => SITE, :token_url => TOKEN_URL, :authorize_url => AUTHORIZE_URL ) # # # client.raise_errors = false # # puts '------rudietudietudiweriuierwe-----------' # # puts client # # puts '------rudietudietudiweriuierwe-----------' # r = client.web_server.authorize_url :redirect_uri => redirect_uri, :scope => :sid # redirect_to r # end # def self.redirect_uri () # uri = URI.parse(request.url) # uri.path = :redirect_uri # uri.query = nil # uri.to_s # end def self . token c = client s = Linkshare :: LinkshareStrategy . new ( c ) token = s . get_token ( Linkshare . username , Linkshare . password , Linkshare . sid ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "failing", "environment", "creation", "test"], "add_tokens": "before ( :each ) do @new_env = mock ( KPEnvironment , EnvControllerTest :: EMPTY_ENVIRONMENT ) KPEnvironment . stub! ( :new ) . and_return ( @new_env ) @new_env . stub! ( :save! ) . and_return ( true ) end it \"should create new environment\" do KPEnvironment . should_receive ( :new ) . with ( { :name => 'production' , :organization_id => @org . id , :prior => @org . locker , :description => nil } ) . and_return ( @new_env ) post :create , :organization_id => @org . cp_key , :name => 'production' , :prior => @org . locker end it \"should save new environment\" do @new_env . should_receive ( :save! ) . and_return ( true ) post :create , :organization_id => @org . cp_key , :name => 'production' , :prior => @org . locker end pending \"this test shouldn't be here - validation of uniqueness constrain should be tested at the model level\" #post :create, :organization_id => @org.cp_key, :name => 'production' #post :create, :organization_id => @org.cp_key, :name => 'production' #response.should_not be_success", "del_tokens": "assigns ( :environment ) . name . should == 'production' assigns ( :environment ) . organization_id . should == @org . id post :create , :organization_id => @org . cp_key , :name => 'production' post :create , :organization_id => @org . cp_key , :name => 'production' response . should_not be_success", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "group", "information", "in", "tag", "entity", "object"], "add_tokens": "# Method: <tt>GET /api/v1/organization/:organization_id/tags</tt> def find_all ( organization_id ) http . get ( endpoint_base ( organization_id ) ) do | response | # Method: <tt>GET /api/v1/organization/:organization_id/tags/:tag_id</tt> def find ( organization_id , id ) http . get ( \"#{endpoint_base(organization_id)}/#{id}\" ) do | response | # Method: <tt>POST /api/v1/organization/:organization_id/tags</tt> def create ( organization_id , params = { } ) http . post ( endpoint_base ( organization_id ) , body : params ) do | response | # Method: <tt>PUT /api/v1/organization/:organization_id/tags/:id</tt> def update ( organization_id , id , params = { } ) http . put ( \"#{endpoint_base(organization_id)}/#{id}\" , body : params ) do | response | # Method: <tt>DELETE /api/v1/organization/:organization_id/tags/:id</tt> def destroy ( organization_id , id ) http . delete ( \"#{endpoint_base(organization_id)}/#{id}\" ) do | response |", "del_tokens": "# Method: <tt>GET /api/v1/organization/:id/tags</tt> def find_all ( id ) http . get ( endpoint_base ( id ) ) do | response | # Method: <tt>GET /api/v1/organization/:id/tags/:tag_id</tt> def find ( id , tag_id ) http . get ( \"#{endpoint_base(id)}/#{tag_id}\" ) do | response | # Method: <tt>POST /api/v1/organization/:id/tags</tt> def create ( id , params = { } ) http . post ( endpoint_base ( id ) , body : params ) do | response | # Method: <tt>PUT /api/v1/organization/:id/tags/:tag_id</tt> def update ( id , tag_id , params = { } ) http . put ( \"#{endpoint_base(id)}/#{tag_id}\" , body : params ) do | response | # Method: <tt>DELETE /api/v1/organization/:id/tags/:tag_id</tt> def destroy ( id , tag_id ) http . delete ( \"#{endpoint_base(id)}/#{tag_id}\" ) do | response |", "commit_type": "add"}
{"commit_tokens": ["added", ":", "id_field", "option", "to", "Index", "::", "Index"], "add_tokens": "# using #add_document or <<. This will also be used # for default_search_field unless you set it # string \"id\". # id_field: This field is as the field to search when doing # searches on a term. For example, if you do a # lookup by term \"cat\", ie index[\"cat\"], this will # be the field that is searched. This will default # to default_field if not set. @default_field = ( @options [ :default_field ] || @options [ :id_field ] || \"id\" ) . to_s @id_field = ( @options [ :id_field ] || @options [ :default_field ] || \"id\" ) . to_s t = Term . new ( @id_field , id . to_s ) t = Term . new ( @id_field , id . to_s )", "del_tokens": "# using #add_document. This will also be used for # default_search_field unless you set it # empty string \"\". @default_field = @options [ :default_field ] || \"\" t = Term . new ( \"id\" , id . to_s ) t = Term . new ( \"id\" , id . to_s )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "logs", "method"], "add_tokens": "unless params . nil?", "del_tokens": "if params . nil?", "commit_type": "fix"}
{"commit_tokens": ["Added", "authentication", "functions", "for", "google", "client", ".", "Create", "config", "file", "for", "client", "still", "need", "to", "figure", "this", "part", "out", "."], "add_tokens": "def authorization_url ( response_type , params ) implicit ( response_type , params ) . authorization_url end def exchange_code_for_token ( code , redirect_uri ) authorization_code ( code , :redirect_uri => redirect_uri ) . get_token end def refresh_access_token ( refresh_token ) refresh_token ( refresh_token ) . get_token end def device_code ( params ) params [ :scope ] = normalize_scope ( params [ :scope ] ) if params [ :scope ] params [ :path ] = params [ :path ] || '/o/oauth2/device/code' params [ :method ] = 'post' implicit ( response_type , params ) . authorization_url", "del_tokens": "def authorization_url ( params ) raise \"Response type required\" unless params [ :response_type ] response_type = params [ :response_type ] grant = implicit ( response_type , params ) grant . authorization_url end", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "number", "in", "code", "."], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "update"}
{"commit_tokens": ["Changed", "how", "arrays", "are", "processed"], "add_tokens": "@level += 1 block . call ( arg ) #@stack[@level].add block.call(arg) @level -= 1 @stack [ @level ] . add @stack . pop end", "del_tokens": "@stack [ @level ] . add block . call ( arg ) end", "commit_type": "change"}
{"commit_tokens": ["Fix", "early", "raised", "error", "in", "Blueprint", "fix", "comment", "in", "architect"], "add_tokens": "# remove the build_dir", "del_tokens": "remove the build_dir", "commit_type": "fix"}
{"commit_tokens": ["added", "UI", "class", "and", "basic", "test"], "add_tokens": "@stdout = configuration [ :stdout ] || $stdout @stderr = configuration [ :stderr ] || $stderr @stdin = configuration [ :stdin ] || $stdin @logger = configuration [ :logger ] || ZTK :: Logger . new ( \"/dev/null\" )", "del_tokens": "super ( { :stdout => $stdout , :stderr => $stderr , :stdin => $stdin , :logger => $logger } . merge ( configuration ) ) config . logger . debug { \"config=#{config.send(:table).inspect}\" }", "commit_type": "add"}
{"commit_tokens": ["Add", "exit", "to", "terminate", "program", "only", "compile", "when", ".", "js", "(", "t", ")", "or", ".", "blueprint", "files", "are", "changed"], "add_tokens": "sub_dir = @args [ 1 ] unless @args [ 1 ] . match ( / ^- / ) @watcher = @project . watch ( \"architect is watching for changes. Type 'quit' or 'exit' to stop.\" ) while not @command =~ / ^(quit|exit)$ / when / ^(quit|exit)$ / end", "del_tokens": "sub_dir = @args [ 1 ] unless @args [ 1 ] . match / ^- / @watcher = @project . watch ( \"architect is watching for changes. Type 'quit' to stop.\" ) while not @command =~ / ^quit$ / when / ^quit$ / end", "commit_type": "add"}
{"commit_tokens": ["fixed", "rspec", "warnings", "-", "should", "=", ">", "expect", "()", ".", "to"], "add_tokens": "expect ( delegate . instance_eval { @entered_node } ) . to be true expect ( delegate . instance_eval { @exit_node } ) . to be true expect ( delegate . instance_eval { @visited_leaf } ) . to be true", "del_tokens": "delegate . instance_eval { @entered_node } . should be_true delegate . instance_eval { @exit_node } . should be_true delegate . instance_eval { @visited_leaf } . should be_true", "commit_type": "fix"}
{"commit_tokens": ["Improved", "yardoc", "in", "Event", "module", "."], "add_tokens": "# bean.subscribe :jump do # puts \"Whee!\" # end # puts \"#{object.class.name} jumped #{distance} metres #{direction}\" # # Whee! # # JumpingBean jumped 4 metres up # @return [nil] # @return [nil]", "del_tokens": "# puts \"#{object} jumped #{distance} metres #{direction}\" # @return nil # @return nil", "commit_type": "improve"}
{"commit_tokens": ["Added", "user", "-", "agent", "to", "http", "requests"], "add_tokens": "VERSION = \"1.0.13\"", "del_tokens": "VERSION = \"1.0.12\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "GraphCollection", "to", "store", "its", "own", "API", "to", "clean", "up", "next_page", "and", "previous_page", "."], "add_tokens": "attr_reader :api def initialize ( response , api ) @api = api define_method \"#{this.to_sym}_page\" do base ? GraphCollection . new ( @api . graph_call ( base , args ) , @api ) : nil GraphCollection . new ( graph_call ( \"#{id}/#{connection_name}\" , args ) , self ) GraphCollection . new ( graph_call ( \"search\" , args . merge ( { :q => search_terms } ) ) , self )", "del_tokens": "def initialize ( response ) define_method \"#{this.to_sym}_page\" do | graph | base ? GraphCollection . new ( graph . graph_call ( base , args ) ) : nil GraphCollection . new ( graph_call ( \"#{id}/#{connection_name}\" , args ) ) GraphCollection . new ( graph_call ( \"search\" , args . merge ( { :q => search_terms } ) ) )", "commit_type": "update"}
{"commit_tokens": ["changes", "DSL", "element", "to", "component"], "add_tokens": "def component id , attribs = { } , & block", "del_tokens": "def element id , attribs = { } , & block", "commit_type": "change"}
{"commit_tokens": ["Remove", "the", "use", "of", "the", "Temp", "directory"], "add_tokens": "init_dirs def init_dirs config [ :gv_public_dir ] = File . expand_path ( config [ :gv_public_dir ] ) unique_start_id = 'GV_' + \"#{Time.now.strftime('%Y%m%d-%H-%M-%S')}\" @public_dir = File . join ( config [ :gv_public_dir ] , unique_start_id ) init_public_dir # Create the Public Dir and copy files from gem root - this public dir # is served by the app is accessible at URL/... FileUtils . mkdir_p ( File . join ( @public_dir , 'GeneValidator' ) ) return unless config [ :host ] == '0.0.0.0' logger . warn 'Will listen on all interfaces (0.0.0.0).' ' Consider using 127.0.0.1 (--host option).'", "del_tokens": "check_dirs init_gv_tempdir init_public_dir def check_dirs config [ :gv_app_dir ] = File . expand_path ( config [ :gv_app_dir ] ) unique_run_id = 'GV_' + \"#{Time.now.strftime('%Y%m%d-%H-%M-%S')}\" @public_dir = File . join ( config [ :gv_app_dir ] , unique_run_id ) FileUtils . mkdir_p ( File . join ( @public_dir , 'GeneValidator' ) ) end # Creates a Temp directory (starting with 'GeneValidator_') each time # GVapp is started. Within this Temp folder, sub directories are created # in which GeneValidator is run. def init_gv_tempdir @temp_dir = Dir . mktmpdir ( 'GeneValidator_' ) # Copy the public folder (in the app root) to the gv_app_dir location - this # gv_app_dir is then used by the app to serve all dependencies... # rubocop:disable Style/GuardClause if config [ :host ] == '0.0.0.0' logger . warn 'Will listen on all interfaces (0.0.0.0).' ' Consider using 127.0.0.1 (--host option).' end # rubocop:enable Style/GuardClause", "commit_type": "remove"}
{"commit_tokens": ["Change", "target_index", "to", "lower", "-", "case"], "add_tokens": "# Change target_index to lower-case since Elasticsearch doesn't # allow upper-case characters in index names. target_index = target_index . downcase", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["updating", "the", "documentation", "for", "#translate"], "add_tokens": "# and the scope option. <em>E.g.</em>, in this example <tt>I18n.t :date, 'en-US'</tt> # I18n.t 'date.formats.short', 'en-US' # I18n.t :'date.formats.short', 'en-US' # I18n.t 'date.formats.short', 'en-US' # I18n.t 'formats.short', 'en-US', :scope => 'date' # I18n.t 'short', 'en-US', :scope => 'date.formats' # I18n.t 'short', 'en-US', :scope => %w(date formats) # I18n.t :foo, :bar => 'baz' # => 'foo baz' # I18n.t :foo, :count => 1 # => 'Foo' # I18n.t :foo, :count => 0 # => 'Foos' # I18n.t :foo, :count => 2 # => 'Foos' # I18n.t :foo, :count => 1 # => '1 foo' # I18n.t :foo, :default => 'default' # I18n.t :foo, :default => :bar # I18n.t :foo, :default => [:bar, 'default']", "del_tokens": "# and the scope option. <em>E.g.</em>, in this example <tt>:date.t 'en-US'</tt> # 'date.formats.short'.t 'en-US' # :'date.formats.short'.t 'en-US' # 'date.formats.short'.t 'en-US' # 'formats.short'.t 'en-US', :scope => 'date' # 'short'.t 'en-US', :scope => 'date.formats' # 'short'.t 'en-US', :scope => %w(date formats) # :foo.t :bar => 'baz' # => 'foo baz' # :foo, :count => 1 # => 'Foo' # :foo, :count => 0 # => 'Foos' # :foo, :count => 2 # => 'Foos' # :foo, :count => 1 # => '1 foo' # :foo.t :default => 'default' # :foo.t :default => :bar # :foo.t :default => [:bar, 'default']", "commit_type": "update"}
{"commit_tokens": ["Fixed", "password_archive_included?", "when", "the", "password_salt", "column", "does", "not", "exist", "."], "add_tokens": "dummy . password_salt = old_password . password_salt if dummy . respond_to? ( :password_salt )", "del_tokens": "dummy . password_salt = old_password . password_salt", "commit_type": "fix"}
{"commit_tokens": ["Use", ":", "if", "and", ":", "unless", "constraints", "to", "detect", "if", "a", "record", "has", "changed", "as", "well", "."], "add_tokens": "t . boolean :hidden algoliasearch :synchronous => true , :index_name => safe_index_name ( \"NestedItem\" ) , :per_environment => true , :unless => :hidden do add_attribute :nb_children @i1 = NestedItem . create :hidden => false @i2 = NestedItem . create :hidden => true @i1 . children << NestedItem . create ( :hidden => true ) << NestedItem . create ( :hidden => true ) result = NestedItem . raw_search ( '' ) result [ 'nbHits' ] . should == 1 @i2 . update_attribute :hidden , false result = NestedItem . raw_search ( '' ) result [ 'nbHits' ] . should == 2", "del_tokens": "algoliasearch :synchronous => true , :index_name => safe_index_name ( \"UniqUser\" ) , :per_environment => true do attribute :nb_children @i1 = NestedItem . create @i2 = NestedItem . create @i1 . children << NestedItem . create << NestedItem . create", "commit_type": "use"}
{"commit_tokens": ["adding", "inherit", "attribute", "to", "if_content", "and", "unless_content"], "add_tokens": "Renders the containing elements only if all of the listed parts exist on a page . part by seprating them with a comma . Setting the optional @inherit @ to true will search ancestors independently for each part . By default @inherit @ is set to @false @ . inherit_attr = tag . attr [ 'inherit' ] || 'false' inherit = inherit_attr . downcase == 'true' ? true : false part_page = page if inherit while ( part_page . part ( name ) . nil? and ( not part_page . parent . nil? ) ) do part_page = part_page . parent end end all_parts_present = false if part_page . part ( name ) . nil? inherit_attr = tag . attr [ 'inherit' ] || 'false' inherit = inherit_attr . downcase == 'true' ? true : false part_page = page if inherit while ( part_page . part ( name ) . nil? and ( not part_page . parent . nil? ) ) do part_page = part_page . parent end end all_parts_present = true if ! part_page . part ( name ) . nil?", "del_tokens": "Renders the containing elements only if all of the listed parts exists on a page . part by seprating them with a comma . all_parts_present = false if page . part ( name ) . nil? all_parts_present = true if ! page . part ( name ) . nil?", "commit_type": "add"}
{"commit_tokens": ["remove", "validates_presence_of", "password_confirmation", "to", "allow", "for", "forms", "that", "do", "not", "include", "an", "authentication"], "add_tokens": "validates_confirmation_of :password , :if => :password_required?", "del_tokens": "validates_presence_of :password_confirmation , :if => :password_required? validates_confirmation_of :password , :if => :validate_password_confirmation_presence? def validate_password_confirmation_presence? # allows applications to turn off password_confirmation validation password_required? end", "commit_type": "remove"}
{"commit_tokens": ["added", "all", "kinds", "of", "features"], "add_tokens": "require 'dare/sound.rb' require 'dare/font.rb' require 'dare/sprite.rb' VERSION = \"0.0.2\" ` #{ magnitude } *Math.cos( #{ angle } *Math.PI/180.0) ` ` #{ magnitude } *Math.sin( #{ angle } *Math.PI/180.0) ` end def self . ms ` (new Date()).getTime() `", "del_tokens": "require 'opal' require 'opal-jquery' ` #{ magnitude } *Math.cos( #{ angle } *Math.PI/180) ` ` #{ magnitude } *Math.sin( #{ angle } *Math.PI/180) `", "commit_type": "add"}
{"commit_tokens": ["Changed", "behavior", "of", "some", "MetaObject", "methods"], "add_tokens": "it 'returns a hash of meta method arrays grouped by their names' do expect ( meta_methods ) . to be_a ( Hash ) expect ( meta_methods . length ) . to eq ( 7 ) it 'returns a hash of the meta properties' do expect ( meta_properties ) . to be_a ( Hash ) expected = { Apple : 0 , Banana : 1 , Orange : 2 } @method = @metaobj . meta_methods [ :normalMethod ] . first @signal = @metaobj . meta_methods [ :someSignal ] . first @metaobj . meta_methods [ :emitSomeSignal ] . first . invoke ( @obj , 'foo' ) @property = @metaobj . meta_properties [ :name ]", "del_tokens": "it 'returns the meta methods' do expect ( meta_methods . length ) . to eq ( 9 ) it 'returns the meta properties' do expected = [ { Apple : 0 , Banana : 1 , Orange : 2 } ] @method = @metaobj . meta_methods . find { | m | m . name == :normalMethod } @signal = @metaobj . meta_methods . find { | m | m . name == :someSignal } @metaobj . meta_methods . find { | m | m . name == :emitSomeSignal } . invoke ( @obj , 'foo' ) @property = @metaobj . meta_properties . find { | p | p . name == :name }", "commit_type": "change"}
{"commit_tokens": ["Remove", "the", "deprecation", "warning", "(", "but", "the", "warning", "remains", "on", "the", "gem", ")", "."], "add_tokens": "format . html { redirect_to ( redirect_block ? redirect_block . call : resource_url ) } format . html { redirect_to ( redirect_block ? redirect_block . call : resource_url ) } format . html { redirect_to ( redirect_block ? redirect_block . call : collection_url ) }", "del_tokens": "format . html { redirect_to parse_redirect_url ( redirect_url , :resource_url , redirect_block ) } format . html { redirect_to parse_redirect_url ( redirect_url , :resource_url , redirect_block ) } format . html { redirect_to parse_redirect_url ( redirect_url , :collection_url , redirect_block ) }", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "a", "typo", "in", "the", "comments"], "add_tokens": "# Naughty, naughty, naughty! Don't blame me when someone hops in", "del_tokens": "# Naughty, naughty, naughty! Don't blame when when someone hops in", "commit_type": "fix"}
{"commit_tokens": ["Fix", "selector", "generator", "to", "properly", "handle", "composite", "key", "associations", "."], "add_tokens": "if identity . is_a? Array identity . each { | id | hash [ id ] = nil } else hash [ identity ] = nil end", "del_tokens": "hash [ identity ] = nil", "commit_type": "fix"}
{"commit_tokens": ["Add", "documentation", "for", "internal", "classes"], "add_tokens": "# @api private # # The internal class wrapping a socket connection. # @return [true, false] whether the connection was successful # @note The connection timeout is currently just 0.5 seconds, which should # be sufficient, but may need to be raised or made configurable for # high-latency situations. That said, if connecting to the remote server # takes that long, we may not want to use the node any way. # Execute the operations on the connection.", "del_tokens": "# Execute the operation on the connection.", "commit_type": "add"}
{"commit_tokens": ["Fix", "job_execution_output", "model", "and", "remove", "it", "from", "the", "api", "as", "it", "s", "not", "used"], "add_tokens": "attributes :id , :execution_id , :output , :timestamp", "del_tokens": "attributes :id , :execution_id , :job_id , :output , :timestamp", "commit_type": "fix"}
{"commit_tokens": ["Use", "absolute", "paths", "when", "paths", "are", "outside", "PWD", "."], "add_tokens": "location = ANSI . ansi ( \"#{determine_path}:#{line}:#{column}\" , :white , :bold ) \"file: #{determine_path.inspect}, line: #{line}, column: #{column})\" # Returns the path to the source of the message. If the path resides in the # current working directory (or a child directory) the path is relative, # otherwise it's absolute. def determine_path full_path = File . expand_path ( source_line . file ) pwd = Dir . pwd if full_path . start_with? ( pwd ) from = Pathname . new ( full_path ) to = Pathname . new ( pwd ) return from . relative_path_from ( to ) . to_s else return full_path end", "del_tokens": "location = ANSI . ansi ( \"#{relative_path}:#{line}:#{column}\" , :white , :bold ) \"file: #{relative_path.inspect}, line: #{line}, column: #{column})\" # Returns the path of the message relative to the current working directory. def relative_path from = Pathname . new ( source_line . file ) to = Pathname . new ( Dir . pwd ) return from . relative_path_from ( to ) . to_s", "commit_type": "use"}
{"commit_tokens": ["updated", "ignore", "for", "coverage", "folder"], "add_tokens": "VERSION = '0.1.1'", "del_tokens": "VERSION = '0.1.0'", "commit_type": "update"}
{"commit_tokens": ["Make", "message", "for", "TemplateNotFoundError", "more", "readable"], "add_tokens": "msg = \"Template #{template.inspect} could not be found in paths:\\n#{paths.map { |pa| \"- #{pa.to_s}\" }.join(\"\\n\")}\"", "del_tokens": "msg = \"Template #{template} could not be found in paths:\\n#{paths.map { |pa| \"- #{pa}\" }.join(\"\\n\")}\"", "commit_type": "make"}
{"commit_tokens": ["make", "plugin", "work", "outside", "Rails"], "add_tokens": "if defined? ( Rails ) env_config = new_config [ Rails . env ] else env_config = nil end def self . initialize ( default_file = File . join ( Rails . root , 'config' , 'application' , 'default.yml' ) , config_file = File . join ( Rails . root , 'config' , 'application' , 'config.yml' ) )", "del_tokens": "env_config = new_config [ Rails . env ] def self . initialize default_file = File . join ( Rails . root , 'config' , 'application' , 'default.yml' ) config_file = File . join ( Rails . root , 'config' , 'application' , 'config.yml' )", "commit_type": "make"}
{"commit_tokens": ["Fix", "passing", "resource", "object", "to", "edit", "methods"], "add_tokens": "resource = BookingSync :: API :: Resource . new ( nil , { id : 50 } )", "del_tokens": "resource = double ( to_s : \"50\" )", "commit_type": "fix"}
{"commit_tokens": ["updated", "Yajl", "::", "Deflate", "::", "StreamReader", "to", "allow", "for", "options", "to", "be", "passed", "to", "it", "s", "constructor", "using", "the"], "add_tokens": "def initialize ( io , options ) super ( options ) def self . parse ( io , options = nil ) Yajl :: Stream . parse ( new ( io , options ) )", "del_tokens": "def initialize ( io ) super ( nil ) def self . parse ( io ) Yajl :: Stream . parse ( new ( io ) )", "commit_type": "update"}
{"commit_tokens": ["allows", "term", "signal", "to", "be", "changed", "if", "needed"], "add_tokens": "Procodile . log ( @process . log_color , description , \"Sending #{@process.term_signal} to #{@pid}\" ) :: Process . kill ( @process . term_signal , pid ) Procodile . log ( @process . log_color , description , \"Sent #{@process.term_signal} signal to old PID #{old_process_pid} (forgetting now)\" ) :: Process . kill ( @process . term_signal , old_process_pid )", "del_tokens": "Procodile . log ( @process . log_color , description , \"Sending TERM to #{@pid}\" ) :: Process . kill ( 'TERM' , pid ) Procodile . log ( @process . log_color , description , \"Sent TERM signal to old PID #{old_process_pid} (forgetting now)\" ) :: Process . kill ( 'TERM' , old_process_pid )", "commit_type": "allow"}
{"commit_tokens": ["made", "logs", "rspec", "test", "better"], "add_tokens": "'Created' => now - ( duration * 3600 ) + 1 # Falls in time range 'Created' => now - ( duration * 3600 ) + 1 } , { 'Severity' => 'OK' , 'Message' => 'Third IEL Log' , 'Created' => now - ( duration * 3600 ) expect ( log_entries ) . to eq ( [ \"OK | First IEL Log | #{now - (duration * 3600) + 1}\" , \"OK | Second IEL Log | #{now - (duration * 3600) + 1}\" ] )", "del_tokens": "'Created' => now 'Created' => now expect ( log_entries ) . to eq ( [ \"OK | First IEL Log | #{now}\" , \"OK | Second IEL Log | #{now}\" ] )", "commit_type": "make"}
{"commit_tokens": ["Fix", "activation", "of", "main", "tabs", "."], "add_tokens": "headers = object . is_a? ( :: ActionController :: Response ) ? object . headers : object headers [ \"Ajax-Info\" ] = object . headers [ \"Ajax-Info\" ] || { } headers [ \"Ajax-Info\" ] [ key . to_s ] = value end def get_header ( object , key ) headers = object . is_a? ( :: ActionController :: Request ) ? object . headers : object if headers [ \"Ajax-Info\" ] . nil? headers [ \"Ajax-Info\" ] = if headers [ 'HTTP_AJAX_INFO' ] require 'json' headers [ 'Ajax-Info' ] = JSON . parse ( headers [ 'HTTP_AJAX_INFO' ] ) else { } end end headers [ 'Ajax-Info' ] [ key . to_s ]", "del_tokens": "object . headers [ \"Ajax-Info\" ] = object . headers [ \"Ajax-Info\" ] || { } object . headers [ \"Ajax-Info\" ] [ key . to_s ] = value", "commit_type": "fix"}
{"commit_tokens": ["Add", "matching", "methods", "to", "Configuration"], "add_tokens": "attr_reader :dataset_1 , :dataset_2 , :score_set , :match_set , :comparators if args . length < 3 || args . length > 4 raise ArgumentError , \"wrong number of arguments (#{args.length} for 3..4)\" if args . length > 3 && args [ 1 ] @score_set = args [ - 2 ] @match_set = args [ - 1 ] def matcher Matcher . new ( @score_set ) end def match_recorder MatchRecorder . new ( matcher , @match_set ) end", "del_tokens": "attr_reader :dataset_1 , :dataset_2 , :score_set , :comparators if args . length < 2 || args . length > 3 raise ArgumentError , \"wrong number of arguments (#{args.length} for 2 or 3)\" if args . length > 2 && args [ 1 ] @score_set = args . last", "commit_type": "add"}
{"commit_tokens": ["Add", "custom", "size", "/", "crop", "parameters", "to", "Photo#find", "."], "add_tokens": "# Get a photo. Can be cropped or resized using the optional parameters. # @param id [String] The ID of the photo to retrieve. # @param width [Integer] Width of customized version of the photo. # @param height [Integer] Height of the customized version of the photo. # @param crop_rect [String] A comma-separated list (x,y,width,height) of the rectangle to crop from the photo. # @return [Unsplash::Photo] The Unsplash Photo. def find ( id , width : nil , height : nil , crop_rect : nil ) custom = { w : width , h : height , rect : crop_rect } . delete_if { | k , v | ! v } photo = Unsplash :: Photo . new JSON . parse ( connection . get ( \"/photos/#{id}\" , custom ) . body )", "del_tokens": "# Get a user. # @param id [String] the ID of the photo to retrieve. # @return [Unsplash::Photo] the Unsplash Photo. def find ( id ) photo = Unsplash :: Photo . new JSON . parse ( connection . get ( \"/photos/#{id}\" ) . body )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "specs", "as", "of", "2016", "-", "08", "-", "18"], "add_tokens": "VERSION = '0.6.1' . freeze", "del_tokens": "VERSION = '0.6.0' . freeze", "commit_type": "update"}
{"commit_tokens": ["Added", "API", "Blueprints", "for", "API", "test", "mocking"], "add_tokens": "# TODO: Actuall create real tests! describe 'GET /aicc' do it 'should respond with information about the Lenovo XClarity Administrator' do response = 200 expect ( response ) . to eq ( 200 ) end end describe 'GET /aicc/network/ipdisable' do it 'should respond with the IPv6 and IPv6 addresses enablement state.' do response = 200 expect ( response ) . to eq ( 200 ) end", "del_tokens": "it 'does something useful' do expect ( false ) . to eq ( true )", "commit_type": "add"}
{"commit_tokens": ["added", "css", "and", "js", "master", "files"], "add_tokens": "app . config . assets . precompile += %w( lines/application.css lines/application.js lines/admin.css lines/admin.js )", "del_tokens": "app . config . assets . precompile += %w( lines/admin.css lines/admin.js )", "commit_type": "add"}
{"commit_tokens": ["Updated", "#move_above", "to", "work", "with", "attr_accessible", "."], "add_tokens": "unless sibling_of? ( other ) parent_id = other . parent_id save! end position = new_position save! position = new_position save!", "del_tokens": "update_attributes! ( :parent_id => other . parent_id ) unless sibling_of? ( other ) update_attributes! ( :position => new_position ) update_attributes! ( :position => new_position )", "commit_type": "update"}
{"commit_tokens": ["add", "ability", "and", "documentation", "from", "opening", "and", "reading", "files"], "add_tokens": "describe \"initialize\" do describe \"words\" do describe \"word_count\" do describe \"word_occurrences\" do describe \"most_occurring_words\" do describe 'word_lengths' do describe \"longest_words\" do describe \"word_density\" do describe \"char_count\" do describe \"average_chars_per_word\" do describe \"unique_word_count\" do describe \"from_file\" do it \"opens and reads a text file\" do counter = WordsCounted . from_file ( 'spec/support/the_hart_and_the_hunter.txt' ) expect ( counter . word_count ) . to eq ( 139 ) end end", "del_tokens": "describe \"#initialize\" do describe \".words\" do describe \".word_count\" do describe \".word_occurrences\" do describe \".most_occurring_words\" do describe '.word_lengths' do describe \".longest_words\" do describe \".word_density\" do describe \".char_count\" do describe \".average_chars_per_word\" do describe \".unique_word_count\" do", "commit_type": "add"}
{"commit_tokens": ["Add", ".", "use", "to", "allow", "for", "custom", "middleware", "."], "add_tokens": "# Apply a custom middleware to the API. Applies # to the current namespace and any children, but # not parents. # # @param middleware_class [Class] The class of the middleware you'd like to inject. def use ( middleware_class , * args ) settings_stack . last [ :middleware ] ||= [ ] settings_stack . last [ :middleware ] << [ middleware_class , * args ] end # Retrieve an array of the middleware classes # and arguments that are currently applied to the # application. def middleware settings_stack . inject ( [ ] ) { | a , s | a += s [ :middleware ] if s [ :middleware ] ; a } end middleware . each { | m | b . use * m }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "Crisis", "object", "that", "simulates", "a", "JSON", "object", "but", "allows", "additional", "the", "access", "of", "the", "fields", "with", "the", "help", "of", "methods", "."], "add_tokens": "# The used SSL certificate for the HTTPS connection require \"sigimera/data/crisis\"", "del_tokens": "# The used SSL certificate for the HTTPS encrpytion", "commit_type": "add"}
{"commit_tokens": ["add", "controller", "to", "handle", "all", "search", "analytic", "logging", "functionality", "in", "quicksearch"], "add_tokens": "# TODO: move this --- is this necessary?", "del_tokens": "def log_search if params [ :query ] . present? && params [ :page ] . present? Search . create ( query : params [ :query ] , page : params [ :page ] ) head :ok else head :bad_request end end def log_event if params [ :category ] . present? && params [ :event_action ] . present? && params [ :label ] . present? Event . create ( category : params [ :category ] , action : params [ :event_action ] , label : params [ :label ] [ 0 .. 250 ] ) if params [ :callback ] . present? head :ok , content_type : 'text/javascript' else head :ok end else head :bad_request end end", "commit_type": "add"}
{"commit_tokens": ["Moving", "helper", "enums", "into", "Misc", "for", "reuse", "."], "add_tokens": "# returns whether the \"copied from\" values are known def copyfrom_known? ( self [ :copyfrom_rev ] >= 0 ) end [ self [ :copyfrom_path ] , self [ :copyfrom_rev ] ] if copyfrom_known? h = { :action => action , :kind => kind } h . merge ( :copied_from => copied_from ) if copyfrom_known? h", "del_tokens": "extend FFI :: Library NodeKind = enum ( :none , :file , :dir , :unknown ) Actions = enum ( :added , 65 , :deleted , 68 , :replaced , 82 , :modified , 77 ) [ self [ :copyfrom_path ] , self [ :copyfrom_rev ] ] unless self [ :copyfrom_rev ] == - 1 { :action => action , :kind => kind , :copied_from => copied_from }", "commit_type": "move"}
{"commit_tokens": ["Fix", "rendering", "of", "octal", "hex", "IntLiterals", "."], "add_tokens": "case format when :dec \"#{val.to_s}#{suffix}\" when :hex \"0x#{val.to_s(16)}#{suffix}\" when :oct \"0#{val.to_s(8)}#{suffix}\" else raise \"invalid C::IntLiteral format: #{format}\" end", "del_tokens": "\"#{val}#{suffix}\"", "commit_type": "fix"}
{"commit_tokens": ["Remove", "response", "and", "add", "conversions", "to", "question", "."], "add_tokens": "require 'tty/prompt/converter_dsl' require 'tty/prompt/converters' include Converters @raw_input , @input = process_input ( @read ) def reader @prompt . reader end # Process input # # @api private def read_input if mask? && echo? reader . getc ( mask ) else reader . mode . echo ( echo ) do reader . mode . raw ( raw ) do if raw? reader . readpartial ( 10 ) elsif character? reader . getc ( mask ) else reader . gets end end end end end # Read input from STDIN and convert # # @param [Symbol] type # # @return [undefined] # # @api private def process_input ( type = nil ) input = read_input answer = if blank? ( input ) nil elsif ! type . nil? && converter_registry . key? ( type ) converter_registry . ( type , input ) elsif block_given? yield ( input ) else input end [ input , answer ] end", "del_tokens": "@raw_input , @input = Response . new ( self , @prompt . reader ) . read_type ( @read )", "commit_type": "remove"}
{"commit_tokens": ["Add", "missing", "message", "to", "rate", "limit", "error"], "add_tokens": "raise RateLimitError . new ( response . parsed_response ) , 'The request was rate limited'", "del_tokens": "raise RateLimitError . new ( response . parsed_response )", "commit_type": "add"}
{"commit_tokens": ["add", "index", "for", "tokens", "add", "boolean", "for", "choosing", "whether", "or", "not", "the", "middleware", "serves", "a", "file"], "add_tokens": "if attachment = Attach :: Attachment . where ( :serve => true ) . find_by_token ( $1 )", "del_tokens": "if attachment = Attach :: Attachment . find_by_token ( $1 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "rubocop", "Style", "/", "SpaceInsideParens", "cop"], "add_tokens": "@request . put ( [ user_id . to_s ] , { isVisitor : is_visitor , email : email , firstname : firstname , lastname : lastname } . merge ( options ) )", "del_tokens": "@request . put ( [ user_id . to_s ] , { isVisitor : is_visitor , email : email , firstname : firstname , lastname : lastname } . merge ( options ) )", "commit_type": "fix"}
{"commit_tokens": ["making", "use", "of", "destructuring", "syntax", "and", "using", "#fetch", "as", "suggested", "on", "avdi", "s", "rubytapas"], "add_tokens": "@relations [ relation ] = @relations . fetch ( relation , [ ] ) << item @relations . each_with_object ( { } ) do | ( rel , val ) , obj | rel = rel . to_s val = val . length == 1 ? val . first . to_hash : val . map ( & :to_hash ) obj [ rel ] = val end", "del_tokens": "@relations [ relation ] = @relations [ relation ] . to_a << item @relations . each_with_object ( { } ) do | pair , obj | key , * value = pair . flatten key = key . to_s obj [ key ] = value . map & :to_hash obj [ key ] . length == 1 and obj [ key ] = obj [ key ] . first end", "commit_type": "make"}
{"commit_tokens": ["Added", "/", "Edited", "a", "few", "options"], "add_tokens": "options . output = File . join ( default_output , options . site ) \"Directory to save the wallpapers. Default:\" + File . join ( default_output , 'SITE' ) . to_s ) do | o | raise \"Output not an directory\" unless ! o || Dir . exists? ( o ) opts . on ( v [ :cmd ] , v [ :long_cmd ] , v [ :desc ] + \"\\tDefault: \" + v [ :default ] . to_s ) do | p | options . params [ k ] = p options . output = File . join ( default_output , options . site )", "del_tokens": "\"Directory to save the wallpapers. Default: #{default_output}\" ) do | o | raise \"Output not an directory\" unless ! o || File . directory? ( o ) opts . on ( v [ :cmd ] , v [ :long_cmd ] , v [ :desc ] + \"\\tDefault: \" + v [ :default ] . to_s ) do options . params [ k ] = true options . output = default_output", "commit_type": "add"}
{"commit_tokens": ["Adding", "user", "and", "completing", "the", "base", "Object", "class"], "add_tokens": "attr_reader :access_token @access_token = access_token . refresh! self . class . default_params :access_token => @access_token . token @access_token", "del_tokens": "attr_accessor :access_token access_token . refresh!", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "that", "the", "proxy", "supports", "method", "calls", "that", "take", "a", "block"], "add_tokens": "def method_missing ( method , * args , & block ) @target . with_replica_block ( @replica ) { @target . send ( method , * args , & block ) }", "del_tokens": "def method_missing ( method , * args ) @target . with_replica_block ( @replica ) { @target . send ( method , * args ) }", "commit_type": "make"}
{"commit_tokens": ["Added", "extract", "numeric", "functions", "to", "hash_path_proc", "."], "add_tokens": "extract_integers : { aliases : [ :extract_ints ] } , extract_floats : { aliases : [ ] } , extract_numbers : { aliases : [ ] } , def self . extract_integers hash , path , value , args , ** params hash . hash_path_set path => ( value . extract_integers ) end def self . extract_floats hash , path , value , args , ** params hash . hash_path_set path => ( value . extract_floats ) end def self . extract_numbers hash , path , value , args , ** params hash . hash_path_set path => ( value . extract_numbers ) end", "del_tokens": "# extract_ints: {aliases: []}, # extract_floats: {aliases: []}, # extract_numbers: {aliases: []},", "commit_type": "add"}
{"commit_tokens": ["Use", "Array#extract_options", "to", "remove", "the", "hash", "options", "from", "the", "args", "in", "the", "audit", "sweeper"], "add_tokens": "options = models . extract_options!", "del_tokens": "options = models . last . is_a? ( Hash ) ? models . pop : { }", "commit_type": "use"}
{"commit_tokens": ["Fix", "namespace", "expectations", "in", "Salmon", "parsing"], "add_tokens": "raise OStatus2 :: BadSalmonError if xml . at_xpath ( '//me:data' , me : XMLNS ) . nil? || xml . at_xpath ( '//me:data' , me : XMLNS ) . attribute ( 'type' ) . nil? || xml . at_xpath ( '//me:sig' , me : XMLNS ) . nil? || xml . at_xpath ( '//me:encoding' , me : XMLNS ) . nil? || xml . at_xpath ( '//me:alg' , me : XMLNS ) . nil? data = xml . at_xpath ( '//me:data' , me : XMLNS ) sig = xml . at_xpath ( '//me:sig' , me : XMLNS ) encoding = xml . at_xpath ( '//me:encoding' , me : XMLNS ) . content alg = xml . at_xpath ( '//me:alg' , me : XMLNS ) . content", "del_tokens": "raise OStatus2 :: BadSalmonError if xml . at_xpath ( '//me:data' ) . nil? || xml . at_xpath ( '//me:data' ) . attribute ( 'type' ) . nil? || xml . at_xpath ( '//me:sig' ) . nil? || xml . at_xpath ( '//me:encoding' ) . nil? || xml . at_xpath ( '//me:alg' ) . nil? data = xml . at_xpath ( '//me:data' ) sig = xml . at_xpath ( '//me:sig' ) encoding = xml . at_xpath ( '//me:encoding' ) . content alg = xml . at_xpath ( '//me:alg' ) . content", "commit_type": "fix"}
{"commit_tokens": ["adding", "yard", "doc", "for", "all", "the", "things"], "add_tokens": "# a new instance of Biffbot::Bulk # # @param token [String] Override Biffbot.token with another token # create a bulk job # # @param name [String] Desired name for bulk job # @param api_type [String] Desired API to use for urls # @param urls [Array] An array of input urls to pass to bulk job # @param options [Hash] An hash of options # @return [Hash] # generate the POST body required for bulk job creation # # @param name [String] Desired name for bulk job # @param api_url [String] Desired API url to use for urls # @param urls [Array] An array of input urls to pass to bulk job # @param options [Hash] An hash of options # @return [Hash] # Using define_method to create methods for each action rather than defining each method seperately. end # retrieve data per given jobName # # @param jobName [String] Name of bulk job # @param _options [Hash] An hash of options # @return [Hash]", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Fixed", "TableData", "::", "Table#fetch_cell", "."], "add_tokens": "def fetch_cell ( row , column , * default_value , & default_block ) raise ArgumentError , \"Must only provide at max one default value or one default block\" if default_value . size > ( block_given? ? 0 : 1 ) row_data . fetch ( column , * default_value , & default_block ) elsif default_value . empty? default_value . first", "del_tokens": "def fetch_cell ( row , column , * default ) raise ArgumentError , \"Must only provide at max one default value or one default block\" if default . size > ( block_given? ? 0 : 1 ) row_data . fetch ( column ) elsif default . empty? default . first", "commit_type": "fix"}
{"commit_tokens": ["added", "files", "to", "separate", "resource", "requests"], "add_tokens": "require 'fitgem_oauth2/activity.rb' require 'fitgem_oauth2/sleep.rb' require 'fitgem_oauth2/steps.rb' def get_call ( url ) response = connection . get do | request | response", "del_tokens": "def activities_on_date ( date ) connection . get \"1/user/#{user_id}/activities/date/#{format_date(date)}.json\" do | request |", "commit_type": "add"}
{"commit_tokens": ["Fixing", "a", "bug", "(", "thanks", "to", "Justin", "Rhodes!", ")", "."], "add_tokens": "self . lights [ light_id . to_i - 1 ]", "del_tokens": "@lights [ light_id . to_i - 1 ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "--", "force", "to", "gem", ":", "bump"], "add_tokens": "on ( '-p' , '--persist' , 'Commit tag and push the changes' ) do | p | options [ :persist ] = true end on ( '-f' , '--force' , 'Act even if the git repo is not clean' ) do | f | options [ :force ] = true if clean? || force? git . pull else fail Anvil :: RepoNotClean end def force? options [ :force ] end", "del_tokens": "on ( '-p' , '--[no-]persist' , 'Commit tag and push the changes' ) do | p | options [ :persist ] = p fail Anvil :: RepoNotClean unless clean? git . pull", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "specify", "additional", "dependencies", "."], "add_tokens": "#{dependencies(config.dependencies).map{|d| \"-d '#{d}'\"}.join(\" \")} \\ def dependencies ( other_dependencies = nil ) other_dependencies ||= [ ] deps [ \"default\" ] | deps [ version ] | other_dependencies", "del_tokens": "#{dependencies.map{|d| \"-d '#{d}'\"}.join(\" \")} \\ def dependencies deps [ \"default\" ] | deps [ version ]", "commit_type": "allow"}
{"commit_tokens": ["Added", "basic", "alarm", "framework", "and", "added", "alarms", "for", "tracker", "problems"], "add_tokens": "require \"quartz_torrent/alarm.rb\" @alarms = Alarms . new # Alarms object for this torrent attr_reader :alarms # Array of currently raised alarms attr_accessor :alarms @alarms = torrentData . alarms . all trackerclient . alarms = torrentData . alarms", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "steps", "to", "update", "expenses"], "add_tokens": "Then 'there should be an expense \"$1\" on \"$2\"' do | notes , date | expense = expenses . detect { | e | e . notes == notes } Then 'there should not be an expense \"$1\" on \"$2\"' do | notes , date | expense = expenses . detect { | e | e . notes == notes } When 'I delete the expense \"$1\" on \"$2\"' do | notes , date | expense = Then %Q{there should be an expense \"#{notes}\" on \"#{date}\"} end Then 'the expense \"$1\" on \"$2\" should have the following attributes:' do | notes , date , table | expense = Then %Q{there should be an expense \"#{notes}\" on \"#{date}\"} table . rows_hash . each do | key , value | expense . send ( key ) . to_s . should == value end end When 'I update the expense \"$1\" on \"$2\" with the following:' do | notes , date , table | expense = Then %Q{there should be an expense \"#{notes}\" on \"#{date}\"} expense . attributes = table . rows_hash harvest_api . expenses . update ( expense ) end", "del_tokens": "Then 'there should be an expense \"$1\" on \"$2\"' do | expense_notes , date | expense = expenses . detect { | e | e . notes == expense_notes } Then 'there should not be an expense \"$1\" on \"$2\"' do | expense_notes , date | expense = expenses . detect { | e | e . notes == expense_notes } When 'I delete the expense \"$1\" on \"$2\"' do | expense_notes , date | expense = Then %Q{there should be an expense \"#{expense_notes}\" on \"#{date}\"} end", "commit_type": "add"}
{"commit_tokens": ["Adds", "multiple", "expression", "support", "to", "queries", "."], "add_tokens": "# Invokes BibTeX string replacement on this element. def replace ( * arguments ) ; self ; end # Invokes BibTeX string joining on this element. def join ; self ; end when / @( \\w +)(?: \\[ ([^ \\] ]*) \\] )? / query . scan ( / @( \\w +)(?: \\[ ([^ \\] ]*) \\] )? / ) . any? do | type , condition | has_type? ( type ) && ( condition . nil? || meets? ( condition . split ( / , \\s * / ) ) ) end def meets? ( * conditions ) conditions . flatten . all? do | condition |", "del_tokens": "when / ^@( \\w +)$ / has_type? ( $1 ) when / ^@( \\w +) \\[ ([^ \\] ]*) \\] $ / has_type? ( $1 ) && meets? ( $2 . split ( / , \\s * / ) ) def meets? ( conditions ) [ conditions ] . flatten . all? do | condition |", "commit_type": "add"}
{"commit_tokens": ["updated", "lazy_load", "to", "reflect", "new", "name"], "add_tokens": "def adjust ( attributes = { } , preload = true ) lazy_load if preload && query . conditions . detect { | c | adjust_attributes . include? ( c [ 1 ] ) } repository . adjust ( adjust_attributes , scoped_query ) # Should probably loop through this beforehand to find out if we should load. Will lower # performance. when Numeric then c [ 2 ] += adjustment when Range then c [ 2 ] = ( c [ 2 ] . first + adjustment ) .. ( c [ 2 ] . last + adjustment ) return true", "del_tokens": "def adjust ( attributes = { } , load = true ) lazy_load! if load && query . conditions . detect { | c | adjust_attributes . include? ( c [ 1 ] ) } affected = repository . adjust ( adjust_attributes , scoped_query ) when Numeric then c [ 2 ] += adjustment when Range then c [ 2 ] = ( c [ 2 ] . first + adjustment ) .. ( c [ 2 ] . last + adjustment ) return affected", "commit_type": "update"}
{"commit_tokens": ["Updated", "README", "/", "CHANGELOG", ".", "Added", "diagnostics", "to", "see", "why", "AES", "/", "GCM", "is", "failing", "in", "Travis", "CI", "."], "add_tokens": "puts \"OpenSSL::OPENSSL_VERSION = #{OpenSSL::OPENSSL_VERSION}\" cipher . auth_data = parts . take ( 3 ) . join ( '.' )", "del_tokens": "cipher . auth_data = parts . take ( 3 ) . join ( '.' )", "commit_type": "update"}
{"commit_tokens": ["Fix", "invoking", "bin", "/", "lilypond", "with", "multiple", "arguments"], "add_tokens": "Kernel . exec ( lilypond , * argv )", "del_tokens": "Kernel . exec ( lilypond , argv . join ( ' ' ) )", "commit_type": "fix"}
{"commit_tokens": ["remove", "#", "char", "from", "output", "files"], "add_tokens": "f . write ( \"generalization error for tree #{te}: #{forest.tree_errors[te-1].round(5)}\\n\" ) f . write ( \"SNP #{p[0]}: #{p[1].round(5)}\\n\" )", "del_tokens": "f . write ( \"generalization error for tree ##{te}: #{forest.tree_errors[te-1].round(5)}\\n\" ) f . write ( \"SNP ##{p[0]}: #{p[1].round(5)}\\n\" )", "commit_type": "remove"}
{"commit_tokens": ["Added", "class", "method", "to", "sort", "nodes", "by", "ancestry", "."], "add_tokens": "arrange_nodes scope . all ( options ) end # Arrange array of nodes into a nested hash of the form # {node => children}, where children = {} if the node has no children def arrange_nodes ( nodes ) # Get all nodes ordered by ancestry and start sorting them into an empty hash nodes . inject ( ActiveSupport :: OrderedHash . new ) do | arranged_nodes , node | end insertion_point end [ node ] = ActiveSupport :: OrderedHash . new arranged_nodes end end # Pseudo-preordered array of nodes. Children will always follow parents, # but the ordering of nodes within a rank depends on their order in the # array that gets passed in def sort_by_ancestry ( nodes ) arranged = nodes . is_a? ( Hash ) ? nodes : arrange_nodes ( nodes . sort_by { | n | n . ancestry || '0' } ) arranged . inject ( [ ] ) do | sorted_nodes , pair | node , children = pair sorted_nodes << node sorted_nodes += sort_by_ancestry ( children ) unless children . blank? sorted_nodes end", "del_tokens": "scope . all ( options ) . inject ( ActiveSupport :: OrderedHash . new ) do | arranged_nodes , node | end ; insertion_point end [ node ] = ActiveSupport :: OrderedHash . new ; arranged_nodes end", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "make", "row", "options", "hash", "optional"], "add_tokens": "def initialize ( row , rownum , options = { } )", "del_tokens": "def initialize ( row , rownum , options )", "commit_type": "fix"}
{"commit_tokens": ["change", "the", "way", "to", "check", "state_file", "is", "valid", "directory", "or", "file", "update", "test", "case", "accordingly"], "add_tokens": "@default_state_file_path = \" default_state_file_\" + @state_tag + \".yaml\" if File . directory? ( @path ) # create a new state file in the provided directory # when recover from failure will also try to read from this file @path = @path + \"/\" + @state_tag + \".yaml\" puts \"provided path is valid derectory, created a new file on #{@path.inspect}\" else # not a directory, then check if it's a valid file if File . exist? ( @path ) @data = YAML . load_file ( @path ) if @data == false || @data == [ ] # this happens if an users created an empty file accidentally puts \"state file on #{@path.inspect} is empty \" @data = { } elsif ! @data . is_a? ( Hash ) # if the file contains invalid data, that is not a hash raise \"state file on #{@path.inspect} contains invalid data, please use other file\" end else raise \"#{@path.inspect} is not a valid directory or the file not exists, please provide valid state file path\" end", "del_tokens": "if File . exists? ( @path ) @data = YAML . load_file ( @path ) if @data == false || @data == [ ] # this happens if an users created an empty file accidentally puts \"state_file on #{@path.inspect} is empty \" @data = { } elsif ! @data . is_a? ( Hash ) # if the file contains invalid data, that is not a hash puts \"state_file data on #{@path.inspect} is invalid\" # don't want to over write the data in original file # create a new file on default path when update_records @path = \"test/default_state_file_\" + @state_tag + \".yaml\" puts \"will use default state_file path #{@path.inspect}\" else # if the file is not exist, just create an empty hash puts \"state_file on #{@path.inspect} not exists\" @data = { } end", "commit_type": "change"}
{"commit_tokens": ["Add", "developer", "and", "container_id", "options", "for", "comment", "threads", "."], "add_tokens": ":developer => false , :container_id => 'disqus_thread' , end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "and", "add", "optional", "Saved", "Searches", "feature"], "add_tokens": "require 'ransack_advanced_search/engine' require 'ransack_advanced_search/version' require 'ransack_advanced_search/helpers/configuration' extend Configuration define_setting :enable_saved_searches , false", "del_tokens": "require 'ransack_advanced_search/engine'", "commit_type": "update"}
{"commit_tokens": ["add", "a", "test", "for", "Decorator", "and", "URL", "helpers", "."], "add_tokens": "config . representer . default_url_options = { :host => \"roar.apotomo.de\" }", "del_tokens": "config . representer . default_url_options = { :host => \"http://roar.apotomo.de\" }", "commit_type": "add"}
{"commit_tokens": ["Allow", "user", "to", "override", "#output_strategy", "and", "choose", "array", "live", "or", "console_log"], "add_tokens": "# You can also override #output_strategy to provide your own logic for # when the real KISSmetrics API, console.log fake, and array fake should be used. # The console_log output strategy outputs all events to the console (if the console is defined). # The array output strategy simply logs all events in the _kmq variable. # The live output strategy sends calls to the async KISSmetrics JS API. # # The default implementation outputs the real API only when # `Rails.env.production?` is true, and otherwise uses console.log @km_api ||= KissmetricsApi . new ( kissmetrics_api_key , session , output_strategy ) # Override this method to set the output strategy. # Available return values: # # :console_log use console.log to display events pushed to KISSmetrics # :array store events pushed to KISSmetrics on _kmq # :live send events to KISSmetrics via the async JS API def output_strategy if use_fake_kissmetrics_api? :console_log else :live end end # Deprecated: Prefer overriding #output_strategy to control the output strategy. # def initialize ( api_key , session , output_strategy ) @session = session @api_key = api_key @output_strategy = output_strategy # that sends events to the console or a global array if the `output_strategy` # parameter to #initialize is :console_log or :array), as well as statements # that push the current state onto the `_kmq` array. if @output_strategy == :console_log elsif @output_strategy == :live elsif @output_strategy == :array \"\" else raise \"Unknown KISSmetrics output strategy: #{@output_strategy}\"", "del_tokens": "# You can also override #use_fake_kissmetrics_api? to provide your own logic for # when the real KISSmetrics API and when the fake should be used. The fake API # simply outputs all events to the console (if the console is defined). The # the default implementation outputs the real API only when # `Rails.env.production?` is true. @km_api ||= KissmetricsApi . new ( kissmetrics_api_key , session , use_fake_kissmetrics_api? ) def initialize ( api_key , session , fake_it ) @session = session @api_key = api_key @fake_it = fake_it # that sends events to the console if the `fake_it` parameter to #initialize # is true), as well as statements that push the current state onto the # `_kmq` array. if @fake_it else", "commit_type": "allow"}
{"commit_tokens": ["added", "new", "kind", "of", "view", "helpers"], "add_tokens": "require 'gravatarify/helpers/rails' ActionView :: Base . send ( :include , Gravatarify :: Helpers :: Rails )", "del_tokens": "require 'gravatarify/view_helper' ActionView :: Base . send ( :include , Gravatarify :: ViewHelper )", "commit_type": "add"}
{"commit_tokens": ["Use", "WatirSpec", ".", "new_browser", "instead", "of", "Browser", ".", "new"], "add_tokens": "browser = WatirSpec . new_browser", "del_tokens": "browser = Browser . new ( * WatirSpec . browser_args )", "commit_type": "use"}
{"commit_tokens": ["added", "homebrew", "specific", "library", "paths", "for", "mac", "os"], "add_tokens": "'/opt/local/lib/proj49/lib/libproj.12.dylib' , # Macports Proj 5 '/opt/local/lib/libproj.15.dylib' , # mac homebrew mac Proj 6 '/opt/local/lib/libproj.13.dylib' , # mac howbrew Proj 5 '/opt/local/lib/libproj.12.dylib' # mac howbrew Proj 5 ]", "del_tokens": "'/opt/local/lib/proj49/lib/libproj.12.dylib' ] # Macports Proj 5", "commit_type": "add"}
{"commit_tokens": ["Implemented", "the", "getting", "of", "rack", "session", "data", "."], "add_tokens": "case File . extname ( request . path ) when \".raw\" render do | xml | xml . h2 \"Raw rack session data\" xml . pre RackSessionAccess . encode ( request . env [ @key ] . to_hash ) else render do | xml | xml . h2 \"Rack session data\" xml . ul do | xml | request . env [ @key ] . each do | k , v | xml . li ( \"#{k.inspect} : #{v.inspect}\" ) end end xml . p do | xml | xml . a ( \"Edit\" , :href => action_path ( :edit ) ) end path = request . path . sub ( / \\. \\w +$ / , '' )", "del_tokens": "render do | xml | xml . h2 \"Rack session data\" xml . ul do | xml | request . env [ @key ] . each do | k , v | xml . li ( \"#{k.inspect} : #{v.inspect}\" ) end xml . p do | xml | xml . a ( \"Edit\" , :href => action_path ( :edit ) ) path = request . path", "commit_type": "implement"}
{"commit_tokens": ["Remove", "notification", "wrapper", ";", "better", "docs"], "add_tokens": "Chatterbox . expects ( :publish_notice ) . with ( \"message\" ) Chatterbox . handle_notice ( \"message\" )", "del_tokens": "it \"should create Notification and return the notice\" do notification = mock ( :notice => { :hash => 'of awesomeness' } ) Chatterbox :: Notification . expects ( :new ) . returns ( notification ) handle_notice ( \"message\" ) end notification = stub ( :notice => { :hash => 'of awesomeness' } ) Chatterbox :: Notification . stubs ( :new ) . returns ( notification ) expects ( :publish_notice ) . with ( { :hash => 'of awesomeness' } ) handle_notice ( \"message\" )", "commit_type": "remove"}
{"commit_tokens": ["Adds", "spec", "for", "html", "safety"], "add_tokens": "@disabled = options . fetch ( :disabled ) { false } @visible = options . fetch ( :visible ) { true } @current = options . fetch ( :current ) { false } @i18n_key = options . fetch ( :i18n_key ) { 'helmsman.helm.fallback' }", "del_tokens": "@disabled = options . fetch ( :disabled ) @visible = options . fetch ( :visible ) @current = options . fetch ( :current ) @i18n_key = options . fetch ( :i18n_key )", "commit_type": "add"}
{"commit_tokens": ["Add", "acquired_with", "and", "include", "tests"], "add_tokens": "extra_fields = self . acquired_with ( ) # #acquire_in. See those methods for more details. # # Fields will be searched in the order listed. If duplicate items are # present, the first occurrence is kept and the rest are removed. # See also: #acquired_with # self . nz_co_loyalty_hoodoo_show_id_fields = args . map ( & :to_s ) . uniq! ( ) end # Return the list of model fields _in_ _addition_ _to_ +id+ which # are being used to \"find-by-identifier\" through calls to #acquire # and #acquire_in. # # See also: #acquire_with # def acquired_with self . nz_co_loyalty_hoodoo_show_id_fields || [ ]", "del_tokens": "extra_fields = self . nz_co_loyalty_hoodoo_show_id_fields || [ ] # #acquire_in. See those for more details. self . nz_co_loyalty_hoodoo_show_id_fields = args", "commit_type": "add"}
{"commit_tokens": ["allow", "single", "imsi", "as", "string"], "add_tokens": "imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array imsis = [ imsis ] if imsis . class != Array", "del_tokens": "imsis = [ imsis ] if imsis . class == String", "commit_type": "allow"}
{"commit_tokens": ["Fix", "pagination", "for", "fetching", "remote", "objects"], "add_tokens": "api . paginate ( resource_name , api_request_options ) . tap do", "del_tokens": "api . get ( resource_name , api_request_options ) . tap do", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "condition", "for", "aliasing", "acts_as_tree", "."], "add_tokens": "if ! defined? ( ActsAsTree )", "del_tokens": "if ! respond_to? ( :acts_as_tree )", "commit_type": "change"}
{"commit_tokens": ["use", "micron", "and", "easycov", "libs"], "add_tokens": "require 'micron/minitest' require \"sample_handler\" EasyCov . path = \"coverage\" EasyCov . filters << EasyCov :: IGNORE_GEMS << EasyCov :: IGNORE_STDLIB EasyCov . start", "del_tokens": "TestGuard . load_simplecov ( ) require \"test_handler\" MiniTest :: Unit . autorun", "commit_type": "use"}
{"commit_tokens": ["Moving", "examples", "to", "separate", "repo"], "add_tokens": "puts \"a key\" end on key_down : 'p' do puts \"p key down\"", "del_tokens": "puts \"a pressed!\"", "commit_type": "move"}
{"commit_tokens": ["Updating", "README", "to", "show", "example", "of", "including", "ProMotion", "as", "a", "module"], "add_tokens": "self . view_did_disappear ( animated ) if self . respond_to? ( \"view_did_disappear:\" )", "del_tokens": "if self . respond_to? ( \"view_did_disappear:\" ) self . view_did_disappear ( animated ) end", "commit_type": "update"}
{"commit_tokens": ["Made", "Term", "accept", "any", "object", "as", "text", "and", "covert", "it", "to", "a", "string", "."], "add_tokens": "@text = txt . to_s def text = ( text ) @text = text . to_s end", "del_tokens": "@text = txt", "commit_type": "make"}
{"commit_tokens": ["Add", "large", "file", "timeout", "handling"], "add_tokens": "VERSION = '0.4.11'", "del_tokens": "VERSION = '0.4.10'", "commit_type": "add"}
{"commit_tokens": ["Add", "form", "tag", "helpers", "."], "add_tokens": "require \"bootstrap-rails-helpers\"", "del_tokens": "require \"bootstrap-rails-helpers\"", "commit_type": "add"}
{"commit_tokens": ["remove", "need", "for", "api", "keys", "in", "specs"], "add_tokens": ":mailgun_api_key => 'foo' ,", "del_tokens": ":mailgun_api_key => credentials [ :mailgun_api_key ] ,", "commit_type": "remove"}
{"commit_tokens": ["Improve", "documentation", "around", "raised", "errors", "."], "add_tokens": "raise SendWithUs :: ApiInvalidKey , \"Invalid api key: #{@configuration.api_key}\" raise SendWithUs :: ApiBadRequest , \"Bad request: \\\"#{path}\\\" with payload \\\"#{payload}\\\"\"", "del_tokens": "raise SendWithUs :: ApiInvalidKey , 'Invalid api key: ' + @configuration . api_key raise SendWithUs :: ApiBadRequest , @response . body", "commit_type": "improve"}
{"commit_tokens": ["Added", "interrupt", "trap", "and", "rescue", "blocks"], "add_tokens": "puts 'Starting domain, projection and Rails server...' puts '=> Ctrl-C to shutdown all servers' env = { 'ROOT_DIR' => ROOT_DIR } pids = [ ] pids << Process . spawn ( env , \"ruby #{File.expand_path '../server', __FILE__}/domain_server.rb\" ) pids << Process . spawn ( env , \"ruby #{File.expand_path '../server', __FILE__}/projection_servers.rb\" ) pids << Process . spawn ( env , 'rails s' ) trap ( :INT ) do pids . each do | pid | begin Process . kill 9 , pid rescue Exception # do nothing end end exit end Process . waitall", "del_tokens": "puts 'Domain and Projection Server started' puts '=> Ctrl-C to shutdown both server' trap ( :INT ) { exit } Process . spawn ( { \"ROOT_DIR\" => ROOT_DIR } , \"ruby #{File.expand_path '../server', __FILE__}/domain_server.rb\" ) Process . spawn ( { \"ROOT_DIR\" => ROOT_DIR } , \"ruby #{File.expand_path '../server', __FILE__}/projection_servers.rb\" ) Process . spawn ( { \"ROOT_DIR\" => ROOT_DIR } , \"rails s\" ) Process . waitall", "commit_type": "add"}
{"commit_tokens": ["Make", "spec", "output", "a", "little", "less", "verbose"], "add_tokens": "save , @verbose = @verbose , false @adapter . storage_exists? ( 'migration_info' )", "del_tokens": "save , @verbose = @verbose , true # false adapter . storage_exists? ( 'migration_info' )", "commit_type": "make"}
{"commit_tokens": ["Added", "some", "basic", "documentation", "to", "OData", "::", "Service", ".", "[", "ci", "skip", "]"], "add_tokens": "attr_reader :service_url # :nodoc: def initialize ( service_url ) # :nodoc: # Opens the service based on the requested URL # @param service_url [String] the URL to the desired OData service # @return [OData::Service] an instance of the service def entities # :nodoc: def complex_types # :nodoc: def namespace # :nodoc: def inspect # :nodoc: # Handles getting OData resources from the service. # @param model [OData::Model] the type of resource being requested # @param criteria [Hash] any criteria to narrow the request # @return [Array] instances of the requested model", "del_tokens": "attr_reader :service_url def initialize ( service_url ) def entities def complex_types def namespace def inspect", "commit_type": "add"}
{"commit_tokens": ["Make", "source", "map", "environments", "configurable"], "add_tokens": "if Rails . config . browserify_rails . source_map_environments . include? ( Rails . env )", "del_tokens": "# Only generate source maps in development if Rails . env == \"development\"", "commit_type": "make"}
{"commit_tokens": ["implementing", "{", "Playlist", "User", "}", "::", "search"], "add_tokens": "def self . search ( * args ) warn 'Spotify API does not support search for playlists' false", "del_tokens": "def self . search #TODO", "commit_type": "implement"}
{"commit_tokens": ["fix", "examples", "/", "all", ".", "rb"], "add_tokens": "require \"numo/gnuplot\"", "del_tokens": "#require \"numo/gnuplot\" require \"../lib/numo/gnuplot\"", "commit_type": "fix"}
{"commit_tokens": ["fixed", ":", "cleaning", "*", ".", "css", ".", "erb", "files", "before", "precompilation"], "add_tokens": "@tasks << [ 'bower:install' , 'bower:resolve' ] if @resolve_before_precompile", "del_tokens": "@tasks << [ 'bower:install' , 'bower:resolve' ] if @resolve_before_precompile", "commit_type": "fix"}
{"commit_tokens": ["Updated", "models", ".", "rb", "and", "index", ".", "js", "to", "make", "them", "more", "clear", "as", "well", "as", "moving", "the", "Ruby", "versions", "of", "the", "models", "so", "they", "won", "t", "be", "post", "-", "processed", "."], "add_tokens": "model_template = File . read ( 'templates/models_template.rb.erb' ) renderer = ERB . new ( model_template , nil , '-' ) file_path = 'app/models/models.rb' File . open ( file_path , 'w' ) { | file | file . puts renderer . result ( binding ) }", "del_tokens": "require_file = File . new ( 'app/models/models.rb' , 'w' ) require_file . puts '# Base QDM module (generated from lib/generate_models.rb) for QDM ' + qdm_version require_file . puts 'module QDM' require_file . puts 'end' require_file . puts \"require 'mongoid'\" require_file . puts \"require_relative 'qdm/basetypes/code'\" require_file . puts \"require_relative 'qdm/basetypes/interval'\" require_file . puts \"require_relative 'qdm/basetypes/quantity'\" require_file . puts \"require_relative 'qdm/basetypes/data_element'\" datatypes . each_key do | datatype | require_file . puts \"require_relative 'qdm/#{datatype.underscore}'\" end require_file . close file_path = 'tmp/' if IS_TEST", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "bug", "lighten", "up", "on", "argument", "types", "."], "add_tokens": "@connection . send ( :send_command , \"AUTHENTICATE XOAUTH #{Array(args[:xoauth]).join(' ')}\" )", "del_tokens": "@connection . authenticate ( 'XOAUTH' , * Array ( args [ :xoauth ] ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "spec", "to", "mark", "Element#visible?", "as", "non", "-", "compliant"], "add_tokens": "not_compliant_on :watir_nokogiri do it \"returns true if the element is visible\" do browser . text_field ( :id , \"new_user_email\" ) . should be_visible end it \"returns true if the element has style='visibility: visible' even if parent has style='visibility: hidden'\" do browser . div ( :id => \"visible_child\" ) . should be_visible end it \"returns false if the element is input element where type == 'hidden'\" do browser . hidden ( :id , \"new_user_interests_dolls\" ) . should_not be_visible end it \"returns false if the element has style='display: none;'\" do browser . div ( :id , 'changed_language' ) . should_not be_visible end it \"returns false if the element has style='visibility: hidden;\" do browser . div ( :id , 'wants_newsletter' ) . should_not be_visible end it \"returns false if one of the parent elements is hidden\" do browser . div ( :id , 'hidden_parent' ) . should_not be_visible end", "del_tokens": "it \"returns true if the element is visible\" do browser . text_field ( :id , \"new_user_email\" ) . should be_visible end it \"returns true if the element has style='visibility: visible' even if parent has style='visibility: hidden'\" do browser . div ( :id => \"visible_child\" ) . should be_visible end it \"returns false if the element is input element where type == 'hidden'\" do browser . hidden ( :id , \"new_user_interests_dolls\" ) . should_not be_visible end it \"returns false if the element has style='display: none;'\" do browser . div ( :id , 'changed_language' ) . should_not be_visible end it \"returns false if the element has style='visibility: hidden;\" do browser . div ( :id , 'wants_newsletter' ) . should_not be_visible end it \"returns false if one of the parent elements is hidden\" do browser . div ( :id , 'hidden_parent' ) . should_not be_visible", "commit_type": "update"}
{"commit_tokens": ["make", "translate", "handle", "default", "keys", "and", "arrays"], "add_tokens": "end options . delete ( :default ) entry = lookup ( locale , * keys . compact ) || default_to ( locale , default , options ) def default_to ( locale , default , options ) case default when String default when Symbol translate ( default , locale , options ) when Array default . detect { | default | default_to ( locale , default , options ) } end end", "del_tokens": "end entry = lookup ( locale , * keys . compact ) || default def translate_first ( keys , locale , options = { } ) keys . each do | key | result = translate key , locale , options return result if result end nil end", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "basic", "setup", "for", "dbs"], "add_tokens": "ROOT = File . expand_path ( '../..' , __FILE__ ) CONFIG = YAML . load_file ( \"#{ROOT}/config/database.yml\" ) CONFIG . each do | name , uri | DataMapper . setup ( name , uri ) DATABASE_ADAPTER = DataMapper . adapters [ :postgres ] connection = DataObjects :: Connection . new ( CONFIG [ 'postgres' ] ) connection = DataObjects :: Connection . new ( CONFIG [ 'postgres' ] ) connection ||= DataObjects :: Connection . new ( CONFIG [ 'postgres' ] ) connection ||= DataObjects :: Connection . new ( CONFIG [ 'postgres' ] ) # require spec support files and shared behavior Dir [ File . expand_path ( '../**/shared/**/*.rb' , __FILE__ ) ] . each { | file | require file }", "del_tokens": "# require spec support files and shared behavior Dir [ File . expand_path ( '../**/shared/**/*.rb' , __FILE__ ) ] . each { | file | require file } RSpec . configure do | config | # noop for now DATABASE_URI = 'postgres://localhost/test' . freeze # DATABASE_URI = 'mysql:/ocalhost/test'.freeze # DATABASE_URI = 'sqlite3://tmp/test.db'.freeze DATABASE_ADAPTER = Veritas :: Adapter :: DataObjects . new ( DATABASE_URI ) connection = DataObjects :: Connection . new ( DATABASE_URI ) connection = DataObjects :: Connection . new ( DATABASE_URI ) connection ||= DataObjects :: Connection . new ( DATABASE_URI ) connection ||= DataObjects :: Connection . new ( DATABASE_URI )", "commit_type": "add"}
{"commit_tokens": ["Moved", "close_connection", "out", "of", "private", "as", "people", "might", "need", "it", "to", "wrap", "connections", "in", "their", "own", "methods"], "add_tokens": "@connection = TCPSocket . new ( attributes [ :server ] , attributes [ :port ] ) @socket = OpenSSL :: SSL :: SSLSocket . new ( @connection ) private", "del_tokens": "@connection = open_connection ( attributes [ :server ] , attributes [ :port ] ) @socket = open_socket ( @connection ) private # Opens a connection to the EPP server. def open_connection ( server , port ) TCPSocket . new ( server , port ) end # Opens an SSL socket with the EPP server. def open_socket ( connection ) OpenSSL :: SSL :: SSLSocket . new ( connection ) end", "commit_type": "move"}
{"commit_tokens": ["Removed", "unused", "error", "class", ".", "Parse", "response", "as", "JSON", "added", "transaction", "count", "method", "."], "add_tokens": "# Returns the total count of transactions in all states. # # @return [Integer] Total transaction count def transaction_count all_transactions [ \"meta\" ] [ \"total_count\" ] end response = RestClient . get ( url , headers ) JSON . parse ( response )", "del_tokens": "RestClient . get ( url , headers )", "commit_type": "remove"}
{"commit_tokens": ["Updated", "several", "gems", "and", "spec", "adjustments", "to", "fix", "error", "."], "add_tokens": "VERSION = '0.9.2'", "del_tokens": "VERSION = '0.9.1'", "commit_type": "update"}
{"commit_tokens": ["Updating", "evolve", "extension", "specs", "adding", "boolean"], "add_tokens": "unless defined? ( Boolean ) class Boolean ; end end require \"origin/extensions/boolean\"", "del_tokens": "Array . send ( :include , Origin :: Extensions :: Array ) BigDecimal . send ( :extend , Origin :: Extensions :: BigDecimal :: ClassMethods ) Hash . send ( :include , Origin :: Extensions :: Hash ) Integer . send ( :extend , Origin :: Extensions :: Integer :: ClassMethods ) NilClass . send ( :include , Origin :: Extensions :: NilClass ) Object . send ( :include , Origin :: Extensions :: Object ) Object . send ( :extend , Origin :: Extensions :: Object :: ClassMethods )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "using", "branch", "."], "add_tokens": "if lock = self . locks [ name ] old_version = lock . version end if tag == seed . version and ( not old_version or tag == old_version ) say \"Installing #{name} #{seed.version} (was #{old_version})\" . green", "del_tokens": "if tag == seed . version say \"Installing #{name} #{seed.version} (was #{tag})\" . green", "commit_type": "add"}
{"commit_tokens": ["Upgraded", "httparty", "to", "a", "more", "recent", "version", "and", "relaxed", "its", "hard", "version", "requirement", "."], "add_tokens": "Version = '0.0.3'", "del_tokens": "Version = '0.0.2'", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "logging", "to", "Derelict", "::", "Parser", "::", "Status"], "add_tokens": "# Provides a description of this Parser # # Mainly used for log messages. def description \"Derelict::Parser::Status instance\" end logger . debug \"Parsing VM list from output using #{description}\" rescue Derelict :: Parser :: Status :: InvalidFormat => e logger . warn \"List parsing failed for #{description}: #{e.message}\" raise # (as symbols) to their state (also as a symbol). Both of these # symbols have spaces converted to underscores (for convenience # when writing literals in other code). logger . debug \"Parsing states from VM list using #{description}\" rescue Derelict :: Parser :: Status :: InvalidFormat => e logger . warn \"State parsing failed for #{description}: #{e.message}\" raise", "del_tokens": "# (as symbols) to their state (also as a symbol).", "commit_type": "add"}
{"commit_tokens": ["fix", "each", "enumerator", "without", "block"], "add_tokens": "return enum_for ( :each ) unless block_given?", "del_tokens": "return enum_for ( :map! ) unless block_given?", "commit_type": "fix"}
{"commit_tokens": ["Adds", "an", "explicit", "short", "timeout", "to", "on_gce?"], "add_tokens": "resp = c . get ( COMPUTE_CHECK_URI ) do | req | # Comment from: oauth2client/client.py # # Note: the explicit `timeout` below is a workaround. The underlying # issue is that resolving an unknown host on some networks will take # 20-30 seconds; making this timeout short fixes the issue, but # could lead to false negatives in the event that we are on GCE, but # the metadata resolution was particularly slow. The latter case is # \"unlikely\". req . options . timeout = 0.1 end rescue [ Faraday :: TimeoutError , Faraday :: ConnectionFailed ]", "del_tokens": "resp = c . get ( COMPUTE_CHECK_URI ) rescue Faraday :: ConnectionFailed", "commit_type": "add"}
{"commit_tokens": ["made", "associations", "homogenous", "(", "one", "class", "type", "only", ")"], "add_tokens": "VERSION = \"0.0.7\"", "del_tokens": "VERSION = \"0.0.6\"", "commit_type": "make"}
{"commit_tokens": ["Implement", "first", "version", "of", "rails", "and", "bundler", "recipe"], "add_tokens": "require 'fileutils' # API to use inside the recipe ############################## # Run a command inside the build directory. In most cases it is not needed to call this method # directly. Look at the other helper methods. # # The method expects as arguments the program name and additional parameters for the program. # The arguments can be group with arguments, but must not: # @example # exec 'echo', %w(a b) # exec ['echo', 'a', 'b'] # exec 'echo', 'a', 'b' puts \" #{args.flatten.join(' ')}\" # @api public # Run a ruby task (like gem, bundler, rake ...) # # The method expects as arguments the program name and additional parameters for the program. # See exec for more examples def ruby_bin ( * args ) exec 'ruby' , '-S' , * args end # @api public # Install files or directory from the build directory # @param [String] source The relative file name to a filename or directory inside the build # directory that should be installed/copied into the destination package # @param [String] destination The diretory name into that the file or directory should be # installed def install ( src , dest_dir ) exec 'dh_install' , src , dest_dir end # @api public # Installs/creates an empty directory # @param [String] path The path name def install_dir ( path ) exec 'dh_installdirs' , path end # @api public # Create a file named destination as a link to a file named source def install_link ( source , destination ) exec 'dh_link' , source , destination end # @api public # Ensure that the given files or directories are no present. Directories are removed # recursively. def rmtree ( * args ) args . flatten . each do | path | :: FileUtils . remove_entry path if File . exists? path end end # default implementation: ######################### # @api public # clean the build directory from all temporary and created files def clean inner . clean end # @api public # build the program (means ./configure and make) def build inner . build end # @api public # create binary (package) version of this file (means make install) def binary inner . binary end", "del_tokens": "# Run a command inside the build directory", "commit_type": "implement"}
{"commit_tokens": ["Fix", "typo", "in", "method", "name", "."], "add_tokens": "def action_upgrade", "del_tokens": "def action_ugrade", "commit_type": "fix"}
{"commit_tokens": ["Used", "require", "rather", "than", "require", "relative", "where", "it", "s", "no", "different"], "add_tokens": "require 'nickel/version' require 'nickel/nlp'", "del_tokens": "require_relative 'nickel/version' require_relative 'nickel/nlp'", "commit_type": "use"}
{"commit_tokens": ["Add", "double", "checked", "locking", "to", "Memoizable", "::", "Memory#fetch"], "add_tokens": "@memory = ThreadSafe :: Cache . new @monitor = Monitor . new def fetch ( name ) @memory . fetch ( name ) do # check for the key @monitor . synchronize do # acquire a lock if the key is not found @memory . fetch ( name ) do # recheck under lock self [ name ] = yield # set the value end end end", "del_tokens": "@memory = ThreadSafe :: Cache . new def fetch ( name , & block ) @memory . compute_if_absent ( name , & block )", "commit_type": "add"}
{"commit_tokens": ["Add", "publish", "--", "exclude", "option"], "add_tokens": "method_option :exclude , aliases : '-e' , type : :array , desc : 'Exclude authors from the final list' topics = topic_service . to_poll ( exclude : options [ :exclude ] ) slack_service . create_poll ( topics )", "del_tokens": "slack_service . create_poll ( topic_service . to_poll )", "commit_type": "add"}
{"commit_tokens": ["Improve", "tests", "for", "stack", "creation", "."], "add_tokens": "def create ( template , parameters ) status = modify_stack do cf_client . create_stack ( :stack_name => name , :template_body => template , :disable_rollback => true , :capabilities => [ \"CAPABILITY_IAM\" ] , :parameters => parameters ) end fail StackUpdateError , \"stack creation failed\" unless status == \"CREATE_COMPLETE\" :created end", "del_tokens": "def create ( template , parameters ) status = modify_stack do cf_client . create_stack ( :stack_name => name , :template_body => template , :disable_rollback => true , :capabilities => [ \"CAPABILITY_IAM\" ] , :parameters => parameters ) end fail StackUpdateError , \"stack creation failed\" unless status == \"CREATE_COMPLETE\" true end", "commit_type": "improve"}
{"commit_tokens": ["Add", "Derelict", "::", "Connection", "class"], "add_tokens": "autoload :Connection , \"derelict/connection\" autoload :Exception , \"derelict/exception\" autoload :Instance , \"derelict/instance\"", "del_tokens": "autoload :Exception , \"derelict/exception\" autoload :Instance , \"derelict/instance\"", "commit_type": "add"}
{"commit_tokens": ["adds", "support", "for", "generic", "message", "headers"], "add_tokens": "def self . dispatch_request ( args = { } ) @method = args [ :method ] @method_args = args [ :method_args ] @headers = args [ :headers ] @node_callback = args [ :node_callback ] handler = @@handlers [ @method ] callback = @@callbacks [ @method ] retval = instance_exec ( * @method_args , & handler ) #retval = handler.call(*method_args) #rescue Exception => e @method_args . unshift ( @node_callback ) # FIXME remove retval = instance_exec ( * @method_args , & callback ) def self . handle_response ( args = { } ) result = args [ :result ] response = args [ :response ] headers = args [ :headers ]", "del_tokens": "def self . dispatch_request ( method , args , node_callback = nil ) handler = @@handlers [ method ] callback = @@callbacks [ method ] retval = handler . call ( * args ) rescue Exception => e retval = callback . call ( node_callback , * args ) def self . handle_response ( result )", "commit_type": "add"}
{"commit_tokens": ["add", "database", "defaults", "to", "Travis", "::", "Config"], "add_tokens": "YAML . load_file ( filename ) [ env ] if File . exists? ( filename ) def env ENV [ 'ENV' ] || 'test' define :amqp => { :host => '127.0.0.1' , :prefetch => 1 } , :database => { :adapter => 'postgresql' , :database => \"travis_#{Travis::Config.env}\" , :encoding => 'unicode' , :min_messages => 'warning' } , def env self . class . env end", "del_tokens": "YAML . load_file ( filename ) [ environment ] if File . exists? ( filename ) def environment defined? ( Rails ) ? Rails . env : 'test' define :amqp => { :host => '127.0.0.1' , :prefetch => 1 } ,", "commit_type": "add"}
{"commit_tokens": ["moved", "Time", "and", "Date", "overloads", "into", "date", ".", "rb"], "add_tokens": "require \"date\"", "del_tokens": "require \"yaml\" require \"redistat/extensions/date_time\"", "commit_type": "move"}
{"commit_tokens": ["Move", "fail", "method", "to", "lamda"], "add_tokens": "fail = lambda do | msg |", "del_tokens": "def fail ( msg )", "commit_type": "move"}
{"commit_tokens": ["added", "support", "for", "netsted", "class", ".", "added", "helpers", "to", "expose", "job", "class", ".", "also"], "add_tokens": "eval ( details [ \"job\" ] . split ( \".\" ) . first ) def signature details [ \"job\" ] end return [ ] unless details [ \"params\" ]", "del_tokens": "Kernel . const_get ( details [ \"job\" ] . split ( \".\" ) . first )", "commit_type": "add"}
{"commit_tokens": ["Fix", "method_added", "extensions", "not", "being", "called", "when", "it", "s", "already", "defined", "in", "the", "machine", "s", "owner", "class", "preventing", "attributes", "from", "being", "initialized", "in", "certain", "places", "like", "DataMapper", "."], "add_tokens": "# method_added may get defined by the class, so instead it's chained class << self alias_method :method_added_without_state_machine , :method_added alias_method :method_added , :method_added_with_state_machine end def method_added_with_state_machine ( method ) #:nodoc: method_added_without_state_machine ( method )", "del_tokens": "def method_added ( method ) #:nodoc: super", "commit_type": "fix"}
{"commit_tokens": ["Add", "author", "relation", "and", "user", "specs"], "add_tokens": "\"wp:featuredmedia\" => :post , \"author\" => :user def user ( r ) r . load_relation ( r . relation ) . first end", "del_tokens": "\"wp:featuredmedia\" => :post", "commit_type": "add"}
{"commit_tokens": ["Add", ":", "scope", "to", "associations", "."], "add_tokens": "# == Examples # collection automatically. It's just a wrapper to input, so all options # supported in input are also supported by association. Some extra options # can also be given: # # == Options # * :conditions - Given as conditions when retrieving the collection # # * :order - Given as order when retrieving the collection # # * :scope - Given as scopes when retrieving the collection # # == Examples # f.association :company, :scope => [ :public, :not_broken ] # # Same as doing Company.public.not_broken.all # find_options = options . slice ( :conditions , :order ) klass = Array ( options [ :scope ] ) . inject ( @reflection . klass ) do | klass , scope | klass . send ( scope ) end klass . all ( find_options ) def define_simple_form_attributes ( attribute , options ) #:nodoc: def default_input_type #:nodoc: def find_attribute_column #:nodoc: def find_association_reflection ( attribute ) #:nodoc:", "del_tokens": "# == Examples: # collection automatically. It also lets you pass :conditions and :order # options, that will be used directly in find. All other options are passed # to input helper. # == Examples: find_options = { :conditions => options . delete ( :conditions ) , :order => options . delete ( :order ) } @reflection . klass . all ( find_options ) def define_simple_form_attributes ( attribute , options ) def default_input_type def find_attribute_column def find_association_reflection ( attribute )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "dc", "option", "to", "the", "service", "interface"], "add_tokens": "require 'pry' if options and options [ :dc ] qs = \"#{qs}#{sep}dc=#{options[:dc]}\" sep = \"&\" end new ( * args ) . get", "del_tokens": "Diplomat :: Service . new . get * args", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "specs", "to", "parser", "strategy"], "add_tokens": "attr_reader :const_definition_paths @root_path = Pathname . new ( root ) . realpath . to_s attr_reader :processor , :pattern , :root_path", "del_tokens": "@root_path = Pathname ( root ) . realpath . to_s attr_reader :const_definition_paths , :processor , :pattern , :root_path", "commit_type": "add"}
{"commit_tokens": ["add", "chronic", "as", "the", "new", "test", "gem"], "add_tokens": "File . directory? ( \"chronic\" ) . should be_true FileUtils . cp_r \"chronic\" , \"chronic-spec\" @info = [ \"chronic-spec\" , \"chronic.rb\" , \"chronic-spec/lib\" ] FileUtils . rmtree 'chronic-spec'", "del_tokens": "File . directory? ( \"gherkin\" ) . should be_true FileUtils . cp_r \"gherkin\" , \"gherkin-spec\" @info = [ \"gherkin-spec\" , \"gherkin.rb\" , \"gherkin-spec/lib\" ] FileUtils . rmtree 'gherkin-spec'", "commit_type": "add"}
{"commit_tokens": ["add", "a", "basic", "tests", "for", "service", "initialization", "and", "basic", "successful", "request"], "add_tokens": "# validate that the handler reponds to all expected methods self . class . rpcs . each do | method_name , rpc | if ! handler . respond_to? rpc [ :handler_method ] raise ArgumentError . new ( \"Handler must respond to .#{rpc[:handler_method]}(req) in order to handle the message #{method_name}.\" ) end end @handler = handler", "del_tokens": "@handler = handler # TODO: validate that handler responds to all expected methods (report good error message if not)", "commit_type": "add"}
{"commit_tokens": ["Added", "RCov", "to", "Gemfile", "and", "rake", "task", ";", "moved", "FormHelper", "to", "new", "file"], "add_tokens": "private # A slightly friendlier version of Capybara's +find_field+, which actually # tells you which locator failed to match (instead of giving a useless # Unable to find '#<XPath::Union:0xXXXXXXX>' message). def nice_find_field ( locator ) begin field = find_field ( locator ) rescue Capybara :: ElementNotFound raise \"Could not find field with locator: '#{locator}'\" end end end", "del_tokens": "# Generic helper methods for website navigation and testing module CapybaraHelper # A slightly friendlier version of Capybara's +find_field+, which actually # tells you which locator failed to match (instead of giving a useless # Unable to find '#<XPath::Union:0xXXXXXXX>' message). def nice_find_field ( locator ) begin field = find_field ( locator ) rescue Capybara :: ElementNotFound raise \"Could not find field with locator: '#{locator}'\" end end end end # Add all helpers to Cucumber's world World ( CapybaraHelper ) World ( FormHelper )", "commit_type": "add"}
{"commit_tokens": ["Allow", "Parent", "to", "be", "Set", "on", "AttributeList"], "add_tokens": "# list. This shouldn't be set since it is automatically assumed; however, # sometimes it can be assumed wrong. # # @return [AttributeList, nil] attr_accessor :parent", "del_tokens": "# list. attr_reader :parent", "commit_type": "allow"}
{"commit_tokens": ["add", "better", "exit", "handler", "to", "avoid", "such", "problems", "in", "the", "future"], "add_tokens": "attr_reader :file class << self def register ( db ) at_exit ( & method ( :exit_handler ) ) unless @db @db = [ ] @db << db end def unregister ( db ) @db . delete ( db ) end def exit_handler @db . each do | db | warn \"Database #{db.file} was not closed, state might be inconsistent\" db . close end end end self . class . register ( self ) self . class . unregister ( self )", "del_tokens": "at_exit ( & method ( :finish ) )", "commit_type": "add"}
{"commit_tokens": ["fix", "stub", ".", "reverted", "back", "to", "controller_name"], "add_tokens": "controller . stub! ( :controller_name ) . and_return ( \"posts\" ) # for correct impressionable type in filter", "del_tokens": "controller . stub! ( :controller_path ) . and_return ( \"posts\" ) # for correct impressionable type in filter", "commit_type": "fix"}
{"commit_tokens": ["remove", "requirement", "on", "solr", "for", "best", "bets", "-", "fall", "back", "on", "in", "-", "memory", "best", "bets", "read", "from", "a", "yml", "file", "if", "no", "solr", "url", "appears", "in", "config", "file"], "add_tokens": "unless QuickSearch :: Engine :: APP_CONFIG [ 'best_bets' ] [ 'solr_url' ] . empty? search_best_bets_index else if defined? QuickSearch :: Engine :: BEST_BETS search_local_best_bets end end def search_local_best_bets if QuickSearch :: Engine :: BEST_BETS_INDEX . has_key? http_request_queries [ 'not_escaped' ] . downcase best_bet_name = QuickSearch :: Engine :: BEST_BETS_INDEX [ http_request_queries [ 'not_escaped' ] . downcase ] best_bet = QuickSearch :: Engine :: BEST_BETS [ best_bet_name ] result = OpenStruct . new result . title = title ( best_bet ) result . link = link ( best_bet ) result . id = '' result . description = description ( best_bet ) result . best_bets_type = 'best-bets-regular' @response = result else nil end end", "del_tokens": "search_best_bets_index", "commit_type": "remove"}
{"commit_tokens": ["use", "chronic", "for", "date", "parsing", "started", "timer", "implementation"], "add_tokens": "hcl tasks hcl add < task > < duration > [ msg ] hcl start < task > [ msg ] def tasks Task . all . each do | task | # TODO more information and formatting options puts \"#{task.id}\\t#{task}\" end end def start * args task = Task . find args . shift puts \"Starting timer for #{task}\" puts task . start ( * args ) end def not_implemented * args", "del_tokens": "hcl add < project > < task > < duration > [ msg ] hcl start < project > < task > [ msg ] def not_implemented alias start not_implemented", "commit_type": "use"}
{"commit_tokens": ["Added", "lines_only", "attribute", "to", "lists", "to", "allow", "for", "easy", "paging", "."], "add_tokens": "attr_reader :lines , :lines_only def initialize ( ** attribs_ , & block ) * * attribs_ , & block ) @lines_only = attribs . delete ( :lines_only ) || false", "del_tokens": "attr_reader :lines def initialize ( ** attribs , & block ) * * attribs , & block )", "commit_type": "add"}
{"commit_tokens": ["move", "app", "clone", "to", "/", "var", "/", "lib", "/", "moonshine", "/", "applications", "/", "#", "{", "application", "}"], "add_tokens": "#parse moonshine.rb from the app @path ||= \"/var/lib/moonshine/applicatons/#{name}\"", "del_tokens": "#parse the environment configuration of the app @path ||= \"/var/lib/moonshine/#{name}\"", "commit_type": "move"}
{"commit_tokens": ["Allow", "to", "create", "association", "from", "build_xyz", "method", "on", "an", "object"], "add_tokens": "expect { @tester . create_object ( stub ( :object => Comment . new ) , :not_existing ) } . to raise_error / association /i @tester . create_object ( stub ( :object => object ) , :custom_item ) . should == 'custom'", "del_tokens": "expect { @tester . create_object ( stub ( :object => Comment . new ) , :not_existing ) } . to raise_error / exist / pending 'WIP' @tester . create_object ( stub ( :object => Comment . new ) , :custom_item ) . should == 'custom'", "commit_type": "allow"}
{"commit_tokens": ["Add", "methods", "on", "port", "to", "send", "and", "receive", "rights", "from", "other", "tasks", "."], "add_tokens": "task = ( opts [ :task ] && opts [ :task ] . to_i ) || ipc_space || mach_task_self opts [ :port ] . to_i semaphore_destroy ( task . to_i , port )", "del_tokens": "task = opts [ :task ] || ipc_space || mach_task_self opts [ :port ] semaphore_destroy ( task , port )", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "to", "Float", "Fixnuma", "nd", "String"], "add_tokens": "include Comparable if args . any? || ! @base register_measurement def self . register_measurement method_name = name . gsub ( / \\s / , '_' ) . gsub ( / .[A-Z] / ) do | s | s [ 0 , 1 ] + '_' + s [ 1 , 1 ] . downcase end . downcase [ Fixnum , Float ] . each do | klass | klass . class_eval %Q{ def to_ #{method_name} #{name}.new(self) end } end String . class_eval %Q{ def to_ #{method_name} #{name}.parse(self) end } end def <=> ( anOther ) to_f <=> anOther . to_f end %w( + - / * ) . each do | operator | class_eval %Q{ def #{operator}(anOther) self . class . new ( self . to_f #{operator} anOther.to_f) end } end", "del_tokens": "if args . any?", "commit_type": "add"}
{"commit_tokens": ["Add", "backend_name", "method", "to", "Attributes"], "add_tokens": "attr_reader :attributes , :options , :backend_class , :backend_name @backend_name = options . delete ( :backend ) @backend_class = Class . new ( get_backend_class ( backend : @backend_name ,", "del_tokens": "attr_reader :attributes , :options , :backend_class @backend_class = Class . new ( get_backend_class ( backend : options . delete ( :backend ) ,", "commit_type": "add"}
{"commit_tokens": ["Created", "table", "with", "columns", "for", "patient_medications"], "add_tokens": "create_table \"patient_medications\" , force : true do | t | t . integer \"patient_id\" t . integer \"medication_id\" t . integer \"user_id\" t . string \"medication_type\" t . string \"dose\" t . string \"route\" t . string \"frequency\" t . text \"notes\" t . date \"date\" t . string \"provider\" t . datetime \"deleted_at\" t . datetime \"created_at\" t . datetime \"updated_at\" end", "del_tokens": "create_table \"drugs_patients\" , force : true do | t | t . integer \"drug_id\" t . integer \"patient_id\" t . datetime \"created_at\" t . datetime \"updated_at\" end", "commit_type": "create"}
{"commit_tokens": ["Fix", "bug", ":", "network_acl", "have_subnet", "()", "dont", "support", "multi", "subnet", "."], "add_tokens": "next true if a . subnet_id == subnet_id next false unless subnet next a . subnet_id == subnet [ :subnet_id ]", "del_tokens": "return true if a . subnet_id == subnet_id return false unless subnet return a . subnet_id == subnet [ :subnet_id ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "rubocop", "warning", "TrailingComma", "in", "unescape_double_quote_spec"], "add_tokens": "expected : 'hoge\"h\"ige' expected : 'hogehige' }", "del_tokens": "expected : 'hoge\"h\"ige' , expected : 'hogehige' , } ,", "commit_type": "fix"}
{"commit_tokens": ["Change", "output", "of", "analysis", ".", "Add", "start", "row", "to", "begin", "sorting"], "add_tokens": "# file doesn't contain a header. If not headerless then empty rows from # beginning of file are discarted and first non empty row is considered as # header. Subsequent rows will be sorted and added in the resulting file # after the header # First row to sort. Will skip rows 0 to start - 1 and add them to top of # file. Rows from start on will be sorted. attr_reader :start # Creates a Sorter and takes as options infile, outfile, rows, cols # including types and a date format for the date columns to sort (optional). # :call-seq: # Sycsvrpo::Sorter.new(infile: \"infile.csv\", # outfile: \"outfile.csv\", # rows: \"1,2-5,12-30\", # cols: \"n:1,s:3\", # headerless: true, # df: \"%d.%m.%Y\", # start: \"2\").execute # The sorted infile will saved to outfile @start = options [ :start ] skipped_rows = [ ] skipped_rows [ 0 ] = \"\" skipped_rows [ 0 ] = rows . shift while skipped_rows [ 0 ] . chomp . strip . empty? end if start ( 0 ... start . to_i ) . each { | row | skipped_rows << rows . shift } skipped_rows . each { | row | out . puts unstring ( row ) }", "del_tokens": "# file doesn't contain a header # Creates a Sorter and takes as options infile, outfile, rows, cols including types and a # date format for the date columns to sort (optional). header = \"\" header = rows . shift while header . chomp . strip . empty? unless headerless out . puts header end", "commit_type": "change"}
{"commit_tokens": ["add", "method", "call", "for", "use", "in", "ApplicationController"], "add_tokens": "def require_tenant ActsAsTenant . require_tenant end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "form", "the", "default", "format"], "add_tokens": "self . format ||= :form", "del_tokens": "self . format ||= :blank", "commit_type": "make"}
{"commit_tokens": ["Allow", "the", "--", "server", "flag", "to", "be", "disabled"], "add_tokens": "attr_accessor :exe_path , :style_sheets , :logger , :log_file , :server_flag options = { :path => Princely . executable , :log_file => nil , :logger => nil , :server_flag => true } . merge ( options ) @exe_path = options [ :path ] raise \"Cannot find prince command-line app in $PATH\" if ! @exe_path || @exe_path . length == 0 raise \"Cannot find prince command-line app at #{@exe_path}\" unless File . executable? ( @exe_path ) @server_flag = options [ :server_flag ] @exe_path << \" --input=html \" @exe_path << \"--server \" if @server_flag @exe_path << \"--log=#{log_file} \"", "del_tokens": "attr_accessor :exe_path , :style_sheets , :logger , :log_file @exe_path = options [ :path ] || Princely . executable raise \"Cannot find prince command-line app in $PATH\" if @exe_path . length == 0 raise \"Cannot find prince command-line app at #{@exe_path}\" if @exe_path && ! File . executable? ( @exe_path ) @exe_path << \" --input=html --server --log=#{log_file} \"", "commit_type": "allow"}
{"commit_tokens": ["Removing", "rate", "limiting", "code", "since", "rate", "limits", "are", "not", "enforced", "when", "Client", "-", "ID", "header", "is", "sent", ".", "This", "also", "speeds", "up", "specs", "significantly", "."], "add_tokens": "response = self . class . get ( request_url , :headers => headers , :query => query )", "del_tokens": "@last_request_time = Time . now - RATE_LIMIT_SEC response = rate_limit do self . class . get ( request_url , :headers => headers , :query => query ) end def rate_limit delta = Time . now - @last_request_time delay = [ RATE_LIMIT_SEC - delta , 0 ] . max sleep delay if delay > 0 begin return yield ensure @last_request_time = Time . now end end RATE_LIMIT_SEC = 1", "commit_type": "remove"}
{"commit_tokens": ["Using", "a", "more", "reliable", "way", "of", "determining", "if", "received", "data", "is", "a", "block", "."], "add_tokens": "data . is_a? ( Proc ) ? data . call ( object ) : data", "del_tokens": "data . respond_to? ( :call ) ? data . call ( object ) : data", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "render", "context", "scope", "stack", ".", "So", "nested", "partials", "works", "correctly", "now", "."], "add_tokens": "short = \"{Exception}\\n#{[ex.to_s, ex.backtrace[0]].flatten.join(\"\\n\")}\" message = \"{Exception}\\n#{[ex.to_s, ex.backtrace].flatten.join(\"\\n\")}\" log . error message $stderr . puts short", "del_tokens": "log . error \"{Exception}\" log . error [ ex . to_s , ex . backtrace ] . flatten . join ( \"\\n\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "locate_line", "test", ".", "Some", "other", "small", "changes", "."], "add_tokens": "# the specified line if is in CompiledMethod cm only, or nil if no module_function :locate_line_in_cm ## p [cm, lines_of_method(cm)] module_function :locate_line module_function :lines_of_method ## pair = meth.locate_line(line) module_function :find_method_with_line", "del_tokens": "# the specified line it is in CompiledMethod cm. or nil if no", "commit_type": "add"}
{"commit_tokens": ["added", "phrase", "source", "view", "and", "ability", "to", "report", "translation", "comment"], "add_tokens": "def lb_sources @translation_key = Tr8n :: TranslationKey . find ( params [ :translation_key_id ] ) render :layout => false", "del_tokens": "def report_comment", "commit_type": "add"}
{"commit_tokens": ["adds", "ability", "to", "start", "processes", "after", "the", "supervisor", "is", "running"], "add_tokens": "processes = @cli_options [ :processes ] . split ( ',' ) if processes . empty? raise Error , \"At least one process must be specified when starting after the supervisor is running\" else instances = ControlClient . run ( @config . sock_path , 'start_processes' , :processes => processes ) if instances . empty? raise Error , \"No processes were started. The type you entered might already be running or isn't defined.\" else instances . each do | instance | puts \"Started #{instance['description']} (PID: #{instance['pid']})\" end end return end if @cli_options [ :processes ] processes = @cli_options [ :processes ] . split ( ',' ) else processes = nil end Supervisor . new ( @config ) . start ( :processes => processes ) Supervisor . new ( @config ) . start ( :processes => processes )", "del_tokens": "raise Error , \"#{@config.app_name} already running (PID: #{current_pid})\" Supervisor . new ( @config ) . start Supervisor . new ( @config ) . start", "commit_type": "add"}
{"commit_tokens": ["Use", "Kernel", "::", "require", "when", "testing"], "add_tokens": "Kernel :: require 'malloc'", "del_tokens": "require 'malloc'", "commit_type": "use"}
{"commit_tokens": ["Added", "easily", "changable", "BRAND", "ing", "of", "tests", "."], "add_tokens": "BRAND = \"@@ \"", "del_tokens": "BRAND = \"@@ \"", "commit_type": "add"}
{"commit_tokens": ["added", "compiler", "spec", "and", "handlebars", "runtime"], "add_tokens": "@source ||= Handlebarer :: Source :: handlebars context . eval ( \"Handlebars.VERSION\" ) context . eval ( \"Handlebars.precompile('#{template}')\" ) . to_s", "del_tokens": "@source ||= %{ var window = { } ; #{Handlebarer::Source::handlebars} var handlebars_version = Handlebars . VERSION ; } context . eval ( \"handlebars_version\" ) # @param [String] file_name name of template file used to resolve mixins inclusion", "commit_type": "add"}
{"commit_tokens": ["add", "build", "test", "using", "a", "build", "directory"], "add_tokens": "o_file = @env . get_build_fname ( source , @env [ 'OBJSUFFIX' , :string ] ) builder . run ( o_file , [ source ] , cache ) or break if sources vars = { 'TARGET' => target , 'SOURCES' => sources , 'LD' => @env [ 'LD' ] || @env [ 'CC' ] , # TODO: figure out whether to use CC or CXX } command = @env . build_command ( @env [ 'LDCOM' ] , vars ) unless cache . up_to_date? ( target , command , sources ) return false unless @env . execute ( \"LD #{target}\" , command ) cache . register_build ( target , command , sources ) end target", "del_tokens": "o_file = source . set_suffix ( @env [ 'OBJSUFFIX' , :string ] ) builder . run ( o_file , [ source ] , cache ) vars = { 'TARGET' => target , 'SOURCES' => sources , 'LD' => @env [ 'LD' ] || @env [ 'CC' ] , # TODO: figure out whether to use CC or CXX } command = @env . build_command ( @env [ 'LDCOM' ] , vars ) unless cache . up_to_date? ( target , command , sources ) return false unless @env . execute ( \"LD #{target}\" , command ) cache . register_build ( target , command , sources ) target", "commit_type": "add"}
{"commit_tokens": ["Fix", "permissions", "in", "aliases", "controller"], "add_tokens": "@list = @object_class = Translation . includes ( :translation_data ) end def edit authorize! :manage , Translation @item = current_object_class . find ( params [ :id ] )", "del_tokens": "@object_class = Translation . includes ( :translation_data ) super", "commit_type": "fix"}
{"commit_tokens": ["Use", "const_get", "instead", "of", "constantize"], "add_tokens": "ActiveInteraction . const_get ( klass )", "del_tokens": "\"ActiveInteraction::#{klass}\" . constantize", "commit_type": "use"}
{"commit_tokens": ["Fixed", "additional", "errors", "in", "the", "835", ".", "xml", "file"], "add_tokens": "VERSION = \"1.4.3\"", "del_tokens": "VERSION = \"1.4.2\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "more", "tests", "for", "STI", "inherited", "model", "mocks"], "add_tokens": "", "del_tokens": "should \"generate the column type specified by the :as key irrespective of the data type\" do end", "commit_type": "add"}
{"commit_tokens": ["Use", "fully", "qualified", "class", "names", "."], "add_tokens": "if base . include? ( RProgram :: Options ) if base . include? ( RProgram :: Options ) if base . include? ( RProgram :: Options ) if base . include? ( RProgram :: Options )", "del_tokens": "if base . include? ( Options ) if base . include? ( Options ) if base . include? ( Options ) if base . include? ( Options )", "commit_type": "use"}
{"commit_tokens": ["fix", "bug", "with", "todolists", "only", "returning", "one", "list"], "add_tokens": "list", "del_tokens": "return list", "commit_type": "fix"}
{"commit_tokens": ["Made", "configurable", "module", "work", "for", "Classes", "/", "Modules", "(", "didn", "t", "previously", ")"], "add_tokens": "# This isn't included in InstanceMethods because we need access to 'klass' define_method :configuration_hash do @configuration_hash ||= klass . default_configuration . dup end private :configuration_hash", "del_tokens": "private def configuration_hash @configuration_hash ||= self . class . default_configuration . dup end", "commit_type": "make"}
{"commit_tokens": ["Add", "feed", "wide", "timezone", "if", "the", "x", "property", "is", "set"], "add_tokens": "attr_reader :feed , :bare_feed , :url , :timezone @timezone = get_timzone def get_timzone if @feed . present? && @feed . first . x_properties [ \"X-WR-TIMEZONE\" ] . first @feed . first . x_properties [ \"X-WR-TIMEZONE\" ] . first . value end end", "del_tokens": "attr_reader :feed , :bare_feed , :url", "commit_type": "add"}
{"commit_tokens": ["fix", "method", "name", "typo", "."], "add_tokens": "response_ctx . response ( ret ) unless response_ctx . responded? resctx . response ( e ) unless resctx . responded?", "del_tokens": "response_ctx . response ( ret ) unless response_ctx . responded resctx . response ( e ) unless resctx . responded", "commit_type": "fix"}
{"commit_tokens": ["Allow", "configuration", "from", "a", "hash"], "add_tokens": "def configure ( config_hash = nil ) if config_hash config_hash . each do | k , v | configuration . send ( \"#{k}=\" , v ) rescue nil if configuration . respond_to? ( \"#{k}=\" ) end end yield ( configuration ) if block_given? configuration . logger . info ( \"#{LOG_PREFIX}#{message}\" ) configuration . logger . warn ( \"#{LOG_PREFIX}#{message}\" )", "del_tokens": "def configure yield ( configuration ) configuration . logger . info ( LOG_PREFIX + message ) if configuration . logger if configuration . logger configuration . logger . warn ( LOG_PREFIX + message ) else puts \"#{LOG_PREFIX}#{message}\" end", "commit_type": "allow"}
{"commit_tokens": ["Use", "encoding", "accessor", "for", "CairoOutputter"], "add_tokens": "encoding . each do | line | encoding . scan ( / (?:0+|1+) / ) . each do | codes | ( barcode . two_dimensional? ? encoding . first . length : encoding . length ) * xdim ( options ) encoding . size * xdim ( options )", "del_tokens": "barcode . encoding . each do | line | barcode . encoding . scan ( / (?:0+|1+) / ) . each do | codes | ( barcode . two_dimensional? ? barcode . encoding . first . length : barcode . encoding . length ) * xdim ( options ) barcode . encoding . size * xdim ( options )", "commit_type": "use"}
{"commit_tokens": ["Add", "Gecko", "::", "Record", "::", "User"], "add_tokens": "require 'gecko/record/location' require 'gecko/record/user'", "del_tokens": "require 'gecko/record/location'", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "the", "Letter", "page", "size", "to", "the", "PDF", "screenshot", "facility", "."], "add_tokens": "# @param pagesize [String, 'A4'] the page size of the PDF to be returned: 'A3', 'A4', 'A5', 'B3', 'B4', 'B5', 'Letter'.", "del_tokens": "# @param pagesize [String, 'A4'] the page size of the PDF to be returned: 'A3', 'A4', 'A5', 'B3', 'B4', 'B5'.", "commit_type": "add"}
{"commit_tokens": ["allow", "WS", "implementation", "to", "pass", "a", "block", "to", "lookup"], "add_tokens": "VERSION = '0.2.12'", "del_tokens": "VERSION = '0.2.11'", "commit_type": "allow"}
{"commit_tokens": ["Fix", "North", "/", "South", "and", "East", "/", "West", "extraction", "for", "bounding", "boxes", "."], "add_tokens": "@upper_left = Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(3)} #{cs.get_y(3)})\" ) @upper_right ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(2)} #{cs.get_y(2)})\" ) @lower_right ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(1)} #{cs.get_y(1)})\" ) @lower_left ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(0)} #{cs.get_y(0)})\" )", "del_tokens": "@upper_left = Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(0)} #{cs.get_y(0)})\" ) @upper_right ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(1)} #{cs.get_y(1)})\" ) @lower_right ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(2)} #{cs.get_y(2)})\" ) @lower_left ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(3)} #{cs.get_y(3)})\" )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "feature", "for", "braced", "strings", "issue"], "add_tokens": "Then / ^my bibliography should contain ( \\d +) ( \\w +)$ / do | count , type | assert_equal count . to_i , @bibliography . q ( \"@#{type.chomp!('s')}\" ) . length end assert_equal count . to_i , @bibliography . q ( \"@#{type.chomp!('s')}[year=#{year}]\" ) . length Then / ^the string \"([^\"]*)\" should be \"([^\"]*)\"$ / do | key , value | assert_equal value , @bibliography . strings [ key ] . to_s end", "del_tokens": "assert_equal @bibliography . q ( \"@#{type.chomp!('s')}[year=#{year}]\" ) . length , count . to_i", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "ModBus", "::", "ReadOnlyProxy", "and", "ModBus", "::", "ReadWriteProxy", "or", "interacting", "with", "modbus", "devices", "like", "a", "hash", ".", "Also", "update", "some", "documentation"], "add_tokens": "require 'rmodbus/proxy'", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["make", "gem", "installs", "go", "a", "bit", "faster"], "add_tokens": "run_in_environment ( env , \"gem install rails --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install rails -v 2.3.10 --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install sqlite3 --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\" --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\" --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\" --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install rspec-rails -v '< 2' --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install hoe -v 1.5.1 --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install test-unit -v 1.2.3 --no-rdoc --no-ri\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\" --no-rdoc --no-ri\" )", "del_tokens": "run_in_environment ( env , \"gem install rails\" ) run_in_environment ( env , \"gem install rails -v 2.3.10\" ) run_in_environment ( env , \"gem install sqlite3\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\"\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\"\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\"\" ) run_in_environment ( env , \"gem install rspec-rails -v '< 2'\" ) run_in_environment ( env , \"gem install hoe -v 1.5.1\" ) run_in_environment ( env , \"gem install test-unit -v 1.2.3\" ) run_in_environment ( env , \"gem install \\\"$SAUCE_GEM\\\"\" )", "commit_type": "make"}
{"commit_tokens": ["Added", "logging", "of", "body", "parameters"], "add_tokens": "puts \"\\n==> #{env[:method].to_s.upcase} #{env[:url]} [#{env[:body]}]\\n\\n\"", "del_tokens": "puts \"\\n==> #{env[:method].to_s.upcase} #{env[:url]} \\n\\n\"", "commit_type": "add"}
{"commit_tokens": ["Add", "logidze", "model", ";", "add", "has_logidze", ";", "fix", "setup", "script"], "add_tokens": "def self . next_migration_number ( _ ) sleep 1 # make sure each time we get a different timestamp Time . new . utc . strftime ( \"%Y%m%d%H%M%S\" )", "del_tokens": "def self . next_migration_number ( dirname ) if ActiveRecord :: Base . timestamped_migrations sleep 1 # make sure each time we get a different timestamp Time . new . utc . strftime ( \"%Y%m%d%H%M%S\" ) else \"%.3d\" % ( current_migration_number ( dirname ) + 1 ) end", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "readme", "file", "."], "add_tokens": "# surrounds two or more consecutive capital letters, perhaps with # convert a given piece of text to titlecase", "del_tokens": "# surrounds two or more consecutive captial letters, perhaps with", "commit_type": "update"}
{"commit_tokens": ["Updating", "OAuth2", "authorization", "mode", "a", "bit", "first", "round", "."], "add_tokens": ":realm => 'OAuth API' , :parameter => %w( bearer_token oauth_token ) , :header => [ / Bearer (.*) /i , / OAuth (.*) /i ] verify_token ( token_parameter || token_header ) end def token_parameter Array ( options [ :parameter ] ) . each do | p | return request [ p ] if request [ p ] nil end def token_header return false unless env [ 'Authorization' ] Array ( options [ :header ] ) . each do | regexp | if env [ 'Authorization' ] =~ regexp return $1 end end nil if token . respond_to? ( :expired? ) && token . expired? :message => error ,", "del_tokens": ":realm => 'OAuth API' if request [ 'oauth_token' ] verify_token ( request [ 'oauth_token' ] ) elsif env [ 'Authorization' ] && t = parse_authorization_header verify_token ( t ) if token . expired? :message => 'The token provided has expired.' ,", "commit_type": "update"}
{"commit_tokens": ["Improve", "documentation", "of", "Node", "class"], "add_tokens": "# Handles all the complexity of accessing the XML contents # Creates a new Node object. # # If the node is not the root node then the secondargument needs to be false. # Access an attribute of the current node. # # XML file: # # Example: # # The workhorse, finds the node matching meth. # # Rough flow guide: # If a block is given then yield to it each for each instance # of the element found in the current node. # If no block given then get the first element found # If the node has only one text element check if the # method called has a ? suffix then return true if node content # looks like a boolean. Otherwise return text content # Otherwise return a new Node instance # Returns the current nodes contents. # Transforms a symbol into a XML element path. # Indicates if the current node is the root of the XML document.", "del_tokens": "# Creates a new Node object. If the node is not the root node then # the second argument needs to be false. # Access an attribute of the current node # Example: # # # Indicates if the current node is the root of the XML document", "commit_type": "improve"}
{"commit_tokens": ["added", "login", "and", "signup", "methods", "to", "users", "controller"], "add_tokens": "def login opts = { } opts [ :pass ] ||= opts [ :password ] post \"/user/api/signin.json\" , opts end def signup opts = { } opts [ :pass ] ||= opts [ :password ] post \"/user/api/signup.json\" , opts end Dailycred :: Response . new ( get_conn . post url , opts )", "del_tokens": "response = get_conn . post url , opts", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "that", "caused", "a", "test", "script", "to", "fail"], "add_tokens": "if parameters && parameters . server_object_mask", "del_tokens": "if parameters && parameters . server_object_mask && parameters . server_object_mask . count != 0", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "issue", "calling", "super", "without", "parameters", "in", "define_method"], "add_tokens": "super ( )", "del_tokens": "super", "commit_type": "fix"}
{"commit_tokens": ["added", "helper", "method", "to", "make", "the", "TabularDataSupport", "proxies", "behave", "as", "regular", "Ruby", "Enumerable"], "add_tokens": "sysprops . each do | sysprop |", "del_tokens": "sysprops . values . each do | sysprop |", "commit_type": "add"}
{"commit_tokens": ["Implement", "sublabels", "for", "issue", "/", "due", "dates"], "add_tokens": "issue_date_label = if @labels [ :sublabels ] [ :issue_date ] && ! @labels [ :sublabels ] [ :issue_date ] . empty? \"#{@labels[:issue_date]} / #{@labels[:sublabels][:issue_date]}:\" else \"#{@labels[:issue_date]}:\" end issue_date_label , align : :right due_date_present = ! @document . due_date . empty? due_date_label = if @labels [ :sublabels ] [ :due_date ] && ! @labels [ :sublabels ] [ :due_date ] . empty? \"#{@labels[:due_date]} / #{@labels[:sublabels][:due_date]}:\" else \"#{@labels[:due_date]}:\" end due_date_label , align : :right", "del_tokens": "due_date_present = ! @document . due_date . empty? \"#{@labels[:issue_date]}:\" , width : 240 \"#{@labels[:due_date]}:\" , width : 240", "commit_type": "implement"}
{"commit_tokens": ["fixed", "bug", "in", "new", "config", "setup"], "add_tokens": "@instance_config = self . config [ :carousels ] [ @ticket . to_sym ]", "del_tokens": "@instance_config = self . config [ :carousels ] [ @ticket ]", "commit_type": "fix"}
{"commit_tokens": ["add", "spec", "for", "tag", "manipulations"], "add_tokens": "config . run_all_when_everything_filtered = true BASE_URL = 'https://www.inoreader.com' :items => '/reader/atom' , :item_ids => '/reader/api/0/stream/items/ids' , :rename_tag => '/reader/api/0/rename-tag' , :disable_tag => '/reader/api/0/disable-tag' , :edit_tag => '/reader/api/0/edit-tag'", "del_tokens": "config . run_all_when_everything_filtered = true BASE_URL = 'https://www.inoreader.com' :items => '/reader/atom' , :item_ids => '/reader/api/0/stream/items/ids'", "commit_type": "add"}
{"commit_tokens": ["Add", "log", "and", "fix", "token", "-", "id", "param", "reference"], "add_tokens": "CabooseStore :: ApiKey . to_s ap body [ 'api-key' ] response = self . api 'complete-action' , { 'token-id' => params [ 'token-id' ] } , order . test?", "del_tokens": "CabooseStore :: ApiKey response = self . api 'complete-action' , { 'token-id' => params [ :token_id ] } , order . test?", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "and", "features", "for", "basic", "functionality", "."], "add_tokens": "@context . set x : x_value . to_i , y : y_value . to_i @pythagorean_eqtn . evaluate_in ( @context ) . should be ( equation_result ) Given / ^a scenario$ / do pending # express the regexp above with the code you wish you had end When / ^I add a new equation$ / do pending # express the regexp above with the code you wish you had end Then / ^it should be accessible in the list of equations$ / do pending # express the regexp above with the code you wish you had end Given / ^a set of variables and values$ / do pending # express the regexp above with the code you wish you had end When / ^I use them in a new equation$ / do pending # express the regexp above with the code you wish you had end Then / ^the result should appear as expected$ / do pending # express the regexp above with the code you wish you had end Then / ^a bound variable \"(.*?)\" with value ( \\d +)$ / do | var_name , value | @context . get ( var_name . to_sym ) . value . should eq value . to_i end", "del_tokens": "@context . set x : x_value , y : y_value @context . evaluate ( @pythagorean_eqtn ) . should be ( equation_result )", "commit_type": "add"}
{"commit_tokens": ["add", "rename", "support", "to", "the", "frontend"], "add_tokens": "name = params [ :name ] wiki = Gollum :: Wiki . new ( $path ) page = wiki . page ( name ) name = params [ :rename ] if params [ :rename ] wiki . update_page ( page , name , format , params [ :content ] , commit_message ) redirect \"/#{Gollum::Page.cname name}\"", "del_tokens": "name = params [ :name ] wiki = Gollum :: Wiki . new ( $path ) page = wiki . page ( name ) wiki . update_page ( page , page . name , format , params [ :content ] , commit_message ) redirect \"/#{name}\"", "commit_type": "add"}
{"commit_tokens": ["fix", "unnecessary", "case", "in", "Plot#new"], "add_tokens": "@options = Hamster . hash ( options )", "del_tokens": "@options = if datasets . last . is_a? Hamster :: Hash datasets . last else Hamster . hash ( options ) end", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "all", "node", "classes", "did", "share", "the", "same", "properties", "and", "indexes", ".", "/", "run", ".", "sh", "Started", "to", "implement", "event", "listeners", "for", "Nodes"], "add_tokens": "# all subclasses share the same index, declared properties and listeners c . instance_eval do const_set ( :LUCENE_INDEX_PATH , Neo4j :: LUCENE_INDEX_STORAGE + \"/\" + self . to_s . gsub ( '::' , '/' ) ) const_set ( :DECL_PROPS , [ ] ) const_set ( :LISTENERS , [ ] ) end unless c . const_defined? ( :LUCENE_INDEX_PATH ) # # Access to class constants. # These properties are shared by the class and its siblings. # For example that means that we can specify properties for a parent # class and the child classes will 'inherit' those properties. # def lucene_index Lucene :: Index . new ( self :: LUCENE_INDEX_PATH ) end def listeners self :: LISTENERS end def decl_props self :: DECL_PROPS end # ------------------------------------------------------------------------", "del_tokens": "# all subclasses share the same index # need to inject a c . instance_eval do | c | # set the path where to store the index @@lucene_index_path = Neo4j :: LUCENE_INDEX_STORAGE + \"/\" + self . to_s . gsub ( '::' , '/' ) @@decl_props = [ ] def lucene_index Lucene :: Index . new ( @@lucene_index_path ) end def decl_props @@decl_props end end", "commit_type": "fix"}
{"commit_tokens": ["Adds", "Vault", "for", "encryption", "of", "PreviewContexts"], "add_tokens": "yaml_string = yaml if :: RiddlerAdmin . configuration . encrypt_preview_contexts? && encrypted_yaml . present? yaml_string = decrypt encrypted_yaml end YAML . safe_load yaml_string update_data hash def update_data hash yaml = hash . to_yaml if :: RiddlerAdmin . configuration . encrypt_preview_contexts? encrypted_yaml = encrypt yaml update_attribute :encrypted_yaml , encrypted_yaml else update_attribute :yaml , yaml end end private def encrypt plaintext :: RiddlerAdmin . encrypt plaintext , key : :: RiddlerAdmin . configuration . preview_context_transit_key end def decrypt ciphertext :: RiddlerAdmin . decrypt ciphertext , key : :: RiddlerAdmin . configuration . preview_context_transit_key end", "del_tokens": "YAML . safe_load yaml update_attribute :yaml , hash . to_yaml", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Jekyll", "new", "command", "options"], "add_tokens": "c . syntax 'octopress new PATH' c . description 'Creates a new Jekyll site scaffold in PATH' c . option 'force' , '--force' , 'Force creation even if PATH already exists' c . option 'blank' , '--blank' , 'Creates scaffolding but with empty files' :: Jekyll :: Commands :: New . process ( args , options . to_symbol_keys ) c . option 'force' , '--force' , 'Force creation even if PATH already exists'", "del_tokens": ":: Jekyll :: Commands :: New . process ( args , options )", "commit_type": "add"}
{"commit_tokens": ["Add", "max_bid", "and", "min_ask", "methods"], "add_tokens": "describe '#min_ask' do it \"should fetch the lowest priced ask\" do min_ask = @client . min_ask a_get ( '/code/data/getDepth.php' ) . should have_been_made . once min_ask . price . should == 17.00009 min_ask . amount . should == 36.22894353 end end describe '#max_bid' do it \"should fetch the highest priced bid\" do max_bid = @client . max_bid a_get ( '/code/data/getDepth.php' ) . should have_been_made . once max_bid . price . should == 17.0 max_bid . amount . should == 82.53875035 end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "system", "tests", "that", "use", "rack", "-", "test"], "add_tokens": "def render ( template_name , options = nil ) options ||= { } options [ :locals ] = { :view => @handler } . merge ( options [ :locals ] || { } ) @sinatra_call . erb ( template_name , options )", "del_tokens": "def render ( * args ) @sinatra_call . erb ( * args )", "commit_type": "add"}
{"commit_tokens": ["Remove", "id", "as", "a", "return", "parameter"], "add_tokens": "plot . to_html path = File . expand_path ( '../../templates/googlecharts/static_html.erb' , __FILE__ ) template = File . read ( path ) chart_script = generate_body ( plot )", "del_tokens": "chart_script , id = plot . to_html [ chart_script , id ] path = File . expand_path ( '../../templates/googlecharts/chart_div.erb' , __FILE__ ) template_div = File . read ( path ) chart_script , id = generate_body ( plot ) chart_div = ERB . new ( template_div ) . result ( binding ) path_static_html = File . expand_path ( '../../templates/googlecharts/static_html.erb' , __FILE__ ) template = File . read ( path_static_html )", "commit_type": "remove"}
{"commit_tokens": ["fix", "time", "zone", "handling", "for", "timestamps", "returning", "for", "cancel", "link"], "add_tokens": "content << content_tag ( :div , :class => 'form-actions' ) do form . button ( ti ( :\" button.save \" ) , :class => 'btn btn-primary' ) + ' ' + cancel_link ( object ) end link_to ( ti ( :\" button.cancel \" ) , polymorphic_path ( object , :returning => true ) , :class => 'cancel' ) when :datetime , :timestamp then \"#{f(val.to_date)} #{f(val.time)}\"", "del_tokens": "content << content_tag ( :div , form . button ( ti ( :\" button.save \" ) , :class => 'btn btn-primary' ) + ' ' + cancel_link ( object ) , :class => 'form-actions' ) link_to ( ti ( :\" button.cancel \" ) , polymorphic_path ( object ) , :class => 'cancel' ) when :datetime , :timestamp then \"#{f(val.to_date)} #{f(val.to_time)}\"", "commit_type": "fix"}
{"commit_tokens": ["Make", "unlock", "/", "yield", "order", "configurable", "."], "add_tokens": "def call ( worker , item , queue ) unlock_order = worker . class . get_sidekiq_options [ 'unique_unlock_order' ] || SidekiqUniqueJobs :: Config . default_unlock_order lock_key = payload_hash ( item ) unlocked = unlock_order == :before_yield ? unlock ( lock_key ) . inspect : 0 if unlock_order == :after_yield || ! defined? unlocked || unlocked != 1 unlock ( lock_key ) end def payload_hash ( item ) SidekiqUniqueJobs :: PayloadHelper . get_payload ( item [ 'class' ] , item [ 'queue' ] , item [ 'args' ] ) end def unlock ( payload_hash ) Sidekiq . redis { | conn | conn . del ( payload_hash ) } end", "del_tokens": "def call ( * args ) item = args [ 1 ] payload_hash = SidekiqUniqueJobs :: PayloadHelper . get_payload ( item [ 'class' ] , item [ 'queue' ] , item [ 'args' ] ) Sidekiq . redis { | conn | conn . del ( payload_hash ) }", "commit_type": "make"}
{"commit_tokens": ["fixing", "the", "nodes", "convenience", "method"], "add_tokens": "h [ 'nodes' ]", "del_tokens": "h [ 'metadata' ] [ 'nodes' ]", "commit_type": "fix"}
{"commit_tokens": ["add", "config", "for", "queue", "and", "aws", "connection"], "add_tokens": ":user_agent , :aws , :queue # sqs queue to write messages DEFAULT_QUEUE = 'production_fixer_job_create' . freeze self . aws = nil self . queue = ENV [ 'FIXER_QUEUE' ] || DEFAULT_QUEUE", "del_tokens": ":user_agent", "commit_type": "add"}
{"commit_tokens": ["added", "method", "to", "return", "the", "total", "time", "taken", "for", "a", "request"], "add_tokens": ":CURLINFO_RESPONSE_CODE => 2097154 , :CURLINFO_TOTAL_TIME => 3145731 def total_time_taken get_info_double ( INFO_VALUES [ :CURLINFO_TOTAL_TIME ] ) end def on_success = ( block ) @success = block end def on_failure = ( block ) @failure = block end", "del_tokens": ":CURLINFO_RESPONSE_CODE => 2097154", "commit_type": "add"}
{"commit_tokens": ["Improve", "plugin", "build", "in", "extconf", ".", "rb"], "add_tokens": "@debug_enabled = enable_config ( 'debug' ) qmake_opts = @debug_enabled ? 'CONFIG+=debug' : '' system ( \"#{@qmake} #{qmake_opts}\" ) && system ( 'make clean' ) && system ( 'make' ) or abort \"failed to build plugin: #{dir.basename}\" if @debug_enabled", "del_tokens": "system ( \"#{@qmake}\" ) && system ( 'make' ) or abort \"failed to build plugin: #{dir.basename}\" if enable_config ( 'debug' )", "commit_type": "improve"}
{"commit_tokens": ["added", "option", "for", "compressed", "output"], "add_tokens": ":import_paths => [ ] , :compress => false outfile << tree . to_css ( :compress => options [ :compress ] )", "del_tokens": ":import_paths => [ ] outfile << tree . to_css", "commit_type": "add"}
{"commit_tokens": ["changed", "client", "sequencer", "protocol", ":", "box", "the", "id", "in", "case", "of", "json", ";", "use", "object", "-", "stream"], "add_tokens": "require 'object-stream' attr_reader :stream_type def initialize server , * conns , log : Logger . new ( $stderr ) , stream_type : ObjectStream :: MSGPACK_TYPE @stream_type = stream_type stream = ObjectStream . new ( conn , type : stream_type ) stream << [ next_id ] # boxed for json stream . close if stream and not stream . closed?", "del_tokens": "require 'msgpack' def initialize server , * conns , log : Logger . new ( $stderr ) MessagePack . pack next_id , conn conn . close unless conn . closed?", "commit_type": "change"}
{"commit_tokens": ["Make", "sure", "to", "read", "all", "messages", "received"], "add_tokens": "@connection . receive . each do | msg | params = parser ( msg ) # why ? next if params [ 'socket_id' ] && params [ 'socket_id' ] == self . socket_id send_local_event ( params [ 'event' ] , params [ 'data' ] , params [ 'channel' ] ) end", "del_tokens": "msg = @connection . receive . first next if msg . nil? params = parser ( msg ) next if params [ 'socket_id' ] && params [ 'socket_id' ] == self . socket_id send_local_event ( params [ 'event' ] , params [ 'data' ] , params [ 'channel' ] )", "commit_type": "make"}
{"commit_tokens": ["Move", "attrs", "to", "the", "top", "of", "the", "file"], "add_tokens": "attr_reader :server , :name , :account_name , :password , :layout , :script attr_writer :account_name , :password end", "del_tokens": "attr_reader :server , :name , :account_name , :password , :layout , :script attr_writer :account_name , :password end", "commit_type": "move"}
{"commit_tokens": ["Remove", "old", "spec", "helpers", "and", "add", "newer", "ones"], "add_tokens": "let ( :text_body ) { email . parts . select { | part | part . mime_type == 'text/plain' } . body . to_s } let ( :html_body ) { email . parts . select { | part | part . mime_type == 'text/html' } . body . to_s } let ( :body ) { email . body . to_s } use_css <<-CSS body { background : #000 } p { color : #f00; line-height: 1.5 } . text { font - size : 14 px } CSS describe \"text/html\" do let ( :email ) { TestMailer . singlepart_html } it \"should have styles applied\" do body . should match ( / <body style=\"background: #000\"> / ) end describe \"text/plain\" do let ( :email ) { TestMailer . singlepart_plain } it \"should not be changed\" do body . should eql ( '<p class=\"text\">Hello World</p>' ) end", "del_tokens": "before ( :each ) { pending } before ( :each ) do css_rules <<-EOF body { background : #000 } p { color : #f00; line-height: 1.5 } . text { font - size : 14 px } EOF end it \"should apply styles for text/html\" do @email = TestMailer . deliver_test_singlepart_html ( :real ) @email . body . should match ( / <body style=\"background: #000\"> / ) it \"should do nothing for text/plain\" do @email = TestMailer . deliver_test_singlepart_plain ( :real ) @email . body . should eql ( '<p class=\"text\">Hello World</p>' )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "false", "positive", "regarding", "rand", "spec"], "add_tokens": "f . email { \"janjiss+#{ rand(300) }@gmail.com\" }", "del_tokens": "f . email { 'janjiss+#{ rand(300) }@gmail.com' }", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "pending", "word", "in", "command", "line"], "add_tokens": "BASIC_KEYWORDS = %w{ name native describe before after it pending subject its should should_not }", "del_tokens": "BASIC_KEYWORDS = %w{ name native describe before after it subject its should should_not }", "commit_type": "add"}
{"commit_tokens": ["Add", "security", "context", "for", "request", "specific", "role", "resolution"], "add_tokens": "# @param [Context] context of the request that may limit resolved roles. def roles_for ( principal , context , reload : false ) def roles_for ( principal , context , reload : false )", "del_tokens": "def roles_for ( principal , reload : false ) def roles_for ( principal )", "commit_type": "add"}
{"commit_tokens": ["Added", "depth", "to", "Token", "class", "and", "lexer", "unified", "naming"], "add_tokens": "TOKEN_KEYS = [ :type , :token , :text , :ts , :te , :depth ] . freeze", "del_tokens": "TOKEN_KEYS = [ :type , :id , :text , :ts , :te ] . freeze", "commit_type": "add"}
{"commit_tokens": ["fix", "radius", "/", "rankby", "synergy", "problem", "(", "online", "one", "of", "it", "can", "exist", ")"], "add_tokens": "radius = options . delete ( :radius ) || 200 if rankby . nil? sensor = options . delete ( :sensor ) || false", "del_tokens": "radius = options . delete ( :radius ) || 200 sensor = options . delete ( :sensor ) || false", "commit_type": "fix"}
{"commit_tokens": ["Make", "merge", "&", "validating", "an", "item", "faster"], "add_tokens": "def merge_and_validate ( user_defined_values ) random_payload = @random_generator . payload item_merged_with_user_input = random_payload . merge ( Utils . stringify_keys ( user_defined_values ) ) errors = validation_errors_for ( item_merged_with_user_input ) errors_on_random_payload = validation_errors_for ( random_payload ) if errors_on_random_payload . any? # The original item was invalid when it was generated, so it's not # the users fault. raise InvalidContentGenerated , error_message ( random_payload , errors ) else # The random item was valid, but it was merged with something invalid. raise InvalidContentGenerated , error_message_custom ( item_merged_with_user_input , user_defined_values , errors ) end item_merged_with_user_input", "del_tokens": "def merge_and_validate ( hash ) item = payload . merge ( Utils . stringify_keys ( hash ) ) errors = validation_errors_for ( item ) raise InvalidContentGenerated , error_message_custom ( item , hash , errors ) item", "commit_type": "make"}
{"commit_tokens": ["Change", "name", "of", "form", "to", "editor", "."], "add_tokens": "attr_reader :model , :editor , :list @editor = EditorBuilder . new ( self ) class EditorBuilder @form_fields << Form :: Element . new ( name , * args ) @form_fields = [ ] def form_fields if @form_fields . empty? @form_fields << Form :: Element . new ( :text_field , column ) @form_fields @form_fields << Form :: CollectionCheckBoxes . new ( :collection_check_boxes , * args ) @form_fields << Form :: CollectionRadioButtons . new ( :collection_radio_buttons , * args ) @form_fields << Form :: CollectionSelect . new ( :collection_select , * args ) @form_fields << Form :: GroupedCollectionSelect . new ( :grouped_collection_select , * args )", "del_tokens": "attr_reader :model , :form , :list @form = FormBuilder . new ( self ) class FormBuilder @fields << Form :: Element . new ( name , * args ) @fields = [ ] def fields if @fields . empty? @fields << Form :: Element . new ( :text_field , column ) @fields @fields << Form :: CollectionCheckBoxes . new ( :collection_check_boxes , * args ) @fields << Form :: CollectionRadioButtons . new ( :collection_radio_buttons , * args ) @fields << Form :: CollectionSelect . new ( :collection_select , * args ) @fields << Form :: GroupedCollectionSelect . new ( :grouped_collection_select , * args )", "commit_type": "change"}
{"commit_tokens": ["Added", "the", "Variables#env_hash", "method", "."], "add_tokens": "# # The environment variables. # # @return [Hash{String => String}] # The Hash of environment variable names and values. # def env_hash ENV end parse_paths ( env_hash [ 'PATH' ] ) parse_paths ( env_hash [ 'LD_LIBRARY_PATH' ] ) if ( home = ( env_hash [ 'HOME' ] || env_hash [ 'HOMEPATH' ] ) ) env_hash [ 'LANG' ] . split ( '.' , 2 ) env_hash [ 'COLUMNS' ] . to_i if env_hash [ 'COLUMNS' ] env_hash [ 'LINES' ] . to_i if env_hash [ 'LINES' ] env_hash [ 'SHELL' ] env_hash [ 'COLORTERM' ] || env_hash [ 'TERM' ] env_hash [ 'EDITOR' ] env_hash [ 'BROWSER' ]", "del_tokens": "parse_paths ( ENV [ 'PATH' ] ) parse_paths ( ENV [ 'LD_LIBRARY_PATH' ] ) if ( home = ( ENV [ 'HOME' ] || ENV [ 'HOMEPATH' ] ) ) ENV [ 'LANG' ] . split ( '.' , 2 ) ENV [ 'COLUMNS' ] . to_i if ENV [ 'COLUMNS' ] ENV [ 'LINES' ] . to_i if ENV [ 'LINES' ] ENV [ 'SHELL' ] ENV [ 'COLORTERM' ] || ENV [ 'TERM' ] ENV [ 'EDITOR' ] ENV [ 'BROWSER' ]", "commit_type": "add"}
{"commit_tokens": ["Implement", "persistent_params", "helper", "and", "config", "option"], "add_tokens": "sort_link = SortLink . new ( field , persistent_params , options ) @params . merge ( sort : field , order : order )", "del_tokens": "sort_link = SortLink . new ( field , params , options ) @params . permit ( :sort , :order , :q ) . merge ( sort : field , order : order )", "commit_type": "implement"}
{"commit_tokens": ["Make", "sure", "that", "require_params", "tests", "for", "nil", "."], "add_tokens": "if instance_variable_get ( \"@#{name}\" . to_sym ) . nil?", "del_tokens": "unless instance_variable_get ( \"@#{name}\" . to_sym )", "commit_type": "make"}
{"commit_tokens": ["Changed", "Model#attributes", "=", "to", "Model#properties", "=", "."], "add_tokens": "resource . properties = { model . serial . name => st . insert_id }", "del_tokens": "resource . attributes = { model . serial . name => st . insert_id }", "commit_type": "change"}
{"commit_tokens": ["added", "fairly", "comprehensive", "error", "retry", "for", "workers", "...", "in", "practice", "seems", "to", "work", "fairly", "well"], "add_tokens": "DEFAULT_WAIT = Dogpile :: CONFIG [ 'default_worker_wait' ] MAX_WAIT = Dogpile :: CONFIG [ 'max_worker_wait' ] WAIT_MULTIPLIER = Dogpile :: CONFIG [ 'worker_wait_multiplier' ] @wait_time = DEFAULT_WAIT @wait_time = DEFAULT_WAIT @wait_time = [ @wait_time * WAIT_MULTIPLIER , MAX_WAIT ] . min sleep @wait_time", "del_tokens": "DEFAULT_SLEEP_TIME = Dogpile :: CONFIG [ 'default_worker_sleep_time' ] MAX_SLEEP_TIME = Dogpile :: CONFIG [ 'max_worker_sleep_time' ] SLEEP_MULTIPLIER = Dogpile :: CONFIG [ 'worker_sleep_multiplier' ] @sleep_time = DEFAULT_SLEEP_TIME @sleep_time = DEFAULT_SLEEP_TIME @sleep_time = [ @sleep_time * SLEEP_MULTIPLIER , MAX_SLEEP_TIME ] . min sleep @sleep_time", "commit_type": "add"}
{"commit_tokens": ["Add", "delete", "and", "refresh", "commands", "to", "the", "cli"], "add_tokens": "success_message \"Manifest is being uploaded in task %{id}s\" class DeleteManfiestCommand < HammerCLIKatello :: WriteCommand resource KatelloApi :: Resources :: Subscription , 'delete_manifest' command_name \"delete_manifest\" success_message \"Manifest is being deleted in task %{id}s\" failure_message \"Manifest deletion failed\" apipie_options end class RefreshManfiestCommand < HammerCLIKatello :: WriteCommand resource KatelloApi :: Resources :: Subscription , 'refresh_manifest' command_name \"refresh_manifest\" success_message \"Manifest is being refreshed in task %{id}s\" failure_message \"Manifest refresh failed\" apipie_options end", "del_tokens": "success_message \"Manifest is being uploaded\"", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "handling", "of", "method_eval"], "add_tokens": "return nil if ( method_name == :eval )", "del_tokens": "@privileges . allow_method :eval RallHook :: Hook . from ( 0 )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "file", "existance", "check", "at", "end", "of", "itcss", "init"], "add_tokens": "File . open @ITCSS_CONFIG_TEMPLATE do | io | template = ERB . new io . read content = init_config . to_yaml File . open @ITCSS_CONFIG_FILE , \"w+\" do | out | out . puts template . result binding puts \"#{@ITCSS_CONFIG_FILE} successfully created!\" . green", "del_tokens": "unless File . exist? ( @ITCSS_CONFIG_FILE ) File . open @ITCSS_CONFIG_TEMPLATE do | io | template = ERB . new io . read content = init_config . to_yaml File . open @ITCSS_CONFIG_FILE , \"w+\" do | out | out . puts template . result binding end puts \"#{@ITCSS_CONFIG_FILE} successfully created!\" . green else puts \"#{@ITCSS_CONFIG_FILE} already exists.\" . red abort", "commit_type": "remove"}
{"commit_tokens": ["fixed", "issue", "with", "exceptions", "not", "showing"], "add_tokens": "if not @curs . nil? rescue Exception => e set_message \"#{e.message}\\n#{e.backtrace.join(\"\\n\")}\" # Wait for the cursor to die -- can cause problems otherwise while @curs . alive? ; end if @curs . nil?", "del_tokens": "if defined? @curs rescue set_message \"Task failed...\" if not defined? @curs", "commit_type": "fix"}
{"commit_tokens": ["Fix", "specs", "now", "that", "logging", "is", "not", "included", "by", "default"], "add_tokens": "require 'maestro_plugin/logging_stdout'", "del_tokens": "require 'logger'", "commit_type": "fix"}
{"commit_tokens": ["Make", "tests", "pass", "using", "mathn", "."], "add_tokens": "c = ( a + b ) . div ( 2 )", "del_tokens": "c = ( a + b ) / 2", "commit_type": "make"}
{"commit_tokens": ["Added", "first", "test", "for", "button", "."], "add_tokens": "require 'page-object/elements' describe Button do context \"when mapping how to find an element\" do it \"should map watir types to same\" do [ :class , :id , :index , :name , :xpath ] . each do | t | identifier = Button . watir_identifier_for t => 'value' identifier . keys . first . should == t end", "del_tokens": "class TestPageObject include PageObject button ( :click_me , { :id => 'click_me' } ) end describe \"button accessors\" do let ( :watir_browser ) { mock_watir_browser } let ( :selenium_browser ) { mock_selenium_browser } let ( :watir_page_object ) { TestPageObject . new ( watir_browser ) } let ( :selenium_page_object ) { TestPageObject . new ( selenium_browser ) } context \"when called on a page object\" do it \"should generate accessor methods\" do watir_page_object . should respond_to :click_me watir_page_object . should respond_to :click_me= # context \"Watir implementation\" do # it \"should get the current item from a select list\" do # watir_browser.stub_chain(:select_list, :value).and_return(\"OH\") # watir_page_object.state.should == \"OH\" # end # # it \"should set the current item of a select list\" do # watir_browser.stub(:select_list).and_return watir_browser # watir_browser.stub(:select).with(\"OH\") # watir_page_object.state = \"OH\" # end # end # # context \"Selenium implementation\" do # it \"should should get the current item from a select list\" do # selenium_browser.stub_chain(:find_element, :attribute).and_return(\"OH\") # selenium_page_object.state.should == \"OH\" # end # # it \"should set the current item of a select list\" do # selenium_browser.stub_chain(:find_element, :send_keys).with(\"OH\") # selenium_page_object.state = \"OH\" # end # end", "commit_type": "add"}
{"commit_tokens": ["updating", "the", "server", "commands", "so", "--", "yes", "works", "and", "enables", "you", "to", "skip", "actions", "by", "entering", "N"], "add_tokens": ":description => \"start, stop or destroy the instances in your result\"", "del_tokens": ":description => \"start or stop the instances in your result\"", "commit_type": "update"}
{"commit_tokens": ["fixed", "typo", "of", "WardenStrategies", "::", "Bcypt", "into", "WardenStrategies", "::", "Bcrypt"], "add_tokens": "Warden :: Strategies . add ( :simple_bcrypt , WardenStrategies :: Bcrypt )", "del_tokens": "Warden :: Strategies . add ( :simple_bcypt , WardenStrategies :: Bcrypt )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "phrases", "list", "when", "no", "cache", "configured"], "add_tokens": "conditions = [ \"\" ] if Tr8n :: Config . enable_caching? conditions [ 0 ] << [ \"verified_at is not null\" ] end", "del_tokens": "conditions = [ \"verified_at is not null\" ]", "commit_type": "fix"}
{"commit_tokens": ["use", "absolute", "paths", "instead", "of", "relative"], "add_tokens": "path = File . join ( File . dirname ( __FILE__ ) , 'classy' ) Dir . foreach ( path ) do | entry | require \"#{path}/#{entry}\" if entry =~ / \\. rb$ /", "del_tokens": "Dir . foreach ( File . join ( File . dirname ( __FILE__ ) , 'classy' ) ) do | entry | require \"classy/#{entry}\" if entry =~ / \\. rb$ /", "commit_type": "use"}
{"commit_tokens": ["Add", "tests", "for", "Thermite", "::", "GithubReleaseBinary"], "add_tokens": "# :nocov: # :nocov: raise Net :: HTTPServerException . new ( response . message , response ) unless ENV . key? ( 'THERMITE_TEST' ) # :nocov: puts \"Downloading latest compiled version (#{version}) from GitHub\" # :nocov: end", "del_tokens": "raise response puts \"Downloading latest compiled version (#{version}) from GitHub\"", "commit_type": "add"}
{"commit_tokens": ["add", "image", "element", "/", "s"], "add_tokens": "# @!method find_image_occurrence(full_image:, partial_image:, visualize: false, threshold: nil) # @param [Float] threshold: [0.5] At what normalized threshold to reject def find_image_occurrence ( full_image : , partial_image : , visualize : false , threshold : nil ) options [ :threshold ] = threshold unless threshold . nil?", "del_tokens": "# @!method find_image_occurrence(full_image:, partial_image:, detector_name: 'ORB', visualize: false) def find_image_occurrence ( full_image : , partial_image : , visualize : false )", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "new", "GA", "code"], "add_tokens": "# Specify whether the legacy Google Analytics code should be used. @@legacy_mode = false cattr_accessor :legacy_mode # analytics URL. This is only applicable in legacy mode. # analytics URL (ssl version). This is only applicable in legacy mode. return legacy_google_analytics_code ( request ) if legacy_mode extra_code = domain_name . blank? ? nil : \"pageTracker._setDomainName(\\\"#{domain_name}\\\");\" code = <<-HTML < script type = \"text/javascript\" > var gaJsHost = ( ( \"https:\" == document . location . protocol ) ? \"https://ssl.\" : \"http://www.\" ) ; document . write ( unescape ( \"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\" ) ) ; < / script > < script type = \"text/javascript\" > var pageTracker = _gat . _getTracker ( \"#{tracker_id}\" ) ; #{extra_code} pageTracker . _initData ( ) ; pageTracker . _trackPageview ( ) ; < / script > HTML code end # Run the legacy version of the Google Analytics code. def self . legacy_google_analytics_code ( request = nil ) end", "del_tokens": "# analytics URL. # analytics URL (ssl version). end", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "raise", "for", "a", "non", "-", "existant", "failure", "app", "to", "the", "point", "of", "call", ".", "This", "way", "the", "app", "can", "be", "specified", "at", "a", "later", "time", "rather", "than", "specifying", "it", "at", "the", "point", "of", "building", "the", "stack"], "add_tokens": "raise \"No Failure App provided\" unless @failure_app", "del_tokens": "raise \"No Failure App provided\" unless @failure_app", "commit_type": "move"}
{"commit_tokens": ["Remove", "enviroment", "cleanup", "until", "implemented", "."], "add_tokens": "it \"should uninstall by migrating down and removing the directory\" do", "del_tokens": "it \"should uninstall by migrating down, removing the directory and cleaning up environment\" do @uninstaller . should_receive ( :cleanup_environment ) it \"should cleanup the environment\" do pending end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "specs", "about", "LU", "factorization", "methods"], "add_tokens": "Numo :: DFloat . eye ( m ) . tap do | mat | ipiv . to_a . each_with_index { | a , b | mat [ [ a - 1 , b ] , true ] = mat [ [ b , a - 1 ] , true ] . dup } mat_l = lu . tril . tap { | mat | mat [ mat . diag_indices ( 0 ) ] = 1.0 } mat_l = lu . tril . tap { | mat | mat [ mat . diag_indices ( 0 ) ] = 1.0 }", "del_tokens": "mat_p = Numo :: DFloat . eye ( m ) ( ipiv - 1 ) . to_a . each_with_index . select do | a , b | unless a - b == 0 tmp = mat_p [ b , true ] . dup mat_p [ b , true ] = mat_p [ a , true ] mat_p [ a , true ] = tmp end mat_p end it 'raises ArgumentError given a invalid mode option' do expect { described_class . lu_fact ( Numo :: DFloat . new ( 2 , 4 ) . rand , mode : 'foo' ) } . to raise_error ( ArgumentError ) mat_l = lu . tril mat_l [ mat_l . diag_indices ( 0 ) ] = 1.0 mat_l = lu . tril mat_l [ mat_l . diag_indices ( 0 ) ] = 1.0", "commit_type": "fix"}
{"commit_tokens": ["Added", "block", "form", "to", "link_to_add", "and", "link_to_remove"], "add_tokens": "# ==== Signatures # # link_to_add(content, association) # # link_to_add(association) do # # content # end # def link_to_add ( * args , & block ) if block_given? content = @template . capture ( & block ) association = args . first else content = args . first association = args . second end @template . link_to ( content , \"javascript:void(0)\" , :class => \"add_nested_fields\" , \"data-association\" => association ) # ==== Signatures # # link_to_remove(content) # # link_to_add do # # content # end # def link_to_remove ( * args , & block ) if block_given? content = @template . capture ( & block ) else content = args . first end hidden_field ( :_destroy ) + @template . link_to ( content , \"javascript:void(0)\" , :class => \"remove_nested_fields\" )", "del_tokens": "def link_to_add ( name , association ) @template . link_to ( name , \"javascript:void(0)\" , :class => \"add_nested_fields\" , \"data-association\" => association ) def link_to_remove ( name ) hidden_field ( :_destroy ) + @template . link_to ( name , \"javascript:void(0)\" , :class => \"remove_nested_fields\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "contacts", "support", "to", "whois", ".", "registro", ".", "br", "parser"], "add_tokens": "# @note This parser is just a stub and provides only a few basic methods # to check for domain availability and get domain status. # Please consider to contribute implementing missing methods. # # @see Whois::Parsers::Example # The Example parser for the list of all available methods.", "del_tokens": "# # = whois.registre.ma parser # # NOTE: This parser is just a stub and provides only a few basic methods # to check for domain availability and get domain status. # Please consider to contribute implementing missing methods. # See WhoisNicIt parser for an explanation of all available methods # and examples.", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "settings", "passed", "in", "Greeklish#converter"], "add_tokens": "converter = Greeklish . converter ( max_expansions : 2 , generate_greek_variants : false ) expect ( words . length ) . to eq ( 2 )", "del_tokens": "converter = Greeklish . converter ( max_expansions : 10 , generate_greek_variants : true )", "commit_type": "change"}
{"commit_tokens": ["Implemented", "support", "for", "FiSH", "encryption", "."], "add_tokens": "require 'blur/client' require 'blur/script' require 'blur/network' require 'blur/encryption' require 'blur/enhancements' require 'blur/script/cache' require 'blur/network/user' require 'blur/network/channel' require 'blur/network/command' require 'blur/network/connection' require 'blur/script/messageparsing'", "del_tokens": "Dir . glob ( \"#{File.dirname __FILE__}/blur/**/*.rb\" ) . each & method ( :require )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "the", "subexpressions", "after", "tokens", "bug"], "add_tokens": "VERSION = '2.1.1'", "del_tokens": "VERSION = '2.1.0'", "commit_type": "fix"}
{"commit_tokens": ["Added", "open", "/", "read", "timeouts"], "add_tokens": "http . read_timeout = 5 # seconds http . open_timeout = 2 # seconds response = begin http . post ( url . path , stringify_keys ( data ) . to_yaml , headers ) rescue TimeoutError => e logger . error \"Timeout while contacting the Hoptoad server.\" nil end", "del_tokens": "response = http . post ( url . path , stringify_keys ( data ) . to_yaml , headers )", "commit_type": "add"}
{"commit_tokens": ["Added", "TODO", "to", "README", "and", "fixed", "exception", "contract", "for", "job", "execution", ".", "Exceptions", "should", "not", "bubble", "up", "to", "runners", "."], "add_tokens": "# Looks up the correct worker class for a job and executes it, running it # through the runner middleware stack first. Returns true if the job finishes # without an exception, false otherwise. # # If you need to keep track of exceptions raised by jobs, add middleware to # handle them, like Woodhouse::Middleware::AirbrakeExceptions. begin @config . runner_middleware . call ( @job , work_object ) { | job , work_object | work_object . send ( job . job_method , job . arguments ) } return true rescue = > err # Ignore the exception return false", "del_tokens": "# TODO: want to do this kind of stuff through middleware if work_object . respond_to? ( :logger= ) work_object . logger = @config . logger @config . runner_middleware . call ( @job , work_object ) { | job , work_object | work_object . send ( job . job_method , job . arguments ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "pass", "sha", "to", "output", "and", "improve", "instructions", "."], "add_tokens": "pdf . text ( 'Be sure to cover the passphrase when scanning the QR code!' ' Decrypt with `gpg -d`.' ) \" Decode with `sixword -d`, then `gpg -d`.\" pdf . fill_rectangle ( xy , pixel_width , pixel_height )", "del_tokens": "pdf . text ( 'Be sure to cover the passphrase when scanning the QR code!' ) \" Decode with `sixword -d`\" pdf . fill_and_stroke_rectangle ( xy , pixel_width , pixel_height )", "commit_type": "add"}
{"commit_tokens": ["Use", "symbol", "rather", "than", "string", "from", "opts", "hash"], "add_tokens": "librarian_version = opts [ :librarian_version ] ||= nil", "del_tokens": "librarian_version = opts [ 'librarian_version' ] ||= nil", "commit_type": "use"}
{"commit_tokens": ["fixed", "bug", "with", "false", "value", "page", "properties"], "add_tokens": "value = @this . get ( var_name , false ) if value . nil? value = instance_variable_get ( \"@#{var_name}\" ) end value", "del_tokens": "@this . get ( var_name , false ) || instance_variable_get ( \"@#{var_name}\" )", "commit_type": "fix"}
{"commit_tokens": ["move", "clone", "dir", "to", "/", "srv", "/", "moonshine", "/", "#", "{", "application", "}"], "add_tokens": "@path ||= \"/srv/moonshine/#{name}\"", "del_tokens": "@path ||= \"/var/lib/moonshine/#{name}\"", "commit_type": "move"}
{"commit_tokens": ["fix", "seed", "structure", "admin", "accessible", "&&", "frendly_id", "static"], "add_tokens": "main_page = Structure . create! ( { :title => \" \", :slug => \"mai n page\" : tructure_ty p => StructureTy e. ain, :parent = > ni l , :as = : dmi n ) #Structure.create!({:title => \"\", :slug => \"broadcasts\", :structure_type => StructureType.broadcasts, :parent => main_page}, :as => :admin) #Structure.create!({:title => \" \", :slug => \"posts\", :structure_type => StructureType.posts, :parent => main_page}, :as => :admin)", "del_tokens": "main_page = Structure . create! ( :title => \" \", :slug => \"mai n page\" : tructure_ty p => StructureTy e. ain, :parent = > ni l #Structure.create!(:title => \"\", :slug => \"broadcasts\", :structure_type => StructureType.broadcasts, :parent => main_page) #Structure.create!(:title => \" \", :slug => \"posts\", :structure_type => StructureType.posts, :parent => main_page)", "commit_type": "fix"}
{"commit_tokens": ["add", "logging", "to", "rake", "task"], "add_tokens": "run ( \"cd #{current_path}; nohup #{rake} RAILS_ENV=#{stage} QUEUE=#{queue} resque:work >> log/resque_worker.log 2>&1\" , :hosts => hosts ) run ( \"cd #{current_path}; nohup #{rake} RAILS_ENV=#{stage} COUNT=#{count} QUEUE=#{queue} resque:work >> log/resque_worker.log 2>&1\" , :hosts => hosts )", "del_tokens": "run ( \"cd #{current_path}; nohup #{rake} RAILS_ENV=#{stage} QUEUE=#{queue} resque:work\" , :hosts => hosts ) run ( \"cd #{current_path}; nohup #{rake} RAILS_ENV=#{stage} COUNT=#{count} QUEUE=#{queue} resque:work\" , :hosts => hosts )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "stupid", "typo", "merging", "errors", ".", "Sorry", "to", "anyone", "who", "used", "this", "in", "the", "last", "day", "or", "two", "."], "add_tokens": "class ActiveRecord :: Base # Creates a single record of seed data for use # with the db:seed rake task. # # === Parameters # constraints :: Immutable reference attributes. Defaults to :id def self . seed ( * constraints , & block ) SeedFu :: Seeder . plant ( self , * constraints , & block ) end def self . seed_many ( * constraints ) seeds = constraints . pop seeds . each do | seed_data | seed ( * constraints ) do | s | seed_data . each_pair do | k , v | s . send \"#{k}=\" , v end", "del_tokens": "# Creates a single record of seed data for use # with the db:seed rake task. # # === Parameters # constraints :: Immutable reference attributes. Defaults to :id def self . seed ( * constraints , & block ) Seeder . plant ( self , * constraints , & block ) end def self . seed_many ( * constraints ) seeds = constraints . pop seeds . each do | seed_data | seed ( * constraints ) do | s | seed_data . each_pair do | k , v | s . send \"#{k}=\" , v", "commit_type": "fix"}
{"commit_tokens": ["Fix", "method", "description", "comment", "and", "remove", "blank", "line"], "add_tokens": "# This method intends to inject the error inside the context of the use case, # so we can identify the use case from it was raised", "del_tokens": "# This method intends to raise the error inside the context of the use case # So we can have a more specific", "commit_type": "fix"}
{"commit_tokens": ["Removed", "requirement", "for", "specific", "activerecord", "vesion"], "add_tokens": "VERSION = \"0.0.16\"", "del_tokens": "VERSION = \"0.0.15\"", "commit_type": "remove"}
{"commit_tokens": ["Adds", "more", "specs", "regarding", "service", "authorization"], "add_tokens": "shared_examples_for :it_is_not_authorized do context 'when no authorization is specified' do it_behaves_like :it_is_not_authorized end context 'when the context is not authorized' do before ( :each ) do allow ( authorization_context ) . to receive ( :meets_some_criteria? ) . and_return ( false ) end it_behaves_like :it_is_not_authorized end", "del_tokens": "context 'when no authorization is specified' do", "commit_type": "add"}
{"commit_tokens": ["change", "name", "of", "sortable", "author", "/", "title", "macros", "to", "marc_", "*"], "add_tokens": "def marc_sortable_author def marc_sortable_title", "del_tokens": "def sortable_author def sortable_title", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "missing", "copyright", "header", ";", "added", "code", "to", "compute", "an", "agent", "identity", "token", "verifier", "."], "add_tokens": "# # Copyright (c) 2009 RightScale Inc # # Permission is hereby granted, free of charge, to any person obtaining # a copy of this software and associated documentation files (the # \"Software\"), to deal in the Software without restriction, including # without limitation the rights to use, copy, modify, merge, publish, # distribute, sublicense, and/or sell copies of the Software, and to # permit persons to whom the Software is furnished to do so, subject to # the following conditions: # # The above copyright notice and this permission notice shall be # included in all copies or substantial portions of the Software. # # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, # EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF # MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND # NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE # LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION # WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. # def self . create_verifier ( base_id , auth_token , timestamp ) hmac = OpenSSL :: HMAC . new ( auth_token , OpenSSL :: Digest :: SHA1 . new ) hmac . update ( base_id . to_s ) hmac . update ( ID_SEPARATOR ) hmac . update ( timestamp . to_s ) return hmac . hexdigest end", "del_tokens": "# Copyright (c) 2009 RightScale, Inc, All Rights Reserved Worldwide.", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "parameter", "to", "use", "the", "tracking", "code", "only", "in", "a", "given", "environment"], "add_tokens": "@env = options [ :env ] || \"production\" return [ @status , @headers , @response ] unless @headers [ 'Content-Type' ] =~ / html / && Rails . env . casecmp ( @env ) == 0", "del_tokens": "return [ @status , @headers , @response ] unless @headers [ 'Content-Type' ] =~ / html /", "commit_type": "add"}
{"commit_tokens": ["Made", "DObject", "slightly", "more", "restrictive", "as", "to", "when", "to", "call", "DRead"], "add_tokens": "if file_name . is_a? ( String ) and file_name != \"\"", "del_tokens": "if file_name != nil and file_name != \"\"", "commit_type": "make"}
{"commit_tokens": ["Use", "build", "custom", "version", "for", "comparison", "."], "add_tokens": "match = version_str . match / (.+) \\+ (.+) / match [ 1 ] match [ 2 ] Logger . dot \"#{package_name.bold} - #{version.bold} (#{ref})\" FileUtils . rm_rf ( package_path ) if Dir . exist? ( package_path ) match = value . match / (.+) \\+ (.+) / match [ 1 ]", "del_tokens": "match = version_str . match / 1000 \\. 0 \\. 0-(.+)-(.+) / match [ 2 ] match [ 1 ] Logger . dot \"#{package_name.bold} - #{version.bold}\" return if Dir . exist? ( package_path ) match = value . match / 1000 \\. 0 \\. 0-(.+)-(.+) / match [ 2 ]", "commit_type": "use"}
{"commit_tokens": ["Fixing", "problem", "with", "execution", "of", "command", "type"], "add_tokens": "kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg321 &>/dev/null && mpg321 #{nyan_mp3} &>/dev/null &\" ) if kernel . system ( 'which mpg321 && type mpg321' ) kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg123 &>/dev/null && mpg123 #{nyan_mp3} &>/dev/null &\" ) if kernel . system ( 'which mpg123 && type mpg123' ) system ( \"killall -9 mpg321 &>/dev/null\" ) if kernel . system ( \"which mpg321 && type mpg321\" ) system ( \"killall -9 mpg123 &>/dev/null\" ) if kernel . system ( \"which mpg123 && type mpg123\" )", "del_tokens": "kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg321 &>/dev/null && mpg321 #{nyan_mp3} &>/dev/null &\" ) if kernel . system ( \"type mpg321\" ) kernel . system ( \"[ -e #{nyan_mp3} ] && type mpg123 &>/dev/null && mpg123 #{nyan_mp3} &>/dev/null &\" ) if kernel . system ( \"type mpg123\" ) system ( \"killall -9 mpg321 &>/dev/null\" ) if kernel . system ( \"type mpg321\" ) system ( \"killall -9 mpg123 &>/dev/null\" ) if kernel . system ( \"type mpg123\" )", "commit_type": "fix"}
{"commit_tokens": ["added", "yard", "documentation", "to", "track"], "add_tokens": "#@private class Class # :nodoc: @basic_properties ||= [ ] instance_variable_set ( property , other_object . instance_variable_get ( property ) )", "del_tokens": "class Class @basic_properties = [ ] instance_variable_set ( property , other_object . instance_variable_get ( property ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "DisjunctionSumScorer", ".", "It", "s", "now", "possible", "to", "do", "disjunction", "(", "or", ")", "queries"], "add_tokens": "def initialize ( sub_scorers , minimum_nr_matchers = 1 )", "del_tokens": "def initialized ( sub_scorers , minimum_nr_matchers = 1 )", "commit_type": "fix"}
{"commit_tokens": ["add", "any", "known", "projection", "in", "Proj4", "::", "Projection", ".", "for_srid"], "add_tokens": "begin Proj4 :: Projection . new 'init=epsg:' + srid . to_s rescue raise \"Unsupported srid: #{srid}\" end", "del_tokens": "raise \"Unsupported srid: #{srid}\"", "commit_type": "add"}
{"commit_tokens": ["making", "better", "use", "of", "Rack", "::", "Request"], "add_tokens": "Rack :: Request . new ( 'REQUEST_METHOD' => 'GET' , 'PATH_INFO' => '/' ) Rack :: Request . new ( 'REQUEST_METHOD' => 'GET' , 'PATH_INFO' => '/bar' )", "del_tokens": "'REQUEST_METHOD' => 'GET' , 'PATH_INFO' => '/' 'REQUEST_METHOD' => 'GET' , 'PATH_INFO' => '/bar'", "commit_type": "make"}
{"commit_tokens": ["Fixed", "bug", "where", "non", "=", "string", "objects", "would", "not", "be", "cast", "to", "strings", "."], "add_tokens": "record_condensed += ' ' + record . send ( f ) . to_s if record . send ( f )", "del_tokens": "record_condensed += ' ' + record . send ( f ) if record . send ( f )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "regression", "for", "missing", "background", "image"], "add_tokens": "image_manager . draw script [ :background ] [ :id ] , nil , nil , script [ :background ] [ :animation ] , script [ :background ]", "del_tokens": "image_manager . draw script [ :background ] [ :id ] , script [ :background ] [ :animation ] , script [ :background ]", "commit_type": "fix"}
{"commit_tokens": ["added", "more", "sensor", "data", "to", "fixtures", "and", "refactored", "parsing", "of", "sensor", "data"], "add_tokens": "@sensors . count . should eq ( 99 ) @sensors . templist . count . should . should eq ( 43 ) @sensors . templist . each do | temp | puts temp . inspect end @sensors . names . count . should eq ( 99 ) end it 'should return an empty list if no data exists' do @sensors . stub ( :getsensors ) . and_return ( nil ) @sensors . names . count . should eq ( 0 )", "del_tokens": "@sensors . count . should eq ( 63 ) @sensors . templist . count . should . should eq ( 14 ) @sensors . names . count . should eq ( 63 )", "commit_type": "add"}
{"commit_tokens": ["added", "a", "working", "test", "suite", ".", "also", "cleaned", "up", "some", "jeweler", "garbage", "."], "add_tokens": "def setup @tabula = Faker :: TabulaIpsum . new end def test_one_word_tabula_ipsum # \"TabulaIpsum with one word will generate text of this one word\" @tabula . wordlist = [ \"foo\" ] assert_equal ( [ \"foo\" ] , @tabula . words ( 1 ) ) assert_match ( / foo /i , @tabula . sentence ) end def test_five_word_tabula_ipsum @tabula . wordlist = [ \"foo\" , \"foo\" , \"foo\" , \"foo\" , \"foo\" ] assert ( @tabula . sentence . scan ( \"foo\" ) . size > 3 )", "del_tokens": "should \"probably rename this file and start testing for real\" do flunk \"hey buddy, you should probably rename this file and start testing for real\"", "commit_type": "add"}
{"commit_tokens": ["add", "doc", "for", ":", "basic_auth_only"], "add_tokens": "basic_auth_only! if opts [ :basic_auth_only ] basic_auth_only! if opts [ :basic_auth_only ]", "del_tokens": "basic_auth_only! if opts [ :basic_only ] basic_auth_only! if opts [ :basic_only ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "possibly", "useless", "use", "of", "a", "variable", "in", "void", "context", "warnings"], "add_tokens": "_foo = new_str", "del_tokens": "new_str", "commit_type": "fix"}
{"commit_tokens": ["moved", "src", "dir", "to", "more", "standard", "names", "ext", "dir"], "add_tokens": "CLOBBER . include ( 'pkg/*' , 'proj4rb-doc/**/*' , 'lib/*.so' , 'lib/*.bundle' , 'lib/*.dll' , 'ext/*.o' , 'ext/*.so' , 'ext/*.bundle' , 'ext/*.dll' , 'ext/Makefile' , 'ext/mkmf.log' ) file 'ext/Makefile' => [ 'ext/extconf.rb' ] do sh 'cd ext; ruby extconf.rb' task :build => [ 'ext/Makefile' , 'ext/projrb.c' ] do sh 'cd ext; make' if File . exists? ( 'ext/projrb.' + suffix ) puts \"Copying 'ext/projrb.#{suffix}' to lib/\" File . copy ( 'ext/projrb.' + suffix , 'lib/projrb.' + suffix ) rdoc . rdoc_files . include ( 'ext/*.c' , 'lib/proj4.rb' ) s . extensions = [ \"ext/extconf.rb\" ] s . files = FileList [ \"lib/**/*.rb\" , \"lib/**/*.dll\" , \"lib/**/*.so\" , \"lib/**/*.bundle\" , \"example/**/*.rb\" , \"ext/extconf.rb\" , \"ext/*.h\" , \"ext/*.c\" , \"test/**/*.rb\" , \"README\" , \"MIT-LICENSE\" , \"rakefile.rb\" ]", "del_tokens": "CLOBBER . include ( 'pkg/*' , 'proj4rb-doc/**/*' , 'lib/*.so' , 'lib/*.bundle' , 'lib/*.dll' , 'src/*.o' , 'src/*.so' , 'src/*.bundle' , 'src/*.dll' , 'src/Makefile' , 'src/mkmf.log' ) file 'src/Makefile' => [ 'src/extconf.rb' ] do sh 'cd src; ruby extconf.rb' task :build => [ 'src/Makefile' , 'src/projrb.c' ] do sh 'cd src; make' if File . exists? ( 'src/projrb.' + suffix ) puts \"Copying 'src/projrb.#{suffix}' to lib/\" File . copy ( 'src/projrb.' + suffix , 'lib/projrb.' + suffix ) rdoc . rdoc_files . include ( 'src/**/*.c' , 'lib/proj4.rb' ) s . extensions = [ \"src/extconf.rb\" ] s . files = FileList [ \"lib/**/*.rb\" , \"lib/**/*.dll\" , \"lib/**/*.so\" , \"lib/**/*.bundle\" , \"example/**/*.rb\" , \"src/extconf.rb\" , \"src/**/*.h\" , \"src/**/*.c\" , \"test/**/*.rb\" , \"README\" , \"MIT-LICENSE\" , \"rakefile.rb\" ]", "commit_type": "move"}
{"commit_tokens": ["Allowed", "for", ":", "dependent", "=", ">", ":", "destroy", "in", "group", "models", "to", "work", "for", "online", "mode", "group", "deletions"], "add_tokens": "before_destroy :before_mirrored_data_destroy after_destroy :after_mirrored_data_destroy before_save :before_mirrored_data_save after_save :after_mirrored_data_save def before_mirrored_data_destroy def after_mirrored_data_destroy def before_mirrored_data_save def after_mirrored_data_save def before_mirrored_data_destroy if offline_mirror_mode == :group_base group_state . update_attribute ( :group_being_destroyed , true ) end # If the app is online, the only thing that can be deleted is the entire group (possibly with its records) raise ActiveRecord :: ReadOnlyRecord if OfflineMirror :: app_online? and offline_mirror_mode != :group_base and ! group_being_destroyed # In the online app, we would normally block attempts to destroy group_owned data of an offline group # However, if the group itself is being destroyed, then that becomes just fine def after_mirrored_data_destroy def before_mirrored_data_save def after_mirrored_data_save private def group_being_destroyed return true unless owning_group # If the group doesn't exist anymore, then it's pretty well \"destroyed\" return group_state . group_being_destroyed end", "del_tokens": "before_destroy :check_mirrored_data_destroy after_destroy :note_mirrored_data_destroy before_save :check_mirrored_data_save after_save :note_mirrored_data_save def check_mirrored_data_destroy def note_mirrored_data_destroy def check_mirrored_data_save def note_mirrored_data_save def check_mirrored_data_destroy # If the app is online, the only thing that can be deleted is the entire group raise ActiveRecord :: ReadOnlyRecord if OfflineMirror :: app_online? and offline_mirror_mode != :group_base def note_mirrored_data_destroy def check_mirrored_data_save def note_mirrored_data_save", "commit_type": "allow"}
{"commit_tokens": ["Added", "task_id", "to", "all", "logging", "so", "it", "s", "easier", "to", "trace", "task", "status", "and", "operations", "."], "add_tokens": "task_id = job [ :task_id ] logger . error \"#{task_id}: #{error}\" logger . debug \"#{task_id}: Suspending #{task_id} for #{error_sleep_time} seconds\" logger . debug \"#{task_id}: Resuming #{task_id}\" out [ :task_id ] = if out [ :instance ] . respond_to? ( :task_id ) out [ :instance ] . send ( :task_id ) . to_s else \"#{out[:class_name]}.#{out[:method]}\" end raise ArgumentError , 'Invalid task id' if out [ :task_id ] . nil? || out [ :task_id ] . empty? task_id = parsed_task [ :task_id ] schedule_log_line = \"#{task_id}: Scheduling job #{class_name}.#{method} as `:#{schedule[:type]}` type\" log_line = \"#{task_id}: Running #{class_name}.#{method}\" job [ :task_id ] = task_id logger . debug \"#{task_id}: Got: #{out}\"", "del_tokens": "logger . error ( error ) logger . debug \"Suspending #{job.id} for #{error_sleep_time} seconds\" logger . debug \"Resuming #{job.id}\" schedule_log_line = \"Scheduling job #{class_name}.#{method} as `:#{schedule[:type]}` type\" log_line = \"Running #{class_name}.#{method}\" logger . debug \"Got: #{out}\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "nonexistent", "staypuft_deployments", "params", "when", "services", "have", "no", "configuration"], "add_tokens": "if params [ :staypuft_deployment ] param_data = params [ :staypuft_deployment ] [ :hostgroup_params ] diffs = [ ] param_data . each do | hostgroup_id , hostgroup_params | hostgroup = Hostgroup . find ( hostgroup_id ) hostgroup_params [ :puppetclass_params ] . each do | puppetclass_id , puppetclass_params | puppetclass = Puppetclass . find ( puppetclass_id ) puppetclass_params . each do | param_name , param_value | hostgroup . set_param_value_if_changed ( puppetclass , param_name , param_value ) end", "del_tokens": "param_data = params [ :staypuft_deployment ] [ :hostgroup_params ] diffs = [ ] param_data . each do | hostgroup_id , hostgroup_params | hostgroup = Hostgroup . find ( hostgroup_id ) hostgroup_params [ :puppetclass_params ] . each do | puppetclass_id , puppetclass_params | puppetclass = Puppetclass . find ( puppetclass_id ) puppetclass_params . each do | param_name , param_value | hostgroup . set_param_value_if_changed ( puppetclass , param_name , param_value )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "most", "of", "the", "directory", "methods", "for", "the", "filesystem", "api", "."], "add_tokens": "if false #file?", "del_tokens": "if 0 #file?", "commit_type": "implement"}
{"commit_tokens": ["add", "support", "for", "disabling", "updating", "auth", "header", "after", "each", "request"], "add_tokens": "if not DeviseTokenAuth . change_headers_on_each_request auth_header = @user . build_auth_header ( @token , @client_id ) elsif @is_batch_request and @client_id and @user", "del_tokens": "if @is_batch_request and @client_id and @user", "commit_type": "add"}
{"commit_tokens": ["use", "#to_s", "instead", "of", "string", "interpolation"], "add_tokens": "print t . report . to_s if options . fetch ( :verbose , true )", "del_tokens": "print \"#{t.report}\" if options . fetch ( :verbose , true )", "commit_type": "use"}
{"commit_tokens": ["fix", "unused", "method", "argument", "in", "actions", "::", "delete"], "add_tokens": "def delete ( id , options = { } ) self . class . delete \"#{self.class.endpoint}#{id}\" , options", "del_tokens": "def delete ( id , options ) self . class . delete \"#{self.class.endpoint}#{id}\" , { }", "commit_type": "fix"}
{"commit_tokens": ["Add", "spec", "for", "Sequel", "translations", "on", "different", "tables"], "add_tokens": "Text :value , null : false DB . create_table? :mobility_string_translations do primary_key :id String :locale , null : false String :key , null : false String :value , null : false Integer :translatable_id , null : false String :translatable_type , null : false index [ :translatable_id , :translatable_type , :locale , :key ] , unique : true , name : :index_mobility_string_translations_on_keys index [ :translatable_id , :translatable_type ] , name : :index_mobility_string_translations_on_translatable end", "del_tokens": "String :value , null : false", "commit_type": "add"}
{"commit_tokens": ["Fix", "double", "connect", "from", "benchmark"], "add_tokens": "send ( level , format_log_message ( level , message , payload , logged_exception , duration ) ) send ( level , format_log_message ( level , message , payload , logged_exception , duration ) )", "del_tokens": "send ( level , format_log_message ( level , message , payload , logged_exception , duration , & block ) ) send ( level , format_log_message ( level , message , payload , logged_exception , duration , & block ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "chk", "method", "sorted", "all", "segment", "objects", "by", "start", "date"], "add_tokens": "iVar << objType . new ( client , value [ \"id\" ] , value ) iVar << objType . new ( client , prop [ \"id\" ] , prop )", "del_tokens": "iVar << objType . new ( client , value [ :id ] , value ) iVar << objType . new ( client , prop [ :id ] , prop )", "commit_type": "fix"}
{"commit_tokens": ["Make", "app", "id", "fall", "back", "to", "environment", "variable", "from", "config", "file"], "add_tokens": "argument :api_secret , :desc => \"Your Intercom api-secret, used for secure mode\" , :optional => true argument :api_key , :desc => \"An Intercom API key, for various rake tasks\" , :optional => true", "del_tokens": "argument :api_secret , :desc => \"Your Intercom api-secret, used for secure mode\" argument :api_key , :desc => \"An Intercom API key, for various rake tasks\"", "commit_type": "make"}
{"commit_tokens": ["use", "explicit", "exceptions", "for", "raise_error"], "add_tokens": "expect { subject . test_cipher ( :SSLv2 , \"AES128-SHA\" ) } . to raise_error ( StandardError ) expect { subject . test_cipher ( :SSLv5 , \"AES128-SHA\" ) } . to raise_error ( StandardError ) expect { subject . test_cipher ( :SSLv2 , \"FOO128-SHA\" ) } . to raise_error ( StandardError ) expect { subject . test_cipher ( :SSLv3 , 'DES-CBC3-MD5' ) } . to raise_error ( StandardError )", "del_tokens": "expect { subject . test_cipher ( :SSLv2 , \"AES128-SHA\" ) } . to raise_error expect { subject . test_cipher ( :SSLv5 , \"AES128-SHA\" ) } . to raise_error expect { subject . test_cipher ( :SSLv2 , \"FOO128-SHA\" ) } . to raise_error expect { subject . test_cipher ( :SSLv3 , 'DES-CBC3-MD5' ) } . to raise_error", "commit_type": "use"}
{"commit_tokens": ["Moving", "miscelanneous", "files", "to", "GenericStorage", "model", "(", "in", "the", "future", "specific", "types", "may", "be", "subclassed", "off", "it", ")", "."], "add_tokens": "@drawings = RubyXL :: GenericStorage . new ( File . join ( 'xl' , 'drawings' ) ) @printer_settings = RubyXL :: GenericStorage . new ( File . join ( 'xl' , 'printerSettings' ) ) @drawings . add_to_zip ( zipfile ) @printer_settings . add_to_zip ( zipfile )", "del_tokens": "@drawings = nil @printer_settings = nil #preserves drawings (exactly, no modification allowed) unless @drawings . nil? 1 . upto ( @drawings . size ) do | i | zipfile . get_output_stream ( File . join ( 'xl' , 'drawings' , \"vmlDrawing#{i}.vml\" ) ) { | f | f . puts ( @drawings [ i ] ) } end end unless @printer_settings . nil? 1 . upto ( @printer_settings . size ) do | i | zipfile . get_output_stream ( File . join ( 'xl' , 'printerSettings' , \"printerSettings#{i}.bin\" ) ) { | f | f . puts ( @printer_settings [ i ] ) } end end", "commit_type": "move"}
{"commit_tokens": ["remove", "the", "buckets", "use", "the", "accessor"], "add_tokens": "# Ignores server weights, oh well srvs = self . servers . dup srvs . size . times do | try | n = rand ( srvs . size ) server = srvs [ n ] srvs . delete_at ( n )", "del_tokens": "return @force_server if @force_server bukkits = @buckets . dup bukkits . nitems . times do | try | n = rand ( bukkits . nitems ) server = bukkits [ n ] bukkits . delete_at ( n )", "commit_type": "remove"}
{"commit_tokens": ["added", "ability", "to", "set", "the", "window", "state", "of", "a", "session"], "add_tokens": "attr_writer :session_file , :visible , :window_state WINDOW_STATES = { minimized : 0 , normal : 1 , maximized : 2 } def window_state @window_state . nil? ? 1 : WINDOW_STATES [ @window_state ] end def visible @visible . nil? ? true : @visible end @session . WindowState = window_state @session . Visible = visible", "del_tokens": "attr_writer :session_file , :visible @session . WindowState = 1 @session . Visible = ( @visible . nil? ? true : @visible )", "commit_type": "add"}
{"commit_tokens": ["Making", "RailsContext", "instances", "from", "rails_context"], "add_tokens": "def rails_context ( description , & definition ) RiotRails . railsify_context ( description ) { context ( description . to_s , RailsContext , & definition ) } RiotRails . railsify_context ( description ) { new_context ( description . to_s , RailsContext , & definition ) }", "del_tokens": "def rails_context ( description , context_class = Riot :: Context , & definition ) RiotRails . railsify_context ( description ) do context ( description . to_s , context_class , & definition ) end RiotRails . railsify_context ( description ) do context ( description . to_s , & definition ) end", "commit_type": "make"}
{"commit_tokens": ["added", "path_prefix", "to", "connection", "options", "in", "bucket"], "add_tokens": "def path_prefix vhost? ? \"/#@name\" : \"\" end path = \"#{proxy_owner.path_prefix}#{options[:path]}\" host = proxy_owner . host proxy_target . request ( method , options . merge ( :host => host ) )", "del_tokens": "proxy_target . request ( method , options . merge ( :host => proxy_owner . host ) ) def path_prefix vhost? ? \"/#@name\" : \"\" end", "commit_type": "add"}
{"commit_tokens": ["improved", "logic", "in", "Tools", ".", "force_upcase"], "add_tokens": "str = str . gsub ( \" #{up.capitalize},\" , \" #{up}\" ) str = str . gsub ( \" #{up.capitalize}.\" , \" #{up}\" ) states = %w[ AK AL AR AZ CA CO CT DC DE FL GA HI IA ID IL KS KY LA MA MD MI MN MO NC ND NE NH NJ NM NV NY OH OK PA RI SC SD TN TX UT VA VT WA WI WV WY ]", "del_tokens": "states = %w[ AK AL AR AZ CA CT DC DE FL GA HI IA ID IL KS KY LA MA MD MI MN MO NC ND NE NH NJ NM NV NY OH OK PA RI SC SD TN TX UT VA VT WA WI WV WY ]", "commit_type": "improve"}
{"commit_tokens": ["update", "action", "needs", "auth", "token", "to", "be", "used", "doing", "that"], "add_tokens": "puts is_navigational_format? do_before_request if is_json_request? token = request . headers [ \"X-#{resource_name.capitalize}-Token\" ] es = request . headers [ \"X-#{resource_name.capitalize}-Es\" ] self . resource = resource_name . capitalize . constantize . where ( :authentication_token => token , :es => es ) . first if self . resource . nil? ##return a 401 else send ( :sign_in , self . resource ) end else send ( \"authenticate_#{resource_name}!\" , force : true ) self . resource = send ( \"current_#{resource_name}\" ) end", "del_tokens": "#puts \"args are: #{args}\" #puts \"resource name is: #{resource_name}\" do_before_request send ( \"authenticate_#{resource_name}!\" , force : true ) self . resource = send ( \"current_#{resource_name}\" )", "commit_type": "update"}
{"commit_tokens": ["Fix", "bin", "/", "reckon", "since", "it", "needs", "access", "to", "csv_parser"], "add_tokens": "attr_accessor :options , :accounts , :tokens , :seen , :csv_parser", "del_tokens": "attr_accessor :options , :accounts , :tokens , :seen", "commit_type": "fix"}
{"commit_tokens": ["Add", "and", "configure", "RSpec", "."], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Use", "URL", "-", "encoding", "function", "from", "stdlib"], "add_tokens": "require 'uri' URI . encode_www_form ( params ) ,", "del_tokens": "require 'cgi' url_encode ( params ) , # @return [String] def url_encode ( hash = { } ) hash . collect do | k , v | \"#{ CGI.escape( k.to_s ) }=#{ CGI.escape( v.to_s ) }\" end . join ( \"&\" ) end", "commit_type": "use"}
{"commit_tokens": ["Added", "another", "test", "including", "one", "that", "fails", "and", "shouldn", "t"], "add_tokens": "# TODO 2010-11-23 (mark) should check that unneeded deps are not defined verify_result ( dep_graph , objective_function , { 'A' => '1.0.0' , 'B' => '2.0.0' } ) end it \"can solve a more complex system with a set of current versions and a longer runlist\" do # pending \"Fixes for densely packed triple\" dep_graph = DepSelector :: DependencyGraph . new setup_constraint ( dep_graph , complex_cookbook_version_constraint ) run_list = [ [ \"A\" , nil ] , [ \"B\" , nil ] , [ \"C\" , nil ] , [ \"D\" , nil ] ] add_run_list ( dep_graph , run_list ) current_versions = { \"A\" => \"1.0.0\" , \"B\" => \"2.0.0\" } objective_function = init_objective_function ( dep_graph , run_list , current_versions ) dep_graph . each_solution do | soln | objective_function . consider ( soln ) end pp objective_function . best_solution dump_result ( dep_graph , objective_function ) # TODO 2010-11-23 (mark) should check that unneeded deps are not defined verify_result ( dep_graph , objective_function , { 'A' => '1.0.0' , 'B' => '2.0.0' , 'C' => '4.0.0' , 'D' => '4.0.0' } )", "del_tokens": "verify_result ( dep_graph , objective_function , { 'A' => '1.0.0' , 'B' => '2.0.0' , 'C' => '1.0.0' } )", "commit_type": "add"}
{"commit_tokens": ["added", "queue", "configuration", "to", "delayed_jobs"], "add_tokens": "def self . queue ( queue = nil ) @queue = queue . to_sym if queue @queue end delayed_options = { retry : 0 , backtrace : true } delayed_options [ :queue ] = typed_self . queue if typed_self . queue typed_self . delay ( delayed_options ) . inner_run ( job_run . id , params )", "del_tokens": "typed_self . delay ( retry : 0 , backtrace : true ) . inner_run ( job_run . id , params )", "commit_type": "add"}
{"commit_tokens": ["Move", "connectedness", "methods", "to", "mixins"], "add_tokens": "require 'tangle/mixin' include Tangle :: Mixin :: Connectedness :: Graph", "del_tokens": "# Get the largest connected subgraph for a vertex. # Also aliased as :component and :connected_component # # connected_subgraph(vertex) => Graph # def connected_subgraph ( vertex ) subgraph { | other | vertex . connected? ( other ) } end alias component connected_subgraph alias connected_component connected_subgraph # Get the largest subgraph that is not connected to a vertex, or what's # left after removing the connected subgraph. # def disconnected_subgraph ( vertex ) subgraph { | other | ! vertex . connected? ( other ) } end # A graph is connected if all vertices are connected to all vertices # An empty graph is disconnected. # def connected? return false if vertices . empty? vertices . combination ( 2 ) . all? do | pair | this , that = pair . to_a this . connected? ( that ) end end # A graph is disconnected if any vertex is not connected to all other. # An empty graph is disconnected. # def disconnected? ! connected? end", "commit_type": "move"}
{"commit_tokens": ["moved", "the", "call", "to", "rebuild_index", "into", "create_index_instance", "()", "which", "is", "used", "by", "ferret_index", "()", ".", "That", "fixes", "the", "problem", "that", "a", "custom", "to_doc", "method", "defined", "in", "a", "model", "class", "won", "t", "be", "used", "by", "rebuild_index", "()", "."], "add_tokens": "# rebuild the index from all data stored for this model. # This is called automatically when no index exists yet. # # TODO: this only works if every model class has it's # own index, otherwise the index will get populated only # with instances from the first model loaded # Retrieve the Ferret::Index::Index instance for this model class. # # as the key. So model classes sharing a single index will share their # Index object, too. ferret_indexes [ class_index_dir ] ||= create_index_instance # creates a new Index::Index instance. Before that, a check is done # to see if the index exists in the file system. If not, index rebuild # from all model data retrieved by find(:all) is triggered. def create_index_instance rebuild_index unless File . file? \"#{class_index_dir}/segments\" Index :: Index . new ( ferret_configuration ) end # Note that the scores retrieved this way aren't normalized across # indexes, so that the order of results after sorting by score will # differ from the order you would get when running the same query # on a single index containing all the data from Model1, Model2 # and Model3. #", "del_tokens": "rebuild_index unless File . file? \"#{configuration[:index_dir]}/segments\" # as the key. ferret_indexes [ class_index_dir ] ||= Index :: Index . new ( ferret_configuration )", "commit_type": "move"}
{"commit_tokens": ["added", "push", "changed", "some", "docs", "merged", "README", "and", "EXAMPLES", "fixed", "the", "Rake", "tasks", "to", "build", "a", "proper", "gem"], "add_tokens": "def checkout ( branch = 'master' , opts = { } ) def push ( remote = 'origin' , branch = 'master' ) self . lib . push ( remote , branch ) end", "del_tokens": "def checkout ( branch , opts = { } )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "naming", "convention", "error", "with", "resource_group_collection"], "add_tokens": "attach_function ( \"sc_resource_group_collection_handle\" , \"sc_resource_group_collection_handle\" , [ :pointer ] , :pointer ) attach_function ( \"sc_resource_group_collection_size\" , \"sc_resource_group_collection_size\" , [ :pointer ] , :int ) attach_function ( \"sc_resource_group_handle\" , \"sc_resource_group_handle\" , [ :pointer , :int ] , :pointer ) attach_function ( \"sc_resource_group_name\" , \"sc_resource_group_name\" , [ :pointer ] , :string ) attach_function ( \"sc_resource_group_description\" , \"sc_resource_group_description\" , [ :pointer ] , :string )", "del_tokens": "attach_function ( \"sc_resource_groups_collection_handle\" , \"sc_resource_groups_collection_handle\" , [ :pointer ] , :pointer ) attach_function ( \"sc_resource_groups_collection_size\" , \"sc_resource_groups_collection_size\" , [ :pointer ] , :int ) attach_function ( \"sc_resource_groups_handle\" , \"sc_resource_groups_handle\" , [ :pointer , :int ] , :pointer ) attach_function ( \"sc_resource_groups_name\" , \"sc_resource_groups_name\" , [ :pointer ] , :string ) attach_function ( \"sc_resource_groups_description\" , \"sc_resource_groups_description\" , [ :pointer ] , :string )", "commit_type": "fix"}
{"commit_tokens": ["Added", "integration", "specs", "for", "creating", "/", "updating", "/", "destroying", "."], "add_tokens": "$db = Friendly . db t . string :email delegated_attribute :name , String", "del_tokens": "$db = Friendly . db # Sequel::MySQL.default_engine = \"InnoDB\" t . string :name delegated_attribute :address1 , String", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "<button", ">", "tag"], "add_tokens": "button = find ( \"//input[@type='submit' or @type='image'][@id='#{locator}' or @value='#{locator}']\" ) . first || find ( \"//button[@id='#{locator}' or @value='#{locator}' or contains(.,'#{locator}')]\" ) . first", "del_tokens": "button = find ( \"//input[@type='submit' or @type='image'][@id='#{locator}' or @value='#{locator}']\" ) . first", "commit_type": "add"}
{"commit_tokens": ["Add", "brackets", "around", "block", "in", "Filter", "::", "create", "."], "add_tokens": "new . tap { | filter | filter . instance_eval ( & block ) }", "del_tokens": "new . tap { | filter | filter . instance_eval & block }", "commit_type": "add"}
{"commit_tokens": ["Adds", "path", "handling", "helpers", "for", "configuration", "files", "."], "add_tokens": "xsd_file_location = File . join ( DineroMailIpn . resources_path , \"/validation/xsd/#{filename}\" )", "del_tokens": "xsd_file_location = File . expand_path ( \"../../../resources/validation/xsd/#{filename}\" , __FILE__ )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "button", "to", "the", "filter", "form"], "add_tokens": "block_with_buttons = lambda { | f | block . call ( f ) ; f . submit ( \"Filter\" ) } form_for :q , search , options , & block_with_buttons", "del_tokens": "form_for :q , search , options , & block", "commit_type": "add"}
{"commit_tokens": ["Fix", "inextricably", "reversed", "title", "checking", "logic"], "add_tokens": "if file_lines . length > 0", "del_tokens": "if file_lines . length < 0", "commit_type": "fix"}
{"commit_tokens": ["added", "first_name", "last_name", "full_name", "methods", "with", "tests"], "add_tokens": "alias last_name lastname alias first_name firstname alias first_name_male firstname_male alias first_name_female firstname_female # Returns a random full name def full_name ( options = { :initial => false , :gender => nil } ) \"#{first_name} #{last_name}\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "XML", "-", "writing", "test"], "add_tokens": "@path . first ( xml , ensure_created : true ) . text = value . iso8601", "del_tokens": "@path . first ( xml , ensure_created : true ) . text = value . to_s", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "non", "-", "standard", "DB", "and", "a", "less", "all", "or", "nothing", "approach", "to", "clearing", "our", "test", "database"], "add_tokens": "config . before ( :all ) do redis = Redis . new ( :db => 15 ) redis . flushdb config . before ( :each ) do Amico . redis . flushdb end config . after ( :all ) do Amico . redis . flushdb Amico . redis . quit end", "del_tokens": "config . before ( :each ) do redis = Redis . new redis . flushall", "commit_type": "use"}
{"commit_tokens": ["Add", "limit", "radius", "and", "wide_search", "as", "params", "for", "ReverseGeocode"], "add_tokens": "def reverse_geocode ( longitude : , latitude : , limit : 10 , radius : 100 , wide_search : false ) \"https://api.postcodes.io/postcodes?lon=#{longitude}&lat=#{latitude}&limit=#{limit}&radius=#{radius}&wideSearch=#{wide_search}\" )", "del_tokens": "def reverse_geocode ( longitude : , latitude : ) \"https://api.postcodes.io/postcodes?lon=#{longitude}&lat=#{latitude}\" )", "commit_type": "add"}
{"commit_tokens": ["Changed", "feature", "flow", "from", "a", "middleware", "to", "a", "method", "call", "this", "allows", "it", "to", "play", "nicer", "with", "the", "rest", "of", "the", "documentation", "."], "add_tokens": "def featureflow Featureflow :: RailsClient . new ( request )", "del_tokens": "def configure_featureflow @featureflow = Featureflow :: RailsClient . new ( request ) before_action :configure_featureflow", "commit_type": "change"}
{"commit_tokens": ["Allow", "lambda", "functions", "in", "config", ".", "ignore_classes"], "add_tokens": "ex = @exceptions . last @configuration . ignore_classes . any? do | to_ignore | to_ignore . is_a? ( Proc ) ? to_ignore . call ( ex ) : to_ignore == error_class ( ex ) end", "del_tokens": "@configuration . ignore_classes . include? ( error_class ( @exceptions . last ) )", "commit_type": "allow"}
{"commit_tokens": ["Added", "remove", "from", "space", "operation", "to", "SpaceMember"], "add_tokens": "def update_role ( space_id , user_id , role ) response = Podio . connection . put do | req | req . url \"/space/#{space_id}/member/#{user_id}\" req . body = { :role => role . to_s } end response . status end def end_membership ( space_id , user_id ) Podio . connection . delete ( \"/space/#{space_id}/member/#{user_id}\" ) . status end", "del_tokens": "def update_space_membership ( space_id , user_id , role ) response = Podio . connection . put do | req | req . url \"/space/#{space_id}/member/#{user_id}\" req . body = { :role => role . to_s } end response . status end", "commit_type": "add"}
{"commit_tokens": ["Allow", "different", "options", "to", "be", "specified", "for", "run_all", "."], "add_tokens": "passed = Runner . run ( [ \"spec/\" ] , options . merge ( options [ :run_all ] || { } ) . merge ( :message => \"Running all specs\" ) )", "del_tokens": "passed = Runner . run ( [ \"spec/\" ] , options . merge ( :message => \"Running all specs\" ) )", "commit_type": "allow"}
{"commit_tokens": ["Change", "spec", "file", "name", "."], "add_tokens": "context 'DynamicScaffold::Manager#editor' do", "del_tokens": "context 'DynamicScaffold::Manager#add_form' do", "commit_type": "change"}
{"commit_tokens": ["Added", "to_s", "to", "HttpError", "and", "it", "will", "display", "body", "."], "add_tokens": "assert ex . response . body . include? ( \"404\" ) assert ex . to_s . include? ( \"404\" ) puts \"EX: #{ex}\"", "del_tokens": "puts \"EX: \" + ex . inspect", "commit_type": "add"}
{"commit_tokens": ["Add", "runners", "and", "default", "values", "for", "booleans", "on", "Task", "."], "add_tokens": "property :runners , :transformer => Api :: collection_transformers [ User ] property :charge_price property :description , :default => '' property :private_description , :default => '' property :private_runner , :default => false property :virtual , :default => false", "del_tokens": "property :description property :virtual", "commit_type": "add"}
{"commit_tokens": ["Add", "smart", "pagination", "capabilities", "to", "collection"], "add_tokens": "attr_reader :configuration , :remaining_rate_limit @remaining_rate_limit @remaining_rate_limit = response . headers [ :x_bc_apilimit_remaining ] raise \"Failed to parse Bigcommerce response: #{e.inspect}\"", "del_tokens": "def configuration @configuration end raise \"Failed to parse Bigcommerce response: #{e}\"", "commit_type": "add"}
{"commit_tokens": ["Removes", "old", "use", "of", "Numisma", "and", "use", "explictly", "I18n"], "add_tokens": "datum = \"(#{datum}.nil? ? '' : ::I18n.localize(#{datum}#{', :currency=>'+currency.gsub(/RECORD/, record) if currency}))\" datum = \"(#{datum}.nil? ? '' : ::I18n.currency_label(#{datum}))\"", "del_tokens": "datum = \"(#{datum}.nil? ? '' : I18n.localize(#{datum}#{', :currency=>'+currency.gsub(/RECORD/, record) if currency}))\" datum = \"(#{datum}.nil? ? '' : Numisma.currencies[#{datum}].label)\"", "commit_type": "remove"}
{"commit_tokens": ["Updated", "in", "response", "to", "Evan", "and", "Myron", "s", "code", "review", "."], "add_tokens": "@get . call ( [ ] , [ key ] ) @set . call ( [ ] , [ key , value ] ) def all # Taken from https://github.com/ezmobius/redis-rb/blob/master/lib/redis.rb hash = Hash . new @get . call ( [ ] , [ ] ) . each_slice ( 2 ) do | field , value | hash [ field ] = value hash # Restore this option to the default (remove this option) def clear ( option ) @set . call ( [ ] , [ option ] )", "del_tokens": "return get ( key ) return set ( key , value ) def get ( option = nil ) if option . nil? # Taken from https://github.com/ezmobius/redis-rb/blob/master/lib/redis.rb hash = Hash . new @get . call ( [ ] , [ ] ) . each_slice ( 2 ) do | field , value | hash [ field ] = value end hash else return @get . call ( [ ] , [ option ] ) # Set the provided option to the provided value. In the absence # of a value, it will unset that option, restoring it to the # default def set ( option , value = nil ) if not value . nil? return @set . call ( [ ] , [ option , value ] ) else return @set . call ( [ ] , [ option ] ) end", "commit_type": "update"}
{"commit_tokens": ["removing", "core", "extensions", "for", "an", "Inflector", "module"], "add_tokens": "autoload :Inflector , 'cloud_crowd/inflector' action_class = Inflector . camelize ( name )", "del_tokens": "# Common CloudCrowd libs: require 'cloud_crowd/core_ext' action_class = name . camelize", "commit_type": "remove"}
{"commit_tokens": ["Update", "Header", "::", "Eth#to_w", "spec", "to", "send", "packet", "onto", "loopback", "interface", "and", "not"], "add_tokens": "Thread . new { sleep 1 ; pkt . eth . to_w ( 'lo' ) } packets = Packet . capture ( 'lo' , max : 1 ,", "del_tokens": "Thread . new { sleep 1 ; pkt . eth . to_w ( 'eth0' ) } packets = Packet . capture ( 'eth0' , max : 1 ,", "commit_type": "update"}
{"commit_tokens": ["Updating", "the", "gemspec", "and", "bumping", "the", "version"], "add_tokens": "VERSION = \"0.2.2\"", "del_tokens": "VERSION = \"0.2.1\"", "commit_type": "update"}
{"commit_tokens": ["removed", "executor", "install", "-", "should", "not", "be", "on", "RDD"], "add_tokens": "# set('spark.ruby.executor.install', default_executor_install) # # Install command which is triggered before on start. # # This command using executor command template. # # # # == Example: # # gem install ruby-spark -v 1.2.0 # # # def default_executor_install # ENV['SPARK_RUBY_EXECUTOR_INSTALL'] || '' # end", "del_tokens": "set ( 'spark.ruby.executor.install' , default_executor_install ) # Install command which is triggered before on start. # This command using executor command template. # # == Example: # gem install ruby-spark -v 1.2.0 # def default_executor_install ENV [ 'SPARK_RUBY_EXECUTOR_INSTALL' ] || '' end", "commit_type": "remove"}
{"commit_tokens": ["Add", "delete", "method", "to", "Disk", "OM"], "add_tokens": "require \"securerandom\" let! ( :client ) { VCloudSdk :: Client . new ( url , username , password , { } , logger ) } let ( :catalog_name ) { ENV [ 'CATALOG_NAME' ] || VCloudSdk :: Test :: DefaultSetting :: CATALOG_NAME } let ( :vapp_template_name ) { VCloudSdk :: Test :: DefaultSetting :: EXISTING_VAPP_TEMPLATE_NAME } subject . find_network_by_name ( \"xxx\" ) describe \"#create_disk\" do it \"creates an independent disk successfully\" do vapp_name = SecureRandom . uuid catalog = client . find_catalog_by_name ( catalog_name ) vapp = catalog . instantiate_vapp_template ( vapp_template_name , vdc_name , vapp_name ) vm = vapp . vms . first new_disk_name = \"test\" new_disk = subject . create_disk ( new_disk_name , 1024 , vm ) new_disk . name . should eql new_disk_name vapp . delete new_disk . delete end end", "del_tokens": "client = VCloudSdk :: Client . new ( url , username , password , { } , logger ) network = subject . find_network_by_name ( \"xxx\" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "secured_card_data", "to", "be", "sent", "to", "eWay"], "add_tokens": "def self . create_secured_card_data 'foo' end end", "del_tokens": "end", "commit_type": "allow"}
{"commit_tokens": ["Add", "documentation", "for", "session", "class"], "add_tokens": "# Provides easy access to session data from the request. # # Extends from +HashWithIndifferentAccess+ and initailised with the # session hash from the request # # <b>Session variables</b>: # Session variables can be accessed the same way as accessing hash with keys. # ```ruby # session[:my_var] # Reads the variable # session.merge!(my_var: \"Some value\") # Write a session variable # ``` # # Apart from session handling, class also provides an API to other session # related information. # Get the elicitation count of a slot. # # Elicitation counts are maintained in the session so that they # can be referred to within the intenthandlers or the views # # Options: # - slot_name: Slot name to return the elicitation count for return self [ \"elicitations\" ] [ slot_name ] [ \"count\" ] end # Increase the elicitation count of a slot. # # Elicitation counts are maintained in the session so that they # can be referred to within the intenthandlers or the views # # Options: # - slot_name: Slot name to increment the elicitation count for # Whether its a new session. # Get application's ID from session # Get Amazon user's ID from session", "del_tokens": "return self [ \"elicitations\" ] [ slot_name ] [ \"count\" ] end", "commit_type": "add"}
{"commit_tokens": ["move", "to", "aws", "-", "sdk3"], "add_tokens": "require 'faraday_middleware/aws_sigv4' faraday . request :aws_sigv4 , class FaradayMiddleware :: AwsSigV4", "del_tokens": "require 'faraday_middleware/aws_signers_v4' faraday . request :aws_signers_v4 , class FaradayMiddleware :: AwsSignersV4", "commit_type": "move"}
{"commit_tokens": ["changed", "user", "to", "user_account", "to", "align", "with", "new", "account", "based", "design"], "add_tokens": "attr_reader :options , :user_account def initialize user_account , options = { } @user_account = user_account @user_account ||= Guest . create break if permit . execute ( user_account , options ) == :break permit_builder . build_role_group_permits_for role_groups permit_builder . build_role_permits_for roles def roles user_account . roles_list def role_groups user_account_class . role_groups . map { | k , v | groups << k if user_account . has_any_role? ( v ) } def user_account_class user_account . class end", "del_tokens": "attr_reader :options , :user def initialize user , options = { } @user = user @user ||= Guest . create break if permit . execute ( user , options ) == :break permit_builder . build_role_group_permits_for role_groups_of ( user ) permit_builder . build_role_permits_for roles_of ( user ) def roles_of user user . roles_list def role_groups_of user User . role_groups . map { | k , v | groups << k if user . has_any_role? ( v ) }", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "last", "unit", "test"], "add_tokens": "@feature_runner = stub Spinach :: Parser . expects ( :open_file ) . with ( filename ) . returns parser = stub parser . stubs ( :parse ) . returns feature = stub with ( feature , anything ) . returns ( @feature_runner ) @feature_runner . stubs ( :run ) . returns ( true ) @feature_runner . stubs ( :run ) . returns ( false ) runner . run . must_equal false", "del_tokens": "@feature = stub with ( filename , anything ) . returns ( @feature ) @feature . stubs ( run : true ) @feature . stubs ( run : false ) runner . run", "commit_type": "fix"}
{"commit_tokens": ["Fix", "browser", "opening", "in", "*", "nix", ";", "fixes", "gh", "-", "22", "gh", "-", "23"], "add_tokens": "nix_de = Launchy :: Detect :: NixDesktopEnvironment . detect", "del_tokens": "nix_de = Launchy :: Detect :: NixDekstopEnvironment . browser", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "shortest", "path", "decorator"], "add_tokens": "d . key = :depth d . bottom = 1.0 / 0 d . d0 = 0 SHORTEST_PATH = Decorate . new { | d | d . key = :shortest_path d . bottom = nil d . d0 = [ ] d . suppremum = lambda { | d1 , d2 | d1 . nil? ? d2 : ( d2 . nil? ? d1 : ( d1 . size < d2 . size ? d1 : d2 ) ) } d . propagate = lambda { | d , e | d . nil? ? [ e ] : ( d + [ e ] ) } }", "del_tokens": "d . key = :depth d . bottom = 1.0 / 0 d . d0 = 0", "commit_type": "add"}
{"commit_tokens": ["Implemented", "class_ruby", "test", "and", "fix", "some", "details", "."], "add_tokens": "require_relative '../container_data/class_data.rb' # TODO classCaptured = Languages :: ClassData . new classCaptured . name = result return classCaptured return pLine . scan ( regexExpression ) [ 0 ] . join ( \"\" )", "del_tokens": "return result return pLine . scan ( regexExpression ) [ 0 ]", "commit_type": "implement"}
{"commit_tokens": ["Changed", "Resource#missing_method", "to", "allow", "?", "queries", "eg", ".", "leg", ".", "photo_url?"], "add_tokens": "class NotAuthorized < GovKitError ; end class InvalidRequest < GovKitError ; end class ResourceNotFound < GovKitError ; end", "del_tokens": "class NotAuthorized < GovKitError ; end class InvalidRequest < GovKitError ; end class ResourceNotFound < GovKitError ; end", "commit_type": "change"}
{"commit_tokens": ["fix", "the", "off", "-", "by", "-", "one", "error"], "add_tokens": "first = peptides . next # shame we have to be this explicit, but it appears to be the only way Enumerator . new do | y | y << first loop do y << peptides . next end end . each_slice ( batch_size ) . with_index ( & block )", "del_tokens": "first = peptides . first peptides . each_slice ( batch_size ) . with_index ( & block )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "config", "/", "initializes", "directory"], "add_tokens": "puts \"rails jinda:seed\\n\"", "del_tokens": "puts \"rake jinda:seed\\n\"", "commit_type": "remove"}
{"commit_tokens": ["Allow", "disabling", "step_into", "for", "very", "special", "cases", "."], "add_tokens": "options = { auto : true , parent : Chef :: Resource , step_into : true } . merge ( options ) step_into ( resource_class , name ) if options [ :step_into ]", "del_tokens": "options = { auto : true , parent : Chef :: Resource } . merge ( options ) step_into ( resource_class , name )", "commit_type": "allow"}
{"commit_tokens": ["Allow", "the", "Figaro", "application", "path", "and", "environment", "to", "be", "changed"], "add_tokens": "attr_writer :path , :environment @path = options [ :path ] @environment = options [ :environment ] ( @path || default_path ) . to_s ( @environment || default_environment ) . to_s", "del_tokens": "@options = options @options . fetch ( :path ) { default_path } . to_s @options . fetch ( :environment ) { default_environment } . to_s", "commit_type": "allow"}
{"commit_tokens": ["Update", "the", "environment", "variable", "scheme"], "add_tokens": "class << self attr_accessor :env end end [ env ]", "del_tokens": "end", "commit_type": "update"}
{"commit_tokens": ["Fixed", ":", "Record", ".", "expiration", "gets", "a", "negative", "value", "for", "never", "expiring", "records"], "add_tokens": "if secs_from_citrus_leaf_epoc == 0 0xFFFFFFFF else now = Time . now . to_i - CITRUSLEAF_EPOCH # Record was not expired at server but if it looks expired at client # because of delay or clock differences, present it as not-expired. secs_from_citrus_leaf_epoc > now ? secs_from_citrus_leaf_epoc - now : 1 end", "del_tokens": "CITRUSLEAF_EPOCH + secs_from_citrus_leaf_epoc - Time . now . to_i", "commit_type": "fix"}
{"commit_tokens": ["add", "syntax", "highlight", "with", "pygments", ".", "rb"], "add_tokens": "require 'pygments' markdown = Redcarpet :: Markdown . new ( HTMLwithPygments . new ( :hard_wrap : true ) , { autolink : true , space_after_headers : true , fenced_code_blocks : true }", "del_tokens": "markdown = Redcarpet :: Markdown . new ( Redcarpet :: Render :: HTML , :autolink => true , :space_after_headers => true , :fenced_code_blocks => true", "commit_type": "add"}
{"commit_tokens": ["updated", "httpmachine", "with", "a", "few", "methods", "that", "will", "be", "used", "across", "the", "lib"], "add_tokens": "require 'core_ext/proc' def self . multi_running? ! Thread . current [ :curl_multi ] . nil? end def self . add_easy_request ( easy_object ) Thread . current [ :curl_multi ] . add ( easy_object ) end def self . service_access ( & block ) block . call Thread . current [ :curl_multi ] = nil", "del_tokens": "require 'http-machine/isolated_block' def self . service_access yield", "commit_type": "update"}
{"commit_tokens": ["Fixed", "composition", "of", "Transformations", "with", "nil", "translations"], "add_tokens": "when PointZero , NilClass self . dup when PointZero , NilClass self . dup", "del_tokens": "when PointZero self when PointZero self", "commit_type": "fix"}
{"commit_tokens": ["Move", "attributes", "to", "Resource", "class"], "add_tokens": "@attributes = Cms :: Resource . collect_attributes ( @resource )", "del_tokens": "@attributes = [ ] @attributes += @resource . columns . reject do | attribute | attribute . name . match ( / _id$ / ) end . map do | column | \"cms/attribute/#{ column.type }\" . classify . constantize . new ( column . name ) end @attributes += @resource . reflect_on_all_associations ( :belongs_to ) . map do | association | Cms :: Attribute :: BelongsTo . new ( association . name , key : association . foreign_key , klass : association . klass ) end @attributes += @resource . reflect_on_all_associations ( :has_many ) . map do | association | Cms :: Attribute :: HasMany . new ( association . name , key : association . foreign_key , klass : association . klass ) end @attributes", "commit_type": "move"}
{"commit_tokens": ["made", "reverse", "geocoder", "more", "flexible", "in", "the", "formats", "of", "latlng", "it", "would", "accept", "(", "string", "array", "etc", ")"], "add_tokens": "latlng = LatLng . normalize ( latlng ) res = self . call_geocoder_service ( \"http://maps.google.com/maps/geo?ll=#{Geokit::Inflector::url_escape(latlng.ll)}&output=xml&key=#{Geokit::Geocoders::google}&oe=utf-8\" ) logger . debug \"Google reverse-geocoding. LL: #{latlng.ll}. Result: #{xml}\"", "del_tokens": "res = self . call_geocoder_service ( \"http://maps.google.com/maps/geo?ll=#{Geokit::Inflector::url_escape(latlng)}&output=xml&key=#{Geokit::Geocoders::google}&oe=utf-8\" ) logger . debug \"Google reverse-geocoding. LL: #{latlng}. Result: #{xml}\"", "commit_type": "make"}
{"commit_tokens": ["Moving", "over", "SectionImporter", "and", "CodeSystemHelper", "from", "QME"], "add_tokens": "require_relative 'health-data-standards/util/code_system_helper' require_relative 'health-data-standards/models/record' require_relative 'health-data-standards/import/c32/section_importer'", "del_tokens": "require_relative 'health-data-standards/models/record'", "commit_type": "move"}
{"commit_tokens": ["Fix", "failing", "specs", "after", "extracting", "the", "config"], "add_tokens": "@file ||= begin return nil_file unless File . exist? ( FILE_NAME ) # Yaml.load_file returns false if the content is blank loaded = YAML . load_file ( FILE_NAME ) || nil_file # if the loaded file misses any of the two keys. loaded . merge! ( nil_file ) { | _k , v1 , v2 | v1 || v2 }", "del_tokens": "private @file ||= if File . exists? ( FILE_NAME ) YAML . load_file ( FILE_NAME ) else nil_config_file", "commit_type": "fix"}
{"commit_tokens": ["Fix", "require", "statements", "to", "simplify", "use", "of", "gem"], "add_tokens": "require 'census_api/client' require 'census_api/request' require 'census_api/version'", "del_tokens": "require 'rubygems' Dir [ \"./lib/census_api/*\" ] . each { | file | require file }", "commit_type": "fix"}
{"commit_tokens": ["Add", "another", "benchmark", "case", "."], "add_tokens": "bm . report ( \"String.new \" ) do bm . report ( \"Easy.new \" ) do bm . report ( \"net/http \" ) do bm . report ( \"open \" ) do bm . report ( \"Easy.perform \" ) do easy = Orthos :: Easy . new i . times do easy . url = \"http://localhost:3001/\" easy . prepare easy . perform end end bm . report ( \"Easy.perform reuse\" ) do bm . report ( \"net/http \" ) do bm . report ( \"open \" ) do bm . report ( \"Easy.perform \" ) do bm . report ( \"Multi.perform \" ) do", "del_tokens": "bm . report ( \"String.new \" ) do bm . report ( \"Easy.new \" ) do bm . report ( \"net/http \" ) do bm . report ( \"open \" ) do bm . report ( \"Easy.perform \" ) do bm . report ( \"net/http \" ) do bm . report ( \"open \" ) do bm . report ( \"Easy.perform \" ) do bm . report ( \"Multi.perform\" ) do", "commit_type": "add"}
{"commit_tokens": ["fixed", "some", "card", "management", "issues"], "add_tokens": "api_request . form_parameters [ :email ] = \"test+email@example.com\" #request.instance_variable_get(\"@body\").should == \"email=test%40example.com&shopId=1234\" request . instance_variable_get ( \"@body\" ) . should =~ / email=test%2Bemail%40example.com / request . instance_variable_get ( \"@body\" ) . should =~ / shopId=1234 /", "del_tokens": "api_request . form_parameters [ :email ] = \"test@example.com\" request . instance_variable_get ( \"@body\" ) . should == \"email=test%40example.com&shopId=1234\"", "commit_type": "fix"}
{"commit_tokens": ["remove", "unique", "lock", "when", "executing", "and", "clearing", "jobs", "in", "sidekiq", "fake", "mode"], "add_tokens": "if testing_enabled? && Sidekiq :: Testing . inline? require 'sidekiq_unique_jobs/inline_testing' def testing_enabled? Sidekiq . const_defined? ( 'Testing' ) && Sidekiq :: Testing . enabled? end", "del_tokens": "if Sidekiq . const_defined? ( 'Testing' ) && Sidekiq :: Testing . enabled? && Sidekiq :: Testing . inline? require 'sidekiq_unique_jobs/testing'", "commit_type": "remove"}
{"commit_tokens": ["remove", "terminate", "-", "myself", "script", "after", "one", "run"], "add_tokens": "desc \"ami NAME\" , \"launches instance and uses it create AMI\"", "del_tokens": "desc \"ami NAME\" , \"laucnhes instance and uses it create AMI\"", "commit_type": "remove"}
{"commit_tokens": ["Add", "basic", "proxy", "support", "."], "add_tokens": "@options = { :ssl => false , :proxy => ENV [ 'HTTP_PROXY' ] } . merge ( options ) if @options [ :proxy ] proxy_uri = URI . parse ( @options [ :proxy ] ) http_proxy proxy_uri . host , proxy_uri . port end", "del_tokens": "@options = { :ssl => false } . merge ( options )", "commit_type": "add"}
{"commit_tokens": ["Added", "raw_", "*", "versions", "of", "resource", "methods"], "add_tokens": "EMPTY_BODY = \"\" extract_response_body raw_get ( path , headers ) end def raw_get ( path , headers = { } ) access_token . get ( uri , headers ) extract_response_body raw_post ( path , body , headers ) end def raw_post ( path , body = '' , headers = { } ) access_token . post ( uri , body , headers ) extract_response_body raw_delete ( path , headers ) end def raw_delete ( path , headers = { } ) access_token . delete ( uri , headers ) def extract_response_body ( resp )", "del_tokens": "oauth_response = access_token . get ( uri , headers ) process_response oauth_response oauth_response = access_token . post ( uri , body , headers ) process_response oauth_response oauth_response = access_token . delete ( uri , headers ) process_response oauth_response def process_response ( resp )", "commit_type": "add"}
{"commit_tokens": ["Remove", "if", "/", "else", "logic", "and", "unnecessary", "return", "in", "#validate_status"], "add_tokens": "raise \"Error occurred\" unless exitstatus . success? true", "del_tokens": "if ! exitstatus . success? raise \"Error occurred\" else return true end", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "fix", "to", "the", "protocol", "to", "ignore", "ping", "packets", "."], "add_tokens": "PING_PAYLOAD = 4294967295 # Minus one interpreted as an unsigned int if @payload_len > 0 && ! isping? @data = socket . read ( @payload_len ) [ @offset .. @data_len + @offset - 1 ] def isping? @payload_len == PING_PAYLOAD end while true resp = Response . new ( @socket ) return resp unless resp . isping? end to_number ( owread . data )", "del_tokens": "if @payload_len > 0 @data = socket . read ( @payload_len ) [ 0 .. @data_len - 1 ] Response . new ( @socket ) return to_number ( owread . data )", "commit_type": "add"}
{"commit_tokens": ["changed", "name", "of", "WebWrap", "to", "Wrap", "."], "add_tokens": "require 'crm_formatter/wrap' wrap = self :: Wrap . new wrap . wrap ## returns formatted urls.", "del_tokens": "require 'crm_formatter/web_wrap' web_wrap = self :: WebWrap . new web_wrap . wrap ## returns formatted urls.", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "confirm", "payment", "with", "a", "HashWithIndifferentAccess"], "add_tokens": "params = Hash [ params . select { | k , v | params . key? k } ] # Need to symbolize keys again because the select will return a hash # with String keys if original params was HashWithIndiffirentAccess params = Utils . symbolize_keys ( params )", "del_tokens": "params = Hash [ params . select { | k , v | keys . include? k } ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "conditional", "for", "serialized", "objects"], "add_tokens": "if options . delete ( :serialized ) options . merge! ( :object => AmpleAssets :: File . find ( options [ :value ] ) ) else options . merge! ( :object => @object . send ( method . to_s . gsub ( / _id$ / , '' ) ) ) end", "del_tokens": "options . merge! ( :object => @object . send ( method . to_s . gsub ( / _id$ / , '' ) ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Client#get_resources", "for", "custom", "resources", "that", "are", "not", "yet", "defined"], "add_tokens": "def requests ( * options , skip_missing : false , retry_errors : true , ** common_options ) options . map { | options | request_options ( ** common_options . merge ( options ) ) } response_class = request_options [ :response_class ] || common_options [ :response_class ] response_class : response_class , request ( response_class : response_class , ** common_options . merge ( request_options ) ) def gets ( * paths , ** options ) * * options", "del_tokens": "def requests ( * options , response_class : nil , skip_missing : false , retry_errors : true ) options . map { | options | request_options ( ** options ) } response_class : request_options [ :response_class ] || response_class , request ( response_class : response_class , ** request_options ) def gets ( * paths , response_class : nil , ** options ) * * options , response_class : response_class ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "adding", "error", "to", "specified", "field", "in", "method", "and", "block", "validators"], "add_tokens": "# # You can also specify field: # # validates_with_block :zip_code do # if @zip_code == \"94301\" # true # else # [false, \"You're in the wrong zip code\"] # end # end # # # it will add returned error message to :zip_code field # opts [ :method ] = method_name add_validator_to_context ( opts , fields . empty? ? [ method_name ] : fields , DataMapper :: Validate :: MethodValidator )", "del_tokens": "add_validator_to_context ( opts , [ method_name ] , DataMapper :: Validate :: MethodValidator )", "commit_type": "add"}
{"commit_tokens": ["Use", "base_path", "when", "returning", "Location", "header"], "add_tokens": "file_url = \"/#{base_path}/#{uid}\"", "del_tokens": "file_url = \"/files/#{uid}\"", "commit_type": "use"}
{"commit_tokens": ["Make", "exception", "checking", "in", "the", "test", "consistent", "."], "add_tokens": "exception_count = 0 exception_count += 1 assert_equal 1 , exception_count exception_count = 0 exception_count += 1 assert_equal 1 , exception_count exception_count = 0 exception_count += 1 assert_equal 1 , exception_count", "del_tokens": "assert false assert false assert false", "commit_type": "make"}
{"commit_tokens": ["Make", "sure", "we", "can", "run", "the", "specs"], "add_tokens": "module Watir include Selenium end", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "syntax", "bug", "I", "missed", "."], "add_tokens": "end @l = :: Logger . new ( @options [ :filename ] )", "del_tokens": "end @l = :: Logger . new ( @options [ :filename ] )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "coveralls", "for", "more", "badge"], "add_tokens": "patch = 3 # Fixes to existing features", "del_tokens": "patch = 2 # Fixes to existing features", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "uniqueMember", "and", "uniqueGroupOfNames", "."], "add_tokens": "options [ :attributes ] ||= %w{ ou cn dn sAMAccountName member uniqueMember }", "del_tokens": "options [ :attributes ] ||= %w{ ou cn dn sAMAccountName member }", "commit_type": "add"}
{"commit_tokens": ["Adding", "README", ".", "md", "documentation", "removing", "unused", "files", "."], "add_tokens": "require_relative '../jackpot_client'", "del_tokens": "require 'jackpot'", "commit_type": "add"}
{"commit_tokens": ["Implement", "required", "option", "and", "make", "tests", "more", "specific"], "add_tokens": "\"<input type='%s' name='%s' value='%s' id='%s' class='%s' />%s\\n\" % [ o [ :input_type ] || 'text' , o [ :input_name ] , o [ :input_value ] , m . crushyid_for ( c ) , o [ :input_class ] , o [ :required ] ] \"<textarea name='%s' id='%s' class='%s'>%s</textarea>%s\\n\" % [ o [ :input_name ] , m . crushyid_for ( c ) , o [ :input_class ] , o [ :input_value ] , o [ :required ] ] # What represents a required field # Can be overriden def crushyfield_required ; \"<span class='crushyfield-required'> *</span>\" ; end o [ :required ] = o [ :required ] == true ? self . class . crushyfield_required : o [ :required ]", "del_tokens": "\"<input type='%s' name='%s' value='%s' id='%s' class='%s' />\\n\" % [ o [ :input_type ] || 'text' , o [ :input_name ] , o [ :input_value ] , m . crushyid_for ( c ) , o [ :input_class ] ] \"<textarea name='%s' id='%s' class='%s'>%s</textarea>\\n\" % [ o [ :input_name ] , m . crushyid_for ( c ) , o [ :input_class ] , o [ :input_value ] ] # What represents a required field # Can be overriden def crushyfield_required ; \"<span style='color:red;'> *</span>\" ; end", "commit_type": "implement"}
{"commit_tokens": ["Add", "coveralls", "gem", "and", "setup", "SimpleCov"], "add_tokens": "require 'coveralls' Coveralls . wear! SimpleCov . start do project_name \"Ork\" command_name \"Protest\" add_filter \"/test/\" end require 'riak/test_server'", "del_tokens": "# require 'coveralls' # Coveralls.wear! require 'riak/test_server'", "commit_type": "add"}
{"commit_tokens": ["use", "simblecov", "when", "COVERAGE", "is", "enabled"], "add_tokens": "if ENV [ \"COVERAGE\" ] require 'codeclimate-test-reporter' CodeClimate :: TestReporter . start require 'coveralls' Coveralls . wear! end", "del_tokens": "require 'codeclimate-test-reporter' CodeClimate :: TestReporter . start require 'coveralls' Coveralls . wear!", "commit_type": "use"}
{"commit_tokens": ["Move", "cache", "to", "a", "clearable", "location"], "add_tokens": "@tmp_path ||= Rails . root . join ( \"tmp\" , \"cache\" , \"browserify-rails\" ) . freeze", "del_tokens": "@tmp_path ||= Rails . root . join ( \"tmp\" , \"browserify-rails\" ) . freeze", "commit_type": "move"}
{"commit_tokens": ["Implemented", "caching", "of", "responses", "."], "add_tokens": ":display_invalid_content => false , :enable_caching => false", "del_tokens": ":display_invalid_content => false", "commit_type": "implement"}
{"commit_tokens": ["Add", "save_and_open_page", ".", "Add", "radio", "button", "support", "via", "#chooses", "method"], "add_tokens": "@response = mock @session . stubs ( :response ) . returns ( @response ) def test_should_send_default_radio_options @response . stubs ( :body ) . returns ( <<-EOS ) < form method = \"get\" action = \"/login\" > < input id = \"user_gender_male\" name = \"user[gender]\" type = \"radio\" value = \"M\" / > < label for = \"user_gender_male\" > Male < / label > < input id = \"user_gender_female\" name = \"user[gender]\" type = \"radio\" value = \"F\" checked = \"checked\" / > < label for = \"user_gender_female\" > Female < / label > < input type = \"submit\" / > < / form > EOS @session . expects ( :get_via_redirect ) . with ( \"/login\" , \"user\" => { \"gender\" => \"F\" } ) @session . clicks_button end", "del_tokens": "@session . stubs ( :response ) . returns ( @response = mock )", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", "for", "config", "methods", "step_definitions_path", "and", "support_path", "."], "add_tokens": "# classes will be searched for. Defaults to '#{features_path}/steps' # files. Defaults to '#{features_path}/support'", "del_tokens": "# classes will be searched for. Defaults to 'features/steps' # files.", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "resetting", "a", "subscription", "s", "balance"], "add_tokens": "it \"is in the canceled state\" do @subscription . reload . state . should == 'canceled' it \"puts it in the active state\" do @subscription . reload . state . should == 'active' end end describe \"adding a one time charge\" do before ( :each ) do @subscription = create_once ( :subscription ) do Chargify :: Subscription . create ( :product_handle => @@pro_plan . handle , :customer_reference => @@johnadoe . reference , :payment_profile_attributes => good_payment_profile_attributes ) end end it \"creates a charge and payment\" do lambda { @subscription . charge ( :amount => 7 , :memo => 'One Time Charge' ) } . should change { @subscription . reload . transactions . size } . by ( 2 ) @subscription . transactions . first . amount_in_cents . should == 700", "del_tokens": "it \"is in the active state\" do it \"is in the active state\" do Chargify :: Subscription . find ( @subscription . id ) . state . should == 'active'", "commit_type": "add"}
{"commit_tokens": ["added", "call", "to", "devise", ":", "customer", "generator", "to", "full_config", "generator"], "add_tokens": "argument :user_class , :type => :string , :default => 'User' , :desc => \"User class name\"", "del_tokens": "class_option :user_class , :type => :string , :default => 'User' , :desc => \"User class name\" def user_class options [ :user_class ] || 'User' end", "commit_type": "add"}
{"commit_tokens": ["Add", "the", ":", "in", "option", "."], "add_tokens": "options . assert_valid_keys ( :type , :only , :except , :if , :unless , :default , :as , :using , :allow_blank , :in ) if options . key? ( :in ) options [ :as ] = options [ :in ] options [ :using ] = scopes end", "del_tokens": "options . assert_valid_keys ( :type , :only , :except , :if , :unless , :default , :as , :using , :allow_blank )", "commit_type": "add"}
{"commit_tokens": ["Added", "first", "unit", "tests", "for", "SSDP"], "add_tokens": "EM . add_periodic_timer ( 1 ) { i += 1 ; print \"listening for \\b#{i}\" }", "del_tokens": "EM . add_periodic_timer ( 1 ) { i += 1 ; puts \"#{i}\\r\" }", "commit_type": "add"}
{"commit_tokens": ["moved", "lines?", "and", "highlight?", "after", "coresponding", "attr_writers"], "add_tokens": "def lines? @lines . nil? ? ! io_tty? : @lines end def highlight? @highlight . nil? ? io_tty? : @highlight end", "del_tokens": "def lines? @lines . nil? ? ! io_tty? : @lines end def highlight? @highlight . nil? ? io_tty? : @highlight end", "commit_type": "move"}
{"commit_tokens": ["fixed", "checks", "of", "privileges", "on", "source", "changes", "fixed", "check", "of", "privileges", "in", "Sandbox", "::", "Privileges#allow"], "add_tokens": "m = klass . shadow . instance_method ( method_name ) if method_name", "del_tokens": "m = klass . instance_method ( method_name ) if method_name", "commit_type": "fix"}
{"commit_tokens": ["Add", "ransack", "and", "search", "for", "resources"], "add_tokens": "attr_reader :key , :ransack_name @ransack_name = \"#{@name}_cont\"", "del_tokens": "attr_reader :key", "commit_type": "add"}
{"commit_tokens": ["fix", "broken", "-", "p", "option"], "add_tokens": "self . log_buffer_size ||= LOG_BUFFER_SIZE_DEFAULT self . pid_file_directory ||= PID_FILE_DIRECTORY_DEFAULT self . port ||= DRB_PORT_DEFAULT self . allow ||= DRB_ALLOW_DEFAULT", "del_tokens": "self . log_buffer_size = LOG_BUFFER_SIZE_DEFAULT self . pid_file_directory = PID_FILE_DIRECTORY_DEFAULT self . port = DRB_PORT_DEFAULT self . allow = DRB_ALLOW_DEFAULT", "commit_type": "fix"}
{"commit_tokens": ["Added", "content", "labels", "/", "assignments"], "add_tokens": "if params [ :notice ] notice = params [ :notice ] else notice = 'Your message was created.' end if params [ :content_label ] && FiatPublication :: ContentLabel . find_by ( name : params [ :content_label ] ) FiatPublication :: ContentLabelAssignment . create ( content_label_id : FiatPublication :: ContentLabel . find_by ( name : params [ :content_label ] ) . id , assignable : @message ) end if params [ :redirect_path ] format . html { redirect_to main_app . send ( params [ :redirect_path ] ) , notice : notice } else format . html { redirect_to main_app . send ( FiatPublication . new_message_redirect_path , @message ) , notice : notice } end params . require ( :message ) . permit ( :subject , :body , :authorable_type , :authorable_id , :name , :company , :email , :phone_number )", "del_tokens": "format . html { redirect_to main_app . send ( FiatPublication . new_message_redirect_path , @message ) , notice : 'Message was created.' } params . require ( :message ) . permit ( :subject , :body , :authorable_type , :authorable_id )", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "socket_timeout", "is", "less", "than", "ack_timeout"], "add_tokens": "SOCKET_TIMEOUT = 10 # broker. Default is 10 seconds.", "del_tokens": "SOCKET_TIMEOUT = 5 # broker. Default is 5 seconds.", "commit_type": "make"}
{"commit_tokens": ["Added", "section", "category", "methods", ".", "Version", "Bump", "."], "add_tokens": "VERSION = \"1.1.0\"", "del_tokens": "VERSION = \"1.0.0\"", "commit_type": "add"}
{"commit_tokens": ["changed", "place", "of", "implementation", "of", "calling", "of", "method_handler"], "add_tokens": "EvalHook :: HookedMethod . new ( self , mname ) method_handler = EvalHook . method_handler ret = nil if method_handler ret = method_handler . handle_method ( @recv . method ( @m ) . owner , self , @m ) end", "del_tokens": "method_handler = EvalHook . method_handler ret = nil if method_handler ret = method_handler . handle_method ( method ( mname ) . owner , self , mname ) end ret || EvalHook :: HookedMethod . new ( self , mname )", "commit_type": "change"}
{"commit_tokens": ["Added", "CVE", "-", "2013", "-", "2615"], "add_tokens": "it \"must have test for CVE-2013-2615\" do sc = kb . find ( \"CVE-2013-2615\" ) sc . should_not be_nil sc . class . should == Codesake :: Dawn :: Kb :: CVE_2013_2615 end", "del_tokens": "it \"must have test for CVE-2013-2615\"", "commit_type": "add"}
{"commit_tokens": ["Remove", "erubi", "/", "version", "file"], "add_tokens": "VERSION = '1.5.0'", "del_tokens": "require 'erubi/version'", "commit_type": "remove"}
{"commit_tokens": ["make", "sure", "non", "-", "timestamped", "migration", "version", "numbers", "are", ">", "the", "last", "one"], "add_tokens": "Dir . glob ( migration_path + '/*rb' ) . map { | f | f . gsub ( / .* \\/ ( \\d +)_.* / , '\\1' ) . to_i } . inject ( 0 ) { | curr , i | i > curr ? i : curr } + 1", "del_tokens": "Dir . glob ( migration_path + '/*rb' ) . map { | f | f . gsub ( / .* \\/ ( \\d +)_.* / , '\\1' ) . to_i } . inject ( 0 ) { | curr , i | i > curr ? i : curr }", "commit_type": "make"}
{"commit_tokens": ["Move", "fn", "factory", "method", "to", "transaction", "instance", "method", "and", "add", "YARD"], "add_tokens": "# Transaction encapsulates calling individual steps registered within a transflow # constructor. # # It's responsible for calling steps in the right order and optionally currying # arguments for specific steps. # # Furthermore you can subscribe event listeners to individual steps within a # transaction. # # @api public # Internal function factory using Transproc extension # # @api private # @attr_reader [Hash<Symbol => Proc,#call>] steps The step map # # @api private # @attr_reader [Array<Symbol>] step_names The names of registered steps # # @api private # @api private # Subscribe event listeners to specific steps # # @example # transaction = Transflow(container: my_container) { # step(:one) { step(:two, publish: true } # } # # class MyListener # def self.two_success(*args) # puts 'yes!' # end # # def self.two_failure(*args) # puts 'oh noez!' # end # end # # transaction.subscribe(two: my_listener) # # transaction.call(some_input) # # @param [Hash<Symbol => Object>] listeners The step=>listener map # # @return [self] # # @api public self # Call the transaction # # Once transaction is called it will call the first step and its result # will be passed to the second step and so on. # # @example # my_container = { # add_one: -> i { i + 1 }, # add_two: -> j { j + 2 } # } # # transaction = Transflow(container: my_container) { # step(:one, with: :add_one) { step(:two, with: :add_two) } # } # # transaction.call(1) # 4 # # @param [Object] input The input for the first step # # @param [Hash] options The curry-args map, optional # # @return [Object] # # @raises TransactionFailedError # # @api public # Coerce a transaction into string representation # # @return [String] # # @api public private # Wrap a proc into composable transproc function # # @param [#call] # # @api private if obj . respond_to? ( :>> ) obj else Registry [ obj ] end", "del_tokens": "def self . [] ( op ) if op . respond_to? ( :>> ) op else Registry [ op ] end end self . class [ obj ]", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "JRUBY", "s", "missing", "KeyError"], "add_tokens": "either . fetch . should be_a KeyError", "del_tokens": "KeyError . should === either . fetch", "commit_type": "fix"}
{"commit_tokens": ["Added", "nonce", "to", "user", "transaction"], "add_tokens": "attr_accessor :datetime , :id , :type , :usd , :btc , :fee , :order_id , :btc_usd , :nonce", "del_tokens": "attr_accessor :datetime , :id , :type , :usd , :btc , :fee , :order_id , :btc_usd", "commit_type": "add"}
{"commit_tokens": ["Adding", "online", "help", "for", "Gitlab", "::", "Shell", "using", "ri", "command", ".", "I", "m", "unsure", "if", "this", "is", "the", "best", "idea", ".", "Some", "refactoring", "still", "needs", "to", "be", "done", "to", "remove", "duplicate", "code", "."], "add_tokens": "unless valid_command? ( cmd )", "del_tokens": "unless Gitlab . actions . include? ( cmd . to_sym )", "commit_type": "add"}
{"commit_tokens": ["Allows", "setting", "of", "timeout", "attribute", "during", "initialize"], "add_tokens": "def initialize ( url , options = { } ) @timeout = options [ :timeout ] || 8", "del_tokens": "def initialize ( url ) @timeout = 8", "commit_type": "allow"}
{"commit_tokens": ["Add", "sleep", "calls", "in", "test", "support", "class", ".", "Improve", "Report", "specs", "."], "add_tokens": "def self . hay sleep rand nil end def self . guys sleep rand \"sup\" end def foo sleep rand nil end def bar sleep rand nil end def baz sleep rand \"blah\" end", "del_tokens": "def self . hay ; end def self . guys ; \"sup\" ; end def foo ; end def bar ; end def baz ; \"blah\" ; end", "commit_type": "add"}
{"commit_tokens": ["adding", "page", "reloading", "as", "the", "changeset", "changes"], "add_tokens": "to_ret [ product . id ] = { :all => true , :name => product . name , 'package' => [ ] , 'errata' => [ ] , 'repo' => [ ] } cs_product = { :name => Product . find ( pid ) . name , 'package' => [ ] , 'errata' => [ ] , 'repo' => [ ] } cs_product [ type ] << { :id => item . send ( \"#{type}_id\" ) , :name => item . display_name }", "del_tokens": "to_ret [ product . id ] = { :all => true , :name => product . name , 'packages' => [ ] , 'errata' => [ ] , 'repos' => [ ] } cs_product = { :name => Product . find ( pid ) . name , 'packages' => [ ] , 'errata' => [ ] , 'repos' => [ ] } cs_product [ type . pluralize ] << { :id => item . send ( \"#{type}_id\" ) , :name => item . display_name }", "commit_type": "add"}
{"commit_tokens": ["Fix", "schema", "dump", "for", "date", "/", "datetime"], "add_tokens": "it \"should define a date column if type is (D)ate\" do column . schema_definition . should == \"\\\"column_name\\\", :date\\n\" end it \"should define a datetime column if type is (D)ate\" do column = DBF :: Column . new \"ColumnName\" , \"T\" , 16 , 0", "del_tokens": "it \"should define a datetime column if type is (D)ate\" do", "commit_type": "fix"}
{"commit_tokens": ["Removing", "the", "displayName", "RAML", "attribute", "from", "generated", "JSON", "Schema"], "add_tokens": "# Repeat and displayName are not supported keywords in JSON Schema param . delete ( 'repeat' ) param . delete ( 'displayName' )", "del_tokens": "# Repeat is not a supported keyword in JSON Schema if param . include? ( 'repeat' ) param . delete ( 'repeat' ) end", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "require", "statement", "in", "connector", "."], "add_tokens": "require_relative 'actionkit_connector/version'", "del_tokens": "require 'actionkit_connector/version'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "undefined", "method", "github", "called", "when", "using", "other", "RequestSource"], "add_tokens": "# Defines a RequestSource object for html/markdown formatting method calls. # Defaults to `github`. # @param [RequestSource] value # @return [RequestSource] attr_accessor :repo_provider def repo_provider @repo_provider || github end repo_provider . html_link ( path )", "del_tokens": "github . html_link ( path )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "and", "tests", "for", "loading", "tilesets", "from", "external", ".", "tsx", "files", "."], "add_tokens": "# Pass :filename in options for resolving relative \"source\" paths parse contents ( filename ) , options . merge ( :filename => filename )", "del_tokens": "parse contents ( filename ) , options", "commit_type": "add"}
{"commit_tokens": ["Allow", "parent", "to", "be", "accessible", "early"], "add_tokens": "self . parent = parent_info . object if parent_info # logger.debug \"Trust.load: Setting new: class: #{klass} strong_params: #{strong_params.inspect}\"", "del_tokens": "self . parent = parent_info . object if parent_info # logger.debug \"Trust.load: Setting new: class: #{klass} info.params: #{info.params.inspect}\"", "commit_type": "allow"}
{"commit_tokens": ["Add", "functionality", "to", "make", "calls", "to", "the", "API", "."], "add_tokens": "require \"faraday\" require \"telegram_bot/connection\" attr_reader :connection # Register the webhook against Telegram register_webhook def self . connection @connection ||= Connection . new end def self . register_webhook res = self . connection . api_call ( :setWebhook , { url : self . configuration . callback_url } ) raise RuntimeError , \"Webhook couldn't be setted: #{res.body}\" if ( res . status != 200 ) end", "del_tokens": "# TODO: Register the webhook", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "couple", "broken", "specs"], "add_tokens": "\"%{_bindir}\" . unrpmize . should == \"bin\" \"bin\" . rpmize . should == \"%{_bindir}\"", "del_tokens": "\"%{_bindir}\" . unrpmize . should == \"/bin\" \"/bin\" . rpmize . should == \"%{_bindir}\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "Rspec", "and", "Cucumber"], "add_tokens": "action_for? ( raw_action [ 1 ] ) element = action_for? ( action ) element . click element def self . action_for? ( action ) page . find ( \"[data-action-for='#{action}']\" )", "del_tokens": "raw_action_for ( raw_action [ 0 ] ) element = raw_action_for ( action ) element . native . click def self . raw_action_for ( action ) @page . find ( \"[data-action-for='#{action}']\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "to", "see", "if", "there", "was", "actually", "an", "error"], "add_tokens": "raise \"Error from API: #{response[\"error\"]}\" if not response [ \"valid\" ]", "del_tokens": "raise \"Error from API: #{response[\"error\"]}\"", "commit_type": "add"}
{"commit_tokens": ["Made", "changes", "to", "connection", "class"], "add_tokens": "method = method . to_sym if ( method == :post || method == :put ) when :get , :delete response = client . send ( method , normalized_path , headers ) when :post , :put response = client . send ( method , path , query , headers ) raise UnhandledHTTPMethodError . new ( \"Unsupported HTTP method, #{method}\" ) headers . delete ( 'Content-Type' )", "del_tokens": "method = method . to_s . downcase if ( method == 'post' || method == 'put' ) when 'get' response = client . get ( normalized_path , headers ) when 'post' response = client . post ( path , query , headers ) when 'put' response = client . put ( path , query , headers ) when 'delete' response = client . delete ( normalized_path , headers ) raise UnhandledHTTPMethodError . new ( \"Unsupported HTTP method, #{method.inspect}\" ) headers . delete ( 'Content-Type' )", "commit_type": "make"}
{"commit_tokens": ["added", "fae", "checkbox", "and", "removed", "some", "required", "options", "on", "fae_radio", "and", "fae_checkbox"], "add_tokens": "def fae_checkbox ( f , attribute , options = { } ) options [ :as ] = :check_boxes options [ :alignment ] = 'radio_collection--horizontal' if options [ :type ] == 'inline' options [ :alignment ] = 'checkbox_collection--vertical' if options [ :type ] == 'stacked' || options [ :type ] . blank? options [ :wrapper_class ] = options [ :wrapper_class ] . present? ? \"#{options[:wrapper_class]} #{options[:alignment]}\" : options [ :alignment ] association_or_input f , attribute , options end raise \"MissingRequiredOption: fae_pulldown requires a 'collection' when using it on an ActiveRecord attribute.\" if ! options . has_key? ( :collection ) && f . object . attribute_names . include? ( attribute . to_s )", "del_tokens": "raise \"MissingRequiredOption: fae_radio requires a 'collection' option with an ActiveRecord#Relation object as its value.\" if ! options . has_key? ( :collection ) && ! f . object . attribute_names . include? ( attribute . to_s ) raise \"MissingRequiredOption: fae_pulldown requires a multi-dimentional 'collection' or ActiveRecord#Relation object option when using it on an ActiveRecord attribute.\" if ! options . has_key? ( :collection ) && f . object . attribute_names . include? ( attribute . to_s )", "commit_type": "add"}
{"commit_tokens": ["removed", "the", "comment", "class", "from", "the", "parser"], "add_tokens": "# finished editing the file successfully", "del_tokens": "#", "commit_type": "remove"}
{"commit_tokens": ["Added", "options", "and", "comments", "to", "trackers"], "add_tokens": "# Analyze the duration of a specific attribute # # Accepts the following options: # * <tt>:line_type</tt> The line type that contains the duration field (determined by the category proc). # * <tt>:if</tt> Proc that has to return true for a request to be passed to the tracker. # * <tt>:title</tt> Title do be displayed above the report # * <tt>:category</tt> Proc that handles request categorization for given fileformat (REQUEST_CATEGORIZER) # * <tt>:duration</tt> The field containing the duration in the request hash. # * <tt>:amount</tt> The amount of lines in the report # # The items in the update request hash are set during the creation of the Duration tracker. # # Example output: # # Request duration - top 20 by cumulative time  Hits  Sum. | Avg. #  # EmployeeController#show.html [GET]  4742  4922.56s  1.04s # EmployeeController#update.html [POST]  4647  2731.23s  0.59s # EmployeeController#index.html [GET]  5802  1477.32s  0.25s # .............", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Change", "default", "level", "for", "plain", "text", "and", "exceptions", "."], "add_tokens": "HASH = { 'short_message' => 'message' , 'host' => 'somehost' , 'level' => GELF :: WARN } assert_equal GELF :: ERROR , hash [ 'level' ] e , h = RuntimeError . new ( 'message' ) , { 'param' => 1 , 'level' => GELF :: FATAL , 'short_message' => 'will be hidden by exception' } assert_equal GELF :: FATAL , hash [ 'level' ] hash = @notifier . __send__ ( :extract_hash , 'message' ) assert_equal 'message' , hash [ 'short_message' ] assert_equal GELF :: INFO , hash [ 'level' ] hash = @notifier . __send__ ( :extract_hash , 'message' , 'level' => GELF :: ERROR ) assert_equal 'message' , hash [ 'short_message' ] assert_equal GELF :: ERROR , hash [ 'level' ]", "del_tokens": "HASH = { 'short_message' => 'message' , 'host' => 'somehost' , 'level' => 0 } e , h = RuntimeError . new ( 'message' ) , { 'param' => 1 , 'short_message' => 'will be hidden by exception' } assert_equal 'message' , @notifier . __send__ ( :extract_hash , 'message' ) [ 'short_message' ] assert_equal HASH , @notifier . __send__ ( :extract_hash , 'message' , 'host' => 'somehost' )", "commit_type": "change"}
{"commit_tokens": ["Added", "documentation", "to", "the", "ProviderDiscovery", "module", "."], "add_tokens": "# Discover the Provider for the given url, then call Provider#raw on that provider. # The query parameter will be passed to both discover_provider and Provider#raw def raw ( url , query = { } ) provider = discover_provider ( url , query ) # Discover the Provider for the given url, then call Provider#get on that provider. # The query parameter will be passed to both discover_provider and Provider#get def get ( url , query = { } ) provider = discover_provider ( url , query ) provider . get ( url , query ) # Returns a new Provider instance based on information from oEmbed discovery # performed on the given url. # # The options Hash recognizes the following keys: # :format:: If given only discover endpoints for the given format. If not format is given, use the first available format found.", "del_tokens": "def raw ( url , options = { } ) provider = discover_provider ( url , options ) def get ( url , options = { } ) provider = discover_provider ( url , options ) provider . get ( url , options )", "commit_type": "add"}
{"commit_tokens": ["remove", "view_stack", "replace", "with", "@styleable_context"], "add_tokens": "@assign_root = true @assign_root = false @styleable_context = nil unless @assign_root @assign_root = false context ( @view ) do create ( @view , element_id , & block ) end unless @styleable_context if @assign_root @styleable_context = root ( default_root ) @styleable_context . addSubview ( element )", "del_tokens": "def initialize @view_stack = [ ] end @create_default_root = true @create_default_root = false @view_stack = [ ] if ! @create_default_root @view_stack << @view @create_default_root = false create ( @view , element_id , & block ) @view_stack . pop @parent = @view_stack . last @view_stack << element @view_stack . pop @parent = @view_stack . last if @view_stack . empty? if @create_default_root @view_stack << root ( default_root ) self . current_view . addSubview ( element ) def current_view @view_stack . last end", "commit_type": "remove"}
{"commit_tokens": ["Use", "UTC", "ISO8601", "timestamp", "in", "requests", "."], "add_tokens": "'Timestamp' => Time . now . utc . iso8601 ,", "del_tokens": "'Timestamp' => Time . now . iso8601 ,", "commit_type": "use"}
{"commit_tokens": ["change", "to_xml_test", "to", "accomodate", "that", "ROXML", "is", "not", "whitespace", "preserving"], "add_tokens": "xml = xml_fixture ( xml_name ) xml . children . each do | child | child . remove! if child . empty? end assert_equal xml , dict . to_xml", "del_tokens": "assert_equal xml_fixture ( xml_name ) , dict . to_xml", "commit_type": "change"}
{"commit_tokens": ["Fixed", "typo", "in", "#create", "warning", "."], "add_tokens": "warn \"Do not call DBI::Model#new directly; use DBI::Model#create instead.\"", "del_tokens": "warn \"Do not call DBI::Model#new directly; use DBI::create instead.\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "date", "/", "time", "value", "extensions", "and", "tests", "."], "add_tokens": "t . datetime :tz_value t . datetime :utc_value self . time_zone_aware_attributes = true self . skip_time_zone_conversion_for_attributes << :utc_value Time . zone = 'EST' '2016-12-31 24:00+01:00' => Time . utc ( 2016 , 12 , 31 , 23 , 0 ) , @item . utc_value = s assert_equal v , @item . utc_value , \"Should have accepted #{s.inspect}\" @item . tz_value = s assert_equal v . in_time_zone , @item . tz_value , \"Should have accepted #{s.inspect}\" @item . tz_value = val assert_nil @item . tz_value , \"Should have rejected #{val.inspect}\" @item . utc_value = val assert_nil @item . utc_value , \"Should have rejected #{val.inspect}\"", "del_tokens": "t . datetime :my_value Time . zone = 'UTC' '2016-12-31 24:00-01:00' => Time . utc ( 2016 , 12 , 31 , 23 , 0 ) , @item . my_value = s assert_equal v , @item . my_value , \"Should have accepted #{s.inspect}\" @item . my_value = val assert_nil @item . my_value , \"Should have rejected #{val.inspect}\"", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Daemons", "usage", "and", "rake", "tasks", "for", "managing", "the", "server", "process"], "add_tokens": "require 'sanford/config' require 'sanford/manager' require 'sanford/host' require 'sanford/hosts' require 'sanford/version' class NoServiceHost < RuntimeError attr_reader :message def initialize ( host_name ) @message = if Sanford :: Hosts . empty? \"No service hosts were defined. \" \"Please define a service host before trying to run Sanford.\" else \"A service host couldn't be found with the name #{host_name.inspect}. \" end end end class NoServicesConfigFile < RuntimeError attr_reader :message def initialize file_path = Sanford :: Config . services_config @message = \"Sanford couldn't require the file '#{file_path}', please make sure it exists or \" \"modify `Sanford::Config.services_config`.\" end end", "del_tokens": "require \"sanford/version\" # Your code goes here...", "commit_type": "implement"}
{"commit_tokens": ["Make", "juici", "/", "database", "self", "contained"], "add_tokens": "require 'mongo' require 'mongoid' module Juici class Database class << self def mongoid_config_file %w[ mongoid.yml mongoid.yml.sample ] . each do | file | path = File . join ( \"config\" , file ) return path if File . exist? ( path ) end raise \"No database config file\" def initialize! if ENV [ 'RACK_ENV' ] == \"development\" Mongoid . logger . level = Logger :: INFO end Mongoid . load! ( mongoid_config_file ) end", "del_tokens": "class Juici :: Database class << self def mongoid_config_file %w[ mongoid.yml mongoid.yml.sample ] . each do | file | path = File . join ( \"config\" , file ) return path if File . exist? ( path ) raise \"No database config file\" end def initialize! if ENV [ 'RACK_ENV' ] == \"development\" Mongoid . logger . level = Logger :: INFO end Mongoid . load! ( mongoid_config_file )", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "better", "algorithm", "to", "squash", "older", "versions", "from", "the", "dependency", "tree"], "add_tokens": "# here it should not raise, since a@0.2 satisfies the dependency expect ( r . sort ) . to eq ( %w{ a@0.3.2 b@0.3.2 c@0.3.2 d@0.3.2 e@0.3.2 f @ 0.2 . 1", "del_tokens": "# here it should not raise, since a@0.2 satisfies the dependency expect ( r . sort ) . to eq ( %w{ a@0.3.2 b@0.3.2 c@0.3.2 d@0.3.2 e@0.3.2 f @ 0.2 . 1", "commit_type": "use"}
{"commit_tokens": ["Added", "profiling", "of", "private", "instance", "methods"], "add_tokens": "[ :shh ] . each { | m | petition . send ( m ) } results . size . should == 6", "del_tokens": "results . size . should == 5", "commit_type": "add"}
{"commit_tokens": ["Fixed", "to", "work", "with", "existing", "App", "that", "already", "use", "Activerecord"], "add_tokens": "VERSION = \"0.3.9\"", "del_tokens": "VERSION = \"0.3.8\"", "commit_type": "fix"}
{"commit_tokens": ["added", "spec", "and", "fixed", "bug"], "add_tokens": "@connecting_call = @call . conversation . calls . where ( [ \"state != 'terminated' and agent_id = ? \" , agent . id ] ) . first", "del_tokens": "@connecting_call = @call . conversation . calls . find_by_agent_id agent . id", "commit_type": "add"}
{"commit_tokens": ["made", "the", "resultset", "compatible", "with", "will_paginate"], "add_tokens": "# The resultset is compatible with will_paginate. # @example Use the resultset and will_paginate in a view # <%= will_paginate resultset %> # The number of pages # @return [Integer] attr_reader :total_pages # The current page # @return [Integer] attr_reader :current_page @per_page = options [ :per_page ] @total_pages = ( @size / @per_page . to_f ) . ceil @current_page = 1 options = { :page => 1 } . merge ( opts ) @current_page = options [ :page ] . to_i build_page ( @current_page ) end # The previous page number # @return [Integer] The number of the previous page or nil, if we are at page 1 def previous_page @current_page > 1 ? ( @current_page - 1 ) : nil end # The next page number # @return [Integer] The number of the next page or nil, if we are at the last page def next_page @current_page < @total_pages ? ( @current_page + 1 ) : nil", "del_tokens": "@per_page = options [ :per_page ] options = { :page => 1 } . merge ( opts ) build_page ( options [ :page ] )", "commit_type": "make"}
{"commit_tokens": ["add", "status", "--", "short", "option", "MUAD", "status"], "add_tokens": "# M U A D", "del_tokens": "# M U A D I X", "commit_type": "add"}
{"commit_tokens": ["Adding", "the", "current", "time", "as", "the", "start", "time", "to", "casperjunit", "parser"], "add_tokens": ":started => Time . now ( ) ,", "del_tokens": ":started => \"\" ,", "commit_type": "add"}
{"commit_tokens": ["add", "yet", "more", "HTTP", "exceptions"], "add_tokens": "Net :: HTTPServerException , Errno :: ECONNABORTED , Errno :: ECONNRESET ,", "del_tokens": "Errno :: ECONNRESET ,", "commit_type": "add"}
{"commit_tokens": ["Use", "clean", "slate", "BasicObject", "for", "Setting"], "add_tokens": "class Settings < BasicObject include :: Kernel @table = :: Hash . new @children = :: Array . new result = :: Hash . new if value . is_a? :: Hash", "del_tokens": "class Settings @table = Hash . new @children = Array . new result = Hash . new if value . is_a? Hash", "commit_type": "use"}
{"commit_tokens": ["removed", "a", "couple", "of", "specs"], "add_tokens": "describe \"::new\" do", "del_tokens": "describe \"::new\" do it \"should add a default ping listener\" do @base . listeners . should include :ping end it \"should add a default nick-taken listener\" do @base . listeners . should include :\" 433 \" end it \"should add a 004 listener, only if channels are set\" do @base . listeners . should_not include :' 004 ' @full . listeners . should include :' 004 ' end it \"should add a 433 nick taken listener\" do @base . listeners . should include :' 433 ' end", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "helpers", "and", "such", "weren", "t", "being", "loaded", "from", "the", "manual", "compiler", ".", "New", "features", "in", "test_helper", ".", "rb", "."], "add_tokens": "Ichiban :: ManualCompiler . new . paths ( [ 'html/html_page.html' , 'html/markdown_page.md' , 'html/uses_helper.html' ] ) assert_compiled 'uses_helper.html'", "del_tokens": "Ichiban :: ManualCompiler . new . paths [ 'html/html_page.html' , 'html/markdown_page.md' ]", "commit_type": "fix"}
{"commit_tokens": ["Updated", "response", "map", "and", "fixed", "minor", "bug", "on", "error", "rows"], "add_tokens": "response = { errors : 0 , status : 200 , total_rows : 0 , error_rows : [ ] } if error_row response [ :error_rows ] << error_row else data . save! end response [ :error_rows ] << log_and_return_error ( row_hash , e , index ) Rails . logger . error e . formatted_exception ( \"Error on #{index}: \\n #{row_hash.values}\" )", "del_tokens": "response = { errors : 0 , status : 200 , total_rows : 0 } error_rows = [ ] error_rows << error_row if error_row data . save! error_rows << log_and_return_error ( row_hash , e , index ) Rails . logger . error ( \"Error on #{index}: \\n #{row_hash.values} \\n#{e.backtrace}\" )", "commit_type": "update"}
{"commit_tokens": ["Allow", "validates_is_confirmed", "to", "validate", "confirmation", "of", "attributes", "which", "aren", "t", "properties", "."], "add_tokens": "if target . class . properties . has_property? ( @field_name ) return true unless target . attribute_dirty? ( @field_name ) end", "del_tokens": "return true unless target . attribute_dirty? ( @field_name )", "commit_type": "allow"}
{"commit_tokens": ["add", "poll", "option", "to", "ccu", "arl", "invalidate"], "add_tokens": "method_option :poll , :desc => 'whether or not to poll for status' , :type => :boolean , :default => false if options [ :poll ] == true && res . code == 201 puts PurgeRenderer . new ( res ) . render if res . time_to_wait status = AkamaiApi :: CCU . status res . uri while status . completed_at . nil? puts StatusRenderer . new ( status ) . render sleep 60 status = AkamaiApi :: CCU . status res . uri end puts StatusRenderer . new ( status ) . render end else puts PurgeRenderer . new ( res ) . render end", "del_tokens": "puts PurgeRenderer . new ( res ) . render", "commit_type": "add"}
{"commit_tokens": ["Use", "regular", "old", "ConditionVariables", "instead", "of", "crazy", "Celluloid", "::", "Wakers"], "add_tokens": "@condition = ConditionVariable . new @condition . signal @condition . signal @lock . synchronize do begin message = locate ( & block ) raise message if message . is_a? ( Celluloid :: SystemEvent ) @condition . wait ( @lock ) unless message end while message . nil? end if block_given? index = @messages . index do | msg | yield ( msg ) || msg . is_a? ( Celluloid :: SystemEvent ) @messages . slice! ( index , 1 ) . first if index else @messages . shift", "del_tokens": "@waker = Waker . new @waker . signal rescue WakerError raise MailboxError , \"dead recipient\" begin @waker . signal rescue WakerError # Silently fail if messages are sent to dead actors end begin @waker . wait message = locate ( & block ) raise message if message . is_a? ( Celluloid :: SystemEvent ) end while message . nil? rescue Celluloid :: WakerError cleanup # force cleanup of the mailbox raise MailboxError , \"mailbox cleanup called during receive\" @lock . synchronize do if block_given? index = @messages . index do | msg | yield ( msg ) || msg . is_a? ( Celluloid :: SystemEvent ) end @messages . slice! ( index , 1 ) . first if index else @messages . shift @waker . cleanup", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "with", "inherited", "callbacks"], "add_tokens": "protected def _provides_callbacks_callback_defined? ( name , check_ancestors : true ) _provides_callbacks_defined_callbacks . include? ( name . to_sym ) || ( check_ancestors && _provides_callbacks_superclass_callback_defined? ( name ) ) end def _provides_callbacks_superclass_callback_defined? ( name ) ancestors . any? { | ancestor | ancestor . include? ( TheHelp :: ProvidesCallbacks ) && ancestor . _provides_callbacks_callback_defined? ( name , check_ancestors : false ) } end", "del_tokens": "def _provides_callbacks_callback_defined? ( name ) _provides_callbacks_defined_callbacks . include? ( name . to_sym ) end", "commit_type": "fix"}
{"commit_tokens": ["Create", "a", "test", "server", "to", "run", "the", "specs", "against", "."], "add_tokens": "@session = Patron :: Session . new @session . base_url = \"http://localhost:9001\" escaped = @session . escape ( string ) unescaped = @session . unescape ( escaped ) it \"should get a url\" do response = @session . get ( \"/test\" ) response . status . should == 200 it \"should get a url with custom headers\" do @session . headers [ \"User-Agent\" ] = \"PatronTest\" response = @session . get ( \"/test\" ) response . status . should == 200", "del_tokens": "require 'patron/request' @curl = Patron :: Session . new end it \"should return the version number of the request library\" do version = Patron :: Session . version version . should be_kind_of ( String ) escaped = @curl . escape ( string ) unescaped = @curl . unescape ( escaped ) it \"should set and return the URL\" do @curl . setopt ( Patron :: CurlOpts :: URL , \"http://thehive.com/\" ) url = @curl . getinfo ( Patron :: CurlInfo :: EFFECTIVE_URL ) url . should == \"http://thehive.com/\" it \"should use proc to handle results\" do pending \"until a test web server is available\" valid = false p = Proc . new { | data | valid = true } @curl . setopt ( Patron :: CurlOpts :: URL , \"http://thehive.com/\" ) @curl . setopt ( Patron :: CurlOpts :: WRITE_HANDLER , p ) @curl . perform valid . should be_true", "commit_type": "create"}
{"commit_tokens": ["Use", "data", "directly", "when", "constructing", "a", "child"], "add_tokens": "@_result [ name ] = self . object_to_hash ( data , :root => include_root , & block ) if resolve_condition ( options )", "del_tokens": "@_result [ name ] = self . object_to_hash ( object , :root => include_root , & block ) if resolve_condition ( options )", "commit_type": "use"}
{"commit_tokens": ["add", "includes", "to", "spec", "before", "statement"], "add_tokens": "require 'action_controller'", "del_tokens": "require 'action_controller'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.7.1\"", "del_tokens": "VERSION = '0.7.0' . freeze", "commit_type": "change"}
{"commit_tokens": ["Add", "missing", "args", "to", "update_attributes"], "add_tokens": "def update_attributes ( * args ) run_callbacks ( :save ) { update ( * args ) }", "del_tokens": "def update_attributes run_callbacks ( :save ) { update }", "commit_type": "add"}
{"commit_tokens": ["Use", "MiniTest", "and", "turn", "."], "add_tokens": "class PostgreSQLCursorTests < MiniTest :: Unit :: TestCase", "del_tokens": "class PostgreSQLCursorTests < Test :: Unit :: TestCase", "commit_type": "use"}
{"commit_tokens": ["Remove", "Addrinfo", "hack", "from", "Moped", "::", "Server"], "add_tokens": "host , port = address . split ( \":\" ) port = port ? port . to_i : 27017 ip_address = :: Socket . getaddrinfo ( host , nil , :: Socket :: AF_INET , :: Socket :: SOCK_STREAM ) . first [ 3 ] @ip_address = ip_address @port = port @resolved_address = \"#{ip_address}:#{port}\"", "del_tokens": "unless ( defined? Addrinfo ) && ( Addrinfo . respond_to? ( :getaddrinfo ) ) # @private class Addrinfo class << self def getaddrinfo ( host , port , family , socktype ) family = :: Socket :: AF_INET socktype = :: Socket :: SOCK_STREAM :: Socket . getaddrinfo ( host , port , family , socktype ) . map do | addrinfo | new ( addrinfo ) end end end def initialize ( addrinfo ) @addrinfo = addrinfo end def ip_address @addrinfo [ 3 ] end def ip_port @addrinfo [ 1 ] end def inspect_sockaddr [ ip_address , ip_port ] . join ( \":\" ) end end end addrinfo = Addrinfo . getaddrinfo ( * address . split ( \":\" ) , :INET , :STREAM ) . first @ip_address = addrinfo . ip_address @port = addrinfo . ip_port @resolved_address = addrinfo . inspect_sockaddr", "commit_type": "remove"}
{"commit_tokens": ["Use", "properly", "crafted", "@prefix", "and", "@suffix"], "add_tokens": "GraphDrawer . new model , states , @prefix , @suffix , & block if block", "del_tokens": "GraphDrawer . new model , states , prefix , suffix , & block if block", "commit_type": "use"}
{"commit_tokens": ["allow", "validation", "spec", "in", "config", "to", "be", "a", "simple", "string", "which", "will", "be", "converted", "to", "an", "array", "of", "a", "single", "element"], "add_tokens": "find_unique_fields validations = field_config [ :validate ] validations = [ validations ] unless validations . is_a? ( Array ) validations : validations def find_unique_fields fields . each do | field_name , field_rule | next if field_rule [ :validations ] . select { | v | v == 'unique' } . empty? unique_fields << field_name end end inherit_fields = inherit_config ? inherit_config [ :fields ] : [ ] inherit_fields . each do | field |", "del_tokens": "validations : field_config [ :validate ] # def find_unique_fields # fields.each do |field_name, field_rule| # next if field_rule[:validations].select {|v| v == 'unique'}.empty? # unique_fields << field_name # end # end inheirt_fields = inherit_config ? inherit_config [ :fields ] : [ ] inheirt_fields . each do | field |", "commit_type": "allow"}
{"commit_tokens": ["updated", "node", ".", "rb", "with", "the", "right", "json", "key", "for", "getting", "the", "ip", "address", "of", "a", "node"], "add_tokens": "if info [ 1 ] [ 'transport' ] != \"\" address ( info [ 1 ] [ 'transport_address' ] ) . split ( ':' ) [ 0 ] address ( info [ 1 ] [ 'http_address' ] ) . split ( ':' ) [ 0 ]", "del_tokens": "if info [ 1 ] [ 'ip' ] != \"\" info [ 1 ] [ 'ip' ] addres ( info [ 1 ] [ 'http_address' ] ) . split ( ':' ) [ 0 ]", "commit_type": "update"}
{"commit_tokens": ["fixed", ":", "symbolize", "hash", "keys", "in", "method", "arguments", "so", "keyword", "args", "are", "happy"], "add_tokens": "VERSION = \"0.12.6\"", "del_tokens": "VERSION = \"0.12.5\"", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "rely", "on", "environment", "for", "support", "."], "add_tokens": "Support . new ( ENV , verbose : verbose ) . supports?", "del_tokens": "Support . new . supports?", "commit_type": "change"}
{"commit_tokens": ["Created", "a", "new", "form", "builder", "subclass", "which", "properly"], "add_tokens": "attr_reader :calls , :block @block = block", "del_tokens": "attr_reader :calls", "commit_type": "create"}
{"commit_tokens": ["Adding", "FakeRedis", "::", "Redis", "::", "Client"], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "add"}
{"commit_tokens": ["added", "test", "cases", "for", "session", "generation", "in", "staging", "and", "production", "environment", "and", "test", "passing", "p2p", "parameter"], "add_tokens": "require File . dirname ( __FILE__ ) + '/../lib/opentok.rb'", "del_tokens": "require File . dirname ( __FILE__ ) + '/../lib/opentok.rb'", "commit_type": "add"}
{"commit_tokens": ["Allow", "easy", "aliasing", "a", "command", "as", "default"], "add_tokens": "if description . is_a? Symbol command ( { :__default => description } ) else command ( :__default , description , & block ) end", "del_tokens": "command ( :__default , description , & block )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "the", "call", "to", "model#valid?", "because", "this", "call", "defeats", "the", "purpose", "of", "captcha", "specifically", "if", "the", "validation", "is", "expensive", "."], "add_tokens": "model = mock ( :errors => errors ) model = mock ; model . stubs ( :errors => errors )", "del_tokens": "model = mock ( :valid? => false , :errors => errors ) model = mock ; model . stubs ( :valid? => false , :errors => errors )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "relation", "URI", "template", "expand"], "add_tokens": "RESERVED_KEYS = %w( data )", "del_tokens": "RESERVED_KEYS = [ :data ]", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "--", "novalidation", "flag"], "add_tokens": "Spiceweasel :: RunList . new ( run_list ) . validate ( cookbook_list , environment_list , role_list ) unless NOVALIDATION", "del_tokens": "Spiceweasel :: RunList . new ( run_list ) . validate ( cookbook_list , environment_list , role_list )", "commit_type": "add"}
{"commit_tokens": ["use", "default", "protocol", "for", "hls", "origin", "urls"], "add_tokens": ":path => video_file . hls_medium . url ( default_protocol : 'http' ) , :path => video_file . hls_low . url ( default_protocol : 'http' ) , :path => video_file . hls_high . url ( default_protocol : 'http' ) , :path => video_file . mp4_medium . url ( host : :hls_origin , default_protocol : 'http' ) , :path => video_file . mp4_low . url ( host : :hls_origin , default_protocol : 'http' ) , :path => video_file . mp4_high . url ( host : :hls_origin , default_protocol : 'http' ) ,", "del_tokens": ":path => video_file . hls_medium . url , :path => video_file . hls_low . url , :path => video_file . hls_high . url , :path => video_file . mp4_medium . url ( :host => :hls_origin ) , :path => video_file . mp4_low . url ( :host => :hls_origin ) , :path => video_file . mp4_high . url ( :host => :hls_origin ) ,", "commit_type": "use"}
{"commit_tokens": ["Fixed", "up", "URL", "in", "comment", "counts", "."], "add_tokens": "def show_comment_counts ( opts ) scc = <<-WHIMPER document . write ( '<script type=\"text/javascript\" src=\"#{ROOT_PATH}get_num_replies.js' + query + '\"></' + 'script>' ) ; scc % opts [ :account ]", "del_tokens": "def show_comment_count ( opts ) <<-WHIMPER document . write ( '<script type=\"text/javascript\" src=\"#{ROOT_PATH}#{opts[:account]}/get_num_replies.js' + query + '\"></' + 'script>' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "base", "path", "to", "be", "specified", "for", "wiki", "links", "."], "add_tokens": "link = :: File . join ( @wiki . base_path , cname ) presence = @wiki . page ( cname ) ? \"present\" : \"absent\" %{<a class=\"internal #{presence}\" href=\"#{link}\">#{name}</a>}", "del_tokens": "if @wiki . page ( cname ) %{<a class=\"internal present\" href=\"#{cname}\">#{name}</a>} else %{<a class=\"internal absent\" href=\"#{cname}\">#{name}</a>} end", "commit_type": "allow"}
{"commit_tokens": ["Add", "ability", "to", "set", "the", "site", "for", "appliance", "users", ".", "Add", "a", "configuration", "method", "."], "add_tokens": "self . site = ESP . site with_api_auth ( ESP . access_key_id , ESP . secret_access_key )", "del_tokens": "self . site = ESP :: SITE [ ESP . env . to_sym ] with_api_auth ( ESP :: Credentials . access_key_id , ESP :: Credentials . secret_access_key )", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "PoolParty", ".", "gemspec"], "add_tokens": "@tc . stub! ( :prepare_to_configuration ) . and_return true @tc . stub! ( :build_and_store_new_config_file ) . and_return true it \"should raise an exception if it cannot find the keypair\" do @tc . stub! ( :keypair_path ) . and_return nil lambda { @tc . rsync_storage_files_to ( @tc . master ) } . should raise_error end", "del_tokens": "it \"should raise an exception if it cannot find the keypair\"", "commit_type": "add"}
{"commit_tokens": ["fix", "problems", "with", "rendering", "sass", "."], "add_tokens": "SOURCE_MAP = { '.css' => [ '.sass' , '.scss' ] } # # Render assets in a single directory (does not walk # directory tree). Files prefixed with an _ are treated # as partials and not rendered. # if File . directory? ( file ) || file =~ / ^ \\. / || file =~ / ^_ / next end engine = Sass :: Engine . new ( File . read ( src_file ) , :syntax => syntax , :load_paths => [ File . dirname ( src_file ) ] , :style => self . sass_render_style ) def self . sass_render_style Amber :: env == :production ? :compact : :nested end", "del_tokens": "next if File . directory? ( file ) || file =~ / ^ \\. / engine = Sass :: Engine . new ( File . read ( src_file ) , :syntax => syntax )", "commit_type": "fix"}
{"commit_tokens": ["Add", "exception", "handling", "to", "a", "AD", "-", "search"], "add_tokens": "raise 'Adauth needs configuring before use' if @config == nil", "del_tokens": "raise \"Adauth needs configuring before use\" if @config == nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "path", "to", "containing", "folder"], "add_tokens": "containing = self . containing_folder def self . containing_folder if FastlaneCore :: Helper . fastlane_enabled? FastlaneCore :: FastlaneFolder . path else '.' end end", "del_tokens": "containing = FastlaneCore :: Helper . fastlane_enabled? ? './fastlane' : '.'", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "the", "SetHITAsReviewing", "operation", "."], "add_tokens": "faker ( 'set_hit_as_reviewing' , :operation => 'SetHITAsReviewing' ) it \"should set a hit as Reviewing and Reviewable\" do hit = RTurk :: Hit . all_reviewable . first RTurk . should_receive ( :SetHITAsReviewing ) . once . with ( :hit_id => hit . id ) hit . set_as_reviewing! RTurk . should_receive ( :SetHITAsReviewing ) . once . with ( :hit_id => hit . id , :revert => true ) hit . set_as_reviewable! end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "systems_controller", "spec", "tests", "for", "wider", "coverage", "."], "add_tokens": "begin @system . update_attributes ( params [ :system ] ) rescue Exception => e", "del_tokens": "if @system . update_attributes ( params [ :system ] ) else", "commit_type": "add"}
{"commit_tokens": ["Use", "helper", "methd", "Cell#alive?", "to", "check", "cells", "instead", "of", "inspecting", "the", "state", "directly"], "add_tokens": "live_neighbors_count = board . neighbors_of_cell_at ( x , y ) . select { | n | n . alive? } . size", "del_tokens": "live_neighbors_count = board . neighbors_of_cell_at ( x , y ) . select { | n | n . state == :live } . size", "commit_type": "use"}
{"commit_tokens": ["fix", "setting", "of", "dirty", "attribute", "value", "of", "enum"], "add_tokens": "def type ; :enum end ; define_method ( \"#{attribute_name}=\" ) do | val | current_value = read_attribute ( attribute_name ) old_value = values [ current_value ] if current_value set_attribute_was ( attribute_name , old_value ) if old_value && old_value != val super ( val ) end", "del_tokens": "attribute ( attribute_name , :: Trax :: Model :: Attributes [ :enum ] :: TypeCaster . new )", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "new", "methods"], "add_tokens": "require 'stringio' def test_image_from_io buffer = StringIO . new ( File . read ( SIMPLE_IMAGE_PATH ) ) image = Image . from_io ( buffer ) image . destroy! end def test_image_create image = Image . create do | f | f . write ( File . read ( SIMPLE_IMAGE_PATH ) ) end image . destroy! end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "merging", "conditions", "and", "joins"], "add_tokens": "@model_class = Class . new ( SqlSanitizer ) it \"should merge association joins and sanitize conditions\" do @ability . can :read , @model_class , :foo => { :bar => 1 } @ability . can :read , @model_class , :too => { :car => 1 , :far => { :bar => 1 } } condition_variants = [ '(toos.far.bar=1 AND toos.car=1) OR (foos.bar=1)' , # faked sql sanitizer is stupid ;-) '(toos.car=1 AND toos.far.bar=1) OR (foos.bar=1)' ] joins_variants = [ [ :foo , { :too => [ :far ] } ] , [ { :too => [ :far ] } , :foo ] ] condition_variants . each do | condition | joins_variants . each do | joins | stub ( @model_class ) . scoped ( :conditions => condition , :joins => joins ) { :found_records } end end @ability . sql_conditions ( :read , @model_class ) . should == '(too.car=1 AND too.far.bar=1) OR (foo.bar=1)' @ability . association_joins ( :read , @model_class ) . should == [ { :too => [ :far ] } , :foo ] @model_class . accessible_by ( @ability ) . should == :found_records end", "del_tokens": "@model_class = Class . new", "commit_type": "add"}
{"commit_tokens": ["fixed", "template", "name", "+", "spec"], "add_tokens": "self [ :template_name ] || Humpyard :: config . default_template_name", "del_tokens": "@template_name ||= Humpyard :: config . default_template_name", "commit_type": "fix"}
{"commit_tokens": ["Remove", "redundnant", "version", "determination", "logic", "from", "download", "command"], "add_tokens": "release = mgr . get_release ( nil , options . pre_release ) puts \"No Xcode release with number #{options.release}. Use the 'list' command to see a list of known releases.\" puts \"Downloading Xcode #{release['version']}\"", "del_tokens": "if options . release xcode_version = options . release else if options . pre_release xcode_version = XcodeInstaller :: XcodeVersions :: LATEST_DP else xcode_version = XcodeInstaller :: XcodeVersions :: LATEST_GA end end release = mgr . get_release ( xcode_version , options . pre_release ) puts \"No Xcode release with number #{xcode_version}. Use the 'list' command to see a list of known releases.\" puts \"Downloading Xcode #{xcode_version}\"", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "with", "blacklist", ".", "it", "should", "work", "now"], "add_tokens": "if ! @blacklist . include? ( status . user . screen_name ) #puts \"#{status.text} ##{status.id}\"", "del_tokens": "if ! @blacklist . include? ( status . user ) #puts \"#{status.text}\"", "commit_type": "fix"}
{"commit_tokens": ["add", "options", "for", "parallel", "crawl"], "add_tokens": "spiderman . parallel_crawl if options [ :parallel ] == true spiderman . crawl if options [ :parallel ] == false", "del_tokens": "spiderman . crawl", "commit_type": "add"}
{"commit_tokens": ["Add", "VCSToolkit", "::", "Repository", "class", "to", "manage", "the", "repository"], "add_tokens": "require 'vcs_toolkit/repository'", "del_tokens": "require 'vcs_toolkit/vcs'", "commit_type": "add"}
{"commit_tokens": ["Adding", "OEmbed", "::", "Provider#build", "and", "#get"], "add_tokens": "def build ( url , options = { } ) format = endpoint [ \"{format}\" ] = ( query [ :format ] || @format ) . to_s [ Net :: HTTP :: Get . new ( uri . path + query_string ) , uri ] end def raw ( url , options = { } ) req , uri = build ( url , options ) http . request ( req ) end def get ( url , options = { } ) OEmbed :: Response . new ( raw ( url , options . merge ( :format => :json ) ) , self )", "del_tokens": "def raw ( url , options = { } ) format = endpoint [ \"{format}\" ] = query [ :format ] || @format http . get ( uri . path + query_string )", "commit_type": "add"}
{"commit_tokens": ["use", "i386", "emulator", "and", "find", "one", "more", "gadget", "!"], "add_tokens": "expect ( OneGadget . gadgets ( file : @libcpath19 , force_file : true ) ) . to eq [ 0x3fd27 , 0x64c64 , 0x64c6a , 0x64c6e ] expect ( OneGadget . gadgets ( file : @libcpath23 , force_file : true ) ) . to eq [ 0x3ac69 , 0x5fbc5 , 0x5fbc6 ]", "del_tokens": "expect ( OneGadget . gadgets ( file : @libcpath19 , force_file : true ) ) . to eq [ 0x3fd27 , 0x64c60 , 0x1244a6 ] expect ( OneGadget . gadgets ( file : @libcpath23 , force_file : true ) ) . to eq [ 0x3ac69 , 0x5fbbe , 0x12036c ]", "commit_type": "use"}
{"commit_tokens": ["Added", "config", "details", "to", "README"], "add_tokens": "# config.email_feedback = false # config.send_from_submitter = false # config.from_email = 'feedback@pointlesscorp.com' # config.to_emails = ['first@example.com', 'second@example.com'] # ==> Google reCAPTCHA Configuration # If you'd like to enable Google reCAPTCHA, # 1. Register your site at: https://www.google.com/recaptcha/admin # 2. !! Ensure you opt for reCAPTCHA v2. Support for v3 is not here yet. # 3. Grab the site and secret key and paste them here. #", "del_tokens": "# config.email_feedback = false # config.send_from_submitter = false # config.from_email = 'feedback@pointlesscorp.com' # config.to_emails = ['first@example.com', 'second@example.com']", "commit_type": "add"}
{"commit_tokens": ["Add", "basic", "documentation", "to", "lib", "/", "autoinc", ".", "rb"], "add_tokens": "# Returns all incrementing fields of the document # # @return [ Hash ] +Hash+ with fields and their autoincrement options # Set an autoincrementing field for a +Mongoid::Document+ # # @param [ Symbol ] field The name of the field to apply autoincrement to # @param [ Hash ] options The options to pass to that field # Manually assign the next number to the passed autoinc field. # # @return [ Fixnum ] The assigned number # Sets autoincrement values for all autoincrement fields. # # @return [ true ] end && true # Set autoincrement value for the passed autoincrement field, # using the passed options # # @param [ Symbol ] field Field to set the autoincrement value for. # @param [ Hash ] options Options to pass through to the serializer. # # @return [ true ] The value of `write_attribute` # Asserts the validity of the passed scope # # @param [ Object ] scope The +Symbol+ or +Proc+ to evaluate # # @return [ Object ] The scope of the autoincrement call # Returns the number to add to the current increment # # @param [ Object ] step The +Integer+ to be returned # or +Proc+ to be evaluated # # @return [ Integer ] The number to add to the current increment # Executes a proc and returns its +Integer+ value # # @param [ Proc ] step_proc The +Proc+ to call # # @return [ Integer ] The number to add to the current increment", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Fix", "active_scaffold_controller_for", "to", "only", "build", "path", "if", "a", "path", "is", "present", "in", "the", "parent", "controller", "and", "check", "for", "singular", "form", "of", "controller", "."], "add_tokens": "if parent_controller and parent_controller . include? ( \"/\" ) [ \"#{klass.to_s.underscore}\" , \"#{klass.to_s.underscore.pluralize}\" , \"#{klass.to_s.underscore.singularize}\" ] . each do | controller_name |", "del_tokens": "if parent_controller [ \"#{klass.to_s.underscore}\" , \"#{klass.to_s.underscore.pluralize}\" ] . each do | controller_name |", "commit_type": "fix"}
{"commit_tokens": ["updated", "form_header", "and", "all", "dummy", "app", "index", "and", "_form", "pages"], "add_tokens": "def form_header ( name ) name = name . class . name . split ( '::' ) . last unless name . is_a? String content_tag :h1 , \"#{params[:action]} #{name}\" . titleize", "del_tokens": "def form_header ( item ) content_tag :h1 , \"#{params[:action]} #{item.class.name.split('::').last}\" . titleize", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "ability", "to", "quiet", "job", "output"], "add_tokens": "require \"benchmark/memory/job/null_output\" # @param quiet [TrueClass, FalseClass] A flag for stopping output. def initialize ( output : $stdout , quiet : false ) @quiet = quiet @output = quiet? ? NullOutput . new : IOOutput . new ( output ) # Check whether the job is set to quiet. # # @return [TrueClass, FalseClass] def quiet? @quiet end", "del_tokens": "def initialize ( output : $stdout ) @output = IOOutput . new ( output )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "few", "comments", ".", "[", "skip", "ci", "]"], "add_tokens": "# @action install # @action upgrade", "del_tokens": "# @action create # @action delete", "commit_type": "fix"}
{"commit_tokens": ["allow", "passing", "options", "to", "the", "engine", "in", "render"], "add_tokens": "options = roy . conf . render || { } template = case view_or_string Tilt . new ( File . join ( dir , file ) , nil , options ) Tilt [ engine ] . new ( nil , nil , options ) { view_or_string . to_s } template . render ( self , params , & block )", "del_tokens": "tilt = case view_or_string Tilt . new ( File . join ( dir , file ) ) Tilt [ engine ] . new { view_or_string . to_s } tilt . render ( self , params , & block )", "commit_type": "allow"}
{"commit_tokens": ["Added", "ability", "to", "reset", "attributes"], "add_tokens": "autoload :Reset , 'attrio/reset' base . send ( :include , Attrio :: Inspect ) base . send ( :include , Attrio :: Reset ) base . send ( :extend , Attrio :: ClassMethods ) self . define_attrio_inspect ( options [ :as ] ) unless options [ :inspect ] == false self . define_attrio_reset ( options [ :as ] ) unless options [ :reset ] == false", "del_tokens": "base . send ( :extend , Attrio :: ClassMethods ) unless options [ :inspect ] == false self . send :include , Attrio :: Inspect end", "commit_type": "add"}
{"commit_tokens": ["Changed", "unless", "conditional", "to", "if", "statement"], "add_tokens": "if ! @section . raw raise \"KSS styleguide section is nil, is section '#{section}' defined in your css?\" end", "del_tokens": "raise \"KSS styleguide section is nil, is section: '#{section}' defined in your css?\" unless @section . raw", "commit_type": "change"}
{"commit_tokens": ["Use", "params", "in", "label", "name"], "add_tokens": "content << \"#{datetime} #{@label} #{line.strip}\\n\"", "del_tokens": "content << \"#{@label} #{datetime}: #{line.strip}\\n\"", "commit_type": "use"}
{"commit_tokens": ["Updated", "README", "and", "various", "rake", "things"], "add_tokens": "repo 'rspec-rails' , :url => 'git://github.com/dchelimsky/rspec-rails' #, :local => \"~/dev/vendor/rspec-rails\" plugin 'rspec' plugin ( 'rspec-rails' ) { sh \"script/generate rspec -f\" }", "del_tokens": "repo 'rspec-rails' , :url => 'git://github.com/ianwhite/rspec-rails' plugin 'rspec' plugin 'rspec-rails' , :branch => 'origin/aliased-render-partial' do sh \"script/generate rspec -f\" end", "commit_type": "update"}
{"commit_tokens": ["added", "user", "/", "details", "endpoint", "support"], "add_tokens": "attr_accessor :oauth_access_token , :id , :type #Artist image URL (optional lazy-loaded property) #@return [String] sevendigital_basic_property :email_address def get_details ( options = { } ) raise Sevendigital :: SevendigitalError if ! authenticated? user_with_details = @api_client . user . get_details ( @oauth_access_token , options ) copy_basic_properties_from ( user_with_details ) user_with_details end", "del_tokens": "attr_accessor :oauth_access_token , :id , :type , :email_address", "commit_type": "add"}
{"commit_tokens": ["use", "translated", "constants", "for", "all", "flash", "messages"], "add_tokens": "flash [ :notice ] = I18n . t ( 'cul.omniauth.only_guest' ) flash [ :notice ] = I18n . t ( 'cul.omniauth.denied' )", "del_tokens": "flash [ :notice ] = \"You must be logged out to access this page\" flash [ :notice ] = \"You not permitted to access this page\"", "commit_type": "use"}
{"commit_tokens": ["Using", "Deploy", "resource", "(", "Chef", ")"], "add_tokens": "app_path = \"/home/huginn/current\" listen '/home/huginn/shared/tmp/sockets/unicorn.sock' pid '/home/huginn/shared/tmp/pids/unicorn.pid'", "del_tokens": "app_path = \"/home/huginn/huginn\" listen '/home/huginn/huginn/tmp/sockets/unicorn.sock' pid '/home/huginn/huginn/tmp/pids/unicorn.pid'", "commit_type": "use"}
{"commit_tokens": ["Implemented", "multi", "-", "column", "flag", "feature", "."], "add_tokens": "t . string :incorrect_flags_column , :null => false , :default => '' end create_table :spaceships_with_2_custom_flags_column , :force => true do | t | t . integer :bits , :null => false , :default => 0 t . integer :commanders , :null => false , :default => 0 end", "del_tokens": "end ActiveRecord :: Schema . define ( :version => 0 ) do end", "commit_type": "implement"}
{"commit_tokens": ["fixing", "test", "to", "match", "expected", "."], "add_tokens": "Rho :: RhoConfig :: add_source ( \"Account\" , { \"url\" => \"http://rhosync.rhohub.com/sources/1\" , \"source_id\" => 1 } ) Rho :: RhoConfig :: add_source ( \"Case\" , { \"url\" => \"http://rhosync.rhohub.com/sources/2\" , \"source_id\" => 2 } ) Rho :: RhoConfig :: add_source ( \"Employee\" , { \"url\" => \"http://rhosync.rhohub.com/sources/3\" , \"source_id\" => 3 } )", "del_tokens": "Rho :: RhoConfig :: add_source ( \"Account\" , { \"url\" => \"http://rhosync.rhomobile.com/sources/1\" , \"source_id\" => 1 } ) Rho :: RhoConfig :: add_source ( \"Case\" , { \"url\" => \"http://rhosync.rhomobile.com/sources/2\" , \"source_id\" => 2 } ) Rho :: RhoConfig :: add_source ( \"Employee\" , { \"url\" => \"http://rhosync.rhomobile.com/sources/3\" , \"source_id\" => 3 } )", "commit_type": "fix"}
{"commit_tokens": ["Made", "an", "initializer", "change", "so", "that", "cp_type", "is", "handled", "right"], "add_tokens": "if attrs . has_key? ( type_key ) && ! ( attrs . has_key? ( :cp_type ) || attrs . has_key? ( 'cp_type' ) )", "del_tokens": "if attrs . has_key? ( type_key ) && ! ( attrs . has_key? ( :cp_type ) || attrs . has_key? ( 'cp_type' ) ) && new_record?", "commit_type": "make"}
{"commit_tokens": ["added", "Smalruby", "::", "Hardware", "::", "SmalrubotV3", "."], "add_tokens": "autoload :SmalrubotV3 def create_hardware ( klass , pin = nil )", "del_tokens": "def create_hardware ( klass , pin )", "commit_type": "add"}
{"commit_tokens": ["Use", "rspec", "/", "rails", "and", "test", "against", "a", "real", "controller"], "add_tokens": "require 'abstract_controller' require 'action_controller' require 'active_support' require 'rspec/rails' Dir [ \"#{File.dirname(__FILE__)}/support/**/*.rb\" ] . each { | f | require f } I18n . default_locale = :en I18n . available_locales = [ :en , :fr ] Timecop . freeze", "del_tokens": "require 'rspec' Dir [ \"#{File.dirname(__FILE__)}/support/**/*.rb\" ] . each { | f | require f }", "commit_type": "use"}
{"commit_tokens": ["update", "parser", "CLI", "graphviz", "graph", "format", "options"], "add_tokens": "@@graph_formats = %w{ jpg png svg pdf ps ps2 eps }", "del_tokens": "@@graph_formats = %w{ jpg png tif tga bmp svg pdf ps ps2 }", "commit_type": "update"}
{"commit_tokens": ["allow", "authentication", "for", "remote", "repos"], "add_tokens": "@resolver . addRemoteRepositoryByUrl ( url )", "del_tokens": "@resolver . addRemoteRepository ( url )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "out", "-", "of", "-", "sequence", "reading", "of", "multiple", "Worksheets"], "add_tokens": "VERSION = '0.6.1.8'", "del_tokens": "VERSION = '0.6.1.7'", "commit_type": "fix"}
{"commit_tokens": ["Added", "users", "/", "update", "method", "and", "spec", ".", "Cleaned", "up", "users", "/", "create", "and", "users", "/", "update", "for", "nil", "values", "to", "not", "send", "over", "key", "value", "pair", "."], "add_tokens": ":is_group_admin => is_group_admin , :password => password , :timezone => timezone } . reject! { | key , value | value . nil? } ) def users_update ( user_id , email = nil , name = nil , title = nil , is_group_admin = nil , password = nil , timezone = nil ) self . class . post ( hipchat_api_url_for ( 'users/update' ) , :body => { :auth_token => @token , :user_id => user_id , :email => email , :name => name , :title => title , :is_group_admin => is_group_admin , :password => password , :timezone => timezone } . reject! { | key , value | value . nil? } ) end", "del_tokens": ":is_group_admin => is_group_admin , :password => password , :timezone => timezone } )", "commit_type": "add"}
{"commit_tokens": ["Use", "global", "model", "cleanup", "code", "from", "dm", "-", "core", ".", "All", "green", "now!"], "add_tokens": "require 'dm-core/spec/lib/spec_helper' require 'dm-core/spec/lib/counter_adapter' config . after :all do DataMapper :: Spec . cleanup_models end", "del_tokens": "require 'dm-core/spec/lib/counter_adapter'", "commit_type": "use"}
{"commit_tokens": ["fix", "broken", "Trash", "spec", "example"], "add_tokens": "TrashTest . properties . should include ( :first_name )", "del_tokens": "TrashTest . property :not_an_att , :from => :notAnAtt TrashTest . properties . should include ( 'not_an_att' )", "commit_type": "fix"}
{"commit_tokens": ["Use", "store", "to", "match", "fetch", "nomenclature"], "add_tokens": "MAPPINGS . store ( byte , type )", "del_tokens": "MAPPINGS [ byte ] = type", "commit_type": "use"}
{"commit_tokens": ["Allow", "load_subclasses", "to", "work", "when", "multiple", "apps", "are", "on", "the", "same", "database", ":", "such", "as", "with", "schemas", "in", "PostgeSQL"], "add_tokens": "if ActiveRecord :: Base . connection . tables . include? ( 'pages' ) # Assume that we have bootstrapped", "del_tokens": "unless Page . connection . tables . empty? # Haven't bootstrapped yet", "commit_type": "allow"}
{"commit_tokens": ["Fix", "top", "level", "constant", "."], "add_tokens": "RUBY = ENV [ 'RUBY' ] || :: File . join (", "del_tokens": "RUBY = ENV [ 'RUBY' ] || File . join (", "commit_type": "fix"}
{"commit_tokens": ["add", "specs", "for", "erb", "and", "remove", "empty", "static", "blocks"], "add_tokens": "result << [ :static , $` ] unless $` . to_s . empty? result << [ :static , src ] unless src . to_s . empty?", "del_tokens": "result << [ :static , $` ] result << [ :static , src ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "tagged", "logging", "when", "tags", "consist", "of", "arrays", "of", "arrays"], "add_tokens": "new_tags = push_tags ( * tags ) yield self pop_tags ( new_tags . size ) # Returns the list of tags pushed after flattening them out and removing blanks new_tags", "del_tokens": "push_tags ( * tags ) yield pop_tags ( tags . size )", "commit_type": "fix"}
{"commit_tokens": ["added", "rspec", "as", "Rakefile", "dependency"], "add_tokens": "def index end", "del_tokens": "{ :type => :helper , :content => { :content => { :type => :helper , :content => \"\\n def index\\n end\\n \" } } }", "commit_type": "add"}
{"commit_tokens": ["Added", "array", "of", "margins", "for", "distribute", "and", "ignoring", "views", "with", "0", "height"], "add_tokens": "margins = params [ :margins ] selected . each_with_index do | view , i | next if st . height == 0 view_margin = if ( margins && margins [ i ] ) margins [ i ] else margin end current_end = ( st . top - view_margin ) unless current_end st . left = current_end + view_margin st . top = current_end + view_margin", "del_tokens": "selected . each do | view | current_end = ( st . top - margin ) unless current_end st . left = current_end + margin st . top = current_end + margin", "commit_type": "add"}
{"commit_tokens": ["removed", "double", "render", "from", "Admin", "::", "ResourceController"], "add_tokens": "@model_class = model_class . to_s . singularize . camelize . constantize unless model_class . nil? def index default_display_responses end def show default_display_responses end def new default_display_responses end def edit default_display_responses end default_modify_responses default_modify_responses default_modify_responses format . xml do if action_name == 'index' render :xml => models else render :xml => model end", "del_tokens": "around_filter :default_display_responses , :only => [ :index , :show , :new , :edit ] around_filter :default_modify_responses :only => [ :create , :update , :destroy ] @model_class = model_class . to_s . camelize . constantize unless model_class . nil? yield case action_name when 'index' format . xml { render :xml => models } else format . xml { render :xml => model } yield", "commit_type": "remove"}
{"commit_tokens": ["add", "take", "element", "screenshot", "for", "oss"], "add_tokens": "assert_equal 129 , @c . implemented_mjsonwp_commands . length assert_equal 44 , @c . implemented_core_commands . length", "del_tokens": "assert_equal 128 , @c . implemented_mjsonwp_commands . length assert_equal 43 , @c . implemented_core_commands . length", "commit_type": "add"}
{"commit_tokens": ["add", "a", "test", "to", "verify", "that", "the", "correct", "parameters", "are", "passed", "to", "the", "host", "key", "verifier"], "add_tokens": "blob = Net :: SSH :: Buffer . from ( :key , key ) . to_s", "del_tokens": "writer = Net :: SSH :: Buffer . new writer . write_key ( key ) blob = writer . to_s", "commit_type": "add"}
{"commit_tokens": ["fix", "dead", "code", "thanks", "Coveralls!"], "add_tokens": "config . each { | _ | called += 1 ; break } assert_equal 1 , called", "del_tokens": "begin config . each { | _ | called += 1 ; break } rescue assert_equal 1 , called end", "commit_type": "fix"}
{"commit_tokens": ["Improved", "Czech", "one", "-", "character", "word", "NBSPs"], "add_tokens": "input . gsub ( / \\W [aikosuvAIKOSUV] / ) { | s | \" \" + s . strip + \" \"}", "del_tokens": "input . gsub ( / [aikosuvAIKOSUV] / ) { | s | \" \" + s . strip + \" \"}", "commit_type": "improve"}
{"commit_tokens": ["Remove", "comments", "(", "WFT", ")"], "add_tokens": "", "del_tokens": "= begin = end", "commit_type": "remove"}
{"commit_tokens": ["Use", "with_options", "instead", "of", "OptionalPropDef", "."], "add_tokens": "with_options ( required : false , & block )", "del_tokens": "OptionalPropDef . eval ( & block ) . each do | name , schema | schema . options [ :required ] = false update_context ( name , schema ) end", "commit_type": "use"}
{"commit_tokens": ["change", "Unit#expr", "from", "attribute", "to", "method"], "add_tokens": "def expr @expr || @name || string_form end @expr = nil", "del_tokens": "attr_reader :expr @expr = expr", "commit_type": "change"}
{"commit_tokens": ["adds", "most", "of", "the", "path_matching", "mechanism"], "add_tokens": "raise \"no handler present, please add one using 'to:'\" unless options [ :to ] raise \"no context for given route\" unless @current_context Routes . add ( ref , route , @current_context , options ) Router . set_initial context", "del_tokens": "# @routes[current_context] = { # key: { # route: Route.new(route), # to: options.fetch(:to) # } # } Routes . create ( ref , route , options ) @inital_context = context", "commit_type": "add"}
{"commit_tokens": ["Add", "signing", "of", "order", "xsd"], "add_tokens": "require \"openssl\" require \"base64\" body = build_xsd signature = client . config . debug ? \"FAKE_SIGNATURE\" : sign ( client . config . private_key , body ) \"X-Walmart-Body-Signature\" => signature body : body def sign ( key , data ) Base64 . urlsafe_encode64 ( key . sign ( OpenSSL :: Digest :: SHA256 . new , data ) ) end", "del_tokens": "require \"builder\" \"X-Walmart-Body-Signature\" => \"DIGITAL SIG\" body : build_xsd", "commit_type": "add"}
{"commit_tokens": ["Adding", "an", "option", "for", "schema", "validation", "."], "add_tokens": ":version => nil , :validate_schema => false version_string = \"draft-03\" version_string = @options [ :version ] # validate the schema, if requested if @options [ :validate_schema ] begin metaschema_file = File . join ( Pathname . new ( File . dirname ( __FILE__ ) ) . parent . parent , \"resources\" , \"#{version_string}.json\" ) . to_s meta_validator = JSON :: Validator . new ( metaschema_file , schema_data ) meta_validator . validate rescue JSON :: Schema :: ValidationError , JSON :: Schema :: SchemaError raise $! end end", "del_tokens": ":version => nil", "commit_type": "add"}
{"commit_tokens": ["Improve", "error", "methods", "and", "do", "some", "refactoring"], "add_tokens": "def code ; 400 end title : 'Bad Request' , detail : 'This request is not supported.' ) ] class NotFoundError < :: JSONAPI :: Exceptions :: Error def code ; 404 end title : 'Not Found' , detail : 'The requested resource was not found.' ) ] class InternalServerError < :: JSONAPI :: Exceptions :: Error def code ; 500 end def errors [ JSONAPI :: Error . new ( code : 500 , status : :internal_server_error , title : 'Internal Server Error' , detail : 'An internal error ocurred while processing the request.' ) ] end end end", "del_tokens": "# 400 - Bad Request ################################ def code 400 end title : 'Bad Request.' , detail : \"Sorry, but this request is not supported.\" ) ] # 500 - Internal Server Error ################################ class InternalServerError < :: JSONAPI :: Exceptions :: Error def code 500 end title : 'Internal Server error.' , detail : \"Sorry, but an error ocurred during this request.\" ) ] end", "commit_type": "improve"}
{"commit_tokens": ["Remove", "matchy", "as", "it", "was", "incorrectly", "stating", "the", "number", "of", "assertions"], "add_tokens": "assert_equal 'Wynn Netherland' , me . name assert_equal 'pengwynn' , me . username assert_equal 'pengwynn' , us . first . username assert_equal 'jnunemaker' , us . last . username assert_equal 123 , values . first assert_equal 456 , values . last", "del_tokens": "me . name . should == 'Wynn Netherland' me . username . should == 'pengwynn' us . first . username . should == 'pengwynn' us . last . username . should == 'jnunemaker' values . first . should == 123 values . last . should == 456", "commit_type": "remove"}
{"commit_tokens": ["Adds", "methods", "for", "read_ony", "write_only", "and", "update_only", "ressources"], "add_tokens": "return [ ] unless self . class . can_read_external? Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'info' , organization , \"Fetching #{Maestrano::Connector::Rails::External.external_name} #{self.external_entity_name.pluralize}\" ) # Maestrano::Connector::Rails::ConnectorLogger.log('info', organization, \"Received data: Source=#{Maestrano::Connector::Rails::External.external_name}, Entity=#{self.external_entity_name}, Response=#{entities}\") Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'info' , organization , \"Sending create #{external_entity_name}: #{mapped_connec_entity} to #{Maestrano::Connector::Rails::External.external_name}\" ) Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'info' , organization , \"Sending update #{external_entity_name} (id=#{external_id}): #{mapped_connec_entity} to #{Maestrano::Connector::Rails::External.external_name}\" )", "del_tokens": "Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'info' , organization , \"Fetching #{@@external_name} #{self.external_entity_name.pluralize}\" ) # Maestrano::Connector::Rails::ConnectorLogger.log('info', organization, \"Received data: Source=#{@@external_name}, Entity=#{self.external_entity_name}, Response=#{entities}\") Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'info' , organization , \"Sending create #{external_entity_name}: #{mapped_connec_entity} to #{@@external_name}\" ) Maestrano :: Connector :: Rails :: ConnectorLogger . log ( 'info' , organization , \"Sending update #{external_entity_name} (id=#{external_id}): #{mapped_connec_entity} to #{@@external_name}\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "scenario", "with", "stderr", "output", "and", "some", "refactorings"], "add_tokens": "def create_double ( filename , options = { } ) f . puts '#!/usr/bin/env ruby' f . puts \"puts \\\"#{options[:stdout]}\\\"\" if options [ :stdout ] f . puts \"warn \\\"#{options[:stderr]}\\\"\" if options [ :stderr ]", "del_tokens": "def create_double ( filename , content ) f . puts content", "commit_type": "add"}
{"commit_tokens": ["Create", "parent", "class", "for", "ColorModes", "classes", "and", "implement", "equality", "methods"], "add_tokens": "class Base def eql? ( other ) self . class == other . class && to_a == other . to_a end def == ( other ) to_a == other_to_self ( other ) . to_a end end Class . new ( ColorModes :: Base ) do def other_to_self ( other ) other . to_ #{name} end", "del_tokens": "Class . new do", "commit_type": "create"}
{"commit_tokens": ["Fixed", "up", "the", "redirect", "limit", "code", "."], "add_tokens": "redirect_limit = options [ :redirect_limit ] || @options [ :redirect_limit ] || 10 options = options . clone options [ :redirect_limit ] = redirect_limit content = head ( url , options )", "del_tokens": "redirect_limit = options [ :redirect_limit ] content = head ( url , redirect_limit )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "require", "statement", "to", "avoid", "deprecation", "warnings", "."], "add_tokens": "require 'rmagick'", "del_tokens": "require 'RMagick'", "commit_type": "update"}
{"commit_tokens": ["Fix", "typos", "in", "ChainableInitialization", "documentation"], "add_tokens": "# arguments to be passed in. This module halts the propagation of # initialization arguments before invoking the Object class'", "del_tokens": "# arguments to be passed in. This module halts the propgation of # initialization arguments before invoking the Object classes'", "commit_type": "fix"}
{"commit_tokens": ["Changing", "SQL", "security", "insertions", "so", "that", "we", "avoid", "circular", "dependency", "exceptions"], "add_tokens": "skip_before_action :restrict_access", "del_tokens": "skip_before_action :restrict_access , :set_root_resource", "commit_type": "change"}
{"commit_tokens": ["remove", "deprecation", "warning", "for", "Comparing", "equality", "between", "ActionController", "::", "Parameters", "and", "a", "Hash"], "add_tokens": "subject { described_class . model_attributes ( raw_attributes ) . to_unsafe_h } it { is_expected . to include ( 'coverage' => coverage . to_s ) }", "del_tokens": "subject { described_class . model_attributes ( raw_attributes ) } it { is_expected . to eq ( 'coverage' => coverage . to_s ) }", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "where", "logout", "pointed", "to", "wrong", "option"], "add_tokens": "redirect_to_unauth def failure login redirect_to_unauth , notice : params [ :message ]", "del_tokens": "redirect_to_auth def failure conf = Rails . configuration . DAILYCRED_OPTIONS path = ! conf [ :after_unauth ] . nil? ? conf [ :after_unauth ] : dailycred_engine . auth_info_path redirect_to path , notice : params [ :message ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "spec", "after", "changing", "version", "number", "."], "add_tokens": ". with ( body : \"brq_websitekey=12345678&brq_payment_method=ideal&brq_culture=nl-NL&brq_currency=EUR&brq_amount=10.0&brq_invoicenumber=12345&brq_service_ideal_action=Pay&brq_service_ideal_issuer=ABNANL2A&brq_service_ideal_version=2&brq_return=http%3A%2F%2Fwww.return.url%2F&cust_foo=bar&cust_quux=42&add_buckaruby=Buckaruby+#{Buckaruby::VERSION}&brq_signature=0fb3ff3c1f140b5aede33a0fdacbc5675830120d\" ) . with ( body : \"brq_websitekey=12345678&brq_payment_method=ideal&brq_culture=nl-NL&brq_currency=EUR&brq_amount=10.0&brq_invoicenumber=12345&brq_service_ideal_action=Pay&brq_service_ideal_issuer=ABNANL2A&brq_service_ideal_version=2&brq_return=http%3A%2F%2Fwww.return.url%2F&add_myreference=12345&add_buckaruby=Buckaruby+#{Buckaruby::VERSION}&brq_signature=f7996840436bdd55dada28b80c62ed88af10cd23\" )", "del_tokens": ". with ( body : \"brq_websitekey=12345678&brq_payment_method=ideal&brq_culture=nl-NL&brq_currency=EUR&brq_amount=10.0&brq_invoicenumber=12345&brq_service_ideal_action=Pay&brq_service_ideal_issuer=ABNANL2A&brq_service_ideal_version=2&brq_return=http%3A%2F%2Fwww.return.url%2F&cust_foo=bar&cust_quux=42&add_buckaruby=Buckaruby+#{Buckaruby::VERSION}&brq_signature=3335ef9c73400fb02f4a4833b9c0f71a60db56c3\" ) . with ( body : \"brq_websitekey=12345678&brq_payment_method=ideal&brq_culture=nl-NL&brq_currency=EUR&brq_amount=10.0&brq_invoicenumber=12345&brq_service_ideal_action=Pay&brq_service_ideal_issuer=ABNANL2A&brq_service_ideal_version=2&brq_return=http%3A%2F%2Fwww.return.url%2F&add_myreference=12345&add_buckaruby=Buckaruby+#{Buckaruby::VERSION}&brq_signature=7efc0c3402b5cd04bf12517b90ba126174629aeb\" )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "rim", "status", "verify", "clean", "when", "remotes", "are", "dirty", "[", "BS", "-", "236", "]"], "add_tokens": "# don't check the last (remote) status nodes (leaves of the status tree) # these are normally remote commits which could be dirty # the initial commit would also be a leave # TODO: see print_status stat . dirty? || stat . parents . any? { | p | ! p . parents . empty? && any_dirty? ( p ) }", "del_tokens": "stat . dirty? || stat . parents . any? { | p | any_dirty? ( p ) }", "commit_type": "fix"}
{"commit_tokens": ["Added", "development", "mode", "to", "raise", "exceptions", "in", "development"], "add_tokens": ":json_parser => MultiJson . default_adapter , # Development mode # When enabled we don't swallow internal exceptions. # Useful for debugging connection issues. :development_mode => false def development_mode? development_mode . eql? ( true ) end", "del_tokens": ":json_parser => MultiJson . default_adapter", "commit_type": "add"}
{"commit_tokens": ["Remove", "code", "that", "ignores", "special", "passages", "."], "add_tokens": "end", "del_tokens": "elsif %w{ StorySubtitle StoryAuthor StoryMenu StorySettings } . include? k puts \"WARNING: ignoring passage '#{k}'\" @passages [ k ] [ :exclude_from_output ] = true end", "commit_type": "remove"}
{"commit_tokens": ["Updated", "the", "docs", "and", "comments", "for", "the", "new", "features"], "add_tokens": "# @param [Array] args An array of arguments; you can pass a method name, an array of method names # or a method name and an options hash. # @param [Block] &block An optional block for complex configurations # Avaliable options: # - :weight (default: 1) The weight for this indexed value # @example Simple index declaration # blueprint.index :name # @example Index declaration with options # blueprint.index :name, :weight => 10 # @example Mass index declaration # blueprint.index :name, :first_name, :profession # @example Index declaration with a block # blueprint.index :complex, :weight => 10 do # # add some logic here to calculate the value for 'complex' # end", "del_tokens": "# @param [String] name The name of the method that delivers the value for the index # @param [Hash] options # @option options [Integer] :weight (1) The weight for this indexed value", "commit_type": "update"}
{"commit_tokens": ["made", "simple", "async", "method", "example", "simpler"], "add_tokens": "puts 'started foo' sleep ( 1 ) puts 'finished foo' puts 'calling foo' puts 'doing something else' # waiting for everybody to stop Thread . list . reject { | t | t == Thread . current } . each & :join", "del_tokens": "puts \"running foo\" sleep ( 1 ) puts \"hello\"", "commit_type": "make"}
{"commit_tokens": ["fixed", "bug", "with", "checking", "nobot", "in", "fields"], "add_tokens": "acct . fields . any? { | f | f =~ NoBotRegex }", "del_tokens": "acct . fields . collect { | f | f =~ NoBotRegex } . include? true", "commit_type": "fix"}
{"commit_tokens": ["adding", "ability", "to", "check", "for", "existence", "of", "sections"], "add_tokens": "config . app_host = \"file:///Users/nat/github/site_prism/test_site/html\"", "del_tokens": "config . app_host = \"file:///Users/nat/github/prismatic/test_site/html\"", "commit_type": "add"}
{"commit_tokens": ["Remove", "sub_domains", "and", "super_domain_of?", "(", "use", ">", ">", "=", "instead", ")"], "add_tokens": "describe Union , \">\" do ( Boolean > TrueClass ) . should be_true ( Boolean > Boolean ) . should be_false ( Boolean > Integer ) . should be_false", "del_tokens": "describe SByC , \"super_domain_of?\" do Boolean . should be_super_domain_of ( TrueClass ) Boolean . should_not be_super_domain_of ( Boolean ) Boolean . should_not be_super_domain_of ( Integer )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "tests", "for", "new", "which", "-", "ing", "."], "add_tokens": "before do allow ( PoiseLanguages :: Utils ) . to receive ( :which ) do | name | \"/which/#{name}\" end end", "del_tokens": "def which ( name ) \"/which/#{name}\" end def which ( name ) \"/which/#{name}\" end", "commit_type": "fix"}
{"commit_tokens": ["use", "empty?", "rather", "than", "any?"], "add_tokens": "if args . empty? super else if args . empty? super else if args . empty? super else apply_finder_options ( args . first ) . all end", "del_tokens": "if args . any? else super if args . any? else super args . any? ? apply_finder_options ( args . first ) . all : super", "commit_type": "use"}
{"commit_tokens": ["change", "the", "way", "the", "secret", "key", "is", "stored", "and", "accessed"], "add_tokens": "SECRET_SPY_KEY = Object . new if __spy_args . first === __method_spy__ . class :: SECRET_SPY_KEY base_object . send ( method_name , SECRET_SPY_KEY )", "del_tokens": "if __spy_args . first === __method_spy__ . class . __secret_method_key__ # @private def __secret_method_key__ @__secret_method_key__ ||= Object . new end base_object . send ( method_name , __secret_method_key__ )", "commit_type": "change"}
{"commit_tokens": ["Use", "activerecord", "translations", "by", "default", "."], "add_tokens": "base = defined? ( ActiveRecord ) ? :ar : :amo I18n . load_path . unshift File . expand_path ( \"mail_form/locales/#{base}.en.yml\" , File . dirname ( __FILE__ ) )", "del_tokens": "I18n . load_path . unshift File . expand_path ( 'mail_form/locales/en.yml' , File . dirname ( __FILE__ ) )", "commit_type": "use"}
{"commit_tokens": ["add", "Job#branch_info", "fixes", "travis", "show", "for", "jobs"], "add_tokens": "run_cli ( 'show' , '6180.1' , '-E' ) . should be_success", "del_tokens": "run_cli ( 'show' , '6180.1' ) . should be_success", "commit_type": "add"}
{"commit_tokens": ["added", "html_list", "for", "tests", "fixed", "5"], "add_tokens": "#options[:active_li_class] ||= '' #options[:ul_class] ||= '' #options[:ul_id] ||= '' #crumb_string = '<ul class=\"#{options[:ul_class]}\" id=\"#{options[:ul_id]}\">' + crumb_string + '</ul>'", "del_tokens": "options [ :active_li_class ] ||= '' options [ :ul_class ] ||= '' options [ :ul_id ] ||= '' crumb_string = '<ul class=\"#{options[:ul_class]}\" id=\"#{options[:ul_id]}\">' + crumb_string + '</ul>'", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "typo", "in", "lib", "/", "licensee", ".", "rb"], "add_tokens": "# Over which percent is a match considered a match", "del_tokens": "# Over watch percent is a match considered a match", "commit_type": "fix"}
{"commit_tokens": ["allow", "custom", "purging", "conditions", "for", "#purge"], "add_tokens": "# Takes one or two arguments: # # 1. # <regexp> is a string containing a varnish compatible regexp # # 2. # .purge <costum-purge-conditions> # .purge :list # v.purge \"req.http.host ~ www.foo.com && req.http.url ~ images\" # def purge ( * args ) c = 'purge' c << \".#{args.shift}\" if [ :url , :hash , :list ] . include? ( args . first ) response = cmd ( c , * args ) case c when 'purge.list'", "del_tokens": "# .purge :list # .purge <costum-field> <args> # +op+:: :url, :hash, :list or a custom field # +regexp+:: a string containing a varnish compatible regexp def purge ( op , * regexp_or_args ) c = [ :url , :hash , :list ] . include? ( op ) ? \"purge.#{op}\" : \"purge #{op}\" response = cmd ( c , * regexp_or_args ) case op when :list", "commit_type": "allow"}
{"commit_tokens": ["add", "require", "lingua", "/", "stemmer", "to", "spec", "/", "spec_helper", ".", "rb"], "add_tokens": "require 'sad_panda/status_message' require 'lingua/stemmer'", "del_tokens": "require 'sad_panda/status_message'", "commit_type": "add"}
{"commit_tokens": ["Created", "more", "elegant", "date", "parsing"], "add_tokens": "# Assumes date formats: \"2008-07-14 12:11:20\" or alike. # Returns -1 if first_date < second_date, nil if equal # and 1 if first_date > second_date (<=>) return nil if first_date . nil? || second_date . nil? first_date . gsub ( / [^0-9| \\s ] / , '' ) . to_i <=> second_date . gsub ( / [^0-9| \\s ] / , '' ) . to_i", "del_tokens": "# Assumes date formats: \"2008-07-14 12:11:20\" # Returns -1 if first_date < second_date, 0 if equal # and 1 if first_date > second_date first_date = first_date [ 0 .. 9 ] second_date = second_date [ 0 .. 9 ] first_year = first_date [ 0 .. 3 ] . to_i second_year = second_date [ 0 .. 3 ] . to_i return - 1 if first_year < second_year return 1 if first_year > second_year first_month = first_date [ 5 .. 6 ] . to_i second_month = second_date [ 5 .. 6 ] . to_i return - 1 if first_month < second_month return 1 if first_month > second_month first_day = first_date [ 8 .. 9 ] . to_i second_day = second_date [ 8 .. 9 ] . to_i return - 1 if first_day < second_day return 1 if first_day > second_day return 0", "commit_type": "create"}
{"commit_tokens": ["added", "parse", "and", "parse!", "to", "ClassMethods"], "add_tokens": "assert_equal %Q{ Usage : rake_test_loader [ options ] assert_equal %Q{ Usage : rake_test_loader [ options ] assert_equal %Q{ Usage : rake_test_loader [ options ]", "del_tokens": "assert_equal %Q{ Usage : optparse_check [ options ] assert_equal %Q{ Usage : optparse_check [ options ] assert_equal %Q{ Usage : optparse_check [ options ]", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "where", "agent", "loses", "call", "controls", "after", "another", "agent", "transfers", "a", "call", "to", "them"], "add_tokens": "call = agent . active_call", "del_tokens": "call = agent . calls . last", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "known", "bug", "in", "write_multiple_registers"], "add_tokens": "param = { :err => 0 , :addr => param [ :addr ] , :quant => param [ :quant ] , :val => req [ 6 , param [ :quant ] * 2 ] . to_array_int16 }", "del_tokens": "param = { :err => 0 , :addr => param [ :addr ] , :quant => param [ :quant ] , :val => req [ 6 , param [ :quant ] ] . to_array_int16 }", "commit_type": "fix"}
{"commit_tokens": ["Added", "DSL", "specs", "and", "improved", "error", "message", "."], "add_tokens": "if File . exists? guardfile begin dsl = new dsl . instance_eval ( File . read ( guardfile . to_s ) , guardfile . to_s , 1 ) rescue UI . error \"Invalid Guardfile, original error is:\\n#{$!}\" exit 1 end else UI . error \"No Guardfile in current folder, please create one.\" exit 1 end", "del_tokens": "dsl = new dsl . instance_eval ( File . read ( guardfile . to_s ) , guardfile . to_s , 1 ) rescue UI . error \"Guardfile not found or invalid\" exit 1", "commit_type": "add"}
{"commit_tokens": ["Adds", "pull", "-", "request", "and", "general", "GitHub", "functionality", "."], "add_tokens": "def config_hash @config_hash ||= { } end def config ( key = nil , value = nil ) if key and value command ( 'config' , [ key , value ] ) config_hash [ key ] = value value elsif key value = config_hash [ key ] unless value value = command ( 'config' , [ '--get' , key ] ) config_hash [ key ] = value end value else if config_hash . empty? str = command ( 'config' , '--list' ) lines = str . split ( \"\\n\" ) lines . each do | line | ( key , * values ) = line . split ( '=' ) config_hash [ key ] = values . join ( '=' ) end end config_hash end end def repo_name unless @repo_name origin_url = config [ 'remote.origin.url' ] raise Git :: Process :: GitProcessError . new ( \"There is not origin url set up.\" ) if origin_url . empty? @repo_name = origin_url . sub ( / ^.*:(.*?)(.git)?$ / , '\\1' ) end @repo_name end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "stop", "output", "exception", "class", "."], "add_tokens": "require_relative \"pause_output/exceptions\"", "del_tokens": "class Error < StandardError ; end", "commit_type": "add"}
{"commit_tokens": ["Made", "merb", "-", "i", "work"], "add_tokens": "autoload :FastCGI , \"merb_core/rack/adapter/fcgi\" autoload :Irb , \"merb_core/rack/adapter/irb\"", "del_tokens": "autoload :FastCGI , \"merb_core/rack/adapter/fcgi\"", "commit_type": "make"}
{"commit_tokens": ["add", "simple", "provider", "fix", "todo", "move", "roadmap", "issues", "to", "github", "issues"], "add_tokens": "headers = Multimap . new event [ 'msg' ] [ 'headers' ] . each do | key , value | if Array === value value . each do | v | headers [ key ] = v end else headers [ key ] = value end end headers headers", "del_tokens": "headers event [ 'msg' ] [ 'headers' ] . reject { | k , _ | k == 'Received' } # @todo", "commit_type": "add"}
{"commit_tokens": ["Add", "position", "to", "product", "images"], "add_tokens": "default_scope order ( 'position' ) :position , def process config = AssetSync . config bucket = config . fog_directory uri = \"http://#{bucket}.s3.amazonaws.com/media-images/#{self.id}#{File.extname(self.title.downcase)}\" self . image = URI . parse ( uri ) self . save end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["removed", "experimental", "comment", "from", "trading", "method"], "add_tokens": "#### Private User Trading ####", "del_tokens": "#### Private User Trading (Still experimental!) ####", "commit_type": "remove"}
{"commit_tokens": ["Added", "hook", "method", "so", "that", "other", "add", "-", "ons", "can", "tie", "into", "order", "meta", "data", "display", "."], "add_tokens": "# override this if you want to tie-in to meta_data_for's headline def meta_data_headline_extentions_for ( order ) end html += ')' html += meta_data_headline_extentions_for ( order ) html += '</h3>'", "del_tokens": "html += ')</h3>'", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "of", "relations", "as", "scope", "to", "MissingUniqueIndexChecker"], "add_tokens": "@index_columns ||= ( [ wrapped_attribute_name ] + scope_columns ) . map ( & :to_s ) end def scope_columns @scope_columns ||= Array . wrap ( validator . options [ :scope ] ) . map do | scope_item | model . _reflect_on_association ( scope_item ) &. foreign_key || scope_item end", "del_tokens": "@index_columns ||= ( [ wrapped_attribute_name ] + Array . wrap ( validator . options [ :scope ] ) ) . map ( & :to_s )", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "debug", "from", "messaging", "gems", "."], "add_tokens": "def self . enqueue ( task_spec , payload , connect_opts = { } ) def self . connect ( connect_opts = { } , & block ) TaskClient . new ( connect_opts , & block ) def initialize ( connect_opts = { } , & block )", "del_tokens": "def self . enqueue ( task_spec , payload , connect_opts = nil ) def self . connect ( connect_opts = nil , & block ) Tasks . new ( connect_opts , & block ) def initialize ( connect_opts = nil , & block )", "commit_type": "remove"}
{"commit_tokens": ["Add", "instrumentation", "for", "the", "request"], "add_tokens": "autoload :ErrorHandling , 'rocket_pants/controller/error_handling' autoload :Respondable , 'rocket_pants/controller/respondable' autoload :Versioning , 'rocket_pants/controller/versioning' autoload :Instrumentation , 'rocket_pants/controller/instrumentation' Instrumentation ,", "del_tokens": "autoload :ErrorHandling , 'rocket_pants/controller/error_handling' autoload :Respondable , 'rocket_pants/controller/respondable' autoload :Versioning , 'rocket_pants/controller/versioning'", "commit_type": "add"}
{"commit_tokens": ["Fix", "bugs", ";", "specs", "passing"], "add_tokens": "http = RestResponse . new ( SurveyGizmo . put ( handle_route ( :create ) , query : self . attributes_without_blanks ) ) handle_response ( http ) if http . ok? self . attributes = http . data self else false http = RestResponse . new ( SurveyGizmo . post ( handle_route ( :update ) , query : self . attributes_without_blanks ) ) if http . ok? self . attributes = http . data", "del_tokens": "if ENV [ 'GIZMO_DEBUG' ] ap \"SG Set attributes during _create\" ap http_response end http = SurveyGizmo . put ( handle_route ( :create ) , query : self . attributes_without_blanks ) handle_response ( http ) do if @_response . ok? self . attributes = @response . data self else false end http = SurveyGizmo . post ( handle_route ( :update ) , query : self . attributes_without_blanks ) if @_response . ok? self . attributes = @response . data", "commit_type": "fix"}
{"commit_tokens": ["make", "it", "easy", "to", "prefix", "metrics"], "add_tokens": "WF_SDK_VERSION = '1.4.0' . freeze", "del_tokens": "WF_SDK_VERSION = '1.3.0' . freeze", "commit_type": "make"}
{"commit_tokens": ["using", "dynamic", "class", "for", "test"], "add_tokens": "setup { @klass = Class . new @klass . send :include , FourInfo :: Contactable } should \"begin with appropriate default for #{attribute}_column\" do assert_equal attribute , @klass . send ( \"#{attribute}_column\" ) end new_column_name = :custom_column @klass . send \"#{attribute}_column\" , new_column_name assert_equal new_column_name , @klass . send ( \"#{attribute}_column\" )", "del_tokens": "# check for appropriate default assert_equal attribute , User . send ( \"#{attribute}_column\" ) # set to new value new_column_name = :new_column User . send \"#{attribute}_column\" , new_column_name assert_equal new_column_name , User . send ( \"#{attribute}_column\" )", "commit_type": "use"}
{"commit_tokens": ["fixing", "download_with_retry", ".", "rb", "relative", "path", "for", "running", "on", "aws", "via", "git"], "add_tokens": "require_relative File . join \"../..\" , * ( \"../download_with_retry\" if ENV [ \"LOGNAME\" ] == \"nakilon\" ) ,", "del_tokens": "require_relative File . join * ( \"../../../download_with_retry\" if ENV [ \"LOGNAME\" ] == \"nakilon\" ) ,", "commit_type": "fix"}
{"commit_tokens": ["update", "files_to_check", "to", "not", "include", "factory", "files", "by", "default"], "add_tokens": "@files_to_check ||= %w{ db/schema.rb }", "del_tokens": "@files_to_check ||= %w{ db/schema.rb spec/spec_helpers/girl.rb }", "commit_type": "update"}
{"commit_tokens": ["Fixed", "bug", "when", "title", "used", "."], "add_tokens": "title_used = false if title_used && title_used . id == existing_dashboard . id", "del_tokens": "title_used = false if title_used . id == existing_dashboard . id", "commit_type": "fix"}
{"commit_tokens": ["added", "sketching", "ability", "and", "example", "app"], "add_tokens": "height 800 height 100", "del_tokens": "height 850 height 50", "commit_type": "add"}
{"commit_tokens": ["Make", "listen", "actually", "work", "and", "be", "honest", "about", "what", "it", "does", "."], "add_tokens": "# Listen for new messages in the room, yielding them to the provided block as they arrive. # Each message is a hash with: # * +:body+: the body of the message # * +:type+: Campfire message type # * +:room_id+: Campfire room id # * +:created_at+: message timestamp # room.speak \"Go away!\" if m[:body] =~ /Java/i def listen raise \"no block provided\" unless block_given? join # you have to be in the room to listen url = \"http://#{auth[:username]}:#{auth[:password]}@streaming.#{Connection::HOST}/room/#{@id}/live.json\" Yajl :: HttpStream . get ( url , :symbolize_keys => true ) do | message | yield ( message )", "del_tokens": "# Get and array of the messages that have been posted to the room. Each # messages is a hash with: # * +:person+: the display name of the person that posted the message # * +:message+: the body of the message # # room.listen # #=> [{:person=>\"Brandon\", :message=>\"I'm getting very sleepy\", :user_id=>\"148583\", :id=>\"16434003\"}] # # Called without a block, listen will return an array of messages that have been # posted since you joined. listen also takes an optional block, which then polls # for new messages every 5 seconds and calls the block for each message. # room.speak \"#{m[:person]}, Go away!\" if m[:message] =~ /Java/i def listen ( interval = 5 ) url = URI . parse ( \"http://#{auth[:username]}:#{auth[:password]}@streaming.#{Connection::HOST}/room/#{@id}/live.json\" ) Yajl :: HttpStream . get ( url ) do | message | { :id => message [ 'id' ] , :user_id => message [ 'user_id' ] , :message => message [ 'body' ] }", "commit_type": "make"}
{"commit_tokens": ["Added", "new", "features", "cleaned", "up", "readme"], "add_tokens": "module AssociationCollection searcher_class . new ( attributes . merge ( :scope => searcher_scope ) ) def search ( attributes = { } ) searcher_class . search ( attributes . merge ( :scope => searcher_scope ) ) end private def searcher_class \"#{@reflection.klass.name}Searcher\" . constantize end def searcher_scope @owner . send ( @reflection . name ) end", "del_tokens": "class AssociationCollection raise @reflection . inspect \"#{@reflection.klass.name}Searcher\" . constantize", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "only", "update", "the", "@approval", "object", "if", "we", "need", "to", "."], "add_tokens": "set_approval_state ( 'pending' ) changed = { } changed [ attr ] = changed_to @approval = approvals . build ( :event => 'update' , :state => 'pending' , :object => changed ) @approval . save if @approval . present? && @approval . new_record?", "del_tokens": "set_approval_state 'pending' @approval = approvals . build ( :event => 'update' , :state => 'pending' , :object => { } ) @approval . object [ attr ] = changed_to @approval . save if @approval", "commit_type": "make"}
{"commit_tokens": ["Fix", "integration", "tests", "for", "new", "build", "layout", "."], "add_tokens": "directories_match ( Dir [ File . join ( temp_path , 'pkg' , '*' ) ] . first , fixture_path )", "del_tokens": "directories_match ( File . join ( temp_path , 'pkg' ) , fixture_path )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "for", "using", "tags", "."], "add_tokens": "tags = email_data . delete ( :tags ) payload [ :email_data ] = email_data if email_data . any? payload [ :tags ] = tags if tags", "del_tokens": "payload [ :email_data ] = email_data", "commit_type": "add"}
{"commit_tokens": ["fixed", "name", "of", "test", "class", "in", "first", "hooking", "test"], "add_tokens": "class X2 9 x = X2 . new", "del_tokens": "class X x = X . new", "commit_type": "fix"}
{"commit_tokens": ["change", "button", "1", "for", "win7"], "add_tokens": "def click_open click_button ( \"Button1\" ) # Windows 7 # click_button(\"Button2\")", "del_tokens": "def click_open click_button ( \"Button2\" )", "commit_type": "change"}
{"commit_tokens": ["fix", "yaml", "to", "properly", "output", "to_hash"], "add_tokens": "{ :setup => nil , :windows => { 'default' => combined } }", "del_tokens": "{ :setup => nil , :windows => combined }", "commit_type": "fix"}
{"commit_tokens": ["making", "the", "first", "test", "more", "like", "a", "real", "test"], "add_tokens": "html . should have_tag ( \"script[src = ?]\" , %r{ /javascripts/kaltura_upload.js?[0-9]* } )", "del_tokens": "html . should have_tag ( \"script[src = ?]\" , %r{ /javascripts/kaltura_upload.js?[0-9]+ } )", "commit_type": "make"}
{"commit_tokens": ["Add", "--", "no", "-", "validate", "-", "references", "to", "specify", "nothing", "to", "be", "validated"], "add_tokens": "parser . on ( '--[no-]validate-references \"before,require,subscribe,notify\"' , Array , 'References to validate' ) do | res | if res == false options [ :validate_references ] = [ ] else options [ :validate_references ] ||= [ ] res . each do | item | unless %w( before require subscribe notify ) . include? ( item ) raise ArgumentError , \"Invalid reference validation #{item}\" end options [ :validate_references ] << item end", "del_tokens": "parser . on ( '--validate-references \"before,require,subscribe,notify\"' , Array , 'References to validate' ) do | res | options [ :validate_references ] ||= [ ] res . each do | item | unless %w( before require subscribe notify ) . include? ( item ) raise ArgumentError , \"Invalid reference validation #{item}\" end options [ :validate_references ] << item", "commit_type": "add"}
{"commit_tokens": ["Fix", "validating", "fields", "and", "templates"], "add_tokens": "if Page . first . respond_to? ( code_name ) or Page . first . respond_to? ( code_name . pluralize ) or template . self_and_ancestors . map { | t | t . code_name unless t . code_name == code_name } . include? ( code_name . pluralize ) or template . self_and_ancestors . map { | t | t . code_name t . code_name == code_name } . include? ( code_name . singularize ) or template . descendants . map { | t | t . code_name t . code_name == code_name } . include? ( code_name . pluralize ) or template . descendants . map { | t | t . code_name t . code_name == code_name } . include? ( code_name . singularize )", "del_tokens": "if Page . first . respond_to? ( code_name . pluralize ) or template . self_and_ancestors . map { | t | t . code_name } . include? ( code_name . pluralize ) or template . self_and_ancestors . map { | t | t . code_name } . include? ( code_name . singularize ) or template . descendants . map { | t | t . code_name } . include? ( code_name . pluralize ) or template . descendants . map { | t | t . code_name } . include? ( code_name . singularize )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "formatting", "of", "partial", "path", "in", "log", "line"], "add_tokens": "trim_path_right str , maxlen def trim_path_right path , maxlen mxln = maxlen . abs comps = path . split \"/\" str = comps . pop comps . reverse . each do | comp | newstr = comp + \"/\" + str if newstr . length + 4 <= mxln str = newstr else newstr = \"...\" + \"/\" + str if newstr . length <= mxln str = newstr end break end end str end", "del_tokens": "# magic number 3 for the ellipses ... path = str . split ( '/' ) newstr = \"...\" path . reverse . each do | element | if newstr . length + element . length > mxln while newstr . length < mxln newstr . insert 0 , \" \" end return newstr else if newstr . length > 3 newstr . insert 3 , \"/\" end newstr . insert 3 , element end end newstr", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "filter_attributes", "method", "to", "work", "with", "strong_parameters"], "add_tokens": "def before_embedded ( record , action ) ; end def filter_attributes ( name , attrs , action ) attrs end attrs = filter_attributes ( r . class . name , attrs , :update ) attrs = filter_attributes ( r . class . name , attrs , :create ) attrs = filter_attributes ( r . class . name , attrs , :update ) attrs = filter_attributes ( r . class . name , attrs , :create ) controller . send ( :before_embedded , record , :create ) controller . send ( :before_embedded , record , :update ) controller . send ( :before_embedded , record , :destroy )", "del_tokens": "def before_embedded_update ( record ) ; end def before_embedded_create ( record ) ; end def before_embedded_destroy ( record ) ; end controller . send ( :before_embedded_create , record ) controller . send ( :before_embedded_update , record ) controller . send ( :before_embedded_destroy , record )", "commit_type": "add"}
{"commit_tokens": ["Add", "type", "option", "for", "AR", "table", "backend", "options"], "add_tokens": "if type = options [ :type ] case type . to_sym when :text , :string options [ :class_name ] = Mobility :: ActiveRecord . const_get ( \"#{type.capitalize}Translation\" ) options [ :association_name ] = :\" mobility_ #{ type } _translations \" else raise ArgumentError , \"type must be one of: [text, string]\" end end options [ :association_name ] ||= :mobility_text_translations", "del_tokens": "options [ :association_name ] ||= :mobility_translations", "commit_type": "add"}
{"commit_tokens": ["changed", "omniAuth", "access_token", "path", "to", "use", "oauth", "/", "token"], "add_tokens": "# The token url is located at /oauth/token", "del_tokens": "# The token url is located at /oauth/token like proposed in draft oAuth2.16 # but can still be reached at /access_token so older libs still work", "commit_type": "change"}
{"commit_tokens": ["Fix", "edit", "state", "for", "ingest", "form", "and", "associations"], "add_tokens": "attr_accessor :type , :value , :group , :internal , :persisted def persisted? return @persisted end", "del_tokens": "attr_accessor :type , :value , :group , :internal", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "cache", "key", "discrepancy", "when", "reloading", "a", "request"], "add_tokens": "arguments << { } unless arguments . last . is_a? ( Hash ) should_reload = arguments . last . delete ( :reload ) || ! CachedResource . config . cache_enabled arguments . pop if arguments . last . empty?", "del_tokens": "options = ( arguments . last . is_a? ( Hash ) ? arguments . last : { } ) should_reload = options . delete ( :reload ) || ! CachedResource . config . cache_enabled", "commit_type": "fix"}
{"commit_tokens": ["remove", ".", "count", "(", "n", ")", "related", "code"], "add_tokens": "", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Remove", "the", "repeat", "attribute", "from", "frequency"], "add_tokens": "# Recurrence.hourly(total: 5) # Recurrence.daily(total: 5) # Recurrence.weekly(on: :saturday, total: 5) # Recurrence.monthly(on: 15, total: 5) # Recurrence.yearly(on: [:january, 14], total: 5)", "del_tokens": "# Recurrence.hourly(repeat: 5) # Recurrence.daily(repeat: 5) # Recurrence.weekly(on: :saturday, repeat: 5) # Recurrence.monthly(on: 15, repeat: 5) # Recurrence.yearly(on: [:january, 14], repeat: 5)", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "found", "issue", "after", "testing"], "add_tokens": "validates :url , pattern : / #{ Regexp . escape ( settings . app_host ) } \\/ ? /", "del_tokens": "URL_PATTERN = / #{ Regexp . escape ( settings . app_host ) } \\/ ? /", "commit_type": "fix"}
{"commit_tokens": ["Use", "RR", "for", "mocking", "."], "add_tokens": "require 'rr' Riot :: Situation . send :include , RR :: Adapters :: RRMethods", "del_tokens": "#require 'rr' #Riot::Situation.send :include, RR::Adapters::RRMethods", "commit_type": "use"}
{"commit_tokens": ["Fix", "sorting", "issue", "in", "Utils", ".", "normalize_params"], "add_tokens": "flatten_params ( params ) . sort . map do | pair | end * '&'", "del_tokens": "flatten_params ( params ) . map do | pair | end . sort * '&'", "commit_type": "fix"}
{"commit_tokens": ["add", ":", "prevent", "new", "attribute", "hosts", "from", "being", "changed", "and", "show", "deprecated", "debug", "message", "on", "using", "method", "host"], "add_tokens": "def hosts # prevent original array from being changed @hosts . dup end # New but deprecated method to access the old host attr for compatibility reasons logger . debug ( 'Deprecated method host is used. Please update to hosts.join() etc.' ) hosts . join ( ', ' )", "del_tokens": "attr_reader :hosts # Deprecated method to access the old host attr return hosts . join ( ', ' )", "commit_type": "add"}
{"commit_tokens": ["removed", "styleguide", "from", "the", "routes", "and", "updated", "README", "and", "changelog"], "add_tokens": "match \"/colors\" => \"styleguide#colors\" match \"/typography\" => \"styleguide#typography\"", "del_tokens": "match \"styleguide/colors\" => \"styleguide#colors\" match \"styleguide/typography\" => \"styleguide#typography\"", "commit_type": "remove"}
{"commit_tokens": ["fix", "api", "changes", "for", "aws", "sdk", "v3"], "add_tokens": "Aws :: Sigv4 :: Signer . new ( service : service_name , region : region , credentials : credentials . call ) def signer . sign_request ( req ) self . call . sign_request ( req ) Aws :: Sigv4 :: Signer . new ( service : service_name , region : region , credentials : credentials )", "del_tokens": "Aws :: Signers :: V4 . new ( credentials . call , service_name , region ) def signer . sign ( req ) self . call . sign ( req ) Aws :: Signers :: V4 . new ( credentials , service_name , region )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "up", "path", "to", "session", "grantor", "examples", "."], "add_tokens": "require File . expand_path ( '../a_session_grantor' , __FILE__ )", "del_tokens": "require File . expand_path ( '../../shared/models/a_session_grantor' , __FILE__ )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "attribute", "data", "type", "."], "add_tokens": "# TODO: Fix it!! Ugly! attributes = @rubySyntaxSupport . get_attribute ( pLine ) attributeName = [ ] attributes . each do | attribute | currentAttribute = attributes . pop attributeName . push ( currentAttribute . name ) end attributeName . each do | elementName | attribute = Languages :: AttributeData . new ( elementName ) attribute . visibility = @visibility @currentClass . add_attribute ( attribute ) end", "del_tokens": "attributeName = @rubySyntaxSupport . get_attribute ( pLine ) attribute = Languages :: AttributeData . new ( attributeName ) attribute . visibility = @visibility @currentClass . add_attribute ( attribute )", "commit_type": "fix"}
{"commit_tokens": ["add", "filters", "&", "back", "to", "ipapi", "com"], "add_tokens": "ip_lookup : :ipapi_com , #ip_lookup: :telize,", "del_tokens": "# ip_lookup: :ipapi_com, ip_lookup : :telize ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "company", "custom", "data"], "add_tokens": "proc_or_symbol . call ( proxied_object )", "del_tokens": "proc_or_symbol . call ( user )", "commit_type": "fix"}
{"commit_tokens": ["fix", "NaN", "/", "Infinity", "handling"], "add_tokens": "rescue FFI_Yajl :: EncodeError => e", "del_tokens": "rescue FII_Yajl :: EncodeError => e", "commit_type": "fix"}
{"commit_tokens": ["removed", "Post", ".", "published", "field", "from", "scopes", "and", "tests"], "add_tokens": "scope :posted , -> { where ( 'created_at <= ?' , Time . now ) } created_at <= Time . now", "del_tokens": "scope :posted , -> { where ( 'created_at <= ? AND published = ?' , Time . now , true ) } published && created_at <= Time . now", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "specifying", "a", "default", "operator", "for", "a", "field"], "add_tokens": "attr_reader :definition , :field , :only_explicit #, :relation [ :integer , :double , :float , :decimal ] . include? column . type end def textual? [ :string , :text ] . include? column . type @only_explicit = ! ! options [ :only_explicit ] @default_operator = options [ :default_operator ] if options . has_key? ( :default_operator )", "del_tokens": "attr_reader :definition , :field , :only_explicit , :relation @only_explicit = ! ! options [ :only_explicit ] # TODO: options[:default_operator]", "commit_type": "implement"}
{"commit_tokens": ["using", "id", "instead", "of", "job_id"], "add_tokens": "attr_accessor :id , :details , :locked_at @id = args [ \"id\" ] execute ( \"DELETE FROM jobs WHERE id = #{job.id}\" ) find_one { \"SELECT * FROM jobs WHERE id = #{job.id}\" } find_one { \"SELECT * FROM jobs ORDER BY id ASC LIMIT 1\" } job = find_one { \"SELECT * FROM jobs WHERE locked_at IS NULL ORDER BY id ASC LIMIT 1 FOR UPDATE\" } locked = execute ( \"UPDATE jobs SET locked_at = (CURRENT_TIMESTAMP) WHERE id = #{job.id} AND locked_at IS NULL\" ) execute ( \"SELECT * FROM jobs ORDER BY id ASC\" ) . each do | r | \"id\" => r [ \"id\" ] ,", "del_tokens": "attr_accessor :job_id , :details , :locked_at @job_id = args [ \"job_id\" ] execute ( \"DELETE FROM jobs WHERE job_id = #{job.job_id}\" ) find_one { \"SELECT * FROM jobs WHERE job_id = #{job.job_id}\" } find_one { \"SELECT * FROM jobs ORDER BY job_id ASC LIMIT 1\" } job = find_one { \"SELECT * FROM jobs WHERE locked_at IS NULL ORDER BY job_id ASC LIMIT 1 FOR UPDATE\" } locked = execute ( \"UPDATE jobs SET locked_at = (CURRENT_TIMESTAMP) WHERE job_id = #{job.job_id} AND locked_at IS NULL\" ) execute ( \"SELECT * FROM jobs ORDER BY job_id ASC\" ) . each do | r | \"job_id\" => r [ \"job_id\" ] ,", "commit_type": "use"}
{"commit_tokens": ["Add", "specs", "for", "fedora", "module"], "add_tokens": "require 'polisher/bodhi' def self . client @client ||= Curl :: Easy . new end client . url = \"#{PACKAGE_LIST}#{user}\" client . http_get packages = client . body_str # simply dispatch to bodhi to get latest updates Polisher :: Bodhi . versions_for name do | target , name , versions | bl . call ( :fedora , name , versions ) unless ( bl . nil? ) end", "del_tokens": "curl = Curl :: Easy . new ( \"#{PACKAGE_LIST}}#{user}\" ) curl . http_get packages = curl . body_str # XXX bug w/ python-pkgwat, some html content # is being returned w/ versions, need to look into versions = Pkgwat . get_versions ( name ) versions . reject! { | pkg | pkg [ 'stable_version' ] == \"None\" } versions = versions . collect { | pkg | pkg [ 'stable_version' ] } bl . call ( :fedora , name , versions ) unless ( bl . nil? ) versions", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "dirty", "tracking", "attributes", "."], "add_tokens": "Version = VERSION = '0.6.2'", "del_tokens": "Version = VERSION = '0.6.1'", "commit_type": "add"}
{"commit_tokens": ["Added", "process", "blockers", "to", "Rails", "summarizer"], "add_tokens": "tracker . update ( request ) if tracker . should_update? ( request ) def should_update? ( request ) return false if options [ :line_type ] && ! request . has_line_type? ( options [ :line_type ] ) if options [ :if ] . kind_of? ( Symbol ) return false unless request [ options [ :if ] ] elsif options [ :if ] . respond_to? ( :call ) return false unless options [ :if ] . call ( request ) end if options [ :unless ] . kind_of? ( Symbol ) return false if request [ options [ :unless ] ] elsif options [ :unless ] . respond_to? ( :call ) return false if options [ :unless ] . call ( request ) end return true end", "del_tokens": "tracker . update ( request ) return if options [ :line_type ] && ! request . has_line_type? ( options [ :line_type ] ) return if options [ :line_type ] && ! request . has_line_type? ( options [ :line_type ] )", "commit_type": "add"}
{"commit_tokens": ["changed", "how", "javascript", "is", "included"], "add_tokens": "it \"shouldn't render growl\" do describe \"country_scripts\" do it \"should render country scripts\" do pending \"figure out how to test country_scripts #{__FILE__}\" #helper.country_scripts.should include('muck_countries') end it \"shouldn't render country scripts\" do @@country_scripts_included = true helper . country_scripts . should be_blank end end describe \"muck_form_for\" do pending \"test muck_form_for #{__FILE__}\" end describe \"show_hide_on_click\" do it \"should render show/hide jquery script\" do helper . show_hide_on_click ( 'id_to_show' , 'id_to_hide' ) . should include ( \"jQuery('#id_to_show')\" ) helper . show_hide_on_click ( 'id_to_show' , 'id_to_hide' ) . should include ( \"jQuery('#id_to_hide')\" ) end end", "del_tokens": "it \"should n't render growl\" do # describe \"country_scripts\" do # it \"should render country scripts\" do # helper.country_scripts.should include('muck-countries') # end # it \"shouldn't render country scripts\" do # @@country_scripts_included = true # helper.country_scripts.should be_empty # end # end # # describe \"muck_form_for\" do # end # # describe \"show_hide_on_click\" do # it \"should render show/hide jquery script\" do # helper.show_hide_on_click('id_to_show', 'id_to_hide').should include(\"jQuery('id_to_show')\") # helper.show_hide_on_click('id_to_show', 'id_to_hide').should include(\"jQuery('id_to_hide')\") # end # end", "commit_type": "change"}
{"commit_tokens": ["add", "retrieval", "of", "default", "configuration"], "add_tokens": "# sets configuration options on this entity # uses a DataForms form # returns the iq context for the answer def configure ( form ) # retrieve default configuration of this entity # returns the iq context for the answer def default_configuration subscribee = connection . jid . bare args = { 'node' => node_id } if node_id iq = connection . iq_stanza ( 'to' => jid . bare , 'type' => 'get' ) do | xml | xml . pubsub ( :xmlns => EM :: Xmpp :: Namespaces :: PubSub ) do | sub | sub . default ( args ) end end send_iq_stanza_fibered iq end # subscribe and configure this entity at the same time # see subscribe and configure # returns the iq context for the answer def subscribe_and_configure ( form ) subscribee = connection . jid . bare iq = connection . iq_stanza ( 'to' => jid . bare , 'type' => 'set' ) do | xml | xml . pubsub ( :xmlns => EM :: Xmpp :: Namespaces :: PubSub ) do | sub | sub . subscribe ( 'node' => node_id , 'jid' => subscribee ) sub . options do | options | connection . build_submit_form ( options , form ) end end end send_iq_stanza_fibered iq end", "del_tokens": "def set_options ( form ) #TODO: configure # subscribe_and_configure", "commit_type": "add"}
{"commit_tokens": ["Fixed", "working", "with", "large", "archives"], "add_tokens": "unless window_position . respond_to? ( :to_int ) then raise TypeError , \"can't convert #{window_position.class} into Integer\" window_position = window_position . to_int unless window_size . respond_to? ( :to_int ) then raise TypeError , \"can't convert #{window_size.class} into Integer\" window_size = window_size . to_int", "del_tokens": "unless window_position . kind_of? ( Fixnum ) then raise ArgumentError , 'non-integer window position given' unless window_size . kind_of? ( Fixnum ) then raise ArgumentError , 'non-integer window size given'", "commit_type": "fix"}
{"commit_tokens": ["Move", "parsing", "of", "columns", "to", "class"], "add_tokens": "require_relative 'columns/column' attr_accessor :count @count = columns_count @columns = Array . new ( @count ) end # Parse Columns data # @param [Nokogiri::XML:Element] node with Columns data # @return [DocumentGrid] value of Columns data def self . parse ( columns_grid ) columns_count = 1 columns_count = columns_grid . attribute ( 'num' ) . value . to_i unless columns_grid . attribute ( 'num' ) . nil? columns = Columns . new ( columns_count ) columns . separator = columns_grid . attribute ( 'sep' ) . value unless columns_grid . attribute ( 'sep' ) . nil? i = 0 columns_grid . xpath ( 'w:col' ) . each do | col | width = col . attribute ( 'w' ) . value width = StringHelper . round ( width . to_f / 566.9 , 2 ) unless width . nil? space = col . attribute ( 'space' ) . value space = StringHelper . round ( space . to_f / 566.9 , 2 ) unless space . nil? columns . columns [ i ] = Column . new ( width , space ) i += 1 end columns", "del_tokens": "@columns = Array . new ( columns_count )", "commit_type": "move"}
{"commit_tokens": ["Updated", "examples", "issues", "and", "Rakefile"], "add_tokens": "when Qt :: SystemTrayIcon :: Trigger when Qt :: SystemTrayIcon :: DoubleClick when Qt :: SystemTrayIcon :: MiddleClick @typeComboBox . addItem ( style ( ) . standardIcon ( Qt :: Style :: SP_MessageBoxInformation ) , @typeComboBox . addItem ( style ( ) . standardIcon ( Qt :: Style :: SP_MessageBoxWarning ) , @typeComboBox . addItem ( style ( ) . standardIcon ( Qt :: Style :: SP_MessageBoxCritical ) ,", "del_tokens": "when Qt :: SystemTrayIcon :: Trigger : when Qt :: SystemTrayIcon :: DoubleClick : break when Qt :: SystemTrayIcon :: MiddleClick : break else @typeComboBox . addItem ( style ( ) . standardIcon ( Qt :: Style :: SP_MessageBoxInformation ) , @typeComboBox . addItem ( style ( ) . standardIcon ( Qt :: Style :: SP_MessageBoxWarning ) , @typeComboBox . addItem ( style ( ) . standardIcon ( Qt :: Style :: SP_MessageBoxCritical ) ,", "commit_type": "update"}
{"commit_tokens": ["Add", "allow_nil", "option", "and", "handle", "it", "in", "IntegerSchema", "."], "add_tokens": "validate_constraints ( sanitized_object ) if ! sanitized_object . nil?", "del_tokens": "validate_constraints ( sanitized_object )", "commit_type": "add"}
{"commit_tokens": ["Added", "all", "followers", "/", "followees", "by", "model", "."], "add_tokens": "# view all selfs followers by model # # Example: # >> @clyde.all_followers_by_model # => [@bonnie] def all_followers_by_model ( model ) get_followers_of ( self , model ) end def get_followers_of ( me , model = nil ) followers = ! model ? me . followers : me . followers . where ( :ff_type => model . to_s ) followers . collect do | f | elsif missing_method . to_s =~ / ^all_(.+)_followers$ / all_followers_by_model ( $1 . camelize )", "del_tokens": "def get_followers_of ( me ) me . followers . collect do | f |", "commit_type": "add"}
{"commit_tokens": ["Added", "migrations", "contact", "form", "saving", "and", "regex"], "add_tokens": "@message = ContactForm . new ( contact_form_params ) session [ :return_to ] = request . referer if @message . save EmailContactFormWorker . perform_async ( @message . id ) format . html { redirect_to \"#{session[:return_to]}\" , notice : \"Your message has been sent successfully thank you.\" } else flash [ :error ] = 'You missed out some required fields. Please try again.' format . html { redirect_to \"#{session[:return_to]}\" } end", "del_tokens": "session [ :return_to ] = request . referer Notifier . contact_form ( params ) . deliver format . html { redirect_to \"#{session[:return_to]}#contact_form\" , notice : \"Your message has been sent successfully thank you.\" }", "commit_type": "add"}
{"commit_tokens": ["Added", "example", "bowlers", "for", "command", "-", "line", "and", "yaml", "markups", "."], "add_tokens": "# # By default it {String#bowl}es the input, substituting # ASCII symbols like letters, digits, dots, commas and parenthesis # to the same symbols within fullwidth latin set (`U+FF01`  `U+FFFF`). # Now its safe to have input string, containing, when :eol then '.' else '.' out = out . split ( / \\R / ) . map { | line | line . gsub ( / ( #{ v [ :from ] } * \\s *) #{ k . bowl } ( \\s * #{ v [ :till ] } *) / ) { from , till = $~ [ 1 , 2 ] \" #{k.bowl} #{from.spacefy} #{till.spacefy} \" } } . join ( \"\\n\" ) # @param [String] str the input string. NB! It might be dangerous to call this method # without preceeding call to {#defreeze} (mainly {String#bowl} on input inside {#defreeze}). @out = str . uncarriage . unify.u n spacefy.u n bowl", "del_tokens": "# # By default it {String#bowl}es the input, substituting: # # - symbols like dots, commas and parenthesis to Burmese letters # (I was unable to locate Klingon in UTF tables, pity on me); # - digits staying alone are prepended with another weird UTF symbol, # making it well-formed ruby methods; # - ruby method omonims, available in this context, are prepended with # same UTF symbol, and therefore are made distinguishable from # methods themselves. Now its safe to have input string, containing, # # raise Exception.new \"Reserved symbols are used in input. Aborting\" \\ # if /[#{String::BOWL_SYMBOLS}]/ =~ str else '\\R' out . gsub! ( / ( #{ v [ :from ] } * \\s *) #{ k } ( \\s * #{ v [ :till ] } *) / ) { from , till = $~ [ 1 , 2 ] \"#{k} #{from.gsub(/\\s/, String::SYMBOL_FOR_SPACE)} #{till.gsub(/\\s/, String::SYMBOL_FOR_SPACE)} \" } # @param [String] str the input string. NB! It might be dangerous to call this method without preceeding call to {#defreeze} (mainly {String#bowl} on input inside {#defreeze}). # # @out = str . uncarriage . unify.u n bowl", "commit_type": "add"}
{"commit_tokens": ["Added", "spec", "for", "interpolated", "lines", ".", "Rest", "to", "fix", "segmented", "lines"], "add_tokens": "paths . push ( firstPath + self . path_basis ( p0 , p1 , p2 , p3 ) . to_s ) # merge first & second path paths . push ( path_basis ( p1 , p2 , p3 , p3 ) . segment + path_basis ( p2 , p3 , p3 , p3 ) . to_s )", "del_tokens": "paths . push ( firstPath + self . path_basis ( p0 , p1 , p2 , p3 ) ) ; # merge first & second path paths . push ( path_basis ( p1 , p2 , p3 , p3 ) . segment + path_basis ( p2 , p3 , p3 , p3 ) )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "the", "link", "behaviour", "when", "duplicating", "a", "block"], "add_tokens": "# # * link: It doesn't dup the field but stores the same object. It's # useful in Active Record fields so we can store the same id and # not creating a duplicate of the object (e.g. if we have a block # with a related post we don't want the post to be duplicated) when :link field_value # and then we store the new id in the fields_info hash fields_info [ \"#{field}_id\" . to_sym ] = dupped_value . nil? ? nil : dupped_value . id", "del_tokens": "# and then we remove the old id from the fields_info hash fields_info [ \"#{field}_id\" . to_sym ] = nil", "commit_type": "implement"}
{"commit_tokens": ["use", "singleton_class", "when", "extending", "test", "workflow"], "add_tokens": "if defined? ( flexmock ) flexmock ( workflow . class ) . should_receive ( :terminal? ) . and_return ( true ) end", "del_tokens": "workflow . singleton_class . extend ( WorkerUnitTestFlow :: ClassMethods ) module ClassMethods def terminal? ( name ) return true end end", "commit_type": "use"}
{"commit_tokens": ["Add", "tests", "for", "props", "controller"], "add_tokens": "let ( :prop_for_long_term_rent ) { FactoryGirl . create ( :pwb_prop , :available_for_long_term_rent , price_rental_monthly_current_cents : 100000 ) } let ( :prop_for_sale ) { FactoryGirl . create ( :pwb_prop , :available_for_sale , price_sale_current_cents : 10000000 ) } describe 'GET #show_for_rent' do it 'renders correct template' do expect ( get ( :show_for_rent , params : { id : prop_for_long_term_rent . id , url_friendly_title : \"tt\" } ) ) . to render_template ( 'pwb/props/show' ) end end describe 'GET #show_for_sale' do context 'with id of for sale prop' do it 'renders correct template' do expect ( get ( :show_for_sale , params : { id : prop_for_sale . id , url_friendly_title : \"tt\" } ) ) . to render_template ( 'pwb/props/show' ) end end context 'with id of for rent prop' do it 'renders correct template' do expect ( get ( :show_for_sale , params : { id : prop_for_long_term_rent . id , url_friendly_title : \"tt\" } ) ) . to render_template ( 'pwb/props/not_found' ) end end end", "del_tokens": "# describe 'GET #show_for_rent' do # it 'renders correct template' do # # byebug # expect(get(:show_for_rent)).to render_template('pwb/welcome/show_for_rent') # # above results in error: # # ActionController::UrlGenerationError Exception: No route matches {:action=>\"prop_show_for_rent\", :controller=>\"pwb/props\"} # end # end", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "RspecApiDocumentation", "::", "Example"], "add_tokens": "class Example < Mustache self . example = example def example_group ExampleGroup . new ( example . example_group ) example_group . dirname def filename description . downcase . gsub ( / \\s + / , '_' ) . gsub ( / [^a-z_] / , '' )", "del_tokens": "class Example @example = example def filename description . downcase . gsub ( / \\s + / , '_' ) . gsub ( / [^a-z_] / , '' ) ExampleGroup . new ( example . example_group ) . dirname def filepath ( base_dir ) base_dir . join ( dirname , filename ) def render ( template ) Mustache . render ( template , metadata ) end", "commit_type": "add"}
{"commit_tokens": ["Adding", "access", "to", "some", "extra", "listing", "attributes", "."], "add_tokens": "# [state] The current state of the item # [hue] The hue of the listing's primary image (HSV color). # [saturation] The saturation of the listing's primary image (HSV color). # [brightness] The value of the listing's primary image (HSV color). # [black_and_white?] True if the listing's primary image is in black & white. attribute :modified , :from => :last_modified_tsz :tags , :materials , :hue , :saturation , :brightness , :is_black_and_white def black_and_white? is_black_and_white end # Time that this listing was last modified # def modified_at Time . at ( modified ) end", "del_tokens": ":tags , :materials", "commit_type": "add"}
{"commit_tokens": ["Adding", "more", "to", "the", "basic", "error", "code", "."], "add_tokens": "super ( c_error . best_message ) class CError < FFI :: ManagedStruct class << self def release ( ptr ) C . clear ( ptr ) end end # returns the most accurate message for an error def best_message # create a buffer, which may be used to hold the best message buf = FFI :: MemoryPointer . new ( 1024 ) msg = C . best_message ( self , buf , 1024 ) # return a duplicate of msg, since it may be stored in the buffer # allocated above msg . dup end ffi_lib 'libsvn_subr-1.so.1' typedef CError . by_ref , :error typedef :int , :size attach_function :best_message , :svn_err_best_message , [ :error , :buffer_inout , :size ] , :string attach_function :clear , :svn_error_clear , [ :error ] , :void end", "del_tokens": "@message = c_error [ :message ] class CError < FFI :: Struct end # TODO: add a release method that calls svn_error_clear", "commit_type": "add"}
{"commit_tokens": ["Add", "forwardMessage", "getMe", "and", "sendLocation", "requests", "."], "add_tokens": "# This object represents a sendMessage request validates :chat_id , numericality : true , unless : \"chat_id.to_s[0,1] == '@'\"", "del_tokens": "# This object represents a Telegram user or bot. validates :chat_id , numericality : true", "commit_type": "add"}
{"commit_tokens": ["added", "block", "evaluation", "to", "Logging#child"], "add_tokens": "ch = ChildLogger . new ( self , fields ) if ! block_given? ch else yield ch end", "del_tokens": "ChildLogger . new ( self , fields )", "commit_type": "add"}
{"commit_tokens": ["Adds", "non_block", "argument", "to", "Queue#pop"], "add_tokens": "# If +non_block+ is true, it will raise {Error} instead. # @raise {Error} if queue is empty and +non_block+ is true # @param non_block [Boolean] def pop ( non_block = false ) raise Error if non_block", "del_tokens": "def pop", "commit_type": "add"}
{"commit_tokens": ["updated", "deps", "and", "assets", "."], "add_tokens": "VERSION = \"2.4.0\"", "del_tokens": "VERSION = \"2.3.0\"", "commit_type": "update"}
{"commit_tokens": ["Use", "xpath", "to", "traverse", "the", "ast", "."], "add_tokens": "Given / ^a cookbook with a single recipe that creates a directory resource with an interpolated variable and a literal$ / do Given / ^a cookbook with a single recipe that creates a directory resource with a literal and interpolated variable$ / do write_recipe %q{ directory \"base_dir/#{node[:sub_dir]}\" do owner \"root\" group \"root\" mode \"0755\" action :create end } . strip end", "del_tokens": "Given / ^a cookbook with a single recipe that creates a directory resource with an interpolated literal and expression$ / do", "commit_type": "use"}
{"commit_tokens": ["Add", "base", "Derelict", "::", "Exception", "class"], "add_tokens": "autoload :Exception , \"derelict/exception\"", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["Added", "DeploYML", "::", "ORMS", "and", "Project#migrate!", "."], "add_tokens": "require 'deployml/orms' require 'deployml/utils' # Mapping of possible 'server' names to their mixins. # Mapping of possible 'orm' names to their mixins. ORMS = { :active_record => ORMS :: ActiveRecord , :data_mapper => ORMS :: DataMapper } load_orm! # # Place-holder method for {#migrate!}. # def migrate! end migrate! # # Loads the ORM configuration. # def load_orm! if @config . orm unless ORMS . has_key? ( @config . orm ) raise ( UnknownORM , \"Unknown ORM #{@config.orm}\" , caller ) end extend ORMS [ @config . orm ] initialize_orm ( ) if self . respond_to? ( :initialize_orm ) end end", "del_tokens": "require 'deployml/utils' # Mapping of possible :server names to their Server handler classes.", "commit_type": "add"}
{"commit_tokens": ["allow", "specifying", "theme", "options", "via", "Themes#register"], "add_tokens": "attr_reader :name , :directory_name , :options def initialize ( name , options = { } ) @options = options def has_home_button? @options [ :home_button ] end", "del_tokens": "attr_reader :name , :directory_name def initialize ( name )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "spec", "failures", "on", "JRuby"], "add_tokens": "expect ( string . to_slug . word_chars! ) . to match ( / [a-z ]* /i ) expect ( ss . approximate_ascii! ) . to match ( / [ \\x0 - \\x7f ] / )", "del_tokens": "expect ( string . to_slug . word_chars ) . to match ( / [a-z ]* /i ) expect ( ss . approximate_ascii ) . to match ( / [ \\x0 - \\x7f ] / )", "commit_type": "fix"}
{"commit_tokens": ["Added", "actions", ".", "Working", "on", "selectors"], "add_tokens": "return true if ( view . rmq_data . has_style? ( selector ) ) || view . rmq_data . has_tag? ( selector ) return true if view . getId == selector", "del_tokens": "# TODO, make this faster #return true if (view.rmq_data.has_style?(selector)) || view.rmq_data.has_tag?(selector) # TODO, make this hugely faster #return true if view.object_id == selector", "commit_type": "add"}
{"commit_tokens": ["Added", "valid?", "method", "and", "created", "numeralize", "class", "method", "."], "add_tokens": "def self . valid? exp ! ( numeralize ( exp ) =~ / \\A (.*? \\s ){5}.*? \\S \\z / ) . nil? end def self . numeralize exp exp = exp . to_s . downcase exp end def parse_cron_numbers exp , min , max numbers = Array . new exp = MyCron . numeralize ( exp )", "del_tokens": "def parse_cron_numbers exp , min , max numbers = Array . new exp . downcase!", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "image", "series", "slice", "spacing"], "add_tokens": "# Collect slice positions and sort them: slice_positions = NArray . to_na ( @images . collect { | image | image . pos_slice } . sort )", "del_tokens": "# Collect slice positions: slice_positions = NArray . to_na ( @images . collect { | image | image . pos_slice } )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "use", "new", "api"], "add_tokens": "# frozen_string_literal: true SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter . new ( [ ] )", "del_tokens": "SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter [ ]", "commit_type": "change"}
{"commit_tokens": ["add", "render", "function", "to", "renderer"], "add_tokens": "def render \"test\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "comment", "based", "timestamp", "."], "add_tokens": "# The first line of the SQL should be a comment specifying the timestamp for the source. # -- 2016-12-19 15:45 # -- 2016-12-19 # -- 201612191545 # -- 20161219 # # The timestamp will be converted into a 12-digit number, if time is not specified it will be right-padded # with zeroes to get to the 12-digit number. def add_source ( sql ) sql_def = BarkestCore :: MsSqlDefinition . new ( sql , '' ) # # The source files should specify a timestamp in the first comment. # -- 2016-12-19 15:45 # -- 2016-12-19 # -- 201612191545 # -- 20161219 # # The timestamp will be converted into a 12-digit number, if time is not specified it will be right-padded # with zeroes to get to the 12-digit number. #", "del_tokens": "# The +timestamp+ should be in the form YYYYMMDDHHMM, but will be right-padded with zeroes to fill out the full # width if you only specify part. # 20161209 => 201612090000 def add_source ( timestamp , sql ) sql_def = BarkestCore :: MsSqlDefinition . new ( sql , '' , timestamp )", "commit_type": "change"}
{"commit_tokens": ["Remove", "array", "versions", "of", "iteration", "method", "in", "Node"], "add_tokens": "describe '#each_ancestor' do describe '#each_child_node' do describe '#each_descendent' do", "del_tokens": "shared_context 'ancestor nodes' do end describe '#each_ancestor' do include_context 'ancestor nodes' describe '#ancestors' do include_context 'ancestor nodes' it 'returns an array' do expect ( target_node . ancestors ) . to be_an ( Array ) end it 'returns the same nodes as #each_ancestor' do types = target_node . ancestors . map ( & :type ) expect ( types ) . to eq ( expected_types ) end end shared_context 'child nodes' do end describe '#each_child_node' do include_context 'child nodes' describe '#child_nodes' do include_context 'child nodes' it 'returns an array' do expect ( root_node . child_nodes ) . to be_an ( Array ) end it 'returns same nodes as #each_child_node' do types = target_node . child_nodes . map ( & :type ) expect ( types ) . to eq ( expected_types ) end end shared_context 'descendent nodes' do end describe '#each_descendent' do include_context 'descendent nodes' describe '#descendents' do include_context 'descendent nodes' it 'returns an array' do expect ( target_node . descendents ) . to be_an ( Array ) end it 'returns same nodes as #each_descendent' do types = target_node . descendents . map ( & :type ) expect ( types ) . to eq ( expected_types ) end end", "commit_type": "remove"}
{"commit_tokens": ["Add", "wkt_helper", "method", "to", "hide", "wkt", "internals"], "add_tokens": "end def wkt_helper raise 'Not implemented' \"POINT (#{wkt_helper})\" def wkt_helper \"LINESTRING #{wkt_helper}\" def wkt_helper \"(#{@points.map{ |point| point.wkt_helper }.join(', ')})\" \"MULTILINESTRING (#{wkt_helper})\" end def wkt_helper @lines . map ( & :wkt_helper ) . join ( ', ' ) \"POLYGON (#{wkt_helper})\" def wkt_helper holes = @holes . map ( & :wkt_helper ) . join ( ', ' ) if @holes . any? [ @border_line . wkt_helper , holes ] . compact . join ( ', ' ) \"MULTIPOLYGON (#{wkt_helper})\" def wkt_helper @polygons . map { | polygon | \"(#{polygon.wkt_helper})\" } . join ( ', ' )", "del_tokens": "\"POINT (#{wkt_latlon})\" def wkt_latlon \"LINESTRING #{wkt_linestring}\" def wkt_linestring \"(#{@points.map(&:wkt_latlon).join(', ')})\" \"MULTILINESTRING (#{@lines.map(&:wkt_linestring).join(', ')})\" \"POLYGON (#{wkt_polygon})\" def wkt_polygon holes = @holes . map ( & :wkt_linestring ) . join ( ', ' ) if @holes . any? [ @border_line . wkt_linestring , holes ] . compact . join ( ', ' ) \"MULTIPOLYGON (#{wkt_multipolygon})\" def wkt_multipolygon @polygons . map { | p | \"(#{p.wkt_polygon})\" } . join ( ', ' )", "commit_type": "add"}
{"commit_tokens": ["fixed", "implementation", "of", "custom", "redirections"], "add_tokens": "rclass = @redirect_hash [ method_name . to_sym ] def handle_redirection ( klass , recv , method_id , sandbox ) if @last_allowed @last_allowed . handle_redirection ( klass , recv , method_id , sandbox ) else nil end end @last_allowed = tmp @last_allowed = tmp @last_allowed = tmp @last_allowed = tmp @last_allowed = tmp return true", "del_tokens": "rclass = @redirect_hash [ method_name ] return true private def allow_method_instance ( klass , recv ) end", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unecessary", "64", "-", "bit", "binary", "not", "workaround"], "add_tokens": "@key0 = ~ Zlib . crc32 ( char , ~ @key0 ) @key2 = ~ Zlib . crc32 ( ( @key1 >> 24 ) . chr , ~ @key2 )", "del_tokens": "# # NOTE: XOR'ing with 0xffffffff is used instead of simple bit negation # in case this is run on a platform with a native integer size of # something other than 32 bits. @key0 = Zlib . crc32 ( char , @key0 ^ 0xffffffff ) ^ 0xffffffff @key2 = Zlib . crc32 ( ( @key1 >> 24 ) . chr , @key2 ^ 0xffffffff ) ^ 0xffffffff", "commit_type": "remove"}
{"commit_tokens": ["Use", "Erubis", "to", "built", "html", "for", "breadcrumbs", "rather", "than", "raw", "strings", "with", "interpolation", ".", "Remove", "PathSet", "class", "and", "move", "code", "into", "Breadcrumb", "class", "."], "add_tokens": "require 'sinatra/base' require 'easy_breadcrumbs/version' require 'easy_breadcrumbs/breadcrumb' route_matchers = Sinatra :: Application . routes [ 'GET' ] . map { | route | route [ 0 ] } breadcrumb = Breadcrumb . new ( request_path , route_matchers )", "del_tokens": "require \"sinatra/base\" require \"easy_breadcrumbs/version\" require \"easy_breadcrumbs/breadcrumb\" routes = Sinatra :: Application . routes [ \"GET\" ] . map { | route | route [ 0 ] } breadcrumb = Breadcrumb . new ( request_path , routes )", "commit_type": "use"}
{"commit_tokens": ["removed", "redundant", "tests", "added", "test", "for", "parsing", "from", "a", "file"], "add_tokens": "class LoadError < StandardError ; end raise LoadError , \"argument must be a String or File\" unless [ String , File ] . include? ( html . class )", "del_tokens": "raise LoadError unless [ String , File ] . include? ( html . class ) class LoadError < StandardError ; end", "commit_type": "remove"}
{"commit_tokens": ["Remove", "syntax", "flag", "from", "policy", "load", "write", "plan", "to", "stderr", "when", "loading"], "add_tokens": "records = load filename , 'yaml' $stderr . puts plan . actions . map ( & :to_s )", "del_tokens": "c . desc \"Syntax (ruby or YAML, will be auto-detected from file extension)\" c . flag [ :syntax ] records = load filename , options [ :syntax ]", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "feature", "annotation", "which", "is", "combined", "with", "scenario", "annotation", "when", "present"], "add_tokens": "@current_feature_started = false # Called for the feature name and after the before feature has been called def feature_name ( * args ) @current_feature_started = true end # Take care of annotation only if matched if comment . match ( ProbeDockProbe :: Annotation :: ANNOTATION_REGEXP ) # If the feature already started, the annotations are for scenarios if @current_feature_started @annotation = ProbeDockProbe :: Annotation . new ( comment ) else @feature_annotation = ProbeDockProbe :: Annotation . new ( comment ) end end # Called after the feature has been executed def after_feature ( * args ) @current_feature_started = false @feature_annotation = nil end if @annotation && @feature_annotation # Annotation on current feature and current scenario result_options [ :annotation ] = @feature_annotation . merge ( @annotation ) elsif @annotation # Annotation only for current scenario elsif @feature_annotation # Annotation for the current feature result_options [ :annotation ] = @feature_annotation @annotation = nil", "del_tokens": "@annotation = ProbeDockProbe :: Annotation . new ( comment ) # Annotation detected in the comments if @annotation @annotation = nil", "commit_type": "add"}
{"commit_tokens": ["update", "query", "and", "record", "fetching"], "add_tokens": "def query ( text , params , fetch_plan = \"*:0\" ) class_name = 'com.orientechnologies.orient.core.sql.query.OSQLSynchQuery' q = OrientdbBinary :: Protocols :: SqlCommandPayload . new text : text , serialized_params : \"params:#{params}\" , fetch_plan : fetch_plan , class_name : class_name _command ( q . to_binary_s , class_name ) end", "del_tokens": "# def query(text, params) # class_name = 'com.orientechnologies.orient.core.sql.OCommandSQL' # q = OrientdbBinary::Protocols::SqlCommandPayload.new text: text, serialized_params: \"params:#{JSON.generate(params)}\", # class_name: class_name # _command(q.to_binary_s, class_name) # end", "commit_type": "update"}
{"commit_tokens": ["fix", "version", "check", ".", "fix", "etcd", "binary", "path"], "add_tokens": "expect ( client . version ) . to match ( / ^etcd v0 \\. \\d + \\. / )", "del_tokens": "expect ( client . version ) . to match ( / ^etcd v0 \\. 2 \\. / )", "commit_type": "fix"}
{"commit_tokens": ["Use", "middleware", "to", "serve", "assets"], "add_tokens": "require 'front_end_builds/middleware/admin_assets' app . middleware . use ( FrontEndBuilds :: Middleware :: AdminAssets , \"#{root}/public\" )", "del_tokens": "app . middleware . insert_before ( :: ActionDispatch :: Static , :: ActionDispatch :: Static , \"#{root}/public\" )", "commit_type": "use"}
{"commit_tokens": ["updated", "how", "context", "gets", "passed", "and", "added", "comments"], "add_tokens": "# adds a field based on the result of the block # if the field doesn't already exist # def add ( struct , field , block ) h = struct . hash # removes a field # def remove ( struct , field , block ) struct . hash . delete ( field ) # computes an existing field passing the current value # as a parameter to the block # def compute ( struct , field , block ) h = struct . hash", "del_tokens": "def add ( struct , hash , field , block ) h = struct . send ( hash ) def remove ( struct , hash , field , block ) struct . send ( hash ) . delete ( field ) def compute ( struct , hash , field , block ) h = struct . send ( hash )", "commit_type": "update"}
{"commit_tokens": ["Removed", "use", "of", "deep_dup", "method", "when", "rendering", "a", "partial", "."], "add_tokens": "options = RuntimeContext . new ( builder , options ) . to_hash . with_indifferent_access", "del_tokens": "options = RuntimeContext . new ( builder , options ) . to_hash . with_indifferent_access . deep_dup", "commit_type": "remove"}
{"commit_tokens": ["improved", "travis", ";", "removed", "local", "testing", "conflicts"], "add_tokens": "ActiveRecord :: Schema . define ( version : 1387736448 ) do", "del_tokens": "ActiveRecord :: Schema . define ( version : 1387763867 ) do create_table \"user_queue\" , force : true do | t | t . string \"code\" t . datetime \"expires_at\" t . text \"data\" t . datetime \"created_at\" t . datetime \"updated_at\" end create_table \"user_queues\" , force : true do | t | t . string \"code\" t . datetime \"expires_at\" t . text \"data\" t . string \"context\" t . datetime \"created_at\" t . datetime \"updated_at\" end", "commit_type": "improve"}
{"commit_tokens": ["Fix", "undefined", "method", "any?", "for", "nil", ":", "NilClass", "error", "when", "not", "subscribed", "to", "any", "mailboxes", "."], "add_tokens": "all = safely { @conn . list ( '' , '*' ) } || [ ] subscribed = safely { @conn . lsub ( '' , '*' ) } || [ ]", "del_tokens": "all = safely { @conn . list ( '' , '*' ) } subscribed = safely { @conn . lsub ( '' , '*' ) }", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "test", "for", "HGNC"], "add_tokens": "assert_equal ( 'HGNC:10007' , hgnc . refseq2hgncid [ 'XM_017023849' ] ) assert_equal ( 'XM_017023849' , hgnc . hgncid2refseq [ 'HGNC:10007' ] ) assert_equal ( 'HGNC:10007' , hgnc . refseq2hgncid ( 'XM_017023849' ) ) assert_equal ( 'XM_017023849' , hgnc . hgncid2refseq ( 'HGNC:10007' ) )", "del_tokens": "assert_equal ( 'HGNC:10007' , hgnc . refseq2hgncid [ 'NM_001278720' ] ) assert_equal ( 'NM_001278720' , hgnc . hgncid2refseq [ 'HGNC:10007' ] ) assert_equal ( 'HGNC:10007' , hgnc . refseq2hgncid ( 'NM_001278720' ) ) assert_equal ( 'NM_001278720' , hgnc . hgncid2refseq ( 'HGNC:10007' ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "value", "auto", "-", "casting", "to", "the", "sax", "parser", "with", "the", "ability", "to", "skip", "casting", "for", "user", "defined", "keys", "."], "add_tokens": "attr_reader :skip_type_casting def initialize ( args = { } ) @skip_type_casting = [ ] if args . key? :skip_type_casting args [ :skip_type_casting ] = [ args [ :skip_type_casting ] ] unless args [ :skip_type_casting ] . is_a? ( Array ) @skip_type_casting . concat ( args [ :skip_type_casting ] ) end @skip_type_casting . map! { | key | format ( key ) } auto_cast = ! ( skip_type_casting . include? ( path . last ) || skip_type_casting . include? ( key . to_s ) ) if auto_cast case when value =~ / false /i then value = false when value =~ / false /i then value = true when value . match ( / ^[0-9]+$ / ) then value = value . to_i when value . match ( / ^[0-9]+[.][0-9]+$ / ) then value = value . to_f when value . match ( / [0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}.[0-9a-z]+ /i ) value = Time . parse ( value ) end end # Ensure the key is an underscored Symbol. # # Examples: # # 'ApplyBuyerProtection' -> :apply_buyer_protection # 'PayPalEmailAddress' -> :paypal_email_address # 'SoldOffeBay' -> :sold_off_ebay # # @return [Symbol] the reformatted key. # key = key . to_s key = key . gsub ( 'PayPal' , 'Paypal' ) key = key . gsub ( 'eBay' , 'Ebay' ) key . underscore . to_sym", "del_tokens": "def initialize key . underscore", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "on", "Home", "Button", "."], "add_tokens": "return \"Problem connecting to rubygems.org\" begin @http . start ( ) do | h | response = h . request ( req ) return response . message end rescue alert \"Problem connecting to rubygems.org\" return \"Problem connecting to rubygems.org\" end", "del_tokens": "@http . start ( ) do | h | response = h . request ( req ) return response . message end", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "hard", "-", "coded", "Figaro", "ENV", "variable", "prefix"], "add_tokens": "FIGARO_ENV_PREFIX = \"_FIGARO_\"", "del_tokens": "FIGARO_ENV_PREFIX = \"FIGARO_\"", "commit_type": "change"}
{"commit_tokens": ["use", "thread", "sleep", "instead", "of", "IO", "sleep", "as", "IO", "sleep", "appears", "to", "have", "issues", "on", "travis"], "add_tokens": "sleep ( self . class . sleep_time ) \"that was slow IO\"", "del_tokens": "return ` sleep #{ self . class . sleep_time } ; echo \"that was slow IO\" `", "commit_type": "use"}
{"commit_tokens": ["fixed", "initialization", "of", "bunny", "connection", "to", "happen", "after", "the", "fork", "but", "before", "starting", "the", "event", "loop"], "add_tokens": "VERSION = \"0.12.2\"", "del_tokens": "VERSION = \"0.12.1\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "pip", "support", "for", "licensed"], "add_tokens": "Source :: NPM . new ( self ) , Source :: Python . new ( self )", "del_tokens": "Source :: NPM . new ( self )", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "registration", "property", "alias", "."], "add_tokens": "# If the options does not include a +:collection_protocol_event+, then the SCG is assigned # If the options does not include a +:specimen_collection_site+, then the SCG is assigned # to the participant's collection site as determined by {CaTissue::Participant#collection_site}, # {CaTissue::SpecimenCollectionGroup} constructor: # * :registration => a new {CaTissue::CollectionProtocolRegistration} for this protocol # and the specified participant unless params . has_key? ( :registration ) || params . has_key? ( :collection_protocol_registration ) then params [ :registration ] = registration ( pnt ) || make_cpr ( pnt ) end", "del_tokens": "# If the options does not include a :collection_protocol_event, then the SCG is assigned # If the options does not include a :specimen_collection_site, then the SCG is assigned # to the participant's collection site as determined by {Participant#collection_site}, # {SpecimenCollectionGroup} constructor: # * :registration => a new CollectionProtocolRegistration for this protocol and the specified participant # If there is no :name parameter, then this method builds a new unique SCG name as this # CollectionProtocol's name followed by a unique suffix. params [ :registration ] ||= registration ( pnt ) || make_cpr ( pnt )", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "an", "error", "where", "the", "test", "cases", "might", "leave", "some", "files", "lying", "around", "."], "add_tokens": "raise ArgumentError , \"#{@fn} is not a regular file\" raise ArgumentError , \"#{@fn} is not writeable\" raise ArgumentError , \"#{::File.dirname(@fn)} is not writable\"", "del_tokens": "raise StandardError , \"#{@fn} is not a regular file\" raise StandardError , \"#{@fn} is not writeable\" raise StandardError , \"#{::File.dirname(@fn)} is not writable\"", "commit_type": "fix"}
{"commit_tokens": ["removed", "ruby", "versions", "not", "supported", "by", "active_support", "and", "added", "coveralls"], "add_tokens": "require 'coveralls' Coveralls :: SimpleCov :: Formatter", "del_tokens": "# require 'coveralls' # Coveralls::SimpleCov::Formatter", "commit_type": "remove"}
{"commit_tokens": ["Allows", "endpoints", "classes", "to", "preserve", "the", "body", "of", "the", "response", "."], "add_tokens": "process_response ( @connection . run_request ( self . class :: Method , self . class :: Path , params , headers ) ) response = DropboxApiV2 :: Response . new ( raw_response . env [ :api_result ] )", "del_tokens": "response = @connection . run_request ( self . class :: Method , self . class :: Path , params , headers ) process_response response response = DropboxApiV2 :: Response . new ( raw_response . body )", "commit_type": "allow"}
{"commit_tokens": ["Moved", "rails", "testing", "setup", "into", "test", "/", "rails", ".", "Thanks", "to", "@cainlevy", "for", "the", "tip"], "add_tokens": "ENV [ \"RAILS_ROOT\" ] = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , 'rails' ) ) require File . expand_path ( File . join ( ENV [ \"RAILS_ROOT\" ] , 'config' , 'environment' ) ) require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '..' , 'init' ) ) File . join ( File . join ( ENV [ \"RAILS_ROOT\" ] , 'public' ) )", "del_tokens": "require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '..' , 'config' , 'environment' ) ) File . join ( File . dirname ( __FILE__ ) , '..' , 'public' )", "commit_type": "move"}
{"commit_tokens": ["Changed", "the", "way", "to", "compare", "signatures", "again"], "add_tokens": "calculatedSignature . bytes == expectedSignature . bytes", "del_tokens": "secure_compare ( calculatedSignature , expectedSignature ) def secure_compare ( a , b ) return false if a . empty? || b . empty? || a . bytesize != b . bytesize l = a . unpack \"C#{a.bytesize}\" res = 0 b . each_byte { | byte | res |= byte ^ l . shift } res == 0 end", "commit_type": "change"}
{"commit_tokens": ["Made", "it", "UTC", "edited", "the", "notes", "on", "top", "."], "add_tokens": "# it should produce colorized output (either parsed or part of the file format) \"[#{datetime.getutc.asctime}] [#{severity}]: #{msg}\\n\"", "del_tokens": "# it should produce colorized output (either parsed or part of the file format) # it should wrap logger. # it will log in UTC by default \"[#{datetime.asctime}] [#{severity}]: #{msg}\\n\"", "commit_type": "make"}
{"commit_tokens": ["adding", "em", "-", "winrs", "as", "a", "dependency", "in", "the", "gemfile"], "add_tokens": ":source_image => 'SUSE__SUSE-Linux-Enterprise-Server-11SP2-20120521-en-us-30GB.vhd' , @server_instance . should_receive ( :is_image_windows? ) . at_least ( :twice ) . and_return ( true ) @server_instance . should_receive ( :is_image_windows? ) . at_least ( :twice ) . and_return ( true ) @server_instance . should_receive ( :is_image_windows? ) . at_least ( :twice ) . and_return ( true ) @server_instance . should_receive ( :is_image_windows? ) . exactly ( 3 ) . times . and_return ( true ) @server_instance . run @server_instance . should_receive ( :is_image_windows? ) . exactly ( 3 ) . times . and_return ( true )", "del_tokens": ":source_image => 'source_image' , #@server_instance.should_receive(:is_image_windows?).at_least(:twice).and_return(true) @server_instance . stub ( :is_image_windows? ) . and_return ( true ) #@server_instance.should_receive(:is_image_windows?).at_least(:twice).and_return(true) @server_instance . stub ( :is_image_windows? ) . and_return ( true ) #@server_instance.should_receive(:is_image_windows?).at_least(:twice).and_return(true) @server_instance . stub ( :is_image_windows? ) . and_return ( true ) #@server_instance.should_receive(:is_image_windows?).exactly(3).times.and_return(true) @server_instance . stub ( :is_image_windows? ) . and_return ( true ) @server_instance . run #@server_instance.should_receive(:is_image_windows?).exactly(3).times.and_return(true) @server_instance . stub ( :is_image_windows? ) . and_return ( true )", "commit_type": "add"}
{"commit_tokens": ["Use", "more", "subject", "/", "let", "."], "add_tokens": "subject . const_defined? ( 'VERSION' ) . should be_true", "del_tokens": "Nmap . const_defined? ( 'VERSION' ) . should == true", "commit_type": "use"}
{"commit_tokens": ["Remove", "useless", "rakefile", "and", "try", "to", "fix", "test"], "add_tokens": "before do Shop :: Command :: init ( 'theme_name' ) Shop :: Command :: makefile end", "del_tokens": "before { Shop :: Command :: init ( 'theme_name' ) } Shop :: Command :: makefile", "commit_type": "remove"}
{"commit_tokens": ["Using", "the", "RedGreen", "test", "-", "colorization", "gem", "if", "it", "is", "available"], "add_tokens": "begin # Try to load the 'redgreen' gem and use it for test output require 'redgreen' TestRunner = Test :: Unit :: UI :: Console :: RedGreenTestRunner rescue # Stick with the regular TestRunner TestRunner = Test :: Unit :: UI :: Console :: TestRunner end TestRunner . run ( cls )", "del_tokens": "Test :: Unit :: UI :: Console :: TestRunner . run ( cls )", "commit_type": "use"}
{"commit_tokens": ["Added", "contributed", "dot", "graph", "from", "Erik", "Andrejko"], "add_tokens": "dot # TODO bullet", "del_tokens": "# TODO bullet", "commit_type": "add"}
{"commit_tokens": ["use", "plain", "avoiding", "MissingTemplate", "error"], "add_tokens": "render plain : 'test' render plain : 'test'", "del_tokens": "render text : 'test' render text : 'test'", "commit_type": "use"}
{"commit_tokens": ["Added", "logic", "to", "VCR", "::", "Config", ".", "http_stubbing_adapter", "so", "that", "it", "returns", "the", "appropriate", "value", "if", "just", "one", "of", "fakeweb", "/", "webmock", "are", "loaded", "."], "add_tokens": "attr_writer :http_stubbing_adapter def http_stubbing_adapter @http_stubbing_adapter || begin defined_constants = [ :FakeWeb , :WebMock ] . select { | c | Object . const_defined? ( c ) } defined_constants [ 0 ] . to_s . downcase . to_sym if defined_constants . size == 1 end end", "del_tokens": "attr_accessor :http_stubbing_adapter", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "button", "helper", "bs_collapsible_button", "."], "add_tokens": "let ( :html_attributes ) do attributes . map { | k , v | \"#{k}=\\\"#{v}\\\"\" } . join ( \" \" ) end let ( :html ) { \"<a #{html_attributes}>foo</a>\" } describe \"bs_collapsible_button\" do let ( :attributes ) do { href : '#' , class : \"btn\" , :\" data-target \" => \"bar\" , :\" data-toggle \" => \"collapse\" } end it \"should render a button with a collapsible\" do helper . bs_collapsible_button ( \"foo\" , \"bar\" ) . should == html end context \"with style\" do it \"should render a collapsible button with the proper style\" do attributes [ :class ] = \"btn btn-primary\" helper . bs_collapsible_button ( \"foo\" , \"bar\" , style : \"primary\" ) . should == html end end end", "del_tokens": "let ( :html_attributes ) do attributes . map { | k , v | \"#{k}=\\\"#{v}\\\"\" } . join ( \" \" ) end html = \"<a #{html_attributes}>foo</a>\" html = \"<a #{html_attributes}>foo</a>\" html = \"<a #{html_attributes}>foo</a>\"", "commit_type": "add"}
{"commit_tokens": ["fix", "integration", "outside", "of", "Rails"], "add_tokens": "test_case . class . superclass . to_s =~ / ^Sauce:: / suite . superclass . to_s =~ / ^Sauce:: /", "del_tokens": "[ Sauce :: TestCase , Sauce :: RailsTestCase ] . include? test_case . class . superclass [ Sauce :: TestCase , Sauce :: RailsTestCase ] . include? suite . superclass", "commit_type": "fix"}
{"commit_tokens": ["Added", "fetching", "of", "all", "current", "invoices", "."], "add_tokens": "describe \".all\" do it \"returns an empty array when there are no current invoices\" do savon . expects ( 'CurrentInvoice_GetAll' ) . returns ( :empty_result ) subject . all . size . should == 0 end it \"returns a single current invoice\" do savon . expects ( 'CurrentInvoice_GetAll' ) . returns ( :single_result ) savon . expects ( 'CurrentInvoice_GetData' ) . with ( 'entityHandle' => { 'Id' => 1 } ) . returns ( :success ) all = subject . all all . size . should == 1 all . first . should be_instance_of ( Economic :: CurrentInvoice ) end it \"returns multiple current invoices\" do savon . expects ( 'CurrentInvoice_GetAll' ) . returns ( :multiple_results ) savon . expects ( 'CurrentInvoice_GetData' ) . returns ( :success ) savon . expects ( 'CurrentInvoice_GetData' ) . returns ( :success ) all = subject . all all . size . should == 2 all . items . first . should be_instance_of ( Economic :: CurrentInvoice ) all . items . last . should be_instance_of ( Economic :: CurrentInvoice ) end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Allow", "interpolation", "options", "to", "be", "set", "in", "the", "application", "controller", "."], "add_tokens": "# def interpolation_options # { } # end def set_flash_message! ( status , default_message = nil ) resource_name = if resource_class if resource_class . respond_to? ( :human_name ) resource_class . human_name else resource_class . name . humanize end else \"Resource\" end given_options = if self . respond_to? ( :interpolation_options ) interpolation_options else { } end :resource_name => resource_name } . merge ( given_options )", "del_tokens": "# You cannot overwrite :resource_name and :default options using this # method. Check <tt>set_flash_message!</tt> for more information. # def interpolation_options { } end def set_flash_message! ( status , default_message = '' ) :resource_name => resource_class ? resource_class . human_name : 'Resource' , } . merge ( interpolation_options )", "commit_type": "allow"}
{"commit_tokens": ["Added", "should_not_allow_vlaues_for", ".", "Really", "refactored", "the", "tests", "to", "remove", "duplication", "."], "add_tokens": "values . each do | value | # An ActiveRecord assertion that expects to fail with a given value or set of values for a given # attribute. # # Example # should_not_allow_values_for :email, \"a@b.cd\" # should_not_allow_values_for :email, \"a@b.cd\", \"e@f.gh\" def should_not_allow_values_for ( attribute , * values ) values . each do | value | should ( \"allow value of \\\"#{value}\\\" for #{attribute}\" ) do topic . write_attribute ( attribute , value ) topic . valid? topic . errors . on ( attribute ) end end end", "del_tokens": "Array ( values ) . each do | value |", "commit_type": "add"}
{"commit_tokens": ["Add", "aliases", "for", "story_branch", "executable"], "add_tokens": "# Version: 0.1.7", "del_tokens": "# Version: 0.1.5a", "commit_type": "add"}
{"commit_tokens": ["fix", "cache", "test", "for", "latest", "rest", "-", "core", ";", "remove", "fake", "post", "in", "facebook"], "add_tokens": "get ( \"method/#{path}\" , { :format => 'json' } . merge ( query ) , { :site => old_site } . merge ( opts ) , & cb )", "del_tokens": "uri = url ( \"method/#{path}\" , { :format => 'json' } . merge ( query ) , { :site => old_site } . merge ( opts ) ) if opts [ :post ] post ( url ( \"method/#{path}\" , { :format => 'json' } , { :site => old_site } . merge ( opts ) ) , query , { } , opts . merge ( 'cache.key' => uri , 'cache.post' => true ) , & cb ) else get ( uri , { } , opts , & cb ) end", "commit_type": "fix"}
{"commit_tokens": ["add", "HTTP", "method", "and", "path", "info", "to", "exception", "messages"], "add_tokens": "Net :: HTTP . start ( @hostname , 443 , use_ssl : true , read_timeout : 70 ) do | http | response = http . request ( request , & block ) raise_on_error ( request , response ) def raise_on_error ( request , response ) msg = \"Rackspace returned HTTP status #{response.code}\" msg += \"(rackspace tx id: #{response[\"X-TRANS-ID\"]}, #{request.method} #{request.path})\" raise error_klass , msg", "del_tokens": "cloud_http do | http | http . request ( request , & block ) end end def cloud_http ( & block ) Net :: HTTP . start ( @hostname , 443 , use_ssl : true , read_timeout : 70 ) do | http | response = block . call ( http ) raise_on_error ( response ) def raise_on_error ( response ) raise error_klass , \"Rackspace returned HTTP status #{response.code} (rackspace transaction id: #{response[\"X-TRANS-ID\"]})\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "save", "the", "children", "of", "a", "commit"], "add_tokens": "# @return [Array<Object>] The unique identifiers of the children of this # commit attr_reader :children @children = [ ] @repo = repo end # Adds the unique identifier of a child of this commit to the list of child # commits # # @param [Object] child The unique identifier of the child commit to add def add_child ( child ) @children << child", "del_tokens": "@repo = repo", "commit_type": "allow"}
{"commit_tokens": ["added", "shell", "script", "to", "generate", "phase"], "add_tokens": "VERSION = \"1.9.0\"", "del_tokens": "VERSION = \"1.8.3\"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "initializing", "Mixlib", "::", "Log", "with", "a", "logger"], "add_tokens": "@logger , @loggers = nil # Sets the log device to +new_log_device+. Any additional loggers # that had been added to the +loggers+ array will be cleared. def logger = ( new_log_device ) reset! @logger = new_log_device reset! @logger = logger_for ( * opts ) @logger . formatter = Mixlib :: Log :: Formatter . new ( ) if @logger . respond_to? ( :formatter= ) alias :log :add private def logger_for ( * opts ) if opts . empty? Logger . new ( STDOUT ) elsif LEVELS . keys . inject ( true ) { | quacks , level | quacks && opts . first . respond_to? ( level ) } opts . first else Logger . new ( * opts ) end end", "del_tokens": "@logger = nil def logger = ( value ) @logger = value @loggers = nil @logger = ( opts . empty? ? Logger . new ( STDOUT ) : Logger . new ( * opts ) ) @logger . formatter = Mixlib :: Log :: Formatter . new ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "path", "prefix", "to", "url_handler"], "add_tokens": "configurable_attr :path_prefix , '' \"#{path_prefix}/#{parameters.uid}.#{extension}?#{query_string}#{sha_string}\" path . sub ( path_prefix , '' ) . sub ( / ^ \\/ / , '' ) . split ( '.' ) . first object . nil? || ( object . respond_to? ( :empty? ) ? object . empty? : false )", "del_tokens": "\"/#{parameters.uid}.#{extension}?#{query_string}#{sha_string}\" path . sub ( / ^ \\/ / , '' ) . split ( '.' ) . first object . nil? || object . empty?", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bunch", "of", "scss", "-", "lint", "issues"], "add_tokens": "\"<div class='error-explanation' id='error-explanation'>There were problems with the following fields:<ul>#{errors.join('')}<ul></div>\"", "del_tokens": "\"<div class='errorExplanation' id='errorExplanation'>There were problems with the following fields:<ul>#{errors.join('')}<ul></div>\"", "commit_type": "fix"}
{"commit_tokens": ["Remove", "rubocop", "error", "supression", "."], "add_tokens": "body = \"[[UIStoryboard storyboardWithName:@\\\"#{@storyboard}\\\" bundle:[NSBundle mainBundle]]\" \"instantiateViewControllerWithIdentifier:@\\\"#{@name}\\\"]\"", "del_tokens": "# rubocop:disable Metrics/LineLength body = \"[[UIStoryboard storyboardWithName:@\\\"#{@storyboard}\\\" bundle:[NSBundle mainBundle]] instantiateViewControllerWithIdentifier:@\\\"#{@name}\\\"]\" # rubocop:enable Metrics/LineLength", "commit_type": "remove"}
{"commit_tokens": ["Use", "TableDefinition#table_name", "for", ":", "name", "option", "if", "available", "."], "add_tokens": "def self . from_file ( path , options = nil ) options ||= { } options [ :name ] ||= @definition . table_name super ( path , options ) end definition = self . class . definition columns = definition . columns options = options . merge ( accessors : columns . map ( & :accessor ) , name : definition . table_name ) { | key , v1 , v2 | if key == :accessors raise \"Can't handle reordering of accessors - don't redefine accessors in CustomTables for now\" elsif key == :name v1 || v2 end }", "del_tokens": "columns = self . class . definition . columns options = options . merge ( accessors : columns . map ( & :accessor ) )", "commit_type": "use"}
{"commit_tokens": ["Fixing", "typo", "in", "security", "check", "and", "adding", "it", "in", "the", "KB"], "add_tokens": ":mitigation => \"Please upgrade fastreader gem to a newer version\" ,", "del_tokens": ":mitigation => \"Please upgrade fastreader gem to a newer version\"", "commit_type": "fix"}
{"commit_tokens": ["moved", "xml", "schema", "defs", "into", "own", "methods"], "add_tokens": "# @return [String] xml builder . Document xml_schema do # @return {Hash<Symbol=>String>} xml schema information used in output xml def xml_schema { :xmlns => 'urn:iso:std:iso:20022:tech:xsd:pain.001.002.03' , :' xmlns:xsi ' => 'http://www.w3.org/2001/XMLSchema-instance' , :' xsi:schemaLocation ' => 'urn:iso:std:iso:20022:tech:xsd:pain.001.002.03 pain.001.002.03.xsd' } end", "del_tokens": "builder . Document :xmlns => 'urn:iso:std:iso:20022:tech:xsd:pain.001.002.03' , :' xmlns:xsi ' => 'http://www.w3.org/2001/XMLSchema-instance' , :' xsi:schemaLocation ' => 'urn:iso:std:iso:20022:tech:xsd:pain.001.002.03 pain.001.002.03.xsd' do", "commit_type": "move"}
{"commit_tokens": ["Use", "guard", "in", "recursion", "functions"], "add_tokens": "require 'transproc/conditional' guarded = Transproc ( :guard , -> v { v . is_a? ( :: Array ) } , -> v { Transproc ( :array_recursion , fn ) [ v ] } ) guarded [ item ] guarded = Transproc ( :guard , -> v { v . is_a? ( :: Hash ) } , -> v { Transproc ( :hash_recursion , fn ) [ v ] } ) result [ key ] = guarded [ result . delete ( key ) ]", "del_tokens": "if item . is_a? ( :: Array ) Transproc ( :array_recursion , fn ) [ item ] else item end item = result . delete ( key ) if item . is_a? ( :: Hash ) result [ key ] = Transproc ( :hash_recursion , fn ) [ item ] else result [ key ] = item end", "commit_type": "use"}
{"commit_tokens": ["Added", "configuration", ".", "Added", "documentation", "to", "some", "controller", "methods", "."], "add_tokens": "# # @return [Boolean] the result of the permission evaluation # will halt controller flow # # @param [Symbol] action the current controller action # @param [Hash] config the configuration for what to do with the given action # @return [Boolean] the result of the permission evaluation flash_type : Authorizable . configuration . flash_error # # @param [Hash] options the data for the permission # @return [Boolean] the result of the permission # @param [Symbol] flash_type the kind of flash message to be displayed # @param [String] message the message to display in the flash message # @param [Proc|String] path the redirect path if the request is html def authorizable_respond_with ( flash_type , message , path = \"\" )", "del_tokens": "flash_type : :alert def authorizable_respond_with ( flash_type , message , path )", "commit_type": "add"}
{"commit_tokens": ["add", "test", "defined_class", "value", "as", "symbol", "and", "fix", "it"], "add_tokens": "@conditions . positive [ m ] = v . to_s @conditions . negative [ m ] = v . to_s", "del_tokens": "@conditions . positive [ m ] = v @conditions . negative [ m ] = v", "commit_type": "add"}
{"commit_tokens": ["Use", "accessor", "method", "when", "accessing", "the", "values", "hash"], "add_tokens": "values [ k ] values [ k ] = v", "del_tokens": "@values [ k ] @values [ k ] = v", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "new", "line", "to", "the", "code", "during", "registration", "to", "deal", "with", "a", "comment", "as", "the", "last", "line", "of", "the", "code"], "add_tokens": "contents = %{(function() {#{code}\\n})();\\n//@ sourceURL=#{module_id}} . to_json contents = \"function() {#{code}\\n}\"", "del_tokens": "contents = %{(function() {#{code}})();\\n//@ sourceURL=#{module_id}} . to_json contents = \"function() {#{code}}\"", "commit_type": "add"}
{"commit_tokens": ["Using", "a", "directory", "manifest", "-", "this", "allows", "us", "to", "split", "up", "site", ".", "pp", "into", "seperate", "files", "."], "add_tokens": "puppet_cmd += \" #{$config['agent']['puppetcode']}/#{environment}/manifests/\"", "del_tokens": "puppet_cmd += \" #{$config['agent']['puppetcode']}/#{environment}/manifests/site.pp\"", "commit_type": "use"}
{"commit_tokens": ["Added", "fix", "to", "schedule!", "function", "to", "ensure", "singularity", "of", "enqueued", "recurring", "jobs"], "add_tokens": "Delayed :: Job . transaction do self . class . jobs . destroy_all if Gem . loaded_specs [ 'delayed_job' ] . version . to_s . first . to_i < 3 Delayed :: Job . enqueue self , enqueue_opts [ :priority ] , enqueue_opts [ :run_at ] else Delayed :: Job . enqueue self , enqueue_opts end", "del_tokens": "if Gem . loaded_specs [ 'delayed_job' ] . version . to_s . first . to_i < 3 Delayed :: Job . enqueue self , enqueue_opts [ :priority ] , enqueue_opts [ :run_at ] else Delayed :: Job . enqueue self , enqueue_opts", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "newline", "(", "line", "feed", ")", "after", "e"], "add_tokens": "s + \"e\\n\"", "del_tokens": "s + \"e\"", "commit_type": "add"}
{"commit_tokens": ["added", "ugly", "phrk", "example", "and", "updated", "some", "of", "the", "other", "examples"], "add_tokens": "class ItemSearchResponse ox_tag :camelcase ox_elem :total_results , :as => Integer , :in => 'Items' ox_elem :total_pages , :as => Integer , :in => 'Items' response = ItemSearchResponse . from_xml ( xml_for ( :amazon ) )", "del_tokens": "class Response ox_tag 'ItemSearchResponse' ox_elem :total_results , :from => 'TotalResults' , :as => Integer , :in => 'Items' ox_elem :total_pages , :from => 'TotalPages' , :as => Integer , :in => 'Items' response = Response . from_xml ( xml_for ( :amazon ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "N", "+", "1", "issue", "with", "show", "multiple", "action"], "add_tokens": "resources = resource_klass . get_resources ( keys , context )", "del_tokens": "if keys . length > 1 resources = [ ] keys . each do | key | resources . push ( resource_klass . find_by_key ( key , context : context ) ) end else resources = resource_klass . find_by_key ( keys [ 0 ] , context : context ) end", "commit_type": "fix"}
{"commit_tokens": ["improve", "Model#to_hash", "s", "capacity", "to", "ignore", "empty", "values"], "add_tokens": "val = format_value ( send ( name . underscore ) ) val . empty? ? hash : hash . merge ( format_key ( name ) => val ) protected when AmazonFlexPay :: Model val . to_hash", "del_tokens": "protected val = send ( name . underscore ) if val . nil? or val == '' or val == [ ] hash else hash . merge ( format_key ( name ) => val . is_a? ( AmazonFlexPay :: Model ) ? val . to_hash : format_value ( val ) ) end", "commit_type": "improve"}
{"commit_tokens": ["Adds", "test", "to", "Transaction", ".", "find_by_reference", "method"], "add_tokens": "it \"initializes search with default options\" do it \"initializes search with given options\" do describe \".find_by_reference\" do it 'initializes search with given reference code' do now = Time . now Time . stub now : now PagSeguro :: SearchByReference . should_receive ( :new ) . with ( \"transactions\" , hash_including ( reference : 'ref1234' ) , ) PagSeguro :: Transaction . find_by_reference ( 'ref1234' ) end end it \"initializes search with default options\" do it \"initializes search with given options\" do", "del_tokens": "it \"initializes report with default options\" do it \"initializes report with given options\" do it \"initializes report with default options\" do it \"initializes report with given options\" do", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "HTTP", "PUT", "."], "add_tokens": "attr_accessor :url , :upload_data", "del_tokens": "attr_accessor :url", "commit_type": "add"}
{"commit_tokens": ["Add", "FloatLiteral#exponent", "and", "try", "to", "roundtrip", "them", "correctly", "."], "add_tokens": "case format when :dec if exponent \"#{val / 10**exponent}e#{exponent}#{suffix}\" else \"#{val}#{suffix}\" end when :hex \"0x#{float_hex(val / 2**exponent)}p#{exponent || 0}#{suffix}\" else raise \"invalid C::FloatLiteral format: #{format}\" end end private HEX_DIGITS = %w[ 0 1 2 3 4 5 6 7 8 9 a b c d e f ] def float_hex ( value ) int , frac = value . divmod ( 1 ) string = \"#{int.to_s(16)}.\" # 64-bit floats have 53 bits of significand ~ 14 hex digits. 14 . times do break if frac < 1e-17 int , frac = ( frac * 16 ) . divmod ( 1 ) string << HEX_DIGITS [ int ] end string", "del_tokens": "\"#{val}#{suffix}\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "generic", "configs", "defined", "in", "worker_config"], "add_tokens": "# TODO: Is this necessary anymore or just put in worker.rb? Decide when flat file queue_adapter is implemented. # Default values for all the config attributes @default_config ||= WorkerConfig . initial_default_config", "del_tokens": "include Rumx :: Bean # WorkerConfig sets the index but we don't want to make it a writable attribute bean_attr_reader :index , :integer , \"Index of this worker instance\" # max_count is the only config attribute defined in worker_config so we hack it's default value of zero here @default_config ||= { :max_count => 0 }", "commit_type": "fix"}
{"commit_tokens": ["add", "save_current_page", "in", "driver", ".", "rb"], "add_tokens": "def save_current_page ( to_dir = \"C:\\\\temp\" ) Dir . mkdir ( to_dir ) unless File . exists? ( to_dir ) file_name = Time . now . strftime ( \"%m%d%H%M%S\" ) + \".html\" file = File . join ( to_dir , file_name ) File . new ( file , \"w\" ) . puts page_source end sleep 0.5", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "opts", "bug", "for", "Table", "and", "introduced", "test", "/", "bm1_compression", ".", "rb"], "add_tokens": "} . inject ( 0 ) { | i , ( k , v ) | i = i | v if o . index ( k ) ; i }", "del_tokens": "} . inject ( 0 ) { | i , ( k , v ) | i = i & v if o . index ( k ) ; i }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "xmlId", "and", "method", "refrence"], "add_tokens": "options [ :id ] = resource . id if request . local_method != 'POST'", "del_tokens": "options [ :id ] = resource . id if request . method! = 'POST'", "commit_type": "fix"}
{"commit_tokens": ["Updating", "default", "remember_for", "using", "only", ".", "days", "while", "testing", "confirmation", "period", "and", "some", "more", "docs", "."], "add_tokens": "# after a certain period (ie 7 days). By default confirm_in is # zero, it means users always have to confirm to sign in. Devise . model_config ( self , :confirm_in , 0 . days ) # # confirm_in = 1.day and confirmation_sent_at = today # # confirm_in = 5.days and confirmation_sent_at = 4.days.ago # # confirm_in = 5.days and confirmation_sent_at = 5.days.ago # # confirm_in = 0.days ( Date . today - confirmation_sent_at . to_date ) . days < confirm_in", "del_tokens": "# after a certain period (ie 7 days). Devise . model_config ( self , :confirm_in , 0 ) # # confirm_in = 1 and confirmation_sent_at = today # # confirm_in = 5 and confirmation_sent_at = 4.days.ago # # confirm_in = 5 and confirmation_sent_at = 5.days.ago # # confirm_in = 0 ( Date . today - confirmation_sent_at . to_date ) . days . to_i < confirm_in . to_i", "commit_type": "update"}
{"commit_tokens": ["Added", "globals", "parameter", "to", "report", "method", "."], "add_tokens": "def self . report ( source , options = nil , globals = nil , out = nil ) linter = Lint . new ( options , globals ) end", "del_tokens": "def self . report ( source , options = nil , out = nil ) linter = Lint . new ( options ) end", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "new", "poise_shell_out", "helper", "to", "resolve", "issues", "in", "python_package", "with", "$HOME", "."], "add_tokens": "include Poise :: Utils :: ShellOut def language_command_shell_out ( name , * command_args , ** options ) options [ :environment ] ||= { } options [ :environment ] . update ( parent . send ( :\" #{ name } _environment \" ) ) poise_shell_out ( command , options )", "del_tokens": "require 'chef/mixin/shell_out' include Chef :: Mixin :: ShellOut def language_command_shell_out ( name , * command_args ) options = if command_args . last . is_a? ( Hash ) command_args . pop . dup else { } end options [ :environment ] = parent . send ( :\" #{ name } _environment \" ) . merge ( options [ :environment ] || { } ) shell_out ( command , options )", "commit_type": "use"}
{"commit_tokens": ["Fix", "to", "get", "current_tenant", "working2"], "add_tokens": "ActiveSupport . on_load ( :action_controller ) do helper_method :current_tenant end", "del_tokens": "#ActiveSupport.on_load(:action_controller) do # helper_method :current_tenant #end", "commit_type": "fix"}
{"commit_tokens": ["Changed", ":", "experiment", ".", "chooses", "uses", "Redis", "to", "store", "state", "better", "for", "(", "when", "we", "get", "to", ")", "browser", "integration"], "add_tokens": "elsif response # everyday use else # during functional testing @vanity_identity = \"test\"", "del_tokens": "else", "commit_type": "change"}
{"commit_tokens": ["make", "XPUB", "and", "XSUB", "inherit", "from", "PUB", "and", "SUB"], "add_tokens": "class XPUB < PUB class XSUB < SUB", "del_tokens": "class XPUB < Socket class XSUB < Socket", "commit_type": "make"}
{"commit_tokens": ["Added", "/", "to", "end", "of", "requests", "to", "prevent", "304", "moved", "responses"], "add_tokens": "API_URL + '/' + resource . to_s + '/' + \"#{self.find_detail(resource)['id']}-#{id.to_s}/\" API_URL + '/' + resource . to_s + '/'", "del_tokens": "API_URL + '/' + resource . to_s + '/' + \"#{self.find_detail(resource)['id']}-#{id.to_s}\" API_URL + '/' + resource . to_s", "commit_type": "add"}
{"commit_tokens": ["removed", "safe", "guard", "for", "unknown", "value", "evaluations"], "add_tokens": "raise \"unknown value rule evaluation. this shouldn't happen\"", "del_tokens": "return Evaluation . new ( true , nil )", "commit_type": "remove"}
{"commit_tokens": ["Change", "attr_accessor", "into", "attr_reader", "&&", "explain"], "add_tokens": "# The name of the autoincrementing model. attr_reader ( :model_name ) # The name of the field of the autoincrementing model. attr_reader ( :field_name ) # The constraint, allowing for more then one series on the same # +model_name+ +field_name+ combination. attr_reader ( :scope_key ) # The mongo connection to the autoincrement counters collection. attr_reader ( :collection ) # The autoincrement offset. attr_reader ( :seed ) # How the next autoincrement number should be calculated. attr_reader ( :step ) @model_name = model_name . to_s @field_name = field_name . to_s @scope_key = options . fetch ( :scope , nil ) @step = options . fetch ( :step , 1 ) @seed = options . fetch ( :seed , nil ) @collection = :: Mongoid . default_session [ 'auto_increment_counters' ] create if @seed && ! exists?", "del_tokens": "attr_accessor ( :model_name , :field_name , :scope_key , :collection , :seed , :step , ) self . model_name = model_name . to_s self . field_name = field_name . to_s self . scope_key = options . fetch ( :scope , nil ) self . step = options . fetch ( :step , 1 ) self . seed = options . fetch ( :seed , nil ) self . collection = :: Mongoid . default_session [ 'auto_increment_counters' ] create if seed && ! exists?", "commit_type": "change"}
{"commit_tokens": ["Added", "user", "&", "group", "attributes", ";", "cleaned", "up", "API"], "add_tokens": "attr_accessor :digest , :repo , :bundle , :command , :args , :stdin , :env , :user , :group # Check if the bundle described by this CommandSpec exists # # @return [Boolean] # Absolute command filename # # @return [String] # Check if the command file exists # # @return [Boolean] # Command manifest filename # # @return [String] def manifest_file alias_method :config_file , :manifest_file # Retrieve the command's Manifest, loading it from disk if necessary # If no Manifest is available, returns an empty hash # # @return [Hash] def manifest if File . exists? ( manifest_file ) && File . readable? ( manifest_file ) then MultiJson . load ( File . read ( manifest_file ) ) alias_method :load_config , :manifest # Bundle digest filename # # @return [String] path to bundle digest file # Retrieve the bundle digest # # @return [Hash] # Retrieve the bundle manifest # # @return [Hash] def load_bundle_manifest alias_method :load_manifest , :load_bundle_manifest # Update the digest hashes for this bundle s << \" user: #{self.user}\" s << \" group: #{self.group}\"", "del_tokens": "attr_accessor :repo , :digest , :bundle , :command , :args , :stdin , :env def config_file def load_config if File . exists? config_file then MultiJson . load ( File . read ( config_file ) ) def load_manifest", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "method", "alias", "for", "groups"], "add_tokens": "alias_method :groups , :member_of self . new ( entry [ ldap_dn_attribute . to_sym ] . last )", "del_tokens": "self . new ( entry [ ldap_dn_attribute . to_sym ] . last , search_base )", "commit_type": "add"}
{"commit_tokens": ["Add", "WSDL", "handling", "using", "Wasabi", "as", "a", "backend", "for", "now"], "add_tokens": "TEST_ROOT = File . expand_path ( '..' , __FILE__ )", "del_tokens": "require 'lolsoap'", "commit_type": "add"}
{"commit_tokens": ["Change", "repeat", "specs", "when", "repeat", "starts", "in", "integral", "part"], "add_tokens": "assert_equal \"1234567.<897>E0\" , assert_equal \"12345678.<978>E0\" , assert_equal \"1234567897.<897>E0\" , assert_equal \"12345678978.<978>E0\" , assert_equal \"1234567897897.<897>E0\" , assert_equal \"12345678978978.<978>E0\" , assert_equal \"1234567897897897897897897.<897>E0\" , assert_equal \"12345678978978978978978978978978978978978978978978.<978>E0\" ,", "del_tokens": "assert_equal \"1234567.89<789>E0\" , assert_equal \"12345678.9<789>E0\" , assert_equal \"1234567897.89<789>E0\" , assert_equal \"12345678978.9<789>E0\" , assert_equal \"1234567897897.89<789>E0\" , assert_equal \"12345678978978.9<789>E0\" , assert_equal \"1234567897897897897897897.89<789>E0\" , assert_equal \"12345678978978978978978978978978978978978978978978.9<789>E0\" ,", "commit_type": "change"}
{"commit_tokens": ["allow", "aws", "credentials", "to", "be", "set", "in", "config"], "add_tokens": "# Default is app's asset_prefix used by Sprockets and can't be changed. @prefix ||= val @local_compiled_assets_dir ||= manifest . dir # AWS bucket name, can be stored in ENV but can be overwritten in config block # defaults to looking in ENV['AWS_BUCKET_NAME'] # AWS access id key given by Amazon, should be stored in env but can be set to be elsewhere # defaults to looking at ENV[\"AWS_ACCESS_ID_KEY\"] raise FogSettingError , \"access key id must be set in ENV or configure block\" attr_writer :aws_access_key_id # AWS secret access key given by Amazon, should be stored in env but can be set to be elsewhere # defaults to looking at ENV[\"AWS_SECRET_ACCESS_KEY\"] def aws_secret_access_key raise FogSettingError , \"secret access key must be set in ENV or configure block\" attr_writer :aws_secret_access_key", "del_tokens": "# Default is app's asset_prefix used by Sprockets. val . prepend ( \"/\" ) unless val . start_with? ( \"/\" ) @prefix = val . chomp ( \"/\" ) manifest . dir # AWS bucket name, should be stored in ENV but can be overwritten in config block # TODO should allow this setting to be taken from elsewhere in case juggling multiple AWS accounts raise FogSettingError , \"AWS_ACCESS_KEY_ID must be set in ENV\" # TODO should allow this setting to be taken from elsewhere in case juggling multiple AWS accounts def aws_access_key_id = ( val ) raise FogSettingError , \"AWS_ACCESS_KEY_ID is sensitive data that should not be defined where it can be checked into source control. Please set it in ENV.\" end # TODO should allow this setting to be taken from elsewhere in case juggling multiple AWS accounts def aws_secret_access_key raise FogSettingError , \"AWS_SECRET_ACCESS_KEY must be set in ENV\" # TODO should allow this setting to be taken from elsewhere in case juggling multiple AWS accounts def aws_secret_access_key = ( val ) raise FogSettingError , \"AWS_SECRET_ACCESS_KEY is sensitive data that should not be defined where it can be checked into source control. Please set it in ENV.\" end", "commit_type": "allow"}
{"commit_tokens": ["Use", "hash", "lookup", "instead", "of", "case", "statements"], "add_tokens": "WIRES = { :int32 => 0 , :uint32 => 0 , :sint32 => 0 , :int64 => 0 , :uint64 => 0 , :sint64 => 0 , :bool => 0 , :fixed64 => 1 , :sfixed64 => 1 , :double => 1 , :string => 2 , :bytes => 2 , :fixed32 => 5 , :sfixed32 => 5 , :float => 5 , } wire = WIRES [ type ] if wire wire elsif Class === type && encodable? ( type ) elsif Module === type 0", "del_tokens": "case type when Class if encodable? ( type ) 2 else raise UnknownType , type end when :int32 , :uint32 , :sint32 , :int64 , :uint64 , :sint64 , :bool , Module 0 when :fixed64 , :sfixed64 , :double 1 when :string , :bytes when :fixed32 , :sfixed32 , :float 5", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "in", "buffer_input", "for", "stderr", "."], "add_tokens": "append_stderr strip_ansi_escape ( data ) , & block", "del_tokens": "append_stderr strip_ansi_escap ( data ) , & block", "commit_type": "fix"}
{"commit_tokens": ["Use", "native", "downcase", "and", "upcase"], "add_tokens": "string . downcase . unpack ( \"U*\" ) . map { | char | Mappings :: DOWNCASE [ char ] or char } . flatten . pack ( \"U*\" ) string . upcase . unpack ( \"U*\" ) . map { | char | Mappings :: UPCASE [ char ] or char } . flatten . pack ( \"U*\" )", "del_tokens": "string . unpack ( \"U*\" ) . map { | char | Mappings :: DOWNCASE [ char ] or char } . flatten . pack ( \"U*\" ) string . unpack ( \"U*\" ) . map { | char | Mappings :: UPCASE [ char ] or char } . flatten . pack ( \"U*\" )", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "undefined", "methods", "included", "in", "ActionView"], "add_tokens": "", "del_tokens": "ActionView :: Base . send ( :include , Datagrid :: Helper )", "commit_type": "fix"}
{"commit_tokens": ["add", "trigger", "method", "and", "tests"], "add_tokens": "proc do | instance , payload = { } | # raise if the instance has not been saved yet... uri = URL . get_resource_path ( instance . type , eid : instance . eid , id : instance . id ) instance . request . post ( \"#{uri}/trigger\" , payload )", "del_tokens": "proc do | |", "commit_type": "add"}
{"commit_tokens": ["Moved", "XML", "classes", "to", "Resync", "::", "XML", "submodule"], "add_tokens": "module XML describe Url do def parse ( xml_string ) doc = REXML :: Document . new ( xml_string ) Url . load_from_xml ( doc . root ) end it 'can round-trip to XML' do xml = ' < url > url = parse ( xml ) expect ( url . save_to_xml ) . to be_xml ( xml ) end", "del_tokens": "describe Url do def parse ( xml_string ) doc = REXML :: Document . new ( xml_string ) Url . load_from_xml ( doc . root ) end it 'can round-trip to XML' do xml = ' < url > url = parse ( xml ) expect ( url . save_to_xml ) . to be_xml ( xml )", "commit_type": "move"}
{"commit_tokens": ["adding", "some", "tests", "removing", "some", "of", "the", "optimizations", "that", "don", "t", "help", "much"], "add_tokens": "score += match_val emit ( this , score )", "del_tokens": "field :_ngrams_weight , :type => Integer if ( i == 0 ) { score += match_val / /prefix match } else { score += 1 } emit ( this , score / this . _ngrams_weight ) self . _ngrams_weight = field_values . inject ( 0 ) { | accum , item | accum += item . length }", "commit_type": "add"}
{"commit_tokens": ["add", "simple", "syntax", "for", "combining", "RelativeTimes"], "add_tokens": "[ @@in_seconds , @@in_months ] . each do | hash | define_method ( unit ) do | additional = RelativeTime . new | time = RelativeTime . new ( self , unit ) time + additional", "del_tokens": "[ @@in_months , @@in_seconds ] . each do | hash | define_method ( unit ) do RelativeTime . new ( self , unit )", "commit_type": "add"}
{"commit_tokens": ["create", "modify_erb", ".", "rb", ";", "insert", "#line", "as", "original", "line", "number"], "add_tokens": "@file = TMPL_DIR + \"/#{@tmpl}.c\" safe_level = nil trim_mode = '%<>' er = ERB . new ( File . read ( @file ) , safe_level , trim_mode ) er . filename = @file er . result ( binding ) er . run ( binding )", "del_tokens": "file = TMPL_DIR + \"/#{@tmpl}.c\" \"\\n\" + ERB . new ( File . read ( file ) ) . result ( binding ) puts \"\\n/* ERB from #{file} */\" ERB . new ( File . read ( file ) ) . run ( binding )", "commit_type": "create"}
{"commit_tokens": ["add", "tests", "for", "auto", "round", "offsets"], "add_tokens": "VERSION = '1.8.23'", "del_tokens": "VERSION = '1.8.22'", "commit_type": "add"}
{"commit_tokens": ["fix", "table", "formatter", "in", "case", "no", "columns", "values", "are", "provided", "and", "no", "valid", "header", "values", "are", "provided"], "add_tokens": "row_column_widths = header_column_widths if row_column_widths . empty? widths . empty? ? [ ] : scale_widths ( widths , opts )", "del_tokens": "scale_widths ( widths , opts )", "commit_type": "fix"}
{"commit_tokens": ["use", "reader", "path", "in", "ctor"], "add_tokens": "reader = WorldDb :: Reader . new ( myopts . data_path ) reader . load_countries ( name ) reader . load_regions ( myopts . country , name ) reader . load_cities ( myopts . country , name ) reader . load ( name )", "del_tokens": "reader = WorldDb :: Reader . new reader . load_countries ( name , myopts . data_path ) reader . load_regions ( myopts . country , name , myopts . data_path ) reader . load_cities ( myopts . country , name , myopts . data_path ) reader . load ( name , myopts . data_path )", "commit_type": "use"}
{"commit_tokens": ["Fix", "double", "migration", "of", "indexes", "(", "in", "situations", "where", "3rd", "party", "code", "would", "cause", "model", "classes", "to", "be", "loaded", "multiple", "times", ")"], "add_tokens": "@indexes = model . schema . indexes . uniq", "del_tokens": "@indexes = model . schema . indexes", "commit_type": "fix"}
{"commit_tokens": ["Add", "--", "pull", "to", "build"], "add_tokens": "VERSION = \"0.9.0\"", "del_tokens": "VERSION = \"0.8.0\"", "commit_type": "add"}
{"commit_tokens": ["Fixing", "MGET", "adding", "more", "specs", "for", "strings"], "add_tokens": "def mget ( * keys ) def mset ( * pairs )", "del_tokens": "def mget ( keys ) def mset ( pairs )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "logtime", "display", "so", "we", "re", "actually", "displaying", "ms", "like", "we", "say", "we", "are"], "add_tokens": "ModernTimes . logger . info { \"#{self}::on_message (#{('%.1f' % (@time_track.last_time*1000.0))}ms)\" } if ModernTimes :: JMS :: Connection . log_times?", "del_tokens": "ModernTimes . logger . info { \"#{self}::on_message (#{('%.1f' % @time_track.last_time)}ms)\" } if ModernTimes :: JMS :: Connection . log_times?", "commit_type": "fix"}
{"commit_tokens": ["Change", "History", "file", "to", "markdown", "format", "and", "renamed", "it", "to", "changelog", "."], "add_tokens": "raise \"The VCR cassette #{name} uses an old format that is now deprecated. VCR provides a rake task to migrate your old cassettes to the new format. See http://github.com/myronmarston/vcr/blob/master/CHANGELOG.md for more info.\"", "del_tokens": "raise \"The VCR cassette #{name} uses an old format that is now deprecated. VCR provides a rake task to migrate your old cassettes to the new format. See http://github.com/myronmarston/vcr/blob/master/History.rdoc for more info.\"", "commit_type": "change"}
{"commit_tokens": ["making", "it", "so", "that", ":", "parent", "and", ":", "class", "can", "coexist", "in", "a", "factory", "definition"], "add_tokens": "@options [ :class ] ||= parent . class_name", "del_tokens": "@options [ :class ] = parent . class_name", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "$", "(", "back_ref", ")"], "add_tokens": "handle :ivar , :lvar , :cvar , :gvar , :back_ref private def dispatch write ( children . first . to_s ) # Emitter for nth_ref nodes (regexp captures) private def dispatch write ( PREFIX ) write ( children . first . to_s )", "del_tokens": "handle :ivar , :lvar , :cvar , :gvar def self . emit ( node , buffer ) buffer . append ( node . children . first . to_s ) self # Emitter for nth ref variable access def self . emit ( node , buffer ) buffer . append ( PREFIX ) buffer . append ( node . children . first . to_s ) self", "commit_type": "add"}
{"commit_tokens": ["Removed", "explicit", "jquery", "plugin", "initialization"], "add_tokens": "@form = form ( session [ 'form_field_values' ] . merge ( params ) )", "del_tokens": "# p '================================' # pp session['form_field_values'] @form = form ( session [ 'form_field_values' ] . merge ( params ) ) # pp params # pp session['form_field_values'].merge(params) # pp @form.values < script type = 'text/javascript' > $ ( document ) . ready ( function ( ) { $ ( 'form' ) . hungryForm ( ) ; } ) ; < / script >", "commit_type": "remove"}
{"commit_tokens": ["Remove", "unused", "variable", "in", "specs"], "add_tokens": "stack . push", "del_tokens": "new_buffer = stack . push", "commit_type": "remove"}
{"commit_tokens": ["Fix", "invitation", "feed", "not", "being", "created", ".", "Fix", "joinable", "not", "working", "when", "there", "is", "only", "a", "single", "permission", "in", "the", "permissions", "column", ".", "Fix", "component_view_permission", "not", "being", "used", "."], "add_tokens": "if cached_membership != nil if membership = memberships . where ( :user_id => user . id ) . first", "del_tokens": "unless cached_membership . nil? if membership = find_user_membership ( user ) # Finds a membership for the given user, caching it because it will probably be checked again for another permission def find_user_membership ( user ) unless @cached_membership && @cached_membership . user_id == user . id @cached_membership = memberships . where ( :user_id => user . id ) . first end return @cached_membership end", "commit_type": "fix"}
{"commit_tokens": ["Update", "and", "simplify", "AttrDeprecated", "::", "Configuration"], "add_tokens": "class << self attr_writer :configuration end def self . configuration @configuration ||= Configuration . new end def self . configure yield ( configuration ) end def self . reset @configuration = Configuration . new end class Configuration attr_accessor :enable , :full_trace , :raise , :log , :slack def initialize @enabled = true @full_trace = false @raise = false @rails_logger = { level : :debug , color : true }", "del_tokens": "require 'active_support/concern' module Configuration extend ActiveSupport :: Concern included do add_config :log_environments add_config :exception_environments add_config :airbrake_environments end module ClassMethods def configure yield self end def add_config ( value ) @name = value if value end", "commit_type": "update"}
{"commit_tokens": ["Add", "explicit", "template", "node", "in", "grammar"], "add_tokens": "describe 'the strconcat rule' do let ( :rule ) { :strconcat } describe 'the strconcat rule' do let ( :rule ) { :strconcat } [ :strconcat , [ :static , \"!\" ] ] describe 'the template rule' do let ( :rule ) { :template } let ( :text ) { \"Hello ${who}!\" } specify { expected = [ :template , [ :fn , [ :strconcat , [ :static , \"Hello \" ] , [ :wlang , '$' , [ :fn , [ :static , \"who\" ] ] ] , [ :static , \"!\" ] ] ] ] subject . should eq ( expected ) } end", "del_tokens": "describe 'the concat rule' do let ( :rule ) { :concat } describe 'concat rule' do let ( :rule ) { :concat } [ :concat , [ :static , \"!\" ] ]", "commit_type": "add"}
{"commit_tokens": ["Add", "pagination", "to", "collection", "photos"], "add_tokens": "def photos ( page = 1 , per_page = 10 ) params = { page : page , per_page : per_page } list = JSON . parse ( connection . get ( \"/collections/#{id}/photos\" , params ) . body )", "del_tokens": "def photos list = JSON . parse ( connection . get ( \"/collections/#{id}/photos\" ) . body )", "commit_type": "add"}
{"commit_tokens": ["Make", "test", "on", "only", "one", "list", "page", "to", "reduce", "time", "and", "overload"], "add_tokens": "products_with_additive = additive . products ( page : 1 ) products_for_brand = brand . products ( page : 1 ) products_for_nutrition_grade = nutrition_grade . products ( page : 1 ) products_for_language = language . products ( page : 1 ) products_for_state = product_state . products ( page : 1 ) products_for_entry_date = entry_date . products ( page : 1 ) products_for_last_edit_date = last_edit_date . products ( page : 1 ) products_for_number_of_ingredients = number_of_ingredients . products ( page : 1 )", "del_tokens": "products_with_additive = additive . products ( page : - 1 ) products_for_brand = brand . products ( page : - 1 ) products_for_nutrition_grade = nutrition_grade . products ( page : - 1 ) products_for_language = language . products ( page : - 1 ) products_for_state = product_state . products ( page : - 1 ) products_for_entry_date = entry_date . products ( page : - 1 ) products_for_last_edit_date = last_edit_date . products ( page : - 1 ) products_for_number_of_ingredients = number_of_ingredients . products ( page : - 1 )", "commit_type": "make"}
{"commit_tokens": ["Fixing", "a", "few", "things", "Code", "Climate", "was", "complaining", "about"], "add_tokens": "helper . experiment_table ( Experiment . all ) . should eql_file ( 'spec/data/helpers/experiment_table.html' ) end end describe '#experiment_table_header' do it 'renders a header row in the report table' do helper . experiment_table_header . should eql_file ( 'spec/data/helpers/experiment_table_header.html' ) end end describe '#experiment_table_row' do it 'renders a data row in the report table' do helper . experiment_table_row ( experiment ) . should eql_file ( 'spec/data/helpers/experiment_table_row.html' )", "del_tokens": "experiment_table ( Experiment . all ) . should eql_file ( 'spec/data/helpers/experiment_table.html' )", "commit_type": "fix"}
{"commit_tokens": ["Update", "version", "and", "changelog", "for", "release"], "add_tokens": "VERSION = '3.1.0'", "del_tokens": "VERSION = '3.0.0'", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "spec", "for", "EnvConfigLoader"], "add_tokens": "require \"delivery_boy/config_error\"", "del_tokens": "ConfigError = Class . new ( StandardError )", "commit_type": "add"}
{"commit_tokens": ["Move", "IO", "selection", "to", "UI", "module", ".", "Add", "--", "no", "-", "pager", "option", "."], "add_tokens": "options << [ '--no-pager' , 'Do not pipe search results into a pager' ] @use_pager = argv . flag? ( 'pager' , true ) if @use_pager IO . popen ( ( '$PAGER' || 'less -R' ) , 'w' ) do | io |", "del_tokens": "attr_accessor :use_pager @use_pager = true if use_pager extend_ui_puts IO . popen ( '$PAGER' , 'w' ) do | io | def extend_ui_puts UI . module_eval do class << self attr_accessor :io_type end def self . puts ( params ) begin if io_type io_type . puts ( params ) else Kernel :: puts ( params ) end rescue exit 1 end end end end", "commit_type": "move"}
{"commit_tokens": ["Fixed", "another", "small", "issue", "around", "the", "sip", "headers", "-", "we", "now", "camel", "case", "the", "key"], "add_tokens": "result [ k . to_s ( ) . camelcase ( :lower ) ] = val", "del_tokens": "result [ k . to_s ( ) ] = val", "commit_type": "fix"}
{"commit_tokens": ["allow", "scripts", "file", "for", "HTML"], "add_tokens": "docxml . at ( \"//body\" ) << mathjax ( @openmathdelim , @closemathdelim ) @scripts and docxml . at ( \"//body\" ) << File . read ( @scripts , encoding : \"UTF-8\" )", "del_tokens": "docxml . at ( \"//*[local-name() = 'body']\" ) << mathjax ( @openmathdelim , @closemathdelim )", "commit_type": "allow"}
{"commit_tokens": ["Updated", "gemspec", "and", "README", "."], "add_tokens": "Version = Gem :: Version . new ( \"0.0.3\" )", "del_tokens": "Version = Gem :: Version . new ( \"0.0.2\" )", "commit_type": "update"}
{"commit_tokens": ["Remove", "out", "-", "dated", "references", "to", "operation", "callbacks"], "add_tokens": "# Execute the operation on the connection.", "del_tokens": "# Execute the operation on the connection. Pass a callback if you're # interested in the results.", "commit_type": "remove"}
{"commit_tokens": ["implement", "logging", "between", "2", "any", "tags"], "add_tokens": "tag1 = @options [ :tag1 ] tag2 = @options [ :tag2 ] tags_strings = [ ] self . all_tags . each { | x | tags_strings . push ( x [ 'name' ] ) } if tags_strings . include? ( tag1 ) if tags_strings . include? ( tag2 ) hash = Hash [ tags_strings . map . with_index . to_a ] index1 = hash [ tag1 ] index2 = hash [ tag2 ] log += self . generate_log_between_tags ( self . all_tags [ index1 ] , self . all_tags [ index2 ] ) else puts \"Can't find tag #{tag2} -> exit\" exit end else puts \"Can't find tag #{tag1} -> exit\" exit end time_string = github_git_data_commits_get [ 'committer' ] [ 'date' ] Time . parse ( time_string )", "del_tokens": "log += self . generate_log_between_tags ( @options [ :tag1 ] , @options [ :tag2 ] ) if github_git_data_commits_get time_string = github_git_data_commits_get [ 'committer' ] [ 'date' ] Time . parse ( time_string ) else puts \"Can't find tag #{prev_tag['name']} -> exit\" exit end", "commit_type": "implement"}
{"commit_tokens": ["Fix", "build", "&", "update", "CHANGELOG"], "add_tokens": "let ( :available_objects ) { [ [ \"Post\" , Integral :: Post ] , [ \"Category\" , Integral :: Category ] , [ \"Page\" , Integral :: Page ] , [ \"List\" , Integral :: List ] , [ \"Image\" , Integral :: Image ] , [ \"User\" , Integral :: User ] ] } let ( :available_actions ) { [ [ \"Update\" , \"update\" ] , [ \"Create\" , \"create\" ] , [ \"Delete\" , \"destroy\" ] , [ \"Publish\" , \"publish\" ] ] }", "del_tokens": "let ( :available_objects ) { [ [ \"Post\" , Integral :: Post ] , [ \"Page\" , Integral :: Page ] , [ \"List\" , Integral :: List ] , [ \"Image\" , Integral :: Image ] , [ \"User\" , Integral :: User ] ] } let ( :available_actions ) { [ [ \"Update\" , \"update\" ] , [ \"Create\" , \"create\" ] , [ \"Delete\" , \"destroy\" ] ] }", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "quote", "enclosed", "TXT", "records", "that", "contained", "semicolons", "."], "add_tokens": "# skip semicolons within \"quote segments\" (TXT records) string . gsub! ( / ((?<! \\\\ );)(?=(?:[^\"]|\"[^\"]*\")*$).* /o , \"\" )", "del_tokens": "string . gsub! ( / (?<! \\\\ );.* /o , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "warning", "if", "a", "packages", "name", "doesn", "t", "match", "with", "it", "s", "url", "."], "add_tokens": "check_path package , value [ 'url' ] url = transform_package ( value ) check_path package , url memo [ url ] = constraint def self . check_path ( package , url ) uri = GitCloneUrl . parse ( url ) path = uri . path . sub ( %r{ ^/ } , '' ) return if path == package puts \" The source of package #{package.bold} is set to #{url.bold} which would be install to #{\"elm-stuff/#{path}\".bold}. This would cause a conflict when trying to compile anything . The name of a package must match the source url ' s path . #{package.bold} <=> #{path.bold} \" Process . exit end", "del_tokens": "memo [ transform_package ( value ) ] = constraint", "commit_type": "add"}
{"commit_tokens": ["Add", "docs", "and", "fixed", "breadcrumb", "links", "."], "add_tokens": "name = crumb . name ? truncate ( crumb . name . capitalize , :length => 30 ) : '' url = eval ( crumb . url )", "del_tokens": "name = crumb . name url = crumb . url", "commit_type": "add"}
{"commit_tokens": ["updates", "noid", "dependency", "and", "delegates", "identifier", "validation", "to", "the", "noid", "library"], "add_tokens": "class IdService @@minter = Noid :: Minter . new ( :template => '.reeddeeddk' ) @@namespace = \"id:\" # remove the fedora namespace since it's not part of the noid identifier . slice! ( @@namespace ) @@minter . valid? identifier \"#{@@namespace}#{@@minter.mint}\"", "del_tokens": "class IdService @@xdigits = Noid :: XDIGIT . join identifier =~ / ^id:[#@@xdigits]{2} \\d {2}[#@@xdigits]{2} \\d {2}[#@@xdigits]$ / minter = Noid :: Minter . new ( :template => '.reeddeeddk' ) return \"id:#{minter.mint}\"", "commit_type": "update"}
{"commit_tokens": ["move", "Item", "and", "child", "classes", "to", "lib", "/", "flor", "/", "item", ".", "rb"], "add_tokens": ". collect { | h | Flor :: Schedule . new ( h ) } . collect { | h | Flor :: Message . new ( h ) } Flor :: Execution . new (", "del_tokens": ". collect { | h | Schedule . new ( h ) } . collect { | h | Message . new ( h ) } Execution . new ( class Item attr_reader :values , :content def id ; @values [ :id ] ; end def exid ; @values [ :exid ] ; end def initialize ( h ) @values = h @content = h ? JSON . parse ( h [ :content ] ) : { } end end class Message < Item def point ; @content [ 'point' ] ; end end class Execution < Item end class Schedule < Item end", "commit_type": "move"}
{"commit_tokens": ["fix", "up", "Rakefile", "and", "functional", "tests"], "add_tokens": "describe \"Test sspinegotiate with encrypt/decrypt via WinRM\" do @winrm = WinRM :: WinRMWebService . new ( ENV [ \"test_winrm_endpoint\" ] , :sspinegotiate , :user => ENV [ \"test_winrm_user\" ] . dup , :pass => ENV [ \"test_winrm_pass\" ] . dup ) end", "del_tokens": "describe \"Test sspinegotiate with encrypt/decrypt via WinRM\" , :windows_and_func_spec_enabled do @winrm = WinRM :: WinRMWebService . new ( ENV [ \"test_winrm_endpoint\" ] , :sspinegotiate , :user => ENV [ \"test_winrm_user\" ] , :pass => ENV [ \"test_winrm_pass\" ] ) describe \"Negative test:\" do before do %x{ winrm set winrm/config/service @{AllowUnencrypted=\"true\"} } end after do %x{ winrm set winrm/config/service @{AllowUnencrypted=\"false\"} } end describe \"when AllowUnencrypted is set to true\" do it \"should raise an exception\" do expect { @winrm . run_cmd ( 'ipconfig' ) } . to raise_exception end end end end", "commit_type": "fix"}
{"commit_tokens": ["Removing", "outdated", "stuff", "from", "light_show", ".", "rb"], "add_tokens": "end", "del_tokens": "# print status of light1 puts light1 # true if we want to have a colorful party looping = true end if looping", "commit_type": "remove"}
{"commit_tokens": ["Updated", "specs", "for", "DateTime", "and", "Time"], "add_tokens": "object . date_attribute . should be_instance_of ( Date ) object . date_attribute . should be_instance_of ( Date ) object . date_attribute . should be_instance_of ( Date ) it 'should not cast <String> with invalid format' do } . should_not raise_exception object . date_attribute . should be_nil object . date_attribute . should be_instance_of ( Date )", "del_tokens": "object . date_attribute . should be_instance_of ( Date ) object . date_attribute . should be_instance_of ( Date ) object . date_attribute . should be_instance_of ( Date ) it 'should not cast <String> without format' do } . should_not raise_exception object . date_attribute . should be_nil object . date_attribute . should be_instance_of ( Date )", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "render", "directly", "on", "table", "."], "add_tokens": "table = TTY :: Table . new rows , :renderer => :basic table . to_s table . column_widths . should == [ 5 , 6 ]", "del_tokens": "subject . extract_column_widths ( rows ) . should == [ 5 , 6 ]", "commit_type": "change"}
{"commit_tokens": ["Change", "to", "rely", "on", "custom", "inspection", "."], "add_tokens": "include Enumerable", "del_tokens": "include Enumerable , Equatable", "commit_type": "change"}
{"commit_tokens": ["added", "yard", "private", "tag", "to", "hide", "internal", "class", "from", "public", "documentation"], "add_tokens": "class Client #:nodoc: #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private #@private", "del_tokens": "class Client", "commit_type": "add"}
{"commit_tokens": ["Update", "version", "and", "readme", "file", "."], "add_tokens": "VERSION = \"0.0.3\"", "del_tokens": "VERSION = \"0.0.2\"", "commit_type": "update"}
{"commit_tokens": ["Add", "node", "/", "role", "association", "command", "and", "tests"], "add_tokens": "manifest_file = File . new ( manifest_path )", "del_tokens": "manifest_file = File . new ( \"#{project_root}/puppet/roles/#{role}/manifests/init.pp\" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "has_one", "associations", "on", "form"], "add_tokens": "VERSION = \"0.9.3\"", "del_tokens": "VERSION = \"0.9.2\"", "commit_type": "fix"}
{"commit_tokens": ["fixed", "Canvas", "failed", "x", "y", "."], "add_tokens": "super ( opts . reject { | k , v | [ :width , :height ] . include? ( k ) } )", "del_tokens": "super ( opts . reject { | k , v | defaults . keys . include? ( k ) } )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "sync", "time", "reading", "for", "regular", "time"], "add_tokens": "@lock = Mutex . new @lock . synchronize do current = Time . now . to_f if @last_time < current @last_time = current else # clock moved back in time @last_time += 0.000_001 end", "del_tokens": "current = Time . now . to_f if @last_time < current @last_time = current else # clock moved back in time @last_time += 0.000_001", "commit_type": "change"}
{"commit_tokens": ["Fixed", "some", "old", "crappy", "code"], "add_tokens": "## # Cell width. attr_reader :width def initialize width , options = nil @value , options = options , { } unless Hash === options @value = options . fetch :value , value @alignment = options . fetch :alignment , :left @colspan = options . fetch :colspan , 1 \" #{value} \" . align alignment , width + 2 value . to_s . length + 2", "del_tokens": "def initialize width , options = { } @alignment = :left @colspan = 1 if options . is_a? Hash @value = options [ :value ] @alignment = options [ :alignment ] unless options [ :alignment ] . nil? @colspan = options [ :colspan ] unless options [ :colspan ] . nil? else @value = options end \" #{value.to_s} \" . align alignment , @width + 2 @value . to_s . length + 2", "commit_type": "fix"}
{"commit_tokens": ["Make", "it", "possible", "to", "define", "main", "menu", "with", "variable", "count", "of", "custom"], "add_tokens": "'*modules' , conf . alt_menu = { '*modules' => [ [ 'shop' , %w[ admin/catalog admin/shipping_addresses admin/product_requests admin/discount_levels admin/manufacturers ] ] , [ 'clients' , %w[ admin/users admin/orders ] ] , [ 'other' , %w[ admin/news_articles admin/colors admin/colors admin/countries admin/currencies admin/email_messages admin/messages admin/settings ] ] , [ 'permissions' , %w[ admin/admins admin/roles ] ] , ] }", "del_tokens": "'admin/home' ,", "commit_type": "make"}
{"commit_tokens": ["Allow", "attributes", "to", "be", "optional", "in", "Algebra", "::", "Project#initialize"], "add_tokens": "def initialize ( relation , attributes = [ ] )", "del_tokens": "def initialize ( relation , attributes )", "commit_type": "allow"}
{"commit_tokens": ["add", "encrypted_password", "to", "columns", "to", "remove"], "add_tokens": "return current_object_class . column_names - [ 'id' , 'created_at' , 'updated_at' , 'encrypted_password' ]", "del_tokens": "return current_object_class . column_names - [ 'id' , 'created_at' , 'updated_at' ]", "commit_type": "add"}
{"commit_tokens": ["remove", "useless", "default", "value", "for", "On", "s", "configuration"], "add_tokens": "def initialize ( front_object , results , challenges , helpers , configuration )", "del_tokens": "def initialize ( front_object , results , challenges , helpers , configuration = { } )", "commit_type": "remove"}
{"commit_tokens": ["fixes", "to", "rails", "5", "version"], "add_tokens": "if Rails :: VERSION :: MAJOR >= 5 search_params = params . dup . permit! . to_h . with_indifferent_access else search_params = params end @q = model . ransack ( search_params [ :q ] )", "del_tokens": "@q = model . ransack ( params [ :q ] )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "missing", "require", "for", "Batik", "again"], "add_tokens": "PATCH = 2", "del_tokens": "PATCH = 1", "commit_type": "add"}
{"commit_tokens": ["Fixed", "small", "issue", "with", "blacklisting"], "add_tokens": "hash = self . to_hash hash . delete ( \"subscription_status\" )", "del_tokens": "hash = self . to_hash . delete ( \"subscription_status\" )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "the", "specials", "/", "flag", "endpoitn", "."], "add_tokens": "# Allows users to indicate a special is improper in some way. # # @params special_id [String] The id of the special being flagged. # @param venue_id [String] The id of the venue running the special. # @param problem [String] One of not_redeemable, not_valuable, other. # @param options [Hash] A customizable set of options. # @option options [String] text Additional text about why the user has flagged this special. # @require_acting_user Yes # @see https://developer.foursquare.com/docs/specials/flag.html def flag_special ( special_id , venue_id , problem , options = { } ) post ( \"specials/#{special_id}/flag\" , { :venueId => venue_id , :problem => problem } . merge ( options ) ) nil end # @param special_id [String] Id of special to retrieve.", "del_tokens": "# @param id [String] Id of special to retrieve.", "commit_type": "implement"}
{"commit_tokens": ["adding", "twitter", "support", "as", "a", "plugin"], "add_tokens": "def do_configure! ( plugin , forced_options = nil ) if forced_options . nil? options = plugin_object . options . inject ( Hash . new ) do | acc , option | print \"#{option}: \" val = STDIN . gets . strip val = true if val == 'true' val = false if val == 'false' acc . merge ( option => val ) end else options = forced_options", "del_tokens": "def do_configure! ( plugin ) options = plugin_object . options . inject ( Hash . new ) do | acc , option | print \"#{option}: \" val = STDIN . gets . strip val = true if val == 'true' val = false if val == 'false' acc . merge ( option => val )", "commit_type": "add"}
{"commit_tokens": ["Add", "resource_model", "private", "method", "for", "resources"], "add_tokens": "@resource = resource_model def resource_model params [ :controller ] . sub ( / ^cms \\/ / , '' ) . classify . safe_constantize end", "del_tokens": "@resource = params [ :controller ] . classify . safe_constantize", "commit_type": "add"}
{"commit_tokens": ["Add", "automatically", "config", "/", "locales", "/", "*", ".", "yml", "in", "the", "i18n", "load", "path", "in", "order", "to", "fix", "Rails3", "issue"], "add_tokens": "# Add if not added Rails.root/config/locales/*.yml in the I18n.load_path if ! @i18n_routing_path_set and defined? ( Rails ) and Rails . respond_to? ( :root ) and Rails . root I18n . load_path = ( I18n . load_path << Dir [ Rails . root . join ( 'config' , 'locales' , '*.yml' ) ] ) . uniq @i18n_routing_path_set = true end Rack :: Mount :: Route . send :include , I18nRouting :: RackMountRoute", "del_tokens": "Rack :: Mount :: Route . send :include , I18nRouting :: RackMountRoute", "commit_type": "add"}
{"commit_tokens": ["implemented", "handle_gasgn", "and", "handle_cdecl", "of", "MultiHookHandler", "+", "2", "spec", "pass", ":", "GREEN", "-", ">", "REFACTOR"], "add_tokens": "lastret = hh . handle_method ( * args ) return lastret if lastret nil end def handle_cdecl ( * args ) @nested_hook_handlers . each do | hh | lastret = hh . handle_cdecl ( * args ) return lastret if lastret end nil def handle_gasgn ( * args ) @nested_hook_handlers . each do | hh | lastret = hh . handle_gasgn ( * args ) return lastret if lastret end nil end", "del_tokens": "hh . handle_method ( * args )", "commit_type": "implement"}
{"commit_tokens": ["Added", "test", "with", "the", "mock"], "add_tokens": "describe QueryReport :: FilterModule do it 'should be able to add custom filter' do", "del_tokens": "require 'query_report/report' describe QueryReport :: Report do it 'should be able to add custom filter with one arity' do", "commit_type": "add"}
{"commit_tokens": ["updated", "marshaling", "to", "work", "better", "with", "dates"], "add_tokens": ":old_value => Marshal . dump ( nil ) , :new_value => Marshal . dump ( hash [ :value ] . to_s ) ) :old_value => Marshal . dump ( hash [ :old_value ] . to_s ) , :new_value => Marshal . dump ( hash [ :new_value ] . to_s ) )", "del_tokens": ":new_value => Marshal . dump ( hash [ :value ] ) ) :old_value => Marshal . dump ( hash [ :old_value ] ) , :new_value => Marshal . dump ( hash [ :new_value ] ) )", "commit_type": "update"}
{"commit_tokens": ["fix", "node", "syntax", ";", "accidentally", "wacked", "a", "comment"], "add_tokens": "# {#range_end}", "del_tokens": "{ #range_end}", "commit_type": "fix"}
{"commit_tokens": ["Fix", "new", "pay", "attrs", "errors"], "add_tokens": "application_fee : ( backer . price_in_cents * 0.07 ) . to_s", "del_tokens": "application_fee : ( backer . price_in_cents * 0.07 )", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "more", "complicated", "example", "to", "the", "spec", "-", "decorations", "+", "gender", "+", "numeric", "rules", "-", "in", "one", "sentence"], "add_tokens": "unknown = mock ( \"unknown\" ) unknown . stub! ( :gender ) . and_return ( \"unknown\" ) Tr8n :: GenderRule . transform ( unknown , \"registered on\" ) . should eq ( \"registered on\" ) Tr8n :: GenderRule . transform ( unknown , \"he\" , \"she\" ) . should eq ( \"he/she\" ) Tr8n :: GenderRule . transform ( unknown , \"his\" , \"her\" ) . should eq ( \"his/her\" ) Tr8n :: GenderRule . transform ( unknown , \"he\" , \"she\" , \"he/she\" ) . should eq ( \"he/she\" )", "del_tokens": "unknwon = mock ( \"unknwon\" ) unknwon . stub! ( :gender ) . and_return ( \"unknwon\" ) Tr8n :: GenderRule . transform ( unknwon , \"registered on\" ) . should eq ( \"registered on\" ) Tr8n :: GenderRule . transform ( unknwon , \"he\" , \"she\" ) . should eq ( \"he/she\" ) Tr8n :: GenderRule . transform ( unknwon , \"his\" , \"her\" ) . should eq ( \"his/her\" ) Tr8n :: GenderRule . transform ( unknwon , \"he\" , \"she\" , \"he/she\" ) . should eq ( \"he/she\" )", "commit_type": "add"}
{"commit_tokens": ["Use", ":", "write_attribute", "everywhere", ".", "Add", "tests", "."], "add_tokens": "previous . send :write_attribute , attr . to_sym , ary . first", "del_tokens": "previous . send \"#{attr}=\" , ary . first", "commit_type": "use"}
{"commit_tokens": ["fix", "printing", "for", "class", "add", "tests"], "add_tokens": "if object . is_a? ( MongoMapper :: Document ) || object . is_a? ( MongoMapper :: EmbeddedDocument ) elsif printable == :class && ( object . ancestors & [ MongoMapper :: Document , MongoMapper :: EmbeddedDocument ] ) . size > 0 return object . inspect if ! defined? ( ActiveSupport :: OrderedHash ) || ! object . respond_to? ( :keys ) hash [ c . first ] = c . last . type . to_s . underscore . intern", "del_tokens": "is_mongo = object . class . include? ( MongoMapper :: Document ) || object . class . include? ( MongoMapper :: EmbeddedDocument ) if is_mongo elsif printable == :class and is_mongo return object . inspect if ! defined? ( ActiveSupport :: OrderedHash ) || ! object . respond_to? ( :columns ) hash [ c . first ] = c . last . type . to_s", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ClassAttributeWithStaticValue", "handling", "of", "syntax", "errors"], "add_tokens": "rescue :: Parser :: SyntaxError next # RuboCop linter will report syntax errors", "del_tokens": "rescue = > ex if ex . message =~ / tRCURLY / # Code is likely a method call instead of a hash, so ignore it next else raise end", "commit_type": "fix"}
{"commit_tokens": ["Added", "search", "for", "plain", "text", "method"], "add_tokens": "#Regex that match plain text in html HTML_PLAIN_TEXT_REGEX = / (?<=>)(([^><])+)(?=<) / results = find_translation def self . find_translation key = result [ 0 ] [ 1 ... - 1 ] results << key def self . find_plain_text results = SearchResult . new dirs = I18nAdminUtils :: Config . search_folders dirs . each do | dir | Dir . glob ( \"#{dir}/**/*.*\" ) . each do | filename | results [ filename ] = find_plain_text_in_file ( filename ) end end results end def self . find_plain_text_in_file ( filename ) list = [ ] File . open ( filename ) . read . scan ( HTML_PLAIN_TEXT_REGEX ) . each do | result | list << result [ 0 ] unless result [ 0 ] . blank? end list end", "del_tokens": "results = find_transaltion def self . find_transaltion results << result [ 0 ] [ 1 ... - 1 ] locale = 'en'", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "use", "new", "HTTP", "signature", "format", "."], "add_tokens": "HTTP_SIGNATURE = 'Signature keyId=\"/%s/keys/%s\",algorithm=\"%s\",signature=\"%s\"' sig = gen_signature ( 'date: ' + now )", "del_tokens": "HTTP_SIGNATURE = 'Signature keyId=\"/%s/keys/%s\",algorithm=\"%s\" %s' sig = gen_signature ( now )", "commit_type": "update"}
{"commit_tokens": ["fixed", "bug", "where", "tag!", "()", "allows", "kernel", "level", "private", "methods", "to", "leak"], "add_tokens": "method_missing ( sym . to_sym , * args , & block )", "del_tokens": "self . __send__ ( sym , * args , & block )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "String", ".", "indent", "refinement", "to", "take", "args", "and", "pass", "to", "indent"], "add_tokens": "def indent * args NRSER . indent self , * args", "del_tokens": "def indent NRSER . indent self", "commit_type": "fix"}
{"commit_tokens": ["updated", "README", "and", "added", "danish", "cream", "locale", "file"], "add_tokens": "app_orm unless orm . to_sym == :active_record def app_orm File . insert_into routes_file , :after => 'do' , :content => 'root :to => \"welcome#index\"'", "del_tokens": "app_orm def app_orm return if orm == 'active_record' File . insert_into routes_file , :after => 'do' , :content => 'root :to => \"welcome#index\"'", "commit_type": "update"}
{"commit_tokens": ["change", "delete", "schema", ";", "no", "delete", "if", "not", "partial"], "add_tokens": "if active_token and not [ :O_PAREN , :COLON ] . include? ( active_token . type ) # delete from start of active token to end of a :start_position => position_start , :end_position => active_token . pos_end - 1 , :range_type => 'inclusive'", "del_tokens": "if active_token :position => position_start , :length => active_token . value . length", "commit_type": "change"}
{"commit_tokens": ["Remove", "fixed", "version", "for", "json", "gem"], "add_tokens": "VERSION = '0.1.2'", "del_tokens": "VERSION = '0.1.1'", "commit_type": "remove"}
{"commit_tokens": ["Add", "another", "utility", "method", "to", "MessageEvent"], "add_tokens": "alias_method :send , :send_message alias_method :message , :send_message alias_method :respond , :send_message", "del_tokens": "def send ( content ) ; @message . send ( content ) ; end def message ( content ) ; @message . message ( content ) ; end", "commit_type": "add"}
{"commit_tokens": ["Adding", "missing", "test", "for", "setnx", "command"], "add_tokens": "it \"should set the value of a key, only if the key does not exist\" do @client . set ( \"key1\" , \"test value\" ) @client . setnx ( \"key1\" , \"new value\" ) @client . setnx ( \"key2\" , \"another value\" ) @client . get ( \"key1\" ) . should == \"test value\" @client . get ( \"key2\" ) . should == \"another value\" end", "del_tokens": "it \"should set the value of a key, only if the key does not exist\"", "commit_type": "add"}
{"commit_tokens": ["Add", "rails", "thor", "command", "also", "."], "add_tokens": "require 'yaml' if appid . present? && secret . present? && token_file . present? Wechat :: Api . new ( appid , secret , token_file ) elsif corpid . present? && corpsecret . present? && token_file . present? Wechat :: CorpApi . new ( corpid , corpsecret , token_file , agentid ) else You need create config / wechat . yml with wechat appid and secret . For example : desc 'message_send [OPENID, TEXT_MESSAGE]' , '()' def message_send ( openid , text_message ) puts Helper . with ( options ) . message_send Wechat :: Message . to ( openid ) . text ( text_message ) end", "del_tokens": "if appid . nil? || secret . nil? || token_file . nil? You need create ~ / . wechat . yml with wechat appid and secret . For example : Wechat :: Api . new ( appid , secret , token_file )", "commit_type": "add"}
{"commit_tokens": ["Add", "required", "gems", "for", "Dummy", "apps", "and", "bump", "gem", "version"], "add_tokens": "VERSION = '0.2.0'", "del_tokens": "VERSION = '0.1.5'", "commit_type": "add"}
{"commit_tokens": ["Fix", "redefinition", "bug", "in", "SSL", "module", "and", "better", "argument", "checking", "for", "DNSResolver"], "add_tokens": "rescue = > ex if respond_to? :on_ssl_error on_ssl_error ( ex ) else raise ex end on_peer_cert ( @ssl_socket . peer_cert ) if respond_to? :on_peer_cert on_ssl_result ( @ssl_socket . verify_result ) if respond_to? :on_ssl_result on_ssl_connect if respond_to? :on_ssl_connect end", "del_tokens": "# Called when the peer's SSL certificate has been read # Equivalent to OpenSSL::SSL::SSLSocket#peer_cert def on_peer_cert ( cert ) ; end # Called after verification of the peer's SSL certificate # against the context provided by the ssl_context method. # All SSL certificate validity-checking logic should be # placed inside this method. Equivalent to # OpenSSL::SSL::SSLSocket#verify_result def on_ssl_result ( result ) ; end # Called after the initial SSL handshake has completed def on_ssl_connect ; end # Called if an error occurs doing SSL handshaking or renegotiation def on_ssl_error ( error ) close end on_peer_cert ( @ssl_socket . peer_cert ) on_ssl_result ( @ssl_socket . verify_result ) on_ssl_connect end", "commit_type": "fix"}
{"commit_tokens": ["Added", "data", "value", "labels", "for", "bar", "graphs", "positioned", "above", "the", "bar"], "add_tokens": "ORIG_VALUES_INDEX = 3 #Only for normalized data # Output the values for the bars on a bar graph # Default is false attr_accessor :show_labels_for_bar_values @hide_line_markers = @hide_legend = @hide_title = @hide_line_numbers = @show_labels_for_bar_values = false @norm_data << [ data_row [ DATA_LABEL_INDEX ] , norm_data_points , data_row [ DATA_COLOR_INDEX ] , data_row [ DATA_VALUES_INDEX ] ] # Draws the data value over the data point in bar graphs def draw_value_label ( x_offset , y_offset , data_point ) return if @hide_line_markers #y_offset = @graph_bottom + LABEL_MARGIN @d . fill = @font_color @d . font = @font if @font @d . stroke ( 'transparent' ) @d . font_weight = NormalWeight @d . pointsize = scale_fontsize ( @marker_font_size ) @d . gravity = NorthGravity @d = @d . annotate_scaled ( @base_image , 1.0 , 1.0 , x_offset , y_offset , data_point . to_s , @scale ) debug { @d . line 0.0 , y_offset , @raw_columns , y_offset } end", "del_tokens": "@hide_line_markers = @hide_legend = @hide_title = @hide_line_numbers = false @norm_data << [ data_row [ DATA_LABEL_INDEX ] , norm_data_points , data_row [ DATA_COLOR_INDEX ] ]", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "set", "API", "info", "(", "title", "description", "license", "terms", "and", "contact", "email", ")"], "add_tokens": ":models => [ ] , :info => { } options . reverse_merge! ( defaults ) info = options [ :info ] apis : routes_array , info : parse_info ( info ) { } . tap do | api_description | api_description [ :models ] = parse_entity_models ( models ) unless models . empty? end def parse_info ( info ) { contact : info [ :contact ] , description : info [ :description ] , license : info [ :license ] , licenseUrl : info [ :license_url ] , termsOfServiceUrl : info [ :terms_of_service_url ] , title : info [ :title ] } . delete_if { | key , value | value . blank? } end", "del_tokens": ":models => [ ] options = defaults . merge ( options ) apis : routes_array api_description = { } api_description [ :models ] = parse_entity_models ( models ) unless models . empty? api_description", "commit_type": "add"}
{"commit_tokens": ["Adding", "find_where", "method", "and", "specs", "."], "add_tokens": "# Public: Finds record based on where condition and returns all fields. # # sobject - The String name of the sobject. # where - String where clause or Hash made up of field => value pairs. # select - Optional array of field names to return. # # Returns Hash of sobject record. def find_where ( sobject , where = { } , select_fields = [ ] ) if where . is_a? ( String ) where_clause = where elsif where . is_a? ( Hash ) conditions = [ ] where . each { | k , v | # Wrap strings in single quotes. v = v . is_a? ( String ) ? \"'#{v}'\" : v v = 'NULL' if v . nil? conditions << \"#{k} = #{v}\" } where_clause = conditions . join ( \" AND \" ) end # Get list of fields if none were specified. if select_fields . empty? field_names = field_list ( sobject ) else field_names = select_fields end soql = \"Select #{field_names.join(\", \")} From #{sobject} Where #{where_clause}\" result = query ( soql ) end # Public: Finds a single record and returns all fields. # # sobject - The String name of the sobject. # id - The id of the record. If field is specified, id should be the id # of the external field. # field - External ID field to use. # # Returns Hash of sobject record.", "del_tokens": "description = describe ( sobject )", "commit_type": "add"}
{"commit_tokens": ["add", "level", "to", "indicate", "how", "many", "tags", "to", "import", "with", "Internet", "Explorer", "and", "directory"], "add_tokens": "# Options for importing attr_accessor :opts # Creates a new Importer and sets the path to the bookmarks file. Opts may # be :level which indicates to which levels tags should be imported. def initialize ( path_to_bookmarks , opts = { } ) @opts = opts # Extracts the tags from a tag string. If a level is provided during # initialization the level is restricting the count of tags imported based # on the level value if tag_string . empty? || opts [ :level ] == 0 tags = tag_string . first . split ( '/' ) level = [ opts [ :level ] || tags . size , tags . size ] . min tags [ - level .. - 1 ] . join ( ',' )", "del_tokens": "# Creates a new Importer and sets the path to the bookmarks file def initialize ( path_to_bookmarks ) if tag_string . empty? tag_string . first . gsub ( \"/\" , \",\" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "filter", "and", "unfold", "nodes", "skipping", "multiple", "rows", "."], "add_tokens": "@value = nil def prepare source . prepare end def value if @value . nil? && ! empty? advance end @value end @value . nil? && source . empty?", "del_tokens": "attr_reader :value advance value . nil? && source . empty?", "commit_type": "fix"}
{"commit_tokens": ["Added", "specs", "to", "validate", "negative", "Floats"], "add_tokens": "return true if value =~ / \\A [+-]?(?:0 \\. \\d {1, #{ precision } }) \\z / return true if value =~ / \\A [+-]?(?: \\d {1, #{ scale } }(?: \\. 0)?) \\z / return true if value =~ / \\A [+-]?(?: \\d {1, #{ scale - precision } }| \\d {0, #{ scale - precision } } \\. \\d {1, #{ precision } }) \\z / return true if value =~ / \\A [+-]?(?: \\d +| \\d * \\. \\d +) \\z /", "del_tokens": "return true if value =~ / \\A (?:0 \\. \\d {1, #{ precision } }) \\z / return true if value =~ / \\A (?: \\d {1, #{ scale } }(?: \\. 0)?) \\z / return true if value =~ / \\A (?: \\d {1, #{ scale - precision } }| \\d {0, #{ scale - precision } } \\. \\d {1, #{ precision } }) \\z / return true if value =~ / \\A (?: \\d +| \\d * \\. \\d +) \\z /", "commit_type": "add"}
{"commit_tokens": ["added", "send_at", "to", "X", "-", "SMTPAPI", "header"], "add_tokens": ":subscriptiontrack_text , :footer_text , :spamcheck_score , :sg_unique_args , :sg_send_at def send_at ( utc_timestamp ) @sg_send_at = utc_timestamp end header_opts [ :send_at ] = @sg_send_at unless @sg_send_at . blank?", "del_tokens": ":subscriptiontrack_text , :footer_text , :spamcheck_score , :sg_unique_args", "commit_type": "add"}
{"commit_tokens": ["implement", "mechanism", "choosing", "by", "preferences"], "add_tokens": "sasl . should be_an_instance_of SASL :: DigestMD5 sasl . should be_an_instance_of SASL :: Plain sasl . should be_an_instance_of SASL :: Anonymous end it 'should choose ANONYMOUS' do preferences = SASL :: Preferences . new class << preferences def want_anonymous? true end end SASL . new ( %w( PLAIN DIGEST-MD5 ANONYMOUS ) , preferences ) . should be_an_instance_of SASL :: Anonymous end it 'should choose DIGEST-MD5' do preferences = SASL :: Preferences . new class << preferences def has_password? true end end SASL . new ( %w( PLAIN DIGEST-MD5 ANONYMOUS ) , preferences ) . should be_an_instance_of SASL :: DigestMD5 end it 'should choose PLAIN' do preferences = SASL :: Preferences . new class << preferences def has_password? true end def allow_plaintext? true end end SASL . new ( %w( PLAIN ANONYMOUS ) , preferences ) . should be_an_instance_of SASL :: Plain end it 'should disallow PLAIN by default' do preferences = SASL :: Preferences . new class << preferences def has_password? true end end lambda { SASL . new ( %w( PLAIN ANONYMOUS ) , preferences ) } . should raise_error ( SASL :: UnknownMechanism )", "del_tokens": "sasl . class . should == SASL :: DigestMD5 sasl . class . should == SASL :: Plain sasl . class . should == SASL :: Anonymous", "commit_type": "implement"}
{"commit_tokens": ["add", ":", "expose", "logger", ".", "level", "severity", "to", "set", "during", "initialize"], "add_tokens": "# +max_connections+:: maximum number of simultaneous processed connections, this does not limit the number of concurrent TCP connections # +opts+:: hash with optional settings # +opts.logger_severity+:: logger level when default logger is used @logger . level = opts . include? ( :logger_severity ) ? opts [ :logger_severity ] : Logger :: DEBUG", "del_tokens": "# +max_connections+:: maximum number of simultaneous processed connections, this does not limit the TCP connection itself # +opts+:: optional hash with settings", "commit_type": "add"}
{"commit_tokens": ["added", "custom", "Faraday", "test", "adapter"], "add_tokens": "c . use MnoeFaradayTestAdapter do | receiver |", "del_tokens": "c . adapter ( :test ) do | receiver |", "commit_type": "add"}
{"commit_tokens": ["Make", "proper", "/", "efficient", "use", "of", "Bundler", "in", "CI", "features", "."], "add_tokens": "file . puts \"source 'https://rubygems.org'\" ruby_app_shell ( 'bundle install --local || bundle install' )", "del_tokens": "ruby_app_shell ( 'bundle install' )", "commit_type": "make"}
{"commit_tokens": ["Fix", "name", "of", "CommentNode", "file"], "add_tokens": "module HamlLint :: Tree", "del_tokens": "module HamlLint", "commit_type": "fix"}
{"commit_tokens": ["fix", "pointer", "test", "based", "on", "last", "change", "fix", "refresh", "on", "object", "to", "parse", "properly", "like", "everything", "else"], "add_tokens": "data = Parse . get @class_name , @parse_object_id", "del_tokens": "data = Parse . client . get self . uri", "commit_type": "fix"}
{"commit_tokens": ["Move", "all", "preset", "instance", "variables", "up", "to", "readers", "with", "defaults"], "add_tokens": "attr_reader_default :all_of , [ ] attr_reader_default :any_of , [ ] attr_reader_default :definitions , { } attr_reader_default :dependencies , { } attr_reader_default :one_of , [ ] attr_reader_default :pattern_properties , { } attr_reader_default :properties , { }", "del_tokens": "# these are all the subschema types; default them to empty data # structures for simplified iteration @all_of = [ ] @any_of = [ ] @one_of = [ ] @definitions = { } @dependencies = { } @pattern_properties = { } @properties = { }", "commit_type": "move"}
{"commit_tokens": ["Fix", "a", "Rubocop", "ABC", "offense", "."], "add_tokens": "write_asset_file ( directory , asset ) # Write asset file to disk def write_asset_file ( directory , asset ) FileUtils . mkpath ( directory ) unless File . directory? ( directory ) begin # Save file to disk File . open ( File . join ( directory , asset . filename ) , 'w' ) do | file | file . write ( asset . content ) end rescue Exception => e puts \"Asset Pipeline: Failed to save '#{asset.filename}' to \" \"disk: #{e.message}\" raise e end end", "del_tokens": "FileUtils . mkpath ( directory ) unless File . directory? ( directory ) begin # Save file to disk File . open ( File . join ( directory , asset . filename ) , 'w' ) do | file | file . write ( asset . content ) end rescue Exception => e puts \"Asset Pipeline: Failed to save '#{asset.filename}' to \" \"disk: #{e.message}\" raise e end", "commit_type": "fix"}
{"commit_tokens": ["Add", "generic", "<", "=", ">", "method", "."], "add_tokens": "def compare_fields [ :ignored_files , :ignored_methods , :ignored_classes ] end compare_fields . each do | field | cmp = send ( field ) <=> other . send ( field ) return cmp if cmp . nonzero? 0", "del_tokens": "fields = [ :ignored_files , :ignored_methods , :ignored_classes ] cmp = ignored_files <=> other . ignored_files if cmp == 0 cmp = ignored_classes <=> other . ignored_classes if cmp == 0 cmp = ignored_methods <=> other . ignored_methods end", "commit_type": "add"}
{"commit_tokens": ["Adding", "basic", "tokens", "for", "starting", "a", "heredocs"], "add_tokens": "CONDITIONAL_TERMINATOR = / \\A (&&| \\| \\| ) / HEREDOC_START = / \\A <<[A-z0-9]+ / heredoc_token || def heredoc_token if md = @chunk . match ( HEREDOC_START ) token :Heredoc , md [ 0 ] md [ 0 ] . length end end", "del_tokens": "CONDITIONAL_TERMINATOR = / \\A (&&| \\| \\| ) /", "commit_type": "add"}
{"commit_tokens": ["remove", "loading", "firefox", "if", "using", "JRuby"], "add_tokens": "@browser = Celerity :: Browser . new ( :proxy => options [ :proxy ] , :resynchronize => options [ :resynchronize ] )", "del_tokens": "@browser = Celerity :: Browser . new ( :proxy => options [ :proxy ] )", "commit_type": "remove"}
{"commit_tokens": ["Removing", "useless", "dependency", "to", "json", "library", "using", "Yajl", "instead"], "add_tokens": "require 'yajl' retval [ 'data' ] = Yajl :: Parser . parse ( res ) retval [ 'data' ] = Yajl :: Parser . parse ( err . response )", "del_tokens": "require 'json' retval [ 'data' ] = JSON . parse ( res ) retval [ 'data' ] = JSON . parse ( err . response )", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "some", "wrongs", "code", "."], "add_tokens": "faraday . ssl [ :verify ] = conf . ssl_verify == 'true'", "del_tokens": "faraday . ssl [ :verify ] = conf . to_s . eql? ( 'true' ) ? true : false", "commit_type": "fix"}
{"commit_tokens": ["Made", "the", "code", "for", "encoding", "data", "element", "values", "more", "robust"], "add_tokens": "# Class for interacting with the DICOM object. # Encodes a value to binary (used for inserting values into a DICOM object). add_msg ( \"Invalid tag format (#{value}). Expected format: 'GGGG,EEEE'\" )", "del_tokens": "# Class for handling the DICOM contents: # Encodes a value to binary (used for inserting values to a DICOM object). add_msg ( \"Invalid tag format (#{value}).\" )", "commit_type": "make"}
{"commit_tokens": ["Add", "option", "to", "specify", "a", "routing", "key"], "add_tokens": "def initialize ( queue_name : , exchange : , processor : , routing_key : '#' ) @bindings = { exchange => routing_key }", "del_tokens": "def initialize ( queue_name : , exchange : , processor : ) @bindings = { exchange => \"#\" }", "commit_type": "add"}
{"commit_tokens": ["Making", "release", "task", "more", "robust", "bumping", "version", "."], "add_tokens": "$version = '0.1.4.pre'", "del_tokens": "$version = '0.1.3.pre'", "commit_type": "make"}
{"commit_tokens": ["added", "api", "methods", "to", "forum", "and", "thread", "began", "post", "obj", "."], "add_tokens": "attr_reader :id , :forum , :slug , :title , :created_at , :allow_comments , :url , :identifier , :forum , :posts @posts = [ ] def load_posts ( opts = { } ) @posts = Post . list ( self , opts ) end def update ( opts = { } ) result = Disqus :: Api :: update_thread ( opts . merge ( :forum_api_key => forum . key , :thread_id => id , :title => title , :slug => slug , :url => url , :allow_comments => allow_comments ) ) return result [ \"succeeded\" ] end", "del_tokens": "attr_reader :id , :forum , :slug , :title , :created_at , :allow_comments , :url , :identifier", "commit_type": "add"}
{"commit_tokens": ["changed", "shell", "back", "to", "=", ">", "for", "evaluated", "output"], "add_tokens": "\" => \" + parse_tree_node . evaluate . inspect", "del_tokens": "\"result> \" + parse_tree_node . evaluate . inspect", "commit_type": "change"}
{"commit_tokens": ["Fix", "accusative", "function", "for", "work", "with", "two", "words"], "add_tokens": "self . sub ( / (.*)( ?)/, ' 1\\2').su b ( /(. * ) ( (.+))?$/, '\\ 1  2').sub( / ( .*)  ( (.+))?$/, '\\1 \\ 2 )", "del_tokens": "self . sub ( / $/ , '). s u b(/  $ /, '  )", "commit_type": "fix"}
{"commit_tokens": ["Add", "conditions", "support", "for", "images", "insert", "dialogue", "so", "that", "custom", "conditions", "can", "be", "supplied", ".", "This", "then", "supplies", "a", "conditions", "hash", "to", "paginate_images", "which", "hopefully", "avoids", "XSS", "(", "Cross", "site", "scripting", ")"], "add_tokens": "@conditions = params [ :conditions ] unless params [ :conditions ] . blank? extra_condition = params [ :conditions ] . split ( ',' ) extra_condition [ 1 ] = true if extra_condition [ 1 ] == \"true\" extra_condition [ 1 ] = false if extra_condition [ 1 ] == \"false\" extra_condition [ 1 ] = nil if extra_condition [ 1 ] == \"nil\" paginate_images ( { extra_condition [ 0 ] . to_sym => extra_condition [ 1 ] } ) else paginate_images end def paginate_images ( conditions = { } ) @images = Image . paginate :page => ( @paginate_page_number ||= params [ :page ] ) , :conditions => { :parent_id => nil } . merge! ( conditions ) , :order => 'created_at DESC' , :per_page => Image . per_page ( from_dialog? ) , end", "del_tokens": "paginate_images def paginate_images @images = Image . paginate :page => ( @paginate_page_number ||= params [ :page ] ) , :conditions => 'parent_id is null' , :order => 'created_at DESC' , :per_page => Image . per_page ( from_dialog? ) , end", "commit_type": "add"}
{"commit_tokens": ["added", "four", "column", "image", "(", "still", "need", "icon", ")", "and", "made", "callout", "fa_icons", "fixed", "-", "width"], "add_tokens": "'Embedded Content' => 'FullWidthEmbeddedContent' , 'Four Images' => 'FourColumnImage' , 'Image and Text (No Wrap)' => 'LeftImageRightText'", "del_tokens": "'Image and Text (No Wrap)' => 'LeftImageRightText' , 'Embedded Content' => 'FullWidthEmbeddedContent'", "commit_type": "add"}
{"commit_tokens": ["Use", "version_author", "to", "capture", "whodunnit"], "add_tokens": "version_author : '1742' ,", "del_tokens": "whodunnit : '1742' ,", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "load", "local", "version"], "add_tokens": "require_relative '../lib/pastel'", "del_tokens": "require_relative 'lib/pastel'", "commit_type": "change"}
{"commit_tokens": ["Move", "HOST", "constant", "into", "new", "AppleDeveloperCenter", "module"], "add_tokens": "pw = Security :: InternetPassword . find ( :server => XcodeDownload :: AppleDeveloperCenter :: HOST )", "del_tokens": "HOST = \"developer.apple.com\" pw = Security :: InternetPassword . find ( :server => HOST )", "commit_type": "move"}
{"commit_tokens": ["Make", "inline_resource", "more", "standard", "and", "extensible"], "add_tokens": "create_key ( false , :create ) create_key ( true , :regenerate ) def create_key ( regenerate , action ) Cheffish . inline_resource ( self , action ) do", "del_tokens": "create_key ( false ) create_key ( true ) def create_key ( regenerate ) Cheffish . inline_resource ( self ) do", "commit_type": "make"}
{"commit_tokens": ["Allow", "regular", "methods", "to", "be", "turned", "into", "callback"], "add_tokens": "# collaborator # .do_some_other_thing(when_done: callback(:it_was_done_method)) # # def it_was_done_method(some_arg:) # puts \"In a method: #{some_arg}\" # end # callback :it_was_done_method # # STDOUT: \"In a method: done by Bar\" private # Regardless of whether the callback is pointing to an existing instance # method or if it is defined via the block argument, the callback will # also be wrapped in logging statements that can help you trace the # execution path through your code in the event of any anomolies. # @param name [Symbol] The name of the callback. If no block is provided, # then name must be the name of an existing instance method. # @param block [Proc] If a block is provided, the block will act as the # though it is the body of an instance method when the callback is # invoked. without_logging = \"#{name}_without_logging\" . to_sym provides_callbacks_define_method_with_block ( without_logging , & block ) provides_callbacks_alias_method ( without_logging , name ) provides_callbacks_define_wrapper ( name , without_logging ) self end def provides_callbacks_method_defined? ( name ) method_defined? ( name ) || private_method_defined? ( name ) end def provides_callbacks_define_method_with_block ( without_logging , & block ) return unless block_given? define_method ( without_logging , & block ) private without_logging end def provides_callbacks_alias_method ( without_logging , name ) return unless provides_callbacks_method_defined? ( name ) alias_method without_logging , name private without_logging end def provides_callbacks_define_wrapper ( name , without_logging ) make_public = public_method_defined? ( name ) send ( without_logging , * args ) private name unless make_public", "del_tokens": "# # Callbacks can be given to collaborating objects, but the actual methods are # defined as private methods. This allows the object to control which other # objects are able to invoke the callbacks (at least to the extent that Ruby # lets you do so.) # The provided block will be used to define an instance method. This # behaves similarly to #define_method, however it will ensure that # callbacks are logged if the object has a #logger method defined. # @param name [Symbol] The name of the callback # @param block [Proc] The code that will be executed in the context of the # object when the callback is invoked. define_method ( \"#{name}_without_logging\" , & block ) send ( \"#{name}_without_logging\" , * args ) private name self", "commit_type": "allow"}
{"commit_tokens": ["Add", "full", "api", "specs", "for", "DummyStore"], "add_tokens": "# -*- encoding: utf-8 -*- # # spec_helper.rb # # Copyright (c) 2013 by Philippe Bourgau. All rights reserved. # # This library is free software; you can redistribute it and/or # modify it under the terms of the GNU Lesser General Public # License as published by the Free Software Foundation; either # version 3.0 of the License, or (at your option) any later version. # # This library is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU # Lesser General Public License for more details. # # You should have received a copy of the GNU Lesser General Public # License along with this library; if not, write to the Free Software # Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, # MA 02110-1301 USA require 'storexplore' require 'storexplore/testing' Storexplore :: Testing . config do | config | config . dummy_store_generation_dir = File . join ( File . dirname ( __FILE__ ) , '../tmp' ) end", "del_tokens": "require 'storexplore'", "commit_type": "add"}
{"commit_tokens": ["added", "storyboard", "names", "to", "constants", "collection"], "add_tokens": "Dir [ \"#{options.source_dir}/**/*.storyboard\" ] . each_with_index do | storyboard , storyboard_index | storyboards << filename constants [ filename ] << Location . new ( 'storyboards' , nil , storyboard , filename , storyboard_index + 1 )", "del_tokens": "Dir [ \"#{options.source_dir}/**/*.storyboard\" ] . each do | storyboard | storyboards << filename", "commit_type": "add"}
{"commit_tokens": ["Added", "integration", "tests", "for", "inheritance"], "add_tokens": "def initialize ( klass , options , & block ) @klass = klass attribute = Attrio :: Attribute . new ( @klass , attribute_name , type , attribute_options ) . define_writer . define_reader @klass . send ( self . as ) [ name . to_sym ] = attribute", "del_tokens": "def initialize ( object , options , & block ) @object = object attribute = Attrio :: Attribute . new ( @object , attribute_name , type , attribute_options ) . define_writer . define_reader @object . send ( self . as ) [ name . to_sym ] = attribute", "commit_type": "add"}
