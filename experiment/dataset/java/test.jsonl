{"commit_tokens": ["Fix", "runtime", "context", "injection", "when", "using", "Steno", "logger", "and", "log", "builder", "."], "add_tokens": "import com . arpnetworking . logback . StenoClassOfCallerConverter ; import com . arpnetworking . logback . StenoFileOfCallerConverter ; import com . arpnetworking . logback . StenoLineOfCallerConverter ; import com . arpnetworking . logback . StenoMethodOfCallerConverter ; public static final ClassicConverter FILE_CONVERTER = new StenoFileOfCallerConverter ( ) ; public static final ClassicConverter CLASS_CONVERTER = new StenoClassOfCallerConverter ( ) ; public static final ClassicConverter METHOD_CONVERTER = new StenoMethodOfCallerConverter ( ) ; public static final ClassicConverter LINE_CONVERTER = new StenoLineOfCallerConverter ( ) ;", "del_tokens": "import ch . qos . logback . classic . pattern . ClassOfCallerConverter ; import ch . qos . logback . classic . pattern . FileOfCallerConverter ; import ch . qos . logback . classic . pattern . LineOfCallerConverter ; import ch . qos . logback . classic . pattern . MethodOfCallerConverter ; public static final ClassicConverter FILE_CONVERTER = new FileOfCallerConverter ( ) ; public static final ClassicConverter CLASS_CONVERTER = new ClassOfCallerConverter ( ) ; public static final ClassicConverter METHOD_CONVERTER = new MethodOfCallerConverter ( ) ; public static final ClassicConverter LINE_CONVERTER = new LineOfCallerConverter ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "option", "to", "define", "views", "/", "and", "pages", "using", "the", "PageFactory", "+", "a", "few", "low", "level", "steps", "so", "you", "can", "verify", "elements", "in", "your", "defined", "views", "and", "click", "them"], "add_tokens": "public WebElement table_Row_1 ; @ FindBy ( id = \"something_rather\" ) public WebElement non_existing ; @ FindBy ( xpath = \"//td[text()='new value']\" ) public WebElement New_value_cell ;", "del_tokens": "public WebElement tableRow1 ;", "commit_type": "add"}
{"commit_tokens": ["Changing", "the", "target", "SDK", "to", "Java", "7"], "add_tokens": "return TreeNode . query ( root , point , new ArrayList < Interval < T > > ( ) ) ;", "del_tokens": "return TreeNode . query ( root , point , new ArrayList < > ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "first", "attempt", "at", "an", "XML", "Schema", "for", "GPD", "and", "added", "the", "validation", "against", "it", "."], "add_tokens": "/* XML Schema file for GPD on the classpath. */ private static final String GPD_SCHEMA = \"schema/gpd/gpd.xsd\" ; // Validate against the GPD schema. File schema = null ; try { schema = new File ( JpdlValidator . class . getClassLoader ( ) . getResource ( GPD_SCHEMA ) . toURI ( ) ) ; } catch ( URISyntaxException usEx ) { LOGGER . error ( \"Cannot locate GPD schema.\" , usEx ) ; return null ; } return XmlUtils . validate ( document , schema ) ? document : null ;", "del_tokens": "* TODO : Include validation for GPD . // TODO: Validate the document before returning it. return document ;", "commit_type": "add"}
{"commit_tokens": ["added", "new", "resource", "methods", "to", "client", "factory"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["make", "minimization", "work", "properly", "(", "only", "in", "debug", "mode", ")", "&", "add", "4", "more", "unit", "tests"], "add_tokens": "import ro . isdc . wro . config . ConfigurationContext ; * The minimization is can be switched off only in debug mode . return ! ( ConfigurationContext . get ( ) . getConfig ( ) . isDebug ( ) && \"false\" . equalsIgnoreCase ( minimizeAsString ) ) ;", "del_tokens": "return ! \"false\" . equalsIgnoreCase ( minimizeAsString ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "the", "parsing", "of", "orders", "without", "a", "cid"], "add_tokens": "exchangeOrder . setCid ( order . optLong ( 2 , - 1 ) ) ;", "del_tokens": "exchangeOrder . setCid ( order . getLong ( 2 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "app", "bundle"], "add_tokens": "this ( context , new File ( context . getApplicationInfo ( ) . sourceDir ) , name , flags ) ; } public ApkSoSource ( Context context , File apkPath , String name , int flags ) { apkPath ,", "del_tokens": "import java . util . HashMap ; import java . util . Map ; import javax . annotation . Nullable ; new File ( context . getApplicationInfo ( ) . sourceDir ) ,", "commit_type": "add"}
{"commit_tokens": ["remove", "generated", "CSSs", "update", "font", "-", "awesome", "to", "fix", "fonts", "rendering"], "add_tokens": "/* Assets (pictures / javascript) */ router . GET ( ) . route ( \"/favicon.ico\" ) . with ( Results . redirect ( \"/assets/images/logo.png\" ) ) ; router . GET ( ) . route ( \"/assets/webjars/{fileName: .*}\" ) . with ( AssetsController . class , \"serveWebJars\" ) ; router . GET ( ) . route ( \"/assets/{fileName: .*}\" ) . with ( AssetsController . class , \"serveStatic\" ) ; /* Application Routes */ router . GET ( ) . route ( \"/events\" ) . with ( ApplicationController . class , \"events\" ) ;", "del_tokens": "router . GET ( ) . route ( \"/events\" ) . with ( ApplicationController . class , \"events\" ) ; /////////////////////////////////////////////////////////////////////// // Assets (pictures / javascript) /////////////////////////////////////////////////////////////////////// router . GET ( ) . route ( \"/assets/webjars/{fileName: .*}\" ) . with ( AssetsController . class , \"serveWebJars\" ) ; router . GET ( ) . route ( \"/assets/{fileName: .*}\" ) . with ( AssetsController . class , \"serveStatic\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "transparent", "style", "for", "splash", "."], "add_tokens": "import javafx . scene . paint . Color ; final Stage splashStage = new Stage ( StageStyle . TRANSPARENT ) ; final Scene splashScene = new Scene ( splashScreen . getParent ( ) , Color . TRANSPARENT ) ; splashStage . initStyle ( StageStyle . TRANSPARENT ) ;", "del_tokens": "final Stage splashStage = new Stage ( StageStyle . UNDECORATED ) ; final Scene splashScene = new Scene ( splashScreen . getParent ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "bug", "in", "facebook", "url", "generation"], "add_tokens": "return String . format ( SCOPED_AUTHORIZE_URL , config . getApiKey ( ) , formURLEncode ( config . getCallback ( ) ) , formURLEncode ( config . getScope ( ) ) ) ;", "del_tokens": "return String . format ( SCOPED_AUTHORIZE_URL , formURLEncode ( config . getCallback ( ) ) , formURLEncode ( config . getScope ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "encoding", "in", "Verifier", "constructor"], "add_tokens": "Preconditions . checkNotNull ( value , \"Must provide a valid string as verifier\" ) ; this . value = value ;", "del_tokens": "this . value = URLUtils . percentDecode ( value ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "fields", "final", ".", "Style", "tweak", "."], "add_tokens": "final View view ; final int layer ; layeredViewQueue . addLast ( new LayeredView ( child , layer + 1 ) ) ;", "del_tokens": "View view ; int layer ; layeredViewQueue . addLast ( new LayeredView ( child , layer + 1 ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "formatting", "and", "modifiers", "."], "add_tokens": "private static final ImmutableList < StreamVariantsRequest > requests = ShardUtils . getVariantRequests ( private static final int EXPECTED_CHRY_NUM_VARIANTS = 5971309 ;", "del_tokens": "ImmutableList < StreamVariantsRequest > requests = ShardUtils . getVariantRequests ( final int EXPECTED_CHRY_NUM_VARIANTS = 5971309 ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "stack", "reference", "to", "session", "on", "disconnect", "."], "add_tokens": "IoSession currentSession = this . session ; if ( currentSession != null && ! currentSession . isClosing ( ) ) { currentSession . getRemoteAddress ( ) , Long . valueOf ( this . connectionTimeout ) ) ; currentSession . close ( true ) ;", "del_tokens": "if ( this . session != null && ! this . session . isClosing ( ) ) { this . session . getRemoteAddress ( ) , Long . valueOf ( this . connectionTimeout ) ) ; this . session . close ( true ) . awaitUninterruptibly ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "tests", "for", "perspective", "-", "framework", "module"], "add_tokens": "import static org . hamcrest . Matchers . * ; assertThat ( message . getId ( ) , is ( notNullValue ( ) ) ) ; assertThat ( message . getCloudType ( ) , is ( notNullValue ( ) ) ) ;", "del_tokens": "import static org . hamcrest . Matchers . equalTo ; import static org . junit . Assert . assertNotNull ; assertNotNull ( message . getId ( ) ) ; assertNotNull ( message . getCloudType ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["updates", "for", "stricter", "metamodel", "validation", "."], "add_tokens": "public String disableUpdateCountryAndState ( ) {", "del_tokens": "public String disableUpdateCountryAndState ( final Country country , final State state ) {", "commit_type": "update"}
{"commit_tokens": ["adding", "cdi", "stereotype", "in", "order", "to", "make", "easier", "the", "registration", "process", "of", "handlers"], "add_tokens": "Set < Class < ? extends Annotation > > annotations = bean . getStereotypes ( ) ; for ( Class < ? extends Annotation > annotation : annotations ) { if ( stereotypesInfo . containsKey ( annotation ) ) { return stereotypesInfo . get ( annotation ) . getStereotypeQualifier ( ) ;", "del_tokens": "Annotation [ ] annotations = bean . getBeanClass ( ) . getAnnotations ( ) ; for ( Annotation annotation : annotations ) { if ( stereotypesInfo . containsKey ( annotation . annotationType ( ) ) ) { return stereotypesInfo . get ( annotation . annotationType ( ) ) . getStereotypeQualifier ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "iteration", "count", "option", "(", "-", "i", ")", "to", "PBKDF2Engine", "main", "tested", "with", "WildFly10"], "add_tokens": "import java . util . Arrays ; * salt and 1000 iterations ( default ) using HMacSHA1 . Assume that password is in * < p > * < p > * The iteration count is configurable . In verification mode , the iteration * count supplied in the candidate string must be no less than the int iterations = 1000 ; if ( args . length >= 2 && args [ 0 ] . equals ( \"-i\" ) ) { iterations = Integer . parseInt ( args [ 1 ] ) ; args = Arrays . copyOfRange ( args , 2 , args . length ) ; } boolean verifyOK = ( p . getIterationCount ( ) >= iterations ) && e . verifyKey ( password ) ;", "del_tokens": "* salt and 1000 iterations using HMacSHA1 . Assume that password is in * int iterations = 1000 ; boolean verifyOK = e . verifyKey ( password ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "plexus", "-", "utils", "dependency"], "add_tokens": "if ( str == null || str . length ( ) < 1 ) if ( str == null || str . length ( ) < 1 ) if ( str == null || str . length ( ) < 1 )", "del_tokens": "import org . codehaus . plexus . util . StringUtils ; if ( StringUtils . isEmpty ( str ) ) if ( StringUtils . isEmpty ( str ) ) if ( StringUtils . isEmpty ( str ) )", "commit_type": "remove"}
{"commit_tokens": ["Added", "isMaximized", "-", "method", "."], "add_tokens": "builder . create ( ) . show ( ) ;", "del_tokens": "builder . show ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "weak", "typed", "generic", "Promise", "to", "be", "strong", "typed", "."], "add_tokens": "* * @ param < T > Type of object returned by promise Promise < T > oldPromise = this . promise ;", "del_tokens": "Promise oldPromise = this . promise ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "other", "platform", "sha1", "to", "dependency", "info"], "add_tokens": "import org . apache . commons . io . FileUtils ; import java . io . * ; // todo check file encoding and create file in other encoding and calculate its sha1 DependencyInfo originalDependencyInfo = factory . createDependencyInfo ( basedir , fileName ) ; if ( originalDependencyInfo != null ) { originalDependencyInfo . setSystemPath ( null ) ; dependencyInfos . add ( originalDependencyInfo ) ;", "del_tokens": "import java . io . File ; import java . io . IOException ; DependencyInfo dependencyInfo = factory . createDependencyInfo ( basedir , fileName ) ; if ( dependencyInfo != null ) { dependencyInfo . setSystemPath ( null ) ; dependencyInfos . add ( dependencyInfo ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "constructor", "to", "ReportEngine", "that", "will", "take", "an", "already", "created"], "add_tokens": "/ * * * < p > * Creates a new { @ link ReportEngine } using the given * { @ link WindupEnvironment } . This new { @ link ReportEngine } will use a newly * created { @ link WindupEngine } . * < / p > * * @ param settings * Windup settings to use for this { @ link ReportEngine } * / this ( settings , new WindupEngine ( settings ) ) ; } / * * * < p > * Creates a { @ link ReportEngine } using an already existing * { @ link WindupEngine } . * < / p > * * < p > * < b > IMPORTANT : keep in mind that { @ link WindupEngine } is not inherently * thread safe , so if you are using it for more then one task be sure to * manage this risk yourself . * < / p > * * @ param settings * Windup settings to use for this { @ link ReportEngine } * @ param engine * Windup engine to use for this { @ link ReportEngine } * / public ReportEngine ( WindupEnvironment settings , WindupEngine engine ) { windupEngine = engine ;", "del_tokens": "windupEngine = new WindupEngine ( settings ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "the", "Database", "Topic", "Provider", "wasn", "t", "catching", "and", "handling", "exceptions", "."], "add_tokens": "return getWrapperFactory ( ) . create ( getEntity ( Topic . class , id ) , false ) ; return getWrapperFactory ( ) . create ( getRevisionEntity ( Topic . class , id , revision ) , true ) ;", "del_tokens": "import org . jboss . pressgang . ccms . model . utils . EnversUtilities ; final Topic topic = getEntityManager ( ) . find ( Topic . class , id ) ; return getWrapperFactory ( ) . create ( topic , false ) ; final Topic dummyTopic = new Topic ( ) ; dummyTopic . setTopicId ( id ) ; return getWrapperFactory ( ) . create ( EnversUtilities . getRevision ( getEntityManager ( ) , dummyTopic , revision ) , true ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "socketio", "to", "netty", "4", ".", "Fix", "packet", "framer"], "add_tokens": "import io . netty . channel . socket . nio . NioServerSocketChannel ; bootstrap = new ServerBootstrap ( ) . group ( new NioEventLoopGroup ( ) , new NioEventLoopGroup ( ) ) . channel ( NioServerSocketChannel . class ) . childHandler ( pipelineFactory ) . childOption ( ChannelOption . TCP_NODELAY , true ) . childOption ( ChannelOption . TCP_NODELAY , true ) ;", "del_tokens": "bootstrap = new ServerBootstrap ( ) . group ( new NioEventLoopGroup ( ) , new NioEventLoopGroup ( ) ) . childHandler ( pipelineFactory ) . childOption ( ChannelOption . TCP_NODELAY , true ) . childOption ( ChannelOption . TCP_NODELAY , true ) ;", "commit_type": "move"}
{"commit_tokens": ["Allow", "sending", "an", "access", "token", "with", "LegacyCentralDogmaBuilder"], "add_tokens": "final String authorization = \"Bearer \" + accessToken ( ) ; req . headers ( ) . set ( HttpHeaderNames . AUTHORIZATION , authorization ) ;", "del_tokens": "import com . linecorp . centraldogma . internal . CsrfToken ; req . headers ( ) . set ( HttpHeaderNames . AUTHORIZATION , \"Bearer \" + CsrfToken . ANONYMOUS ) ;", "commit_type": "allow"}
{"commit_tokens": ["Making", "database", "configurable", "in", "the", "servlet", "."], "add_tokens": "import org . apache . commons . configuration . Configuration ; import org . apache . commons . configuration . ConfigurationException ; import org . apache . commons . configuration . PropertiesConfiguration ; private static Configuration config = null ; ClassNotFoundException , SQLException , ConfigurationException { if ( SimpleStorageServlet . config == null ) SimpleStorageServlet . config = new PropertiesConfiguration ( \"database.properties\" ) ; String connector = SimpleStorageServlet . config . getString ( \"db.connector\" ) ; String url = SimpleStorageServlet . config . getString ( \"db.url\" ) ; String username = SimpleStorageServlet . config . getString ( \"db.username\" ) ; String password = SimpleStorageServlet . config . getString ( \"db.password\" ) ;", "del_tokens": "// database connection configuration // TODO put this into a configuration file. private static final String username = \"oryx\" ; private static final String password = \"\" ; private static final String url = \"jdbc:mysql://localhost/oryx\" ; private final String connector = \"com.mysql.jdbc.Driver\" ; ClassNotFoundException , SQLException {", "commit_type": "make"}
{"commit_tokens": ["Added", "fix", "in", "DAO", "to", "prevent", "exception", "when", "findOne", "returns", "null"], "add_tokens": "return dbObject != null ? map ( dbObject ) : null ; BasicDBObject dbObject = ( BasicDBObject ) collection ( ) . findOne ( new BasicDBObject ( query ) , new BasicDBObject ( fields ) ) ; return dbObject != null ? map ( dbObject ) : null ; BasicDBObject dbObject = ( BasicDBObject ) collection ( ) . findOne ( new BasicDBObject ( query ) ) ; return dbObject != null ? map ( dbObject ) : null ;", "del_tokens": "if ( dbObject == null ) { return null ; } else { return map ( dbObject ) ; } return map ( ( BasicDBObject ) collection ( ) . findOne ( new BasicDBObject ( query ) , new BasicDBObject ( fields ) ) ) ; return map ( ( BasicDBObject ) collection ( ) . findOne ( new BasicDBObject ( query ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "acl", "tests", "and", "setup", "test", "instance", "of", "consul", "to", "support", "acl", "testing"], "add_tokens": "@ WebIntegrationTest ( value = { \"spring.application.name=testConsulDiscovery\" , \"spring.cloud.consul.discovery.preferIpAddress=true\" } , randomPort = true )", "del_tokens": "@ WebIntegrationTest ( value = { \"spring.application.name=testConsulDiscovery\" , \"spring.cloud.consul.discovery.preferIpAddress=true\" } , randomPort = true )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "option", "to", "disable", "minutes", "picker", "(", "giving", "you", "an", "hours", "only", "picker", ")"], "add_tokens": "View . OnClickListener , private CheckBox enableMinutes ; enableMinutes = ( CheckBox ) findViewById ( R . id . enable_minutes ) ; // Check if picker mode is specified in Style.xml // Ensure a consistent state between enableSeconds and enableMinutes enableMinutes . setOnClickListener ( this ) ; enableSeconds . setOnClickListener ( this ) ; tpd . enableMinutes ( enableMinutes . isChecked ( ) ) ; @ Override public void onClick ( View view ) { if ( enableSeconds . isChecked ( ) && view . getId ( ) == R . id . enable_seconds ) enableMinutes . setChecked ( true ) ; if ( ! enableMinutes . isChecked ( ) && view . getId ( ) == R . id . enable_minutes ) enableSeconds . setChecked ( false ) ; }", "del_tokens": "// check if picker mode is specified in Style.xml", "commit_type": "implement"}
{"commit_tokens": ["Add", "the", "payload", "in", "the", "first", "digest", "attempt", "."], "add_tokens": "request . getUrl ( ) , request . getPayload ( ) ) , Void . class ) ;", "del_tokens": "request . getUrl ( ) ) , Void . class ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "Locale", ".", "ROOT", "for", "locale", "-", "neutral", "comparisons", "and", "conversions", "."], "add_tokens": "return osName != null && osName . toLowerCase ( Locale . ROOT ) . contains ( \"windows\" ) ; if ( diaPath . toLowerCase ( Locale . ROOT ) . endsWith ( DIA_EXTENSION ) ) {", "del_tokens": "return osName != null && osName . toLowerCase ( Locale . ENGLISH ) . contains ( \"windows\" ) ; if ( diaPath . toLowerCase ( Locale . ENGLISH ) . endsWith ( DIA_EXTENSION ) ) {", "commit_type": "use"}
{"commit_tokens": ["fix", "wrong", "use", "of", "putIfAbsent", "()"], "add_tokens": "getCache ( ) . putIfAbsent ( serviceName , super . getModelService ( serviceName ) ) ; service = getCache ( ) . get ( serviceName ) ; getMetadataKeyCache ( ) . putIfAbsent ( keyName , super . getModelMetadataKey ( keyName ) ) ; key = getMetadataKeyCache ( ) . get ( keyName ) ;", "del_tokens": "service = super . getModelService ( serviceName ) ; getCache ( ) . putIfAbsent ( serviceName , service ) ; key = super . getModelMetadataKey ( keyName ) ; getMetadataKeyCache ( ) . putIfAbsent ( keyName , key ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "name", "of", "archive", "files", "(", "from", "timestamp", "in", "milliseconds", "to", "something", "more", "human", "-", "readable", ")", "."], "add_tokens": "import java . text . SimpleDateFormat ; import java . util . Date ; SimpleDateFormat sdf = new SimpleDateFormat ( \"yyyyMMddHHmmss\" ) ; return \"structurizr-\" + workspaceId + \"-\" + sdf . format ( new Date ( ) ) + \".json\" ;", "del_tokens": "return \"structurizr-\" + workspaceId + \"-\" + System . currentTimeMillis ( ) + \".json\" ;", "commit_type": "change"}
{"commit_tokens": ["Implement", "$", "{}", "substitutions", "in", "the", "tokenizer"], "add_tokens": "START , END , COMMA , COLON , OPEN_CURLY , CLOSE_CURLY , OPEN_SQUARE , CLOSE_SQUARE , VALUE , NEWLINE , UNQUOTED_TEXT , SUBSTITUTION ;", "del_tokens": "START , END , COMMA , COLON , OPEN_CURLY , CLOSE_CURLY , OPEN_SQUARE , CLOSE_SQUARE , VALUE , NEWLINE , UNQUOTED_TEXT ;", "commit_type": "implement"}
{"commit_tokens": ["Remove", "redundant", "value", "=", "from", "annotation"], "add_tokens": "@ Ignore ( \"Travis CI failure; suspect older liblmdb version\" )", "del_tokens": "@ Ignore ( value = \"Travis CI failure; suspect older liblmdb version\" )", "commit_type": "remove"}
{"commit_tokens": ["changed", "the", "push", "instance", "id"], "add_tokens": "* @ param pushAppGUID The unique ID of the Push service instance that the application must connect to . public void initialize ( Context context , String pushAppGUID ) { if ( validateString ( pushAppGUID ) ) { applicationId = pushAppGUID ; * @ param pushAppGUID The unique ID of the Push service instance that the application must connect to . public void initialize ( Context context , String pushAppGUID , String pushClientSecret ) { if ( validateString ( pushClientSecret ) && validateString ( pushAppGUID ) ) { applicationId = pushAppGUID ;", "del_tokens": "* @ param pushInstanceId The unique ID of the Push service instance that the application must connect to . public void initialize ( Context context , String pushInstanceId ) { if ( validateString ( pushInstanceId ) ) { applicationId = pushInstanceId ; * @ param pushInstanceId The unique ID of the Push service instance that the application must connect to . public void initialize ( Context context , String pushInstanceId , String pushClientSecret ) { if ( validateString ( pushClientSecret ) && validateString ( pushInstanceId ) ) { applicationId = pushInstanceId ;", "commit_type": "change"}
{"commit_tokens": ["changing", "method", "name", "per", "sync", "up"], "add_tokens": "public abstract void shutdown ( SourceState state ) ;", "del_tokens": "public abstract void publishSourceMeta ( SourceState state ) ;", "commit_type": "change"}
{"commit_tokens": ["Upgraded", "all", "plugin", "versions", "increased", "minimum", "java", "to", "8", "and", "avoid"], "add_tokens": "private void checkInvalid ( ) { HollowNode < K , V > v = root ; if ( u . sp == null ) { // v is the only parent u . next = root ; root = u ; } else { // two parents if ( u . sp == v ) { // v is the second parent u . sp = null ; } else { // v is the first parent u . sp = null ; u . next = null ; } } } else { maxRank = Math . max ( maxRank , doRankedLinks ( u ) ) ; u . rank += 1 ; assert root == null ;", "del_tokens": "private void checkInvalid ( ) { HollowNode < K , V > v = root ; if ( u . sp == null ) { // v is the only parent u . next = root ; root = u ; } else { // two parents if ( u . sp == v ) { // v is the second parent u . sp = null ; } else { // v is the first parent u . sp = null ; u . next = null ; } } } else { maxRank = Math . max ( maxRank , doRankedLinks ( u ) ) ; u . rank += 1 ; assert root == null ;", "commit_type": "upgrade"}
{"commit_tokens": ["Removed", "use", "of", "depricated", "selenium", "AndroidDriver"], "add_tokens": "throw new WebDriverExtensionException ( \"Sorry! browserIsAndroid() is only \" + \"implemented for RemoteWebDriver at the moment.\" ) ;", "del_tokens": "import org . openqa . selenium . android . AndroidDriver ; } else if ( ThreadDriver . getDriver ( ) instanceof AndroidDriver ) { return true ; return false ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "wrong", "String", "comparison", "in", "EnclosedJsonRecordReader"], "add_tokens": "while ( token != null && ! ( token == JsonToken . START_ARRAY && parser . getCurrentName ( ) . equals ( \"features\" ) ) ) {", "del_tokens": "while ( token != null && ! ( token == JsonToken . START_ARRAY && parser . getCurrentName ( ) == \"features\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Change", "indeterminate", "progress", "bar", "animation", "to", "accelerating"], "add_tokens": "private static final int DEFAULT_SECTION_NUMBER = 5 ; private static final float MIN_WIDTH_DP = 256.0f ; /** Used to calculate the gap positions in a accelarate shape. */ @ Override public float getInterpolation ( float value ) { return value * value ; } } ; /** Used to calculate the gap positions in a accelarate/decelarate shape. */ // private Interpolator mInterpolator = new Interpolator() { // @Override public float getInterpolation(float value) { // if (value <= 0.5f) // return 2 * value * value; // float offset = value - 0.5f; // return 0.5f + (2*offset) - (2*offset*offset); // } // }", "del_tokens": "private static final int DEFAULT_SECTION_NUMBER = 6 ; private static final float MIN_WIDTH_DP = 64.0f ; /** Used to calculate the gap positions in a accelarate/decelarate shape. */ @ Override public float getInterpolation ( float value ) { if ( value <= 0.5f ) return 2 * value * value ; float offset = value - 0.5f ; return 0.5f + ( 2 * offset ) - ( 2 * offset * offset ) ; } } ;", "commit_type": "change"}
{"commit_tokens": ["Improves", "logging", "in", "workman", "and", "causes", "the", "process", "to", "exit", "when", "the", "work", "dir", "is", "not", "accessible", ".", "(", "These", "were", "changes", "that", "I", "made", "but", "accidentally", "did", "not", "push", "before", "Bill", "s", "last", "push", ")", "."], "add_tokens": "return new File ( configurationManager . getWorkDirectoryPath ( ) ) ;", "del_tokens": "File workDir ; String workDirPath = configurationManager . getWorkDirectoryPath ( ) ; if ( null != workDirPath ) { workDir = new File ( workDirPath ) ; } else { workDir = new File ( System . getProperty ( \"java.io.tmpdir\" ) , \"duplication-work\" ) ; } if ( ! workDir . exists ( ) ) { if ( ! workDir . mkdirs ( ) ) { throw new RuntimeException ( \"Unable to create work dir: \" + workDir . getAbsolutePath ( ) + \". Check that workman \" + \"process has permission to create this directory\" ) ; } } return workDir ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "async", "invocation", "example", "in", "README"], "add_tokens": "import com . aliyuncs . fc . constants . Const ; InvokeFunctionRequest invkReq = new InvokeFunctionRequest ( SERVICE_NAME , FUNCTION_NAME ) ; InvokeFunctionResponse invkResp = client . invokeFunction ( invkReq ) ; assertTrue ( ! Strings . isNullOrEmpty ( invkResp . getRequestId ( ) ) ) ; assertEquals ( \"hello world\" , new String ( invkResp . getContent ( ) ) ) ; // Invoke Function Async invkReq . setInvocationType ( Const . INVOCATION_TYPE_ASYNC ) ; invkResp = client . invokeFunction ( invkReq ) ; assertEquals ( HttpURLConnection . HTTP_ACCEPTED , invkResp . getStatus ( ) ) ;", "del_tokens": "InvokeFunctionRequest request = new InvokeFunctionRequest ( SERVICE_NAME , FUNCTION_NAME ) ; InvokeFunctionResponse response = client . invokeFunction ( request ) ; assertTrue ( ! Strings . isNullOrEmpty ( response . getRequestId ( ) ) ) ; assertEquals ( \"hello world\" , new String ( response . getContent ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "name", "of", "initializeBaseColors", "method", "to", "initBaseColors", "to", "be", "consistent", "."], "add_tokens": "initBaseColors ( ) ; private void initBaseColors ( ) {", "del_tokens": "initializeBaseColors ( ) ; private void initializeBaseColors ( ) {", "commit_type": "change"}
{"commit_tokens": ["allow", "a", "JSONArray", "to", "be", "used", "to", "create", "a", "Content", "to", "POST", "with"], "add_tokens": "import us . monoid . json . JSONArray ; * Create a content object from a JSON object . Use this to POST the content to a URL . * the JSON object to use / * * * Create a content object from a JSON array . Use this to POST the content to a URL . * * @ param someJson * the JSON array to use * @ return the content to send * / public static Content content ( JSONArray someJson ) { Content c = null ; try { c = new Content ( \"application/json; charset=UTF-8\" , someJson . toString ( ) . getBytes ( \"UTF-8\" ) ) ; } catch ( UnsupportedEncodingException e ) { /* UTF-8 is never unsupported */ } return c ; }", "del_tokens": "* Create a content object from JSON . Use this to POST the content to a URL . * the JSON to use", "commit_type": "allow"}
{"commit_tokens": ["fix", "issue", "with", "the", "peek", "view", "consuming", "click", "events"], "add_tokens": "return false ; return super . dispatchTouchEvent ( event ) ; public int getMoveThreshold ( ) { return MOVE_THRESHOLD ; }", "del_tokens": "return true ; return false ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "builder", "to", "create", "SoapMessage", "."], "add_tokens": "import javax . xml . soap . MessageFactory ; final SOAPMessage message = MessageFactory . newInstance ( ) . createMessage ( ) ;", "del_tokens": "import com . sun . xml . internal . messaging . saaj . soap . ver1_1 . Message1_1Impl ; final SOAPMessage message = new Message1_1Impl ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "getters", "so", "unit", "tests", "can", "be", "performed", "better", "in", "other", "modules"], "add_tokens": "public double getPercent ( ) { return percent ; } private final double percent ; public RequirementCoverage ( double percent ) { this . percent = percent / 100 ; / * double totalCount = context . getModel ( ) . getRequirements ( ) . size ( ) ; if ( 0 == totalCount ) { return 1.0 ; } double passedCount = context . getRequirements ( RequirementStatus . PASSED ) . size ( ) ; double failedCount = context . getRequirements ( RequirementStatus . FAILED ) . size ( ) ; return ( ( passedCount + failedCount ) / totalCount ) / limit ; * / return 0 ;", "del_tokens": "private final long limit ; public RequirementCoverage ( long limit ) { this . limit = limit ; throw new RuntimeException ( \"Not implemented, need to keep track of requirements\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Making", "center", "circle", "object", "more", "accessible", ".", "Adding", "fitToCenter", "feature"], "add_tokens": "// circularView.setAnimateMarkerOnHighlight(true);", "del_tokens": "circularView . setAnimateMarkerOnHighlight ( true ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "reference", "to", "base", ".", "X", "which", "the", "guava", "team", "does", "not", "plan", "on"], "add_tokens": "Preconditions . checkState ( inputs . size ( ) == list . size ( ) ) ;", "del_tokens": "import com . google . common . base . X ; X . assertTrue ( inputs . size ( ) == list . size ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "fromJson", "()", "method", "to", "all", "CSL", "model", "classes"], "add_tokens": "private String name ; / * * * Converts the given string to a $ name $ * @ param str the string * @ return the converted $ name $ * / public static $ name $ fromString ( String str ) { $ types : { t | if ( str . equals ( \"$t$\" ) ) { return $ t ; format = \"toEnum\" $ ; \\ } } $ throw new IllegalArgumentException ( \"Unknown $name$: \" + str ) ; }", "del_tokens": "private String name ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "paren", "typo", "in", "java", "."], "add_tokens": "if ( result != null && ( ( org . postgresql . ResultSet ) result ) . reallyResultSet ( ) )", "del_tokens": "if ( result != null ) && ( ( org . postgresql . ResultSet ) result . reallyResultSet ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "capability", "to", "manipulate", "prompt", "string"], "add_tokens": "public class ShellInformationProvider implements BannerProvider , HistoryFileNameProvider , PromptProvider , PromptManager { private static final String DEFAULT_PROMPT = \"perspective>\" ; private Optional < String > prompt = Optional . empty ( ) ; return prompt . isPresent ( ) ? prompt . get ( ) : DEFAULT_PROMPT ; } @ Override public void setPrompt ( String prompt ) { this . prompt = Optional . ofNullable ( prompt ) ; } @ Override public void resetPrompt ( ) { this . prompt = Optional . empty ( ) ;", "del_tokens": "public class ShellInformationProvider implements BannerProvider , HistoryFileNameProvider , PromptProvider { return \"perspective>\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "verifying", "deorbit", "callback"], "add_tokens": "import java . security . * ; public static boolean verifySignature ( String publicKeyIn , byte [ ] signatureIn , byte [ ] data ) throws Exception { PublicKey publicKey = getRSAPublicKeyFromString ( publicKeyIn ) ; Signature signature = Signature . getInstance ( \"SHA256withRSA\" , \"BC\" ) ; signature . initVerify ( publicKey ) ; signature . update ( data ) ; return signature . verify ( signatureIn ) ; }", "del_tokens": "import java . security . KeyFactory ; import java . security . PrivateKey ; import java . security . PublicKey ; import java . security . Security ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "equals", "and", "hashcode", "to", "DbCacheArg", "to", "avoid", "reloading", "value", "from", "API", "when", "argument", "did", "not", "change", "."], "add_tokens": "import javax . annotation . Nonnull ; public DbCacheArg ( ARG_TYPE arg , @ Nonnull FetchType fetchType ) { @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; DbCacheArg < ? > that = ( DbCacheArg < ? > ) o ; if ( ! arg . equals ( that . arg ) ) return false ; return fetchType == that . fetchType ; } @ Override public int hashCode ( ) { int result = arg . hashCode ( ) ; result = 31 * result + ( fetchType != null ? fetchType . hashCode ( ) : 0 ) ; return result ; }", "del_tokens": "public DbCacheArg ( ARG_TYPE arg , FetchType fetchType ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "the", "PATCH", "method"], "add_tokens": "GET , POST , PUT , DELETE , PATCH ;", "del_tokens": "GET , POST , PUT , DELETE ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "allow", "field", "state", "listeners", "modifications", "during", "informing", "them", "."], "add_tokens": "informStateListeners ( newState ) ; } private void informStateListeners ( FieldState newState ) { // Iterate over copy of listeners to guard against listeners modification. List < FieldStateListener > stateListeners = new ArrayList < FieldStateListener > ( fieldStateListeners ) ; for ( FieldStateListener fieldStateListener : stateListeners ) {", "del_tokens": "for ( FieldStateListener fieldStateListener : fieldStateListeners ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "special", "case", "for", "startsWith"], "add_tokens": "* assertTrue ( StringHelper . startsWith ( \"abc\" , \"\" ) ) ; assertTrue ( StringHelper . startsWith ( \"\" , \"\" ) ) ; assertFalse ( StringHelper . startsWith ( null , \"\" ) ) ;", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["added", "new", "events", "to", "ckeditor"], "add_tokens": "public static final String EVENT_INITIALIZED = \"initialized\" ; public static final String EVENT_BLUR = \"blur\" ; public static final String EVENT_FOCUS = \"focus\" ; Collections . unmodifiableCollection ( Arrays . asList ( EVENT_SAVE , EVENT_INITIALIZED , EVENT_BLUR , EVENT_FOCUS ) ) ;", "del_tokens": "Collections . unmodifiableCollection ( Arrays . asList ( EVENT_SAVE ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Moving", "equals", "/", "hashcode", "to", "bottom", "of", "classes", "."], "add_tokens": "@ Override public boolean equals ( Object other ) { if ( other == null ) return false ; if ( other instanceof AgigaCoref ) { AgigaCoref o = ( AgigaCoref ) other ; return Util . safeEquals ( mentions , o . mentions ) ; } return false ; } @ Override public int hashCode ( ) { return Util . safeHashCode ( mentions ) ; }", "del_tokens": "@ Override public boolean equals ( Object other ) { if ( other == null ) return false ; if ( other instanceof AgigaCoref ) { AgigaCoref o = ( AgigaCoref ) other ; return Util . safeEquals ( mentions , o . mentions ) ; } return false ; } @ Override public int hashCode ( ) { return Util . safeHashCode ( mentions ) ; }", "commit_type": "move"}
{"commit_tokens": ["Added", "the", "JaxMethodLocator", "so", "that", "the", "correct", "method", "reference", "can", "be", "found", "to", "get", "annotations", "from"], "add_tokens": "if ( hasAtLeastOneJaxRSAnnotation ( clazz . getDeclaredAnnotations ( ) ) ) { if ( hasAtLeastOneJaxRSAnnotation ( interfaceClass . getDeclaredAnnotations ( ) ) ) { static boolean hasAtLeastOneJaxRSAnnotation ( Annotation [ ] annotations ) {", "del_tokens": "import java . util . function . Function ; Function < Class < ? > , Boolean > selector = aClass -> hasAtLeastOneJaxRSAnnotation ( aClass . getDeclaredAnnotations ( ) ) ; if ( selector . apply ( clazz ) ) { if ( selector . apply ( interfaceClass ) ) { private static boolean hasAtLeastOneJaxRSAnnotation ( Annotation [ ] annotations ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "empty", "sketch", "SketchHex", "constructor"], "add_tokens": "private String sketchName = \"\" ; / * * * Initialize a SketchHex object with no data . * / public SketchHex ( ) { }", "del_tokens": "private String sketchName ;", "commit_type": "add"}
{"commit_tokens": ["Added", "assert", "statement", "for", "signedData", "version", "number", ".", "Fixes", "issue", "7", "."], "add_tokens": "final SignedData signedData ; signedData = new SignedData ( digestAlgorithms , contentInfo , certificates , crls , signerInfos ) ; assert ( signedData . getVersion ( ) . getValue ( ) . equals ( BigInteger . ONE ) ) ; ci = new ContentInfo ( CMSObjectIdentifiers . signedData , signedData ) ; final PkiMessageImpl msg = new PkiMessageImpl ( signedData ) ;", "del_tokens": "final SignedData sd ; sd = new SignedData ( digestAlgorithms , contentInfo , certificates , crls , signerInfos ) ; ci = new ContentInfo ( CMSObjectIdentifiers . signedData , sd ) ; final PkiMessageImpl msg = new PkiMessageImpl ( sd ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "TextWatcher", "not", "added", "to", "EditText"], "add_tokens": "setEditText ( editText ) ; if ( this . editText != null ) { this . editText . removeTextChangedListener ( getTextWatcher ( ) ) ; }", "del_tokens": "this . editText = editText ; this . editText . removeTextChangedListener ( getTextWatcher ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "$CALIPERRC", "instead", "of", "~", "/", ".", "caliperrc", "if", "set", "."], "add_tokens": "String caliperRcEnvVar = System . getenv ( \"CALIPERRC\" ) ; File caliperRcFile = ( caliperRcEnvVar == null ) ? new File ( System . getProperty ( \"user.home\" ) , \".caliperrc\" ) : new File ( caliperRcEnvVar ) ; if ( caliperRcFile . exists ( ) ) { properties . load ( new FileInputStream ( caliperRcFile ) ) ;", "del_tokens": "File dotCaliperRc = new File ( System . getProperty ( \"user.home\" ) , \".caliperrc\" ) ; if ( dotCaliperRc . exists ( ) ) { properties . load ( new FileInputStream ( dotCaliperRc ) ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "new", "test", "cases", "for", "DynamicDataStore"], "add_tokens": "while ( ! _serviceQueue . isEmpty ( ) ) Entry < T > entry = _serviceQueue . poll ( ) ; if ( entry != null ) addToRecycleQueue ( entry ) ;", "del_tokens": "while ( true ) Entry < T > entry = pollFromService ( ) ; if ( entry == null ) break ; addToRecycleQueue ( entry ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "get", "status", "to", "reflect", "android", "platform", "and", "locale", "as", "well"], "add_tokens": "import java . util . Locale ; build . addProperty ( \"version\" , \"0.2\" ) ; os . addProperty ( \"arch\" , android . os . Build . CPU_ABI ) ; os . addProperty ( \"name\" , \"Android\" ) ; os . addProperty ( \"version\" , android . os . Build . VERSION . SDK_INT ) ; os . addProperty ( \"locale\" , Locale . getDefault ( ) . toString ( ) ) ;", "del_tokens": "build . addProperty ( \"version\" , \"0.1-snapshot\" ) ; os . addProperty ( \"arch\" , System . getProperty ( \"os.arch\" ) ) ; os . addProperty ( \"name\" , System . getProperty ( \"os.name\" ) ) ; os . addProperty ( \"version\" , System . getProperty ( \"os.version\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "integration", "test", "for", "subject", "in", "text", "template"], "add_tokens": "@ Test public void subjectInTextTemplate ( ) throws NotificationException , MessagingException , IOException { notificationService . send ( new Email ( null , new TemplateContent ( \"classpath:/template/thymeleaf/source/withSubject.txt\" , new SimpleBean ( \"foo\" , 42 ) ) , \"recipient@sii.fr\" ) ) ; AssertEmail . assertSimilar ( new ExpectedEmail ( \"Subject on first line\" , new ExpectedContent ( getClass ( ) . getResourceAsStream ( \"/template/thymeleaf/expected/simple_foo_42.txt\" ) , \"text/plain.*\" ) , \"test.sender@sii.fr\" , \"recipient@sii.fr\" ) , greenMail . getReceivedMessages ( ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "note", "about", "reusing", "the", "Client", "since", "creating", "the", "Jersey", "Client", "is", "slow", "."], "add_tokens": "import org . t3as . snomedct . service . AnalysisRequest ; * method can and should be reused repeatedly , since creating the Jersey Client is a relatively time consuming * operation .", "del_tokens": "import org . t3as . snomedct . service . AnalysisRequest ; * method can be reused repeatedly .", "commit_type": "add"}
{"commit_tokens": ["changed", "init", "to", "restart", "so", "that", "callbacks", "can", "be", "used", "more", "than", "once"], "add_tokens": "lm . restartLoader ( loaderId , null , lm . restartLoader ( loaderId , null ,", "del_tokens": "lm . initLoader ( loaderId , null , lm . initLoader ( loaderId , null ,", "commit_type": "change"}
{"commit_tokens": ["Making", "BitUtils", ".", "ulpDistance", "(", "double", "double", ")", "save", "."], "add_tokens": "* @ version $ Id : Statistic . java , v 1.5 2008 - 04 - 23 12 : 08 : 25 fwilhelm Exp $ boolean equals = false ; try { equals = Math . abs ( BitUtils . ulpDistance ( a , b ) ) <= ulpDistance ; } catch ( ArithmeticException e ) { } return equals ;", "del_tokens": "* @ version $ Id : Statistic . java , v 1.4 2008 - 04 - 23 08 : 18 : 52 fwilhelm Exp $ return BitUtils . ulpDistance ( a , b ) <= ulpDistance ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "minor", "issues", "and", "added", "post", "+", "comment", "example", "files"], "add_tokens": "if ( ! bReader . ready ( ) ) if ( line == null || line . isEmpty ( ) )", "del_tokens": "if ( ! reader . ready ( ) ) if ( line == null )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "getChildren", "()", "method", "of", "GitDirectory", "using", "ls", ".", "Probably", "temporary", "solution", "but", "it", "works"], "add_tokens": "public List < GitFileSystemObject > getTree ( ) throws IOException {", "del_tokens": "public List < GitFileSystemObject > getTree ( ) {", "commit_type": "implement"}
{"commit_tokens": ["Allow", "predefine", "default", "state", "strategy", "."], "add_tokens": "import java . util . Map ; private static Map < String , String > sOptions ; sOptions = processingEnv . getOptions ( ) ; ViewStateClassGenerator viewStateClassGenerator = new ViewStateClassGenerator ( sOptions ) ;", "del_tokens": "ViewStateClassGenerator viewStateClassGenerator = new ViewStateClassGenerator ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "resources", "into", "an", "array", "to", "save", "my", "eyes", "."], "add_tokens": "/** Assets which need to be copied to the output directory when generating HTML. */ private static final String [ ] ASSETS = { \"bootstrap.min.css\" , \"bootstrap.min.js\" , \"jquery.min.js\" , \"lightbox.js\" , \"spoon.css\" , \"lightbox.css\" , \"loading.gif\" , \"next.png\" , \"prev.png\" , \"close.png\" , \"jquery-ui-1.8.18.custom.min.js\" , \"jquery.smooth-scroll.min.js\" } ; for ( String asset : ASSETS ) { copyResourceToOutput ( asset , output ) ; }", "del_tokens": "copyResourceToOutput ( \"bootstrap.min.css\" , output ) ; copyResourceToOutput ( \"bootstrap.min.js\" , output ) ; copyResourceToOutput ( \"jquery.min.js\" , output ) ; copyResourceToOutput ( \"lightbox.js\" , output ) ; copyResourceToOutput ( \"spoon.css\" , output ) ; copyResourceToOutput ( \"lightbox.css\" , output ) ; copyResourceToOutput ( \"loading.gif\" , output ) ; copyResourceToOutput ( \"next.png\" , output ) ; copyResourceToOutput ( \"prev.png\" , output ) ; copyResourceToOutput ( \"close.png\" , output ) ; copyResourceToOutput ( \"jquery-ui-1.8.18.custom.min.js\" , output ) ; copyResourceToOutput ( \"jquery.smooth-scroll.min.js\" , output ) ;", "commit_type": "move"}
{"commit_tokens": ["Update", "to", "adapt", "to", "assertion", "sentences", "now", "returning", "void"], "add_tokens": "private Sentence < FrankClient , Void > waitUntil ( FrankClient frank ) {", "del_tokens": "private Sentence < FrankClient , Boolean > waitUntil ( FrankClient frank ) {", "commit_type": "update"}
{"commit_tokens": ["Makes", "IonRawBinaryWriter", "s", "currentFieldSid", "an", "int", "primitive", "instead", "of", "an", "Integer", "cutting", "down", "on", "allocations", "and", "garbage", "caused", "by", "autoboxing", "."], "add_tokens": "private static final int SID_UNASSIGNED = - 1 ; private int currentFieldSid ; this . currentFieldSid = SID_UNASSIGNED ; return currentFieldSid > SID_UNASSIGNED ; if ( isInStruct ( ) && currentFieldSid <= SID_UNASSIGNED ) if ( currentFieldSid > SID_UNASSIGNED ) currentFieldSid = SID_UNASSIGNED ; if ( currentFieldSid > SID_UNASSIGNED )", "del_tokens": "private Integer currentFieldSid ; this . currentFieldSid = null ; return currentFieldSid != null ; if ( isInStruct ( ) && currentFieldSid == null ) if ( currentFieldSid != null ) currentFieldSid = null ; if ( currentFieldSid != null )", "commit_type": "make"}
{"commit_tokens": ["Add", "importexport", "info", "to", "todo", "sync", "example"], "add_tokens": "new ServerApiKeyCredential ( getString ( R . string . stitch_user1_api_key ) ) )", "del_tokens": "new ServerApiKeyCredential ( \"xEfxAP4jFWaWEs5WWpff7XyQMh1T56CCMmDEV9oxXtItPHBveA6bc6IEjOhQLes6\" ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "property", ":", "pixelatedZoom", "."], "add_tokens": "private boolean pixelatedZoom = false ; public void setPixelatedZoom ( boolean pixelatedZoom ) { if ( pixelatedZoom == this . pixelatedZoom ) return ; this . pixelatedZoom = pixelatedZoom ; repaint ( ) ; propertyChangeSupport . firePropertyChange ( \"pixelatedZoom\" , ! pixelatedZoom , pixelatedZoom ) ; } public boolean isPixelatedZoom ( ) { return pixelatedZoom ; } AffineTransform imageTransform = getImageTransform ( ) ; if ( pixelatedZoom && ( imageTransform . getScaleX ( ) >= 1 || imageTransform . getScaleY ( ) >= 1 ) ) { g . setRenderingHint ( RenderingHints . KEY_INTERPOLATION , RenderingHints . VALUE_INTERPOLATION_NEAREST_NEIGHBOR ) ; } else { g . setRenderingHint ( RenderingHints . KEY_INTERPOLATION , RenderingHints . VALUE_INTERPOLATION_BICUBIC ) ; } g . transform ( imageTransform ) ;", "del_tokens": "g . setRenderingHint ( RenderingHints . KEY_INTERPOLATION , RenderingHints . VALUE_INTERPOLATION_BICUBIC ) ; g . transform ( getImageTransform ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "code", "to", "use", "boolean", ".", "parseBoolean", "method", "instead", "of", "string", "comparison"], "add_tokens": "private boolean skipProviderHeirarchy ; this . skipProviderHeirarchy = Boolean . parseBoolean ( this . dictSection . get ( \"skipProviderHierarchy\" ) ) ; if ( ! this . skipProviderHeirarchy ) { if ( ! this . skipProviderHeirarchy ) {", "del_tokens": "import java . util . HashMap ; private final String loadProviderHeirarchy ; this . loadProviderHeirarchy = this . dictSection . get ( \"loadProvidersTree\" ) ; if ( this . loadProviderHeirarchy == null || this . loadProviderHeirarchy . equalsIgnoreCase ( \"true\" ) ) { if ( this . loadProviderHeirarchy == null || this . loadProviderHeirarchy . equalsIgnoreCase ( \"true\" ) ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "JSON", "writer", "for", "excluded", "creatives"], "add_tokens": "ImpExt . ExcludedCreative . Builder exCreat = ImpExt . ExcludedCreative . newBuilder ( ) ; readExcludedCreativeField ( par , exCreat , fieldName ) ; return exCreat ; protected void readExcludedCreativeField ( JsonParser par , ImpExt . ExcludedCreative . Builder exCreat , String fieldName ) exCreat . setBuyerCreativeId ( par . getText ( ) ) ;", "del_tokens": "import com . google . doubleclick . AdxExt . BidExt . EventNotificationToken ; ImpExt . ExcludedCreative . Builder excludedCreative = ImpExt . ExcludedCreative . newBuilder ( ) ; readExcludedCreativeField ( par , excludedCreative , fieldName ) ; return excludedCreative ; protected void readExcludedCreativeField ( JsonParser par , ImpExt . ExcludedCreative . Builder excludedCreative , String fieldName ) excludedCreative . setBuyerCreativeId ( par . getText ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "verify", "device", "over", "serial", "port", "is", "a", "Firmata", "device", ".", "Including", "support", "in", "configuration", "to", "turn", "it", "off", "if", "needed", "."], "add_tokens": "/ * * * Try to talk to the board and verify that it is responding in a Firmata protocol . * Do this by requesting protocol version and checking the response . * / private Boolean testProtocolCommunication = true ; testProtocolCommunication = configuration . testProtocolCommunication ; / * * * Try to talk to the board and verify that it is responding in a Firmata protocol . * Do this by requesting protocol version and checking the response . * / public Boolean getTestProtocolCommunication ( ) { return testProtocolCommunication ; } / * * * Try to talk to the board and verify that it is responding in a Firmata protocol . * Do this by requesting protocol version and checking the response . * * @ param testProtocolCommunication Boolean true to run the test on start . False to disable the test . * / public void setTestProtocolCommunication ( Boolean testProtocolCommunication ) { this . testProtocolCommunication = testProtocolCommunication ; } * Convert the configuration to a string , for loggers , etc . \", testProtocolCommunication=\" + testProtocolCommunication +", "del_tokens": "* Convert the cofiguration to a string , for loggers , etc .", "commit_type": "add"}
{"commit_tokens": ["Updating", "the", "AttributeMixin", "to", "have", "a", "check", "for", "attributes"], "add_tokens": "return attributeMixin . hasAttribute ( MULTIPLE ) ;", "del_tokens": "return attributeMixin . getAttribute ( MULTIPLE ) != null && attributeMixin . getAttribute ( MULTIPLE ) . equals ( TRUE ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "track", "test", "for", "invalid", "tracking", "number"], "add_tokens": "@ Test Track track = Track . getTrackingInfo ( carrier , \"invalid\" , null ) ; assertEquals ( track . getCarrier ( ) , carrier ) ; assertEquals ( track . getTrackingNumber ( ) , \"invalid\" ) ; assertEquals ( track . getTrackingStatus ( ) , null ) ;", "del_tokens": "@ Test ( expected = InvalidRequestException . class ) Track . getTrackingInfo ( carrier , \"invalid\" , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "displaying", "list", "of", "available", "WiFi", "access", "points"], "add_tokens": "import android . net . wifi . ScanResult ; import java . util . List ; private static WifiManager getWifiManager ( Context context ) { return ( WifiManager ) context . getSystemService ( Context . WIFI_SERVICE ) ; } return getWifiManager ( context ) . getConnectionInfo ( ) ; } public static List < ScanResult > getAccessPointList ( Context context ) { return getWifiManager ( context ) . getScanResults ( ) ;", "del_tokens": "WifiManager wifiManager = ( WifiManager ) context . getSystemService ( Context . WIFI_SERVICE ) ; return wifiManager . getConnectionInfo ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "Sh", "-", "Server", "bug", "."], "add_tokens": "return this . messageFactory . createUserDataAnswer ( userData ) ;", "del_tokens": "return createUserDataAnswer ( userData ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "API", "retries", "from", "3", "to", "10"], "add_tokens": "private static final int API_RETRIES = 10 ;", "del_tokens": "private static final int API_RETRIES = 3 ;", "commit_type": "change"}
{"commit_tokens": ["using", "different", "maven", "launch4j", "plugin"], "add_tokens": "package com . github . riccardove . easyjasub . html2image ; / * * # % L * easyjasub - lib * % % * Copyright ( C ) 2014 Riccardo Vestrini * % % * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * # L % * /", "del_tokens": "package com . github . riccardove . easyjasub . html2image ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "Recycler", "(", "incorrect", "use", "of", "key", "and", "index", ")"], "add_tokens": "@ TargetApi ( Build . VERSION_CODES . ICE_CREAM_SANDWICH ) if ( Build . VERSION . SDK_INT >= 14 ) { scrap . setAccessibilityDelegate ( null ) ; } @ TargetApi ( Build . VERSION_CODES . HONEYCOMB ) View result = scrapViews . get ( position , null ) ; if ( result != null ) { scrapViews . remove ( position ) ; return result ; result = scrapViews . valueAt ( index ) ; if ( Build . VERSION . SDK_INT >= 11 ) { scrapViews . removeAt ( index ) ; } else { scrapViews . remove ( scrapViews . keyAt ( index ) ) ; } return result ; return null ;", "del_tokens": "scrap . setAccessibilityDelegate ( null ) ; for ( int i = 0 ; i < size ; i ++ ) { View view = scrapViews . get ( i ) ; int fromPosition = scrapViews . keyAt ( i ) ; if ( fromPosition == position ) { scrapViews . remove ( i ) ; return view ; } View r = scrapViews . valueAt ( index ) ; scrapViews . removeAt ( index ) ; return r ; } else { return null ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "movie", "recording", "function", "and", "dependency"], "add_tokens": "import com . jogamp . opengl . util . texture . awt . AWTTextureIO ;", "del_tokens": "import com . jogamp . opengl . util . texture . TextureData ; import com . jogamp . opengl . util . texture . awt . * ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "performance", "problem", "in", "LinkedHashMultimap", ".", "removeAll", "(", "key", ")", "as", "documented", "in", "http", ":", "//", "code", ".", "google", ".", "com", "/", "p", "/", "guava", "-", "libraries", "/", "issues", "/", "detail?id", "=", "371&start", "=", "100"], "add_tokens": "for ( V value : delegate ) { linkedEntries . remove ( createEntry ( value ) ) ; }", "del_tokens": "linkedEntries . removeAll ( createEntries ( delegate ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "an", "int", "overflow", "bug"], "add_tokens": "// Get absolute value of current val to ensure correctness even at 9 quintillion+ requests final long currentVal = Math . abs ( numberOfModOps . incrementAndGet ( ) ) ; // make sure to truncate after the mod. This allows up to 2^31 clients. final int index = ( int ) ( currentVal % clients . size ( ) ) ;", "del_tokens": "final long currentVal = numberOfModOps . incrementAndGet ( ) ; final int index = ( int ) currentVal % clients . size ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "type", "of", "UVIndexTime", "attribute", "."], "add_tokens": "private Instant uvIndexTime ; public Instant getUvIndexTime ( ) { public void setUvIndexTime ( Instant uvIndexTime ) {", "del_tokens": "private Integer uvIndexTime ; public Integer getUvIndexTime ( ) { public void setUvIndexTime ( Integer uvIndexTime ) {", "commit_type": "fix"}
{"commit_tokens": ["implement", "human", "readable", "json", "generation", "."], "add_tokens": "import com . google . gson . Gson ; import com . google . gson . GsonBuilder ; import com . google . gson . JsonElement ; import com . google . gson . JsonParser ; import com . google . protobuf . DescriptorProtos ; private final JsonParser parser ; private final Gson gson ; this . parser = new JsonParser ( ) ; this . gson = new GsonBuilder ( ) . setPrettyPrinting ( ) . create ( ) ; String jsonString = JsonFormat . printToString ( transformer . transform ( data ) ) ; // System.out.println(\"### pre: \" + jsonString); // System.out.println(\"######################\"); // format JsonElement el = parser . parse ( jsonString ) ; jsonString = gson . toJson ( el ) ; // System.out.println(\"### after: \" + jsonString); // System.out.println(\"######################\"); //write FileUtils . writeStringToFile ( file , jsonString , \"UTF-8\" ) ; return transformer . transform ( ( M ) builder . build ( ) ) ;", "del_tokens": "FileUtils . writeStringToFile ( file , JsonFormat . printToString ( transformer . transform ( data ) ) ) ; return transformer . transform ( ( M ) builder . build ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Use", "FileDescriptor", ".", "in", "for", "the", "ConsoleReader", "."], "add_tokens": "ConsoleReader reader = new ConsoleReader ( new FileInputStream ( FileDescriptor . in ) , new PrintWriter ( System . out ) ) ; if ( buf != null && buf . startsWith ( COMMAND_PREFIX ) && ! buf . startsWith ( COMMAND_PREFIX + \"all\" ) && ! buf . startsWith ( COMMAND_PREFIX + \"sql\" ) )", "del_tokens": "ConsoleReader reader = new ConsoleReader ( ) ; if ( buf != null && buf . startsWith ( COMMAND_PREFIX ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "defaultPropagation", "to", "toString", "of", "Database", "."], "add_tokens": "return \"Database [dialect=\" + dialect + \", allowImplicitTransactions=\" + allowImplicitTransactions + \", defaultIsolation=\" + defaultIsolation + \", defaultPropagation=\" + defaultPropagation + ']' ;", "del_tokens": "return \"Database [dialect=\" + dialect + \", allowImplicitTransactions=\" + allowImplicitTransactions + \", defaultIsolation=\" + defaultIsolation + ']' ;", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "@Name", "annotation", "into", "sub", "-", "package", "."], "add_tokens": "package de . bit3 . jsass . annotation ;", "del_tokens": "package de . bit3 . jsass ;", "commit_type": "move"}
{"commit_tokens": ["fix", "build", "test", "failed", "issue"], "add_tokens": "apiSource . setOutputTemplate ( \"https://raw.github.com/kongchen/api-doc-template/master/v1.1/markdown.mustache\" ) ;", "del_tokens": "apiSource . setOutputTemplate ( \"https://raw.github.com/kongchen/api-doc-template/master/v1.1/strapdown.html\" + \".mustache\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "parts", "method", "and", "part", "name"], "add_tokens": "import java . util . Iterator ; return formData == null ? new Part ( ) : new Part ( formData . getFirst ( partName ) , partName ) ; formValues . forEach ( p -> parts . add ( new Part ( p , partName ) ) ) ; return parts ; } public List < Part > parts ( ) { Iterator < String > iterator = formData . iterator ( ) ; List < Part > parts = new ArrayList < > ( ) ; while ( iterator . hasNext ( ) ) { String next = iterator . next ( ) ; Deque < FormData . FormValue > formValues = formData . get ( next ) ; for ( FormData . FormValue value : formValues ) { parts . add ( new Part ( value , next ) ) ; } }", "del_tokens": "return formData == null ? new Part ( ) : new Part ( formData . getFirst ( partName ) ) ; formValues . forEach ( p -> parts . add ( new Part ( p ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "zero", "-", "filled", "payload", "for", "UNCOMPRESSED", "."], "add_tokens": "this . compressableBuffer = ByteString . copyFrom ( new byte [ 1024 ] ) ;", "del_tokens": "private static final String COMPRESSABLE_FILE = \"/com/google/net/stubby/testing/integration/testdata/compressable.txt\" ; this . compressableBuffer = createBufferFromFile ( COMPRESSABLE_FILE ) ;", "commit_type": "use"}
{"commit_tokens": ["using", "ApacheHttpClient4", "too", "get", "rid", "of", "dependency", "to", "deprecated", "org", ".", "apache", ".", "commons", ".", "httpclient", ".", "HttpClient"], "add_tokens": "final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ; final HMACJerseyClient client = HMACJerseyClient . create ( ) ;", "del_tokens": "import com . sun . jersey . client . apache . config . DefaultApacheHttpClientConfig ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ; final HMACJerseyClient client = HMACJerseyClient . create ( new DefaultApacheHttpClientConfig ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "method", "to", "clear", "cached", "executor", "reference", "."], "add_tokens": "/ * * * Clears any cached reference to a query executor . The next time this * Query is used , it will get an executor from getExecutor and cache a * reference to it . * / protected void clearExecutorReference ( ) { mExecutor = null ; } * Return a new or cached query executor .", "del_tokens": "* Return a new or cached executor .", "commit_type": "add"}
{"commit_tokens": ["Changed", "sleep", "()", "to", "thread", ".", "join", "()"], "add_tokens": "// $Id: ChannelMonoTest.java,v 1.2 2003/09/19 16:17:12 belaban Exp $ mythread . join ( ) ;", "del_tokens": "// $Id: ChannelMonoTest.java,v 1.1 2003/09/18 09:52:56 rds13 Exp $ Util . sleep ( 2000 ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "CollectionUtil", ".", "sortByValue", "()"], "add_tokens": "\"1.5.5\" ) ;", "del_tokens": "\"1.5.4\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "time", "support", "for", "instagram"], "add_tokens": "return getValueForDate ( params , key , describeService ) ; } else { return params . getValueForParam ( key ) ; } } protected String getValueForDate ( ServiceParams params , String key , DescribeService describeService ) throws POIProxyException { SimpleDateFormat sdf = new SimpleDateFormat ( DATE_FORMAT ) ; try { if ( describeService . getDateFormat ( ) . compareTo ( DescribeService . TIMESTAMP ) == 0 ) { return sdf . parse ( params . getValueForParam ( key ) ) . getTime ( ) + \"\" ; } else { SimpleDateFormat outsdf = new SimpleDateFormat ( describeService . getDateFormat ( ) ) ; } catch ( ParseException e ) { logger . warn ( e ) ; throw new POIProxyException ( \"Error with dates\" ) ;", "del_tokens": "SimpleDateFormat sdf = new SimpleDateFormat ( DATE_FORMAT ) ; SimpleDateFormat outsdf = new SimpleDateFormat ( describeService . getDateFormat ( ) ) ; try { } catch ( ParseException e ) { logger . warn ( e ) ; throw new POIProxyException ( \"Error with dates\" ) ; } else { return params . getValueForParam ( key ) ;", "commit_type": "add"}
{"commit_tokens": ["improved", "error", "message", ";", "fix", "http", "node", "names"], "add_tokens": "writer . write ( \"<html><body><h1>\" + e . getMessage ( ) + \"</h1>\" ) ; writer . write ( \"<details><br/>\" ) ; printException ( e , writer ) ; writer . write ( \"</body></html>\" ) ; private void printException ( Throwable e , Writer writer ) throws IOException { writer . write ( \"type: \" + e . getClass ( ) + \"<br/>\\n\" ) ; writer . write ( \"message: \" + e . getMessage ( ) + \"<br/>\\n\" ) ; for ( StackTraceElement element : e . getStackTrace ( ) ) { writer . write ( \" \" + element . toString ( ) + \"<br/>\\n\" ) ; } if ( e . getCause ( ) != null && e . getCause ( ) != e ) { writer . write ( \"<br/>\\n\" ) ; writer . write ( \"... cause by ... <br/>\\n\" ) ; writer . write ( \"<br/>\\n\" ) ; printException ( e . getCause ( ) , writer ) ; } }", "del_tokens": "writer . write ( \"<html><body><h1>\" + e . getMessage ( ) + \"</h1></body></html>\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "the", "problem", "of", "missing", "cap", "of", "cylinder", "."], "add_tokens": "double theta0 = ( ( double ) ( slice ) / sliceNumber ) * 2.0 * Math . PI ; double theta1 = ( ( double ) ( slice + 1 ) / sliceNumber ) * 2.0 * Math . PI ;", "del_tokens": "double theta0 = ( ( slice ) / sliceNumber ) * 2.0 * Math . PI ; double theta1 = ( ( slice + 1 ) / sliceNumber ) * 2.0 * Math . PI ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "coding", "rules", "violations"], "add_tokens": "if ( obj == null ) return false ; if ( obj == this ) return true ; if ( obj . getClass ( ) != getClass ( ) ) return false ; return ( groupId == null ) ? ( other . groupId == null ) : groupId . equals ( other . groupId ) && ( ( artifactId == null ) ? ( other . artifactId == null ) : artifactId . equals ( other . artifactId ) ) && ( ( version == null ) ? ( other . version == null ) : version . equals ( other . version ) ) ;", "del_tokens": "if ( obj == null ) { return false ; } if ( obj == this ) { return true ; } if ( obj . getClass ( ) != getClass ( ) ) { return false ; } boolean isEqual = ( groupId == null ) ? ( other . groupId == null ) : groupId . equals ( other . groupId ) ; isEqual = isEqual && ( ( artifactId == null ) ? ( other . artifactId == null ) : artifactId . equals ( other . artifactId ) ) ; isEqual = isEqual && ( ( version == null ) ? ( other . version == null ) : version . equals ( other . version ) ) ; return isEqual ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "GDE", "-", "3", "for", "MOEA"], "add_tokens": "protected int currentGeneration = 0 ; protected NondominatedSortingPopulation population = new NondominatedSortingPopulation ( ) ; protected void evaluate ( Population population ) {", "del_tokens": "private int currentGeneration = 0 ; private NondominatedSortingPopulation population = new NondominatedSortingPopulation ( ) ; private void evaluate ( Population population ) {", "commit_type": "implement"}
{"commit_tokens": ["fixed", "name", "attribute", "to", "id"], "add_tokens": "super . println ( \"<a id=\\\"\" + name + \"\\\"></a>\" ) ;", "del_tokens": "super . println ( \"<a name=\\\"\" + name + \"\\\"/>\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "empty", "region", "integration", "test", "."], "add_tokens": "@ Test public void testEmptyRegion ( ) throws IOException , GeneralSecurityException { ImmutableList < StreamVariantsRequest > requests = ShardUtils . getVariantRequests ( helper . PLATINUM_GENOMES_VARIANTSET , \"chrDoesNotExist:100:200\" , 100L ) ; assertEquals ( 1 , requests . size ( ) ) ; Iterator < StreamVariantsResponse > iter = VariantStreamIterator . enforceShardBoundary ( requests . get ( 0 ) , helper . getAuth ( ) , ShardBoundary . Requirement . OVERLAPS , null ) ; assertFalse ( iter . hasNext ( ) ) ; iter = VariantStreamIterator . enforceShardBoundary ( requests . get ( 0 ) , helper . getAuth ( ) , ShardBoundary . Requirement . STRICT , null ) ; assertFalse ( iter . hasNext ( ) ) ; } // TODO test a shard where the entire first result will be empty due to the strict shard boundary requirement. Same for reads.", "del_tokens": "// TODO test a shard where the entire first result will be empty due to the strict shard boundary requirement. Same for reads.", "commit_type": "add"}
{"commit_tokens": ["added", "some", "final", "modifiers", "to", "AbstractObjective"], "add_tokens": "public final boolean isMinimizing ( ) { public final void setMinimizing ( ) { public final void setMaximizing ( ) {", "del_tokens": "public boolean isMinimizing ( ) { public void setMinimizing ( ) { public void setMaximizing ( ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "CrossSiteIframeLinker", "which", "supports", "dev", "mode", "instead", "of", "deprecated", "XSLinker"], "add_tokens": "import com . google . gwt . core . linker . CrossSiteIframeLinker ; public class AppCacheLinker extends CrossSiteIframeLinker {", "del_tokens": "import com . google . gwt . core . linker . XSLinker ; public class AppCacheLinker extends XSLinker {", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "non", "-", "https", "protocols", "in", "host"], "add_tokens": "import java . net . MalformedURLException ; import java . net . URL ; * @ throws MojoExecutionException protected GitHubClient createClient ( String hostname ) throws MojoExecutionException { if ( ! hostname . contains ( \"://\" ) ) return new GitHubClient ( hostname ) ; try { URL hostUrl = new URL ( hostname ) ; return new GitHubClient ( hostUrl . getHost ( ) , hostUrl . getPort ( ) , hostUrl . getProtocol ( ) ) ; } catch ( MalformedURLException e ) { throw new MojoExecutionException ( \"Could not parse host URL \" + hostname ) ; }", "del_tokens": "protected GitHubClient createClient ( String hostname ) { return new GitHubClient ( hostname ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "that", "window", "start", "and", "end", "are", "equal", "in", "GCM", "API"], "add_tokens": "long startSeconds = Common . getStartMs ( request ) / 1_000 ; long endSeconds = Math . max ( Common . getEndMs ( request ) / 1_000 , startSeconds + 1 ) ; . setExecutionWindow ( startSeconds , endSeconds )", "del_tokens": ". setExecutionWindow ( Common . getStartMs ( request ) / 1_000 , Common . getEndMs ( request ) / 1_000 )", "commit_type": "fix"}
{"commit_tokens": ["Moving", "tests", "to", "proper", "packages"], "add_tokens": "package com . jnape . palatable . lambda . traversable ;", "del_tokens": "package spike ; import com . jnape . palatable . lambda . traversable . TraversableIterable ;", "commit_type": "move"}
{"commit_tokens": ["Add", "a", "test", "for", "registry", "translation", "...", "and", "now", "it", "works", "...", "when", "a", "listener", "is", "added", "events", "for", "existing", "metrics", "are", "issued", "."], "add_tokens": "//When this listener is added, it is notified of all existing metrics.", "del_tokens": "import com . codahale . metrics . Metric ; import java . util . Map ; final Map < String , Metric > metrics = registry . getMetrics ( ) ; for ( String name : kvProps . stringPropertyNames ( ) ) { String translateName = kvProps . getProperty ( name ) ; Metric metric = metrics . get ( name ) ; if ( metric != null ) { translateRegistry . remove ( translateName ) ; translateRegistry . register ( translateName , metric ) ; } }", "commit_type": "add"}
{"commit_tokens": ["add", "more", "tests", "and", "javadoc", "for", "queries"], "add_tokens": "public B setNull ( String name ) { properties . put ( name , of ( ) ) ; return self ( ) ; }", "del_tokens": "public B setNull ( String name ) { properties . put ( name , of ( ) ) ; return self ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "throws", "to", "Swift", "deserialization", "functions"], "add_tokens": "//SwiftyJSON.toTryGetAccessor()", "del_tokens": "//SwiftyJSON.toGetAccessor()", "commit_type": "add"}
{"commit_tokens": ["added", "a", "finally", "block", "to", "ensure", "that", "the", "InputStream", "is", "closed", "if", "an", "exception", "is", "raised"], "add_tokens": "public static Document getEventDocFromUrl ( String url ) throws IOException , ParserConfigurationException , SAXException { Document doc = null ; InputStream in = null ; try { String webPage = WebBrowser . request ( url ) ; in = new ByteArrayInputStream ( webPage . getBytes ( \"UTF-8\" ) ) ; DocumentBuilderFactory dbf = DocumentBuilderFactory . newInstance ( ) ; DocumentBuilder db = dbf . newDocumentBuilder ( ) ; doc = db . parse ( in ) ; doc . getDocumentElement ( ) . normalize ( ) ; } finally { if ( in != null ) { in . close ( ) ; } }", "del_tokens": "import java . io . UnsupportedEncodingException ; import java . net . MalformedURLException ; * @ throws MalformedURLException public static Document getEventDocFromUrl ( String url ) throws MalformedURLException , IOException , ParserConfigurationException , SAXException , UnsupportedEncodingException { //InputStream in = (new URL(url)).openStream(); String webPage = WebBrowser . request ( url ) ; InputStream in = new ByteArrayInputStream ( webPage . getBytes ( \"UTF-8\" ) ) ; DocumentBuilderFactory dbf = DocumentBuilderFactory . newInstance ( ) ; DocumentBuilder db = dbf . newDocumentBuilder ( ) ; Document doc = db . parse ( in ) ; doc . getDocumentElement ( ) . normalize ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "xpath", "dialect", "for", "conditionExpressions"], "add_tokens": "@ Test @ Ignore @ Test @ Ignore @ Test @ Ignore", "del_tokens": "@ Test @ Test @ Test", "commit_type": "add"}
{"commit_tokens": ["Fix", "table", "split", "and", "add", "unit", "test"], "add_tokens": "String [ ] values = concatenatedTableLocation . split ( \"\\\\.\" ) ; case 1 : table = values [ 0 ] ;", "del_tokens": "String [ ] values = concatenatedTableLocation . split ( \".\" ) ; case 0 : table = concatenatedTableLocation ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "dispatch", "hanging", "when", "load", "()", "is", "called", "twice", "with", "the", "same", "key"], "add_tokens": "import java . util . AbstractMap . SimpleImmutableEntry ; private final List < SimpleImmutableEntry < K , CompletableFuture < V > > > loaderQueue ; this . loaderQueue = new ArrayList < > ( ) ; loaderQueue . add ( new SimpleImmutableEntry < > ( key , future ) ) ; loaderQueue . forEach ( entry -> { keys . add ( entry . getKey ( ) ) ; queuedFutures . add ( entry . getValue ( ) ) ;", "del_tokens": "import java . util . LinkedHashMap ; import java . util . Map ; private final Map < K , CompletableFuture < V > > loaderQueue ; this . loaderQueue = new LinkedHashMap < > ( ) ; loaderQueue . put ( key , future ) ; loaderQueue . forEach ( ( key , future ) -> { keys . add ( key ) ; queuedFutures . add ( future ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "dynamic", "huffman", "and", "PairHMM", "edits"], "add_tokens": "boolean isSupported = new IntelPairHmmOMP ( ) . load ( ) ; if ( ! isSupported ) isSupported = new IntelPairHmm ( ) . load ( ) ;", "del_tokens": "final boolean isSupported = new IntelPairHmmOMP ( ) . load ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "behavior", "of", "getX", "()", "so", "it", "will", "pick", "up", "the", "next", "column", "following", "an", "explicit", "getX", "(", "int", ")", "or", "getX", "(", "String", ")"], "add_tokens": "column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; public Long getLongOrNull ( int columnOneBased ) { column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ; column = columnOneBased + 1 ; column = rs . findColumn ( columnName ) + 1 ;", "del_tokens": "public Long getLongOrNull ( int column ) {", "commit_type": "change"}
{"commit_tokens": ["remove", "ensureCapacity", "as", "it", "should", "be", "done", "internally", "to", "the", "graph", "implementation"], "add_tokens": "logger . info ( i + \" \" + sw . getSeconds ( ) / ( i + 1 ) + \" secs/run (path length:\" + p . locations ( ) + \")\" ) ;", "del_tokens": "logger . info ( i + \" \" + sw . getSeconds ( ) / ( i + 1 ) + \" secs/run (path length:\" + p . locations ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "AssertionError", "while", "loading", "enum", "from", "String"], "add_tokens": "import com . evernote . android . job . util . JobCat ; import net . vrallev . android . cat . CatLog ; private static final CatLog CAT = new JobCat ( \"JobRequest\" ) ; try { mBackoffPolicy = BackoffPolicy . valueOf ( cursor . getString ( cursor . getColumnIndex ( JobStorage . COLUMN_BACKOFF_POLICY ) ) ) ; } catch ( Throwable t ) { CAT . e ( t ) ; // https://gist.github.com/vRallev/574563f0e3fe636b19a7 mBackoffPolicy = DEFAULT_BACKOFF_POLICY ; } try { mNetworkType = NetworkType . valueOf ( cursor . getString ( cursor . getColumnIndex ( JobStorage . COLUMN_NETWORK_TYPE ) ) ) ; } catch ( Throwable t ) { CAT . e ( t ) ; // https://gist.github.com/vRallev/574563f0e3fe636b19a7 mNetworkType = DEFAULT_NETWORK_TYPE ; }", "del_tokens": "mBackoffPolicy = BackoffPolicy . valueOf ( cursor . getString ( cursor . getColumnIndex ( JobStorage . COLUMN_BACKOFF_POLICY ) ) ) ; mNetworkType = NetworkType . valueOf ( cursor . getString ( cursor . getColumnIndex ( JobStorage . COLUMN_NETWORK_TYPE ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Logger", "permission", "for", "CodeRunner"], "add_tokens": "private boolean async ; return new Logger ( clazz , false ) ; Runnable r = new Runnable ( ) new Thread ( r ) . start ( ) ; r . run ( ) ;", "del_tokens": "private boolean async = true ; return new Logger ( clazz , true ) ; Thread thread = new Thread ( ) thread . start ( ) ; thread . run ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "in", "Holy", "See", "."], "add_tokens": "VAT ( 0 , \"Vatican City\" , null , null , null , new String [ ] { \"Holy See\" } ) ,", "del_tokens": "VAT ( 0 , \"Vatican City\" , null , null , null , new String [ ] { \"Holy See)\" } ) ,", "commit_type": "fix"}
{"commit_tokens": ["fixing", "package", "name", "for", "jsonrc", "importer", "it"], "add_tokens": "CoreOptions . mavenBundle ( ) . groupId ( \"org.ow2.chameleon.fuchsia.importer\" ) . artifactId ( \"jabsorb-importer\" ) . versionAsInProject ( )", "del_tokens": "CoreOptions . mavenBundle ( ) . groupId ( \"org.ow2.chameleon.fuchsia.jsonrpc\" ) . artifactId ( \"fuchsia-jabsorb-importer\" ) . versionAsInProject ( )", "commit_type": "fix"}
{"commit_tokens": ["Added", "generation", "of", "Start", "event", "for", "attached", "nodes", "."], "add_tokens": "* Attaches the given component node ( or complete tree ) as a child * to the component managed by this manager . The node or tree may not * have been started . If the component managed by this manager belongs * to a tree that has already been started , all attached components * will automatically be sent a { @ link Start } event ( using the * component as channel ) .", "del_tokens": "* Attaches the given component node as a child to the component * managed by this manager .", "commit_type": "add"}
{"commit_tokens": ["Fix", "multiple", "constructor", "issue", "when", "data", "classes", "have", "default", "values", "for", "all", "parameters"], "add_tokens": "// Get all members List < VariableElement > fieldElements = getFields ( typeUtil , typeElement ) ; constructors = filterExecutableElementsOfSize ( constructors , fieldElements . size ( ) ) ; if ( constructors . size ( ) == 0 ) { throw new IllegalStateException ( \"Could not find an appropriate constructor on \" + typeElement . toString ( ) + \". \" + \"There were \" + fieldElements . size ( ) + \" member variables, but no visible \" + \"constructors with that many elements.\" ) ; } throw new IllegalStateException ( typeElement . toString ( ) + \" has more than one valid constructor. PaperParcel \" + \"requires only one constructor.\" ) ; private static < T extends ExecutableElement > List < T > filterExecutableElementsOfSize ( List < T > list , int expectedSize ) { ArrayList < T > filteredList = new ArrayList < > ( list . size ( ) ) ; for ( T e : list ) { if ( e . getParameters ( ) . size ( ) == expectedSize ) { filteredList . add ( e ) ; } } return filteredList ; }", "del_tokens": "throw new IllegalStateException ( typeElement . toString ( ) + \" has more than one public constructor\" ) ; // Try to match parameters with members by name. If can't, fallback to ordering. If both fail, throw. List < VariableElement > fieldElements = getFields ( typeUtil , typeElement ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "AnnotatorModel", "pretrained", "()", "compliant", "with", "java", "output", "types"], "add_tokens": "LemmatizerModel lemmatizer = LemmatizerModel . pretrained ( \"lemma_antbnc\" ) ;", "del_tokens": "LemmatizerModel lemmatizer = ( LemmatizerModel ) LemmatizerModel . pretrained ( \"lemma_antbnc\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Moved", "saucerest", "dependency", "to", "common", "library", "so", "that", "archetype", "projects", "dont", "need", "to", "include", "it"], "add_tokens": "* * @ param e not used @ Override protected void starting ( Description description ) { super . starting ( description ) ; //log the session id to the system out if ( sessionIdProvider . getSessionId ( ) != null ) { System . out . println ( String . format ( \"SauceOnDemandSessionID=%1$s job-name=%2$s\" , sessionIdProvider . getSessionId ( ) , description . getDisplayName ( ) ) ) ; } }", "del_tokens": "* * * * @ param e not used", "commit_type": "move"}
{"commit_tokens": ["Add", "paperparcel", "-", "java7", "and", "paperparcel", "-", "java8"], "add_tokens": "package nz . bradcampbell . paperparcel . java7example ;", "del_tokens": "package nz . bradcampbell . paperparcel . javaexample ;", "commit_type": "add"}
{"commit_tokens": ["use", "not", "jquery", "where", "not", "extremely", "inevitable"], "add_tokens": "int height = getElement ( ) . getClientHeight ( ) ; int newHeight = fakeDiv . getClientHeight ( ) + 25 ;", "del_tokens": "int height = getHeightImpl ( getElement ( ) ) ; int newHeight = getHeightImpl ( fakeDiv ) + 25 ; private native int getHeightImpl ( Element e ) / * - { return $ wnd . $ ( e ) . height ( ) ; } - * / ;", "commit_type": "use"}
{"commit_tokens": ["Change", "visibility", "of", "two", "methods", "we", "need", "in", "some", "other", "projects", "."], "add_tokens": "public void changeTeXAnnotation ( String newTeX ) { public void fixGoldCd ( ) {", "del_tokens": "void changeTeXAnnotation ( String newTeX ) { void fixGoldCd ( ) {", "commit_type": "change"}
{"commit_tokens": ["fixed", "incorrect", "arguments", "size", "check"], "add_tokens": "if ( args . length > 3 ) {", "del_tokens": "if ( args . length >= 3 ) {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "writeNULLData", "()", "writeBooleanData", "()", "writeInegerData", "()", "readNULLData", "()", "readBooleanData", "()", "readInegerData", "()"], "add_tokens": "* read Boolean with length without tag int length = readLength ( ) ; return this . readBooleanData ( length ) ; } / * * * Read Boolean without tag and length ( only data ) * * / public boolean readBooleanData ( int length ) throws AsnException , IOException { * read Integer with length without tag int length = this . readLength ( ) ; return this . readIntegerData ( length ) ; } / * * * read Integer without length and tag ( only data ) * @ param length * @ return * @ throws AsnException * @ throws IOException * / public long readIntegerData ( int length ) throws AsnException , IOException { * Read NULL with tag and length this . readNullData ( length ) ; } / * * * Read NULL without tag and length * * / public void readNullData ( int length ) throws AsnException , IOException {", "del_tokens": "int length = readLength ( ) ; int length = this . readLength ( ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "that", "the", "web", "app", "starts", "up", "first", ";", "then", "add", "the", "maven", "indexer", "later", "on"], "add_tokens": "// lets create a maven indexer try { MavenIndexerFacade mavenIndexer = new MavenIndexerFacade ( ) ; mavenIndexer . setCacheDirectory ( new File ( \"target/mavenIndexer\" ) ) ; mavenIndexer . start ( ) ; } catch ( Throwable e ) { LOG . warn ( \"Could not create MavenIndexerFacade: \" + e , e ) ; } LOG . info ( \"Joining the jetty server thread...\" ) ;", "del_tokens": "// lets create a maven indexer try { MavenIndexerFacade mavenIndexer = new MavenIndexerFacade ( ) ; mavenIndexer . setCacheDirectory ( new File ( \"target/mavenIndexer\" ) ) ; mavenIndexer . start ( ) ; } catch ( Throwable e ) { LOG . warn ( \"Could not create MavenIndexerFacade: \" + e , e ) ; }", "commit_type": "make"}
{"commit_tokens": ["Added", "AsyncCourtesyMonitor", "-", "an", "abstract", "base", "class", "for", "courtesy", "monitors", "that", "update", "themselves", "asynchronously", "(", "for", "example", "by", "handling", "events", "or", "by", "polling", ")", "."], "add_tokens": "public abstract class PollingCourtesyMonitor extends AsyncCourtesyMonitor { allow ( poll ( ) ) ; allow ( ) ;", "del_tokens": "public abstract class PollingCourtesyMonitor implements CourtesyMonitor { private boolean allow = true ; allow = poll ( ) ; synchronized ( PollingCourtesyMonitor . this ) { if ( allow ) { PollingCourtesyMonitor . this . notifyAll ( ) ; } } / * ( non - Javadoc ) * @ see ca . eandb . jdcp . worker . policy . CourtesyMonitor # allowTasksToRun ( ) * / public final boolean allowTasksToRun ( ) { return allow ; } / * ( non - Javadoc ) * @ see ca . eandb . jdcp . worker . policy . BlockingCourtesyMonitor # waitFor ( ) * / public final synchronized void waitFor ( ) throws InterruptedException { if ( ! allow ) { wait ( ) ; } }", "commit_type": "add"}
{"commit_tokens": ["Use", "DirectBuffer", "for", "in", "-", "memory", "log", "segments", "."], "add_tokens": "Buffer buffer = DirectBuffer . allocate ( Math . min ( 1024 * 1024 , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) ;", "del_tokens": "Buffer buffer = HeapBuffer . allocate ( Math . min ( 1024 * 1024 , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "default", "value", "for", "request", "/", "response", "in", "the", "UI"], "add_tokens": "import com . strategicgains . restexpress . plugin . swagger . utilities . SwaggerObjectConverter ; . setDefaultValue ( propertyMetadata . defaultValue ) if ( model . defaultValue ( ) != null && model . defaultValue ( ) != \"\" ) { try { if ( field . getType ( ) . isArray ( ) ) { propertyMetadata . defaultValue = SwaggerObjectConverter . convertObjectTo ( model . defaultValue ( ) , field . getType ( ) . getComponentType ( ) ) ; } else { propertyMetadata . defaultValue = SwaggerObjectConverter . convertObjectTo ( model . defaultValue ( ) , field . getType ( ) ) ; } } catch ( Exception ex ) { } } Object defaultValue = null ;", "del_tokens": "propertyMetadata . value = model . value ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "configuration", "of", "SerialPortJavaComm", "."], "add_tokens": "port . setFlowControlMode ( javax . comm . SerialPort . FLOWCONTROL_NONE ) ;", "del_tokens": "port . setFlowControlMode ( gnu . io . SerialPort . FLOWCONTROL_NONE ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "decoder", "still", "debugging", "updated", "unit", "test", "with", "new", "packet", "captures"], "add_tokens": "// initial chunk size private static final int CHUNK_SIZE = 0x80 ; // chunk delimiter private static final byte CHUNK_DELIMITER = ( byte ) 0xC3 ; int correction = 0 ; // we will fill the buffer chunk by chunk skipping any CHUNK_DELIMITER found for ( int i = in . position ( ) ; i < in . position ( ) + readAmount ; i += CHUNK_SIZE ) { if ( in . array ( ) [ i ] == CHUNK_DELIMITER ) { i ++ ; correction ++ ; } buf . put ( in . array ( ) , i , Math . min ( CHUNK_SIZE , in . position ( ) + readAmount + correction - i ) ) ; } if ( buf . position ( ) < header . getSize ( ) - correction ) { // we have just decoded full buf, need to advance original IoBuffer in . skip ( correction + buf . position ( ) ) ;", "del_tokens": "import org . red5 . io . utils . BufferUtils ; BufferUtils . put ( buf , in , readAmount ) ; if ( buf . position ( ) < header . getSize ( ) ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "demos", "of", "setDragView", "XML", "attributes", ".", "Clickable", "view", "in", "the", "header"], "add_tokens": "import android . text . Html ; private static final String TAG = \"DemoActivity\" ; Log . i ( TAG , \"onPanelSlide, offset \" + slideOffset ) ; Log . i ( TAG , \"onPanelExpanded\" ) ; Log . i ( TAG , \"onPanelCollapsed\" ) ; Log . i ( TAG , \"onPanelAnchored\" ) ; TextView t = ( TextView ) findViewById ( R . id . name ) ; t . setText ( Html . fromHtml ( getString ( R . string . hello ) ) ) ; t = ( TextView ) findViewById ( R . id . follow ) ; t . setText ( Html . fromHtml ( getString ( R . string . follow ) ) ) ;", "del_tokens": "Log . i ( \"TEST\" , \"onPanelExpanded\" ) ; Log . i ( \"TEST\" , \"onPanelCollapsed\" ) ; Log . i ( \"TEST\" , \"onPanelAnchored\" ) ; TextView t = ( TextView ) findViewById ( R . id . brought_by ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "constants", "for", "the", "various", "technologies", "identified", "by", "the", "Spring", "component", "finder", "."], "add_tokens": "public static final String SPRING_MVC_CONTROLLER = \"Spring MVC Controller\" ; public static final String SPRING_SERVICE = \"Spring Service\" ; public static final String SPRING_REPOSITORY = \"Spring Repository\" ; public static final String SPRING_COMPONENT = \"Spring Component\" ; componentsFound . addAll ( findClassesAnnotated ( org . springframework . stereotype . Controller . class , SPRING_MVC_CONTROLLER ) ) ; componentsFound . addAll ( findImplementationClassesAnnotated ( org . springframework . stereotype . Service . class , SPRING_SERVICE ) ) ; componentsFound . addAll ( findImplementationClassesAnnotated ( org . springframework . stereotype . Repository . class , SPRING_REPOSITORY ) ) ; componentsFound . addAll ( findImplementationClassesAnnotated ( org . springframework . stereotype . Component . class , SPRING_COMPONENT ) ) ;", "del_tokens": "componentsFound . addAll ( findClassesAnnotated ( org . springframework . stereotype . Controller . class , \"Spring MVC Controller\" ) ) ; componentsFound . addAll ( findImplementationClassesAnnotated ( org . springframework . stereotype . Service . class , \"Spring Service\" ) ) ; componentsFound . addAll ( findImplementationClassesAnnotated ( org . springframework . stereotype . Repository . class , \"Spring Repository\" ) ) ; componentsFound . addAll ( findImplementationClassesAnnotated ( org . springframework . stereotype . Component . class , \"Spring Component\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "child", "selector", "and", "change", "model", "to", "not", "match", "the", "root", "view"], "add_tokens": "import android . view . View ; import android . widget . FrameLayout ; private FrameLayout wrapInRoot ( View view ) { FrameLayout root = new FrameLayout ( getContext ( ) ) ; root . addView ( view ) ; return root ; } View root = wrapInRoot ( view ) ; assertContentsInOrder ( ViewSelector . compile ( \"EditView\" ) . matchView ( root ) ) ; assertContentsInOrder ( ViewSelector . compile ( \"TextView\" ) . matchView ( root ) , view ) ;", "del_tokens": "assertContentsInOrder ( ViewSelector . compile ( \"EditView\" ) . matchView ( view ) ) ; assertContentsInOrder ( ViewSelector . compile ( \"TextView\" ) . matchView ( view ) , view ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "tests", "for", "callback", "functionallity"], "add_tokens": "import com . google . gson . reflect . TypeToken ; import java . lang . reflect . Type ; protected List < T > parseListOfResponses ( List < Response > responses )", "del_tokens": "protected List < T > parseListOfResponses ( List < Response > responses ) {", "commit_type": "add"}
{"commit_tokens": ["Change", "in", "ImageParser", "s", "use", "of", "the", "HttpResponse", "object"], "add_tokens": "byte [ ] imgBytes ; imgBytes = IOUtils . inputStreamToBytes ( is ) ; . println ( \"ImageParser Error: Could not get the image\" ) ; Image image = java . awt . Toolkit . getDefaultToolkit ( ) . createImage ( imgBytes ) ;", "del_tokens": "ImageProducer producer ; producer = ( ImageProducer ) ( ( ObjectInputStream ) is ) . readObject ( ) ; . println ( \"ImageParser Error: Not a recognized image format\" ) ; Image image = java . awt . Toolkit . getDefaultToolkit ( ) . createImage ( producer ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "the", "ability", "to", "retry", "operations", "if", "a", "transient", "failure", "occurs", ".", "Also"], "add_tokens": "// $Id: MySQLRepository.java,v 1.3 2001/03/19 22:59:08 mdb Exp $ / * * * Determines whether or not the supplied SQL exception is a transient * failure , meaning one that is not related to the SQL being executed , * but instead to the environment at the time of execution , like the * connection to the database having been lost . * * @ return true if the exception was thrown due to a transient * failure , false if not . * / protected boolean isTransientException ( SQLException sqe ) { String msg = sqe . getMessage ( ) ; return ( msg != null && msg . indexOf ( \"Lost connection\" ) != - 1 ) ; }", "del_tokens": "// $Id: MySQLRepository.java,v 1.2 2001/03/01 22:59:51 mdb Exp $", "commit_type": "add"}
{"commit_tokens": ["Add", "zero", "-", "lag", "EMA", "indicator"], "add_tokens": "public void smallTimeFrame ( ) {", "del_tokens": "public void smallTimeFrame ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "closing", "dispatcher", "before", "all", "expected", "messages", "delivered", "."], "add_tokens": "testResults . until . completes ( ) ; assertEquals ( 3 , ( ( TestMailbox ) mailbox ) . counts . size ( ) ) ;", "del_tokens": "testResults . until . completes ( ) ; assertEquals ( 3 , ( ( TestMailbox ) mailbox ) . counts . size ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "parens", "to", "dubious", "looking", "logic", "."], "add_tokens": "&& ( ( flowLevel != 0 && analysis . allowFlowPlain ) || ( flowLevel == 0 && analysis . allowBlockPlain ) ) ) return 0 ; && ( ( flowLevel != 0 && analysis . allowFlowPlain ) || ( flowLevel == 0 && analysis . allowBlockPlain ) ) ) return 0 ;", "del_tokens": "&& ( flowLevel != 0 && analysis . allowFlowPlain || flowLevel == 0 && analysis . allowBlockPlain ) ) return 0 ; && ( flowLevel != 0 && analysis . allowFlowPlain || flowLevel == 0 && analysis . allowBlockPlain ) ) return 0 ;", "commit_type": "add"}
{"commit_tokens": ["Improved", "toString", "()", "methods", "."], "add_tokens": "+ \" [matchKey=\" + ( ( getMatchKey ( ) instanceof Class ) ? ( ( Class < ? > ) getMatchKey ( ) ) . getSimpleName ( ) : getMatchKey ( ) ) + \"]\" ;", "del_tokens": "+ \" [matchKey=\" + getMatchKey ( ) + \"]\" ;", "commit_type": "improve"}
{"commit_tokens": ["added", "mechanism", "to", "get", "translation", "of", "a", "resource", "bundle", "key", "as", "native", "script", "."], "add_tokens": "@ Test ( groups = { TestGroups . NATIVE } ) @ Test ( enabled = true ) Object translatedText = ( ( JavascriptExecutor ) driver ) . executeScript ( \"getL10nKeyTranslation\" , \"button\" ) ; Assert . assertEquals ( translatedText , \"EN Button\" ) ;", "del_tokens": "@ Test ( groups = { TestGroups . NATIVE } ) / * * * TDOO lukeis refactor test to verify experimental support in native mode is working fine . * / @ Test ( enabled = false ) try { ( ( JavascriptExecutor ) driver ) . executeScript ( \"return document.title\" ) ; Assert . fail ( ) ; } catch ( WebDriverException e ) { Assert . assertTrue ( e . getMessage ( ) . contains ( \"Executing script is only available in web views.\" ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Make", "capacity", "a", "parameter", "to", "the", "constructor", "rather", "than", "a", "baked", "in"], "add_tokens": "public { { blockingQueueClassName } } ( int capacity ) super ( capacity ) ;", "del_tokens": "public { { blockingQueueClassName } } ( ) super ( { { capacity } } ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "@ScopeAnnotation", ".", "Added", "Binder", ".", "addError", "()", ".", "Removed", "Scopes", ".", "DEFAULT", ".", "We", "now", "refer", "to", "this", "as", "no", "scope", "."], "add_tokens": "import static java . lang . annotation . ElementType . * ; @ Target ( ANNOTATION_TYPE )", "del_tokens": "@ Target ( { ElementType . ANNOTATION_TYPE } )", "commit_type": "add"}
{"commit_tokens": ["Allow", "Soloader", "to", "work", "with", "system", "apps"], "add_tokens": "private static boolean isSystemApp ; isSystemApp = checkIfSystemApp ( context ) ; if ( isSystemApp ) { private static boolean checkIfSystemApp ( Context context ) { return ( context != null ) && ( context . getApplicationInfo ( ) . flags & ( ApplicationInfo . FLAG_SYSTEM | ApplicationInfo . FLAG_UPDATED_SYSTEM_APP ) ) ! = 0 ; } // This is to account for the fact that we want to load .so files from the apk itself when it is // a system app. if ( isSystemApp && sSystemLoadLibraryWrapper != null ) { sSystemLoadLibraryWrapper . loadLibrary ( shortName ) ; return true ; }", "del_tokens": "ApplicationInfo applicationInfo = context . getApplicationInfo ( ) ; boolean isSystemApplication = ( applicationInfo . flags & ApplicationInfo . FLAG_SYSTEM ) != 0 && ( applicationInfo . flags & ApplicationInfo . FLAG_UPDATED_SYSTEM_APP ) == 0 ; if ( isSystemApplication ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "implementation", "of", "the", "Permissions", "and", "PermissionsBuilder", "interfaces"], "add_tokens": "* @ return @ return This object . public PermissionsBuilder setState ( PermissionType type , PermissionState state ) ;", "del_tokens": "public void setState ( PermissionType type , PermissionState state ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "imports", "due", "to", "jerry", "-", "core", "change"], "add_tokens": "import com . sangupta . jerry . ds . counter . LongCounter ;", "del_tokens": "import com . sangupta . jerry . ds . LongCounter ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "methods", "into", "Result", "class", "for", "better", "user", "experience"], "add_tokens": "assertNotNull ( weatherResponse ) ; assertTrue ( TextUtils . isEmpty ( checkSecondResponse . getResult ( ) . getAction ( ) ) ) ;", "del_tokens": "assertNull ( checkSecondResponse . getResult ( ) . getAction ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "tag", "configuration", "and", "add", "@since", "tag"], "add_tokens": "* @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 1 * @ since 1.0 - beta - 2", "del_tokens": "/ * * * @ parameter expression = \"${tag}\" * @ todo This doesn 't seem to be used. Can it be removed? * / private String tag ; * @ required public void setTag ( String tag ) { this . tag = tag ; }", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "<link", ">", "in", "MicrodataDocument", ".", "getLink"], "add_tokens": "return String . format ( \"a[rel=%1$s], link[rel=%1$s]\" , rel ) ;", "del_tokens": "return String . format ( \"a[rel=%s]\" , rel ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "VisUI", "skin", "loading", ".", "Updated", "README", "."], "add_tokens": "if ( ! VisUI . isLoaded ( ) ) {", "del_tokens": "import com . github . czyzby . kiwi . util . common . Exceptions ; try { lmlData . setDefaultSkin ( VisUI . getSkin ( ) ) ; } catch ( final IllegalStateException exception ) { // No #isLoaded(). Assuming that the user wants a default skin. Exceptions . ignore ( exception ) ; lmlData . setDefaultSkin ( VisUI . getSkin ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "smooth", "scrolling", "to", "a", "position"], "add_tokens": "private boolean isStartOfSection ( int position ) { return position == 0 || mAdapter . getHeaderId ( position ) == mAdapter . getHeaderId ( position - 1 ) ; } private int getHeaderOverlap ( int position ) { boolean isStartOfSection = isStartOfSection ( position ) ; if ( ! isStartOfSection ) { View header = mAdapter . getView ( position , null , mList ) ; int widthMeasureSpec = MeasureSpec . makeMeasureSpec ( 0 , MeasureSpec . UNSPECIFIED ) ; int heightMeasureSpec = MeasureSpec . makeMeasureSpec ( 0 , MeasureSpec . UNSPECIFIED ) ; header . measure ( widthMeasureSpec , heightMeasureSpec ) ; return header . getMeasuredHeight ( ) ; } return 0 ; } @ SuppressLint ( \"NewApi\" ) if ( Build . VERSION . SDK_INT < Build . VERSION_CODES . HONEYCOMB ) { mList . smoothScrollToPosition ( position ) ; } else { int offset = mAdapter == null ? 0 : getHeaderOverlap ( position ) ; mList . smoothScrollToPositionFromTop ( position , offset ) ; } offset += mAdapter == null ? 0 : getHeaderOverlap ( position ) ; offset += mAdapter == null ? 0 : getHeaderOverlap ( position ) ;", "del_tokens": "mList . smoothScrollToPosition ( position ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "bigger", "buffer", "size", "for", "the", "lots", "of", "sets", "test", "."], "add_tokens": "new DefaultConnectionFactory ( 350000 , 32768 ) ,", "del_tokens": "new DefaultConnectionFactory ( 350000 , 8192 ) ,", "commit_type": "use"}
{"commit_tokens": ["add", "null", "check", "on", "handler", ".", "end", "call"], "add_tokens": "if ( cellHandler != null ) { cellHandler . end ( ) ; }", "del_tokens": "cellHandler . end ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "cas", "may", "return", "true", "even", "it", "failed", "."], "add_tokens": "while ( tryCount <= operation . getMaxTries ( )", "del_tokens": "while ( tryCount < operation . getMaxTries ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "GitHubEnterprise", "to", "rate", "limit", "checks"], "add_tokens": "import java . io . FileNotFoundException ; GitHub gitHub = null ; } catch ( FileNotFoundException ex ) { logger . log ( Level . INFO , \"Rate limit API not found.\" ) ;", "del_tokens": "GitHub gitHub ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Map", "properties", "handling", "in", "Constants", "."], "add_tokens": "protected static Object cast ( String value , Class target , Properties properties ) { String [ ] keys = value . split ( \"\\\\s*(?<!\\\\\\\\),\\\\s*\" ) ; for ( String key : keys ) { map . put ( key , properties . getProperty ( key ) ) ; returnValue = cast ( properties . getProperty ( desc . key ) , method . getReturnType ( ) , properties ) ;", "del_tokens": "protected static Object cast ( String value , Class target ) { String [ ] values = value . split ( \"\\\\s*(?<!\\\\\\\\),\\\\s*\" ) ; for ( int i = 0 ; ( i + 1 ) < values . length ; i += 2 ) { map . put ( values [ i ] , values [ i + 1 ] ) ; returnValue = cast ( properties . getProperty ( desc . key ) , method . getReturnType ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "package", "names", "of", "Event", "and", "EventTemplate", "classes"], "add_tokens": "package org . fluentd . logger . sender ;", "del_tokens": "package org . fluentd . logger ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "the", "name", "of", "getActivityList", "()", "to", "getAllOpenedActivities", "()", "."], "add_tokens": "* This method returns an ArrayList of all the opened / active activities . * @ return ArrayList of all the opened activities public ArrayList < Activity > getAllOpenedActivities ( ) return soloActivity . getAllOpenedActivities ( ) ;", "del_tokens": "* This method returns an ArrayList of all the active activities . * @ return ArrayList of all the active activities public ArrayList < Activity > getActivityList ( ) return soloActivity . getActivityList ( ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "change", "which", "got", "forgotten", "in", "last", "commit", "."], "add_tokens": "ext , classifier , dependency . isOptional ( ) , dependency . getFile ( ) ) ) ;", "del_tokens": "ext , classifier , dependency . isOptional ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "exec", "to", "pom", "for", "easier", "trying", "out"], "add_tokens": "String master = \"https://localhost:8443/api/v1/\" ; if ( args . length == 1 ) { master = args [ 0 ] ; } client = new KubernetesClient ( master ) ;", "del_tokens": "client = new KubernetesClient ( \"https://localhost:8443/api/v1/\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "utilize", "prebuild", "sql", "functions", "in", "the", "db", "object"], "add_tokens": "static final boolean DEBUG = false ; ShillelaghInjector injector = new ShillelaghInjector ( classPackage , className , targetType ) ; if ( tableObject . getIdColumnName ( ) == null ) { logger . e ( String . format ( \"%s does not have an id column. Did you forget @id?\" , targetType ) ) ; }", "del_tokens": "static final boolean DEBUG = true ; ShillelaghInjector injector = new ShillelaghInjector ( classPackage , className , targetType , logger ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "PropertyDispatcher", "class", "for", "dispatching", "efficiently", "interface", "setters", "."], "add_tokens": "@ BeanProxyClass ( value = \"org.vesalainen.code.impl.BTImpl\" )", "del_tokens": "@ BeanProxyClass ( value = \"org.vesalainen.code.BTImpl\" )", "commit_type": "add"}
{"commit_tokens": ["make", "it", "compile", "in", "java", "6"], "add_tokens": "if ( value1 == null || value1 . trim ( ) . length ( ) == 0 ) if ( value2 == null || value2 . trim ( ) . length ( ) == 0 )", "del_tokens": "if ( value1 == null || value1 . trim ( ) . isEmpty ( ) ) if ( value2 == null || value2 . trim ( ) . isEmpty ( ) )", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "annotate", "a", "type", "directly", "with", "Intent", "(", "not", "surrounded", "by", "IntentFilters", ")"], "add_tokens": "import java . lang . annotation . ElementType ; @ Target ( ElementType . TYPE )", "del_tokens": "@ Target ( { } )", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "account", "for", "development", "changes", "."], "add_tokens": "boolean success = true ; success = compareFiles ( in , out ) ; assertTrue ( \"Files are not identical\" , success ) ; if ( out != null && success == true )", "del_tokens": "assertTrue ( \"Files are not identical\" , compareFiles ( in , out ) ) ; if ( out != null )", "commit_type": "update"}
{"commit_tokens": ["Added", "all", "user", "chatroom", "and", "session", "endpoints", "."], "add_tokens": "public MUCRoomEntity ( String roomName , String naturalName , String description ) {", "del_tokens": "public MUCRoomEntity ( String naturalName , String roomName , String description ) {", "commit_type": "add"}
{"commit_tokens": ["removing", "even", "more", "console", "output", "that", "appears", "to", "be", "causing", ":"], "add_tokens": "logger . debug ( httpMethod + \" => \" + url ) ;", "del_tokens": "import org . apache . http . client . config . RequestConfig ; import org . apache . http . config . SocketConfig ; import org . apache . http . conn . ConnectionKeepAliveStrategy ; import org . apache . http . protocol . HttpContext ; import java . util . concurrent . TimeUnit ; import static org . mockserver . configuration . SystemProperties . maxTimeout ; if ( logger . isDebugEnabled ( ) ) { System . out . println ( httpMethod + \" => \" + url ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "assumption", "for", "test", "."], "add_tokens": "import java . security . Provider ; import java . security . Provider . Service ; import java . security . Security ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; import org . junit . Assume ; Assume . assumeTrue ( algorithmExists ( algorithm ) ) ; private boolean algorithmExists ( String algorithm ) { for ( Provider provider : Security . getProviders ( ) ) { for ( Service service : provider . getServices ( ) ) { if ( service . getType ( ) . equals ( \"MessageDigest\" ) && service . getAlgorithm ( ) . equals ( algorithm ) ) { return true ; } } } return false ; }", "del_tokens": "import java . util . ArrayList ; import java . util . Collection ; import java . util . List ;", "commit_type": "add"}
{"commit_tokens": ["fix", "warnings", "(", "sort", "of", ")"], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) Filter < ? > filter = newFromThis ( filterClass , Object . class , annotation ) ;", "del_tokens": "Filter filter = newFromThis ( filterClass , Object . class , annotation ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "handling", "for", "unregistered", "variable", "to", "get", "meaningful", "path"], "add_tokens": "if ( lookup . contains ( \"__\" ) ) { String [ ] tmp = lookup . split ( \"__\" ) ; if ( tmp . length > 1 && ! tmp [ 1 ] . trim ( ) . equals ( \"\" ) ) { return setSuffixMatch ( tmp [ 1 ] . trim ( ) ) ; } else { lookup = tmp [ 0 ] ; } } private String setSuffixMatch ( String suffix ) { if ( suffix == null ) { return \"\" ; } suffix = suffix . toLowerCase ( ) . trim ( ) ; if ( suffix . equals ( \"soil\" ) ) { return setGroupMatch ( \"4051\" ) ; } else if ( suffix . equals ( \"soillayer\" ) ) { return setGroupMatch ( \"4052\" ) ; } else if ( suffix . equals ( \"weather\" ) ) { return setGroupMatch ( \"5041\" ) ; } else if ( suffix . equals ( \"weatherdaily\" ) ) { return setGroupMatch ( \"5052\" ) ; } else { return \"\" ; } } private String setGroupMatch ( String groupOrder ) {", "del_tokens": "public String setGroupMatch ( String groupOrder ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "javadoc", "reusing", "single", "method", "."], "add_tokens": "* @ see # mktemp ( String , boolean ) return mktemp ( template , false ) ;", "del_tokens": "* @ see mktemp ( String , boolean ) try { String path = template + \"XXXXXX\" ; checkWrite ( path ) ; loadLibrary ( ) ; return new UnixFile ( mktemp0 ( path ) ) ; } catch ( IOException err ) { System . err . println ( \"UnixFile.mktemp: IOException: template=\" + template ) ; throw err ; }", "commit_type": "fix"}
{"commit_tokens": ["allow", "dashes", "for", "conjunctions", "allow", "missing", "dots", "in", "meridian", "indicators"], "add_tokens": "Calendar cal = getCalendar ( ) ; Calendar cal = getCalendar ( ) ; Calendar utcCal = getCalendar ( ) ; Calendar localCal = getCalendar ( ) ;", "del_tokens": "Calendar cal = new GregorianCalendar ( ) ; Calendar cal = new GregorianCalendar ( ) ; Calendar utcCal = new GregorianCalendar ( ) ; Calendar localCal = new GregorianCalendar ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "support", "for", "MVI", "for", "ViewGroups"], "add_tokens": "private static final boolean DEBUG = false ;", "del_tokens": "private static final boolean DEBUG = true ;", "commit_type": "add"}
{"commit_tokens": ["remove", "syso", "and", "add", "log", "instead"], "add_tokens": "logger . info ( \"exporting {}\" , exportDeclaration . getMetadata ( ) ) ; logger . info ( \"destroying exportation {}\" , exportDeclaration . getMetadata ( ) ) ;", "del_tokens": "System . out . println ( \"trying to export\" ) ; //Class ref = Class.forName(classname); System . out . println ( \"trying to unexport\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "transaction", "support", "to", "DbConnectionFilter", "references", ":", "http", ":", "//", "code", ".", "google", ".", "com", "/", "p", "/", "activeweb", "/", "issues", "/", "detail?id", "=", "13"], "add_tokens": "List < ConnectionSpecWrapper > allConnections = Configuration . getConnectionSpecWrappers ( ) ;", "del_tokens": "List < ConnectionSpecWrapper > allConnections = Configuration . getConnectionWrappers ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "a", "factory", "method", "static", "."], "add_tokens": "static public TangConf processConfiguration ( Map < String , String > conf ) throws ReflectiveOperationException {", "del_tokens": "public TangConf processConfiguration ( Map < String , String > conf ) throws ReflectiveOperationException {", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "custom", "ViewPager", ".", "PageTransformer", "."], "add_tokens": "import android . support . v4 . view . ViewPager ; @ StyleRes final int animationStyle , @ Nullable final ViewPager . PageTransformer pageTransformer ) { final EmojiView emojiView = new EmojiView ( context , clickListener , longClickListener , recentEmoji , variantEmoji , backgroundColor , iconColor , dividerColor , pageTransformer ) ; @ StyleRes private int keyboardAnimationStyle ; @ Nullable private ViewPager . PageTransformer pageTransformer ; keyboardAnimationStyle = animation ; return this ; } @ CheckResult public Builder setPageTransformer ( @ Nullable final ViewPager . PageTransformer transformer ) { pageTransformer = transformer ; final EmojiPopup emojiPopup = new EmojiPopup ( rootView , editText , recentEmoji , variantEmoji , backgroundColor , iconColor , dividerColor , keyboardAnimationStyle , pageTransformer ) ;", "del_tokens": "@ StyleRes final int animationStyle ) { final EmojiView emojiView = new EmojiView ( context , clickListener , longClickListener , recentEmoji , variantEmoji , backgroundColor , iconColor , dividerColor ) ; @ StyleRes private int animationStyle ; animationStyle = animation ; final EmojiPopup emojiPopup = new EmojiPopup ( rootView , editText , recentEmoji , variantEmoji , backgroundColor , iconColor , dividerColor , animationStyle ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "failure", "in", "sonar", "build"], "add_tokens": "private Integer nodeIdOffset ; assertRootNodeAsExpected ( 1 + nodeIdOffset ) ; assertFeatureNodeAsExpected ( 2 + nodeIdOffset ) ; assertScenarioNodeAsExpected ( 3 + nodeIdOffset ) ; assertStepNodeAsExpected ( 4 + nodeIdOffset , STEP_NODE + \"1\" ) ; assertStepNodeAsExpected ( 5 + nodeIdOffset , STEP_NODE + \"2\" ) ; assertStepNodeAsExpected ( 6 + nodeIdOffset , STEP_NODE + \"3\" ) ; int indexInt = Integer . valueOf ( index ) ; if ( nodeIdOffset == null ) { nodeIdOffset = indexInt - 1 ; } details . put ( indexInt , json ) ;", "del_tokens": "assertRootNodeAsExpected ( 1 ) ; assertFeatureNodeAsExpected ( 2 ) ; assertScenarioNodeAsExpected ( 3 ) ; assertStepNodeAsExpected ( 4 , STEP_NODE + \"1\" ) ; assertStepNodeAsExpected ( 5 , STEP_NODE + \"2\" ) ; assertStepNodeAsExpected ( 6 , STEP_NODE + \"3\" ) ; details . put ( Integer . valueOf ( index ) , json ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "CGLib", "class", "I", "believe", "it", "will", "help", "to", "find", "public", "cglib", "functions"], "add_tokens": "* @ version $ Id : Enhancer . java , v 1.13 2002 / 12 / 27 12 : 11 : 37 baliuka Exp $ Class interceptor , boolean delegating , Object filter ) ; return ( Factory ) enhanceHelper ( true , obj , obj . getClass ( ) . isInterface ( ) ? null : obj . getClass ( ) , obj . getClass ( ) . isInterface ( ) ? new Class [ ] { obj . getClass ( ) } : null , interceptor , obj . getClass ( ) . getClassLoader ( ) , null , null ) ; Object key = keyFactory . newInstance ( cls , interfaces , wreplace , ih . getClass ( ) , delegating , filter ) ;", "del_tokens": "* @ version $ Id : Enhancer . java , v 1.12 2002 / 12 / 22 00 : 21 : 17 herbyderby Exp $ Class interceptor , boolean delegating ) ; return ( Factory ) enhanceHelper ( true , obj , obj . getClass ( ) , null , interceptor , obj . getClass ( ) . getClassLoader ( ) , null , null ) ; Object key = keyFactory . newInstance ( cls , interfaces , wreplace , ih . getClass ( ) , delegating ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "all", "of", "dialect", "-", "detection", "code", "to", "Dialect", "."], "add_tokens": "this ( connectionProvider , Dialect . detect ( connectionProvider ) ) ;", "del_tokens": "this ( connectionProvider , resolveDialect ( connectionProvider ) ) ; / * * * Tries to detect the dialect of database automatically . * / @ NotNull private static Dialect resolveDialect ( @ NotNull Provider < Connection > connectionProvider ) { try { Connection connection = connectionProvider . get ( ) ; try { return Dialect . detect ( connection ) ; } finally { connection . close ( ) ; } } catch ( SQLException e ) { throw new DatabaseException ( \"Failed autodetect database dialect: \" + e , e ) ; } }", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "If", "-", "Modified", "-", "Since"], "add_tokens": "if ( this . http . getIfModifiedSince ( ) != null ) { reqStr . append ( \"If-Modified-Since: \" ) ; reqStr . append ( this . http . getIfModifiedSince ( ) ) ; reqStr . append ( \"\\r\\n\" ) ; }", "del_tokens": "* @ param datum * @ throws ProtocolException", "commit_type": "add"}
{"commit_tokens": ["Fixed", "IllegalStateException", "on", "trying", "to", "label", "a", "rule", "from", "within", "a", "recursion"], "add_tokens": "if ( ! ( ProxyMatcher . unwrap ( matcher ) instanceof TestMatcher ) ) { // special case: TestMatchers do not add nodes if ( ProxyMatcher . unwrap ( matcher ) instanceof ActionMatcher ) { if ( ProxyMatcher . unwrap ( parent . getMatcher ( ) ) instanceof FollowMatcher ) { return ProxyMatcher . unwrap ( matcher ) instanceof TestMatcher || parent != null && parent . inPredicate ( ) ;", "del_tokens": "if ( ! ( matcher instanceof TestMatcher ) ) { // special case: TestMatchers do not add nodes if ( matcher instanceof ActionMatcher ) { if ( parent . getMatcher ( ) instanceof FollowMatcher ) { return matcher instanceof TestMatcher || parent != null && parent . inPredicate ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["move", "instrumentation", "to", "kopeme", "-", "analysis"], "add_tokens": "String jarFileName = TestKoPeMeKiekerPremain . getFileInTarget ( \"-javassist_agent.jar\" ) ;", "del_tokens": "String jarFileName = \"kopeme-core-0.10-SNAPSHOT-javassist_agent.jar\" ;", "commit_type": "move"}
{"commit_tokens": ["Make", "it", "possible", "to", "provide", "different", "metrics", "for", "different", "event", "-", "types", "/", "topics", "."], "add_tokens": "public NakadiReaderFactory ( final ClientHttpRequestFactory clientHttpRequestFactory , final BackoffStrategy backoffStrategy , final CursorManager cursorManager , final ObjectMapper objectMapper ) { final Class < T > eventType , final Listener < T > listener , @ Nullable final MetricsCollector metricsCollector ) {", "del_tokens": "private final MetricsCollector metricsCollector ; public NakadiReaderFactory ( final ClientHttpRequestFactory clientHttpRequestFactory , final BackoffStrategy backoffStrategy , final CursorManager cursorManager , final ObjectMapper objectMapper , @ Nullable final MetricsCollector metricsCollector ) { this . metricsCollector = metricsCollector ; final Class < T > eventType , final Listener < T > listener ) {", "commit_type": "make"}
{"commit_tokens": ["fixed", "get", "cluster", "metric", "return", "value"], "add_tokens": "import java . util . Map ; < T extends Metric > Map < String , T > getClusterMetric ( HiveMQMetric < T > metric ) ;", "del_tokens": "< T extends Metric > T getClusterMetric ( HiveMQMetric < T > metric ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "concurrent", "modification", "exception", "in", "listener", "store", "implementations"], "add_tokens": "final int sizeHint = listeners == null ? 0 : listeners . size ( ) ; return copyList ( listenerClass , nullSafeStream ( listeners ) . map ( w -> w . listener ) , sizeHint ) . stream ( ) ;", "del_tokens": "import java . util . Collections ; if ( listeners == null ) { return Collections . < T > emptyList ( ) . stream ( ) ; } return listeners . stream ( ) . map ( wrapper -> wrapper . listener ) . map ( obj -> listenerClass . cast ( obj ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "README", "&", "NodeExample", "to", "mention", "Asset", ".", "WAVES"], "add_tokens": "import static com . wavesplatform . wavesj . Asset . WAVES ; 1 * TOKEN , WAVES , FEE , WAVES ,", "del_tokens": "1 * TOKEN , null , FEE , null ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "#JAWR", "-", "334"], "add_tokens": "// Checks that the requested Path is a normalized one. If not don't // treat the request if ( ! PathNormalizer . isNormalized ( requestedPath ) ) { LOGGER . warn ( \"Un-normalized paths are not supported: \" + requestedPath ) ; response . setStatus ( HttpServletResponse . SC_FORBIDDEN ) ; return ; } if ( LOGGER . isDebugEnabled ( ) ) { } * the content type if ( null == bundlesHandler . resolveBundleForPath ( requestedPath ) && isValidRequestedPath ( requestedPath ) ) {", "del_tokens": "if ( LOGGER . isDebugEnabled ( ) ) * teh ontentt type if ( null == bundlesHandler . resolveBundleForPath ( requestedPath ) && isValidRequestedPath ( requestedPath ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Snorocket", "to", "conform", "to", "changes", "in", "importer", "interface", "."], "add_tokens": "return new Ontology < T > ( null , null , null , taxonomy , affectedNodes ) ;", "del_tokens": "return new Ontology < T > ( null , taxonomy , affectedNodes ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "that", "the", "inProcessClient", "never", "throws", "a", "ConditionalCheckFailedException", "(", "+", "test", ")"], "add_tokens": "import com . amazonaws . services . dynamodb . model . ConditionalCheckFailedException ; try { } catch ( Exception e ) { if ( e instanceof ConditionalCheckFailedException ) { throw ( ConditionalCheckFailedException ) e ; } log . error ( e . getMessage ( ) , e ) ; return new PutItemResult ( ) ; }", "del_tokens": "try { } catch ( Exception e ) { log . error ( e . getMessage ( ) , e ) ; return new PutItemResult ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "shared", "library", "name", "and", "fixed", "unit", "test"], "add_tokens": "System . loadLibrary ( \"CouchbaseLiteJavaForestDB\" ) ; Log . e ( TAG , \"ERROR: Failed to load libCouchbaseLiteJavaForestDB\" ) ; fail ( \"ERROR: Failed to load libCouchbaseLiteJavaForestDB.\" ) ;", "del_tokens": "System . loadLibrary ( \"cbforest\" ) ; Log . e ( TAG , \"ERROR: Failed to load libcbforest\" ) ; fail ( \"ERROR: Failed to load libcbforest.\" ) ;", "commit_type": "change"}
{"commit_tokens": ["use", "nio", ".", "Path", "(", "and", "related", ")", "instead", "of", "io", ".", "File"], "add_tokens": "import java . nio . file . Paths ; assertEquals ( fileWrapper . getFilename ( ) , Paths . get ( VALID_FILENAME ) . toAbsolutePath ( ) . toString ( ) ) ;", "del_tokens": "assertEquals ( fileWrapper . getFilename ( ) , VALID_FILENAME ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "the", "Cache", "Database", "."], "add_tokens": "assertEquals ( 10 , databases . size ( ) ) ;", "del_tokens": "assertEquals ( 9 , databases . size ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "static", "context", "fields"], "add_tokens": "private final UnleashConfig config ; this . config = unleashConfig ; UnleashContext enhancedContext = context . applyStaticFields ( config ) ; . anyMatch ( as -> getStrategy ( as . getName ( ) ) . isEnabled ( as . getParameters ( ) , enhancedContext ) ) ;", "del_tokens": ". anyMatch ( as -> getStrategy ( as . getName ( ) ) . isEnabled ( as . getParameters ( ) , context ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "GET", "call", "for", "checklists", "of", "a", "card"], "add_tokens": "List < Card > getListCards ( String listId , Argument ... args ) ; List < CheckList > getCardChecklists ( String cardId , Argument ... args ) ;", "del_tokens": "List < Card > getListCards ( String string , Argument ... args ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "CharsetEncoder", "instead", "of", "String", ".", "getBytes"], "add_tokens": "import java . nio . ByteBuffer ; import java . nio . charset . CharsetEncoder ; private final CharsetEncoder encoder ; encoder = Charset . forName ( charsetName ) . newEncoder ( ) ; public RequestOutputStream write ( final String value ) throws IOException { final ByteBuffer bytes = encoder . encode ( CharBuffer . wrap ( value ) ) ; super . write ( bytes . array ( ) , 0 , bytes . limit ( ) ) ; final Writer writer = new OutputStreamWriter ( output , output . encoder . charset ( ) ) ;", "del_tokens": "private final Charset charset ; charset = Charset . forName ( charsetName ) ; public RequestOutputStream write ( String value ) throws IOException { super . write ( value . getBytes ( charset ) ) ; final Writer writer = new OutputStreamWriter ( output , output . charset ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "the", "json", "cahed", "object", "class", "to", "Sticker"], "add_tokens": "return \"InlineQueryResultCachedSticker{\" + \", sticker_file_id='\" + stickerFileId + '\\'' +", "del_tokens": "return \"InlineQueryResultCachedGif{\" + \", gifUrl='\" + stickerFileId + '\\'' +", "commit_type": "change"}
{"commit_tokens": ["Added", "lookup", "torrents", "methods", "to", "session", "."], "add_tokens": "/ * * * Looks for a torrent with the given info - hash . In * case there is such a torrent in the session , a torrent_handle to that * torrent is returned . * * @ param infoHash * @ return * / public TorrentHandle findTorrent ( Sha1Hash infoHash ) { torrent_handle th = s . find_torrent ( infoHash . getSwig ( ) ) ; return th . is_valid ( ) ? new TorrentHandle ( th ) : null ; } / * * * Returns a list of torrent handles to all the * torrents currently in the session . * * @ return * / public List < TorrentHandle > getTorrents ( ) { torrent_handle_vector v = s . get_torrents ( ) ; long size = v . size ( ) ; List < TorrentHandle > l = new ArrayList < TorrentHandle > ( ( int ) size ) ; for ( int i = 0 ; i < size ; i ++ ) { l . add ( new TorrentHandle ( v . get ( i ) ) ) ; } return l ; }", "del_tokens": "//public TorrentHandle", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "unit", "tests", "for", "SegmentAggregator", ":"], "add_tokens": "private long outstandingAppendLength ; this . outstandingAppendLength = 0 ; return this . outstandingAppendLength >= this . config . getFlushThresholdBytes ( ) this . outstandingAppendLength , } else if ( operation instanceof StreamSegmentAppendOperation || operation instanceof CachedStreamSegmentAppendOperation ) { // Update current outstanding length - but we only keep track of this for appends (MergeBatches do not count for flush thresholds). this . outstandingAppendLength += operation . getLength ( ) ; this . outstandingAppendLength -= flushArgs . getTotalLength ( ) ; assert this . outstandingAppendLength >= 0 : \"negative outstandingAppendLength\" ;", "del_tokens": "private long outstandingLength ; this . outstandingLength = 0 ; return this . outstandingLength >= this . config . getFlushThresholdBytes ( ) this . outstandingLength , // Update current state (note that MergeBatchOperations have a length of 0 if added to the BatchStreamSegment - because they don't have any effect on it). this . outstandingLength += operation . getLength ( ) ; this . outstandingLength -= flushArgs . getTotalLength ( ) ; assert this . outstandingLength >= 0 : \"negative outstandingLength\" ;", "commit_type": "add"}
{"commit_tokens": ["Make", "XML", "formatting", "for", "requests", "behave", "that", "same", "as", "for", "responses"], "add_tokens": "* @ return request sent last time postTo ( ) or getFrom ( ) was called . return formatValue ( super . request ( ) ) ; * @ return response received last time postTo ( ) or getFrom ( ) was called . return formatValue ( super . response ( ) ) ; } private String formatValue ( String value ) { result = getEnvironment ( ) . getHtmlForXml ( value ) ; result = value ;", "del_tokens": "* @ return request sent last time postTo ( ) was called . return getEnvironment ( ) . getHtmlForXml ( super . request ( ) ) ; * @ return response received last time postTo ( ) was called . String response = super . response ( ) ; result = getEnvironment ( ) . getHtmlForXml ( response ) ; result = response ;", "commit_type": "make"}
{"commit_tokens": ["Add", "test", "for", "MultiEvent", "interrupt", "behavior", ";", "fix", "bug", "in", "process"], "add_tokens": "import static org . junit . Assert . assertNull ; import static org . mockito . Mockito . when ; @ Test public void shouldStopWaitingAndInterruptInnerEventsIfThreadIsInterrupted ( ) throws InterruptedException { Thread multiEventThread = Thread . currentThread ( ) ; IntSupplier mockObject = mock ( IntSupplier . class ) ; // Will examine value to see if thread was allowed to complete when ( mockObject . getAsInt ( ) ) . thenReturn ( 1 ) ; Event < Integer > event1 = new FakeEvent < > ( mockObject :: getAsInt , ONE_HUNDRED_MILLIS ) ; // Fake an interrupt Event < Integer > event2 = new FakeEvent < > ( ( ) -> { multiEventThread . interrupt ( ) ; return 10 ; } , FIFTY_MILLIS ) ; Integer result = new MultiEvent < > ( event1 , event2 ) . waitUpTo ( 200 , MILLIS ) ; Thread . interrupted ( ) ; // Clear interrupt so we can sleep. Thread . sleep ( 200 ) ; // Sleep so we can let threads finish if they weren't interrupted. verifyZeroInteractions ( mockObject ) ; assertNull ( \"Expected waitUpTo to be interrupted and return null, but returned an event\" + \"result.\" , result ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "auto", "config", "for", "cosmos", "db"], "add_tokens": "import org . springframework . context . annotation . Scope ; * @ return CloudStorageAccount bean @ Scope ( \"prototype\" ) LOG . debug ( \"cloudStorageAccount called, connection string = \" + properties . getConnectionString ( ) ) ; * @ return CloudStorageAccount object LOG . debug ( \"createCloudStorageAccount called\" ) ; if ( properties . getConnectionString ( ) != null ) { final String connectionString = properties . getConnectionString ( ) ; final String msg = \"Error creating CloudStorageAccount: \" + e . getMessage ( ) ; LOG . error ( msg , e ) ; throw new AzureStorageAutoConfigureException ( msg , e ) ; final String msg = \"Error creating CloudStorageAccount: \" + e . getMessage ( ) ; LOG . error ( msg , e ) ; throw new AzureStorageAutoConfigureException ( msg , e ) ;", "del_tokens": "* @ return LOG . debug ( \"cloudStorageAccount called, account name = \" + properties . getName ( ) ) ; * @ return LOG . debug ( \"createCloudStorageAccount called, account name = \" + properties . getName ( ) ) ; if ( properties . getName ( ) != null ) { final String connectionString = properties . buildStorageConnectString ( ) ; LOG . error ( \"Error creating CloudStorageAccount: \" + e . getMessage ( ) , e ) ; LOG . error ( \"Error creating CloudStorageAccount: \" + e . getMessage ( ) , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "empty", "properties", "by", "default", "in", "config"], "add_tokens": "private Properties properties = new Properties ( ) ; public PersistenceUnitConfig setProperty ( String key , String value ) {", "del_tokens": "private Properties properties ; public PersistenceUnitConfig addProperty ( String key , String value ) {", "commit_type": "add"}
{"commit_tokens": ["make", "LzoFileInput", "recursion", "configurable", "as", "in", "MAPREDUCE", "-", "1501"], "add_tokens": "boolean recursive = job . getConfiguration ( ) . getBoolean ( \"mapred.input.dir.recursive\" , false ) ; if ( recursive && fileStatus . isDir ( ) ) {", "del_tokens": "if ( fileStatus . isDir ( ) ) {", "commit_type": "make"}
{"commit_tokens": ["use", "reflection", "to", "get", "the", "source", "and", "target", "(", "this", "guarantees", "and", "preserves", "the", "changes", "via", "SFG", ")", "."], "add_tokens": "// eventable.setSourceStateVertix(currentHold);", "del_tokens": "eventable . setSourceStateVertix ( currentHold ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "incorrect", "removal", "of", "FormElementController"], "add_tokens": "return removeElement ( element . getName ( ) ) ;", "del_tokens": "return elements . remove ( element . getName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "@Json", "annotations", "to", "Ride", ".", "Status", "values"], "add_tokens": "import com . squareup . moshi . Json ; @ Json ( name = \"processing\" ) PROCESSING ( \"processing\" ) , @ Json ( name = \"no_drivers_available\" ) NO_DRIVERS_AVAILABLE ( \"no_drivers_available\" ) , @ Json ( name = \"accepted\" ) ACCEPTED ( \"accepted\" ) , @ Json ( name = \"arriving\" ) ARRIVING ( \"arriving\" ) , @ Json ( name = \"in_progress\" ) IN_PROGRESS ( \"in_progress\" ) , @ Json ( name = \"driver_canceled\" ) DRIVER_CANCELED ( \"driver_canceled\" ) , @ Json ( name = \"rider_canceled\" ) RIDER_CANCELED ( \"rider_canceled\" ) , @ Json ( name = \"completed\" ) COMPLETED ( \"completed\" ) ;", "del_tokens": "PROCESSING ( \"processing\" ) , NO_DRIVERS_AVAILABLE ( \"no_drivers_available\" ) , ACCEPTED ( \"accepted\" ) , ARRIVING ( \"arriving\" ) , IN_PROGRESS ( \"in_progress\" ) , DRIVER_CANCELED ( \"driver_canceled\" ) , RIDER_CANCELED ( \"rider_canceled\" ) , COMPLETED ( \"completed\" ) ; @ Override public String toString ( ) { return this . value ; }", "commit_type": "add"}
{"commit_tokens": ["Adding", "jvm", ".", "options", "to", "Karaf", "."], "add_tokens": "import org . apache . commons . lang3 . StringUtils ; import org . junit . Assert ; public class ManagedServiceFactoryIT extends Assert { @ Inject @ Filter ( \"(language=spanish)\" ) private Greeter spanishGreeter ; final String jvmOptions = StringUtils . defaultIfBlank ( System . getProperty ( \"jvm.options\" ) , \"-Dnoop\" ) ; vmOption ( jvmOptions ) , editConfigurationFileExtend ( \"etc/com.savoirtech.eos.itest.bundle.greeter-2.cfg\" , \"language\" , \"spanish\" ) , editConfigurationFileExtend ( \"etc/com.savoirtech.eos.itest.bundle.greeter-2.cfg\" , \"pattern\" , \"Hola, %s!\" ) , assertEquals ( \"Hello, OSGi!\" , helloService . sayHello ( \"english\" , \"OSGi\" ) ) ; assertEquals ( \"Hola, OSGi!\" , helloService . sayHello ( \"spanish\" , \"OSGi\" ) ) ;", "del_tokens": "public class ManagedServiceFactoryIT { System . out . println ( helloService . sayHello ( \"english\" , \"OSGi\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "Class", ".", "isEnum", "instead", "of", "destinationType", ".", "isSubOf", "(", "Enum", ".", "class", ")", ";"], "add_tokens": "return destinationType . getType ( ) . isEnum ( ) ;", "del_tokens": "return destinationType . isSubOf ( Enum . class ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "another", "pattern", "of", "FillGap", "example", "."], "add_tokens": "protected float getHeaderTranslationY ( int scrollY ) {", "del_tokens": "private float getHeaderTranslationY ( int scrollY ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "DynamicBean", "DirectBean", "and", "other", "enhancements"], "add_tokens": "import org . joda . beans . DynamicBean ; public class MapBean extends HashMap < String , Object > implements DynamicBean < MapBean > , MetaBean < MapBean > { @ Override public void propertyDefine ( String propertyName , Class < ? > propertyType ) { // no need to define } @ Override public void propertyRemove ( String propertyName ) { remove ( propertyName ) ; }", "del_tokens": "public class MapBean extends HashMap < String , Object > implements Bean < MapBean > , MetaBean < MapBean > {", "commit_type": "add"}
{"commit_tokens": ["Added", "value", "conversion", "when", "setting", "a", "property", "value", "."], "add_tokens": "field . set ( obj , convert ( value , getType ( ) ) ) ; setter . invoke ( obj , convert ( value , getType ( ) ) ) ; private Object convert ( Object value , Class < ? > toType ) { if ( value == null || toType . isAssignableFrom ( value . getClass ( ) ) ) { return value ; } if ( toType . equals ( String . class ) ) { return String . valueOf ( value ) ; } if ( value instanceof String ) { return U . convert ( ( String ) value , toType ) ; } return value ; }", "del_tokens": "field . set ( obj , value ) ; setter . invoke ( obj , value ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "method", "names", "to", "match", "what", "is", "really", "happening", "."], "add_tokens": "public void associateTrace ( Trace < E > trace ) associateTrace ( trace , Thread . currentThread ( ) ) ; public void associateTrace ( Trace < E > trace , Thread thread ) public Trace < E > disassociateTrace ( ) return disassociateTrace ( Thread . currentThread ( ) ) ; public Trace < E > disassociateTrace ( Thread thread )", "del_tokens": "public void startTrace ( Trace < E > trace ) startTrace ( trace , Thread . currentThread ( ) ) ; public void startTrace ( Trace < E > trace , Thread thread ) public Trace < E > endTrace ( ) return endTrace ( Thread . currentThread ( ) ) ; public Trace < E > endTrace ( Thread thread )", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "generic", "form", "methods", "to", "play", "with", "selects", "referenced", "from", "a", "reference", "view"], "add_tokens": "public static final String PATH = \"/Services\" ;", "del_tokens": "public static final String PATH = \"/services\" ;", "commit_type": "add"}
{"commit_tokens": ["fix", "LoggedInFilter", "and", "check", "user", "principal"], "add_tokens": "SecurityContext securityContext = m . get ( SecurityContext . class ) ; if ( securityContext == null || securityContext . getUserPrincipal ( ) == null ) { requestContext . abortWith ( Response . status ( Status . UNAUTHORIZED ) . build ( ) ) ;", "del_tokens": "if ( m . get ( SecurityContext . class ) != null ) { return ; requestContext . abortWith ( Response . status ( Status . UNAUTHORIZED ) . build ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "add", "counter", "support", "on", "standard", "columns"], "add_tokens": "\"TimeUUIDType\" ) , UTF_8_TYPE ( \"UTF8Type\" ) , UUID_TYPE ( \"UUIDType\" ) , COUNTER_TYPE ( \"CounterColumnType\" ) ;", "del_tokens": "\"TimeUUIDType\" ) , UTF_8_TYPE ( \"UTF8Type\" ) , UUID_TYPE ( \"UUIDType\" ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "compile", "error", "with", "new", "camel"], "add_tokens": "@ UriEndpoint ( scheme = \"controller\" , syntax = \"controller:name\" , consumerClass = ControllerConsumer . class , label = \"api\" , title = \"Controller\" )", "del_tokens": "@ UriEndpoint ( scheme = \"controller\" , syntax = \"controller:name\" , consumerClass = ControllerConsumer . class , label = \"api\" )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "tests", "to", "match", "changes", "in", "RF2", "importer", "."], "add_tokens": "import java . math . BigDecimal ; import au . csiro . ontology . model . DecimalLiteral ; DecimalLiteral lit = ( DecimalLiteral ) dt1 . getLiteral ( ) ; Assert . assertEquals ( new BigDecimal ( \"8\" ) , lit . getValue ( ) ) ; DecimalLiteral lit2 = ( DecimalLiteral ) dt2 . getLiteral ( ) ; Assert . assertEquals ( new BigDecimal ( \"500\" ) , lit2 . getValue ( ) ) ; DecimalLiteral lit4 = ( DecimalLiteral ) dt4 . getLiteral ( ) ; Assert . assertEquals ( new BigDecimal ( \"1\" ) , lit4 . getValue ( ) ) ;", "del_tokens": "import au . csiro . ontology . model . FloatLiteral ; FloatLiteral lit = ( FloatLiteral ) dt1 . getLiteral ( ) ; Assert . assertEquals ( 8 , lit . getValue ( ) , 0.001f ) ; FloatLiteral lit2 = ( FloatLiteral ) dt2 . getLiteral ( ) ; Assert . assertEquals ( 500 , lit2 . getValue ( ) , 0.001f ) ; FloatLiteral lit4 = ( FloatLiteral ) dt4 . getLiteral ( ) ; Assert . assertEquals ( 1 , lit4 . getValue ( ) , 0.001f ) ;", "commit_type": "update"}
{"commit_tokens": ["adding", "log4j", "configurations", "adding", "logging", "statements", "to", "unit", "test"], "add_tokens": "import org . apache . log4j . Logger ; private static Logger _logger = Logger . getLogger ( TaskSet . class ) ; _logger . debug ( \"TaskSet queued new task <object: \" + task + \", attribute: \" + attribute + \">\" ) ; { synchronized ( _taskAdded ) { _taskAdded . wait ( timeout ) ; } }", "del_tokens": "System . out . println ( \"Constructing TaskSet\" ) ; _taskAdded . wait ( timeout ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "ClassOption", "for", "AMRulesRegressor", "split", "criterion"], "add_tokens": "import java . sql . PreparedStatement ; //SplitCriterion splitCriterion = new SDRSplitCriterionAMRules(); SplitCriterion splitCriterion = ( SplitCriterion ) ( ( SplitCriterion ) ( ( AMRulesRegressor ) this . amRules ) . splitCriterionOption . getPreMaterializedObject ( ) ) . copy ( ) ;", "del_tokens": "SplitCriterion splitCriterion = new SDRSplitCriterionAMRules ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "network", "type", "negotiation", "causing", "an", "infinite", "loop"], "add_tokens": "JSONObject ob = method . getServers ( \"/networks\" , null , false ) ;", "del_tokens": "JSONObject ob = method . getServers ( getNetworkResource ( ) , null , false ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "push", "buttons", "and", "allow", "button", "creation", "to", "be", "overridden", "if", "desired", "."], "add_tokens": "import com . google . gwt . user . client . ui . ButtonBase ; import com . google . gwt . user . client . ui . PushButton ; contents . setWidget ( 1 , 0 , createButton ( _confirmChoices [ 1 ] , new ClickHandler ( ) { contents . setWidget ( 1 , 1 , createButton ( _confirmChoices [ 0 ] , new ClickHandler ( ) { protected ButtonBase createButton ( String text ) { return new PushButton ( text ) ; }", "del_tokens": "import com . google . gwt . user . client . ui . Button ; contents . setWidget ( 1 , 0 , new Button ( _confirmChoices [ 1 ] , new ClickHandler ( ) { contents . setWidget ( 1 , 1 , new Button ( _confirmChoices [ 0 ] , new ClickHandler ( ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "summary", "tab", "to", "Javametrics", "."], "add_tokens": "* Test method for { @ link com . ibm . javametrics . dataproviders . GCDataProvider # getLatestGCPercentage ( ) } . double gctime = GCDataProvider . getLatestGCPercentage ( ) ; gctime = GCDataProvider . getLatestGCPercentage ( ) ;", "del_tokens": "* Test method for { @ link com . ibm . javametrics . dataproviders . GCDataProvider # getGCCollectionTime ( ) } . double gctime = GCDataProvider . getGCCollectionTime ( ) ; gctime = GCDataProvider . getGCCollectionTime ( ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "tests", "for", "changed", "behaviour", "of", "TimeAxis", ".", "getBaseUnit"], "add_tokens": "@ Test ( expected = ChronoException . class ) PlainTime . axis ( ) . getBaseUnit ( WALL_TIME ) ; @ Test ( expected = ChronoException . class ) PlainTime . axis ( ) . getBaseUnit ( PRECISION ) ; @ Test ( expected = ChronoException . class ) PlainTime . axis ( ) . getBaseUnit ( AM_PM_OF_DAY ) ;", "del_tokens": "import static org . hamcrest . CoreMatchers . nullValue ; @ Test assertThat ( PlainTime . axis ( ) . getBaseUnit ( WALL_TIME ) , is ( nullValue ( ) ) ) ; @ Test assertThat ( PlainTime . axis ( ) . getBaseUnit ( PRECISION ) , is ( nullValue ( ) ) ) ; @ Test assertThat ( PlainTime . axis ( ) . getBaseUnit ( AM_PM_OF_DAY ) , is ( nullValue ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "login", "method", "so", "that", "setting", "the", "resource", "is", "supported", "."], "add_tokens": "public void login ( String username , String password ) throws XMPPException { login ( username , password , \"Smack\" ) ; } / * * * Login to the server using the strongest authentication mode supported by * the server , then set our presence to available . If more than five seconds * elapses in each step of the authentication process without a response from * the server , or if an error occurs , a XMPPException will be thrown . * * @ param username the username . * @ param password the password . * @ param resource the resource . * @ throws XMPPException if an error occurs . * / public synchronized void login ( String username , String password , String resource ) throws XMPPException { // Send the packet packetWriter . sendPacket ( discoveryAuth ) ; // Wait up to five seconds for a response from the server. auth . setResource ( resource ) ; // Send the packet. packetWriter . sendPacket ( auth ) ; // Wait up to five seconds for a response from the server.", "del_tokens": "public synchronized void login ( String username , String password ) throws XMPPException { packetWriter . sendPacket ( discoveryAuth ) ; // Wait up to five seconds for a response from the server. auth . setResource ( \"Smack\" ) ; packetWriter . sendPacket ( auth ) ; // Wait up to five seconds for a response from the server.", "commit_type": "add"}
{"commit_tokens": ["Added", "comments", "regarding", "character", "encoding", "and", "sorting"], "add_tokens": "import redis . clients . jedis . Protocol ; // Redis protocol charset (Jedis uses UTF-8 as a constant) public static final Charset CHARSET = Charset . forName ( Protocol . CHARSET ) ; private DataContainer ( byte [ ] bytes , String string , Source source ) { byte [ ] bytes = str . getBytes ( CHARSET ) ; private int calculateHash ( byte [ ] bytes , String string , Source source ) { switch ( source ) { case BYTES : return Arrays . hashCode ( bytes ) ; case STRING : return string . hashCode ( ) ; default : return 0 ; } } // compare string representation of data (in the same way as redis does)", "del_tokens": "import javax . xml . crypto . Data ; public DataContainer ( byte [ ] bytes , String string , Source source ) { private int calculateHash ( byte [ ] bytes , String string , Source source ) { switch ( source ) { case BYTES : return Arrays . hashCode ( bytes ) ; case STRING : return string . hashCode ( ) ; default : return 0 ; } } byte [ ] bytes = str . getBytes ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "OnDatabaseChange", "to", "improve", "readability"], "add_tokens": "import nl . nl2312 . rxcupboard . OnDatabaseChange ; rxBind ( rxCupboard . changes ( Item . class ) ) . subscribe ( new OnDatabaseChange < Item > ( ) { public void onInsert ( Item entity ) { adapter . add ( entity ) ; } @ Override public void onDelete ( Item entity ) { adapter . remove ( entity ) ;", "del_tokens": "rxBind ( rxCupboard . changes ( Item . class ) ) . subscribe ( new Action1 < DatabaseChange < Item > > ( ) { public void call ( DatabaseChange < Item > databaseChange ) { if ( databaseChange instanceof DatabaseChange . DatabaseInsert ) { adapter . add ( databaseChange . entity ( ) ) ; } else if ( databaseChange instanceof DatabaseChange . DatabaseDelete ) { adapter . remove ( databaseChange . entity ( ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "Content", "Spec", "node", "types", "and", "added", "some", "helper", "methods", "to", "go", "with", "the", "new", "types", "."], "add_tokens": "final Predicate metaDataTopicMatch = criteriaBuilder . equal ( root . get ( \"CSNodeType\" ) , CommonConstants . CS_NODE_META_DATA_TOPIC ) ; final Predicate topicTypeMatches = criteriaBuilder . or ( normalTopicMatch , levelTopicMatch , metaDataTopicMatch ) ;", "del_tokens": "final Predicate topicTypeMatches = criteriaBuilder . or ( normalTopicMatch , levelTopicMatch ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "variables", "and", "methods", "to", "match", "the", "database", "entity", "that", "the", "REST", "entities", "represent", "."], "add_tokens": "import org . jboss . pressgang . ccms . rest . v1 . entities . RESTTranslatedTopicV1 ; public static final String TRANSLATED_TOPIC_NAME = \"translatedTopic\" ; private RESTTranslatedCSNodeStringCollectionV1 translatedNodeStrings_OTM = null ; private RESTTranslatedTopicV1 translatedTopic = null ; if ( translatedTopic != null ) { clone . translatedTopic = translatedTopic . clone ( deepCopy ) ; } clone . translatedTopic = translatedTopic ; public RESTTranslatedTopicV1 getTranslatedTopic ( ) { return translatedTopic ; } public void setTranslatedTopic ( final RESTTranslatedTopicV1 translatedTopic ) { this . translatedTopic = translatedTopic ; } public void explicitSetTranslatedTopic ( final RESTTranslatedTopicV1 translatedTopic ) { this . translatedTopic = translatedTopic ; setParameterToConfigured ( TRANSLATED_TOPIC_NAME ) ; }", "del_tokens": "private RESTTranslatedCSNodeStringCollectionV1 translatedNodeStrings_OTM ;", "commit_type": "add"}
{"commit_tokens": ["Added", "--", "dead", "-", "young", "options"], "add_tokens": "public abstract static class ChainedStackTraceReader implements StackTraceReader {", "del_tokens": "abstract static class ChainedStackTraceReader implements StackTraceReader {", "commit_type": "add"}
{"commit_tokens": ["Change", "MalformedUriTemplate", "and", "VariableExpansion", "exceptions", "to", "runtime", "exceptions"], "add_tokens": "public class MalformedUriTemplateException extends RuntimeException", "del_tokens": "public class MalformedUriTemplateException extends Exception", "commit_type": "change"}
{"commit_tokens": ["adding", "support", "for", "only", "parsing", "Header", "records", "ignoring", "Atom", "records", "."], "add_tokens": "boolean headerOnly ; headerOnly = false ; consumer . setHeaderOnly ( headerOnly ) ; public boolean isHeaderOnly ( ) { return headerOnly ; } public void setHeaderOnly ( boolean flag ) { headerOnly = flag ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "NTLMSSP", "in", "SPNEGO", "default", "to", "it", "."], "add_tokens": "/ * * * * / public static ASN1ObjectIdentifier NTLMSSP_OID ;", "del_tokens": "private static ASN1ObjectIdentifier NTLMSSP_OID ;", "commit_type": "add"}
{"commit_tokens": ["Change", "default", "directory", "monitor", "interval", "from", "5s", "to", "10s"], "add_tokens": "* @ parameter expression = \"${interval}\" default - value = \"10\"", "del_tokens": "* @ parameter expression = \"${interval}\" default - value = \"5\"", "commit_type": "change"}
{"commit_tokens": ["Allow", "whitespace", "in", "comma", "separated", "CLI", "arguments", "."], "add_tokens": "import com . google . common . base . Splitter ; private static final Splitter CLI_OPTION_SPLITTER = Splitter . on ( ',' ) . trimResults ( ) . omitEmptyStrings ( ) ; return CLI_OPTION_SPLITTER . splitToList ( commaSeparatedArg ) ;", "del_tokens": "import java . util . Arrays ; return Arrays . asList ( StringUtils . split ( commaSeparatedArg , ',' ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "pico", "s", "module", "components", "."], "add_tokens": "import org . javers . core . diff . appenders . PropertyChangeSetAppender ; import org . javers . core . diff . calculators . MultiEdgeDifferenceCalculator ; DFSGraphToSetConverter . class , NewObjectAppender . class , ObjectRemovedAppender . class , PropertyChangeSetAppender . class , MultiEdgeDifferenceCalculator . class } ;", "del_tokens": "DFSGraphToSetConverter . class , NewObjectAppender . class , ObjectRemovedAppender . class } ;", "commit_type": "update"}
{"commit_tokens": ["added", "new", "Properties", "for", "Step", "Log", "and", "new", "temp", "API", "exposed", "in", "engine", "execution", "facade"], "add_tokens": "import java . util . Date ; private String orderNumber ; private String parentFlow ; private String type ; public String getOrderNumber ( ) { return orderNumber ; } public void setOrderNumber ( String orderNumber ) { this . orderNumber = orderNumber ; } public String getParentFlow ( ) { return parentFlow ; } public void setParentFlow ( String parentFlow ) { this . parentFlow = parentFlow ; } public String getType ( ) { return type ; } public void setType ( String type ) { this . type = type ; } . append ( this . orderNumber , that . orderNumber ) . append ( this . parentFlow , that . parentFlow ) . append ( this . type , that . type ) . append ( this . orderNumber ) . append ( this . parentFlow ) . append ( this . type )", "del_tokens": "import java . lang . Object ; import java . lang . Override ; import java . lang . String ; import java . util . Date ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "Arguments", "rule", "updated", "MixinReference", "rule", "to", "use", "stack", "values", "instead", "of", "trimming"], "add_tokens": "import com . bazaarvoice . jless . ast . node . InternalNode ; SelectorGroup ( ) , ';' , resolveMixinReference ( NodeTreeUtils . getFirstChild ( ( InternalNode ) pop ( ) , SelectorNode . class ) . toString ( ) , null ) , Class ( ) , name . set ( match ( ) ) , Arguments ( ) , Ws0Nodes ( ) , ';' , Ws0 ( ) , '(' , Ws0 ( ) , Sequence ( Ws0 ( ) , '(' , Ws0 ( ) , ')' , push ( new ArgumentsNode ( ) ) )", "del_tokens": "SelectorGroup ( ) , Ws0Nodes ( ) , ';' , resolveMixinReference ( popMixinName ( ) , null ) , Class ( ) , name . set ( matchMixinName ( ) ) , Arguments ( ) , Ws0Nodes ( ) , ';' , '(' , Ws0 ( ) , Sequence ( '(' , Ws0 ( ) , ')' , push ( new ArgumentsNode ( ) ) ) / * * * Method returns trimmed mixin name * / String matchMixinName ( ) { return super . match ( ) . trim ( ) ; } / * * * Method pops trimmed mixin name * @ return * / String popMixinName ( ) { return pop ( ) . toString ( ) . trim ( ) ; }", "commit_type": "update"}
{"commit_tokens": ["Move", "variable", "to", "where", "it", "is", "used", "."], "add_tokens": "FileChannel channel = raf . getChannel ( ) ; /** Sets the length of the file. */", "del_tokens": "FileChannel channel = raf . getChannel ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Improve", "reliability", "of", "Instance", "creation", "."], "add_tokens": "public class PtrRecord extends Record {", "del_tokens": "class PtrRecord extends Record {", "commit_type": "improve"}
{"commit_tokens": ["Remove", "superflous", "message", ".", "toString", "()", "calls", "which", "made", "JDK14LoggerAdapter", "vulnerable", "to", "null", "input", "."], "add_tokens": "logger . log ( Level . WARNING , msg , t ) ;", "del_tokens": "logger . log ( Level . WARNING , msg . toString ( ) , t ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "cube", "map", "texture", "support", "."], "add_tokens": "/ * * * Add cube map texture support . * / public static final String V_1_6_9 = \"1.6.9\" ; public static final String CURRENT = V_1_6_9 ;", "del_tokens": "public static final String CURRENT = V_1_6_8 ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "usage", "of", "class", "HTMLdtd"], "add_tokens": "import java . util . Locale ; import java . util . Set ; import com . helger . commons . collection . CollectionHelper ; private static final Set < String > EMPTY_HTML_TAGS = CollectionHelper . newSet ( \"AREA\" , \"BASE\" , \"BASEFONT\" , \"BR\" , \"COL\" , \"FRAME\" , \"HR\" , \"IMG\" , \"INPUT\" , \"ISINDEX\" , \"LINK\" , \"META\" , \"PARAM\" ) ; private static boolean _isHTMLEmptyTag ( @ Nonnull final String sTagName ) { return EMPTY_HTML_TAGS . contains ( sTagName . toUpperCase ( Locale . US ) ) ; } bPrintClosingTag = ! _isHTMLEmptyTag ( sTagName ) ;", "del_tokens": "bPrintClosingTag = ! HTMLdtd . isEmptyTag ( sTagName ) ;", "commit_type": "remove"}
{"commit_tokens": ["made", "base", "class", "for", "resultset", "and", "statement", "for", "fetching", "methods"], "add_tokens": "import nl . topicus . jdbc . AbstractCloudSpannerFetcher ; abstract class AbstractCloudSpannerResultSet extends AbstractCloudSpannerFetcher implements ResultSet", "del_tokens": "import nl . topicus . jdbc . metadata . AbstractCloudSpannerWrapper ; abstract class AbstractCloudSpannerResultSet extends AbstractCloudSpannerWrapper implements ResultSet @ Override public void setFetchDirection ( int direction ) throws SQLException { if ( direction != ResultSet . FETCH_FORWARD ) throw new SQLFeatureNotSupportedException ( \"Only FETCH_FORWARD is supported\" ) ; } @ Override public int getFetchDirection ( ) throws SQLException { return ResultSet . FETCH_FORWARD ; } @ Override public void setFetchSize ( int rows ) throws SQLException { // silently ignore } @ Override public int getFetchSize ( ) throws SQLException { return 1 ; }", "commit_type": "make"}
{"commit_tokens": ["Allow", "more", "aspects", "of", "the", "interface", "to", "be", "modified"], "add_tokens": "private Pagination . InterfaceRenderer renderInterface = Pagination . DEFAULT_INTERFACE_RENDERER ; private int interfaceWidth = Pagination . INTERFACE_WIDTH ; private @ MonotonicNonNull IntFunction < String > pageCommand ; public Pagination . @ NonNull Builder < T > renderInterface ( final Pagination . @ NonNull InterfaceRenderer renderInterface ) { this . renderInterface = renderInterface ; public Pagination . @ NonNull Builder < T > interfaceWidth ( final int width ) { this . interfaceWidth = width ; this . renderInterface , this . interfaceWidth ,", "del_tokens": "import org . checkerframework . checker . nullness . qual . Nullable ; private Pagination . EmptyRenderer renderEmpty = PaginationImpl . RENDER_EMPTY ; private Pagination . UnknownPageRenderer renderUnknownPage = PaginationImpl . RENDER_UNKNOWN_PAGE ; private @ Nullable IntFunction < String > pageCommand ; public Pagination . @ NonNull Builder < T > renderEmpty ( final Pagination . @ NonNull EmptyRenderer renderEmpty ) { this . renderEmpty = renderEmpty ; public Pagination . @ NonNull Builder < T > renderUnknownPage ( final Pagination . @ NonNull UnknownPageRenderer renderUnknownPage ) { this . renderUnknownPage = renderUnknownPage ; this . renderEmpty , this . renderUnknownPage ,", "commit_type": "allow"}
{"commit_tokens": ["Add", "a", "try", "/", "catch", "to", "EmbeddedServerHelper", ".", "teardown", "to", "shut", "up", "io", "exceptions"], "add_tokens": "public void teardown ( ) { try { cleaner . cleanupDataDirectories ( ) ; rmdir ( TMP ) ; } catch ( IOException e ) { // IGNORE }", "del_tokens": "public void teardown ( ) throws IOException { cleaner . cleanupDataDirectories ( ) ; rmdir ( TMP ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "small", "size", "image", "generation"], "add_tokens": "mGeneratedDateIcon = mImageGenerator . generateDateImage ( mCurrentDate , R . drawable . empty_calendar ) ;", "del_tokens": "mGeneratedDateIcon = mImageGenerator . generateDateImage ( mCurrentDate , R . drawable . calendar_empty ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ordering", "issue", "with", "singleton", "scope", "OAuth2"], "add_tokens": "@ Configuration protected abstract static class OAuth2RestTemplateConfiguration { @ Bean @ Primary public OAuth2RestTemplate oauth2RestTemplate ( OAuth2ClientContext oauth2ClientContext , OAuth2ProtectedResourceDetails details ) { OAuth2RestTemplate template = new OAuth2RestTemplate ( details , oauth2ClientContext ) ; return template ; }", "del_tokens": "@ Bean @ Primary public OAuth2RestTemplate oauth2RestTemplate ( OAuth2ClientContext oauth2ClientContext , OAuth2ProtectedResourceDetails details ) { OAuth2RestTemplate template = new OAuth2RestTemplate ( details , oauth2ClientContext ) ; return template ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "Image", "to", "the", "list", "of", "classes", "to", "stub", ".", "It", "does", "strange", "contortions", "with", "elements", "that", "are", "difficult", "to", "work", "around", "."], "add_tokens": "import com . google . gwt . user . client . ui . Image ; * { @ link Widget } , { @ link Image } , and most subclasses of { @ link Panel } . It will also include any * classes specified via the { @ link WithClassesToStub } annotation on the test class . This makes * it much safer to test code that uses or extends these types . classes . add ( Image . class ) ;", "del_tokens": "* { @ link Widget } , and most subclasses of { @ link Panel } . It will also include any classes * specified via the { @ link WithClassesToStub } annotation on the test class . This makes it much * safer to test code that uses or extends these types .", "commit_type": "add"}
{"commit_tokens": ["Add", "additional", "/", "remaining", "test", "cases", "for", "the", "ThreadAdapter", "class", "."], "add_tokens": "* Causes the current , executing Thread to join and wait for this Thread to terminate . * Causes the current , executing Thread to join and wait for this Thread to terminate , or until the specified * Causes the current executing Thread to join and wait for this Thread to terminate , or until the specified", "del_tokens": "* Causes the current executing Thread to join and wait for this Thread to terminate . * Causes the current executing Thread to join and wait for this Thread to terminate or until the specified * Causes the current executing Thread to join and wait for this Thread to terminate or until the specified", "commit_type": "add"}
{"commit_tokens": ["Change", "postInvalidate", "to", "invalidate", "for", "updateSeries", "method", "."], "add_tokens": "invalidate ( ) ;", "del_tokens": "postInvalidate ( ) ;", "commit_type": "change"}
{"commit_tokens": ["remove", "generic", "signature", "since", "it", "causes", "issues", "when", "using", "non", "-", "writables"], "add_tokens": "@ SuppressWarnings ( \"rawtypes\" ) public class ESHiveOutputFormat extends ESOutputFormat implements HiveOutputFormat { public RecordWriter getHiveRecordWriter ( JobConf jc , Path finalOutPath , Class valueClass , boolean isCompressed , Properties tableProperties , Progressable progress ) {", "del_tokens": "import java . util . Map ; public class ESHiveOutputFormat extends ESOutputFormat implements HiveOutputFormat < Object , Map < Writable , Writable > > { public RecordWriter getHiveRecordWriter ( JobConf jc , Path finalOutPath , Class < ? extends Writable > valueClass , boolean isCompressed , Properties tableProperties , Progressable progress ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "configuration", "option", "for", "floating", "ips"], "add_tokens": "private Map < String , String > serviceProperties ; public static PropertiesBuilder newBuilder ( ) { public PropertiesBuilder putProperty ( String key , String value ) { return this ; } public PropertiesBuilder putProperties ( Map < String , String > map ) { this . serviceProperties . putAll ( map ) ; return this ; return new PropertiesImpl ( ImmutableMap . < String , String > builder ( ) . putAll ( this . serviceProperties ) . build ( ) ) ;", "del_tokens": "private final Map < String , String > serviceProperties ; public static PropertiesBuilder create ( ) { public void setProperty ( String key , String value ) { return new PropertiesImpl ( ImmutableMap . < String , String > builder ( ) . putAll ( this . serviceProperties ) . build ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "string", "comparision", "while", "setting", "thriftClass", "conf", "in", "ThriftUtils", "."], "add_tokens": "if ( ! existingThrift . equals ( thriftClass . getName ( ) ) ) { \"Already registered a different thriftClass for \" + genericClass . getName ( ) + \". old: \" + existingThrift + \" new: \" + thriftClass ) ;", "del_tokens": "if ( existingThrift != thriftClass . getName ( ) ) { \"Register different thriftClass for the same format class: \" + genericClass . getName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "enabling", "/", "disabling", "swipe", "directions"], "add_tokens": "/ * * * Enable a swipe direction ( none are enabled by default ) * Automatically adds on addBackground * * @ param direction Integer const from SwipeDirections * / public SwipeActionAdapter addEnabledDirection ( Integer direction ) { mTouchListener . addEnabledDirection ( direction ) ; return this ; } if ( SwipeDirections . getAllDirections ( ) . contains ( key ) ) { mBackgroundResIds . put ( key , resId ) ; addEnabledDirection ( key ) ; }", "del_tokens": "if ( SwipeDirections . getAllDirections ( ) . contains ( key ) ) mBackgroundResIds . put ( key , resId ) ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "the", "co", "-", "class", "support", "."], "add_tokens": "* return true if this interface is a dual interface boolean isDual ( ) ; / * * * get the vtable interface of this dispatch interface . Works only when this is a dual interface . * / @ VTID ( 10 )", "del_tokens": "* get the vtable interface of this dispatch interface . Works only when this is a dual interface .", "commit_type": "implement"}
{"commit_tokens": ["Implemented", "test", "for", "U", ".", "map", "(", "2", "entries", ")", "."], "add_tokens": "Map < String , Integer > map = U . map ( \"a\" , 1 , \"b\" , 2 ) ; eq ( ( map . size ( ) ) , 2 ) ; eq ( ( map . get ( \"a\" ) . intValue ( ) ) , 1 ) ; eq ( ( map . get ( \"b\" ) . intValue ( ) ) , 2 ) ;", "del_tokens": "fail ( \"Not yet implemented\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Adds", "better", "javadoc", "on", "TagKey", "/", "Value", "factory", "methods", "."], "add_tokens": "* Constructs a new { @ link TagKey } from the given string . The string will be sanitize such that : * < ol > * < li > length is restricted to { @ link MAX_LENGTH } , strings longer than that will be truncated . * < li > characters are restricted to printable ascii characters , non - printable characters will be * replaced by an underscore '_' . * < / ol >", "del_tokens": "* Constructs a new { @ link TagKey } from the given string .", "commit_type": "add"}
{"commit_tokens": ["Removed", "some", "hard", "-", "coded", "algorithms", "."], "add_tokens": "import org . bouncycastle . asn1 . DEROctetString ; import com . google . code . jscep . util . AlgorithmDictionary ; public PkcsPkiEnvelope parse ( ContentInfo envContentInfo ) throws IOException { LOGGER . entering ( getClass ( ) . getName ( ) , \"parse\" , envContentInfo ) ; assert ( envContentInfo . getContentType ( ) . equals ( CMSObjectIdentifiers . data ) ) ; final DEROctetString octetString = ( DEROctetString ) envContentInfo . getContent ( ) ; final ContentInfo envInfo = ContentInfo . getInstance ( ASN1Object . fromByteArray ( octetString . getOctets ( ) ) ) ; final Cipher cipher = Cipher . getInstance ( AlgorithmDictionary . lookup ( keyTransInfo . getKeyEncryptionAlgorithm ( ) ) ) ; // TODO: Hardcoded Algorithm final Cipher msgCipher = Cipher . getInstance ( AlgorithmDictionary . lookup ( algId ) ) ;", "del_tokens": "public PkcsPkiEnvelope parse ( byte [ ] envelopeBytes ) throws IOException { LOGGER . entering ( getClass ( ) . getName ( ) , \"parse\" , envelopeBytes ) ; final ContentInfo envInfo = ContentInfo . getInstance ( ASN1Object . fromByteArray ( envelopeBytes ) ) ; // TODO: Hardcoded Algorithm final Cipher cipher = Cipher . getInstance ( \"RSA\" ) ; // TODO: Hardcoded Algorithm final Cipher msgCipher = Cipher . getInstance ( \"DES/CBC/PKCS5Padding\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "serialization", "examples", "back", "in"], "add_tokens": "import io . fabric8 . kubernetes . client . ConfigBuilder ; import static io . fabric8 . kubernetes . client . internal . SerializationUtils . dumpAsYaml ; import static io . fabric8 . kubernetes . client . internal . SerializationUtils . dumpWithoutRuntimeStateAsYaml ; ReplicationController gotRc = client . replicationControllers ( ) . inNamespace ( \"thisisatest\" ) . withName ( \"nginx-controller\" ) . get ( ) ; log ( \"Get RC by name in namespace\" , gotRc ) ; // Dump the RC as YAML log ( \"Dump RC as YAML\" , dumpAsYaml ( gotRc ) ) ; log ( \"Dump RC as YAML without state\" , dumpWithoutRuntimeStateAsYaml ( gotRc ) ) ; Thread . sleep ( 1000 ) ; //Create another RC inline Thread . sleep ( 1000 ) ;", "del_tokens": "import io . fabric8 . kubernetes . api . model . ConfigBuilder ; log ( \"Get RC by name in namespace\" , client . replicationControllers ( ) . inNamespace ( \"thisisatest\" ) . withName ( \"nginx-controller\" ) . get ( ) ) ; //Create an ohter RC inline", "commit_type": "add"}
{"commit_tokens": ["Add", "core", "SeedRunner", "and", "its", "SPI", "(", "retrofitted", "to", "CLI", "runner", ")"], "add_tokens": "import org . seedstack . seed . core . spi . SeedRunnable ; public class SeedRunner implements SeedRunnable { @ Override public int run ( String [ ] args ) throws Exception { return execute ( args ) ;", "del_tokens": "public final class SeedRunner { private SeedRunner ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "for", "demo", "app"], "add_tokens": "import android . widget . ImageView ; //Tests that every single name on the ListView is being displayed. public void testListViewPeople ( ) { //Tests that the click listener works on the first item of the ListView. public void testListViewClickOnImage ( ) { //Tests that every single name on the RecyclerView is being displayed. public void testRecyclerViewPeople ( ) { solo . clickOnText ( getActivity ( ) . getString ( R . string . tab_2_name ) ) ; solo . sleep ( 500 ) ; List < Person > listPeople = DataProvider . getListPeople ( ) ; for ( Person person : listPeople ) { assertTrue ( solo . searchText ( person . getName ( ) , 1 , true , true ) ) ; } } //Tests that the click listener works on the first item of the RecyclerView. public void testRecyclerViewClickOnImage ( ) { solo . clickOnText ( getActivity ( ) . getString ( R . string . tab_2_name ) ) ; List < Person > listPeople = DataProvider . getListPeople ( ) ; solo . clickOnView ( solo . getCurrentViews ( ImageView . class , solo . getView ( R . id . recycler_view ) ) . get ( 0 ) ) ; assertTrue ( solo . waitForText ( getActivity ( ) . getString ( R . string . my_name_string , listPeople . get ( 0 ) . getName ( ) ) ) ) ; }", "del_tokens": "//Tests that every single name on the list is being displayed. public void testListPeople ( ) { //Tests that the click listener works on the first item of the list. public void testClickOnImage ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "Hover", "Style", "on", "each", "Steps", "."], "add_tokens": "import gwt . material . design . client . base . HasTitle ; import gwt . material . design . client . constants . Axis ; public class MaterialStep extends ComplexWidget implements HasActive , HasTitle { private Div divDescription = new Div ( ) ; @ Override protected void onLoad ( ) { super . onLoad ( ) ; if ( getParent ( ) instanceof MaterialStepper ) { MaterialStepper stepper = ( MaterialStepper ) getParent ( ) ; if ( stepper . getAxis ( ) == Axis . HORIZONTAL ) { conCircle . add ( divTitle ) ; } else { conBody . insert ( divTitle , 0 ) ; } conCircle . add ( divLine ) ; } } public void setTitle ( String title ) { divTitle . getElement ( ) . setInnerHTML ( title ) ; public void setDescription ( String description ) { divDescription . setStyleName ( \"description\" ) ; divDescription . getElement ( ) . setInnerHTML ( description ) ; conBody . insert ( divDescription , 1 ) ;", "del_tokens": "public class MaterialStep extends ComplexWidget implements HasActive { private String title ; public String getTitle ( ) { return title ; public void setTitle ( String title ) { this . title = title ; divTitle . getElement ( ) . setInnerHTML ( title ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "class", "package", "-", "local"], "add_tokens": "class GetterStrippingMBeanInfo", "del_tokens": "public class GetterStrippingMBeanInfo", "commit_type": "make"}
{"commit_tokens": ["Use", "0", "as", "a", "sentinel", "for", "no", "timeout", "."], "add_tokens": "if ( timeoutNanos == 0 && ! hasDeadline ) { if ( timeoutNanos != 0 && hasDeadline ) { } else if ( timeoutNanos != 0 ) {", "del_tokens": "if ( timeoutNanos == - 1 && ! hasDeadline ) { if ( timeoutNanos != - 1 && hasDeadline ) { } else if ( timeoutNanos != - 1 ) {", "commit_type": "use"}
{"commit_tokens": ["adding", "failing", "tests", "for", "endpoints", "."], "add_tokens": "import com . couchbase . client . core . service . Service ; * ( { @ link Service } has to handle it .", "del_tokens": "* ( { @ link com . couchbase . client . core . service . Service } has to handle it .", "commit_type": "add"}
{"commit_tokens": ["Fix", "get", "impl", "vendor", "for", "cxf"], "add_tokens": "return vendor . toLowerCase ( ) . indexOf ( \"apache\" ) != - 1 ;", "del_tokens": "return vendor . toLowerCase ( ) . indexOf ( \"cxf\" ) != - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["added", "@SerializedName", "for", "multi", "-", "word", "fields", "-", "thanks", "@vinhhv"], "add_tokens": "/ * * * Represents < code > / batches < / code > endpoint documented at * https : //goshippo.com/docs/reference#batches @ SerializedName ( \"metadata\" ) @ SerializedName ( \"default_carrier_account\" ) @ SerializedName ( \"default_servicelevel_token\" ) @ SerializedName ( \"label_filetype\" ) @ SerializedName ( \"batch_shipments\" ) @ SerializedName ( \"creation_succeeded\" ) @ SerializedName ( \"creation_failed\" ) @ SerializedName ( \"purchase_succeeded\" ) @ SerializedName ( \"purchase_failed\" ) @ SerializedName ( \"object_results\" )", "del_tokens": "/ * * Represents . . / batches endpoint documented at https : //goshippo.com/docs/reference#batches private int count ; private String previous ; private String next ;", "commit_type": "add"}
{"commit_tokens": ["add", "light", "version", "based", "on", "spark"], "add_tokens": "package com . github . avarabyeu . jashing ;", "del_tokens": "package com . github . avarabyeu . jashing . controllers ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "error", "messages", "based", "on", "feedback", "from", "mcasperson", "."], "add_tokens": "\"A previous revision of this topic has been pushed to Zanata, and has not yet been translated.\" + \"This previous revision has been included in the book, but will display content that is older than what was defined by the Content Specification.\" , \"A previous revision of this topic has been pushed to Zanata, and has been translated.\" + \" This previous revision has been included in the book, but will display content that is older than what was defined by the Content Specification.\" , + \" In most cases the existing translations will be able to be reused when the topic is pushed to Zanata.\"", "del_tokens": "\"An older revision of this topic has been pushed to Zanata, but has not been translated.\" + \" As such the topic will be displayed using the untranslated content and possibly contain invalid translations, once translated.\" , \"An older revision of this topic has been pushed to Zanata, but has been translated.\" + \" As such the topic may possibly contain invalid translations.\" , + \" In most cases the older translations will be able to be reused when pushed to Zanata.\"", "commit_type": "update"}
{"commit_tokens": ["Add", "unpredictable", "number", "to", "GPO"], "add_tokens": "import java . security . SecureRandom ; import com . github . devnied . emvnfccard . model . enums . TransactionTypeEnum ; public final class EMVTerminal { / * * * Random * / private static final SecureRandom random = new SecureRandom ( ) ; val = new byte [ ] { ( byte ) TransactionTypeEnum . PURCHASE . getKey ( ) } ; val = BytesUtils . fromString ( \"01\" ) ; } else if ( pTagAndLength . getTag ( ) == EMVTags . UNPREDICTABLE_NUMBER ) { random . nextBytes ( ret ) ; private EMVTerminal ( ) {", "del_tokens": "public final class TagValueFactory { val = BytesUtils . fromString ( \"00\" ) ; val = BytesUtils . fromString ( \"00\" ) ; private TagValueFactory ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "build", ".", "Unfortunately", "another", "regexp", "rule", "was", "required", "."], "add_tokens": "public static /* replaceWith:genericSignature */ < KType , VType > /* end:replaceWith */ ObjectObjectOpenHashMap < KType , VType > from ( KType [ ] keys , VType [ ] values ) public static /* replaceWith:genericSignature */ < KType , VType > /* end:replaceWith */", "del_tokens": "public static /* removeIf:primitive */ < KType , VType > /* end:removeIf */ ObjectObjectOpenHashMap < KType , VType > from ( KType [ ] keys , VType [ ] values ) public static /* removeIf:primitive */ < KType , VType > /* end:removeIf */", "commit_type": "fix"}
{"commit_tokens": ["Added", "tutorial", "for", "custom", "type", "conversion"], "add_tokens": "private final Class < ? > projectionInterface ; @ SuppressWarnings ( \"unchecked\" ) public < T extends TypeConverter > T getTypeConverterAs ( Class < T > ... clazz ) { return ( T ) XBProjector . this . typeConverter ; }", "del_tokens": "private final Class projectionInterface ;", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "to", "query", "and", "insert", "rich", "-", "text", "content", "."], "add_tokens": "/ * * * Rich - text content of this text - editing area . * The returned document is immutable , it does not reflect * subsequent edits of this text - editing area . * / StyledDocument < S > getDocument ( ) ; / * * * Returns rich - text content of the given paragraph . * / StyledDocument < S > subDocument ( int paragraphIndex ) ; / * * * Returns rich - text content of the given character range . * / StyledDocument < S > subDocument ( int start , int end ) ; / * * * Replaces a range of characters with the given rich - text document . * / void replace ( int start , int end , StyledDocument < S > replacement ) ; / * * * Equivalent to * { @ code replace ( range . getStart ( ) , range . getEnd ( ) , replacement ) } . * / default void replace ( IndexRange range , StyledDocument < S > replacement ) { replace ( range . getStart ( ) , range . getEnd ( ) , replacement ) ; }", "del_tokens": "void replace ( int start , int end , StyledDocument < S > replacement ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "Multi", "table", "test", "case"], "add_tokens": "KeysAndAttributes keysAndAttributes1 = new KeysAndAttributes ( ) ; List < String > attributesToGet1 = new ArrayList < String > ( ) ; attributesToGet1 . add ( hashKeyValue2 ) ; keysAndAttributes1 . setAttributesToGet ( attributesToGet1 ) ; keys . add ( new Key ( new AttributeValue ( \"1\" ) ) ) ; keysAndAttributes1 . setKeys ( keys ) ; // requestItems.put(\"Vito's Table\", keysAndAttributes); requestItems . put ( tableName2 , keysAndAttributes1 ) ; //Test on Table 2", "del_tokens": "keys . add ( new Key ( new AttributeValue ( \"7\" ) ) ) ; requestItems . put ( \"Vito's Table\" , keysAndAttributes ) ; requestItems . put ( tableName2 , keysAndAttributes ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "stylesheet", "Friendly", "+", "extract", "and", "enhance", "Style"], "add_tokens": "import static gutenberg . util . Style . style ;", "del_tokens": "import static gutenberg . pygments . Style . style ;", "commit_type": "add"}
{"commit_tokens": ["Add", "simple", "method", "to", "build", "OrientRequiredResources", "by", "String"], "add_tokens": "return requireResource ( ODatabaseSecurityResources . CLASS + \".\" + oClass . getName ( ) , permissions ) ; } public static RequiredOrientResource [ ] requireResource ( final String resource , final OrientPermission ... permissions ) { return new RequiredOrientResource [ ] { new RequiredOrientResourceImpl ( resource , permissions ) } ;", "del_tokens": "return new RequiredOrientResource [ ] { new RequiredOrientResourceImpl ( ODatabaseSecurityResources . CLASS + \".\" + oClass . getName ( ) , permissions ) } ;", "commit_type": "add"}
{"commit_tokens": ["changed", "visibility", "to", "allow", "adding", "rules"], "add_tokens": "public void addRule ( Rule rule ) {", "del_tokens": "protected void addRule ( Rule rule ) {", "commit_type": "change"}
{"commit_tokens": ["Update", "exception", "message", "in", "run", "listener", "rather", "than", "just", "sysoutting", "the", "report", "."], "add_tokens": "import java . lang . reflect . Field ; String scottReport = FailureRenderer . render ( description , failure . getException ( ) ) ; setExceptionMessage ( failure . getException ( ) , scottReport ) ; private void setExceptionMessage ( Object object , Object fieldValue ) { final String fieldName = \"detailMessage\" ; Class < ? > clazz = object . getClass ( ) ; while ( clazz != null ) { try { Field field = clazz . getDeclaredField ( fieldName ) ; field . setAccessible ( true ) ; field . set ( object , fieldValue ) ; return ; } catch ( NoSuchFieldException e ) { clazz = clazz . getSuperclass ( ) ; } catch ( Exception e ) { throw new IllegalStateException ( e ) ; } } }", "del_tokens": "// TODO: the simple System.out.println really not fits nicely into the test reports. // try changing the original exception's message with reflection. See issue #8. System . out . println ( failure . getTestHeader ( ) + \" FAILED!\" ) ; System . out . println ( FailureRenderer . render ( description , failure . getException ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "annotations", "to", "the", "user", "class"], "add_tokens": "import edu . ksu . canvas . annotation . CanvasField ; import edu . ksu . canvas . annotation . CanvasObject ; @ CanvasObject ( postKey = \"user\" ) @ CanvasField ( postKey = \"name\" ) @ CanvasField ( postKey = \"sortable_name\" ) @ CanvasField ( postKey = \"short_name\" ) @ CanvasField ( overrideObjectKey = \"pseudonym\" , postKey = \"sis_user_id\" ) @ CanvasField ( postKey = \"avatar][url\" ) @ CanvasField ( postKey = \"email\" ) @ CanvasField ( postKey = \"time_zone\" )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "https", "tests", "for", "http", "-", "connector", "."], "add_tokens": "private boolean sslTrustAll ; if ( sslTrustAll ) { log . warning ( \"SSL: Creating connection using 'trust all' option\" ) ; sslTrustAll = msg . getRequestObject ( ) . getTrustAll ( ) ; if ( sslTrustAll ) { log . warning ( \"SSL: Trusting all certificates. This option should be considered unsecure and should not be enabled in production environments.\" ) ; builder . loadTrustMaterial ( null , new TrustSelfSignedStrategy ( ) ) ; } builder . loadTrustMaterial ( ks ) ;", "del_tokens": "private boolean sslAllowAllHostnames ; if ( sslAllowAllHostnames ) { TrustStrategy strat = null ; if ( msg . getRequestObject ( ) . getTrustSelfSigned ( ) ) { strat = new TrustSelfSignedStrategy ( ) ; } builder . loadTrustMaterial ( ks , strat ) ; sslAllowAllHostnames = msg . getRequestObject ( ) . getAllowAllHostnames ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "test", "case", "for", "load", "Collection"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "handle", "embedded", "end", "of", "line", "characters", "in", "notes", "."], "add_tokens": "if ( m_note != null ) { m_note = m_note . replace ( EOL_PLACEHOLDER , '\\n' ) ; } if ( m_note != null ) { buffer . append ( m_note . replace ( '\\n' , EOL_PLACEHOLDER ) ) ; } / * * * Placeholder character used in MPX files to represent * carriage returns embedded in note text . * / private static final char EOL_PLACEHOLDER = ( char ) 0x7F ;", "del_tokens": "buffer . append ( m_note ) ;", "commit_type": "update"}
{"commit_tokens": ["fixes", "toExcelPivot", "was", "passing", "null", "instead", "of", "sheetName", "in", "one", "of", "the", "overloads"], "add_tokens": "return excelServiceImpl . toExcelPivot ( domainObjects , cls , sheetName , fileName ) ;", "del_tokens": "return excelServiceImpl . toExcelPivot ( domainObjects , cls , null , fileName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "createPictureDrawable", "=", ">", "getDrawable"], "add_tokens": "import android . graphics . drawable . Drawable ; private final Picture picture ; private final RectF bounds ; private PictureDrawable drawable = null ; * Get a { @ link Drawable } of the SVG . public PictureDrawable getDrawable ( ) { if ( drawable == null ) { drawable = new PictureDrawable ( picture ) ; } return drawable ;", "del_tokens": "private Picture picture ; private RectF bounds ; * Create a picture drawable from the SVG . public PictureDrawable createPictureDrawable ( ) { return new PictureDrawable ( picture ) ;", "commit_type": "change"}
{"commit_tokens": ["Makes", "minor", "improvements", "to", "debug", "documentation", "."], "add_tokens": "* *", "del_tokens": "* *", "commit_type": "make"}
{"commit_tokens": ["Changed", "no", "-", "arg", "constructor", "to", "a", "form", "more", "suitable", "for", "unit", "testing", "."], "add_tokens": "protected TestingAuthenticationToken ( ) { throw new IllegalArgumentException ( \"Cannot use default constructor\" ) ;", "del_tokens": "private TestingAuthenticationToken ( ) { super ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "synonyms", "and", "replace", "synonyms"], "add_tokens": "if ( ! synonyms ) { stringBuilder . append ( \"synonyms=0\" ) ; if ( ! replaceSynonyms ) { stringBuilder . append ( \"replaceSynonymsInHighlight=0\" ) ;", "del_tokens": "if ( synonyms ) { stringBuilder . append ( \"synonyms=1\" ) ; if ( replaceSynonyms ) { stringBuilder . append ( \"replaceSynonymsInHighlight=1\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "unit", "test", "for", "MapperFactoryImpl", "failing"], "add_tokens": "import com . google . common . collect . Iterables ; for ( DAMethod method : Iterables . filter ( daMapperClass . methods , DAMethodPredicates . isMapperFactoryMethod ( ) ) ) {", "del_tokens": "ImmutableList < DAMethod > mapperFactoryMethods = FluentIterable . from ( daMapperClass . methods ) . filter ( new Predicate < DAMethod > ( ) { @ Override public boolean apply ( @ Nullable DAMethod daMethod ) { return daMethod != null && daMethod . mapperFactoryMethod ; } } ) . toList ( ) ; for ( DAMethod method : mapperFactoryMethods ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "serverType", "parameter", "defaulting", "to", "apacheds"], "add_tokens": "/ * * * The server can be one of : * < ul > * < li > apacheds < / li > * < li > opendj < / li > * < li > unboundid < / li > * < / ul > * / @ Parameter ( property = \"ldap.type\" , defaultValue = \"apacheds\" ) private String serverType ; return serverType ;", "del_tokens": "return \"apacheds\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "switch", "off", "reusing", "the", "Node"], "add_tokens": "if ( getNode ( ) != null && ! getNode ( ) . isClosed ( ) )", "del_tokens": "if ( getNode ( ) != null )", "commit_type": "add"}
{"commit_tokens": ["Make", "DataWatcher", "public", "and", "improve", "/", "document", "it"], "add_tokens": "import com . nextfaze . databind . util . DataWatcher ; public void onDataChange ( ) { public void onDataLoadingChange ( ) { public void onDataError ( @ NonNull Throwable e ) { mDataWatcher . setEnabled ( shown ) ;", "del_tokens": "private static final String TAG = DataLayout . class . getSimpleName ( ) ; public void onChange ( ) { public void onLoadingChange ( ) { public void onError ( @ NonNull Throwable e ) { mDataWatcher . setShown ( shown ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "a", "typo", "bug", "in", "IrcDiscoveryTest", ".", "Patch", "from", "Nathan", "Baulch", ".", "Resolves", "issue", "33", "."], "add_tokens": "String formattedIP = decoded [ i ] . getAddress ( ) . getHostAddress ( ) + \":\" + ( ( Integer ) decoded [ i ] . getPort ( ) ) . toString ( ) ; assertEquals ( \"IPs decoded improperly\" , ips [ i ] , formattedIP ) ;", "del_tokens": "String formattedIP = decoded [ 0 ] . getAddress ( ) . getHostAddress ( ) + \":\" + ( ( Integer ) decoded [ i ] . getPort ( ) ) . toString ( ) ; assertEquals ( \"IPs decoded improperly\" , ips [ 0 ] , formattedIP ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "POM", "for", "deploying", "to", "Maven", "central", "and", "corrected", "some", "missing", "Javadoc", "params", "."], "add_tokens": "* @ param context the context for processing the data frame * @ param context the context for processing the data frame * @ param context the context for processing the data frame * * @ param context the context for processing the data frame", "del_tokens": "* @ param context", "commit_type": "update"}
{"commit_tokens": ["Add", "safeSubtract", "(", "long", ")"], "add_tokens": "int result = a - b ; if ( ( a ^ result ) < 0 && ( a ^ b ) < 0 ) { return result ; } / * * * Safely subtracts one long from another . * * @ param a the first value * @ param b the second value to subtract from the first * @ return the result * @ throws ArithmeticException if the result overflows a long * / public static long safeSubtract ( long a , long b ) { long result = a - b ; // check for a change of sign in the result when the inputs have the different signs if ( ( a ^ result ) < 0 && ( a ^ b ) < 0 ) { throw new ArithmeticException ( \"Subtraction overflows a long: \" + a + \" - \" + b ) ; } return result ;", "del_tokens": "int sum = a - b ; if ( ( a ^ sum ) < 0 && ( a ^ b ) < 0 ) { return sum ;", "commit_type": "add"}
{"commit_tokens": ["add", "source", "and", "destination", "exchange", "key"], "add_tokens": "@ JsonProperty ( \"src-exchange-key\" ) private String sourceExchangeKey ; @ JsonProperty ( \"dest-exchange-key\" ) private String destinationExchangeKey ; public String getSourceExchangeKey ( ) { return sourceExchangeKey ; } public void setSourceExchangeKey ( String sourceExchangeKey ) { this . sourceExchangeKey = sourceExchangeKey ; } public String getDestinationExchangeKey ( ) { return destinationExchangeKey ; } public void setDestinationExchangeKey ( String destExchangeKey ) { this . destinationExchangeKey = destExchangeKey ; } return \"ShovelDetails{\" + \"sourceExchange=\" + sourceExchange + \"sourceExchangeKey=\" + sourceExchangeKey + \", sourceQueue=\" + sourceQueue + \", destinationExchange='\" + destinationExchange + \", destinationExchangeKey='\" + destinationExchangeKey + '\\''", "del_tokens": "return \"ShovelDetails{\" + \"sourceExchange=\" + sourceExchange + \", sourceQueue=\" + sourceQueue + \", destinationExchange='\" + destinationExchange + '\\''", "commit_type": "add"}
{"commit_tokens": ["Implement", "the", "remrange", "*", "commands", "zrev", "*", "commands", "next", "."], "add_tokens": "@ Override public Long zremrangebyscore ( String key , String min , String max ) throws WrongTypeException , NotFloatMinMaxException , NotImplementedException {", "del_tokens": "@ Override public Long zremrangebyscore ( String key , String min , String max ) throws WrongTypeException , NotImplementedException {", "commit_type": "implement"}
{"commit_tokens": ["use", "Dependencies", "only", "where", "absolutely", "necessary", "further", "cleanup"], "add_tokens": "List < Dependency > consumerDependencies = new ArrayList < Dependency > ( ) ; Model projectModel = this . project . getModel ( ) ; Dependencies modelDependencies = new Dependencies ( ) ; modelDependencies . addAll ( projectModel . getDependencies ( ) ) ; for ( Profile profile : projectModel . getProfiles ( ) ) if ( modelDependencies . contains ( profileDependency ) ) // our assumption here is that the profileDependency has been added to model because of // allow dynamic dependencies due to OS or JDK. List < Dependency > result = consumerDependencies ; protected void createConsumerDependencies ( Model effectiveModel , List < Dependency > consumerDependencies )", "del_tokens": "Dependencies consumerDependencies = new Dependencies ( ) ; Model model = this . project . getModel ( ) ; // special dependencies are those that have been added via profiles, etc. Dependencies specialDependencies = new Dependencies ( ) ; for ( Dependency dependency : model . getDependencies ( ) ) { if ( ! consumerDependencies . contains ( dependency ) ) { specialDependencies . add ( dependency ) ; } } for ( Profile profile : model . getProfiles ( ) ) if ( specialDependencies . contains ( profileDependency ) ) // our assumption here is that the profileDependency has been added to effective POM because of // allow // dynamic dependencies due to OS or JDK. List < Dependency > result = consumerDependencies . toList ( ) ; protected void createConsumerDependencies ( Model effectiveModel , Dependencies consumerDependencies )", "commit_type": "use"}
{"commit_tokens": ["Implemented", "resetConsumable", "for", "the", "Vacuum", "class"], "add_tokens": "public VacuumConsumableStatus getConsumables ( ) { return consumables ; } case \"reset_consumable\" : return resetConsumableStatus ( paramsArray ) ; private Object resetConsumableStatus ( JSONArray params ) { if ( params == null ) return null ; String name = params . optString ( 0 , \"\" ) ; consumables . reset ( name ) ; return ok ( ) ; }", "del_tokens": "import org . json . JSONObject ; JSONObject paramsObject = null ; if ( params . getClass ( ) == JSONObject . class ) { paramsObject = ( JSONObject ) params ; }", "commit_type": "implement"}
{"commit_tokens": ["fix", "DockerRuleImagePullTest", "test", "/", "don", "t", "start", "container", "to", "test", "pull"], "add_tokens": "log . debug ( \"rule before {}\" , container . id ( ) ) ; log . debug ( \"after {}\" , container . id ( ) ) ; log . debug ( \"{} state {}\" , container . id ( ) , state ) ;", "del_tokens": "super . before ( ) ; log . info ( \"------------ before\" ) ; super . after ( ) ; log . info ( \"------------ after\" ) ; log . debug ( \"container state: {}\" , state ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "debug", "message", "for", "lookup", "plugins", "directory"], "add_tokens": "log . debug ( \"Lookup plugins in '{}'\" , pluginsDirectory . getAbsolutePath ( ) ) ; log . error ( \"No '{}' directory\" , pluginsDirectory . getAbsolutePath ( ) ) ;", "del_tokens": "log . error ( \"No '{}' directory\" , pluginsDirectory ) ;", "commit_type": "add"}
{"commit_tokens": ["Changing", "rule", "format", "in", "PyLint", "to", "CODE", "(", "codeName", ")"], "add_tokens": "final String rootFolder = getRootFolder ( ) ; final List < Violation > actual = violationsReporterApi ( ) // assertThat ( actual . get ( 0 ) . getRule ( ) . orNull ( ) ) // . isEqualTo ( \"0330(bad-continuation)\" ) ;", "del_tokens": "String rootFolder = getRootFolder ( ) ; List < Violation > actual = violationsReporterApi ( ) //", "commit_type": "change"}
{"commit_tokens": ["added", "annotations", "Experimental", "ThrowsRuntimeException", "ThrowsRuntimeExceptions", "improved", "utilities"], "add_tokens": "* @ return the same object from arguments public static Deferred defer ( @ Nonnull final Deferred deferred ) { return deferred ; * @ param < T > type of the object to be processed * @ return the same object from arguments . public static < T > T deferredClose ( @ Nullable final T closeable ) { return closeable ; * * @ param < T > type of closeable object * @ return the same closeable object from arguments public static < T extends Closeable > T defer ( @ Nullable final T closeable ) { return closeable ; * @ return the same runnable object from arguments . public static Runnable defer ( @ Nonnull final Runnable runnable ) { return runnable ; * @ return the same object from arguments public static Disposable defer ( @ Nonnull final Disposable disposable ) { return disposable ;", "del_tokens": "public static void defer ( @ Nonnull final Deferred deferred ) { public static void deferredClose ( @ Nullable final Object closeable ) { * public static void defer ( @ Nullable final Closeable closeable ) { public static void defer ( @ Nonnull final Runnable runnable ) { public static void defer ( @ Nonnull final Disposable disposable ) {", "commit_type": "add"}
{"commit_tokens": ["add", "optional", "trailing", "slashes", "to", "patterns"], "add_tokens": "Pattern . compile ( \"git@(.+):([^/]+)/([^/]+)/?\" ) , Pattern . compile ( \"https?://[^/]+@([^/]+)/([^/]+)/([^/]+)/?\" ) , Pattern . compile ( \"https?://([^/]+)/([^/]+)/([^/]+)/?\" ) , Pattern . compile ( \"git://([^/]+)/([^/]+)/([^/]+)/?\" ) , Pattern . compile ( \"ssh://git@([^/]+)/([^/]+)/([^/]+)/?\" )", "del_tokens": "Pattern . compile ( \"git@(.+):([^/]+)/([^/]+)\" ) , Pattern . compile ( \"https?://[^/]+@([^/]+)/([^/]+)/([^/]+)\" ) , Pattern . compile ( \"https?://([^/]+)/([^/]+)/([^/]+)\" ) , Pattern . compile ( \"git://([^/]+)/([^/]+)/([^/]+)\" ) , Pattern . compile ( \"ssh://git@([^/]+)/([^/]+)/([^/]+)\" )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "multiple", "SQL", "commands", "in", "upgrade", "file"], "add_tokens": "String [ ] cmds = sql . split ( \";\" ) ; for ( String cmd : cmds ) { //Log.d(TAG, \"cmd=\" + cmd); if ( cmd . trim ( ) . length ( ) > 0 ) { db . execSQL ( cmd ) ; } }", "del_tokens": "//Log.d(TAG, sql); db . execSQL ( sql ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "constants", "to", "more", "appropriate", "place"], "add_tokens": "private static final String VAGRANT_DIR_PROPERTY_SUFFIX = \".vagrantDir\" ; private static final String VAGRANT_VM_PROPERTY_SUFFIX = \".vagrantVm\" ; private static final String VAGRANT_IP_PROPERTY_SUFFIX = \".vagrantIp\" ;", "del_tokens": "import static com . xebialabs . overcast . VagrantCloudHost . VAGRANT_DIR_PROPERTY_SUFFIX ; import static com . xebialabs . overcast . VagrantCloudHost . VAGRANT_IP_PROPERTY_SUFFIX ; import static com . xebialabs . overcast . VagrantCloudHost . VAGRANT_VM_PROPERTY_SUFFIX ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "from", "Exception", "to", "warning"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger s_aLogger = LoggerFactory . getLogger ( LoadedFont . class ) ; boolean bWarnedOnTooSmallMaxWidth = false ; boolean bSplitNow = fNewWidth > fMaxWidth ; if ( bSplitNow && nCPOfs == 0 ) { if ( ! bWarnedOnTooSmallMaxWidth ) { s_aLogger . warn ( \"The provided max width (\" + fMaxWidth + \") is too small to hold a single character! Will create an overlap!\" ) ; bWarnedOnTooSmallMaxWidth = true ; } bSplitNow = false ; } if ( bSplitNow )", "del_tokens": "int nIterations = 0 ; final int nMaxIterations = sLine . length ( ) * 3 ; if ( fNewWidth > fMaxWidth ) ++ nIterations ; if ( nIterations > nMaxIterations ) throw new IllegalStateException ( \"Seems to be an endless loop (\" + nIterations + \" iterations). Input String (length \" + sLine . length ( ) + \")=<\" + sLine + \">\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "logging", "in", "MediaSearcher", "client"], "add_tokens": "import org . apache . log4j . Logger ; public final Logger logger = Logger . getLogger ( MediaSearcher . class ) ; try { publisherJedis . publish ( CHANNEL , message ) ; } catch ( Exception e ) { logger . error ( e ) ; } public void delete ( String message ) { try { publisherJedis . publish ( CHANNEL , message ) ; } catch ( Exception e ) { logger . error ( e ) ; }", "del_tokens": "publisherJedis . publish ( CHANNEL , message ) ; public void delete ( String message ) { publisherJedis . publish ( CHANNEL , message ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "test", "for", "error", "handling", "and", "fixed", "issues", "with", "the", "ordering", "test"], "add_tokens": "@ Property ( name = ComponentBindingsProvider . RESOURCE_TYPE_PROP , value = \"test/bindings/order\" ) , bindings . put ( \"message2\" , \"Third\" ) ;", "del_tokens": "@ Property ( name = ComponentBindingsProvider . RESOURCE_TYPE_PROP , value = \"test/bindings/ordered\" ) ,", "commit_type": "add"}
{"commit_tokens": ["fix", "war", "path", "extraction", "."], "add_tokens": "final String warPath = appServerClass . getProtectionDomain ( ) . getCodeSource ( ) . getLocation ( ) . getPath ( ) ; log . info ( \"warPath=[{}]\" , warPath ) ; wac . setWar ( warPath ) ;", "del_tokens": "final URL location = appServerClass . getProtectionDomain ( ) . getCodeSource ( ) . getLocation ( ) ; try { wac . setBaseResource ( Resource . newResource ( location ) ) ; } catch ( final IOException e ) { throw new RuntimeException ( \"cant create server, app server class is unreachable.\" ) ; } public static void main ( final String [ ] args ) { final URL file1 = JettyServer . class . getProtectionDomain ( ) . getCodeSource ( ) . getLocation ( ) ; System . out . println ( \"this jar: \" + file1 ) ; final URL file2 = WebAppContext . class . getProtectionDomain ( ) . getCodeSource ( ) . getLocation ( ) ; System . out . println ( \"jetty jar: \" + file2 ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "transforming", "a", "component", "into", "legacy", "text"], "add_tokens": "public enum TextColor implements TextFormat { BLACK ( '0' ) , DARK_BLUE ( '1' ) , DARK_GREEN ( '2' ) , DARK_AQUA ( '3' ) , DARK_RED ( '4' ) , DARK_PURPLE ( '5' ) , GOLD ( '6' ) , GRAY ( '7' ) , DARK_GRAY ( '8' ) , BLUE ( '9' ) , GREEN ( 'a' ) , AQUA ( 'b' ) , RED ( 'c' ) , LIGHT_PURPLE ( 'd' ) , YELLOW ( 'e' ) , WHITE ( 'f' ) ; / * * * The legacy code . * / @ Deprecated private final char legacy ; TextColor ( final char legacy ) { this . legacy = legacy ; } @ Deprecated @ Override public char legacy ( ) { return this . legacy ; }", "del_tokens": "public enum TextColor { BLACK , DARK_BLUE , DARK_GREEN , DARK_AQUA , DARK_RED , DARK_PURPLE , GOLD , GRAY , DARK_GRAY , BLUE , GREEN , AQUA , RED , LIGHT_PURPLE , YELLOW , WHITE ;", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "new", "GCM", "v3"], "add_tokens": "public void onMessage ( String from , Bundle data ) { System . out . println ( \"### message from: \" + from ) ; for ( String key : data . keySet ( ) ) { System . out . println ( \"> \" + key + \": \" + data . get ( key ) ) ;", "del_tokens": "import eu . inloop . easygcm . WakeLockRelease ; public void onMessage ( String s , Bundle bundle , WakeLockRelease wakeLockRelease ) { System . out . println ( \"### message: \" + s ) ; for ( String key : bundle . keySet ( ) ) { System . out . println ( \"> \" + key + \": \" + bundle . get ( key ) ) ; wakeLockRelease . release ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "app", "cache", "linker", "less", "chatty"], "add_tokens": "logger . log ( TreeLogger . DEBUG , \"Make sure you have the following\"", "del_tokens": "logger . log ( TreeLogger . INFO , \"Make sure you have the following\"", "commit_type": "make"}
{"commit_tokens": ["fixed", "tinkerpop", "test", "suite", "error"], "add_tokens": "import com . steelbridgelabs . oss . neo4j . structure . partitions . NoReadPartition ; if ( configuration == null ) // neo4j driver configuration Config config = Config . build ( ) . toConfig ( ) ; return new Neo4JGraph ( new AnyLabelReadPartition ( graphName ) , new String [ ] { graphName } , driver , vertexIdProvider , edgeIdProvider , configuration ) ; return new Neo4JGraph ( new NoReadPartition ( ) , new String [ ] { } , driver , vertexIdProvider , edgeIdProvider , configuration ) ;", "del_tokens": "if ( null == configuration ) Config config = Config . build ( ) . toConfig ( ) ; return new Neo4JGraph ( new AnyLabelReadPartition ( graphName ) , new String [ ] { graphName } , driver , vertexIdProvider , edgeIdProvider ) ; return new Neo4JGraph ( driver , vertexIdProvider , edgeIdProvider ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "MultiUpdateOperation", "combine", "method", "for", "increment"], "add_tokens": "updates . set ( i , left ) ;", "del_tokens": "AttributeUpdateWrapper newWrapper = left . combineForSameAttribute ( right ) ; if ( newWrapper == null ) { return null ; } updates . set ( i , newWrapper ) ;", "commit_type": "fix"}
{"commit_tokens": ["Create", "the", "JobManager", "after", "booting", "."], "add_tokens": "* Create the job manager . We may need to reschedule jobs and some applications aren 't initializing the * manager in Application . onCreate ( ) . It may happen that some jobs can 't be created if the JobCreator * wasn 't registered, yet. Apps / Libraries need to figure out how to solve this themselves. JobManager . create ( context ) ;", "del_tokens": "* We don 't need to do anything. This receiver causes the app to be loaded. In the onCreate() * method of the Application object we initialize the JobManager . There we reschedule tasks * if necessary .", "commit_type": "create"}
{"commit_tokens": ["Add", "git", "hub", "writer", "to", "write", "project", "contents", "to", "git", "hub"], "add_tokens": "import org . junit . ClassRule ; @ ClassRule public static SetupInitialConext setupInitialConext = new SetupInitialConext ( ) ;", "del_tokens": "import org . junit . BeforeClass ; import javax . naming . Context ; import javax . naming . InitialContext ; import javax . naming . spi . InitialContextFactory ; import javax . naming . spi . InitialContextFactoryBuilder ; import javax . naming . spi . NamingManager ; import java . util . Hashtable ; @ BeforeClass public static void createMockInitialContext ( ) throws NamingException { NamingManager . setInitialContextFactoryBuilder ( new InitialContextFactoryBuilder ( ) { @ Override public InitialContextFactory createInitialContextFactory ( Hashtable < ? , ? > environment ) throws NamingException { return new InitialContextFactory ( ) { @ Override public Context getInitialContext ( Hashtable < ? , ? > environment ) throws NamingException { return new InitialContext ( environment ) { @ Override public Object lookup ( String name ) throws NamingException { if ( \"serverOutputDir\" . equals ( name ) ) { return \"foo\" ; } else { return super . lookup ( name ) ; } } } ; } } ; } } ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "IT", "for", "classified", "dependency", "and", "verify", "script"], "add_tokens": "return \"test\" . equals ( projectDependency . getScope ( ) ) ? null : projectDependency ;", "del_tokens": "import org . apache . maven . artifact . Artifact ; if ( \"test\" . equals ( projectDependency . getScope ( ) ) ) { // remove test dependencies from consumer POM return null ; } String artifactKey = projectDependency . getGroupId ( ) + \":\" + projectDependency . getArtifactId ( ) ; Dependency consumerDependency ; Artifact artifact = this . project . getArtifactMap ( ) . get ( artifactKey ) ; if ( artifact != null ) { consumerDependency = new Dependency ( ) ; consumerDependency . setGroupId ( artifact . getGroupId ( ) ) ; consumerDependency . setArtifactId ( artifact . getArtifactId ( ) ) ; consumerDependency . setVersion ( artifact . getVersion ( ) ) ; consumerDependency . setScope ( artifact . getScope ( ) ) ; consumerDependency . setType ( artifact . getType ( ) ) ; consumerDependency . setClassifier ( artifact . getClassifier ( ) ) ; consumerDependency . setOptional ( artifact . isOptional ( ) ) ; // for completeness, actually system scope is sick for consumers consumerDependency . setSystemPath ( projectDependency . getSystemPath ( ) ) ; consumerDependency . setExclusions ( projectDependency . getExclusions ( ) ) ; } else { // it's a dependency of an inactive profile, which is already interpolated consumerDependency = projectDependency ; } return consumerDependency ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "quotes", "for", "URL", "in", "javadoc"], "add_tokens": "* @ see \"http://docs.oracle.com/javase/8/docs/api/java/util/Optional.html\"", "del_tokens": "* @ see http : //docs.oracle.com/javase/8/docs/api/java/util/Optional.html", "commit_type": "add"}
{"commit_tokens": ["Adding", "combined", "UiAutomator", "/", "Robotium", "test"], "add_tokens": "* SOFTWARE , EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE .", "del_tokens": "* SOFTWARE , EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE . < / div >", "commit_type": "add"}
{"commit_tokens": ["Fixed", "java", ".", "lang", ".", "NullPointerException"], "add_tokens": "* LastModified : Jun 25 , 2014 * if ( estream != null ) { stream . buffer . clear ( ) ; stream . readFrom ( estream ) ; return stream ; } else { throw e ; }", "del_tokens": "* LastModified : Jun 9 , 2014 * stream . buffer . clear ( ) ; stream . readFrom ( estream ) ; return stream ;", "commit_type": "fix"}
{"commit_tokens": ["made", "this", "stack", "area", "renderer", "reusable", "."], "add_tokens": "* Chart generation utility code around JFreeChart . * @ see StackedAreaRenderer2 * @ see DataSetBuilder * @ see ShiftedCategoryAxis", "del_tokens": "* See issue 93. Detect an error in X11 and handle it gracefully .", "commit_type": "make"}
{"commit_tokens": ["add", "logging", "option", "on", "the", "WebAuthProvider", "class"], "add_tokens": "String generateCodeVerifier ( ) { return Base64 . encodeToString ( code , Base64 . URL_SAFE | Base64 . NO_WRAP | Base64 . NO_PADDING ) ; String generateCodeChallenge ( @ NonNull String codeVerifier ) { return getBase64String ( signature ) ;", "del_tokens": "public String generateCodeVerifier ( ) { String verifier = Base64 . encodeToString ( code , Base64 . URL_SAFE | Base64 . NO_WRAP | Base64 . NO_PADDING ) ; Log . d ( TAG , \"Generated code verifier is \" + verifier ) ; return verifier ; public String generateCodeChallenge ( @ NonNull String codeVerifier ) { String challenge = getBase64String ( signature ) ; Log . d ( TAG , \"Generated code challenge is \" + challenge ) ; return challenge ;", "commit_type": "add"}
{"commit_tokens": ["Add", "TouchInterceptionFrameLayout", "s", "test", "."], "add_tokens": "import android . widget . TextView ; public class TouchInterceptionScrollViewActivity extends Activity implements ObservableScrollViewCallbacks { setContentView ( R . layout . activity_touchinterception_scrollview ) ; ( ( TextView ) findViewById ( R . id . title ) ) . setText ( getClass ( ) . getSimpleName ( ) ) ;", "del_tokens": "public class TouchIntereceptionActivity extends Activity implements ObservableScrollViewCallbacks { setContentView ( R . layout . activity_touchinterception ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ASM", "Verfifier", "for", "checking", "instrumented", "classes", ";"], "add_tokens": "AsyncResponseReceiver < Integer > xxxData = getData ( ) ; Exception exception = null ; Object rufnummernProzessierenResponse = null ; exception = e ; Response < ? > response = new Response ( \"4711\" , null , exception ) ;", "del_tokens": "Response < ? > response = new Response < > ( \"4711\" ) ;", "commit_type": "add"}
{"commit_tokens": ["improved", "support", "for", "any", "type", "of", "table", "contents", "type"], "add_tokens": "return getTables ( dataType . getName ( ) ) ; } / * * * Get table names by data type * * @ param dataType * data type * @ return table names * @ throws SQLException * @ since 3.0 . 1 * / public List < String > getTables ( String dataType ) throws SQLException { return getContents ( dataType . getName ( ) ) ; } / * * * Get contents by data type * * @ param dataType * data type * @ return list of contents * @ throws SQLException * @ since 3.0 . 1 * / public List < Contents > getContents ( String dataType ) throws SQLException { dataType ) ;", "del_tokens": "dataType . getName ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "ability", "to", "turn", "custom", "button", "to", "expand", "on", "and", "off", ".", "The", "ability", "to", "change", "the", "speed", "of", "the", "button", "is", "controlled", "in", "the", "spinner", "on", "the", "right", "side", "of", "the", "toolbar", ".", "Speed", "and", "Custom", "click", "ability", "can", "be", "changed", "at", "any", "time", "no", "matter", "the", "rotation", "or", "state", ".", "Even", "if", "items", "are", "expanded", "the", "arrow", "will", "rotate", "back", "if", "it", "is", "turned", "off", "or", "rotate", "to", "an", "expanded", "position", "if", "the", "button", "is", "turned", "on", ".", "Ability", "to", "set", "no", "speed", "on", "the", "button", "also", "set", "."], "add_tokens": "private LayoutInflater mInflater ; mInflater = LayoutInflater . from ( context ) ; } public MyExpandableAdapter ( Context context , List < ExpandingObject > itemList , int customClickableViewId ) { super ( context , itemList , customClickableViewId ) ; mInflater = LayoutInflater . from ( context ) ; } public MyExpandableAdapter ( Context context , List < ExpandingObject > itemList , int customClickableViewId , long animationDuration ) { super ( context , itemList , customClickableViewId , animationDuration ) ; mInflater = LayoutInflater . from ( context ) ; View view = mInflater . inflate ( R . layout . recycler_item_layout_parent , parent , false ) ; View view = mInflater . inflate ( R . layout . recycler_item_layout_child , parent , false ) ;", "del_tokens": "private LayoutInflater inflater ; this . inflater = LayoutInflater . from ( context ) ; View view = inflater . inflate ( R . layout . recycler_item_layout_parent , parent , false ) ; View view = inflater . inflate ( R . layout . recycler_item_layout_child , parent , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "functionality", "to", "Parcels", "to", "wrap", "under", "a", "specific", "type", "using", "the", "associated", "factory", "mapping", "."], "add_tokens": "public static Parcelable wrap ( Object input ) { if ( input == null ) { return wrap ( null , null ) ; } return wrap ( input . getClass ( ) , input ) ; } public static < T > Parcelable wrap ( Class < ? extends T > inputType , T input ) { Parcelable parcelable = Parcels . wrap ( inputType , input ) ;", "del_tokens": "public static Parcelable wrap ( Object input ) { Parcelable parcelable = Parcels . wrap ( input ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "DDL", "statements", "in", "normal", "Statement", "(", "as", "opposed", "to"], "add_tokens": "import java . sql . PreparedStatement ; PreparedStatement ps = getConnection ( ) . prepareStatement ( sql ) ; return ps . executeUpdate ( ) ;", "del_tokens": "throw new SQLFeatureNotSupportedException ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "imports", "justifying", "text"], "add_tokens": "if ( mJustifiedText . replace ( \" \" , \"\" ) . replace ( \"\" , mThinSpace ) . equals ( this . getText ( ) . toString ( ) . replace ( \" \" , \"\" ) . replace ( \"\" , mThinSpace ) ) ) { } while ( wordCount < ( sH . getWordHolderIndex ( ) + 1 ) ) {", "del_tokens": "import android . text . Spanned ; if ( mJustifiedText . replace ( \" \" , \"\" ) . replace ( \"\" , mThinSpace ) . equals ( this . getText ( ) . toString ( ) . replace ( \" \" , \"\" ) . replace ( \"\" , mThinSpace ) ) ) while ( wordCount < ( sH . getWordHolderIndex ( ) + 1 ) ) {", "commit_type": "remove"}
{"commit_tokens": ["create", "a", "new", "connection", "every", "time", "we", "write", "to", "graphite", ".", "not", "sure", "this", "is", "the", "right", "way", "to", "do", "things", "as", "it", "seems", "very", "expensive", ".", "but", "effectively", "this", "is", "what", "we", "were", "doing", "before", "except", "that", "i", "wasn", "t", "doing", "a", "close", "()", "on", "the", "socket", "at", "the", "end", "and", "i", "think", "this", "was", "leaving", "connections", "dangling", "."], "add_tokens": "Socket socket = new Socket ( host , port ) ; Writer writer = new PrintWriter ( socket . getOutputStream ( ) , true ) ; socket . close ( ) ;", "del_tokens": "Writer writer = connect ( ) ; /** */ private Writer connect ( ) throws Exception { Socket socket = new Socket ( host , port ) ; return new PrintWriter ( socket . getOutputStream ( ) , true ) ; }", "commit_type": "create"}
{"commit_tokens": ["Add", "JSON", "format", "for", "404", "error", "messages"], "add_tokens": "errors . put ( \"errorMsg\" , \"Internal error: \" + message ) ; public static Response notFound ( String message ) { Map < String , String > errors = new HashMap < > ( ) ; errors . put ( \"errorMsg\" , \"Not found: \" + message ) ; return Response . status ( Response . Status . NOT_FOUND ) . entity ( errors ) . type ( APPLICATION_JSON_TYPE ) . build ( ) ; errors . put ( \"errorMsg\" , \"Bad request: \" + message ) ;", "del_tokens": "errors . put ( \"errorMsg\" , \"Internal Error: \" + message ) ; public static Response notFound ( Object entity ) { return Response . status ( Response . Status . NOT_FOUND ) . entity ( entity ) . type ( APPLICATION_JSON_TYPE ) . build ( ) ; errors . put ( \"errorMsg\" , \"Internal Error: \" + message ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "getEmail", "method"], "add_tokens": "HttpRequest request = buildRequest ( \"GET\" , buildUrlPath ( \"email\" , emailId ) ) ;", "del_tokens": "HttpRequest request = buildRequest ( \"GET\" , \"/email\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "when", "listing", "files", "in", "FTP", "."], "add_tokens": "import org . apache . commons . net . ftp . FTPClientConfig ; type = ftpClient . getSystemName ( ) ; if ( type == null ) { if ( type . startsWith ( \"UNIX\" ) ) { engine = ftpClient . initiateListParsing ( FTPClientConfig . SYST_UNIX , null ) ; LOGGER . warn ( \"Error at listing ftp server files\" , e ) ;", "del_tokens": "try { type = ftpClient . getSystemType ( ) ; } catch ( IOException e ) { if ( \"UNIX\" . equals ( type ) ) { engine = ftpClient . initiateListParsing ( \"org.apache.commons.net.ftp.parser.UnixFTPEntryParser\" , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "subtitle", "api", "signatures", "(", "not", "implemented", "and", "I", "m", "deferring", "them", ")", "and", "add", "an", "untested", "implementation", "of", "encodeVideo"], "add_tokens": "public final static native void Encoder_encodeVideo ( long jarg1 , Encoder jarg1_ , long jarg2 , MediaPacket jarg2_ , long jarg3 , MediaPicture jarg3_ ) ; public final static native void Encoder_encodeAudio ( long jarg1 , Encoder jarg1_ , long jarg2 , MediaPacket jarg2_ , long jarg3 , MediaAudio jarg3_ ) ;", "del_tokens": "public final static native int Decoder_decodeSubtitle ( long jarg1 , Decoder jarg1_ , long jarg2 , MediaSubtitle jarg2_ , long jarg3 , MediaPacket jarg3_ , int jarg4 ) ; public final static native int Encoder_encodeVideo ( long jarg1 , Encoder jarg1_ , long jarg2 , MediaPacket jarg2_ , long jarg3 , MediaPicture jarg3_ ) ; public final static native int Encoder_encodeAudio ( long jarg1 , Encoder jarg1_ , long jarg2 , MediaPacket jarg2_ , long jarg3 , MediaAudio jarg3_ ) ; public final static native int Encoder_encodeSubtitle ( long jarg1 , Encoder jarg1_ , long jarg2 , MediaPacket jarg2_ , long jarg3 , MediaSubtitle jarg3_ ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "some", "comments", "for", "these", "classes"], "add_tokens": "/ * * * Used for sending a HazeltaskTask to a member * @ author jclawson * * /", "del_tokens": "protected SubmitTaskOp ( ) { super ( null ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "IllegalArgumentException", "when", "OPTIONS", "in", "cors"], "add_tokens": "GET , HEAD , PUT , POST , DELETE , OPTIONS", "del_tokens": "GET , HEAD , PUT , POST , DELETE", "commit_type": "fix"}
{"commit_tokens": ["added", "dynamic", "suggestion", "height", "support"], "add_tokens": "this . mColorName = mColor . getName ( ) ; return mColor . getName ( ) + \"fssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\" ; dest . writeString ( mColorName ) ; }", "del_tokens": "this . mColorName = mColor . getName ( ) + \"ssssssssssssssssssssssssssssfffffffffsdfsdfsssssssssssssssssssssssssssssssssssssssssfffffffffsdfsdfsssssssssssssssss\" ; return \"ssssssssssssssssssssssssssssfffffffffsdfsdfsssssssssssssssssssssssssssssssssssssssssfffffffffsdfsdfsssssssssssssssss\" ; dest . writeString ( mColorName ) ; }", "commit_type": "add"}
{"commit_tokens": ["Removing", "support", "for", "the", "deprecated", "@Modules"], "add_tokens": "* { @ code GinModule } implementations to use .", "del_tokens": "* { @ code GinModule } types to use to provide explicit bindings .", "commit_type": "remove"}
{"commit_tokens": ["Adding", "toast", "commands", "support", "."], "add_tokens": "@ XmlElement ( name = \"commands\" ) public WnsToastCommands commands ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "random", "forest", "regression", "test"], "add_tokens": "int k = smile . math . Math . max ( y ) ; // Stratified sampling in case class is unbalanced. // That is, we sample each class separately. for ( int j = 0 ; j <= k ; j ++ ) { int nj = 0 ; ArrayList < Integer > cj = new ArrayList < Integer > ( ) ; for ( int i = 0 ; i < n ; i ++ ) { if ( y [ i ] == j ) { cj . add ( i ) ; nj ++ ; } } for ( int i = 0 ; i < nj ; i ++ ) { int xi = Math . randomInt ( nj ) ; samples [ cj . get ( xi ) ] += classWeight [ j ] ; }", "del_tokens": "for ( int i = 0 ; i < n ; i ++ ) { int xi = Math . randomInt ( n ) ; samples [ xi ] += classWeight [ y [ xi ] ] ; // If the data is unbalanced, small class will unlikely be sampled // with a simple sampling strategy. Here we use strata sampling // that samples each class separately. int k = smile . math . Math . max ( y ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "Mapper", "supply", "collection", "of", "all", "Binders"], "add_tokens": "public BindingAdapter ( @ NonNull ListAdapter adapter , @ NonNull Mapper mapper ) { mBinders = new ArrayList < Binder > ( mapper . getAllBinders ( ) ) ; public BindingAdapter ( @ NonNull ListAdapter adapter , @ NonNull Mapper mapper , boolean takeOwnership ) { mBinders = new ArrayList < Binder > ( mapper . getAllBinders ( ) ) ;", "del_tokens": "import java . util . Collection ; public BindingAdapter ( @ NonNull ListAdapter adapter , @ NonNull Collection < Binder > binders , @ NonNull Mapper mapper ) { mBinders = new ArrayList < Binder > ( binders ) ; public BindingAdapter ( @ NonNull ListAdapter adapter , @ NonNull ArrayList < Binder > binders , @ NonNull Mapper mapper , boolean takeOwnership ) { mBinders = new ArrayList < Binder > ( binders ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "initial", "support", "for", "the", "@Data", "annotation", ".", "Currently", "produces", "getters", "and", "setters", "only"], "add_tokens": "lombok . AccessLevel DEFAULT_ACCESS_LEVEL = lombok . AccessLevel . PUBLIC ; lombok . AccessLevel value ( ) default lombok . AccessLevel . PUBLIC ;", "del_tokens": "AccessLevel value ( ) default lombok . AccessLevel . PUBLIC ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "useless", "usage", "of", "Option", "in", "FxmlNode"], "add_tokens": "FxmlFile getFile ( ) ; Class < ? extends FxmlController > getControllerClass ( ) ; default FxmlStylesheet getStylesheet ( ) { return FxmlStylesheet . INHERIT ;", "del_tokens": "FxmlFile getFxmlFile ( ) ; Option < Class < ? extends FxmlController > > getControllerClass ( ) ; default Option < FxmlStylesheet > getStylesheet ( ) { return Option . none ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "skeleton", "classes", "needed", "for", "Query", "annotated", "method", "implementations"], "add_tokens": "import org . springframework . data . simpledb . query . SimpleDbQueryLookupStrategy ; return SimpleDbQueryLookupStrategy . create ( simpledbOperations , key ) ;", "del_tokens": "return null ;", "commit_type": "add"}
{"commit_tokens": ["Make", "gen", "errors", "slightly", "more", "informative"], "add_tokens": "throw new AssertionError ( \"Invalid boolean constant: \" + value . value ( ) + \" at \" + value . location ( ) ) ; throw new UnsupportedOperationException ( \"Binary literals are not supported\" ) ;", "del_tokens": "throw new AssertionError ( \"Invalid boolean constant: \" + value . value ( ) ) ; throw new AssertionError ( \"Binary literals are not supported\" ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "a", "parse", "issue", "related", "to", "field", "size", "syntax"], "add_tokens": "and ( opt ( IDENTIFIER ) , opt ( attribute_specifier_seq ) , \":\" , constant_expression ) , declarator", "del_tokens": "declarator , and ( opt ( IDENTIFIER ) , opt ( attribute_specifier_seq ) , \":\" , constant_expression )", "commit_type": "fix"}
{"commit_tokens": ["added", "future", "works", "[", "pme", "]"], "add_tokens": "assertThat ( parser . parse ( \"foo.foo\") ) . i sEqualTo( n ew bs( \" foo\", ar( \" foo\") ) ) ;", "del_tokens": "assertThat ( parser . parse ( \"foo.foo\") ) . i sEqualTo( n ew bs( \" foo\", v ar( \" foo\") ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "tests", "change", "exceptions", "to", "runtime", "exceptions", "to", "avoid", "boilerplate", "code", "for", "users", "."], "add_tokens": "import org . json . JSONException ; import java . io . UnsupportedEncodingException ; public void testDefaultValues ( ) { assertTrue ( response . getResponseText ( ) . equalsIgnoreCase ( \"\" ) ) ;", "del_tokens": "public void testDefaultValues ( ) { assertTrue ( response . getResponseText ( ) == null ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "comments", "to", "toFieldVisitor", "()"], "add_tokens": "// Especial enum constant // Normal enum constants // Normal fields this . getDescriptor ( field . generics ( ) ) , // TODO Implement", "del_tokens": "this . getDescriptor ( field . generics ( ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Use", "if", "exists", "when", "dropping", "tables", "in", "postgres"], "add_tokens": "if ( flavor ( ) == Flavor . postgresql ) { ddl ( \"drop table if exists \" + tableName ) . executeQuietly ( ) ; } else { ddl ( \"drop table \" + tableName ) . executeQuietly ( ) ; }", "del_tokens": "ddl ( \"drop table \" + tableName ) . executeQuietly ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "JMX", "scraping", "over", "SSL"], "add_tokens": "boolean ssl = false ; if ( yamlConfig . containsKey ( \"ssl\" ) ) { cfg . ssl = ( Boolean ) yamlConfig . get ( \"ssl\" ) ; } JmxScraper scraper = new JmxScraper ( config . jmxUrl , config . username , config . password , config . ssl , config . whitelistObjectNames , config . blacklistObjectNames , receiver ) ;", "del_tokens": "JmxScraper scraper = new JmxScraper ( config . jmxUrl , config . username , config . password , config . whitelistObjectNames , config . blacklistObjectNames , receiver ) ;", "commit_type": "allow"}
{"commit_tokens": ["Made", "variables", "names", "more", "similar", "to", "the", "other", "interpreters"], "add_tokens": "* @ param expressions filterDice ( final Iterable < DiceNotationExpression > expressions ) { expsItr = expressions . iterator ( ) ;", "del_tokens": "* @ param exps filterDice ( final Iterable < DiceNotationExpression > exps ) { expsItr = exps . iterator ( ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "Setter", "that", "handles", "an", "array"], "add_tokens": "@ Option ( name = \"-array\" ) public void testOnArray ( ) throws Exception { assertEquals ( \"one\" , array [ 0 ] ) ; assertEquals ( \"two\" , array [ 1 ] ) ; assertEquals ( \"three\" , array [ 2 ] ) ;", "del_tokens": "// There is no OptionHandler for Arrays //@Option(name=\"-array\", multiValued=true) //TODO: How to use 'multiValued' on arrays? // There should be no difference to use on lists (from the user point of view). public void t_estOnArray ( ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Added", "license", "headers", "to", "all", "Java", "files"], "add_tokens": "* Licensed to the Apache Software Foundation ( ASF ) under one or more * contributor license agreements . See the NOTICE file distributed with * this work for additional information regarding copyright ownership . * The ASF licenses this file to You under the Apache License , Version 2.0 * ( the \"License\" ) ; you may not use this file except in compliance with * the License . You may obtain a copy of the License at", "del_tokens": "* Copyright 2005 The Apache Software Foundation * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at", "commit_type": "add"}
{"commit_tokens": ["Added", "transfer", "of", "@XmlMixed", "but", "mixed", "-", "content", "is", "not", "properly", "deserialized", "in", "combination", "with", "@XmlElementWrapper", "(", "see", "http", ":", "//", "stackoverflow", ".", "com", "/", "questions", "/", "21444292", "/", ")", "."], "add_tokens": "import javax . xml . bind . annotation . XmlMixed ; JClass xmlMixedModelClass = codeModel . ref ( XmlMixed . class ) ; for ( JClass annotationModelClass : new JClass [ ] { xmlAnyElementModelClass , xmlMixedModelClass , xmlElementRefsModelClass , xmlElementsModelClass } ) { writeSummary ( \"\\tCorrecting method [\" + method . type ( ) . fullName ( ) + \"#\" + method . name ( ) + \"()] in \"", "del_tokens": "for ( JClass annotationModelClass : new JClass [ ] { xmlAnyElementModelClass , xmlElementRefsModelClass , xmlElementsModelClass } ) { writeSummary ( \"\\tCorrecting method [\" + method . type ( ) . fullName ( ) + \"#\" + method . name ( ) + \"()] from \"", "commit_type": "add"}
{"commit_tokens": ["Use", "oauth", "credentials", "for", "new", "getgluejava", "test", "account", "."], "add_tokens": "private static final String CLIENT_ID = \"7FD930E5C9D030F696ACA631343EB3\" ; private static final String CLIENT_SECRET = \"EB4B93F673B95A5A2460CF983BB0A4\" ; private static final String TEMPORARY_ACCESS_TOKEN = \"FA1429A2D4B3FA39EF57E15689A6B4\" ; /* Expires Dec. 21, 2013, 8:35 a.m. */", "del_tokens": "private static final String CLIENT_ID = \"8D195792E4A18575EE0D50CE42A11F\" ; private static final String CLIENT_SECRET = \"68BA81EC69ED72D8DF0D3C705EC40B\" ; private static final String TEMPORARY_ACCESS_TOKEN = \"!-- FILL IN ACCESS TOKEN --!\" ;", "commit_type": "use"}
{"commit_tokens": ["Change", "the", "AbstractTypeToFieldChecker", "to", "use", "the", "new", "TypeStructureInformation", "lookup", "object", ".", "This", "avoids", "nasty", "class", "loading", "."], "add_tokens": "import static org . mutabilitydetector . AnalysisSession . createWithCurrentClassPath ; import static org . mutabilitydetector . CheckerRunner . createWithCurrentClasspath ; import org . mutabilitydetector . checkers . info . SessionCheckerRunner ; import org . mutabilitydetector . checkers . info . TypeStructureInformation ; SessionCheckerRunner runner = new SessionCheckerRunner ( createWithCurrentClassPath ( ) , createWithCurrentClasspath ( ) ) ; TypeStructureInformation typeInfo = new TypeStructureInformation ( runner ) ; checker = new AbstractTypeToFieldChecker ( typeInfo ) ;", "del_tokens": "checker = new AbstractTypeToFieldChecker ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "initial", "dictionary", "/", "segment", "work"], "add_tokens": "// Functionality for reading and writing LazyNode structures // ByteBuffer must be allocated with enough space before calling", "del_tokens": "// ByterBuffer must be allocated with enough space before calling", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", "in", "method", "name"], "add_tokens": "public synchronized void addAll ( int index , Collection < Layer > layers ) {", "del_tokens": "public synchronized void allAll ( int index , Collection < Layer > layers ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "methods", "to", "perform", "batch", "querying"], "add_tokens": "Set < String > kids = new HashSet < String > ( this . abstractionFinder . getDataSource ( ) . getAllKeyIds ( i , 10000 ) ) ; // List<String> kids = this.abstractionFinder.getDataSource().getAllKeyIds(i, 1000); if ( kids . isEmpty ( ) ) break ; // BATCH QUERY results . putAll ( this . abstractionFinder . doFind ( kids , propIdsSet , query . getStart ( ) , query . getFinish ( ) ) ) ; // ONE PATIENT AT A TIME QUERIES // for (String keyId : kids) { // if (logger.isLoggable(Level.FINER)) // logger.finer(\"Processing key \" + keyId); // results.put(keyId, // this.abstractionFinder.doFind(keyId, // propIdsSet, query.getStart(), // query.getFinish())); // }", "del_tokens": "List < String > kids = this . abstractionFinder . getDataSource ( ) . getAllKeyIds ( i , 1000 ) ; if ( kids . isEmpty ( ) ) break ; for ( String keyId : kids ) { if ( logger . isLoggable ( Level . FINER ) ) logger . finer ( \"Processing key \" + keyId ) ; results . put ( keyId , this . abstractionFinder . doFind ( keyId , propIdsSet , query . getStart ( ) , query . getFinish ( ) ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "constructor", "specifying", "bitvector", "implementation", "."], "add_tokens": "this ( orig , bitSize , tb , new SuccinctBitVector ( bitSize ) ) ; } public LOUDSTrie ( Trie orig , int bitSize , TailBuilder tb , SuccinctBitVector bv ) { this . bv = bv ;", "del_tokens": "bv = new SuccinctBitVector ( bitSize ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "survive", "existings", "ice_root"], "add_tokens": "if ( ! tmproot . mkdirs ( ) && ! tmproot . isDirectory ( ) ) throw new IOException ( \"Unable to create ice root: \" + tmproot . getAbsolutePath ( ) ) ;", "del_tokens": "if ( ! tmproot . mkdirs ( ) ) throw new IOException ( \"Unable to create ice root: \" + tmproot . getAbsolutePath ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "javadoc", "to", "updatePartitions", "method"], "add_tokens": "* Initializes offsets to start streaming at the oldest available offset ( BEGIN ) . / * * * Updates offsets in case the currently stored offset is no longer available . Streaming will start at the oldest available offset ( BEGIN ) to minimize the amount of events skipped . * /", "del_tokens": "* Initializes offsets to start streaming at the oldes available offset ( BEGIN ) .", "commit_type": "add"}
{"commit_tokens": ["Add", "Flag", "to", "Detect", "if", "new", "counter", "was", "created"], "add_tokens": "/ * * * Reflects whether or not a new counter was created before exexuting this counter operation . * * @ return { @ code true } if a new counter was created ; { @ code false } if the counter already existed . * / boolean newCounterCreated ( ) ; private final boolean newCounterCreated ; * @ param newCounterCreated { @ code true } if a new counter was created before executing this operation ; * { @ code false } if the counter already existed . final DateTime creationDateTime , final boolean newCounterCreated ) this . newCounterCreated = newCounterCreated ; this . newCounterCreated = false ; } / * * * Copy Constructor . * * @ param counterOperation * / public Impl ( final CounterOperation counterOperation ) { Preconditions . checkNotNull ( counterOperation ) ; this . operationUuid = counterOperation . getOperationUuid ( ) ; this . counterShardDataKey = counterOperation . getCounterShardDataKey ( ) ; this . counterOperationType = counterOperation . getCounterOperationType ( ) ; this . appliedAmount = counterOperation . getAppliedAmount ( ) ; this . creationDateTime = counterOperation . getCreationDateTime ( ) ; this . newCounterCreated = counterOperation . newCounterCreated ( ) ; @ Override public boolean newCounterCreated ( ) { return this . newCounterCreated ; }", "del_tokens": "final DateTime creationDateTime )", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "internal", "use", "of", "the", "method", "get", "()", "in", "Some", "."], "add_tokens": "return Option . apply ( f . apply ( value ) ) ; return function . apply ( value ) ; return Stream . of ( value ) ;", "del_tokens": "return Option . apply ( f . apply ( get ( ) ) ) ; return function . apply ( get ( ) ) ; return Stream . of ( get ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["make", "byteOrder", "into", "java", ".", "nio", ".", "ByteOrder"], "add_tokens": "import java . nio . ByteOrder ; Long version = Long . parseLong ( getXmlAttributeValue ( messageSchemaNode , \"version\" , \"0\" ) ) ; // default version is 0 ByteOrder byteOrder = lookupByteOrder ( getXmlAttributeValue ( messageSchemaNode , \"byteOrder\" , \"littleEndian\" ) ) ; / * * * Helper function to convert a schema byteOrder ( littleEndian or bigEndian ) into a { @ link java . nio . ByteOrder } * * @ param order specified as a FIX SBE string * @ return ByteOrder representation * / public static ByteOrder lookupByteOrder ( final String order ) { if ( order . equals ( \"littleEndian\" ) ) { return ByteOrder . LITTLE_ENDIAN ; } else if ( order . equals ( \"bigEndian\" ) ) { return ByteOrder . BIG_ENDIAN ; } return ByteOrder . LITTLE_ENDIAN ; }", "del_tokens": "String version = getXmlAttributeValueNullable ( messageSchemaNode , \"version\" ) ; String byteOrder = getXmlAttributeValue ( messageSchemaNode , \"byteOrder\" , \"littleEndian\" ) ; / * * * TODO : use java . nio . ByteOrder to save byte order enumeration * /", "commit_type": "make"}
{"commit_tokens": ["add", "support", "to", "define", "the", "new", "logging", "in", "configSchema", "xml", "file", "instead", "of", "completely", "in", "config", ".", "properties", ".", "overrides", "can", "still", "be", "done", "via", "config", "file", "."], "add_tokens": "Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( new Runnable ( ) { @ Override public void run ( ) { try { //wait a second before shutting down to allow async logging to finish Thread . sleep ( 2000 ) ; } catch ( InterruptedException e ) { } } } ) ) ;", "del_tokens": "import com . cisco . oss . foundation . configuration . FoundationConfigurationListener ; import com . cisco . oss . foundation . configuration . FoundationConfigurationListenerRegistry ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "NPE", "in", "thread", "CPU", "reported"], "add_tokens": "if ( threadDump . get ( ids [ i ] ) == null ) { continue ; } threadDump . get ( ids [ i ] ) . lastAllocatedBytes = alloc [ i ] ; if ( threadDump . get ( ids [ i ] ) == null ) { continue ; } if ( threadDump . get ( id ) == null ) { continue ; }", "del_tokens": "threadDump . get ( ids [ i ] ) . lastAllocatedBytes = alloc [ i ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "onlyShowIfEmpty", "flag", "to", "LoadingAdapter"], "add_tokens": "@ NonNull private final DataObserver mDataObserver = new SimpleDataObserver ( ) { @ Override public void onChange ( ) { notifyDataSetChanged ( ) ; } } ; @ Getter private boolean mOnlyShowIfEmpty ; mData . registerDataObserver ( mDataObserver ) ; mData . unregisterDataObserver ( mDataObserver ) ; public void setLoadingItemEnabled ( boolean loadingItemEnabled ) { if ( loadingItemEnabled != mLoadingItemEnabled ) { mLoadingItemEnabled = loadingItemEnabled ; notifyDataSetChanged ( ) ; } } public void setOnlyShowIfEmpty ( boolean onlyShowIfEmpty ) { if ( onlyShowIfEmpty != mOnlyShowIfEmpty ) { mOnlyShowIfEmpty = onlyShowIfEmpty ; notifyDataSetChanged ( ) ; } } if ( mOnlyShowIfEmpty ) { return mData . isLoading ( ) && mData . isEmpty ( ) ; }", "del_tokens": "import lombok . Setter ; @ Setter", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "simple", "integration", "test", "."], "add_tokens": "testConfiguration . addRegisterEntitiesPackagePrefix ( \"org.isisaddons.module.devutils\" ) ;", "del_tokens": "testConfiguration . addRegisterEntitiesPackagePrefix ( \"dom\" ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "radiobuttons", "and", "comboboxes", "(", "unfinished", "/", "don", "t", "work", "yet", ")"], "add_tokens": "writer . append ( \"<script src='../resources/AngularFaces/angular.js'></script>\\r\\n\" ) ; // writer.append(\"<script src='../javax.faces.resource/glue.js.jsf?ln=AngularFaces'></script>\\r\\n\"); writer . append ( \"<script src='../resources/AngularFaces/glue.js'></script>\\r\\n\" ) ;", "del_tokens": "import javax . faces . application . * ; @ ResourceDependencies ( { @ ResourceDependency ( library = \"AngularFaces\" , name = \"glue.js\" ) , @ ResourceDependency ( library = \"AngularFaces\" , name = \"angular.js\" ) } ) // writer.append(\"<script src='../resources/AngularFaces/1.0/glue.js'></script>\\r\\n\"); // writer.append(\"<script src='../resources/AngularFaces/1.0/angular.js'></script>\\r\\n\");", "commit_type": "add"}
{"commit_tokens": ["Make", "RxJava", "defer", "to", "background", "thread"], "add_tokens": ". subscribeOn ( Schedulers . io ( ) )", "del_tokens": ". observeOn ( Schedulers . io ( ) )", "commit_type": "make"}
{"commit_tokens": ["Fixing", "XML", "serialization", "issue", "."], "add_tokens": "import java . lang . reflect . Type ; import com . google . gson . JsonElement ; import com . google . gson . JsonObject ; import com . google . gson . JsonSerializationContext ; import com . google . gson . JsonSerializer ; @ ThreadSafe public final class OutgoingCallerIdConverter extends AbstractConverter implements JsonSerializer < OutgoingCallerId > { @ Override public JsonElement serialize ( final OutgoingCallerId outgoingCallerId , final Type type , final JsonSerializationContext context ) { final JsonObject object = new JsonObject ( ) ; writeSid ( outgoingCallerId . getSid ( ) , object ) ; writeAccountSid ( outgoingCallerId . getAccountSid ( ) , object ) ; writeFriendlyName ( outgoingCallerId . getFriendlyName ( ) , object ) ; writePhoneNumber ( outgoingCallerId . getPhoneNumber ( ) , object ) ; writeDateCreated ( outgoingCallerId . getDateCreated ( ) , object ) ; writeDateUpdated ( outgoingCallerId . getDateUpdated ( ) , object ) ; writeUri ( outgoingCallerId . getUri ( ) , object ) ; return object ; }", "del_tokens": "@ ThreadSafe public final class OutgoingCallerIdConverter extends AbstractConverter {", "commit_type": "fix"}
{"commit_tokens": ["Add", "permanently", "denied", "option", "to", "listener"], "add_tokens": "if ( ActivityCompat . shouldShowRequestPermissionRationale ( activity , permission ) ) { listener . onPermissionDenied ( permission ) ; } else { listener . onPermissionPermanentlyDenied ( permission ) ; }", "del_tokens": "listener . onPermissionDenied ( permission ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "the", "warning", "-", "unused", "variable", "."], "add_tokens": "logger . info ( \"Ignoring OS bit.... \" + ch + \"!=\" + ch2 ) ;", "del_tokens": "System . out . println ( \"Ignoring OS bit.... \" + ch + \"!=\" + ch2 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "density", "strings", "for", "all", "current", "dpi", "buckets"], "add_tokens": "case DisplayMetrics . DENSITY_TV : return \"tvdpi\" ; case DisplayMetrics . DENSITY_280 : case DisplayMetrics . DENSITY_360 : case DisplayMetrics . DENSITY_400 : case DisplayMetrics . DENSITY_420 : case DisplayMetrics . DENSITY_560 :", "del_tokens": "case DisplayMetrics . DENSITY_TV : return \"tvdpi\" ;", "commit_type": "add"}
{"commit_tokens": ["updates", "to", "CSV", "reading", "and", "writing"], "add_tokens": "if ( iter . hasNext ( ) ) { sb . append ( \"\\n\" ) ; }", "del_tokens": "sb . append ( \"\\n\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "access", "token", "from", "URI"], "add_tokens": "processedPath . append ( \"?\" ) ;", "del_tokens": "// Token String accessToken ; if ( StringUtils . isNotEmpty ( requestOptions . getAccessToken ( ) ) ) { accessToken = requestOptions . getAccessToken ( ) ; } else if ( resource != null ) { accessToken = resource . getMarketplaceAccessToken ( ) ; if ( StringUtils . isEmpty ( accessToken ) ) { accessToken = MercadoPago . SDK . getAccessToken ( ) ; } } else { accessToken = MercadoPago . SDK . getAccessToken ( ) ; } if ( ! path . equals ( \"/oauth/token\" ) ) { processedPath . append ( \"?access_token=\" ) . append ( accessToken ) ; }", "commit_type": "remove"}
{"commit_tokens": ["fix", "inner", "non", "static", "classes", "detection", "by", "classpath", "scan"], "add_tokens": "import java . lang . reflect . Modifier ; // only static inner classes are allowed because guice will not be able to instantiate inner class final boolean isInner = cls . getEnclosingClass ( ) != null && ! Modifier . isStatic ( cls . getModifiers ( ) ) ; if ( ! isInner && ! cls . isAnnotationPresent ( InvisibleForScanner . class ) ) {", "del_tokens": "if ( ! cls . isAnnotationPresent ( InvisibleForScanner . class ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "redoc", "support", "for", "OpenAPI", "."], "add_tokens": "templateString = templateString . replaceAll ( \"\\\\{\\\\{ specPath \\\\}\\\\}\" , this . basePath + \".json\" ) ;", "del_tokens": "templateString = templateString . replaceAll ( \"\\\\{\\\\{ swaggerSpecPath \\\\}\\\\}\" , this . basePath + \".json\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "sortBy", "with", "direction", "(", "asc", "/", "desc", ")"], "add_tokens": "return sortByInternal ( value , SortDirection . Ascending ) ; / * * * Sort results according to the index specified by { @ code value } and { @ code direction } . * * @ return this object for method chaining . * / public QueryBuilder sortBy ( String value , SortDirection direction ) { return sortByInternal ( value , direction ) ; } private QueryBuilder sortByInternal ( String value , SortDirection direction ) { options . put ( direction == SortDirection . Ascending ? \"ascending\" : \"descending\" , true ) ;", "del_tokens": "return sortByInternal ( value ) ; private QueryBuilder sortByInternal ( String value ) { // TODO error checking", "commit_type": "add"}
{"commit_tokens": ["changed", "artifactId", "(", "s", ")", "and", "folder", "names", "to", "follow", "maven", "naming", "conventions"], "add_tokens": "/ * * / createCFIndex , /*createLuceneIndex,*/", "del_tokens": "createCFIndex , createLuceneIndex ,", "commit_type": "change"}
{"commit_tokens": ["Change", "text", "-", "setter", "to", "use", "precomputed", "-", "text", "-", "compat", "(", "androix", ".", "core", ")"], "add_tokens": "* @ see PrecomputedTextSetterCompat", "del_tokens": "* @ see PrecomputedTextSetter", "commit_type": "change"}
{"commit_tokens": ["fix", "bug", "in", "Polygon", "class"], "add_tokens": "// gl.glTranslated(X, Y, 0);", "del_tokens": "gl . glTranslated ( X , Y , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "shortTextAlgorithm", "from", "none", "to", "default", "50", "."], "add_tokens": "private int shortTextAlgorithm = 50 ;", "del_tokens": "private int shortTextAlgorithm = 0 ;", "commit_type": "change"}
{"commit_tokens": ["Use", "InputStream", "instead", "of", "byte", "array"], "add_tokens": "import java . io . InputStream ; return byteBufFlux . aggregate ( ) . asInputStream ( ) . map ( bytes -> deserialize ( bytes , type ) ) ; private < T > T deserialize ( InputStream inputStream , Class < T > type ) { T value = objectMapper . readValue ( inputStream , type ) ; inputStream . close ( ) ; return value ;", "del_tokens": "return byteBufFlux . aggregate ( ) . asByteArray ( ) . map ( bytes -> deserialize ( bytes , type ) ) ; private < T > T deserialize ( byte [ ] bytes , Class < T > type ) { return objectMapper . readValue ( bytes , type ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "explanation", "of", "hardcoded", "constant", "(", "referring", "to", "RFC2409", ")", "."], "add_tokens": "/** \"Second Oakley Default Group\" from RFC2409, section 6.2. */", "del_tokens": "/** Modulus bytes from flazr */", "commit_type": "change"}
{"commit_tokens": ["Added", "log", ".", "error", "if", "there", "is", "a", "duplicate", "listener", "registration"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger log = LoggerFactory . getLogger ( NettyTransportDataHolder . class ) ; if ( channelInitializers . get ( key ) == null ) { this . channelInitializers . put ( key , initializer ) ; } else { log . error ( \"Netty transport listener \" + key + \" already registered\" ) ; }", "del_tokens": "this . channelInitializers . put ( key , initializer ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "JoltUtils", ".", "store", "()", "added", "test"], "add_tokens": "@ SuppressWarnings ( \"deprecation\" ) @ SuppressWarnings ( \"deprecation\" ) @ SuppressWarnings ( \"deprecation\" )", "del_tokens": "@ Test ( description = \"No exception if we don't try to remove from an ImmutableMap.\" ) public void doNotUnnecessarilyDieOnImmutableMaps ( ) throws IOException { Map expected = JsonUtils . jsonToMap ( JsonUtils . toJsonString ( top ) ) ; JsonUtils . removeRecursive ( top , \"tuna\" ) ; Diffy . Result result = diffy . diff ( expected , top ) ; if ( ! result . isEmpty ( ) ) { Assert . fail ( \"Failed.\\nhere is a diff:\\nexpected: \" + JsonUtils . toJsonString ( result . expected ) + \"\\n actual: \" + JsonUtils . toJsonString ( result . actual ) ) ; } } @ Test ( expectedExceptions = UnsupportedOperationException . class , description = \"Exception if try to remove from an Immutable map.\" ) public void correctExceptionWithImmutableMap ( ) throws IOException { JsonUtils . removeRecursive ( top , \"c\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "parsing", "a", "bit", "tighter"], "add_tokens": "Casts . STRING_ONLY , TokenParser . FORMAT_NO_SPACE_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_NO_SPACE_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_NO_SPACE_STRING + \" \" + TokenParser . FORMAT_NO_SPACE_STRING + \" \" + TokenParser . FORMAT_NO_SPACE_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_NO_SPACE_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_NO_SPACE_STRING , 1 ) ) ;", "del_tokens": "Casts . STRING_ONLY , TokenParser . FORMAT_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_STRING ) ) ; Casts . STRING_ONLY , TokenParser . FORMAT_STRING , 1 ) ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "unique", "point", "and", "location", "checking", "-", "nested", "geoFields", "are", "ignored", "because", "Distance", "in", "GeoResult", "would", "be", "nonsense"], "add_tokens": "private boolean checkUnique = false ; if ( ! checkUnique ) return ; if ( ! checkUnique ) return ; checkUnique = part . getProperty ( ) . toDotPath ( ) . split ( \".\" ) . length <= 1 ; checkUniqueLocation ( part ) ; checkUniqueLocation ( part ) ; ArgumentProcessingResult result = bindArguments ( iterator , shouldIgnoreCase ( part ) , arguments , borderStatus , ignoreBindVars ) ; checkUniqueLocation ( part ) ;", "del_tokens": "import org . springframework . data . mapping . PersistentProperty ; import org . springframework . data . mapping . PropertyPath ; if ( part . getProperty ( ) . toDotPath ( ) . split ( \".\" ) . length <= 1 ) { checkUniqueLocation ( part ) ; } if ( part . getProperty ( ) . toDotPath ( ) . split ( \".\" ) . length <= 1 ) { checkUniqueLocation ( part ) ; } ArgumentProcessingResult result = bindArguments ( iterator , shouldIgnoreCase ( part ) , arguments , borderStatus , ignoreBindVars ) ; if ( part . getProperty ( ) . toDotPath ( ) . split ( \".\" ) . length <= 1 ) { checkUniqueLocation ( part ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "on", "endWith", "assertion", "calling", "shouldStartWith", "error", "message", "factory", "instead", "of", "shouldEndWith"], "add_tokens": "import static org . fest . assertions . error . ShouldEndWith . shouldEndWith ; throw failures . failure ( info , shouldEndWith ( actual , suffix ) ) ;", "del_tokens": "throw failures . failure ( info , shouldStartWith ( actual , suffix ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "front", "()", "with", "comparator"], "add_tokens": "import static org . junit . Assert . assertArrayEquals ; import java . util . Arrays ; import org . junit . Test ; @ Test public void testFrontWithComparator ( ) { final int [ ] refArray = { 8 , 16 , 9 } ; IntComparator comparator = new AbstractIntComparator ( ) { @ Override public int compare ( int k1 , int k2 ) { return ( k1 & 3 ) - ( k2 & 3 ) ; } } ; IntHeapSemiIndirectPriorityQueue queue = new IntHeapSemiIndirectPriorityQueue ( refArray , comparator ) ; queue . enqueue ( 0 ) ; queue . enqueue ( 1 ) ; queue . enqueue ( 2 ) ; final int [ ] front = new int [ 2 ] ; assertEquals ( 2 , queue . front ( front ) ) ; Arrays . sort ( front ) ; assertArrayEquals ( new int [ ] { 0 , 1 } , front ) ; }", "del_tokens": "import it . unimi . dsi . fastutil . ints . IntHeapSemiIndirectPriorityQueue ; import it . unimi . dsi . fastutil . ints . IntOpenHashSet ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "XorShift", "that", "could", "result", "in", "negative", "nextInt", "(", "n", ")", "values", "."], "add_tokens": "return ( ( int ) nextLong ( ) >>> ( 48 - bits ) ) ;", "del_tokens": "return ( int ) ( nextLong ( ) >>> ( 48 - bits ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "sample", "for", "data", "binding"], "add_tokens": "binding . setVariable ( vn . tiki . noadapterdatabinding . BR . item , item ) ; binding . setVariable ( vn . tiki . noadapterdatabinding . BR . onClick , this ) ;", "del_tokens": "binding . setVariable ( vn . tiki . noadapter . BR . item , item ) ; binding . setVariable ( vn . tiki . noadapter . BR . onClick , this ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "whitespace", "in", "the", "license", "header"], "add_tokens": "* Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and", "del_tokens": "* Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "select", "redis", "database"], "add_tokens": "protected int port = 6379 ; / * * * Redis database * / protected short database = 0 ; jedisPool = new JedisPool ( jedisPoolConfig , host , port , Protocol . DEFAULT_TIMEOUT , null , database ) ; public void setDatabase ( short database ) { this . database = database ; } public void setDatabase ( int database ) { this . database = ( short ) database ; } public void setDatabase ( String database ) { setDatabase ( Short . valueOf ( database ) ) ; } public void setKeyPrefix ( String keyPrefix ) { public void setKeyDelimiter ( String keyDelimiter ) {", "del_tokens": "protected int port ; jedisPool = new JedisPool ( jedisPoolConfig , host , port , Protocol . DEFAULT_TIMEOUT ) ; public RedisJobStore setKeyPrefix ( String keyPrefix ) { return this ; public RedisJobStore setKeyDelimiter ( String keyDelimiter ) { return this ;", "commit_type": "add"}
{"commit_tokens": ["Added", "surface", "position", "report", "decoder"], "add_tokens": "private static final long serialVersionUID = - 1901589500173456758L ; * Otherwise it can be a little worse than it actually is . 0 means unknown .", "del_tokens": "private static final long serialVersionUID = 8593107448574597504L ; * Otherwise it can be a little worse than it actually is .", "commit_type": "add"}
{"commit_tokens": ["Change", "security", "related", "comment", "suggested", "by", "@mala"], "add_tokens": "// This is sample code. You should consider about security and scalability. // This is sample code. You should consider about security and scalability.", "del_tokens": "// This is sample code. This code may not secure. // This is sample code. This code may not secure.", "commit_type": "change"}
{"commit_tokens": ["Fixed", "an", "NPE", "in", "continueSettling"], "add_tokens": "import java . util . Arrays ; // Make sure, there is a captured view if ( mCapturedView == null ) { return false ; }", "del_tokens": "import java . util . Arrays ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "text", "edit", "activation", "when", "clicked", "on", "icons"], "add_tokens": "else if ( part != ElementPart . ICONS && e . getClickCount ( ) > 1 ) {", "del_tokens": "else if ( e . getClickCount ( ) > 1 ) {", "commit_type": "remove"}
{"commit_tokens": ["Make", "getAllWindowHandlesAndTitles", "()", "even", "more", "bullet", "proof"], "add_tokens": "import org . aludratest . service . gui . web . selenium . selenium2 . condition . DropDownBoxOptionLabelsPresence ; try { String title = driver . getTitle ( ) ; handlesAndTitles . put ( initialWindowHandle , title ) ; } catch ( WebDriverException e ) { // ignore current window } String title ; handlesAndTitles . put ( handle , title = driver . getTitle ( ) ) ; LOGGER . debug ( \"Window with handle {} has title '{}'\" , handle , title ) ; catch ( WebDriverException e ) { // ignore this window } try { driver . switchTo ( ) . window ( initialWindowHandle ) ; } catch ( WebDriverException e ) { // selenium could now be on an unexpected window LOGGER . warn ( \"Could not switch back to initial window after window iteration. Active window is now unspecified.\" ) ; }", "del_tokens": "import org . aludratest . service . gui . web . selenium . selenium2 . condition . DropDownBoxOptionLabelsPresence ; String title = driver . getTitle ( ) ; handlesAndTitles . put ( initialWindowHandle , title ) ; handlesAndTitles . put ( handle , driver . getTitle ( ) ) ; LOGGER . debug ( \"Window with handle {} has title '{}'\" , handle , title ) ; driver . switchTo ( ) . window ( initialWindowHandle ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "boolean", "return", "value", "."], "add_tokens": ". equals ( \"1\" ) ) ;", "del_tokens": ". equals ( \"true\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "signature", "of", "getDefaultLayoutXml", "()", ".", "It", "is", "no", "longer", "necessary", "to", "pass", "a", "user", "name", "because", "the", "default", "layout", "xml", "is", "taken", "from", "a", "user", "named", "default", "."], "add_tokens": "public IXml getDefaultLayoutXml ( HttpServletRequest req ) ;", "del_tokens": "public IXml getDefaultLayoutXml ( HttpServletRequest req , String sUserName ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "more", "warnings", "reported", "by", "other", "tools"], "add_tokens": "this . principal = requireNonNull ( principal , \"principal\" ) ; this . authorities = requireNonNull ( authorities , \"authorities\" ) ;", "del_tokens": "this . principal = requireNonNull ( principal , \"principal\" ) ; ; this . authorities = requireNonNull ( authorities , \"authorities\" ) ; ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "line", "in", "LotteAnimatablePointValue"], "add_tokens": "pointKeyframes . add ( vertex ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "jargs", "command", "-", "line", "argument", "parsing"], "add_tokens": "tracker , e . getMessage ( ) != null ? e . getMessage ( ) : e . getClass ( ) . getSimpleName ( ) ) ;", "del_tokens": "tracker , e . getMessage ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "invalid", "description", "for", "generateGitPropertiesFile"], "add_tokens": "* Specifies whether plugin should generate properties file . * By default it will not generate any additional file , * just add properties to maven project 's properties for further filtering * If set to \"true\" properties will be fully generated with no placeholders inside .", "del_tokens": "* Specifies whether the goal runs in verbose mode . * To be more specific , this means more info being printed out while scanning for paths and also * it will make git - commit - id \"eat it's own dog food\" : - ) *", "commit_type": "fix"}
{"commit_tokens": ["improved", "logger", "by", "supporting", "metadata", "in", "json"], "add_tokens": "* Log4j2 Message for Logger that support parameterized messages , using { } as placeholder , eg . : < br / > * error ( \"Something failed: {}\" , ex , \"do'h\" ) ; // => \"Hello {beautiful} {world}\"<br/> * < / code > < br / > * < / code > < br / >", "del_tokens": "* Log4j2 Message for Logger that support parameterized messages , using { } or { name } as placeholder , eg . : < br / > * info ( \"The Answer is {answer}\" , 42L ) ; // => \"The Answer is {42}\" * < / code > * < br / > * < / code > * < br / >", "commit_type": "improve"}
{"commit_tokens": ["Add", "Late", "and", "Lazy", "classes", "."], "add_tokens": "* this . object = object ; return object ;", "del_tokens": "* return this . object = object ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "a", "few", "more", "endpoints"], "add_tokens": "private String reblog_key ; public String getReblogKey ( ) { return this . reblog_key ; } / * * * Like this post * / public void like ( ) { client . like ( this . id , this . reblog_key ) ; } / * * * Unlike this post * / public void unlike ( ) { client . unlike ( this . id , this . reblog_key ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Allow", "MessagesExporter", "to", "merge", "existing", "localization"], "add_tokens": "import org . apache . commons . lang . LocaleUtils ; if ( args . length > 1 ) { LocaleProxy . setLocale ( LocaleUtils . toLocale ( args [ 1 ] ) ) ; } String key = descriptor . key ; key += '[' + entry . getKey ( ) + ']' ; builder . append ( key ) ; String value = proxy . getProperties ( ) . getProperty ( key , entry . getValue ( ) )", "del_tokens": "builder . append ( descriptor . key ) ; builder . append ( '[' ) . append ( entry . getKey ( ) ) . append ( ']' ) ; String value = entry . getValue ( )", "commit_type": "allow"}
{"commit_tokens": ["added", "java", "docs", "to", "new", "Methods", "and", "classes"], "add_tokens": "/ * * * @ return subClass to allow Builder pattern * / / * * * if any extra binding is required binds all badgeItem , BottomNavigationTab and BadgeTextView * * @ param bottomNavigationTab to which badgeItem needs to be attached * / abstract void bindToBottomTabInternal ( BottomNavigationTab bottomNavigationTab ) ; / * * * binds all badgeItem , BottomNavigationTab and BadgeTextView * * @ param bottomNavigationTab to which badgeItem needs to be attached * / bindToBottomTabInternal ( bottomNavigationTab ) ; / * * * @ return returns if BadgeTextView 's reference is valid * /", "del_tokens": "bindToBottomTabInternal ( getSubInstance ( ) , bottomNavigationTab ) ; abstract void bindToBottomTabInternal ( T badgeItem , BottomNavigationTab bottomNavigationTab ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "API", "errors", "-", "set", "methods", "should", "be", "void"], "add_tokens": "public abstract void setLikes ( int likes ) ; public abstract void setViews ( int views ) ;", "del_tokens": "public abstract int setLikes ( int likes ) ; public abstract int setViews ( int views ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "bug", "in", "generalize", "for", "large", "deviations"], "add_tokens": "int rs_size = resultStack . size ( ) ; int path_size = mpsrc . getPathSize ( ipath ) ; if ( rs_size == path_size && rs_size == stack . size ( ) ) {", "del_tokens": "if ( mp == null ) throw GeometryException . GeometryInternalError ( ) ; if ( resultStack . size ( ) == stack . size ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["removed", "excess", "whitespace", "at", "EOL", "[", "skip", "ci", "]"], "add_tokens": "*", "del_tokens": "*", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "default", "filter", "to", "Json", "-", "RPC", "importer"], "add_tokens": "@ ServiceProperty ( name = TARGET_FILTER_PROPERTY , value = \"(&(\" + PROTOCOL_NAME + \"=jsonrpc)(scope=generic))\" )", "del_tokens": "@ ServiceProperty ( name = \"target\" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "droid", "-", "sugar", "to", "forward", "calls", "to", "native", "methods", "to", "the", "fakes", "."], "add_tokens": "if ( ! isAbstract ) {", "del_tokens": "if ( ! wasNative && ! isAbstract ) {", "commit_type": "allow"}
{"commit_tokens": ["fix", "the", "webp", "extension", "column", "name", "to", "the", "tile", "data", "column"], "add_tokens": "TileTable . COLUMN_TILE_DATA , DEFINITION ,", "del_tokens": "TileTable . COLUMN_TILE_ROW , DEFINITION ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "getLastCellNum", "()", ".", "The", "previous", "implementation", "was", "returning", "the", "physical", "number", "of", "cells", "+", "1", "not", "the", "index", "of", "the", "last", "cell", ".", "Also", "implemented", "getPhysicalNumberOfCells", "()"], "add_tokens": "private TreeMap < Integer , Cell > cellMap = new TreeMap < > ( ) ; public void setCellMap ( TreeMap < Integer , Cell > cellMap ) { return ( short ) ( cellMap . size ( ) == 0 ? - 1 : cellMap . lastEntry ( ) . getValue ( ) . getColumnIndex ( ) + 1 ) ; / * * * Gets the number of defined cells ( NOT number of cells in the actual row ! ) . * That is to say if only columns 0 , 4 , 5 have values then there would be 3. * * @ return int representing the number of defined cells in the row . * / @ Override public int getPhysicalNumberOfCells ( ) { return cellMap . size ( ) ; }", "del_tokens": "private Map < Integer , Cell > cellMap = new TreeMap < > ( ) ; public void setCellMap ( Map < Integer , Cell > cellMap ) { return ( short ) ( cellMap . size ( ) == 0 ? - 1 : cellMap . size ( ) + 1 ) ; / * * * Not supported * / @ Override public int getPhysicalNumberOfCells ( ) { throw new NotSupportedException ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "copy", "/", "paste", "error", "in", "BootsrapApplicationListener"], "add_tokens": "bootstrapMap . put ( \"spring.config.location\" , configLocation ) ;", "del_tokens": "bootstrapMap . put ( \"spring.config.location\" , configName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "multiple", "Parent", "Selectors", "for", "a", "single", "parent", "selector", "."], "add_tokens": "if ( mainSelector . length == 1 ) { String [ ] sel = new String [ base . length ] ; for ( int j = 0 ; j < base . length ; j ++ ) { final String selector = base [ j ] ; if ( selector . indexOf ( \"&\" ) >= 0 ) { sel [ j ] = selector . replace ( \"&\" , mainSelector [ 0 ] ) ; } else { sel [ j ] = mainSelector [ 0 ] + ' ' + selector ; } } return sel ; } else { // is there an & operator in the selector? for ( String s : base ) { int andCount = 0 ; int idx = - 1 ; while ( ( idx = s . indexOf ( '&' , idx + 1 ) ) >= 0 ) { andCount ++ ; } count += mainSelector . length * Math . max ( 1 , andCount ) ;", "del_tokens": "// is there an & operator in the selector? for ( String s : base ) { int andCount = 0 ; int idx = - 1 ; while ( ( idx = s . indexOf ( '&' , idx + 1 ) ) >= 0 ) { andCount ++ ; count += mainSelector . length * Math . max ( 1 , andCount ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "default", "methods", "in", "automapped", "interfaces"], "add_tokens": "import org . davidmoten . rx . jdbc . exceptions . AutomappedInterfaceInaccessibleException ; throw new AutomappedInterfaceInaccessibleException (", "del_tokens": "import org . davidmoten . rx . jdbc . exceptions . AutomappedClassInaccessibleException ; throw new AutomappedClassInaccessibleException (", "commit_type": "add"}
{"commit_tokens": ["Removed", "IOException", "from", "close", "method", "declaration", "."], "add_tokens": "public void close ( ) {", "del_tokens": "public void close ( ) throws IOException {", "commit_type": "remove"}
{"commit_tokens": ["Improve", "package", "structure", "and", "updated", "kotlin"], "add_tokens": "public void test ( ) {", "del_tokens": "public void test ( ) throws IllegalAccessException , InstantiationException , ClassNotFoundException {", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "short", "name", "generation", "algorithm", "."], "add_tokens": "public static void main ( String [ ] args ) throws Exception { final ConformanceTest ct = new ConformanceTest ( ) ; ct . setUp ( ) ; ct . testAcceptedFileNames ( ) ; } root . addFile ( \"jdom-1.0.jar\" ) ;", "del_tokens": "root . addFile ( \"IOUtils.1.4.0-SNAPSHOT.jar\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "logging", "of", "timeout", "dates"], "add_tokens": "logger . info ( \"[PROXY TIMEOUT SET] %s/%s; %s\" , repo . getKey ( ) , path , new Date ( System . currentTimeMillis ( ) + timeout ) ) ;", "del_tokens": "logger . info ( \"[PROXY TIMEOUT SET] %s/%s; %s\" , repo . getKey ( ) , path , new Date ( timeout ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "MAJ", "-", "740", "+", "version", "change"], "add_tokens": "return \"1.5.4\" ;", "del_tokens": "return \"1.5.3\" ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "connection", "s", "state", "regardless", "of", "listener"], "add_tokens": "// Update internal state switch ( output . type ( ) ) { case psubscribe : patterns . add ( output . pattern ( ) ) ; break ; case punsubscribe : patterns . remove ( output . pattern ( ) ) ; break ; case subscribe : channels . add ( output . channel ( ) ) ; break ; case unsubscribe : channels . remove ( output . channel ( ) ) ; break ; default : break ; } // notify watchers, if any", "del_tokens": "patterns . add ( output . pattern ( ) ) ; patterns . remove ( output . pattern ( ) ) ; channels . add ( output . channel ( ) ) ; channels . remove ( output . channel ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "HTML", "profiles"], "add_tokens": "htmlSerializer . write ( output , triples , profiles . length > 0 ? profiles [ 0 ] : null ) ;", "del_tokens": "htmlSerializer . write ( output , triples , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "data", "(", "latest", "model", "file", "format", ")"], "add_tokens": "private static final String MODEL_PATH = \"model/gbtree/v40/binary-logistic.model\" ;", "del_tokens": "private static final String MODEL_PATH = \"model/gbtree/binary-logistic.model\" ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "method", "isIn", "(", "Collection", ")", "for", "all", "assertion", "classes", "."], "add_tokens": "import java . util . Collection ; * @ param values the given array to search the actual value in . * @ throws AssertionError if the actual value is not in the given array . / * * * Verifies that the actual value is in the given collection of values . * @ param values the given collection to search the actual value in . * @ return { @ code this } assertion object . * @ throws NullPointerException if the given collection is { @ code null } . * @ throws IllegalArgumentException if the given collection is empty . * @ throws AssertionError if the actual value is not in the given collection . * / S isIn ( Collection < ? > values ) ;", "del_tokens": "* @ param values the given values to search the actual value in . * @ throws AssertionError if the actual value is not in the given values .", "commit_type": "implement"}
{"commit_tokens": ["add", "support", "for", "shutting", "down", "the", "ConnectionManager"], "add_tokens": "void shutdown ( ) ; }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "transition", "to", "DrawerViewActivity"], "add_tokens": "import android . view . animation . LinearInterpolator ; findViewById ( R . id . slide_bg ) . setOnClickListener ( this ) ; ViewTransitionBuilder . transit ( findViewById ( R . id . lay_buttons ) ) . interpolator ( new AccelerateInterpolator ( ) ) . adapter ( mDrawerListenerAdapter ) . transitViewGroup ( new ViewTransitionBuilder . ViewGroupTransition ( ) { break ; case R . id . slide_bg : mDrawerListenerAdapter . addTransition ( ViewTransitionBuilder . transit ( findViewById ( R . id . bg ) ) . interpolator ( new LinearInterpolator ( ) ) . translationXAsFractionOfWidth ( 0.25f ) ) ;", "del_tokens": "ViewTransitionBuilder builder ; builder = ViewTransitionBuilder . transit ( findViewById ( R . id . lay_buttons ) ) . interpolator ( new AccelerateInterpolator ( ) ) . adapter ( mDrawerListenerAdapter ) . transitViewGroup ( new ViewTransitionBuilder . ViewGroupTransition ( ) { mDrawerListenerAdapter . addTransition ( builder ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "TODOs", ".", "MockOs", "support", "will", "probably", "never", "happen", "."], "add_tokens": "//import tests.io.MockOs; //private final MockOs mockOs = new MockOs(); //mockOs.install(); //mockOs.uninstall(); / * public void testFileBecomesInaccessibleDuringReadResultsInIoException ( ) throws Exception { / * public void testFileBecomesInaccessibleDuringWriteIsSilentlyDiscarded ( ) throws Exception {", "del_tokens": "import java . io . IOException ; import java . io . OutputStream ; //TODO import tests.io.MockOs; //TODO private final MockOs mockOs = new MockOs(); //TODO mockOs.install(); //TODO mockOs.uninstall(); / * TODO public void testFileBecomesInaccessibleDuringReadResultsInIoException ( ) throws Exception { / * TODO public void testFileBecomesInaccessibleDuringWriteIsSilentlyDiscarded ( ) throws Exception {", "commit_type": "remove"}
{"commit_tokens": ["Remove", "unnecessary", "and", "dangerous", "lock", "from", "PackedForwardBuffer"], "add_tokens": "private RetentionBuffer prepareBuffer ( String tag , int writeSize )", "del_tokens": "private synchronized RetentionBuffer prepareBuffer ( String tag , int writeSize )", "commit_type": "remove"}
{"commit_tokens": ["use", "handler", "to", "replace", "result", "callback"], "add_tokens": "import android . os . Message ; ( handler , serial , nextCallable , callback , caller ) ; final TaskCallback < Result > callback , final Caller caller ) { // TaskMap public static final int MSG_REMOVE_TASK_BY_TAG = 4001 ; * Handler  * TODO cancelAll mUiHandler = new Handler ( Looper . getMainLooper ( ) ) { @ Override public void handleMessage ( final Message msg ) { super . handleMessage ( msg ) ; if ( mDebug ) { LogUtils . v ( TAG , \"handleMessage() what=\" + msg . what ) ; } switch ( msg . what ) { case MSG_REMOVE_TASK_BY_TAG : { final String tag = ( String ) msg . obj ; remove ( tag ) ; } break ; default : break ; } } } ;", "del_tokens": "final ResultCallback nextCallback = new ResultCallback ( ) { @ Override public void onDone ( final int hashCode , final String tag ) { remove ( tag ) ; } } ; ( handler , serial , nextCallback , nextCallable , callback , caller ) ; final TaskCallback < Result > callback , final Caller caller ) { * Handler mUiHandler = new Handler ( Looper . getMainLooper ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Using", "the", "property", "org", ".", "mozilla", ".", "javascript", ".", "JavaAdapter", "to", "allow", "the", "JavaAdapter", "class", "to", "come", "from", "another", "package", "."], "add_tokens": "\"regexp.NativeRegExp\" , \"NativeScript\" // Define the JavaAdapter class, allowing it to be overridden. try { String defaultName = \"org.mozilla.javascript.JavaAdapter\" ; String adapterName = System . getProperty ( defaultName , defaultName ) ; Class adapterClass = Class . forName ( adapterName ) ; ScriptableObject . defineClass ( scope , adapterClass , sealed ) ; } catch ( ClassNotFoundException e ) { }", "del_tokens": "\"regexp.NativeRegExp\" , \"NativeScript\" , \"JavaAdapter\"", "commit_type": "use"}
{"commit_tokens": ["Use", "AccentHelper", "to", "get", "the", "paletty", "for", "AccentRatingBar"], "add_tokens": "import com . negusoft . holoaccent . AccentHelper ; mPalette = AccentHelper . getPalette ( context ) ;", "del_tokens": "Resources resources = context . getResources ( ) ; if ( resources instanceof AccentResources ) mPalette = ( ( AccentResources ) resources ) . getPalette ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "WebDriverType", "modify", "CrawlerConfiguration", "to", "use", "the", "new", "enum", "."], "add_tokens": "* Implements a configuration class to get and set * all the necessary options for the crawler . * private WebDriverType webDriverType ; public WebDriverType getWebDriverType ( ) { return webDriverType ; } public void setWebDriverType ( WebDriverType webDriverType ) { this . webDriverType = webDriverType ; }", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Fixing", "test", "of", "||", "and", "|", "lexing", ".", "No", "code", "was", "broken", "just", "the", "test", "."], "add_tokens": "public void testPipe ( ) assertSimple ( \"|\" , Token . PIPE ) ;", "del_tokens": "public void testPipe_UnexpectedCharacter ( ) newLexer ( \"|a\" ) ; char [ ] expected = assertUnexpectedCharacter ( 'a' , 1 , 2 ) ; assertLength ( 1 , expected ) ; assertContains ( '|' , expected ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "BYTE", "type", "isSubType"], "add_tokens": "case BYTE : throw new IllegalArgumentException ( \"missing implementation for \" + sup + \"/\" + sub ) ;", "del_tokens": "throw new IllegalArgumentException ( sup + \" is unsuitable type\" ) ;", "commit_type": "add"}
{"commit_tokens": ["changing", "to", "HttpClient", ".", "openConnection", "(", "String", ")"], "add_tokens": "* * * * even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the GNU * * You should have received a copy of the GNU Lesser General Public License along with Sprockets . If * not , see < http : //www.gnu.org/licenses/>. return new ImageResponse ( HttpClient . openConnection ( params . format ( ) ) ) ;", "del_tokens": "* * * * even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the GNU * * You should have received a copy of the GNU Lesser General Public License along with Sprockets . * If not , see < http : //www.gnu.org/licenses/>. import java . net . URL ; return new ImageResponse ( HttpClient . openConnection ( new URL ( params . format ( ) ) ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "@Factory", "in", "fabric", "-", "mq", "cdi", "tests", "."], "add_tokens": "import io . fabric8 . mq . ActiveMQConfig ; import io . fabric8 . mq . ActiveMQConfigurer ; return DeltaspikeTestBase . createDeployment ( ) . addClasses ( DeltaspikeTestBase . getDeltaSpikeHolders ( ) ) . addClasses ( ActiveMQConfigurer . class ) ;", "del_tokens": "import io . fabric8 . mq . ActiveMQConnectionFactoryProducer ; return DeltaspikeTestBase . createDeployment ( ) . addClass ( ActiveMQConnectionFactoryProducer . class ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "getCurrentURL", "as", "a", "testable", "-", "string"], "add_tokens": "Select select = getSelect ( ) ; select . selectByValue ( value ) ;", "del_tokens": "getSelect ( ) . selectByValue ( value ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "dynamic", "enum", "processor", "to", "handle", "interfaces"], "add_tokens": "if ( e . getKind ( ) == ElementKind . CLASS || e . getKind ( ) == ElementKind . INTERFACE ) { DynamicEnumeration de = e . getAnnotation ( DynamicEnumeration . class ) ; String cName = de == null ? classElement . getSimpleName ( ) + \"Enum\" : de . className ( ) ;", "del_tokens": "if ( e . getKind ( ) == ElementKind . CLASS ) { String cName = classElement . getSimpleName ( ) + \"Enum\" ;", "commit_type": "update"}
{"commit_tokens": ["removes", "the", "DefaultFormatter", "class", "and", "uses", "the", "StringFormatter", "as", "default", "formatter", "."], "add_tokens": "import org . cubeengine . dirigent . formatter . StringFormatter ; * Constructor . Uses the { @ link StringFormatter } as the default formatter . this ( new StringFormatter ( ) ) ;", "del_tokens": "import org . cubeengine . dirigent . formatter . DefaultFormatter ; * Constructor . Uses the { @ link DefaultFormatter } as the default formatter . this ( new DefaultFormatter ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", ":", "the", "update", "method", "was", "never", "called", "."], "add_tokens": "import java . util . Dictionary ; import org . osgi . service . cm . ConfigurationException ; import org . osgi . service . cm . ManagedService ; final LoggingServiceFactory loggingServiceFactory = new LoggingServiceFactory ( configFactory ) ; String paxLoggingName = PaxLoggingService . class . getName ( ) ; // configuration for loggingServiceFactory Hashtable managedServiceProps = new Hashtable ( ) ; managedServiceProps . put ( Constants . SERVICE_PID , CONFIGURATION_PID ) ; ManagedService managedService = new ManagedService ( ) { public void updated ( Dictionary iProperties ) throws ConfigurationException { loggingServiceFactory . updated ( iProperties ) ; } } ; bundleContext . registerService ( ManagedService . class . getName ( ) , managedService , managedServiceProps ) ;", "del_tokens": "LoggingServiceFactory loggingServiceFactory = new LoggingServiceFactory ( configFactory ) ; properties . put ( Constants . SERVICE_PID , CONFIGURATION_PID ) ; String paxLoggingName = PaxLoggingService . class . getName ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "ping", "command", "instead", "of", "sleep", "to", "test", "timeout", "exception", "on", "Windows"], "add_tokens": "import org . apache . commons . lang3 . SystemUtils ; import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . TimeoutException ; if ( SystemUtils . IS_OS_WINDOWS ) { // native sleep command is not available on Windows platform // mock using standard ping to localhost instead // (Windows ping does 4 requests which takes about 3 seconds) commands . add ( \"ping\" ) ; commands . add ( \"127.0.0.1\" ) ; } else { commands . add ( \"sleep\" ) ; commands . add ( \"3\" ) ; } if ( SystemUtils . IS_OS_WINDOWS ) { // native sleep command is not available on Windows platform // mock using standard ping to localhost instead // (Windows ping does 4 requests which takes about 3 seconds) commands . add ( \"ping\" ) ; commands . add ( \"127.0.0.1\" ) ; } else { commands . add ( \"sleep\" ) ; commands . add ( \"3\" ) ; }", "del_tokens": "import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . TimeoutException ; commands . add ( \"sleep\" ) ; commands . add ( \"3\" ) ; commands . add ( \"sleep\" ) ; commands . add ( \"3\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "guard", "for", "invalid", "index", "of", "aTexture", "in", "non", "-", "texture", "shaders"], "add_tokens": "if ( aTexture != - 1 ) { gl . enableVertexAttribArray ( aTexture ) ; } if ( aTexture != - 1 ) { gl . vertexAttribPointer ( aTexture , 2 , FLOAT , false , 40 , 32 ) ; }", "del_tokens": "gl . enableVertexAttribArray ( aTexture ) ; gl . vertexAttribPointer ( aTexture , 2 , FLOAT , false , 40 , 32 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "capability", "to", "disable", "the", "capture", "of", "binary", "contents", "(", "eg", ":", "video"], "add_tokens": "// if captureContent is set, default policy is to capture binary contents too private boolean captureBinaryContent = true ; if ( contentType != null && ( contentType . startsWith ( \"text/\" ) || contentType . startsWith ( \"application/x-javascript\" ) ) || contentType . startsWith ( \"application/javascript\" ) || contentType . startsWith ( \"application/json\" ) || contentType . startsWith ( \"application/xml\" ) || contentType . startsWith ( \"application/xhtml+xml\" ) ) { } else if ( captureBinaryContent ) { public void setCaptureBinaryContent ( boolean captureBinaryContent ) { this . captureBinaryContent = captureBinaryContent ; }", "del_tokens": "if ( contentType != null && contentType . startsWith ( \"text/\" ) ) { } else {", "commit_type": "add"}
{"commit_tokens": ["added", "type", "support", "for", "TextAnnotation", "beans"], "add_tokens": "void setDataset ( String dataset ) { void addPropertyValue ( String property , String value ) {", "del_tokens": "void setDataset ( String dataset ) { void addPropertyValue ( String property , String value ) {", "commit_type": "add"}
{"commit_tokens": ["making", "the", "ezleveldb", "database", "thread", "safe", ".", "making", "torture", "test", "threaded", "."], "add_tokens": "public class TestEzLevelDb {", "del_tokens": "public class TestEzLevelDbTable {", "commit_type": "make"}
{"commit_tokens": ["Use", "single", "quote", "for", "system", "TestDoc"], "add_tokens": "assertThat ( assertThatTestDoc . getTestDoc ( ) , is ( \"check that '{0}' {1}\" ) ) ;", "del_tokens": "assertThat ( assertThatTestDoc . getTestDoc ( ) , is ( \"check if \\\"{0}\\\" {1}\" ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "test", "to", "use", "unique", "port"], "add_tokens": "bootstrapProperties . setProperty ( \"default.http.port\" , \"9082\" ) ; assertTrue ( HttpPortUtil . getHttpPort ( serverXML , bootstrapProperties ) == 9082 ) ;", "del_tokens": "bootstrapProperties . setProperty ( \"default.http.port\" , \"9080\" ) ; assertTrue ( HttpPortUtil . getHttpPort ( serverXML , bootstrapProperties ) == 9080 ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "messages", "to", "be", "filtered", "out", "from", "writing", "."], "add_tokens": "* Will output all the messages , including tags , into a stream . return this . write ( stream , new MessageCondition ( ) { public boolean accept ( final Message msg ) { // accept every message return true ; } } ) ; } / * * * Will output the messages , including tags , that meet a specific condition , * into a stream . * * @ param stream * Target . * @ param condition * When this object 's {@link MessageCondition#accept(Message)} * returns true on a message , the message will be included in the * stream . * @ return True if written , false otherwise . * / public boolean write ( final OutputStream stream , final MessageCondition condition ) { if ( stream == null ) { throw new IllegalArgumentException ( \"Stream may not be null.\" ) ; } else if ( condition == null ) { throw new IllegalArgumentException ( \"Condition may not be null.\" ) ; } if ( ! condition . accept ( msg ) ) { continue ; }", "del_tokens": "* Will output the log , including tags , into a stream .", "commit_type": "allow"}
{"commit_tokens": ["Added", "method", "to", "use", "template", "around", "a", "struct", ".", "Added", "documentation", "for", "it", "to", "readme", "."], "add_tokens": "* http : //www.apache.org/licenses/LICENSE-2.0 @ Test public void struct ( ) { this . structTemplate . addTemplate ( \"test\" , \"${stringField}\" ) ; String actual = this . structTemplate . execute ( \"test\" , this . struct ) ; assertEquals ( \"TestValue\" , actual ) ; }", "del_tokens": "* http : //www.apache.org/licenses/LICENSE-2.0", "commit_type": "add"}
{"commit_tokens": ["use", "static", "function", "in", "URLDecoder"], "add_tokens": "path [ i ] = URLDecoder . decode ( path [ i ] , \"UTF-8\" ) ;", "del_tokens": "private final URLDecoder urlDecoder = new URLDecoder ( ) ; path [ i ] = urlDecoder . decode ( path [ i ] , \"UTF-8\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "@With", "interceptors", "in", "Java"], "add_tokens": "public static Result notIntercepted ( ) { return ok ( Interceptor . state ) ; } @ With ( Interceptor . class ) public static Result interceptedUsingWith ( ) { return ok ( Interceptor . state ) ; } @ Intercepted public static Result intercepted ( ) { return ok ( Interceptor . state ) ; }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["add", "/", "forget", "Fedora", "and", "DuraCloud", "-", "based", "stores", "done", ".", "plus", "part", "of", "add", "sets", "."], "add_tokens": "import com . github . cwilper . fcrepo . cloudsync . service . util . JSON ; import java . util . Map ; private final String url ; private final String username ; private final String password ; private final String providerId ; private final String providerName ; private final String space ; private final String prefix ; Map < String , String > map = JSON . getMap ( JSON . parse ( store . getData ( ) ) ) ; url = normalize ( nonEmpty ( \"url\" , map . get ( \"url\" ) ) ) ; username = normalize ( nonEmpty ( \"username\" , map . get ( \"username\" ) ) ) ; password = nonEmpty ( \"password\" , map . get ( \"password\" ) ) ; providerId = normalize ( nonEmpty ( \"providerId\" , map . get ( \"providerId\" ) ) ) ; providerName = normalize ( nonEmpty ( \"providerName\" , map . get ( \"providerName\" ) ) ) ; space = normalize ( nonEmpty ( \"space\" , map . get ( \"space\" ) ) ) ; prefix = normalize ( map . get ( \"prefix\" ) ) ;", "del_tokens": "// TODO: validate store fields, including json data", "commit_type": "add"}
{"commit_tokens": ["changed", "pager", "transformer", "animation", "background", "colors", "now", "animate", "while", "changing", "as", "well", "as", "the", "statusbar", "color", "."], "add_tokens": "// background_layout.setBackgroundColor(permissionModel.getLayoutColor());", "del_tokens": "background_layout . setBackgroundColor ( permissionModel . getLayoutColor ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["adding", "test", "for", "encodedBase", ".", "charAt", "(", "0", ")", "-", "A", ">", "=", "0"], "add_tokens": "int encodedBaseLength = encodedBase . length ( ) ; if ( encodedBaseLength > 0 ) { if ( ( encodedBase . charAt ( 0 ) - 'A' >= 0 ) ) if ( encodedBaseLength > 1 && ( ( int ) encodedBase . charAt ( 0 ) - 'A' >= 0 ) ) int stripAtEnd = ( int ) ( encodedBase . charAt ( 1 ) - 'A' ) ; if ( encodedBase . length ( ) > 2 && ( ( int ) encodedBase . charAt ( 0 ) - 'A' >= 0 ) ) } else { // shouldn't happen, but if so, simply return the encodedBase return encodedBase ; }", "del_tokens": "if ( encodedBase . length ( ) > 0 ) if ( encodedBase . length ( ) > 1 ) int stripAtEnd = ( int ) ( encodedBase . charAt ( 1 ) - 'A' ) ; if ( encodedBase . length ( ) > 2 )", "commit_type": "add"}
{"commit_tokens": ["Removes", "wrong", "prefix", "in", "config", "loading"], "add_tokens": "ActorSystem actorSystem = ActorSystem . create ( \"lagom-client\" , configuration ,", "del_tokens": "ActorSystem actorSystem = ActorSystem . create ( \"lagom-client\" , configuration . getConfig ( \"akka\" ) ,", "commit_type": "remove"}
{"commit_tokens": ["Remove", "ref", "to", "composite", "discovery", "client", "."], "add_tokens": "then ( discoveryClient ) . isInstanceOf ( ZookeeperDiscoveryClient . class ) ;", "del_tokens": "import java . lang . reflect . Field ; import org . springframework . cloud . client . discovery . composite . CompositeDiscoveryClient ; import org . springframework . util . ReflectionUtils ; then ( discoveryClient ) . isInstanceOf ( CompositeDiscoveryClient . class ) ; CompositeDiscoveryClient composite = ( CompositeDiscoveryClient ) discoveryClient ; Field field = ReflectionUtils . findField ( CompositeDiscoveryClient . class , \"discoveryClients\" ) ; ReflectionUtils . makeAccessible ( field ) ; List < DiscoveryClient > discoveryClients = ( List < DiscoveryClient > ) ReflectionUtils . getField ( field , composite ) ; DiscoveryClient first = discoveryClients . get ( 0 ) ; then ( first ) . isInstanceOf ( ZookeeperDiscoveryClient . class ) ;", "commit_type": "remove"}
{"commit_tokens": ["create", "all", "logs", "after", "first", "log", "created"], "add_tokens": "logger . info ( format ( \"Created log for [%s-%d], now create other logs if necessary\" , topic , partition ) ) ; final int configPartitions = getPartition ( topic ) ; for ( int i = 0 ; i < configPartitions ; i ++ ) { getOrCreateLog ( topic , i ) ; }", "del_tokens": "logger . info ( format ( \"Created log for [%s-%d]\" , topic , partition ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Fixed", "TabbedPanel", "NPE", "for", "good", "now", "I", "hope"], "add_tokens": "if ( content [ i ] != null ) data += \"{\\\"widget\\\":\" + String . valueOf ( content [ i ] . widget != null ? content [ i ] . widget . getID ( ) : - 1 ) + \",\\\"name\\\":\\\"\" + ( content [ i ] . name != null ? content [ i ] . name : \"unnamed\" ) + \"\\\"}\" ; else data += \"{\\\"widget\\\":-1, \\\"name\\\":\\\"-NULL-\\\"}\" ;", "del_tokens": "data += \"{\\\"widget\\\":\" + String . valueOf ( content [ i ] . widget != null ? content [ i ] . widget . getID ( ) : - 1 ) + \",\\\"name\\\":\\\"\" + ( content [ i ] . name != null ? content [ i ] . name : \"unnamed\" ) + \"\\\"}\" ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "squid", ":", "S2325", "-", "private", "methods", "that", "don", "t", "access", "instance", "data"], "add_tokens": "Schedulers . increaseNoOfSchedullers ( ) ; Schedulers . increaseNoOfSchedullers ( ) ; Schedulers . decreaseNoOfSchedullers ( ) ; Schedulers . decreaseNoOfRunningSchedullers ( ) ; Schedulers . decreaseNoOfSchedullers ( ) ; Schedulers . decreaseNoOfRunningSchedullers ( ) ; String id = Schedulers . getUUID ( ) ; Schedulers . increaseNoOfRunningSchedullers ( ) ; String id = Schedulers . getUUID ( ) ; Schedulers . increaseNoOfRunningSchedullers ( ) ; private static synchronized void increaseNoOfSchedullers ( ) { private static synchronized void increaseNoOfRunningSchedullers ( ) { private static synchronized void decreaseNoOfSchedullers ( ) { private static synchronized void decreaseNoOfRunningSchedullers ( ) { private static synchronized String getUUID ( ) {", "del_tokens": "instance . increaseNoOfSchedullers ( ) ; instance . increaseNoOfSchedullers ( ) ; instance . decreaseNoOfSchedullers ( ) ; instance . decreaseNoOfRunningSchedullers ( ) ; instance . decreaseNoOfSchedullers ( ) ; instance . decreaseNoOfRunningSchedullers ( ) ; String id = getUUID ( ) ; increaseNoOfRunningSchedullers ( ) ; String id = getUUID ( ) ; increaseNoOfRunningSchedullers ( ) ; private synchronized void increaseNoOfSchedullers ( ) { private synchronized void increaseNoOfRunningSchedullers ( ) { private synchronized void decreaseNoOfSchedullers ( ) { private synchronized void decreaseNoOfRunningSchedullers ( ) { private synchronized String getUUID ( ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "use", "of", "getMethod", "()", "getField", "()", "instead", "use", "getDeclaredXxxx", "()", "and", "setAccessible", "(", "true", ")"], "add_tokens": "for ( Class c = clazz ; c != Object . class ; c = c . getSuperclass ( ) ) for ( Field field : clazz . getDeclaredFields ( ) ) { if ( ! field . isAccessible ( ) ) field . setAccessible ( true ) ; fields . add ( new SimpleAnnotatedField < Object > ( field ) ) ; } for ( Class c = clazz ; c != Object . class ; c = c . getSuperclass ( ) ) for ( Method method : clazz . getDeclaredMethods ( ) ) { if ( ! method . isAccessible ( ) ) method . setAccessible ( true ) ; methods . add ( new SimpleAnnotatedMethod < Object > ( method ) ) ; } if ( ! constructor . isAccessible ( ) ) constructor . setAccessible ( true ) ;", "del_tokens": "for ( Field field : clazz . getFields ( ) ) fields . add ( new SimpleAnnotatedField < Object > ( field ) ) ; for ( Method member : clazz . getDeclaredMethods ( ) ) methods . add ( new SimpleAnnotatedMethod < Object > ( member ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "value", "mapper", "for", "observable", "set", "commands"], "add_tokens": "msg . setValue ( valueMapper . map ( new ObservedValue ( value , keyIsObservableObject ) ) ) ; msg . setValue ( valueMapper . map ( new ObservedValue ( value , isObservableObject ) ) ) ;", "del_tokens": "if ( keyIsObservableObject ) { msg . setObservableObjectId ( parent . getId ( value ) ) ; } else { msg . setSimpleObjectValue ( value ) ; } if ( isObservableObject ) { msg . setObservableObjectId ( parent . getId ( value ) ) ; } else { msg . setSimpleObjectValue ( value ) ; }", "commit_type": "use"}
{"commit_tokens": ["fixed", "highly", "nasty", "bug", "in", "number", "handling"], "add_tokens": "return \"\\\"\" + new Long ( n . longValue ( ) ) . toString ( ) + \"\\\"\" ; return new Long ( n . longValue ( ) ) . toString ( ) ; @ SuppressWarnings ( \"unchecked\" ) public DataArray fromMapsAndCollections ( @ SuppressWarnings ( \"rawtypes\" ) Collection c ) { @ SuppressWarnings ( \"unchecked\" ) @ SuppressWarnings ( \"unchecked\" )", "del_tokens": "import com . nominanuda . lang . ObjectConvertor ; return \"\\\"\" + new Integer ( n . intValue ( ) ) . toString ( ) + \"\\\"\" ; return new Integer ( n . intValue ( ) ) . toString ( ) ; public DataArray fromMapsAndCollections ( Collection c ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "comment", "to", "the", "Dao", "constructor", "in", "support", "of", "issue", "13"], "add_tokens": "* your Activity . The DAO maintains no database state , but rather * only the { @ link Context } to initialize the database if needed . * It is safe to construct multiple instances of the DAO since all * database access occurs a singleton instance of { @ link SQLiteOpenHelper } * provided by your generated { @ link DatabaseFactory } .", "del_tokens": "* your Activity .", "commit_type": "add"}
{"commit_tokens": ["Add", "shutdown", "hook", "to", "SeedMain"], "add_tokens": "public void launch ( String [ ] args ) throws Exception { int returnCode = execute ( args ) ; LOGGER . info ( \"CLI command finished with return code {}\" , returnCode ) ; System . exit ( returnCode ) ; } @ Override public void shutdown ( ) throws Exception { // nothing to do", "del_tokens": "public int launch ( String [ ] args ) throws Exception { return execute ( args ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bugs", "and", "improved", "code"], "add_tokens": "File propertiesFile = new File ( propertiesPath ) ; if ( ! propertiesFile . exists ( ) ) try { propertiesFile . createNewFile ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } InputStream inputStream ; try { inputStream = new FileInputStream ( propertiesFile ) ; properties . load ( inputStream ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } catch ( FileNotFoundException e ) { //TODO: log exception", "del_tokens": "synchronized ( propertiesPath ) { File propertiesFile = new File ( propertiesPath ) ; if ( ! propertiesFile . exists ( ) ) try { propertiesFile . createNewFile ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } InputStream inputStream ; inputStream = new FileInputStream ( propertiesFile ) ; try { properties . load ( inputStream ) ; } catch ( IOException e ) { //TODO: log exception e . printStackTrace ( ) ; } } catch ( FileNotFoundException e ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "the", "test", "with", "relative", "paths"], "add_tokens": "if ( ( settings = ws . child ( settingsPath ) ) . exists ( ) ) { if ( ( settings = ws . child ( settingsPath ) ) . exists ( ) ) {", "del_tokens": "if ( ( settings = new FilePath ( ws . getChannel ( ) , settingsPath ) ) . exists ( ) ) { if ( ( settings = new FilePath ( ws . getChannel ( ) , settingsPath ) ) . exists ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "Olympus", "&", "Panasonic", "RAW", "file", "special", "TIFF", "markers", "."], "add_tokens": "// special presentation for long arrays if ( length > 16 ) { final String componentTypeName = object . getClass ( ) . getComponentType ( ) . getName ( ) ; return String . format ( \"[%d %s%s]\" , length , componentTypeName , length == 1 ? \"\" : \"s\" ) ;", "del_tokens": "// special presentation for frequently very long byte arrays final Class < ? > componentType = object . getClass ( ) . getComponentType ( ) ; boolean isByteArray = componentType . getName ( ) . equals ( \"byte\" ) ; if ( isByteArray && length > 12 ) { return String . format ( \"[%d byte%s]\" , length , length == 1 ? \"\" : \"s\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "single", "quoting", "rules", "for", "Smartypants", "extension"], "add_tokens": "! Character . isLetter ( getContext ( ) . getInputBuffer ( ) . charAt ( getContext ( ) . getCurrentIndex ( ) - 1 ) ) , '\\'' ,", "del_tokens": "SingleQuoteStart ( ) , public Rule SingleQuoteStart ( ) { return Sequence ( '\\'' , TestNot ( AnyOf ( \")!],.;:-? \\t\\n\" ) ) , TestNot ( // do not convert the English apostrophes as in it's, I've, I'll, etc... FirstOf ( 's' , 't' , \"m\" , \"ve\" , \"ll\" , \"re\" ) , TestNot ( Alphanumeric ( ) ) ) ) ; }", "commit_type": "improve"}
{"commit_tokens": ["Add", "errors", "for", "procedures", "listen", "by", "a", "Handler", "."], "add_tokens": "boolean isProcedureOnError = procedures . getAllProceduresInError ( adapter ) != null && procedures . getAllProceduresInError ( adapter ) . getNumberOfProceduresInError ( ) > 0 ; if ( isProcedureOnError || procedures . isError ( ) ) { / * * Procedures on errors * * / if ( isProcedureOnError ) { jobDataMap . put ( QuartzUtils . PROCEDURES_IN_ERROR , procedures . getAllProceduresInError ( adapter ) ) ; }", "del_tokens": "import org . quartz . JobExecutionException ; if ( ( procedures . getAllProceduresInError ( adapter ) != null && procedures . getAllProceduresInError ( adapter ) . getNumberOfProceduresInError ( ) > 0 ) || procedures . isError ( ) ) { / * * Procedures on errors * * / if ( procedures . getAllProceduresInError ( adapter ) != null && procedures . getAllProceduresInError ( adapter ) . getNumberOfProceduresInError ( ) > 0 ) { jobDataMap . put ( QuartzUtils . PROCEDURES_IN_ERROR , procedures . getAllProceduresInError ( adapter ) ) ; //throw new JobExecutionException(); }", "commit_type": "add"}
{"commit_tokens": ["Add", "id", "for", "popupmenu", "."], "add_tokens": "int order = item . getItemId ( ) ; private void requestPermission ( String [ ] ... permissions ) { AndPermission . with ( this ) . permission ( permissions ) . rationale ( mRationale ) . onGranted ( new Action ( ) { @ Override public void onAction ( List < String > permissions ) { toast ( R . string . successfully ) ; } } ) . onDenied ( new Action ( ) { @ Override public void onAction ( @ NonNull List < String > permissions ) { toast ( R . string . failure ) ; if ( AndPermission . hasAlwaysDeniedPermission ( MainActivity . this , permissions ) ) { mSetting . showSetting ( permissions ) ; } } } ) . start ( ) ; } for ( int i = 0 ; i < menuArray . length ; i ++ ) { String menuText = menuArray [ i ] ; menu . add ( 0 , i , i , menuText ) ;", "del_tokens": "int order = item . getOrder ( ) ; for ( String menuText : menuArray ) { menu . add ( menuText ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "logic", "to", "make", "Authentication", "UI", "more", "extensible", "."], "add_tokens": "protected void startAuthenticationUI ( ) { BoxAuthentication . getInstance ( ) . startAuthenticationUI ( this ) ; } mSession . startAuthenticationUI ( ) ;", "del_tokens": "BoxAuthentication . getInstance ( ) . startAuthenticationUI ( mSession ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "requirement", "for", "fragments", "lots", "of", "cleanup"], "add_tokens": "if ( a . length ( ) > 0 ) { ParallaxViewTag tag = new ParallaxViewTag ( ) ; tag . alphaIn = a . getFloat ( 0 , 0f ) ; tag . alphaOut = a . getFloat ( 1 , 0f ) ; tag . xIn = a . getFloat ( 2 , 0f ) ; tag . xOut = a . getFloat ( 3 , 0f ) ; tag . yIn = a . getFloat ( 4 , 0f ) ; tag . yOut = a . getFloat ( 5 , 0f ) ; view . setTag ( R . id . parallax_view_tag , tag ) ; }", "del_tokens": "ParallaxViewTag parallaxViewTag = new ParallaxViewTag ( ) ; parallaxViewTag . alphaIn = a . getFloat ( 0 , 0.0f ) ; parallaxViewTag . alphaOut = a . getFloat ( 1 , 0.0f ) ; parallaxViewTag . xIn = a . getFloat ( 2 , 0.0f ) ; parallaxViewTag . xOut = a . getFloat ( 3 , 0.0f ) ; parallaxViewTag . yIn = a . getFloat ( 4 , 0.0f ) ; parallaxViewTag . yOut = a . getFloat ( 5 , 0.0f ) ; view . setTag ( R . id . TAG_ID , parallaxViewTag ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "exception", "to", "the", "log"], "add_tokens": "LOGGER . error ( \"Ignoring exception during application close due to exception at startup: \" + e , e ) ;", "del_tokens": "LOGGER . info ( \"Ignoring exception during application close due to exception at startup\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "empty", "params", "when", "update", "issue", "."], "add_tokens": "protected static final String USER_AGENT = \"backlog4jv2\" ; protected static final String CONTENT_TYPE = \"application/x-www-form-urlencoded; charset=UTF-8\" ; protected static final String CHARSET = \"UTF-8\" ; protected static final String LINE_FEED = \"\\r\\n\" ; protected String apiKey ; protected String bearerToken ; protected int readTimeout ; protected int connectionTimeout ;", "del_tokens": "private static final String USER_AGENT = \"backlog4jv2\" ; private static final String CONTENT_TYPE = \"application/x-www-form-urlencoded; charset=UTF-8\" ; private static final String CHARSET = \"UTF-8\" ; private static final String LINE_FEED = \"\\r\\n\" ; private String apiKey ; private String bearerToken ; private int readTimeout ; private int connectionTimeout ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "error", "while", "cleaning", "up", "store"], "add_tokens": "node . delete ( ) ;", "del_tokens": "node . delete ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "empty", "path", "lookups", "work", "correctly", "(", "equivalent", "to", ".", ")", "."], "add_tokens": "return tree . snapshotBaseEntries ( ) ; return getFileAttributeView ( tree . getBasePath ( ) . getFileSystem ( ) . getPath ( \".\" ) , type ) ;", "del_tokens": "tree . readLock ( ) . lock ( ) ; try { return tree . snapshotBaseEntries ( ) ; } finally { tree . readLock ( ) . unlock ( ) ; } return getFileAttributeView ( JimfsPath . empty ( tree . getBasePath ( ) . getFileSystem ( ) ) , type ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "spy", "memcached", "library", "dependencies", ".", "Created", "the", "context", "file", ".", "Started", "creating", "the", "first", "aspect", "POJO", "class", "."], "add_tokens": "public static final String DEFAULT_STRING = \"[unassigned]\" ; String namespace ( ) default DEFAULT_STRING ; int keyIndex ( ) default 0 ;", "del_tokens": "String namespace ( ) default \"[unassigned]\" ; int zeroBasedKeyParamIndex ( ) default 0 ;", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "embedded", "apiman", "-", "rt", "features", ".", "xml", "to", "remove", "wrap", ":", "bundles"], "add_tokens": "String gatewayEndpoint = getConfig ( ) . getGatewayRestEndpoint ( ) ; String username = getConfig ( ) . getGatewayBasicAuthUsername ( ) ; String password = getConfig ( ) . getGatewayBasicAuthPassword ( ) ; / * * * @ return the config * / public IConfig getConfig ( ) { return config ; } / * * * @ param config the config to set * / public void setConfig ( IConfig config ) { this . config = config ; }", "del_tokens": "String gatewayEndpoint = config . getGatewayRestEndpoint ( ) ; String username = config . getGatewayBasicAuthUsername ( ) ; String password = config . getGatewayBasicAuthPassword ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "option", "to", "send", "threadName", "along", "with", "the", "log", "message", "."], "add_tokens": "private boolean useThreadName = false ; GelfConverter converter = new GelfConverter ( facility , useLoggerName , useThreadName , additionalFields , shortMessageLength , hostname ) ; / * * * If true , an additional field call \"_threadName\" will be added to each gelf message . Its contents will be the * fully qualified name of the logger . e . g : com . company . Thingo . * / public boolean isUseThreadName ( ) { return useThreadName ; } public void setUseThreadName ( boolean useThreadName ) { this . useThreadName = useThreadName ; }", "del_tokens": "GelfConverter converter = new GelfConverter ( facility , useLoggerName , additionalFields , shortMessageLength , hostname ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "getMovieAlternativeTitles", "not", "using", "the", "country", "correctly"], "add_tokens": "URL url = tmdbMovieAltTitles . getIdUrl ( movieId , ApiUrl . DEFAULT_STRING , country ) ;", "del_tokens": "URL url = tmdbMovieAltTitles . getIdUrl ( movieId , country ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "plugin", "templates", "path", "to", "/", "opoopress", "/", "templates"], "add_tokens": "ClassTemplateLoader loader3 = new ClassTemplateLoader ( RendererImpl . class , \"/opoopress/templates\" ) ;", "del_tokens": "ClassTemplateLoader loader3 = new ClassTemplateLoader ( RendererImpl . class , \"/org/opoo/press/templates\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "AbstractApplicationCache", "and", "collapse", "functionality", "into", "ApplicationCache"], "add_tokens": "extends ApplicationCache", "del_tokens": "import org . realityforge . gwt . appcache . client . html5 . AbstractApplicationCache ; extends AbstractApplicationCache", "commit_type": "remove"}
{"commit_tokens": ["add", "INPUT_PROMPT_USE_BLANK", "to", "ExecutionConstants", ".", "java"], "add_tokens": "//for prompt inputs: if added to system context means it need to use blank value as the input value public static final String INPUT_PROMPT_USE_BLANK = \"INPUT_PROMPT_USE_BLANK\" ;", "del_tokens": "//for non-required inputs behavior (can be: PROMPT or SUPPRESS_PROMPT) public static final String NON_REQUIRED_INPUTS_BEHAVIOR = \"NON_REQUIRED_INPUTS_BEHAVIOR\" ;", "commit_type": "add"}
{"commit_tokens": ["remove", "html", "element", "in", "HeaderRecyclerViewAdapter", "s", "javadoc"], "add_tokens": "* *", "del_tokens": "* < p > * < p >", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "clicking", "an", "item", "in", "a", "ListView"], "add_tokens": "private void verifySerializable ( Serializable serializable ) {", "del_tokens": "private void verifySerializable ( Serializable serializable ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "LazyPainter", "-", "loaded", "class", "name", "."], "add_tokens": "new LazyPainter ( \"com.seaglass.painter.TitlePaneMaximizeButtonPainter\" , TitlePaneMaximizeButtonPainter . BACKGROUND_DISABLED , new Insets ( 0 ,", "del_tokens": "new LazyPainter ( \"com.TitlePaneMaximizeButtonPainter\" , TitlePaneMaximizeButtonPainter . BACKGROUND_DISABLED , new Insets ( 0 ,", "commit_type": "fix"}
{"commit_tokens": ["improved", "Iterator", "/", "Iterable", "support"], "add_tokens": "* @ param < E > is the generic type of the { @ link # next ( ) iterated } elements .", "del_tokens": "* @ param < E > is the templated type of the elements to iterate .", "commit_type": "improve"}
{"commit_tokens": ["Added", "reconnection", "option", "(", "3", "seconds", ")"], "add_tokens": "LiveQueryClient . init ( WS_URL , MY_APP_ID , true ) ;", "del_tokens": "LiveQueryClient . init ( WS_URL , MY_APP_ID ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "methods", "to", "stop", "a", "build", "and", "get", "a", "specific", "build", "from", "a", "job", "by", "its"], "add_tokens": "public String Stop ( ) throws HttpResponseException , IOException { return client . get ( url + \"stop\" ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "last", "few", "FilterConstants"], "add_tokens": "/* PropertyTag Constants */ /* BlobConstant Constants */ public static final String BLOB_CONSTANT_IDS_FILTER_VAR = \"blobConstantIds\" ; public static final String BLOB_CONSTANT_IDS_FILTER_VAR_DESC = \"Blob Constant IDs\" ; public static final String BLOB_CONSTANT_NAME_FILTER_VAR = \"blobConstantName\" ; public static final String BLOB_CONSTANT_NAME_FILTER_VAR_DESC = \"Blob Constant Name\" ; /* StringConstant Constants */ public static final String STRING_CONSTANT_IDS_FILTER_VAR = \"stringConstantIds\" ; public static final String STRING_CONSTANT_IDS_FILTER_VAR_DESC = \"String Constant IDs\" ; public static final String STRING_CONSTANT_NAME_FILTER_VAR = \"stringConstantName\" ; public static final String STRING_CONSTANT_NAME_FILTER_VAR_DESC = \"String Constant Name\" ; public static final String STRING_CONSTANT_VALUE_FILTER_VAR = \"stringConstantValue\" ; public static final String STRING_CONSTANT_VALUE_FILTER_VAR_DESC = \"String Constant Value\" ; /* Role Constants */ public static final String ROLE_IDS_FILTER_VAR = \"roleIds\" ; public static final String ROLE_IDS_FILTER_VAR_DESC = \"Role IDs\" ; public static final String ROLE_NAME_FILTER_VAR = \"roleName\" ; public static final String ROLE_NAME_FILTER_VAR_DESC = \"Role Name\" ; public static final String ROLE_DESCRIPTION_FILTER_VAR = \"roleDesc\" ; public static final String ROLE_DESCRIPTION_FILTER_VAR_DESC = \"Role Description\" ;", "del_tokens": "/* Property tag Constants */", "commit_type": "add"}
{"commit_tokens": ["Changed", ":", "Made", "munged", "constructor", "accessible", "(", "otherwise", "it", "fails", "for", "non", "public", "classes", ")"], "add_tokens": "mungedConstructor = reflectionFactory . newConstructorForSerialization ( type , nonSerializableAncestorConstructor ) ; mungedConstructor . setAccessible ( true ) ;", "del_tokens": "mungedConstructor = reflectionFactory . newConstructorForSerialization ( type , nonSerializableAncestorConstructor ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "lookup", "tables", "for", "SmiObjectType", "."], "add_tokens": "import org . jsmiparser . AbstractMibTestCase ; public class SmiDefaultParserTest extends AbstractMibTestCase { assertEquals ( mib . getTables ( ) . size ( ) + mib . getRows ( ) . size ( ) + mib . getVariables ( ) . size ( ) , mib . getObjectTypes ( ) . size ( ) ) ; checkObjectTypeAccessAll ( mib ) ;", "del_tokens": "import junit . framework . TestCase ; public class SmiDefaultParserTest extends TestCase {", "commit_type": "add"}
{"commit_tokens": ["Use", "Hamcrest", "for", "tests", ".", "Simplify", "methods", "."], "add_tokens": "import static org . hamcrest . Matchers . nullValue ; import static org . hamcrest . core . Is . is ; assertThat ( user . getUid ( ) , is ( 8L ) ) ; assertThat ( user . getName ( ) , is ( \"baz\" ) ) ; assertThat ( user . getLockedLastTime ( ) , is ( nullValue ( ) ) ) ; assertThat ( user . getMaxAgents ( ) , is ( 15 ) ) ; assertThat ( user . getNumAgents ( ) , is ( 0 ) ) ; assertThat ( user . getLastLoggedIn ( ) , is ( new DateTime ( 1379929725L * 1000L ) ) ) ; assertThat ( user . getNumFields ( ) , is ( 0 ) ) ;", "del_tokens": "assertEquals ( 8 , user . getUid ( ) ) ; assertEquals ( \"baz\" , user . getName ( ) ) ; assertEquals ( null , user . getLockedLastTime ( ) ) ; assertEquals ( 15 , user . getMaxAgents ( ) ) ; assertEquals ( 0 , user . getNumAgents ( ) ) ; assertEquals ( new DateTime ( 1379929725L * 1000L ) , user . getLastLoggedIn ( ) ) ; assertEquals ( 0 , user . getNumFields ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "new", "data", "structures", "for", "observers", "and", "observer", "resolution", "."], "add_tokens": "protected final Object getInstance ( ) {", "del_tokens": "import javax . webbeans . manager . Manager ; protected final Object getInstance ( Manager manager ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "Tree", "memory", "limit", "to", "CL", "Gurobi", "solver", "(", "forgot", "to", "commit", "this", "file", "earlier", ")"], "add_tokens": "return new ClGurobiIlpSolver ( tempDir , numThreads , workMemMegs ) ;", "del_tokens": "return new ClGurobiIlpSolver ( tempDir , numThreads ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "DefaultEntityTest", "-", "fixed", "build", "error"], "add_tokens": "private class TestAttributeListener implements AttributeListener < Integer > { public void attributeAdded ( final AttributeEvent < Integer > event ) { val = event . getValue ( ) ; public void attributeChanged ( final AttributeEvent < Integer > event ) { val = event . getValue ( ) ; public void attributeRemoved ( final AttributeEvent < Integer > event ) { final TestAttributeListener testAttributeListener = new TestAttributeListener ( ) ;", "del_tokens": "private class TestAttributeListener < T > implements AttributeListener < T > { public void attributeAdded ( final AttributeEvent < T > event ) { val = ( int ) event . getValue ( ) ; public void attributeChanged ( final AttributeEvent < T > event ) { val = ( int ) event . getValue ( ) ; public void attributeRemoved ( final AttributeEvent < T > event ) { final TestAttributeListener < Integer > testAttributeListener = new TestAttributeListener < Integer > ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Adds", "missing", "exceptions", "to", "deserialization", "resolution"], "add_tokens": "public static final TransportErrorCode PolicyViolation = new TransportErrorCode ( 404 , 1008 , \"Policy Violation/Not Found\" ) ; public static final TransportErrorCode UnexpectedCondition = new TransportErrorCode ( 500 , 1011 , \"Unexpected Condition/Internal Server Error\" ) ; // This is a manually maintained list that keeps all possible numerical pairs. Some HTTP status codes may // be duplicate in this list but that's because their websocket counterparts are different. Note how // both ProtocolError and UnsupportedData are included but BadRequest isn't. That's correct.", "del_tokens": "public static final TransportErrorCode PolicyViolation = new TransportErrorCode ( 404 , 1008 , \"Policy Violation\" ) ; public static final TransportErrorCode UnexpectedCondition = new TransportErrorCode ( 500 , 1011 , \"Unexpected Condition\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "AchillesPropertyHelper", ".", "Component", "names", "are", "not", "in", "the", "same", "order", "as", "the", "component", "classes", "/", "getters", "/", "setters"], "add_tokens": "Column column = multiKeyField . getAnnotation ( Column . class ) ; if ( column != null ) { if ( isNotBlank ( column . name ( ) ) ) { componentNames . add ( column . name ( ) ) ; } else { componentNames . add ( multiKeyField . getName ( ) ) ; } }", "del_tokens": "Column column = multiKeyField . getAnnotation ( Column . class ) ; if ( column != null ) { if ( isNotBlank ( column . name ( ) ) ) { componentNames . add ( column . name ( ) ) ; } else { componentNames . add ( multiKeyField . getName ( ) ) ; } }", "commit_type": "fix"}
{"commit_tokens": ["Updated", "per", "pull", "request", "via", "James"], "add_tokens": "// Change the pen color of the line the tortoise draws to \"blue\" --#4", "del_tokens": "// Change the color of the line the tortoise draws to \"blue\" --#4", "commit_type": "update"}
{"commit_tokens": ["added", "ability", "to", "set", "custom", "light", "shader", "+", "test"], "add_tokens": "ShaderProgram customLightShader = null ; ShaderProgram shader = customLightShader != null ? customLightShader : lightShader ; shader . begin ( ) ; shader . setUniformMatrix ( \"u_projTrans\" , combined ) ; if ( customLightShader != null ) updateLightShader ( ) ; if ( customLightShader != null ) updateLightShaderPerLight ( light ) ; shader . end ( ) ; / * * * Called before light rendering start * * Override this if you are using custom light shader * / protected void updateLightShader ( ) { } / * * * Called for custom light shader before each light is rendered * * Override this if you are using custom light shader * / protected void updateLightShaderPerLight ( Light light ) { } } / * * * Set custom light shader , null to reset to default * * Changes will take effect next time # render ( ) is called * / public void setLightShader ( ShaderProgram customLightShader ) { this . customLightShader = customLightShader ; }", "del_tokens": "lightShader . begin ( ) ; lightShader . setUniformMatrix ( \"u_projTrans\" , combined ) ; lightShader . end ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["updated", "javadoc", "example", "for", "cassandraHostConfigurator"], "add_tokens": "* & lt ; constructor - arg & gt ; & lt ; ref bean = \"cassandraHostConfigurator\" / & gt ; & lt ; / constructor - arg & gt ; * & lt ; / bean & gt ; * * & lt ; bean id = \"cassandraHostConfigurator\" class = \"me.prettyprint.cassandra.service.CassandraHostConfigurator\" & gt ; * & lt ; constructor - arg value = \"localhost:9170\" / & gt ;", "del_tokens": "* & lt ; constructor - arg & gt ; * & lt ; list & gt ; * & lt ; value & gt ; localhost : 9170 & lt ; / value & gt ; * & lt ; / list & gt ; * & lt ; / constructor - arg & gt ;", "commit_type": "update"}
{"commit_tokens": ["Added", "constructors", "and", "toString", "for", "ArraySet", "."], "add_tokens": "public ArraySet ( int size ) { this . store = new ArrayList < E > ( size ) ; } private ArraySet ( ArrayList < E > set ) { this . store = set ; } this ( new ArrayList < E > ( Arrays . asList ( array ) ) ) ; this ( new ArrayList < E > ( set ) ) ; this ( new ArrayList < E > ( collection . size ( ) ) ) ; public ArraySet < E > subList ( int start , int length ) { return new ArraySet < E > ( this . store . subList ( start , length ) ) ; } public E get ( int index ) { return store . get ( index ) ; } @ Override public String toString ( ) { return this . store . toString ( ) ;", "del_tokens": "this . store = new ArrayList < E > ( Arrays . asList ( array ) ) ; this . store = new ArrayList < E > ( set ) ; this . store = new ArrayList < E > ( collection . size ( ) ) ; public E get ( int index ) { return store . get ( index ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "anonymous", "/", "inner", "classes", "tests", "to", "TestAssertionLoading"], "add_tokens": "import java . io . Serializable ; public class SharingClass implements Serializable { public StaticInnerClass getStaticInnerClass ( ) { return new StaticInnerClass ( ) ; } public InnerClass getInnerClass ( ) { ClientInterface client = new ClientImplementation ( ) ; return new InnerClass ( ) ; } public ServerAssertion getAnonymousClass ( ) { ClientInterface client = new ClientImplementation ( ) ; return new ServerAssertion ( ) { public void server ( ) { ServerInterface server = new ServerImplemenation ( ) ; } } ; } public class InnerClass extends ServerAssertion { public void server ( ) { ServerInterface server = new ServerImplemenation ( ) ; } public static class StaticInnerClass extends ServerAssertion {", "del_tokens": "public class SharingClass { public Shared client ( ) { return new Shared ( ) ; public static class Shared extends ServerAssertion {", "commit_type": "add"}
{"commit_tokens": ["Removed", "a", "misleading", "comment", "."], "add_tokens": "public static byte [ ] decode ( String pData ) throws IOException { public static void main ( String [ ] pArgs ) throws IOException {", "del_tokens": "/ * * * Quick implementation , using the undocumented * { @ code sun . misc . BASE64Decoder . decodeBuffer ( String ) } . * / public static byte [ ] decode ( String pData ) throws java . io . IOException { //return DECODER.decodeBuffer(pData); public static void main ( String [ ] pArgs ) throws java . io . IOException {", "commit_type": "remove"}
{"commit_tokens": ["improves", "the", "code", "by", "moving", "functionality", "out", "of", "an", "exception", "and", "preventing", "that", "the", "exception", "gets", "thrown", "."], "add_tokens": "Object arg = null ; // may be null because it might be a constant macro if ( forIndex < args . length )", "del_tokens": "Object arg ; try catch ( ArrayIndexOutOfBoundsException ignored ) { arg = null ; // Might be a constant macro }", "commit_type": "improve"}
{"commit_tokens": ["Use", "fallback", "implementation", "when", "executable", "resources", "could", "not", "be", "loaded", "in", "the", "standard", "way"], "add_tokens": "String resourceName = \"nativebin/\" + path ; InputStream is = getClass ( ) . getResourceAsStream ( resourceName ) ; if ( is == null ) { // Use this for Java 9+ only if required resourceName = \"ws/schild/jave/nativebin/\" + path ; LOG . debug ( \"Alternative copy from SystemResourceAsStream <\" + resourceName + \"> to target <\" + dest . getAbsolutePath ( ) + \">\" ) ; is = ClassLoader . getSystemResourceAsStream ( resourceName ) ; }", "del_tokens": "String resourceName = \"ws/schild/jave/nativebin/\" + path ; InputStream is = ClassLoader . getSystemResourceAsStream ( resourceName ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "ability", "to", "use", "JsonRpcMethod", "to", "disambiguiate", "methods"], "add_tokens": "private boolean requireAnnotatedMethodName = false ; Set < Method > methods = findCandidateMethods ( getHandlerInterfaces ( serviceName ) , partialMethodName , requireAnnotatedMethodName ) ; / * * * Sets whether or not the server should require method name specified in the JsonRpcMethod annotation * if it is present . When true , JsonRpcMethod annotations can be used to resolve ambiguity between * overloaded methods that take the same number of Object type parameters . * * @ param requireAnnotatedMethodName the requireAnnotatedMethodName to set * / public void setRequireAnnotatedMethodName ( boolean requireAnnotatedMethodName ) { this . requireAnnotatedMethodName = requireAnnotatedMethodName ; }", "del_tokens": "Set < Method > methods = findCandidateMethods ( getHandlerInterfaces ( serviceName ) , partialMethodName ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "api", "for", "2", ".", "x", "raw"], "add_tokens": "* Manifest header specifying the string of executable services . public static final String PROBE_EXECUTABLE = \"PaxExam-Executable\" ;", "del_tokens": "* Manifest header specifying the full qualified name of the test class . public static final String PROBE_TEST_CLASS = \"PaxExam-TestClassName\" ; / * * * Manifest header specifying the test method name in the test class . * / public static final String PROBE_TEST_METHOD = \"PaxExam-TestMethodName\" ;", "commit_type": "add"}
{"commit_tokens": ["Make", "LocalScheduler", "run", "async", "."], "add_tokens": "import com . twitter . heron . scheduler . local . LocalContext ; ShellUtils . runASyncProcess ( true , false , schedulerCmd . toString ( ) , new File ( topologyWorkingDirectory ) ) ; LOG . info ( String . format ( \"Please find working directory %s for more running status.\" , LocalContext . workingDirectory ( config ) ) ) ; return true ;", "del_tokens": "// TO DO: we need to run as async process return 0 == ShellUtils . runSyncProcess ( true , true , schedulerCmd . toString ( ) , new StringBuilder ( ) , new StringBuilder ( ) , new File ( topologyWorkingDirectory ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "way", "to", "parse", "semicolon", "s", "as", "queries", "."], "add_tokens": "import java . util . Map . Entry ; for ( final Entry < String , String > entry : filterVars . entrySet ( ) ) if ( entry . getValue ( ) != null ) query . append ( entry . getKey ( ) + \"=\" + entry . getValue ( ) . replace ( \";\" , \"%3B\" ) + \";\" ) ;", "del_tokens": "for ( final String key : filterVars . keySet ( ) ) final String value = filterVars . get ( key ) ; if ( value != null ) query . append ( key + \"=\" + value + \";\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "last", "-", "minute", "problem", "with", "new", "IngestTest"], "add_tokens": "if ( contentEncoding != null ) { switch ( contentEncoding ) { case \"application/zip\" : in = new ZipInputStream ( in ) ; break ; case \"application/gzip\" : case \"application/x-gzip\" : in = new GZIPInputStream ( in ) ; break ; }", "del_tokens": "switch ( contentEncoding ) { case \"application/zip\" : in = new ZipInputStream ( in ) ; break ; case \"application/gzip\" : case \"application/x-gzip\" : in = new GZIPInputStream ( in ) ; break ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "the", "API_URL", "to", "not", "point", "to", "https", "by", "default"], "add_tokens": "public static final String API_URL = \"http://api.opentok.com\" ;", "del_tokens": "public static final String API_URL = \"https://api.opentok.com\" ;", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "low", "footprint", "writing", "of", "Excel", "files", "in", "new", "Excel"], "add_tokens": "import org . zuinnote . hadoop . office . format . common . writer . MSExcelLowFootprintWriter ; // check if it is low footprint if ( ! this . howc . getLowFootprint ( ) ) { currentOfficeSpreadSheetWriter = new MSExcelWriter ( writerFormat , this . howc ) ; } else { // low footprint if ( MSExcelWriter . FORMAT_OLD . equals ( writerFormat ) ) { LOG . warn ( \"Low footprint mode is only supported for new Excel format .xlsx. Continuing with standard writing mode\" ) ; currentOfficeSpreadSheetWriter = new MSExcelWriter ( writerFormat , this . howc ) ; } else { LOG . info ( \"Storing new Excel file ,xlsx in low footprint mode\" ) ; currentOfficeSpreadSheetWriter = new MSExcelLowFootprintWriter ( writerFormat , this . howc ) ; } }", "del_tokens": "currentOfficeSpreadSheetWriter = new MSExcelWriter ( writerFormat , this . howc ) ; if ( this . oStream != null ) { this . oStream . close ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "|", "not", "working", "in", "request", "params"], "add_tokens": "queryString = \"?\" + queryString . replace ( \"|\" , \"%7C\" ) ;", "del_tokens": "queryString = \"?\" + queryString ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "RequestId", "header", "name", "overloads"], "add_tokens": "* Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 1 or \"scenario\" : \"negative\" , \"value\" : - 2 * Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 1 or \"scenario\" : \"negative\" , \"value\" : - 2 * Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 105 or \"scenario\" : \"negative\" , \"value\" : - 2 * Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 105 or \"scenario\" : \"negative\" , \"value\" : - 2", "del_tokens": "* Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 1 or \"scenario\" : \"negative\" , \"value\" : - 2 * Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 1 or \"scenario\" : \"negative\" , \"value\" : - 2 * Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 105 or \"scenario\" : \"negative\" , \"value\" : - 2 * Send a post request with header values \"scenario\" : \"positive\" , \"value\" : 105 or \"scenario\" : \"negative\" , \"value\" : - 2", "commit_type": "add"}
{"commit_tokens": ["Change", "ByteStore", "to", "(", "mostly", ")", "not", "do", "any", "locking", "internally", "."], "add_tokens": "public int size ( ) { public ByteStore createCopy ( ) { int written = buf . remaining ( ) ; setSize ( Math . max ( size , pos + written ) ) ; buf . position ( buf . position ( ) + written ) ; return written ;", "del_tokens": "public int sizeInBytes ( ) { public ByteStore copy ( ) { writeLock ( ) . lock ( ) ; try { int written = buf . remaining ( ) ; setSize ( Math . max ( size , pos + written ) ) ; buf . position ( buf . position ( ) + written ) ; return written ; } finally { writeLock ( ) . unlock ( ) ; }", "commit_type": "change"}
{"commit_tokens": ["fix", "isAllow", "couldn", "t", "resolve", "action", ":", "allow"], "add_tokens": "boolean action = rule . get ( \"action\" ) . getAsString ( ) . equals ( \"allow\" ) ;", "del_tokens": "boolean action = rule . get ( \"action\" ) . equals ( \"allow\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "support", "of", "changeset", "ids", "uniqueness"], "add_tokens": "import com . github . mongobee . exception . MongobeeChangeSetException ; public List < Method > fetchChangeSets ( final Class < ? > type ) throws MongobeeChangeSetException { private List < Method > filterChangeSetAnnotation ( List < Method > allMethods ) throws MongobeeChangeSetException { final Set < String > changeSetIds = new HashSet < > ( ) ; String id = method . getAnnotation ( ChangeSet . class ) . id ( ) ; if ( changeSetIds . contains ( id ) ) { throw new MongobeeChangeSetException ( String . format ( \"Duplicated changeset id found: '%s'\" , id ) ) ; } changeSetIds . add ( id ) ;", "del_tokens": "public List < Method > fetchChangeSets ( final Class < ? > type ) { private List < Method > filterChangeSetAnnotation ( List < Method > allMethods ) {", "commit_type": "implement"}
{"commit_tokens": ["Added", "logging", "to", "debug", "test", "."], "add_tokens": "Thread . sleep ( SingleConnectionFactory . CONNECTION_ESTABLISH_INTERVAL_IN_MS * 10 ) ;", "del_tokens": "Thread . sleep ( SingleConnectionFactory . CONNECTION_ESTABLISH_INTERVAL_IN_MS * 2 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "CriteriaUtils", "to", "use", "the", "unqualified", "class", "name", "as", "the", "default", "entity", "name"], "add_tokens": "import javax . persistence . Entity ; * < p > * Please note that the entity name is deduced from the unqualified class name . * You should use { @ link # createCriteria ( EntityManager , String ) } * if you have changed the entity name by using the < code > name < / code > attribute * of the { @ link Entity } annotation . * < / p > * return new CriteriaImpl ( entityManager , persistentClass . getSimpleName ( ) ) ; * < p > * Please note that the entity name is deduced from the unqualified class name . * You should use { @ link # createCriteria ( EntityManager , Class , String ) } * if you have changed the entity name by using the < code > name < / code > attribute * of the { @ link Entity } annotation . * < / p > * return new CriteriaImpl ( entityManager , persistentClass . getSimpleName ( ) , alias ) ;", "del_tokens": "return new CriteriaImpl ( entityManager , persistentClass . getName ( ) ) ; return new CriteriaImpl ( entityManager , persistentClass . getName ( ) , alias ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "\\", "r", "to", "clear", "the", "existing", "description", "."], "add_tokens": "import com . j256 . simplemagic . logger . Logger ; import com . j256 . simplemagic . logger . LoggerFactory ; private static Logger logger = LoggerFactory . getLogger ( MagicEntry . class ) ; private final boolean clearFormat ; Long andValue , boolean unsignedType , Object testValue , boolean formatSpacePrefix , boolean clearFormat , MagicFormatter formatter ) { this . clearFormat = clearFormat ; if ( clearFormat ) { contentData . sb . setLength ( 0 ) ; } logger . trace ( \"matched data: {}: {}\" , this , contentData ) ;", "del_tokens": "Long andValue , boolean unsignedType , Object testValue , boolean formatSpacePrefix , MagicFormatter formatter ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "order", "of", "imports", "problem"], "add_tokens": "println ( \"BeanShell 1.1 alpha - by Pat Niemeyer (pat@pat.net)\" ) ;", "del_tokens": "println ( \"BeanShell 1.1 beta - by Pat Niemeyer (pat@pat.net)\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "non", "-", "deprecated", "method"], "add_tokens": "final ProjectHelper helper = ProjectHelper . getProjectHelper ( ) ; helper . parse ( project , buildFile ) ;", "del_tokens": "ProjectHelper . configureProject ( project , buildFile ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "environment", "variables", "if", "property", "values", "does", "not", "exist"], "add_tokens": "|| prop . getProperty ( \"fb.page.token\" ) . indexOf ( \"<PAGE_TOKEN>\" ) == 0 ) ? System . getenv ( \"PAGE_TOKEN\" ) || prop . getProperty ( \"fb.validation.token\" ) . indexOf ( \"<VALIDATION_TOKEN>\" ) == 0 ) ? System . getenv ( \"VALIDATION_TOKEN\" )", "del_tokens": "|| prop . getProperty ( \"fb.page.token\" ) . indexOf ( \"<PAGE_TOKEN>\" ) == 0 ) ? System . getProperty ( \"PAGE_TOKEN\" ) || prop . getProperty ( \"fb.validation.token\" ) . indexOf ( \"<VALIDATION_TOKEN>\" ) == 0 ) ? System . getProperty ( \"VALIDATION_TOKEN\" )", "commit_type": "use"}
{"commit_tokens": ["improve", "compatibility", "of", "ESHadoopScheme", "with", "custom", "File", "systems"], "add_tokens": "// NB: we need to set this property even though it is not being used - and since and URI causes problem, use only the resource/file //conf.set(\"mapred.output.dir\", set.getTargetUri() + \"/\" + set.getTargetResource()); conf . set ( \"mapred.output.dir\" , set . getTargetResource ( ) ) ;", "del_tokens": "// NB: there's no es:// protocol - this is just a fake placeholder that will cause exceptions if any File-based output class is used conf . set ( \"mapred.output.dir\" , \"es://\" + set . getTargetUri ( ) + \"/\" + set . getTargetResource ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["adding", "five", "and", "four", "gram", "features"], "add_tokens": "Trainer nercTrainer = new FixedTrainer ( props , trainSet , testSet , params ) ; \"Provide directory containing dictionaries if dictionary features in params file is activated\\n\" ) ;", "del_tokens": "Trainer nercTrainer = chooseTrainer ( trainSet , testSet , props , params ) ; trainParser . addArgument ( \"-m\" , \"--trainMethod\" ) . choices ( \"fixed\" , \"optimized\" ) . required ( true ) . help ( \"Uses features as specified in trainParams.txt file or will try to optimize the variables values\\n\" ) ; \"Provide directory containing dictionaries for its use with dict featureset\\n\" ) ; / * * * Choose the NameFinder training according to training method . * * @ return the name finder trainer * @ throws IOException * throws * / private Trainer chooseTrainer ( String trainSet , String testSet , Properties props , TrainingParameters params ) throws IOException { Trainer nercTrainer = null ; if ( props . getProperty ( \"trainMethod\" ) . equalsIgnoreCase ( \"fixed\" ) ) { nercTrainer = new FixedTrainer ( props , trainSet , testSet , params ) ; } else if ( props . getProperty ( \"trainMethod\" ) . equalsIgnoreCase ( \"optimized\" ) ) { nercTrainer = new FixedTrainer ( props , trainSet , testSet , params ) ; } else { System . err . println ( \"You need to provide the directory containing the dictionaries!\\n\" ) ; System . exit ( 1 ) ; } return nercTrainer ; }", "commit_type": "add"}
{"commit_tokens": ["use", "sorted", "attachment", "list", "for", "change", "atom", "label"], "add_tokens": "container . changeAtomLabel ( a . getCurrentIndex ( ) , index ) ; secondContainer . changeAtomLabel ( a . getCurrentIndex ( ) , index ) ;", "del_tokens": "// public abstract String convertSMILES2MolFile(String smiles) throws CTKException; // public abstract String convertMolFile2SMILES(String molfile) throws CTKException; container . changeAtomLabel ( a . getCurrenIndex ( ) , index ) ; secondContainer . changeAtomLabel ( a . getCurrenIndex ( ) , index ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "bug", "where", "host", "discovery", "caused", "server", "crash", "."], "add_tokens": "import java . nio . ByteBuffer ; private ByteBuffer emptyBuffer = ByteBuffer . allocate ( 0 ) ; udp . datagramChannel . send ( emptyBuffer , fromAddress ) ;", "del_tokens": "import com . esotericsoftware . kryo . serialize . FieldSerializer ; udp . datagramChannel . send ( udp . writeBuffer , fromAddress ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "SLF4J", "instead", "of", "JUL"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private final Logger logger = LoggerFactory . getLogger ( getClass ( ) ) ;", "del_tokens": "import java . util . logging . Logger ; private final Logger logger = Logger . getLogger ( getClass ( ) . getName ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "safe", "point", "information", "for", "ttop", "command"], "add_tokens": "private long lastSafePointCount ; private long lastSafePointTime ; private long lastSafePointSyncTime ; private SafePointMonitor spMon ; public void setSafePointMonitor ( SafePointMonitor spMon ) { this . spMon = spMon ; } long currentSafePointCount = spMon == null ? 0 : spMon . getSafePointCount ( ) ; long currentSafePointTime = spMon == null ? 0 : spMon . getSafePointTime ( ) ; long currentSafePointSyncTime = spMon == null ? 0 : spMon . getSafePointSyncTime ( ) ; } if ( currentSafePointCount > 0 ) { double spRate = ( TimeUnit . SECONDS . toNanos ( 1 ) * ( double ) ( currentSafePointCount - lastSafePointCount ) ) / timeSplit ; double spCpuUsage = ( ( double ) ( currentSafePointTime - lastSafePointTime ) ) / timeSplit ; double spSyncCpuUsage = ( ( double ) ( currentSafePointSyncTime - lastSafePointSyncTime ) ) / timeSplit ; double spAvg = ( ( double ) ( currentSafePointTime + currentSafePointSyncTime - lastSafePointTime - lastSafePointSyncTime ) ) / ( currentSafePointCount - lastSafePointCount ) / TimeUnit . MILLISECONDS . toNanos ( 1 ) ; sb . append ( String . format ( \" safe point rate: %.1f (events/s) avg. safe point pause: %.2fms\\n\" , spRate , spAvg ) ) ; sb . append ( String . format ( \" safe point sync time: %.2f%% processing time: %.2f%% (wallclock time)\\n\" , 100 * spSyncCpuUsage , 100 * spCpuUsage ) ) ; } lastSafePointCount = currentSafePointCount ; lastSafePointTime = currentSafePointTime ; lastSafePointSyncTime = currentSafePointSyncTime ;", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Make", "some", "more", "stuff", "public", "rev", "for", "release", "."], "add_tokens": "public PseudoXAStompletTransaction currentTransaction ( ) {", "del_tokens": "PseudoXAStompletTransaction currentTransaction ( ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "parsing", "an", "ODBC", "Literal", "Escape", "Sequence", ".", "Created", "Unit", "Test", "to", "ensure", "the", "rest", "of", "the", "parsing", "was", "not", "affected", "."], "add_tokens": "MONKEYS_AT ( \"@\" ) , TS ( \"ts\" ) ;", "del_tokens": "MONKEYS_AT ( \"@\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "an", "error", "on", "connectWithURL", "passed", "parameters", "."], "add_tokens": "connection = MysqlBaseService . connectWithURL ( username , password ,", "del_tokens": "connection = MysqlBaseService . connectWithURL ( username , username ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "Date", "type", "where", "needed", "."], "add_tokens": "import java . util . Date ; public Date date_created ;", "del_tokens": "public String date_created ;", "commit_type": "use"}
{"commit_tokens": ["fixes", "issues", "related", "with", "https", ":", "//", "github", ".", "com", "/", "MER", "-", "C", "/", "wiki", "-", "java", "/", "issues", "/", "82"], "add_tokens": "wiki = new Wiki ( domain , scriptPath , prot + \"://\" ) ; if ( sectionNumber == - 1 ) wiki . edit ( pageTitle , text , sectionTitle , minor , bot , sectionNumber , basetime ) ; else wiki . edit ( pageTitle , text , summary , minor , bot , sectionNumber , basetime ) ;", "del_tokens": "wiki = new Wiki ( ) ; wiki . init ( prot , domain , scriptPath ) ; wiki . edit ( pageTitle , text , summary , minor , bot , sectionNumber , sectionTitle , basetime ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "builtin", "support", "for", "URI", "/", "URL"], "add_tokens": "import java . net . URI ; import java . net . URL ; boolean writeSpecial ( Object obj ) throws IOException { if ( obj instanceof Date ) { jgen . writeNumber ( ( ( Date ) obj ) . getTime ( ) ) ; } else if ( obj instanceof URL ) { jgen . writeString ( obj . toString ( ) ) ; } else if ( obj instanceof URI ) { jgen . writeString ( obj . toString ( ) ) ; } else { return false ; } return true ; } boolean writeEnum ( Object obj ) throws IOException { //try to handle all primitives/special cases before treating this as json object if ( value != null && ! writePrimitive ( value ) && ! writeSpecial ( value ) && ! writeEnum ( value ) && ! writeList ( value ) && ! writeMap ( value ) ) {", "del_tokens": "} else if ( obj instanceof Date ) { jgen . writeNumber ( ( ( Date ) obj ) . getTime ( ) ) ; private boolean writeEnum ( Object obj ) throws IOException { //try to handle all primitives before treating this as json object if ( value != null && ! writePrimitive ( value ) && ! writeEnum ( value ) && ! writeList ( value ) && ! writeMap ( value ) ) {", "commit_type": "add"}
{"commit_tokens": ["move", "the", "shutdown", "of", "the", "client", "in", "the", "servlet", "test", "to", "before", "es", "shutdown"], "add_tokens": "factory . shutdown ( ) ;", "del_tokens": "factory . shutdown ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Implement", "Create", "and", "Drop", "Collection", "API", "s"], "add_tokens": "/ * * * Drop the collection with the name indicated by the entity class . * * @ param entityClass class that determines the collection to drop / delete . * / < T > void dropCollection ( Class < T > entityClass ) ; / * * * Drop the collection with the given name . * * @ param collectionName name of the collection to drop / delete . * / void dropCollection ( String collectionName ) ;", "del_tokens": "/ * * * Drop the collection with the name indicated by the entity class . * * @ param entityClass class that determines the collection to drop / delete . * / < T > void dropCollection ( Class < T > entityClass ) ; / * * * Drop the collection with the given name . * * @ param collectionName name of the collection to drop / delete . * / void dropCollection ( String collectionName ) ;", "commit_type": "implement"}
{"commit_tokens": ["fixed", "snap", "bearing", "using", "routeUtils"], "add_tokens": "> routeProgress . getRoute ( ) . getDistance ( ) ) {", "del_tokens": "> RouteUtils . getDistanceToEndOfRoute ( routeProgress . getRoute ( ) . getLegs ( ) . get ( 0 ) . getSteps ( ) . get ( 0 ) . getManeuver ( ) . asPosition ( ) , routeProgress . getRoute ( ) , TurfConstants . UNIT_METERS ) ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "the", "first", "response", "for", "the", "page", "makig", "sure", "the", "first", "version", "of", "response", "headers", "are", "there"], "add_tokens": "verifiedUrls . add ( resp ) ; return responseFetcher . get ( url , true , requestHeaders ) ;", "del_tokens": "return responseFetcher . get ( url , false , requestHeaders ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "npe", "when", "dyno", "starts", "up", "and", "dynamite", "has", "a", "node", "that", "is", "down"], "add_tokens": "Z z = from . get ( x ) ; if ( z != null ) { Y y = transform . get ( x ) ; toMap . put ( y , z ) ; }", "del_tokens": "Y y = transform . get ( x ) ; toMap . put ( y , from . get ( x ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "logging", "statements", "and", "enable", "simple", "logging", "for", "tests"], "add_tokens": "LOG . debug ( \"{} loaded by {}\" , name , loader ) ; LOG . trace ( \"delegate.findClass({})\" , name ) ; LOG . trace ( \"delegate.findResource({})\" , name ) ; LOG . trace ( \"delegate.findResources({})\" , name ) ;", "del_tokens": "LOG . debug ( \"{0} loaded by {1}\" , name , loader ) ; LOG . trace ( \"delegate.findClass({0})\" , name ) ; LOG . trace ( \"delegate.findResource({0})\" , name ) ; LOG . trace ( \"delegate.findResources({0})\" , name ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "warn", "when", "ClassNotFoundException", "happens"], "add_tokens": "import org . apache . commons . lang . ArrayUtils ; import org . kametic . specifications . AbstractSpecification ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; for ( Class < ? > clazz : clazzes ) if ( methodAnnotatedWith . isSatisfiedBy ( method ) ) } catch ( Throwable classNotFoundException ) logger . trace ( \"Exception on isSatisfiedBy () \" + classNotFoundException . getMessage ( ) ) ;", "del_tokens": "import org . apache . commons . lang . ArrayUtils ; import org . kametic . specifications . AbstractSpecification ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; for ( Class < ? > clazz : clazzes ) if ( methodAnnotatedWith . isSatisfiedBy ( method ) ) } catch ( Throwable cnfe ) logger . warn ( \"Exception on isSatisfiedBy () \" + cnfe . getMessage ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["used", ":", "Once", "used", "all", "N", "-", "tuples", "can", "be", "reduced", "to", "1", "-", "tuples", "."], "add_tokens": "import com . startingblocktech . tcases . VarBindingDef ; // Yes, relocate to used list. Once used, all N-tuples can be reduced to 1-tuples. // This enables different combinations that may be required to complete tests for // other tuples. In particular, it allows for an NA binding of an optional variable, // which will never appear in N-tuples. unused_ . remove ( i ) ; for ( Iterator < VarBindingDef > bindings = tuple . getBindings ( ) ; bindings . hasNext ( ) ; ) { Tuple tuple1 = new Tuple ( bindings . next ( ) ) ; if ( used_ . indexOf ( tuple1 ) < 0 ) { used_ . add ( tuple1 ) ; } }", "del_tokens": "// Yes, relocated to used list. used_ . add ( unused_ . remove ( i ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "find", "bug", "error", "."], "add_tokens": "Map < String , Object > params = new HashMap < > ( ) ; params . put ( \"hello\" , \"test\" ) ; params . put ( \"x\" , 1 ) ; client . invoke ( \"test\" , params , byteArrayOutputStream ) ; JsonNode node = readJSON ( byteArrayOutputStream ) ; assertTrue ( node . has ( PARAMS ) ) ; assertTrue ( node . get ( PARAMS ) . isObject ( ) ) ; try { Long . parseLong ( node . get ( ID ) . asText ( ) ) ; } catch ( NumberFormatException e ) { fail ( ) ; } }", "del_tokens": "Map < String , Object > params = new HashMap < > ( ) ; params . put ( \"hello\" , \"test\" ) ; params . put ( \"x\" , 1 ) ; client . invoke ( \"test\" , params , byteArrayOutputStream ) ; JsonNode node = readJSON ( byteArrayOutputStream ) ; assertTrue ( node . has ( PARAMS ) ) ; assertTrue ( node . get ( PARAMS ) . isObject ( ) ) ; try { long id = Long . parseLong ( node . get ( ID ) . asText ( ) ) ; } catch ( NumberFormatException e ) { fail ( ) ; } }", "commit_type": "fix"}
{"commit_tokens": ["added", "binding", "for", "search", "stats", "to", "search", "results"], "add_tokens": "private SearchStats stats ; public SearchResults ( MessageInfo messages , List < YammerProfile > users , List < Group > groups , SearchStats searchStats ) { this . stats = searchStats ; public int getUserCount ( ) { return stats . userCount ; } public int getGroupCount ( ) { return stats . groupCount ; } public int getMessageCount ( ) { return stats . messageCount ; } public int getTopicCount ( ) { return stats . topicCount ; } static class SearchStats { private int groupCount ; private int messageCount ; private int topicCount ; private int userCount ; public SearchStats ( int groupCount , int messageCount , int topicCount , int userCount ) { this . groupCount = groupCount ; this . messageCount = messageCount ; this . topicCount = topicCount ; this . userCount = userCount ; } }", "del_tokens": "public SearchResults ( MessageInfo messages , List < YammerProfile > users , List < Group > groups ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "getPastTweets", "method", "form", "Twitter", "sub"], "add_tokens": "//getPastTweets(keywords, follows); logger . error ( e ) ;", "del_tokens": "getPastTweets ( keywords , follows ) ; e . printStackTrace ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "generics", "+", "apply", "checkstyle", "-", "patches", "on", "*", "SchemagenMojo"], "add_tokens": "* * private List < String > compileSourceRoots ; * @ Override protected List < String > getCompileSourceRoots ( ) protected List < String > getClasspathElements ( MavenProject project )", "del_tokens": "* * private List compileSourceRoots ; * protected List getCompileSourceRoots ( ) protected List < String > getClasspathElements ( MavenProject project )", "commit_type": "add"}
{"commit_tokens": ["Add", "argument", "to", "Java", "unit", "test"], "add_tokens": "SparkSession spark = com . johnsnowlabs . nlp . SparkNLP . start ( true ) ;", "del_tokens": "SparkSession spark = com . johnsnowlabs . nlp . SparkNLP . start ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "progressbar", "for", "scene", "builder"], "add_tokens": "@ FXMLController ( value = \"/resources/fxml/ui/ProgressBar.fxml\" , title = \"Material Design Example\" ) @ FXML private C3DProgressBar progress1 ; @ FXML private C3DProgressBar progress2 ; new KeyFrame ( Duration . ZERO , new KeyValue ( progress1 . progressProperty ( ) , 0 ) , new KeyValue ( progress2 . progressProperty ( ) , 0 ) ) , new KeyFrame ( Duration . seconds ( 2 ) , new KeyValue ( progress1 . progressProperty ( ) , 1 ) , new KeyValue ( progress2 . progressProperty ( ) , 1 ) ) ) ; task . setCycleCount ( Timeline . INDEFINITE ) ; task . play ( ) ;", "del_tokens": "@ FXMLController ( value = \"/resources/fxml/ui/ProgressBar.fxml\" , title = \"Material Design Example\" ) @ FXML private C3DProgressBar progress1 ; @ FXML private C3DProgressBar progress2 ; new KeyFrame ( Duration . ZERO , new KeyValue ( progress1 . progressProperty ( ) , 0 ) , new KeyValue ( progress2 . progressProperty ( ) , 0 ) ) , new KeyFrame ( Duration . seconds ( 2 ) , new KeyValue ( progress1 . progressProperty ( ) , 1 ) , new KeyValue ( progress2 . progressProperty ( ) , 1 ) ) ) ; task . setCycleCount ( 5 ) ; task . playFromStart ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "pretty", "printer", "for", "Nodes", "and", "new", "print", "()", "method", "to", "all", "Groovy", "objects", "for", "easy", "printing", "."], "add_tokens": "Class groovyClass = loader . parseClass ( \"src/test/org/codehaus/groovy/classgen/Main.groovy\" ) ;", "del_tokens": "import java . io . FileInputStream ; import java . io . InputStream ; protected GroovyClassLoader loader = new GroovyClassLoader ( ) ; InputStream in = new FileInputStream ( \"src/test/org/codehaus/groovy/classgen/Main.groovy\" ) ; Class groovyClass = loader . parseClass ( in ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "two", "errors", "on", "latest", "C#", "commits"], "add_tokens": "RTObject resolvePath = resolvePath ( pathOnChoice ) ;", "del_tokens": "RTObject resolvePath = resolvePath ( getPathOnChoice ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "default", "package", "name", "."], "add_tokens": "GlobalInfo . appPackage = appContext . getPackageName ( ) ;", "del_tokens": "//GlobalInfo.appPackage = appContext.getPackageName(); GlobalInfo . appPackage = \"org.mozilla.firefox\" ;", "commit_type": "change"}
{"commit_tokens": ["Removing", "HibernateProxyInitializer", "class", "of", "some", "tests"], "add_tokens": "import br . com . caelum . vraptor . serialization . NullProxyInitializer ; private NullProxyInitializer initializer ; initializer = new NullProxyInitializer ( ) ; assertThat ( result ( ) , is ( \"{\\\"someProxy\\\":{\\\"aField\\\":\\\"abc\\\",\\\"name\\\":\\\"my name\\\"}}\" ) ) ;", "del_tokens": "import br . com . caelum . vraptor . serialization . HibernateProxyInitializer ; private HibernateProxyInitializer initializer ; initializer = new HibernateProxyInitializer ( ) ; assertThat ( result ( ) , is ( \"{\\\"client\\\":{\\\"aField\\\":\\\"abc\\\",\\\"name\\\":\\\"my name\\\"}}\" ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Changed", "behavior", "of", "FieldFilter", "to", "throw", "InvalidPathException", "instead", "of", "returning", "null", "when", "a", "field", "is", "queried", "for", "on", "a", "json", "array"], "add_tokens": "throw new InvalidPathException ( \"Trying to access field on array\" ) ;", "del_tokens": "return null ;", "commit_type": "change"}
{"commit_tokens": ["using", "user", "based", "auth", "+", "some", "refactoring"], "add_tokens": "customHeaders . put ( Constants . HEADER_ACCEPT , \"application/json\" ) ; customHeaders . put ( Constants . HEADER_CONTENT_TYPE , \"application/json\" ) ;", "del_tokens": "customHeaders . put ( \"Accept\" , \"application/json\" ) ; customHeaders . put ( \"Content-Type\" , \"application/json\" ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "DUMP", "RESTORE", "and", "MIGRATE", "commands"], "add_tokens": "DEL , DUMP , EXISTS , EXPIRE , EXPIREAT , KEYS , MIGRATE , MOVE , OBJECT , PERSIST , PEXPIRE , PEXPIREAT , PTTL , RANDOMKEY , RENAME , RENAMENX , RESTORE , TTL , TYPE ,", "del_tokens": "DEL , EXISTS , EXPIRE , EXPIREAT , KEYS , MOVE , OBJECT , PERSIST , PEXPIRE , PEXPIREAT , PTTL , RANDOMKEY , RENAME , RENAMENX , TTL , TYPE ,", "commit_type": "add"}
{"commit_tokens": ["remove", "TODO", "add", "class", "description", "and", "move", "junit", "rule", "to", "testutil", "module", "where", "it", "belongs"], "add_tokens": "/ * * * This is a helper class for testing appmon4j integration . * For example it allows a clean initialization of the InApplicationMonitor instance in a setup @ before method . * * This class partially exposes methods , usually not available , and thus should not be used in production code . * Especially as this code may induce concurrence problems in a multi threading environment . * * @ see de . is24 . util . monitoring . TestHelper * @ see de . is24 . util . monitoring . InApplicationMonitorRule * /", "del_tokens": "// TODO move this class, and maybe some other tools to a dedicated Testing module and provide a dedicated jar", "commit_type": "remove"}
{"commit_tokens": ["Removed", "option", "to", "set", "serialize", "nulls", ".", "Explicitly", "transferring", "nulls", "for", "custom", "fields", "and", "removing", "nulls", "everywhere", "else", "using", "adapters"], "add_tokens": "import com . ardoq . model . Workspace ; import java . util . Date ; public class ModelAdapter implements JsonDeserializer < Model > , JsonSerializer < Model > { private Gson gson ( ) { return new GsonBuilder ( ) . registerTypeAdapter ( Date . class , new Iso8601Adapter ( ) ) . create ( ) ; } public JsonElement serialize ( Model reference , Type type , JsonSerializationContext jsonSerializationContext ) { JsonElement jsonElement = gson ( ) . toJsonTree ( reference , Model . class ) ; JsonObject jsonObject = jsonElement . getAsJsonObject ( ) ; JsonUtils . removeReservedNullVaules ( jsonObject ) ; return jsonElement ; }", "del_tokens": "public class ModelAdapter implements JsonDeserializer < Model > {", "commit_type": "remove"}
{"commit_tokens": ["add", "request", "by", "1", "after", "request", "max", "test", "to", "check", "for", "problems"], "add_tokens": "package com . github . davidmoten . rx . testing ; WITHOUT_BACKP , BACKP_INITIAL_REQUEST_MAX , BACKP_INITIAL_REQUEST_MAX_THEN_BY_ONE , BACKP_ONE_BY_ONE , BACKP_TWO_BY_TWO , BACKP_REQUEST_ZERO , BACKP_REQUEST_NEGATIVE , BACKP_FIVE_BY_FIVE , BACKP_FIFTY_BY_FIFTY , BACKP_THOUSAND_BY_THOUSAND ; } ; else if ( testType == TestType . BACKP_INITIAL_REQUEST_MAX_THEN_BY_ONE ) return new TestSubscriber < T > ( ) { AtomicInteger count = new AtomicInteger ( ) ; @ Override public void onStart ( ) { request ( Long . MAX_VALUE ) ; } @ Override public void onNext ( T t ) { super . onNext ( t ) ; if ( unsubscribeAfter . isPresent ( ) && count . incrementAndGet ( ) == unsubscribeAfter . get ( ) ) unsubscribe ( ) ; // Hopefully doesn't cause a problem (for example by 1 // getting added to Long.MAX_VALUE making it a negative // value because of overflow) request ( 1 ) ; }", "del_tokens": "package com . github . davidmoten . rx ; WITHOUT_BACKP , BACKP_INITIAL_REQUEST_MAX , BACKP_ONE_BY_ONE , BACKP_TWO_BY_TWO , BACKP_REQUEST_ZERO , BACKP_REQUEST_NEGATIVE , BACKP_FIVE_BY_FIVE , BACKP_FIFTY_BY_FIFTY , BACKP_THOUSAND_BY_THOUSAND ;", "commit_type": "add"}
{"commit_tokens": ["add", "debugging", "print", "class", "which", "causes", "dependency"], "add_tokens": "Object cls = cp . next ( ) ; // System.err.println(\"d0: \" + cls); new ClassReader ( cp . getInputStream ( cls ) ) . accept ( gatherNamesVisitor , true ) ; Object cls = cp . next ( ) ; // System.err.println(\"d1: \" + cls); new ClassReader ( cp . getInputStream ( cls ) ) . accept ( depFind , true ) ; System . out . println ( e . getClassName ( ) + \"\\t => \" + e . getDependency ( ) ) ;", "del_tokens": "new ClassReader ( cp . getInputStream ( cp . next ( ) ) ) . accept ( gatherNamesVisitor , true ) ; new ClassReader ( cp . getInputStream ( cp . next ( ) ) ) . accept ( depFind , true ) ; System . out . println ( e . getClassName ( ) ) ; // e.getDependency()", "commit_type": "add"}
{"commit_tokens": ["Fixed", "TKP", "Launcher", "on", "Mac", "added", "Homebrew", "support"], "add_tokens": "CommandLineUtils . launch ( \"%s -data %s\" , config . getEclipsePath ( ) , config . workspacePath ) ; boolean exists = new File ( config . getEclipsePath ( ) ) . exists ( ) ; String base = config . getEclipsePath ( ) . substring ( 0 , config . getEclipsePath ( ) . indexOf ( File . separator , 3 ) ) ; config . setup . set ( SetupCheckPoints . EclipseIsInstalled , exists , \"could not find Eclipse at: \" + base ) ;", "del_tokens": "CommandLineUtils . launch ( \"%s -data \\\"%s\\\"\" , config . eclipsePath , config . workspacePath ) ; boolean exists = new File ( config . eclipsePath ) . exists ( ) ; String base = config . eclipsePath . substring ( 0 , config . eclipsePath . indexOf ( File . separator , 3 ) ) ; config . setup . set ( SetupCheckPoints . EclipseIsInstalled , exists , \"could not find Eclipse at \" + base ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "padding", "and", "compensate", "for", "zero", "length", "triplets"], "add_tokens": "import org . afplib . Data ; return factory . sf ( data , 0 , getLength ( ) + 2 ) ; private int getLength ( ) { int result = length ; if ( ( data [ 6 ] & 0x08 ) == 0x08 ) { // padding int padding = 0 ; if ( data [ data . length - 1 ] == 0 ) { padding = Data . toUnsigned ( data , data . length - 3 , data . length - 2 ) ; } else { padding = Data . toUnsigned ( data , data . length - 1 , data . length - 1 ) ; } result -= padding ; } return result ; }", "del_tokens": "return factory . sf ( data , 0 , length + 2 ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "insane", "double", "ternary", "operator"], "add_tokens": "if ( maximumIndex > 0 ) { return items . get ( random . nextInt ( maximumIndex ) ) ; } else if ( maximumIndex == 0 ) { return items . get ( 0 ) ; } else { return null ; }", "del_tokens": "* return maximumIndex > 0 ? items . get ( random . nextInt ( maximumIndex ) ) : maximumIndex == 0 ? items . get ( 0 ) : null ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "support", "for", "faster", "diffs", "of", "two", "sorted", "sets", "."], "add_tokens": "@ SuppressWarnings ( { \"rawtypes\" , \"unchecked\" } ) if ( c instanceof SmallSet ) { SmallSet other = ( SmallSet ) c ; ArrayList < E > tmp = new ArrayList < E > ( this . size ( ) - other . size ( ) ) ; Sort . diffSortedLists ( this . list , other . list , tmp ) ; boolean changed = ( tmp . size ( ) != this . list . size ( ) ) ; this . list = tmp ; return changed ; } else { return list . removeAll ( c ) ; } } /** Gets a new SmallSet containing the difference of this set with the other. */ public SmallSet < E > diff ( SmallSet < E > other ) { SmallSet < E > tmp = new SmallSet < E > ( this . size ( ) - other . size ( ) ) ; Sort . diffSortedLists ( this . list , other . list , tmp . list ) ; return tmp ;", "del_tokens": "return list . removeAll ( c ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "additional", "method", "to", "AccessControllable", "to", "get", "the", "list", "of", "accessIds", "for", "a", "given", "object", "."], "add_tokens": "DBObject dbObject ; dbObject = ( DBObject ) findById ( id ) ; //noinspection unchecked save ( ( T ) dbObject ) ; DBObject dbObject ; dbObject = ( DBObject ) findById ( id ) ; //noinspection unchecked save ( ( T ) dbObject ) ; } @ Override public List < String > getAccessIds ( String id ) { DBObject dbObject ; try { dbObject = ( DBObject ) findById ( id ) ; } catch ( NoSuchItemException e ) { throw new RuntimeException ( e ) ; } //noinspection unchecked return ( List < String > ) dbObject . get ( ACCESS_CONTROL_LIST_FIELD ) ;", "del_tokens": "T entity ; entity = findById ( id ) ; entity = getEnhancer ( ) . enhance ( entity ) ; DBObject dbObject = ( DBObject ) entity ; save ( entity ) ; T entity ; entity = findById ( id ) ; entity = getEnhancer ( ) . enhance ( entity ) ; DBObject dbObject = ( DBObject ) entity ; save ( entity ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "integration", "test", "."], "add_tokens": "String clientId = System . getenv ( GoogleCloudStorageIntegrationHelper . GCS_TEST_CLIENT_ID ) ; String clientSecret = System . getenv ( GoogleCloudStorageIntegrationHelper . GCS_TEST_CLIENT_SECRET ) ; String projectId = System . getenv ( GoogleCloudStorageIntegrationHelper . GCS_TEST_PROJECT_ID ) ; Assert . assertNotNull ( \"Expected value for env var \" + GoogleCloudStorageIntegrationHelper . GCS_TEST_CLIENT_ID , clientId ) ; Assert . assertNotNull ( \"Expected value for env var \" + GoogleCloudStorageIntegrationHelper . GCS_TEST_CLIENT_SECRET , clientSecret ) ; Assert . assertNotNull ( \"Expected value for env var \" + GoogleCloudStorageIntegrationHelper . GCS_TEST_PROJECT_ID , projectId ) ;", "del_tokens": "String clientId = System . getenv ( GoogleCloudStorageIntegrationHelper . GCS_TEST_CLIENT_ID ) ; String clientSecret = System . getenv ( GoogleCloudStorageIntegrationHelper . GCS_TEST_CLIENT_SECRET ) ; String projectId = System . getenv ( GoogleCloudStorageIntegrationHelper . GCS_TEST_PROJECT_ID ) ; Assert . assertNotNull ( clientId ) ; Assert . assertNotNull ( clientSecret ) ; Assert . assertNotNull ( projectId ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "log", "for", "proxy", "url"], "add_tokens": "log . trace ( String . format ( \"Prerender proxy will send request to:%s\" , apiUrl ) ) ; CloseableHttpResponse proxyResponse = null ; proxyResponse = httpClient . execute ( getMethod ) ;", "del_tokens": "CloseableHttpResponse proxyResponse = httpClient . execute ( getMethod ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "third", "RetryResult", "(", "instead", "of", "using", "null", ")", "to", "denote", "proceed"], "add_tokens": "return Interceptor . RetryResult . PROCEED ; return Interceptor . RetryResult . PROCEED ;", "del_tokens": "return null ; return null ;", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "ui", "required", "api", "."], "add_tokens": "mWorkerInfo . getCapacityBytes ( ) , 0 , new ArrayList < Integer > ( ) ) ; if ( mWorkerInfo . getCapacityBytes ( ) < requestBytes ) {", "del_tokens": "mWorkerInfo . TOTAL_BYTES , 0 , new ArrayList < Integer > ( ) ) ; if ( mWorkerInfo . TOTAL_BYTES < requestBytes ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "buggy", "optimization", "of", "global", "close", "()", "method", "--", "shouldn", "t", "exclude", "from", "closeing", "nodes", "without", "dependencies", "because", "they", "could", "be", "initialized", "bypassing", "dependencies", "(", "via", "other", "init", "methods", ")"], "add_tokens": "n . getCloseMethod ( ) . ifPresent ( closeMethod -> { CompilationNode refNode = cxt . getCompilationNode ( n . declaringType ) ; CtExpression < ? > access = root . access ( refNode , AccessType . Read ) ; closeBody . addStatement ( f . Code ( ) . createInvocation ( access , closeMethod . getReference ( ) ) ) ; } ) ;", "del_tokens": "if ( n . getDependencies ( ) . isEmpty ( ) ) { n . getCloseMethod ( ) . ifPresent ( closeMethod -> { CompilationNode refNode = cxt . getCompilationNode ( n . declaringType ) ; CtExpression < ? > access = root . access ( refNode , AccessType . Read ) ; closeBody . addStatement ( f . Code ( ) . createInvocation ( access , closeMethod . getReference ( ) ) ) ; } ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Moved", "yaml", "initializer", "to", "config", "package", "."], "add_tokens": "package cf . spring . config ; import cf . spring . YamlDocument ; import cf . spring . YamlPropertySource ;", "del_tokens": "package cf . spring ;", "commit_type": "move"}
{"commit_tokens": ["Updated", "code", "to", "remove", "deprecated", "methods"], "add_tokens": "import org . apache . http . entity . mime . MultipartEntityBuilder ; MultipartEntityBuilder entityBuilder = MultipartEntityBuilder . create ( ) ; entityBuilder . addTextBody ( \"UPLOADCARE_PUB_KEY\" , client . getPublicKey ( ) ) ; entityBuilder . addTextBody ( \"UPLOADCARE_STORE\" , store ) ; entityBuilder . addPart ( \"file\" , new FileBody ( file ) ) ; entityBuilder . addPart ( \"file\" , new ByteArrayBody ( bytes , filename ) ) ; request . setEntity ( entityBuilder . build ( ) ) ;", "del_tokens": "import org . apache . http . entity . mime . MultipartEntity ; import org . apache . http . entity . mime . content . StringBody ; MultipartEntity entity = new MultipartEntity ( ) ; StringBody pubKeyBody = StringBody . create ( client . getPublicKey ( ) , \"text/plain\" , null ) ; StringBody storeBody = StringBody . create ( store , \"text/plain\" , null ) ; entity . addPart ( \"UPLOADCARE_PUB_KEY\" , pubKeyBody ) ; entity . addPart ( \"UPLOADCARE_STORE\" , storeBody ) ; entity . addPart ( \"file\" , new FileBody ( file ) ) ; entity . addPart ( \"file\" , new ByteArrayBody ( bytes , filename ) ) ; request . setEntity ( entity ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "method", "to", "display", "table", "status"], "add_tokens": "if ( query == null ) {", "del_tokens": "if ( query == null || StringUtils . isBlank ( type ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "compilation", "of", "Groovy", "class", "in", "incorrect", "folder"], "add_tokens": "package org . codenarc . rule ; import org . codehaus . groovy . control . Phases ; public abstract class AbstractEnhanceableAstVisitorRule extends AbstractAstVisitorRule { public final static String ENHANCED_MODE_SYSTEM_PROPERTY = \"org.codenarc.enhancedMode\" ; private boolean enhancedMode = Boolean . getBoolean ( ENHANCED_MODE_SYSTEM_PROPERTY ) ; public boolean isEnhancedMode ( ) { return enhancedMode ; } public void setEnhancedMode ( boolean enhancedMode ) { this . enhancedMode = enhancedMode ; } public int getCompilerPhase ( ) { return enhancedMode ? Phases . SEMANTIC_ANALYSIS : super . getCompilerPhase ( ) ;", "del_tokens": "package org . codenarc . rule import org . codehaus . groovy . control . Phases abstract class AbstractEnhanceableAstVisitorRule extends AbstractAstVisitorRule { public final static String ENHANCED_MODE_SYSTEM_PROPERTY = 'org.codenarc.enhancedMode' boolean enhancedMode = Boolean . getBoolean ( ENHANCED_MODE_SYSTEM_PROPERTY ) int getCompilerPhase ( ) { enhancedMode ? Phases . SEMANTIC_ANALYSIS : super . compilerPhase", "commit_type": "fix"}
{"commit_tokens": ["added", "OMS3", "script", "for", "featurereshaper"], "add_tokens": "import org . jgrasstools . gears . modules . v . featurefilter . FeatureFilter ; import org . jgrasstools . gears . modules . v . reshape . FeatureReshaper ; moduleName2Class . put ( \"CoverageSummary\" , CoverageSummary . class ) ; moduleName2Class . put ( \"FeatureFilter\" , FeatureFilter . class ) ; moduleName2Class . put ( \"FeatureReshaper\" , FeatureReshaper . class ) ; moduleName2Class . put ( \"MarchingSquaresVectorializer\" , MarchingSquaresVectorializer . class ) ; moduleName2Class . put ( \"RasterCatToFeatureAttribute\" , RasterCatToFeatureAttribute . class ) ;", "del_tokens": "moduleName2Class . put ( \"CoverageSummary\" , CoverageSummary . class ) ; moduleName2Class . put ( \"MarchingSquaresVectorializer\" , MarchingSquaresVectorializer . class ) ; moduleName2Class . put ( \"RasterCatToFeatureAttribute\" , RasterCatToFeatureAttribute . class ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "deprecation", "status", "based", "on", "CUDA", "functions"], "add_tokens": "* Deprecated Note that this function is * * @ deprecated Deprecated in CUDA * Deprecated Note that this function is * * @ deprecated Deprecated in CUDA * Deprecated Note that this function is * * @ deprecated Deprecated in CUDA * Deprecated Note that this function is * * @ deprecated Deprecated in CUDA * Deprecated Note that this function is * * @ deprecated Deprecated in CUDA * Deprecated Note that this function is * * @ deprecated Deprecated in CUDA * * @ deprecated Deprecated as of CUDA 5.0 * * @ deprecated Deprecated as of CUDA 3.0 if ( true ) { throw new UnsupportedOperationException ( \"This function is deprecated as of CUDA 3.0\" ) ; } * * @ deprecated Deprecated as of CUDA 3.0 * * @ deprecated Deprecated as of CUDA 3.0 * * @ deprecated Deprecated as of CUDA 3.0 * * @ deprecated Deprecated as of CUDA 3.0 * * @ deprecated Deprecated as of CUDA 3.0 * * @ deprecated Deprecated as of CUDA 3.0", "del_tokens": "* DeprecatedNote that this function is * DeprecatedNote that this function is * DeprecatedNote that this function is * DeprecatedNote that this function is * DeprecatedNote that this function is * DeprecatedNote that this function is", "commit_type": "update"}
{"commit_tokens": ["Changed", "default", "number", "of", "items", "from", "20", "to", "50", "."], "add_tokens": "private static final int DEFAULT_MAX_ITEMS = 50 ;", "del_tokens": "private static final int DEFAULT_MAX_ITEMS = 20 ;", "commit_type": "change"}
{"commit_tokens": ["Use", "partHeader", "to", "set", "Content", "-", "Disposition", "value"], "add_tokens": "partBuffer . append ( \"form-data; name=\\\"\" ) . append ( name ) ; partBuffer . append ( '\"' ) ; return partHeader ( \"Content-Disposition\" , partBuffer . toString ( ) ) ;", "del_tokens": "partBuffer . append ( \"Content-Disposition: form-data; name=\\\"\" ) ; partBuffer . append ( name ) ; partBuffer . append ( \"\\\"\\r\\n\\r\\n\" ) ; output . write ( partBuffer . toString ( ) ) ; return this ;", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "if", "all", "buckets", "removed", "all", "the", "nodes", "are", "removed", "."], "add_tokens": "import com . couchbase . client . core . message . config . FlushRequest ; cluster . send ( new FlushRequest ( bucket , password ) ) . toBlocking ( ) . single ( ) ;", "del_tokens": "//cluster.send(new FlushRequest(bucket, password)).toBlocking().single();", "commit_type": "make"}
{"commit_tokens": ["fixed", "preprocessing", "according", "to", "changed", "semantics", "of", "getSenses"], "add_tokens": "return result ;", "del_tokens": "return result ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "method", "for", "obtaining", "capabilities", "."], "add_tokens": "import java . security . Provider ; import java . security . Provider . Service ; import java . security . Security ; private boolean cipherExists ( String algorithm ) { return algorithmExists ( \"Cipher\" , algorithm ) ; private boolean algorithmExists ( String serviceType , String algorithm ) { for ( Provider provider : Security . getProviders ( ) ) { for ( Service service : provider . getServices ( ) ) { if ( service . getType ( ) . equals ( serviceType ) ) { if ( service . getAlgorithm ( ) . equals ( algorithm ) ) { return true ; } } } } return false ; } return algorithmExists ( \"MessageDigest\" , digest ) ;", "del_tokens": "import javax . crypto . Cipher ; import java . security . GeneralSecurityException ; import java . security . MessageDigest ; private boolean cipherExists ( String cipher ) { try { Cipher . getInstance ( cipher ) ; return true ; } catch ( GeneralSecurityException e ) { return false ; } try { MessageDigest . getInstance ( digest ) ; return true ; } catch ( GeneralSecurityException e ) { return false ; }", "commit_type": "update"}
{"commit_tokens": ["added", "logic", "to", "look", "for", "MMS_HOME", "in", "System", ".", "getProperty", "/", "command", "line"], "add_tokens": "private final static String HOME_DIR = \"MMS_HOME\" ; private final Logger logger = Logger . getLogger ( \"MGCP\" ) ; String home = getHomeDir ( ) ; throw new IOException ( HOME_DIR + \" not set\" ) ; / * * * Gets the Media Server Home directory . * * @ TODO This method duplicates the logic in org . mobicents . media . server . bootstrap . Main * * @ return the path to the home directory . * / private static String getHomeDir ( ) { String mmsHomeDir = System . getProperty ( HOME_DIR ) ; if ( mmsHomeDir == null ) { mmsHomeDir = System . getenv ( HOME_DIR ) ; } ; return mmsHomeDir ; } int txID = event . getMessage ( ) . getTxID ( ) ;", "del_tokens": "private final Logger logger = Logger . getLogger ( \"MGCP\" ) ; String home = System . getenv ( \"MMS_HOME\" ) ; throw new IOException ( \"MMS_HOME not set\" ) ; int txID = event . getMessage ( ) . getTxID ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "png", "to", "webp", "convert"], "add_tokens": "String command = CMD_DIR + ( src . getName ( ) . endsWith ( \".gif\" ) ? \"/gif2webp \" : \"/cwebp \" ) + src . getPath ( ) + \" -o \" + dest . getPath ( ) ;", "del_tokens": "if ( dest . exists ( ) ) dest . delete ( ) ; boolean create = dest . createNewFile ( ) ; String command = CMD_DIR + ( src . getName ( ) . endsWith ( \".gif\" ) ? \"/gif2webp \" : \"/dwebp \" ) + src . getPath ( ) + \" -o \" + dest . getPath ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "more", "stuff", "in", "UserPrincipal", "implementation", "."], "add_tokens": "} else if ( ! this . ugi . getUserName ( ) . equals ( ( ( HadoopUserPrincipal ) obj ) . ugi . getUserName ( ) ) || ! Arrays . equals ( this . ugi . getGroupNames ( ) , ( ( HadoopUserPrincipal ) obj ) . ugi . getGroupNames ( ) ) ) { return name . hashCode ( ) ;", "del_tokens": "// private HadoopFileSystem hdfs; // this.hdfs = hdfs; } else if ( ! this . ugi . getUserName ( ) . equals ( ( ( HadoopUserPrincipal ) obj ) . ugi . getUserName ( ) ) || ! Arrays . equals ( this . ugi . getGroupNames ( ) , ( ( HadoopUserPrincipal ) obj ) . ugi . getGroupNames ( ) ) ) { int hash = 948 ; hash = hash * ugi . hashCode ( ) ; return hash ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "two", "unreported", "bugs", "that", "popped", "-", "up", "and", "added", "unit", "tests", "to", "detect", "them", "in", "the", "future"], "add_tokens": "try { return new JarHandler ( this , parent , file , file . toURL ( ) , name ) ; } catch ( IOException e ) { log . debug ( \"Exception while trying to handle file (\" + name + \") as a jar: \" + e . getMessage ( ) ) ; } log . debug ( \"IGNORING: Exception while trying to handle file (\" + name + \") as a jar through ZipEntryContext: \" , e ) ;", "del_tokens": "return new JarHandler ( this , parent , file , file . toURL ( ) , name ) ; IOException ex = new IOException ( \"Exception while trying to handle file (\" + name + \") through ZipEntryContext: \" ) ; ex . initCause ( e ) ; throw ex ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "default", "write", "consistency", "level", "to", "QUORUM"], "add_tokens": "import com . stratio . deep . entity . Cell ; import com . stratio . deep . entity . Cells ; * Default write consistency level . Defaults to QUORUM . private String writeConsistencyLevel = ConsistencyLevel . QUORUM . name ( ) ;", "del_tokens": "import com . stratio . deep . cql . DeepConfigHelper ; import com . stratio . deep . entity . Cell ; import com . stratio . deep . entity . Cells ; import org . apache . cassandra . hadoop . ConfigHelper ; import org . apache . cassandra . hadoop . cql3 . CqlConfigHelper ; import org . apache . commons . lang . ArrayUtils ; import org . apache . hadoop . conf . Configuration ; import org . apache . hadoop . mapreduce . Job ; import java . io . IOException ; * Default write consistency level . Defaults to LOCAL_ONE . private String writeConsistencyLevel = ConsistencyLevel . LOCAL_ONE . name ( ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "test", "case", "for", "applying", "decorator", "only", "on", "correct", "widget"], "add_tokens": "import android . view . ViewGroup ; import android . widget . TextView ; import com . mounacheikhna . decor . AttrsDecorator ; import com . mounacheikhna . decor . DecorValue ; import static org . mockito . Matchers . any ; import static org . mockito . Mockito . never ; @ Mock AttrsDecorator < TextView > textViewDecorator ; TextView textView ; @ Mock ViewGroup parent ; parent . addView ( view ) ; //this is maybe just useless since parent is a mock textView = new TextView ( context ) ; parent . addView ( textView ) ; //maybe useless ? } @ Test public void applyDecoratorIsAplliedOnlyOnCorrectWidget ( ) throws Exception { decorators . add ( textViewDecorator ) ; String name = \"android.widget.TextView\" ; decorFactory . onViewCreated ( view , name , parent , context , attributeSet ) ; //verify(textViewDecorator, never()).apply(view, any(DecorValue.class)); //pb here is that apply is // protected (we can't make it public, it changes a lot)", "del_tokens": "View parent ; parent = new View ( context ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "mergeSequence", "and", "add", "more", "yielder", "tests"], "add_tokens": "if ( pQueue . isEmpty ( ) && ! accumulator . yielded ( ) ) {", "del_tokens": "if ( pQueue . isEmpty ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "annotation", "to", "add", "comments", "to", "test", "report"], "add_tokens": "* < li > report message < / li > @ XmlType ( propOrder = { \"name\" , \"status\" , \"reportMessage\" , \"duration\" , \"operateOnDeployment\" , \"runAsClient\" , \"exception\" , \"propertyEntries\" } ) private String reportMessage ; public String getReportMessage ( ) { return reportMessage ; } @ XmlAttribute public void setReportMessage ( String reportMessage ) { this . reportMessage = reportMessage ; }", "del_tokens": "@ XmlType ( propOrder = { \"name\" , \"status\" , \"duration\" , \"operateOnDeployment\" , \"runAsClient\" , \"exception\" , \"propertyEntries\" } )", "commit_type": "add"}
{"commit_tokens": ["add", "content", "type", "for", "file", "upload"], "add_tokens": "XML ( \"text/xml; charset=utf-8\" ) , JPG ( \"image/jpeg\" ) , PNG ( \"image/png\" ) , GIF ( \"image/gif\" ) , ;", "del_tokens": "XML ( \"text/xml; charset=utf-8\" ) , ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "jaxio", "/", "pack", "-", "backend", "-", "jpa", "/", "issues", "/", "2"], "add_tokens": "import com . jaxio . celerio . util . StringUtil ; import static com . jaxio . celerio . util . StringUtil . hasLength ; private String catalog ; @ Setter private String schema ; @ Setter / * * * ( Optional ) The catalog of the sequence generator . * / public String getCatalog ( ) { return catalog ; } public boolean hasCatalog ( ) { return hasLength ( catalog ) ; } / * * * ( Optional ) The schema of the sequence generator . * / public String getSchema ( ) { return schema ; } public boolean hasSchema ( ) { return hasLength ( schema ) ; } return allocationSize != null && allocationSize != 50 ;", "del_tokens": "return allocationSize != null && allocationSize != 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "EclipseHack", "parser", "so", "it", "can", "handle", "@AutoValue", "classes", "nested", "inside", "interfaces", "."], "add_tokens": "if ( token . equals ( \"class\" ) || token . equals ( \"interface\" ) ) {", "del_tokens": "if ( token . equals ( \"class\" ) ) {", "commit_type": "update"}
{"commit_tokens": ["changed", "unix", "overthere", "connection", "from", "sftp", "to", "scp"], "add_tokens": "connectionOptions . set ( SshConnectionBuilder . CONNECTION_TYPE , SshConnectionType . SCP ) ;", "del_tokens": "connectionOptions . set ( SshConnectionBuilder . CONNECTION_TYPE , SshConnectionType . SFTP ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "converter", "for", "greater", "and", "less", "than"], "add_tokens": "public class JpaEqualConverter < T , V > implements SpecificationConverter < EqualSpecification < V > , JpaCriteriaBuilder < T > , Predicate > { public Predicate convert ( EqualSpecification < V > specification , JpaCriteriaBuilder < T > builder , SpecificationTranslator < JpaCriteriaBuilder < T > , Predicate > translator ) {", "del_tokens": "public class JpaEqualConverter < T > implements SpecificationConverter < EqualSpecification < T > , JpaCriteriaBuilder < T > , Predicate > { public Predicate convert ( EqualSpecification < T > specification , JpaCriteriaBuilder < T > builder , SpecificationTranslator < JpaCriteriaBuilder < T > , Predicate > translator ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "failing", "get", "/", "delete", "tests"], "add_tokens": "DeleteRequest req = new DeleteRequest ( \"https://rally1.rallydev.com/slm/webservice/1.32/defect/1234.js\" ) ;", "del_tokens": "DeleteRequest req = new DeleteRequest ( \"https://rally1.rallydev.com/slm/webservice/x/defect/1234.js\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "wrong", "initialization", "of", "the", "constructor", "that", "set", "to", "null", "a", "listener"], "add_tokens": "&& ( command . getState ( ) . equals ( PHATCommand . State . Success ) || command . getState ( ) . equals ( PHATCommand . State . Fail ) ) ) {", "del_tokens": "&& command . getState ( ) . equals ( PHATCommand . State . Success ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "how", "the", "internal", "ids", "are", "processed"], "add_tokens": "htmlExpected = \"<a href=\\\"#an-internal-link\\\">A link</a>\" ;", "del_tokens": "htmlExpected = \"<a href=\\\"#aninternallink\\\">A link</a>\" ;", "commit_type": "change"}
{"commit_tokens": ["use", "send", "()", "instead", "of", "sendMessage", "()"], "add_tokens": "transport . send ( message ) ;", "del_tokens": "transport . sendMessage ( message , toArray ) ;", "commit_type": "use"}
{"commit_tokens": ["Update", "metric", "name", "label", "."], "add_tokens": "io . println ( \" \\\"__name__\\\": \\\"\" + prometheusName + \"\\\"\" ) ; if ( key . toLowerCase ( ) . equals ( \"__name__\" ) ) {", "del_tokens": "io . println ( \" \\\"name\\\": \\\"\" + prometheusName + \"\\\"\" ) ; if ( key . toLowerCase ( ) . equals ( \"name\" ) ) {", "commit_type": "update"}
{"commit_tokens": ["Adds", "constructor", "to", "take", "ClientConfiguration", "."], "add_tokens": "import com . amazonaws . ClientConfiguration ; this ( longLivedCredentials , new ClientConfiguration ( ) ) ; } / * * * Constructs a new STSSessionCredentialsProvider , which will use the * specified long lived AWS credentials to make a request to the AWS * Security Token Service ( STS ) to request short lived session credentials , * which will then be returned by this class 's {@link #getCredentials()} * method . * * @ param longLivedCredentials * The main AWS credentials for a user 's account. * * @ param clientConfiguration * Client configuration connection parameters . * / public STSSessionCredentialsProvider ( AWSCredentials longLivedCredentials , ClientConfiguration clientConfiguration ) { securityTokenService = new AWSSecurityTokenServiceClient ( longLivedCredentials , clientConfiguration ) ;", "del_tokens": "securityTokenService = new AWSSecurityTokenServiceClient ( longLivedCredentials ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "race", "condition", "from", "test"], "add_tokens": "import java . util . ArrayList ; List < Response < Object > > responseList = new ArrayList < Response < Object > > ( ) ; long waitUntil = System . currentTimeMillis ( ) + 20000 ; while ( responseList . size ( ) < 3 && System . currentTimeMillis ( ) < waitUntil ) { wait ( WaitMode . ALL , 10000 , cid ) ; List < Response < Object > > tmpResponses = getAndRemoveResponses ( cid ) ; assertNotNull ( tmpResponses ) ; responseList . addAll ( tmpResponses ) ;", "del_tokens": "//for we expect that 3 response will be returned in one step, we have to ensurce that the adapter has sent the notifications. 50msec should be enough. try { Thread . sleep ( 50 ) ; } catch ( InterruptedException e ) { //ignore wait ( WaitMode . ALL , 10000 , cid ) ; List < Response < Object > > responseList = getAndRemoveResponses ( cid ) ; assertNotNull ( responseList ) ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "Avenir", "typeface", "Dynamic", "setting", "of", "default", "typeface"], "add_tokens": "/ * * * The default typeface * / public static int DEFAULT_TYPEFACE ; DEFAULT_TYPEFACE = TypefaceType . getDefaultTypeface ( context ) ;", "del_tokens": "/ * * * The default typeface * / public static final int DEFAULT_TYPEFACE = TypefaceType . ROBOTO_REGULAR . getValue ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Improved", "checking", "for", "declared", "annotation", "properties"], "add_tokens": "private ImmutableSet < IRI > annotationPropertyIris ; annotationPropertyIris = ImmutableSet . copyOf ( reasoner . getRootOntology ( ) . getAnnotationPropertiesInSignature ( Imports . INCLUDED ) . stream ( ) . map ( OWLNamedObject :: getIRI ) . collect ( toSet ( ) ) ) ; return annotationPropertyIris . contains ( arg . getValueAsIRI ( ) ) ;", "del_tokens": "return isDeclared ( asAnnotationProperty ( arg ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["add", "remaining", "/", "users", "endpoints"], "add_tokens": "public void setPassword ( String password ) { public void setEmail ( String email ) { public void setPhoneNumber ( String phoneNumber ) { public void setClientId ( String clientId ) { this . clientId = clientId ; } public void setVerifyPassword ( Boolean verifyPassword ) { this . verifyPassword = verifyPassword ; } public void setVerifyEmail ( Boolean verifyEmail ) { this . verifyEmail = verifyEmail ; } public void setVerifyPhoneNumber ( Boolean verifyPhoneNumber ) { this . verifyPhoneNumber = verifyPhoneNumber ; }", "del_tokens": "public void setPassword ( String password , Boolean needsVerification ) { this . verifyPassword = needsVerification ; public void setEmail ( String email , String clientId , Boolean needsVerification ) { this . clientId = clientId ; this . verifyEmail = needsVerification ; public void setPhoneNumber ( String phoneNumber , Boolean needsVerification ) { this . verifyPhoneNumber = needsVerification ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "test", "in", "own", "package", "to", "detect", "package", "-", "private", "problems", "."], "add_tokens": "package de . mkammerer . argon2 . test ; import de . mkammerer . argon2 . Argon2 ; import de . mkammerer . argon2 . Argon2Factory ;", "del_tokens": "package de . mkammerer . argon2 ;", "commit_type": "move"}
{"commit_tokens": ["Update", "to", "latest", "API", "version"], "add_tokens": "import org . trellisldp . api . ConstraintService ; import org . trellisldp . api . ConstraintViolation ;", "del_tokens": "import org . trellisldp . spi . ConstraintService ; import org . trellisldp . spi . ConstraintViolation ;", "commit_type": "update"}
{"commit_tokens": ["Fixing", "squid", ":", "S1444", "-", "public", "static", "fields", "should", "be", "constant", "."], "add_tokens": "public static final EmptyDisposable EMPTY = new EmptyDisposable ( ) ;", "del_tokens": "public static EmptyDisposable EMPTY = new EmptyDisposable ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "some", "bug", "on", "findbugs"], "add_tokens": "BufferedReader br = null ; br = new BufferedReader ( new InputStreamReader ( if ( br != null ) { br . close ( ) ; }", "del_tokens": "BufferedReader br = new BufferedReader ( new InputStreamReader (", "commit_type": "fix"}
{"commit_tokens": ["Added", "BYTE_ARRAY", "type", "and", "revamped", "a", "good", "bit", "of", "the", "DataType", "class", "after", "adding", "new", "tests", ".", "byte", "[]", "dataType", "must", "be", "specified", "."], "add_tokens": "case BYTE_ARRAY :", "del_tokens": "case SERIALIZABLE :", "commit_type": "add"}
{"commit_tokens": ["Move", "constructor", "as", "first", "method", "after", "field", "definitions"], "add_tokens": "/ * * * * / private JAXBUtil ( ) { }", "del_tokens": "/ * * * * / private JAXBUtil ( ) { }", "commit_type": "move"}
{"commit_tokens": ["fixed", "a", "bug", "reported", "in", "issue", "3", "."], "add_tokens": "String name ; name = aliases . get ( decl ) ; else name = decl . getName ( ) ; if ( name . equals ( \"IUnknown\" ) || name . equals ( \"IDispatch\" ) ) return \"Com4jObject\" ; return name ;", "del_tokens": "if ( baseName . equals ( \"IUnknown\" ) || baseName . equals ( \"IDispatch\" ) ) baseName = \"Com4jObject\" ; return aliases . get ( decl ) ; return decl . getName ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "to", "suite", "and", "make", "sure", "everything", "has", "@RunWith"], "add_tokens": "import org . junit . contrib . truth . extensiontest . ExtensionTest ; SubjectTest . class , ExtensionTest . class", "del_tokens": "SubjectTest . class", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "close", "method", "to", "DockerClient"], "add_tokens": "import java . io . * ; public class DockerClient implements Closeable { @ Override public void close ( ) throws IOException { client . destroy ( ) ; }", "del_tokens": "import java . io . File ; import java . io . IOException ; import java . io . InputStream ; import java . io . StringWriter ; public class DockerClient {", "commit_type": "add"}
{"commit_tokens": ["fixed", "grammar", "in", "error", "message"], "add_tokens": "+ \"] could not be found in the JVM library path nor could it be loaded from the embedded JAR resource file; you may need to explicitly define the library path '-Djava.library.path' where this native library can be found.\" ) ; + \"] could not be found in the JVM library path nor could it be loaded from the embedded JAR resource file; you may need to explicitly define the library path '-Djava.library.path' where this native library can be found.\" ) ;", "del_tokens": "+ \"] could not found in the JVM library path nor could it be loaded from the embedded JAR resource file; you may need to explicitly define the library path '-Djava.library.path' where this native library can be found.\" ) ; + \"] could not found in the JVM library path nor could it be loaded from the embedded JAR resource file; you may need to explicitly define the library path '-Djava.library.path' where this native library can be found.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "complex", "test", "+", "some", "cleanup"], "add_tokens": "// Generates invoke replacement logic and new trycatchblocks requires", "del_tokens": "// Generates store logic and restore addLabel for each continuation point", "commit_type": "add"}
{"commit_tokens": ["Removed", "all", "fixed", "array", "implementations"], "add_tokens": "* The initial capacity of the heap is { @ link # DEFAULT_HEAP_CAPACITY } and * adjusts automatically based on the sequence of insertions and deletions .", "del_tokens": "* The initial capacity of the heap is * { @ link BinaryArrayHeap # DEFAULT_HEAP_CAPACITY } and adjusts automatically * based on the sequence of insertions and deletions .", "commit_type": "remove"}
{"commit_tokens": ["using", "ephemeral", "admin", "port", "for", "test"], "add_tokens": "public static final String DEFAULT_SCAN_PKG = \"netflix\" ; final String adminPagesPkgPath = ConfigurationManager . getConfigInstance ( ) . getString ( PROP_ID_ADMIN_PAGES_SCAN , DEFAULT_SCAN_PKG ) ;", "del_tokens": "final String adminPagesPkgPath = ConfigurationManager . getConfigInstance ( ) . getString ( PROP_ID_ADMIN_PAGES_SCAN , \"com.netflix\" ) ;", "commit_type": "use"}
{"commit_tokens": ["allow", "for", "carriage", "return", "characters", "in", "unit", "test"], "add_tokens": "assertEquals ( 2 , list . size ( ) ) ; assertEquals ( \"line 2\" , list . get ( 0 ) . trim ( ) ) ; assertEquals ( \"line 3\" , list . get ( 1 ) . trim ( ) ) ;", "del_tokens": "assertEquals ( Arrays . asList ( \"line 2\" , \"line 3\" ) , list ) ;", "commit_type": "allow"}
{"commit_tokens": ["fix", "the", "length", "of", "java", "uuid"], "add_tokens": "if ( uuid . length ( ) == 36 ) {", "del_tokens": "if ( uuid . length ( ) == 32 ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "next", "format", "version"], "add_tokens": "return \"0.5.1\" ;", "del_tokens": "return \"0.5\" ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "problem", "in", "TenantConfigProvisioner", ".", "prependTenantPath"], "add_tokens": "import org . apache . commons . io . FilenameUtils ; return FilenameUtils . separatorsToUnix ( Paths . get ( TenantConfigRepository . PATH_CONFIG_TENANT , path ) . toString ( ) ) ;", "del_tokens": "return Paths . get ( TenantConfigRepository . PATH_CONFIG_TENANT , path ) . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "an", "IdealReason", "based", "on", "Pandora", "s", "json"], "add_tokens": "public enum StreamType { buffered , live , none }", "del_tokens": "public enum StreamType { buffered , live , none }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "tests", "with", "gcm", "pub", "sub"], "add_tokens": "private Provider < GcmPubSub > gcmPubProvider = new Provider < GcmPubSub > ( ) { @ Override public GcmPubSub get ( Object ... context ) { return GcmPubSub . getInstance ( ( Context ) context [ 0 ] ) ; } } ; GcmPubSub gcmPubSub = gcmPubProvider . get ( context ) ; gcmPubSub . getInstance ( context ) . subscribe ( deviceToken , \"/topics/\" + catgory , null ) ; GcmPubSub gcmPubSub = gcmPubProvider . get ( context ) ; gcmPubSub . unsubscribe ( deviceToken , \"/topics/\" + catgory ) ;", "del_tokens": "import java . net . URLEncoder ; GcmPubSub . getInstance ( context ) . subscribe ( deviceToken , \"/topics/\" + URLEncoder . encode ( catgory ) , null ) ; GcmPubSub . getInstance ( context ) . unsubscribe ( deviceToken , \"/topics/\" + URLEncoder . encode ( catgory ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "attribute", "for", "setting", "expand", "/", "collapse", "aim", "duration"], "add_tokens": "* < p > * < p > * < p > private final boolean ATTRS_SHOW_DIM_BACKGROUND_DEFAULT = true ; private final int ATTRS_SUGGESTION_ANIM_DURATION_DEFAULT = 250 ; private long mSuggestionSectionAnimDuration ; this . mSuggestionSectionAnimDuration = a . getInt ( R . styleable . FloatingSearchView_floatingSearch_suggestionsListAnimDuration , ATTRS_SUGGESTION_ANIM_DURATION_DEFAULT ) ; / * * * Set the duration for the suggestions list expand / collapse * animation . * * @ param duration * / public void setSuggestionsAnimDuration ( long duration ) { this . mSuggestionSectionAnimDuration = duration ; } setDuration ( mSuggestionSectionAnimDuration ) . this . mSuggestionSectionAnimDuration = savedState . suggestionsSectionAnimSuration ; private long suggestionsSectionAnimSuration ; suggestionsSectionAnimSuration = in . readLong ( ) ; out . writeLong ( suggestionsSectionAnimSuration ) ;", "del_tokens": "* < p / > * < p / > * < p / > private static final boolean ATTRS_SHOW_DIM_BACKGROUND_DEFAULT = true ; private final int SUGGESTIONS_LIST_HEIGHT_UPDATE_ANIM_DURATION = 250 ; setDuration ( SUGGESTIONS_LIST_HEIGHT_UPDATE_ANIM_DURATION ) .", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "API", "to", "load", "environment", "specific", "properties", "file", "."], "add_tokens": "public static void loadCascadedPropertiesFromResources ( String configName ) throws IOException { String defaultConfigFileName = configName + \".properties\" ; if ( instance == null ) { instance = getConfigInstance ( ) ; } ClassLoader loader = Thread . currentThread ( ) . getContextClassLoader ( ) ; URL url = loader . getResource ( defaultConfigFileName ) ; Properties props = new Properties ( ) ; InputStream fin = url . openStream ( ) ; props . load ( fin ) ; fin . close ( ) ; String environment = getDeploymentContext ( ) . getDeploymentEnvironment ( ) ; if ( environment != null && environment . length ( ) > 0 ) { String envConfigFileName = configName + \"-\" + environment + \".properties\" ; url = loader . getResource ( envConfigFileName ) ; InputStream fin2 = url . openStream ( ) ; props . load ( fin2 ) ; fin2 . close ( ) ; } if ( instance instanceof AggregatedConfiguration ) { ConcurrentMapConfiguration config = new ConcurrentMapConfiguration ( ) ; config . loadProperties ( props ) ; ( ( AggregatedConfiguration ) instance ) . addConfiguration ( config , configName ) ; } else { ConfigurationUtils . loadProperties ( props , instance ) ; } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "bug", "casuing", "NullPointerException", "during", "updating"], "add_tokens": "VanillaDb . newPlanner ( ) . executeUpdate ( sql , tx ) ;", "del_tokens": "int count = VanillaDb . newPlanner ( ) . executeUpdate ( sql , tx ) ; if ( count > 1 ) throw new RuntimeException ( \"Update: '\" + sql + \"' affect more than 1 record.\" ) ; else if ( count < 1 ) throw new RuntimeException ( \"Update: '\" + sql + \"' fails.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "delete", "directory", "to", "the", "sdcard", "added", "1000", "+", "colors", "to", "colors", ".", "xml"], "add_tokens": "import android . os . Environment ; / * * * Delete directory * @ param path * @ return returns true if deletion was successful * / public static boolean deleteDirectory ( File path ) { if ( path . exists ( ) ) { File [ ] files = path . listFiles ( ) ; if ( files == null ) { return true ; } for ( int i = 0 ; i < files . length ; i ++ ) { if ( files [ i ] . isDirectory ( ) ) { deleteDirectory ( files [ i ] ) ; } else { files [ i ] . delete ( ) ; } } } return ( path . delete ( ) ) ; }", "del_tokens": "import quickutils . core . QuickUtils ; import android . os . Environment ;", "commit_type": "add"}
{"commit_tokens": ["add", "optional", "timeout", "for", "async", "connection", "flush"], "add_tokens": "import org . junit . * ; import org . junit . rules . ExpectedException ; import java . util . concurrent . TimeUnit ; import static org . junit . Assert . assertTrue ; @ Rule public ExpectedException exception = ExpectedException . none ( ) ; @ Test public void clear ( ) throws Exception { async . set ( key , value ) ; async . get ( key ) ; async . clear ( ) ; assertTrue ( async . flush ( ) . isEmpty ( ) ) ; } @ Test public void flushTimeout ( ) throws Exception { exception . expect ( RedisException . class ) ; exception . expectMessage ( \"Command timed out\" ) ; async . set ( key , value ) ; async . blpop ( 1 , key ) ; async . flush ( 1 , TimeUnit . MICROSECONDS ) ; }", "del_tokens": "import org . junit . Before ; import org . junit . Test ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "basic", "ogg", "flac", "read", "test"], "add_tokens": "int [ ] next = new int [ 8 ] ; for ( int i = 0 ; i < 8 ; i ++ ) { next [ i ] = IOUtils . toInt ( data [ i + offset ] ) ; } sampleRate = ( next [ 0 ] << 12 ) + ( next [ 1 ] << 4 ) + ( ( next [ 2 ] & 0xf0 ) >> 4 ) ; numChannels = ( ( next [ 2 ] & 0x0e ) >> 1 ) + 1 ; bitsPerSample = ( ( next [ 2 ] & 0x01 ) << 4 ) + ( ( next [ 3 ] & 0xf0 ) >> 4 ) + 1 ; numberOfSamples = ( ( next [ 3 ] & 0x0f ) << 30 ) + ( next [ 4 ] << 24 ) + ( next [ 5 ] << 16 ) + ( next [ 6 ] << 8 ) + next [ 7 ] ;", "del_tokens": "byte [ ] next = new byte [ 8 ] ; System . arraycopy ( data , offset , next , 0 , 8 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "null", "checks", "in", "ASyncTask", "."], "add_tokens": "if ( mSuperCardToast != null ) { mSuperCardToast . dismiss ( ) ; } if ( mSuperCardToast != null ) { }", "del_tokens": "mSuperCardToast . dismiss ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "minor", "bug", "that", "appears", "when", "testing", "very", "small", "applications", "."], "add_tokens": "ArrayList < TextView > textViewList = getCurrentTextViews ( null ) ;", "del_tokens": "ArrayList < TextView > textViewList = getCurrentTextViews ( scrollListView ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "tx", "calls"], "add_tokens": "LOGGER . error ( \"Could not encode URI parameter: {}\" , e . getMessage ( ) ) ; LOGGER . error ( \"Could not encode URI parameter: {}\" , e . getMessage ( ) ) ; LOGGER . error ( \"Could not encode URI parameter: {}\" , e . getMessage ( ) ) ;", "del_tokens": "LOGGER . error ( \"could not encode URI parameter\" , e ) ; LOGGER . error ( \"could not encode URI parameter\" , e ) ; LOGGER . error ( \"could not encode URI parameter\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "find", "(", "String", "query", ")", "functionality"], "add_tokens": "channels = client . findByName ( \"pvk:01<first>, pvk:02<second>\" ) ; channels = client . findByTag ( \"tagA, tagB\" ) ; @ Test public void testQueryString ( ) { String query = \"pvk:*\" ; assertTrue ( \"Failed to query for pvk:* - expect 3 found \" + client . find ( query ) . size ( ) , client . find ( query ) . size ( ) == 3 ) ; query = \"* prop=1,2\" ; assertTrue ( \"Failed to query using name and property, expected: 3 found: \" + client . find ( query ) . size ( ) , client . find ( query ) . size ( ) == 3 ) ; query = \"pvk* prop=1,2 prop2=*\" ; assertTrue ( \"Failed to query using name and multiple properties, expected: 1 found: \" + client . find ( query ) . size ( ) , client . find ( query ) . size ( ) == 1 ) ; query = \"pvk* prop=1,2 Tags=Taga,Tagb\" ; assertTrue ( \"Failed to query using name and property and tag, expected: 1 found: \" + client . find ( query ) . size ( ) , client . find ( query ) . size ( ) == 1 ) ; query = \"pvk* prop=1, 2 Tags=Taga, Tagb\" ; assertTrue ( \"Failed to query using name and property and tag with spaces, expected: 1 found: \" + client . find ( query ) . size ( ) , client . find ( query ) . size ( ) == 1 ) ; }", "del_tokens": "channels = client . findByName ( \"pvk:01<first>, pvk:02<second>\" ) ; channels = client . findByTag ( \"tagA, tagB\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "A", "text", "label", "CmsLabel", "added", "to", "XML", "Template", "mechanism", ".", "First", "version", "of", "the", "Login", "screen", "."], "add_tokens": "* @ version $ Revision : 1.3 $ $ Date : 2000 / 01 / 25 18 : 05 : 34 $ registerTag ( \"LABEL\" , CmsXmlWpTemplateFile . class , \"handleAnyTag\" , C_REGISTER_MAIN_RUN ) ; } else if ( tagname . equals ( \"label\" ) ) { classname = \"com.opencms.workplace.CmsLabel\" ;", "del_tokens": "* @ version $ Revision : 1.2 $ $ Date : 2000 / 01 / 25 16 : 16 : 17 $", "commit_type": "add"}
{"commit_tokens": ["Fix", "Parseable", ".", "parse", "()", "to", "use", "passed", "-", "in", "options"], "add_tokens": "private ConfigParseOptions initialOptions ; this . initialOptions = fixupOptions ( baseOptions ) ; if ( finalOptions . getSyntax ( ) == ConfigSyntax . PROPERTIES ) { finalOptions . getSyntax ( ) ) ; return Parser . parse ( tokens , origin , finalOptions , if ( finalOptions . getAllowMissing ( ) ) { return initialOptions ;", "del_tokens": "private ConfigParseOptions options ; this . options = fixupOptions ( baseOptions ) ; if ( options . getSyntax ( ) == ConfigSyntax . PROPERTIES ) { options . getSyntax ( ) ) ; return Parser . parse ( tokens , origin , options , if ( options . getAllowMissing ( ) ) { return options ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "custom", "handling", "for", "Any"], "add_tokens": "import com . google . protobuf . Any ; Any any = Any . newBuilder ( ) . setTypeUrl ( \"type.googleapis.com/google.protobuf.Value\" ) . setValue ( value . toByteString ( ) ) . build ( ) ; . putAnyMap ( \"any\" , any ) node . set ( \"anyMap\" , newObjectNode ( ) . set ( \"any\" , anyNode ( ) ) ) ; private static ObjectNode anyNode ( ) { byte [ ] bytes = Value . newBuilder ( ) . setStringValue ( \"test\" ) . build ( ) . toByteArray ( ) ; String base64 = camelCase ( ) . getSerializationConfig ( ) . getBase64Variant ( ) . encode ( bytes ) ; return newObjectNode ( ) . put ( \"typeUrl\" , \"type.googleapis.com/google.protobuf.Value\" ) . put ( \"value\" , base64 ) ; } node . set ( \"anyMap\" , newObjectNode ( ) ) ; node . set ( \"anyMap\" , NullNode . getInstance ( ) ) ;", "del_tokens": "// .putAnyMap(\"any\", null) TODO // node.set(\"anyMap\", newObjectNode().put(\"any\", null)); TODO // node.set(\"anyMap\", newObjectNode()); TODO // node.set(\"anyMap\", NullNode.getInstance()); TODO", "commit_type": "remove"}
{"commit_tokens": ["Changed", "interface", "to", "extend", "Context", ".", "This", "provides", "interface", "-", "level", "compatibility", "with", "objects", "requiring", "a", "Context", "rather", "than", "requiring", "implementations", "to", "also", "implement", "Context", "."], "add_tokens": "public interface SecureContext extends Context {", "del_tokens": "public interface SecureContext {", "commit_type": "change"}
{"commit_tokens": ["added", "list", "(", "PrintWriter", ")"], "add_tokens": "Class < Properties > propertiesClass = Properties . class ; listPrintStream = propertiesClass . getMethod ( \"list\" , PrintStream . class ) ; listPrintWriter = propertiesClass . getMethod ( \"list\" , PrintWriter . class ) ; // this shouldn't happen, btw we handle the case in which the delegate method is not available... // so, it's fine. if ( matches ( listPrintWriter , method ) ) return listPrintWriter ;", "del_tokens": "Class < Properties > pclass = Properties . class ; listPrintStream = pclass . getMethod ( \"list\" , PrintStream . class ) ; listPrintWriter = pclass . getMethod ( \"list\" , PrintWriter . class ) ; // this shouldn't happen, btw we handle the case where the delegate method is not available...", "commit_type": "add"}
{"commit_tokens": ["Improved", "the", "reflection", "code", "to", "not", "use", "introspection", ".", "Simplified", "the", "data", "structures", "."], "add_tokens": "* This identifies which fields you want to expose via JMX . This is done through reflection . If the field is not public * then it will try to open the accessibility on the field . Instead of annotating the fields , you can annotate your * < tt > getXxx ( ) < / tt > and < tt > setXxx ( ) < / tt > methods with { @ link JmxAttributeMethod } .", "del_tokens": "* This identifies which fields are exposed via JMX . This can be used or you can annotate your < tt > getXxx ( ) < / tt > and * < tt > setXxx ( ) < / tt > methods with { @ link JmxAttributeMethod } . This is done through reflection . If the field is not * public then it will try to open the accessibility on the field .", "commit_type": "improve"}
{"commit_tokens": ["fixed", "a", "bug", "pointed", "out", "by", "vlad", "smyshlyaev", "<albedo072@gmail", ".", "com", ">"], "add_tokens": "List < String > usages = wrapLines ( localize ( handler . option . usage ( ) , rb ) , widthUsage ) ; private String localize ( String s , ResourceBundle rb ) { if ( rb != null ) return rb . getString ( s ) ; return s ; } / * *", "del_tokens": "List < String > usages = wrapLines ( handler . option . usage ( ) , widthUsage ) ; / * *", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "VerifyMojo", "that", "checks", "if", "any", "errors", "have", "occurred", "and", "that", "fails", "the", "build", "if", "any", "errors", "occurred", "."], "add_tokens": "import java . util . Collections ; private static final String ERRORS_KEY = \"errors\" ; if ( skip ) { } return Collections . unmodifiableCollection ( builtImagesMap . values ( ) ) ; protected void registerPluginError ( DockerPluginError error ) { List < DockerPluginError > errors = obtainListFromPluginContext ( ERRORS_KEY ) ; errors . add ( error ) ; } protected List < DockerPluginError > getPluginErrors ( ) { List < DockerPluginError > list = obtainListFromPluginContext ( ERRORS_KEY ) ; return Collections . unmodifiableList ( list ) ; }", "del_tokens": "if ( skip ) { } return builtImagesMap . values ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "SharedKey", "to", "queue", "service"], "add_tokens": "public class SharedKeyLiteFilter extends com . microsoft . windowsazure . services . blob . implementation . SharedKeyLiteFilter { public SharedKeyLiteFilter ( @ Named ( QueueConfiguration . ACCOUNT_NAME ) String accountName , @ Named ( QueueConfiguration . ACCOUNT_KEY ) String accountKey ) { super ( accountName , accountKey ) ;", "del_tokens": "import com . sun . jersey . api . client . ClientHandlerException ; import com . sun . jersey . api . client . ClientRequest ; import com . sun . jersey . api . client . ClientResponse ; import com . sun . jersey . api . client . filter . ClientFilter ; public class SharedKeyLiteFilter extends ClientFilter { private final com . microsoft . windowsazure . services . blob . implementation . SharedKeyLiteFilter blobSharedKeyFilter ; public SharedKeyLiteFilter ( @ Named ( QueueConfiguration . ACCOUNT_NAME ) String accountName , @ Named ( QueueConfiguration . ACCOUNT_KEY ) String accountKey ) { blobSharedKeyFilter = new com . microsoft . windowsazure . services . blob . implementation . SharedKeyLiteFilter ( accountName , accountKey ) ; } @ Override public ClientResponse handle ( ClientRequest cr ) throws ClientHandlerException { // Only sign if no other filter has done it yet if ( cr . getHeaders ( ) . getFirst ( \"Authorization\" ) == null ) { blobSharedKeyFilter . sign ( cr ) ; } return this . getNext ( ) . handle ( cr ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "NPEs", "in", "Maven", "plugin", "IT"], "add_tokens": "return path . endsWith ( \".class\" ) ;", "del_tokens": "return true ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "SolrRDD", ".", "buildShardList", "to", "support", "collection", "aliases", "that", "point", "to", "multiple", "collections", "behind", "the", "scenes", "."], "add_tokens": "File targetDir = new File ( \"target\" ) ; if ( ! targetDir . isDirectory ( ) ) fail ( \"Project 'target' directory not found at: \" + targetDir . getAbsolutePath ( ) ) ; cluster = new MiniSolrCloudCluster ( 1 , null , targetDir , solrXml , null , null , null ) ; protected static void createCollection ( String collectionName , int numShards , int replicationFactor , int maxShardsPerNode , String confName ) throws Exception { createCollection ( collectionName , numShards , replicationFactor , maxShardsPerNode , confName , null ) ; protected static void createCollection ( String collectionName , int numShards , int replicationFactor , int maxShardsPerNode , String confName , File confDir ) throws Exception { modParams . set ( \"maxShardsPerNode\" , maxShardsPerNode ) ;", "del_tokens": "import org . apache . solr . cloud . ZkController ; cluster = new MiniSolrCloudCluster ( 1 , null , solrXml , null , null , null ) ; protected static void createCollection ( String collectionName , int numShards , int replicationFactor , String confName ) throws Exception { createCollection ( collectionName , numShards , replicationFactor , confName , null ) ; protected static void createCollection ( String collectionName , int numShards , int replicationFactor , String confName , File confDir ) throws Exception {", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "for", "numeric", "-", "alphabetical", "bibliographies"], "add_tokens": "protected static BibTeXDatabase loadUnixDatabase ( ) throws IOException , ParseException { InputStream is = AbstractBibTeXTest . class . getResourceAsStream ( \"/unix.bib.gz\" ) ;", "del_tokens": "protected BibTeXDatabase loadUnixDatabase ( ) throws IOException , ParseException { InputStream is = getClass ( ) . getResourceAsStream ( \"/unix.bib.gz\" ) ;", "commit_type": "add"}
{"commit_tokens": ["using", "config", "file", "for", "ssl"], "add_tokens": "// get host and port from arangodb.properties // configuration.setArangoHost(new ArangoHost(\"localhost\", 8529)); ArangoConfigure configuration = new ArangoConfigure ( \"/ssl-arangodb.properties\" ) ; ArangoConfigure configuration = new ArangoConfigure ( \"/ssl-arangodb.properties\" ) ; ArangoConfigure configuration = new ArangoConfigure ( \"/ssl-arangodb.properties\" ) ; configuration . getArangoHost ( ) . setHost ( \"127.0.0.1\" ) ;", "del_tokens": "configuration . setArangoHost ( new ArangoHost ( \"localhost\" , 8529 ) ) ; ArangoConfigure configuration = new ArangoConfigure ( ) ; configuration . setArangoHost ( new ArangoHost ( \"localhost\" , 8530 ) ) ; configuration . setUseSsl ( true ) ; ArangoConfigure configuration = new ArangoConfigure ( ) ; configuration . setArangoHost ( new ArangoHost ( \"localhost\" , 8530 ) ) ; configuration . setUseSsl ( true ) ; ArangoConfigure configuration = new ArangoConfigure ( ) ; configuration . setArangoHost ( new ArangoHost ( \"127.0.0.1\" , 8530 ) ) ; configuration . setUseSsl ( true ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "in", "close", "connection", "watch", "debug", "tool"], "add_tokens": "if ( ! this . connectionHandle . isClosed ( ) && this . threadToMonitor . equals ( this . connectionHandle . getThreadUsingConnection ( ) ) ) {", "del_tokens": "if ( ! this . connectionHandle . isClosed ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "BUS", "pattern", "."], "add_tokens": "import org . dihedron . commons . streams . Streams ; DataBase database = DataBaseLoader . loadFromStream ( Streams . fromClassPath ( \"org/dihedron/crypto/providers/smartcard/discovery/smartcards.xml\" ) ) ; @ Test public void testLoadFromURL ( ) throws SmartCardException , IOException { DataBase database = DataBaseLoader . loadFromStream ( Streams . fromURL ( \"classpath:org/dihedron/crypto/providers/smartcard/discovery/smartcards.xml\" ) ) ; logger . trace ( \"database:\\n {}\" , database ) ; }", "del_tokens": "DataBase database = DataBaseLoader . loadFromClassPath ( \"org/dihedron/crypto/providers/smartcard/discovery/smartcards.xml\" ) ;", "commit_type": "add"}
{"commit_tokens": ["removing", "deprecated", "function", "of", "TypeFactory"], "add_tokens": "ObjectMapper objectMapper = createObjectMapper ( ) ; tableList = objectMapper . readValue ( dbFile , objectMapper . getTypeFactory ( ) . constructCollectionType ( ArrayList . class , Table . class ) ) ;", "del_tokens": "tableList = createObjectMapper ( ) . readValue ( dbFile , TypeFactory . collectionType ( ArrayList . class , Table . class ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "updated", "date", "to", "submissions"], "add_tokens": "import java . util . Date ; / * * * Get the date the submission was published * @ return * / public abstract Date getUpdated ( ) ; / * * * Set the data the submission was published * @ param date * / public abstract void setUpdated ( Date date ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "toString", "()", "to", "LocationOccurence", "and", "QueryBuilder", ".", "Updated", "LuceneGazetteer", "so", "it", "creates", "a", "Filter", "for", "all", "non", "-", "name", "portions", "of", "the", "query", "parameters", "(", "feature", "code", "ancestry", "historical", "etc", ".", ")", "so", "those", "criteria", "are", "not", "included", "in", "the", "scoring", "to", "avoid", "unexpected", "results", "because", "scores", "were", "weighted", "differently", ".", "Updated", "ClavinLocationResolver", "to", "use", "the", "new", "QueryBuilder", "."], "add_tokens": "* * * * @ Override public String toString ( ) { return String . format ( \"\\\"%s\\\":%d\" , text , position ) ; }", "del_tokens": "* * * *", "commit_type": "add"}
{"commit_tokens": ["Remove", "an", "extra", "null", "check", "."], "add_tokens": "if ( implementsTypes . length > 0 ) {", "del_tokens": "if ( ( implementsTypes != null ) && ( implementsTypes . length > 0 ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "@Id", "annotations"], "add_tokens": "if ( beanProperty . getAnnotation ( Id . class ) != null || beanProperty . getAnnotation ( javax . persistence . Id . class ) != null || beanProperty . getName ( ) . equals ( \"_id\" ) ) { break ;", "del_tokens": "if ( beanProperty . getName ( ) . equals ( \"_id\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "path", "property", "to", "baseUri"], "add_tokens": "String path = props . getPath ( ) != null ? props . getPath ( ) : \"\" ; this . baseURI = builder ( ) . scheme ( props . getProtocol ( ) ) . host ( props . getHost ( ) ) . port ( props . getPort ( ) ) . path ( \"/\" ) . path ( path ) . build ( ) ; this . dbURI = builder ( baseURI ) . path ( props . getDbName ( ) ) . path ( \"/\" ) . build ( ) ;", "del_tokens": "baseURI = builder ( ) . scheme ( props . getProtocol ( ) ) . host ( props . getHost ( ) ) . port ( props . getPort ( ) ) . path ( \"/\" ) . build ( ) ; dbURI = builder ( baseURI ) . path ( props . getDbName ( ) ) . path ( \"/\" ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "UserType", ".", "isNested", "()"], "add_tokens": "return getParent ( ) . getDescriptorType ( ) != DescriptorType . PROTO ;", "del_tokens": "return getParent ( ) . getDescriptorType ( ) == DescriptorType . PROTO ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "extended", "support", "for", "ID", "and", "IDREF", "."], "add_tokens": "final MTypeInfo < T , C > draftTI = getTypeInfo ( typeInfo ) ; final MTypeInfo < T , C > ti ; switch ( id ) { case ID : ti = new CMID < T , C > ( draftTI . getTargetType ( ) , draftTI ) ; break ; case IDREF : ti = new CMIDREF < T , C > ( draftTI . getTargetType ( ) , draftTI ) ; break ; default : ti = draftTI ; break ; }", "del_tokens": "final MTypeInfo < T , C > ti = getTypeInfo ( typeInfo ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "logging", "when", "trying", "to", "get", "manifest", "from", "location"], "add_tokens": "LOGGER . info ( \"Trying to get manifest from \" + location ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "the", "chooser", "to", "be", "configured", "to", "allow", "read", "-", "only", "directories", "to", "be", "selected", "."], "add_tokens": "public static final String EXTRA_ALLOW_READ_ONLY_DIRECTORY = \"allow_read_only_directory\" ; final Boolean allowReadOnlyDir = getIntent ( ) . getBooleanExtra ( EXTRA_ALLOW_READ_ONLY_DIRECTORY , false ) ; final DirectoryChooserFragment fragment = DirectoryChooserFragment . newInstance ( newDirName , initialDir , allowReadOnlyDir ) ;", "del_tokens": "final DirectoryChooserFragment fragment = DirectoryChooserFragment . newInstance ( newDirName , initialDir ) ;", "commit_type": "allow"}
{"commit_tokens": ["Allow", "programmatic", "registration", "of", "adapters", "and", "resource", "creators", "."], "add_tokens": "import io . fabric8 . kubernetes . client . dsl . ClientLoggableResource ; ExtensionAdapter < T > adapter = Adapters . get ( type ) ; if ( adapter != null ) { return adapter . adapt ( this ) ;", "del_tokens": "import io . fabric8 . kubernetes . client . dsl . ClientLoggableResource ; import java . util . Map ; import java . util . ServiceLoader ; private static Map < String , ResourceCreator > resourceCreatorMap ; for ( ExtensionAdapter < T > adapter : ServiceLoader . load ( ExtensionAdapter . class ) ) { if ( adapter . getExtensionType ( ) . isAssignableFrom ( type ) ) { return adapter . adapt ( this ) ; }", "commit_type": "allow"}
{"commit_tokens": ["create", "interface", "for", "errors", "from", "ATSD", "on", "SQL", "statement", "execution"], "add_tokens": "public class ErrorSection implements AtsdExceptionRepresentation { private List < ExceptionSection > exception = new ArrayList < > ( ) ; private final Map < String , Object > additionalProperties = new HashMap < > ( ) ; @ Override @ Override @ Override", "del_tokens": "public class ErrorSection { private List < ExceptionSection > exception = new ArrayList < ExceptionSection > ( ) ; private final Map < String , Object > additionalProperties = new HashMap < String , Object > ( ) ;", "commit_type": "create"}
{"commit_tokens": ["added", "test", "case", "for", "GO_TO_SLEEP"], "add_tokens": "// public void testGoToSleep() throws IOException // { // try // { // proto.goToSleep(); // System.out.println(\"Backend OK with sleep command\"); // } // catch (CommandException e) // { // System.out.println(\"Backend refused sleep command: \" + e.getMessage()); // } // } // // @Test", "del_tokens": "@ Test public void testGoToSleep ( ) throws IOException { // TODO }", "commit_type": "add"}
{"commit_tokens": ["Changed", "FileChooser", "behaviour", "(", "see", "long", "desc", ".", ")"], "add_tokens": "if ( selectionMode == SelectionMode . FILES ) showDialog ( locale . popupChooseFile ) ; else { Array < FileHandle > files = new Array < FileHandle > ( ) ; files . add ( currentDirectory ) ; notifyListnerAndCloseDialog ( files ) ; }", "del_tokens": "showDialog ( locale . popupChooseFile ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "bug", "where", "getActionBarHeight", "would", "throw", "a", "ResourcesNotFoundException", "if", "custom", "value", "was", "set", "for", "android", ":", "actionBarSize", "in", "the", "theme", "."], "add_tokens": "result = TypedValue . complexToDimensionPixelSize ( tv . data , context . getResources ( ) . getDisplayMetrics ( ) ) ;", "del_tokens": "result = context . getResources ( ) . getDimensionPixelSize ( tv . resourceId ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "javadoc", "and", "version", "def"], "add_tokens": "* Provides support for Groovy 2.0 . return new Version ( 2 , 0 , 0 , \"beta-1\" ) ;", "del_tokens": "* Provides support for Groovy 1.9 . return new Version ( 1 , 8 , 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "spark", "jvm", "metrics", "and", "rename", "tag", "to", "source"], "add_tokens": "@ Test public void jvmName1 ( ) { final String name = \"12345-1-2-3-4-5.<driver>.jvm.non-heap.max\" ; final Id expected = new DefaultId ( \"spark.non-heap.max\" ) . withTag ( \"role\" , \"driver\" ) . withTag ( \"source\" , \"jvm\" ) . withTag ( \"appId\" , \"12345-1-2-3-4-5\" ) ; assertEquals ( expected , f . apply ( name ) ) ; } @ Test public void jvmName2 ( ) { final String name = \"20150626-185518-1776258826-5050-2845-S1.jvm.non-heap.max\" ; final Id expected = new DefaultId ( \"spark.non-heap.max\" ) . withTag ( \"source\" , \"jvm\" ) . withTag ( \"appId\" , \"20150626-185518-1776258826-5050-2845-S1\" ) ; assertEquals ( expected , f . apply ( name ) ) ; } @ Test . withTag ( \"source\" , \"BlockManager\" ) . withTag ( \"source\" , \"DAGScheduler\" ) . withTag ( \"source\" , \"DAGScheduler\" ) . withTag ( \"source\" , \"StreamingMetrics\" ) . withTag ( \"source\" , \"StreamingMetrics\" ) . withTag ( \"source\" , \"StreamingMetrics\" )", "del_tokens": "@ Test . withTag ( \"driver\" , \"BlockManager\" ) . withTag ( \"driver\" , \"DAGScheduler\" ) . withTag ( \"driver\" , \"DAGScheduler\" ) . withTag ( \"driver\" , \"StreamingMetrics\" ) . withTag ( \"driver\" , \"StreamingMetrics\" ) . withTag ( \"driver\" , \"StreamingMetrics\" )", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "XLog", "initialized", "before", "use"], "add_tokens": "import com . elvishew . xlog . internal . util . StackTraceUtil ; / * * * Throw an IllegalStateException if not initialized . * / static void assertInitialization ( ) { if ( ! sIsInitialized ) { throw new IllegalStateException ( \"Do you forget to initialize XLog?\" ) ; } } assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ; assertInitialization ( ) ;", "del_tokens": "import com . elvishew . xlog . internal . util . StackTraceUtil ;", "commit_type": "make"}
{"commit_tokens": ["added", "support", "of", "adding", "and", "editing", "of", "anchors", "for", "topics"], "add_tokens": "public Topic findTopicForLink ( final ExtraTopic link ) { if ( link == null ) return null ; return this . root . findForAttribute ( ExtraTopic . TOPIC_UID_ATTR , link . getValue ( ) ) ;", "del_tokens": "public Topic findTopicForUID ( final String topicUID ) { return this . root . findForAttribute ( \"uid\" , topicUID ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "position", "and", "add", "default", "0", "value", "for", "k", "-", "safety", "factor", "argument", "to"], "add_tokens": "if ( args . length < 5 || args . length > 6 ) { System . err . println ( \"VoltCompiler [project file] [hosts] [sites per host] [leader IP] [output JAR] [k-safety factor (optional/future)] \" ) ; final String leaderAddress = args [ 3 ] ; final String outputJar = args [ 4 ] ; int k_factor = 0 ; if ( args . length == 6 ) { k_factor = Integer . parseInt ( args [ 5 ] ) ; }", "del_tokens": "if ( args . length != 6 ) { System . err . println ( \"VoltCompiler [project file] [hosts] [sites per host] [k-safety factor] [leader IP] [output JAR]\" ) ; final int k_factor = Integer . parseInt ( args [ 3 ] ) ; final String leaderAddress = args [ 4 ] ; final String outputJar = args [ 5 ] ;", "commit_type": "move"}
{"commit_tokens": ["Use", "checkAndFetch", "()", "where", "possible"], "add_tokens": "HttpEntity entity = checkAndFetch ( response , url ) ; socket . setEnabledProtocols ( protocols . toArray ( new String [ 0 ] ) ) ; }", "del_tokens": "int statusCode = response . getStatusLine ( ) . getStatusCode ( ) ; if ( statusCode != 200 ) { String msg = \"Had HTTP StatusCode \" + statusCode + \" for request: \" + url + \", response: \" + response . getStatusLine ( ) . getReasonPhrase ( ) ; log . warning ( msg ) ; throw new IOException ( msg ) ; } HttpEntity entity = response . getEntity ( ) ; socket . setEnabledProtocols ( protocols . toArray ( new String [ protocols . size ( ) ] ) ) ; }", "commit_type": "use"}
{"commit_tokens": ["Improve", "color", "overriding", ":", "add", "dark", "and", "actionbar", "overriding"], "add_tokens": "private final int mExplicitColorDark ; private final int mExplicitColorActionBar ; mExplicitColorActionBar = 0 ; mExplicitColorActionBar = 0 ; public AccentResources ( Context c , Resources resources , int color , int colorDark , int colorActionBar ) { mExplicitColorActionBar = colorActionBar ; initialize ( mContext , mExplicitColor , mExplicitColorDark , mExplicitColorActionBar ) ; private synchronized void initialize ( Context c , int explicitColor , int explicitColorDark , int explicitColorActionBar ) { mPalette = initPalette ( c , explicitColor , explicitColorDark , explicitColorActionBar ) ; private AccentPalette initPalette ( Context c , int explicitColor , int explicitColorDark , int explicitColorActionBar ) { int colorActionBar = explicitColorActionBar != 0 ? explicitColorActionBar : attrs . getColor ( R . styleable . HoloAccent_accentColorActionBar , color ) ;", "del_tokens": "private final int mExplicitColorDark ; public AccentResources ( Context c , Resources resources , int color , int colorDark ) { initialize ( mContext , mExplicitColor , mExplicitColorDark ) ; private synchronized void initialize ( Context c , int explicitColor , int explicitColorDark ) { mPalette = initPalette ( c , explicitColor , explicitColorDark ) ; private AccentPalette initPalette ( Context c , int explicitColor , int explicitColorDark ) { int colorActionBar = explicitColorDark != 0 ? explicitColorDark : attrs . getColor ( R . styleable . HoloAccent_accentColorActionBar , holoBlue ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "validator", "based", "on", "JSON", "annotation"], "add_tokens": "import com . microsoft . rest . Validator ; Validator . validate ( body , Salmon . class ) ; client . getPolymorphism ( ) . putValidMissingRequired ( body ) ; } catch ( NullPointerException ex ) { Assert . assertTrue ( ex . getMessage ( ) . contains ( \"birthday == null\" ) ) ;", "del_tokens": "import com . microsoft . rest . ServiceException ; import org . junit . Ignore ; @ Ignore ( \"Pending validation work\" ) client . getPolymorphism ( ) . putValid ( body ) ; } catch ( ServiceException ex ) {", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "forcing", "the", "plugin", "to", "run", "on", "pom", "packaged", "projects"], "add_tokens": "/ * * * Specifies whether the execution in pom projects should be skipped . * Override this value to false if you want to force the plugin to run on 'pom' packaged projects . * * @ parameter expression = \"${git.skipPoms}\" default - value = \"true\" * / private boolean skipPoms ; if ( isPomProject ( project ) && skipPoms ) {", "del_tokens": "if ( isPomProject ( project ) ) {", "commit_type": "add"}
{"commit_tokens": ["Removing", "HibernateProxyInitializer", "class", "of", "some", "tests"], "add_tokens": "import br . com . caelum . vraptor . serialization . NullProxyInitializer ; this . serialization = new XStreamJSONPSerialization ( response , new DefaultTypeNameExtractor ( ) , new NullProxyInitializer ( ) , XStreamBuilderImpl . cleanInstance ( ) ) ;", "del_tokens": "import br . com . caelum . vraptor . serialization . HibernateProxyInitializer ; this . serialization = new XStreamJSONPSerialization ( response , new DefaultTypeNameExtractor ( ) , new HibernateProxyInitializer ( ) , XStreamBuilderImpl . cleanInstance ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Created", "AbstractMaps", "to", "inherit", "toString", "()"], "add_tokens": "* fastUtil 1.12 : Fast & compact specialized hash - based utility classes for Java", "del_tokens": "* fastUtil 1.11 : Fast & compact specialized hash - based utility classes for Java", "commit_type": "create"}
{"commit_tokens": ["change", "ClassTaxonomy", "to", "an", "abstract", "class", "that", "provides", "some", "basic", "hashing", "functions", "for", "testing", "purposes"], "add_tokens": "class ConcurrentClassTaxonomy extends ClassTaxonomy {", "del_tokens": "class ConcurrentClassTaxonomy implements ClassTaxonomy {", "commit_type": "change"}
{"commit_tokens": ["use", "default", "annoation", "instance", "creator", "in", "PerformanceTestRunnerJUnit"], "add_tokens": "import de . dagere . kopeme . annotations . AnnotationDefaults ; private static final PerformanceTestingClass DEFAULTPERFORMANCETESTINGCLASS = AnnotationDefaults . of ( PerformanceTestingClass . class ) ;", "del_tokens": "import java . lang . annotation . Annotation ; private static final PerformanceTestingClass DEFAULTPERFORMANCETESTINGCLASS = new PerformanceTestingClass ( ) { @ Override public Class < ? extends Annotation > annotationType ( ) { return PerformanceTestingClass . class ; } @ Override public int overallTimeout ( ) { try { return ( int ) PerformanceTestingClass . class . getMethod ( \"overallTimeout\" ) . getDefaultValue ( ) ; } catch ( NoSuchMethodException | SecurityException e ) { e . printStackTrace ( ) ; } return 100 ; } @ Override public boolean logFullData ( ) { try { return ( boolean ) PerformanceTestingClass . class . getMethod ( \"logFullData\" ) . getDefaultValue ( ) ; } catch ( NoSuchMethodException | SecurityException e ) { e . printStackTrace ( ) ; } return false ; } } ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "CouchbaseLite", "header", "and", "renamed", "NativeLibraryLoader"], "add_tokens": "// CouchbaseLite.java // NativeLibrary . load ( ) ;", "del_tokens": "NativeLibraryLoader . load ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "TODO", "to", "calculate", "median", "correctly", "."], "add_tokens": "int n = measurements . length ; return ( n % 2 == 0 ) ? ( measurements [ n / 2 - 1 ] + measurements [ n / 2 ] ) / 2 : measurements [ n / 2 ] ;", "del_tokens": "// TODO: average middle two if the set is even-sized return measurements [ measurements . length / 2 ] ;", "commit_type": "implement"}
{"commit_tokens": ["added", "test", "for", "statically", "generated", "site"], "add_tokens": "private boolean keepLines = true ;", "del_tokens": "private boolean keepLines = false ;", "commit_type": "add"}
{"commit_tokens": ["make", "gw", "work", "on", "remote", "rr", "and", "request", "stream"], "add_tokens": "@ ServiceMethod ( \"one\" )", "del_tokens": "@ ServiceMethod ( \"hello\" )", "commit_type": "make"}
{"commit_tokens": ["Change", "the", "UTF8_CHARSET", "property", "into", "a", "String", "for", "better", "JVM", "compatibility", "."], "add_tokens": "import java . io . UnsupportedEncodingException ; public static final String UTF8_CHARSET = \"UTF-8\" ; try { textFrame = new String ( this . currentFrame . array ( ) , UTF8_CHARSET ) ; } catch ( UnsupportedEncodingException ex ) { // TODO: Fire an 'onError' handler here ex . printStackTrace ( ) ; textFrame = \"\" ; }", "del_tokens": "public static final Charset UTF8_CHARSET = Charset . forName ( \"UTF-8\" ) ; textFrame = new String ( this . currentFrame . array ( ) , UTF8_CHARSET ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "whatsnew", "need", "to", "test", "further"], "add_tokens": "import java . nio . file . FileVisitResult ; import java . nio . file . Files ; import java . nio . file . Path ; import java . nio . file . Paths ; import java . nio . file . SimpleFileVisitor ; import javax . xml . bind . JAXB ; import com . sun . javafx . application . ParametersImpl ; String whatsnew = null ; // configure the whats-new option if ( named . containsKey ( \"whats-new\" ) ) whatsnew = named . get ( \"whats-new\" ) ;", "del_tokens": "import com . sun . javafx . application . ParametersImpl ; import javax . xml . bind . JAXB ; import java . nio . file . * ;", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "to", "allow", "/", "block", "opening", "and", "saving", "operations", "."], "add_tokens": "if ( editor . isOpenEnabled ( ) ) { try { if ( editor . getFile ( ) == null ) { String fileName = editor . readLine ( \"Save to file:\" ) ; editor . save ( new File ( fileName ) ) ; } else { editor . save ( null ) ; } undoContext . clear ( ) ; editor . setDirty ( false ) ; } catch ( IOException e ) { //noop", "del_tokens": "try { if ( editor . getFile ( ) == null ) { String fileName = editor . readLine ( \"Save to file:\" ) ; editor . save ( new File ( fileName ) ) ; } else { editor . save ( null ) ; undoContext . clear ( ) ; editor . setDirty ( false ) ; } catch ( IOException e ) { //noop", "commit_type": "add"}
{"commit_tokens": ["Added", "state", "new", "to", "the", "HistoryDetails", ".", "isReady", "()", "method"], "add_tokens": "return ! ( state . equals ( \"running\" ) || state . equals ( \"queued\" ) || state . equals ( \"new\" ) ) ;", "del_tokens": "return ! ( state . equals ( \"running\" ) || state . equals ( \"queued\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "attempt", "test", "to", "reflect", "housekeeping", "."], "add_tokens": "assertEquals ( 2 , attempts . values ( ) . toArray ( ) [ 1 ] ) ; assertEquals ( 2 , attempts . values ( ) . toArray ( ) [ 2 ] ) ; attemptsJSON = store . getAttempts ( TEST_PROJECT . getProjectId ( ) , TEST_COLLECTION ) ; assertNotNull ( attemptsJSON ) ; attempts = JSON_MAPPER . readValue ( attemptsJSON , Map . class ) ; assertEquals ( 3 , attempts . entrySet ( ) . size ( ) ) ; assertEquals ( 0 , attempts . values ( ) . toArray ( ) [ 0 ] ) ; assertEquals ( 0 , attempts . values ( ) . toArray ( ) [ 1 ] ) ; assertEquals ( 0 , attempts . values ( ) . toArray ( ) [ 2 ] ) ; assertEquals ( 0 , attempts . entrySet ( ) . size ( ) ) ;", "del_tokens": "assertEquals ( 3 , attempts . entrySet ( ) . size ( ) ) ; assertEquals ( - 1 , attempts . values ( ) . toArray ( ) [ 0 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["move", "newNumber", "to", "ConfigNumber", "rather", "than", "AbstractConfigValue"], "add_tokens": "return newValue ( ConfigNumber . newNumber ( origin , value , return newValue ( ConfigNumber . newNumber ( origin , value , return newValue ( ConfigNumber . newNumber ( origin , value ,", "del_tokens": "return newValue ( AbstractConfigValue . newNumber ( origin , value , return newValue ( AbstractConfigValue . newNumber ( origin , value , return newValue ( AbstractConfigValue . newNumber ( origin , value ,", "commit_type": "move"}
{"commit_tokens": ["added", "new", "demos", "for", "UTCTimeBox", "and", "UTCDateTimeRangeController"], "add_tokens": "import com . google . gwt . i18n . client . DateTimeFormat . PredefinedFormat ; this ( DateTimeFormat . getFormat ( PredefinedFormat . DATE_MEDIUM ) ) ; public static final Long getValueForToday ( ) { return trimTimeToMidnight ( date2utc ( new Date ( ) ) ) ; }", "del_tokens": "init ( new DateBox ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "reduced", "bit", "serialization", "methods", "."], "add_tokens": "public final int read24Bit ( ) throws Exception { return ( ( buffer [ position ++ ] & 0xFF ) << 16 ) | ( ( buffer [ position ++ ] & 0xFF ) << 8 ) | ( buffer [ position ++ ] & 0xFF ) ; } public final long read56Bit ( ) throws Exception { return ( ( ( long ) ( buffer [ position ++ ] & 255 ) << 48 ) + ( ( long ) ( buffer [ position ++ ] & 255 ) << 40 ) + ( ( long ) ( buffer [ position ++ ] & 255 ) << 32 ) + ( ( long ) ( buffer [ position ++ ] & 255 ) << 24 ) + ( ( buffer [ position ++ ] & 255 ) << 16 ) + ( ( buffer [ position ++ ] & 255 ) << 8 ) + ( buffer [ position ++ ] & 255 ) ) ; } + ( ( buffer [ position ++ ] & 255 ) << 8 ) + ( buffer [ position ++ ] & 255 ) ) ;", "del_tokens": "+ ( ( buffer [ position ++ ] & 255 ) << 8 ) + ( ( buffer [ position ++ ] & 255 ) << 0 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "roundtrip", "verification", "to", "equivs", "tests", "."], "add_tokens": "import software . amazon . ion . junit . IonAssert ; treeReader = system ( ) . newReader ( datagram ) ; byte [ ] encoded = datagram . getBytes ( ) ; IonReader binaryReader = system ( ) . newReader ( encoded ) ; ReaderCompare . compare ( treeReader , binaryReader ) ;", "del_tokens": "// Pass 4: Encode to binary, and use Reader if ( ! myFileIsBinary ) { // Check the encoding of text to binary. treeReader = system ( ) . newReader ( datagram ) ; byte [ ] encoded = datagram . getBytes ( ) ; IonReader binaryReader = system ( ) . newReader ( encoded ) ; ReaderCompare . compare ( treeReader , binaryReader ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "parameters", "part", "of", "name"], "add_tokens": "Pattern pattern = Pattern . compile ( \"(.*)(\\\\[.*\\\\])\" ) ; Matcher matcher = pattern . matcher ( result ) ; String params = \"\" ; if ( matcher . matches ( ) ) { result = matcher . group ( 1 ) ; params = ' ' + matcher . group ( 2 ) ; } result = simplify ( result ) ; result = splitCamelCaseWordsWithLowdashes ( result ) ; result = lowdashesToSpaces ( result ) ; return result + params ; } public static String lowdashesToSpaces ( String text ) { return text . replaceAll ( \"(_)+\" , \" \" ) ; } public static String simplify ( String text ) { return text . replaceAll ( \".*\\\\.([^.]+)\" , \"$1\" ) ; public static String splitCamelCaseWordsWithLowdashes ( String camelCaseString ) {", "del_tokens": "result = result . replaceAll ( \".*\\\\.([^.^0-9]+)\" , \"$1\" ) ; result = result . replaceAll ( \"((.*\\\\D)|(^))\\\\.([0-9][^.]+)\" , \"$4\" ) ; result = splitCamelCase ( result ) ; result = result . replaceAll ( \"(_)+\" , \" \" ) ; return result ; public static String splitCamelCase ( String camelCaseString ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "version", "150", "changed", "version", "testing", "in", "regexp"], "add_tokens": "if ( ( state . cx . getLanguageVersion ( ) != Context . VERSION_DEFAULT ) && ( state . cx . getLanguageVersion ( ) <= Context . VERSION_1_4 ) ) { if ( ( state . cx . getLanguageVersion ( ) ! = Context . VERSION_DEFAULT ) && ( state . cx . getLanguageVersion ( ) <= Context . VERSION_1_4 ) )", "del_tokens": "if ( state . cx . getLanguageVersion ( ) == Context . VERSION_1_2 ) { if ( state . cx . getLanguageVersion ( ) == Context . VERSION_1_2 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "of", "error", "response"], "add_tokens": "error = InstagramErrorResponse . parse ( gson , response . getBody ( ) ) ; error = InstagramErrorResponse . parse ( gson , response . getBody ( ) ) ;", "del_tokens": "error = gson . fromJson ( response . getBody ( ) , InstagramErrorResponse . class ) ; error = gson . fromJson ( response . getBody ( ) , InstagramErrorResponse . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "Args", "for", "null", "checking", "."], "add_tokens": "import org . jfree . graphics2d . Args ; Args . nullNotPermitted ( f , \"f\" ) ;", "del_tokens": "if ( f == null ) { throw new IllegalArgumentException ( \"Null 'f' argument.\" ) ; }", "commit_type": "use"}
{"commit_tokens": ["Fixed", ":", "using", "appropriate", "GCJ", "instantiator"], "add_tokens": "} else if ( JVM_NAME . startsWith ( GNU ) ) { return new GCJSerializationInstantiator ( type ) ; }", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["Add", "scanning", "for", "configuration", "classes", "by", "marker", "annotations"], "add_tokens": "return Collections . emptyList ( ) ;", "del_tokens": "return null ;", "commit_type": "add"}
{"commit_tokens": ["Created", "ManifestHelper", "and", "moved", "AndroidManifest", "metadata", "read", "methods", "from", "SugarConfig", "to", "ManifestHelper"], "add_tokens": "import com . orm . util . ManifestHelper ; import static com . orm . util . ManifestHelper . getDatabaseVersion ; import static com . orm . util . ManifestHelper . getDebugEnabled ; super ( context , ManifestHelper . getDatabaseName ( context ) ,", "del_tokens": "import com . orm . util . SugarConfig ; import static com . orm . util . SugarConfig . getDatabaseVersion ; import static com . orm . util . SugarConfig . getDebugEnabled ; super ( context , SugarConfig . getDatabaseName ( context ) ,", "commit_type": "create"}
{"commit_tokens": ["Add", "a", "size", "()", "method", "to", "the", "dictionary", "interface", "."], "add_tokens": "* / * * * Get the number of sequences in the automaton . This method is slow for * { @ link Dictionary } instances , since it needs to traverse the automaton . * * @ return Number of sequences . * / public int size ( ) { int nSeqs = 0 ; Iterator < CharSequence > iter = iterator ( ) ; while ( iter . hasNext ( ) ) { ++ nSeqs ; iter . next ( ) ; } return nSeqs ; } * * * *", "del_tokens": "* * * * *", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "getting", "revisions"], "add_tokens": "return revEntity ;", "del_tokens": "return entity ;", "commit_type": "fix"}
{"commit_tokens": ["removing", "buggy", "test", "(", "original", "fsa_morph", "does", "nothing", "like", "that", "-", "this", "disables", "proper", "synthesis", ")"], "add_tokens": "if ( encodedBase . length ( ) > 0 ) if ( encodedBase . length ( ) > 1 ) if ( encodedBase . length ( ) > 2 )", "del_tokens": "if ( encodedBase . length ( ) > 0 && Character . isUpperCase ( encodedBase . charAt ( 0 ) ) ) if ( encodedBase . length ( ) > 1 && Character . isUpperCase ( encodedBase . charAt ( 0 ) ) ) if ( encodedBase . length ( ) > 2 && Character . isUpperCase ( encodedBase . charAt ( 0 ) ) )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "missing", "default", "values", "for", "schematronDirectory", "and", "xsltDirectory", "."], "add_tokens": "* default - value = \"${basedir}/src/main/schematron\" * @ parameter property = \"xsltDirectory\" default - value = \"${basedir}/src/main/xslt\"", "del_tokens": "* default = \"${basedir}/src/main/schematron\" * @ parameter property = \"xsltDirectory\" default = \"${basedir}/src/main/xslt\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "deserializing", "BigInteger", "/", "BigDecimal", "from", "String"], "add_tokens": "final BigInteger bigInteger ; if ( vpack . isString ( ) ) { bigInteger = new BigInteger ( vpack . getAsString ( ) ) ; } else { bigInteger = vpack . getAsBigInteger ( ) ; } return bigInteger ; final BigDecimal bigDecimal ; if ( vpack . isString ( ) ) { bigDecimal = new BigDecimal ( vpack . getAsString ( ) ) ; } else { bigDecimal = vpack . getAsBigDecimal ( ) ; } return bigDecimal ; final VPackSlice parent , final VPackSlice vpack , final VPackDeserializationContext context ) {", "del_tokens": "return vpack . getAsBigInteger ( ) ; return vpack . getAsBigDecimal ( ) ; final VPackSlice parent , final VPackSlice vpack , final VPackDeserializationContext context ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "generator", "for", "C", "++", "trypes"], "add_tokens": "private final File templatesFolder ; private final File outputFolder ; private final Configuration cfg ; @ Override root . put ( \"getCppObjectType\" , new CppObjectType ( ) ) ;", "del_tokens": "private File templatesFolder ; private File outputFolder ; private Configuration cfg ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "MOJO", "-", "1438", ":", "Validate", "and", "transform", "don", "t", "use", "resolver", "to", "resolve", "doctype", "declaration", "in", "source", "files"], "add_tokens": "validator . validate ( new StreamSource ( pFile ) ) ; try { spf . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ) ; } catch ( SAXException e ) { // Ignore this } catch ( ParserConfigurationException e ) { // Ignore this } final File [ ] files = getFiles ( pValidationSet . getDir ( ) , pValidationSet . getIncludes ( ) ,", "del_tokens": "pSchema . newValidator ( ) . validate ( new StreamSource ( pFile ) ) ; try { spf . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ) ; } catch ( SAXException e ) { // Ignore this } catch ( ParserConfigurationException e ) { // Ignore this } final File [ ] files = getFiles ( pValidationSet . getDir ( ) , pValidationSet . getIncludes ( ) ,", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "elements", "by", "default", "just", "take", "first", "."], "add_tokens": "return findElement ( false , by ) ; } public WebElement findElement ( boolean atMostOne , By by ) { if ( elements . size ( ) == 1 || ! atMostOne ) {", "del_tokens": "if ( elements . size ( ) == 1 ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "getResult", "()", "method", "on", "Connection", "class", "which", "will", "return", "number", "of", "affected", "rows", "after", "an", "executeUpdate", "()", "call", "."], "add_tokens": "this . connection . setResultInternal ( statement . executeUpdate ( ) ) ;", "del_tokens": "int result ; result = statement . executeUpdate ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "keep", "alive", "mechanism", "."], "add_tokens": "import org . jgrapes . core . internal . GeneratorRegistry ; / * * * Wait until all generators and event queues are exhausted . When this * stage is reached , nothing can happen anymore unless a new event is * sent from an external thread . * * @ throws InterruptedException * / public static void awaitExhaustion ( ) throws InterruptedException { GeneratorRegistry . getInstance ( ) . awaitExhaustion ( ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "loadFromFile", "fallback", "if", "file", "does", "not", "exist"], "add_tokens": "return buildFromSettings ( ) ; } else if ( ! this . file . exists ( ) || ! this . file . isFile ( ) ) { return buildFromSettings ( ) ; final IntervalTree tree = new IntervalTree ( ) ; final IntervalTreeConfiguration configuration = new IntervalTreeConfiguration ( ) ; return tree ; } protected IntervalTree buildFromSettings ( ) { final IntervalTree tree = new IntervalTree ( ) ; final IntervalTreeConfiguration configuration = new IntervalTreeConfiguration ( ) ; configuration . setAutoBalancing ( this . autoBalancing ) ; configuration . setValueComparator ( this . valueComparator ) ; configuration . setIntervalFilter ( this . filter ) ; configuration . setWritingCollectionsToFile ( this . writeCollections ) ; configuration . setFactory ( this . factory ) ; configuration . setPersistor ( this . persistor ) ; tree . setConfiguration ( configuration ) ;", "del_tokens": "final IntervalTree tree = new IntervalTree ( ) ; // set the configuration final IntervalTreeConfiguration configuration = new IntervalTreeConfiguration ( ) ; configuration . setAutoBalancing ( this . autoBalancing ) ; configuration . setValueComparator ( this . valueComparator ) ; configuration . setIntervalFilter ( this . filter ) ; configuration . setWritingCollectionsToFile ( this . writeCollections ) ; configuration . setFactory ( this . factory ) ; configuration . setPersistor ( this . persistor ) ; tree . setConfiguration ( configuration ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "getting", "the", "title", "of", "some", "docbook", "element", "wouldn", "t", "render", "any", "child", "elements", "properly", "."], "add_tokens": "return XMLUtilities . convertNodeToString ( node , false ) ;", "del_tokens": "return ( ( Element ) node ) . getTextContent ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unused", "references", "to", "Context"], "add_tokens": "public OpenStreetMapTileDownloader ( final OpenStreetMapTileFilesystemProvider aMapTileFSProvider ) {", "del_tokens": "import android . content . Context ; protected final Context mCtx ; public OpenStreetMapTileDownloader ( final Context ctx , final OpenStreetMapTileFilesystemProvider aMapTileFSProvider ) { this . mCtx = ctx ;", "commit_type": "remove"}
{"commit_tokens": ["update", "maven", "libraries", "and", "remove", "guava", "restriction"], "add_tokens": "import org . apache . maven . model . Build ; import org . apache . maven . plugin . testing . stubs . MavenProjectStub ; final MavenProject project = new ProjectStub ( pom ) ; // for some reason the superclass method newMavenSession() does not copy properties from the // project model to the session. This is needed for the use of ExpressionEvaluator in BuildMojo. session . getRequest ( ) . setUserProperties ( project . getModel ( ) . getProperties ( ) ) ;", "del_tokens": "final MavenExecutionRequest executionRequest = new DefaultMavenExecutionRequest ( ) ; final ProjectBuildingRequest buildingRequest = executionRequest . getProjectBuildingRequest ( ) ; final ProjectBuilder projectBuilder = this . lookup ( ProjectBuilder . class ) ; final MavenProject project = projectBuilder . build ( pom , buildingRequest ) . getProject ( ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "test", "for", "new", "request", "object"], "add_tokens": "Router . mapRequest ( Methods . POST ) . toUrl ( \"/post\" ) . onClassAndMethod ( ApplicationController . class , \"post\" ) ; Router . mapRequest ( Methods . PUT ) . toUrl ( \"/put\" ) . onClassAndMethod ( ApplicationController . class , \"put\" ) ; Router . mapRequest ( Methods . POST ) . toUrl ( \"/jsonpathpost\" ) . onClassAndMethod ( ApplicationController . class , \"post\" ) ; Router . mapRequest ( Methods . PUT ) . toUrl ( \"/jsonpathput\" ) . onClassAndMethod ( ApplicationController . class , \"put\" ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "unit", "tests", "and", "length", "calculator", "for", "enclosing", "bounding", "box"], "add_tokens": "import static com . github . davidmoten . geo . GeoHash . hashLengthToEncloseBoundingBox ; public void testCoverBoundingBoxWithHashLength4AroundBoston ( ) { @ Test public void testEnclosingHashLengthAroundBoston ( ) { int length = hashLengthToEncloseBoundingBox ( SCHENECTADY_LAT , SCHENECTADY_LON , HARTFORD_LAT , HARTFORD_LON ) ; Set < String > hashes = hashesToCoverBoundingBoxWithHashLength ( SCHENECTADY_LAT , SCHENECTADY_LON , HARTFORD_LAT , HARTFORD_LON , length ) ; assertEquals ( Sets . newHashSet ( \"dr\" ) , hashes ) ; } @ Test public void testCoverBoundingBoxWithHashLength3AroundBoston ( ) { Set < String > hashes = hashesToCoverBoundingBoxWithHashLength ( SCHENECTADY_LAT , SCHENECTADY_LON , HARTFORD_LAT , HARTFORD_LON , 3 ) ; assertEquals ( Sets . newHashSet ( \"dr7\" , \"dre\" , \"drk\" , \"drs\" ) , hashes ) ; }", "del_tokens": "public void testCoverBoundingBoxWithHashLengthAroundBoston ( ) {", "commit_type": "add"}
{"commit_tokens": ["updated", "api", "response", ";", "update", "to", "gradle"], "add_tokens": "public static final String VERSION = \"2017-05-19\" ;", "del_tokens": "public static final String VERSION = \"2017-02-16\" ;", "commit_type": "update"}
{"commit_tokens": ["Implemented", "more", "comprehensive", "assertions", "on", "attributes", "of", "a", "view", "selection", "."], "add_tokens": "@ Test public void testAttribute ( ) { TextView view = viewFactory . createTextView ( ) ; view . setText ( \"foo\" ) ; view . setTag ( \"bar\" ) ; assertThatSelection ( \"TextView\" , view ) . attribute ( \"text\" ) . containsOnly ( \"foo\" ) ; assertThatSelection ( \"TextView\" , view ) . attribute ( \"tag\" ) . containsOnly ( \"bar\" ) ; } @ Test public void testFailingAttributeOnEmptySelection ( ) { try { assertThatSelection ( \"ImageView\" , viewFactory . createTextView ( ) ) . attribute ( \"tag\" ) ; failHard ( ) ; } catch ( AssertionError ex ) { // expected } } assertThatSelection ( \"ImageView\" , view ) . hasAttributeEqualTo ( \"tag\" , \"foo\" ) ;", "del_tokens": "assertThatSelection ( \"ImageView\" , viewFactory . createTextView ( ) ) . hasAttributeEqualTo ( \"tag\" , \"foo\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "Override", "Model", "Feature", "in", "DAOClass", "generators"], "add_tokens": "sw . lnprint ( \"import \" + conf . metaDataPackageName + \".Table;\" ) ; sw . lnTabPrint ( \" set_Value(Table.\" + distinctHasOne [ i ] + \", \" + distinctHasOneVar + \");\" ) ; sw . lnTabPrint ( \" return (DAO_\" + distinctHasOneStr + \")get_Value(Table.\" + distinctHasOne [ i ] + \");\" ) ;", "del_tokens": "sw . lnTabPrint ( \" set_Value(\\\"\" + distinctHasOne [ i ] + \"\\\", \" + distinctHasOneVar + \");\" ) ; sw . lnTabPrint ( \" return (DAO_\" + distinctHasOneStr + \")get_Value(\\\"\" + distinctHasOne [ i ] + \"\\\");\" ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "proper", "handling", "of", "inner", "classes"], "add_tokens": "* } writer . end ( ) ; writer . end ( ) ; public void Basic ( ) throws IOException { @ Test public void Inner_Classes ( ) throws IOException { writer . beginClass ( testType ) ; writer . beginClass ( testType2 ) ; writer . end ( ) ; writer . beginConstructor ( new Parameter ( \"a\" , Types . STRING ) ) ; writer . end ( ) ; writer . end ( ) ; match ( \"/testInnerClasses\" , w . toString ( ) ) ; }", "del_tokens": "* } writer . end ( ) ; writer . end ( ) ; public void Basic ( ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["added", "warning", "on", "class", "header"], "add_tokens": "* WARNING this class is still a prototype . *", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "to", "upload", "files"], "add_tokens": "assertEquals ( \"Article ID doesn't match\" , Long . valueOf ( 123456789 ) , articles . get ( 0 ) . getArticleId ( ) ) ;", "del_tokens": "assertEquals ( \"Articles size doesn't match\" , 1 , articles . size ( ) ) ; assertEquals ( \"Wrong article ID\" , Long . valueOf ( 123456789L ) , articles . get ( 0 ) . getArticleId ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", ";", "refactor", ";", "add", "convenience", "methods"], "add_tokens": "RDFParser p = NanopubUtils . getParser ( format ) ;", "del_tokens": "import org . openrdf . rio . Rio ; import org . openrdf . rio . helpers . RDFaParserSettings ; RDFParser p = Rio . createParser ( format ) ; p . getParserConfig ( ) . set ( RDFaParserSettings . FAIL_ON_RDFA_UNDEFINED_PREFIXES , true ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "pointer", "instead", "of", "memory"], "add_tokens": "private final Pointer pointer ; Arguments ( final Pointer pointer ) { final Pointer memory = new Memory ( size * Pointer . SIZE ) ;", "del_tokens": "private final Memory pointer ; Arguments ( final Memory pointer ) { final Memory memory = new Memory ( size * Pointer . SIZE ) ; memory . clear ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "classfields", "key", "not", "unique"], "add_tokens": "if ( ( ! recClassInfo2 . seek ( \"=\" ) ) || ( strRecordClass == null ) || ( strRecordClass . length ( ) == 0 ) )", "del_tokens": "if ( ! recClassInfo2 . seek ( \"=\" ) )", "commit_type": "make"}
{"commit_tokens": ["fix", "bugs", "in", "histogram", "when", "there", "are", "null", "/", "NA", "in", "array"], "add_tokens": "private DDF ddf , ddf1 , mdf ; for ( int i = 0 ; i < bins . size ( ) ; i ++ ) { System . out . println ( bins . get ( i ) . getX ( ) + \" - \" + bins . get ( i ) . getY ( ) ) ; } //createTableMovie(); //mdf = manager.sql2ddf(\"select year, length, rating, votes from movie\"); //List<HistogramBin> bins = mdf.getVectorHistogram(\"length\", 5);", "del_tokens": "private DDF ddf , ddf1 ; System . out . println ( bins ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "aggregation", "functions", "for", "float"], "add_tokens": "import com . deathrayresearch . outlier . aggregator . NumReduceUtils ; public class FloatColumn extends AbstractColumn implements NumReduceUtils { RoaringBitmap isNonNegative ( ) { public double [ ] toDoubleArray ( ) { double [ ] output = new double [ data . length ] ; for ( int i = 0 ; i < data . length ; i ++ ) { output [ i ] = data [ i ] ; } return output ; }", "del_tokens": "public class FloatColumn extends AbstractColumn { RoaringBitmap isNoNegative ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "start", "of", "cql", "-", "to", "-", "elm", "project"], "add_tokens": "package org . cqframework . cql . cql2js ;", "del_tokens": "package org . cqframework . cql . cql2elm ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "that", "RedisDecoder", "could", "not", "parse", "long", "integerReply", "."], "add_tokens": "// 32 : 20(bytes of a maximum long) + 2(\\r\\n) + 1($ or *) this . lookasideBuffer = new byte [ 32 ] ;", "del_tokens": "// 16 : 11(bytes of a maximum integer) + 2(\\r\\n) + 1($ or *) this . lookasideBuffer = new byte [ 16 ] ;", "commit_type": "fix"}
{"commit_tokens": ["use", "abstract", "methods", "to", "simplify", "the", "dsl", "for", "java", "classes", "to", "work", "with"], "add_tokens": "public ConsumerInteractionJavaDsl given ( String providerState ) { return this ; public Interaction willRespondWith ( return this . build ( ) ;", "del_tokens": "ConsumerInteractionJavaDsl ( String providerState ) { } public static ConsumerInteractionJavaDsl given ( String providerState ) { return new ConsumerInteractionJavaDsl ( providerState ) ; public ConsumerInteractionJavaDsl willRespondWith ( return this ;", "commit_type": "use"}
{"commit_tokens": ["added", "Google", "+", "and", "LinkedIn", "authentication", "filters"], "add_tokens": "if ( user . getPicture ( ) == null ) { user . setPicture ( \"http://graph.facebook.com/\" + fbID + \"/picture?type=large\" ) ; }", "del_tokens": "// } else { // SecurityUtils.setAuthCookie(user, request, response);", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "the", "Support", "V8", "library", "for", "RenderScript"], "add_tokens": "import android . support . v8 . renderscript . Allocation ; import android . support . v8 . renderscript . Element ; import android . support . v8 . renderscript . RenderScript ; import android . support . v8 . renderscript . ScriptIntrinsicBlur ;", "del_tokens": "import android . renderscript . Allocation ; import android . renderscript . Element ; import android . renderscript . RenderScript ; import android . renderscript . ScriptIntrinsicBlur ;", "commit_type": "change"}
{"commit_tokens": ["create", "one", "context", "per", "instance"], "add_tokens": "private GenericXmlApplicationContext context = new GenericXmlApplicationContext ( ) ; System . out . println ( \"loading context\" ) ;", "del_tokens": "private GenericXmlApplicationContext context ; context = new GenericXmlApplicationContext ( ) ;", "commit_type": "create"}
{"commit_tokens": ["Move", "common", "function", "from", "builder", "to", "interface"], "add_tokens": "interface CommonBuilder < T > { / * * * Optional : Specifies { @ link GetResolver } for Get Operation * which allows you to customize behavior of Get Operation * < p > * Default value is instance of { @ link DefaultGetResolver } * * @ param getResolver get resolver * @ return builder * / @ NonNull T withGetResolver ( @ NonNull GetResolver getResolver ) ; } public static class Builder implements CommonBuilder < Builder > { @ Override public static class CompleteBuilder implements CommonBuilder < CompleteBuilder > { @ Override", "del_tokens": "public static class Builder { / * * * Optional : Specifies { @ link GetResolver } for Get Operation * which allows you to customize behavior of Get Operation * < p > * Default value is instance of { @ link DefaultGetResolver } * * @ param getResolver get resolver * @ return builder * / public static class CompleteBuilder { / * * * Optional : Specifies { @ link GetResolver } for Get Operation * which allows you to customize behavior of Get Operation * < p > * Default value is instance of { @ link DefaultGetResolver } * * @ param getResolver get resolver * @ return builder * /", "commit_type": "move"}
{"commit_tokens": ["removed", "use", "of", "deprecated", "code"], "add_tokens": "import org . apache . commons . text . StringEscapeUtils ;", "del_tokens": "import org . apache . commons . lang3 . StringEscapeUtils ;", "commit_type": "remove"}
{"commit_tokens": ["added", "msisdn", "to", "customer", "[", "release", "-", "type", "final", "]"], "add_tokens": "import javax . validation . constraints . NotNull ; import javax . validation . constraints . Pattern ; private String msisdn = null ; / * * * The customer 's Mobile Subscriber Integrated Services Digital Network-Number (MSISDN). This must conform to the ITU E.164 * numbering plan ( https : //www.itu.int/rec/T-REC-E.164/en) e.g. 27821234567 for a South African number. * * / public Customer msisdn ( String msisdn ) { this . msisdn = msisdn ; return this ; } @ ApiModelProperty ( required = true , value = \"This must conform to the ITU E.164 numbering plan (https://www.itu.int/rec/T-REC-E.164/en) e.g. 27821234567 for a South African number.\" ) @ Pattern ( regexp = \"^\\\\+?[1-9]\\\\d{0,14}\" ) @ JsonProperty ( \"msisdn\" ) @ NotNull public String getMsisdn ( ) { return msisdn ; } public void setMsisdn ( String msisdn ) { this . msisdn = msisdn ; } && Objects . equals ( status , customer . status ) && Objects . equals ( msisdn , customer . msisdn ) ; return Objects . hash ( firstName , lastName , address , dateOfBirth , status , msisdn ) ; sb . append ( \" msisdn: \" ) . append ( Utils . toIndentedString ( msisdn ) ) . append ( \"\\n\" ) ;", "del_tokens": "&& Objects . equals ( status , customer . status ) ; return Objects . hash ( firstName , lastName , address , dateOfBirth , status ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "to", "use", "client", "module", "."], "add_tokens": "import org . apache . http . impl . client . DefaultHttpClient ; import vcap . client . CfTokens ; import vcap . client . CloudController ; final CfTokens cfTokens = new CfTokens ( ) ; final CfTokens . CfToken target = cfTokens . getTargetToken ( ) ; LOGGER . info ( \"Using Cloud Controller at: {}\" , target . getTarget ( ) ) ; final String url = \"http://\" + localIp ( target . getTarget ( ) ) + \":\" + serverPort ; final CloudController cloudController = new CloudController ( new DefaultHttpClient ( ) , target . getTarget ( ) ) ;", "del_tokens": "import vcap . service . integration . CfUtil ; import vcap . service . integration . CloudControllerClient ; import vcap . service . integration . CreateAuthTokenRequest ; import vcap . service . integration . CreateServicePlanRequest ; import vcap . service . integration . CreateServiceRequest ; import java . util . HashMap ; final CfUtil . HostToken target = CfUtil . getTargetToken ( ) ; LOGGER . info ( \"Using Cloud Controller at: {}\" , target . getHost ( ) ) ; final String url = \"http://\" + localIp ( target . getHost ( ) ) + \":\" + serverPort ; final CloudControllerClient cloudControllerClient = new CloudControllerClient ( target . getHost ( ) , target . getToken ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "code", "for", "format", "tachyon", "fs", "."], "add_tokens": "delete ( src , true ) ; public void delete ( String f , boolean recursive ) { mFs . delete ( new Path ( f ) , recursive ) ;", "del_tokens": "delete ( new Path ( src ) , true ) ; public void delete ( Path f , boolean recursive ) { mFs . delete ( f , recursive ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "pair", "of", "UI", "bugs", "on", "RelationPage", "."], "add_tokens": "import java . io . Serializable ; public class Range implements Iterable < Integer > , Comparable < Range > , Serializable { private static final long serialVersionUID = - 5916908704306283230L ;", "del_tokens": "public class Range implements Iterable < Integer > , Comparable < Range > {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "specify", "a", "user", "s", "ExecutorService", "instance", "for", "launching", "."], "add_tokens": "import java . util . concurrent . Executor ; import java . util . concurrent . ExecutorService ; protected static final String DEFAULT_EXECUTOR_KEY = \"EXECUTOR\" ; / * * * The Executor service to use when launching the program * associated to this Launch * / private Executor executorService = null ; public Launch ( final Scheduler scheduler , final Class < ? > jobClass ) throws LaunchException { this ( scheduler , jobClass , null ) ; } public Launch ( final Scheduler scheduler , final Class < ? > jobClass , ExecutorService executorService ) this . executorService = executorService ; // If an ExecutorService was specified, // we put it in the JobDataMap to be able to use it when the program will be launched. if ( this . executorService != null ) { this . job . getJobDataMap ( ) . put ( DEFAULT_EXECUTOR_KEY , executorService ) ; }", "del_tokens": "public Launch ( final Scheduler scheduler , final Class < ? > jobClass )", "commit_type": "allow"}
{"commit_tokens": ["add", "logging", "of", "db", "result", "count"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger LOG = LoggerFactory . getLogger ( CassandraSampleRepository . class ) ; LOG . debug ( \"Querying database for resource {}, from {} to {}\" , resource , lower . minus ( resolution ) , upper ) ; Results < Measurement > results = new ResultProcessor ( resource , lower , upper , descriptor , resolution ) . process ( driverAdapter ) ; LOG . debug ( \"{} results returned from database\" , driverAdapter . getResultCount ( ) ) ; return results ; LOG . debug ( \"Querying database for resource {}, from {} to {}\" , resource , lower , upper ) ; DriverAdapter driverAdapter = new DriverAdapter ( cassandraSelect ( resource , lower , upper ) ) ; for ( Row < Sample > row : driverAdapter ) { LOG . debug ( \"{} results returned from database\" , driverAdapter . getResultCount ( ) ) ;", "del_tokens": "return new ResultProcessor ( resource , lower , upper , descriptor , resolution ) . process ( driverAdapter ) ; for ( Row < Sample > row : new DriverAdapter ( cassandraSelect ( resource , lower , upper ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["make", "guice", "-", "bridge", "dependency", "optional", ":", "support", "could", "be", "activated", "with", "UseHkBridge", "option"], "add_tokens": "GuiceFilterRegistration ( EnumSet . class , EnumSet . of ( DispatcherType . REQUEST ) ) , / * * * Enables guice bridge for hk to allow hk services to see guice beans . This is not often required and * so disabled by default . For example , it could be required if * { @ link ru . vyarus . dropwizard . guice . module . installer . feature . jersey . HK2Managed } used to properly instantiate * service by hk when it also depends on guice services . * < p > * IMPORTANT : requires extra dependency on hk2 guice - bridge : 'org.glassfish.hk2:guice-bridge:2.5.0-b32' * / UseHkBridge ( Boolean . class , false ) ;", "del_tokens": "GuiceFilterRegistration ( EnumSet . class , EnumSet . of ( DispatcherType . REQUEST ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Removed", "unncessary", "new", "line", "that", "is", "created", "automatically", "by", "the", "mapreduce", "TextOutputFormat"], "add_tokens": "// remove last separator (new line does not need to be added anymore, apperantly this is done by textoutputformat String currentCSVRowString = currentCSVRowSB . substring ( 0 , currentCSVRowSB . length ( ) - 1 ) ;", "del_tokens": "// remove last separator and add new line String currentCSVRowString = currentCSVRowSB . substring ( 0 , currentCSVRowSB . length ( ) - 1 ) + \"\\n\" ;", "commit_type": "remove"}
{"commit_tokens": ["use", "LinkedList", "because", "concurrency", "won", "t", "occur"], "add_tokens": "// log.info(\"requested=\" + n); // .onBackpressureBlock() . buffer ( Runtime . getRuntime ( ) . availableProcessors ( ) - 5 )", "del_tokens": "// log.info(\"requested=\" + n); // .onBackpressureBlock() . buffer ( Runtime . getRuntime ( ) . availableProcessors ( ) - 5 )", "commit_type": "use"}
{"commit_tokens": ["Added", "InstanceStateGson", "annotation", "to", "save", "state", "object", "using", "Gson"], "add_tokens": "package com . alexvasilkov . android . commons . state ;", "del_tokens": "package com . alexvasilkov . android . commons . utils ; public String value ( ) default \"\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "check", "to", "type", "discovery", "in", "MetaDataRegistry"], "add_tokens": "if ( collectionValueType != null ) { String typeName = NameUtil . getFormalName ( collectionValueType ) + \"[]\" ; propertyMetaData . setType ( typeName ) ; addHref ( propertyMetaData , collectionValueType , suffix ) ; }", "del_tokens": "String typeName = NameUtil . getFormalName ( collectionValueType ) + \"[]\" ; propertyMetaData . setType ( typeName ) ; addHref ( propertyMetaData , collectionValueType , suffix ) ;", "commit_type": "add"}
{"commit_tokens": ["Allowing", "overriding", "of", "properties", "and", "adding", "a", "external", "classpath", "."], "add_tokens": "import java . util . Arrays ; public static Props loadPropsInDir ( Props parent , File dir , String ... suffixes ) { Arrays . sort ( files ) ; public static Props loadProps ( Props parent , File ... propFiles ) { try { Props props = new Props ( parent ) ; for ( File f : propFiles ) { if ( f . isFile ( ) ) { props = new Props ( props , f ) ; } } return props ; } catch ( IOException e ) { throw new RuntimeException ( \"Error loading properties.\" , e ) ; } } parentProps . put ( \"azkaban.flow.start.milliseconds\" , loadTime . toString ( \"SSS\" ) ) ; parentProps . put ( \"azkaban.flow.start.timezone\" , loadTime . toString ( \"ZZZZ\" ) ) ;", "del_tokens": "public static Props loadPropsInDir ( Props parent , File dir , String ... suffixes ) { parentProps . put ( \"azkaban.flow.start.milliseconds\" , loadTime . toString ( \"SSS\" ) ) ; parentProps . put ( \"azkaban.flow.start.timezone\" , loadTime . toString ( \"ZZZZ\" ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "unit", "test", "logging", "to", "debug", "GitHub", "build", "issue"], "add_tokens": "assertTrue ( Files . exists ( extractionDirectory . resolve ( someSymbolicLinkFilename ) ) , \"Symbolic link wasn't created when extracting some-symbolic-link.txt\" + \".\" ) ; \"Extracted file 'some-file.txt' and the symbolic link 'some-symbolic-link.txt' contents should have matched.\" ) ; assertTrue ( Files . isSameFile ( extractionDirectory . resolve ( someFilename ) . toRealPath ( ) , extractionDirectory . resolve ( someSymbolicLinkFilename ) . toRealPath ( ) ) , \"The real path of the link=\" + extractionDirectory . resolve ( someSymbolicLinkFilename ) + \", realpath=\" + extractionDirectory . resolve ( someSymbolicLinkFilename ) . toRealPath ( ) + \" should have pointed to path=\" + extractionDirectory . resolve ( someFilename ) . toRealPath ( ) ) ; assertTrue ( Files . isSameFile ( extractionDirectory . resolve ( someFilename ) , extractionDirectory . resolve ( someSymbolicLinkFilename ) ) , \"The extracted file some-file.txt and the symbolic link some-symbolic-link.txt should be the same file.\" ) ;", "del_tokens": "assertTrue ( Files . exists ( extractionDirectory . resolve ( someSymbolicLinkFilename ) ) , \"Symbolic link wasn't created when extracting some-symbolic-link.txt\" + \".\" ) ; assertTrue ( Files . isSameFile ( extractionDirectory . resolve ( someFilename ) , extractionDirectory . resolve ( someSymbolicLinkFilename ) ) ) ; \"Extracted file contents should have matched original\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Javadoc", "in", "various", "places", "and", "cleanup", "imports"], "add_tokens": "/ * * * Checks whether showing secondary text in view is enabled for this spinner ( defaults to false ) . * @ return True if this PickerSpinner shows the item 's secondary text in the view as well as in * dropdown , false if only in dropdown . * /", "del_tokens": "import android . util . Log ;", "commit_type": "add"}
{"commit_tokens": ["adds", "integration", "tests", "for", "non", "-", "audited"], "add_tokens": "import org . apache . isis . applib . fixturescripts . FixtureScripts ; fixtureScripts . runFixtureScript ( new AuditDemoAppFixture ( ) , null ) ; transactionService . nextTransaction ( ) ; @ Inject private FixtureScripts fixtureScripts ;", "del_tokens": "scenarioExecution ( ) . install ( new AuditDemoAppFixture ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "build", "error", "in", "Travis", "due", "to", "generic", "type", "decleration"], "add_tokens": "public static final EndPoint NEGATIVE_INFINITY = new EndPoint ( Infinity . NEGATIVE ) ; public static final EndPoint POSITIVE_INFINITY = new EndPoint ( Infinity . POSITIVE ) ;", "del_tokens": "/ * * * @ author Canh Ngo * / public static final EndPoint < ? > NEGATIVE_INFINITY = new EndPoint < > ( Infinity . NEGATIVE ) ; public static final EndPoint < ? > POSITIVE_INFINITY = new EndPoint < > ( Infinity . POSITIVE ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "offer", "/", "poll", "fail", "counters"], "add_tokens": "Producer p = new Producer ( queue ) ; final Thread thread = new Thread ( p ) ; int f = 0 ; f ++ ; System . out . format ( \"%d - ops/sec=%,d - %s result=%d failed.poll=%d failed.offer=%d\\n\" , Integer . valueOf ( runNumber ) , Long . valueOf ( ops ) , queue . getClass ( ) . getSimpleName ( ) , result , f , p . fails ) ; int fails = 0 ; int f = 0 ; f ++ ; fails = f ;", "del_tokens": "final Thread thread = new Thread ( new Producer ( queue ) ) ; // Thread.yield(); System . out . format ( \"%d - ops/sec=%,d - %s result=%d\\n\" , Integer . valueOf ( runNumber ) , Long . valueOf ( ops ) , queue . getClass ( ) . getSimpleName ( ) , result ) ; // Thread.yield();", "commit_type": "add"}
{"commit_tokens": ["upgraded", "log4j", "properties", "file", ";", "some", "clean", "-", "up", "in", "SimpleReader", "(", "not", "used", "code", "and", "comments", ")", ";", "BioPAXIOHandlerAdapter", "s", "logger", "fix", ".."], "add_tokens": "private static final Log log = LogFactory . getLog ( BioPAXIOHandlerAdapter . class ) ;", "del_tokens": "private static final Log log = LogFactory . getLog ( BioPAXIOHandler . class ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["fixed", ":", "possible", "null", "pointer", "dereference"], "add_tokens": "if ( text != null ) { bytes [ 0 ] = text . getTextEncoding ( ) ; byte [ ] textBytes = text . toBytes ( true , false ) ; if ( textBytes . length > 0 ) { BufferTools . copyIntoByteBuffer ( textBytes , 0 , textBytes . length , bytes , 1 ) ; }", "del_tokens": "if ( text != null ) bytes [ 0 ] = text . getTextEncoding ( ) ; else bytes [ 0 ] = 0 ; byte [ ] textBytes = text . toBytes ( true , false ) ; if ( textBytes . length > 0 ) { BufferTools . copyIntoByteBuffer ( textBytes , 0 , textBytes . length , bytes , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "tmpDir", "for", "shared", "object", "load"], "add_tokens": "import java . io . File ; private File tmpDir ; public IntelDeflaterFactory ( File tmpDir ) { this . tmpDir = tmpDir ; } public IntelDeflaterFactory ( ) { this ( null ) ; } boolean intelDeflaterSupported = new IntelDeflater ( ) . load ( tmpDir ) ;", "del_tokens": "boolean intelDeflaterSupported = new IntelDeflater ( ) . load ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "a", "few", "newer", "Apache", "logformat", "specifiers", "."], "add_tokens": "this ( nLogFormatToken , nValueName , nValueType , nCasts , nRegex , 0 ) ; } public NamedTokenParser ( final String nLogFormatToken , final String nValueName , final String nValueType , final EnumSet < Casts > nCasts , final String nRegex , final int prio ) { super ( nLogFormatToken , nValueName , nValueType , nCasts , nRegex , prio ) ; startOffset + start , end - start , getPrio ( ) ) ;", "del_tokens": "super ( nLogFormatToken , nValueName , nValueType , nCasts , nRegex ) ; startOffset + start , end - start ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "synchronization", "problems", "in", "file", "write", "channel", "listener"], "add_tokens": "protected void done ( final StreamSinkChannel channel , final Exception exception ) {", "del_tokens": "protected void writeDone ( final StreamSinkChannel channel ) {", "commit_type": "fix"}
{"commit_tokens": ["updated", "test", "to", "avoid", "random", "failure", "for", "commons", "io"], "add_tokens": "public static final int INTERVAL = 1000 ; return new FileAlterationMonitor ( INTERVAL , observer ) ;", "del_tokens": "return new FileAlterationMonitor ( 1000 , observer ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "new", "helper", "method", "so", "you", "can", "use", "a", "typed", "reference", "for", "discovery", "of", "the", "package", "."], "add_tokens": "public synchronized Morphia mapPackageFromClass ( Class clazz ) { return mapPackage ( clazz . getPackage ( ) . getName ( ) , false ) ; } Embedded embeddedAnn = ReflectionUtils . getClassEmbeddedAnnotation ( c ) ; Entity enityAnn = ReflectionUtils . getClassEntityAnnotation ( c ) ; if ( enityAnn != null || embeddedAnn != null ) {", "del_tokens": "Embedded classMongoEmbedded = ReflectionUtils . getClassEmbeddedAnnotation ( c ) ; Entity classMongoDocument = ReflectionUtils . getClassEntityAnnotation ( c ) ; if ( classMongoDocument != null || classMongoEmbedded != null ) {", "commit_type": "add"}
{"commit_tokens": ["change", "some", "method", "from", "private", "to", "protected", "."], "add_tokens": "protected StringBuilder fileToStringBuilder ( File file ) throws IOException { protected StringBuilder inputStreamToStringBuilder ( InputStream inputStream )", "del_tokens": "private StringBuilder fileToStringBuilder ( File file ) throws IOException { private StringBuilder inputStreamToStringBuilder ( InputStream inputStream )", "commit_type": "change"}
{"commit_tokens": ["Added", "tests", "for", "comment", "list", "view"], "add_tokens": "* @ deprecated Init should always be called so that each corresponding call to destroy is matched .", "del_tokens": "* @ deprecated init should always be called !", "commit_type": "add"}
{"commit_tokens": ["added", "finals", "moved", "fields", "to", "the", "top"], "add_tokens": "public final static int FILL = ViewGroup . LayoutParams . MATCH_PARENT ; if ( ! sb . toString ( ) . equals ( hasUserInput . get ( sb ) ) ) { if ( o == null || ! o . getClass ( ) . equals ( getClass ( ) ) ) { public interface SimpleItemSelectedListener { public void onItemSelected ( AdapterView a , View v , int pos , long id ) ; } private final AnimatorSet anim = new AnimatorSet ( ) ;", "del_tokens": "public interface SimpleItemSelectedListener { public void onItemSelected ( AdapterView a , View v , int pos , long id ) ; } public final static int FILL = ViewGroup . LayoutParams . FILL_PARENT ; if ( sb . toString ( ) . equals ( hasUserInput . get ( sb ) ) == false ) { if ( o == null || o . getClass ( ) . equals ( getClass ( ) ) == false ) { @ Override @ Override @ Override private AnimatorSet anim = new AnimatorSet ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "origin", "check", "the", "same", "as", "spring"], "add_tokens": "handshakeInterceptors . add ( new OriginHandshakeInterceptor ( this . allowedOrigins ) ) ;", "del_tokens": "if ( ! this . allowedOrigins . isEmpty ( ) ) { OriginHandshakeInterceptor interceptor = new OriginHandshakeInterceptor ( ) ; interceptor . setAllowedOrigins ( this . allowedOrigins ) ; handshakeInterceptors . add ( interceptor ) ; }", "commit_type": "make"}
{"commit_tokens": ["Added", "missing", "and", "other", "count", "to", "TermFacetResponse"], "add_tokens": "private long missing ; private long other ; public TermFacetResponse ( List < TermBucket > buckets , long missing , long other ) { this . missing = missing ; this . other = other ; public long getMissing ( ) { return missing ; } public long getOther ( ) { return other ; }", "del_tokens": "public TermFacetResponse ( List < TermBucket > buckets ) {", "commit_type": "add"}
{"commit_tokens": ["Improve", "card", "parsing", "(", "Multiple", "AIDs", ")"], "add_tokens": "boolean status = extractPublicData ( app ) ; if ( ! ret ) { ret = status ; // Try to read EF 1 and record 1 gpo = provider . transceive ( new CommandApdu ( CommandEnum . READ_RECORD , 1 , 0x0C , 0 ) . toBytes ( ) ) ; if ( ! ResponseUtils . isSucceed ( gpo ) ) { return false ; }", "del_tokens": "if ( ret = extractPublicData ( app ) ) { break ; return false ;", "commit_type": "improve"}
{"commit_tokens": ["Implemented", "costless", "meld", "Pairing", "Heap", "variant"], "add_tokens": "* The above scenario , although efficiently supported by using union - find with * path compression , invalidates the claimed bounds .", "del_tokens": "* The above scenario is efficiently supported by using union - find with path * compression but it invalidates the claimed bounds .", "commit_type": "implement"}
{"commit_tokens": ["Adding", "front", "end", "update", "support", "."], "add_tokens": "File activePath = new File ( basePath , \".active\" ) ; File archivePath = new File ( basePath , \".archive\" ) ;", "del_tokens": "File activePath = new File ( basePath , \"active\" ) ; File archivePath = new File ( basePath , \"archive\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "standard", "JDK", "functions", "for", "system", "property", "access", "."], "add_tokens": "private static final boolean DEBUG = Boolean . getBoolean ( ApplicationLoader . class . getName ( ) + \".DEBUG\" ) ; // To make this class invokable e.g. during automatic testing we simply return in case of success (status 0). if ( status != 0 ) { System . exit ( status ) ; }", "del_tokens": "private static final boolean DEBUG = System . getProperty ( ApplicationLoader . class . getName ( ) + \".DEBUG\" ) != null ; System . exit ( status ) ;", "commit_type": "use"}
{"commit_tokens": ["implement", "help", "request", "as", "a", "type", "of", "validation", "failure"], "add_tokens": "import java . util . Arrays ; super ( specification . toString ( ) , Arrays . < ValidationFailure > asList ( new ValidationFailureHelpRequested ( specification ) ) ) ;", "del_tokens": "super ( specification . toString ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Remove", "jgrapht", "dependency", "which", "requires", "commenting", "-", "out", "MentionCEAFScorer"], "add_tokens": "import com . google . common . annotations . Beta ; @ Beta", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Fix", "notification", "count", "argument", "."], "add_tokens": "return factory . createCount ( get ( buildEndpoint ( \"notifications/count\" ) , params ) )", "del_tokens": "return factory . createCount ( get ( buildEndpoint ( \"notifications/count\" ) ) )", "commit_type": "fix"}
{"commit_tokens": ["move", "CancellableConsumer", "to", "another", "package"], "add_tokens": "package com . tmall . wireless . tangram . reactive ;", "del_tokens": "package com . tmall . wireless . tangram . support ;", "commit_type": "move"}
{"commit_tokens": ["Change", "TypeStructureInformationChecker", "to", "only", "handle", "analysing", "a", "single", "class", ".", "Let", "TypeStructureInformation", "deal", "with", "storing", "results", "from", "multiple", "classes", "."], "add_tokens": "import static org . mutabilitydetector . checkers . info . ClassIdentifier . forClass ; import java . util . HashMap ; import java . util . Map ; import org . mutabilitydetector . checkers . util . TypeStructureInformationChecker ; private final ISessionCheckerRunner sessionCheckerRunner ; private final Map < Dotted , Boolean > isAbstractMap = new HashMap < Dotted , Boolean > ( ) ; this . sessionCheckerRunner = sessionCheckerRunner ; public boolean isTypeAbstract ( Dotted className ) { Boolean result = false ; if ( isAbstractMap . containsKey ( className ) ) { result = isAbstractMap . get ( className ) ; } else { TypeStructureInformationChecker checker = TypeStructureInformationChecker . newChecker ( className ) ; sessionCheckerRunner . run ( checker , forClass ( className ) ) ; result = checker . isAbstract ( ) ; isAbstractMap . put ( className , result ) ; } return result ; }", "del_tokens": "// TODO Auto-generated constructor stub", "commit_type": "change"}
{"commit_tokens": ["move", "getNeighborConcurrentGroupList", "()", "to", "interface", "method", "and"], "add_tokens": "public synchronized List < NeighborConcurrentGroup > getNeighborConcurrentGroupList ( ) { // unmodifiable and snapshot list for concurrent process, return Collections . unmodifiableList ( new CopyOnWriteArrayList < NeighborConcurrentGroup > ( neighborConcurrentGroupList ) ) ; } @ Override public synchronized Map < String , NeighborConcurrentGroup > getNeighborConcurrentGroupMap ( ) { return neighborConcurrentGroupMap != null ? Collections . unmodifiableMap ( neighborConcurrentGroupMap ) : Collections . emptyMap ( ) ;", "del_tokens": "public synchronized Map < String , NeighborConcurrentGroup > getNeighborConcurrentGroupMap ( ) { return neighborConcurrentGroupMap != null ? Collections . unmodifiableMap ( neighborConcurrentGroupMap ) : Collections . emptyMap ( ) ; } public synchronized List < NeighborConcurrentGroup > getNeighborConcurrentGroupList ( ) { // unmodifiable and snapshot, for framework final CopyOnWriteArrayList < NeighborConcurrentGroup > snapshotList = new CopyOnWriteArrayList < NeighborConcurrentGroup > ( neighborConcurrentGroupList ) ; return Collections . unmodifiableList ( snapshotList ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "a", "more", "convenient", "method", "for", "getting", "app", "ids"], "add_tokens": "public static final String id ( String id ) { return prefix . concat ( Utils . noSpaces ( Utils . stripAndTrim ( id . replaceAll ( prefix , \"\" ) , \" \" ) , \"-\" ) ) ; return prefix . concat ( Utils . noSpaces ( Utils . stripAndTrim ( id , \" \" ) , \"-\" ) ) ; } else { return null ; @ Override public final void setId ( String id ) { this . id = id ( id ) ; }", "del_tokens": "@ Override public final void setId ( String id ) { this . id = prefix . concat ( Utils . noSpaces ( Utils . stripAndTrim ( id . replaceAll ( prefix , \"\" ) , \" \" ) , \"-\" ) ) ; this . id = prefix . concat ( Utils . noSpaces ( Utils . stripAndTrim ( id , \" \" ) , \"-\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "random", "distributions", "to", "behavior", "trees", "."], "add_tokens": "import com . badlogic . gdx . ai . btree . LeafTask ; import com . badlogic . gdx . ai . utils . random . ConstantIntegerDistribution ; import com . badlogic . gdx . ai . utils . random . IntegerDistribution ; public IntegerDistribution times = ConstantIntegerDistribution . ONE ; private int t ; @ Override public void start ( Dog dog ) { super . start ( dog ) ; t = times . nextInt ( ) ; } for ( int i = 0 ; i < t ; i ++ )", "del_tokens": "import com . badlogic . gdx . ai . btree . LeafTask ; public int times = 1 ; for ( int i = 0 ; i < times ; i ++ )", "commit_type": "add"}
{"commit_tokens": ["fix", "links", "and", "buttons", "of", "dictionary", "pages"], "add_tokens": "public static final String LABELS_dict_synonym_link_edit = \"{labels.dict_synonym_link_edit}\" ; /** The key of the message: Details */ public static final String LABELS_dict_synonym_link_details = \"{labels.dict_synonym_link_details}\" ; public static final String LABELS_dict_kuromoji_link_edit = \"{labels.dict_kuromoji_link_edit}\" ; /** The key of the message: Details */ public static final String LABELS_dict_kuromoji_link_details = \"{labels.dict_kuromoji_link_details}\" ;", "del_tokens": "public static final String LABELS_dict_synonym_link_update = \"{labels.dict_synonym_link_update}\" ; /** The key of the message: Confirm */ public static final String LABELS_dict_synonym_link_confirm = \"{labels.dict_synonym_link_confirm}\" ; public static final String LABELS_dict_kuromoji_link_update = \"{labels.dict_kuromoji_link_update}\" ; /** The key of the message: Confirm */ public static final String LABELS_dict_kuromoji_link_confirm = \"{labels.dict_kuromoji_link_confirm}\" ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "processing", "of", "variable", "path", "in", "embedded", "structures"], "add_tokens": "final JBBPParser parser = JBBPParser . prepare ( \"bit:3 bitf; var somevar; bool bbb; long aaa; ubyte kkk; {{int lrn; {int [(lrn/aaa*1*(2*somevar-4))/(100%9>>bitf)&56|~kkk^78&bbb];}}}\" ) ;", "del_tokens": "final JBBPParser parser = JBBPParser . prepare ( \"bit:3 bitf; var somevar; bool bbb; long aaa; ubyte kkk; {{{int [(aaa*1*(2*somevar-4))/(100%9>>bitf)&56|~kkk^78&bbb];}}}\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Making", "the", "fares", "tests", "pass", "."], "add_tokens": ". origin ( \"Parada Repblica 2, Brazil\") . destination ( \"Praa Pres. Kenedy, Santo Andr - SP, Brazil\") if ( route . fare != null && route . fare . value != null && \"BRL\" . equals ( route . fare . currency . getCurrencyCode ( ) ) ) {", "del_tokens": ". origin ( \"Fisherman's Wharf, San Francisco\" ) . destination ( \"Union Square, San Francisco\" ) if ( route . fare != null && route . fare . value != null && \"USD\" . equals ( route . fare . currency . getCurrencyCode ( ) ) ) {", "commit_type": "make"}
{"commit_tokens": ["Update", "config", "doc", "and", "version"], "add_tokens": "public static String SDK_VERSION = \"2.3.0\" ;", "del_tokens": "public static String SDK_VERSION = \"2.2.19\" ;", "commit_type": "update"}
{"commit_tokens": ["added", "modules", "folder", ";", "added", "artifact", "juel", "-", "spi", "(", "JAR", "Service", "Provider", ")", ";", "added", "RootPropertyResolver"], "add_tokens": "import javax . el . ELContext ; import javax . el . FunctionMapper ; import javax . el . VariableMapper ; ELContext context = new ELContext ( ) { @ Override public VariableMapper getVariableMapper ( ) { return null ; } @ Override public FunctionMapper getFunctionMapper ( ) { return null ; } @ Override public ELResolver getELResolver ( ) { return null ; } } ; out . println ( tree . getRoot ( ) . getValue ( new Bindings ( null , null ) , context , null ) ) ;", "del_tokens": "import de . odysseus . el . util . SimpleContext ; out . println ( tree . getRoot ( ) . getValue ( new Bindings ( null , null ) , new SimpleContext ( ) , null ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "methods", "to", "concatenate", "a", "translation", "rotation", "or", "scale", "directly", "onto", "an"], "add_tokens": "buf . append ( FloatMath . toString ( x ) ) ; buf . append ( FloatMath . toString ( y ) ) ;", "del_tokens": "buf . append ( x ) ; buf . append ( y ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "stopwatch", "timing", "to", "provider", "manager", "and", "context", ".", "providers", "support"], "add_tokens": "\"HelpScout\" , \"Pardot\" , \"Marketo\" , \"Google Analytics\" , \"Chartbeat\" , \"Vero\"", "del_tokens": "\"HelpScount\" , \"Pardot\" , \"Marketo\" , \"Google Analytics\" , \"Chartbeat\" , \"Vero\"", "commit_type": "add"}
{"commit_tokens": ["Removing", "references", "to", "Grail", "."], "add_tokens": "public static final String CODEC_NAME = \"Owl Platform Aggregator-Solver codec\" ;", "del_tokens": "public static final String CODEC_NAME = \"Grail Aggregator-Solver codec\" ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "issue", "of", "check", "quota", "before", "recording", "the", "usage", "."], "add_tokens": "return ( upper && value <= bound ) || ( ! upper && value >= bound ) ;", "del_tokens": "if ( checkQuotaBeforeRecording ) { return ( upper && value < bound ) || ( ! upper && value > bound ) ; } else { return ( upper && value <= bound ) || ( ! upper && value >= bound ) ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "static", "final", "in", "constant"], "add_tokens": "private static final String MY_PACKAGE_NAME = \"com.androidsx.smileys\" ; private static final String EMAIL = \"yourmail@mail.com\" ;", "del_tokens": "private String MY_PACKAGE_NAME = \"com.androidsx.smileys\" ; private String EMAIL = \"yourmail@mail.com\" ;", "commit_type": "add"}
{"commit_tokens": ["changed", "modifiers", "of", "AbstractListModels", "class"], "add_tokens": "public abstract class AbstractListModels < T extends AbstractModel >", "del_tokens": "abstract class AbstractListModels < T extends AbstractModel >", "commit_type": "change"}
{"commit_tokens": ["Add", "javadoc", "to", "FixedCircularPath", "and", "reformat", "code", "for", "SpiralPath"], "add_tokens": "* CircularPath extension used to place NoxItem objects in a circle inside NoxView * element . Every circle level will be filled with NoxItem instances .", "del_tokens": "* Fixed circular Path implementation used to place NoxItem objects in a circle inside NoxView * element . Every circle level will be fixed with NoxItem instances .", "commit_type": "add"}
{"commit_tokens": ["Add", "extra", "parameters", "to", "the", "DockerClient", "constructor", "s"], "add_tokens": "this ( 10000 , true ) ; } public DockerClient ( Integer readTimeout , boolean enableLoggingFilter ) throws DockerException { this ( Config . createConfig ( ) , readTimeout , enableLoggingFilter ) ; this ( serverUrl , 10000 , true ) ; public DockerClient ( String serverUrl , Integer readTimeout , boolean enableLoggingFilter ) throws DockerException { this ( configWithServerUrl ( serverUrl ) , readTimeout , enableLoggingFilter ) ; } public DockerClient ( Config config , Integer readTimeout , boolean enableLoggingFilter ) { // 1 hour client . setReadTimeout ( readTimeout ) ; if ( enableLoggingFilter ) client . addFilter ( new SelectiveLoggingFilter ( ) ) ;", "del_tokens": "this ( Config . createConfig ( ) ) ; this ( configWithServerUrl ( serverUrl ) ) ; private DockerClient ( Config config ) { client . setReadTimeout ( 10000 ) ; client . addFilter ( new SelectiveLoggingFilter ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "logging", "code", "from", "DirectoryClassLoader"], "add_tokens": "import org . culturegraph . mf . exceptions . MetafactureException ; throw new MetafactureException ( \"Could not add \" + file + \" to class loader\" , e ) ;", "del_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger LOG = LoggerFactory . getLogger ( DirectoryClassLoader . class ) ; LOG . info ( \"Adding jar and class files in {} to class loader\" , dir ) ; LOG . info ( \"Adding {} to class loader\" , file ) ; LOG . error ( \"Could not add {} to class loader: {}\" , file , e ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "to", "ChainLight", "rayStartOffset", "for", "specifying", "a", "gap", "between", "chain", "and", "beginning", "of", "rays", "."], "add_tokens": "public static float defaultRayStartOffset = 0 ; public float rayStartOffset ; rayStartOffset = ChainLight . defaultRayStartOffset ; Vector2 vRayOffset = Pools . obtain ( Vector2 . class ) ; float angle = rayAngle . angle ( ) ; vRayOffset . set ( this . rayStartOffset , 0 ) . rotateRad ( angle ) ; v1 . set ( vDirection ) . scl ( position ) . add ( vSegmentStart ) . add ( vRayOffset ) ; v2 . set ( distance , 0 ) . rotateRad ( angle ) . add ( v1 ) ; Pools . free ( vRayOffset ) ;", "del_tokens": "v1 . set ( vDirection ) . scl ( position ) . add ( vSegmentStart ) ; v2 . set ( distance , 0 ) . rotateRad ( rayAngle . angle ( ) ) . add ( v1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Allows", "use", "of", "territory", "names", "as", "well", "as", "codes"], "add_tokens": "@ Test public void checkFullName ( ) throws Exception { LOG . info ( \"checkFullName\" ) ; assertEquals ( Territory . AAA , Territory . fromString ( \"International\" ) ) ; assertEquals ( Territory . AAA , Territory . fromString ( \"Worldwide\" ) ) ; assertEquals ( Territory . AAA , Territory . fromString ( \"Earth\" ) ) ; assertEquals ( Territory . NLD , Territory . fromString ( \"Netherlands\" ) ) ; assertEquals ( Territory . CN_XZ , Territory . fromString ( \"Xizang\" ) ) ; assertEquals ( Territory . CN_XZ , Territory . fromString ( \"Tibet\" ) ) ; }", "del_tokens": "@ Test ( expected = IllegalArgumentException . class ) public void testFromStringError4 ( ) { LOG . info ( \"testFromStringError4\" ) ; Territory . fromString ( \"Netherlands\" ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "the", "toggle", "button", "being", "typed", "on", "first", "CLI", "toggle", "for", "libGdx"], "add_tokens": "import com . github . ykrasik . jaci . util . exception . SneakyException ; throw SneakyException . sneakyThrow ( e ) ;", "del_tokens": "throw new RuntimeException ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["used", "/", "wgb", "renamed", "cause", "and", "effect"], "add_tokens": "res . setActivity ( pid ) ; res . setEntity ( aid ) ; ActivityRef aid , EntityRef eid ) { res . setActivity ( aid ) ; res . setEntity ( eid ) ; u . getActivity ( ) , u . getEntity ( ) ) ; g . getEntity ( ) , g . getActivity ( ) ) ; res . setActivity ( pid ) ; res . setEntity ( aid ) ;", "del_tokens": "res . setEffect ( pid ) ; res . setCause ( aid ) ; ActivityRef pid , EntityRef aid ) { res . setEffect ( pid ) ; res . setCause ( aid ) ; u . getEffect ( ) , u . getCause ( ) ) ; g . getEffect ( ) , g . getCause ( ) ) ; res . setCause ( pid ) ; res . setEffect ( aid ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "for", "RubyEnumerable", "::", "dropWhile"], "add_tokens": "if ( ! block . yield ( item ) || cutPoint ) { public RubyEnumerator < RubyArray < E > > eachCons ( int n ) { if ( n <= 0 ) { throw new IllegalArgumentException ( \"invalid size\" ) ; } return new RubyEnumerator < RubyArray < E > > ( new EachConsIterable < E > ( iter , n ) ) ; }", "del_tokens": "if ( block . yield ( item ) || cutPoint ) { public RubyEnumerator < RubyArray < E > > eachCons ( int n ) { if ( n <= 0 ) { throw new IllegalArgumentException ( \"invalid size\" ) ; } return new RubyEnumerator < RubyArray < E > > ( new EachConsIterable < E > ( iter , n ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["implemented", "the", "policy", "definition", "management", "ui", "pages", ":", "https", ":", "//", "issues", ".", "jboss", ".", "org", "/", "browse", "/", "APIMAN", "-", "129"], "add_tokens": "@ TranslationKey ( defaultValue = \"APIMan - Import Policy Definition(s)\" ) public static final String TITLE_IMPORT_POLICY_DEF = \"page.title.import-policyDef\" ; //$NON-NLS-1$ @ TranslationKey ( defaultValue = \"No policy definitions have been added/imported! You must add at least one policy if you want to do any governance of your services.\" ) public static final String NO_POLICY_DEFS_ADMIN_MESSAGE = \"noEntitiesFound.admin-policyDefs\" ; //$NON-NLS-1$ @ TranslationKey ( defaultValue = \"No policy definitions matched the filter criteria. Please try modifying the filter or else import at least one Policy Definition that matches it.\" ) public static final String NO_FILTERED_POLICY_DEFS_ADMIN_MESSAGE = \"noEntitiesFound.admin-policyDefs.filtered\" ; //$NON-NLS-1$", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Adding", "support", "for", "MasterCard", "series", "2", "BINs"], "add_tokens": "// MasterCard numbers start with the numbers 51 through 55, and 2221 through 2720. MasterCard ( Pattern . compile ( \"^5[1-5][0-9]{5,}$|^(222[1-9]|2[3-6][0-9][0-9]|27[0-1][0-9]|2720)[0-9]{12}$\" ) ) ,", "del_tokens": "// MasterCard numbers start with the numbers 51 through 55, but this // will only detect MasterCard credit cards; there are other cards // issued using the MasterCard system that do not fall into this IIN // range. MasterCard ( Pattern . compile ( \"^5[1-5][0-9]{5,}$\" ) ) , // There are Diners Club cards that begin with 5 and have 16 digits. // These are a joint venture between Diners Club and MasterCard, and // should be processed like a MasterCard.", "commit_type": "add"}
{"commit_tokens": ["moved", "Strings", "to", "fields", "extra", "test", "cases", "null", "check"], "add_tokens": "private final String alert = \"alert\" ; private final String sound = \"sound\" ; private final String badge = \"badge\" ; private final String simplePush = \"simple-push\" ; this . attributes . put ( alert , message ) ; this . attributes . put ( this . sound , sound ) ; this . attributes . put ( this . badge , badge ) ; this . attributes . put ( simplePush , fixVersion ( version ) ) ; this . attributes . put ( simplePush , entries ) ; if ( version != null && ! version . startsWith ( \"version=\" ) ) {", "del_tokens": "this . attributes . put ( \"alert\" , message ) ; this . attributes . put ( \"sound\" , sound ) ; this . attributes . put ( \"badge\" , badge ) ; this . attributes . put ( \"simple-push\" , fixVersion ( version ) ) ; this . attributes . put ( \"simple-push\" , entries ) ; if ( ! version . startsWith ( \"version=\" ) ) {", "commit_type": "move"}
{"commit_tokens": ["Fix", "lastRunDuration", "for", "Sched", "Exec", "stats"], "add_tokens": "long totalRuns , long totalRunTimeNanos , @ Since ( \"1.6\" ) long lastRunDurationNanos ) ;", "del_tokens": "long totalRuns , long totalRunTimeNanos ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "pom", "property", "placeholder", "replacement"], "add_tokens": "import java . util . regex . Matcher ; final String html = HTML_TEMPLATE . replaceAll ( \"\\\\$LOCATION\" , Matcher . quoteReplacement ( url ) ) ;", "del_tokens": "final String html = HTML_TEMPLATE . replaceAll ( \"\\\\$LOCATION\" , url ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "don", "t", "need", "to", "parse", "the", "SMTPResponse", "more", "often", "then", "needed"], "add_tokens": "class SMTPResponseDecoder extends FrameDecoder implements ChannelLocalSupport { SMTPResponseImpl response = ( SMTPResponseImpl ) ctx . getAttachment ( ) ; ctx . setAttachment ( null ) ; ctx . setAttachment ( response ) ; return null ;", "del_tokens": "class SMTPResponseDecoder extends FrameDecoder { SMTPResponseImpl response = null ; // reset the index as we not reached the end of the SMTPResponse buffer . resetReaderIndex ( ) ; return response ;", "commit_type": "make"}
{"commit_tokens": ["Add", "initial", "workings", "for", "document", "storage", "and", "retrieval"], "add_tokens": "* Stores related items into the storage repo , and is responsible for storing the given relatedItems * into the repo", "del_tokens": "* Created with IntelliJ IDEA . * User : dominictootell * Date : 01 / 06 / 2013 * Time : 22 : 14 * To change this template use File | Settings | File Templates .", "commit_type": "add"}
{"commit_tokens": ["added", "configuration", "switches", "to", "(", "de", "-", ")", "activate", "sql", "and", "sql", "parameter", "collection"], "add_tokens": "import org . stagemonitor . core . StageMonitor ; public static final boolean ACTIVE = ! StageMonitor . getConfiguration ( ) . getDisabledPlugins ( ) . contains ( JdbcPlugin . class . getSimpleName ( ) ) && StageMonitor . getConfiguration ( ) . isStagemonitorActive ( ) ; if ( ACTIVE && StageMonitor . getConfiguration ( ) . collectSql ( ) ) { P6SpyLoadableOptions options = P6SpyOptions . getActiveInstance ( ) ; addStagemonitorLogger ( options ) ; wrapConnections = options . getDriverNames ( ) == null || options . getDriverNames ( ) . isEmpty ( ) ; if ( ! wrapConnections ) { logger . info ( \"Stagemonitor will not wrap connections with p6spy wrappers, because p6spy is already \" + \"configured in your application\" ) ; } P6Core . initialize ( ) ; } else { wrapConnections = false ; } } private void addStagemonitorLogger ( P6SpyLoadableOptions options ) { @ Pointcut ( \"if()\" ) public static boolean ifActivated ( ) { return ACTIVE ; } @ Around ( value = \"ifActivated() && dataSourceConnection()\" )", "del_tokens": "P6SpyLoadableOptions options = P6SpyOptions . getActiveInstance ( ) ; wrapConnections = options . getDriverNames ( ) == null || options . getDriverNames ( ) . isEmpty ( ) ; if ( ! wrapConnections ) { logger . info ( \"Stagemonitor will not wrap connections with p6spy wrappers, because p6spy is already \" + \"configured in your application\" ) ; } P6Core . initialize ( ) ; @ Around ( value = \"dataSourceConnection()\" )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "getObject", "(", "..", ")", "with", "null", "default", "bug"], "add_tokens": "if ( child != null ) { if ( defaultValue == null ) { return ( TO ) child . value ; }", "del_tokens": "if ( child != null && defaultValue != null ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "typo", "in", "disjoint", "and", "a", "test"], "add_tokens": "OGCGeometry g2 = flattened2 . geometryN ( j ) ;", "del_tokens": "OGCGeometry g2 = flattened2 . geometryN ( i ) ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "Deployment", "and", "DeploymentConfig", "objects", "to", "be", "enriched", "and", "defaulted", "with", "name", "labels", "annotations", "image", "etc"], "add_tokens": "return checkForKind ( builder , \"ReplicationController\" , \"ReplicaSet\" , \"Deployment\" , \"DeploymentConfig\" ) ;", "del_tokens": "return checkForKind ( builder , \"ReplicationController\" , \"ReplicaSet\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "certificate", "processing", "for", "mutual", "TLS", "to", "token", "endpoint"], "add_tokens": "Property [ ] properties , String clientCertificate , String [ ] clientCertificatePath ) return callToken ( params , clientId , clientSecret , properties , clientCertificate , clientCertificatePath ) ; String parameters , String clientId , String clientSecret , Property [ ] properties , String clientCertificate , String [ ] clientCertificatePath ) . setClientCertificate ( clientCertificate ) . setClientCertificatePath ( clientCertificatePath )", "del_tokens": "Property [ ] properties ) return callToken ( params , clientId , clientSecret , properties ) ; String parameters , String clientId , String clientSecret , Property [ ] properties )", "commit_type": "add"}
{"commit_tokens": ["Added", "addListener", "()", "to", "the", "extra", "params", "phase"], "add_tokens": "private List < Server . Listener > listeners = new LinkedList < > ( ) ; @ Override public ExtraParamsPhase addListener ( Server . Listener listener ) { this . listeners . add ( listener ) ; return this ; } NettyServer server = new NettyServer ( port , registry , marshallerRegistry , staticResolver , queueObserver , activeChannels , contextPath , appName , acceptKeepAlive , supportZip , metricFactory , maxContentLength , requestTimeoutMs ) ; server . addListeners ( listeners ) ; return server ;", "del_tokens": "return new NettyServer ( port , registry , marshallerRegistry , staticResolver , queueObserver , activeChannels , contextPath , appName , acceptKeepAlive , supportZip , metricFactory , maxContentLength , requestTimeoutMs ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "CopyOnWriteArrayList", "for", "leader", "response", "callbacks", "in", "order", "to", "prevent", "ConcurrentModificationException", "."], "add_tokens": "import java . util . concurrent . CopyOnWriteArrayList ; import net . kuujo . copycat . protocol . AppendEntriesRequest ; import net . kuujo . copycat . protocol . AppendEntriesResponse ; private final List < AsyncCallback < Void > > responseCallbacks = new CopyOnWriteArrayList < > ( ) ;", "del_tokens": "import net . kuujo . copycat . protocol . AppendEntriesRequest ; import net . kuujo . copycat . protocol . AppendEntriesResponse ; private final List < AsyncCallback < Void > > responseCallbacks = new ArrayList < > ( ) ;", "commit_type": "use"}
{"commit_tokens": ["use", "vector", "instead", "of", "png"], "add_tokens": "setStatus ( errString . toString ( ) , errorColor , R . drawable . fingerprint_error , null ) ; setStatus ( helpString . toString ( ) , errorColor , R . drawable . fingerprint_error , null ) ; setStatus ( R . string . state_success , successColor , R . drawable . fingerprint_success , new YoYo . AnimatorCallback ( ) { setStatus ( R . string . state_failure , errorColor , R . drawable . fingerprint_error , null ) ;", "del_tokens": "setStatus ( errString . toString ( ) , errorColor , R . drawable . ic_close_white_24dp , null ) ; setStatus ( helpString . toString ( ) , errorColor , R . drawable . ic_close_white_24dp , null ) ; setStatus ( R . string . state_success , successColor , R . drawable . ic_check_white_24dp , new YoYo . AnimatorCallback ( ) { setStatus ( R . string . state_failure , errorColor , R . drawable . ic_close_white_24dp , null ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "possible", "problem", "in", "the", "calculation", "of", "parameter", "step", "if", "it", "is", "not", "set", "by", "the", "user", "."], "add_tokens": "if ( logger . isLoggable ( Level . FINE ) )", "del_tokens": "// if (logger.isLoggable(Level.FINE)) System . out . println ( logString ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "timestamp", "to", "Calendar", "deserializer"], "add_tokens": "import co . aurasphere . botmill . core . internal . util . json . CalendarFromTimestampJsonDeserializer ; builder . registerTypeAdapter ( IncomingMessage . class , new IncomingMessageDeserializer ( ) ) ; // Deserializes timestamp as Calendar. builder . registerTypeAdapter ( Calendar . class , new CalendarFromTimestampJsonDeserializer ( ) ) ;", "del_tokens": "builder . registerTypeAdapter ( IncomingMessage . class , new IncomingMessageDeserializer ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "try", "-", "with", "-", "resources", "in", "tests", "to", "compile", "with", "jdk6"], "add_tokens": "final byte [ ] pdfBytes = PdfTextExtractorTest . readDocument ( new File ( resourceRoot , \"yaxiststar.pdf\" ) ) ;", "del_tokens": "import java . io . FileInputStream ; import java . io . InputStream ; final byte [ ] pdfBytes = readDocument ( new File ( resourceRoot , \"yaxiststar.pdf\" ) ) ; protected static byte [ ] readDocument ( final File file ) throws IOException { try ( ByteArrayOutputStream fileBytes = new ByteArrayOutputStream ( ) ; InputStream inputStream = new FileInputStream ( file ) ) { final byte [ ] buffer = new byte [ 8192 ] ; while ( true ) { final int bytesRead = inputStream . read ( buffer ) ; if ( bytesRead == - 1 ) { break ; } fileBytes . write ( buffer , 0 , bytesRead ) ; } return fileBytes . toByteArray ( ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["Move", "markdown", "emitter", "from", "tzatziki", "to", "gutenberg"], "add_tokens": "* < br > * < br >", "del_tokens": "* < p / > * < p / >", "commit_type": "move"}
{"commit_tokens": ["add", "paramKeys", "()", "method", "to", "ParamValueProvider", "interface"], "add_tokens": "* public Result createUser ( @ Binder ( value = UserBinder . class , model = \"u\" ) User user ) { * the frontend developer shall not use { @ code u . name } and { @ code u . password } to refer", "del_tokens": "* public Result createUser ( @ Binder ( value = UserBinder . class , model = \"p\" ) User user ) { * the developer shall not use { @ code u . name } and { @ code u . password } to refer", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "we", "manually", "add", "values", "to", "the", "map", "."], "add_tokens": "HashMap < String , Object > msg = new HashMap < > ( ) ;", "del_tokens": "HashMap < String , Object > msg = new HashMap < > ( obj ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "null", "pointer", "bug", "."], "add_tokens": "if ( metadata == null ) { METADATA = new ArrayList < Byte > ( 0 ) ; } else { METADATA = new ArrayList < Byte > ( metadata . size ( ) ) ; for ( int k = 0 ; k < metadata . size ( ) ; k ++ ) { METADATA . add ( metadata . get ( k ) ) ; }", "del_tokens": "METADATA = new ArrayList < Byte > ( metadata . size ( ) ) ; for ( int k = 0 ; k < metadata . size ( ) ; k ++ ) { METADATA . add ( metadata . get ( k ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "index", "keeping", "for", "AST", "nodes"], "add_tokens": "import org . parboiled . common . FileUtils ; public void customPegDownTests ( ) { public void customPegDownTests2 ( ) { public void testHTMLSuppression ( ) { @ Test ( dependsOnMethods = \"testHTMLSuppression\" ) public void testASTIndices ( ) { testAST ( \"pegdown/AstText\" ) ; }", "del_tokens": "public void customPegDownTests ( ) throws Exception { public void customPegDownTests2 ( ) throws Exception { public void testHTMLSuppression ( ) throws Exception {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "code", "quality", "issues", "found", "by", "FindBugs"], "add_tokens": "public static final CustomTransitionController LEFT_IN_PLACE = new CustomTransitionController ( ) { public static final CustomTransitionController RIGHT_IN_PLACE = new CustomTransitionController ( ) {", "del_tokens": "public static CustomTransitionController LEFT_IN_PLACE = new CustomTransitionController ( ) { public static CustomTransitionController RIGHT_IN_PLACE = new CustomTransitionController ( ) { View mView ; boolean mShouldStart = true ; mView = page ;", "commit_type": "fix"}
{"commit_tokens": ["add", "builder", "to", "biocrelation", "not", "finished"], "add_tokens": "private static final BioCLocation . Builder BUILDER = BioCLocation . newBuilder ( ) . setOffset ( OFFSET ) . setLength ( LENGTH ) ; BioCLocation base = BUILDER . build ( ) ; BioCLocation base = BUILDER . build ( ) ; BioCLocation baseCopy = BUILDER . build ( ) ; BioCLocation diffOffset = BUILDER . setOffset ( OFFSET_2 ) . build ( ) ; BioCLocation diffLength = BUILDER . setLength ( LENGTH_2 ) . build ( ) ;", "del_tokens": "BioCLocation . Builder builder = BioCLocation . newBuilder ( ) . setOffset ( OFFSET ) . setLength ( LENGTH ) ; BioCLocation base = builder . build ( ) ; BioCLocation . Builder builder = BioCLocation . newBuilder ( ) . setOffset ( OFFSET ) . setLength ( LENGTH ) ; BioCLocation base = builder . build ( ) ; BioCLocation baseCopy = builder . build ( ) ; BioCLocation diffOffset = builder . setOffset ( OFFSET_2 ) . build ( ) ; BioCLocation diffLength = builder . setLength ( LENGTH_2 ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "valueOf", "static", "methods", "for", "JAX", "-", "RS", "construction", "also", "deprecating", "the", "toVidispineString", "methods"], "add_tokens": "/ * * * Encode the SampleCount as < code > samples @ [ str_timebase | nom [ : denom ] ] < / code > ( e . g . 124222 @ 44100 , 400 @ 30000 : 1001 ) * @ return * / return samples + \"@\" + rate . toEncodedString ( ) ; @ Deprecated return valueOf ( countAndRate ) ; } / * * * Parse a sample count & timebase as < code > samples @ [ str_timebase | nom [ : denom ] ] < / code > * N . B . This does NOT consider the case where only a sample count is specified : it MUST include a timebase * * @ param countAndRate * A sample count and a time base . The syntax is { number of samples } @ { textual representation of time base } 124222 @ 44100 , * 400 @ 30000 : 1001 , 400 @ NTSC * * @ return * / public static SampleCount valueOf ( final String countAndRate ) { if ( countAndRate == null ) return null ; @ Deprecated return toString ( ) ;", "del_tokens": "return toVidispineString ( ) ; return samples + \"@\" + rate . toEncodedString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "using", "method", "pointers", "as", "closures"], "add_tokens": "return new MethodClosure ( object , property ) ;", "del_tokens": "import org . codehaus . groovy . lang . Closure ; return new Closure ( ) { public Object call ( Object args ) { return InvokerHelper . invokeMethod ( object , property , args ) ; } } ;", "commit_type": "add"}
{"commit_tokens": ["Add", "IntBitSet", ".", "with", "method", "."], "add_tokens": "public static IntBitSet with ( int ... elements ) { IntBitSet result ; result = new IntBitSet ( ) ; for ( int e : elements ) { result . add ( e ) ; } return result ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "mouse", "over", "and", "click", "to", "Scene"], "add_tokens": "private boolean dissolve = false , nextDissolve = false , preDissolve = false , nowDissolve = false ; nowDissolve = true ; if ( tmp > 1.0 ) { nowDissolve = false ; tmp = 1.0 ; } if ( nowDissolve ) sceneList . get ( nowSceneID ) . drawscene ( g ) ; public boolean isNowDissolve ( ) { return nowDissolve ; }", "del_tokens": "private boolean dissolve = false , nextDissolve = false , preDissolve = false ; sceneList . get ( nowSceneID ) . drawscene ( g ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "shutdown", "hook", "to", "RythmConfigurer", "so", "that", "we", "can", "gracefully", "shutdown", "RythmEngine"], "add_tokens": "import org . springframework . beans . factory . DisposableBean ; public class RythmConfigurer extends RythmEngineFactory implements RythmHolder , InitializingBean , DisposableBean , ResourceLoaderAware , ServletContextAware , WebMvcConfigurer { @ Override public void destroy ( ) throws Exception { if ( null != engine ) { engine . shutdown ( ) ; } } // WebApplicationContext ctx = (WebApplicationContext)getApplicationContext(); // if (!config.containsKey(RythmConfigurationKey.HOME_TMP.getKey())) { // File tmpdir = (File)ctx.getServletContext().getAttribute(\"javax.servlet.context.tempdir\"); // if (null != tmpdir) { // config.put(RythmConfigurationKey.HOME_TMP.getKey(), new File(tmpdir, \"__rythm\")); // } // }", "del_tokens": "public class RythmConfigurer extends RythmEngineFactory implements RythmHolder , InitializingBean , ResourceLoaderAware , ServletContextAware , WebMvcConfigurer {", "commit_type": "add"}
{"commit_tokens": ["add", "attachArtifactMojo", "+", "site", "doc"], "add_tokens": "* @ deprecated Please use sources instead / * * * Additional source directories * @ parameter * * / private File [ ] sources ; if ( this . directory != null ) { this . project . addCompileSourceRoot ( this . directory . getAbsolutePath ( ) ) ; this . getLog ( ) . info ( \"Source directory: \" + this . directory + \" added.\" ) ; } if ( this . sources != null ) { for ( int i = 0 ; i < sources . length ; ++ i ) { this . project . addCompileSourceRoot ( this . sources [ i ] . getAbsolutePath ( ) ) ; this . getLog ( ) . info ( \"Source directory: \" + this . sources [ i ] + \" added.\" ) ; } }", "del_tokens": "* @ required this . project . addCompileSourceRoot ( this . directory . getAbsolutePath ( ) ) ; this . getLog ( ) . info ( \"Source directory: \" + this . directory + \" added.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "missing", "read", "lock", ";", "use", "volatile", "on", "arrays", "to", "ensure", "everybody", "sees", "same", "version", "simplify", "remainder", "of", "locking", "code", "and", "remove", "redundant", "uses", "of", "synchronize", ".", "Looks", "like", "weirdness", "is", "finally", "gone", "."], "add_tokens": "lock . readLock ( ) . lock ( ) ; try { return allStrings . get ( existingIndex ) ; } finally { lock . readLock ( ) . unlock ( ) ; } // Bucket bucket = allStrings.getOrCreateBucket(efficientString.hashCode); // existingIndex = bucket.get(efficientString); // if (existingIndex >= 0) { // // conflicting write // return allStrings.get(existingIndex); // }", "del_tokens": "import com . jillesvangurp . efficientstring . EfficientStringBiMap . Bucket ; return allStrings . get ( existingIndex ) ; Bucket bucket = allStrings . getOrCreateBucket ( efficientString . hashCode ) ; existingIndex = bucket . get ( efficientString ) ; if ( existingIndex >= 0 ) { // conflicting write return allStrings . get ( existingIndex ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "javadoc", "for", "the", "packages", "."], "add_tokens": "* Operation modes for texture coordinate generation by * { @ link NormalizingPlyReader } .", "del_tokens": "* Operation modes for texture coordinate generation .", "commit_type": "add"}
{"commit_tokens": ["add", "activator", "and", "deactivator", "for", "Pool"], "add_tokens": "if ( ! isInterrupted ( ) ) { Runtime . getRuntime ( ) . removeShutdownHook ( shutdownHook ) ; shutdownHook . run ( ) ; }", "del_tokens": "shutdownHook . run ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "AdapteeCollection<T", ">", "compatible", "with", "List<T", ">", "interface", "so", "any", "class", "implementing", "a", "List", "could", "be", "used", "as", "an", "AdapteeCollection", "by", "simply", "implementing", "it", "."], "add_tokens": "boolean add ( T element ) ; boolean remove ( T element ) ; boolean addAll ( Collection < ? extends T > elements ) ; boolean removeAll ( Collection < ? > elements ) ;", "del_tokens": "void add ( T element ) ; void remove ( T element ) ; void addAll ( Collection < T > elements ) ; void removeAll ( Collection < T > elements ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "assembly", "to", "pom", "to", "create", "standalone"], "add_tokens": "assertFalse ( entity . getBindVars ( ) . indexOf ( \"name\" ) == - 1 ) ; assertFalse ( entity . getBindVars ( ) . indexOf ( \"age\" ) == - 1 ) ;", "del_tokens": "assertThat ( entity . getBindVars ( ) . get ( 0 ) , is ( \"name\" ) ) ; assertThat ( entity . getBindVars ( ) . get ( 1 ) , is ( \"age\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "debugging", "for", "cleaner", "test", "run"], "add_tokens": "//System.out.println(\"Initializing the SpringContextHolder class.\"); //System.out.println(\"Setting current Spring Application Context in SpringContextHolder class.\");", "del_tokens": "System . out . println ( \"Initializing the SpringContextHolder class.\" ) ; System . out . println ( \"Setting current Spring Application Context in SpringContextHolder class.\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["move", "version", "resolving", "into", "Versions"], "add_tokens": "package com . github . to2mbn . jmccc . version ;", "del_tokens": "package com . github . to2mbn . jmccc . launch ; import com . github . to2mbn . jmccc . version . Library ; import com . github . to2mbn . jmccc . version . Native ; import com . github . to2mbn . jmccc . version . Version ;", "commit_type": "move"}
{"commit_tokens": ["Add", "use", "method", "in", "graph", "to", "use", "an", "injectable", "instance", "easier"], "add_tokens": "/ * * * Increase reference count . * / void retain ( ) { } / * * * Retain an instance injected as a field of an object * @ param owner The owner of the field * @ param field The field * / void retain ( Object owner , Field field ) { retain ( ) ; / * * * Decrease reference count . * / void release ( ) { totalRefCount -- ; } / * * * Release an instance injected as a field of an object * @ param owner The owner of the field * @ param field The field * / release ( ) ;", "del_tokens": "void retain ( Object owner , Field field ) { totalRefCount -- ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "Version", "read", "by", "property"], "add_tokens": "PropertiesReader propertiesReader = new PropertiesReader ( ) ; Properties properties = propertiesReader . getProperties ( \"version.properties\" ) ; }", "del_tokens": "import com . tagmycode . sdk . ResourceReader ; ResourceReader resourceReader = new ResourceReader ( ) ; Properties properties = resourceReader . getProperties ( \"version.properties\" ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "header", "table", "capacity", "update", "and", "max", "size", "parsing"], "add_tokens": "if ( maxHeaderTableSizeChangeRequired && ( b & 0xE0 ) != 0x20 ) {", "del_tokens": "if ( maxHeaderTableSizeChangeRequired && ( b & 0xF0 ) != 0x20 ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "typoTolerance", "+", "allowTyposOnNumericTokens", "query", "parameters", "handling"], "add_tokens": "protected boolean typoTolerance ; protected boolean allowTyposOnNumericTokens ; analytics = synonyms = replaceSynonyms = typoTolerance = allowTyposOnNumericTokens = true ; analytics = synonyms = replaceSynonyms = typoTolerance = allowTyposOnNumericTokens = true ; / * * * @ param If set to false , disable typo - tolerance . Default to true . * / public Query enableTypoTolerance ( boolean enabled ) { this . typoTolerance = enabled ; return this ; } / * * * @ param If set to false , disable typo - tolerance on numeric tokens . Default to true . * / public Query enableTyposOnNumericTokens ( boolean enabled ) { this . allowTyposOnNumericTokens = enabled ; return this ; } if ( ! typoTolerance ) { if ( stringBuilder . length ( ) > 0 ) stringBuilder . append ( '&' ) ; stringBuilder . append ( \"typoTolerance=false\" ) ; } if ( ! allowTyposOnNumericTokens ) { if ( stringBuilder . length ( ) > 0 ) stringBuilder . append ( '&' ) ; stringBuilder . append ( \"allowTyposOnNumericTokens=false\" ) ; }", "del_tokens": "analytics = synonyms = replaceSynonyms = true ; analytics = synonyms = replaceSynonyms = true ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "NullPointerException", "in", "AbstractServerStream", "when", "deframer", "reports", "error", "and", "fix", "error", "message", "propagation"], "add_tokens": "writeStatusToTrailers ( status ) ; private void writeStatusToTrailers ( Status status ) { stashedTrailers . removeAll ( Status . CODE_KEY ) ; stashedTrailers . removeAll ( Status . MESSAGE_KEY ) ; stashedTrailers . put ( Status . CODE_KEY , status ) ; if ( status . getDescription ( ) != null ) { stashedTrailers . put ( Status . MESSAGE_KEY , status . getDescription ( ) ) ; } } if ( stashedTrailers == null ) { stashedTrailers = new Metadata . Trailers ( ) ; } writeStatusToTrailers ( status ) ;", "del_tokens": "trailers . removeAll ( Status . CODE_KEY ) ; trailers . removeAll ( Status . MESSAGE_KEY ) ; trailers . put ( Status . CODE_KEY , status ) ; if ( status . getDescription ( ) != null ) { trailers . put ( Status . MESSAGE_KEY , status . getDescription ( ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "methods", "for", "the", "Provider", "interface", "."], "add_tokens": "import org . jboss . pressgang . ccms . wrapper . collection . UpdateableCollectionWrapper ; UpdateableCollectionWrapper < TranslatedTopicStringWrapper > getTranslatedTopicStrings ( ) ; void setTranslatedTopicStrings ( UpdateableCollectionWrapper < TranslatedTopicStringWrapper > translatedStrings ) ;", "del_tokens": "import org . jboss . pressgang . ccms . wrapper . collection . CollectionWrapper ; CollectionWrapper < TranslatedTopicStringWrapper > getTranslatedStrings ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "logic", "error", "in", "TemplateBase", ".", "cloneMe"], "add_tokens": "public static final String version = \"1.0.0-20121110\" ;", "del_tokens": "public static final String version = \"1.0.0-20121106\" ; if ( null == t ) return \"This is not rythm template\" ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "abbreviation", "and", "some", "tests"], "add_tokens": "\"ggf\" , \"Dr\" , \"Prof\" , \"bspw\" , \"etc\" , \"ca\" , \"lt\"", "del_tokens": "\"ggf\" , \"Dr\" , \"Prof\" , \"bspw\" , \"etc\" , \"ca\"", "commit_type": "add"}
{"commit_tokens": ["Make", "DataUriFeature", "public", "so", "others", "can", "use", "it", "."], "add_tokens": "public class DataUriFeature implements Feature {", "del_tokens": "class DataUriFeature implements Feature {", "commit_type": "make"}
{"commit_tokens": ["Making", "conversion", "of", "By", "clasess", "to", "JQuery", "selectors", "more", "safe", "-", "issue", "a", "warning", "if", "By", "class", "is", "unsupported", "yet", "but", "don", "t", "fail", "right", "away"], "add_tokens": "assertEquals ( \"[name='products[0].quantity']\" , getJQuerySelector ( By . name ( \"products[0].quantity\" ) ) ) ; assertEquals ( \"#addProductButton\" , getJQuerySelector ( By . id ( \"addProductButton\" ) ) ) ; assertEquals ( \".product_row\" , getJQuerySelector ( By . className ( \"product_row\" ) ) ) ; assertEquals ( \"form input.hello\" , getJQuerySelector ( By . cssSelector ( \"form input.hello\" ) ) ) ; assertEquals ( \"label[for='operatingAddressSameAsLegalfalse']\" , getJQuerySelector ( By . xpath ( \"//label[@for='operatingAddressSameAsLegalfalse']\" ) ) ) ; assertEquals ( \"a[class='menu_item'][to='review']\" , getJQuerySelector ( By . xpath ( \"//a[@class='menu_item'][@to='review']\" ) ) ) ;", "del_tokens": "assertEquals ( \"$(\\\"*[name='products[0].quantity']\\\")\" , getJQuerySelector ( By . name ( \"products[0].quantity\" ) ) ) ; assertEquals ( \"$(\\\"#addProductButton\\\")\" , getJQuerySelector ( By . id ( \"addProductButton\" ) ) ) ; assertEquals ( \"$(\\\".product_row\\\")\" , getJQuerySelector ( By . className ( \"product_row\" ) ) ) ; assertEquals ( \"$(\\\"label[for='operatingAddressSameAsLegalfalse']\\\")\" , getJQuerySelector ( By . xpath ( \"//label[@for='operatingAddressSameAsLegalfalse']\" ) ) ) ; assertEquals ( \"$(\\\"a[class='menu_item'][to='review']\\\")\" , getJQuerySelector ( By . xpath ( \"//a[@class='menu_item'][@to='review']\" ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "support", "for", "hourly", "s3", "data", "ingestion", "from", "secor", ":"], "add_tokens": "return getInt ( \"secor.finalizer.lookback.periods\" , 10 ) ; public boolean getBoolean ( String name , boolean defaultValue ) { return mProperties . getBoolean ( name , defaultValue ) ; }", "del_tokens": "public boolean getMessageTimestampUsingHour ( ) { return getBoolean ( \"message.timestamp.using.hour\" , false ) ; } public int getFinalizerLagSecond ( ) { return getInt ( \"finalizer.lag.second\" , 3600 ) ; } return getInt ( \"finalizer.lookback.periods\" , 10 ) ; private boolean getBoolean ( String name , boolean defaultValue ) { return mProperties . getBoolean ( name , defaultValue ) ; }", "commit_type": "add"}
{"commit_tokens": ["changes", "polling", "default", "type", "to", "sscommand", "."], "add_tokens": "private static final String DEFAULT_POLL_TYPE = \"sscommand\" ;", "del_tokens": "private static final String DEFAULT_POLL_TYPE = \"ping\" ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "broken", "test", "case", "."], "add_tokens": "directConnection . accept ( getContext ( ) ) ;", "del_tokens": "directConnection . accept ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Create", "hierarchical", "PlaceRequests", "from", "strings"], "add_tokens": "// TODO: Tis is currently limited to a a parent/child hierarchy with depth 1 String [ ] parentChild = urlString . split ( \"/\" ) ; String parent = parentChild [ 0 ] ; places . add ( new PlaceRequest ( parent ) ) ; String child = parentChild [ 1 ] ; if ( child . contains ( \";\" ) ) String [ ] split = child . split ( \";\" ) ; String childPlace = split [ 0 ] ; places . add ( new PlaceRequest ( childPlace ) . with ( params [ 0 ] , params [ 1 ] ) ) ; places . add ( new PlaceRequest ( child ) ) ;", "del_tokens": "String token = urlString . split ( \"/\" ) [ 1 ] ; if ( token . contains ( \";\" ) ) String [ ] split = token . split ( \";\" ) ; String place = split [ 0 ] ; places . add ( new PlaceRequest ( place ) . with ( params [ 0 ] , params [ 1 ] ) ) ; places . add ( new PlaceRequest ( token ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "for", "MASPECTJ", "-", "16", ":", "support", "classifiers", "and", "types", "."], "add_tokens": "* Module to be referenced through AJC - mojo * @ author < a href = \"mailto:tel@objectnet.no\" > Thor Age Eldby < / a > /** Artifact's classifier */ private String classifier ; /** Artifact's type */ private String type ; String ts = getGroupId ( ) + \":\" + getArtifactId ( ) ; if ( getType ( ) != null ) ts += \":\" + getType ( ) ; // TODO where to place the classifier? return ts ; } / * * * @ return classifier of artifact * / public String getClassifier ( ) { return classifier ; } / * * * @ param classifier classifier of artifact * / public void setClassifier ( String classifier ) { this . classifier = classifier ; } / * * * @ return type of artifact * / public String getType ( ) { return type ; } / * * * @ param type type fo artifact * / public void setType ( String type ) { this . type = type ;", "del_tokens": "* Module to be referenced through AJC - mojo * @ author < a href = \"mailto:tel@objectnet.no\" > Thor ge E dby</ a > return getGroupId ( ) + \":\" + getArtifactId ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "/", "added", "functionality", "in", "FastMoney", "for", "handling", "invalid", "numbers", "and", "algorithmic", "rounding", "problems", "."], "add_tokens": "assertEquals ( \"CHF 1234\" , Money . of ( new BigDecimal ( \"1234.0\" ) , \"CHF\" ) . toString ( ) ) ; assertEquals ( \"CHF 0.01\" , Money . of ( new BigDecimal ( \"0.0100\" ) , \"CHF\" ) . toString ( ) ) ;", "del_tokens": "assertEquals ( \"CHF 1234.0\" , Money . of ( new BigDecimal ( \"1234.0\" ) , \"CHF\" ) . toString ( ) ) ; assertEquals ( \"CHF 0.0100\" , Money . of ( new BigDecimal ( \"0.0100\" ) , \"CHF\" ) . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "mutable", "types", "for", "search", "param", "defaults"], "add_tokens": "import com . google . common . collect . * ; import java . util . HashMap ; static final private List < String > DEFAULT_FACET_FIELD = Lists . newArrayList ( ) ; static final private Map < String , String > DEFAULT_FQ = new HashMap < String , String > ( ) ; static final private List < String > DEFAULT_FL = Lists . newArrayList ( ) ; static final private Map < String , String > DEFAULT_CUSTOM = new HashMap < String , String > ( ) ;", "del_tokens": "import com . google . common . collect . HashMultimap ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . ImmutableMap ; import com . google . common . collect . Multimap ; static final private List < String > DEFAULT_FACET_FIELD = ImmutableList . of ( ) ; static final private Map < String , String > DEFAULT_FQ = ImmutableMap . of ( ) ; static final private List < String > DEFAULT_FL = ImmutableList . of ( ) ; static final private Map < String , String > DEFAULT_CUSTOM = ImmutableMap . of ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "number", "of", "(", "hard", "coded", ")", "iterations", "of", "implied", "vol", "solver", "(", "rarely", "required", "but", "saver", ")", "."], "add_tokens": "final int maxIterations = 500 ;", "del_tokens": "final int maxIterations = 50 ;", "commit_type": "change"}
{"commit_tokens": ["Added", "contract", "between", "builder", "and", "customIcon"], "add_tokens": "public CustomIcon ( CustomIconContract customIconContract ) { this . uuid = customIconContract . getUuid ( ) ; this . data = customIconContract . getData ( ) ;", "del_tokens": "public CustomIcon ( CustomIconBuilder customIconBuilder ) { this . uuid = customIconBuilder . uuid ; this . data = customIconBuilder . data ;", "commit_type": "add"}
{"commit_tokens": ["changed", "Completion", "to", "use", "CompleteOperation", "a", "simple", "holder", "object", "for"], "add_tokens": "* Populate the CompleteOperation object with possible * completions + offset if needed * @ param completeOperation operation void complete ( CompleteOperation completeOperation ) ;", "del_tokens": "* Return a list of possible completions based on the line and * position of the cursor . * @ param line the buffer line * @ param cursor position * @ return possible completions List < String > complete ( String line , int cursor ) ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "path", "to", "obtain", "service"], "add_tokens": "private static String obtainPath = \"/obtain\" ;", "del_tokens": "private static String obtainPath = \"/obtain/getrecord\" ;", "commit_type": "fix"}
{"commit_tokens": ["add", "unit", "test", "+", "modify", "logs"], "add_tokens": "new Result . Failure < > ( pageElement , Messages . FAIL_MESSAGE_UNABLE_TO_FIND_ELEMENT , true , pageElement . getPage ( ) . getCallBack ( ) ) ;", "del_tokens": "new Result . Failure < > ( e . getMessage ( ) , Messages . FAIL_MESSAGE_UNABLE_TO_FIND_ELEMENT , true , pageElement . getPage ( ) . getCallBack ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "generics", "that", "were", "useless", "and", "causes", "compiler", "errors", "on", "Java"], "add_tokens": "public < T > T newImplementorInstance ( Class < T > iface ) ;", "del_tokens": "* public < T , U extends T > U newImplementorInstance ( Class < T > iface ) ;", "commit_type": "change"}
{"commit_tokens": ["updates", "to", "injection", "setup", "and", "navigator", "lifecycle", "calls"], "add_tokens": "import okhttp3 . OkHttpClient ; import okhttp3 . logging . HttpLoggingInterceptor ; import retrofit2 . Retrofit ; import retrofit2 . adapter . rxjava . RxJavaCallAdapterFactory ; import retrofit2 . converter . jackson . JacksonConverterFactory ; private static final String NOAA_API_BASE_URL = \"https://tidesandcurrents.noaa.gov/\" ; return Navigator . withRoot ( new TideLocationsScreen ( ) ) . build ( ) ; } @ Provides @ Singleton static NoaaApi provideNoaaApi ( Retrofit retrofit ) { return retrofit . create ( NoaaApi . class ) ; } @ Provides @ Singleton static Retrofit provideRetrofit ( OkHttpClient httpClient ) { return new Retrofit . Builder ( ) . baseUrl ( NOAA_API_BASE_URL ) . addCallAdapterFactory ( RxJavaCallAdapterFactory . create ( ) ) . addConverterFactory ( JacksonConverterFactory . create ( ) ) . client ( httpClient ) . build ( ) ; } @ Provides @ Singleton static OkHttpClient provideHttpClient ( ) { HttpLoggingInterceptor interceptor = new HttpLoggingInterceptor ( ) ; interceptor . setLevel ( HttpLoggingInterceptor . Level . BODY ) ; return new OkHttpClient . Builder ( ) . addInterceptor ( interceptor ) . build ( ) ;", "del_tokens": "import static com . wealthfront . magellan . Navigator . withRoot ; return Navigator . withRoot ( new HomeScreen ( ) ) . build ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "string", "argument", "equality", "predicate", "."], "add_tokens": "if ( ! parameter . equals ( expected ) ) {", "del_tokens": "if ( parameter . equals ( expected ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "in", "the", "expire", "command"], "add_tokens": "public static LuaAstStringValue stringValue ( String value ) { return new LuaAstStringValue ( value ) ; public static LuaAstIntValue intValue ( int value ) { return new LuaAstIntValue ( value ) ; } public static LuaAstDoubleValue doubleValue ( double value ) { return new LuaAstDoubleValue ( value ) ;", "del_tokens": "public static LuaAstStringValue stringValue ( String key ) { return new LuaAstStringValue ( key ) ; public static LuaAstDoubleValue doubleValue ( double score ) { return new LuaAstDoubleValue ( score ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "a", "few", "German", "abbreviations"], "add_tokens": "private static final String [ ] ABBREV_LIST = { \"Mr\" , \"Mrs\" , \"No\" , \"pp\" , \"St\" , \"no\" , \"Aug\" , \"Sep\" , \"Sept\" , \"Oct\" , \"Okt\" , \"Nov\" , \"Dec\" , \"Ph.D\" , \"PhD\" , // German: \"ggf\" , \"Dr\" , \"Prof\" , \"bspw\" , \"etc\" } ; for ( int i = 0 ; i < ABBREV_LIST . length ; i ++ ) { abbreviations . add ( ABBREV_LIST [ i ] ) ;", "del_tokens": "private static final String [ ] abbrevList = { \"Mr\" , \"Mrs\" , \"No\" , \"pp\" , \"St\" , \"no\" , \"Dr\" , \"Prof\" , \"Aug\" , \"Sep\" , \"Sept\" , \"Oct\" , \"Okt\" , \"Nov\" , \"Dec\" , \"Ph.D\" , \"PhD\" , \"ggf\" } ; for ( int i = 0 ; i < abbrevList . length ; i ++ ) { abbreviations . add ( abbrevList [ i ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "test2ndLevelRead2", "test", "with", "a", "different", "ear", "archive"], "add_tokens": "{ List < VirtualFileHandler > children = handler . getChildren ( true ) ; throw new IOException ( \"Child not found \" + path + \" for \" + handler + \", available children: \" + children ) ; }", "del_tokens": "throw new IOException ( \"Child not found \" + path + \" for \" + handler ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "a", "@JoinColumn", "annotation", "to", "avoid", "a", "couple", "alter", "table", "queries"], "add_tokens": "@ JoinTable ( name = \"rs_attributes\" , joinColumns = @ JoinColumn ( name = \"RegisteredServiceImpl_id\" ) )", "del_tokens": "@ JoinTable ( name = \"rs_attributes\" )", "commit_type": "add"}
{"commit_tokens": ["changed", "entrybuilder", "to", "allow", "initialization", "with", "a", "given", "UUID"], "add_tokens": "public EntryBuilder ( UUID uuid ) { this . uuid = uuid ; } public EntryBuilder uuid ( UUID uuid ) { this . uuid = uuid ; return this ; }", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["Added", "more", "read", "path", "tests", "and", "fix", "bugs", "uncovered", "."], "add_tokens": "static final int BUFFER_SIZE = 2 * READ_LENGTH ; private final AsyncSegmentInputStream asyncInput ; private final CircularBuffer buffer = new CircularBuffer ( BUFFER_SIZE ) ; @ GuardedBy ( \"$lock\" ) private long offset ; SegmentInputStreamImpl ( AsyncSegmentInputStream asyncInput , long offset ) { this . asyncInput = asyncInput ; this . offset = offset ; } while ( ( outstandingRequest != null && outstandingRequest . isDone ( ) && buffer . capacityAvailable ( ) > 0 ) || ( buffer . dataAvailable ( ) < WireCommands . TYPE_PLUS_LENGTH_SIZE ) ) { handleRequest ( ) ; }", "del_tokens": "import lombok . RequiredArgsConstructor ; @ RequiredArgsConstructor private final AsyncSegmentInputStream asyncInput ; private final CircularBuffer buffer = new CircularBuffer ( 2 * SegmentOutputStream . MAX_WRITE_SIZE ) ; private long offset = 0 ; if ( outstandingRequest . isDone ( ) || buffer . dataAvailable ( ) < WireCommands . TYPE_PLUS_LENGTH_SIZE ) { handleRequest ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Adding", "priorities", "and", "starting", "values", "for", "some", "variables"], "add_tokens": "import org . apache . log4j . Logger ; import edu . jhu . hltcoe . parse . IlpViterbiParser ; private static Logger log = Logger . getLogger ( CplexIlpSolver . class ) ; File ordFile = new File ( lpFile . getAbsolutePath ( ) . replace ( \".lp\" , \".ord\" ) ) ; if ( ordFile . exists ( ) ) { log . debug ( \"Reading ORD file: \" + ordFile . getPath ( ) ) ; cplex . readOrder ( ordFile . getAbsolutePath ( ) ) ; } File mstFile = new File ( lpFile . getAbsolutePath ( ) . replace ( \".lp\" , \".mst\" ) ) ; if ( mstFile . exists ( ) ) { log . debug ( \"Reading MST file: \" + mstFile . getPath ( ) ) ; cplex . readMIPStart ( mstFile . getAbsolutePath ( ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "spec", "version", "check", "when", "calculating", "hashes"], "add_tokens": "import org . cyclonedx . CycloneDxSchema ; List < Hash > hashes = BomUtils . calculateHashes ( file , CycloneDxSchema . Version . VERSION_12 ) ;", "del_tokens": "List < Hash > hashes = BomUtils . calculateHashes ( file ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "simple", "resolution", "for", "resolveTypeVariable", "when", "getting", "to", "ParameterizedTypes"], "add_tokens": "// If the currently available resolvedType is still a type variable // retrieve the position of the type variable within the type // variables of the current class, so we can look in the next // subclass for the concrete type } else if ( resolvedType instanceof ParameterizedType ) { // Since we can only want a class object, we don't // care about type arguments of the parameterized type // and just set the raw type of it as the resolved // type resolvedType = ( ( ParameterizedType ) resolvedType ) . getRawType ( ) ; }", "del_tokens": "// If the currently available resolvedType is still a type variable // retrieve the position of the type variable within the type // variables of the current class, so we can look in the next // subclass for the concrete type }", "commit_type": "add"}
{"commit_tokens": ["Remove", "static", "keyword", "for", "resampleImage", "method"], "add_tokens": "private BufferedImage resampleImage ( BufferedImage origImage , int width , int height ) {", "del_tokens": "private static BufferedImage resampleImage ( BufferedImage origImage , int width , int height ) {", "commit_type": "remove"}
{"commit_tokens": ["Removing", "parenthesis", "from", "version", "doesn", "t", "follow", "expected", "user", "agent", "format"], "add_tokens": "client . addUserAgent ( \"Example app\" , \"0.1\" , \"amd64\" ) ;", "del_tokens": "client . addUserAgent ( \"Example app\" , \"(0.1)\" , \"amd64\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["making", "code", "for", "scanning", "WiFi", "more", "readable"], "add_tokens": "WifiManager wifiManager = ( WifiManager ) context . getSystemService ( Context . WIFI_SERVICE ) ; wifiManager . startScan ( ) ;", "del_tokens": "( ( WifiManager ) context . getSystemService ( Context . WIFI_SERVICE ) ) . startScan ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "stronger", "control", "over", "closed", "connections", "validate", "will", "ensure", "a", "client", "does", "not", "come", "out", "the", "pool", "with", "a", "broken", "connection", "."], "add_tokens": "import org . sakaiproject . nakamura . api . lite . StorageClientException ; try { return client . validate ( ) ; } catch ( StorageClientException e ) { return false ; }", "del_tokens": "return client . validate ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "primary", "flag", "to", "Column", "Builder"], "add_tokens": "private Integer index ; private Boolean primary ; * Gets the primary flag for the column . * @ return the primary flag public Boolean getPrimary ( ) { return primary ; * Sets the primary flag for the column . * * @ param primary the new primary flag public AddColumnToSheetBuilder setPrimary ( Boolean primary ) { this . primary = primary ; return this ; column . primary = primary ;", "del_tokens": "private int index ; /** The index. */ private int index ; * Sets the position for the column . * @ param index the index * @ return the adds the column to sheet builder public AddColumnToSheetBuilder setIndex ( int index ) { this . index = index ; return this ; * Gets the index . * @ return the index public int getIndex ( ) { return index ; column . index = index ;", "commit_type": "add"}
{"commit_tokens": ["added", "readme", "files", "and", "light", "convenience", "methods"], "add_tokens": "final Map . Entry < ? , ? > o = ( Map . Entry < ? , ? > ) obj ;", "del_tokens": "final Map . Entry o = ( Map . Entry ) obj ;", "commit_type": "add"}
{"commit_tokens": ["Allowed", "dynamic", "updating", "of", "highlight", "or", "veto", "policies", "from", "a", "calendar", "selection", "listener", "."], "add_tokens": "* * Note : Any calendar selection listeners will be notified before the calendar is redrawn , so * that the programmer may optionally update any tightly linked code that may affect this * particular redrawing of the calendar . ( For example , a programmer might be change a highlight * policy based on the currently selected date . ) drawCalendar ( displayedYearMonth ) ;", "del_tokens": "drawCalendar ( displayedYearMonth ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "new", "toggle", "icons", "and", "fixed", "issue", "with", "rippler", "if", "its", "position", "was", "behind", "the", "control"], "add_tokens": "import com . cctintl . c3dfx . controls . C3DToggleButton ; import com . cctintl . c3dfx . controls . C3DToggleNode ; import de . jensd . fx . fontawesome . Icon ; C3DToggleNode node = new C3DToggleNode ( ) ; Icon value = new Icon ( \"HEART\" ) ; value . setPadding ( new Insets ( 10 ) ) ; node . setGraphic ( value ) ; node . setText ( \"AA\" ) ; pane . getChildren ( ) . add ( node ) ;", "del_tokens": "import com . cctintl . c3dfx . controls . C3DToggleButton ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "alert", "channel", "show", "method"], "add_tokens": "import java . util . List ; import java . util . ArrayList ; * Returns the alert channel with the given id . * @ return The alert channel / * * * Returns the set of alert channels with the given name . * < P > * This is needed because the API does not contain an operation to get a channel using the name directly . * @ param name The name of the alert channels to return * @ return The set of alert channels * / public Collection < AlertChannel > show ( String name ) { List < AlertChannel > ret = new ArrayList < AlertChannel > ( ) ; Collection < AlertChannel > channels = list ( ) ; for ( AlertChannel channel : channels ) { if ( channel . getName ( ) . equals ( name ) ) ret . add ( channel ) ; } return ret ; }", "del_tokens": "* Returns the set of alert channels with the given name . * @ return The set of alert channels", "commit_type": "add"}
{"commit_tokens": ["use", "PippoRuntimeException", "with", "varargs", "(", "similar", "with", "Logger", "from", "slf4j", ")"], "add_tokens": "private static final Logger log = LoggerFactory . getLogger ( TrimouTemplateEngine . class ) ; throw new PippoRuntimeException ( \"Template '{}' not found!\" , templateName ) ;", "del_tokens": "private final Logger log = LoggerFactory . getLogger ( TrimouTemplateEngine . class ) ; throw new PippoRuntimeException ( String . format ( \"Template '%s' not found!\" , templateName ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "reverse", "()", "in", "SequenceSet", "and", "SequenceMap"], "add_tokens": "import junit . framework . Assert ; @ Test public void testReversal ( ) { SequenceSet < Integer > s = new SequenceSet < > ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { s . add ( i ) ; } SequenceSet < Integer > n = s . reverse ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertEquals ( 9 - i , n . get ( i ) . intValue ( ) ) ; } System . out . println ( n ) ; } @ Test public void testReversalMap ( ) { SequenceMap < Integer , String > s = new SequenceMap < > ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { s . put ( i , String . valueOf ( i ) ) ; } SequenceMap < Integer , String > n = s . reverse ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertEquals ( 9 - i , n . indexOf ( i ) ) ; } System . out . println ( n ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "pipeline", "and", "stages", "processing", "metrics"], "add_tokens": "import com . codahale . metrics . Timer ; import com . streamsets . pipeline . metrics . MetricsConfigurator ; import java . util . concurrent . TimeUnit ; private List < StageOutput > stageOutput ; private Timer processingTimer ; processingTimer = MetricsConfigurator . createTimer ( metrics , \"pipeline.batchProcessing\" ) ; long start = System . currentTimeMillis ( ) ; processingTimer . update ( System . currentTimeMillis ( ) - start , TimeUnit . MILLISECONDS ) ;", "del_tokens": "private volatile List < StageOutput > stageOutput ;", "commit_type": "add"}
{"commit_tokens": ["Making", "animate", "markers", "on", "still", "highlight", "flag", "configurable", "in", "XML"], "add_tokens": "mAnimateMarkersOnStillHighlight = a . getBoolean ( R . styleable . CircularView_animateMarkersOnStillHighlight , false ) ;", "del_tokens": "mAnimateMarkersOnStillHighlight = false ;", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "of", "-", "and", "fixed", "some", "bugs", "in", "-", "TemporalProperty", "and", "TemporalExpiringProperty", "."], "add_tokens": "import java . util . concurrent . ConcurrentHashMap ; public static final Instant EXPIRES_NEVER = new Instant ( Long . MAX_VALUE ) ; Set < PropertyChangeListener < T > > listeners = Collections . newSetFromMap ( new ConcurrentHashMap < PropertyChangeListener < T > , Boolean > ( ) ) ; public void set ( Instant expires , T value ) { void set ( Instant effectiveFrom , Instant expires , T value ) { / * * * Adds a new listener to notify when the property 's value is changed. * < p > * Note , that the listener wil currently NOT be notified when a value expires . < br / > * That may change in a future version . * * @ see dk . clanie . properties . ObservableProperty # addChangeListener ( dk . clanie . properties . PropertyChangeListener ) * /", "del_tokens": "import java . util . concurrent . ConcurrentSkipListMap ; private static final Instant EXPIRES_NEVER = new Instant ( Long . MAX_VALUE ) ; Set < PropertyChangeListener < T > > listeners = Collections . newSetFromMap ( new ConcurrentSkipListMap < PropertyChangeListener < T > , Boolean > ( ) ) ; private void set ( Instant expires , T value ) { private void set ( Instant effectiveFrom , Instant expires , T value ) {", "commit_type": "add"}
{"commit_tokens": ["Using", "ServletContextCache", "for", "more", "throughput", "on", "Tomcat", "."], "add_tokens": "import com . aoindustries . servlet . ServletContextCache ; && ServletContextCache . getResource ( servletContext , pagePath ) != null", "del_tokens": "&& servletContext . getResource ( pagePath ) != null", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "type", "-", "checking", "bug", "in", "instanceof", "."], "add_tokens": "* Determines whether the given node is a FOR , DO , or WHILE node .", "del_tokens": "* Determines whether the given node is a FOR , DO , WHILE , WITH , or IF node .", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "proper", "calls", "to", "preDestroy", "for", "output", "writers", "and", "ensured"], "add_tokens": "private JmxTransExporterConfiguration config ; private volatile JmxTransExporterConfiguration newConfiguration ; replaceConfigurationIfChanged ( ) ; private void replaceConfigurationIfChanged ( ) { if ( newConfiguration != null ) { logger . log ( Level . INFO , \"Configuration has changed, destroying the old configuration and replacing with the new\" ) ; config . destroy ( ) ; config = newConfiguration ; newConfiguration = null ; } } this . newConfiguration = configuration ;", "del_tokens": "private volatile JmxTransExporterConfiguration config ; this . config = configuration ;", "commit_type": "implement"}
{"commit_tokens": ["Made", "fields", "final", "where", "possible", "."], "add_tokens": "private final int [ ] params ; private final int repeat ;", "del_tokens": "private int [ ] params ; private int repeat ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "Generics", "bug", "in", "Probability", "Match"], "add_tokens": "public class ProbailityMatch < T > implements Comparable < ProbailityMatch < T > >", "del_tokens": "public class ProbailityMatch < T > implements Comparable < ProbailityMatch >", "commit_type": "fix"}
{"commit_tokens": ["Allow", "unicode", "characters", "in", "passwords", "."], "add_tokens": "private static final Pattern PASSWORD_PATTERN = Pattern . compile ( \"^[^\\\\x00-\\\\x1F]{5,}$\" ) ;", "del_tokens": "private static final Pattern PASSWORD_PATTERN = Pattern . compile ( \"^[a-zA-Z0-9_-]{5,}$\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "table", "list", "in", "example"], "add_tokens": "import java . util . ArrayList ; * * @ author sbrunner private List < Processor > iterProcessors = new ArrayList < Processor > ( ) ;", "del_tokens": "private List < Processor > iterProcessors ;", "commit_type": "add"}
{"commit_tokens": ["Add", "repo", "id", "(", "necessary", "for", "authentication", ")"], "add_tokens": "log ( LOG_DEBUG , \"Allow snapshots: \" + allowSnapshots ) ;", "del_tokens": "log ( LOG_DEBUG , \"Allow snapshots: \" + offline ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "dependency", "versions", "and", "improved", "Spring", "configuration"], "add_tokens": "import org . springframework . boot . autoconfigure . EnableAutoConfiguration ; import org . springframework . context . annotation . ComponentScan ; import org . springframework . context . annotation . Configuration ; @ Configuration @ EnableAutoConfiguration @ ComponentScan", "del_tokens": "import org . springframework . boot . autoconfigure . SpringBootApplication ; @ SpringBootApplication", "commit_type": "update"}
{"commit_tokens": ["Remove", "duplicate", "minBy", "and", "maxBy", "methods", "in", "BiFunction"], "add_tokens": "return reduce ( BinaryOperator . Util . minBy ( comparator ) ) ; return reduce ( BinaryOperator . Util . maxBy ( comparator ) ) ;", "del_tokens": "return reduce ( BiFunction . Util . minBy ( comparator ) ) ; return reduce ( BiFunction . Util . maxBy ( comparator ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "overlapping", "areas", "in", "topology"], "add_tokens": "import java . util . Collection ; * Finds an area at the specified position in the grid . If there are multiple areas sharing * the same position , the first of them is returned in a non - deterministic way . Therefore , * this method should be used for topologies that do not allow overlapping areas . * @ return the area at the specified position or { @ code null } when there is no such area / * * * Finds all the areas at the specified position in the grid . * @ param x the x coordinate of the grid cell * @ param y the y coordinate of the grid cell * @ return the collection of areas at the specified position or an empty collection when there is no such area * / public Collection < Area > findAllAreasAt ( int x , int y ) ;", "del_tokens": "* Finds an area at the specified position in the grid . * @ return the node at the specified position or { @ code null } when there is no such area", "commit_type": "allow"}
{"commit_tokens": ["Add", "progressbar", "to", "splash", "screen"], "add_tokens": "import javafx . scene . control . ProgressBar ; import javafx . scene . layout . VBox ; ImageView imageView = new ImageView ( getClass ( ) . getResource ( getImagePath ( ) ) . toExternalForm ( ) ) ; ProgressBar splashProgressBar = new ProgressBar ( ) ; splashProgressBar . setPrefWidth ( imageView . getImage ( ) . getWidth ( ) ) ; VBox vbox = new VBox ( ) ; vbox . getChildren ( ) . addAll ( imageView , splashProgressBar ) ; return vbox ;", "del_tokens": "Pane imagePane = new Pane ( ) ; Image img = new Image ( getClass ( ) . getResource ( getImagePath ( ) ) . toExternalForm ( ) ) ; imagePane . getChildren ( ) . add ( new ImageView ( img ) ) ; return imagePane ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "when", "sending", "request", "with", "non", "-", "ASCII", "chars"], "add_tokens": "byte [ ] bytes = body . getBytes ( StandardCharsets . UTF_8 ) ; this . bodyLength = bytes . length ; this . body = new ByteArrayInputStream ( bytes ) ;", "del_tokens": "this . bodyLength = body . length ( ) ; this . body = new ByteArrayInputStream ( body . getBytes ( StandardCharsets . UTF_8 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "debug", "method", "for", "easy", "way", "of", "sending", "messages", "to", "System", ".", "out"], "add_tokens": "private static String sPortalBaseDir = null ; public boolean DEBUG = false ; / * * * Just a simple debug method that prints * messages to System . out * / public void debug ( String message ) { if ( DEBUG ) System . out . println ( \"DEBUG: \" + message ) ; }", "del_tokens": "private static String sPortalBaseDir = null ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "more", "fields", "to", "the", "tumor", "level", "..."], "add_tokens": "* @ return the number of read records processedCount += patient . getTumors ( ) . size ( ) ;", "del_tokens": "* @ return the number of written patients processedCount ++ ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "SecurityException", "in", "NetworkController", "regarding", "missing", "Bluetooth", "permission"], "add_tokens": "import android . Manifest ; import android . content . pm . PackageManager ; return isBluetoothAvailable ( ) && hasBlueBoothPermission ( ) && bluetoothAdapter . isEnabled ( ) ; } private boolean hasBlueBoothPermission ( ) { return context . checkCallingOrSelfPermission ( Manifest . permission . BLUETOOTH ) == PackageManager . PERMISSION_GRANTED ;", "del_tokens": "return isBluetoothAvailable ( ) && bluetoothAdapter . isEnabled ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "read", "me", "for", "blitz4j", "."], "add_tokens": "if ( this . props != null ) { Enumeration enumeration = this . props . propertyNames ( ) ; while ( enumeration . hasMoreElements ( ) ) { String key = ( String ) enumeration . nextElement ( ) ; ConfigurationManager . getConfigInstance ( ) . setProperty ( key , props . getProperty ( key ) ) ; }", "del_tokens": "Enumeration enumeration = props . propertyNames ( ) ; while ( enumeration . hasMoreElements ( ) ) { String key = ( String ) enumeration . nextElement ( ) ; ConfigurationManager . getConfigInstance ( ) . setProperty ( key , props . getProperty ( key ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "no", "type", "to", "search"], "add_tokens": "if ( index . getType ( ) != null && index . getType ( ) . trim ( ) . length ( ) > 0 ) {", "del_tokens": "if ( index . getType ( ) != null ) { } else { list . add ( \"_all\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "setInnerPaddingColor", "getInnerPaddingColor", "and", "set", "the", "default", "color", "to", "background_holo_light"], "add_tokens": "/ * * * Sets the InnerPadding 's color. After setting a recalculation is initiated. * @ param color the new InnerPadding 's color * / public void setInnerPaddingColor ( int color ) { mInnerPaddingColor = color ; onDataChanged ( ) ; } / * * * Returns the color of the InnerPadding . * * @ return the color of the InnerPadding * / public int getInnerPaddingColor ( ) { return mInnerPaddingColor ; } mGraphPaint . setColor ( mInnerPaddingColor ) ; private int mInnerPaddingColor = Color . parseColor ( \"#fff3f3f3\" ) ; // Holo light background", "del_tokens": "mGraphPaint . setColor ( 0xFFFFFFFF ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "getPackageInstaller", "()", "method", "."], "add_tokens": "@ Nullable public static String getPackageInstaller ( @ NonNull final Context context ) { return packageManager . getInstallerPackageName ( context . getPackageName ( ) ) ;", "del_tokens": "import android . text . TextUtils ; / * * * Checks if an application with the passed name is the installer of the calling app . * * @ param packageName The package name of the tested application . * @ return true if the application with the passed package is the installer . * / public static boolean isPackageInstaller ( @ NonNull final Context context , @ Nullable final String packageName ) { final String appPackageName = context . getPackageName ( ) ; final String installerPackageName = packageManager . getInstallerPackageName ( appPackageName ) ; return TextUtils . equals ( installerPackageName , packageName ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Map", "instead", "of", "an", "implementation", "."], "add_tokens": "public static void namedUpdateQuery ( String query , Map < String , Object > parameters ) { private static List < Object > namedQuery ( String query , Map < String , Object > parameters , boolean change ) {", "del_tokens": "public static void namedUpdateQuery ( String query , HashMap < String , Object > parameters ) { private static List < Object > namedQuery ( String query , HashMap < String , Object > parameters , boolean change ) {", "commit_type": "use"}
{"commit_tokens": ["added", "a", "test", "for", "generalize", "case"], "add_tokens": "Geometry large_dev1 = OperatorGeneralize . local ( ) . execute ( int pc1 = ( ( MultiPath ) large_dev1 ) . getPointCount ( ) ; Geometry large_dev2 = OperatorGeneralize . local ( ) . execute ( densified_geom , 40 , false , null ) ; int pc2 = ( ( MultiPath ) large_dev2 ) . getPointCount ( ) ; assertTrue ( pc2 == 3 ) ;", "del_tokens": "Geometry large_dev = OperatorGeneralize . local ( ) . execute ( int pc1 = ( ( MultiPath ) large_dev ) . getPointCount ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "further", "benchmark", "to", "make", "customer", "showcase", "more", "realistic", "add", "first", "results"], "add_tokens": "w . setName ( \"benchmarka\" + format . format ( new Date ( ) ) ) ; // Todo: Create fresh workspace in MTM s . setName ( h . getUniqueString ( ) ) ; s . setDescription ( h . getUniqueText ( 10 ) ) ; r . setName ( h . getUniqueString ( ) ) ; r . setDescription ( h . getUniqueText ( 10 ) ) ;", "del_tokens": "import net . leanix . dropkit . api . Client ; import net . leanix . mtm . api . WorkspacesApi ; import org . kohsuke . randname . RandomNameGenerator ; RandomNameGenerator rnd = new RandomNameGenerator ( 0 ) ; w . setName ( \"benchmark\" + format . format ( new Date ( ) ) ) ; // Todo: Create workspace s . setName ( rnd . next ( ) ) ; s . setDescription ( \"Create by SDK\" ) ; r . setName ( rnd . next ( ) ) ; r . setDescription ( \"Created by SDK\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "output", "properties", "."], "add_tokens": "import org . codehaus . mojo . xml . transformer . OutputProperty ; t = newTransformer ( template , pTransformationSet ) ; private Transformer newTransformer ( Templates template , TransformationSet pTransformationSet ) throws TransformerConfigurationException , MojoExecutionException , MojoFailureException { Transformer t = template . newTransformer ( ) ; OutputProperty [ ] properties = pTransformationSet . getOutputProperties ( ) ; if ( properties != null ) { for ( int i = 0 ; i < properties . length ; i ++ ) { final String name = properties [ i ] . getName ( ) ; if ( name == null || \"\" . equals ( name ) ) { throw new MojoFailureException ( \"Missing or empty output property name\" ) ; } final String value = properties [ i ] . getValue ( ) ; if ( value == null ) { throw new MojoFailureException ( \"Missing value for output property \" + name ) ; } try { t . setOutputProperty ( name , value ) ; } catch ( IllegalArgumentException e ) { throw new MojoExecutionException ( \"Unsupported property name or value: \" + name + \" => \" + value + e . getMessage ( ) , e ) ; } } } return t ; }", "del_tokens": "t = template . newTransformer ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "ToolbarHelper", "to", "ToolbarManager", ".", "Add", "support", "to", "manager", "many", "groups", "instead", "of", "normal", "and", "contextual", "group", "."], "add_tokens": "ViewCompat . postOnAnimation ( DatePicker . this , this ) ; ViewCompat . postOnAnimation ( DatePicker . this , this ) ; ViewCompat . postOnAnimation ( DatePicker . this , this ) ; ViewCompat . postOnAnimation ( DatePicker . this , this ) ;", "del_tokens": "postOnAnimation ( this ) ; System . out . println ( \"scroll by: \" + scrollBy + \" \" + lastPos + \" \" + mTargetPos ) ; postOnAnimation ( this ) ; postOnAnimation ( this ) ; System . out . println ( \"scroll by: \" + scrollBy + \" \" + firstPos + \" \" + mTargetPos ) ; postOnAnimation ( this ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "keep", "-", "alive", "support", "."], "add_tokens": "while ( ! finalAccept . isClosed ( ) ) { session . execute ( ) ; } e . printStackTrace ( ) ; pw . print ( \"HTTP/1.1 \" + status . getDescription ( ) + \" \\r\\n\" ) ; int pending = data != null ? data . available ( ) : - 1 ; // This is to support partial sends, see serveFile() if ( pending > 0 ) { pw . print ( \"Connection: keep-alive\\r\\n\" ) ; pw . print ( \"Content-Length: \" + pending + \"\\r\\n\" ) ; } safeClose ( outputStream ) ; safeClose ( outputStream ) ; FileOutputStream fileOutputStream = null ; fileOutputStream = new FileOutputStream ( tempFile . getName ( ) ) ; FileChannel dest = fileOutputStream . getChannel ( ) ; safeClose ( fileOutputStream ) ;", "del_tokens": "session . execute ( ) ; pw . print ( \"HTTP/1.0 \" + status . getDescription ( ) + \" \\r\\n\" ) ; int pending = data . available ( ) ; // This is to support partial sends, see serveFile() safeClose ( outputStream ) ; FileOutputStream outputStream = null ; outputStream = new FileOutputStream ( tempFile . getName ( ) ) ; FileChannel dest = outputStream . getChannel ( ) ; safeClose ( outputStream ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "initial", "version", "of", "my", "UPC", "reader", "and", "modified", "some", "common", "files"], "add_tokens": "import com . google . zxing . upc . UPCReader ; boolean tryUPC = false ; boolean tryQR = false ; if ( possibleFormats == null ) { tryUPC = true ; tryQR = true ; } else if ( possibleFormats . contains ( BarcodeFormat . UPC ) ) { tryUPC = true ; } else if ( possibleFormats . contains ( BarcodeFormat . QR_CODE ) ) { tryQR = true ; // UPC is much faster to decode, so try it first. if ( tryUPC ) { try { return new UPCReader ( ) . decode ( image , hints ) ; } catch ( ReaderException e ) { } } // Then fall through to QR codes. if ( tryQR ) { try { return new QRCodeReader ( ) . decode ( image , hints ) ; } catch ( ReaderException e ) { } } throw new ReaderException ( ) ;", "del_tokens": "// TODO for now we are only support QR Code so this behaves accordingly. This needs to // become more sophisticated if ( possibleFormats == null || possibleFormats . contains ( BarcodeFormat . QR_CODE ) ) { return new QRCodeReader ( ) . decode ( image , hints ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "spring", "resource", "cache", "content", "in", "inputstream"], "add_tokens": "return IO . readContentAsString ( springResource . getFile ( ) ) ;", "del_tokens": "return IO . readContentAsString ( springResource . getInputStream ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "data", "property", "to", "field", "options"], "add_tokens": "import com . google . code . siren4j . annotations . Siren4JOptionData ; @ Siren4JFieldOption ( title = \"option2\" , value = \"foo2\" , optionDefault = true , data = { @ Siren4JOptionData ( key = \"key1\" , value = \"value1\" ) , @ Siren4JOptionData ( key = \"key2\" , value = \"value2\" ) } )", "del_tokens": "@ Siren4JFieldOption ( title = \"option2\" , value = \"foo2\" , optionDefault = true )", "commit_type": "add"}
{"commit_tokens": ["Allow", "argument", "validations", "in", "the", "same", "way", "as", "object", "validation"], "add_tokens": "this , result . invalidElementsMap ( ) , element , filter , target result . addInvalidElement ( invalidElement ) ;", "del_tokens": "this , result . invalidElements , element , filter , target result . invalidElements . put ( invalidElement . name ( ) , invalidElement ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "NullPointerException", "appearance", "when", "action", "with", "parameters", "invoked", "in", "initial", "state", "."], "add_tokens": "T trans_trigger = t . getTrigger ( ) ; if ( trans_trigger != null && trans_trigger . equals ( trigger ) ) {", "del_tokens": "if ( t . getTrigger ( ) . equals ( trigger ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "that", "show", "open", "issues", "with", "non", "visible", "classes", "and", "classes", "without", "default", "constructor"], "add_tokens": "LOG . log ( Level . SEVERE , \"Could not set field value for field \" + field , e ) ; output . add ( object , field . getName ( ) ) ;", "del_tokens": "JavolutionTranscoder . _log . log ( Level . WARNING , \"Could not set field value for field \" + field ) ; output . add ( object ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "getTreasureDataCredentials", "method", "in", "TreasureDataClient", "class"], "add_tokens": "return apiKey ; return String . format ( \"%s{apiKey=%s}\" , this . getClass ( ) . getName ( ) ,", "del_tokens": "return apiKey ; // null return String . format ( \"%s{apiKey=%s}\" , TreasureDataCredentials . class . getName ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "redacted", "fields", "to", "be", "hidden", "from", "toString"], "add_tokens": "import java . util . regex . Pattern ; private static final Pattern REDACTED_PATTERN = Pattern . compile ( \"\\\\W@redacted\\\\W\" ) ; boolean isRedacted = REDACTED_PATTERN . matcher ( field . documentation ( ) ) . find ( ) ; if ( isRedacted ) { toString . addStatement ( \"sb.append(\\\"<REDACTED>\\\")\" ) ; } if ( field . required ( ) ) {", "del_tokens": "if ( field . required ( ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Removed", "dependency", "with", "internal", "Prodevelop", "Maven", "Repo"], "add_tokens": "import es . alrocar . csv . CsvReader ;", "del_tokens": "import java . util . List ; import org . apache . commons . lang3 . StringUtils ; import es . alrocar . jpe . parser . JPEParser ; import es . prodevelop . csv . CsvReader ; import es . prodevelop . gvsig . mini . geom . AttributePoint . Attribute ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "null", "reference", "in", "the", "log", "message"], "add_tokens": "String classLevelUri = resolveRequestUri ( controllerClass , requestMapping ( controllerClass ) ) ; String classLevelUri = resolveRequestUri ( controllerClass , requestMapping ( controllerClass ) ) ; String methodLevelUri = resolveRequestUri ( controllerClass , requestMapping ( handlerMethod . getMethod ( ) ) ) ; protected static String resolveRequestUri ( Class clazz , RequestMapping requestMapping ) { log . info ( \"Class {} has no @RequestMapping\" , clazz ) ; log . info ( \"Class {} contains a @RequestMapping, but could not resolve the uri\" , clazz ) ; clazz ) ;", "del_tokens": "String classLevelUri = resolveRequestUri ( requestMapping ( controllerClass ) ) ; String classLevelUri = resolveRequestUri ( requestMapping ( controllerClass ) ) ; String methodLevelUri = resolveRequestUri ( requestMapping ( handlerMethod . getMethod ( ) ) ) ; protected static String resolveRequestUri ( RequestMapping requestMapping ) { log . info ( \"Class {} has no @RequestMapping\" , requestMapping ) ; log . info ( \"Class {} contains a @RequestMapping, but could not resolve the uri\" , requestMapping ) ; requestMapping ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "case", "for", "serialization", "of", "OWLOneOf"], "add_tokens": "public void testShouldSerializeOWLObjectOneOfImpl ( ) { delayTestFinish ( TEST_DELAY_MS ) ; OWLDataFactoryImpl dataFactory = new OWLDataFactoryImpl ( false , false ) ; final OWLIndividual indA = dataFactory . getOWLNamedIndividual ( IRI . create ( \"http://org.semanticweb.owlapi/a\" ) ) ; final OWLIndividual indB = dataFactory . getOWLNamedIndividual ( IRI . create ( \"http://org.semanticweb.owlapi/b\" ) ) ; final OWLIndividual indC = dataFactory . getOWLNamedIndividual ( IRI . create ( \"http://org.semanticweb.owlapi/c\" ) ) ; Set < OWLIndividual > operands = CollectionFactory . createSet ( indA , indB , indC ) ; final OWLObjectOneOfImpl in = new OWLObjectOneOfImpl ( operands ) ; OWLObjectSerializationTestsServiceAsync service = GWT . create ( OWLObjectSerializationTestsService . class ) ; service . testOWLObjectOneOfImpl ( in , new AsyncCallback < OWLObjectOneOfImpl > ( ) { @ Override public void onFailure ( Throwable throwable ) { throwable . printStackTrace ( ) ; fail ( throwable . getMessage ( ) ) ; } @ Override public void onSuccess ( OWLObjectOneOfImpl out ) { assertEquals ( in , out ) ; finishTest ( ) ; } } ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "factory", "to", "use", "new", "simplified", "model", "."], "add_tokens": "public Concept createNamedConcept ( String id ) { public Role createNamedRole ( String id ) { public Feature createNamedFeature ( String id ) { public Concept createExistential ( Role role , Concept filler ) { public Concept createDatatype ( Feature feature , Operator operator , Literal literal ) {", "del_tokens": "public Concept createConcept ( String id ) { public Role createRole ( String id ) { public Feature createFeature ( String id ) { public Concept createExistential ( NamedRole role , Concept filler ) { public Concept createDatatype ( NamedFeature feature , Operator operator , Literal literal ) {", "commit_type": "update"}
{"commit_tokens": ["fixed", "compilation", "problem", "with", "java", "7"], "add_tokens": "public Statement apply ( final Statement statement , final Description description ) {", "del_tokens": "public Statement apply ( Statement statement , Description description ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "better", "message", "to", "send", "to", "IDE", "when", "an", "error", "occurrs"], "add_tokens": "messager . printMessage ( WARNING , \"PEAPOD: an error has occurred while generating code.. \" + e . getMessage ( ) + \" \" + Arrays . toString ( e . getStackTrace ( ) ) ) ;", "del_tokens": "messager . printMessage ( ERROR , \"PEAPOD: an error has occurred while generating code.. \" + e . getMessage ( ) + \" \" + e . getStackTrace ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "boxed", "-", "type", "null", "handling"], "add_tokens": "ConverterTarget unwrapped = Parcels . unwrap ( ParcelsTestUtil . wrap ( target ) ) ;", "del_tokens": "import android . os . Parcelable ; android . os . Parcel parcel = android . os . Parcel . obtain ( ) ; Parcelable parcelable = new ConverterTarget $$ Parcelable ( target ) ; parcelable . writeToParcel ( parcel , 0 ) ; ConverterTarget unwrapped = Parcels . unwrap ( new ConverterTarget $$ Parcelable ( parcel ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "hasOutput", "property", "to", "Block", "interface"], "add_tokens": "@ Override public boolean getHasOutput ( ) { return true ; } * ParamOutputBlock bound to the scope in which it was defined and the @ Override public boolean getHasOutput ( ) { return source != null ; }", "del_tokens": "* ParameterOutputBlock bound to the scope in which it was defined and the", "commit_type": "add"}
{"commit_tokens": ["Add", "capability", "to", "set", "up", "Html", "Unit", "browser", "language"], "add_tokens": "public static final String BROWSER_LANGUAGE_CAPABILITY = \"browserLanguage\" ; BrowserVersion browserVersionObject = BrowserVersion . getDefault ( ) ; browserVersionObject = BrowserVersion . FIREFOX_38 ; browserVersionObject = BrowserVersion . FIREFOX_45 ; browserVersionObject = BrowserVersion . FIREFOX_45 ; browserVersionObject = BrowserVersion . CHROME ; browserVersionObject = BrowserVersion . INTERNET_EXPLORER ; } Object rawLanguage = capabilities . getCapability ( BROWSER_LANGUAGE_CAPABILITY ) ; if ( rawLanguage instanceof String ) { browserVersionObject . setBrowserLanguage ( ( String ) rawLanguage ) ; return browserVersionObject ;", "del_tokens": "return BrowserVersion . FIREFOX_38 ; return BrowserVersion . FIREFOX_45 ; return BrowserVersion . FIREFOX_45 ; return BrowserVersion . CHROME ; return BrowserVersion . INTERNET_EXPLORER ; return BrowserVersion . getDefault ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "::", "|"], "add_tokens": "public RubyArray < E > ( R ubyArray< E > ther) return union ( other ) ; }", "del_tokens": "public RubyArray < E > ( R ubyArray< E > ther) return union ( other ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "issue", "22", "and", "refactoring", "bits", "of", "HAL", "to", "use", "new", "data", "structures", "shrink", "code", "duplication", "and", "eliminate", "the", "use", "of", "secret", "properties", "for", "setting", "critical", "parameters", "."], "add_tokens": "return windowSize - ( Math . abs ( positionOffset ) - 1 ) ; }", "del_tokens": "return windowSize - ( Math . abs ( positionOffset ) - 1 ) ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "sort", "multiple", "targets", "feature", "."], "add_tokens": "import java . util . Collections ; private boolean isSortedTargets = false ; // check text value to sort the targets checkNumeric ( textBody ) ; private void checkNumeric ( String text ) { try { int target_order = Integer . parseInt ( text . trim ( ) ) ; isSortedTargets = true ; slideShape . setTargetOrder ( target_order ) ; } catch ( NumberFormatException e ) { return ; } } // check if sorting shapes is required if ( isSortedTargets ) { sortShapes ( ) ; } private void sortShapes ( ) { Collections . sort ( shapesList ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "of", "JRebel", "reloading"], "add_tokens": "/** enable JRebel reloading */ private boolean jrebel ; initJRebel ( ) ; jrebel = true ; protected void initJRebel ( ) { if ( jrebel ) { bind ( ClassMetadataReloader . class ) . asEagerSingleton ( ) ; } }", "del_tokens": "bind ( ClassMetadataReloader . class ) . asEagerSingleton ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "WrappedSqlException", "to", "allow", "IncrementalRows", "to", "throw", "a", "SQLException", "(", "Parth", "Chandra", ")"], "add_tokens": "throw new WrappedSqlException ( ex ) ;", "del_tokens": "throw new RuntimeException ( ex . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "the", "mean", "for", "an", "int", "array"], "add_tokens": "final double [ ] badArrayDouble = { } ; assertTrue ( \"testing the mean\" , Double . isNaN ( tsp . mean ( badArrayDouble ) ) ) ; int [ ] arr = { 1 , 5 , 8 , 7 , 6 } ; assertEquals ( \"testing the mean\" , 5.4 , tsp . mean ( arr ) , delta ) ; final int [ ] badArrayInt = { } ; assertTrue ( \"testing the mean\" , Double . isNaN ( tsp . mean ( badArrayInt ) ) ) ;", "del_tokens": "final double [ ] badArray = { } ; assertTrue ( \"testing the mean\" , Double . isNaN ( tsp . mean ( badArray ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "MultiAudience#of", "to", "Audience#of", "and", "use", "for", "-", "loops", "instead", "of", "forEach"], "add_tokens": "* An audience that forwards to another audience . @ FunctionalInterface", "del_tokens": "* An audience that forwards all methods to another audience .", "commit_type": "move"}
{"commit_tokens": ["Add", "specialised", "exception", "to", "indicate", "token", "is", "expired"], "add_tokens": "throw new TokenExpiredException ( \"Token is expired\" ) ;", "del_tokens": "throw new TokenValidationException ( \"Token is expired\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "DatagramSocket", "constructor", "to", "use", "the", "lookback", "address", "to", "bind", "on", ".", "This", "fixes", "an", "issue", "on", "Windows", "systems", "where", "the", "DatagramSocket", ".", "close", "()", "takes", "3000", "ms", "to", "unbind", "when", "connecting", "to", "a", "non", "exisitig", "or", "disabled", "graylog", "server", "in", "the", "same", "subnet", "."], "add_tokens": "import java . net . * ; private final SocketAddress loopbackAddress = new InetSocketAddress ( \"localhost\" , 0 ) ; return new DatagramSocket ( loopbackAddress ) ;", "del_tokens": "import java . net . DatagramPacket ; import java . net . DatagramSocket ; import java . net . InetAddress ; import java . net . SocketException ; return new DatagramSocket ( ) ;", "commit_type": "change"}
{"commit_tokens": ["update", "messaging", "types", "and", "message", "tags"], "add_tokens": "MESSAGE_TAG", "del_tokens": "MESSAGE_TAG , @ SerializedName ( \"NON_PROMOTIONAL_SUBSCRIPTION\" ) NON_PROMOTIONAL_SUBSCRIPTION", "commit_type": "update"}
{"commit_tokens": ["Made", "methods", "to", "read", "and", "write", "var", "signed", "ints", "public"], "add_tokens": "public static void writeVariableLengthUnsignedInt ( int i , DataOutput dataOutput ) throws IOException { public static int readVariableLengthUnsignedInt ( DataInput dataInput ) throws IOException {", "del_tokens": "protected static void writeVariableLengthUnsignedInt ( int i , DataOutput dataOutput ) throws IOException { protected static int readVariableLengthUnsignedInt ( DataInput dataInput ) throws IOException {", "commit_type": "make"}
{"commit_tokens": ["Add", "utils", "class", ";", "load", "nanopub", "from", "TriG", "file"], "add_tokens": "import java . io . File ; import java . io . FileInputStream ; import java . io . IOException ; import java . io . InputStream ; import org . openrdf . OpenRDFException ; import org . openrdf . rio . RDFHandlerException ; import org . openrdf . rio . helpers . RDFHandlerBase ; import org . openrdf . rio . trig . TriGParser ; public NanopubImpl ( File trigFile ) throws MalformedNanopubException , IOException { final List < Statement > statements = new ArrayList < Statement > ( ) ; TriGParser p = new TriGParser ( ) ; p . setRDFHandler ( new RDFHandlerBase ( ) { @ Override public void handleStatement ( Statement st ) throws RDFHandlerException { statements . add ( st ) ; } } ) ; InputStream in = new FileInputStream ( trigFile ) ; try { p . parse ( in , \"\" ) ; } catch ( OpenRDFException ex ) { ex . printStackTrace ( ) ; } in . close ( ) ; init ( statements ) ; } private void init ( Collection < Statement > statements ) throws MalformedNanopubException { if ( pubinfoUri == null ) {", "del_tokens": "public void init ( Collection < Statement > statements ) throws MalformedNanopubException { if ( pubinfo == null ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "some", "extra", "<p", ">"], "add_tokens": "* * * * * * * * * * * *", "del_tokens": "* < p > * < p > * < p > * < p > * < p > * < p > * < p > * < p > * < p > * < p > * < p > * < p >", "commit_type": "remove"}
{"commit_tokens": ["Fix", "filter", "host", "supplier", "without", "alternate", "ip", "addresses"], "add_tokens": "Host foundHost = lookup . get ( host . getHostName ( ) ) ; if ( foundHost == null ) { for ( String addr : host . getAlternateIpAddresses ( ) ) { foundHost = lookup . get ( addr ) ; if ( foundHost != null ) { break ; } if ( foundHost != null ) { host . setTokenRanges ( foundHost . getTokenRanges ( ) ) ; return true ; }", "del_tokens": "for ( String addr : host . getAlternateIpAddresses ( ) ) { Host foundHost = lookup . get ( addr ) ; if ( foundHost != null ) { host . setTokenRanges ( foundHost . getTokenRanges ( ) ) ; return true ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "when", "the", "application", "has", "multiple", "types", "of", "request", "mapping", "handlers"], "add_tokens": "private final WebApplicationContext context ; private boolean isMappingBuilt = false ; private List < RequestMappingHandlerMapping > handlerMappings ; List < RequestMappingHandlerMapping > handlerMappings ) { this . context = context ; this . handlerMappings = handlerMappings ; for ( RequestMappingHandlerMapping handlerMapping : handlerMappings ) { processMethod ( handlerMapping ) ; } isMappingBuilt = true ; public Documentation getDocumentation ( ) { if ( ! isMappingBuilt ) { buildMappingDocuments ( context ) ; } return documentation ; }", "del_tokens": "private RequestMappingHandlerMapping handlerMapping ; @ Getter RequestMappingHandlerMapping handlerMapping ) { this . handlerMapping = handlerMapping ; buildMappingDocuments ( context ) ; processMethod ( handlerMapping ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "SuroControl", "to", "wait", "for", "shutdown", "command"], "add_tokens": "private static void waitForShutdown ( int port ) throws IOException { new SuroControl ( ) . start ( port ) ;", "del_tokens": "import java . net . ServerSocket ; import java . net . Socket ; import java . util . concurrent . Future ; private static void waitForShutdown ( int port ) { ServerSocket serverSocket ; try { serverSocket = new ServerSocket ( port ) ; Socket client = serverSocket . accept ( ) ; } catch ( IOException e ) { System . err . println ( \"Exception: couldn't create socket\" ) ; System . exit ( 1 ) ; }", "commit_type": "use"}
{"commit_tokens": ["Added", "parseRadar", "to", "allow", "more", "than", "MAXIMUM_PAGE_RESULTS", "per", "parse", "."], "add_tokens": "* @ return Next page token parseResults ( client , places , results , Math . min ( limit , MAXIMUM_PAGE_RESULTS ) ) ; / * * * Parses the specified Radar raw json String into a list of places . * * @ param places to parse into * @ param str Radar raw json * @ param limit the maximum amount of places to return * / public static void parseRadar ( GooglePlaces client , List < Place > places , String str , int limit ) { // parse json JSONObject json = new JSONObject ( str ) ; // check root elements String statusCode = json . getString ( STRING_STATUS ) ; checkStatus ( statusCode , json . optString ( STRING_ERROR_MESSAGE ) ) ; if ( statusCode . equals ( STATUS_ZERO_RESULTS ) ) return ; JSONArray results = json . getJSONArray ( ARRAY_RESULTS ) ; parseResults ( client , places , results , Math . min ( limit , MAXIMUM_RADAR_RESULTS ) ) ; }", "del_tokens": "* @ return list of parsed places parseResults ( client , places , results , limit ) ; limit = Math . min ( limit , MAXIMUM_PAGE_RESULTS ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "ClassCastException", "when", "looking", "at", "the", "internals", "of", "an", "InvocationTargetException", "."], "add_tokens": "Throwable t = e ; if ( t instanceof InvocationTargetException ) { t = t . getCause ( ) ; throw new RuntimeException ( \"Unable to reset views for \" + target , t ) ; Throwable t = e ; if ( t instanceof InvocationTargetException ) { t = t . getCause ( ) ; throw new RuntimeException ( \"Unable to inject views for \" + target , t ) ;", "del_tokens": "if ( e instanceof InvocationTargetException ) { e = ( Exception ) e . getCause ( ) ; throw new RuntimeException ( \"Unable to reset views for \" + target , e ) ; if ( e instanceof InvocationTargetException ) { e = ( Exception ) e . getCause ( ) ; throw new RuntimeException ( \"Unable to inject views for \" + target , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "changes", "of", "wrapTextProperty", "show", "immediately", "."], "add_tokens": "import javafx . beans . InvalidationListener ; import org . fxmisc . richtext . Paragraph ; import org . fxmisc . richtext . StyledTextArea ; private final InvalidationListener onWrapWidthChange = obs -> requestLayout ( ) ; boolean wasEmpty = this . isEmpty ( ) ; if ( ! wasEmpty ) { // dispose old ParagraphGraphic (unregister listeners etc.) ParagraphGraphic < S > oldGraphic = getParagraphGraphic ( ) ; } super . updateItem ( item , empty ) ; if ( wasEmpty && ! empty ) { startListening ( ) ; } else if ( ! wasEmpty && empty ) { stopListening ( ) ; } } else if ( getWrapWidth ( ) == Region . USE_COMPUTED_SIZE ) { private void startListening ( ) { skin . wrapWidth . addListener ( onWrapWidthChange ) ; } private void stopListening ( ) { skin . wrapWidth . removeListener ( onWrapWidthChange ) ; }", "del_tokens": "import org . fxmisc . richtext . Paragraph ; import org . fxmisc . richtext . StyledTextArea ; super . updateItem ( item , empty ) ; // dispose old ParagraphGraphic (unregister listeners etc.) tryGetParagraphGraphic ( ) . ifPresent ( oldGraphic -> { } ) ; } else if ( skin . wrapWidth . get ( ) == Region . USE_COMPUTED_SIZE ) {", "commit_type": "make"}
{"commit_tokens": ["use", "singleton", "for", "service", "bus", "clients", "and", "update", "azure", "packages", "to", "latest"], "add_tokens": "public static final ReceiveMode QUEUE_RECEIVE_MODE = ReceiveMode . PEEKLOCK ; public static final ReceiveMode SUBSCRIPTION_RECEIVE_MODE = ReceiveMode . PEEKLOCK ;", "del_tokens": "public static final ReceiveMode QUEUE_RECEIVE_MODE = ReceiveMode . PeekLock ; public static final ReceiveMode SUBSCRIPTION_RECEIVE_MODE = ReceiveMode . PeekLock ;", "commit_type": "use"}
{"commit_tokens": ["Added", "WHATTF", "syntax", "to", "validate", "HTML", "5"], "add_tokens": "return new InputSource ( HtmlValidationResponseFilter . class . getResourceAsStream ( \"/relaxng/\" + systemId ) ) ;", "del_tokens": "return new InputSource ( HtmlValidationResponseFilter . class . getResourceAsStream ( \"/schemas/html5/\" + systemId ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "check", "so", "only", "instances", "of", "ContextualUndoView", "are", "swipeable", ".", "Allowing", "for", "mixing", "of", "view", "types", "with", "some", "un", "-", "dissmissible"], "add_tokens": "if ( mDownView != null && mDownView instanceof ContextualUndoView ) { return false ;", "del_tokens": "if ( mDownView != null ) { return false ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "state", "from", "GitHub", "Client"], "add_tokens": ". setInterceptor ( gitHubMockInterceptor ) ;", "del_tokens": "GitHubServiceFactory . reset ( ) ; . getGitHubService ( \"https://api.github.com/repos/tomasbjerre/git-changelog-lib\" , null , gitHubMockInterceptor ) ;", "commit_type": "remove"}
{"commit_tokens": ["Adding", "attributes", "html", "and", "outerHtml"], "add_tokens": "* the attr annotation value . html and outerHtml are also valid values for attr . * For example : * A field mapping a the inner html code of a link with id foo * < / p > * < pre > * { @ code @ Selector ( value = \"#foo\" , attr = \"html\" ) String fooHtml ; } * < / pre > * A field mapping a the outer html code of a link with id foo * < / p > * < pre > * { @ code @ Selector ( value = \"#foo\" , attr = \"outerHtml\" ) String fooOuterHtml ; } * < / pre >", "del_tokens": "* the attr annotation value . See the examples on how to do that .", "commit_type": "add"}
{"commit_tokens": ["Remove", "redundant", "type", "parameter", "from", "custom", "assertion", "assertMismatch", "."], "add_tokens": "public static void assertMismatch ( Object input , Matcher < ? > matcher , Pattern descriptionOfMismatch )", "del_tokens": "public static < T > void assertMismatch ( Object input , Matcher < ? > matcher , Pattern descriptionOfMismatch )", "commit_type": "remove"}
{"commit_tokens": ["add", "the", "missing", "CPOSTAG", "convert", "from", "POS_RP"], "add_tokens": "} else if ( pos . equals ( LangLib . POS_POS ) || pos . equals ( LangLib . POS_RP ) ) {", "del_tokens": "} else if ( pos . equals ( LangLib . POS_POS ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "grammar", "and", "SmiNotificationType", "so", "that", "IfMibTest", "now", "passes"], "add_tokens": "// TODO What exactly should this method do for the case of NOTIFICATION-TYPE? //m_type = m_type.resolveThis(reporter, null);", "del_tokens": "m_type = m_type . resolveThis ( reporter , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "sonar", "clone", "()", "warnings"], "add_tokens": "return null != coordinate && ( Math . abs ( this . x - coordinate . x ) < delta && Math . abs ( this . y - coordinate . y ) < delta ) ; public Object clone ( ) { // NOSONAR super.clone() not supported by GWT", "del_tokens": "if ( coordinate == null ) { return false ; } return ( Math . abs ( this . x - coordinate . x ) < delta && Math . abs ( this . y - coordinate . y ) < delta ) ; public Object clone ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "regular", "mutable", "list", "instead", "of", "copying", "an", "immutable", "list", "on", "each", "mutation"], "add_tokens": "import static com . google . common . collect . Lists . newArrayList ; private final List < FileMetaData > files ; this . files = newArrayList ( files ) ; files . add ( fileMetaData ) ;", "del_tokens": "private List < FileMetaData > files ; this . files = ImmutableList . copyOf ( files ) ; files = ImmutableList . < FileMetaData > builder ( ) . addAll ( files ) . add ( fileMetaData ) . build ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "build", "and", "findbugs", "warnings"], "add_tokens": "import org . apache . commons . io . Charsets ; * @ param excludeExtensions a set of extensions with which jarStream . write ( json . getBytes ( Charsets . UTF_8 ) ) ;", "del_tokens": "* @ param excludedExtensions a set of extensions with which FileOutputStream outputStream = null ; jarStream . write ( json . getBytes ( ) ) ; if ( outputStream != null ) { IOUtils . closeQuietly ( outputStream ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Move", "helper", "method", "to", "Utils", "."], "add_tokens": "classSimpleName = Utils . getClassSimpleName ( className ) ;", "del_tokens": "classSimpleName = getClassSimpleName ( className ) ; /* Fake Class#getSimpleName logic. */ private static String getClassSimpleName ( String className ) { int lastPeriod = className . lastIndexOf ( \".\" ) ; if ( lastPeriod != - 1 ) { return className . substring ( lastPeriod + 1 ) ; } else { return className ; } }", "commit_type": "move"}
{"commit_tokens": ["added", "profile", "call", "and", "fixed", "request", "access", "token", "api", "call"], "add_tokens": "KiteConnect kiteConnect = new KiteConnect ( \"xxxxxxtyyy\" ) ; kiteConnect . setUserId ( \"yyyyyy\" ) ; User user = kiteConnect . requestAccessToken ( \"xxxyyyyzzzzzz\" , \"xxxxxxx\" ) ; examples . getProfile ( kiteConnect ) ;", "del_tokens": "KiteConnect kiteConnect = new KiteConnect ( \"xxxxxxxxxxx\" ) ; kiteConnect . setUserId ( \"xxxxxx\" ) ; User user = kiteConnect . requestAccessToken ( \"xxxxxxxx\" , \"xxxxxxxx\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "specific", "execption", "message", "."], "add_tokens": "throw new MojoExecutionException ( \"Failed to write the tidy POM.\" , e ) ;", "del_tokens": "throw new MojoExecutionException ( e . getMessage ( ) , e ) ;", "commit_type": "use"}
{"commit_tokens": ["Made", "the", "Device", "class", "and", "Vacuum", "class", "serializable", "and", "added", "serialisation", "test", "."], "add_tokens": "import java . io . ObjectInputStream ; import java . io . ObjectOutputStream ; import java . io . Serializable ; public class Device implements Serializable { private static final long serialVersionUID = - 924264471464948810L ; private static byte [ ] rcv = new byte [ 65507 ] ; private transient DatagramSocket socket ; private void writeObject ( ObjectOutputStream out ) throws IOException { out . defaultWriteObject ( ) ; out . writeInt ( socket . getSoTimeout ( ) ) ; } private void readObject ( ObjectInputStream in ) throws IOException , ClassNotFoundException { in . defaultReadObject ( ) ; socket = new DatagramSocket ( ) ; socket . setSoTimeout ( in . readInt ( ) ) ; }", "del_tokens": "public class Device { private byte [ ] rcv = new byte [ 65507 ] ; private DatagramSocket socket ;", "commit_type": "make"}
{"commit_tokens": ["changing", "the", "rest", "path", "to", "the", "api", "prefix"], "add_tokens": "return \"/api/domains/\" + domain + \"/projects/\" + project + \"/cia/events\" ;", "del_tokens": "return \"/rest/domains/\" + domain + \"/projects/\" + project + \"/cia/events\" ;", "commit_type": "change"}
{"commit_tokens": ["Use", "same", "value", "as", "original", "libnoise"], "add_tokens": "return controlPoints . get ( index1 ) . outputValue ;", "del_tokens": "return controlPoints . get ( lastIndex ) . outputValue ;", "commit_type": "use"}
{"commit_tokens": ["Updating", "file", "name", "from", "dest", ".", "properties", "to", "ctct_api", ".", "properties"], "add_tokens": "in = Config . class . getClassLoader ( ) . getResourceAsStream ( \"ctct_api.properties\" ) ;", "del_tokens": "in = Config . class . getClassLoader ( ) . getResourceAsStream ( \"dest.properties\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "sugar", "method", "for", "generating", "intervals", "of", "selectable", "times"], "add_tokens": "import android . support . annotation . IntRange ; public Timepoint ( @ IntRange ( from = 0 , to = 23 ) int hour , @ IntRange ( from = 0 , to = 59 ) int minute , @ IntRange ( from = 0 , to = 59 ) int second ) { public Timepoint ( @ IntRange ( from = 0 , to = 23 ) int hour , @ IntRange ( from = 0 , to = 59 ) int minute ) { public Timepoint ( @ IntRange ( from = 0 , to = 23 ) int hour ) { @ IntRange ( from = 0 , to = 23 ) @ IntRange ( from = 0 , to = 59 ) @ IntRange ( from = 0 , to = 59 )", "del_tokens": "public Timepoint ( int hour , int minute , int second ) { public Timepoint ( int hour , int minute ) { public Timepoint ( int hour ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "context", "as", "it", "is", "not", "really", "used", "."], "add_tokens": "public MongoDatabaseProvider ( ) { this ( null , null ) ; } public MongoDatabaseProvider ( String mongoPortProperty , String mongoDbNameProperty ) { String uniqueName = String . format ( \"%s_%s\" , UUID . randomUUID ( ) . toString ( ) . substring ( 0 , 3 ) ,", "del_tokens": "private final Object context ; public MongoDatabaseProvider ( Object context , String mongoPortProperty , String mongoDbNameProperty ) { this . context = context ; public MongoDatabaseProvider ( String mongoPortProperty , String mongoDbNameProperty ) { this ( \"\" , mongoPortProperty , mongoDbNameProperty ) ; } public MongoDatabaseProvider ( Object context ) { this ( context , null , null ) ; } public MongoDatabaseProvider ( ) { this ( \"\" ) ; } String uniqueName = String . format ( \"%s_%s_%s\" , UUID . randomUUID ( ) . toString ( ) , context , if ( uniqueName . length ( ) > 32 ) { uniqueName = uniqueName . substring ( uniqueName . length ( ) - 32 ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "thread", "handling", "for", "completion", "listeners", "add", "test", "cases", "to", "check", "correctness", "."], "add_tokens": "new Handler ( Looper . getMainLooper ( ) ) . post ( new Runnable ( ) { @ Override public void run ( ) { if ( null != completionListener ) { completionListener . onError ( \"Error encoding message\" ) ; } } } ) ; } else { new Handler ( Looper . getMainLooper ( ) ) . post ( new Runnable ( ) { @ Override public void run ( ) { if ( null != completionListener ) { completionListener . onError ( \"Can't complete request when not connected. Please reconnect!\" ) ; } } } ) ;", "del_tokens": "if ( null != completionListener ) { completionListener . onError ( \"Error encoding message\" ) ; } } else if ( null != completionListener ) { completionListener . onError ( \"Can't complete request when not connected. Please reconnect!\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "issue", "with", "repeated", "options", "taking", "only", "the", "last", "value", "specified", ";"], "add_tokens": "if ( ! arguments . containsKey ( option ) ) { valuesForCurrentArgument = new ArrayList < String > ( ) ; arguments . put ( option , valuesForCurrentArgument ) ; } valuesForCurrentArgument = arguments . get ( option ) ;", "del_tokens": "valuesForCurrentArgument = new ArrayList < String > ( ) ; arguments . put ( option , valuesForCurrentArgument ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "basic", "test", "to", "verify", "cookies", "are", "sent", "and", "received", ".", "@psh"], "add_tokens": "public class GetAndPostIntegrationTest extends IntegrationTestBase < GetAndPostIntegrationTest . TestServer > { @ Override public TestServer createTestServer ( ) { return new TestServer ( ) ; }", "del_tokens": "public class GetAndPostIntegrationTest { private HttpClient httpclient ; private TestServer testServer ; @ Before public void setUp ( ) { testServer = new TestServer ( ) ; httpclient = new DefaultHttpClient ( ) ; try { testServer . start ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } @ After public void tearDown ( ) { httpclient . getConnectionManager ( ) . shutdown ( ) ; testServer . stop ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["removed", "redundant", "line", "in", "EntityFactory", "simplified", "setUp", "()", "in", "EntityIdFromTest"], "add_tokens": "TypeMapper mapper = typeMapper ( ) . registerAllDummyTypes ( ) . build ( ) ;", "del_tokens": "TypeMapper mapper = typeMapper ( ) . registerEntity ( DummyUserDetails . class ) . registerValueObject ( DummyNetworkAddress . class ) . build ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "object", "hook", "and", "testcase"], "add_tokens": "import java . util . Map ; final ObjectHook < ? > objectHook ; public JsonStream ( Reader reader , JsonObjectFactory jsonObjectFactory , JsonArrayFactory jsonArrayFactory , ObjectHook < ? > objectHook ) { this . objectHook = objectHook != null ? objectHook : ( map ) -> { return map ; } ; if ( v . type == StackValue . TYPE_OBJECT ) { @ SuppressWarnings ( \"unchecked\" ) Map < String , Object > map = ( Map < String , Object > ) v . value ; return this . objectHook . toObject ( map ) ; }", "del_tokens": "public JsonStream ( Reader reader , JsonObjectFactory jsonObjectFactory , JsonArrayFactory jsonArrayFactory ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "config"], "add_tokens": "final Set < InetSocketAddress > instances ; final EVCacheServerGroupConfig config ; if ( instancesSpecific . containsKey ( rSet ) ) { config = instancesSpecific . get ( rSet ) ; instances = config . getInetSocketAddress ( ) ; } else { instances = new HashSet < InetSocketAddress > ( ) ; config = new EVCacheServerGroupConfig ( rSet , instances , rendPort , rendMemcachedPort , rendMementoPort ) ; instancesSpecific . put ( rSet , config ) ; }", "del_tokens": "final Set < InetSocketAddress > instances = new HashSet < InetSocketAddress > ( ) ; final EVCacheServerGroupConfig config = new EVCacheServerGroupConfig ( rSet , instances , rendPort , rendMemcachedPort , rendMementoPort ) ; if ( ! instancesSpecific . containsKey ( rSet ) ) instancesSpecific . put ( rSet , config ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "embedding", "site", "page"], "add_tokens": "@ SuppressWarnings ( { \"rawtypes\" } ) return loadFromPluginAnnotation ( clazz , null ) ; } public static PluginDefinition loadFromPluginAnnotation ( final IPluginInterface pluginInstance ) { return loadFromPluginAnnotation ( pluginInstance . getClass ( ) , pluginInstance ) ; } @ SuppressWarnings ( { \"rawtypes\" , \"unchecked\" } ) private static PluginDefinition loadFromPluginAnnotation ( final Class clazz , final IPluginInterface pluginInstance ) { PluginDefinition def ; if ( pluginInstance == null ) { def = new PluginDefinition ( name , description , clazz ) ; } else { def = new PluginDefinition ( name , description , pluginInstance ) ; }", "del_tokens": "@ SuppressWarnings ( { \"rawtypes\" , \"unchecked\" } ) PluginDefinition def = new PluginDefinition ( name , description , clazz ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "test", "for", "Assertion", "error"], "add_tokens": "import org . junit . rules . ExpectedException ; @ Rule public ExpectedException exception = ExpectedException . none ( ) ; // https://github.com/marklogic/marklogic-sesame/issues/66 // https://github.com/marklogic/marklogic-sesame/issues/68 // https://github.com/marklogic/marklogic-sesame/issues/61 // https://github.com/marklogic/marklogic-sesame/issues/63 @ Test public void addWithNull ( ) throws Exception { ValueFactory f = conn . getValueFactory ( ) ; final URI alice = f . createURI ( \"http://example.org/people/alice\" ) ; URI name = f . createURI ( \"http://example.org/ontology/name\" ) ; exception . expect ( AssertionError . class ) ; Statement st = f . createStatement ( alice , name , null ) ; }", "del_tokens": "//https://github.com/marklogic/marklogic-sesame/issues/66 //https://github.com/marklogic/marklogic-sesame/issues/68 //https://github.com/marklogic/marklogic-sesame/issues/61", "commit_type": "add"}
{"commit_tokens": ["use", "special", "-", "header", "MAGIC", "in", "PADDING", "instead", "of", "simple", "NULL"], "add_tokens": "private final static byte MAGIC_PADDING = 0x42 ; if ( alignBlocks && ( magicB1 == MAGIC_PADDING ) ) { bufOutput . put ( MAGIC_PADDING ) ; // Magic for Padding int i = 1 ;", "del_tokens": "if ( alignBlocks && ( magicB1 == 0 ) ) { int i = 0 ;", "commit_type": "use"}
{"commit_tokens": ["add", "generics", "resolution", "method", "preserving", "root", "variables"], "add_tokens": "final Map < Class < ? > , LinkedHashMap < String , Type > > generics = GenericsResolutionUtils . resolveWithRootVariables ( type , null ) ;", "del_tokens": "import java . util . Collections ; @ SuppressWarnings ( \"PMD.AvoidInstantiatingObjectsInLoops\" ) // leave type variables to track where would they go final LinkedHashMap < String , Type > rootGenerics = new LinkedHashMap < String , Type > ( ) ; for ( TypeVariable var : type . getTypeParameters ( ) ) { // special variables type, known by resolver (no exceptions for unknown generics will be thrown) rootGenerics . put ( var . getName ( ) , new ExplicitTypeVariable ( var ) ) ; } final Map < Class < ? > , LinkedHashMap < String , Type > > generics = GenericsResolutionUtils . resolve ( type , rootGenerics , Collections . < Class < ? > , LinkedHashMap < String , Type > > emptyMap ( ) , Collections . < Class < ? > > emptyList ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "mandatory", "tags", "to", "successfully", "deploy", "artifacts", "to", "sonatype"], "add_tokens": "* Handles the distributed write to cassandra in batch . *", "del_tokens": "* Created by luca on 05 / 02 / 14.", "commit_type": "add"}
{"commit_tokens": ["Changed", "Event", "stream", "return", "type", "from", "Observable", "to", "Flowable", "."], "add_tokens": "import io . github . robwin . circuitbreaker . utils . CircuitBreakerUtils ; import io . reactivex . Flowable ; Flowable < CircuitBreakerEvent > getEventStream ( ) ;", "del_tokens": "import io . github . robwin . circuitbreaker . utils . CircuitBreakerUtils ; import io . reactivex . Observable ; Observable < CircuitBreakerEvent > getEventStream ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "the", "new", "spreadsheet", "table", "detector", "for", "the", "-", "g", "command", "line", "option"], "add_tokens": "import technology . tabula . detectors . DetectionAlgorithm ; import technology . tabula . detectors . SpreadsheetDetectionAlgorithm ; // guess the page areas to extract using a detection algorithm // currently we only have a detector that uses spreadsheets to find table areas DetectionAlgorithm detector = new SpreadsheetDetectionAlgorithm ( ) ; List < Rectangle > guesses = detector . detect ( page ) ; for ( Rectangle guessRect : guesses ) { Page guess = page . getArea ( guessRect ) ; tables . addAll ( basicExtractor . extract ( guess ) ) ; } } else { tables . addAll ( verticalRulingPositions == null ? basicExtractor . extract ( page ) : basicExtractor . extract ( page , verticalRulingPositions ) ) ;", "del_tokens": "tables . addAll ( verticalRulingPositions == null ? basicExtractor . extract ( page ) : basicExtractor . extract ( page , verticalRulingPositions ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "node", "iterator", "in", "ontology", "to", "return", "unique", "values", "."], "add_tokens": "Set < Node < T > > set = new HashSet < > ( nodeMap . values ( ) ) ; return set . iterator ( ) ;", "del_tokens": "return nodeMap . values ( ) . iterator ( ) ;", "commit_type": "update"}
{"commit_tokens": ["made", "the", "filters", "on", "StatementClient", "return", "a", "new", "object", "rather", "than", "mutate", "the", "current", "one"], "add_tokens": "protected String username ; protected String password ; } this . username = user ; this . password = password ;", "del_tokens": "} final String username = user ;", "commit_type": "make"}
{"commit_tokens": ["Add", "class", "level", "javadoc", "indicating", "that", "all", "returned", "dates", "are", "limited", "to", "4", "-", "digit", "years"], "add_tokens": "* LocalDate } s , etc . * * < p > Note : Currently , all returned dates that contain a year field are limited to 4 - digit years , * i . e , 1 , 000 - 9 , 999. In future versions , a flag may be added to limit to 4 - digit years or not .", "del_tokens": "* LocalDate } s , etc . .", "commit_type": "add"}
{"commit_tokens": ["change", "visibility", "of", "the", "class"], "add_tokens": "class AutomataFactory", "del_tokens": "public class AutomataFactory", "commit_type": "change"}
{"commit_tokens": ["made", "dynamic", "jdbc", "mapper", "use", "duplicate", "of", "class", "meta", "for", "thread", "safety"], "add_tokens": "final ResultSetMapperBuilder < T > builder = new ResultSetMapperBuilderImpl < T > ( target , classMeta . duplicate ( ) , setterFactory , AsmHelper . isAsmPresent ( ) ) ;", "del_tokens": "final ResultSetMapperBuilder < T > builder = new ResultSetMapperBuilderImpl < T > ( target , classMeta , setterFactory , AsmHelper . isAsmPresent ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "DualAbstractHandler", "so", "that", "netty", "-", "router", "can", "be", "used", "in", "Sinetja", "more", "easily"], "add_tokens": "public abstract class DualAbstractHandler < RouteLike extends MethodRouter < Object , RouteLike > > extends AbstractHandler < Object , RouteLike > { public DualAbstractHandler ( MethodRouter < Object , RouteLike > router ) {", "del_tokens": "public abstract class DualAbstractHandler extends AbstractHandler < Object , Router > { public DualAbstractHandler ( Router router ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "area", "for", "high", "speed", "headers", "."], "add_tokens": "public static final int OBJECT_NAME_POS = 5 ; public static final int METHOD_NAME_POS = 6 ; public static final int ARGS_POS = 7 ;", "del_tokens": "public static final int OBJECT_NAME_POS = 4 ; public static final int METHOD_NAME_POS = 5 ; public static final int ARGS_POS = 6 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "null", "check", "to", "findByCriteria", "()", "."], "add_tokens": "if ( c != null ) { criteria . add ( c ) ; }", "del_tokens": "criteria . add ( c ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "possibility", "to", "config", "the", "map", "type", "between", "Hybrid", "Terrain", "Satellite", "and", "RoadMap", "."], "add_tokens": "MapTypeId mapTypeId = builder . mapTypeId != null ? builder . mapTypeId : MapTypeId . TERRAIN ; options . setMapTypeId ( mapTypeId ) ; MapTypeId mapTypeId ; public Builder setMapTypeId ( MapTypeId mapTypeId ) { this . mapTypeId = mapTypeId ; return this ; }", "del_tokens": "options . setMapTypeId ( MapTypeId . TERRAIN ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "without", "(", "T", "T", "...", ")", "to", "C", ".", "List"], "add_tokens": "elements = _ . concat ( elements , element ) ; }", "del_tokens": "} ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "setWatcher", "()", "compile", "error", "."], "add_tokens": "watcher . setUpdateCallback ( this :: loadPolicy ) ;", "del_tokens": "watcher . setUpdateCallback ( loadPolicy ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "queries", "list", "and", "userDefined", "boolean"], "add_tokens": "import com . stratio . streaming . commons . messages . StreamQuery ; import java . io . Serializable ; public class StratioStream implements Serializable { private List < StreamQuery > queries ; private Boolean userDefined ; public StratioStream ( String streamName , List < ColumnNameTypeValue > columns , List < StreamQuery > queries ) { this . queries = queries ; } public Boolean getUserDefined ( ) { return userDefined ; } public void setUserDefined ( Boolean userDefined ) { this . userDefined = userDefined ; } public List < StreamQuery > getQueries ( ) { return queries ; } public void setQueries ( List < StreamQuery > queries ) { this . queries = queries ;", "del_tokens": "public class StratioStream { public StratioStream ( String streamName , List < ColumnNameTypeValue > columns ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "TestSubscriber#assertValuesWith", "(", "Consumer<T", ">", "...", "expectations", ")"], "add_tokens": "/ * * * Assert the specified values have been received . Values storage should be enabled to * use this method . * @ param expectations One or more methods that can verify the values and throw a * exception ( like an { @ link AssertionError } ) if the value is not valid . * @ see # configureValuesStorage ( boolean ) * / public final TestSubscriber < T > assertValuesWith ( Consumer < T > ... expectations ) { if ( ! valuesStorage ) { throw new IllegalStateException ( \"Using assertNoValues() requires enabling values storage\" ) ; } final int expectedValueCount = expectations . length ; if ( expectedValueCount != values . size ( ) ) { throw new AssertionError ( \"Different value count: expected = \" + expectedValueCount + \", actual = \" + valueCount , null ) ; } for ( int i = 0 ; i < expectedValueCount ; i ++ ) { Consumer < T > consumer = expectations [ i ] ; T actualValue = values . get ( i ) ; consumer . accept ( actualValue ) ; } return this ; } T actualValue = nextValuesSnapshot . get ( i ) ; consumer . accept ( actualValue ) ;", "del_tokens": "T actualSignal = nextValuesSnapshot . get ( i ) ; consumer . accept ( actualSignal ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "ClassCastException", "with", "bad", "username", "."], "add_tokens": "IQ response = ( IQ ) collector . nextResult ( 5000 ) ; if ( response == null ) { // If the server replied with an error, throw an exception. else if ( response . getType ( ) == IQ . Type . ERROR ) { throw new XMPPException ( response . getError ( ) ) ; // Otherwise, no error so continue processing. Authentication authTypes = ( Authentication ) response ; collector . cancel ( ) ; response = ( IQ ) collector . nextResult ( 5000 ) ;", "del_tokens": "Authentication authTypes = ( Authentication ) collector . nextResult ( 5000 ) ; collector . cancel ( ) ; if ( authTypes == null ) { else if ( authTypes . getType ( ) . equals ( IQ . Type . ERROR ) ) { throw new XMPPException ( authTypes . getError ( ) ) ; IQ response = ( IQ ) collector . nextResult ( 5000 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "JDoc", "and", "made", "minor", "code", "improvements", "."], "add_tokens": "* Provides the default connection factory . * @ Produces @ Singleton", "del_tokens": "@ Produces @ Singleton", "commit_type": "add"}
{"commit_tokens": ["Move", "recommended", "third", "-", "party", "vocabulary", "to", "new", "class", "NanopubVocab"], "add_tokens": "addPubinfoStatement ( NanopubVocab . CREATION_TIME , vf . createLiteral ( date ) ) ; addPubinfoStatement ( NanopubVocab . HAS_CREATOR , creator ) ; addPubinfoStatement ( NanopubVocab . HAS_AUTHOR , author ) ;", "del_tokens": "addPubinfoStatement ( NanopubImpl . CREATION_TIME , vf . createLiteral ( date ) ) ; addPubinfoStatement ( NanopubImpl . HAS_CREATOR , creator ) ; addPubinfoStatement ( NanopubImpl . HAS_AUTHOR , author ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "dependency", "on", "EasyBind", "."], "add_tokens": "import javafx . beans . binding . Bindings ; Bindings . bindContent ( getChildren ( ) , cellListManager . getNodes ( ) ) ; Bindings . unbindContent ( getChildren ( ) , cellListManager . getNodes ( ) ) ;", "del_tokens": "import org . fxmisc . easybind . EasyBind ; private final org . fxmisc . easybind . Subscription childrenBinding ; this . childrenBinding = EasyBind . listBind ( getChildren ( ) , cellListManager . getNodes ( ) ) ; childrenBinding . unsubscribe ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "some", "tests", "for", "Drawables", "class"], "add_tokens": "Bitmap bitmap = bitmapUtils . getScaledBitmap ( data , scaleToWidth , scaleToHeight ) ; drawable = createDrawable ( bitmap , key ) ; public void setMetrics ( DisplayMetrics metrics ) { this . metrics = metrics ; } Bitmap bitmap = bitmapUtils . getScaledBitmap ( in , pixelsX , pixelsY ) ; CacheableDrawable drawable = createDrawable ( bitmap , name ) ; protected CacheableDrawable createDrawable ( Bitmap bitmap , String name ) { return new CacheableDrawable ( bitmap , name ) ; }", "del_tokens": "import android . graphics . BitmapFactory ; Bitmap bitmap = bitmapUtils . getScaledBitmap ( BitmapFactory . decodeByteArray ( data , 0 , data . length ) , scaleToWidth , scaleToHeight ) ; drawable = new CacheableDrawable ( bitmap , key ) ; Bitmap bitmap = bitmapUtils . getScaledBitmap ( BitmapFactory . decodeStream ( in ) , pixelsX , pixelsY ) ; CacheableDrawable drawable = new CacheableDrawable ( bitmap , name ) ;", "commit_type": "add"}
{"commit_tokens": ["Implementing", "JedisCommands", "interface", "for", "interace", "compatibility"], "add_tokens": "return client . get ( ) . get ( key ) ;", "del_tokens": "//.setPort(22122) //.setRetryPolicyFactory(new RetryNTimes.RetryFactory(1, true)) //.setMaxConnsPerHost(3) //.withHostSupplier(new EurekaHostsSupplier(\"dynomite_redis_puneet\", 22122)) return client . get ( ) . get ( key ) . getResult ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Updated", "domain", "objects", "according", "to", "new", "version", "of", "the", "api"], "add_tokens": "private String shortLink ; public String getShortLink ( ) { return shortLink ; public void setShortLink ( String shortLink ) { this . shortLink = shortLink ; public String getShortUrl ( ) { return shortUrl ; } public void setShortUrl ( String shortUrl ) { this . shortUrl = shortUrl ; }", "del_tokens": "public String getShortUrl ( ) { return shortUrl ; public void setShortUrl ( String shortUrl ) { this . shortUrl = shortUrl ;", "commit_type": "update"}
{"commit_tokens": ["add", "another", "example", "...", "MemoryPool", "...", "this", "uses"], "add_tokens": "public String getDataSourceName ( String typeName , String attributeName , String entry ) { String typeNameClean = \"\" ; if ( typeName != null ) { typeNameClean = cleanupStr ( typeName ) ; } String caps = WordUtils . capitalize ( typeNameClean + \".\" + attributeName , PERIOD ) ; String key = getDataSourceName ( retrieveTypeNameValue ( res . getTypeName ( ) ) , res . getAttributeName ( ) , entry . getKey ( ) ) ; boolean isNumeric = JmxUtils . isNumeric ( entry . getValue ( ) ) ; if ( isNumeric ) { String key = getDataSourceName ( retrieveTypeNameValue ( res . getTypeName ( ) ) , res . getAttributeName ( ) , entry . getKey ( ) ) ; sb . append ( \"<datasource><name>\" + key + \"</name><type>GAUGE</type><heartbeat>400</heartbeat><min>U</min><max>U</max></datasource>\\n\" ) ; }", "del_tokens": "public static String getDataSourceName ( String str , String entry ) { String caps = WordUtils . capitalize ( str , PERIOD ) ; String key = getDataSourceName ( res . getAttributeName ( ) , entry . getKey ( ) ) ; String key = getDataSourceName ( res . getAttributeName ( ) , entry . getKey ( ) ) ; sb . append ( \"<datasource><name>\" + key + \"</name><type>GAUGE</type><heartbeat>400</heartbeat><min>U</min><max>U</max></datasource>\\n\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "VOMSServerInfoStore", "interface", "definition", "."], "add_tokens": "* a vo name passed as argument . * @ param voName a VO name * the vo name passed as argument public Set < VOMSServerInfo > getVOMSServerInfo ( String voName ) ;", "del_tokens": "* a vo alias passed as argument . * @ param voAlias a VO alias * the vo alias passed as argument public Set < VOMSServerInfo > getVOMSServerInfo ( String voAlias ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "build", "so", "that", "travis", "build", "once", "again", "actually", "runs", "tests", "and", "is", "useful", ":", "P"], "add_tokens": "import java . io . OutputStreamWriter ; import java . io . Writer ; final Writer writer ; writer = new OutputStreamWriter ( prettyPrintBuffer , Constants . DEFAULT_CHARSET ) ;", "del_tokens": "final PrintWriter writer ; writer = new PrintWriter ( prettyPrintBuffer ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "max", "cache", "object", "size", "configurable", "and", "disable", "client", "-", "side", "compressions"], "add_tokens": "import net . spy . memcached . FailureMode ; import net . spy . memcached . transcoders . SerializingTranscoder ; public static MemcachedCacheBroker create ( final MemcachedCacheBrokerConfig config ) SerializingTranscoder transcoder = new SerializingTranscoder ( config . getMaxObjectSize ( ) ) ; // disable compression transcoder . setCompressionThreshold ( Integer . MAX_VALUE ) ; . setFailureMode ( FailureMode . Retry ) . setTranscoder ( transcoder ) protected MemcachedClientIF getClient ( ) { return client ; }", "del_tokens": "public static CacheBroker create ( final MemcachedCacheBrokerConfig config )", "commit_type": "make"}
{"commit_tokens": ["change", "modulo", "to", "division", "in", "CRS", "/", "CCS", "matrix", "align"], "add_tokens": "return Math . min ( rows * columns , ( ( cardinality / MINIMUM_SIZE ) + 1 )", "del_tokens": "return Math . min ( rows * columns , ( ( cardinality % MINIMUM_SIZE ) + 1 )", "commit_type": "change"}
{"commit_tokens": ["Added", "@ScopeAnnotation", ".", "Added", "Binder", ".", "addError", "()", ".", "Removed", "Scopes", ".", "DEFAULT", ".", "We", "now", "refer", "to", "this", "as", "no", "scope", "."], "add_tokens": "import static java . lang . annotation . ElementType . * ; @ Target ( ANNOTATION_TYPE )", "del_tokens": "@ Target ( { ElementType . ANNOTATION_TYPE } )", "commit_type": "add"}
{"commit_tokens": ["use", "@Test", "annotation", "in", "SailthruUtilTest", "tests"], "add_tokens": "import org . junit . Test ; import static org . junit . Assert . assertEquals ; public class SailthruUtilTest { @ Test @ Test @ Test @ Test", "del_tokens": "import junit . framework . TestCase ; import com . google . gson . GsonBuilder ; public class SailthruUtilTest extends TestCase {", "commit_type": "use"}
{"commit_tokens": ["Improve", "error", "reporting", "of", "ParseFilters"], "add_tokens": "* String filterName = \"<unnamed>\" ; JsonNode nameNode = afilterNode . get ( \"name\" ) ; if ( nameNode != null ) { filterName = nameNode . getTextValue ( ) ; } if ( classNode == null ) { LOG . error ( \"Filter {} doesn't specified a 'class' attribute\" , filterName ) ; } filterName += '[' + className + ']' ; LOG . error ( \"Filter {} does not implement ParseFilter\" , filterName ) ; LOG . info ( \"No field 'params' for filer {}\" , filterName ) ; LOG . info ( \"Setup {}\" , filterName ) ; LOG . error ( \"Can't setup {}: {}\" , filterName , e ) ; throw new RuntimeException ( \"Can't setup \" + filterName , e ) ;", "del_tokens": "* if ( classNode == null ) LOG . error ( \"Class \" + className + \" does not implement ParseFilter\" ) ; LOG . info ( \"No field 'params' for instance of class \" + className ) ; LOG . info ( \"Loaded instance of class \" + className ) ; LOG . error ( \"Can't load or instanciate class : \" + className ) ; throw new RuntimeException ( \"Can't load or instanciate class : \" + className ) ;", "commit_type": "improve"}
{"commit_tokens": ["making", "connPool", ".", "init", "()", "to", "exec", "in", "parallel"], "add_tokens": "import java . util . concurrent . ExecutionException ; final ExecutorService threadPool = Executors . newFixedThreadPool ( Math . max ( 10 , hostsUp . size ( ) ) ) ; final List < Future < Void > > futures = new ArrayList < Future < Void > > ( ) ; for ( final Host host : hostsUp ) { futures . add ( threadPool . submit ( new Callable < Void > ( ) { @ Override public Void call ( ) throws Exception { addHost ( host , false ) ; return null ; } } ) ) ; try { for ( Future < Void > future : futures ) { try { future . get ( ) ; } catch ( InterruptedException e ) { // do nothing } catch ( ExecutionException e ) { throw new RuntimeException ( e ) ; } } } finally { threadPool . shutdownNow ( ) ; }", "del_tokens": "for ( Host host : hostsUp ) { addHost ( host , false ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "floats", "for", "font", "size"], "add_tokens": "return getBox ( ) . getVisualContext ( ) . getFont ( ) . getSize2D ( ) ;", "del_tokens": "return getBox ( ) . getVisualContext ( ) . getFont ( ) . getSize ( ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "copyright", "real", "begin", "year", "is", "2015", "and", "now", "2016"], "add_tokens": "* Copyright 2015 - 2016 the original author or authors .", "del_tokens": "* Copyright 2014 - 2015 the original author or authors .", "commit_type": "fix"}
{"commit_tokens": ["Use", "interfaces", "to", "remove", "cyclical", "dependency", "on", "blueflood", "-", "http", "in", "bf", "-", "core"], "add_tokens": "import com . rackspacecloud . blueflood . service . Configuration ; import com . rackspacecloud . blueflood . service . IngestionService ; public class HttpMetricsIngestionServer implements IngestionService { public HttpMetricsIngestionServer ( ) { this . port = Configuration . getIntegerProperty ( \"HTTP_INGESTION_PORT\" ) ; this . timeout = DEFAULT_TIMEOUT ; //TODO: make configurable this . processorChain = createDefaultProcessorChain ( ) ; public void startService ( ScheduleContext context ) {", "del_tokens": "public class HttpMetricsIngestionServer { public HttpMetricsIngestionServer ( Integer portToListen , ScheduleContext context ) { this ( portToListen , context , null , DEFAULT_TIMEOUT ) ; public HttpMetricsIngestionServer ( Integer portToListen , ScheduleContext context , AsyncChain < List < Metric > , Boolean > processorChain , TimeValue timeout ) { this . port = portToListen ; this . timeout = timeout ; if ( processorChain == null ) { this . processorChain = createDefaultProcessorChain ( ) ; }", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "docs", "managingEditor", "webMaster", "and", "generator", "on", "RSS"], "add_tokens": "syndFeed . setDocs ( channel . getDocs ( ) ) ; syndFeed . setManagingEditor ( channel . getManagingEditor ( ) ) ; syndFeed . setWebMaster ( channel . getWebMaster ( ) ) ; syndFeed . setGenerator ( channel . getGenerator ( ) ) ; item . setComments ( sEntry . getComments ( ) ) ; channel . setDocs ( syndFeed . getDocs ( ) ) ; channel . setManagingEditor ( syndFeed . getManagingEditor ( ) ) ; channel . setWebMaster ( syndFeed . getWebMaster ( ) ) ; channel . setGenerator ( syndFeed . getGenerator ( ) ) ; syndEntry . setComments ( item . getComments ( ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Move", "httpcontext", "call", "to", "activator"], "add_tokens": "import org . osgi . service . http . HttpContext ; httpServiceTracker = new HttpServiceTracker ( context , getServicePid ( ) , getServletClass ( ) , getDefaultSystemContextPath ( context ) , getHttpContext ( ) ) ; / * * * Get the Servlet context for this servlet . * Override if different from default context . * @ return The httpcontext . * / public HttpContext getHttpContext ( ) { return null ; // Override this }", "del_tokens": "httpServiceTracker = new HttpServiceTracker ( context , getServicePid ( ) , getServletClass ( ) , getDefaultSystemContextPath ( context ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "bugs", "in", "voice", "activity", "detector", ".", "Added", "availability", "for", "configuring", "and", "playing", "speaktoit", "recognition", "engine", "sounds", ".", "Simplified", "sample", "activities", "."], "add_tokens": "void onResult ( final AIResponse result ) ; void onError ( final AIError error ) ; void onCancelled ( ) ; @ Override public void onCancelled ( ) { AIDialog . this . close ( ) ; if ( resultsListener != null ) { resultsListener . onCancelled ( ) ; } }", "del_tokens": "public void onResult ( final AIResponse result ) ; public void onError ( final AIError error ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unnecessary", "code", "that", "modifies", "server", ".", "xml", "rather", "than", "using", "snippet"], "add_tokens": "putFileInMap ( WLP_CFG_POM_FILE , featureInstaller . addFeaturesToInstall ( pomInputStream ) ) ;", "del_tokens": "putFileInMap ( WLP_CFG_POM_FILE , featureInstaller . addFeaturesToInstall ( pomInputStream , true ) ) ; String pathToServerXML = \"myProject-wlpcfg/servers/LibertyProjectServer/server.xml\" ; InputStream serverInputStream = new ByteArrayInputStream ( getFileFromMap ( pathToServerXML ) ) ; putFileInMap ( pathToServerXML , featureInstaller . addFeaturesToInstall ( serverInputStream , false ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "tests", "to", "use", "workMemMegs"], "add_tokens": "IlpSolverFactory factory = new IlpSolverFactory ( IlpSolverId . GUROBI_CL , 2 , 128 ) ;", "del_tokens": "IlpSolverFactory factory = new IlpSolverFactory ( IlpSolverId . GUROBI_CL , 2 , - 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["adds", "test", "for", "command", "line"], "add_tokens": "TestUsage . class , TestCommandLine . class , TestGetCSV . class } )", "del_tokens": "TestUsage . class , TestGetCSV . class } )", "commit_type": "add"}
{"commit_tokens": ["implemented", "importData", "method", "in", "HttpClientAdaptor", "class"], "add_tokens": "String path = String . format ( HttpURL . V3_TABLE_IMPORT , e ( request . getTable ( ) . getName ( ) ) ) ; System . out . println ( \"json data: \" + jsonData ) ; double elapsedTime = ( Double ) map . get ( \"elapsed_time\" ) ; return new ImportResult ( request . getTable ( ) , elapsedTime ) ; String V3_TABLE_IMPORT = \"/v3/table/import/%s/%s/msgpack.gz\" ;", "del_tokens": "String path = String . format ( HttpURL . V3_JOB_SUBMIT , e ( request . getTable ( ) . getName ( ) ) , e ( ImportRequest . toFormatName ( request . getFormat ( ) ) ) ) ; double time = ( Double ) map . get ( \"time\" ) ; return new ImportResult ( request . getTable ( ) ) ; String V3_IMPORT = \"/v3/table/import/%s/%s/%s\" ; String V3_EXPORT = \"/v3/table/import/%s/%s/%s\" ; private static Logger LOG = Logger . getLogger ( HttpConnectionImpl . class . getName ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["fixed", "failing", "test", "(", "redux", ")"], "add_tokens": "@ Exposed String output (", "del_tokens": "public String output (", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "flexibility", "around", "scheduler", "interval", "configuration", ".", "Add", "sample", "data", "sets", "to", "ingest", "into", "druid", ".", "Add", "missing", "start", "script", "."], "add_tokens": "private static final int INITIAL_WORK_EXECUTE_DELAY = 2 ; // In secs private final int WORK_GENERATE_INTERVAL ; // In secs private final int WORK_EXECUTE_INTERVAL ; // In secs private final int WORK_TRACKER_INTERVAL ; // In secs private Cancellable workExecutor ; WORK_GENERATE_INTERVAL = getWorkGenerateInterval ( ) ; WORK_EXECUTE_INTERVAL = getWorkExecuteInterval ( ) ; WORK_TRACKER_INTERVAL = getWorkTrackInterval ( ) ; workExecutor = schedule ( INITIAL_WORK_EXECUTE_DELAY , WORK_EXECUTE_INTERVAL , EXECUTE_WORK ) ; workProgressTracker = schedule ( INITIAL_WORK_TRACKER_DELAY , WORK_TRACKER_INTERVAL , TRACK_WORK ) ; workExecutor . cancel ( ) ;", "del_tokens": "private static final int INITIAL_WORK_ASSIGNER_DELAY = 2 ; // In secs private static final int WORK_GENERATE_INTERVAL = 15 ; // In secs private static final int WORK_ASSIGN_INTERVAL = 15 ; // In secs private static final int WORK_TRACKER_INTERVAL = 15 ; // In secs private Cancellable workAssigner ; workAssigner = schedule ( INITIAL_WORK_ASSIGNER_DELAY , WORK_ASSIGN_INTERVAL , EXECUTE_WORK ) ; workProgressTracker = schedule ( INITIAL_WORK_ASSIGNER_DELAY , WORK_TRACKER_INTERVAL , TRACK_WORK ) ; workAssigner . cancel ( ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "duplication", "from", "unit", "tests"], "add_tokens": "assertStringsEqual ( \"sauce:job-result=\" , true ) ; assertStringsEqual ( \"sauce:job-result=\" , false ) ; private void assertStringsEqual ( String s , boolean b ) { assertEquals ( s + b , sauceHelper . getTestResultString ( b ) ) ; }", "del_tokens": "assertEquals ( \"sauce:job-result=true\" , sauceHelper . getTestResultString ( true ) ) ; assertEquals ( \"sauce:job-result=false\" , sauceHelper . getTestResultString ( false ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updating", "of", "separate", "user", "object", "fields", "was", "added", "."], "add_tokens": "//System.out.println(allRequestParams); userService . updateUserField ( id , allRequestParams ) ;", "del_tokens": "System . out . println ( allRequestParams ) ;", "commit_type": "update"}
{"commit_tokens": ["improve", "performace", "of", "language", "detection", "(", "adding", "title", "shortening", "minimum", "lenght", ")"], "add_tokens": "import static ch . epfl . bbp . uima . BlueCasUtil . getTitle ; import org . apache . uima . jcas . JCas ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @ ConfigurationParameter ( name = MIN_TEXT_LENGTH , defaultValue = \"150\" ) String title = getTitle ( jCas ) ; // add title to text if too small if ( text . length ( ) < minTextLenght && title . length ( ) > 0 ) { text = title + \" \" + text ; }", "del_tokens": "import org . apache . uima . jcas . JCas ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @ ConfigurationParameter ( name = MIN_TEXT_LENGTH , defaultValue = \"200\" )", "commit_type": "improve"}
{"commit_tokens": ["add", "zinc", "configuration", "to", "ignored", "configurations"], "add_tokens": "\"versionManagement\" , \"resolutionRules\" , \"bootArchives\" , \"webapp\" , \"checkstyle\" , \"jacocoAgent\" , \"jacocoAnt\" , \"pmd\" , \"cobertura\" , \"zinc\" ) ;", "del_tokens": "\"versionManagement\" , \"resolutionRules\" , \"bootArchives\" , \"webapp\" , \"checkstyle\" , \"jacocoAgent\" , \"jacocoAnt\" , \"pmd\" , \"cobertura\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "optional", "stream", "method", "with", "content", "type"], "add_tokens": "* Transfers blocking the bytes from a given InputStream to this response . Using application / octet - stream * stream ( inputStream , MediaType . APPLICATION_OCTET_STREAM_TYPE ) ; } / * * * Transfers blocking the bytes from a given InputStream to this response * * @ param inputStream The data to be sent * @ param mediaType The stream Content - Type * / public void stream ( InputStream inputStream , MediaType mediaType ) { setResponseMediaType ( mediaType ) ;", "del_tokens": "* Transfers blocking the bytes from a given inputstream to this response", "commit_type": "add"}
{"commit_tokens": ["Improve", "creation", "API", "for", "PluginSource", "builders"], "add_tokens": "* deployment using the { @ link TinyPlugzConfigurator } . A default instance can * also be obtained by { @ link PluginSource # builder ( ) } .", "del_tokens": "* deployment using the { @ link TinyPlugzConfigurator } .", "commit_type": "improve"}
{"commit_tokens": ["Fix", "LimitingSMTPClientTransport", "and", "add", "a", "unit", "test", "for", "it"], "add_tokens": "private final CloseListener listener ; private final SMTPClientSession session ; public final CloseListener getListener ( ) { return listener ; }", "del_tokens": "private CloseListener listener ; private SMTPClientSession session ;", "commit_type": "fix"}
{"commit_tokens": ["add", "transactional", "database", "return", "from", "beginTransaction", "()", "method"], "add_tokens": "return bufferedParameters ( this ) //execute once per set of parameters . flatMap ( executeOnce ( ) ) //run results through select handler . lift ( toOperator ( context . handlers ( ) . selectHandler ( ) ) ) ;", "del_tokens": "return bufferedParameters ( this ) . flatMap ( executeOnce ( ) ) . lift ( toOperator ( context . handlers ( ) . selectHandler ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "javadocs", "for", "lens", "and", "friends", ";", "opting", "against", "native", "Java", "behavior", "and", "for", "safer", "behavior", "around", "accessing", "potentially", "null", "values", "in", "list", "and", "map", "lenses", "."], "add_tokens": "/ * * * A functor over some value of type < code > A < / code > that can be mapped over and retrieved later . * * @ param < A > the value type * / public final class Identity < A > implements Functor < A > { / * * * Retrieve the value . * * @ return the value * / / * * * Covariantly map over the value . * * @ param fn the mapping function * @ param < B > the new value type * @ return an Identity over B ( the new value ) * /", "del_tokens": "public class Identity < A > implements Functor < A > {", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "slug", "is", "set", "when", "specified", "during", "construction", "&", "generated", "automatically", "."], "add_tokens": "assertEquals ( createdUser . username . toLowerCase ( ) , user . slug ) ; User user = new User ( 0L , username , username . toUpperCase ( ) , username + \"test-slug\" , username + \"@testy.com\" , System . currentTimeMillis ( ) , ImmutableList . of ( ) ) ; assertEquals ( username + \"test-slug\" , user . slug ) ;", "del_tokens": "User user = new User ( 0L , username , username . toUpperCase ( ) , username + \"@testy.com\" , System . currentTimeMillis ( ) , ImmutableList . of ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "delete", "action", "at", "joblog", "page"], "add_tokens": "/** The key of the message: Start now */", "del_tokens": "/** The key of the message: Start Now */", "commit_type": "fix"}
{"commit_tokens": ["Use", "Set", "instead", "of", "List", "to", "avoid", "redundant", "values"], "add_tokens": "import java . util . LinkedHashSet ; import java . util . LinkedList ; * @ author Pascal Christoph private LinkedHashSet < T > values = new LinkedHashSet < T > ( ) ; values = new LinkedHashSet < T > ( ) ; return new LinkedList < T > ( values ) ;", "del_tokens": "private List < T > values = Collections . emptyList ( ) ; values = new ArrayList < T > ( ) ; return values ;", "commit_type": "use"}
{"commit_tokens": ["Updating", "with", "different", "naming", "convention", "to", "match", "JS", "."], "add_tokens": "private Widget container = null ; public void setContainer ( final Widget container ) { this . container = container ; public Widget getContainer ( ) { return container ; // If the user hasn't specified the container, default to the widget's parent if ( container == null ) { configure ( this , container ) ; protected void configure ( final Widget w , final Widget container ) { configure ( w . getElement ( ) , container . getElement ( ) , format , weekStart . getValue ( ) , toDaysOfWeekDisabledString ( daysOfWeekDisabled ) , autoClose ,", "del_tokens": "private Widget parent = null ; public void setParent ( final Widget parent ) { this . parent = parent ; public Widget getParent ( ) { return parent ; // If the user hasn't specified the parent, default to the widget's parent if ( parent == null ) { configure ( this , parent ) ; protected void configure ( final Widget w , final Widget widgetParent ) { configure ( w . getElement ( ) , widgetParent . getElement ( ) , format , weekStart . getValue ( ) , toDaysOfWeekDisabledString ( daysOfWeekDisabled ) , autoClose ,", "commit_type": "update"}
{"commit_tokens": ["added", "test", "now", "100%", "for", "core", "-", "impl", ".", "api"], "add_tokens": "import org . project . neutrino . nfvo . catalogue . mano . descriptor . * ; @ Bean ( name = \"VNFFGDescriptorRepository\" ) GenericRepository < VNFForwardingGraphDescriptor > vnffgDescriptorRepository ( ) { return mock ( GenericRepository . class ) ; }", "del_tokens": "import org . project . neutrino . nfvo . catalogue . mano . descriptor . NetworkServiceDescriptor ; import org . project . neutrino . nfvo . catalogue . mano . descriptor . VirtualDeploymentUnit ; import org . project . neutrino . nfvo . catalogue . mano . descriptor . VirtualLinkDescriptor ; import org . project . neutrino . nfvo . catalogue . mano . descriptor . VirtualNetworkFunctionDescriptor ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "plug", "in", "your", "own", "subscription", "manager", ".", "This", "way", "you"], "add_tokens": "this . subscriptionManager = configuration . getSubscriptionManagerProvider ( ) . createManager ( configuration . getMetadataReader ( ) ,", "del_tokens": "this . subscriptionManager = new SubscriptionManager ( configuration . getMetadataReader ( ) ,", "commit_type": "add"}
{"commit_tokens": ["fix", "service", "bus", "test", "failure"], "add_tokens": "final String subscriptionClientClz = SubscriptionClient . class . getName ( ) ; verifyBeanCreationException ( \"Failed to instantiate [\" + subscriptionClientClz + \"]\" , SubscriptionClient . class ) ;", "del_tokens": "verifyBeanCreationException ( \"Failed to instantiate [com.microsoft.azure.servicebus.SubscriptionClient]: \" + \"Factory method 'subscriptionClient' threw exception; nested exception is \" + \"com.microsoft.azure.servicebus.primitives.CommunicationException: \" + \"java.nio.channels.UnresolvedAddressException. This is usually caused by incorrect hostname\" + \" or network configuration.\" , SubscriptionClient . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "unit", "test", "files", "."], "add_tokens": "// Test a new random universal hash function with hash width of 32 bits logger . info ( \"The 32 bit hash value of \\\"{}\\\" is {}.\" , string , Integer . toBinaryString ( hashValue ) ) ; // Test a new random universal hash function with hash width of 8 bits logger . info ( \"The 8 bit hash value of {} is {}.\" , pi , Integer . toBinaryString ( hashValue ) ) ; // Test a new random universal hash function with hash width of zero bits (corner case) logger . info ( \"The 0 bit hash value of {} is {}.\" , date , Integer . toBinaryString ( hashValue ) ) ;", "del_tokens": "// test a new random universal hash function with hash width of 32 bits logger . info ( \"The 32 bit hash value of \\\"{}\\\" is {}\" , string , Integer . toBinaryString ( hashValue ) ) ; // test a new random universal hash function with hash width of 8 bits logger . info ( \"The 8 bit hash value of {} is {}\" , pi , Integer . toBinaryString ( hashValue ) ) ; // test a new random universal hash function with hash width of zero bits (corner case) logger . info ( \"The 0 bit hash value of {} is {}\" , date , Integer . toBinaryString ( hashValue ) ) ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "minor", "logging", "issue", "in", "miniUI", "which", "I", "thought", "was", "a", "bug", "in", "remove"], "add_tokens": "// System.out.println(\"cannot remove \" + coord + \" \" + ret); counter += ret ;", "del_tokens": "System . out . println ( \"cannot remove \" + coord + \" \" + ret ) ; counter ++ ;", "commit_type": "fix"}
{"commit_tokens": ["added", "more", "test", "cases", "and", "also", "fixed", "a", "bug", "in", "the", "use", "of", "new", "methods", "such", "as", "String", ".", "size"], "add_tokens": "// lets see if there's a new static method we've added in groovy-land to this class return doMethodInvoke ( null , method , staticArgumentList . toArray ( ) ) ; return doMethodInvoke ( object , method , EMPTY_ARRAY ) ; Object answer = doMethodInvoke ( object , genericGetMethod , arguments ) ; return answer ; doMethodInvoke ( object , method , arguments ) ; doMethodInvoke ( object , genericSetMethod , arguments ) ; return doMethodInvoke ( object , method , argumentArray ) ; protected Object doMethodInvoke ( Object object , Method method , Object [ ] argumentArray ) { // System.out.println(\"Evaluating method: \" + method); // System.out.println(\"on object: \" + object + \" with arguments: \" + InvokerHelper.toString(argumentArray));", "del_tokens": "return doMethodInvoke ( null , method , arguments , staticArgumentList ) ; return doMethodInvoke ( method , object , EMPTY_ARRAY ) ; Object answer = doMethodInvoke ( genericGetMethod , object , arguments ) ; return answer ; doMethodInvoke ( method , object , arguments ) ; doMethodInvoke ( genericSetMethod , object , arguments ) ; return doMethodInvoke ( method , object , argumentArray ) ; protected Object doMethodInvoke ( Method method , Object object , Object [ ] argumentArray ) { // System.out.println(\"Evaluating method: \" + method); // System.out.println(\"on object: \" + object + \" with arguments: \" + InvokerHelper.toString(argumentArray));", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "and", "removed", "incorrect", "Javadoc", "."], "add_tokens": "* Exception to be thrown in case of problems parsing service responses .", "del_tokens": "* Created by rolf on 2 / 10 / 15.", "commit_type": "add"}
{"commit_tokens": ["Added", "getEncodedImageSize", "to", "EncodedImage", "class"], "add_tokens": "InputStream jpegDataStream = jpegBufferInputStream ; if ( encodedImage . getSize ( ) > length ) { jpegDataStream = new LimitedInputStream ( jpegDataStream , length ) ; } if ( ! isJpegComplete ) { jpegDataStream = new TailAppendingInputStream ( jpegDataStream , EOI_TAIL ) ; return doDecodeStaticImage ( jpegDataStream , encodedImage . getSampleSize ( ) ) ;", "del_tokens": "import com . facebook . imagepipeline . memory . PooledByteBuffer ; final CloseableReference < PooledByteBuffer > bytesRef = encodedImage . getByteBufferRef ( ) ; try { InputStream jpegDataStream = jpegBufferInputStream ; if ( bytesRef . get ( ) . size ( ) > length ) { jpegDataStream = new LimitedInputStream ( jpegDataStream , length ) ; } if ( ! isJpegComplete ) { jpegDataStream = new TailAppendingInputStream ( jpegDataStream , EOI_TAIL ) ; } return doDecodeStaticImage ( jpegDataStream , encodedImage . getSampleSize ( ) ) ; } finally { CloseableReference . closeSafely ( bytesRef ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "FixedThreadPool", "instead", "of", "CachedThreadPool", "for", "NGStream", "reader", "threads", "name", "threads", "and", "notify", "threads", "blocked", "in", "waitForChunk", "on", "disconnection", "."], "add_tokens": "// An NGInputStream is required per NGSession and each NGInputStream requires one thread to loop reading chunks // by executing Runnables on another thread with a timeout. So, the thread pool size needs to be twice the // DEFAULT_SESSIONPOOL size. private static final ExecutorService executor = Executors . newFixedThreadPool ( NGServer . DEFAULT_SESSIONPOOLSIZE * 2 ) ; Thread . currentThread ( ) . setName ( mainThread . getName ( ) + \" read stream thread (NGInputStream pool)\" ) ; Thread . currentThread ( ) . setName ( mainThread . getName ( ) + \" read chunk thread (NGInputStream pool)\" ) ; } finally { Thread . currentThread ( ) . setName ( Thread . currentThread ( ) . getName ( ) + \" (idle)\" ) ; readEof ( ) ; Thread . currentThread ( ) . setName ( Thread . currentThread ( ) . getName ( ) + \" (idle)\" ) ; readEof ( ) ; / * * * Notify threads waiting in waitForChunk on either EOF chunk read or client disconnection . * / private synchronized void readEof ( ) { eof = true ; notifyAll ( ) ; } / * * * If EOF chunk has not been received , but no data is available , block until data is received , EOF or disconnection .", "del_tokens": "private static final ExecutorService executor = Executors . newCachedThreadPool ( ) ; eof = true ; notify ( ) ; / * * * If EOF chunk has not been received , but no data is available , block until data is received .", "commit_type": "use"}
{"commit_tokens": ["fixed", "2", "-", "complement", "parsing"], "add_tokens": "return result + ( - 1 << l ) ; if ( radix > 0 || result < ( 1L << ( l - 1 ) ) ) return result + ( - 1L << l ) ;", "del_tokens": "return result - ( Integer . MAX_VALUE >> ( Integer . SIZE - l ) ) ; if ( radix > 0 || result < ( 1 << ( l - 1 ) ) ) return result - ( Long . MAX_VALUE >> ( Long . SIZE - l ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "EntityListeners", "on", "a", "per", "family", "basis"], "add_tokens": "* Called whenever an { @ link Entity } is added to { @ link Engine } or a specific { @ link Family } * * See { @ link Engine # addEntityListener ( EntityListener ) } and { @ link Engine # addEntityListener ( Family , EntityListener ) } } * Called whenever an { @ link Entity } is removed from { @ link Engine } or a specific { @ link Family } * * See { @ link Engine # addEntityListener ( EntityListener ) } and { @ link Engine # addEntityListener ( Family , EntityListener ) } }", "del_tokens": "* Called whenever an { @ link Entity } is added to { @ link Engine } * Called whenever an { @ link Entity } is removed from { @ link Engine }", "commit_type": "add"}
{"commit_tokens": ["added", "the", "@DelayStart", "annotation", "to", "delay", "startup", "of", "@Every", "jobs", "."], "add_tokens": "import org . joda . time . DateTime ; import de . spinscale . dropwizard . jobs . annotations . DelayStart ; int secondInterval = TimeParserUtil . parseDuration ( annotation . value ( ) ) ; . withIntervalInSeconds ( secondInterval ) . repeatForever ( ) ; DateTime start = new DateTime ( ) ; DelayStart delayAnnotation = clazz . getAnnotation ( DelayStart . class ) ; if ( delayAnnotation != null ) { int secondDelay = TimeParserUtil . parseDuration ( delayAnnotation . value ( ) ) ; start = start . plusSeconds ( secondDelay ) ; } Trigger trigger = TriggerBuilder . newTrigger ( ) . withSchedule ( scheduleBuilder ) . startAt ( start . toDate ( ) ) . build ( ) ;", "del_tokens": "int secondDelay = TimeParserUtil . parseDuration ( annotation . value ( ) ) ; . withIntervalInSeconds ( secondDelay ) . repeatForever ( ) ; Trigger trigger = TriggerBuilder . newTrigger ( ) . withSchedule ( scheduleBuilder ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "zero", "&", "one", "to", "use", "byte", "instead", "of", "Double"], "add_tokens": "private static final Byte zero = new Byte ( ( byte ) 0 ) ; private static final Byte one = new Byte ( ( byte ) 1 ) ;", "del_tokens": "private static final Double zero = new Double ( 0.0 ) ; private static final Double one = new Double ( 1.0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "NPE", "caused", "by", "exceptions", "down", "the", "chain", "references", ":", "http", ":", "//", "code", ".", "google", ".", "com", "/", "p", "/", "activeweb", "/", "issues", "/", "detail?id", "=", "9"], "add_tokens": "private ByteArrayOutputStream bout ; private FilterChain badFilterChain ; badFilterChain = new FilterChain ( ) { public void doFilter ( ServletRequest servletRequest , ServletResponse servletResponse ) throws IOException , ServletException { throw new RuntimeException ( \"I'm a bad... bad exception!\" ) ; } } ; / * * * If there is exception in the FilterChain below RequestDispatcher , it should not * attempt to do anything to it . * * @ throws IOException * @ throws ServletException * / @ Test public void shouldPassExternalExceptionUpTheStack ( ) throws IOException , ServletException { request . setServletPath ( \"/css/main.css\" ) ; request . setMethod ( \"GET\" ) ; config . addInitParameter ( \"exclusions\" , \"css,images,js\" ) ; dispatcher . init ( config ) ; dispatcher . doFilter ( request , response , badFilterChain ) ; a ( response . getContentAsString ( ) ) . shouldBeEqual ( \"I'm a bad... bad exception!\" ) ; }", "del_tokens": "ByteArrayOutputStream bout ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "Snippet", "support", ".", "Added", "IntelliJ", "specific", "files", "to", ".", "gitignore", "."], "add_tokens": "import org . jmusixmatch . snippet . Snippet ; import org . jmusixmatch . snippet . get . SnippetGetMessage ; / * * * Get Snippet for the specified trackID . * @ param trackID * @ return * @ throws MusixMatchException * / public Snippet getSnippet ( int trackID ) throws MusixMatchException { Snippet snippet = null ; SnippetGetMessage message = null ; Map < String , Object > params = new HashMap < String , Object > ( ) ; params . put ( Constants . API_KEY , apiKey ) ; params . put ( Constants . TRACK_ID , new String ( \"\" + trackID ) ) ; String response = null ; response = MusixMatchRequest . sendRequest ( Helper . getURLString ( Methods . TRACK_SNIPPET_GET , params ) ) ; Gson gson = new Gson ( ) ; try { message = gson . fromJson ( response , SnippetGetMessage . class ) ; } catch ( JsonParseException jpe ) { handleErrorResponse ( response ) ; } snippet = message . getContainer ( ) . getBody ( ) . getSnippet ( ) ; return snippet ; } Methods . TRACK_SUBTITLE_GET , params ) ) ;", "del_tokens": "Methods . TRACK_SUBTITLE_GET , params ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "acceptable", "timestamp", "parameter", "to", "what", "the", "server", "actually", "sends"], "add_tokens": "String acceptable = oauthParams . getFirst ( \"oauth_acceptable_timestamps\" ) ;", "del_tokens": "String acceptable = oauthParams . getFirst ( \"acceptable_timestamps\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "javadoc", "typos", "in", "Matcher#toMatchResult"], "add_tokens": "* Returns the match state of this matcher as a MatchResult . The result * @ return a MatchResult with the state of this matcher", "del_tokens": "* Returns the match state of this matcher as a NamedMatchResult . The result * @ return a NamedMatchResult with the state of this matcher", "commit_type": "fix"}
{"commit_tokens": ["Added", "string", "matching", "optimization", "for", "one", "-", "letter", "strings"], "add_tokens": "return new CharMatcher ( c ) ; return Character . isLetter ( c ) ? new CharIgnoreCaseMatcher ( c ) : ch ( c ) ; return cLow == cHigh ? ch ( cLow ) : new CharRangeMatcher ( cLow , cHigh ) ; public Rule string ( @ NotNull String string ) { if ( string . length ( ) == 1 ) return ch ( string . charAt ( 0 ) ) ; // optimize one-letter strings if ( string . length ( ) == 1 ) return charIgnoreCase ( string . charAt ( 0 ) ) ; // optimize one-letter strings", "del_tokens": "return new CharMatcher < V > ( c ) ; return Character . isLetter ( c ) ? new CharIgnoreCaseMatcher < V > ( c ) : ch ( c ) ; return cLow == cHigh ? ch ( cLow ) : new CharRangeMatcher < V > ( cLow , cHigh ) ; public Rule string ( String string ) {", "commit_type": "add"}
{"commit_tokens": ["Change", "Proxy", "Port", "to", "integer"], "add_tokens": "public void setProxy ( String host , int port , String username , String password ) { httpClient . setProxy ( host , port , username , password ) ;", "del_tokens": "public void setProxy ( String host , String port , String username , String password ) { httpClient . setProxy ( host , Integer . parseInt ( port ) , username , password ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "bug", "of", "reversed", "indexed", "arrays", "unflattening"], "add_tokens": "private static final String arrayIndex = \"\\\\[\\\\s*\\\\d+\\\\s*\\\\]\" ; private static final String objectComplexKey = \"\\\\[\\\\s*\\\".*\\\"\\\\s*\\\\]\" ; private static final String objectKey = \"[^\\\\.\\\\[\\\\]]+\" ; Pattern . compile ( arrayIndex + \"|\" + objectComplexKey + \"|\" + objectKey ) ; if ( keyPart . matches ( objectComplexKey ) ) return keyPart . matches ( arrayIndex ) ; || currentVal . asArray ( ) . get ( aryIdx ) . equals ( Json . NULL ) ) {", "del_tokens": "Pattern . compile ( \"\\\\[\\\\s*\\\\d+\\\\s*\\\\]|\\\\[\\\\s*\\\".*\\\"\\\\s*\\\\]|[^\\\\.\\\\[\\\\]]+\" ) ; if ( keyPart . matches ( \"^\\\\[\\\\s*\\\".*$\" ) ) return keyPart . matches ( \"\\\\[\\\\s*\\\\d+\\\\s*\\\\]\" ) ; || currentVal . asArray ( ) . get ( aryIdx ) == null ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "health", "check", "to", "ignore", "exceptions", "retrieving", "the", "query", "trace"], "add_tokens": "import com . datastax . driver . core . exceptions . TraceRetrievalException ; import com . google . common . base . Stopwatch ; Stopwatch stopwatch = Stopwatch . createStarted ( ) ; // Coarsely record the query duration based on local observation. If possible it will be updated // to a more accurate measurement from the query trace. long queryDurationMicros = stopwatch . stop ( ) . elapsed ( TimeUnit . MICROSECONDS ) ; String coordinator ; try { QueryTrace trace = cqlResult . getExecutionInfo ( ) . getQueryTrace ( ) ; coordinator = trace . getCoordinator ( ) . toString ( ) ; // Update the query duration with the more accurate measurement returned from the trace queryDurationMicros = trace . getDurationMicros ( ) ; } catch ( TraceRetrievalException e ) { // Sometimes the query succeeds but the trace cannot be retrieved. Sleeping and querying for the // trace again may work but we're not really interested in making the health check take longer. // Don't raise the exception, just update the message parameters. coordinator = \"unknown\" ; } message . append ( \" | CQL: \" ) . append ( host ) . append ( \" -> \" ) . append ( coordinator ) . append ( \" \" ) . append ( queryDurationMicros ) . append ( \"us\" ) ;", "del_tokens": "QueryTrace trace = cqlResult . getExecutionInfo ( ) . getQueryTrace ( ) ; message . append ( \" | CQL: \" ) . append ( host ) . append ( \" -> \" ) . append ( trace . getCoordinator ( ) ) . append ( \" \" ) . append ( trace . getDurationMicros ( ) ) . append ( \"us\" ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "error", "in", "the", "method", "name", "."], "add_tokens": "static public BaudRate getBaudrate ( Integer value ) {", "del_tokens": "static public BaudRate getParity ( Integer value ) {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "the", "node", "at", "the", "starting", "point", "of", "a", "circular", "reference", "to", "the", "circular", "nodes", "now"], "add_tokens": "node = newCircularNode ( parentNode , instances , e . getPropertyPath ( ) ) ; private Node findNodeMatchingPropertyPath ( final Node node , final PropertyPath propertyPath ) { if ( node == null ) { return null ; } if ( node . matches ( propertyPath ) ) { return node ; } return findNodeMatchingPropertyPath ( node . getParentNode ( ) , propertyPath ) ; } private Node newCircularNode ( final Node parentNode , final Instances instances , final PropertyPath circleStartPath ) node . setCircleStartPath ( circleStartPath ) ; node . setCircleStartNode ( findNodeMatchingPropertyPath ( parentNode , circleStartPath ) ) ;", "del_tokens": "node = newCircularNode ( parentNode , instances ) ; node . setCircleStartPath ( e . getPropertyPath ( ) ) ; private static Node newCircularNode ( final Node parentNode , final Instances instances )", "commit_type": "add"}
{"commit_tokens": ["Added", "dedicated", "test", "for", "loading", "configuration", "."], "add_tokens": "public void crawl ( ) throws ConfigurationException { CompositeConfiguration config = ConfigUtil . load ( new File ( this . getClass ( ) . getResource ( \"/\" ) . getFile ( ) ) ) ; Assert . assertEquals ( \".html\" , config . getString ( \"output.extension\" ) ) ;", "del_tokens": "public void crawl ( ) throws ConfigurationException { // File test = new File(\"/content\"); // System.out.println(test.exists()); CompositeConfiguration config = new CompositeConfiguration ( ) ; URL defaultConfigFileUrl = this . getClass ( ) . getResource ( \"/default.properties\" ) ; File defaultConfigFile = new File ( defaultConfigFileUrl . getFile ( ) ) ; Assert . assertTrue ( defaultConfigFile . exists ( ) ) ; config . addConfiguration ( new PropertiesConfiguration ( defaultConfigFile ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "DuctileDB", "."], "add_tokens": "Configuration conf = getConfigurationForHBaseBackend ( ) ; private Configuration getConfigurationForHBaseBackend ( ) { conf . setProperty ( \"storage.backend\" , \"hbase\" ) ;", "del_tokens": "Configuration conf = getConfigurationForCassandraBackend ( ) ; private Configuration getConfigurationForCassandraBackend ( ) { conf . setProperty ( \"storage.backend\" , \"cassandra\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "GDD", "calculation", "that", "if", "the", "GDD", "value", "for", "a", "day", "<", "0", "then", "consider", "it", "as", "0", "."], "add_tokens": "String gdd = substract ( tavg , baseTemp ) ; if ( gdd != null && compare ( gdd , \"0\" , CompareMode . GREATER ) ) { calGdd = sum ( calGdd , gdd ) ; }", "del_tokens": "calGdd = sum ( calGdd , substract ( tavg , baseTemp ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Update", "vert", ".", "x", "module", "to", "reflect", "RESTful", "url", "changes", "."], "add_tokens": "routeMatcher . get ( \"/rhq-metrics/metrics/:id/\" , new Handler < HttpServerRequest > ( ) { routeMatcher . post ( \"/rhq-metrics/metrics/:id\" , new Handler < HttpServerRequest > ( ) { routeMatcher . get ( \"/rhq-metrics/metrics\" , new Handler < HttpServerRequest > ( ) { routeMatcher . post ( \"/rhq-metrics/metrics\" , new Handler < HttpServerRequest > ( ) {", "del_tokens": "routeMatcher . get ( \"/rhq-metrics/:id/data\" , new Handler < HttpServerRequest > ( ) { routeMatcher . post ( \"/rhq-metrics/:id/data\" , new Handler < HttpServerRequest > ( ) { routeMatcher . get ( \"/rhq-metrics/data\" , new Handler < HttpServerRequest > ( ) { routeMatcher . post ( \"/rhq-metrics/data\" , new Handler < HttpServerRequest > ( ) {", "commit_type": "update"}
{"commit_tokens": ["changed", "from", "maven", "to", "gradle", "along", "with", "embedded", "mongo", "to", "enable", "testing"], "add_tokens": "import org . apache . commons . lang3 . NotImplementedException ;", "del_tokens": "import org . apache . commons . lang . NotImplementedException ;", "commit_type": "change"}
{"commit_tokens": ["Added", "keyMatch3", "and", "keyMatch4", "function", ".", "Added", "corresponding", "test", "cases", "."], "add_tokens": "* KeyMatch3Func is the wrapper for keyMatch3 .", "del_tokens": "* KeyMatch3Func is the wrapper for keyMatch2 .", "commit_type": "add"}
{"commit_tokens": ["moved", "System", ".", "exit", "to", "correct", "spot", "so", "neverending", "thread", "doesn", "t", "return"], "add_tokens": "System . exit ( - 1 ) ; //set exit code so show that there was an error", "del_tokens": "int exitCode = 0 ; exitCode = - 1 ; //set exit code so show that there was an error } finally { System . exit ( exitCode ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "OP", "permission", "for", "Bukkit", "."], "add_tokens": "if ( p . isOp ( ) ) { result = true ; } else { result = p . hasPermission ( perm ) ; }", "del_tokens": "result = p . hasPermission ( perm ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "NullScheduler", "NullLauncher", "NullUploader", "NullLauncher", "to", "spis"], "add_tokens": "package com . twitter . heron . spi . statemgr ; public class NullStateManager implements IStateManager {", "del_tokens": "package com . twitter . heron . statemgr . dummy ; public class DummyStateManager implements IStateManager {", "commit_type": "move"}
{"commit_tokens": ["Changed", "to", "inherit", "from", "PackageMemberAnnotation", "from", "which", "we"], "add_tokens": "public class ClassAnnotation extends PackageMemberAnnotation { public ClassAnnotation ( String className , String sourceFile ) { super ( className ) ; protected String formatPackageMember ( String key ) { if ( key . equals ( \"\" ) ) return className ; else throw new IllegalArgumentException ( \"unknown key \" + key ) ;", "del_tokens": "public class ClassAnnotation implements BugAnnotation { private String className ; private String superclassName ; public ClassAnnotation ( String className , String superclassName , String sourceFile ) { this . className = className ; this . superclassName = superclassName ; public String getClassName ( ) { return className ; } public String getSuperclassName ( ) { return superclassName ; } public String toString ( ) { return className ;", "commit_type": "change"}
{"commit_tokens": ["use", "enum", "to", "indicate", "script", "result", "type"], "add_tokens": "import java . nio . ByteBuffer ; * where 0 indicates false and 1 indicates true , or as a null * bulk reply for script output . @ Override public void set ( ByteBuffer bytes ) { output = ( bytes != null ) ? Boolean . TRUE : Boolean . FALSE ; }", "del_tokens": "* where 0 indicates false and 1 indicates true .", "commit_type": "use"}
{"commit_tokens": ["Add", "factory", "methods", "for", "non", "-", "Vertx", "environments"], "add_tokens": "/ * * * Gets a < code > PairtreeFactory < / code > that creates its own Vertx environment . This is useful if running in a * simple script that isn 't using Vertx for anything else. * * @ return A < code > PairtreeFactory < / code > backed by the default Pairtree implementation * / public static PairtreeFactory getFactory ( ) { return getFactory ( Vertx . vertx ( ) , DEFAULT_TYPE ) ; } * @ return A < code > PairtreeFactory < / code > backed by the default Pairtree implementation / * * * Gets a < code > PairtreeFactory < / code > that uses the its own Vertx environment to create a Pairtree of the * supplied Pairtree implementation type . * * @ param aImpl The desired Pairtree implementation * @ return A < code > PairtreeFactory < / code > backed by the desired implementation * / public static PairtreeFactory getFactory ( final PairtreeImpl aImpl ) { return getFactory ( Vertx . vertx ( ) , aImpl ) ; }", "del_tokens": "* @ return A < code > PairtreeFactory < / code > backed by the default implementation", "commit_type": "add"}
{"commit_tokens": ["Used", "ArtifactBuilder", "to", "create", "the", "new", "Artifacts", "in", "the", "RepositoryManagerDriver", ";", "fixed", "artifacts", "endpoint"], "add_tokens": "@ Api ( value = \"/result/{buildRecordId}/artifact\" , description = \"Results of building process\" ) @ Path ( \"/result/{buildRecordId}/artifact\" )", "del_tokens": "@ Api ( value = \"/result/${buildRecordId}/artifact\" , description = \"Results of building process\" ) @ Path ( \"/result/${buildRecordId}/artifact\" )", "commit_type": "use"}
{"commit_tokens": ["Add", "first", "test", "case", "to", "chorus", "-", "selftest"], "add_tokens": "public static class ProcessRedirector implements Runnable {", "del_tokens": "private class ProcessRedirector implements Runnable {", "commit_type": "add"}
{"commit_tokens": ["Fix", "problem", "with", "argument", "name", "in", "generated", "code"], "add_tokens": "String fieldName = \"params\" ; int index = 0 ; if ( argument . name . equals ( fieldName ) ) { fieldName = \"params\" + index ; } index ++ ; \"\\t\\t\" + argumentClassName + \" \" + fieldName + \" = \" + argumentsWrapperNewInstance + \"\\t\\tmViewCommands.beforeApply(LocalViewCommand.\" + method . uniqueName + \", \" + fieldName + \");\\n\" + \"\\t\\tmViewCommands.afterApply(LocalViewCommand.\" + method . uniqueName + \", \" + fieldName + \");\\n\" +", "del_tokens": "\"\\t\\t\" + argumentClassName + \" params = \" + argumentsWrapperNewInstance + \"\\t\\tmViewCommands.beforeApply(LocalViewCommand.\" + method . uniqueName + \", params);\\n\" + \"\\t\\tmViewCommands.afterApply(LocalViewCommand.\" + method . uniqueName + \", params);\\n\" +", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bad", "comments", "in", "tests"], "add_tokens": "// Create a tracker report // Retrieve a tracker report // Index tracker reports // Create a payment_log report // Retrieve a payment_log report // Index payment_log reports", "del_tokens": "// Create a shipment report // Retrieve a shipment report // Index shipment reports // Create a shipment report // Retrieve a shipment report // Index shipment reports", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "pull", "in", "Common_Content", "from", "the", "local", "file", "system"], "add_tokens": "// Common Content File Names public static final String [ ] COMMON_CONTENT_FILES = new String [ ] { \"Conventions.xml\" , \"Feedback.xml\" , \"Legal_Notice.xml\" } ; public static final String DEFAULT_BUGZILLA_URL = \"https://bugzilla.redhat.com/\" ; public static final String LEGAL_NOTICE_XML = \"<xi:include href=\\\"Legal_Notice.xml\\\" xmlns:xi=\\\"http://www.w3.org/2001/XInclude\\\">\\n\" + \"\\t<xi:fallback xmlns:xi=\\\"http://www.w3.org/2001/XInclude\\\">\\n\" + \"\\t\\t<xi:include href=\\\"Common_Content/Legal_Notice.xml\\\" xmlns:xi=\\\"http://www.w3.org/2001/XInclude\\\" />\\n\" + \"\\t</xi:fallback>\\n\" + \"</xi:include>\" ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "orchestration4", "sample", "quickstart", "proc", "def", "unit", "test", "created", "."], "add_tokens": "private static final String INPUT_JPDL = \"src/test/resources/jpdl3/esbOrchestration4Sample/processdefinition.xml\" ;", "del_tokens": "private static final String INPUT_JPDL = \"src/test/resources/jpdl3/esbOrchestration3Sample/processdefinition.xml\" ;", "commit_type": "add"}
{"commit_tokens": ["Make", "backgroundColor", "and", "backgroundTexture", "volatile"], "add_tokens": "private volatile int backgroundColor = Color . DKGRAY ; private volatile Bitmap backgroundTexture ;", "del_tokens": "private int backgroundColor = Color . DKGRAY ; private Bitmap backgroundTexture ;", "commit_type": "make"}
{"commit_tokens": ["Added", "copyright", "message", "and", "AppVeyor", "tests"], "add_tokens": "* ( C ) Copyright IBM Corporation 2014 , 2017 , 2018.", "del_tokens": "* ( C ) Copyright IBM Corporation 2014 , 2017.", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", ":", "the", "behaviors", "of", "two", "authenticate", "methods", "are", "different"], "add_tokens": "authenticate ( new AuthenticateRequest ( email , password ) ) ; AuthenticateResult result = clientAdaptor . authenticate ( request ) ; TreasureDataCredentials credentials = result . getTreasureDataCredentials ( ) ; setTreasureDataCredentials ( credentials ) ; return result ;", "del_tokens": "AuthenticateResult result = clientAdaptor . authenticate ( new AuthenticateRequest ( email , password ) ) ; TreasureDataCredentials credentials = result . getTreasureDataCredentials ( ) ; setTreasureDataCredentials ( credentials ) ; return clientAdaptor . authenticate ( request ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "unit", "tests", "updated", "readme"], "add_tokens": "import com . github . sakserv . minicluster . util . FileUtils ; private Configuration yarnConfig ; public Configuration getYarnConfig ( ) { return yarnConfig ; this . yarnConfig = builder . yarnConfig ; private Configuration yarnConfig ; public Builder setYarnConfig ( Configuration yarnConfig ) { this . yarnConfig = yarnConfig ; return this ; } if ( yarnLocalCluster . getYarnConfig ( ) == null ) { throw new IllegalArgumentException ( \"ERROR: Missing required config: Yarn Configuration\" ) ; } public void configure ( ) { } stop ( true ) ; } public void stop ( boolean cleanUp ) { LOG . info ( \"YARN: Stopping MiniYarnCluster\" ) ; if ( cleanUp ) { cleanUp ( ) ; } LOG . info ( \"YARN: Starting MiniYarnCluster\" ) ; miniYARNCluster . serviceInit ( yarnConfig ) ; miniYARNCluster . init ( yarnConfig ) ; public void cleanUp ( ) { FileUtils . deleteFolder ( \"target/\" + testName ) ; }", "del_tokens": "private Configuration conf ; public Configuration getConf ( ) { return conf ; public void configure ( ) { conf = new Configuration ( ) ; } miniYARNCluster . serviceInit ( conf ) ; miniYARNCluster . init ( conf ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "typed", "properties", "api", "breaking", "change"], "add_tokens": "import de . flapdoodle . embed . process . builder . TypedProperty ; public class RuntimeConfigBuilder extends AbstractBuilder < IRuntimeConfig > { private static final TypedProperty < IArtifactStore > ARTIFACT_STORE = TypedProperty . with ( \"ArtifactStore\" , IArtifactStore . class ) ; private static final TypedProperty < ProcessOutput > PROCESS_OUTPUT = TypedProperty . with ( \"ProcessOutput\" , ProcessOutput . class ) ; private static final TypedProperty < ICommandLinePostProcessor > CMD_POSTPROCESSOR = TypedProperty . with ( \"CommandLinePostProcessor\" , ICommandLinePostProcessor . class ) ; set ( ARTIFACT_STORE , artifactStore ) ; set ( PROCESS_OUTPUT , processOutput ) ; set ( CMD_POSTPROCESSOR , commandLinePostProcessor ) ; IArtifactStore artifactStore = get ( ARTIFACT_STORE ) ; ProcessOutput processOutput = get ( PROCESS_OUTPUT ) ; ICommandLinePostProcessor commandLinePostProcessor = get ( CMD_POSTPROCESSOR ) ;", "del_tokens": "public class RuntimeConfigBuilder extends AbstractBuilder < IRuntimeConfig > { set ( IArtifactStore . class , artifactStore ) ; set ( ProcessOutput . class , processOutput ) ; set ( ICommandLinePostProcessor . class , commandLinePostProcessor ) ; IArtifactStore artifactStore = get ( IArtifactStore . class ) ; ProcessOutput processOutput = get ( ProcessOutput . class ) ; ICommandLinePostProcessor commandLinePostProcessor = get ( ICommandLinePostProcessor . class ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "redundent", "code", "from", "standard", "equals", "method"], "add_tokens": "for ( String name : propertyNames ( ) ) {", "del_tokens": "Set < String > names = propertyNames ( ) ; if ( names . equals ( other . propertyNames ( ) ) == false ) { return false ; } for ( String name : names ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "unnecessary", "initialize", "and", "improve", "javadoc", "."], "add_tokens": "* Returns { @ code true } if the configuration contains an entry for the given * resource .", "del_tokens": "* Returns { @ code true } if the configuration contains exactly one entry for * the given resource . initializeIfRequired ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "unit", "tests", "."], "add_tokens": "throw new EInvalidData ( \"Created at date not available\" ) ;", "del_tokens": "throw new EInvalidData ( \"CSDL not available\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "garbage", "lexemes", "accumulating", "when", "executing", "generateInflections", ";", "and", "for", "guessing", "inflexive", "/", "foreign", "nouns"], "add_tokens": "private ArrayList < Wordform > generateInflections_TryLemmas ( String lemma , Word w ) { ArrayList < Wordform > result = generateInflections ( lex , lemma ) ; if ( lex . isMatchingStrong ( AttributeNames . i_Source , \"generateInflections\" ) ) lex . getParadigm ( ) . removeLexeme ( lex ) ; return result ; if ( lex . isMatchingStrong ( AttributeNames . i_Source , \"generateInflections\" ) ) lex . getParadigm ( ) . removeLexeme ( lex ) ;", "del_tokens": "private ArrayList < Wordform > generateInflections_TryLemmas ( String lemma , Word w ) { return generateInflections ( lex , lemma ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "project", "configuration", "and", "layouts", "in", "example"], "add_tokens": "bAccessPointScan = ( Button ) findViewById ( R . id . b_access_points_scan ) ;", "del_tokens": "bAccessPointScan = ( Button ) findViewById ( R . id . b_access_point_scan ) ;", "commit_type": "update"}
{"commit_tokens": ["remove", "deprecated", "and", "unused", "apis"], "add_tokens": "public void onDraw ( Canvas c , RecyclerView parent , RecyclerView . State state ) { super . onDraw ( c , parent , state ) ; public void getItemOffsets ( Rect outRect , View view , RecyclerView parent , RecyclerView . State state ) { super . getItemOffsets ( outRect , view , parent , state ) ;", "del_tokens": "public void onDraw ( Canvas c , RecyclerView parent ) { public void getItemOffsets ( Rect outRect , int itemPosition , RecyclerView parent ) {", "commit_type": "remove"}
{"commit_tokens": ["fix", "the", "order", "of", "adapter", "after", "actions"], "add_tokens": "// TODO: class annotations if ( i < classAnnotations . length ) { annotation = classAnnotations [ i ] ; annotation = methodAnnotations [ i - classAnnotations . length ] ; if ( i >= classAnnotations . length ) { boolean matching = true ; LinkedList < Adapter > runAdapters = new LinkedList < > ( ) ; adapter . context = context ; runAdapters . addFirst ( adapter ) ; matching = adapter . match ( ) ; context = adapter . context ; break ; for ( Adapter adapter : runAdapters ) { adapter . after ( ) ; context = adapter . context ; } if ( ! matching ) { return NoAdapter . NO_ADAPTER ; }", "del_tokens": "if ( i < methodAnnotations . length ) { annotation = methodAnnotations [ i ] ; annotation = classAnnotations [ i - methodAnnotations . length ] ; if ( i < methodAnnotations . length ) { boolean matching = adapter . match ( ) ; adapter . after ( ) ; return noAdapter ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "PayPal", "Express", "checkout", "via", "API", "&", "collect", "payment", "for", "an", "invoice", "."], "add_tokens": "public static final String LIBRARY_VERSION = \"1.1.57\" ;", "del_tokens": "public static final String LIBRARY_VERSION = \"1.1.56\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "read", "only", "SelfHolder", "for", "validation", "phase"], "add_tokens": "self = new ReadOnlySelfHolder ( e ) ;", "del_tokens": "self = new SelfHolder ( ) ; self . setElement ( e ) ; self . setPath ( null ) ; self . setVariable ( null ) ; self . setUnmodifiable ( true ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ResolutionType", "NotSet", "(", "-", "1", ")", "."], "add_tokens": "NotSet ( - 1 ) , Fixed ( 0 ) , WontFix ( 1 ) , Invalid ( 2 ) , Duplication ( 3 ) , CannotReproduce ( 4 ) ; return NotSet ;", "del_tokens": "Fixed ( 0 ) , WontFix ( 1 ) , Invalid ( 2 ) , Duplication ( 3 ) , CannotReproduce ( 4 ) ; return null ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "stats", "resource", "to", "show", "all", "available", "endpoints", "."], "add_tokens": "group ( false , \"group\" , \"groups\" ) , repository ( false , \"repository\" , \"repositories\" ) , deploy_point ( true , \"deploy\" , \"deploys\" ) ; private String singular ; private String plural ; private StoreType ( final boolean writable , final String singular , final String plural ) this . singular = singular ; this . plural = plural ; } public String pluralEndpointName ( ) { return plural ; } public String singularEndpointName ( ) { return singular ;", "del_tokens": "group ( false ) , repository ( false ) , deploy_point ( true ) ; private StoreType ( final boolean writable )", "commit_type": "add"}
{"commit_tokens": ["added", "public", "to", "Envelope2D", "added", "comments", "in", "development", "to", "OperatorSimplifyOGC", ".", "execute"], "add_tokens": "public final class Envelope2D { double xmin ; double ymin ; double xmax ; double ymax ; public void setCoords ( Point2D pt ) { public Envelope2D getInflated ( double dx , double dy ) { void centerAt ( Point2D pt ) { public void queryLowerLeft ( Point2D pt ) { public void queryLowerRight ( Point2D pt ) { public void queryUpperLeft ( Point2D pt ) { public void queryUpperRight ( Point2D pt ) { double _boundaryDistance ( Point2D pt ) { int _envelopeSide ( Point2D pt ) { public int clipLine ( Point2D p1 , Point2D p2 )", "del_tokens": "final class Envelope2D { public double xmin ; public double ymin ; public double xmax ; public double ymax ; void setCoords ( Point2D pt ) { Envelope2D getInflated ( double dx , double dy ) { // TODO This should either call setFromPoints(points, int count) or vice // versa // public Envelope2D getCopy() { // Envelope2D ret = new Envelope2D(xmin, ymin, xmax, ymax); // return ret; // } public void centerAt ( Point2D pt ) { void queryLowerLeft ( Point2D pt ) { void queryLowerRight ( Point2D pt ) { void queryUpperLeft ( Point2D pt ) { void queryUpperRight ( Point2D pt ) { public double _boundaryDistance ( Point2D pt ) { public int _envelopeSide ( Point2D pt ) { int clipLine ( Point2D p1 , Point2D p2 )", "commit_type": "add"}
{"commit_tokens": ["Allowing", "FunctionContext", "filter", "to", "be", "re", "-", "entrant", "for", "a", "single", "request", "."], "add_tokens": "ServletContext oldServletContext = servletContextTL . get ( ) ; HttpServletRequest oldRequest = requestTL . get ( ) ; HttpServletResponse oldResponse = responseTL . get ( ) ; servletContextTL . set ( oldServletContext ) ; requestTL . set ( oldRequest ) ; responseTL . set ( oldResponse ) ;", "del_tokens": "servletContextTL . remove ( ) ; requestTL . remove ( ) ; responseTL . remove ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "setOnIcon", "and", "setOffIcon", "when", "compiled"], "add_tokens": "setOnText ( icon . getElement ( ) . getString ( ) ) ; setOffText ( icon . getElement ( ) . getString ( ) ) ;", "del_tokens": "setOnText ( icon . getElement ( ) . toString ( ) ) ; setOffText ( icon . getElement ( ) . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "public", "get", "method", "for", "error", "message", "at", "RequestError"], "add_tokens": "private String errorMessage ; public String getErrorMessage ( ) { return errorMessage ; }", "del_tokens": "private String errorMessage ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "NPE", "when", "the", "fragment", "of", "a", "preference", "header", "is", "null", "."], "add_tokens": "if ( preferenceHeader . getFragment ( ) != null && preferenceHeader . getFragment ( ) . equals ( initialFragment ) ) {", "del_tokens": "if ( preferenceHeader . getFragment ( ) . equals ( initialFragment ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "line", "number", "on", "a", "test"], "add_tokens": ". in ( file ) . onLine ( 21 ) . atColumn ( 14 ) ;", "del_tokens": ". in ( file ) . onLine ( 6 ) . atColumn ( 14 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "job", "to", "runningTaskFutures", "AFTER", "it", "is", "stored", "in", "the", "registry"], "add_tokens": "} finally { this . runningTasksFutures . put ( job . getReferenceId ( ) , new SubmittedPrintJob ( future , job . getReferenceId ( ) , job . getAppId ( ) ) ) ;", "del_tokens": "this . runningTasksFutures . put ( job . getReferenceId ( ) , new SubmittedPrintJob ( future , job . getReferenceId ( ) , job . getAppId ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "structure", "for", "testing", "the", "run", "-", "method", "of", "ProcessCreateContainers"], "add_tokens": "SuggestTree generalIndex = new SuggestTree ( 7 ) ; // SuggestTree generalIndex = new SuggestTree(7); @ Test public void testContainerRun ( ) { //TODO: include an image to this test or make another one with an image HttpServletRequest request = this . initializeTest ( ) ; ProcessCreateResponse response = ProcessCreateRequest . checkRequestParameter ( request , this . servletConfig . getServletContext ( ) ) ; CreateRequestContainer suggestTreeCreateRequestContainer = new CreateRequestContainer ( ) ; suggestTreeCreateRequestContainer . setSuggestString ( \"testband\" ) ; suggestTreeCreateRequestContainer . setIndexName ( \"testIndex\" ) ; suggestTreeCreateRequestContainer . setKey ( \"testkey\" ) ; suggestTreeCreateRequestContainer . setWeight ( 1 ) ; suggestTreeCreateRequestContainer . run ( this . servletConfig . getServletContext ( ) ) ; String retrieveResponse = generalIndex . getBestSuggestions ( \"test\" ) . toString ( ) ; //FIXME: insert correct response-string. //assertTrue(output.equals(\"testband, testIndex, testkey\")); }", "del_tokens": "SuggestTree generalIndex = new SuggestTree ( 7 ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "new", "line", "character", "in", "context", "clue", "--", "avoid", "unexpected", "formatting"], "add_tokens": "+ docText . substring ( conTextSpan . begin , conTextSpan . end ) . replaceAll ( \"[\\\\n|\\\\r]\" , \" \" ) context . setModifierValue ( value . replaceAll ( \"[\\\\n|\\\\r]\" , \" \" ) ) ;", "del_tokens": "+ docText . substring ( conTextSpan . begin , conTextSpan . end ) context . setModifierValue ( value ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "ability", "to", "use", "both", "FileType", "and", "arbitrary", "mime", "-", "type", "to", "configure", "the", "file", "type", "selection", "process", ".", "-", "P"], "add_tokens": "NONE ( \"\" ) , JPEG ( \"image/jpeg\" ) , JPG ( \"image/jpeg\" ) , PNG ( \"image/png\" ) , XML ( \"application/xml\" ) , XLS ( \"application/vnd.ms-excel\" ) , XLSX ( \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" ) , DOC ( \"application/msword\" ) , DOCX ( \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\" ) , HTML ( \"text/html\" ) , TXT ( \"text/plain\" ) , PDF ( \"application/pdf\" ) ; private String mimeType ; FileType ( String mimeType ) { this . mimeType = mimeType ; } public String getMimeType ( ) { return mimeType ; }", "del_tokens": "NONE , JPEG , JPG , PNG , XML , XLS , XLSX , DOC , DOCX , HTML , TXT , PDF", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", ":", "related", "to", "samza", "batching"], "add_tokens": "Set < Stream > streams = topology . getStreams ( ) ;", "del_tokens": "Set < Stream > streams = topo . getStreams ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "last", "month", "more", "explicit", "."], "add_tokens": "return of ( newYear , MONTHS_IN_YEAR + 1 , getDayOfMonth ( ) ) ;", "del_tokens": "return of ( newYear , getMonth ( ) + 1 , getDayOfMonth ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "another", "test", "gives", "as", "an", "example", "in", "the", "source", "."], "add_tokens": "private static final Configuration conf ; /** Show some documentation when somebody does a GET request. */ @ SuppressWarnings ( \"MethodMayBeStatic\" )", "del_tokens": "static final Configuration conf ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "invisible", "column", "data", "upon", "reattachments", "."], "add_tokens": "return colIndex < headers . size ( ) && ( headers . get ( colIndex ) . $ this ( ) . is ( \":visible\" ) || headers . get ( colIndex ) . isVisible ( ) ;", "del_tokens": "return colIndex < headers . size ( ) && headers . get ( colIndex ) . $ this ( ) . is ( \":visible\" ) && headers . get ( colIndex ) . isVisible ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "two", "issues", "with", "smile", "-", "backed", "serialization", "added", "a", "unit", "test"], "add_tokens": "out . writeInt ( payload . length ) ; payload = new byte [ numBytes ] ; in . readFully ( payload ) ;", "del_tokens": "byte [ ] bytes = new byte [ numBytes ] ; in . readFully ( bytes ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "authorization", "grant", "request", "to", "use", "body", "instead", "of", "header", "for", "clientId", "/", "clientSecret"], "add_tokens": "builder . clientId ( clientId ) ; builder . clientSecret ( clientSecret ) ;", "del_tokens": "builder . authorizationHeader ( clientId , clientSecret ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "null", "handling", "from", "testing"], "add_tokens": "* @ param instant the instant to add the duration to , null means now if ( instant == null ) { return new Instant ( addTo ( DateTimeUtils . currentTimeMillis ( ) , scalar ) ) ; } * @ param instant the instant to update with the added duration , must not be null if ( instant == null ) { throw new IllegalArgumentException ( \"The instant must not be null\" ) ; }", "del_tokens": "* @ param instant the instant to add the duration to * @ throws IllegalArgumentException if the instant is null * @ param instant the instant to update with the added duration", "commit_type": "fix"}
{"commit_tokens": ["Added", "overloaded", "startservers", "method", "and", "modified", "stopserver", "method"], "add_tokens": "package org . menacheri . server ; / * * * A generic interface used to manage a server . * @ author Abraham Menacherry * * / public interface IServerManager { public void startServers ( int tcpPort , int flashPort , int udpPort ) ; public void startServers ( ) ; / * * * Used to stop the server and manage cleanup of resources . * * / public void stopServers ( ) ; }", "del_tokens": "package org . menacheri . server ; / * * * A generic interface used to manage a server . * @ author Abraham Menacherry * * / public interface IServerManager { public void startServers ( int tcpPort , int flashPort , int udpPort ) ; / * * * Used to stop the server and manage cleanup of resources . Server name is * for future use , implementations may ignore this parameter . * * / public void stopServer ( int [ ] ports ) ; }", "commit_type": "add"}
{"commit_tokens": ["Changed", "asymmetric", "signature", "algorithm", "to", "be", "SHA256withRSA", "instead", "of", "SHA1withRSA", "and", "added", "comments", "about", "how", "Java", "handles", "other", "specified", "algorithms", "."], "add_tokens": "static private final String ASYMMETRIC_SIGNATURE_ALGORITHM = \"SHA256with\" + ASYMMETRIC_KEY_TYPE ; static private final String ASYMMETRIC_ENCRYPTION_ALGORITHM = ASYMMETRIC_KEY_TYPE + \"/NONE/OAEPWithSHA-256AndMGF1Padding\" ; // NOTE: The mode is not used for non-block ciphers so NONE is specified above. Java will // ignore any specified mode anyway with non-block ciphers. // NOTE: Java's PKCS5Padding implementation is actually PKCS7Padding which is a superset // of PKCS5Padding, but the PKCS7Padding string is not recognized by the default Java cipher // implementation so we have to specify PKCS5Padding above.", "del_tokens": "static private final String ASYMMETRIC_SIGNATURE_ALGORITHM = \"SHA1with\" + ASYMMETRIC_KEY_TYPE ; static private final String ASYMMETRIC_ENCRYPTION_ALGORITHM = ASYMMETRIC_KEY_TYPE + \"/ECB/OAEPWithSHA-256AndMGF1Padding\" ;", "commit_type": "change"}
{"commit_tokens": ["Use", "File", "API", "to", "join", "the", "directory", "to", "the", "filename", "."], "add_tokens": "LOGGER . log ( Level . FINER , \"Attempting to get filename: {0}\" , file . getAbsolutePath ( ) ) ;", "del_tokens": "import au . com . bytecode . opencsv . CSVReader ; import java . util . ArrayList ; import java . util . List ; filename = this . pathnamePrefix + filename ; LOGGER . log ( Level . FINER , \"Attempting to get filename: {0}\" , filename ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "special", "case", "logic", "for", "literals", "to", "superclass"], "add_tokens": "if ( literal . caseSensitive ( ) || Character . charCount ( literal . codePointAt ( 0 ) ) == literal . length ( ) && ! Character . isLetter ( literal . codePointAt ( 0 ) ) ) else if ( literal . length ( ) == 0 ) { visitEpsilon ( ) ; }", "del_tokens": "if ( literal . caseSensitive ( ) )", "commit_type": "move"}
{"commit_tokens": ["Removed", "the", "old", "logic", "that", "relied", "on", "JXPath"], "add_tokens": "* Changes the frame by index void changeRuntime ( Integer index ) ; void resetFramePath ( ) ;", "del_tokens": "* Change the runtime so we can inject to other frames * * @ param framePath * / void changeRuntime ( String framePath ) ; / * * * Change frame by index , needed for frames with nonames or duplicate names void changeRuntime ( int index ) ;", "commit_type": "remove"}
{"commit_tokens": ["Improve", "query", "result", "fix", "results", "(", "Nil", "row", "list", ")", "minor", "source", "formatting", "(", "remove", "useless", "imports", ")"], "add_tokens": "return ( this . result = res . getRowList ( ) . resultSet ( ) . withStatement ( this ) ) ;", "del_tokens": "return ( this . result = res . getRowList ( ) . resultSet ( ) . withStatement ( this ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "intermediate", "class", "for", "dedicated", "emitter", ":", "steps", "and", "tags"], "add_tokens": "return FAILED . equalsIgnoreCase ( status ) ;", "del_tokens": "return SKIPPED . equalsIgnoreCase ( status ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "docs", "to", "postback", "webhook"], "add_tokens": "* @ param user_id the user id * @ param page_id the page id * @ param timestamp the timestamp * @ param key the postback key * @ param value the postback value * @ return Boolean whether has a user id * @ return Boolean whether has a page id * @ return Boolean whether has a timestamp * @ return Boolean whether has a postback * @ return String the user id * @ return String the page id * @ return Long the timestamp * @ return Map the postback data", "del_tokens": "* @ param user_id * @ param page_id * @ param timestamp * @ param key * @ param value * @ return Boolean * @ return Boolean * @ return Boolean * @ return Boolean * @ return String * @ return String * @ return Long * @ return Map < String , String >", "commit_type": "add"}
{"commit_tokens": ["Use", "pipe", "separator", "for", "top", "level", "transaction", "."], "add_tokens": "return new LoggingTransaction ( mLog , mRepo . enterTransaction ( ) , false ) ; return new LoggingTransaction ( mLog , mRepo . enterTransaction ( level ) , false ) ; return new LoggingTransaction ( mLog , mRepo . enterTopTransaction ( level ) , true ) ;", "del_tokens": "return new LoggingTransaction ( mLog , mRepo . enterTransaction ( ) ) ; return new LoggingTransaction ( mLog , mRepo . enterTransaction ( level ) ) ; return new LoggingTransaction ( mLog , mRepo . enterTopTransaction ( level ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bugs", ";", "Test", "failed", "when", "startFragment", "()", "does", "not", "called"], "add_tokens": "if ( mAttached ) { getFragmentInstrumentation ( ) . callFragmentOnDestroy ( ) ; }", "del_tokens": "getFragmentInstrumentation ( ) . callFragmentOnDestroy ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "infinite", "loop", "in", "LZ4JavaUnsafeUncompressor", "."], "add_tokens": "if ( matchDec == 0 || matchOff < destOff ) { if ( matchDec == 0 || matchOff < destOff ) {", "del_tokens": "if ( matchOff < destOff ) { if ( matchOff < destOff ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "invalid", "database", "path", "and", "close", "connection", "handling"], "add_tokens": "protected void handleClose ( Throwable t ) {", "del_tokens": "private void handleClose ( Throwable t ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "c3p0", "pooled", "ConnectionProvider", "example"], "add_tokens": "public static String nextUrl ( ) { return \"jdbc:h2:mem:test\" + dbNumber . incrementAndGet ( ) + \";DB_CLOSE_DELAY=-1\" ; } return new ConnectionProviderFromUrl ( nextUrl ( ) ) ;", "del_tokens": "return new ConnectionProviderFromUrl ( \"jdbc:h2:mem:test\" + dbNumber . incrementAndGet ( ) + \";DB_CLOSE_DELAY=-1\" ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "synchronization", "of", "best", "solution", "accessors"], "add_tokens": "* @ throws NullPointerException if < code > problem < / code > is < code > null < / code > // check problem if ( problem == null ) { throw new NullPointerException ( \"Error while creating search: problem can not be null.\" ) ; } return bestSolution ; return bestSolutionEvaluation ; // update best solution: create copy because new solution // might be further modified in subsequent search steps bestSolution = problem . copySolution ( newSolution ) ; bestSolutionEvaluation = newSolutionEvaluation ;", "del_tokens": "// lock acquired when updating/accessing best solution and its evaluation to ensure consistency private final Object bestSolutionLock = new Object ( ) ; // synchronize with best solution updates synchronized ( bestSolutionLock ) { return bestSolution ; } // synchronize with best solution updates synchronized ( bestSolutionLock ) { return bestSolutionEvaluation ; } // update best solution: // - create copy because new solution might be further modified in subsequent search steps // - acquire lock to ensure consistent return values of getBestSolution() and getBestSolutionEvaluation() synchronized ( bestSolutionLock ) { bestSolution = problem . copySolution ( newSolution ) ; bestSolutionEvaluation = newSolutionEvaluation ; }", "commit_type": "remove"}
{"commit_tokens": ["allow", "including", "files", "with", "unknown", "file", "extension", "without", "registering", "an", "explicit", "filter"], "add_tokens": "String result = textBlock . getValue ( ) ; if ( filter != null ) { result = filter . convert ( result , attributes , model ) ;", "del_tokens": "if ( filter == null ) { throw new JadeCompilerException ( this , template . getTemplateLoader ( ) , \"filter [\" + getValue ( ) + \"] does not exist\" ) ; String result = filter . convert ( textBlock . getValue ( ) , attributes , model ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "some", "prep", "for", "dynamic", "class", "reloading", ".", "Not", "sure", "how", "we", "ll", "do", "that"], "add_tokens": "// At some point we'll see if we can dynamically reload classes: setup ( Api . class . getClassLoader ( ) ) ; // // Set up reflections: // ServletContext servletContext = getServletContext(); // Set<URL> urls = new HashSet<>( // ClasspathHelper.forWebInfLib(servletContext)); // urls.add(ClasspathHelper.forWebInfClasses(servletContext)); // Reflections reflections = new Reflections( // new ConfigurationBuilder().setUrls(urls)); // new Reflections(ClasspathHelper.forClassLoader(classLoaders)); // // // Get the default handler: // defaultRequestHandler = new RequestHandler(); // defaultRequestHandler.endpointClass = DefaultRequestHandler.class; // try { // defaultRequestHandler.method = DefaultRequestHandler.class // .getMethod(\"notImplemented\", HttpServletRequest.class, // HttpServletResponse.class); // } catch (NoSuchMethodException | SecurityException e) { // throw new ServletException( // \"Code issue - default request handler not found\", e); // } // // configureEndpoints(reflections); // configureHome(reflections); // configureNotFound(reflections); // configureBoom(reflections); } void setup ( ClassLoader classLoader ) { ClasspathHelper . forClassLoader ( classLoader ) ) ; throw new RuntimeException (", "del_tokens": "import java . net . URL ; import java . util . HashSet ; import javax . servlet . ServletContext ; import org . reflections . util . ConfigurationBuilder ; ServletContext servletContext = getServletContext ( ) ; Set < URL > urls = new HashSet < > ( ClasspathHelper . forWebInfLib ( servletContext ) ) ; urls . add ( ClasspathHelper . forWebInfClasses ( servletContext ) ) ; new ConfigurationBuilder ( ) . setUrls ( urls ) ) ; throw new ServletException (", "commit_type": "add"}
{"commit_tokens": ["Fixing", "squid", ":", "S1132", "-", "Strings", "literals", "should", "be", "placed", "on", "the", "left", "side", "when", "checking", "for", "equality", "."], "add_tokens": "if ( \"*\" . equals ( uid ) ) { if ( \"*\" . equals ( cn ) ) { if ( \"null\" . equals ( getAttributeOrNa ( attrs , k ) ) ) {", "del_tokens": "if ( uid . equals ( \"*\" ) ) { if ( cn . equals ( \"*\" ) ) { if ( getAttributeOrNa ( attrs , k ) . equals ( \"null\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "logic", "to", "get", "MsConnection", "for", "passed", "MsConnection", "ID", "and", "MsCOnnection", "List", "for", "passed", "EndpointId", "for", "RA"], "add_tokens": "public MsConnection getMsConnection ( String msConnectionId ) { for ( MsSession e : calls ) { for ( MsConnection c : e . getConnections ( ) ) { if ( c . getId ( ) . equals ( msConnectionId ) ) { return c ; } } } return null ; } public List < MsConnection > getMsConnections ( String endpointName ) { List < MsConnection > msConnectionList = new ArrayList < MsConnection > ( ) ; for ( MsSession e : calls ) { for ( MsConnection c : e . getConnections ( ) ) { if ( c . getEndpoint ( ) . equals ( endpointName ) ) { msConnectionList . add ( c ) ; } } } return msConnectionList ; }", "del_tokens": "public MsConnection getMsConnection ( String msConnectionId ) { // TODO Add logic here return null ; }", "commit_type": "implement"}
{"commit_tokens": ["add", "special", "case", "constructor", "for", "unknown", "implementations"], "add_tokens": ". endConstructor ( ) . emitEmptyLine ( ) . beginConstructor ( EnumSet . of ( Modifier . PUBLIC ) , long . class . getName ( ) , \"pointer\" ) . emitStatement ( \"super(pointer)\" ) . endConstructor ( ) ;", "del_tokens": ". endConstructor ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Created", "a", "factory", "method", "in", "the", "ProductId", "class", "that", "creates", "a", "PRODID", "property", "for", "this", "library", "."], "add_tokens": "setProductId ( ProductId . biweekly ( ) ) ;", "del_tokens": "setProductId ( new ProductId ( \"-//Michael Angstadt//biweekly \" + Biweekly . VERSION + \"//EN\" ) ) ;", "commit_type": "create"}
{"commit_tokens": ["use", "ISO", "-", "8859", "-", "1", "for", "HTTP", "Headers"], "add_tokens": "import java . nio . charset . StandardCharsets ; char c = ( char ) ( b [ i ] & 0xFF ) ; byte [ ] keyBytes = values . get ( 0 ) . getBytes ( StandardCharsets . ISO_8859_1 ) ; data . add ( keyBytes ) . add ( COLON ) . add ( values . get ( i ) . getBytes ( StandardCharsets . ISO_8859_1 ) ) . add ( CRLF ) ; data . add ( method . getBytes ( StandardCharsets . ISO_8859_1 ) ) . add ( SPACE ) . add ( uri . getBytes ( StandardCharsets . ISO_8859_1 ) ) . add ( SPACE ) . add ( reason . getBytes ( StandardCharsets . ISO_8859_1 ) ) . add ( CRLF ) ;", "del_tokens": "char c = ( char ) b [ i ] ; byte [ ] keyBytes = values . get ( 0 ) . getBytes ( ) ; data . add ( keyBytes ) . add ( COLON ) . add ( values . get ( i ) . getBytes ( ) ) . add ( CRLF ) ; data . add ( method . getBytes ( ) ) . add ( SPACE ) . add ( uri . getBytes ( ) ) . add ( SPACE ) . add ( reason . getBytes ( ) ) . add ( CRLF ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "Flash", "plugin", "in", "Chrome"], "add_tokens": "private final boolean flashEnabled ; // Chrome only? String enableFlash = load ( \"flash.enabled\" , \"false\" , \"Enable the Flash plugin. Property only works in Chrome for now.\" ) ; if ( enableFlash != null && ( enableFlash . equalsIgnoreCase ( \"true\" ) || enableFlash . equalsIgnoreCase ( \"yes\" ) || enableFlash . equalsIgnoreCase ( \"on\" ) || enableFlash . equalsIgnoreCase ( \"1\" ) ) ) { flashEnabled = true ; } else { flashEnabled = false ; } public boolean shouldEnableFlash ( ) { return flashEnabled ; } }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "ExtendedFormulaFactory", "."], "add_tokens": "public int formulas ( ) {", "del_tokens": "public int formuas ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "and", "clarified", "some", "comments", "."], "add_tokens": "// Delivery failed for some IO-related reason; re-enqueue for another attempt, but // only if the notification is in the sent notification buffer (i.e. if it hasn't // been re-enqueued for another reason). // SHUTDOWN errors from Apple are harmless; nothing bad happened with the delivered notification, so // we don't want to notify listeners of the error (but we still do need to reconnect).", "del_tokens": "// Delivery failed for some IO-related reason; re-enqueue for another attempt", "commit_type": "add"}
{"commit_tokens": ["Fixed", "to", "read", "on", "4", "byte", "for", "files", "and", "all", "is", "well", "."], "add_tokens": "compressed . skip ( Util . round ( header . getFileSize ( ) , 3 ) ) ;", "del_tokens": "if ( compressed . skip ( header . getFileSize ( ) ) != header . getFileSize ( ) ) throw new IllegalStateException ( \"Didn't skip far enough.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "body", "matching", "for", "verifications"], "add_tokens": "import static com . tomakehurst . wiremock . client . WireMock . postRequestedFor ; private static final String SAMPLE_JSON = \"{ \\n\" + \" \\\"thing\\\": { \\n\" + \" \\\"importantKey\\\": \\\"Important value\\\", \\n\" + \" } \\n\" + \"} \" ; @ Test public void verifiesWithBody ( ) { testClient . postWithBody ( \"/add/this\" , SAMPLE_JSON , \"application/json\" , \"utf-8\" ) ; verify ( postRequestedFor ( urlEqualTo ( \"/add/this\" ) ) . withBodyMatching ( \".*\\\"importantKey\\\": \\\"Important value\\\".*\" ) ) ; }", "del_tokens": "// @Test // public void verifiesWithBody() { // testClient.post(\"/add/this\"); // verify(postRequestedFor(urlMatching(\"/[a-z]+/this\"))); // }", "commit_type": "add"}
{"commit_tokens": ["Make", "QueryResult", "a", "public", "class", "."], "add_tokens": "public class QueryResult implements Iterable < BasicDocumentRevision > {", "del_tokens": "class QueryResult implements Iterable < BasicDocumentRevision > {", "commit_type": "make"}
{"commit_tokens": ["Fixed", "dependencies", "to", "dropwizard", "metrics"], "add_tokens": "import com . codahale . metrics . annotation . Counted ;", "del_tokens": "import com . ryantenney . metrics . annotation . Counted ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "flag", "to", "turn", "off", "reading", "native", "code", "from", "JSNI", "blocks", "."], "add_tokens": "if ( hasNativeCode ( m ) ) { return super . methodDeclaration ( m ) + \" \" + extractNativeMethodBody ( m ) + \"\\n\\n\" ; } else { // Warning reported in header generator. return \"\" ; } if ( hasNativeCode ( method ) ) { methodBody = extractNativeMethodBody ( method ) ; } else { // Warning reported in header generator. return \"\" ; } if ( m != null && ( m . getModifiers ( ) & Modifier . NATIVE ) > 0 && hasNativeCode ( m ) ) { J2ObjC . warning ( m , \"no native code found\" ) ; return \"\" ;", "del_tokens": "return super . methodDeclaration ( m ) + \" \" + extractNativeMethodBody ( m ) + \"\\n\\n\" ; methodBody = extractNativeMethodBody ( method ) ; if ( m != null && ( m . getModifiers ( ) & Modifier . NATIVE ) > 0 ) { J2ObjC . error ( m , \"no native code found\" ) ; return \"ERROR\" ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "some", "redundant", "code", "."], "add_tokens": "this ( atom1 , atom2 , order ) ;", "del_tokens": "atoms = new Atom [ 2 ] ; setAtomAt ( atom1 , 0 ) ; setAtomAt ( atom2 , 1 ) ; setOrder ( order ) ;", "commit_type": "remove"}
{"commit_tokens": ["Moved", "the", "TranslatedCSNode", "and", "TranslatedXMLCondition", "fields", "from", "TranslatedTopicData", "to", "TranslatedTopic", "since", "it", "was", "just", "a", "duplication", "of", "data", "that", "wasn", "t", "necessary", "."], "add_tokens": "translatedTopic . get ( \"translatedCSNode\" ) . get ( \"translatedCSNodeId\" ) , translatedCSNodeId ) ; translatedCSNodeIdCondition = criteriaBuilder . isNull ( translatedTopic . get ( \"translatedCSNode\" ) ) ;", "del_tokens": "getOriginalRootPath ( ) . get ( \"translatedCSNode\" ) . get ( \"translatedCSNodeId\" ) , translatedCSNodeId ) ; translatedCSNodeIdCondition = criteriaBuilder . isNull ( getOriginalRootPath ( ) . get ( \"translatedCSNode\" ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Adding", "the", "ability", "so", "that", "the", "android", "edition", "can", "shim", "out", "the", "XmlStreamWriter", "with", "an", "implementation", "that", "is", "supported", "by", "Android", "while", "at", "the", "same", "time", "using", "the", "same", "code", "to", "parse", "the", "RDF", "format"], "add_tokens": "import static junit . framework . Assert . assertTrue ; assertTrue ( copy . getUrlComponents ( ) . isEmpty ( ) ) ; } @ Test public void testDefaultAccount ( ) { Account account = Account . makeDefaultAccount ( ) ; assertTrue ( account . isDefault ( ) ) ;", "del_tokens": "Assert . assertTrue ( copy . getUrlComponents ( ) . isEmpty ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "it", "possible", "to", "close", "the", "LRU", "cache"], "add_tokens": "public final class IntLruCache < T extends AutoCloseable > implements AutoCloseable private final AutoCloseable [ ] values ; values = new AutoCloseable [ capacity ] ; final AutoCloseable [ ] values = this . values ; values [ size - 1 ] . close ( ) ; public void close ( ) { for ( @ DoNotSub int i = 0 ; i < size ; i ++ ) { try { values [ i ] . close ( ) ; } catch ( Exception e ) { LangUtil . rethrowUnchecked ( e ) ; } } }", "del_tokens": "public final class IntLruCache < T extends AutoCloseable > private final Object [ ] values ; values = new Object [ capacity ] ; final Object [ ] values = this . values ; ( ( AutoCloseable ) values [ size - 1 ] ) . close ( ) ;", "commit_type": "make"}
{"commit_tokens": ["move", "variable", "related", "methods", "to", "new", "TypeVariableUtils"], "add_tokens": "final Map < Class < ? > , LinkedHashMap < String , Type > > generics = TypeVariableUtils . trackRootVariables ( type , null ) ;", "del_tokens": "final Map < Class < ? > , LinkedHashMap < String , Type > > generics = GenericsResolutionUtils . resolveWithRootVariables ( type , null ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "less", "calls", "to", "prevent", "travis", "from", "failing", "the", "build", "during", "peak"], "add_tokens": "final int parallelCount = 10 ; // Limited for automated tests, increase for in depth tests", "del_tokens": "final int parallelCount = 50 ; // Limited for automated tests, increase for in depth tests", "commit_type": "use"}
{"commit_tokens": ["change", "getPixelType", "to", "getFormat", "to", "match", "the", "audio", "methods"], "add_tokens": "public PixelFormat . Type getFormat ( ) { return PixelFormat . Type . swigToEnum ( VideoJNI . PixelFormatDescriptor_getFormat ( swigCPtr , this ) ) ;", "del_tokens": "public PixelFormat . Type getPixelType ( ) { return PixelFormat . Type . swigToEnum ( VideoJNI . PixelFormatDescriptor_getPixelType ( swigCPtr , this ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Removed", "many", "hasValue", "methods", "for", "specific", "number", "types", "like", "integer", "or", "double", "as", "they", "can", "be", "replaced", "by", "a", "generic", "assertion", "that", "uses", "java", ".", "lang", ".", "Number", "as", "expected", "type"], "add_tokens": "public void hasValue ( Number expectedValue ) { if ( expectedValue == null ) { if ( ! expectedValue . equals ( actual . getValue ( ) ) ) {", "del_tokens": "public void hasValue ( Number expectedValue ) { if ( expectedValue == null ) { if ( ! expectedValue . equals ( actual . getValue ( ) ) ) { public void hasValue ( int expectedValue ) { isNotNull ( ) ; if ( actual . intValue ( ) != expectedValue ) { failWithMessage ( \"Actual observable integer should have the value <%s> but was <%s>\" , expectedValue , actual . intValue ( ) ) ; } } public void hasValue ( double expectedValue ) { isNotNull ( ) ; if ( actual . doubleValue ( ) != expectedValue ) { failWithMessage ( \"Actual observable double should have the value <%s> but was <%s>\" , expectedValue , actual . doubleValue ( ) ) ; } } public void hasValue ( long expectedValue ) { isNotNull ( ) ; if ( actual . longValue ( ) != expectedValue ) { failWithMessage ( \"Actual observable long should have the value <%s> but was <%s>\" , expectedValue , actual . longValue ( ) ) ; } } public void hasValue ( float expectedValue ) { isNotNull ( ) ; if ( actual . floatValue ( ) != expectedValue ) { failWithMessage ( \"Actual observable float should have the value <%s> but was <%s>\" , expectedValue , actual . floatValue ( ) ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "packaging", "and", "date", "forwarding"], "add_tokens": "while ( date . before ( now ) )", "del_tokens": "if ( date . before ( now ) )", "commit_type": "fix"}
{"commit_tokens": ["Change", "protocol", "new", "unit", "tests"], "add_tokens": "import com . google . gson . JsonObject ; import java . util . HashMap ; private HashMap < String , JsonObject > contexts ; public HashMap < String , JsonObject > getContexts ( ) {", "del_tokens": "/ * * * Contexts that were matched by the intent * / @ SerializedName ( \"inputContexts\" ) private String [ ] inputContexts ; / * * * Contexts that were added by the intent * / @ SerializedName ( \"outputContexts\" ) private String [ ] outputContexts ; private String [ ] contexts ; / * * * Contexts that were matched by the intent * / public String [ ] getInputContexts ( ) { return inputContexts ; } public String [ ] getContexts ( ) { / * * * Contexts that were added by the intent * / public String [ ] getOutputContexts ( ) { return outputContexts ; }", "commit_type": "change"}
{"commit_tokens": ["Fixed", "javadoc", "--", "OrdinalMap", "is", "O", "(", "1", ")", "time", "not", "O", "(", "n", ")", "time"], "add_tokens": "* The < code > OrdinalMap < / code > is memory - efficient and can retrieve an object given an ordinal , or an ordinal given an object , both in < code > O ( 1 ) < / code > time . < p / >", "del_tokens": "* The < code > OrdinalMap < / code > is memory - efficient and can retrieve an object given an ordinal , or an ordinal given an object , both in < code > O ( n ) < / code > time . < p / >", "commit_type": "fix"}
{"commit_tokens": ["make", "the", "pagination", "steps", "a", "generic", "command", "instead", "of", "having", "a", "specific", "handling", "inside", "the", "resource", "processor"], "add_tokens": "public class DirPaginator extends Paginator implements Directive { @ Override public List < PathAndModelSupplier > generateOutputPaths ( FileResource resource , Locale locale , @ Override public String name ( ) { return \"dir-pagination\" ; }", "del_tokens": "public class DirPaginator extends Paginator { public List < PathAndModelSupplier > handlePagination ( FileResource resource , Locale locale ,", "commit_type": "make"}
{"commit_tokens": ["Removing", "warnings", "(", "using", "stricter", "compiler", ")", "."], "add_tokens": "@ SuppressWarnings ( \"resource\" ) private static String getQualifiedGeneratedClassName ( final String packageName , final String generatedClassName ) { private static void appendClassBody ( final SourceWriter sourceWriter , final Set < JType > reflectedClasses ) { private static boolean isVisible ( final JType type ) {", "del_tokens": "private String getQualifiedGeneratedClassName ( final String packageName , final String generatedClassName ) { private void appendClassBody ( final SourceWriter sourceWriter , final Set < JType > reflectedClasses ) { private boolean isVisible ( final JType type ) {", "commit_type": "remove"}
{"commit_tokens": ["fix", "the", "missing", "path", "method", "for", "additional", "interactions", "updated", "example", "test"], "add_tokens": ". path ( \"/second\" ) assertEquals ( new ConsumerClient ( url ) . options ( \"/second\" ) , 200 ) ;", "del_tokens": "assertEquals ( new ConsumerClient ( url ) . options ( \"/\" ) , 200 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "small", "issue", "with", "message", "correlator", "and", "added", "sync", "message", "correlator", "to", "integration", "tests"], "add_tokens": "setVariable ( targetVariableName , receivedHeaderValues . get ( headerElementName ) . toString ( ) ) ;", "del_tokens": "setVariable ( targetVariableName , ( String ) receivedHeaderValues . get ( headerElementName ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Create", "default", "instructions", "in", "MapboxNavigation", "and", "rename", "defaultMilestone", "boolean"], "add_tokens": "private boolean defaultMilestonesEnabled = true ; / * * * Will create a set of pre - defined Milestones for basic updates while navigating along a route . * * @ param enabled - will create default milestones ( default ) * @ since 0.4 . 0 * / public void setDefaultMilestonesEnabled ( boolean enabled ) { this . defaultMilestonesEnabled = enabled ; public boolean defaultMilestonesEnabled ( ) { return defaultMilestonesEnabled ;", "del_tokens": "private boolean defaultInstructionsDisabled = false ; public void setDefaultInstructionsDisabled ( boolean disabled ) { this . defaultInstructionsDisabled = disabled ; public boolean defaultInstructionsDisabled ( ) { return defaultInstructionsDisabled ;", "commit_type": "create"}
{"commit_tokens": ["Add", "text", "/", "html", "parser", "to", "accommodate", "default", "result", "format", "for", "ASK", "queries", "in", "DBPedia"], "add_tokens": "RDF_TURTLE ( new UnsupportedFormatParser ( \"RDF Turtle\" ) , EnumSet . of ( GRAPH ) , \"text/turtle\" , \"text/n3\" , \"text/rdf+n3\" , \"application/n3\" ) , TEXT_HTML ( new HTMLParser ( ) , EnumSet . of ( ASK ) , \"text/html\" ) ; // If the expected type is unknown, we should let the server decide, otherwise we could // wind up requesting a response type that doesn't match the actual resuts (e.g. xml with CONSTRUCT). // TODO: We could include multiple media types in the Accept: field, but that assumes that the // server has proper support for content negotiation. Many servers only look at the first value.", "del_tokens": "RDF_TURTLE ( new UnsupportedFormatParser ( \"RDF Turtle\" ) , EnumSet . of ( GRAPH ) , \"text/turtle\" , \"text/n3\" , \"text/rdf+n3\" , \"application/n3\" ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "original", "error", "cause", "is", "not", "overseen", "."], "add_tokens": "throw new IllegalStateException ( e ) ;", "del_tokens": "LOG . error ( \"error initializing Dialect\" , e ) ;", "commit_type": "make"}
{"commit_tokens": ["Adds", "currency", "pairs", "in", "pairs", "enum", "fixes", "javadoc", "for", "placeOrderAndWaitUntilActive", "in", "OrderManager"], "add_tokens": "SPK_ETH ( \"SPK\" , \"ETH\" , 26.0 ) , TRX_BTC ( \"TRX\" , \"BTC\" , 26.0 ) , TRX_ETH ( \"TRX\" , \"ETH\" , 26.0 ) , TRX_USD ( \"TRX\" , \"USD\" , 26.0 ) , RCN_BTC ( \"RCN\" , \"BTC\" , 26.0 ) , RCN_ETH ( \"RCN\" , \"ETH\" , 26.0 ) , RCN_USD ( \"RCN\" , \"USD\" , 26.0 ) , RLC_BTC ( \"RLC\" , \"BTC\" , 26.0 ) , RLC_ETH ( \"RLC\" , \"ETH\" , 26.0 ) , RLC_USD ( \"RLC\" , \"USD\" , 26.0 ) , AID_BTC ( \"AID\" , \"BTC\" , 26.0 ) , AID_USD ( \"AID\" , \"USD\" , 26.0 ) , AID_ETH ( \"AID\" , \"ETH\" , 26.0 ) , SNG_BTC ( \"SNG\" , \"BTC\" , 26.0 ) , SNG_ETH ( \"SNG\" , \"ETH\" , 26.0 ) , SNG_USD ( \"SNG\" , \"USD\" , 26.0 ) , REP_BTC ( \"REP\" , \"BTC\" , 26.0 ) , REP_ETH ( \"REP\" , \"ETH\" , 26.0 ) , REP_USD ( \"REP\" , \"USD\" , 26.0 ) , ELF_BTC ( \"ELF\" , \"BTC\" , 26.0 ) , ELF_ETH ( \"ELF\" , \"ETH\" , 26.0 ) , ELF_USD ( \"ELF\" , \"USD\" , 26.0 ) , RCL_ETH ( \"RCL\" , \"ETH\" , 26.0 ) ;", "del_tokens": "SPK_ETH ( \"SPK\" , \"ETH\" , 26.0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "google", "OpenID", "ProviderType", "to", "googleopenid", "(", "lcased", ")", "."], "add_tokens": "googleopenid ,", "del_tokens": "googleOpenID ,", "commit_type": "change"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "Glossary", "searching", "on", "categories", "."], "add_tokens": "target = target . queryParam ( \"q\" , search . getQuery ( ) ) . queryParam ( \"mode\" , search . getMode ( ) ) . queryParam ( \"status\" , search . getStatus ( ) ) . queryParam ( // list parameters need to passed as an object array to get multiple query parameters; otherwise there is a single query // parameter with a list of values, which the API won't understand if ( search . getCategory ( ) != null ) target = target . queryParam ( \"category\" , search . getCategory ( ) . toArray ( ) ) ;", "del_tokens": "target = target . queryParam ( \"q\" , search . getQuery ( ) ) . queryParam ( \"category\" , search . getCategory ( ) ) . queryParam ( \"mode\" , search . getMode ( ) ) . queryParam ( \"status\" , search . getStatus ( ) ) . queryParam (", "commit_type": "fix"}
{"commit_tokens": ["Added", "schema", "summary", "for", "dexp", "command"], "add_tokens": "@ Test public void dexp_help ( ) { exec ( \"dexp\" , \"--help\" ) ; } @ Test public void dexp_tags ( ) { exec ( \"dexp\" , \"--tags\" , \"-f\" , \"target/test.stp\" ) ; } private void exec ( String ... cmd ) {", "del_tokens": "private void exec ( String ... cmd ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "defect", ":", "Attribute", ":", "record_version", "is", "not", "defined", "in", "model"], "add_tokens": "} else if ( metaModel . isVersioned ( ) ) {", "del_tokens": "} else {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "URLs", "to", "api", "and", "stream"], "add_tokens": "public static String _api_base_url = \"api.datasift.com/\" ; public static String _stream_base_url = \"stream.datasift.com/\" ;", "del_tokens": "public final static String _api_base_url = \"api.datasift.net/\" ; public static String _stream_base_url = \"stream.datasift.net/\" ;", "commit_type": "change"}
{"commit_tokens": ["add", "doc", "for", "webstart", "plugin"], "add_tokens": "private String dnamest ; public void setDnamest ( String dnamest ) { this . dnamest = dnamest ; public String getDnamest ( ) { return dnamest ; appendToDnameBuffer ( dnamest , buffer , \"ST\" ) ;", "del_tokens": "private String dnameSt ; public void setDnameSt ( String dnameSt ) { this . dnameSt = dnameSt ; public String getDnameSt ( ) { return dnameSt ; appendToDnameBuffer ( dnameSt , buffer , \"ST\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "PropertyHelper", "to", "properly", "deal", "with", "a", "lack", "of", "individual", "values", "for", "a", "given", "property", "[", "B"], "add_tokens": "return extractor . getValue ( ) . id ( ) ; return null ;", "del_tokens": "break ; return extractor . getValue ( ) . id ( ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "support", "for", "custom", "expressions"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "scripts", "to", "add", "header", "to", "source", "files", "created", "by", "SnappyData", "and", "a", "script"], "add_tokens": "/ * * Copyright ( c ) 2010 - 2016 SnappyData , Inc . All rights reserved . * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; you * may not use this file except in compliance with the License . You * may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or * implied . See the License for the specific language governing * permissions and limitations under the License . See accompanying * LICENSE file . * /", "del_tokens": "/ * * * Encapsulates the hive catalog as created by Snappy Spark . * < p / > * Created by kneeraj on 10 / 1 / 15. * /", "commit_type": "add"}
{"commit_tokens": ["move", "production", "up", "into", "BaseReduce"], "add_tokens": "super ( production ) ; this . lookahead = new IntBitSet ( ) ;", "del_tokens": "public final int production ; this . production = production ; this . lookahead = new IntBitSet ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Update", "to", "new", "analytics", "success", "response", "code"], "add_tokens": "assertEquals ( 200 , responseCode . get ( ) ) ; assertEquals ( 200 , responseCode . get ( ) ) ;", "del_tokens": "assertEquals ( 201 , responseCode . get ( ) ) ; assertEquals ( 201 , responseCode . get ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["change", "org", ".", "codelogger", ".", "utils", ".", "ValueUtils", ".", "getEnumInstance", "(", "Class<T", ">", "String", ")", "to", "public"], "add_tokens": "public static < T extends Enum > T getEnumInstance ( final Class < T > ct , final String name ) {", "del_tokens": "* * protected < T extends Enum > T getEnumInstance ( final Class < T > ct , final String name ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "owner", "&", "group", "of", "a", "file", "to", "ES", "index"], "add_tokens": "indexFile ( child , stats , filepath , path . getInputStream ( child ) ) ; private void indexFile ( FileAbstractModel fileAbstractModel , ScanStatistic stats , String filepath , InputStream fileReader ) throws Exception { final String filename = fileAbstractModel . name ; final Instant lastmodified = fileAbstractModel . lastModifiedDate ; final long size = fileAbstractModel . size ; // Attributes doc . getAttributes ( ) . setOwner ( fileAbstractModel . owner ) ; doc . getAttributes ( ) . setGroup ( fileAbstractModel . group ) ; // Attributes", "del_tokens": "indexFile ( stats , child . name , filepath , path . getInputStream ( child ) , child . lastModifiedDate , child . size ) ; private void indexFile ( ScanStatistic stats , String filename , String filepath , InputStream fileReader , Instant lastmodified , long size ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Fix", "Picasso", "indicators", "current", "switch", "state"], "add_tokens": "mIndicator . setChecked ( mPicasso . areIndicatorsEnabled ( ) ) ;", "del_tokens": "mIndicator . setChecked ( false ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "some", "more", "optimize", "in", "-", "place", "bugs"], "add_tokens": "//osm2Graph(osmReader, args);", "del_tokens": "osm2Graph ( osmReader , args ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "configuration", "property", "names", "public"], "add_tokens": "public static final String CONF_MAXBLOCKSIZE = AbstractBitcoinRecordReader . CONF_MAXBLOCKSIZE ; public static final String CONF_FILTERMAGIC = AbstractBitcoinRecordReader . CONF_FILTERMAGIC ; public static final String CONF_USEDIRECTBUFFER = AbstractBitcoinRecordReader . CONF_USEDIRECTBUFFER ; public static final String CONF_ISSPLITABLE = AbstractBitcoinFileInputFormat . CONF_ISSPLITABLE ;", "del_tokens": "private static final String CONF_MAXBLOCKSIZE = AbstractBitcoinRecordReader . CONF_MAXBLOCKSIZE ; private static final String CONF_FILTERMAGIC = AbstractBitcoinRecordReader . CONF_FILTERMAGIC ; private static final String CONF_USEDIRECTBUFFER = AbstractBitcoinRecordReader . CONF_USEDIRECTBUFFER ; private static final String CONF_ISSPLITABLE = AbstractBitcoinFileInputFormat . CONF_ISSPLITABLE ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "disabling", "configuration", "of", "Redis"], "add_tokens": "import org . springframework . session . data . redis . config . ConfigureNotifyKeyspaceEventsAction ; initializer = new EnableRedisKeyspaceNotificationsInitializer ( connectionFactory , new ConfigureNotifyKeyspaceEventsAction ( ) ) ;", "del_tokens": "initializer = new EnableRedisKeyspaceNotificationsInitializer ( connectionFactory ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "touch", "listener", "callback", "support", "."], "add_tokens": "import butterknife . OnTouch ; OnTextChanged . class , // OnTouch . class //", "del_tokens": "OnTextChanged . class //", "commit_type": "add"}
{"commit_tokens": ["update", "sample", "to", "reflect", "new", "api", "change", "."], "add_tokens": "push . unregister ( new MFPPushResponseListener < String > ( ) {", "del_tokens": "push . unregisterDevice ( new MFPPushResponseListener < String > ( ) {", "commit_type": "update"}
{"commit_tokens": ["Adding", "converge", "for", "CoProduct3", "and", "higher", "as", "well", "as", "type", "-", "indexed", "projections"], "add_tokens": "import com . jnape . palatable . traitor . annotations . TestTraits ; import com . jnape . palatable . traitor . runners . Traits ; import org . junit . runner . RunWith ; import testsupport . traits . CoProductProjections ; @ RunWith ( Traits . class ) @ TestTraits ( { CoProductProjections . class } ) public Class < ? > projections ( ) { return CoProduct2 . class ;", "del_tokens": "import java . util . Optional ; import static com . jnape . palatable . lambda . adt . hlist . HList . tuple ; @ Test public void project ( ) { assertEquals ( tuple ( Optional . of ( 1 ) , Optional . empty ( ) ) , CoProduct2 . a ( 1 ) . project ( ) ) ; assertEquals ( tuple ( Optional . empty ( ) , Optional . of ( \"b\" ) ) , CoProduct2 . b ( \"b\" ) . project ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "years", "and", "weeks", "to", "HourDayMonthBucketer"], "add_tokens": "public static final BucketType years = new BucketType ( \"year\" , new byte [ ] { 4 } ) ; public static final BucketType weeks = new BucketType ( \"weeks\" , new byte [ ] { 5 } ) ; } else if ( bucketType == years ) { returnVal = yearFloor ( dt ) ; } else if ( bucketType == weeks ) { returnVal = weekFloor ( dt ) ; return ImmutableList . of ( hours , days , months , years , weeks ) ; public static DateTime yearFloor ( DateTime dt ) { return monthFloor ( dt ) . withMonthOfYear ( 1 ) ; } public static DateTime weekFloor ( DateTime dt ) { DateTime startOfWeek = dt . minusDays ( dt . getDayOfWeek ( ) - 1 ) ; return dayFloor ( dt ) . withYear ( startOfWeek . getYear ( ) ) . withMonthOfYear ( startOfWeek . getMonthOfYear ( ) ) . withDayOfMonth ( startOfWeek . getDayOfMonth ( ) ) ; }", "del_tokens": "return ImmutableList . of ( hours , days , months ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "option", "to", "show", "logger", "name", "in", "a", "compact", "format"], "add_tokens": "FALSE , SHORT , COMPACT , LONG ;", "del_tokens": "FALSE , SHORT , LONG ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "bug", "and", "more", "logging", "messages", "for", "AckProcessor", "."], "add_tokens": "LOG . debug ( \"Getting zxid can be committd for cluster configuration {}\" , cnf . getVersion ( ) ) ; if ( cnf . contains ( ph . getServerId ( ) ) ) { // Only consider the peer who is in the given configuration. if ( ackZxid != null ) { // Ignores those who haven't acknowledged. zxids . add ( ackZxid ) ; } LOG . debug ( \" - {}'s last acked zxid {}\" , ph . getServerId ( ) , ackZxid ) ; if ( quorumSize == 0 ) { // In one case, there's only one server in cluster, and the server is // removed. Commit it directly. return cnf . getVersion ( ) ; } return Zxid . ZXID_NOT_EXIST ; LOG . debug ( \"Zxid can be committed for pending configuration is {}.\" , zxidCanCommit ) ; LOG . debug ( \"Pending configuration {} is committed, turn it into\" + \" current configuration.\" , pendingConfig . getVersion ( ) ) ; LOG . debug ( \"Zxid can be committed for current configuration is {}\" , zxidCanCommit ) ;", "del_tokens": "LOG . debug ( \"Last zxid of {} is {}\" , ph . getServerId ( ) , ph . getLastAckedZxid ( ) ) ; if ( ackZxid != null && cnf . contains ( ph . getServerId ( ) ) ) { // Add to list only if it's in the given cluster configuration and it // has sent at least one ACK to leader. zxids . add ( ph . getLastAckedZxid ( ) ) ; return this . lastCommittedZxid ; LOG . debug ( \"Pending configuration can COMMIT {}\" , zxidCanCommit ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "test", "cases", "&", "Adding", "$ref", "condition"], "add_tokens": "private static final String REF = \"$ref\" ; private JsonSchema parentSchema ; this . parentSchema = parentSchema ; if ( isEnumObjectSchema ( parentSchema ) ) { private static boolean isEnumObjectSchema ( JsonSchema jsonSchema ) { // There are three conditions for enum object schema // 1. The current schema contains key \"type\", and the value is object // 2. The current schema contains key \"enum\", and the value is an array // 3. The parent schema if refer from components, which means the corresponding enum object class would be generated JsonNode typeNode = null ; JsonNode enumNode = null ; JsonNode refNode = null ; if ( jsonSchema != null ) { if ( jsonSchema . getSchemaNode ( ) != null ) { typeNode = jsonSchema . getSchemaNode ( ) . get ( TYPE ) ; enumNode = jsonSchema . getSchemaNode ( ) . get ( ENUM ) ; } if ( jsonSchema . getParentSchema ( ) != null && jsonSchema . getParentSchema ( ) . getSchemaNode ( ) != null ) { refNode = jsonSchema . getParentSchema ( ) . getSchemaNode ( ) . get ( REF ) ; } } if ( typeNode != null && enumNode != null && refNode != null ) {", "del_tokens": "private JsonNode parentSchemaNode ; parentSchemaNode = parentSchema . getSchemaNode ( ) ; if ( isEnumObjectSchema ( parentSchemaNode ) ) { private static boolean isEnumObjectSchema ( JsonNode schemaNode ) { JsonNode typeNode = schemaNode . get ( TYPE ) ; JsonNode enumNode = schemaNode . get ( ENUM ) ; if ( typeNode != null && enumNode != null ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "for", "HtmlRenderer", "compatibility", "."], "add_tokens": "* Copyright ( C ) 2013 , 2014 , 2015 , 2016 , 2017 , 2018 AO Industries , Inc . NavigationTreeRenderer . writeNavigationTree (", "del_tokens": "* Copyright ( C ) 2013 , 2014 , 2015 , 2016 , 2017 AO Industries , Inc . NavigationTreeRenderer . writeNavigationTreeImpl (", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "Camel", "messaging"], "add_tokens": "import org . springframework . beans . factory . annotation . Autowired ; import io . codearte . accurest . messaging . AccurestMessaging ; import io . codearte . accurest . messaging . noop . NoOpAccurestMessaging ; @ Autowired ( required = false ) AccurestMessaging accurestMessaging ; BatchStubRunner batchStubRunner = new BatchStubRunnerFactory ( stubRunnerOptions , dependencies , accurestMessaging != null ? accurestMessaging : new NoOpAccurestMessaging ( ) ) . buildBatchStubRunner ( ) ;", "del_tokens": "BatchStubRunner batchStubRunner = new BatchStubRunnerFactory ( stubRunnerOptions , dependencies ) . buildBatchStubRunner ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "exception", "stack", "info", "when", "nutz", "catch", "exception"], "add_tokens": "obj = Return . fail ( \"%s:\\n%s\" , e . getMessage ( ) , Lang . getStackTrace ( e ) ) ;", "del_tokens": "obj = Return . fail ( \"%s\" , e . getMessage ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "remoteRefSpec", "attribute", "to", "fetch", "task"], "add_tokens": "import java . util . ArrayList ; private String remoteRefSpec ; / * * * Sets the remote refSpec preference for push operation . * * @ antdoc . notrequired * @ param remoteRefSpec ( Default value is '+/refs/heads/*:refs/remote/origin/*' ) * * One is able to provide an null or empty string to not set any refSpec . * / public void setRemoteRefSpec ( String remoteRefSpec ) { this . remoteRefSpec = remoteRefSpec ; } List < RefSpec > specs = new ArrayList < RefSpec > ( ) ; if ( null != remoteRefSpec && remoteRefSpec != \"\" ) { specs . add ( new RefSpec ( remoteRefSpec ) ) ; }", "del_tokens": "String currentBranch = git . getRepository ( ) . getBranch ( ) ; List < RefSpec > specs = Arrays . asList ( new RefSpec ( currentBranch + \":\" + currentBranch ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "new", "method", "for", "the", "switch", "between", "printing", "a", "semi", "colon", "for", "the", "last", "enum", "value"], "add_tokens": "import java . util . * ; @ Test public void enumDeclarationWithAnnotationAndMethod ( ) throws IOException { javaWriter . emitPackage ( \"com.squareup\" ) ; javaWriter . beginType ( \"com.squareup.Foo\" , \"enum\" , EnumSet . of ( PUBLIC ) ) ; List < String > list = Arrays . asList ( \"BAR\" , \"BAZ\" ) ; int index = 0 ; for ( Iterator < String > i = list . iterator ( ) ; i . hasNext ( ) ; ) { javaWriter . emitAnnotation ( \"ProtoEnum\" , index ) ; javaWriter . emitEnumValue ( i . next ( ) , ! i . hasNext ( ) ) ; index ++ ; } javaWriter . beginMethod ( \"void\" , \"foo\" , EnumSet . of ( PUBLIC ) ) ; javaWriter . endMethod ( ) ; javaWriter . endType ( ) ; assertCode ( \"\" + \"package com.squareup;\\n\" + \"\\n\" + \"public enum Foo {\\n\" + \" @ProtoEnum(0)\\n\" + \" BAR,\\n\" + \" @ProtoEnum(1)\\n\" + \" BAZ;\\n\" + \" public void foo() {\\n\" + \" }\\n\" + \"}\\n\" ) ; }", "del_tokens": "import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . EnumSet ; import java . util . LinkedHashMap ; import java . util . Map ; import java . util . Set ;", "commit_type": "add"}
{"commit_tokens": ["Move", "IRedisManager", "back", "to", "root"], "add_tokens": "package org . crazycake . shiro ;", "del_tokens": "package org . crazycake . shiro . common ;", "commit_type": "move"}
{"commit_tokens": ["Added", "default", "filtering", "of", "marked", "type", ".", "Added", "easy", "wrapping", "on"], "add_tokens": "private static long requireNonNegative ( final long value ) { if ( value < 0 ) { . toNanos ( requireNonNegative ( initialDelay ) ) , unit . toNanos ( requireNonNegative ( period ) ) ) ) ;", "del_tokens": "private static long requireAboveZero ( final long value ) { if ( value <= 0 ) { if ( period < 0 ) { throw new IllegalArgumentException ( ) ; } . toNanos ( requireAboveZero ( initialDelay ) ) , unit . toNanos ( period ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "fetch", "destination", "docs", "based", "on", "identity", "fields", "not"], "add_tokens": "private List < String > comparisonExclusionPaths ; private String sourceTimestampPath ; public List < String > getComparisonExclusionPaths ( ) { return comparisonExclusionPaths ; } public void setComparisonExclusionPaths ( List < String > comparisonExclusionPaths ) { this . comparisonExclusionPaths = comparisonExclusionPaths ; } public String getSourceTimestampPath ( ) { return sourceTimestampPath ; public void setSourceTimestampPath ( String sourceTimestampPath ) { this . sourceTimestampPath = sourceTimestampPath ;", "del_tokens": "private String destinationEntityTimestampField ; private List < String > sourceEntityKeyFields ; private String sourceEntityTimestampField ; public String getDestinationEntityTimestampField ( ) { return destinationEntityTimestampField ; } public void setDestinationEntityTimestampField ( String destinationEntityTimestampField ) { this . destinationEntityTimestampField = destinationEntityTimestampField ; } public List < String > getSourceEntityKeyFields ( ) { return sourceEntityKeyFields ; } public void setSourceEntityKeyFields ( List < String > sourceEntityKeyFields ) { this . sourceEntityKeyFields = sourceEntityKeyFields ; } public String getSourceEntityTimestampField ( ) { return sourceEntityTimestampField ; public void setSourceEntityTimestampField ( String sourceEntityTimestampField ) { this . sourceEntityTimestampField = sourceEntityTimestampField ;", "commit_type": "update"}
{"commit_tokens": ["improved", "rendering", "of", "string", "differences", "in", "conditions"], "add_tokens": "import org . spockframework . runtime . condition . * ; String str1 = ( String ) op1 ; String str2 = ( String ) op2 ; StringDistanceMatrix matrix = new StringDistanceMatrix ( str1 , str2 ) ; return String . format ( \"false\\n%d difference(s) (%d%% similarity)\\n%s\" , matrix . getDistance ( ) , matrix . getSimilarityInPercent ( ) , new StringDifferenceRenderer ( ) . render ( str1 , str2 , matrix . computePath ( ) ) ) ;", "del_tokens": "import org . spockframework . runtime . condition . EditDistance ; import org . spockframework . util . Tuple2 ; Tuple2 < String , String > diffs = new EditDistance ( ( String ) op1 , ( String ) op2 ) . showDistance ( ) ; return String . format ( \"false\\n%s\\n%s\" , diffs . get0 ( ) , diffs . get1 ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Adding", "hadoop", "build", "info", "plugin", "and", "using", "it", "to", "augment", "built", "info"], "add_tokens": "public String getBuiltRepoSha ( ) { return info . getProperty ( \"pipeline.built.repo.sha\" , \"?\" ) ; } public String getSourceMd5Checksum ( ) { return info . getProperty ( \"pipeline.built.source.md5.checksum\" , \"?\" ) ; } log . info ( \" Version : {}\" , getVersion ( ) ) ; log . info ( \" Built date : {}\" , getBuiltDate ( ) ) ; log . info ( \" Built by : {}\" , getBuiltBy ( ) ) ; log . info ( \" Built Repo SHA : {}\" , getBuiltRepoSha ( ) ) ; log . info ( \" Built Source MD5: {}\" , getSourceMd5Checksum ( ) ) ;", "del_tokens": "log . info ( \" Version : {}\" , getVersion ( ) ) ; log . info ( \" Built date : {}\" , getBuiltDate ( ) ) ; log . info ( \" Built by : {}\" , getBuiltBy ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "query", "util", "changes", "to", "Hashmap<String", "Object", ">", "instead", "of", "Hashmap<String", "String", ">"], "add_tokens": "HashMap < String , Object > parameters = new HashMap < String , Object > ( ) ; parameters . put ( \"include\" , QueryUtil . generateCommaSeparatedList ( includes ) ) ;", "del_tokens": "HashMap < String , String > parameters = new HashMap < String , String > ( ) ; if ( includes != null ) { parameters . put ( \"include\" , QueryUtil . generateCommaSeparatedList ( includes ) ) ; }", "commit_type": "implement"}
{"commit_tokens": ["Added", "javadoc", "comments", "for", "ListIndexes", "[", "rev", ":", "alex", ".", "scown", "]"], "add_tokens": "/ * * Copyright 2015 Hewlett - Packard Development Company , L . P . * Licensed under the MIT License ( the \"License\" ) ; you may not use this file except in compliance with the License . * / / * * * An index returned from IDOL OnDemand * / / * * * @ return The name of the index * / / * * * @ return The type of the index * / private final IndexType type ; / * * * @ return The flavor of the index . May be null * / private final IndexFlavor flavor ; / * * * @ return The description of the index * / / * * * @ return The date that index or connector was created . May be null * / private IndexType type ; private IndexFlavor flavor ;", "del_tokens": "private final String type ; private final String flavor ; private String type ; private String flavor ;", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "activate", "the", "tools", "profile", "via", "a", "property", "to", "run", "the", "test", "."], "add_tokens": "import static org . junit . Assert . assertTrue ; import java . io . IOException ; final File testDir = ResourceExtractor . simpleExtractResources ( getClass ( ) , \"/compute-pi-cxxtest-test\" ) ; final File outputFile = getTestRunnerCpp ( \"/compute-pi-cxxtest-test/compute-pi-test/\" ) ; verifier . getSystemProperties ( ) . setProperty ( MSBuildMojoITHelper . MSBUILD_PLUGIN_TOOLS_ENABLE , \"true\" ) ; assertTrue ( \"Test class not generated\" , outputFile . exists ( ) ) ; private File getTestRunnerCpp ( String directory ) throws IOException { final File outputDirectory = ResourceExtractor . simpleExtractResources ( getClass ( ) , directory ) ; return new File ( outputDirectory , \"cxxtest-runner.cpp\" ) ; }", "del_tokens": "@ Test public void testCxxTestGenerate ( ) throws Exception { File testDir = ResourceExtractor . simpleExtractResources ( getClass ( ) , \"/compute-pi-cxxtest-test\" ) ; Verifier verifier = new Verifier ( testDir . getAbsolutePath ( ) ) ; addPropertiesToVerifier ( verifier ) ; verifier . executeGoal ( GROUPID + \":\" + ARTIFACTID + \":\" + CxxTestGenMojo . MOJO_NAME ) ; verifier . verifyErrorFreeLog ( ) ; verifier . resetStreams ( ) ; } File testDir = ResourceExtractor . simpleExtractResources ( getClass ( ) , \"/compute-pi-cxxtest-test\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "three", "types", "of", "zoom", ":", "horizontal", "vertical", "both"], "add_tokens": "mChartZoomer = new ChartZoomer ( context , ChartZoomer . ZOOM_HORIZONTAL_AND_VERTICAL ) ;", "del_tokens": "mChartZoomer = new ChartZoomer ( context ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "unit", "test", "for", "createFolder"], "add_tokens": "import static org . skyscreamer . jsonassert . JSONCompareMode . * ; import org . junit . Rule ; import static com . github . tomakehurst . wiremock . client . WireMock . * ; import com . github . tomakehurst . wiremock . junit . WireMockRule ; @ Rule public final WireMockRule wireMockRule = new WireMockRule ( 8080 ) ; @ Test @ Category ( UnitTest . class ) public void createFolderSendsRequestWithRequiredFields ( ) { BoxAPIConnection api = new BoxAPIConnection ( \"\" ) ; api . setBaseURL ( \"http://localhost:8080/\" ) ; BoxFolder rootFolder = BoxFolder . getRootFolder ( api ) ; String parentFolderID = rootFolder . getID ( ) ; String createdFolderName = \"[createFolderSendsRequestWithRequiredFields] Child Folder\" ; stubFor ( post ( urlMatching ( \"/folders\" ) ) . withRequestBody ( equalToJson ( \"{ \\\"name\\\": \\\"\" + createdFolderName + \"\\\", \\\"parent\\\": {\\\"id\\\": \\\"\" + parentFolderID + \"\\\"} }\" , LENIENT ) ) . willReturn ( aResponse ( ) . withHeader ( \"Content-Type\" , \"application/json\" ) . withBody ( \"{\\\"id\\\": \\\"0\\\"}\" ) ) ) ; BoxFolder childFolder = rootFolder . createFolder ( createdFolderName ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "(", "empty", ")", "when", "no", "data", "is", "present", "."], "add_tokens": "out . append ( ''). a p pend(p a d(e m ptyWidth, \" empty)\")) . a p pend(\"  \\n\");", "del_tokens": "out . append ( ''). a p pend(p a d(e m ptyWidth, \" o results.\")) . a p pend(\"  \\n\");", "commit_type": "use"}
{"commit_tokens": ["Use", "foreach", "instead", "of", "iterator"], "add_tokens": "for ( RuntimeInfo runtimeInfo : runtimesInfos ) { for ( Entry < Integer , RuntimeNode > entry : rootNode . getNodes ( ) . entrySet ( ) ) {", "del_tokens": "Iterator < RuntimeInfo > itr = runtimesInfos . iterator ( ) ; while ( itr . hasNext ( ) ) { RuntimeInfo runtimeInfo = itr . next ( ) ; Iterator < Entry < Integer , RuntimeNode > > itr = rootNode . getNodes ( ) . entrySet ( ) . iterator ( ) ; while ( itr . hasNext ( ) ) { Entry < Integer , RuntimeNode > entry = itr . next ( ) ;", "commit_type": "use"}
{"commit_tokens": ["remove", "ServiceDirectoryConfig", "class", "the", "unnecessary", "wrapper", "of", "Configuration", "."], "add_tokens": "import org . apache . commons . configuration . Configuration ; private static final Configuration serviceDirectoryConfig = ConfigurationFactory . getConfiguration ( ) ; public static Configuration getServiceDirectoryConfig ( ) {", "del_tokens": "import com . cisco . oss . foundation . directory . config . ServiceDirectoryConfig ; private static final ServiceDirectoryConfig serviceDirectoryConfig = new ServiceDirectoryConfig ( ConfigurationFactory . getConfiguration ( ) ) ; public static ServiceDirectoryConfig getServiceDirectoryConfig ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Make", "some", "FLAC", "bits", "more", "common", "and", "start", "on", "a", "basic", "Tika", "Ogg", "Parser"], "add_tokens": "import org . gagravarr . ogg . HighLevelStreamPacket ; public abstract class VorbisPacket extends HighLevelStreamPacket { super ( oggPacket ) ; super ( ) ; @ Override @ Override }", "del_tokens": "public abstract class VorbisPacket { private OggPacket oggPacket ; private byte [ ] data ; this . oggPacket = oggPacket ; this . oggPacket = null ; } protected OggPacket getOggPacket ( ) { return oggPacket ; } public byte [ ] getData ( ) { if ( data != null ) { return data ; } if ( oggPacket != null ) { return oggPacket . getData ( ) ; } return null ; } public void setData ( byte [ ] data ) { this . data = data ; } public OggPacket write ( ) { this . oggPacket = new OggPacket ( getData ( ) ) ; return this . oggPacket ; }", "commit_type": "make"}
{"commit_tokens": ["Fix", "bug", "where", "payment", "method", "account", "ID", "was", "not", "being", "stored"], "add_tokens": "this . _accountId = accountId ;", "del_tokens": "this . _accountId = _accountId ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "check", "for", "a", "field", "loosing", "compile", "time", "constant", "."], "add_tokens": "FIELD_CONSTANT_REMOVED ( \"java.field.removedWithConstant\" , BREAKING , NON_BREAKING , POTENTIALLY_BREAKING ) ,", "del_tokens": "FIELD_CONSTANT_REMOVED ( \"java.field.removedWithConstant\" , BREAKING , POTENTIALLY_BREAKING , POTENTIALLY_BREAKING ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "arbitrarily", "nested", "multi", "-", "module", "maven", "projects", ".", "Now", "seeks", ".", "git", "directory", "by", "climbing", "MavenProject", ".", "getParent", "()", ".", "Also", "fixed", "bug", "where", "guessed", ".", "git", "directory", "paths", "were", "missing", "a", "directory", "separator", "."], "add_tokens": "//Walk up the project parent hierarchy seeking the .git directory MavenProject mavenProject = project ; while ( mavenProject != null ) { dotGitDirectory = new File ( mavenProject . getBasedir ( ) , Constants . DOT_GIT ) ; if ( dotGitDirectory . exists ( ) && dotGitDirectory . isDirectory ( ) ) { return dotGitDirectory ; } // If we've reached the top-level parent and not found the .git directory, look one level further up if ( mavenProject . getParent ( ) == null ) { dotGitDirectory = new File ( mavenProject . getBasedir ( ) . getParentFile ( ) , Constants . DOT_GIT ) ; if ( dotGitDirectory . exists ( ) && dotGitDirectory . isDirectory ( ) ) { return dotGitDirectory ; } } mavenProject = mavenProject . getParent ( ) ;", "del_tokens": "// guess the .git location as the basedir of the project dotGitDirectory = new File ( project . getBasedir ( ) . getAbsolutePath ( ) + Constants . DOT_GIT ) ; if ( dotGitDirectory . exists ( ) && dotGitDirectory . isDirectory ( ) ) { return dotGitDirectory ; } File basedir = project . getBasedir ( ) ; dotGitDirectory = new File ( basedir . getParent ( ) + Constants . DOT_GIT ) ; if ( dotGitDirectory . exists ( ) && dotGitDirectory . isDirectory ( ) ) { return dotGitDirectory ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "end", "-", "of", "-", "data", "buffer", "handling"], "add_tokens": "if ( matrixbytes [ i ] >= ( binlen + process_p ) ) { if ( process_p != 0 ) { binlen = encodeRemainder ( matrixbytes [ symbolsize ] - binlen , binlen ) ; } if ( debug ) System . out . printf ( \"FN1 \" ) ; if ( debug ) System . out . printf ( \"RP \" ) ; System . out . printf ( \"\\nHex Data: \" ) ; System . out . printf ( \"+Buffer=: \" ) ; System . out . printf ( \"%02X \" , target [ i ] ) ; System . out . printf ( \"\\n\\n\" ) ;", "del_tokens": "if ( matrixbytes [ i ] >= binlen ) { binlen = encodeRemainder ( matrixbytes [ symbolsize ] - binlen , binlen ) ; if ( debug ) System . out . printf ( \"FN1 \" ) ; if ( debug ) System . out . printf ( \"RP \" ) ; System . out . printf ( \"\\n\\n\" ) ; System . out . printf ( \"\\n\\n\" ) ; System . out . printf ( \"%03d \" , target [ i ] ) ; System . out . printf ( \"\\n\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["updated", "libs", "fixed", "src", "attributes", "in", "samples"], "add_tokens": "import carbon . widget . ImageView ; ImageView airplaneModeIcon = ( ImageView ) v . findViewById ( R . id . airplaneModeIcon ) ; ( ( ImageView ) v ) . setColorFilter ( getResources ( ) . getColor ( R . color . carbon_black_54 ) ) ; ( ( ImageView ) v ) . setColorFilter ( 0xffffffff ) ; ( ( ImageView ) v ) . setColorFilter ( getResources ( ) . getColor ( R . color . carbon_black_54 ) ) ; ( ( ImageView ) v ) . setColorFilter ( 0xffffffff ) ;", "del_tokens": "SVGView airplaneModeIcon = ( SVGView ) v . findViewById ( R . id . airplaneModeIcon ) ; ( ( SVGView ) v ) . setColorFilter ( getResources ( ) . getColor ( R . color . carbon_black_54 ) ) ; ( ( SVGView ) v ) . setColorFilter ( 0xffffffff ) ; ( ( SVGView ) v ) . setColorFilter ( getResources ( ) . getColor ( R . color . carbon_black_54 ) ) ; ( ( SVGView ) v ) . setColorFilter ( 0xffffffff ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "PersistableBundleCompatTest", "an", "unit", "test"], "add_tokens": "package com . evernote . android . job . util . support ; import com . evernote . android . job . test . JobRobolectricTestRunner ; import org . junit . FixMethodOrder ; import org . junit . runners . MethodSorters ; import static org . assertj . core . api . Java6Assertions . assertThat ; @ RunWith ( JobRobolectricTestRunner . class ) @ FixMethodOrder ( MethodSorters . JVM )", "del_tokens": "package com . evernote . android . job . test ; import android . support . test . filters . SmallTest ; import android . support . test . runner . AndroidJUnit4 ; import com . evernote . android . job . util . support . PersistableBundleCompat ; import static org . assertj . core . api . Assertions . assertThat ; @ RunWith ( AndroidJUnit4 . class ) @ SmallTest @ SuppressWarnings ( \"ConstantConditions\" )", "commit_type": "make"}
{"commit_tokens": ["Add", "sample", "and", "first", "test"], "add_tokens": "private boolean hasOverrides ; @ Override public void installOverrideModules ( Module ... modules ) { //we allow multiple calls to this method boolean oldHasOverrides = hasOverrides ; hasOverrides = false ; installModules ( modules ) ; boolean doOverrideModulesExist = modules != null && modules . length != 0 ; hasOverrides = oldHasOverrides || doOverrideModulesExist ; } if ( ! hasOverrides || ! scope . containsKey ( binding . getKey ( ) ) ) { scope . put ( binding . getKey ( ) , toProvider ( binding ) ) ; }", "del_tokens": "scope . put ( binding . getKey ( ) , toProvider ( binding ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "com", ".", "sdl", ".", "bootstrap", ".", "button", ".", "DownloadFile"], "add_tokens": "* public boolean download ( String [ ] filePath ) { return new RunExe ( ) . download ( filePath ) ;", "del_tokens": "import org . openqa . selenium . firefox . FirefoxDriver ; import org . testng . Assert ; import java . io . IOException ; public void download ( String [ ] filePath ) { try { Process process = Runtime . getRuntime ( ) . exec ( filePath [ 0 ] + \" \" + filePath [ 1 ] + \" \" + uploadName ( ) ) ; if ( 0 != process . waitFor ( ) ) { Assert . fail ( ) ; } } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } private String uploadName ( ) { return WebLocator . driver instanceof FirefoxDriver ? \"Opening\" : \"Save As\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "compiler", "and", "checkstyle", "warnings", "."], "add_tokens": "import org . hamcrest . collection . IsIterableContainingInOrder ; import static org . junit . Assert . * ; Matcher < String > matcher = CombinableMatcher . < String > both ( equalTo ( \"abc\" ) ) . and ( equalTo ( \"bc\" ) ) ; Matcher < String > matcher = anyOf ( equalTo ( \"ab\" ) , equalTo ( \"bc\" ) , equalTo ( \"ac\" ) ) ; . hasPhoneList ( IsIterableContainingInOrder . contains (", "del_tokens": "import java . util . regex . MatchResult ; import static org . hamcrest . MatcherAssert . assertThat ; import static org . hamcrest . collection . IsIterableContainingInOrder . contains ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; Matcher matcher = CombinableMatcher . < String > both ( equalTo ( \"abc\" ) ) . and ( equalTo ( \"bc\" ) ) ; Matcher matcher = anyOf ( equalTo ( \"ab\" ) , equalTo ( \"bc\" ) , equalTo ( \"ac\" ) ) ; . hasPhoneList ( contains (", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "more", "general", "built", "-", "in", "number", "conversion"], "add_tokens": "actions . setValue ( convertToNumber ( text ( \"oneOrMore\" ) , Integer . class ) )", "del_tokens": "actions . setValue ( convertToInteger ( text ( \"oneOrMore\" ) ) )", "commit_type": "implement"}
{"commit_tokens": ["fix", "HealthCheckInstaller", ":", "avoid", "pure", "HealthCheck", "types", "installation"], "add_tokens": "return FeatureUtils . is ( type , NamedHealthCheck . class ) ;", "del_tokens": "import com . codahale . metrics . health . HealthCheck ; return FeatureUtils . is ( type , HealthCheck . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "Default", "Method", "for", "setRefreshing"], "add_tokens": "public void setRefreshing ( ) { this . setRefreshing ( true ) ; } public void setRefreshing ( boolean doScroll ) { if ( state == REFRESHING ) return ; state = REFRESHING ; switch ( currentMode ) { case MODE_PULL_DOWN_TO_REFRESH : if ( doScroll ) smoothScrollTo ( - headerHeight ) ; headerLayout . refreshing ( ) ; break ; case MODE_PULL_UP_TO_REFRESH : if ( doScroll ) smoothScrollTo ( headerHeight ) ; footerLayout . refreshing ( ) ; break ; } }", "del_tokens": "public void setRefreshing ( boolean doScroll ) { if ( state == REFRESHING ) return ; state = REFRESHING ; switch ( currentMode ) { case MODE_PULL_DOWN_TO_REFRESH : if ( doScroll ) smoothScrollTo ( - headerHeight ) ; headerLayout . refreshing ( ) ; break ; case MODE_PULL_UP_TO_REFRESH : if ( doScroll ) smoothScrollTo ( headerHeight ) ; footerLayout . refreshing ( ) ; break ; } }", "commit_type": "add"}
{"commit_tokens": ["add", "unit", "tests", "and", "length", "calculator", "for", "enclosing", "bounding", "box"], "add_tokens": "import static org . junit . Assert . assertFalse ; @ Test public void testHashContains ( ) { LatLong centre = decodeHash ( \"dre7\" ) ; assertTrue ( GeoHash . hashContains ( \"dre7\" , centre . getLat ( ) , centre . getLon ( ) ) ) ; assertFalse ( GeoHash . hashContains ( \"dre7\" , centre . getLat ( ) + 20 , centre . getLon ( ) ) ) ; assertFalse ( GeoHash . hashContains ( \"dre7\" , centre . getLat ( ) , centre . getLon ( ) + 20 ) ) ; } @ Test public void testHashLengthToEncloseBoundingBoxReturns0IfBoxTooBig ( ) { assertEquals ( 0 , GeoHash . hashLengthToEncloseBoundingBox ( 80 , - 170 , - 80 , 170 ) ) ; }", "del_tokens": "import static com . github . davidmoten . geo . GeoHash . hashesToCoverBoundingBoxWithMinHashesPerAxis ; // @Test public void testCoverBoundingBoxAroundBostonNumIsTwo ( ) { Set < String > hashes = hashesToCoverBoundingBoxWithMinHashesPerAxis ( SCHENECTADY_LAT , SCHENECTADY_LON , HARTFORD_LAT , HARTFORD_LON , 3 ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testCoverBoundingBoxMustBePassedMinHashesGreaterThanZero ( ) { hashesToCoverBoundingBoxWithMinHashesPerAxis ( 0 , 135 , 10 , 145 , 0 ) ; }", "commit_type": "add"}
{"commit_tokens": ["Use", "local", "variable", "for", "target", "class", "."], "add_tokens": "inject = injector . getMethod ( \"inject\" , targetClass , sourceType ) ;", "del_tokens": "inject = injector . getMethod ( \"inject\" , target . getClass ( ) , sourceType ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "multiple", "solr", "queries", "in", "dysco"], "add_tokens": "public final Logger logger = Logger . getLogger ( SolrDyscoHandler . class ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "shortcut", "to", "get", "key", "from", "unfetched", "proxy"], "add_tokens": "@ Test public final void testGetKeyWithoutFetching ( ) { RootEntity root = new RootEntity ( ) ; ReferencedEntity reference = new ReferencedEntity ( ) ; root . r = reference ; reference . setFoo ( \"bar\" ) ; Key < ReferencedEntity > k = ds . save ( reference ) ; String keyAsString = k . getId ( ) . toString ( ) ; ds . save ( root ) ; root = ds . get ( root ) ; ReferencedEntity p = root . r ; assertIsProxy ( p ) ; assertNotFetched ( p ) ; Assert . assertEquals ( keyAsString , ds . getKey ( p ) . getId ( ) . toString ( ) ) ; // still unfetched? assertNotFetched ( p ) ; p . getFoo ( ) ; // should be fetched now. assertFetched ( p ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Removed", "final", "as", "the", "class", "needs", "to", "be", "extendable"], "add_tokens": "public class HttpClientSettings { public int getConnectionTimeout ( ) { public void setConnectionTimeout ( int connectionTimeout ) { public String getProxyPassword ( ) { public void setProxyPassword ( String proxyPassword ) { public URL getProxyUrl ( ) { public void setProxyUrl ( URL proxyUrl ) { public String getProxyUser ( ) { public void setProxyUser ( String proxyUser ) { public int getReadTimeout ( ) { public void setReadTimeout ( int readTimeout ) {", "del_tokens": "public final class HttpClientSettings { public final int getConnectionTimeout ( ) { public final void setConnectionTimeout ( int connectionTimeout ) { public final String getProxyPassword ( ) { public final void setProxyPassword ( String proxyPassword ) { public final URL getProxyUrl ( ) { public final void setProxyUrl ( URL proxyUrl ) { public final String getProxyUser ( ) { public final void setProxyUser ( String proxyUser ) { public final int getReadTimeout ( ) { public final void setReadTimeout ( int readTimeout ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "issue", "with", "closure", "postprocessor", "with", "excluded", "global", "bundles"], "add_tokens": "if ( ! excludedBundles . contains ( bundle . getName ( ) ) ) { generateBundleModuleArgs ( args , bundleMap , resultBundlePathMapping , bundle , globalBundleDependencies ) ; }", "del_tokens": "generateBundleModuleArgs ( args , bundleMap , resultBundlePathMapping , bundle , globalBundleDependencies ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "startup", "test", "and", "expanded", "it", "to", "use", "SSL", "by", "default"], "add_tokens": "public static final String SERVER_BIND_IP_KEY = \"rest.bindIP\" ; public static final String SERVER_BIND_PORT_KEY = \"rest.bindPort\" ; public static final String SERVER_BIND_SSL_ENABLED_KEY = \"rest.ssl.enabled\" ; public static final String SERVER_BIND_SSL_KEYSTORE_PATH_KEY = \"rest.ssl.keystore.path\" ; public static final String SERVER_BIND_SSL_KEYSTORE_TYPE_KEY = \"rest.ssl.keystore.type\" ; public static final String SERVER_BIND_SSL_KEYSTORE_PASSWORD_KEY = \"rest.ssl.keystore.password\" ; public static final String SERVER_BIND_SSL_KEY_PASSWORD_KEY = \"rest.ssl.key.password\" ;", "del_tokens": "private static final String SERVER_BIND_IP_KEY = \"rest.bindIP\" ; private static final String SERVER_BIND_PORT_KEY = \"rest.bindPort\" ; private static final String SERVER_BIND_SSL_ENABLED_KEY = \"rest.ssl.enabled\" ; private static final String SERVER_BIND_SSL_KEYSTORE_PATH_KEY = \"rest.ssl.keystore.path\" ; private static final String SERVER_BIND_SSL_KEYSTORE_TYPE_KEY = \"rest.ssl.keystore.type\" ; private static final String SERVER_BIND_SSL_KEYSTORE_PASSWORD_KEY = \"rest.ssl.keystore.password\" ; private static final String SERVER_BIND_SSL_KEY_PASSWORD_KEY = \"rest.ssl.key.password\" ;", "commit_type": "fix"}
{"commit_tokens": ["add", "spark", "java", "for", "testing", "api"], "add_tokens": "import static spark . Spark . * ; get ( \"/\" , ( request , response ) -> { return testRequests ( ) + \"\\n\\n\" + testJsonBuilder ( ) ; //testRequests(); } ) ; public static String testJsonBuilder ( ) throws IOException return json ; public static String testRequests ( ) throws UnirestException { . header ( \"cookie\" , \"foo=bar; bar=baz\" ) . header ( \"accept\" , \"application/json\" ) . header ( \"content-type\" , \"application/json\" ) . header ( \"x-pretty-print\" , \"2\" ) . body ( \"{\\\"foo\\\": \\\"bar\\\"}\" ) . asString ( ) ; return response . getStatusText ( ) ;", "del_tokens": "testJsonBuilder ( ) ; testRequests ( ) ; public static void testJsonBuilder ( ) throws IOException System . out . println ( json ) ; public static void testRequests ( ) throws UnirestException { . header ( \"cookie\" , \"foo=bar; bar=baz\" ) . header ( \"accept\" , \"application/json\" ) . header ( \"content-type\" , \"application/json\" ) . header ( \"x-pretty-print\" , \"2\" ) . body ( \"{\\\"foo\\\": \\\"bar\\\"}\" ) . asString ( ) ; System . out . println ( response . getStatusText ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "getExtensionFactory", "in", "PluginManager", "interface"], "add_tokens": "public DefaultExtensionFinder ( PluginManager pluginManager ) { extensionWrapper . setExtensionFactory ( pluginManager . getExtensionFactory ( ) ) ;", "del_tokens": "protected ExtensionFactory extensionFactory ; public DefaultExtensionFinder ( PluginManager pluginManager , ExtensionFactory extensionFactory ) { this . extensionFactory = extensionFactory ; extensionWrapper . setExtensionFactory ( extensionFactory ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "support", "for", "intercepting", "an", "appended", "LST", "when", "written", "via", "the", "public", "IonWriter", "APIs", "."], "add_tokens": "if ( self . isUserLSTAppend ) { self . flush ( ) ; } else { // flush out the pre-existing symbol and user content before the user provided symbol table self . finish ( ) ; // replace the symbol table context with the user provided one // TODO determine if the resolver mode should be configurable for this use case self . imports = new ImportedSymbolContext ( ImportedSymbolResolverMode . DELEGATE , self . userImports ) ; } self . isUserLSTAppend = false ; @ Override public void writeSymbolToken ( final IonManagedBinaryWriter self , final SymbolToken value ) { if ( self . user . getDepth ( ) == 1 && self . user . getFieldId ( ) == IMPORTS_SID && value . getSid ( ) == ION_SYMBOL_TABLE_SID ) { self . isUserLSTAppend = true ; self . userState = LOCALS_AT_TOP ; } } public void writeSymbolToken ( final IonManagedBinaryWriter self , final SymbolToken value ) { } private boolean isUserLSTAppend ; this . isUserLSTAppend = false ; userState . writeSymbolToken ( this , token ) ;", "del_tokens": "// flush out the pre-existing symbol and user content before the user provided symbol table self . finish ( ) ; // replace the symbol table context with the user provided one // TODO determine if the resolver mode should be configurable for this use case self . imports = new ImportedSymbolContext ( ImportedSymbolResolverMode . DELEGATE , self . userImports ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "word", "writable"], "add_tokens": "public static final String [ ] pathsThatShouldNotBeWritable = {", "del_tokens": "public static final String [ ] pathsThatShouldNotBeWrtiable = {", "commit_type": "fix"}
{"commit_tokens": ["Added", "readLong", "in", "UI", "better", "selection", "of", "segment", "in", "Cache"], "add_tokens": "private static final int NUMBER_OF_SEGMENTS_EXPONENT = 8 ; private static final long SEGMENTS_KEY_MASK = NUMBER_OF_SEGMENTS - 1 ; return ( int ) ( key & SEGMENTS_KEY_MASK ) ;", "del_tokens": "private static final int NUMBER_OF_SEGMENTS_EXPONENT = 7 ; return ( int ) ( ( key >> ( 64 - NUMBER_OF_SEGMENTS_EXPONENT ) ) + NUMBER_OF_SEGMENTS / 2 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "strikethrough", "support", "for", "android"], "add_tokens": "TEXT ( 0x114 ) , STRIKETHROUGH ( 0x115 ) ;", "del_tokens": "TEXT ( 0x114 ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "slash", "character", "problem", "if", "it", "is", "entered", "last", "char", "of", "connection", "string"], "add_tokens": "return null ; String serverUrl = elasticSearchServer . endsWith ( \"/\" ) ? elasticSearchServer . substring ( 0 , elasticSearchServer . length ( ) - 1 ) : elasticSearchServer ; StringBuilder sb = new StringBuilder ( serverUrl ) ; sb . append ( \"/\" ) . append ( defaultIndex ) ;", "del_tokens": "return null ; //To change body of implemented methods use File | Settings | File Templates. //To change body of implemented methods use File | Settings | File Templates. StringBuilder sb = new StringBuilder ( elasticSearchServer ) ; if ( ! elasticSearchServer . endsWith ( \"/\" ) ) sb . append ( \"/\" ) ; sb . append ( defaultIndex ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "unnecessary", "synchronisation", "setName", "added", "to", "chat", "conversation", "builder"], "add_tokens": "public final void execute ( @ NonNull StoreTransaction < T > transaction ) {", "del_tokens": "synchronized public final void execute ( @ NonNull StoreTransaction < T > transaction ) {", "commit_type": "remove"}
{"commit_tokens": ["Use", "new", "structure", "for", "the", "feature", "installer"], "add_tokens": "import java . util . Collections ; import com . ibm . liberty . starter . pom . AddFeaturesCommand ; AddFeaturesCommand command = new AddFeaturesCommand ( services , serviceConnector ) ; PomModifier pomModifier = new PomModifier ( pomInputStream , Collections . singleton ( command ) ) ; putFileInMap ( WLP_CFG_POM_FILE , pomModifier . getPomBytes ( ) ) ;", "del_tokens": "FeatureInstaller featureInstaller = new FeatureInstaller ( services , serviceConnector ) ; putFileInMap ( WLP_CFG_POM_FILE , featureInstaller . addFeaturesToInstall ( pomInputStream ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Made", "Br", "tag", "as", "self", "closing"], "add_tokens": "private static boolean selfClosing = true ; super ( selfClosing , Br . class . getSimpleName ( ) . toLowerCase ( ) , base , attributes ) ; if ( ! ( abstractAttribute != null && ( abstractAttribute instanceof BaseAttribute || abstractAttribute instanceof GlobalAttribute ) ) ) { / * * * @ param selfClosing * < code > true < / code > to set as self closing tag and * < code > false < / code > for not to set as self closing tag . The * default value is < code > true < / code > . * @ since 1.0 . 0 * @ author WFF * / public static void setSelfClosing ( final boolean selfClosing ) { Br . selfClosing = selfClosing ; } public static boolean isSelfClosing ( ) { return selfClosing ; }", "del_tokens": "super ( Br . class . getSimpleName ( ) . toLowerCase ( ) , base , attributes ) ; if ( ! ( abstractAttribute != null && ( abstractAttribute instanceof BaseAttribute || abstractAttribute instanceof GlobalAttribute ) ) ) {", "commit_type": "make"}
{"commit_tokens": ["add", "colorstatelist", "for", "button", "text", "color"], "add_tokens": "setTextColor ( BootstrapDrawableFactory . bootstrapButtonText ( getContext ( ) , params ) ) ;", "del_tokens": "// FIXME should use a text selector for outlines", "commit_type": "add"}
{"commit_tokens": ["Fix", "regression", "where", "ArrayData", "didn", "t", "reload", "if", "invalidated", "during", "a", "load"], "add_tokens": "cancelTask ( ) ; cancelTask ( ) ; cancelTask ( ) ; private void cancelTask ( ) { if ( mTask != null ) { mTask . cancel ( ) ; mTask = null ; } }", "del_tokens": "if ( mTask != null ) { mTask . cancel ( ) ; mTask = null ; } if ( mTask != null ) { mTask . cancel ( ) ; mTask = null ; }", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "tests", ".", "Updated", "dependencies", "."], "add_tokens": "private final File destination ; * @ param destination public CompileTask ( File source , File destination , Log log , boolean verbose ) { this . destination = destination ; OutputStream out = null ; out = new FileOutputStream ( destination ) ; cleanUpAndThrowError ( destination , e ) ; log . error ( \"Could not compile \" + source . getName ( ) + \" because \" + e . getMessage ( ) , e ) ;", "del_tokens": "private final File dest ; * @ param dest public CompileTask ( File source , File dest , Log log , boolean verbose ) { this . dest = dest ; OutputStream out = new FileOutputStream ( dest ) ; cleanUpAndThrowError ( dest , e ) ; log . error ( \"Could not compile \" + source . getName ( ) , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "delegation", "of", "static", "methods", "."], "add_tokens": "Object methodInvoked ( Class clazz , String methodName , Object instance , String [ ] paramTypes , Object [ ] params ) ;", "del_tokens": "Object methodInvoked ( String className , String methodName , Object instance , String [ ] paramTypes , Object [ ] params ) ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "context", "tests", "around", "added", "AppiumDriverTest"], "add_tokens": "package io . appium . java_client ; public class ContextTest {", "del_tokens": "package io . appium . java_client . ios ; public class IOSContextTest {", "commit_type": "move"}
{"commit_tokens": ["Added", "jandex", "to", "the", "mix"], "add_tokens": "import org . wildfly . apigen . generator . ResourceRef ; List < ResourceRef > references = config . getReferences ( ) ; ResourceRef resourceRef = references . get ( 0 ) ;", "del_tokens": "List < Config . ResourceRef > references = config . getReferences ( ) ; Config . ResourceRef resourceRef = references . get ( 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "deepest", "logical", "area", "when", "searching", "an", "area", "in", "the", "logical", "tree"], "add_tokens": "LogicalArea ret = null ; //scan the subtree for ( int i = 0 ; i < getChildCount ( ) && ret == null ; i ++ ) ret = getChildArea ( i ) . findArea ( area ) ; //not in the subtree -- is it this area? if ( ret == null && getAreas ( ) . contains ( area ) ) ret = this ; //in our area nodes return ret ;", "del_tokens": "if ( getAreas ( ) . contains ( area ) ) return this ; //in our area nodes else //in the subtree for ( int i = 0 ; i < getChildCount ( ) ; i ++ ) { final LogicalArea ret = getChildArea ( i ) . findArea ( area ) ; if ( ret != null ) return ret ; } return null ;", "commit_type": "use"}
{"commit_tokens": ["fix", "testng", "tests", "with", "parameters"], "add_tokens": "import static java . util . Collections . singletonList ; List < String > testUuid = singletonList ( testResult . get ( 0 ) . getUuid ( ) ) ; List < String > testUuid = singletonList ( testResult . get ( 0 ) . getUuid ( ) ) ; final List < String > secondSuite = singletonList ( uids . get ( 2 ) ) ; @ Test public void shouldUseParametersForHistoryIdGeneration ( ) throws Exception { runTestNgSuites ( \"suites/history-id-parameters.xml\" ) ; final List < TestResult > testResults = results . getTestResults ( ) ; assertThat ( testResults ) . hasSize ( 3 ) . extracting ( TestResult :: getHistoryId ) . containsExactlyInAnyOrder ( \"84bf9104f500de5d87d57530adbd6721\" , \"84bf9104f500de5d87d57530adbd6721\" , \"71e91659283b08ec583ddcdad73075c7\" ) ; }", "del_tokens": "import java . util . Collections ; List < String > testUuid = Collections . singletonList ( testResult . get ( 0 ) . getUuid ( ) ) ; List < String > testUuid = Collections . singletonList ( testResult . get ( 0 ) . getUuid ( ) ) ; final List < String > secondSuite = Collections . singletonList ( uids . get ( 2 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "back", "old", "methods", "(", "deprecated", ")", "on", "RestPlugin"], "add_tokens": "import java . util . Collection ; import java . util . HashMap ; import java . util . HashSet ; import java . util . Map ; import java . util . Set ; @ Deprecated public void registerRootResource ( Variant variant , Class < ? extends RootResource > rootResource ) { addRootResourceVariant ( variant , rootResource ) ; } @ Deprecated public String getRestPath ( ) { return restConfiguration . getRestPath ( ) ; } @ Deprecated public String getJspPath ( ) { return restConfiguration . getJspPath ( ) ; }", "del_tokens": "import java . util . * ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "number", "of", "javadoc", "issues", "in", "Amazon", "SNS", "package", "."], "add_tokens": "* The < code > CreateTopic < / code > action creates a topic to which notifications can be published . Users can create at most 3000 topics . For more", "del_tokens": "* The < code > CreateTopic < / code > action creates a topic to which notifications can be published . Users can create at most 100 topics . For more", "commit_type": "fix"}
{"commit_tokens": ["update", "jwt", ".", "json", "and", "security", ".", "json", "to", "support", "multiple", "certs"], "add_tokens": "Key key ; public Key getKey ( ) { return key ; } public void setKey ( Key key ) { this . key = key ; } public class Key { String kid ; String filename ; String password ; String keyName ; public Key ( ) { } public String getKid ( ) { return kid ; } public void setKid ( String kid ) { this . kid = kid ; } public String getFilename ( ) { return filename ; } public void setFilename ( String filename ) { this . filename = filename ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public String getKeyName ( ) { return keyName ; } public void setKeyName ( String keyName ) { this . keyName = keyName ; } }", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Remove", "async", "scheduled", "task", "from", "Queue", ".", "java"], "add_tokens": "import java . util . concurrent . RejectedExecutionException ;", "del_tokens": "} else if ( state . config . uploadWhenOlderThan > 0 ) { executor . schedule ( new Runnable ( ) { @ Override public void run ( ) { if ( isEventsReadyForUpload ( Time . now ( ) ) ) { uploadRequester . requestUpload ( ) ; } } } , state . config . uploadWhenOlderThan , TimeUnit . MILLISECONDS ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "proper", "HMAC", "-", "SHA1", "for", "message", "authentication"], "add_tokens": "import javax . crypto . Mac ; import javax . crypto . spec . SecretKeySpec ; / * * * A DigestAlgorithm implementing HMAC using SHA1 as digest algorithm as specified by RFC2104 . * / private static final String MAC_ALGORITHM = \"HmacSHA1\" ; private final SecretKeySpec secret ; this . secret = new SecretKeySpec ( secret , MAC_ALGORITHM ) ; Mac mac = Mac . getInstance ( MAC_ALGORITHM ) ; mac . init ( secret ) ; return mac . doFinal ( data ) ; } catch ( Exception e ) {", "del_tokens": "import java . security . MessageDigest ; import java . security . NoSuchAlgorithmException ; import java . util . Arrays ; private static final String DIGEST_ALGORITHM = \"SHA-1\" ; private final byte [ ] secret ; this . secret = Arrays . copyOf ( secret , secret . length ) ; MessageDigest digest = MessageDigest . getInstance ( DIGEST_ALGORITHM ) ; digest . reset ( ) ; digest . update ( secret ) ; digest . update ( data ) ; return Arrays . copyOf ( digest . digest ( ) , DIGEST_LENGTH ) ; } catch ( NoSuchAlgorithmException e ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "MAJ", "-", "719", "."], "add_tokens": "import com . vividsolutions . jts . geom . Coordinate ; // GeodeticCalculator calculator = new GeodeticCalculator(crs); // calculator.setStartingPosition(new DirectPosition2D(crs, mapBounds.getX(), mapBounds.getY())); // calculator.setDestinationPosition(new DirectPosition2D(crs, mapBounds.getMaxX(), mapBounds.getY())); // double distance = calculator.getOrthodromicDistance(); // return distance / mapBounds.getWidth(); Coordinate c1 = new Coordinate ( 0 , 0 ) ; Coordinate c2 = new Coordinate ( 1 , 0 ) ; double distance = JTS . orthodromicDistance ( c1 , c2 , crs ) ; return distance ;", "del_tokens": "import org . geotools . geometry . DirectPosition2D ; import org . geotools . referencing . GeodeticCalculator ; GeodeticCalculator calculator = new GeodeticCalculator ( crs ) ; calculator . setStartingPosition ( new DirectPosition2D ( crs , mapBounds . getX ( ) , mapBounds . getY ( ) ) ) ; calculator . setDestinationPosition ( new DirectPosition2D ( crs , mapBounds . getMaxX ( ) , mapBounds . getY ( ) ) ) ; double distance = calculator . getOrthodromicDistance ( ) ; return distance / mapBounds . getWidth ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "DynamicServerListLoadBalancer", ".", "updateListOfServers", "()", "public", "to", "provide", "alternative", "way", "to", "update", "servers", "at", "runtime", "instead", "of", "relying", "on", "scheduler", "."], "add_tokens": "public void updateListOfServers ( ) {", "del_tokens": "void updateListOfServers ( ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "some", "typo", "in", "Exception", "messages"], "add_tokens": "\"Separator contains illegal character(%s)\" , \"Left bracket contains illegal character(%s)\" , \"Right bracket contains illegal character(%s)\" ,", "del_tokens": "\"Separator contains illegal chracter(%s)\" , \"Left bracket contains illegal chracter(%s)\" , \"Right bracket contains illegal chracter(%s)\" ,", "commit_type": "fix"}
{"commit_tokens": ["update", "changes", "from", "refactored", "names"], "add_tokens": "static final String DEFAULT_TEMPLATE_RESOURCE = \"protobuf_json.vm\" ; } protected String _templateResource ; public ProtobufJSONGenerator ( ) { this ( DEFAULT_TEMPLATE_RESOURCE ) ; } public ProtobufJSONGenerator ( String templateResource ) { _templateResource = templateResource ; public String getTemplateResource ( ) { return _templateResource ; } _engine . mergeTemplate ( getTemplateResource ( ) , \"UTF-8\" , context , writer ) ;", "del_tokens": "static final String TEMPLATE_LOCATION = \"protobuf_json.vm\" ; protected String getTemplateLocation ( ) { return TEMPLATE_LOCATION ; } _engine . mergeTemplate ( getTemplateLocation ( ) , \"UTF-8\" , context , writer ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixing", "loop", "to", "read", "response", "as", "string", "according", "to", "comments", "on", "the", "PR"], "add_tokens": "String line ; while ( ( line = bufReader . readLine ( ) ) != null ) {", "del_tokens": "String line = bufReader . readLine ( ) ; while ( line != null ) { line = bufReader . readLine ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "new", "write", "callback", "APIs", "."], "add_tokens": "* Callback interface , providing methods notified after write syncing either succeeds or fails . * @ author Sergio Bossa public interface WriteCallback { / * * * Method called after successful write syncing . * * @ param syncedLocation * / void onSync ( Location syncedLocation ) ; / * * * Method called after failed write syncing . * * @ param location * @ param error * / void onError ( Location location , Throwable error ) ;", "del_tokens": "* Listener interface , notified at write syncing . * @ author < a href = \"http://hiramchirino.com\" > Hiram Chirino < / a > public interface JournalListener { public interface Write { Location getLocation ( ) ; } public void synced ( Write [ ] writes ) ;", "commit_type": "implement"}
{"commit_tokens": ["Remove", "the", "assumption", "that", "all", "instances", "of", "a", "given", "class", "have", "the", "same", "metaclass", "."], "add_tokens": "import groovy . lang . MetaClass ; * This class is the metaclass used for target < code > Closure < / code > s , any enclosed < code > Closures < / code > , * and the Gant script itself . / * * / public GantMetaClass ( final MetaClass metaClass , final Binding binding ) { super ( metaClass ) ; this . binding = binding ; } closure . setMetaClass ( new GantMetaClass ( closure . getMetaClass ( ) , binding ) ) ;", "del_tokens": "* This class is the metaclass used for target < code > Closure < / code > s . closure . setMetaClass ( new GantMetaClass ( closure . getClass ( ) , binding ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "unit", "test", "to", "TestDivDetails", "to", "check", "binding"], "add_tokens": "public Task ( String title , String description , Priority priority ) { } public Task ( String title , String description , Priority priority , Status status ) { this ( title , description , priority ) ;", "del_tokens": "public Task ( String title , String description , Priority priority , Status status ) {", "commit_type": "add"}
{"commit_tokens": ["make", "remove", "API", "protected", "still", "need", "debug"], "add_tokens": "protected void removeBy ( int position ) { protected void removeBy ( BaseCell data ) { protected void removeBatchBy ( int removeIdx ) { protected void removeBatchBy ( Card group ) {", "del_tokens": "public void removeBy ( int position ) { public void removeBy ( BaseCell data ) { public void removeBatchBy ( int removeIdx ) { public void removeBatchBy ( Card group ) {", "commit_type": "make"}
{"commit_tokens": ["Made", "the", "inner", "classes", "public", "because", "callers", "need", "access", "to", "them", "."], "add_tokens": "// $Id: CDDB.java,v 1.4 2000/12/06 00:26:23 mdb Exp $ public static class Entry public static class Detail public String discid ; public String category ; public String title ; public String [ ] trackNames ; public String extendedData ; public String [ ] extendedTrackData ; StringTokenizer tok = new StringTokenizer ( \"$Revision: 1.4 $\" ) ;", "del_tokens": "// $Id: CDDB.java,v 1.3 2000/10/23 07:37:43 mdb Exp $ public class Entry public class Detail String discid ; String category ; String title ; String [ ] trackNames ; String extendedData ; String [ ] extendedTrackData ; StringTokenizer tok = new StringTokenizer ( \"$Revision: 1.3 $\" ) ;", "commit_type": "make"}
{"commit_tokens": ["removed", "custom", "ReadWriteByteChannel", "interface", "-", "this", "already", "exists", "in", "the", "jdk", "as", "ByteChannel"], "add_tokens": "import java . nio . channels . ByteChannel ; private ByteChannel redirect ; public ByteChannel redirectChannel ( ) private class RedirectedChannel implements ByteChannel", "del_tokens": "import java . nio . channels . ReadableByteChannel ; import java . nio . channels . WritableByteChannel ; private ReadWriteByteChannel redirect ; public ReadWriteByteChannel redirectChannel ( ) private class RedirectedChannel implements ReadWriteByteChannel / * * * A composition of { @ link ReadableByteChannel } and { @ link WritableByteChannel } . * * @ author Gregory P . Moyer * / public interface ReadWriteByteChannel extends ReadableByteChannel , WritableByteChannel { / * * Composite interface * / }", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "sync", "method", "to", "return", "without", "exception", "on", "success", "."], "add_tokens": "return ; * rs = countMatchedFileHash . executeQuery ( ) ;", "del_tokens": "System . out . println ( hash + \" : \" + rs . getInt ( 1 ) ) ; * System . out . println ( countMatchedFileHash . toString ( ) . replace ( \",\" , * \"\\n\" ) ) ; rs = countMatchedFileHash . executeQuery ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["made", "changes", "in", "test", "to", "accomodate", "for", "delta", "value", "that", "may", "occur", "during", "its", "execution"], "add_tokens": "Assert . assertEquals ( 1000 * 60 * 60 * 24 * 3 , parse . get ( 0 ) . getRecurInterval ( ) , 1d ) ;", "del_tokens": "Assert . assertEquals ( 1000 * 60 * 60 * 24 * 3 , parse . get ( 0 ) . getRecurInterval ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "google", "plus", "one", "button", "to", "about", "dialog"], "add_tokens": "this ( context , ( PlusOneButton ) context . getView ( ) . findViewById ( plusOneButton ) ) ; } public PlusOneButtonConnector ( Fragment context , PlusOneButton plusOneButton ) { this . plusOneButton = plusOneButton ; protected void onPlusOne ( ) { protected void onUndoPlusOne ( ) { protected String getUrl ( ) {", "del_tokens": "this . plusOneButton = ( PlusOneButton ) context . getView ( ) . findViewById ( plusOneButton ) ; public void onPlusOne ( ) { public void onUndoPlusOne ( ) { public String getUrl ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "configurable", "Support", "for", "add", "endpoints", "of", "pods", "not", "still", "ready", "on", "kubernetes"], "add_tokens": "import static com . hazelcast . kubernetes . KubernetesProperties . RESOLVE_NOT_READY_ADDRESSES ; Boolean resolveNotReadyAddresses = getOrDefault ( properties , KUBERNETES_SYSTEM_PREFIX , RESOLVE_NOT_READY_ADDRESSES , false ) ; String apiToken = getOrDefault ( properties , KUBERNETES_SYSTEM_PREFIX , KUBERNETES_API_TOKEN , null ) ; + \"namespace: \" + namespace + \", \" + \"resolve-not-ready-addresses: \" + resolveNotReadyAddresses + \", \" + \"kubernetes-master: \" + kubernetesMaster + \"}\" ) ; endpointResolver = new ServiceEndpointResolver ( logger , serviceName , serviceLabel , serviceLabelValue , namespace , resolveNotReadyAddresses , kubernetesMaster , apiToken ) ;", "del_tokens": "String apiToken = getOrDefault ( properties , KUBERNETES_SYSTEM_PREFIX , KUBERNETES_API_TOKEN , null ) ; + \"namespace: \" + namespace + \", \" + \"kubernetes-master: \" + kubernetesMaster + \"}\" ) ; endpointResolver = new ServiceEndpointResolver ( logger , serviceName , serviceLabel , serviceLabelValue , namespace , kubernetesMaster , apiToken ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "public", "method", "to", "be", "package", "private", "to", "discourage", "usage", "outside", "of", "VerifyClient", "."], "add_tokens": "SearchResult [ ] search ( String ... requestIds ) throws IOException , NexmoClientException {", "del_tokens": "public SearchResult [ ] search ( String ... requestIds ) throws IOException , NexmoClientException {", "commit_type": "update"}
{"commit_tokens": ["changing", "interface", "to", "return", "MirrorList"], "add_tokens": "import net . vidageek . mirror . dsl . MirrorList ; public MirrorList < Annotation > annotations ( ) ;", "del_tokens": "public List < Annotation > annotations ( ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "mockito", "to", "test", "case", "event", "test"], "add_tokens": "return new Failure ( ) . withMessage ( ExceptionUtils . getMessage ( throwable ) ) . withStackTrace ( ExceptionUtils . getStackTrace ( throwable ) ) ;", "del_tokens": "Failure failure = new Failure ( ) ; failure . setMessage ( ExceptionUtils . getMessage ( throwable ) ) ; failure . setStackTrace ( ExceptionUtils . getStackTrace ( throwable ) ) ; return failure ;", "commit_type": "add"}
{"commit_tokens": ["Added", "role", "=", "form", "attribute", "to", "Forms"], "add_tokens": "import org . gwtbootstrap3 . client . ui . constants . Attributes ; getElement ( ) . setAttribute ( Attributes . ROLE , \"navigation\" ) ;", "del_tokens": "getElement ( ) . setAttribute ( \"role\" , \"navigation\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "problems", "David", "saw"], "add_tokens": "* Controls whether the version string is used as part of the Disqus identifier . * @ parameter expression = \"${generate-webhelp.use.version.for.disqus}\" default - value = \"0\" transformer . setParameter ( \"use.version.for.disqus\" , useVersionForDisqus ) ;", "del_tokens": "* Controls the branding of the output . * @ parameter expression = \"${generate-webhelp.branding}\" default - value = \"rackspace\" transformer . setParameter ( \"useVersionForDisqus\" , useVersionForDisqus ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "mind", "map", "panel", "listener", "and", "added", "cursor", "change", "for", "areas"], "add_tokens": "final int index = ( int ) ( ( x - this . bounds . getX ( ) ) / iconWidth ) ;", "del_tokens": "final int index = ( int ) Math . round ( y / iconWidth ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "constant", "so", "you", "can", "switch", "your", "idle", "stratetgy", "and", "made", "the", "default", "the", "backoff", "strategy"], "add_tokens": "import uk . co . real_logic . agrona . concurrent . BackoffIdleStrategy ; import uk . co . real_logic . agrona . concurrent . SleepingIdleStrategy ; import java . util . concurrent . TimeUnit ; public static final IdleStrategy SERVER_IDLE_STRATEGY ; static { String idlStrategy = System . getProperty ( \"idleStrategy\" ) ; if ( NoOpIdleStrategy . class . getName ( ) . equalsIgnoreCase ( idlStrategy ) ) { SERVER_IDLE_STRATEGY = new NoOpIdleStrategy ( ) ; } else if ( SleepingIdleStrategy . class . getName ( ) . equalsIgnoreCase ( idlStrategy ) ) { SERVER_IDLE_STRATEGY = new SleepingIdleStrategy ( TimeUnit . MILLISECONDS . toNanos ( 250 ) ) ; } else { SERVER_IDLE_STRATEGY = new BackoffIdleStrategy ( 1 , 10 , 100 , 1000 ) ; } }", "del_tokens": "public static final IdleStrategy SERVER_IDLE_STRATEGY = new NoOpIdleStrategy ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "functional", "collections", "in", "SuiteResults"], "add_tokens": "import fj . Ord ; import fj . data . TreeMap ; private final TreeMap < TestId , String > tests ; this ( false , TreeMap . < TestId , String > empty ( Ord . < TestId > comparableOrd ( ) ) ) ; public SuiteResults ( boolean finished , TreeMap < TestId , String > tests ) { this . tests = tests ; return new SuiteResults ( finished , tests . set ( id , name ) ) ;", "del_tokens": "import java . util . * ; private final Map < TestId , String > tests ; this ( false , new HashMap < TestId , String > ( ) ) ; public SuiteResults ( boolean finished , Map < TestId , String > tests ) { this . tests = new HashMap < TestId , String > ( tests ) ; // TODO: use functional collections Map < TestId , String > tests = new HashMap < TestId , String > ( this . tests ) ; tests . put ( id , name ) ; return new SuiteResults ( finished , tests ) ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "endTime", "to", "getTicketsIncrementally", "."], "add_tokens": "public Iterable < Ticket > getTicketsIncrementally ( Date startTime ) { tmpl ( \"/incremental/tickets.json{?start_time}\" ) . set ( \"start_time\" , ( int ) ( startTime . getTime ( ) / 1000 ) ) , handleList ( Ticket . class , \"tickets\" ) ) ; } public Iterable < Ticket > getTicketsIncrementally ( Date startTime , Date endTime ) { return new PagedIterable < Ticket > ( tmpl ( \"/incremental/tickets.json{?start_time,end_time}\" ) . set ( \"start_time\" , ( int ) ( startTime . getTime ( ) / 1000 ) ) . set ( \"end_time\" , ( int ) ( endTime . getTime ( ) / 1000 ) ) ,", "del_tokens": "public Iterable < Ticket > getTicketsIncrementally ( Date fromDate ) { tmpl ( \"/incremental/tickets.json{?start_time}\" ) . set ( \"start_time\" , ( int ) ( fromDate . getTime ( ) / 1000 ) ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "a", "listener", "to", "give", "access", "to", "process"], "add_tokens": "private final ProcessStartListener startListener ; ProcessExitListener exitListener , ProcessStartListener startListener ) { this . startListener = startListener ; Process process = processBuilder . start ( ) ; if ( startListener != null ) { startListener . start ( process ) ; }", "del_tokens": "private Process process ; ProcessExitListener exitListener ) { synchronized ( this ) { // check if the previous process is still executing if ( process != null ) { // will throw IllegalThreadStateException, if process is still running process . exitValue ( ) ; } process = processBuilder . start ( ) ; } / * * * The process that is currently executing or was the last one to be started using the run * method . * / public Process getProcess ( ) { return this . process ; }", "commit_type": "add"}
{"commit_tokens": ["fixing", "problems", "with", "wrong", "content", "leangth"], "add_tokens": "import java . io . UnsupportedEncodingException ; try { this . responseLength = response . getBytes ( \"UTF-8\" ) . length ; } catch ( UnsupportedEncodingException e ) { this . responseLength = response . length ( ) ; }", "del_tokens": "this . responseLength = response . length ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "template", "method", "AbstractManifestServlet", ".", "handleUnmatchedRequest", "to"], "add_tokens": "else if ( ! handleUnmatchedRequest ( request , response , moduleName , baseUrl , computedBindings ) ) / * * * Sub - classes can override this method to perform handle the inability to find a matching permutation . In which * case the method should return true if the response has been handled . * / protected boolean handleUnmatchedRequest ( final HttpServletRequest request , final HttpServletResponse response , final String moduleName , final String baseUrl , final List < BindingProperty > computedBindings ) throws ServletException , IOException { return false ; }", "del_tokens": "else", "commit_type": "add"}
{"commit_tokens": ["Added", "required", "=", "false", "to", "configurers"], "add_tokens": "@ Autowired ( required = false )", "del_tokens": "@ Autowired", "commit_type": "add"}
{"commit_tokens": ["removed", "jdk", "-", "9", "flag", "from", "test"], "add_tokens": "private final String className ;", "del_tokens": "private String className ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "the", "Javadoc", "comments", "a", "bit", "."], "add_tokens": "* The name of the file to use to drive the build , default is build . gant . * @ param file The name of the file to be used to drive the build . * Set the target to be achieved . * @ param target The target to achieve .", "del_tokens": "* Gantfile to load , default is build . gant . * @ param file The Gantfile . * Set the target to be run . * @ param target The target .", "commit_type": "update"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "::", "combination"], "add_tokens": "} else if ( i != 0 && counter [ i - 1 ] != list . size ( ) - ( counter . length - i + 1 ) ) {", "del_tokens": "} else if ( i != 0 && counter [ i - 1 ] != list . size ( ) - ( counter . length - i ) ) {", "commit_type": "add"}
{"commit_tokens": ["removed", "setUndecorated", "(", "false", ")", "from", "QuickSearchDialog"], "add_tokens": "getDialog ( ) . setTitle ( \"Quick search\" ) ;", "del_tokens": "getDialog ( ) . setUndecorated ( true ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "rounding", "tolerance", "to", "50%"], "add_tokens": "private int roundingTolerance = 50 ; if ( threshold > roundingTolerance )", "del_tokens": "private int roundingTolerance = 0 ; if ( threshold < roundingTolerance )", "commit_type": "fix"}
{"commit_tokens": ["Made", "JaversContainer", "construct", "singletons", "."], "add_tokens": "import org . picocontainer . behaviors . Caching ; DefaultPicoContainer javersContainer = new DefaultPicoContainer ( new Caching ( ) ) ;", "del_tokens": "DefaultPicoContainer javersContainer = new DefaultPicoContainer ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "SplitSampler", ":", "it", "s", "somewhat", "better", "."], "add_tokens": "new InputSampler . SplitSampler < LongWritable , Range > ( 1 << 16 , 10 ) ;", "del_tokens": "new InputSampler . IntervalSampler < LongWritable , Range > ( 0.01 , 100 ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "the", "mask", "of", "the", "background"], "add_tokens": "if ( y < minY || y > maxY ) { if ( x < minX || x > maxX || collisionRaster . isTransparent ( x , y ) ) {", "del_tokens": "if ( y > maxY ) { if ( x > maxX || collisionRaster . isTransparent ( x , y ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "personalized", "send", "time", "support", "to", "send", "API"], "add_tokens": "protected Object schedule_time ; public Send setScheduleTime ( Map < String , Object > scheduleTime ) { this . schedule_time = ( Object ) scheduleTime ; return this ; } public Send setScheduleTime ( Object startTime , Object endTime , String method ) { Map < String , Object > scheduleTime = new HashMap < String , Object > ( ) ; if ( startTime instanceof String || startTime instanceof Number ) { scheduleTime . put ( \"start_time\" , startTime ) ; } if ( endTime instanceof String || endTime instanceof Number ) { scheduleTime . put ( \"end_time\" , endTime ) ; } scheduleTime . put ( \"method\" , method ) ; this . schedule_time = ( Object ) scheduleTime ; return this ; } public Send setScheduleTime ( Object startTime , Object endTime ) { Map < String , Object > scheduleTime = new HashMap < String , Object > ( ) ; if ( startTime instanceof String || startTime instanceof Number ) { scheduleTime . put ( \"start_time\" , startTime ) ; } if ( endTime instanceof String || endTime instanceof Number ) { scheduleTime . put ( \"end_time\" , endTime ) ; } this . schedule_time = ( Object ) scheduleTime ; return this ; }", "del_tokens": "protected String schedule_time ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "minor", "bug", "in", "hasSearchRequest", "and", "adding", "unit", "test"], "add_tokens": "|| getLabel2 ( ) != null && getLabel2 ( ) . size ( ) > 0 || getStatus ( ) != null && getStatus ( ) . size ( ) > 0 ;", "del_tokens": "|| getLabel2 ( ) != null && getLabel2 ( ) . size ( ) > 0 || getStatus ( ) != null ;", "commit_type": "fix"}
{"commit_tokens": ["added", "int8", "[]", "and", "int8", "[]", "s", "into", "BINFILE", "function"], "add_tokens": "UINT8_SPLITTED ( \"uint8[]s\" ) , INT8 ( \"int8[]\" ) , INT8_SPLITTED ( \"int8[]s\" ) ; case INT8 : { result = convertToINT8 ( theFile , - 1 , endOfLine ) ; } break ; case INT8_SPLITTED : { result = convertToINT8 ( theFile , 80 , endOfLine ) ; } break ; @ Nonnull private String convertToINT8 ( @ Nonnull final File file , final int lineLength , @ Nonnull final String endOfLine ) throws IOException { final StringBuilder result = new StringBuilder ( 512 ) ; final byte [ ] array = FileUtils . readFileToByteArray ( file ) ; int endLinePos = lineLength ; boolean addNextLine = false ; for ( final byte b : array ) { if ( addNextLine ) { addNextLine = false ; result . append ( endOfLine ) ; } if ( result . length ( ) > 0 ) { result . append ( ',' ) ; } result . append ( Integer . toString ( b ) ) ; if ( lineLength > 0 && result . length ( ) >= endLinePos ) { addNextLine = true ; endLinePos = result . length ( ) + lineLength ; } } return result . toString ( ) ; }", "del_tokens": "UINT8_SPLITTED ( \"uint8[]s\" ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "mdm", "messages"], "add_tokens": "public PayloadBuilder mdm ( String s ) { return customField ( \"mdm\" , s ) ; } if ( ! root . containsKey ( \"mdm\" ) ) { if ( ! ( customAlert . isEmpty ( ) || customAlert . equals ( aps . get ( \"alert\" ) ) ) ) { if ( aps . containsKey ( \"alert\" ) ) { String alertBody = ( String ) aps . get ( \"alert\" ) ; customAlert . put ( \"body\" , alertBody ) ; } aps . put ( \"alert\" , customAlert ) ; root . put ( \"aps\" , aps ) ;", "del_tokens": "if ( ! ( customAlert . isEmpty ( ) || customAlert . equals ( aps . get ( \"alert\" ) ) ) ) { if ( aps . containsKey ( \"alert\" ) ) { String alertBody = ( String ) aps . get ( \"alert\" ) ; customAlert . put ( \"body\" , alertBody ) ; aps . put ( \"alert\" , customAlert ) ; root . put ( \"aps\" , aps ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "misspelling", "of", "insertOutput", "."], "add_tokens": "if ( insertOutput ( charrefbuf , charrefbuf . length , \"US-ASCII\" . getBytes ( ) ) == - 1 ) return - 1 ; public int insertOutput ( byte [ ] str , int strLen , byte [ ] strEncoding ) { if ( insertOutput ( replacementString , replacementLength , replacementEncoding ) == - 1 ) return - 1 ;", "del_tokens": "if ( insertOuput ( charrefbuf , charrefbuf . length , \"US-ASCII\" . getBytes ( ) ) == - 1 ) return - 1 ; int insertOuput ( byte [ ] str , int strLen , byte [ ] strEncoding ) { if ( insertOuput ( replacementString , replacementLength , replacementEncoding ) == - 1 ) return - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "the", "various", "Progress", "members", "public", "and", "fixed", "a", "build", "error", "(", "due", "to", "a", "bad", "merge", ")", "."], "add_tokens": "public long frame = 0 ; public Fraction fps = Fraction . ZERO ; public long bitrate = 0 ; public long total_size = 0 ; public long out_time_ms = 0 ; public long dup_frames = 0 ; public long drop_frames = 0 ; public float speed = 0 ; public String progress = \"\" ; }", "del_tokens": "long frame = 0 ; Fraction fps = Fraction . ZERO ; long bitrate = 0 ; long total_size = 0 ; long out_time_ms = 0 ; long dup_frames = 0 ; long drop_frames = 0 ; float speed = 0 ; String progress = \"\" ; @ Override public String toString ( ) { return MoreObjects . toStringHelper ( this ) // @formatter:off . add ( \"frame\" , frame ) . add ( \"fps\" , fps ) . add ( \"bitrate\" , bitrate ) . add ( \"total_size\" , total_size ) . add ( \"out_time_ms\" , out_time_ms ) . add ( \"dup_frames\" , dup_frames ) . add ( \"drop_frames\" , drop_frames ) . add ( \"speed\" , speed ) . add ( \"progress\" , progress ) // @formatter:on . toString ( ) ; }", "commit_type": "make"}
{"commit_tokens": ["Improve", "code", "for", "MQTT", "test"], "add_tokens": "import org . mockito . InOrder ; * Test class AMQP ( low level ) message receiving public void LinkerImporterCreated ( ) { assertThat ( linkerInstance . getState ( ) ) . isEqualTo ( ComponentInstance . VALID ) ; public void ImporterCreated ( ) { assertThat ( importerInstance . getState ( ) ) . isEqualTo ( ComponentInstance . VALID ) ; final String queue = \"public\" ; handlerProperties . put ( EventConstants . EVENT_TOPIC , queue ) ; metadata . put ( \"mqtt.queue\" , queue ) ; final String queue = \"public\" ; handlerProperties . put ( EventConstants . EVENT_TOPIC , queue ) ; metadata . put ( \"mqtt.queue\" , queue ) ;", "del_tokens": "* Test class MQTT //@RunWith(PaxExam.class) //@ExamReactorStrategy(PerMethod.class) public void testLinkerImporterCreated ( ) { public void testImporterCreated ( ) { handlerProperties . put ( EventConstants . EVENT_TOPIC , \"public\" ) ; metadata . put ( \"mqtt.queue\" , \"public\" ) ; handlerProperties . put ( EventConstants . EVENT_TOPIC , \"public\" ) ; metadata . put ( \"mqtt.queue\" , \"public\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Updated", "the", "version", "of", "authlete", "-", "java", "-", "common", "and", "implemented", "deleteGrantedScopes", "(", "long", "String", ")", "method", "of", "AuthleteApi", "interface", "."], "add_tokens": "import com . authlete . common . dto . ApiResponse ; private static final String GRANTED_SCOPES_DELETE_API_PATH = \"/api/client/granted_scopes/delete/%d\" ; GrantedScopesRequest request = new GrantedScopesRequest ( subject ) ; @ Override public void deleteGrantedScopes ( long clientId , String subject ) { // Prepare a request body. GrantedScopesRequest request = new GrantedScopesRequest ( subject ) ; executeApiCall ( new ServicePostApiCaller < ApiResponse > ( ApiResponse . class , request , GRANTED_SCOPES_DELETE_API_PATH , clientId ) ) ; } private static final class GrantedScopesRequest public GrantedScopesRequest ( String subject )", "del_tokens": "GrantedScopesGetRequest request = new GrantedScopesGetRequest ( subject ) ; private static final class GrantedScopesGetRequest public GrantedScopesGetRequest ( String subject )", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "few", "change", "listeners", "to", "the", "job", "builder"], "add_tokens": "public class AbstractBeanJobBuilder < D extends BeanDescriptor < E > , E , B > {", "del_tokens": "class AbstractBeanJobBuilder < D extends BeanDescriptor < E > , E , B > {", "commit_type": "add"}
{"commit_tokens": ["Fix", "OnTouchListener", "not", "being", "called", "."], "add_tokens": "if ( state == REFRESHING && disableScrollingWhileRefreshing ) { return true ; } else if ( onAdapterViewTouch ( view , ev ) ) { return true ; if ( null != onTouchListener ) { return onTouchListener . onTouch ( view , ev ) ; }", "del_tokens": "if ( state == REFRESHING ) { return disableScrollingWhileRefreshing ; } else { return onAdapterViewTouch ( view , ev ) ; if ( null != onTouchListener ) { return onTouchListener . onTouch ( view , event ) ; }", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "method", "in", "RestCanvasMessenger", "to", "use", "sendJsonPost", "in", "the", "Rest", "Client"], "add_tokens": "import com . google . gson . FieldNamingPolicy ; import com . google . gson . Gson ; import com . google . gson . GsonBuilder ; public Optional < Quiz > updateQuiz ( String oauthToken , Quiz quiz , String courseId ) throws MessageUndeliverableException , IOException , OauthTokenRequiredException { String url = CanvasURLBuilder . buildCanvasUrl ( canvasBaseUrl , apiVersion , \"courses/\" + courseId + \"/quizzes/\" + quiz . getId ( ) , Collections . emptyMap ( ) ) ; Response response = canvasMessenger . sendToJsonCanvas ( oauthToken , url , getDefaultGsonParser ( ) . toJsonTree ( quiz ) . getAsJsonObject ( ) ) ; return responseParser . parseToObject ( Quiz . class , response ) ;", "del_tokens": "import java . io . UnsupportedEncodingException ; public Optional < Quiz > updateQuiz ( String oauthToken , String courseId , Quiz quiz ) throws MessageUndeliverableException , UnsupportedEncodingException , OauthTokenRequiredException { return null ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "to", "make", "them", "pass", "on", "non", "-", "Unix", "too", "."], "add_tokens": "private static final String LS = System . getProperty ( \"line.separator\" ) ; assertThat ( sysOutContent , is ( \"{ }\" + LS ) ) ;", "del_tokens": "assertThat ( sysOutContent , is ( \"{ }\\n\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "worker", "scheduler", "conf", "to", "the", "custom", "schema"], "add_tokens": "public void baseEngineTest ( ) throws InterruptedException { // Thread.currentThread().join();", "del_tokens": "public void baseEngineTest ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "remote", "vine", "deploy", "timeout", "test", "."], "add_tokens": "if ( eventBus != null ) { eventBus . setVertx ( vertx ) ; } eventBus = new WrappedReliableEventBus ( eventBus , vertx ) ;", "del_tokens": "eventBus = new WrappedReliableEventBus ( eventBus ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "flush", "file", "buffer", ".", "Built", "native", "libraries"], "add_tokens": "public static native void msync ( int fd , long address , long size ) ;", "del_tokens": "public static native void msync ( long address , long size ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "CdTest", "tests", "a", "bit", "more"], "add_tokens": "import org . jboss . aesh . console . Config ; import static org . junit . Assert . assertEquals ; if ( Config . isOSPOSIXCompatible ( ) ) { pushToOutput ( \"cd /tmp\" ) ; assertEquals ( \"/tmp\" , getAeshContext ( ) . getCurrentWorkingDirectory ( ) . getAbsolutePath ( ) ) ; pushToOutput ( \"cd /var/log\" ) ; assertEquals ( \"/var/log\" , getAeshContext ( ) . getCurrentWorkingDirectory ( ) . getAbsolutePath ( ) ) ; pushToOutput ( \"cd ..\" ) ; assertEquals ( \"/var\" , getAeshContext ( ) . getCurrentWorkingDirectory ( ) . getAbsolutePath ( ) ) ; pushToOutput ( \"cd ..\" ) ; assertEquals ( \"/\" , getAeshContext ( ) . getCurrentWorkingDirectory ( ) . getAbsolutePath ( ) ) ; pushToOutput ( \"cd ..\" ) ; assertEquals ( \"/\" , getAeshContext ( ) . getCurrentWorkingDirectory ( ) . getAbsolutePath ( ) ) ; }", "del_tokens": "pushToOutput ( \"cd /tmp\" ) ; pushToOutput ( \"ls\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "path", "handling", "to", "search", "for", "morphotagger", "model"], "add_tokens": "// FIXME - nepamatoti paaujamies ka tur tds modelis bs try { initClassifier ( \"../LVTagger/models/lv-morpho-model.ser.gz\" ) ; } catch ( java . io . FileNotFoundException e ) { initClassifier ( \"../../LVTagger/models/lv-morpho-model.ser.gz\" ) ; }", "del_tokens": "initClassifier ( \"../LVTagger/models/lv-morpho-model.ser.gz\" ) ; // FIXME - nepamatoti paaujamies ka tur tds modelis bs", "commit_type": "change"}
{"commit_tokens": ["Added", "no", "allocation", "static", "method", "for", "DenseVector", "consturction", "for", "those", "who", "are", "not", "in", "the", "same", "package"], "add_tokens": "import jsat . math . Function ; public Vec subtract ( double c ) { return add ( - c ) ; } public void mutableSubtract ( double c ) { mutableAdd ( - c ) ; } public void applyFunction ( Function f ) { for ( int i = 0 ; i < length ( ) ; i ++ ) set ( i , f . f ( get ( i ) ) ) ; }", "del_tokens": "abstract public Vec subtract ( double c ) ; abstract public void mutableSubtract ( double c ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "queue", "to", "list", "for", "immutability"], "add_tokens": "private List < MockDefinition > endpointOrdering ; public List < MockDefinition > getEndpointOrdering ( ) { return Collections . unmodifiableList ( endpointOrdering ) ; private List < String > endpointOrdering = new ArrayList < > ( ) ;", "del_tokens": "import nz . ac . auckland . integration . testing . endpointoverride . CxfEndpointOverride ; import nz . ac . auckland . integration . testing . endpointoverride . UrlConnectionOverride ; private Queue < MockDefinition > endpointOrdering ; public Queue < MockDefinition > getEndpointOrdering ( ) { return endpointOrdering ; private Queue < String > endpointOrdering = new LinkedList < > ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Moved", "the", "event", "Queue", "from", "EventMonitor", "to", "DomainEvents", "enabling", "later", "implementation", "of", "multiple", "EventMonitorThreads", "watching", "the", "same", "queue", "."], "add_tokens": "import java . util . Queue ; import java . util . concurrent . ConcurrentLinkedQueue ; private Queue < DomainEvent > eventQueue = new ConcurrentLinkedQueue < DomainEvent > ( ) ; this . eventMonitor = new EventMonitor ( eventQueue ) ;", "del_tokens": "this . eventMonitor = new EventMonitor ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "the", "visibility", "of", "CircuitBreakerUtils", ".", "isCallPermitted", "to", "public"], "add_tokens": "public static void isCallPermitted ( CircuitBreaker circuitBreaker ) {", "del_tokens": "static void isCallPermitted ( CircuitBreaker circuitBreaker ) {", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "single", "method", "encapsulating", "all", "of", "FSA", "-", "CFSA", "conversion", "."], "add_tokens": "import java . io . InputStream ; protected void doLabelMapping ( ) { protected int updateOffsets ( ) { protected void serialize ( OutputStream os ) throws IOException { / * * * Convert FSA to CFSA . * / public static void convert ( InputStream fsa , OutputStream cfsa ) throws IOException { final String ignored = \"iso8859-1\" ; final CFSAEncoder encoder = new CFSAEncoder ( FSA . getInstance ( fsa , ignored ) ) ; encoder . doLabelMapping ( ) ; encoder . updateOffsets ( ) ; encoder . serialize ( cfsa ) ; }", "del_tokens": "public void doLabelMapping ( ) { public int updateOffsets ( ) { public void serialize ( OutputStream os ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Added", "javadocs", "and", "HIDDEN_STATION", "."], "add_tokens": "boolean add ( Class < ? > eventClass , Listener < ? > listener , int priority , ReferenceStrength strength ) { boolean remove ( Class < ? > eventClass , ListenerWrapper listener ) {", "del_tokens": "import org . eventstudio . exception . EventStudioException ; import org . eventstudio . util . ReflectionUtils ; boolean add ( Listener < ? > listener , int priority , ReferenceStrength strength ) { Class < ? > eventClass = ReflectionUtils . inferParameterClass ( listener . getClass ( ) , \"onEvent\" ) ; if ( eventClass == null ) { throw new EventStudioException ( \"Unable to infer the listened event class.\" ) ; } boolean unregister ( Class < ? > eventClass , ListenerWrapper listener ) {", "commit_type": "add"}
{"commit_tokens": ["change", "semaphore", "to", "prevent", "String", ".", "intern", "risk", "reorder", "core", "plugin", "registration", "after", "changing", "CorePlugin", ".", "equals", "behavior", "fix", "Testing", "Methods"], "add_tokens": "private static Object semaphore = new Object ( ) ; if ( INSTANCE != null ) { INSTANCE . getCorePlugin ( ) . destroy ( ) ; } KeyHandler keyHandler = new DefaultKeyEscaper ( ) ; CorePlugin corePlugin = new CorePlugin ( null , keyHandler ) ; INSTANCE = new InApplicationMonitor ( corePlugin , keyHandler ) ; LOGGER . info ( \"Reset InApplicationMonitor for Testing.\" ) ; INSTANCE . plugins . remove ( previousCorePlugin ) ;", "del_tokens": "private static String semaphore = \"semaphore\" ; KeyHandler keyHandler = new DefaultKeyEscaper ( ) ; CorePlugin corePlugin = new CorePlugin ( null , keyHandler ) ; INSTANCE = new InApplicationMonitor ( corePlugin , keyHandler ) ; LOGGER . info ( \"Reset InApplicationMonitor for Testing.\" ) ; //both core plugins currently have the same name, and name is used for equals, thus first remove than add. INSTANCE . plugins . remove ( previousCorePlugin ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "unit", "tests", "for", "PersistentVector", "(", "up", "to", "80%", ")", "and", "fixed", "some", "bugs", "with", "listIterator", "."], "add_tokens": "Replace the item at the given index . Note : i . put ( i . size ( ) , o ) is equivalent to i . append ( o ) . @ return a new ImList with the replaced item", "del_tokens": "Replace the item at the given index @ return a new ImList with the additional item at the end .", "commit_type": "add"}
{"commit_tokens": ["Fixing", "some", "bugs", "in", "routing", "and", "location", "formatting", "and", "adding", "some", "convenience", "methods", "to", "Respond", "wrapper", "."], "add_tokens": "if ( to == null ) { this . to = \"/\" ; } else if ( to . endsWith ( \"/\" ) ) { this . to = to ; } else { this . to = to + \"/\" ; }", "del_tokens": "this . to = to . endsWith ( \"/\" ) ? to : to + \"/\" ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "createVolume", "request", "to", "use", "all", "available", "disk", "offerings"], "add_tokens": "/ * params = new Param [ ] { } ; * / throw new CloudException ( \"A suitable snapshot or disk offering could not be found to pass to CloudStack createVolume request\" ) ; if ( p != null && ( ! provider . getServiceProvider ( ) . equals ( CSServiceProvider . DEMOCLOUD ) || \"local\" . equals ( offering . type ) ) ) { list . add ( p ) ;", "del_tokens": "params = new Param [ ] { } ; if ( p != null ) { if ( ! provider . getServiceProvider ( ) . equals ( CSServiceProvider . DEMOCLOUD ) && ! provider . getVersion ( ) . greaterThan ( CSVersion . CS3 ) ) { list . add ( p ) ; } else if ( \"local\" . equals ( offering . type ) ) { list . add ( p ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "data", "provider", "so", "tests", "are", "running", "again"], "add_tokens": "import java . util . Collections ; Collections . reverse ( elements ) ; return new EliminationStack < > ( elements ) ;", "del_tokens": "import com . google . common . collect . Lists ; return new EliminationStack < > ( Lists . reverse ( elements ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "scheduling", "service", "to", "call", "internal", "version", "of", "getResourceStatus", ";", "create", "exception", "at", "the", "place", "of", "throwing"], "add_tokens": "private final String usingSchedSvcMesg = \"Invalid call when using task scheduling service\" ; throw new IllegalStateException ( usingSchedSvcMesg ) ; throw new IllegalStateException ( usingSchedSvcMesg ) ; throw new IllegalStateException ( usingSchedSvcMesg ) ; throw new IllegalStateException ( usingSchedSvcMesg ) ;", "del_tokens": "private final IllegalStateException usingSchedSvcExcetption = new IllegalStateException ( \"Invalid call when using task scheduling service\" ) ; throw usingSchedSvcExcetption ; throw usingSchedSvcExcetption ; throw usingSchedSvcExcetption ; throw usingSchedSvcExcetption ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "null", "pointer", "case", "."], "add_tokens": "if ( packet . getTo ( ) == null ) { return false ; } else { return packet . getTo ( ) . indexOf ( to ) != - 1 ; }", "del_tokens": "return packet . getTo ( ) . indexOf ( to ) != - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Changing", "!isBlank", "(", "s", ")", "to", "isNotBlank", "(", "s", ")"], "add_tokens": "while ( StringUtils . isNotBlank ( url ) ) {", "del_tokens": "while ( ! StringUtils . isBlank ( url ) ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "issue", "with", "text", "insertion", "on", "some", "keyboards"], "add_tokens": "// // More details: https://github.com/linkedin/Spyglass/issues/105#issuecomment-674751603 int prevStart = start - tbend - 1 ; int prevEnd = start - 1 ; String prevString = subSequence ( prevStart , prevEnd ) . toString ( ) ; MentionSpan [ ] prevSpans = getSpans ( prevStart , prevEnd , MentionSpan . class ) ; // If the insert string matches the previous string and the previous string contains a mention, then // we will just delete the previous character instead of appending the word. if ( insertString . equals ( prevString ) && prevSpans . length > 0 ) {", "del_tokens": "String previousString = subSequence ( start - tbend - 1 , start - 1 ) . toString ( ) ; if ( insertString . equals ( previousString ) ) { // Delete a character", "commit_type": "fix"}
{"commit_tokens": ["Moved", "to", "JTidy", "based", "testing", "first", "3", "tests", "completed"], "add_tokens": "import org . testng . annotations . BeforeClass ; import org . w3c . tidy . Tidy ; import java . io . Reader ; import java . io . StringReader ; import java . io . StringWriter ; import java . io . Writer ; private final Tidy tidy = new Tidy ( ) ; @ BeforeClass public void setup ( ) { tidy . setPrintBodyOnly ( true ) ; tidy . setShowWarnings ( false ) ; tidy . setQuiet ( true ) ; } assertEqualsMultiline ( toHtml , FileUtils . readAllTextFromResource ( testName + \".pretty.html\" ) ) ; // tidy up html for fair equality test toHtml = tidy ( toHtml ) ; String expected = tidy ( FileUtils . readAllTextFromResource ( testName + \".html\" ) ) ; private String tidy ( String html ) { Reader in = new StringReader ( html ) ; Writer out = new StringWriter ( ) ; tidy . parse ( in , out ) ; return out . toString ( ) ; }", "del_tokens": "String expected = FileUtils . readAllTextFromResource ( testName + \".html\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "the", "functionality", "to", "load", "list", "items", "from", "an", "array", "resource", "."], "add_tokens": "this . setItems ( context . getResources ( ) . getTextArray ( resourceId ) , listener ) ;", "del_tokens": "listAdapter = new ArrayAdapter < CharSequence > ( context , resourceId ) ; listViewClickListener = listener ;", "commit_type": "fix"}
{"commit_tokens": ["making", "ClientStarter", "mockable", "and", "testable"], "add_tokens": "import javax . inject . Inject ; import org . glassfish . jersey . client . JerseyClientBuilder ; import com . google . common . annotations . VisibleForTesting ; private final JerseyClientBuilder jerseyClientBuilder ; public ClientStarter ( ) { super ( ) ; jerseyClientBuilder = new JerseyClientBuilder ( ) ; } @ VisibleForTesting @ Inject ClientStarter ( @ NonNull JerseyClientBuilder jerseyClientBuilder ) { super ( ) ; this . jerseyClientBuilder = jerseyClientBuilder ; } public < RootResponse > Response < RootResponse > create ( @ NonNull String url , @ NonNull Class < RootResponse > clazz ) { Client newClient = jerseyClientBuilder . build ( ) ;", "del_tokens": "import javax . ws . rs . client . ClientBuilder ; public static < RootResponse > Response < RootResponse > create ( @ NonNull String url , @ NonNull Class < RootResponse > clazz ) { Client newClient = ClientBuilder . newClient ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "LIVETRIBE", "-", "58", ":", "allow", "ServiceAgentClient", "to", "connect", "to", "a", "configurable", "address", "."], "add_tokens": "private String connectAddress = Defaults . get ( SA_CLIENT_CONNECT_ADDRESS ) ; if ( settings . containsKey ( SA_CLIENT_CONNECT_ADDRESS ) ) setConnectAddress ( settings . get ( SA_CLIENT_CONNECT_ADDRESS ) ) ; / * * * Sets the IP address to which this client connects to * * @ param connectAddress the new connect address * / public void setConnectAddress ( String connectAddress ) { this . connectAddress = connectAddress ; } InetSocketAddress remoteAddress = new InetSocketAddress ( NetUtils . getByName ( connectAddress ) , port ) ; InetSocketAddress remoteAddress = new InetSocketAddress ( NetUtils . getByName ( connectAddress ) , port ) ;", "del_tokens": "InetSocketAddress remoteAddress = new InetSocketAddress ( NetUtils . getLoopbackAddress ( ) , port ) ; InetSocketAddress remoteAddress = new InetSocketAddress ( NetUtils . getLoopbackAddress ( ) , port ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "way", "StreamingContext", "finds", "and", "reads", "checkpoint", "files", "and", "added", "JavaStreamingContext", ".", "getOrCreate", "."], "add_tokens": "System . err . println ( \"Usage: JavaNetworkWordCount <master> <hostname> <port>\\n\" + JavaStreamingContext ssc = new JavaStreamingContext ( args [ 0 ] , \"JavaNetworkWordCount\" , // words in input stream of \\n delimited text (eg. generated by 'nc')", "del_tokens": "System . err . println ( \"Usage: NetworkWordCount <master> <hostname> <port>\\n\" + JavaStreamingContext ssc = new JavaStreamingContext ( args [ 0 ] , \"NetworkWordCount\" , // words in input stream of \\n delimited test (eg. generated by 'nc')", "commit_type": "change"}
{"commit_tokens": ["Fix", "query", "so", "that", "all", "predicates", "affect", "the", "output"], "add_tokens": "List < Tuple > expected = computeExpected ( \"SELECT COUNT(*) FROM lineitem WHERE tax < discount AND tax > 0.01 AND discount < 0.05\" , FIXED_INT_64 ) ; return input . getDouble ( 0 ) < 0.05 ;", "del_tokens": "List < Tuple > expected = computeExpected ( \"SELECT COUNT(*) FROM lineitem WHERE tax < discount AND tax > 0.01 AND discount < 10.0\" , FIXED_INT_64 ) ; return input . getDouble ( 0 ) < 10.0 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "cases", "for", "query", ".", "algebra"], "add_tokens": "import org . vanilladb . core . query . algebra . BasicQueryTest ; import org . vanilladb . core . query . algebra . index . MultiKeyIndexTest ; // query.parse ParserTest . class , // query.algebra BasicQueryTest . class , MultiKeyIndexTest . class ,", "del_tokens": "// query.parse ParserTest . class ,", "commit_type": "add"}
{"commit_tokens": ["changed", "hashCode", "and", "equals", "of", "PaySetting"], "add_tokens": "return ! ( appId != null ? ! appId . equals ( that . appId ) : that . appId != null ) ; result = 31 * result + ( appId != null ? appId . hashCode ( ) : 0 ) ;", "del_tokens": "return appId . equals ( that . appId ) ; result = 31 * result + appId . hashCode ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Make", "PowerShellNotAvailableException", "an", "optional", "non", "-", "checked", "exception"], "add_tokens": "public class PowerShellNotAvailableException extends RuntimeException {", "del_tokens": "import java . io . IOException ; public class PowerShellNotAvailableException extends IOException { private static final long serialVersionUID = 8387251378765251753L ;", "commit_type": "make"}
{"commit_tokens": ["Added", "format", "util", "in", "U", "."], "add_tokens": "sb . append ( format ( itemFormat , items [ i ] ) ) ; sb . append ( format ( itemFormat , item ) ) ; String data = format ( \"%s: %s in %s ms (%s/sec)\" , name , count , ms , avgs ) ; return format ( msg , totalMem / megs , usedMem / megs , maxMem / megs , gcinfo ) ; public static String format ( String s , Object ... args ) { return String . format ( s , args ) ; }", "del_tokens": "sb . append ( String . format ( itemFormat , items [ i ] ) ) ; sb . append ( String . format ( itemFormat , item ) ) ; String data = String . format ( \"%s: %s in %s ms (%s/sec)\" , name , count , ms , avgs ) ; return String . format ( msg , totalMem / megs , usedMem / megs , maxMem / megs , gcinfo ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "with", "parsing", "lists", "and", "strings", "<", "55", "bytes"], "add_tokens": "if ( noOfBytes > 0 ) { bb . get ( rawData ) ; } noOfBytes = byteBuffer . get ( ) & 0xFF ; result += byteBuffer . get ( ) & 0xFF ; long payloadSize = - 1 ; int offsetSmallList = 0xc0 & 0xff ; payloadSize = ( long ) ( firstByteUnsigned ) - offsetSmallList ; if ( indicator . length == 2 ) { // byte payloadSize = byteBuffer . get ( ) & 0xFF ; } else if ( indicator . length == 3 ) { // short } else if ( indicator . length == 5 ) { // int } else if ( indicator . length == 9 ) { // long } else { LOG . error ( \"Invalid indicator\" ) ; } else { LOG . error ( \"Invalid RLP encoded list detected\" ) ;", "del_tokens": "bb . get ( rawData ) ; noOfBytes = byteBuffer . get ( ) ; result += byteBuffer . get ( ) ; long payloadSize = 0 ; payloadSize = ( long ) ( firstByteUnsigned ) - 0xc0 ; if ( indicator . length < 3 ) { // byte payloadSize = byteBuffer . get ( ) ; } else if ( indicator . length < 4 ) { // short } else if ( indicator . length < 6 ) { // int } else if ( indicator . length < 10 ) { // long", "commit_type": "fix"}
{"commit_tokens": ["Added", "alerts", "to", "the", "agency", ".", "Added", "a", "shortcut", "for", "converting", "date", "strings"], "add_tokens": "* @ return A journey from A to B using public transport . * @ param lineId The id of the line you want to get a timetable for .", "del_tokens": "* @ return A journey from A to B using public TransportApiResult < transport . * @ param stopId The id of the line you want to get a timetable for .", "commit_type": "add"}
{"commit_tokens": ["Changed", "blob", "read", "consistency", "to", "be", "configurable", "and", "changed", "to", "local", "-", "quorum", "by", "default"], "add_tokens": "import com . bazaarvoice . emodb . blob . BlobReadConsistency ; private final ConsistencyLevel _readConsistency ; public AstyanaxStorageProvider ( @ BlobReadConsistency ConsistencyLevel readConsistency , MetricRegistry metricRegistry ) { _readConsistency = checkNotNull ( readConsistency , \"readConsistency\" ) ; ColumnQuery < Composite > query = keyspace . prepareQuery ( placement . getBlobColumnFamily ( ) , _readConsistency ) . prepareQuery ( placement . getBlobColumnFamily ( ) , _readConsistency ) . prepareQuery ( placement . getBlobColumnFamily ( ) , _readConsistency )", "del_tokens": "private static final ConsistencyLevel CONSISTENCY_WEAK = ConsistencyLevel . CL_LOCAL_ONE ; public AstyanaxStorageProvider ( MetricRegistry metricRegistry ) { ColumnQuery < Composite > query = keyspace . prepareQuery ( placement . getBlobColumnFamily ( ) , CONSISTENCY_WEAK ) . prepareQuery ( placement . getBlobColumnFamily ( ) , CONSISTENCY_WEAK ) . prepareQuery ( placement . getBlobColumnFamily ( ) , CONSISTENCY_WEAK )", "commit_type": "change"}
{"commit_tokens": ["Update", "to", "use", "new", "Registration", "interface", "."], "add_tokens": "import org . springframework . cloud . client . serviceregistry . Registration ; @ Autowired ( required = false ) private Registration registration ; return \"Hello World! from \" + this . registration ;", "del_tokens": "return \"Hello World! from \" + this . discovery . getLocalServiceInstance ( ) ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "alter", "User", "Test", "for", "configurable", "Attributes"], "add_tokens": "user1 . set ( \"description\" , \"altered Test User\" ) ; user1 . set ( \"sn\" , \"Test User\" ) ;", "del_tokens": "user1 . set ( \"givenName\" , \"Testname\" ) ; user1 . set ( \"mail\" , \"test@example.com\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "URL", "prefix", "if", "one", "is", "missing", "."], "add_tokens": "String server = config . getServer ( ) ; if ( ! server . startsWith ( \"http://\" ) && ! server . startsWith ( \"https://\" ) ) { if ( server . indexOf ( \":443\" ) != - 1 ) { server = \"https://\" + server ; } else { server = \"http://\" + server ; } } client . setBasePath ( server ) ;", "del_tokens": "client . setBasePath ( config . getServer ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "non", "critical", "nodes", "failing", "the", "build"], "add_tokens": "IGNORED , NOT_INCLUDED , NOT_RUN , RUNNING , PASSED , FAILED , NON_CRITICAL_FAILURE , PARSE_FAILURE , SETUP_TEARDOWN_FAILURE ;", "del_tokens": "IGNORED , NOT_INCLUDED , NOT_RUN , RUNNING , PASSED , FAILED , NON_CRITICAL_FAILURE , PARSE_FAILURE ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "creation", "of", "resources", "with", "repository", "-", "supplied", "paths", "."], "add_tokens": "import java . util . Collection ; import java . util . HashSet ; import java . util . Set ; import static org . fcrepo . kernel . RdfLexicon . CONTAINS ; import static org . fcrepo . kernel . RdfLexicon . HAS_MIXIN_TYPE ; @ Override public FedoraObject createObject ( ) throws FedoraException { return repository . createResource ( getPath ( ) ) ; }", "del_tokens": "import static org . fcrepo . kernel . RdfLexicon . CONTAINS ; import static org . fcrepo . kernel . RdfLexicon . HAS_MIXIN_TYPE ; import java . util . Collection ; import java . util . HashSet ; import java . util . Set ;", "commit_type": "add"}
{"commit_tokens": ["added", "some", "simple", "implementation", "of", "default", "global", "model", "resolver"], "add_tokens": "import pl . matisoft . soy . global . DefaultGlobalModelResolver ; return new DefaultGlobalModelResolver ( ) ;", "del_tokens": "import pl . matisoft . soy . global . EmptyGlobalModelResolver ; return new EmptyGlobalModelResolver ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "u", "instead", "of", "y"], "add_tokens": "assertNotNull ( \"Failed to parse RFC822: \" + s , d2 ) ; assertNotNull ( \"Failed to parse W3C date '\" + s + \"'\" , aDT2 ) ;", "del_tokens": "assertNotNull ( \"Failed to parse: \" + s , d2 ) ; assertNotNull ( aDT2 ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "notices", "of", "modified", "files", ".", "Couple", "of", "other", "minor", "changes", "included", "."], "add_tokens": "* * * Additional changes to original Radeox code by : * * Peter Ledbrook , SpringSource log . warn ( \"<span class=\\\"error\\\">Exception</span>: \" + this , e ) ; log . debug ( \"Input that caused the exception:\\n\" + input ) ;", "del_tokens": "log . warn ( \"<span class=\\\"error\\\">Exception</span>: \" + this + \" (\" + input + \")\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "methods", "type", "(", "String", "text", ")", "and", "typeKeys", "(", "String", "text", ")", "from", "WebLocator"], "add_tokens": "sendKeys ( path ) ; sendKeys ( path ) ;", "del_tokens": "type ( path ) ; type ( path ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "headersize", "argument", "in", "constructor", "since", "the", "field", "is", "used", "during", "construction"], "add_tokens": "this ( context , devMode , 8192 ) ; } public EmbeddedJettyBuilder ( ContextPathConfig context , boolean devMode , int headerBufferSize ) { this . headerBufferSize = headerBufferSize ;", "del_tokens": "public void setHeaderBufferSize ( int headerBufferSize ) { this . headerBufferSize = headerBufferSize ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "to", "set", "AWSCredentialsProvider"], "add_tokens": "private AWSCredentialsProvider credentials = new CustomCredentialsProviderChain ( ) ; if ( ! Validator . isBlank ( roleToAssumeArn ) ) { String sessionId = \"session\" + Math . random ( ) ; STSAssumeRoleSessionCredentialsProvider remoteAccountCredentials = new STSAssumeRoleSessionCredentialsProvider ( credentials , roleToAssumeArn , sessionId ) ; credentials = remoteAccountCredentials ; } } public void setCredentialsProvider ( AWSCredentialsProvider credentialsProvider ) { this . credentials = credentialsProvider ;", "del_tokens": "private AWSCredentialsProvider credentials ; CustomCredentialsProviderChain localAccountCredentials = new CustomCredentialsProviderChain ( ) ; if ( Validator . isBlank ( roleToAssumeArn ) ) { credentials = localAccountCredentials ; } else { String sessionId = \"session\" + Math . random ( ) ; STSAssumeRoleSessionCredentialsProvider remoteAccountCredentials = new STSAssumeRoleSessionCredentialsProvider ( localAccountCredentials , roleToAssumeArn , sessionId ) ; credentials = remoteAccountCredentials ; }", "commit_type": "add"}
{"commit_tokens": ["add", "code", "documentation", "and", "refactor", "for", "consistency"], "add_tokens": "/ * * * < p > Optional capability that allows to add custom command line arguments * to the spawned phantomjs process . < / p > * * < p > Set this capability with a list of of argument strings to add , e . g . * < code > new String [ ] { \"--ignore-ssl-errors=yes\" , \"--load-images=no\" } * < / code > . < / p > * / // Find command line arguments to add String [ ] commandLineArguments = findCommandLineArguments ( desiredCapabilities ) ; . usingCommandLineArguments ( commandLineArguments ) // Add additional command line arguments provided via the // PHANTOMJS_CLI_ARGS_CAPABILITY (if any).", "del_tokens": ". usingCommandLineArguments ( findCommandLineArguments ( desiredCapabilities ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "new", "test", "case", "for", "B", "-", "Tree", "recovery"], "add_tokens": "import org . vanilladb . core . storage . tx . recovery . BTreeIndexRecoveryTest ; BTreePageTest . class , RecoveryBasicTest . class , BTreeIndexRecoveryTest . class ,", "del_tokens": "import org . vanilladb . core . storage . index . btree . BTreeIndexConcurrentTest ; BTreePageTest . class , BTreeIndexConcurrentTest . class , RecoveryBasicTest . class ,", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "disable", "swipes", "in", "a", "certain", "direction"], "add_tokens": "import android . support . annotation . NonNull ; public enum SwipeDirection { DIRECTION_NORMAL_LEFT , DIRECTION_FAR_LEFT , DIRECTION_NORMAL_RIGHT , DIRECTION_FAR_RIGHT , DIRECTION_NEUTRAL ; @ NonNull public static List < SwipeDirection > getAllDirections ( ) { public boolean isLeft ( ) { return this . equals ( DIRECTION_NORMAL_LEFT ) || this . equals ( DIRECTION_FAR_LEFT ) ; } public boolean isRight ( ) { return this . equals ( DIRECTION_NORMAL_RIGHT ) || this . equals ( DIRECTION_FAR_RIGHT ) ; }", "del_tokens": "public class SwipeDirections { public static final int DIRECTION_NORMAL_LEFT = - 1 ; public static final int DIRECTION_FAR_LEFT = - 2 ; public static final int DIRECTION_NORMAL_RIGHT = 1 ; public static final int DIRECTION_FAR_RIGHT = 2 ; public static final int DIRECTION_NEUTRAL = 0 ; static List < Integer > getAllDirections ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "css", "and", "js", "scripts", "to", "html", "report"], "add_tokens": "import org . apache . commons . io . IOUtils ; private XmlNode headNode = createHeadNode ( ) ; private XmlNode htmlNode = node ( \"html\" ) . withChildren ( headNode ) . withChildren ( bodyNode ) ; private XmlNode createHeadNode ( ) { XmlNode headNode = node ( \"head\" ) ; try { String css = IOUtils . toString ( getClass ( ) . getResourceAsStream ( \"/html-report/galen-report.css\" ) ) ; String jquery = IOUtils . toString ( getClass ( ) . getResourceAsStream ( \"/html-report/jquery-1.7.1.min.js\" ) ) ; String galenJs = IOUtils . toString ( getClass ( ) . getResourceAsStream ( \"/html-report/galen-report.js\" ) ) ; headNode . add ( node ( \"style\" ) . withUnescapedText ( css ) ) ; headNode . add ( node ( \"script\" ) . withUnescapedText ( jquery ) ) ; headNode . add ( node ( \"script\" ) . withUnescapedText ( galenJs ) ) ; //TODO make sure it doesn't escape } catch ( Exception e ) { e . printStackTrace ( ) ; } return headNode ; } return new XmlBuilder ( null , htmlNode ) . build ( ) ;", "del_tokens": "return new XmlBuilder ( null , bodyNode ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "npe", "on", "getting", "entity", "annotations", "from", "a", "text", "annotation"], "add_tokens": "for ( EntityAnnotation ea : eas ) { if ( ea . getRelations ( ) != null && ea . getRelations ( ) . contains ( ta ) ) { } }", "del_tokens": "for ( EntityAnnotation ea : eas ) if ( ea . getRelations ( ) . contains ( ta ) )", "commit_type": "fix"}
{"commit_tokens": ["fix", "up", "the", "add", "component", "to", "list", "all", "components", "not", "already", "in", "the", "project"], "add_tokens": "return Results . success ( \"Endpoint added\" ) ;", "del_tokens": "return Results . success ( \"Node deleted\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Javadoc", "to", "better", "describe", "null", "behaviour"], "add_tokens": "* This returns the greater of money1 or money2 . * If one value is null , the other is returned . * This returns the greater of money1 or money2 . * If one value is null , the other is returned .", "del_tokens": "* This returns the greater of money1 or money2 treating null as infinitely small . * This returns the greater of money1 or money2 treating null as infinitely small .", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "problem", "with", "LET", "and", "context", "variables"], "add_tokens": "if ( ( ( String ) iContent ) . startsWith ( \"$\" ) && ! ( ( String ) iContent ) . startsWith ( OSystemVariableResolver . VAR_BEGIN ) )", "del_tokens": "if ( ( ( String ) iContent ) . startsWith ( \"$\" ) )", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "server", "is", "paused", "before", "client", "s", "pause", "episode", "exits", "."], "add_tokens": "int serverTickCount = 0 ; int clientTickCount = 0 ; // We need to make sure that both the client and server have paused, otherwise we are still susceptible // to the \"Holder Lookups\" hang. // Since the server sets its pause state in response to the client's pause state, // and it only performs this check once, at the top of its tick method, // to be sure that the server has had time to set the flag correctly we need to make sure that at least one // server tick method has *started* since the flag was set. // We can't do this by catching the onServerTick events, since we don't receive them when the game is paused. // The following code makes use of the fact that the server both locks and empties the server's futureQueue, every // time through the server tick method. // This locking means that if the client - which needs to wait on the lock - tries to add an event to the queue // in response to an event on the queue being executed, the newly added event will have to happen in a subsequent tick. if ( Minecraft . getMinecraft ( ) . isGamePaused ( ) && ev != null && ev . phase == Phase . END && this . clientTickCount == this . serverTickCount && this . clientTickCount <= 2 ) System . out . println ( \"RACING... client tc: \" + this . clientTickCount + \", server tc: \" + this . serverTickCount ) ; this . clientTickCount ++ ; // Increment our count, and wait for the server to catch up. Minecraft . getMinecraft ( ) . getIntegratedServer ( ) . addScheduledTask ( new Runnable ( ) public void run ( ) { // Increment the server count. PauseOldServerEpisode . this . serverTickCount ++ ; } } ) ; if ( this . serverTickCount > 2 ) episodeHasCompleted ( ClientState . CLOSING_OLD_SERVER ) ; // If the Minecraft server isn't paused at this point, then the following line will cause the server thread to exit... // ...in which case the next line will hang.", "del_tokens": "if ( ev != null && ev . phase == Phase . END ) if ( Minecraft . getMinecraft ( ) . isGamePaused ( ) ) episodeHasCompleted ( ClientState . CLOSING_OLD_SERVER ) ; }", "commit_type": "make"}
{"commit_tokens": ["Changed", "base", "class", "for", "pre", "-", "defined", "support", "Activity", "from", "ActionBarActivity", "to", "FragmentActivity"], "add_tokens": "* @ see ChronoSupportActivity", "del_tokens": "* @ see ChronoActionBarActivity", "commit_type": "change"}
{"commit_tokens": ["added", "clear", "functionality", "atm", "only", "mapped", "in", "emacs", "editing", "mode"], "add_tokens": "keys . add ( new KeyOperation ( 12 , Operation . CLEAR ) ) ; //keys.add(new KeyOperation(24, Operation.NO_ACTION)); ctrl-x keys . add ( new KeyOperation ( new int [ ] { 24 , 21 } , Operation . UNDO ) ) ; //ctrl-x ctrl-u", "del_tokens": "keys . add ( new KeyOperation ( 12 , Operation . DELETE_ALL ) ) ; keys . add ( new KeyOperation ( 24 , Operation . NO_ACTION ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "dialog", "closed", "event", "to", "C3D", "Dialog"], "add_tokens": "if ( newVal != null ) { buttonRect . setFill ( newVal . getFills ( ) . get ( 0 ) . getFill ( ) ) ; double radius = 7 ; if ( newVal . getFills ( ) . get ( 0 ) . getRadii ( ) . getTopLeftHorizontalRadius ( ) > radius ) radius = newVal . getFills ( ) . get ( 0 ) . getRadii ( ) . getTopLeftHorizontalRadius ( ) ; buttonRect . setArcHeight ( radius ) ; buttonRect . setArcWidth ( radius ) ; }", "del_tokens": "buttonRect . setFill ( newVal . getFills ( ) . get ( 0 ) . getFill ( ) ) ; double radius = 7 ; if ( newVal . getFills ( ) . get ( 0 ) . getRadii ( ) . getTopLeftHorizontalRadius ( ) > radius ) radius = newVal . getFills ( ) . get ( 0 ) . getRadii ( ) . getTopLeftHorizontalRadius ( ) ; buttonRect . setArcHeight ( radius ) ; buttonRect . setArcWidth ( radius ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "nested", "timestamp", "fields", "in", "JSON", "and", "Date", "parser"], "add_tokens": "Object fieldValue = getJsonFieldValue ( jsonObject ) ;", "del_tokens": "Object fieldValue = jsonObject . get ( mConfig . getMessageTimestampName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "small", "bug", "in", "serializer", "(", "credit", "Geoff", "Hendrey", ")"], "add_tokens": "out . write ( BYTE_FULL ) ;", "del_tokens": "out . write ( SHORT_FULL ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "CMS", "code", "from", "PkcsPkiEnvelopeParser", "."], "add_tokens": "@ Ignore", "del_tokens": "//@Ignore", "commit_type": "remove"}
{"commit_tokens": ["added", "accept", "header", "fix", "for", "getting", "attachments", "with", "documents"], "add_tokens": "HttpGet get = new HttpGet ( uri ) ; get . addHeader ( \"Accept\" , \"application/json\" ) ; return get ( get ) ;", "del_tokens": "return get ( new HttpGet ( uri ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "additional", "measures", "for", "RPC", "client", "and", "server", "stats", "."], "add_tokens": "public static final MetricName RPC_CLIENT_ERROR_COUNT = new MetricName ( \"/rpc/client/error_count\" ) ; public static final MetricName RPC_CLIENT_REQUEST_BYTES = new MetricName ( \"/rpc/client/request_bytes\" ) ; public static final MetricName RPC_CLIENT_RESPONSE_BYTES = new MetricName ( \"/rpc/client/response_bytes\" ) ; public static final MetricName RPC_CLIENT_ROUNDTRIP_LATENCY = new MetricName ( \"/rpc/client/roundtrip_latency\" ) ; public static final MetricName RPC_CLIENT_UNCOMPRESSED_REQUEST_BYTES = new MetricName ( \"/rpc/client/uncompressed_request_bytes\" ) ; public static final MetricName RPC_CLIENT_UNCOMPRESSED_RESPONSE_BYTES = new MetricName ( \"/rpc/client/uncompressed_response_bytes\" ) ; public static final MetricName RPC_SERVER_ERROR_COUNT = new MetricName ( \"/rpc/server/error_count\" ) ; public static final MetricName RPC_SERVER_REQUEST_BYTES = new MetricName ( \"/rpc/server/request_bytes\" ) ; public static final MetricName RPC_SERVER_RESPONSE_BYTES = new MetricName ( \"/rpc/server/response_bytes\" ) ; public static final MetricName RPC_SERVER_SERVER_LATENCY = new MetricName ( \"/rpc/server/server_latency\" ) ; public static final MetricName RPC_SERVER_UNCOMPRESSED_REQUEST_BYTES = new MetricName ( \"/rpc/server/uncompressed_request_bytes\" ) ; public static final MetricName RPC_SERVER_UNCOMPRESSED_RESPONSE_BYTES = new MetricName ( \"/rpc/server/uncompressed_response_bytes\" ) ;", "del_tokens": "public static final MetricName RPC_CLIENT_BYTES_RECEIVED = new MetricName ( \"/rpc/client/bytes_received\" ) ; public static final MetricName RPC_CLIENT_BYTES_SENT = new MetricName ( \"/rpc/client/bytes_sent\" ) ; public static final MetricName RPC_CLIENT_LATENCY = new MetricName ( \"/rpc/client/latency\" ) ; public static final MetricName RPC_SERVER_BYTES_RECEIVED = new MetricName ( \"/rpc/server/bytes_received\" ) ; public static final MetricName RPC_SERVER_BYTES_SENT = new MetricName ( \"/rpc/server/bytes_sent\" ) ; public static final MetricName RPC_SERVER_LATENCY = new MetricName ( \"/rpc/server/latency\" ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "to", "default", "maven", "layout"], "add_tokens": "originalContent = IOUtils . readFileAtOnceAsString ( \"src/test/resources/fixture.json\" ) ;", "del_tokens": "originalContent = IOUtils . readFileAtOnceAsString ( \"test/junit/fixture.json\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "/", "api", "/", "v1", "/", "login", "and", "/", "api", "/", "v1", "/", "logout"], "add_tokens": "final Service < HttpRequest , HttpResponse > loginService ; final Service < HttpRequest , HttpResponse > logoutService ; loginService = new LoginService ( securityManager , executor ) ; logoutService = new LogoutService ( securityManager , executor ) ; // If the security is not enabled, return the 'anonymous' token. loginService = ( ServiceRequestContext ctx , HttpRequest req ) -> { } ; logoutService = ( ServiceRequestContext ctx , HttpRequest req ) -> HttpResponse . of ( HttpStatus . OK ) ; sb . service ( apiV0PathPrefix + \"authenticate\" , loginService ) . service ( API_V1_PATH_PREFIX + \"login\" , loginService ) . service ( apiV0PathPrefix + \"logout\" , logoutService ) . service ( API_V1_PATH_PREFIX + \"logout\" , logoutService ) ;", "del_tokens": "sb . service ( apiV0PathPrefix + \"authenticate\" , new LoginService ( securityManager , executor ) ) . service ( apiV0PathPrefix + \"logout\" , new LogoutService ( securityManager , executor ) ) ; // If the security is not enabled, '/api/v0/authenticate' will return the 'anonymous' token. sb . service ( apiV0PathPrefix + \"authenticate\" , ( ServiceRequestContext ctx , HttpRequest req ) -> { } ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "tcp", "bottleneck", "caused", "by", "the", "fact", "that", "the", "message", "reading", "and", "message", "handling", "were", "done", "sequentially", ".", "Now", "there", "is", "a", "set", "of", "worker", "threads", "that", "handle", "messages", "and", "the", "read", "loop", "is", "much", "tighter", "."], "add_tokens": "import com . nokia . dempsy . monitoring . StatsCollector ; public void setStatsCollector ( StatsCollector statsCollector ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Created", "the", "GuildMember", "events", "fire", "the", "events", "and", "listen", "for", "them", "in", "ListenerAdapter", "."], "add_tokens": "import java . util . LinkedList ; import net . dv8tion . jda . events . guild . GuildMemberJoinEvent ; import org . json . JSONObject ; api . getEventManager ( ) . handle ( new GuildMemberJoinEvent ( api , responseNumber , guild , user ) ) ;", "del_tokens": "import org . json . JSONObject ; import java . util . LinkedList ;", "commit_type": "create"}
{"commit_tokens": ["Use", "handles", "to", "support", "Java", "9", "tryFinally", "without", "Java", "9", "build", "."], "add_tokens": "import java . lang . reflect . InvocationTargetException ; private static final MethodHandle tryFinallyJava9 ; try { return ( MethodHandle ) tryFinallyJava9 . invokeExact ( target , wrapPost ) ; } catch ( Throwable t ) { throw new RuntimeException ( \"Java 9 detected but MethodHandles.tryFinally missing\" , t ) ; } static { if ( Util . isJava9 ( ) ) { tryFinallyJava9 = Binder . from ( MethodHandle . class , MethodHandle . class , MethodHandle . class ) . invokeStaticQuiet ( MethodHandles . lookup ( ) , MethodHandles . class , \"tryFinally\" ) ; } else { tryFinallyJava9 = null ; } }", "del_tokens": "return MethodHandles . tryFinally ( target , wrapPost ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "counter", "increments", "for", "reporter"], "add_tokens": "spectatorRegistry . counter ( id ) . increment ( curr - prev ) ;", "del_tokens": "spectatorRegistry . counter ( id ) . increment ( prev - curr ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "building", "of", "javadocs", "for", "multiple", "versions", "without", "deleting", "all", "other", "versions", "docs", ";", ")"], "add_tokens": "* Our supported logging levels . These match SLF4J .", "del_tokens": "* Our support logging levels , matching SLF4J .", "commit_type": "allow"}
{"commit_tokens": ["Implemented", "efficient", "parsing", "of", "lines", "."], "add_tokens": "import org . rapidoid . data . Ranges ; import org . rapidoid . wrap . Int ; void scanLnLn ( Ranges ranges , int search , Int result ) ;", "del_tokens": "int scanLnLn ( Range [ ] ranges ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "container", "-", "container", "relationships", "."], "add_tokens": "getModel ( ) . addRelationship ( new Relationship ( this , destination , description ) ) ;", "del_tokens": "Relationship relationship = new Relationship ( this , destination , description ) ; relationships . add ( relationship ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "multiple", "formats", ".", "added", "properties", "parser", "."], "add_tokens": "import org . configureme . sources . ConfigurationSourceKey . Format ; public abstract class BaseHelloWorldRunner { protected abstract Format getTargetConfigFormat ( ) ; protected void runExample ( ) { } protected void research ( Environment in , String description ) { if ( description == null ) description = in . toString ( ) ; LanguageResearcher researcher = new LanguageResearcher ( ) ; System . out . println ( \"Researching \" + description + \" (\" + in + \")\" + \": \" ) ; ConfigurationManager . INSTANCE . configure ( researcher , in , getTargetConfigFormat ( ) ) ; protected void sayHello ( Environment in , String description ) { ConfigurationManager . INSTANCE . configure ( hello , in , getTargetConfigFormat ( ) ) ;", "del_tokens": "public class HelloWorldRunner { public static void main ( String a [ ] ) { private static void sayHello ( Environment in , String description ) { ConfigurationManager . INSTANCE . configure ( hello , in ) ; private static void research ( Environment in , String description ) { if ( description == null ) description = in . toString ( ) ; LanguageResearcher researcher = new LanguageResearcher ( ) ; System . out . println ( \"Researching \" + description + \" (\" + in + \")\" + \": \" ) ; ConfigurationManager . INSTANCE . configure ( researcher , in ) ; }", "commit_type": "add"}
{"commit_tokens": ["use", "httpcontext", "for", "change", "tracker", "so", "that", "it", "passes", "the", "cookies", ".", "fixes", "last", "issue", "with", "couch", "chat", "persona", "login"], "add_tokens": "changeTracker = new CBLChangeTracker ( remote , continuous ? TDChangeTrackerMode . LongPoll : TDChangeTrackerMode . OneShot , lastSequence , this , this . httpContext ) ;", "del_tokens": "changeTracker = new CBLChangeTracker ( remote , continuous ? TDChangeTrackerMode . LongPoll : TDChangeTrackerMode . OneShot , lastSequence , this ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "HashSet", "via", "HashMap2", ".", "keySet", "()"], "add_tokens": "return new HashMap2 < Integer , String > ( r , true ) ;", "del_tokens": "return new HashMap2 < Integer , String > ( r , 0L ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "JavaDoc", "of", "IntrospectionResponse", "."], "add_tokens": "* that the access token does not exist or has expired . Or the client * application associated with the access token does not exist any longer .", "del_tokens": "* that the access token does not exist or has expired .", "commit_type": "update"}
{"commit_tokens": ["Changed", "so", "I", "you", "can", "pass", "a", "per", "-", "request", "user", "-", "agent", "string", "."], "add_tokens": "public SyndFeed retrieveFeed ( URL feedUrl ) throws IllegalArgumentException , IOException , FeedException , FetcherException { return this . retrieveFeed ( this . getUserAgent ( ) , feedUrl ) ; } public SyndFeed retrieveFeed ( String userAgent , URL feedUrl ) throws IllegalArgumentException , IOException , FeedException , FetcherException { connection . addRequestProperty ( \"User-Agent\" , userAgent ) ;", "del_tokens": "public SyndFeed retrieveFeed ( URL feedUrl ) throws IllegalArgumentException , IOException , FeedException , FetcherException { // set the user agent connection . addRequestProperty ( \"User-Agent\" , getUserAgent ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["implemented", "test", "for", "valueOf", "()"], "add_tokens": "CLASS {", "del_tokens": "CLASS_CONVERTER {", "commit_type": "implement"}
{"commit_tokens": ["Add", "zone", "as", "a", "deployment", "context", "."], "add_tokens": "serverId ( \"@serverId\" ) , stack ( \"@stack\" ) , region ( \"@region\" ) , zone ( \"@zone\" ) ;", "del_tokens": "serverId ( \"@serverId\" ) , stack ( \"@stack\" ) , region ( \"@region\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "publishing", "of", "io", "-", "extras", "now", "renamed", "to", "formats", "-", "extra"], "add_tokens": "return \"pnm\" ;", "del_tokens": "return \"PNM\" ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "two", "fields", "from", "Matcher", "."], "add_tokens": "if ( ! isFindLongest ( regex . options ) ) return true ; if ( ! isFindLongest ( regex . options ) ) return true ;", "del_tokens": "// cached values protected final int option ; protected final int caseFoldFlag ; this . option = regex . options ; this . caseFoldFlag = regex . caseFoldFlag ; if ( ! isFindLongest ( option ) ) return true ; if ( ! isFindLongest ( option ) ) return true ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "InhiBeans", "to", "ensure", "consistency", "of", "text", "and", "length", "properties", "of", "StyledTextDocument", "."], "add_tokens": "import inhibeans . property . ReadOnlyIntegerWrapper ; // update length, invalidate text int newLength = length . get ( ) - ( end - start ) + replacement . length ( ) ; length . blockWhile ( ( ) -> { // don't publish length change until text is invalidated length . set ( newLength ) ; text . invalidate ( ) ; } ) ; // emit change event", "del_tokens": "import javafx . beans . property . ReadOnlyIntegerWrapper ; // update length, invalidate text, emit change event length . set ( length . get ( ) - ( end - start ) + replacement . length ( ) ) ; text . invalidate ( ) ; // TODO invalidate length and text \"atomically\"", "commit_type": "use"}
{"commit_tokens": ["allow", "callback", "on", "sync", "to", "disk"], "add_tokens": "/ * * * Callback called when flush buffers to disk * / private CallbackSync callback = null ; fileChannel . position ( 0 ) . truncate ( 0 ) ; / * * * set callback called when buffers where synched to disk * @ param callback * / public void setCallback ( final CallbackSync callback ) { this . callback = callback ; } fileChannel . position ( index * blockSize ) . read ( buf ) ; fileChannel . position ( index * blockSize ) . write ( buf ) ; if ( callback != null ) callback . synched ( ) ; } public static interface CallbackSync { public void synched ( ) ;", "del_tokens": "fileChannel . position ( 0 ) ; fileChannel . truncate ( 0 ) ; fileChannel . position ( index * blockSize ) ; fileChannel . read ( buf ) ; fileChannel . position ( index * blockSize ) ; fileChannel . write ( buf ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "hack", "that", "allows", "nested", "FXMLComponents", "and", "such"], "add_tokens": "import com . google . inject . Injector ; private final Injector injector ; FXMLComponentMembersInjector ( final Injector injector , final FXMLComponent annotation ) { this . injector = injector ; fxmlLoader . setBuilderFactory ( injector . getInstance ( FXMLComponentBuilderFactory . class ) ) ;", "del_tokens": "FXMLComponentMembersInjector ( final FXMLComponent annotation ) {", "commit_type": "add"}
{"commit_tokens": ["added", "method", "getPortIdentifiers", "to", "get", "a", "list", "of", "available", "port", "identifiers", "."], "add_tokens": "import java . util . List ; static public List < String > getPortIdentifiers ( ) { return factory . getPortIdentifiers ( ) ; }", "del_tokens": "/ * static public String [ ] getPortList ( ) { return SerialPortList . getPortNames ( ) ; } * /", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "send", "generic", "request", "without", "expecting", "of", "any", "response", "from", "the", "application"], "add_tokens": "// Status events are sent with a requestId of zero if ( responseClass == null ) { write ( namespace , message , destinationId ) ; return null ; }", "del_tokens": "// Status events are sent with a requestid of zero", "commit_type": "add"}
{"commit_tokens": ["add", "delay", "before", "re", "-", "take", "screenshot"], "add_tokens": "public File takeDeviceScreenshot ( ) throws IOException , InterruptedException { Utils . sleep ( 5000 , \"wait for device\" ) ;", "del_tokens": "public File takeDeviceScreenshot ( ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Adding", "the", "parsers", "for", "the", "html", "representation"], "add_tokens": "* Replaces the emoji 's aliases (between 2 ' : ') occurences and the html representations by their unicode. * \"&#128516;\" = > \"\" * @ return the string with the aliases and html representations replaced by their unicode . // Replace the html for ( Emoji emoji : EmojiManager . getAll ( ) ) { result = result . replace ( emoji . getHtml ( ) , emoji . getUnicode ( ) ) ; } / * * * Replaces the emoji 's unicode occurences by their html representation. * Example : \"\" => \" & 128516;\" * * @ param input the string to parse * @ return the string with the emojis replaced by their html representation . * / public static String parseToHtml ( String input ) { String result = input ; for ( Emoji emoji : EmojiManager . getAll ( ) ) { result = result . replace ( emoji . getUnicode ( ) , emoji . getHtml ( ) ) ; } return result ; }", "del_tokens": "* Replaces the emoji 's aliases (between 2 ' : ') occurences by their unicode. * @ return the string with the aliases replaced by their unicode .", "commit_type": "add"}
{"commit_tokens": ["add", "toString", "methods", "for", "debugging"], "add_tokens": "@ Override public String toString ( ) { return \"ClassJavadoc{\" + \"name='\" + name + '\\'' + \", comment=\" + comment + \", seeAlso=\" + seeAlso + \", other=\" + other + \", methods=\" + methods + '}' ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "https", "servers", "on", "non", "-", "default", "port", "with", "self", "-", "signed", "certs"], "add_tokens": "int port = uri . getPort ( ) ; if ( port <= 0 ) { port = 443 ; } Protocol easyHttps = new Protocol ( \"https\" , ( ProtocolSocketFactory ) new EasySSLProtocolSocketFactory ( ) , port ) ; hc . setHost ( host , port , easyHttps ) ;", "del_tokens": "Protocol easyHttps = new Protocol ( \"https\" , ( ProtocolSocketFactory ) new EasySSLProtocolSocketFactory ( ) , 443 ) ; hc . setHost ( host , 443 , easyHttps ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "RawSocketSender", "class", "--", "fixed", "bug", "of", "inefficient", "Socket#setSoTimeout", "(", "..", ")", "method", "call"], "add_tokens": "socket . connect ( server ) ;", "del_tokens": "socket . connect ( server ) ;", "commit_type": "change"}
{"commit_tokens": ["changed", "start", "arguments", "to", "start"], "add_tokens": "if ( \"start\" . equals ( args [ 0 ] ) ) { startTask . run ( args ) ; return ; } help ( ) ;", "del_tokens": "startTask . run ( args ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "PanasonicMakernoteDirectory", "related", "to", "interpreting", "faces", ".", "Added", "missing", "JPEG", "file", "for", "unit", "tests", "."], "add_tokens": "File file = new File ( \"Source/com/drew/metadata/exif/test/withPanasonicFaces.jpg\" ) ; @ Test // @Ignore(value = \"Need a sample image that contains a detected face\") @ Test // @Ignore(value = \"Need a sample image that contains a recognised face\")", "del_tokens": "import org . junit . Ignore ; File file = new File ( \"Source/com/drew/metadata/exif/test/Panasonic.jpg\" ) ; @ Test @ Ignore ( value = \"Need a sample image that contains a detected face\" ) @ Test @ Ignore ( value = \"Need a sample image that contains a recognised face\" )", "commit_type": "fix"}
{"commit_tokens": ["add", "should", "()", ".", "be", "(", "..", ")", "assertions", "to", "fluent", "interface"], "add_tokens": "if ( methodName . equals ( \"getTagName\" ) || methodName . equals ( \"tagName\" ) ) {", "del_tokens": "if ( methodName . equals ( \"getTagName\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "test", "to", "exercise", "a", "bug", "fix", "."], "add_tokens": "out . delete ( ) ; / * * * Read an MPP8 file with a non - standard task fixed data block size * / public void testBug4 ( ) throws Exception { File out = null ; try { File in = new File ( m_basedir + \"/bug4.mpp\" ) ; MPPFile mpp = new MPPFile ( in ) ; out = File . createTempFile ( \"junit\" , \".mpx\" ) ; mpp . write ( out ) ; } finally { if ( out != null ) { out . delete ( ) ; } } }", "del_tokens": "//out.delete();", "commit_type": "add"}
{"commit_tokens": ["use", "the", "non", "deprecated", "methods"], "add_tokens": "return createGeneratorConfig ( generatorName , packageName , generatorStrategy , jdbcConfig , MySQLDatabase . class . getName ( ) ) ;", "del_tokens": "return createGeneratorConfig ( generatorName , packageName , generatorStrategy , jdbcConfig , MySQLDatabase . class . getName ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "capture", "parameter", "to", "preauthorize", "cards"], "add_tokens": "private final BankAccountOperations bankAccountOperations ; private final CustomerOperations customerOperations ; private final ChargeOperations chargeOperations ; private final FeeOperations feeOperations ; private final PayoutOperations payoutOperations ; private final TransferOperations transferOperations ; private final PlanOperations planOperations ; private final SubscriptionOperations subscriptionsOperations ;", "del_tokens": "private BankAccountOperations bankAccountOperations ; private CustomerOperations customerOperations ; private ChargeOperations chargeOperations ; private FeeOperations feeOperations ; private PayoutOperations payoutOperations ; private TransferOperations transferOperations ; private PlanOperations planOperations ; private SubscriptionOperations subscriptionsOperations ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "the", "Text", "in", "a", "TextContentSpec", "wasn", "t", "being", "expanded", "."], "add_tokens": "// Expand the text final String expandString = getExpansionString ( RESTTextContentSpecV1 . TEXT_NAME ) ; createdContentSpec = getRESTClient ( ) . createJSONTextContentSpec ( expandString , contentSpec , logMessage . getMessage ( ) , createdContentSpec = getRESTClient ( ) . createJSONTextContentSpec ( expandString , contentSpec ) ; // Expand the text final String expandString = getExpansionString ( RESTTextContentSpecV1 . TEXT_NAME ) ; updatedContentSpec = getRESTClient ( ) . updateJSONTextContentSpec ( expandString , contentSpec , logMessage . getMessage ( ) , updatedContentSpec = getRESTClient ( ) . updateJSONTextContentSpec ( expandString , contentSpec ) ;", "del_tokens": "createdContentSpec = getRESTClient ( ) . createJSONTextContentSpec ( \"\" , contentSpec , logMessage . getMessage ( ) , createdContentSpec = getRESTClient ( ) . createJSONTextContentSpec ( \"\" , contentSpec ) ; updatedContentSpec = getRESTClient ( ) . updateJSONTextContentSpec ( \"\" , contentSpec , logMessage . getMessage ( ) , updatedContentSpec = getRESTClient ( ) . updateJSONTextContentSpec ( \"\" , contentSpec ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "label", "support", "for", "aggregation", "responses", "and", "term", "buckets"], "add_tokens": "import com . fasterxml . jackson . annotation . JsonInclude ; private String label ; public RangeFacetResponse ( List < RangeBucket > buckets , String label ) { this . label = label ; @ JsonInclude ( JsonInclude . Include . NON_NULL ) public String getLabel ( ) { return label ; }", "del_tokens": "public RangeFacetResponse ( List < RangeBucket > buckets ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "index", "out", "of", "bounds"], "add_tokens": "final int lastDotIndex = config . mainClass . lastIndexOf ( '.' ) ; final int classIndex = lastDotIndex >= 0 ? lastDotIndex : config . mainClass . length ( ) ; values . put ( \"${bundleIdentifier}\" , config . mainClass . substring ( 0 , classIndex ) ) ;", "del_tokens": "values . put ( \"${bundleIdentifier}\" , config . mainClass . substring ( 0 , config . mainClass . lastIndexOf ( '.' ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "workflow", "running", "test", "back", "in", "."], "add_tokens": "import com . github . jmchilton . blend4j . galaxy . beans . HistoryDetails ; import com . sun . jersey . api . client . ClientResponse ; static ClientResponse testUpload ( final GalaxyInstance galaxyInstance , final String historyId , final File testFile ) { final ToolsClient . FileUploadRequest request = new ToolsClient . FileUploadRequest ( historyId , testFile ) ; final ClientResponse clientResponse = galaxyInstance . getToolsClient ( ) . uploadRequest ( request ) ; assert clientResponse . getStatus ( ) == 200 ; return clientResponse ; } testHistory . setName ( \"blend4j Test History\" ) ; } static void waitForHistory ( final HistoriesClient client , final String historyId ) throws InterruptedException { HistoryDetails details = null ; while ( true ) { details = client . showHistory ( historyId ) ; if ( ! details . getState ( ) . equals ( \"running\" ) ) { break ; } } if ( ! details . getState ( ) . equals ( \"ok\" ) ) { throw new RuntimeException ( \"History no longer, but not in 'ok' state.\" ) ; } Thread . sleep ( 200L ) ; }", "del_tokens": "testHistory . setName ( \"Upload Test History\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Use", "ResourceLoader", "from", "condition", "context", "if", "avilable"], "add_tokens": "private ResourceLoader defaultResourceLoader = new DefaultResourceLoader ( ) ; ResourceLoader loader = context . getResourceLoader ( ) == null ? this . defaultResourceLoader : context . getResourceLoader ( ) ; if ( ! loader . getResource ( location ) . exists ( ) ) {", "del_tokens": "private ResourceLoader loader = new DefaultResourceLoader ( ) ; if ( ! this . loader . getResource ( location ) . exists ( ) ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "missing", "@Filter", "to", "show", "queries"], "add_tokens": "import static org . meridor . perspective . shell . validator . Field . * ; @ Filter ( PROJECTS )", "del_tokens": "import static org . meridor . perspective . shell . validator . Field . CLOUDS ; import static org . meridor . perspective . shell . validator . Field . IMAGE_NAMES ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "where", "to", "accept", "string", "and", "CodeWScope", "types"], "add_tokens": "NOT_EQUAL ( \"$ne\" ) , WHERE ( \"$where\" ) ;", "del_tokens": "NOT_EQUAL ( \"$ne\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "unbounded", "null", "throwing", "exception"], "add_tokens": "if ( argumentDefinition . hasBoundedRange ( ) && isOutOfRange ( argumentDefinition . minValue , argumentDefinition . maxValue , argumentDoubleValue ) ) { if ( argumentDefinition . hasRecommendedRange ( ) && isOutOfRange ( argumentDefinition . minRecommendedValue , argumentDefinition . maxRecommendedValue , argumentDoubleValue ) ) { // if there is no recommended value, do not log anything if ( hasBoundedRange ( ) || hasRecommendedRange ( ) ) { /** Returns {@code true} if the argument has a bounded range; {@code false} otherwise. */ private boolean hasBoundedRange ( ) { return this . minValue != Double . NEGATIVE_INFINITY || this . maxValue != Double . POSITIVE_INFINITY ; } private boolean hasRecommendedRange ( ) { return this . maxRecommendedValue != Double . POSITIVE_INFINITY || this . minRecommendedValue != Double . NEGATIVE_INFINITY ; }", "del_tokens": "if ( isOutOfRange ( argumentDefinition . minValue , argumentDefinition . maxValue , argumentDoubleValue ) ) { if ( isOutOfRange ( argumentDefinition . minRecommendedValue , argumentDefinition . maxRecommendedValue , argumentDoubleValue ) ) { if ( this . maxValue != Double . POSITIVE_INFINITY || this . minValue != Double . NEGATIVE_INFINITY || this . maxRecommendedValue != Double . POSITIVE_INFINITY || this . minRecommendedValue != Double . NEGATIVE_INFINITY ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "exit", "()", "function", "that", "is", "called", "when", "the", "application", "is", "quitted"], "add_tokens": "public void exit ( ) { } // TODO: abstract public void exit(); public void setGLParam ( GL gl ) { Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( ) { @ Override public void run ( ) { exit ( ) ; } } ) ; @ Override public void mouseWheelMoved ( MouseWheelEvent e ) { int wheelRotation = e . getWheelRotation ( ) ; mouse . setWheelRotation ( wheelRotation ) ; if ( wheelRotation != 0 ) { mouseEvent ( MouseEvent . WHEEL_ROTATED , MouseButton . NONE ) ; } }", "del_tokens": "public void setGLParam ( GL gl ) { /** @deprecated */ public void mouseWheelEvent ( ) { } ; public void end ( ) { System . out . println ( \"test\" ) ; } @ Override public void destroy ( ) { end ( ) ; } @ Override public void mouseWheelMoved ( MouseWheelEvent e ) { int wheelRotation = e . getWheelRotation ( ) ; mouse . setWheelRotation ( wheelRotation ) ; if ( wheelRotation != 0 ) { mouseEvent ( MouseEvent . WHEEL_ROTATED , MouseButton . NONE ) ; mouseWheelEvent ( ) ; } }", "commit_type": "add"}
{"commit_tokens": ["Moved", "some", "parts", "of", "TreeTestData", "into", "TreeNode", "so", "that", "they", "can", "be", "used", "in", "other", "projects", "that", "need", "to", "create", "and", "manipulate", "arbitrary", "test", "data", "."], "add_tokens": "TreeNode < String > arrayJava = root . findByPath ( \"src\" , \"org\" , \"math\" , \"Array.java\" ) ; TreeNode < String > matrixJava = root . findByPath ( \"src\" , \"org\" , \"math\" , \"Matrix.java\" ) ; lcaTestCase ( matrixJava , arrayJava , root . findByPath ( \"src\" , \"org\" , \"math\" ) ) ; private TreeNode < String > root = TreeNode . createTestData (", "del_tokens": "TreeNode < String > root = getNode ( \"root\" ) ; TreeNode < String > arrayJava = getNode ( \"root\" , \"src\" , \"org\" , \"math\" , \"Array.java\" ) ; TreeNode < String > matrixJava = getNode ( \"root\" , \"src\" , \"org\" , \"math\" , \"Matrix.java\" ) ; lcaTestCase ( matrixJava , arrayJava , getNode ( \"root\" , \"src\" , \"org\" , \"math\" ) ) ; private TreeNode < String > getNode ( String ... segments ) { return TreeTestData . getByPath ( root , segments ) ; } private TreeNode < String > root = TreeTestData . create (", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "typo", "in", "NodeExample"], "add_tokens": "txId = node . reissueAsset ( alice , assetId , 100 * TOKEN , false , ISSUE_FEE ) ;", "del_tokens": "txId = node . reissueAsset ( alice , assetId , 100 * TOKEN , true , ISSUE_FEE ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "key", "-", "value", "store", "example", "."], "add_tokens": "import net . kuujo . copycat . annotations . Command . Argument ; import net . kuujo . copycat . annotations . StateValue ; @ StateValue public Object get ( @ Argument ( \"key\" ) String key , @ Argument ( value = \"default\" , required = false ) Object defaultValue ) { public boolean set ( @ Argument ( \"key\" ) String key , @ Argument ( \"value\" ) Object value ) { public boolean del ( @ Argument ( \"key\" ) String key ) { Replica replica = new DefaultReplica ( address , vertx , container , this ) ;", "del_tokens": "public Object get ( @ Command . Argument ( \"key\" ) String key , @ Command . Argument ( value = \"default\" , required = false ) Object defaultValue ) { public boolean set ( @ Command . Argument ( \"key\" ) String key , @ Command . Argument ( \"value\" ) Object value ) { public boolean del ( @ Command . Argument ( \"key\" ) String key ) { Replica replica = new DefaultReplica ( address , vertx , this ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "licenses", "to", "the", "project", "."], "add_tokens": "* * * http : //www.apache.org/licenses/LICENSE-2.0 *", "del_tokens": "* < p > * < p > * http : //www.apache.org/licenses/LICENSE-2.0 * < p >", "commit_type": "add"}
{"commit_tokens": ["Allow", "all", "service", "create", "/", "destroy", "bind", "/", "unbind", "methods", "to", "throw", "any", "ServiceBrokerException", "."], "add_tokens": "throws ServiceBrokerException { throws ServiceBrokerException { throws ServiceBrokerException { public String unbindService ( String authToken , String uri ) throws ServiceBrokerException {", "del_tokens": "throws AuthenticationException , BadRequestException { throws AuthenticationException , ResourceNotFoundException { throws AuthenticationException , BadRequestException , ResourceNotFoundException { public String unbindService ( String authToken , String uri ) throws AuthenticationException , ResourceNotFoundException {", "commit_type": "allow"}
{"commit_tokens": ["Adding", "CustomText1", "-", "5", "to", "JobSubmission"], "add_tokens": "import com . bullhornsdk . data . model . entity . customfields . CustomFieldsA ; @ JsonPropertyOrder ( { \"id\" , \"appointments\" , \"billRate\" , \"candidate\" , \"customText1\" , \"customText2\" , \"customText3\" , \"customText4\" , \"customText5\" , \"dateAdded\" , \"dateLastModified\" , \"dateWebResponse\" , \"isDeleted\" , \"isHidden\" , \"jobOrder\" , \"migrateGUID\" , \"payRate\" , \"salary\" , \"sendingUser\" , \"source\" , \"status\" , \"tasks\" } ) public class JobSubmission extends CustomFieldsA implements QueryEntity , UpdateEntity , CreateEntity , SoftDeleteEntity , SearchEntity , DateLastModifiedEntity , EditHistoryEntity {", "del_tokens": "import com . bullhornsdk . data . model . entity . core . type . AbstractEntity ; @ JsonPropertyOrder ( { \"id\" , \"appointments\" , \"billRate\" , \"candidate\" , \"dateAdded\" , \"dateLastModified\" , \"dateWebResponse\" , \"isDeleted\" , \"isHidden\" , \"jobOrder\" , \"migrateGUID\" , \"payRate\" , \"salary\" , \"sendingUser\" , \"source\" , \"status\" , \"tasks\" } ) public class JobSubmission extends AbstractEntity implements QueryEntity , UpdateEntity , CreateEntity , SoftDeleteEntity , SearchEntity , DateLastModifiedEntity , EditHistoryEntity {", "commit_type": "add"}
{"commit_tokens": ["Adding", "option", "to", "dump", "MVs"], "add_tokens": "import org . jcodec . codecs . h264 . io . model . SliceType ; Frame result = createFrame ( activeSps , buffer , firstSliceHeader . frame_num , firstSliceHeader . slice_type , mvs , refsUsed , poc . calcPOC ( firstSliceHeader , firstNu ) ) ; public static Frame createFrame ( SeqParameterSet sps , int [ ] [ ] buffer , int frameNum , SliceType frameType , int [ ] [ ] [ ] [ ] mvs , Frame [ ] [ ] [ ] refsUsed , int POC ) { return new Frame ( width , height , buffer , ColorSpace . YUV420 , crop , frameNum , frameType , mvs , refsUsed , POC ) ;", "del_tokens": "Frame result = createFrame ( activeSps , buffer , firstSliceHeader . frame_num , mvs , refsUsed , poc . calcPOC ( firstSliceHeader , firstNu ) ) ; public static Frame createFrame ( SeqParameterSet sps , int [ ] [ ] buffer , int frame_num , int [ ] [ ] [ ] [ ] mvs , Frame [ ] [ ] [ ] refsUsed , int POC ) { return new Frame ( width , height , buffer , ColorSpace . YUV420 , crop , frame_num , mvs , refsUsed , POC ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "funneling", "strategy", "package", "names"], "add_tokens": "import edu . cmu . lti . oaqa . ecd . flow . strategy . FunnelingStrategy ; import edu . cmu . lti . oaqa . ecd . impl . DefaultFunnelingStrategy ; private FunnelingStrategy getProcessingStrategy ( ) throws ResourceInitializationException { FunnelingStrategy ps = new DefaultFunnelingStrategy ( ) ; ps = BaseExperimentBuilder . loadProvider ( map , FunnelingStrategy . class ) ; FunnelingStrategy ps = getProcessingStrategy ( ) ;", "del_tokens": "import edu . cmu . lti . oaqa . ecd . driver . strategy . DefaultProcessingStrategy ; import edu . cmu . lti . oaqa . ecd . driver . strategy . ProcessingStrategy ; private ProcessingStrategy getProcessingStrategy ( ) throws ResourceInitializationException { ProcessingStrategy ps = new DefaultProcessingStrategy ( ) ; ps = BaseExperimentBuilder . loadProvider ( map , ProcessingStrategy . class ) ; ProcessingStrategy ps = getProcessingStrategy ( ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "humanize", "function", ".", "Now", "don", "t", "splits", "fractional", "numbers", "in", "names"], "add_tokens": "result = result . replaceAll ( \".*\\\\.([^.^0-9]+)\" , \"$1\" ) ; result = result . replaceAll ( \"((.*\\\\D)|(^))\\\\.([0-9][^.]+)\" , \"$4\" ) ;", "del_tokens": "result = result . replaceAll ( \".*\\\\.([^.]+)\" , \"$1\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "very", "embarassing", "bug", "condition", "check", "for", "width", "."], "add_tokens": "if ( width <= 0 || width > maxImageWidth || height <= 0 || height > maxImageHeight ) {", "del_tokens": "if ( width <= 0 && width > maxImageWidth || height <= 0 || height > maxImageHeight ) {", "commit_type": "fix"}
{"commit_tokens": ["adding", "sequences", "from", "sequence", "labeler"], "add_tokens": "//System.err.println(\"parserEventStream.addParseEvents: chunks[\"+ci+\"]=\"+c+\" label=\" +outcome + \" bcg=\" + bcg);", "del_tokens": "//System.err.println(\"parserEventStream.addParseEvents: chunks[\"+ci+\"]=\"+c+\" label=\" +outcome + \" bcg=\" + bcg);", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "date", "type", "variable", "handling", "for", "event", "insert"], "add_tokens": "var = setEventDateVar ( var , isEvent ) ; // if (isEvent && (var.equals(\"pdate\") || var.equals(\"idate\") || var.equals(\"fedate\") | var.equals(\"omdat\") || var.equals(\"mladat\") || var.equals(\"mlrdat\") || var.equals(\"cdate\") || var.equals(\"tdate\") || var.equals(\"hadat\"))) { // var = \"date\"; // } // if (isEvent && (var.equals(\"pdate\") || var.equals(\"idate\") || var.equals(\"fedate\") | var.equals(\"omdat\") || var.equals(\"mladat\") || var.equals(\"mlrdat\") || var.equals(\"cdate\") || var.equals(\"tdate\") || var.equals(\"hadat\"))) { // var = \"date\"; // } if ( isEvent && isDate ( var ) && ! var . equals ( \"edate\" ) ) {", "del_tokens": "if ( isEvent && ( var . equals ( \"pdate\" ) || var . equals ( \"idate\" ) || var . equals ( \"fedate\" ) | var . equals ( \"omdat\" ) || var . equals ( \"mladat\" ) || var . equals ( \"mlrdat\" ) || var . equals ( \"cdate\" ) || var . equals ( \"tdate\" ) || var . equals ( \"hadat\" ) ) ) { var = \"date\" ; } if ( isEvent && ( var . equals ( \"pdate\" ) || var . equals ( \"idate\" ) || var . equals ( \"fedate\" ) | var . equals ( \"omdat\" ) || var . equals ( \"mladat\" ) || var . equals ( \"mlrdat\" ) || var . equals ( \"cdate\" ) || var . equals ( \"tdate\" ) || var . equals ( \"hadat\" ) ) ) {", "commit_type": "update"}
{"commit_tokens": ["added", "config", "method", "on", "NameSubstitutionStrategy"], "add_tokens": "strategy . setup ( getConfig ( ) ) ;", "del_tokens": "if ( strategy instanceof SimpleNameSubstitutionStrategy ) { ( ( SimpleNameSubstitutionStrategy ) strategy ) . setSubstitutionList ( SimpleSubstitutionUtils . getSubstitutionList ( getConfig ( ) ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "ServerPropertiesTests", "on", "OSX"], "add_tokens": "* assertEquals ( InetAddress . getByName ( \"127.0.0.1\" ) , this . properties . getAddress ( ) ) ;", "del_tokens": "* * assertEquals ( InetAddress . getLocalHost ( ) , this . properties . getAddress ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "ambiguity", "class", "to", "pos", "dictionary", "resource"], "add_tokens": "public String getAllTags ( final String word ) { final TreeMultimap < Integer , String > mfTagMap = getOrderedMap ( word ) ; String mfTag = null ; if ( ! mfTagMap . isEmpty ( ) ) { final SortedSet < String > mfTagSet = mfTagMap . get ( mfTagMap . keySet ( ) . first ( ) ) ; mfTag = mfTagSet . first ( ) ; } else { mfTag = \"O\" ; } return mfTag ; } + entry . getValue ( ) + \"\\n\" ) ;", "del_tokens": "+ entry . getValue ( ) . get ( entry . getKey ( ) ) + \"\\n\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "build", "&", "adding", "bare", "minimum", "for", "deserialization"], "add_tokens": "Assert . assertEquals ( \"1\" , pi . getGuid ( ) ) ;", "del_tokens": "Assert . assertEquals ( 1 , pi . getGuid ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "to", "set", "correct", "attributest", "when", "using", "ExternalTerminal", "on", "windows"], "add_tokens": "ExternalTerminal term = new ExternalTerminal ( name , type , System . in , System . out , encoding ) ; Attributes attributes = new Attributes ( ) ; attributes . setInputFlag ( Attributes . InputFlag . IGNCR , true ) ; attributes . setInputFlag ( Attributes . InputFlag . ICRNL , true ) ; term . setAttributes ( attributes ) ; return term ;", "del_tokens": "return new ExternalTerminal ( name , type , System . in , System . out , encoding ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "missing", "throw", "."], "add_tokens": "throw new KsonParseException ( \"nested arrays not supported\" , in ) ;", "del_tokens": "new KsonParseException ( \"nested arrays not supported\" , in ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "configure", "threads", "priority", "for", "image", "loading", "tasks"], "add_tokens": "Thread displayImageTask = new Thread ( new DisplayImageTask ( imageLoadingInfo ) ) ; displayImageTask . setPriority ( configuration . threadPriority ) ; imageLoadingExecutor . submit ( displayImageTask ) ;", "del_tokens": "imageLoadingExecutor . submit ( new DisplayImageTask ( imageLoadingInfo ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "CRC32", "(", "PKZIP", "style", ")", "checksums", "to", "the", "header", "and", "chunks", "in", "the", "table", "save", "files", ".", "Restore", "might", "be", "a", "bit", "slower", "because", "it", "is", "stupidly", "doing", "the", "CRC", "byte", "by", "byte", ".", "Might", "need", "to", "optimize", "that", "by", "going", "back", "to", "heap", "byte", "buffers", "or", "better", "yet", "punting", "the", "direct", "buffers", "to", "C", "for", "CRCing", "."], "add_tokens": "* Copyright ( C ) 2008 - 2009 VoltDB L . L . C . private static final Logger hostLog = Logger . getLogger ( \"HOST\" , VoltLoggerFactory . instance ( ) ) ; final long startTime = System . currentTimeMillis ( ) ; final long endTime = System . currentTimeMillis ( ) ; final long duration = endTime - startTime ; results = performSnapshotDeleteWork ( paths , nonces ) ; hostLog . info ( \"Finished deleting snapshots. Took \" + duration + \" milliseconds\" ) ; return results ; }", "del_tokens": "* Copyright ( C ) 2008 - 2010 VoltDB L . L . C . return performSnapshotDeleteWork ( paths , nonces ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "class", "(", "JettyServer", ")", "to", "run", "the", "server", "as", "a", "standalone", "Java", "process", ".", "This", "makes", "it", "easy", "to", "develop", "&", "debug", "without", "having", "to", "bother", "wit", "a", "servlet", "container", "."], "add_tokens": "private HashMap < String , DataSource > dataSources = new HashMap < > ( ) ; String applicationPathStr = servletConfig . getServletContext ( ) . getRealPath ( \"/\" ) ; if ( applicationPathStr == null ) { // this can happen when running standalone applicationPathStr = System . getProperty ( \"user.dir\" ) ; } final File applicationPath = new File ( applicationPathStr ) ; final String contextPath = request . getContextPath ( ) ; final String requestURI = request . getRequestURI ( ) ; final String path = contextPath == null ? requestURI : requestURI . substring ( contextPath . length ( ) ) ;", "del_tokens": "private HashMap < String , DataSource > dataSources = new HashMap < String , DataSource > ( ) ; final File applicationPath = new File ( servletConfig . getServletContext ( ) . getRealPath ( \"/\" ) ) ; final String path = request . getRequestURI ( ) . substring ( request . getContextPath ( ) . length ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "unit", "test", "for", "the", "PluginAction", "logic"], "add_tokens": "static final public class PluginInfo { private final String version = \"1.0.0\" ; static final public class ProjectsList { return \"Octane CI Data Provider\" ;", "del_tokens": "public class PluginInfo { private final String version = \"1.2\" ; public class ProjectsList { return null ;", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "to", "save", "small", "objects", "to", "String"], "add_tokens": "import com . google . gson . GsonBuilder ; public static void writeUpdateInventoryRequest ( OutputStream out , UpdateInventoryRequest message ) throws IOException { public static void writeProjects ( OutputStream out , List < AgentProjectInfo > projects ) throws IOException { public static < T > String save ( T object , boolean pretty ) { Gson gson ; if ( pretty ) { gson = ( new GsonBuilder ( ) ) . setPrettyPrinting ( ) . create ( ) ; } else { gson = ( new GsonBuilder ( ) ) . create ( ) ; } return gson . toJson ( object ) ; }", "del_tokens": "public void writeUpdateInventoryRequest ( OutputStream out , UpdateInventoryRequest message ) throws IOException { public void writeProjects ( OutputStream out , List < AgentProjectInfo > projects ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["remove", "sketchy", "recursive", "pull", "and", "case", "where", "we", "fail", "silently", "we", "log", "now"], "add_tokens": "log . error ( \"Pull failed\" , ex ) ;", "del_tokens": "// Trigger another pull pull ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "entities", "starting", "work", "on", "selectors"], "add_tokens": "public class AppTest { //extends TestCase { /* */ / * * * //* * //** * //* * //** * //* } * /", "del_tokens": "import junit . framework . Test ; import junit . framework . TestCase ; import junit . framework . TestSuite ; public class AppTest extends TestCase { / * * * / / * * * / / * * * / }", "commit_type": "add"}
{"commit_tokens": ["changed", "reqeustAccessToken", "to", "generateAccessToken", "and", "added", "refresh", "token", "endpoints"], "add_tokens": "User user = kiteConnect . generateSession ( \"xxxyyyyzzzzzz\" , \"xxxxxxx\" ) ;", "del_tokens": "User user = kiteConnect . requestAccessToken ( \"xxxyyyyzzzzzz\" , \"xxxxxxx\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Removing", "cache", "from", "awesome", "oscillator"], "add_tokens": "* Awesome oscillator . ( AO ) * @ see http : //www.forexgurus.co.uk/indicators/awesome-oscillator public class AwesomeOscillatorIndicator implements Indicator < Double > { public Double getValue ( int index ) {", "del_tokens": "* Awesome ( ? ) oscillator . public class AwesomeOscillatorIndicator extends CachedIndicator < Double > { protected Double calculate ( int index ) {", "commit_type": "remove"}
{"commit_tokens": ["add", "counter", "to", "rate", "conversion"], "add_tokens": "import com . google . common . collect . ImmutableList ; List < AnnotatedAttribute > attributes = AnnotationUtils . getMonitoredAttributes ( obj ) ; ImmutableList . Builder < AnnotatedAttribute > builder = ImmutableList . builder ( ) ; for ( AnnotatedAttribute attr : attributes ) { builder . add ( attr . copy ( tags ) ) ; } attrs = builder . build ( ) ;", "del_tokens": "attrs = AnnotationUtils . getMonitoredAttributes ( obj ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "buddy", "message", "bug", "and", "add", "budy", "change", "state", "handler"], "add_tokens": "import com . tvd12 . ezyfox . core . model . ApiBaseUser ; User recipient = ( User ) event . getParameter ( SFSEventParam . RECIPIENT ) ; buddyMessage . setSender ( ( ApiBaseUser ) sfsUser . getProperty ( APIKey . USER ) ) ; buddyMessage . setRecipient ( ( ApiBaseUser ) recipient . getProperty ( APIKey . USER ) ) ;", "del_tokens": "import com . tvd12 . ezyfox . core . model . ApiUser ; import com . tvd12 . ezyfox . sfs2x . model . impl . ApiBuddyImpl ; ApiBuddyImpl recipient = ( ApiBuddyImpl ) event . getParameter ( SFSEventParam . RECIPIENT ) ; buddyMessage . setSender ( ( ApiUser ) sfsUser . getProperty ( APIKey . USER ) ) ; buddyMessage . setRecipient ( recipient . getUser ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "complex", "custom", "types"], "add_tokens": "{ return getCustomClasses ( schema , _customTypeLanguage ) ; } public static CustomClasses getCustomClasses ( DataSchema schema , String customTypeLanguage ) if ( customTypeLanguage != null ) { final Object java = properties . get ( customTypeLanguage ) ; public static class CustomClasses public ClassTemplateSpec customClass ; public ClassTemplateSpec customCoercerClass ;", "del_tokens": "if ( _customTypeLanguage != null ) { final Object java = properties . get ( _customTypeLanguage ) ; private static class CustomClasses private ClassTemplateSpec customClass ; private ClassTemplateSpec customCoercerClass ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "rolling", "config", "to", "advance", "even", "if", "the", "local", "server", "is", "at", "NOT_SERVING", ".", "There", "are", "cases", "where", "this", "is", "correct", "(", "lack", "of", "quorum", "etc", ".", ")", "."], "add_tokens": "if ( ( instanceState . getState ( ) == InstanceStateTypes . SERVING ) || ( instanceState . getState ( ) == InstanceStateTypes . NOT_SERVING ) ) { advanceRollingConfig ( localConfig ) ; }", "del_tokens": "advanceRollingConfig ( localConfig ) ;", "commit_type": "allow"}
{"commit_tokens": ["use", "default", "cache", "size", "for", "h2"], "add_tokens": "\"/metric;mode=mysql;db_close_on_exit=false\" ;", "del_tokens": "\"/metric;mode=mysql;cache_size=0;db_close_on_exit=false\" ;", "commit_type": "use"}
{"commit_tokens": ["Use", "api", ".", "*", "for", "HTTP", "PUT", "and", "data", ".", "*", "for", "Token", "TCP", ".", "Added", "tests"], "add_tokens": "/** Logentries API server address for Token-based input. */ private static final String LE_TOKEN_API = \"data.logentries.com\" ; /** Logentries API server address for HTTP PUT input. */ private static final String LE_HTTP_API = \"api.logentries.com\" ; public int getPort ( ) { if ( ssl_choice ) return http_choice ? LE_HTTP_SSL_PORT : LE_TOKEN_TLS_PORT ; else return http_choice ? LE_HTTP_PORT : LE_TOKEN_PORT ; } public String getAddress ( ) { return http_choice ? LE_HTTP_API , LE_TOKEN_API ; } SSLSocket s = ( SSLSocket ) ssl_factory . createSocket ( getAddress ( ) , getPort ( ) ) ; socket = SSLSocketFactory . getDefault ( ) . createSocket ( getAddress ( ) , getPort ( ) ) ; socket = new Socket ( getAddress ( ) , getPort ( ) ) ;", "del_tokens": "/** Logentries API server address. */ private static final String LE_API = \"data.logentries.com\" ; SSLSocket s = ( SSLSocket ) ssl_factory . createSocket ( LE_API , LE_HTTP_SSL_PORT ) ; socket = SSLSocketFactory . getDefault ( ) . createSocket ( LE_API , LE_TOKEN_TLS_PORT ) ; int port = http_choice ? LE_HTTP_PORT : LE_TOKEN_PORT ; socket = new Socket ( LE_API , port ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "use", "of", "CURIs", "to", "select", "embedded", "items"], "add_tokens": "* Representation used to parse and create HAL + JSON documents from Java classes . * Creates a HalRepresentation having { @ link Links } * Creates a HalRepresentation with { @ link Links } and { @ link Embedded } objects . * * If the Links do contain CURIs , the link - relation types of the embedded objects are shortened . this . embedded = embedded . isEmpty ( ) ? null : embedded . withCuries ( getLinks ( ) . getLinksBy ( \"curies\" ) ) ; * Returns the Links of the HalRepresentation . / * * * Returns the Embedded objects of the HalRepresentation . * * @ return Embedded , possibly beeing { @ link Embedded # isEmpty ( ) empty } * / return embedded != null ? embedded . withCuries ( getLinks ( ) . getLinksBy ( \"curies\" ) ) : emptyEmbedded ( ) ;", "del_tokens": "* this . embedded = embedded . isEmpty ( ) ? null : embedded ; return embedded != null ? embedded : emptyEmbedded ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "type", "coercion", "tests", "still", "incomplete"], "add_tokens": "@ Step ( \"I can coerce a value (.*) to an int\" ) @ Step ( \"I can coerce a value (.*) to an Integer\" ) @ Step ( \"I can coerce a value (.*) to a byte\" ) @ Step ( \"I can coerce a value (.*) to a Byte\" ) @ Step ( \"I can coerce a value (.*) to a char\" ) @ Step ( \"I can coerce a value (.*) to a Character\" )", "del_tokens": "@ Step ( \"I can coerce a value (\\\\d) to an int\" ) @ Step ( \"I can coerce a value (\\\\d) to an Integer\" ) @ Step ( \"I can coerce a value (\\\\w) to a byte\" ) @ Step ( \"I can coerce a value b to a Byte\" ) @ Step ( \"I can coerce a value a to a char\" ) @ Step ( \"I can coerce a value b to a Character\" )", "commit_type": "fix"}
{"commit_tokens": ["added", "list", "(", "PrintStream", ")"], "add_tokens": "InvocationHandler handler = new PropertiesInvocationHandler ( loadPropertiesFor ( clazz ) ) ;", "del_tokens": "InvocationHandler handler = new PropertyInvocationHandler ( loadPropertiesFor ( clazz ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "order", "of", "spawning", "of", "PDUReaderWorker", "thread", ".", "It", "start", "after", "asssign", "value", "of", "Socker", ".", "inputStream", "to", "SMPPSession", ".", "in", "becuase", "the", "PDUReaderWorker", "will", "need", "those", "value", "."], "add_tokens": "new PDUReaderWorker ( ) . start ( ) ; new PDUReaderWorker ( ) . start ( ) ; new PDUReaderWorker ( ) . start ( ) ;", "del_tokens": "new PDUReaderWorker ( ) . start ( ) ; new PDUReaderWorker ( ) . start ( ) ; new PDUReaderWorker ( ) . start ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "util", "package", "after", "change", "openapi", "update"], "add_tokens": "return new Watch < > ( client . getJSON ( ) , response . body ( ) , watchType ) ;", "del_tokens": "return new Watch < > ( new JSON ( client ) , response . body ( ) , watchType ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "main", "method", "into", "AbstractSuite", "class", "so", "that", "all", "suite", "classes", "can", "be", "framework", "entry", "point"], "add_tokens": "public final class SystemConfiguration { + SYSPROP_TEST_SUITE + \")\" ) ; public void setTestSuite ( String suiteClassName ) { this . properties . setProperty ( SYSPROP_TEST_SUITE , suiteClassName ) ; } public void listAppProperties ( ) { LOG . debug ( \"Application properties\" ) ; List < String > keys = new ArrayList < > ( this . properties . stringPropertyNames ( ) ) ; Collections . sort ( keys ) ; keys . stream ( ) . forEach ( ( key ) -> { LOG . debug ( String . format ( \"%50s : %s\" , key , this . properties . getProperty ( key ) ) ) ; } ) ; }", "del_tokens": "public class SystemConfiguration { this . listAppProperties ( ) ; + SYSPROP_TEST_SUITE + \")\" ) ; private void listAppProperties ( ) { LOG . debug ( \"Application properties\" ) ; List < String > keys = new ArrayList < > ( this . properties . stringPropertyNames ( ) ) ; Collections . sort ( keys ) ; keys . stream ( ) . forEach ( ( key ) -> { LOG . debug ( String . format ( \"%50s : %s\" , key , this . properties . getProperty ( key ) ) ) ; } ) ; } private String getLocalJobName ( ) { return this . getHostName ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Removed", "final", "for", "enabling", "inclusion", "with", "CDI", "later", "."], "add_tokens": "public class DefaultRoundingProvider implements", "del_tokens": "public final class DefaultRoundingProvider implements", "commit_type": "remove"}
{"commit_tokens": ["Add", "basic", "converter", "for", "requests", "of", "old", "API"], "add_tokens": "assertEquals ( \"A4 Portrait\" , layout . getString ( \"name\" ) ) ;", "del_tokens": "assertEquals ( \"A4 Landscape\" , layout . getString ( \"name\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "CSVStreamSource", "configurable", "using", "XML"], "add_tokens": "import com . airhacks . enhydrator . in . CSVStreamSource ; CSVFileSource . class , CSVStreamSource . class , VirtualSinkSource . class ,", "del_tokens": "CSVFileSource . class , VirtualSinkSource . class ,", "commit_type": "make"}
{"commit_tokens": ["Fix", "minor", "concurrency", "issue", ";", "Enhance", "error", "logs"], "add_tokens": "private long currentPollingInterval ; try { if ( listenerTask != null ) { listenerTask . interrupt ( ) ; listenerTask . join ( 2 * currentPollingInterval ) ; listenerTask = null ; } } catch ( InterruptedException e ) { log . error ( \"Unable to with for 'listenerTask' to die.\" , e ) ;", "del_tokens": "private long currentPollingInterval = DEFAULT_POLLING_INTERVAL ; if ( listenerTask != null ) { listenerTask . interrupt ( ) ; listenerTask = null ;", "commit_type": "fix"}
{"commit_tokens": ["Moving", "migration", "code", "to", "seperate", "class", "for", "better", "testing", "and", "easier", "removal", "in", "a", "number", "of", "months"], "add_tokens": "import android . app . AlertDialog ; import android . content . DialogInterface ; import android . widget . Toast ;", "del_tokens": "public static void logOrError ( Activity activity , Exception exception ) { if ( Utility . isDebugable ( activity ) ) { throw new IllegalStateException ( exception ) ; } else { Log . e ( UberSdk . UBER_SDK_LOG_TAG , exception . getMessage ( ) , exception ) ; } }", "commit_type": "move"}
{"commit_tokens": ["added", "review", "suggestions", "to", "BailErrorSyntaxStrategie"], "add_tokens": "* This ErrorStrategy throws an exception if the syntax is not matching the expected GDL language , but in * gets executed . public Token recoverInline ( Parser recognizer ) throws RecognitionException { / * * * Make sure we don 't attempt to recover from problems in subrules. * /", "del_tokens": "* This ErrorStrategy throws an exception if the syntax is not matching the expected GDL language , but , in * get executed public Token recoverInline ( Parser recognizer ) throws RecognitionException { /** Make sure we don't attempt to recover from problems in subrules. */", "commit_type": "add"}
{"commit_tokens": ["Added", "JavaSerialization", "for", "comparison", "with", "KryoSerialization", "."], "add_tokens": "import java . io . Serializable ; @ SuppressWarnings ( \"serial\" ) public static class Mock2 implements Serializable @ SuppressWarnings ( \"serial\" ) KryoSerializer < Object > ser = new KryoSerializer < Object > ( ) ; JavaSerializer < Object > serJ = new JavaSerializer < Object > ( ) ; byte [ ] dataJ = serJ . serialize ( o ) ; assertTrue ( dataJ . length > data . length ) ; JavaSerializer < Object > serJ = new JavaSerializer < Object > ( ) ; byte [ ] dataJ = serJ . serialize ( o ) ; assertTrue ( dataJ . length > data . length ) ;", "del_tokens": "public static class Mock2 KryoSerializer < Object > ser = new KryoSerializer < Object > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "multiline", "string", "field", "in", "json"], "add_tokens": "String sb = createSetFromValues ( values ) ; private String createSetFromValues ( Object [ ] values ) throws DataSetException { Object currentValue = values [ i ] ; if ( currentValue == null ) { } sb . append ( FOUR_SPACES + DOUBLE_SPACES + '\"' ) . append ( metaData . getColumns ( ) [ i ] . getColumnName ( ) ) . append ( \"\\\": \" ) ; sb . append ( currentValue . toString ( ) . replaceAll ( NEW_LINE , \"\\\\\\\\n\" ) ) ;", "del_tokens": "String sb = createSetFromColumnValues ( values ) ; private String createSetFromColumnValues ( Object [ ] values ) throws DataSetException { if ( values [ i ] == null ) { } sb . append ( FOUR_SPACES + DOUBLE_SPACES + \"\\\"\" ) . append ( metaData . getColumns ( ) [ i ] . getColumnName ( ) ) . append ( \"\\\": \" ) ; sb . append ( values [ i ] . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "version", "to", "mirror", "Jackson", "dependency"], "add_tokens": "assertEquals ( version . getMinorVersion ( ) , 9 ) ;", "del_tokens": "assertEquals ( version . getMinorVersion ( ) , 6 ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", "synchronization", "level", "to", "a", "private", "lock", "on", "getChangeSupport", "method"], "add_tokens": "* @ author George Waldon - private lock on synchronization private final Object changeLock = new Object ( ) ; synchronized ( changeLock ) {", "del_tokens": "synchronized ( this ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "configuration", "for", "the", "EclipseHack", "test", "."], "add_tokens": "@ Override public Set < String > getSupportedOptions ( ) { return ImmutableSet . of ( EclipseHack . ENABLING_OPTION ) ; }", "del_tokens": "import javax . annotation . processing . SupportedOptions ; // I have avoided using any classes from Guava here for fear of future circularity problems. @ SupportedOptions ( EclipseHack . ENABLING_OPTION )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "squid", ":", "S1118", "squid", ":", "S1197"], "add_tokens": "String [ ] ous = { basePeopleDn , baseGroupDn } ; String [ ] subFolders = { instanceName + \"/avatars\" } ;", "del_tokens": "String ous [ ] = { basePeopleDn , baseGroupDn } ; String subFolders [ ] = { instanceName + \"/avatars\" } ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "some", "test", "on", "bad", "dataset", "with", "composite", "type"], "add_tokens": "try { columnModel . setName ( new GenericType ( StringUtils . split ( parsedColumn . getName ( ) , \":\" ) , typesBelongingCompositeTypeForComparatorType ) ) ; } catch ( IllegalArgumentException e ) { throw new ParseException ( parsedColumn . getName ( ) + \" doesn't fit with the schema declaration of your composite type\" ) ; }", "del_tokens": "columnModel . setName ( new GenericType ( StringUtils . split ( parsedColumn . getName ( ) , \":\" ) , typesBelongingCompositeTypeForComparatorType ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "-", "4", ".", "Make", "scenario", "display", "name", "JUnit", "-", "safe", "."], "add_tokens": "Description scenarioDescription = Description . createSuiteDescription ( \"Scenario: \" + getJunitSafeString ( scenario . getTitle ( ) ) ) ; return uniq . getUniqueDescription ( string . replaceAll ( \"\\r\" , \"\\n\" ) . replaceAll ( \"\\n{2,}\" , \"\\n\" ) . replaceAll ( \"\\n\" , \", \" ) . replaceAll ( \"[\\\\(\\\\)]\" , \"|\" ) ) ;", "del_tokens": "Description scenarioDescription = Description . createSuiteDescription ( \"Scenario: \" + scenario . getTitle ( ) ) ; return uniq . getUniqueDescription ( string . replaceAll ( \"\\n\" , \", \" ) . replaceAll ( \"[\\\\(\\\\)]\" , \"|\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unused", "reference", "to", "(", "soap", ")", "attribute", "map"], "add_tokens": "import javax . xml . soap . SOAPElement ; import javax . xml . soap . SOAPEnvelope ; import javax . xml . soap . SOAPException ; import javax . xml . soap . SOAPHeader ; import javax . xml . soap . SOAPHeaderElement ; import javax . xml . soap . SOAPMessage ;", "del_tokens": "import org . w3c . dom . NamedNodeMap ; import javax . xml . soap . * ; NamedNodeMap namedNodeMap = childNode . getAttributes ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "a", "stream", "to", "convert", "arbitary", "Map", "to", "SassMap", "."], "add_tokens": "import java . util . function . BinaryOperator ; return ( ( Map < ? , ? > ) value ) . entrySet ( ) . stream ( ) . collect ( Collectors . toMap ( entry -> entry . getKey ( ) . toString ( ) , entry -> TypeUtils . convertToSassValue ( entry . getValue ( ) ) , ( origin , duplicate ) -> origin , SassMap :: new ) ) ;", "del_tokens": "SassMap map = new SassMap ( ) ; for ( Map . Entry < ? , ? > entry : ( ( Map < ? , ? > ) value ) . entrySet ( ) ) { String key = entry . getKey ( ) . toString ( ) ; SassValue item = TypeUtils . convertToSassValue ( entry . getValue ( ) ) ; map . put ( key , item ) ; } return map ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "incorrectly", "registering", "String", "or", "a", "primitive", "type", "."], "add_tokens": "* If the class is already registered , the serializer will be changed . RegisteredClass existingRegisteredClass = classToRegisteredClass . get ( type ) ; if ( existingRegisteredClass != null && existingRegisteredClass . id >= 1 && existingRegisteredClass . id <= 17 ) { if ( WARN ) warn ( \"Registration unnecessary, class is registered by default: \" + type . getName ( ) ) ; return ; }", "del_tokens": "* A serializer may not be registered with more than one Kryo instance .", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "view", "portions"], "add_tokens": "new AddBookmark ( \"user\" , \"item\" ) . setTimestamp ( new Date ( 0 ) ) , new SetViewPortion ( \"user\" , \"item\" , 1 ) . setTimestamp ( new Date ( 0 ) )", "del_tokens": "new AddBookmark ( \"user\" , \"item\" ) . setTimestamp ( new Date ( 0 ) )", "commit_type": "add"}
{"commit_tokens": ["using", "Type", "Parameter", "Naming", "Conventions", "(", "https", ":", "//", "docs", ".", "oracle", ".", "com", "/", "javase", "/", "tutorial", "/", "java", "/", "generics", "/", "types", ".", "html", ")"], "add_tokens": "* you may not use this file eTcept in compliance with the License . * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either eTpress or implied . public < T > T fromJson ( String json , Class < T > classOfT ) { return JSON . parseObject ( json , classOfT ) ;", "del_tokens": "* you may not use this file except in compliance with the License . * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . public < X > X fromJson ( String json , Class < X > xClass ) { return JSON . parseObject ( json , xClass ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "to", "the", "new", "exceptions", "."], "add_tokens": "import org . springframework . ldap . NameNotFoundException ; throw new NameNotFoundException ( \"Could not find group with name '\"", "del_tokens": "import org . springframework . ldap . support . EntryNotFoundException ; throw new EntryNotFoundException ( \"Could not find group with name '\"", "commit_type": "change"}
{"commit_tokens": ["Added", "graceful", "shutdown", "and", "cleaned", "up", "the", "shutdown", "procedure", "a", "bit", "."], "add_tokens": "assert line . equals ( \"OK\" ) : \"Expected OK, was \" + line ;", "del_tokens": "assert line . equals ( \"OK\" ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "ambiguity", "class", "features", "for", "pos", "tagging"], "add_tokens": "//final String posTag = this.posDictionary // .getMostFrequentTag(tokens[index].toLowerCase()); final String ambiguityClass = this . posDictionary . getAmbiguityClass ( tokens [ index ] . toLowerCase ( ) ) ; features . add ( this . attributes . get ( \"dict\" ) + \"=\" + ambiguityClass ) ;", "del_tokens": "final String posTag = this . posDictionary . getMostFrequentTag ( tokens [ index ] . toLowerCase ( ) ) ; features . add ( this . attributes . get ( \"dict\" ) + \"=\" + posTag ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "message", "in", "getById", "to", "reflect", "that", "the", "operation", "is", "get", "not", "delete"], "add_tokens": "throw new IllegalArgumentException ( \"Must supply an id to retrieve!\" ) ; if ( id == null ) throw new IllegalArgumentException ( \"Cannot delete a null id!\" ) ;", "del_tokens": "throw new IllegalArgumentException ( \"Cannot delete with a null id!\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "trailing", "slashes", "from", "elasticsearch", "url"], "add_tokens": "import java . util . * ; final String url = getString ( \"stagemonitor.elasticsearch.url\" ) ; if ( url . endsWith ( \"/\" ) ) { return url . substring ( 0 , url . length ( ) - 1 ) ; } return url ;", "del_tokens": "import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . Properties ; return getString ( \"stagemonitor.elasticsearch.url\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "listening", "on", "HTTPS"], "add_tokens": "import com . google . common . base . Strings ; import org . eclipse . jetty . util . ssl . SslContextFactory ; static final String PROPERTY_S3PROXY_KEYSTORE_PATH = \"s3proxy.keystore-path\" ; static final String PROPERTY_S3PROXY_KEYSTORE_PASSWORD = \"s3proxy.keystore-password\" ; String credential , String keyStorePath , String keyStorePassword ) { ServerConnector connector ; if ( endpoint . getScheme ( ) . equals ( \"https\" ) ) { SslContextFactory sslContextFactory = new SslContextFactory ( ) ; sslContextFactory . setKeyStorePath ( keyStorePath ) ; sslContextFactory . setKeyStorePassword ( keyStorePassword ) ; connector = new ServerConnector ( server , sslContextFactory , httpConnectionFactory ) ; } else { connector = new ServerConnector ( server , httpConnectionFactory ) ; } String keyStorePath = properties . getProperty ( PROPERTY_S3PROXY_KEYSTORE_PATH ) ; String keyStorePassword = properties . getProperty ( PROPERTY_S3PROXY_KEYSTORE_PASSWORD ) ; if ( s3ProxyEndpointString . startsWith ( \"https\" ) ) { if ( Strings . isNullOrEmpty ( keyStorePath ) || Strings . isNullOrEmpty ( keyStorePassword ) ) { System . err . println ( \"Both \" + PROPERTY_S3PROXY_KEYSTORE_PATH + \" and \" + PROPERTY_S3PROXY_KEYSTORE_PASSWORD + \" must be set with an HTTP endpoint\" ) ; System . exit ( 1 ) ; } } localIdentity , localCredential , keyStorePath , keyStorePassword ) ;", "del_tokens": "String credential ) { ServerConnector connector = new ServerConnector ( server , httpConnectionFactory ) ; localIdentity , localCredential ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "cloud", "option", "when", "creating", "client", "instance"], "add_tokens": "if ( cloud != null ) { userOptions . put ( \"cloud\" , cloud ) ; } loadConfiguration ( \"iron\" , \"mq\" , userOptions , new String [ ] { \"project_id\" , \"token\" , \"cloud\" } ) ; if ( userOptions . containsKey ( \"cloud\" ) ) { Object cloudOption = userOptions . get ( \"cloud\" ) ; if ( cloudOption != null && cloudOption instanceof Cloud ) { cloud = ( Cloud ) cloudOption ; } } else { cloud = new Cloud ( ( String ) getOption ( \"scheme\" ) , ( String ) getOption ( \"host\" ) , ( ( Number ) getOption ( \"port\" ) ) . intValue ( ) ) ; }", "del_tokens": "loadConfiguration ( \"iron\" , \"mq\" , userOptions , new String [ ] { \"project_id\" , \"token\" } ) ; cloud = new Cloud ( ( String ) getOption ( \"scheme\" ) , ( String ) getOption ( \"host\" ) , ( ( Number ) getOption ( \"port\" ) ) . intValue ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "basic", "spring", "linkage", "/", "beanfactory", "type", "tests"], "add_tokens": "import org . springframework . context . ApplicationContext ; import static org . assertj . core . api . Assertions . assertThat ; public static void ensureSpringSingleton ( final ApplicationContext context , final Class < ? > beanClazz ) { final Object bean1 = context . getBean ( beanClazz ) ; final Object bean2 = context . getBean ( beanClazz ) ; assertThat ( bean1 ) . isEqualTo ( bean2 ) ; } public static void ensureSpringPrototype ( final ApplicationContext context , final Class < ? > beanClazz ) { final Object bean1 = context . getBean ( beanClazz ) ; final Object bean2 = context . getBean ( beanClazz ) ; assertThat ( bean1 ) . isNotEqualTo ( bean2 ) ;", "del_tokens": "import javafx . scene . Scene ; import javafx . scene . control . Button ; import javafx . scene . layout . Pane ; import javafx . stage . Stage ; public static Button fillTestStage ( final Stage stage ) { final Button testButton = new Button ( \"TEST\" ) ; final Pane testPane = new Pane ( testButton ) ; final Scene testScene = new Scene ( testPane ) ; stage . setScene ( testScene ) ; return testButton ;", "commit_type": "add"}
{"commit_tokens": ["allow", "bundlecontext", "detection", "even", "when", "the", "no", "-", "arg", "constructor", "is", "used"], "add_tokens": "import javax . servlet . * ; } @ Override public void init ( ServletConfig pConfig ) throws ServletException { // If no bundle context was provided, we are looking up the servlet context // for the bundlect context, which will be available usually in servlet extender if ( bundleContext == null ) { // try to lookup bundle context from the servlet context ServletContext servletContext = pConfig . getServletContext ( ) ; bundleContext = ( BundleContext ) servletContext . getAttribute ( \"osgi-bundlecontext\" ) ; } // If there is a bundle context available, set up a tracker for tracking the logging // service", "del_tokens": "import javax . servlet . ServletConfig ; import javax . servlet . ServletException ; } @ Override public void init ( ServletConfig pConfig ) throws ServletException {", "commit_type": "allow"}
{"commit_tokens": ["Use", "setTransactionWriteNoSync", "in", "examples", "because", "it", "is", "safer", "."], "add_tokens": "* builder . setTransactionWriteNoSync ( true ) ;", "del_tokens": "* builder . setTransactionNoSync ( true ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "English", "literal", "to", "test", "cases"], "add_tokens": "movieList = tmdb . searchMovie ( \"Star Wars\" , 0 , LANGUAGE_ENGLISH , false , 0 ) ; MovieDb result = tmdb . getMovieInfo ( ID_MOVIE_BLADE_RUNNER , LANGUAGE_ENGLISH ) ; List < MovieList > results = tmdb . getMovieLists ( ID_MOVIE_BLADE_RUNNER , LANGUAGE_ENGLISH , 0 ) ;", "del_tokens": "movieList = tmdb . searchMovie ( \"Star Wars\" , 0 , \"en\" , false , 0 ) ; String language = \"en\" ; MovieDb result = tmdb . getMovieInfo ( ID_MOVIE_BLADE_RUNNER , language ) ; String language = \"en\" ; List < MovieList > results = tmdb . getMovieLists ( ID_MOVIE_BLADE_RUNNER , language , 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "new", "search", "dialog", "to", "be", "able", "to", "test", "this", "with", "selendroid"], "add_tokens": "* Demo project to verify selendroid actions . public void showSearchDialog ( View view ) { Intent nextScreen = new Intent ( getApplicationContext ( ) , SearchUsersActivity . class ) ; startActivity ( nextScreen ) ; }", "del_tokens": "* Demo project to verify NativeAndroidDriver actions .", "commit_type": "add"}
{"commit_tokens": ["Add", "256", "&", "512", "speed", "options", "to", "simulation"], "add_tokens": "if ( speed < 512f ) {", "del_tokens": "if ( speed < 128f ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "function", "to", "resolve", "old", "deployer", "pid"], "add_tokens": "long firstPid = findOldDeployerPid ( deployerName ) ; if ( firstPid > 0 ) {", "del_tokens": "Sigar sigar = new Sigar ( ) ; ProcessQuery q = ProcessQueryFactory . getInstance ( ) . getQuery ( \"Env.\" + ENV_DEPLOYER_NAME + \".eq=\" + deployerName ) ; long minStart = Long . MAX_VALUE ; long firstPid = 0 ; long [ ] pids = q . find ( sigar ) ; if ( pids . length > 1 ) { for ( long pid : pids ) { ProcTime time = sigar . getProcTime ( pid ) ; if ( time . getStartTime ( ) < minStart ) { minStart = time . getStartTime ( ) ; firstPid = pid ; } }", "commit_type": "use"}
{"commit_tokens": ["remove", "spring", "as", "prefix", "from", "configuration", "-", "properties"], "add_tokens": "@ ConfigurationProperties ( prefix = \"async.executor\" )", "del_tokens": "@ ConfigurationProperties ( prefix = \"spring.async.executor\" )", "commit_type": "remove"}
{"commit_tokens": ["adding", "a", "synchronous", "version", "of", "the", "createToken", "method", "that", "can", "be", "used", "in", "rx", "connections"], "add_tokens": "import com . stripe . exception . APIConnectionException ; import com . stripe . exception . APIException ; import com . stripe . exception . CardException ; import com . stripe . exception . InvalidRequestException ; public Token createTokenSynchronous ( final Card card ) throws AuthenticationException , InvalidRequestException , APIConnectionException , CardException , APIException { return createTokenSynchronous ( card , defaultPublishableKey ) ; } public Token createTokenSynchronous ( Card card , String publishableKey ) throws AuthenticationException , InvalidRequestException , APIConnectionException , CardException , APIException { validateKey ( publishableKey ) ; RequestOptions requestOptions = RequestOptions . builder ( ) . setApiKey ( publishableKey ) . build ( ) ; com . stripe . model . Token stripeToken = com . stripe . model . Token . create ( hashMapFromCard ( card ) , requestOptions ) ; com . stripe . model . Card stripeCard = stripeToken . getCard ( ) ; Card resultCard = androidCardFromStripeCard ( stripeCard ) ; return androidTokenFromStripeToken ( resultCard , stripeToken ) ; // try { // validateKey(publishableKey); // // RequestOptions requestOptions = RequestOptions.builder() // .setApiKey(publishableKey).build(); // com.stripe.model.Token stripeToken = com.stripe.model.Token.create( // hashMapFromCard(card), requestOptions); // com.stripe.model.Card stripeCard = stripeToken.getCard(); // Card resultCard = androidCardFromStripeCard(stripeCard); // return androidTokenFromStripeToken(resultCard, stripeToken); //// return new ResponseWrapper(token, null); // } catch (AuthenticationException authenticationException) { // return new ResponseWrapper(null, authenticationException); // } catch (Exception e) { // return new ResponseWrapper(null, e); // } } public class ResponseWrapper {", "del_tokens": "private class ResponseWrapper {", "commit_type": "add"}
{"commit_tokens": ["use", "for", "-", "i", "instead", "of", "for", "-", "each", "to", "reduce", "memory", "alloc"], "add_tokens": "public abstract class LayoutHelperFinder { * Get layoutHelpers that in reverse order protected abstract List < LayoutHelper > reverse ( ) ;", "del_tokens": "public abstract class LayoutHelperFinder implements Iterable < LayoutHelper > { * Get iterator that in reverse order protected abstract Iterable < LayoutHelper > reverse ( ) ;", "commit_type": "use"}
{"commit_tokens": ["changed", "qualifier", "to", "liberty_remote", "for", "remote", "arquillian", "object"], "add_tokens": "+ \" <container qualifier=\\\"liberty_remote\\\" default=\\\"true\\\">\\n\" + \" <configuration>\\n\" ;", "del_tokens": "+ \" <container qualifier=\\\"wlp-remote\\\" default=\\\"true\\\">\\n\" + \" <configuration>\\n\" ;", "commit_type": "change"}
{"commit_tokens": ["remove", "old", "command", "files", ".", "format", "new", "command", "line", "code"], "add_tokens": "return String . format ( \"%.2f B\" , ret ) ;", "del_tokens": "return String . format ( \"%.2f Bytes\" , ret ) ;", "commit_type": "remove"}
{"commit_tokens": ["Made", "cassandraTable", "methods", "return", "CassandraJavaRDD", "instead", "of", "CassandraRDD", "(", "in", "JavaAPI", ")"], "add_tokens": "JavaRDD < String > cassandraRowsRDD = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" ) JavaRDD < String > rdd2 = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" , Person . class ) JavaRDD < String > rdd3 = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" , Person . class ) JavaRDD < String > rdd4 = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" )", "del_tokens": "JavaRDD < String > cassandraRowsRDD = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" ) . toJavaRDD ( ) JavaRDD < String > rdd2 = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" , Person . class ) . toJavaRDD ( ) JavaRDD < String > rdd3 = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" , Person . class ) . toJavaRDD ( ) JavaRDD < String > rdd4 = javaFunctions ( sc ) . cassandraTable ( \"test\" , \"people\" ) . toJavaRDD ( )", "commit_type": "make"}
{"commit_tokens": ["Fix", "bug", "where", "ProcessPersistence", "wasn", "t", "used", "when", "updateOccurrence", "was", "called", "."], "add_tokens": "private void updateOccurrence ( final Occurrence occurrence , final boolean doStart ) { ProcessPersistence < ProcessEntity < K > , K > processHome = null ; if ( doStart ) processHome = getProcessPersistence ( ) ; if ( doStart && isPersistent ) processHome . update ( ) ;", "del_tokens": "private void updateOccurrence ( final Occurrence occurrence , boolean doStart ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "classpath", "of", "the", "additional", "dissector"], "add_tokens": "* , \"load:nl.basjes.parse.http.dissectors.ScreenResolutionDissector\" = \"x\" throw new SerDeException ( \"Found load with bad specification: No such class:\" + dissectorClassName , e ) ;", "del_tokens": "* , \"load:nl.basjes.pig.input.apachehttpdlog.ScreenResolutionDissector\" = \"x\" throw new SerDeException ( \"Found load with bad specification: No such class:\" + key , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "health", "indicator", "to", "main", "application", "context"], "add_tokens": "import org . springframework . cloud . bootstrap . config . PropertySourceBootstrapConfiguration ; import org . springframework . cloud . config . client . ConfigServerHealthIndicator ; ConfigurableApplicationContext context = new SpringApplicationBuilder ( ConfigClientAutoConfiguration . class ) . child ( Object . class ) . web ( false ) . run ( ) ; @ Test public void withHealthIndicator ( ) { ConfigurableApplicationContext context = new SpringApplicationBuilder ( PropertySourceBootstrapConfiguration . class ) . child ( ConfigClientAutoConfiguration . class ) . web ( false ) . run ( ) ; assertEquals ( 1 , BeanFactoryUtils . beanNamesForTypeIncludingAncestors ( context , ConfigClientProperties . class ) . length ) ; assertEquals ( 1 , BeanFactoryUtils . beanNamesForTypeIncludingAncestors ( context , ConfigServerHealthIndicator . class ) . length ) ; context . close ( ) ; }", "del_tokens": "ConfigurableApplicationContext context = new SpringApplicationBuilder ( ConfigClientAutoConfiguration . class ) . child ( Object . class ) . web ( false ) . run ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "copyright", "from", "files", "in", "Maven", "archetype"], "add_tokens": "}", "del_tokens": "/ * * Copyright ( C ) 2016 Lightbend Inc . < http : //www.lightbend.com> * / }", "commit_type": "remove"}
{"commit_tokens": ["Make", "exchange", "use", "HTTP", "response", "channel", "on", "top", "of", "gated", "channel"], "add_tokens": "StreamSinkChannel channel = new HttpResponseChannel ( gatedResponseChannel , bufferPool . allocate ( ) , this ) ;", "del_tokens": "StreamSinkChannel channel = gatedResponseChannel ;", "commit_type": "make"}
{"commit_tokens": ["Add", "mock", "support", "for", "security", "context", "constraints", "operations", "."], "add_tokens": "import io . fabric8 . kubernetes . api . model . SecurityContextConstraintsList ; import io . fabric8 . kubernetes . api . model . SecurityContextConstraintsListBuilder ; for ( int i = 0 ; i < 5 ; i ++ ) { for ( int i = 0 ; i < 5 ; i ++ ) { @ Test public void testListSecurityContextConstraints ( ) { KubernetesMockClient mock = new KubernetesMockClient ( ) ; mock . securityContextConstraints ( ) . list ( ) . andReturn ( new SecurityContextConstraintsListBuilder ( ) . addNewItem ( ) . withNewMetadata ( ) . withName ( \"scc1\" ) . endMetadata ( ) . withAllowHostPorts ( true ) . withAllowPrivilegedContainer ( true ) . endItem ( ) . build ( ) ) . anyTimes ( ) ; KubernetesClient client = mock . replay ( ) ; for ( int i = 0 ; i < 5 ; i ++ ) { SecurityContextConstraintsList result = client . securityContextConstraints ( ) . list ( ) ; Assert . assertNotNull ( result ) ; Assert . assertEquals ( 1 , result . getItems ( ) . size ( ) ) ; } }", "del_tokens": "for ( int i = 0 ; i < 5 ; i ++ ) { for ( int i = 0 ; i < 5 ; i ++ ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "the", "default", "endpointAuthenication", "is", "always", "false"], "add_tokens": "if ( value . equalsIgnoreCase ( \"Y\" ) || value . equalsIgnoreCase ( \"YES\" ) || value . equalsIgnoreCase ( \"TRUE\" ) ) { return true ;", "del_tokens": "if ( value . equalsIgnoreCase ( \"N\" ) || value . equalsIgnoreCase ( \"NO\" ) || value . equalsIgnoreCase ( \"FALSE\" ) ) { return false ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "getArticles", "to", "retrieve", "multiple", "pages"], "add_tokens": "* Get all articles from help center . public Iterable < Article > getArticles ( ) { return new PagedIterable < Article > ( cnst ( \"/help_center/articles.json\" ) , handleList ( Article . class , \"articles\" ) ) ;", "del_tokens": "* Get first page of articles from help center . * @ deprecated use # getArticlesFromPage ( int ) . Same as # getArticlesFromPage ( 0 ) @ Deprecated public List < Article > getArticles ( ) { return complete ( submit ( req ( \"GET\" , cnst ( \"/help_center/articles.json\" ) ) , handleList ( Article . class , \"articles\" ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "NPE", "when", "the", "setConcurrency", "is", "called", "before", "setPrototype", "on", "a", "MpContainer", "."], "add_tokens": "if ( outputConcurrency > 0 ) setupOutputConcurrency ( ) ; { synchronized ( lockForExecutorServiceSetter ) { outputConcurrency = concurrency ; if ( prototype != null ) // otherwise this isn't initialized yet setupOutputConcurrency ( ) ; } } private void setupOutputConcurrency ( ) outputExecutorService = Executors . newFixedThreadPool ( outputConcurrency ) ;", "del_tokens": "outputConcurrency = concurrency ; outputExecutorService = Executors . newFixedThreadPool ( concurrency ) ;", "commit_type": "fix"}
{"commit_tokens": ["update", "build", "plugins", "and", "remove", "classifier", "packages"], "add_tokens": "* FIXME do not check this via system property * doWait ( 1 ) ;", "del_tokens": "doWait ( 1500 ) ;", "commit_type": "update"}
{"commit_tokens": ["change", "Target", "Not", "Found", "log", "level", "to", "debug"], "add_tokens": "LOG . debug ( \"Target not found for navigation property binding in: {}, path={}\" , typeName , path ) ;", "del_tokens": "LOG . warn ( \"Target not found for navigation property binding in: {}, path={}\" , typeName , path ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "createLambdaFunction", "calls", "to", "pass", "context", ".", "Also", "removal", "of", "mllib", "/", "regression", "/", "LabeledPoint", "and", "mllib", "/", "linang", "/", "Vectors", "from", "SparkBootstrap"], "add_tokens": "* Note : Commenting out for now as we don 't need given that we' re only * going to load bare essentials for both driver and worker nodes now . * Leaving in for now but commented out in case we change our minds . / * * / // Not blindly loading Vectors any more for master or slave //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/linalg/Vectors.js\") + \"');\"); // Not blindly loading LabeledPoint any more for master or slave //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/regression/LabeledPoint.js\") + \"');\");", "del_tokens": "// NOTE: Eventaully we want to keep all of mllib, ml, streaming, sql, etc. (anything other than // core modules) from being loaded on workder nodes and loading only on need be basis as they // are required. For now just working with Vectors and LabeledPoint to get all the kinks worked // out and loading mechanism in place on master. Then can go back and do the rest. if ( ! isLoadingOnWorkerNode ( ) ) { engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/mllib/linalg/Vectors.js\" ) + \"');\" ) ; } else { System . out . println ( \"NOT BLINDLY LOADING VECTORS ON WORKER NODE\" ) ; } // NOTE: See note above for Vectors.js - ditto for LabeledPoint if ( ! isLoadingOnWorkerNode ( ) ) { engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/mllib/regression/LabeledPoint.js\" ) + \"');\" ) ; } else { System . out . println ( \"NOT BLINDLY LOADING LABELEDPOINT ON WORKER NODE\" ) ; }", "commit_type": "update"}
{"commit_tokens": ["updating", "namespace", "bumping", "version", "adding", "tests"], "add_tokens": "package com . github . adamyork . wiremock . transformer ;", "del_tokens": "package com . github . radadam . wiremock . transformer ;", "commit_type": "update"}
{"commit_tokens": ["Added", "config", "utils", "for", "obtaining", "configurable", "resource", "instances"], "add_tokens": "import net . jodah . lyra . internal . util . Assert ; Boolean result = isConsumerRecoveryEnabledInternal ( ) ; if ( result != null ) return result ; private Boolean isConsumerRecoveryEnabledInternal ( ) { return consumerRecovery != null ? consumerRecovery : parent != null ? parent . isConsumerRecoveryEnabled ( ) : null ; } / * * * Returns the { @ code channel } as a { @ link ConfigurableChannel } . * * @ throws IllegalArgumentException if { @ code channel } was not created by Lyra * / public static ConfigurableChannel of ( Channel channel ) { Assert . isTrue ( channel instanceof ConfigurableChannel , \"The channel {} was not created by Lyra\" , channel ) ; return ( ConfigurableChannel ) channel ; } / * * * Returns the { @ code connection } as a { @ link ConfigurableConnection } . * * @ throws IllegalArgumentException if { @ code connection } was not created by Lyra * / public static ConfigurableConnection of ( Connection connection ) { Assert . isTrue ( connection instanceof ConfigurableConnection , \"The connection {} was not created by Lyra\" , connection ) ; return ( ConfigurableConnection ) connection ; }", "del_tokens": "if ( consumerRecovery != null ) return consumerRecovery ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "command", "prefix", "from", "bang", "to", "carrat", "since", "jline2", "supports", "bang", "as", "history", "search", "."], "add_tokens": "public static final String COMMAND_PREFIX = \"^\" ; throws Exception throws Exception COMMAND_PREFIX + \"connect \" dispatch ( COMMAND_PREFIX + \"properties \" + i . next ( ) ) ; dispatch ( COMMAND_PREFIX + \"run \" + opts . getRun ( ) ) ; dispatch ( COMMAND_PREFIX + \"quit\" ) ; throws Exception throws Exception terminal . init ( ) ; line = COMMAND_PREFIX + \"help\" ;", "del_tokens": "public static final String COMMAND_PREFIX = \"!\" ; throws IOException throws IOException \"!connect \" dispatch ( \"!properties \" + i . next ( ) ) ; dispatch ( \"!run \" + opts . getRun ( ) ) ; dispatch ( \"!quit\" ) ; throws IOException throws IOException line = \"!help\" ;", "commit_type": "change"}
{"commit_tokens": ["Create", "package", "for", "Glasoperator", "classes"], "add_tokens": "package nl . glasoperator . fitnesse . vodafone ; import nl . hsac . fitnesse . fixture . web . BrowserTest ;", "del_tokens": "package nl . hsac . fitnesse . fixture . web ;", "commit_type": "create"}
{"commit_tokens": ["Adding", "DockerClient", ".", "logContainerStream", "method", "which", "keeps", "the", "log", "stream", "open", "indefinitely", "."], "add_tokens": "return logContainer ( containerId , false ) ; } public ClientResponse logContainerStream ( String containerId ) throws DockerException { return logContainer ( containerId , true ) ; } private ClientResponse logContainer ( String containerId , boolean stream ) throws DockerException { if ( stream ) { params . add ( \"stream\" , \"1\" ) ; // this parameter keeps stream open indefinitely }", "del_tokens": "//params.add(\"stream\", \"1\"); this parameter keeps stream open indindefinitely", "commit_type": "add"}
{"commit_tokens": ["use", "MaxTotal", "replaces", "MaxActive", "in", "latest", "DataSource", "library"], "add_tokens": "import org . apache . commons . dbcp2 . BasicDataSource ; ds . setMaxTotal ( maxActive ) ;", "del_tokens": "import org . apache . commons . dbcp . BasicDataSource ; ds . setMaxActive ( maxActive ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "json", "parser", "for", "grouped", "response"], "add_tokens": "protected Optional < String > groupBy = Optional . absent ( ) ;", "del_tokens": "protected Optional < String > groupBy ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "same", "for", "single", "launcher"], "add_tokens": "createContainerCmd . withEntrypoint ( \"/bin/sh\" ,", "del_tokens": "createContainerCmd . withCmd ( \"/bin/sh\" ,", "commit_type": "fix"}
{"commit_tokens": ["allow", "feign", "to", "decode", "parameterized", "types", ".", "Added", "SpringDecoderTests", "."], "add_tokens": "import java . lang . reflect . ParameterizedType ; if ( type instanceof Class || type instanceof ParameterizedType ) { @ SuppressWarnings ( { \"unchecked\" , \"rawtypes\" } ) HttpMessageConverterExtractor < ? > extractor = new HttpMessageConverterExtractor ( type , messageConverters . getConverters ( ) ) ; return extractor . extractData ( new FeignResponseAdapter ( response ) ) ; } throw new DecodeException ( \"type is not an instance of Class or ParameterizedType: \" + type ) ; private class FeignResponseAdapter implements ClientHttpResponse {", "del_tokens": "if ( type instanceof Class ) { @ SuppressWarnings ( { \"unchecked\" , \"rawtypes\" } ) HttpMessageConverterExtractor < ? > extractor = new HttpMessageConverterExtractor ( ( Class < ? > ) type , messageConverters . getConverters ( ) ) ; Object data = extractor . extractData ( new FeignResponseAdapter ( response ) ) ; return data ; } throw new DecodeException ( \"type is not an instance of Class: \" + type ) ; private class FeignResponseAdapter implements ClientHttpResponse {", "commit_type": "allow"}
{"commit_tokens": ["Added", "LocalDateAdapter", "to", "support", "use", "of", "LocalDate", "for", "date", "-", "only", "properties", "."], "add_tokens": "public DateAdapter ( String outputFormat , String ... inputFormats )", "del_tokens": "protected DateAdapter ( String outputFormat , String ... inputFormats )", "commit_type": "add"}
{"commit_tokens": ["use", "optionl", "get", "tenant", "key", "method", "instead", "of", "required"], "add_tokens": "import static com . icthh . xm . commons . tenant . TenantContextUtils . getTenantKey ; import com . icthh . xm . commons . tenant . TenantKey ; return getTenantKey ( tenantContextHolder ) . map ( TenantKey :: getValue ) . map ( tenantLocalizedMessageConfig :: get ) . map ( localizedMessageConfig -> localizedMessageConfig . get ( messageCode ) ) . map ( localizedMessages -> localizedMessages . get ( locale ) ) . orElse ( null ) ;", "del_tokens": "import static com . icthh . xm . commons . tenant . TenantContextUtils . getRequiredTenantKeyValue ; Map < String , Map < Locale , String > > localizedMessageConfig = tenantLocalizedMessageConfig . get ( getRequiredTenantKeyValue ( tenantContextHolder . getContext ( ) ) ) ; if ( localizedMessageConfig == null ) { return null ; } Map < Locale , String > messages = localizedMessageConfig . get ( messageCode ) ; if ( messages == null ) { return null ; } return messages . get ( locale ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "the", "rest", "of", "the", "JSR", "-", "305", "annotations"], "add_tokens": "import fi . jumi . actors . OnDemandActors ; import javax . annotation . concurrent . NotThreadSafe ; @ NotThreadSafe", "del_tokens": "import fi . jumi . actors . OnDemandActors ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "call", "the", "applyChanges", "always", "."], "add_tokens": "return poll ( java . lang . Long . MAX_VALUE ) ; logger . finest ( \"Poll \" + selector . keys ( ) . size ( ) + \" sockets\" ) ; { return true ; }", "del_tokens": "return instance ( ) . pollSockets ( java . lang . Long . MAX_VALUE ) ; // logger.finest(\"Poll \" + selector.keys().size() + \" sockets\"); return false ;", "commit_type": "make"}
{"commit_tokens": ["Add", "configuration", "for", "MultiWarc", ":"], "add_tokens": "private int maxSecondsBetweenDumps = 600 ; private long lastDumpTime = ( new Date ( ) ) . getTime ( ) / 1000 ; LOGGER . info ( \"Max record per file = \" + maxRecordsPerFile ) ; LOGGER . info ( \"Max seconds between dumps = \" + maxSecondsBetweenDumps ) ; long currentTime = new Date ( ) . getTime ( ) / 1000 ; if ( currentNumberOfRecordsInFile > 0 && ( ( currentNumberOfRecordsInFile > maxRecordsPerFile ) || ( currentTime - lastDumpTime > maxSecondsBetweenDumps ) ) ) { LOGGER . info ( \"Current time = \" + currentTime + \", lastDumpTime = \" + lastDumpTime ) ; } catch ( IOException e ) { currentNumberOfRecordsInFile += 1 ;", "del_tokens": "private int maxSecondsBetweenDumps = 600 private Date lastDumpTime = new Date ( ) ; currentNumberOfRecordsInFile += 1 ; Date currentTime = new Date ( ) ; if ( ( currentNumberOfRecordsInFile > targetRecordsPerFile ) || ( ( currentTime . getTime ( ) - lastDumpTime . getTime ( ) / 1000 > maxSecondsBetweenDumps ) ) { } catch ( IOException badshitHappens ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "stupid", "typo", "error", "for", "left", "key"], "add_tokens": "escapeSequence = getSequence ( Capability . key_left ) ;", "del_tokens": "if ( ctrlState != 0 ) escapeSequence = getSequence ( Capability . key_sleft ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "problem", "with", "test", "compile", "dependecy"], "add_tokens": "Object proxy = Proxy . newProxyInstance ( MethodReflectionProviderCompatibilityTest . class . getClassLoader ( ) ,", "del_tokens": "import net . vidageek . mirror . reflect . MethodReflectorTest ; Object proxy = Proxy . newProxyInstance ( MethodReflectorTest . class . getClassLoader ( ) ,", "commit_type": "fix"}
{"commit_tokens": ["Update", "http", "integration", "tests", "to", "use", "new", "interface", "methods"], "add_tokens": "httpMetricsIngestorServer = new HttpMetricsIngestionServer ( ) ; httpMetricsIngestorServer . startService ( context ) ;", "del_tokens": "httpMetricsIngestorServer = new HttpMetricsIngestionServer ( httpPort , context ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "primitive", "type", "getFullName", "()", "regression"], "add_tokens": "if ( clazz . isPrimitive ( ) ) { return super . getFullName ( ) ; } else { return clazz . getName ( ) ; }", "del_tokens": "return clazz . getName ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "duplicate", "curies", "from", "embedded", "objects", "if", "embedding"], "add_tokens": "import java . util . ArrayList ; import static de . otto . edison . hal . Curies . emptyCuries ; if ( this . links != null ) { removeDuplicateCuriesFromEmbedding ( curies ) ; this . links = this . links . using ( this . curies ) ; private void removeDuplicateCuriesFromEmbedding ( final Curies curies ) { if ( this . links . hasLink ( \"curies\" ) ) { final List < Link > curiLinks = new ArrayList < > ( this . links . getLinksBy ( \"curies\" ) ) ; curies . getCuries ( ) . forEach ( curi -> { curiLinks . removeIf ( ( link -> link . isEquivalentTo ( curi ) ) ) ; } ) ; this . links = copyOf ( this . links ) . replace ( \"curies\" , curiLinks ) . build ( ) ; } }", "del_tokens": "import static de . otto . edison . hal . Curies . emptyCuries ; if ( links != null ) { links = links . using ( curies ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "manual", "override", "for", "forcing", "client", "port", "config"], "add_tokens": "protected int overridePort = DefaultClientConfigImpl . DEFAULT_PORT ; protected boolean shouldUseOverridePort = false ; // override client configuration and use client-defined port if ( clientConfig . getPropertyAsBoolean ( CommonClientConfigKey . ForceClientPortConfiguration , false ) ) { if ( clientConfig . getPropertyAsBoolean ( CommonClientConfigKey . IsSecure , false ) ) { if ( clientConfig . containsProperty ( CommonClientConfigKey . SecurePort ) ) { overridePort = clientConfig . getPropertyAsInteger ( CommonClientConfigKey . SecurePort , DefaultClientConfigImpl . DEFAULT_PORT ) ; shouldUseOverridePort = true ; } else { logger . warn ( \"%s set to force client port but no secure port is set, so ignoring\" , clientName ) ; } } else { if ( clientConfig . containsProperty ( CommonClientConfigKey . Port ) ) { overridePort = clientConfig . getPropertyAsInteger ( CommonClientConfigKey . Port , DefaultClientConfigImpl . DEFAULT_PORT ) ; shouldUseOverridePort = true ; } else { logger . warn ( \"%s set to force client port but no secure port is set, so ignoring\" , clientName ) ; } } } if ( shouldUseOverridePort ) { logger . debug ( \"Using override port of %d on client %s\" , clientName ) ; port = overridePort ; } else { port = svc . getPort ( ) ; }", "del_tokens": "port = svc . getPort ( ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "slow", "tests", "outside", "normal", "junit", "tests", "area"], "add_tokens": "* @ author Kasper B . Graversen generate random content String s = \"\" + number ( 100000 ) + \", \" + string ( 7 ) + \", \" + string ( 10 ) + \", \" + number ( 200 ) + \", \" + date ( ) + \"\\n\" ; if ( r . nextInt ( ) % 30 == 0 ) return \"\\\"\" + s + \"\\\"\" ; return s ; for ( int i = 0 ; i < len ; i ++ ) { if ( r . nextInt ( ) % 6 == 0 ) // sometimes its a space sb . append ( ' ' ) ; else sb . append ( Character . toChars ( 65 + r . nextInt ( 25 ) ) ) ; } if ( r . nextInt ( ) % 30 == 0 ) return \"\\\"\" + sb . toString ( ) + \"\\\"\" ; // some times make it a \"\" string", "del_tokens": "* @ author Kasper B . Graversen return \"\" + number ( 100000 ) + \", \" + string ( 7 ) + \", \" + string ( 10 ) + \", \" + number ( 200 ) + \", \" + date ( ) + \"\\n\" ; for ( int i = 0 ; i < len ; i ++ ) sb . append ( Character . toChars ( 65 + r . nextInt ( 25 ) ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "it", "easy", "to", "scale", "a", "BImage", "when", "loading", "it", "."], "add_tokens": "String key = rsrcPath + \":\" + scale ; WeakReference < Image > iref = _imgcache . get ( key ) ; _imgcache . put ( key , new WeakReference < Image > ( image ) ) ; return getBImage ( rsrcPath , 1f , false ) ; * @ param scale If none - unity the image will be scaled by the supplied factor before being * converted into a { @ link BImage } . public BImage getBImage ( String rsrcPath , float scale , boolean returnNull ) // create and cache a new BUI image with the appropriate (scaled if necessary) data image = new BImage ( scale == 1f ? bufimg : bufimg . getScaledInstance ( Math . round ( bufimg . getWidth ( ) * scale ) , Math . round ( bufimg . getHeight ( ) * scale ) , BufferedImage . SCALE_SMOOTH ) , true ) ;", "del_tokens": "WeakReference < Image > iref = _imgcache . get ( rsrcPath ) ; _imgcache . put ( rsrcPath , new WeakReference < Image > ( image ) ) ; return getBImage ( rsrcPath , false ) ; public BImage getBImage ( String rsrcPath , boolean returnNull ) // create and cache a new BUI image with the appropriate data image = new BImage ( bufimg , true ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "api", "to", "force", "load", "template", "data"], "add_tokens": "return loadFromBuffer ( buf , false ) ; } public int loadFromBuffer ( byte [ ] buf , boolean override ) { boolean result = false ; if ( ! override ) { result = mUiCodeLoader . loadFromBuffer ( reader , pageId , patchVersion ) ; } else { result = mUiCodeLoader . forceLoadFromBuffer ( reader , pageId , patchVersion ) ; }", "del_tokens": "boolean result = mUiCodeLoader . loadFromBuffer ( reader , pageId , patchVersion ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "UuidHandler", "to", "bpsm", ".", "edn", ".", "parser"], "add_tokens": "package bpsm . edn . parser ; class UuidHandler implements TagHandler {", "del_tokens": "package bpsm . edn . parser . handlers ; import bpsm . edn . parser . TagHandler ; public class UuidHandler implements TagHandler {", "commit_type": "move"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "fields", "not", "being", "picked", "up", "by", "hibernate", "."], "add_tokens": "import org . hibernate . validator . Length ; import org . jboss . pressgang . ccms . model . base . AuditedEntity ; public class TranslatedTopicString extends AuditedEntity < TranslatedTopicString > implements java . io . Serializable { private String originalString ; private String translatedString ; private Boolean fuzzyTranslation = false ; @ Column ( name = \"OriginalString\" , columnDefinition = \"TEXT\" ) @ Length ( max = 65535 ) public String getOriginalString ( ) { return originalString ; } public void setOriginalString ( final String originalString ) { this . originalString = originalString ; } @ Column ( name = \"TranslatedString\" , columnDefinition = \"TEXT\" ) @ Length ( max = 65535 ) public String getTranslatedString ( ) { return translatedString ; } public void setTranslatedString ( final String translatedString ) { this . translatedString = translatedString ; } @ Column ( name = \"FuzzyTranslation\" , nullable = false , columnDefinition = \"BIT\" , length = 1 ) @ NotNull public Boolean getFuzzyTranslation ( ) { return fuzzyTranslation ; } public void setFuzzyTranslation ( final Boolean fuzzyTranslation ) { this . fuzzyTranslation = fuzzyTranslation ; }", "del_tokens": "import org . jboss . pressgang . ccms . model . base . BaseTranslatedString ; public class TranslatedTopicString extends BaseTranslatedString < TranslatedTopicString > implements java . io . Serializable {", "commit_type": "fix"}
{"commit_tokens": ["Add", "example", "to", "@Context", "use"], "add_tokens": "import javax . ws . rs . core . Context ; public GreetingResponse hello ( @ Context HttpServletRequest httpRequest , @ QueryParam ( \"name\" ) String name ) { return greet ( httpRequest , new GreetingRequest ( name ) ) ; public GreetingResponse greet ( @ Context HttpServletRequest httpRequest , GreetingRequest request ) { response . setServerInfo ( httpRequest . getServletContext ( ) . getServerInfo ( ) ) ; response . setUserAgent ( httpRequest . getHeader ( \"User-Agent\" ) ) ; public GreetingResponse greet ( @ Context HttpServletRequest httpRequest , @ PathParam ( \"id\" ) String id , @ QueryParam ( \"opt\" ) String opt , GreetingRequest request ) { GreetingResponse response = greet ( httpRequest , request ) ;", "del_tokens": "@ Inject private HttpServletRequest httpServletRequest ; public GreetingResponse hello ( @ QueryParam ( \"name\" ) String name ) { return greet ( new GreetingRequest ( name ) ) ; public GreetingResponse greet ( GreetingRequest request ) { response . setServerInfo ( httpServletRequest . getServletContext ( ) . getServerInfo ( ) ) ; response . setUserAgent ( httpServletRequest . getHeader ( \"User-Agent\" ) ) ; public GreetingResponse greet ( @ PathParam ( \"id\" ) String id , @ QueryParam ( \"opt\" ) String opt , GreetingRequest request ) { GreetingResponse response = greet ( request ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "null", "pointer", "when", "c10n", "configuration", "is", "declared", "in", "the", "default", "package"], "add_tokens": "Package pkg = getClass ( ) . getPackage ( ) ; return pkg != null ? pkg . getName ( ) : \"\" ;", "del_tokens": "return getClass ( ) . getPackage ( ) . getName ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "hash", "functions", "to", "allow", "finalization", "of", "(", "multi", ")", "set", "hashes", "support", "Iterator", "as", "input", "for", "hash", "functions"], "add_tokens": "int memberHash = HashGenerator . combineMultisetHash ( true , members ) ; int subMemberHash = HashGenerator . combineMultisetHash ( true , o . getMembers ( ) ) ; subClassHash = HashGenerator . combineListHash ( subClassHash , subMemberHash ) ; int superMemberHash = HashGenerator . combineMultisetHash ( true , o . getMembers ( ) ) ; superClassHash = HashGenerator . combineListHash ( superClassHash , superMemberHash ) ;", "del_tokens": "int memberHash = HashGenerator . combineSetHash ( members ) ; int subMemberHash = HashGenerator . combineSetHash ( o . getMembers ( ) ) ; subClassHash = HashGenerator . combineSetHash ( subClassHash , subMemberHash ) ; int superMemberHash = HashGenerator . combineSetHash ( o . getMembers ( ) ) ; superClassHash = HashGenerator . combineSetHash ( superClassHash , superMemberHash ) ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "hardcoded", "path", "from", "admin", "manager"], "add_tokens": "private static final String METRICS_ENDPOINT = \"/metrics\" ; private static final String ADMIN_ROOT_FOLDER = \"admin\" ; controlPanel = HandlerUtil . staticFiles ( HandlerUtil . BASE_PATH , ADMIN_ROOT_FOLDER , adminInterceptor ) . handler ; MappedEndpoint getMetrics = HandlerUtil . rest ( Methods . GET , METRICS_ENDPOINT , ( exchange ) -> exchange . send ( MappedEndpoint clearMetrics = HandlerUtil . rest ( Methods . DELETE , METRICS_ENDPOINT , ( exchange ) -> {", "del_tokens": "controlPanel = HandlerUtil . staticFiles ( \"/\" , \"admin\" , adminInterceptor ) . handler ; MappedEndpoint getMetrics = HandlerUtil . rest ( Methods . GET , \"/metrics\" , ( exchange ) -> exchange . send ( MappedEndpoint clearMetrics = HandlerUtil . rest ( Methods . DELETE , \"/metrics\" , ( exchange ) -> {", "commit_type": "remove"}
{"commit_tokens": ["add", "web_origins", "attribute", "to", "the", "Client", "class"], "add_tokens": "private static final String json = \"{\\\"name\\\":\\\"name\\\",\\\"description\\\":\\\"description\\\",\\\"client_secret\\\":\\\"secret\\\",\\\"app_type\\\":\\\"type\\\",\\\"logo_uri\\\":\\\"uri\\\",\\\"oidc_conformant\\\":true,\\\"callbacks\\\":[\\\"value\\\"],\\\"allowed_origins\\\":[\\\"value\\\"],\\\"web_origins\\\":[\\\"value\\\"],\\\"client_aliases\\\":[\\\"value\\\"],\\\"allowed_clients\\\":[\\\"value\\\"],\\\"allowed_logout_urls\\\":[\\\"value\\\"],\\\"jwt_configuration\\\":{\\\"lifetime_in_seconds\\\":100,\\\"scopes\\\":\\\"openid\\\",\\\"alg\\\":\\\"alg\\\"},\\\"encryption_key\\\":{\\\"pub\\\":\\\"pub\\\",\\\"cert\\\":\\\"cert\\\"},\\\"sso\\\":true,\\\"sso_disabled\\\":true,\\\"custom_login_page_on\\\":true,\\\"custom_login_page\\\":\\\"custom\\\",\\\"custom_login_page_preview\\\":\\\"preview\\\",\\\"form_template\\\":\\\"template\\\",\\\"addons\\\":{\\\"rms\\\":{},\\\"mscrm\\\":{},\\\"slack\\\":{},\\\"layer\\\":{}},\\\"token_endpoint_auth_method\\\":\\\"method\\\",\\\"client_metadata\\\":{\\\"key\\\":\\\"value\\\"},\\\"mobile\\\":{\\\"android\\\":{\\\"app_package_name\\\":\\\"pkg\\\",\\\"sha256_cert_fingerprints\\\":[\\\"256\\\"]},\\\"ios\\\":{\\\"team_id\\\":\\\"team\\\",\\\"app_bundle_identifier\\\":\\\"id\\\"}}}\" ; client . setWebOrigins ( stringList ) ; assertThat ( client . getWebOrigins ( ) , contains ( \"value\" ) ) ;", "del_tokens": "private static final String json = \"{\\\"name\\\":\\\"name\\\",\\\"description\\\":\\\"description\\\",\\\"client_secret\\\":\\\"secret\\\",\\\"app_type\\\":\\\"type\\\",\\\"logo_uri\\\":\\\"uri\\\",\\\"oidc_conformant\\\":true,\\\"callbacks\\\":[\\\"value\\\"],\\\"allowed_origins\\\":[\\\"value\\\"],\\\"client_aliases\\\":[\\\"value\\\"],\\\"allowed_clients\\\":[\\\"value\\\"],\\\"allowed_logout_urls\\\":[\\\"value\\\"],\\\"jwt_configuration\\\":{\\\"lifetime_in_seconds\\\":100,\\\"scopes\\\":\\\"openid\\\",\\\"alg\\\":\\\"alg\\\"},\\\"encryption_key\\\":{\\\"pub\\\":\\\"pub\\\",\\\"cert\\\":\\\"cert\\\"},\\\"sso\\\":true,\\\"sso_disabled\\\":true,\\\"custom_login_page_on\\\":true,\\\"custom_login_page\\\":\\\"custom\\\",\\\"custom_login_page_preview\\\":\\\"preview\\\",\\\"form_template\\\":\\\"template\\\",\\\"addons\\\":{\\\"rms\\\":{},\\\"mscrm\\\":{},\\\"slack\\\":{},\\\"layer\\\":{}},\\\"token_endpoint_auth_method\\\":\\\"method\\\",\\\"client_metadata\\\":{\\\"key\\\":\\\"value\\\"},\\\"mobile\\\":{\\\"android\\\":{\\\"app_package_name\\\":\\\"pkg\\\",\\\"sha256_cert_fingerprints\\\":[\\\"256\\\"]},\\\"ios\\\":{\\\"team_id\\\":\\\"team\\\",\\\"app_bundle_identifier\\\":\\\"id\\\"}}}\" ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "maps", ";", "added", "annotations"], "add_tokens": "/ * * * Copyright ( C ) 2011 Twitter , Inc . * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; you may not use this * file except in compliance with the License . You may obtain a copy of the License at * http : //www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing , software distributed * under the License is distributed on an \"AS IS\" BASIS , WITHOUT WARRANTIES OR * CONDITIONS OF ANY KIND , either express or implied . See the License for the * specific language governing permissions and limitations under the License .", "del_tokens": "/ * * Copyright 2012 Twitter , Inc . . * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * http : //www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License .", "commit_type": "add"}
{"commit_tokens": ["Use", "Unix", "directory", "separator", "in", "unit", "test", "."], "add_tokens": "String [ ] convertC = { \"convert\" , \"test-data/cw/c.txt\" , \"test-data/cw/c.xml\" , \"-config=src/main/resources/conf/s-match-Tab2XML.properties\" } ; String [ ] convertW = { \"convert\" , \"test-data/cw/w.txt\" , \"test-data/cw/w.xml\" , \"-config=src/main/resources/conf/s-match-Tab2XML.properties\" } ; String [ ] offlineC = { \"offline\" , \"test-data/cw/c.xml\" , \"test-data/cw/c.xml\" } ; String [ ] offlineW = { \"offline\" , \"test-data/cw/w.xml\" , \"test-data/cw/w.xml\" } ; String [ ] online = { \"online\" , \"test-data/cw/c.xml\" , \"test-data/cw/w.xml\" , \"test-data/cw/result-cw.txt\" } ;", "del_tokens": "String [ ] convertC = { \"convert\" , \"test-data\\\\cw\\\\c.txt\" , \"test-data\\\\cw\\\\c.xml\" , \"-config=src\\\\main\\\\resources\\\\conf\\\\s-match-Tab2XML.properties\" } ; String [ ] convertW = { \"convert\" , \"test-data\\\\cw\\\\w.txt\" , \"test-data\\\\cw\\\\w.xml\" , \"-config=src\\\\main\\\\resources\\\\conf\\\\s-match-Tab2XML.properties\" } ; String [ ] offlineC = { \"offline\" , \"test-data\\\\cw\\\\c.xml\" , \"test-data\\\\cw\\\\c.xml\" } ; String [ ] offlineW = { \"offline\" , \"test-data\\\\cw\\\\w.xml\" , \"test-data\\\\cw\\\\w.xml\" } ; String [ ] online = { \"online\" , \"test-data\\\\cw\\\\c.xml\" , \"test-data\\\\cw\\\\w.xml\" , \"test-data\\\\cw\\\\result-cw.txt\" } ;", "commit_type": "use"}
{"commit_tokens": ["remove", "static", "declaring", "of", "CacheSyncTask", "inner", "class", ".", "so", "that", "we", "can", "simplify", "this", "reference", "."], "add_tokens": "syncService . scheduleWithFixedDelay ( new CacheSyncTask ( ) , private class CacheSyncTask implements Runnable { private final CachedDirectoryLookupService cachedLookupService = CachedDirectoryLookupService . this ; public CacheSyncTask ( ) {", "del_tokens": "syncService . scheduleWithFixedDelay ( new CacheSyncTask ( this ) , private static class CacheSyncTask implements Runnable { private CachedDirectoryLookupService cachedLookupService ; public CacheSyncTask ( CachedDirectoryLookupService cachedLookupService ) { this . cachedLookupService = cachedLookupService ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "timeout", "to", "the", "findBestMatches", "algorithm", ".", "Necessary", "because", "it", "s", "possible", "for", "that", "algorithm", "to", "never", "exhaust", "the", "search", "space", "in", "a", "reasonable", "time", ".", "In", "the", "case", "it", "exceeds", "the", "timeout", "we", "will", "fall", "back", "to", "the", "getGoodEnoughMatches", "algorithm", "which", "is", "much", "faster", "but", "less", "accurate", "."], "add_tokens": "private final long combinationAlgorithmTimeout ; * @ param combinationAlgorithmTimeout Timeout for the findBestMatches algorithm . public Configuration ( List < PasswordMatcher > passwordMatchers , Map < String , Long > guessTypes , List < Dictionary > dictionaries , List < AdjacencyGraph > adjacencyGraphs , Map < Character , Character > leetTable , Pattern yearPattern , Double minimumEntropy , Locale locale , boolean distanceCalc , long combinationAlgorithmTimeout ) this . combinationAlgorithmTimeout = combinationAlgorithmTimeout ; / * * * * @ return Return the timeout for the findBestMatches algorithm * / public long getCombinationAlgorithmTimeout ( ) { return combinationAlgorithmTimeout ; }", "del_tokens": "public Configuration ( List < PasswordMatcher > passwordMatchers , Map < String , Long > guessTypes , List < Dictionary > dictionaries , List < AdjacencyGraph > adjacencyGraphs , Map < Character , Character > leetTable , Pattern yearPattern , Double minimumEntropy , Locale locale , boolean distanceCalc )", "commit_type": "add"}
{"commit_tokens": ["moving", "static", "factory", "to", "it", "s", "own", "type"], "add_tokens": "private CodegenUtils ( ) {", "del_tokens": "import me . qmx . jitescript . CodeBlock ; * private CodegenUtils ( ) { } / * * * Creates a dotted class name from a path / package name * / public static CodeBlock newCodeBlock ( ) { return new CodeBlock ( ) ; } / * * * Creates a dotted class name from a path / package name * / public static CodeBlock newCodeBlock ( CodeBlock block ) { return new CodeBlock ( block ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "methods", "to", "be", "removed"], "add_tokens": "//FIXME Remove this method //FIXME Remove this method", "del_tokens": "//TODO Finish card methods", "commit_type": "add"}
{"commit_tokens": ["Change", "visibility", "of", "withConvertView", "and", "build", "to", "made", "RendererBuilder", "more", "extensible", "."], "add_tokens": "protected RendererBuilder withConvertView ( View convertView ) { protected Renderer build ( ) {", "del_tokens": "RendererBuilder withConvertView ( View convertView ) { Renderer build ( ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "PBOOK", "-", "41"], "add_tokens": "if ( preferences != null ) { refData . put ( ViewConstants . OPTIONS , preferences ) ; } else { refData . put ( ViewConstants . OPTIONS , new Preferences ( ) ) ; }", "del_tokens": "refData . put ( ViewConstants . OPTIONS , preferences ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "stacktraces", "from", "logging", "when", "creating", "database", "schema", "in", "tests"], "add_tokens": "// if (DbSchemaStrategy.CREATE_DROP==dbSchemaStrategy) { // try { // persistenceSessionFactory.dbSchemaDrop(); // } catch (RuntimeException e) { // // ignore // } // }", "del_tokens": "if ( DbSchemaStrategy . CREATE_DROP == dbSchemaStrategy ) { try { persistenceSessionFactory . dbSchemaDrop ( ) ; } catch ( RuntimeException e ) { // ignore } }", "commit_type": "remove"}
{"commit_tokens": ["Add", "charsetName", "of", "UTF", "-", "8"], "add_tokens": "return new ByteArrayInputStream ( sql . getBytes ( \"UTF-8\" ) ) ;", "del_tokens": "return new ByteArrayInputStream ( sql . getBytes ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "some", "code", "that", "is", "not", "going", "to", "be", "reached"], "add_tokens": "Map < String , Row > componentRowsForThisRow = new ConcurrentHashMap < > ( ) ; // the input field, then use it // else { // Row findFirstRow2 = // joiners.get(nextValueMapping) // .findFirstRow(Collections.singletonMap(splitDBField[1], // fromRow.get(splitDBFieldOutput[1]))); // if (findFirstRow2 != null) { // componentRowsForThisRow.put(splitDBFieldOutput[0], // findFirstRow2); // } // } Map < String , String > output = new ConcurrentHashMap < > ( ) ;", "del_tokens": "ConcurrentMap < String , String > output = new ConcurrentHashMap < > ( ) ; ConcurrentMap < String , Row > componentRowsForThisRow = new ConcurrentHashMap < > ( ) ; // the // input field, then use it } else { // Will not likely gain anything // from this due to the // restriction on the origin // table above Row findFirstRow2 = joiners . get ( nextValueMapping ) . findFirstRow ( Collections . singletonMap ( splitDBField [ 1 ] , fromRow . get ( splitDBFieldOutput [ 1 ] ) ) ) ; if ( findFirstRow2 != null ) { componentRowsForThisRow . put ( splitDBFieldOutput [ 0 ] , findFirstRow2 ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "function", "to", "get", "experiment", "by", "given", "EXNAME"], "add_tokens": "private Map < String , String > eidMap ; this . eidMap = new HashMap < > ( ) ; String eid = experiment . getId ( ) ; this . experimentMap . put ( eid , experiment ) ; this . eidMap . put ( experiment . getValueOr ( \"exname\" , \"\" ) , eid ) ; / * * * Return a Experiment by given experiment name . * * @ param exname the experiment name * * @ return { @ link AceExperiment } * / public AceExperiment getExperiment ( String exname ) { if ( this . eidMap . containsKey ( exname ) ) { return this . experimentMap . get ( eidMap . get ( exname ) ) ; } else { return null ; } }", "del_tokens": "this . experimentMap . put ( experiment . getId ( ) , experiment ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Hungarian", "Notation", "instead", "."], "add_tokens": "mRefreshableView . reload ( ) ; mRefreshableView . setWebChromeClient ( defaultWebChromeClient ) ; mRefreshableView . setWebChromeClient ( defaultWebChromeClient ) ; mRefreshableView . setWebChromeClient ( defaultWebChromeClient ) ; return mRefreshableView . getScrollY ( ) == 0 ; return mRefreshableView . getScrollY ( ) >= ( mRefreshableView . getContentHeight ( ) - mRefreshableView . getHeight ( ) ) ;", "del_tokens": "refreshableView . reload ( ) ; refreshableView . setWebChromeClient ( defaultWebChromeClient ) ; refreshableView . setWebChromeClient ( defaultWebChromeClient ) ; refreshableView . setWebChromeClient ( defaultWebChromeClient ) ; return refreshableView . getScrollY ( ) == 0 ; return refreshableView . getScrollY ( ) >= ( refreshableView . getContentHeight ( ) - refreshableView . getHeight ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "source", "from", "stack", "dump"], "add_tokens": "dumpInternal ( e -> LOGGER . debug ( \"\\t{}:{}\" , dumpInternal ( e -> out . printf ( \"\\t%s:%s%n\" , final SynchronousEvent < ? , ? > synchEvent = ( SynchronousEvent < ? , ? > ) event ;", "del_tokens": "dumpInternal ( e -> LOGGER . debug ( \"\\t{}:{}:{}\" , e . getSource ( ) , dumpInternal ( e -> out . printf ( \"\\t%s:%s:%s%n\" , e . getSource ( ) , SynchronousEvent < ? , ? > synchEvent = ( SynchronousEvent < ? , ? > ) event ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "FILTER_URL", "instead", "of", "duplicating", "the", "value"], "add_tokens": "private String metadataUrl = MetadataDisplayFilter . FILTER_URL ;", "del_tokens": "private String metadataUrl = \"/saml/metadata\" ;", "commit_type": "use"}
{"commit_tokens": ["Added", "checking", "for", "no", "method", "for", "params"], "add_tokens": "@ Test try { getThat ( JavaFileObjects . forResource ( \"view/EmptyParams.java\" ) , JavaFileObjects . forResource ( \"view/EmptyParamsView.java\" ) ) . compilesWithoutError ( ) ; Assert . fail ( ) ; } catch ( RuntimeException e ) { Truth . assertThat ( e . getLocalizedMessage ( ) . startsWith ( \"Your params provider interface should contains only one methods, annotated as \" ) ) ; }", "del_tokens": "//Uncomment this when [MOXY-20] will be fixed // @Test getThat ( JavaFileObjects . forResource ( \"view/EmptyParams.java\" ) , JavaFileObjects . forResource ( \"view/EmptyParamsView.java\" ) ) . compilesWithoutError ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "AsyncFuture", ".", "get", "()", "won", "t", "throw", "TimeoutException", "if", "the", "waiting", "time", "elapsed"], "add_tokens": "if ( ! latch . await ( timeout , unit ) ) { throw new TimeoutException ( ) ; }", "del_tokens": "latch . await ( timeout , unit ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "that", "BitVector", ".", "select0", "and", "next0", "returns", "wrong", "position", "when"], "add_tokens": "if ( size0 == 1 ) { node1pos = size ; } else if ( size0 == 2 ) { if ( count == 1 ) return node1pos ; private int node1pos = - 1 ; private int node2pos = - 1 ;", "del_tokens": "if ( size0 == 2 ) { if ( count == 1 ) return 1 ; private int node2pos ;", "commit_type": "fix"}
{"commit_tokens": ["add", "newline", "for", "github", "not", "to", "cry"], "add_tokens": "}", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Created", "a", "validator", "class", "to", "check", "for", "changes", "in", "the", "primary", "attribute", "."], "add_tokens": "public final String getPrimaryUserAttribute ( PortletRequest request ) {", "del_tokens": "protected final String getPrimaryUserAttribute ( PortletRequest request ) {", "commit_type": "create"}
{"commit_tokens": ["Changed", "to", "not", "clear", "the", "map", "when", "finish", "()", "is", "called", ".", "If", "we", "do", "that", "nothing", "will", "ever", "be", "returned", "from", "getResultMap", "()", "."], "add_tokens": "/ * * * No - op . *", "del_tokens": "/ * ( non - Javadoc ) this . resultMap . clear ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Removes", "unneeded", "exception", "in", "signature", "."], "add_tokens": "private void waitForServerStartup ( StopWatch watch , Map < String , String > connectConfig ) throws IOException", "del_tokens": "private void waitForServerStartup ( StopWatch watch , Map < String , String > connectConfig ) throws UnknownHostException , IOException", "commit_type": "remove"}
{"commit_tokens": ["Changed", "map", "type", "in", "groups", "parser"], "add_tokens": "import java . util . TreeMap ; Map < String , LocationGroup > groups = new TreeMap < String , LocationGroup > ( ) ;", "del_tokens": "import java . util . HashMap ; Map < String , LocationGroup > groups = new HashMap < String , LocationGroup > ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "to", "work", "on", "Unix", "."], "add_tokens": "Path thePath = null ; if ( Sys . isWindows ( ) ) { String path = uri . toString ( ) ; path = getWindowsPathIfNeeded ( path ) ; thePath = FileSystems . getDefault ( ) . getPath ( path ) ; } else { thePath = FileSystems . getDefault ( ) . getPath ( uri . getPath ( ) ) ; }", "del_tokens": "String path = uri . toString ( ) ; path = getWindowsPathIfNeeded ( path ) ; Path thePath = FileSystems . getDefault ( ) . getPath ( path ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "versioning", "@Singleton", "to", "prevent", "proxying"], "add_tokens": "import javax . inject . Singleton ; @ Singleton", "del_tokens": "import javax . enterprise . context . ApplicationScoped ; @ ApplicationScoped", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "a", "method", "was", "calling", "itself", "and", "therefore", "throwing", "a", "stack", "overflow", "error", "."], "add_tokens": "return getWrapperFactory ( ) . createCollection ( getRESTTranslatedContentSpecsWithQuery ( query ) , RESTTranslatedContentSpecV1 . class , false ) ;", "del_tokens": "return getWrapperFactory ( ) . createCollection ( getTranslatedContentSpecsWithQuery ( query ) , RESTTranslatedContentSpecV1 . class , false ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "show", "methods", "for", "Component", "owner"], "add_tokens": "import javax . swing . SwingUtilities ; import java . awt . Component ; public static boolean show ( Component owner , String title , String message ) { QuestionDialog dialog = new QuestionDialog ( title , message ) ; return dialog . show ( owner ) ; } public boolean show ( Component owner ) { Window window = null ; if ( owner != null ) { window = SwingUtilities . getWindowAncestor ( owner ) ; } return show ( window ) ; } Integer result = getDialog ( ) . show ( owner ) ;", "del_tokens": "Integer result = getDialog ( ) . show ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "Rendering", "Test", "Framework", "everyone", "and", "removed", "old", "one!"], "add_tokens": "import org . junit . runner . RunWith ; import org . xwiki . rendering . test . integration . RenderingTestSuite ; * Run all tests found in { @ code simple / * . test } files located in the classpath . These { @ code * . test } files must follow * the conventions described in { @ link org . xwiki . rendering . test . integration . TestDataParser } . * * @ since 3.0 RC1 @ RunWith ( RenderingTestSuite . class ) @ RenderingTestSuite . Scope ( \"simple\" ) public class SimpleIntegrationTests", "del_tokens": "import junit . framework . TestCase ; import org . xwiki . rendering . scaffolding . RenderingTestSuite ; import org . xwiki . rendering . wiki . WikiModel ; import org . xwiki . test . ComponentManagerTestSetup ; * Rendering tests not requiring a { @ link WikiModel } implementation ( ie tests that don 't need the notion of Wiki to * run ) . * * @ since 2.0 M1 public class SimpleRenderingTests extends TestCase public static junit . framework . Test suite ( ) throws Exception { RenderingTestSuite suite = new RenderingTestSuite ( \"Rendering tests not requiring the wiki notion\" , \"simple\" ) ; return new ComponentManagerTestSetup ( suite ) ; }", "commit_type": "use"}
{"commit_tokens": ["Add", "simple", "thank", "you", "dialog"], "add_tokens": "showSimpleDialogIfNeeded ( ) ; private void showSimpleDialogIfNeeded ( ) { final boolean shouldShowSimpleDialog = mBtnThankYouAction . getVisibility ( ) == GONE && mLayoutFacebook . getVisibility ( ) == GONE && mLayoutTwitter . getVisibility ( ) == GONE ; if ( shouldShowSimpleDialog && mThankYouLayoutListener != null ) { mThankYouLayoutListener . onShouldShowSimpleDialog ( ) ; } }", "del_tokens": "import android . annotation . TargetApi ;", "commit_type": "add"}
{"commit_tokens": ["Added", "serial", "version", "UID", "."], "add_tokens": "/ * * * * / private static final long serialVersionUID = 5382795596398809726L ; final List < ByteBuffer > lsData = new ArrayList < ByteBuffer > ( 6 ) ;", "del_tokens": "final List < ByteBuffer > lsData = new ArrayList < ByteBuffer > ( 6 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "when", "month", "or", "year", "spinner", "was", "left", "as", "default"], "add_tokens": "return getInteger ( this . monthSpinner ) ; return getInteger ( this . yearSpinner ) ; private Integer getInteger ( Spinner spinner ) { try { return Integer . parseInt ( spinner . getSelectedItem ( ) . toString ( ) ) ; } catch ( NumberFormatException e ) { return 0 ; } }", "del_tokens": "return Integer . parseInt ( this . monthSpinner . getSelectedItem ( ) . toString ( ) ) ; return Integer . parseInt ( this . yearSpinner . getSelectedItem ( ) . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "more", "types", "to", "be", "used", "as", "the", "id", "(", "like", "dbref", "/", "key", "/", "enum", "/", "etc", ")"], "add_tokens": "try { Object dbIdValue = objectFromValue ( mc . getIdField ( ) . getType ( ) , dbId ) ; if ( ! dbIdValue . equals ( value ) ) throw new RuntimeException ( \"id mismatch: \" + value + \" != \" + dbIdValue + \" for \" + entity . getClass ( ) . getName ( ) ) ; mc . getIdField ( ) . set ( entity , dbIdValue ) ; dbObject . put ( ID_KEY , objectToValue ( asObjectIdMaybe ( value ) ) ) ;", "del_tokens": "try { if ( ! dbId . equals ( value ) ) throw new RuntimeException ( \"id mismatch: \" + value + \" != \" + dbId + \" for \" + entity . getClass ( ) . getName ( ) ) ; //set the id field with the \"new\" value if ( dbId instanceof ObjectId && mc . getIdField ( ) . getType ( ) . isAssignableFrom ( String . class ) ) { dbId = dbId . toString ( ) ; } mc . getIdField ( ) . set ( entity , dbId ) ; dbObject . put ( ID_KEY , asObjectIdMaybe ( value ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "blacklist", "on", "mirror", "consumer"], "add_tokens": "this . blackListTopics = Arrays . asList ( consumerConfig . getMirrorTopicsBlackList ( ) . split ( \",\" ) ) ;", "del_tokens": "this . blackListTopics = Arrays . asList ( consumerConfig . getMirrorTopicsWhitelist ( ) . split ( \",\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "kryo", "s", "default", "instantiator", "strategy", "with", "objenesis", "fallback", "."], "add_tokens": "* For instance , if you don 't care about GWT, you can let Kryo make a deep copy for you like that * kryo . setInstantiatorStrategy ( new DefaultInstantiatorStrategy ( new StdInstantiatorStrategy ( ) ) ) ;", "del_tokens": "* For instance , you can let Kryo make a deep copy for you like that * kryo . setInstantiatorStrategy ( new StdInstantiatorStrategy ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "quotes", "around", "command", "line", "parameters", "when", "required", "..."], "add_tokens": "commandLine . createArgument ( ) . setValue ( it . next ( ) . toString ( ) ) ;", "del_tokens": "commandLine . createArgument ( ) . setLine ( it . next ( ) . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "test", "for", "sub", "-", "builder", "creation"], "add_tokens": "withValueMethod . body ( ) . assign ( JExpr . _this ( ) . ref ( builderField ) , nullSafe ( param , JExpr . _new ( builderFieldElementType ) . arg ( JExpr . _this ( ) ) . arg ( param ) . arg ( JExpr . FALSE ) ) ) ;", "del_tokens": "withValueMethod . body ( ) . assign ( JExpr . _this ( ) . ref ( builderField ) , JExpr . _new ( builderFieldElementType ) . arg ( JExpr . _this ( ) ) . arg ( param ) . arg ( JExpr . FALSE ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "FilterFactory", "interface", "and", "default", "implementation", "to", "allow", "other", "methods", "of", "instantiating", "dynamically", "compiled", "ZuulFilters"], "add_tokens": "static FilterFactory FILTER_FACTORY = new DefaultFilterFactory ( ) ; / * * * Sets a FilterFactory * * @ param factory * / public void setFilterFactory ( FilterFactory factory ) { FILTER_FACTORY = factory ; } filter = ( ZuulFilter ) FILTER_FACTORY . newInstance ( clazz ) ; filter = ( ZuulFilter ) FILTER_FACTORY . newInstance ( clazz ) ;", "del_tokens": "filter = ( ZuulFilter ) clazz . newInstance ( ) ; filter = ( ZuulFilter ) clazz . newInstance ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "getAll", "methods", "for", "object", "and", "document", "crud", "mixins"], "add_tokens": "import java . util . Iterator ; * @ param < T > entity type ( if not specified then getAll method will not work ) public interface DocumentCrudMixin < T > { / * * * NOTE : works only if generic parameter set . Method can 't be used in case when queried type doesn' t have * class reference . * * @ return all records of type * / Iterator < ODocument > getAll ( ) ;", "del_tokens": "public interface DocumentCrudMixin {", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "boolean", "and", "Boolean"], "add_tokens": "} else if ( matches ( Integer . class , type ) || matches ( int . class , type ) || matches ( Boolean . class , type ) || matches ( boolean . class , type ) || matches ( Date . class , type ) || matches ( Long . class , type )", "del_tokens": "} else if ( matches ( Integer . class , type ) || matches ( int . class , type ) || matches ( Date . class , type ) || matches ( Long . class , type )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "bug", "with", "Record", "attributes"], "add_tokens": "} else if ( this . typeAAAARecordAttributes . getName ( ) != null ) { return this . typeAAAARecordAttributes . getName ( ) ;", "del_tokens": "return this . typeAAAARecordAttributes . getName ( ) ; } else if ( this . typeAAAARecordAttributes . getName ( ) != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "LoadBalanceAlgorithm", "to", "reeturn", "null", "if", "no", "valid", "choice", "can", "be", "made", "."], "add_tokens": "if ( ! iter . hasNext ( ) ) { return null ; }", "del_tokens": "Preconditions . checkArgument ( iter . hasNext ( ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "some", "compiler", "warning", "related", "to", "type", "paramaters", "and", "unused", "imports", "."], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import android . widget . AdapterView ; import android . widget . ArrayAdapter ; import android . widget . Button ; import android . widget . EditText ; import android . widget . LinearLayout ; import android . widget . Spinner ; import android . widget . TextView ; ArrayAdapter < String > adapter = new ArrayAdapter < String > ( activity , android . R . layout . simple_spinner_item , optionNames ) ;", "del_tokens": "import android . widget . * ; import java . util . ArrayList ; import java . util . List ; ArrayAdapter adapter = new ArrayAdapter ( activity , android . R . layout . simple_spinner_item , optionNames ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "tests", "and", "some", "documentation"], "add_tokens": "import static org . hamcrest . CoreMatchers . not ; import static org . hamcrest . CoreMatchers . nullValue ; this . migrationRepository = new MigrationRepository ( \"cassandra/migrationtest/successful\" ) ; @ Test public void shouldThrowExceptionWhenCqlScriptWithoutVersionGiven ( ) { MigrationException exception = null ; try { new MigrationRepository ( \"cassandra/migrationtest/failing/wrongnaming\" ) ; } catch ( MigrationException e ) { exception = e ; } assertThat ( exception , is ( not ( nullValue ( ) ) ) ) ; assertThat ( exception . getScriptName ( ) , is ( equalTo ( \"init.cql\" ) ) ) ; assertThat ( exception . getStatement ( ) , is ( nullValue ( ) ) ) ; assertThat ( exception . getMessage ( ) , is ( not ( nullValue ( ) ) ) ) ; } @ Test public void shouldReturnZeroAsVersionWhenEmptyDirectoryGiven ( ) { MigrationRepository repository = new MigrationRepository ( \"cassandra/migrationtest/empty\" ) ; assertThat ( repository . getLatestVersion ( ) , is ( equalTo ( 0 ) ) ) ; } @ Test public void shouldReturnCorrectVersionNumberWhenPathWithLeadingSlashGiven ( ) { MigrationRepository repository = new MigrationRepository ( \"/cassandra/migrationtest/empty\" ) ; assertThat ( repository . getLatestVersion ( ) , is ( equalTo ( 0 ) ) ) ; }", "del_tokens": "this . migrationRepository = new MigrationRepository ( \"cassandra/migrationtest\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", ":", "setting", "readTimeout", "before", "opening", "of", "a", "connection", "had", "no", "effect", "."], "add_tokens": "socket . setSoTimeout ( getReadTimeout ( ) ) ; Modbus . log ( ) . warning ( \"Unable to close port: \" + e . getLocalizedMessage ( ) ) ; if ( isOpened ( ) ) { try { socket . setSoTimeout ( readTimeout ) ; } catch ( Exception e ) { Modbus . log ( ) . warning ( \"Unable to set readTimeout: \" + e . getLocalizedMessage ( ) ) ; }", "del_tokens": "socket . setSoTimeout ( Modbus . MAX_RESPONSE_TIMEOUT ) ; //do nothing try { socket . setSoTimeout ( readTimeout ) ; } catch ( Exception e ) { //do nothing", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "TreeStreamTest", "."], "add_tokens": "List < String > actual = TreeStream . depthFirst ( treeDef , getNode ( root ) )", "del_tokens": "List < String > stream = TreeStream . toParent ( TreeNode . treeDef ( ) , getNode ( root ) ) . map ( TreeNode :: getObj ) . collect ( Collectors . toList ( ) ) ; Assert . assertEquals ( actual , stream ) ; List < String > stream = TreeStream . breadthFirst ( TreeNode . treeDef ( ) , getNode ( root ) ) . map ( TreeNode :: getObj ) . collect ( Collectors . toList ( ) ) ; Assert . assertEquals ( actual , stream ) ; List < String > actual = TreeStream . depthFirst ( TreeNode . treeDef ( ) , getNode ( root ) ) List < String > stream = TreeStream . depthFirst ( TreeNode . treeDef ( ) , getNode ( root ) ) . map ( TreeNode :: getObj ) . collect ( Collectors . toList ( ) ) ; Assert . assertEquals ( actual , stream ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "usage", "of", "toJson", "function", "in", "RestClient"], "add_tokens": "return httpClient . post ( uri , withAuthorization ( withContentType ( MediaTypes . HAL ) ) , data , type ) ;", "del_tokens": "return httpClient . post ( uri , withAuthorization ( withContentType ( MediaTypes . HAL ) ) , toJson ( data ) , type ) ;", "commit_type": "remove"}
{"commit_tokens": ["Removing", "previosly", "added", "System", ".", "out", ".", "prinltn", "s"], "add_tokens": "texts [ i ] = item . getText ( ) ;", "del_tokens": "System . out . println ( \"======================\" ) ; System . out . println ( \"Clicking menu . Indexes: \" + Arrays . toString ( indexes ) ) ; System . out . println ( \"Calling component.getMenu for \" + indexes [ 0 ] ) ; System . out . println ( \"Got \" + menu ) ; System . out . println ( \"Calling component.getMenuComponent for \" + indexes [ i ] ) ; System . out . println ( \"Got \" + item ) ; ; texts [ i ] = item . getText ( ) ; System . out . println ( \"Calling component.getMenuComponent for \" + indexes [ i ] ) ; System . out . println ( \"Got \" + menu ) ; System . out . println ( \"Callig clickMouse for \" + texts [ texts . length - 1 ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["updated", "to", "latest", "GH", "master"], "add_tokens": "new DijkstraBidirectionRef ( queryGraph , weighting , traversalMode ) ;", "del_tokens": "new DijkstraBidirectionRef ( queryGraph , encoder , weighting , traversalMode ) ;", "commit_type": "update"}
{"commit_tokens": ["Implement", "a", "Parser", "instead", "of", "RegExp"], "add_tokens": "import static org . junit . Assert . * ; new NormalVersion (", "del_tokens": "import static org . junit . Assert . * ; NormalVersion v = new NormalVersion ( @ Test public void shouldHaveStaticFactoryMethod ( ) { NormalVersion v = NormalVersion . valueOf ( \"1.2.3\" ) ; assertEquals ( 1 , v . getMajor ( ) ) ; assertEquals ( 2 , v . getMinor ( ) ) ; assertEquals ( 3 , v . getPatch ( ) ) ; }", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "for", "the", "offset", "(", "Integer", "startRows", ")", "method", "on", "the", "QueryBuilder", ".", "Not", "supported", "on", "all", "database", "types", "."], "add_tokens": "public void appendLimitValue ( StringBuilder sb , int limit , Integer offset ) { sb . append ( \"LIMIT \" ) ; if ( offset == null ) { sb . append ( \"0 \" ) ; } else { sb . append ( offset ) . append ( ' ' ) ; } sb . append ( limit ) . append ( ' ' ) ; } @ Override public boolean isOffsetLimitArgument ( ) { return true ; } @ Override public void appendOffsetValue ( StringBuilder sb , int offset ) { throw new IllegalStateException ( \"Offset is part of the LIMIT in database type \" + getClass ( ) ) ;", "del_tokens": "public void appendLimitValue ( StringBuilder sb , int limit ) { sb . append ( \"LIMIT 0 \" ) . append ( limit ) . append ( ' ' ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "name", "collision", "+", "minor", "cleanup"], "add_tokens": "String emptyB1 = \"public static EmptyTag \" + tag + \"(Attr.ShortForm shortAttr)\" ; String containerD1 = \"public static ContainerTag \" + tag + \"(Attr.ShortForm shortAttr)\" ; String containerE1 = \"public static ContainerTag \" + tag + \"(Attr.ShortForm shortAttr, String text)\" ; String containerF1 = \"public static ContainerTag \" + tag + \"(Attr.ShortForm shortAttr, DomContent... dc)\" ;", "del_tokens": "String emptyB1 = \"public static EmptyTag \" + tag + \"(Attr.Shortform shortAttr)\" ; String containerD1 = \"public static ContainerTag \" + tag + \"(Attr.Shortform shortAttr)\" ; String containerE1 = \"public static ContainerTag \" + tag + \"(Attr.Shortform shortAttr, String text)\" ; String containerF1 = \"public static ContainerTag \" + tag + \"(Attr.Shortform shortAttr, DomContent... dc)\" ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "non", "-", "empty", "string", "for", "metrics", "scope", "fix", "missing", "metrics"], "add_tokens": "this ( cube , db , batchSize , maxBatchAgeMs , syncLevel , null ) ;", "del_tokens": "this ( cube , db , batchSize , maxBatchAgeMs , syncLevel , \"\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "LifecycleException", "when", "stopping", "Tomcat"], "add_tokens": "private Realm realm ; // Use a NullRealm if no Realm was specified. Realm realm = this . realm ; if ( realm == null ) { realm = new NullRealm ( ) ; }", "del_tokens": "private static final Realm NULL_REALM = new NullRealm ( ) ; private Realm realm = NULL_REALM ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "hacker", "detection", "to", "CompositeQuery", "demo"], "add_tokens": "import com . ocpsoft . rewrite . servlet . config . Redirect ; EncodeQuery encodeQuery = EncodeQuery . params ( ) . to ( \"c\" ) ; encodeQuery . onChecksumFailure ( Redirect . temporary ( context . getContextPath ( ) + \"/hacker\" ) ) ; * If hacking is detected , redirect to the hackers page . . defineRule ( ) . perform ( encodeQuery ) . addRule ( Join . path ( \"/\" ) . to ( \"/index.xhtml\" ) ) . addRule ( Join . path ( \"/hacker\" ) . to ( \"/hacker.xhtml\" ) ) ;", "del_tokens": ". defineRule ( ) . perform ( EncodeQuery . params ( ) . to ( \"c\" ) ) . addRule ( Join . path ( \"/\" ) . to ( \"/index.xhtml\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "typo", "in", "a", "comment"], "add_tokens": "* Evaluates to a value used as a multiplier for generating the next delay for", "del_tokens": "* Evaluates to a vaule used as a multiplier for generating the next delay for", "commit_type": "fix"}
{"commit_tokens": ["changed", "up", "several", "metric", "params"], "add_tokens": "import static com . mapbox . services . android . navigation . v5 . navigation . NavigationConstants . NAVIGATION_NOTIFICATION_ID ; import static com . mapbox . services . android . navigation . v5 . navigation . NavigationHelper . buildInstructionString ;", "del_tokens": "import static com . mapbox . services . android . navigation . v5 . navigation . NavigationConstants . NAVIGATION_NOTIFICATION_ID ; import static com . mapbox . services . android . navigation . v5 . navigation . NavigationHelper . buildInstructionString ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "type", "of", "sub", "-", "ranges", "on", "Range", "type"], "add_tokens": "List < String > getRanges ( ) ; void setRanges ( List < String > ranges ) ;", "del_tokens": "List < Range > getRanges ( ) ; void setRanges ( List < Range > ranges ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "javadoc", "changed", "name", "of", "session", "id", "provider"], "add_tokens": "/ * * * The underlying { @ link SauceOnDemandSessionIdProvider } instance which contains the Selenium session id . This is typically * the unit test being executed . * / private final SauceOnDemandSessionIdProvider sessionIdProvider ; / * * * The instance of the Sauce OnDemand Java REST API client . * / public SauceOnDemandTestWatcher ( SauceOnDemandSessionIdProvider sessionIdProvider ) { public SauceOnDemandTestWatcher ( SauceOnDemandSessionIdProvider sessionIdProvider , SauceOnDemandAuthentication authentication ) { public SauceOnDemandTestWatcher ( SauceOnDemandSessionIdProvider sessionIdProvider , final String username , final String accessKey ) { * Invoked if the unit test passes without error or failure . Invokes the Sauce REST API to mark the Sauce Job * as 'passed' . * @ param description not used * Invoked if the unit test either throws an error or fails . Invokes the Sauce REST API to mark the Sauce Job * as 'failed' . * @ param e not used * @ param description not used", "del_tokens": "private final SessionIdProvider sessionIdProvider ; public SauceOnDemandTestWatcher ( SessionIdProvider sessionIdProvider ) { public SauceOnDemandTestWatcher ( SessionIdProvider sessionIdProvider , SauceOnDemandAuthentication authentication ) { public SauceOnDemandTestWatcher ( SessionIdProvider sessionIdProvider , final String username , final String accessKey ) { * @ param description * * @ param e * @ param description", "commit_type": "update"}
{"commit_tokens": ["Fix", "whitespace", "in", "logging", "."], "add_tokens": "getLogger ( ) . debug ( \"Creating a table with databaseObject: \" + databaseObject . getClass ( ) . getName ( ) + \" in database \" + databaseName + \" with sourceAttribute \" + this . sourceId ) ;", "del_tokens": "getLogger ( ) . debug ( \"Creating a table with databaseObject: \" + databaseObject . getClass ( ) . getName ( ) + \"in database \" + databaseName + \" with sourceAttribute \" + this . sourceId ) ;", "commit_type": "fix"}
{"commit_tokens": ["improve", "jwt", "parser", "memory", "allocation"], "add_tokens": "CharSequence tokenSeq = Strings . clean ( sb ) ; String token = tokenSeq != null ? tokenSeq . toString ( ) : null ; sb . setLength ( 0 ) ;", "del_tokens": "String token = Strings . clean ( sb . toString ( ) ) ; sb = new StringBuilder ( 128 ) ;", "commit_type": "improve"}
{"commit_tokens": ["updated", "X", "-", "Pages", "example"], "add_tokens": "/ * * * Step 1 : Get first page * / //Get market orders (the complexity here is error handling that retries on failure) / * * * Step 2 : Safely get X - Pages header * / / * * * Step 3 : Get the rest of the pages . * * This can be done in threads * For public endpoints ApiClient is fully thread safe . * For authorized endpoints one instance of ApiClient is required per refresh token * / for ( int i = 2 ; i <= xPages ; i ++ ) { //For each page greater than one.", "del_tokens": "//Get market orders //Step 2: Safely get X-Pages header //Step 3: Get the rest of the pages //For each page greater than one. This can be done in threads, but, require a new ApiClient and MarketApi for each thread for ( int i = 2 ; i <= xPages ; i ++ ) {", "commit_type": "update"}
{"commit_tokens": ["adding", "ruben", "s", "changes", "with", "visitor", "data", ".", "starting", "to", "separate", "the", "network", "dispatcher", "."], "add_tokens": "// utm_source query parameter See the Marketing Campaign Tracking", "del_tokens": "// utm_source query parameter See the Marketing Campaign Tracking", "commit_type": "add"}
{"commit_tokens": ["Add", "NA2", "with", "chat", ".", "na2", ".", "lol", ".", "riotgames", ".", "com", "address", "."], "add_tokens": "NA ( \"chat.na1.lol.riotgames.com\" , \"na.api.pvp.net\" , RIOT ) , / * * * North - America # 2 * / NA2 ( \"chat.na2.lol.riotgames.com\" , \"na.api.pvp.net\" , RIOT ) ,", "del_tokens": "NA ( \"chat.na1.lol.riotgames.com\" , \"na.api.pvp.net\" , RIOT ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "overwrite", "parameter", "to", "the", "POST", "and", "PUT", "methods"], "add_tokens": "private Boolean m_overwrite = null ; @ IXSetterReflector ( name = \"overwrite\" ) public void setOverwrite ( boolean overwrite ) { m_overwrite = overwrite ; } StringBuilder uri = new StringBuilder ( ) ; uri . append ( getPath ( ) ) ; String delim = \"?\" ; if ( m_overwrite != null ) { uri . append ( delim + \"overwrite=\" + m_overwrite ) ; delim = \"&\" ; } executeRequest ( \"POST\" , uri . toString ( ) , getBody ( ) , getBodyFormat ( ) ) ; private Boolean m_overwrite = null ; @ IXSetterReflector ( name = \"overwrite\" ) public void setOverwrite ( boolean overwrite ) { m_overwrite = overwrite ; } StringBuilder uri = new StringBuilder ( ) ; uri . append ( getPath ( ) ) ; String delim = \"?\" ; if ( m_overwrite != null ) { uri . append ( delim + \"overwrite=\" + m_overwrite ) ; delim = \"&\" ; } executeRequest ( \"PUT\" , uri . toString ( ) , getBody ( ) , getBodyFormat ( ) ) ;", "del_tokens": "executeRequest ( \"POST\" , getPath ( ) , getBody ( ) , getBodyFormat ( ) ) ; executeRequest ( \"PUT\" , getPath ( ) , getBody ( ) , getBodyFormat ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "placement", "and", "wording", "of", "the", "comment", "for", "clearer", "description", "."], "add_tokens": "// Since the CSV file has the most recent trades at the top of the file, we'll reverse the list to feed the List<Tick> correctly.", "del_tokens": "// Looks like the CSV file has the most recent trades at the top of the file - will need to reverse the resulting list.", "commit_type": "change"}
{"commit_tokens": ["Add", "parameter", "for", "controlling", "the", "output", "directory"], "add_tokens": "@ Parameter ( defaultValue = \"${project.build.outputDirectory}\" , required = true , readonly = true ) / * * * / @ Parameter ( defaultValue = \"${project.build.outputDirectory}/META-INF/services\" , required = true ) private File outputDirectory ; private File getOutputDirectory ( ) { return outputDirectory ; } @ Override throws MojoExecutionException { File parentFolder = getOutputDirectory ( ) ; List < Class < ? > > interfaceClasses ) throws MojoExecutionException { classNamesIter . remove ( ) ; break ;", "del_tokens": "@ Parameter ( defaultValue = \"${project.build.directory}/classes\" , required = true , readonly = true ) throws MojoExecutionException { // TODO give the user an option to write them to the source folder or // any other folder? File parentFolder = new File ( getClassFolder ( ) , \"META-INF\" + File . separator + \"services\" ) ; List < Class < ? > > interfaceClasses ) throws MojoExecutionException { classNamesIter . remove ( ) ; break ;", "commit_type": "add"}
{"commit_tokens": ["Moving", "the", "v1", "client", "into", "its", "own", "package", "updating", "the", "runIt", ".", "bat", "with", "new", "location", "."], "add_tokens": "package com . yubico . client . v1 ; System . err . println ( \"\\nUsage: java com.yubico.client.v1.YubicoClient Auth_ID OTP\" ) ; System . err . println ( \"\\nEg. java com.yubico.client.v1.YubicoClient 28 vvfucnlcrrnejlbuthlktguhclhvegbungldcrefbnku\" ) ;", "del_tokens": "package com . yubico ; System . err . println ( \"\\nUsage: java com.yubico.YubicoClient Auth_ID OTP\" ) ; System . err . println ( \"\\nEg. java com.yubico.YubicoClient 28 vvfucnlcrrnejlbuthlktguhclhvegbungldcrefbnku\" ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "support", "for", "argument", "handling", "."], "add_tokens": "import org . jspringbot . argument . ArgumentHandlerRegistry ; Object [ ] handledParams = ArgumentHandlerRegistry . REGISTRY . handlerArguments ( params ) ; return ( ( Keyword ) context . getBean ( keywordToBeanMap . get ( keyword ) ) ) . execute ( handledParams ) ;", "del_tokens": "return ( ( Keyword ) context . getBean ( keywordToBeanMap . get ( keyword ) ) ) . execute ( params ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "bug", "of", "form", "upload", "with", "mime", "type", "set", "but", "not", "work", "."], "add_tokens": "if ( options != null && options . mimeType != null && ! options . mimeType . equals ( \"\" ) ) {", "del_tokens": "if ( options != null && options . mimeType != null && options . mimeType . equals ( \"\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "where", "a", "missing", "typeName", "query", "result", "could", "end", "up", "with", "an", "extra", ".", "in", "the", "path", "."], "add_tokens": "* * * * * if ( typeName != null && typeName . length ( ) > 0 ) { if ( typeName != null && typeName . length ( ) > 0 ) { *", "del_tokens": "* * * * * if ( typeName != null ) { if ( typeName != null ) { *", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "regression", "of", "FLEX", "-", "163"], "add_tokens": "// If available, invoke the MessageBroker.createThreadLocalObjects() method: Method createThreadLocalObjMethod = ReflectionUtils . findMethod ( MessageBroker . class , \"createThreadLocalObjects\" ) ; if ( createThreadLocalObjMethod != null ) { ReflectionUtils . invokeMethod ( createThreadLocalObjMethod , null ) ; } // If available, invoke the MessageBroker.releaseThreadLocalObjects() method: Method releaseThreadLocalObjMethod = ReflectionUtils . findMethod ( MessageBroker . class , \"releaseThreadLocalObjects\" ) ; if ( releaseThreadLocalObjMethod != null ) { ReflectionUtils . invokeMethod ( releaseThreadLocalObjMethod , null ) ; }", "del_tokens": "MessageBroker . createThreadLocalObjects ( ) ; MessageBroker . releaseThreadLocalObjects ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Creating", "and", "Upgrading", "database", "can", "be", "done", "overriding", "proper", "provider"], "add_tokens": "openHelper = new ProviGenOpenHelper ( getContext ( ) , this , contractHolder ) ; public void onCreateDatabase ( SQLiteDatabase database ) { openHelper . autoCreateDatabase ( database ) ; } public void onUpgradeDatabase ( SQLiteDatabase database , int oldVersion , int newVersion ) { openHelper . autoUpgradeDatabase ( database , oldVersion , newVersion ) ; openHelper = new ProviGenOpenHelper ( getContext ( ) , this , contractHolder ) ;", "del_tokens": "if ( openHelper == null ) { openHelper = new ProviGenOpenHelper ( getContext ( ) , contractHolder ) ; } else { openHelper . setContractHolder ( contractHolder ) ; } public void setProviGenOpenHelper ( ProviGenOpenHelper proviGenOpenHelper ) { openHelper = proviGenOpenHelper ; if ( openHelper != null ) { openHelper . setContractHolder ( contractHolder ) ; }", "commit_type": "create"}
{"commit_tokens": ["Add", "support", "for", "viewing", "in", "-", "memory", "ZIP", "/", "JAR", "files", "as", "FileSystems", "using", "FileSystems", ".", "newFileSystem", "(", "Path", "ClassLoader", ")", "."], "add_tokens": "return getFileSystem ( ) . provider ( ) . toUri ( this ) ;", "del_tokens": "String uri = fs . provider ( ) . getScheme ( ) + \"://\" + fs + \"/\" + toAbsolutePath ( ) . toString ( ) ; return URI . create ( uri ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "stage", "-", "library", "localization", "all", "the", "way", "to", "the", "rest", "API"], "add_tokens": "import java . util . Locale ; private final StageLibrary stageLibrary ; private final Locale locale ; public StageLibraryResource ( StageLibrary stageLibrary , Locale locale ) { this . locale = locale ; return Response . ok ( ) . type ( MediaType . APPLICATION_JSON ) . entity ( stageLibrary . getStages ( locale ) ) . build ( ) ;", "del_tokens": "private StageLibrary stageLibrary ; public StageLibraryResource ( StageLibrary stageLibrary ) { return Response . ok ( ) . type ( MediaType . APPLICATION_JSON ) . entity ( stageLibrary . getStages ( ) ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "ActionProcessButton", "progress", "indicator", "height"], "add_tokens": "import com . dd . processbutton . R ; double indicatorHeight = getDimension ( R . dimen . layer_padding ) ; int bottom = ( int ) ( getMeasuredHeight ( ) - indicatorHeight ) ;", "del_tokens": "double indicatorHeightPercent = 0.05 ; // 5% int bottom = ( int ) ( getMeasuredHeight ( ) - getMeasuredHeight ( ) * indicatorHeightPercent ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "failing", "Jenkins", "build", "."], "add_tokens": "st . execute ( \"DROP TABLE IF EXISTS input_table;\" + \"CREATE TABLE input_table(the_geom Polygon);\" + st . execute ( \"DROP TABLE input_table;\" ) ; st . execute ( \"DROP TABLE IF EXISTS input_table;\" + \"CREATE TABLE input_table(the_geom Polygon);\" + st . execute ( \"DROP TABLE input_table;\" ) ; st . execute ( \"DROP TABLE IF EXISTS input_table;\" + \"CREATE TABLE input_table(smallc Polygon, bigc Polygon);\" + st . execute ( \"DROP TABLE input_table;\" ) ; st . execute ( \"DROP TABLE IF EXISTS input_table;\" + \"CREATE TABLE input_table(geomA Polygon, geomB Polygon);\" + st . execute ( \"DROP TABLE input_table;\" ) ;", "del_tokens": "st . execute ( \"CREATE TABLE input_table(the_geom Polygon);\" + st . execute ( \"CREATE TABLE input_table(the_geom Polygon);\" + st . execute ( \"CREATE TABLE input_table(smallc Polygon, bigc Polygon);\" + st . execute ( \"CREATE TABLE input_table(geomA Polygon, geomB Polygon);\" +", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "expiration", "time"], "add_tokens": "this ( name , observer , Integer . MAX_VALUE , Long . MAX_VALUE ) ; this ( name , observer , queueSize , Long . MAX_VALUE ) ; long cutoff = System . currentTimeMillis ( ) - expireTime ; if ( update . getTimestamp ( ) < cutoff ) {", "del_tokens": "this ( name , observer , Integer . MAX_VALUE , - 1 ) ; this ( name , observer , queueSize , - 1 ) ; if ( ( System . currentTimeMillis ( ) - expireTime ) < update . getTimestamp ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Change", "default", "name", "of", "an", "re", "-", "uploaded", "files", ".", "In", "case", "there", "is", "already", "a", "key", "with", "the", "same", "name", "(", "dataset", ".", "hex", ")", "default", "name", "would", "include", "number", "so", "that", "the", "new", "file", "is", "unique", "(", "e", ".", "g", ".", "dataset1", ".", "hex", "dataset2", ".", "hex", "...", ")", "."], "add_tokens": "int i = 0 ; String res = n + \".hex\" ; Key k = Key . make ( res ) ; while ( DKV . get ( k ) != null ) k = Key . make ( res = n + ++ i + \".hex\" ) ; return res ;", "del_tokens": "String dst = n + \".hex\" ; return dst ;", "commit_type": "change"}
{"commit_tokens": ["make", "two", "internal", "EncodedText", "methods", "private"], "add_tokens": "private static String bytesToString ( byte [ ] bytes , String characterSet ) throws CharacterCodingException { private static byte [ ] stringToBytes ( String s , String characterSet ) {", "del_tokens": "public static String bytesToString ( byte [ ] bytes , String characterSet ) throws CharacterCodingException { public static byte [ ] stringToBytes ( String s , String characterSet ) {", "commit_type": "make"}
{"commit_tokens": ["allow", "disabling", "the", "text", "above", "the", "thumb", "sliders", "from", "xml"], "add_tokens": "private boolean mShowTextAboveThumbs ; mShowTextAboveThumbs = true ; mShowTextAboveThumbs = a . getBoolean ( R . styleable . RangeSeekBar_valuesAboveThumbs , true ) ; mTextOffset = ! mShowTextAboveThumbs ? 0 : this . mTextSize + PixelUtil . dpToPx ( context , if ( mShowTextAboveThumbs && ! selectedValuesAreDefault ) {", "del_tokens": "mTextOffset = this . mTextSize + PixelUtil . dpToPx ( context , if ( ! selectedValuesAreDefault ) {", "commit_type": "allow"}
{"commit_tokens": ["Updated", "models", "to", "use", "Regex", "constants"], "add_tokens": "import alpine . validation . RegexSequence ; @ Pattern ( regexp = RegexSequence . Definition . ALPHA_NUMERIC , message = \"The API key must contain only alpha and/or numeric characters\" )", "del_tokens": "@ Pattern ( regexp = \"[A-Za-z0-9]+\" , message = \"The API key must contain only alpha and/or numeric characters\" )", "commit_type": "update"}
{"commit_tokens": ["Moved", "the", "AquaCropTest", "to", "the", "right", "place", "."], "add_tokens": "data = agMIPFileLoader . readFile ( \"BDJE0XXX.AgMIP\" ) ) ; aquaCropConverter . writeFile ( \"BDJE0XXX_AquaCrop.tmp\" , data ) ;", "del_tokens": "// AdvancedHashMap<String,Object> result = // agMIPFileLoader.readFile(\"D:\\\\UserData\\\\projecten\\\\AGMIP\\\\Sentinel\\\\BDJE0XXX.AgMIP\"); aquaCropConverter . writeFile ( \"D:\\\\UserData\\\\projecten\\\\AGMIP\\\\Sentinel\\\\BDJE0XXX_AquaCrop.tmp\" , agMIPFileLoader . readFile ( \"D:\\\\UserData\\\\projecten\\\\AGMIP\\\\Sentinel\\\\BDJE0XXX.AgMIP\" ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "loading", "of", "countries", ".", "txt"], "add_tokens": "countryCodes = loadCountryCodes ( ADX_DICT + \"countries.txt\" ) ; private ImmutableMap < Object , CountryCodes > loadCountryCodes ( String resourceName ) { try ( InputStream is = new ResourceTransport ( ) . open ( resourceName ) ) { @ Override public InputStream open ( String url ) throws IOException { String resourceName = url . startsWith ( \"/\" ) ? url : new URL ( url ) . getPath ( ) ;", "del_tokens": "countryCodes = loadCountryCodes ( transport , ADX_DICT + \"countries.txt\" ) ; private ImmutableMap < Object , CountryCodes > loadCountryCodes ( Transport transport , String resourceName ) { try ( InputStream is = transport . open ( resourceName ) ) { private String resourceName ; public String getResourceName ( ) { return resourceName ; } public ResourceTransport setResourceName ( String resourceName ) { this . resourceName = resourceName ; return this ; } @ Override public InputStream open ( String url ) throws IOException { String resourceName = this . resourceName == null ? new URL ( url ) . getPath ( ) : this . resourceName ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "setOrdered", "(", "true", ")", "to", "StorageTransforms", ".", "Objects", ".", "GetMedia"], "add_tokens": "return input . apply ( ParDo . named ( \"StorageTransforms.Objects.GetMedia\" ) . of ( new ObjectsDoFn < StorageObject , T > ( applicationName ) { @ Override protected void processElement ( Storage . Objects objects , ProcessContext context ) throws IOException { StorageObject object = context . element ( ) ; for ( T t : deserialize ( objects . get ( object . getBucket ( ) , object . getName ( ) ) . executeMediaAsInputStream ( ) ) ) { context . output ( t ) ; } } } ) ) . setOrdered ( true ) ;", "del_tokens": "return input . apply ( ParDo . named ( \"StorageTransforms.Objects.GetMedia\" ) . of ( new ObjectsDoFn < StorageObject , T > ( applicationName ) { @ Override protected void processElement ( Storage . Objects objects , ProcessContext context ) throws IOException { StorageObject object = context . element ( ) ; for ( T t : deserialize ( objects . get ( object . getBucket ( ) , object . getName ( ) ) . executeMediaAsInputStream ( ) ) ) { context . output ( t ) ; } } } ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "forceReset", "handling", "and", "world", "seed", "specification", "."], "add_tokens": "FileWorldGenerator fwparams ; this . fwparams = ( FileWorldGenerator ) params ; if ( this . fwparams != null && this . fwparams . isForceReset ( ) ) return true ;", "del_tokens": "WorldSettings . GameType gameType ; FileWorldGenerator fwparams = ( FileWorldGenerator ) params ; this . gameType = GameType . SURVIVAL ; // Set the game mode. The best way to do this seems to be to set it in the TagCompound as follows; // this value is then used when adding the player to the game. NBTTagCompound tag = MinecraftServer . getServer ( ) . worldServers [ 0 ] . getWorldInfo ( ) . getPlayerNBTTagCompound ( ) ; if ( tag != null ) tag . setInteger ( \"playerGameType\" , this . gameType . getID ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "setup", "Toolbar", "from", "support", "appcompat", "-", "v7"], "add_tokens": "import android . support . v7 . widget . Toolbar ; / * * * Allow to use a toolbar without set it as action bar . * / private Toolbar mToolbar ; / * * * Set a toolbar which isn 't set as action bar. * * @ param toolbar toolbar . * / public void setToolbar ( Toolbar toolbar ) { mToolbar = toolbar ; } if ( Build . VERSION . SDK_INT >= Build . VERSION_CODES . KITKAT if ( mToolbar != null ) { actionBarHeight = mToolbar . getHeight ( ) ; } else if ( mHoldingActivity instanceof ActionBarActivity ) {", "del_tokens": "if ( Build . VERSION . SDK_INT == Build . VERSION_CODES . KITKAT if ( mHoldingActivity instanceof ActionBarActivity ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "issue", "related", "to", "the", "ripples", "effect"], "add_tokens": "boolean applyWavesEffect = false ; if ( ! waves . isEmpty ( ) ) { applyWavesEffect = true ; widget . getElement ( ) . addClassName ( \"waves-effect waves-\" + waves ) ; } if ( applyWavesEffect ) initWaves ( ) ; / * * * As materialize . js does not provide a init method we are calling displayEffect * directly . If Materialize ever change this function name we must change it here * as well . * / private native void initWaves ( ) / * - { $ wnd . Waves . displayEffect ( ) ; } - * / ;", "del_tokens": "if ( ! waves . isEmpty ( ) ) widget . getElement ( ) . addClassName ( \"waves-effect waves-\" + waves ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "of", "the", "failing", "unit", "tests", "."], "add_tokens": "Assert . assertTrue ( disease . getSamePrimaries ( ) . size ( ) > 0 ) ; Assert . assertTrue ( disease . getHistory ( ) . size ( ) > 0 ) ; Assert . assertNotNull ( disease . getSigns ( ) ) ; Assert . assertNotNull ( disease . getExams ( ) ) ; Assert . assertNotNull ( disease . getMortality ( ) ) ; Assert . assertEquals ( \"See abstractor notes\" , disease . getModuleId ( ) . get ( 0 ) . getValue ( ) ) ;", "del_tokens": "Assert . assertEquals ( 10 , disease . getSamePrimaries ( ) . size ( ) ) ; Assert . assertEquals ( 7 , disease . getHistory ( ) . size ( ) ) ; Assert . assertNull ( disease . getSigns ( ) ) ; Assert . assertNull ( disease . getExams ( ) ) ; Assert . assertNull ( disease . getMortality ( ) ) ; Assert . assertEquals ( \"M3 Module 5: PH10\" , disease . getModuleId ( ) . get ( 0 ) . getValue ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "calculating", "expiration", "time", "Must", "be", "calculated", "from", "the", "created_at", "not", "the", "current", "time"], "add_tokens": "DateTime createdAt = oAuthResponse . getCreateAt ( ) ; if ( expiresIn != null && createdAt != null ) { expiration = createdAt . plusSeconds ( expiresIn . intValue ( ) ) ;", "del_tokens": "if ( expiresIn != null ) { expiration = new DateTime ( System . currentTimeMillis ( ) + ( expiresIn * 1000 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "set", "system", "properties", "."], "add_tokens": "HELP_OPT ( \"h\" ) , //Shows help information, never used in this plugin.", "del_tokens": "HELP_OPT ( \"h\" ) ,", "commit_type": "add"}
{"commit_tokens": ["Fixing", "COALS", "bug", ":", "It", "was", "expecting", "15000", "words", "to", "exist", "which", "may", "not", "always", "be", "true", "."], "add_tokens": "if ( maxWords == 0 || maxWords > wordToSemantics . size ( ) )", "del_tokens": "if ( maxWords == 0 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "invoice", "pay", "and", "update", "methods"], "add_tokens": "public Invoice pay ( ) throws StripeException { return this . pay ( null ) ; } public Invoice update ( Map < String , Object > params ) throws StripeException { return update ( params , null ) ; } public Invoice update ( Map < String , Object > params , String apiKey ) throws StripeException { return request ( RequestMethod . POST , instanceURL ( Invoice . class , this . id ) , params , Invoice . class , apiKey ) ; } public Invoice pay ( String apiKey ) throws StripeException { return request ( RequestMethod . POST , String . format ( \"%s/pay\" , instanceURL ( Invoice . class , this . getId ( ) ) ) , null , Invoice . class , apiKey ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "typos", "in", "docs", "and", "log", "messages"], "add_tokens": "* Specifies a class that should be called each time the < code > BeaconService < / code > sees * activities or services set different MonitorNotifier instances , the last one set will receive * < code > Region < / code > object , and providing updates on the estimated mDistance every seconds while * an existing monitored Region .", "del_tokens": "* Specifies a class that should be called each time the < code > BeaconService < / code > gets sees * activities or services set different RangeNotifier instances , the last one set will receive * < code > Region < / code > object , and providing updates on the estimated mDistance very seconds while * and existing monitored Region .", "commit_type": "fix"}
{"commit_tokens": ["Add", "assertions", "for", "ObservableValue", "to", "public", "API"], "add_tokens": "import javafx . beans . value . * ; public static < T > ObservableValueAssert < T > assertThat ( ObservableValue < T > actual ) { return new ObservableValueAssert < > ( actual ) ; }", "del_tokens": "import javafx . beans . value . ObservableBooleanValue ; import javafx . beans . value . ObservableNumberValue ; import javafx . beans . value . ObservableObjectValue ; import javafx . beans . value . ObservableStringValue ;", "commit_type": "add"}
{"commit_tokens": ["Use", "context", "from", "WebPage", "in", "preference", "to", "request"], "add_tokens": "return ( req == null ) ? Serialization . XML : SerializationEE . getDefault ( getServletContext ( ) , req ) ;", "del_tokens": "return ( req == null ) ? Serialization . XML : SerializationEE . getDefault ( req . getServletContext ( ) , req ) ;", "commit_type": "use"}
{"commit_tokens": ["Improve", "upon", "the", "style", "system", "making", "it", "way", "clearer", "and", "easier", "to", "use"], "add_tokens": "import org . springframework . boot . WebApplicationType ; . web ( WebApplicationType . NONE ) ; ctx . close ( ) ;", "del_tokens": ". web ( false ) ;", "commit_type": "improve"}
{"commit_tokens": ["Move", "native", "API", "to", "SnappyNative", ".", "java"], "add_tokens": "String version = Snappy . getNativeLibraryVersion ( ) ; src . flip ( ) ; int maxCompressedLen = Snappy . getMaxCompressedLength ( src . remaining ( ) ) ; _logger . info ( \"max compressed length:\" + maxCompressedLen ) ; //long uncompressedLen = Snappy.getUncompressedLength(dest); //", "del_tokens": "String version = Snappy . nativeLibraryVersion ( ) ; Snappy . compress ( src , dest ) ; long uncompressedLen = Snappy . getUncompressedLength ( dest ) ; _logger . info ( \"uncompressed length:\" + uncompressedLen ) ;", "commit_type": "move"}
{"commit_tokens": ["adding", "isNew", "Flag", "to", "Users", "and", "Groups", "."], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import static org . junit . Assert . * ; assertFalse ( group . isNew ( ) ) ;", "del_tokens": "import java . util . ArrayList ; import java . util . List ; import static org . junit . Assert . * ;", "commit_type": "add"}
{"commit_tokens": ["Add", "events", "methods", "and", "iterator", "remove", "useless", "getInitial", "from", "iterators", "cleanup", "imports"], "add_tokens": "import com . asana . models . * ; import com . asana . models . Event ; for ( Event e : client . events . get ( \"29898626391464\" ) ) { System . out . println ( e . action ) ; }", "del_tokens": "import com . asana . models . ResultBody ; import com . asana . models . Task ; import com . asana . models . User ;", "commit_type": "add"}
{"commit_tokens": ["changed", "processInstanceId", "back", "into", "processDefinitionId", ".", "no", "clue", "how", "i", "managed", "to", "screw", "that", "one", "up", "in", "the", "first", "place"], "add_tokens": "* @ author Erik Winlof String processDefinitionId = getMandatoryPathParameter ( req , \"processDefinitionId\" ) ;", "del_tokens": "* @ author Erik Winl f String processDefinitionId = getMandatoryPathParameter ( req , \"processInstanceId\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "path", "to", "naether", "jar", "have", "tests", "use", "VERSION", "file", "for", "checking", "version"], "add_tokens": "import java . io . IOException ; import org . apache . commons . io . FileUtils ; public void createInstanceWithPomPath ( ) throws IOException { assertEquals ( FileUtils . readFileToString ( new File ( \"VERSION\" ) ) , mavenProject . getVersion ( ) ) ;", "del_tokens": "public void createInstanceWithPomPath ( ) { assertEquals ( \"0.5.0\" , mavenProject . getVersion ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "ModelDispAction", ".", "java", "not", "cache", "bug"], "add_tokens": "public void addModelCache ( String formName , Object keyValue , ModelHandler modelHandler , Object model ) {", "del_tokens": "private void addModelCache ( String formName , Object keyValue , ModelHandler modelHandler , Object model ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "test", "for", "string", "representations", "of", "composite", "objects"], "add_tokens": "return new MemberSourceProvider ( ) . getName ( descriptor . getMethod ( ) ) + \", line \" + descriptor . getLineNumber ( ) ; return new MemberSourceProvider ( ) . getName ( descriptor . getMethod ( ) ) + \", line \" + descriptor . getLineNumber ( ) ; return new MemberSourceProvider ( ) . getName ( descriptor . getInvokingMethod ( ) ) + \", line \" + descriptor . getLineNumber ( ) ;", "del_tokens": "return new MemberSourceProvider ( ) . getName ( descriptor . getMethod ( ) ) ; return new MemberSourceProvider ( ) . getName ( descriptor . getMethod ( ) ) ; return new MemberSourceProvider ( ) . getName ( descriptor . getInvokedMethod ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "initial", "_", "in", "security", "group", "names", "and", "prepped", "for", "build"], "add_tokens": "if ( i == 0 && Character . isDigit ( c ) || c == '_' || c == '-' ) { else if ( i > 0 && ( Character . isLetterOrDigit ( c ) ) ) {", "del_tokens": "if ( i == 0 && Character . isDigit ( c ) ) { else if ( i > 0 && ( Character . isLetterOrDigit ( c ) || c == '-' || c == '_' ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "getComment", "to", "trim", "more", "whitespace"], "add_tokens": "return trimmed . substring ( 1 ) . trim ( ) ;", "del_tokens": "return trimmed . substring ( 1 ) ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "isLessThan", "/", "isGreaterThan", "methods"], "add_tokens": "if ( day . compareTo ( lastDOM ) > 0 ) { if ( dayOfMonth . compareTo ( month . getLastDayOfMonth ( SAMPLE_YEAR ) ) > 0 ) {", "del_tokens": "if ( day . isGreaterThan ( lastDOM ) ) { if ( dayOfMonth . isGreaterThan ( month . getLastDayOfMonth ( SAMPLE_YEAR ) ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "HistogramRollup", "class", "and", "test"], "add_tokens": "public void computeFromRollups ( Points < ? extends Rollup > input ) throws IOException { // See this and get mind blown: // http://stackoverflow.com/questions/18907262/bounded-wildcard-related-compiler-error Map < Long , ? extends Points . Point < ? extends Rollup > > points = input . getPoints ( ) ; for ( Map . Entry < Long , ? extends Points . Point < ? extends Rollup > > item : points . entrySet ( ) ) { Rollup rollup = item . getValue ( ) . getData ( ) ; if ( ! ( rollup instanceof BasicRollup ) ) { throw new IOException ( \"Cannot create BasicRollup from type \" + rollup . getClass ( ) . getName ( ) ) ; } BasicRollup basicRollup = ( BasicRollup ) rollup ; public static BasicRollup buildRollupFromRollups ( Points < ? extends Rollup > input ) throws IOException {", "del_tokens": "public void computeFromRollups ( Points < BasicRollup > input ) throws IOException { Map < Long , Points . Point < BasicRollup > > points = input . getPoints ( ) ; for ( Map . Entry < Long , Points . Point < BasicRollup > > item : points . entrySet ( ) ) { BasicRollup basicRollup = item . getValue ( ) . getData ( ) ; public static BasicRollup buildRollupFromRollups ( Points < BasicRollup > input ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Use", "varargs", "for", "withXXXX", "collection", "methods", "."], "add_tokens": "import static io . sundr . builder . internal . functions . TypeAs . UNWRAP_ARRAY_OF ; JavaType unwraped = combine ( UNWRAP_COLLECTION_OF , UNWRAP_ARRAY_OF ) . apply ( property . getType ( ) ) ; JavaProperty arrayProperty = new JavaPropertyBuilder ( property ) . withType ( new JavaTypeBuilder ( unwraped ) . withArray ( true ) . build ( ) ) . withArray ( true ) . build ( ) ; . withArguments ( new JavaProperty [ ] { arrayProperty } )", "del_tokens": "JavaType unwraped = TypeAs . UNWRAP_ARRAY_OF . apply ( property . getType ( ) ) ; . withArguments ( new JavaProperty [ ] { property } )", "commit_type": "use"}
{"commit_tokens": ["Added", "validation", "for", "reading", "patient", "-", "level", "fields", "from", "flat", "file", "."], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "expected", "exception", "for", "http", "client", "unit", "test"], "add_tokens": "import org . junit . Rule ; import org . junit . rules . ExpectedException ; @ Rule public ExpectedException expectedException = ExpectedException . none ( ) ; expectedException . expect ( ViSearchException . class ) ; client = new ViSearchHttpClientImpl ( invalidEndpoint , validAccessKey , validSecretKey , mockedHttpClient ) ; client . get ( path , params ) ;", "del_tokens": "try { client = new ViSearchHttpClientImpl ( invalidEndpoint , validAccessKey , validSecretKey , mockedHttpClient ) ; client . get ( path , params ) ; assert ( false ) ; // should not be executed } catch ( Exception e ) { assertTrue ( e instanceof ViSearchException ) ; }", "commit_type": "use"}
{"commit_tokens": ["added", "exploded", "Turtle", "w", "/", "June"], "add_tokens": "ExplodedTurtle , Turtle , Spider", "del_tokens": "Turtle , Spider", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "use", "the", "PressGangCCMS", "Proxy", "Factory"], "add_tokens": "import org . jboss . pressgang . ccms . rest . v1 . client . PressGangCCMSProxyFactoryV1 ; client = PressGangCCMSProxyFactoryV1 . create ( serverUrl ) . getRESTClient ( ) ;", "del_tokens": "client = ProxyFactory . create ( RESTInterfaceV1 . class , serverUrl ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "the", "tests", "for", "SitemapParserBolt", "+", "showed", "how", "to", "use", "it", "in", "Topologgy", "(", "even", "if", "the", "demo", "spout", "doesn", "t", "currently", "generate", "a", "relevant", "URL", "and", "metadata", ")"], "add_tokens": "import com . digitalpebble . storm . crawler . bolt . SiteMapParserBolt ; builder . setBolt ( \"sitemap\" , new SiteMapParserBolt ( ) ) . localOrShuffleGrouping ( \"fetch\" ) ; \"sitemap\" ) ; . localOrShuffleGrouping ( \"sitemap\" , Constants . StatusStreamName )", "del_tokens": "\"fetch\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "getScaledTouchSlop", "rather", "than", "the", "deprecated", "getTouchSlop"], "add_tokens": "ViewConfiguration config = ViewConfiguration . get ( context ) ; mTouchSlop = config . getScaledTouchSlop ( ) ;", "del_tokens": "mTouchSlop = ViewConfiguration . getTouchSlop ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", ".", "courier", "schema", "language"], "add_tokens": "MultiFormatSchemaParser schemaParser = new MultiFormatSchemaParser ( options . getResolverPath ( ) , options . getParsersForFileFormats ( ) ) ; Set < ClassTemplateSpec > specs = new HashSet < ClassTemplateSpec > ( ClassTemplateSpecs . allReferencedTypes ( spec ) ) ;", "del_tokens": "// TODO: make schema parser pluggable so we can integrate .courier file format DataSchemaParser schemaParser = new DataSchemaParser ( options . getResolverPath ( ) ) ; Set < ClassTemplateSpec > specs = new HashSet < ClassTemplateSpec > ( ClassTemplateSpecs . allReferencedTypes ( spec ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "singleton", "class", "for", "static", "buffers", ".", "This", "improves", "deserialization", "performance", "by", "about", "250%", ".", "Thanks", "to", "Tatu", "Saloranta", "for", "the", "idea!"], "add_tokens": "import de . undercouch . bson4jackson . io . StaticBufferedInputStream ; in = new StaticBufferedInputStream ( in ) ;", "del_tokens": "in = new BufferedInputStream ( in ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "javadoc", "statement", "that", "makes", "no", "sense", "for", "fields", "."], "add_tokens": "/** Emits a field declaration. */ /** Emits a field declaration. */ /** Emits a field declaration. */", "del_tokens": "/** Emits a field declaration. Should not contain a trailing semicolon. */ /** Emits a field declaration. Should not contain a trailing semicolon. */ /** Emits a field declaration. Should not contain a trailing semicolon. */", "commit_type": "remove"}
{"commit_tokens": ["add", "customReaders", "support", "and", "aliases"], "add_tokens": "import java . util . HashMap ; import java . util . Map ; private Map < String , String > aliases = new HashMap < String , String > ( ) ; private Map < String , CellValueReader < ? > > customReaders = new HashMap < String , CellValueReader < ? > > ( ) ; return new DynamicCsvMapper < T > ( target , reflectionService ( target ) , fieldMapperErrorHandler , mapperBuilderErrorHandler , defaultDateFormat , aliases , customReaders ) ; CsvMapperBuilder < T > builder = new CsvMapperBuilder < T > ( target , reflectionService ( target ) , aliases , customReaders ) ; public void addAlias ( String key , String value ) { aliases . put ( key . toUpperCase ( ) , value . toUpperCase ( ) ) ; } public void addCustomValueReader ( String column , CellValueReader < ? > cellValueReader ) { customReaders . put ( column . toUpperCase ( ) , cellValueReader ) ; }", "del_tokens": "return new DynamicCsvMapper < T > ( target , reflectionService ( target ) , fieldMapperErrorHandler , mapperBuilderErrorHandler , defaultDateFormat ) ; CsvMapperBuilder < T > builder = new CsvMapperBuilder < T > ( target , reflectionService ( target ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "Splitter", "to", "constant", "static", "final", "."], "add_tokens": "private static final Splitter COMMA_SPLITTER = Splitter . on ( ',' ) . trimResults ( ) . omitEmptyStrings ( ) ; return Lists . newArrayList ( COMMA_SPLITTER . split ( testParam ) ) ;", "del_tokens": "return Lists . newArrayList ( Splitter . on ( ',' ) . trimResults ( ) . omitEmptyStrings ( ) . split ( testParam ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "the", "GwtTitaniumBootstrap", "class", "to", "support", "GWT", "Hosted", "Mode"], "add_tokens": "if ( isDevelopmentMode ( ) ) { // In development mode we don't need to override the streams and // catch exception since we run from within a JVM. runner . run ( this ) ; return ; } } catch ( Throwable e ) { private boolean isDevelopmentMode ( ) { return ! GWT . isScript ( ) && GWT . isClient ( ) ; }", "del_tokens": "} catch ( Throwable e ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "properties", "for", "alpha", "animators"], "add_tokens": "import android . util . Property ; public Property < View , Float > getAlphaProperty ( ) { return View . ALPHA ; public static Property < View , Float > getAlphaProperty ( ) {", "del_tokens": "public String getAlphaProperty ( ) { return \"alpha\" ; public static String getAlphaProperty ( ) {", "commit_type": "use"}
{"commit_tokens": ["fix", "sonar", "issue", ":", "Loops", "should", "not", "contain", "more", "than", "a", "single", "break", "or", "continue", "statement"], "add_tokens": "if ( shouldExcludeField ( field , excludedFields ) || isStaticOrFinal ( field ) ) { private boolean isStaticOrFinal ( Field field ) { int fieldModifiers = field . getModifiers ( ) ; return Modifier . isStatic ( fieldModifiers ) || Modifier . isFinal ( fieldModifiers ) ; }", "del_tokens": "if ( shouldExcludeField ( field , excludedFields ) ) { continue ; } //do not populate static nor final fields int fieldModifiers = field . getModifiers ( ) ; if ( Modifier . isStatic ( fieldModifiers ) || Modifier . isFinal ( fieldModifiers ) ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "issue", "with", "searching", "in", "context", "with", "search", "strategy"], "add_tokens": "return customContextFinder ( strategy ) . visibleElement ( by ) ; return customContextFinder ( strategy ) . visibleElements ( by ) ; return customContextFinder ( strategy ) . presentInDomElement ( by ) ; return customContextFinder ( strategy ) . presentInDomElements ( by ) ; private OurElementFinder customContextFinder ( OurSearchStrategy strategy ) { return new OurElementFinder ( getWebDriver ( ) , strategy , this ) ;", "del_tokens": "import com . wiley . autotest . selenium . SeleniumHolder ; import static com . wiley . autotest . selenium . SeleniumHolder . * ; return customFinder ( strategy ) . visibleElement ( by ) ; return customFinder ( strategy ) . visibleElements ( by ) ; return customFinder ( strategy ) . presentInDomElement ( by ) ; return customFinder ( strategy ) . presentInDomElements ( by ) ; private OurElementFinder customFinder ( OurSearchStrategy strategy ) { return new OurElementFinder ( getWebDriver ( ) , strategy ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "blank", "node", "round", "-", "tripping", "as", "a", "blank", "node", "label", "change"], "add_tokens": "Model bnodeModel = model . filter ( null , uri1 , vf . createLiteral ( plainLit . getLabel ( ) , XMLSchema . STRING ) ) ; assertEquals ( \"Blank node was not round-tripped\" , 1 , bnodeModel . size ( ) ) ; assertTrue ( \"Blank node was not round-tripped as a blank node\" , bnodeModel . subjects ( ) . iterator ( ) . next ( ) instanceof BNode ) ;", "del_tokens": "// assertTrue(statements.contains(st1));", "commit_type": "add"}
{"commit_tokens": ["Added", "maxOpenFiles", "option", "that", "does", "partial", "merging", "if", "neccessary", "to", "prevent", "excessive", "number", "of", "open", "files", "."], "add_tokens": "public void writeChunk ( Iterator < T > values , OutputStream out ) throws IOException { while ( values . hasNext ( ) ) { T next = values . next ( ) ; writeChunkValue ( next , out ) ;", "del_tokens": "import org . geirove . exmeso . ExternalMergeSort . SortHandler ; public void writeChunk ( List < T > values , OutputStream out ) throws IOException { for ( T value : values ) { writeChunkValue ( value , out ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "to", "register", "custom", "randomizer", "through", "the", "spring", "factory", "bean"], "add_tokens": "package io . github . benas . jpopulator . spring ; public class JPopulatorFactoryBeanTest { public void testJPopulatorFactoryBean ( ) { assertPerson ( person ) ; } @ Test public void testJPopulatorFactoryBeanWithCustomRandomizers ( ) { ApplicationContext applicationContext = new ClassPathXmlApplicationContext ( \"/application-context-with-custom-randomizers.xml\" ) ; Populator populator = ( Populator ) applicationContext . getBean ( \"populator\" ) ; // the populator managed by spring should be correctly configured assertThat ( populator ) . isNotNull ( ) ; // the populator should populate valid instances Person person = populator . populateBean ( Person . class ) ; assertPerson ( person ) ; System . out . println ( \"person.getEmail() = \" + person . getEmail ( ) ) ; assertThat ( person . getEmail ( ) ) . isNotNull ( ) . isNotEmpty ( ) . contains ( \"@\" ) ; } private void assertPerson ( Person person ) {", "del_tokens": "package io . github . benas . jpopulator . impl ; public class SpringSupportTest { public void testJPopulatorSpringFactoryBean ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "singleton", "to", "handle", "Exception", "List", "querying", "from", "classes", "extending"], "add_tokens": "import com . stratio . tests . utils . ExceptionList ; private final ExceptionList exceptions = ExceptionList . getInstance ( ) ; return exceptions . getExceptions ( ) ;", "del_tokens": "import java . util . ArrayList ; private List < Exception > exceptions = new ArrayList < Exception > ( ) ; return exceptions ; public void setExceptions ( List < Exception > exceptions ) { this . exceptions = exceptions ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "doc", "attribute", "for", "documentation", "to", "Rule", "and", "Terminal"], "add_tokens": "addTerminal ( method , name , term . expression ( ) , term . doc ( ) , term . priority ( ) , term . base ( ) , term . options ( ) ) ; addTerminal ( method , expression , expression , \"\" , rw . priority ( ) , 10 , rw . options ( ) ) ; addTerminal ( method , rw . left ( ) , expression , \"\" , rw . priority ( ) , 10 , rw . options ( ) ) ;", "del_tokens": "addTerminal ( method , name , term . expression ( ) , term . priority ( ) , term . base ( ) , term . options ( ) ) ; addTerminal ( method , expression , expression , rw . priority ( ) , 10 , rw . options ( ) ) ; addTerminal ( method , rw . left ( ) , expression , rw . priority ( ) , 10 , rw . options ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "more", "dead", "code", "and", "fixing", "some", "javadoc"], "add_tokens": "* < i > { @ literal @ } Selector ( \"a.linksToExample\" ) Link { @ literal < } ExamplePage { @ literal > < / } ExamplePage { @ literal > } linkToExample ; < / i >", "del_tokens": "* < i > { @ literal @ } Selector ( \"a.linksToExample\" ) Link { @ literal < } ExamplePage { @ literal > < / } ExamplePage { @ literal > } linkToExample ; < / i >", "commit_type": "remove"}
{"commit_tokens": ["adding", "defaults", "for", "nullable", "fields", "in", "avro", "conversion"], "add_tokens": "WorkUnitState state , boolean nullable ) throws UnsupportedDateTypeException { / * * * is field nullable * @ return * / public boolean isNullable ( ) { return nullable ; } . getAsString ( ) , schemaNode . get ( \"dataType\" ) . getAsJsonObject ( ) , state , isNullable ( ) ) ) ; . getAsString ( ) , schemaNode . get ( \"dataType\" ) . getAsJsonObject ( ) , state , isNullable ( ) ) ) ;", "del_tokens": "WorkUnitState state ) throws UnsupportedDateTypeException { boolean nullable = schemaNode . has ( \"isNullable\" ) ? schemaNode . get ( \"isNullable\" ) . getAsBoolean ( ) : false ; . getAsString ( ) , schemaNode . get ( \"dataType\" ) . getAsJsonObject ( ) , state ) ) ; . getAsString ( ) , schemaNode . get ( \"dataType\" ) . getAsJsonObject ( ) , state ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "BinaryGetResponse", "to", "actually", "return", "stored", "flags", "and", "value", "(", "previously", "it", "just", "returned", "an", "errorcode", ")", "."], "add_tokens": "import java . nio . ByteBuffer ; super ( create ( command , item ) ) ; } private static ByteBuffer create ( BinaryCommand command , Item item ) { final ByteBuffer message = BinaryResponse . create ( command , ErrorCode . SUCCESS , 4 /* flags */ , 0 , item . getValue ( ) . length , 0 ) ; message . putInt ( item . getFlags ( ) ) ; message . put ( item . getValue ( ) ) ; message . rewind ( ) ; return message ;", "del_tokens": "super ( command , ErrorCode . NOT_SUPPORTED ) ; // public BinaryResponse(BinaryCommand command, Item item) { // create(command, item); // }", "commit_type": "fix"}
{"commit_tokens": ["removed", "deprecated", "PutOnGetMap", "added", "toString", "()", "to", "PutIfAbsentMap", "changed", "QueueConsumer", "to", "rename", "the", "thread", "back", "after", "finished", "running"], "add_tokens": "String previousName = thread . getName ( ) ; try { if ( ! mode . compareAndSet ( MODE_START , MODE_RUNNING ) ) { throw new IllegalStateException ( \"Should be in state MODE_START, but actully not.\" ) ; } int m ; // while ( ( ( m = mode . get ( ) ) == MODE_RUNNING ) || ( m == MODE_STOP_WHEN_EMPTY && queue . size ( ) > 0 ) ) { consume ( ) ; } if ( ! mode . compareAndSet ( MODE_STOP_WHEN_EMPTY , MODE_STOPPED ) && ! mode . compareAndSet ( MODE_STOP_ASAP , MODE_STOPPED ) ) { throw new IllegalStateException ( \"Should be in state MODE_STOP_WHEN_EMPTY or MODE_STOP_ASAP, but actully not.\" ) ; } thread . interrupt ( ) ; } finally { thread . setName ( previousName ) ;", "del_tokens": "if ( ! mode . compareAndSet ( MODE_START , MODE_RUNNING ) ) { throw new IllegalStateException ( \"Should be in state MODE_START, but actully not.\" ) ; } int m ; // while ( ( ( m = mode . get ( ) ) == MODE_RUNNING ) || ( m == MODE_STOP_WHEN_EMPTY && queue . size ( ) > 0 ) ) { consume ( ) ; } if ( ! mode . compareAndSet ( MODE_STOP_WHEN_EMPTY , MODE_STOPPED ) && ! mode . compareAndSet ( MODE_STOP_ASAP , MODE_STOPPED ) ) { throw new IllegalStateException ( \"Should be in state MODE_STOP_WHEN_EMPTY or MODE_STOP_ASAP, but actully not.\" ) ; thread . interrupt ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "javadoc", "so", "it", "doesn", "t", "fail", "the", "build"], "add_tokens": "* < p >", "del_tokens": "* < p / >", "commit_type": "fix"}
{"commit_tokens": ["Added", "view", "form", "with", "a", "lot", "of", "form", "groups"], "add_tokens": "public class BootstrapForm extends AbstractHCForm < BootstrapForm > implements IMutableBootstrapFormGroupContainer", "del_tokens": "public class BootstrapForm extends AbstractHCForm < BootstrapForm > implements IBootstrapFormGroupContainer", "commit_type": "add"}
{"commit_tokens": ["Use", "reflection", "to", "load", "Build", ".", "BOOTLOADER", "and", "Build", ".", "RADIO", "since", "those", "are", "found", "in", "a", "higher", "API", "level", "than", "the", "one", "we", "compile", "against", "."], "add_tokens": "import com . apptentive . android . sdk . util . Reflection ; // Use reflection to load info from classes not available at API level 7. String bootloaderVersion = Reflection . getBootloaderVersion ( ) ; if ( bootloaderVersion != null ) { setString ( bootloaderVersion , \"record\" , \"device\" , \"bootloader_version\" ) ; } String radioVersion = Reflection . getRadioVersion ( ) ; if ( radioVersion != null ) { setString ( radioVersion , \"record\" , \"device\" , \"radio_version\" ) ; }", "del_tokens": "//setString(Build.VERSION.SDK, \"record\", \"device\", \"version\", \"os_sdk\");", "commit_type": "use"}
{"commit_tokens": ["Remove", "deferred", "JS", "injection", "to", "resolve", "loading", "issues", "."], "add_tokens": "MaterialResourceInjector . injectJs ( MaterialPathAnimatorDebugClientBundle . INSTANCE . pathanimatorDebugJs ( ) ) ; MaterialResourceInjector . injectJs ( MaterialPathAnimatorClientBundle . INSTANCE . pathanimatorJs ( ) ) ;", "del_tokens": "MaterialResourceInjector . injectJs ( MaterialPathAnimatorDebugClientBundle . INSTANCE . pathanimatorDebugJs ( ) , false , true , false ) ; MaterialResourceInjector . injectJs ( MaterialPathAnimatorClientBundle . INSTANCE . pathanimatorJs ( ) , true , false , false ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "null", "checks", "to", "fromPb", "in", "BucketInfo", "and", "BlobInfo", "updated", "tests"], "add_tokens": "BucketInfo bucketInfo = BucketInfo . of ( \"b\" ) ; compareBuckets ( bucketInfo , BucketInfo . fromPb ( bucketInfo . toPb ( ) ) ) ; @ Test assertEquals ( \"EU\" , Location . eu ( ) . value ( ) ) ; assertSame ( Location . eu ( ) , Location . of ( \"EU\" ) ) ; assertSame ( Location . us ( ) , Location . of ( \"uS\" ) ) ; @ Test assertEquals ( 1 , createBeforeRule . timeMillis ( ) ) ; assertEquals ( Type . UNKNOWN , rawRule . type ( ) ) ;", "del_tokens": "assertEquals ( \"EN\" , Location . eu ( ) . value ( ) ) ; assertSame ( Location . asia ( ) , Location . of ( \"EU\" ) ) ; assertSame ( Location . asia ( ) , Location . of ( \"uS\" ) ) ; assertEquals ( 10 , createBeforeRule . timeMillis ( ) ) ; assertEquals ( Type . UNKNOWN , isLiveRule . type ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "dead", "code", "and", "switched", "to", "UTF", "8", "strings", "to", "fix", "HTML", "body", "encoding"], "add_tokens": "", "del_tokens": "@ Test @ Ignore ( \"test case is an Outlook contact card, not an email, waiting for proper test data\" ) public void testGithubIssue28_AnomalousMessageError ( ) throws IOException { OutlookMessage msg = parseMsgFile ( \"test-messages/msg_with_anomaly.msg\" ) ; OutlookMessageAssert . assertThat ( msg ) . hasFromName ( \"Gustavo Garrido\" ) ; OutlookMessageAssert . assertThat ( msg ) . hasFromEmail ( \"geg@garridolawfirm.com\" ) ; OutlookMessageAssert . assertThat ( msg ) . hasSubject ( \"Test E-Mail\" ) ; OutlookMessageAssert . assertThat ( msg ) . hasOnlyToRecipients ( createRecipient ( \"Sven Sielenkemper\" , \"sielenkemper@otris.de\" ) ) ; OutlookMessageAssert . assertThat ( msg ) . hasOnlyCcRecipients ( createRecipient ( \"niklas.lindson@gmail.com\" , \"niklas.lindson@gmail.com\" ) ) ; OutlookMessageAssert . assertThat ( msg ) . hasNoBccRecipients ( ) ; OutlookMessageAssert . assertThat ( msg ) . hasNoOutlookAttachments ( ) ; assertThat ( msg . getBodyText ( ) ) . isNotEmpty ( ) ; assertThat ( msg . getBodyHTML ( ) ) . isNull ( ) ; assertThat ( msg . getBodyRTF ( ) ) . isNotEmpty ( ) ; assertThat ( normalizeText ( msg . getBodyText ( ) ) ) . isEqualTo ( \"Just a test to get an email with one cc recipient.\\n\" ) ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "final", "to", "function", "signatures"], "add_tokens": "void testingStarted ( final long numberOfTests ) ; void singleTestStarted ( final UnitTest test ) ; void singleTestExecuted ( final UnitTest test , final String uri , final long errors , final long prevalence ) ;", "del_tokens": "void testingStarted ( long numberOfTests ) ; void singleTestStarted ( UnitTest test ) ; void singleTestExecuted ( UnitTest test , String uri , long errors , long prevalence ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "option", "to", "only", "query", "for", "services", "that", "are", "passing", "health", "checks", "."], "add_tokens": "this . properties . isQueryPassing ( ) , QueryParams . DEFAULT ) ;", "del_tokens": "false , QueryParams . DEFAULT ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "api", "to", "set", "additional", "certificate", "for", "ssl", "request"], "add_tokens": "import java . security . KeyStore ; public void testGet ( ) { KeyStore keyStore = KeyStores . load ( this . getClass ( ) . getResourceAsStream ( \"/keystore\" ) , \"123456\" . toCharArray ( ) ) ; response = Requests . get ( \"https://127.0.0.1:8443/https\" ) . keyStore ( keyStore ) . send ( ) . toTextResponse ( ) ; assertEquals ( 200 , response . getStatusCode ( ) ) ;", "del_tokens": "public void testGet ( ) throws Exception { assertFalse ( response . getBody ( ) . isEmpty ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "Serializable", "to", "properly", "store", "working", "memories"], "add_tokens": "import java . io . Serializable ; public class CompositeList < E > extends AbstractSequentialList < E > implements Serializable {", "del_tokens": "public class CompositeList < E > extends AbstractSequentialList < E > {", "commit_type": "implement"}
{"commit_tokens": ["updated", "javadoc", "and", "added", "logging"], "add_tokens": "import org . owasp . appsensor . AppSensorServer ; import org . owasp . appsensor . Logger ; import org . owasp . appsensor . event . impl . LocalEventManager ; / * * * No - op user manager that is used most likely in test configurations . * It is possible the response handler could handle these actions * directly , but unlikely . * * @ author John Melton ( jtmelton @ gmail . com ) http : //www.jtmelton.com/ * * / private static Logger logger = AppSensorServer . getInstance ( ) . getLogger ( ) . setLoggerClass ( LocalEventManager . class ) ; / * * * { @ inheritDoc } * / logger . info ( \"The no-op user manager did not logout the user as requested.\" ) ; / * * * { @ inheritDoc } * / logger . info ( \"The no-op user manager did not disable the user as requested.\" ) ;", "del_tokens": "//do nothing //do nothing", "commit_type": "update"}
{"commit_tokens": ["Updated", "the", "builder", "to", "remove", "conditional", "statements", "and", "to", "pull", "down"], "add_tokens": "import java . util . regex . Pattern ; import java . util . regex . PatternSyntaxException ; else if ( temp [ 0 ] . equalsIgnoreCase ( \"condition\" ) ) { final String condition = temp [ 1 ] ; node . setConditionStatement ( condition ) ; try { Pattern . compile ( condition ) ; } catch ( PatternSyntaxException exception ) { log . error ( String . format ( ProcessorConstants . ERROR_INVALID_CONDITION_MSG , lineCounter , originalInput ) ) ; return false ; } }", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Changed", "log", "level", "in", "test"], "add_tokens": "private static final boolean LOG_INFO = false ;", "del_tokens": "private static final boolean LOG_INFO = true ;", "commit_type": "change"}
{"commit_tokens": ["remove", "the", "comment", "generating", "for", "general", "method"], "add_tokens": "// use block comments and limit the length of each line // it's not beauty to add some no use comment to the method if ( false ) { StringBuilder sb = new StringBuilder ( ) ; method . addJavaDocLine ( \"/**\" ) ; //$NON-NLS-1$ sb . append ( \" * created by XMBG\" ) ; //$NON-NLS-1$ if ( ! suppressDate ) { sb . append ( \" on \" + getDateString ( ) ) ; } else { sb . append ( \".\" ) ; } method . addJavaDocLine ( sb . toString ( ) ) ; method . addJavaDocLine ( \" */\" ) ; //$NON-NLS-1$", "del_tokens": "//  StringBuilder sb = new StringBuilder ( ) ; method . addJavaDocLine ( \"/**\" ) ; //$NON-NLS-1$ sb . append ( \" * created by XMBG\" ) ; //$NON-NLS-1$ if ( ! suppressDate ) { sb . append ( \" on \" + getDateString ( ) ) ; } else { sb . append ( \".\" ) ; method . addJavaDocLine ( sb . toString ( ) ) ; method . addJavaDocLine ( \" */\" ) ; //$NON-NLS-1$", "commit_type": "remove"}
{"commit_tokens": ["Add", "test", "for", "RubyEnumerable", "::", "eachEntry"], "add_tokens": "public RubyEnumerable < E > eachEntry ( ItemBlock < E > block ) { return this ; public RubyEnumerator < RubyArray < E > > eachSlice ( int n ) { return new RubyEnumerator < RubyArray < E > > ( new EachSliceIterable < E > ( iter , n ) ) ; public void eachSlice ( int n , ListBlock < E > block ) { for ( RubyArray < E > ra : new EachSliceIterable < E > ( iter , n ) ) { block . yield ( ra ) ; }", "del_tokens": "public RubyArray < E > eachEntry ( ItemBlock < E > block ) { RubyArray < E > rubyArray = newRubyArray ( ) ; rubyArray . add ( item ) ; return rubyArray ; public void eachSlice ( int n , ListBlock < E > block ) { for ( RubyArray < E > ra : new EachSliceIterable < E > ( iter , n ) ) { block . yield ( ra ) ; } public RubyEnumerator < RubyArray < E > > eachSlice ( int n ) { return new RubyEnumerator < RubyArray < E > > ( new EachSliceIterable < E > ( iter , n ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "test", "prefix", "from", "WalletTest", "methods", ".", "It", "s", "unnecessary", "with", "JUnit", "4", "."], "add_tokens": "public void basicSpending ( ) throws Exception { public void sideChain ( ) throws Exception { public void listeners ( ) throws Exception { public void balance ( ) throws Exception { public void blockChainCatchup ( ) throws Exception { public void balances ( ) throws Exception { public void finneyAttack ( ) throws Exception {", "del_tokens": "public void testBasicSpending ( ) throws Exception { public void testSideChain ( ) throws Exception { public void testListener ( ) throws Exception { public void testBalance ( ) throws Exception { public void testBlockChainCatchup ( ) throws Exception { public void testBalances ( ) throws Exception { public void testFinneyAttack ( ) throws Exception {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "MBUILDHELPER", "-", "32", ":", "failOnError", "expression", "references", "removeCritical"], "add_tokens": "* @ parameter default - value = \"true\" expression = \"${buildhelper.failOnError}\"", "del_tokens": "* @ parameter default - value = \"true\" expression = \"${buildhelper.removeCritical}\"", "commit_type": "fix"}
{"commit_tokens": ["Update", "Either", "with", "contracts", "and", "companion", "object"], "add_tokens": "import com . bluecatcode . common . contract . errors . ContractViolation ; import static com . bluecatcode . common . contract . Preconditions . require ; throw new ContractViolation ( \"Left value is absent\" ) ; require ( secondChoice != null , \"Expected non-null secondChoice\" ) ; public < E extends Exception > R orThrow ( Function < L , E > leftFunction ) throws E { require ( leftFunction != null , \"Expected non-null leftFunction\" ) ; require ( rightFunction != null , \"Expected non-null rightFunction\" ) ; require ( rightFunction != null , \"Expected non-null rightFunction\" ) ;", "del_tokens": "import static com . google . common . base . Preconditions . checkArgument ; throw new IllegalStateException ( \"Left value is absent\" ) ; checkArgument ( secondChoice != null , \"Expected non-null secondChoice\" ) ; public < E extends RuntimeException > R orThrow ( Function < L , E > leftFunction ) { checkArgument ( leftFunction != null , \"Expected non-null leftFunction\" ) ; checkArgument ( rightFunction != null , \"Expected non-null rightFunction\" ) ; checkArgument ( rightFunction != null , \"Expected non-null rightFunction\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "extra", "checks", "to", "ensure", "there", "are", "no", "extra", "solutions", "on", "test", "cases", "but", "disabled", "for", "L2", "as", "termination", "conditions", "not", "implemented", "on", "that", "machine", "."], "add_tokens": "/** Check that a list recursion pattern terminates on a non empty list. */ /** Check that a list recursion pattern terminates when the termination case is a one element list. */ public void testListIterationTerminatesOnNonEmptyFinalCase ( ) throws Exception { resolveAndAssertSolutions ( \"[[f([X]), (f([_|XS]) :- f(XS))], (?- f([a, b, c])), [[]]]\" ) ; }", "del_tokens": "/** Check that a list recursion pattern termintes on a non empty list. */", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "in", "IncrementalArrayData", "where", "data", "was", "cleared", "before", "onInvalidate", "called"], "add_tokens": "mDirty = false ; boolean firstItem = true ; // If invalidated while shown, we lazily clear the data so the user doesn't see blank data while loading final boolean needToClear = firstItem ; firstItem = false ; if ( needToClear && size ( ) > 0 ) { onClear ( ) ; mData . clear ( ) ; }", "del_tokens": "if ( mDirty ) { onClear ( ) ; mData . clear ( ) ; } mDirty = false ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "the", "logError", "()", "method", "of", "BugReporter", "using", "the"], "add_tokens": "private class Reporter implements BugReporter { public void logError ( String message ) { logger . logMessage ( ConsoleLogger . ERROR , message ) ; } private ConsoleLogger logger ; public AnalysisRun ( Project project , ConsoleLogger logger ) { this . logger = logger ;", "del_tokens": "private static class Reporter implements BugReporter { public AnalysisRun ( Project project ) {", "commit_type": "implement"}
{"commit_tokens": ["using", "new", "API", "for", "rest", "services"], "add_tokens": "void start ( RESTConfig restConfig ) throws Exception ;", "del_tokens": "void start ( RESTConfig restConfig ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "failing", "tool", "shed", "tests", "."], "add_tokens": "final WebResource baseResource = super . path ( \"get_repository_revision_install_info\" ) ; final WebResource resource = withQueryParams ( baseResource , revision ) ; return super . getResponse ( resource ) ; return withQueryParams ( resource , ( Repository ) revision ) . queryParam ( \"changeset_revision\" , revision . getRevision ( ) ) ;", "del_tokens": "return super . getResponse ( withQueryParams ( super . path ( \"repository_revision_install_info\" ) , revision ) ) ; return withQueryParams ( resource , ( Repository ) revision ) . queryParam ( \"revision\" , revision . getRevision ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["made", "event", "listener", "stuff", "thread", "-", "safe"], "add_tokens": "import net . sf . mmm . util . event . AbstractSynchronizedEventSource ; AbstractSynchronizedEventSource < ContentModelEvent , EventListener < ContentModelEvent > > implements * This method registers the given < code > contentClass < / code > to this * This method { @ link # addClass ( ContentClass ) registers } the given", "del_tokens": "import net . sf . mmm . util . event . AbstractEventSource ; AbstractEventSource < ContentModelEvent , EventListener < ContentModelEvent > > implements * This method registeres the given < code > contentClass < / code > to this * This method { @ link # addClass ( ContentClass ) registeres } the given", "commit_type": "make"}
{"commit_tokens": ["add", "callback", "to", "the", "send", "flow"], "add_tokens": "import org . jboss . aerogear . unifiedpush . message . MessageResponseCallback ; * We also pass a { @ link MessageResponseCallback } to handle the message * @ param callback the { @ link MessageResponseCallback } * / void send ( UnifiedMessage unifiedMessage , MessageResponseCallback callback ) ; / * * * Returns the server URL * * @ return the server URL * / String getServerURL ( ) ; / * * * Set the server URL * * @ param serverURL void setServerURL ( String serverURL ) ;", "del_tokens": "* void send ( UnifiedMessage unifiedMessage ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "exitApple", "method", "into", "Applet"], "add_tokens": "// static JFrame frame; // static GraphicsDevice displayDevice; // if (displayDevice == null) { GraphicsEnvironment environment = GraphicsEnvironment . getLocalGraphicsEnvironment ( ) ; GraphicsDevice displayDevice = environment . getDefaultScreenDevice ( ) ; // } JFrame frame = new JFrame ( displayDevice . getDefaultConfiguration ( ) ) ; // frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame . setDefaultCloseOperation ( JFrame . DISPOSE_ON_CLOSE ) ; applet . setWindowFrame ( frame ) ; applet . setDisplayDevice ( displayDevice ) ;", "del_tokens": "static JFrame frame ; static GraphicsDevice displayDevice ; if ( displayDevice == null ) { GraphicsEnvironment environment = GraphicsEnvironment . getLocalGraphicsEnvironment ( ) ; displayDevice = environment . getDefaultScreenDevice ( ) ; } frame = new JFrame ( displayDevice . getDefaultConfiguration ( ) ) ; frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "auto", "-", "resize", "issue", "for", "default", "viewport"], "add_tokens": "if ( rayHandler . customViewport ) { frameBuffer . end ( rayHandler . viewportX , rayHandler . viewportY , rayHandler . viewportWidth , rayHandler . viewportHeight ) ; } else { frameBuffer . end ( ) ; }", "del_tokens": "frameBuffer . end ( rayHandler . viewportX , rayHandler . viewportY , rayHandler . viewportWidth , rayHandler . viewportHeight ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "annotations", "and", "classes", "utils"], "add_tokens": "private static final Pattern LINE_START_PATTERN = Pattern . compile ( \"^.*\" , Pattern . MULTILINE ) ; String lastWord ; sb . append ( lastWord = word ) ; sb . append ( lastWord = endOfWord ) ; sb . append ( lastWord = word ) ; int lastNewLine = lastWord . lastIndexOf ( \"\\n\" ) ; if ( lastNewLine != - 1 ) { currentPosition = lastWord . length ( ) - lastNewLine ; } public static String leftPad ( String text , String padding , int linesToIgnore ) { StringBuilder result = new StringBuilder ( ) ; Matcher matcher = LINE_START_PATTERN . matcher ( text ) ; while ( matcher . find ( ) ) { if ( linesToIgnore > 0 ) { linesToIgnore -- ; } else { result . append ( padding ) ; } result . append ( matcher . group ( ) ) . append ( \"\\n\" ) ; } return result . toString ( ) ; }", "del_tokens": "sb . append ( word ) ; sb . append ( endOfWord ) ; sb . append ( word ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "missed", "Loopable", "in", "BlockStatmentWithLoops", "clear", "optimize", "()", "in", "ForInStatment", "&", "ForMapStatment"], "add_tokens": "import webit . script . core . ast . loop . Loopable ; public class BlockStatmentWithLoops extends AbstractStatment implements BlockStatment , Loopable {", "del_tokens": "public class BlockStatmentWithLoops extends AbstractStatment implements BlockStatment {", "commit_type": "add"}
{"commit_tokens": ["Make", "app", "cache", "linker", "less", "chatty"], "add_tokens": "logger . log ( TreeLogger . DEBUG , \"Make sure you have the following\"", "del_tokens": "logger . log ( TreeLogger . INFO , \"Make sure you have the following\"", "commit_type": "make"}
{"commit_tokens": ["Fixing", "MockService", ".", "Minor", "improvements", "in", "code", "."], "add_tokens": "deleteCache ( ) ; deleteCache ( ) ; } public static void deleteCache ( ) {", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Change", "DefaultDockerClient", "constructor", "to", "protected"], "add_tokens": "protected DefaultDockerClient ( final Builder builder ) {", "del_tokens": "private DefaultDockerClient ( final Builder builder ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "typo", "in", "function", "name"], "add_tokens": "public String requestSignatureFromDocuments ( RequestSignatureFromDocuments request , InputStream [ ] stream ) return requestSignatureFromDocuments ( request , streams . toArray ( new InputStream [ streams . size ( ) ] ) ) ;", "del_tokens": "public String reqeustSignatureFromDocuments ( RequestSignatureFromDocuments request , InputStream [ ] stream ) return reqeustSignatureFromDocuments ( request , streams . toArray ( new InputStream [ streams . size ( ) ] ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "BBAN", "Structure", "for", "Bahrain"], "add_tokens": "BbanStructureEntry . accountNumber ( 14 , 'c' ) ) ) ;", "del_tokens": "BbanStructureEntry . accountNumber ( 14 , 'n' ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Used", "artifact", "builder", "to", "assemble", "artifact", "objects"], "add_tokens": "import org . artifactory . build . api . builder . ArtifactBuilder ; ArtifactBuilder artifactBuilder = new ArtifactBuilder ( ) . name ( mavenArtifact . canonicalName ) . type ( mavenArtifact . type ) . md5 ( getMd5 ( mavenArtifact . groupId , mavenArtifact . fileName , mavenBuild ) ) ; return artifactBuilder . build ( ) ;", "del_tokens": "Artifact artifact = new Artifact ( ) ; artifact . setName ( mavenArtifact . canonicalName ) ; artifact . setType ( mavenArtifact . type ) ; artifact . setMd5 ( getMd5 ( mavenArtifact . groupId , mavenArtifact . fileName , mavenBuild ) ) ; return artifact ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "utility", "method", "and", "use", "api", "method", "instead", "."], "add_tokens": "import java . util . Collections ; when ( httpServletRequest . getHeaders ( TraceeConstants . HTTP_HEADER_NAME ) ) . thenReturn ( Collections . enumeration ( Arrays . asList ( ) ) ) ; when ( httpServletRequest . getHeaders ( TraceeConstants . HTTP_HEADER_NAME ) ) . thenReturn ( Collections . enumeration ( Arrays . asList ( \"{ \\\"\" + TraceeConstants . REQUEST_ID_KEY + \"\\\":\\\"123\\\"}\" ) ) ) ;", "del_tokens": "when ( httpServletRequest . getHeaders ( TraceeConstants . HTTP_HEADER_NAME ) ) . thenReturn ( Utilities . toEnumeration ( Arrays . asList ( ) ) ) ; when ( httpServletRequest . getHeaders ( TraceeConstants . HTTP_HEADER_NAME ) ) . thenReturn ( Utilities . toEnumeration ( Arrays . asList ( \"{ \\\"\" + TraceeConstants . REQUEST_ID_KEY + \"\\\":\\\"123\\\"}\" ) ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "the", "email", "generation", "functionality"], "add_tokens": "import io . apptik . json . generator . GeneratorConfig ; import io . apptik . json . generator . generators . formats . * ; import static io . apptik . json . generator . matcher . FormatMatchers . * ; stringFormatMatchers . put ( isEmailFormat ( ) , EmailGenerator . class ) ;", "del_tokens": "import io . apptik . json . generator . GeneratorConfig ; import io . apptik . json . generator . generators . formats . DateTimeGenerator ; import io . apptik . json . generator . generators . formats . TimeGenerator ; import io . apptik . json . generator . generators . formats . UriGenerator ; import io . apptik . json . generator . generators . formats . DateGenerator ; import static io . apptik . json . generator . matcher . FormatMatchers . isDateFormat ; import static io . apptik . json . generator . matcher . FormatMatchers . isDateTimeFormat ; import static io . apptik . json . generator . matcher . FormatMatchers . isTimeFormat ; import static io . apptik . json . generator . matcher . FormatMatchers . isUriFormat ;", "commit_type": "add"}
{"commit_tokens": ["removed", "bin", "folder", "and", "Meta", "-", "inf", "folder", "which", "are", "unnecessary"], "add_tokens": "socket = new InternalSocket ( asyncHttpClient ) ; //socket = new InternalSocket(asyncHttpClient);", "del_tokens": "socket = new InternalSocket ( asyncHttpClient ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "javadocs", "for", "all", "methods", "in", "library", "module"], "add_tokens": "* Interface to allow for handling clicks of the ParentObject . * * @ author Ryan Brooks * @ since 5 / 27 / 2015 * @ version 1.0", "del_tokens": "* Created by Ryan Brooks on 5 / 21 / 15.", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "class", "WizardDialog", ".", "Additionally", "theming", "FragmentDialogs", "does", "now", "work", "."], "add_tokens": "import android . support . annotation . StyleRes ; import android . support . v4 . app . FragmentManager ; * * @ param themeResourceId * The resource id of the theme , which should be used by the dialog , as an { @ link * Integer } value . The resource id must correspond to a valid theme protected AbstractHeaderDialogFragment ( @ StyleRes final int themeResourceId ) { super ( themeResourceId ) ; / * * * Creates a dialog , which is designed according to Android 5 's Material Design guidelines even * on pre - Lollipop devices , is able to show fragments and may contain a header . * / public AbstractHeaderDialogFragment ( ) { this ( - 1 ) ; } protected void onAttachDecorators ( @ NonNull final View view , @ NonNull final FragmentManager fragmentManager ) { super . onAttachDecorators ( view , fragmentManager ) ;", "del_tokens": "public AbstractHeaderDialogFragment ( ) { super ( ) ; protected void onAttachDecorators ( @ NonNull final View view ) { super . onAttachDecorators ( view ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "request", "token"], "add_tokens": "StatusCode statusCode = StatusCode . SUCCESS ; statusCode = policyCompliance ? StatusCode . SUCCESS : StatusCode . POLICY_VIOLATION ; if ( statusCode == StatusCode . SUCCESS ) { statusCode = StatusCode . CONNECTION_FAILURE ; statusCode = StatusCode . SERVER_FAILURE ; return statusCode ; // support token String requestToken = updateResult . getRequestToken ( ) ; if ( StringUtils . isNotBlank ( requestToken ) ) { resultLogMsg . append ( \"Support Token: \" ) . append ( requestToken ) . append ( \"\\n\" ) ; }", "del_tokens": "StatusCode sendUpdate = StatusCode . SUCCESS ; sendUpdate = policyCompliance ? StatusCode . SUCCESS : StatusCode . POLICY_VIOLATION ; if ( sendUpdate == StatusCode . SUCCESS ) { sendUpdate = StatusCode . CONNECTION_FAILURE ; sendUpdate = StatusCode . SERVER_FAILURE ; return sendUpdate ;", "commit_type": "add"}
{"commit_tokens": ["allowing", "rank", "-", "0", "deltas"], "add_tokens": "Preconditions . checkArgument ( rank >= 0 ) ;", "del_tokens": "Preconditions . checkArgument ( rank >= 1 ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "example", "file", "from", "specs"], "add_tokens": "import com . helger . commons . io . resource . FileSystemResource ; assertNotNull ( aMarshaller . read ( new FileSystemResource ( \"src/test/resources/example/business-card-test1.xml\" ) ) ) ; assertNotNull ( aMarshaller . read ( new FileSystemResource ( \"src/test/resources/example/business-card-example-spec.xml\" ) ) ) ;", "del_tokens": "import com . helger . commons . io . resource . ClassPathResource ; import com . helger . pd . businesscard . PDBusinessCardMarshaller ; assertNotNull ( aMarshaller . read ( new ClassPathResource ( \"example/business-card-test1.xml\" ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "config"], "add_tokens": "Config config = new Config ( ) ; config . set ( \"a.b.c.d.e\" , \"1\" ) ; config . set ( \"aa.x.y.z\" , \"X\" ) ; config . set ( \"a.c.d.e\" , \"3\" ) ; config . set ( \"a.d.e\" , \"4\" ) ; \"a:\\n\" + \" b:\\n\" + \" c:\\n\" + \" d:\\n\" + \" e: 1\\n\" + \" c:\\n\" + \" d:\\n\" + \" e: 3\\n\" + \" d:\\n\" + \" e: 4\\n\" + assertEquals ( expected , config . toYaml ( \"a\" ) ) ;", "del_tokens": "Config root = new Config ( ) ; Config one = new Config ( ) ; root . setConfig ( \"one\" , one ) ; Config two = new Config ( ) ; one . setConfig ( \"two\" , two ) ; two . setValue ( \"hello\" , \"world\" ) ; \"one:\\n\" + \" two:\\n\" + \" hello: world\\n\" + assertEquals ( expected , root . toYaml ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "in", "comment", "."], "add_tokens": "* @ param attributesToRetrieve , contains the list of attributes to retrieve .", "del_tokens": "* @ param attributesToRetrieve , contains the list of attributes to retrieve as a string separated by \",\"", "commit_type": "fix"}
{"commit_tokens": ["use", "data", "from", "Context", "(", "after", "a", "save", ")"], "add_tokens": "public final PageElement smilejs = new PageElement ( \"-smilejs\" , \"link a html balise with onclick by js (smilejs)\" ) ;", "del_tokens": "public final PageElement smilejs = new PageElement ( \"-smilejs\" , \"link a html balise with onclick by js (smile)\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "CVE", "-", "2009", "-", "2693", "directory", "traversal", "issue", "for", "[", "JBCOMMON", "-", "115", "]", "."], "add_tokens": "String canonicalDocBasePrefix = dest . getCanonicalPath ( ) ; if ( ! canonicalDocBasePrefix . endsWith ( File . separator ) ) { canonicalDocBasePrefix += File . separator ; } if ( ! file . getCanonicalPath ( ) . startsWith ( canonicalDocBasePrefix ) ) { throw new IOException ( \"illegalPath: \" + fileName ) ; }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Implement", "ability", "to", "create", "default", "bean", ".", "Execute", "provisioning", "only", "when", "list", "is", "not", "empty", "."], "add_tokens": "import static com . icthh . xm . commons . config . client . repository . TenantConfigRepository . PATH_API_CONFIG_TENANT ; import lombok . AllArgsConstructor ; import lombok . RequiredArgsConstructor ; import org . springframework . beans . factory . annotation . Autowired ; @ AllArgsConstructor @ RequiredArgsConstructor ( onConstructor = @ __ ( { @ Autowired } ) ) withConfigurations ( tenant . getTenantKey ( ) , ( ) -> { String tenantKey = tenant . getTenantKey ( ) ; tenantConfigRepository . createConfigsFullPath ( tenantKey , configurations ) ; } ) ; withConfigurations ( tenantKey , ( ) -> tenantConfigRepository . deleteConfigFullPath ( tenantKey , PATH_API_CONFIG_TENANT ) ) ; private void withConfigurations ( String tenant , Runnable runnable ) { if ( configurations != null && ! configurations . isEmpty ( ) ) { runnable . run ( ) ; } else { log . warn ( \"Skip ms-config provisioning as configuration list was not added. tenant: {}\" , tenant ) ; } }", "del_tokens": "String tenantKey = tenant . getTenantKey ( ) ; tenantConfigRepository . createConfigsFullPath ( tenantKey , configurations ) ; tenantConfigRepository . deleteConfigFullPath ( tenantKey , TenantConfigRepository . PATH_API_CONFIG_TENANT ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "min", "/", "max", "date", "calls", "to", "ReminderDatePicker", "and", "documentation", "updates"], "add_tokens": "// Min and mix date to be shown (are currently not restored during rotation as they are mostly set in the onCreate() anyway): * Spinner items and dates in the date picker after the given date will get disabled . * Gets the current maximum allowed date . * @ return The maximum date , or null if there is none .", "del_tokens": "// Min and mix date to be shown: * Spinner items and dates in the date picker before the given date will get disabled . * Gets the current minimum allowed date . * @ return The minimum date , or null if there is none .", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "the", "RAW", "Images", "endpoint", "with", "regards", "to", "SVG", "images", "."], "add_tokens": "import javax . ws . rs . core . Response ; @ Produces ( { \"image/gif\" , \"image/png\" , \"image/jpeg\" , \"image/svg+xml\" } ) public Response getRAWImage ( @ PathParam ( \"id\" ) final Integer id , @ QueryParam ( \"lang\" ) final String locale ) @ Produces ( { \"image/gif\" , \"image/png\" , \"image/jpeg\" , \"image/svg+xml\" } ) public Response getRAWImageRevision ( @ PathParam ( \"id\" ) final Integer id , @ PathParam ( \"rev\" ) final Integer revision , @ Produces ( { \"image/gif\" , \"image/png\" , \"image/jpeg\" , \"image/svg+xml\" } ) public Response getRAWImageThumbnail ( @ PathParam ( \"id\" ) final Integer id , @ QueryParam ( \"lang\" ) final String locale )", "del_tokens": "@ Produces ( { \"image/gif\" , \"image/png\" , \"image/jpeg\" , MediaType . APPLICATION_SVG_XML } ) public byte [ ] getRAWImage ( @ PathParam ( \"id\" ) final Integer id , @ QueryParam ( \"lang\" ) final String locale ) @ Produces ( { \"image/gif\" , \"image/png\" , \"image/jpeg\" , MediaType . APPLICATION_SVG_XML } ) public byte [ ] getRAWImageRevision ( @ PathParam ( \"id\" ) final Integer id , @ PathParam ( \"rev\" ) final Integer revision , @ Produces ( { \"image/gif\" , \"image/png\" , \"image/jpeg\" , MediaType . APPLICATION_SVG_XML } ) public byte [ ] getRAWImageThumbnail ( @ PathParam ( \"id\" ) final Integer id , @ QueryParam ( \"lang\" ) final String locale )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "validation", "method", "to", "throw", "exception", "/", "SpServerError"], "add_tokens": "import org . eclipse . hawkbit . tenancy . configuration . validator . exceptions . TenantConfigurationValidatorException ; / * * * base interface for clases which can validate tenant configuration values . * * / / * * * validates the tenant configuration value * * @ param tenantConfigurationValue * value which will be validated . * @ throws TenantConfigurationValidatorException * is thrown , when parameter is invalid . * / void validate ( Object tenantConfigurationValue ) throws TenantConfigurationValidatorException ;", "del_tokens": "boolean validate ( Object tenantConfigurationValue ) ;", "commit_type": "change"}
{"commit_tokens": ["move", "set_log_level", "to", "naether", "set", "verbose", "logging", "to", "debug"], "add_tokens": "// Set the initial ArrayList clearDependencies ( ) ; // Set the initial ArrayList clearBuildArtifacts ( ) ; log . debug ( \"Resolving Dependencies\" ) ;", "del_tokens": "dependencies = new ArrayList < Dependency > ( ) ; buildArtifacts = new ArrayList < Artifact > ( ) ; log . info ( \"Resolving Dependencies\" ) ;", "commit_type": "move"}
{"commit_tokens": ["allow", "fully", "qualified", "class", "names"], "add_tokens": "if ( ! tokenizer . accept ( TokenType . IDENTIFIER ) && ( ! tokenizer . accept ( TokenType . DOTTED_IDENTIFIER ) ) ) {", "del_tokens": "if ( ! tokenizer . accept ( TokenType . IDENTIFIER ) ) {", "commit_type": "allow"}
{"commit_tokens": ["changed", "stack", "to", "be", "protected"], "add_tokens": "protected UnpickleStack stack ;", "del_tokens": "private UnpickleStack stack ;", "commit_type": "change"}
{"commit_tokens": ["improve", "test", "coverage", "fix", "bugs", "in", "base64", "and", "long", "string", "escaping"], "add_tokens": "// Flush the last 1 or 2 characters if this is the last time though the loop if ( ptr == end ) { _writer . write ( _outputBuffer , start , ptr - start ) ; break output_loop ; } // Let's also reserve room for possible lf char each round // note: RISON does not escape newlines _outputBuffer [ _outputTail ++ ] = '\\n' ; b24 |= ( ( ( int ) input [ inputPtr ] ) & 0xFF ) << 8 ;", "del_tokens": "// Let's also reserve room for possible (and quoted) lf char each round // note: must quote in JSON value _outputBuffer [ _outputTail ++ ] = '\\\\' ; _outputBuffer [ _outputTail ++ ] = 'n' ; b24 |= ( ( ( int ) input [ inputPtr ++ ] ) & 0xFF ) << 8 ;", "commit_type": "improve"}
{"commit_tokens": ["Use", "more", "specific", "types", "for", "date", "columns", "where", "available"], "add_tokens": "@ Override public String typeDate ( ) { return \"timestamp(3)\" ; } @ Override public String typeDate ( ) { return \"timestamp(3)\" ; }", "del_tokens": "// return \"timestamp(3)\"; // TODO", "commit_type": "use"}
{"commit_tokens": ["Updated", "vehicle", "sign", "list", "and", "API"], "add_tokens": "import com . helger . commons . locale . country . CountryCache ; m_aCountry = CountryCache . getInstance ( ) . getCountry ( aCountry ) ;", "del_tokens": "m_aCountry = aCountry ;", "commit_type": "update"}
{"commit_tokens": ["Add", "configuration", "parameter", "to", "accept", "keys", "using", "either", "the", "Base32", "or", "the", "Base64", "representation", "."], "add_tokens": "import org . apache . commons . codec . binary . Base64 ; byte [ ] decodedKey ; switch ( config . getKeyRepresentation ( ) ) { case BASE32 : Base32 codec32 = new Base32 ( ) ; decodedKey = codec32 . decode ( secret ) ; break ; case BASE64 : Base64 codec64 = new Base64 ( ) ; decodedKey = codec64 . decode ( secret ) ; break ; default : throw new IllegalArgumentException ( \"Unknown key representation type.\" ) ; } byte [ ] encodedKey ; switch ( config . getKeyRepresentation ( ) ) { case BASE32 : Base32 codec = new Base32 ( ) ; encodedKey = codec . encode ( secretKey ) ; break ; case BASE64 : Base64 codec64 = new Base64 ( ) ; encodedKey = codec64 . encode ( secretKey ) ; break ; default : throw new IllegalArgumentException ( \"Unknown key representation type.\" ) ; } // Creating a string in the specified representation.", "del_tokens": "Base32 codec = new Base32 ( ) ; byte [ ] decodedKey = codec . decode ( secret ) ; Base32 codec = new Base32 ( ) ; byte [ ] encodedKey = codec . encode ( secretKey ) ; // Creating a string with the Base32 encoded bytes.", "commit_type": "add"}
{"commit_tokens": ["Change", "payment_source", "to", "payment_method", "in", "order", "charges"], "add_tokens": "+ \"'payment_method': {\" + \"'payment_method': {\" + \"'payment_method': {\" + \"'payment_method': {\" + \"'payment_method': {\" + \"'payment_method': {\"", "del_tokens": "+ \"'payment_source': {\" + \"'payment_source': {\" + \"'payment_source': {\" + \"'payment_source': {\" + \"'payment_source': {\" + \"'payment_source': {\"", "commit_type": "change"}
{"commit_tokens": ["fix", "the", "formatting", "of", "SaltStackClientTest", ":", "add", "new", "line", "at", "the", "end", "of", "a", "file"], "add_tokens": "}", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["added", "necessary", "charset", "arguments", "for", "guava", "hashing", "interfaces"], "add_tokens": "import java . nio . charset . StandardCharsets ; hasher . putString ( experimentId , StandardCharsets . UTF_8 ) ; hasher . putString ( trace . getTrace ( ) , StandardCharsets . UTF_8 ) ; hasher . putString ( String . valueOf ( sequenceId ) , StandardCharsets . UTF_8 ) ;", "del_tokens": "hasher . putString ( experimentId ) ; hasher . putString ( trace . getTrace ( ) ) ; hasher . putString ( String . valueOf ( sequenceId ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "visibility", "of", "abstract", "methods", "."], "add_tokens": "public abstract EthSendTransaction sendTransaction ( public abstract String getFromAddress ( ) ;", "del_tokens": "abstract EthSendTransaction sendTransaction ( abstract String getFromAddress ( ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "woraround", "for", "wrong", "accessors"], "add_tokens": "if ( values . length == length ) { throw new IllegalStateException ( \"This vector can't grow up.\" ) ; } int capacity = Math . min ( length , ( cardinality * 3 ) / 2 + 1 ) ; double $ values [ ] = new double [ capacity ] ; int $ indices [ ] = new int [ capacity ] ; System . arraycopy ( values , 0 , $ values , 0 , cardinality ) ; System . arraycopy ( indices , 0 , $ indices , 0 , cardinality ) ; values = $ values ; indices = $ indices ;", "del_tokens": "int newSize = Math . min ( length , ( cardinality * 3 ) / 2 + 1 ) ; double newValues [ ] = new double [ newSize ] ; int newIndices [ ] = new int [ newSize ] ; System . arraycopy ( values , 0 , newValues , 0 , cardinality ) ; System . arraycopy ( indices , 0 , newIndices , 0 , cardinality ) ; this . values = newValues ; this . indices = newIndices ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "upload", "script", "to", "look", "for", "the", "properties", "locally", "."], "add_tokens": "public class ApplicationTest extends ApplicationTestCase < PrefsApplication > { super ( PrefsApplication . class ) ;", "del_tokens": "import android . app . Application ; public class ApplicationTest extends ApplicationTestCase < Application > { super ( Application . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "some", "basic", "usage", "docs", "to", "the", "readme", ".", "Provide", "BasicTrustGraphAdvertisement", "helper", "."], "add_tokens": "* having the ttl given . * @ param mesage the message to deliver * @ param neighbor the id of the neighbor to send the message to * @ param ttl the new ttl for the message *", "del_tokens": "* having the ttl given .", "commit_type": "add"}
{"commit_tokens": ["making", "methods", "protected", "rather", "than", "private", "so", "this", "class", "can", "be", "extended"], "add_tokens": "protected static String getRandomUsername ( ) { protected SortedSet < PdbPair > getAlignmentPairsFromServer ( ) { // int pairDelay = DEFAULT_PAIR_FETCH_DELAY; // // String pairDelayS=resourceManager.getString(CONNECTION_PAIR_DELAY); // if ( pairDelayS !=null) { // // try { // pairDelay = Integer.parseInt(pairDelayS); // } catch (NumberFormatException ex){ // ex.printStackTrace(); // } // } protected void sendResultsToServer ( List < String > results ) {", "del_tokens": "private static String getRandomUsername ( ) { private SortedSet < PdbPair > getAlignmentPairsFromServer ( ) { int pairDelay = DEFAULT_PAIR_FETCH_DELAY ; String pairDelayS = resourceManager . getString ( CONNECTION_PAIR_DELAY ) ; if ( pairDelayS != null ) { try { pairDelay = Integer . parseInt ( pairDelayS ) ; } catch ( NumberFormatException ex ) { ex . printStackTrace ( ) ; } } private void sendResultsToServer ( List < String > results ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "utility", "classes", "for", "creating", "simple", "models", "and", "simple", "beans"], "add_tokens": "import static org . jboss . webbeans . test . util . Util . createSimpleModel ; import static org . jboss . webbeans . test . util . Util . getEmptyAnnotatedItem ; SimpleComponentModel < Order > order = createSimpleModel ( Order . class , manager ) ; SimpleComponentModel < Cat > cat = createSimpleModel ( Cat . class , manager ) ;", "del_tokens": "SimpleComponentModel < Order > order = new SimpleComponentModel < Order > ( new SimpleAnnotatedType ( Order . class ) , getEmptyAnnotatedItem ( Order . class ) , manager ) ; SimpleComponentModel < Cat > cat = new SimpleComponentModel < Cat > ( new SimpleAnnotatedType ( Cat . class ) , getEmptyAnnotatedItem ( Cat . class ) , manager ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "manifest", "support", "to", "util", "-", "reflect"], "add_tokens": "package net . sf . mmm . util . reflect . manifest ;", "del_tokens": "package net . sf . mmm . util . resource . manifest ;", "commit_type": "move"}
{"commit_tokens": ["Update", "the", "errors", "thrown", "and", "java", "doc", "Sender"], "add_tokens": "import java . io . UnsupportedEncodingException ; / * * * Senders can send JSON string payloads to Rollbar . * / / * * * Send the json payload ( already serialized as a String ) to Rollbar * @ param jsonPayload the payload to send * @ return a { @ link RollbarResponse } indicating what happened . * @ throws ConnectionFailedException if the connection failed before receiving a response from Rollbar . * @ throws UnsupportedEncodingException if the json couldn 't be encoded as UTF8. * / RollbarResponse Send ( String jsonPayload ) throws ConnectionFailedException , UnsupportedEncodingException ;", "del_tokens": "import java . io . IOException ; RollbarResponse Send ( String jsonPayload ) throws IOException , ConnectionFailedException ;", "commit_type": "update"}
{"commit_tokens": ["Added", "to", "the", "documentation", "of", "the", "ActivatorManager", "Class"], "add_tokens": "import java . lang . reflect . Field ; * The ActivatorManager holds all the Activator - instances and runs them parallel in Threads . //TODO: Is this working? What is the definition of Threads not used? Does Sleep count / * try { Field target = Thread . class . getDeclaredField ( \"target\" ) ; target . setAccessible ( true ) ; Activator activator = ( Activator ) target . get ( this ) ; } catch ( NoSuchFieldException | IllegalAccessException | ClassCastException e ) { Errorhandling is not implemented jet e . printStackTrace ( ) ; } * /", "del_tokens": "* Created by Leander on 24.09 . 2014. //TODO: Handling when Thread gets terminated", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "footers", "in", "boardview", "columns"], "add_tokens": "private View mFooter ; View header , View footer ) { mFooter = footer ; View getFooter ( ) { return mFooter ; } private View mFooter = null ; / * * * Sets footer view that will be positioned below the column * * @ param footer View that will be positioned below the column . Default value is null . * * @ return instance of the { @ link Builder } * / public Builder setFooter ( @ Nullable View footer ) { mFooter = footer ; return this ; } mHeader , mFooter ) ;", "del_tokens": "View header ) { mHeader ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "prone", "warning", "for", "dexmaker", "-", "tests", "and", "dexmaker", "-", "mockito", "-", "tests"], "add_tokens": "Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; @ Override Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; @ SuppressWarnings ( \"FloatingPointLiteralPrecision\" ) public static class Instance { Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; Object instance = generatedClass . getDeclaredConstructor ( ) . newInstance ( ) ; if ( params [ 0 ] . equals ( typeId ) ) { @ Override", "del_tokens": "Object instance = generatedClass . newInstance ( ) ; Object instance = generatedClass . newInstance ( ) ; Object instance = generatedClass . newInstance ( ) ; Object instance = generatedClass . newInstance ( ) ; Object instance = generatedClass . newInstance ( ) ; public class Instance { Object instance = generatedClass . newInstance ( ) ; Object instance = generatedClass . newInstance ( ) ; if ( params [ 0 ] == typeId ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "unit", "tests", "for", "failover", "with", "ack", "response", "mode"], "add_tokens": "LOG . warn ( \"emit() failed due to buffer full. retrying...\" ) ;", "del_tokens": "LOG . warn ( \"emit() failed due to buffer full\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "reporting", "for", "null", "argument", "collections", "."], "add_tokens": "final Object fieldInstance = field . get ( callerArguments ) ; if ( fieldInstance == null ) { throw new CommandLineException . CommandLineParserInternalException ( String . format ( \"The ArgumentCollection field '%s' in '%s' must have an initial value\" , field . getName ( ) , callerArguments . getClass ( ) . getName ( ) ) ) ; } createArgumentDefinitions ( fieldInstance , controllingDescriptor ) ;", "del_tokens": "createArgumentDefinitions ( field . get ( callerArguments ) , controllingDescriptor ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "page", "traversals", "in", "more", "places", "to", "allow", "for", "concurrent", "subrequests", "."], "add_tokens": "new CapturePage . PageHandler < Void > ( ) { public Void handlePage ( Page page ) throws ServletException , IOException { return null ; public Set < PageRef > getEdges ( Page page ) { return page . getChildPages ( ) ; } } , new CapturePage . EdgeFilter ( ) { @ Override public boolean applyEdge ( PageRef childPage ) { return book . equals ( childPage . getBook ( ) ) ;", "del_tokens": "import java . util . ArrayList ; import java . util . List ; new CapturePage . PageHandler ( ) { public void handlePage ( Page page ) throws ServletException , IOException { public List < PageRef > getEdges ( Page page ) { // Add all child pages that are in the same book Set < PageRef > childRefs = page . getChildPages ( ) ; List < PageRef > inBook = new ArrayList < PageRef > ( childRefs . size ( ) ) ; for ( PageRef childRef : childRefs ) { if ( book . equals ( childRef . getBook ( ) ) ) { inBook . add ( childRef ) ; } } return inBook ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "to", "customize", "injector", "stage"], "add_tokens": "import com . google . inject . Stage ; final String stageName = ( String ) props . get ( TinyPlugzGuice . INJECTOR_STAGE ) ; final Stage stage = stageName == null ? Stage . PRODUCTION : Stage . valueOf ( stageName ) ; return Guice . createInjector ( stage , modules ) ;", "del_tokens": "return Guice . createInjector ( modules ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "bug", "for", "any", "html", "alert", "on", "PhantomJs"], "add_tokens": "return msg . substring ( msg . indexOf ( \"\\\"\" ) + 1 , msg . length ( ) ) . replace ( ALERT_KEY , \"\" ) . replace ( \" (:)\" , \"\" ) ;", "del_tokens": "return msg . substring ( msg . indexOf ( \"\\\"\" ) + 1 , msg . length ( ) - 1 ) . replace ( ALERT_KEY , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "compile", "errors", "related", "to", "commit", "returning", "Object", "instead", "of", "boolean"], "add_tokens": "public ListenableFuture < Object > commitAsync ( final byte [ ] operation ) throws RaftException { ListenableFuture < ListenableFuture < Object > > response = executor . submit ( new Callable < ListenableFuture < Object > > ( ) { public ListenableFuture < Object > call ( ) throws Exception { public Object commit ( final byte [ ] operation ) throws RaftException , InterruptedException {", "del_tokens": "public ListenableFuture < Boolean > commitAsync ( final byte [ ] operation ) throws RaftException { ListenableFuture < ListenableFuture < Boolean > > response = executor . submit ( new Callable < ListenableFuture < Boolean > > ( ) { public ListenableFuture < Boolean > call ( ) throws Exception { public boolean commit ( final byte [ ] operation ) throws RaftException , InterruptedException {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "boxed", "int", "will", "never", "remove", "attachment"], "add_tokens": "public SlackMessage removeAttachment ( int index ) { public SlackMessage setAttachments ( List < SlackAttachment > attach ) {", "del_tokens": "public SlackMessage removeAttachment ( Integer index ) { public SlackMessage setAttachments ( ArrayList < SlackAttachment > attach ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "jmx", "performance", "counters", "http", ":", "//", "github", ".", "com", "/", "rantav", "/", "hector", "/", "issues", "/", "#issue", "/", "1"], "add_tokens": "public static void main ( String [ ] args ) throws IllegalStateException , PoolExhaustedException , Exception {", "del_tokens": "public static void main ( String [ ] args ) throws IllegalStateException , PoolExhaustedException , Exception {", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "the", "Soy", "calling", "types", "checker", ":", "When", "a", "template", "is", "called", "with", "data", "=", "all", "overriding", "an", "optional", "string", "param", "with", "an", "explicit", "param", "of", "kind", "=", "text", "would", "ignore", "the", "type", "of", "the", "explicit", "param", "."], "add_tokens": "if ( argType != null ) { // The types of the parameters. If this is an explicitly declared parameter, // then this collection will have only one member; If it's an implicit // parameter then this may contain multiple types. Note we don't use // a union here because the rules are a bit different than the normal rules // for assigning union types. // It's possible that the set may be empty, because all of the callees // are external. In that case there's nothing we can do, so we don't // report anything. Collection < SoyType > declaredParamTypes = calleeParamTypes . params . get ( callerParam . getKey ( ) ) ; for ( SoyType formalType : declaredParamTypes ) { checkArgumentAgainstParamType ( call , callerParam . getKey ( ) , argType , formalType , calleeParamTypes . isIndirect ( callerParam . getKey ( ) ) ) ; }", "del_tokens": "if ( argType == null ) { continue ; } // The types of the parameters. If this is an explicitly declared parameter, // then this collection will have only one member; If it's an implicit // parameter then this may contain multiple types. Note we don't use // a union here because the rules are a bit different than the normal rules // for assigning union types. // It's possible that the set may be empty, because all of the callees // are external. In that case there's nothing we can do, so we don't // report anything. Collection < SoyType > declaredParamTypes = calleeParamTypes . params . get ( callerParam . getKey ( ) ) ; for ( SoyType formalType : declaredParamTypes ) { checkArgumentAgainstParamType ( call , callerParam . getKey ( ) , argType , formalType , calleeParamTypes . isIndirect ( callerParam . getKey ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "minor", "documentation", "to", "promote", "consistency"], "add_tokens": "* Gets any note data you have associated with the Candidate .", "del_tokens": "* You can store additional information about the candidate here such as your internal system 's * identifier for this individual . This will allow you to keep track of them .", "commit_type": "update"}
{"commit_tokens": ["Added", "an", "example", "for", "chaning", "fonts"], "add_tokens": "mImageGenerator . setDateColor ( Color . parseColor ( \"#009688\" ) ) ;", "del_tokens": "mImageGenerator . setDateColor ( Color . parseColor ( \"#3c6eaf\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "all", "test", "for", "the", "VNFDependency", "CRUD", "operations"], "add_tokens": "public VNFDependency postVNFDependency (", "del_tokens": "public VNFDependency update (", "commit_type": "add"}
{"commit_tokens": ["Fix", "generation", "of", "spurious", "metadata", ".", "xml", "file", "entries"], "add_tokens": "ArtifactStore [ ] artifactStores = ( ArtifactStore [ ] ) stores . toArray ( new ArtifactStore [ stores . size ( ) ] ) ; artifactStores . length == 1 ? artifactStores [ 0 ] : new CompositeArtifactStore ( artifactStores ) ;", "del_tokens": "new CompositeArtifactStore ( ( ArtifactStore [ ] ) stores . toArray ( new ArtifactStore [ stores . size ( ) ] ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "all", "json", "unmarshaller", "classes", "for", "requests"], "add_tokens": "@ Suite . SuiteClasses ( { AlternatorTableTest . class , AlternatorItemTest . class , AlternatorQueryTest . class , AlternatorScanTest . class } )", "del_tokens": "@ Suite . SuiteClasses ( { AlternatorTableTest . class , AlternatorItemTest . class , AlternatorQueryTest . class , AlternatorScanTest . class } )", "commit_type": "add"}
{"commit_tokens": ["added", "method", "to", "allow", "table", "to", "class", "mapping"], "add_tokens": "if ( recipients == null || recipients . isEmpty ( ) )", "del_tokens": "if ( recipients . equals ( \" \" ) || recipients . isEmpty ( ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "create", "method", "and", "meta", "data", "interface", "plus", "new", "test"], "add_tokens": "import org . fuin . esc . api . StreamAlreadyExistsException ; @ Override public final void createStream ( final StreamId streamId ) throws StreamAlreadyExistsException { // Do nothing } version = - 1 ;", "del_tokens": "version = 0 ;", "commit_type": "add"}
{"commit_tokens": ["added", "a", "method", "to", "add", "a", "complete", "content", "map"], "add_tokens": "* Sends binary content to the client skipping rendering / * * * Adds an additional content map to the content rendered in the template . * Already existing values with the same key are overwritten . * * @ param content The content map to add * @ return A response object { @ link mangoo . io . routing . Response } * / public Response andContent ( Map < String , Object > content ) { this . content . putAll ( content ) ; return this ; }", "del_tokens": "* Sends binary content to the client skipping renderin", "commit_type": "add"}
{"commit_tokens": ["Fix", "method", "name", "to", "reflect", "return", "type"], "add_tokens": "this . serverCommunicationHandler = ServerCommunicationHandlerFactory . getInstance ( ) . getServerCommunicationHandler ( environment , messageHandler ) ;", "del_tokens": "this . serverCommunicationHandler = ServerCommunicationHandlerFactory . getInstance ( ) . getProcessManagerSlave ( environment , messageHandler ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "TypeOf", "to", "get", "parameterized", "type", "from", "a", "class"], "add_tokens": "RETROW_EXCEPTION_AFTER_DIAGNOSTIC_FAILURE , MISSING_GENERIC_PARAMETER", "del_tokens": "RETROW_EXCEPTION_AFTER_DIAGNOSTIC_FAILURE", "commit_type": "add"}
{"commit_tokens": ["upgrading", "ormlite", "and", "junit", "versions"], "add_tokens": "import java . io . IOException ; } catch ( IOException e ) { } catch ( IOException e ) {", "del_tokens": "import java . sql . SQLException ; } catch ( SQLException e ) { } catch ( SQLException e ) {", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "more", "test", "cases", "for", "Quartz", "expressions", "."], "add_tokens": "assertExpression ( \"*/45 * * * * *\" , \"every 45 seconds\" ) ; assertExpression ( \"0 0 * * * ?\" , \"every hour\" ) ; assertExpression ( \"0 0 0/1 * * ?\" , \"every hour\" ) ; } /* Examples exposed at cron documentations */ @ Test public void testEveryDayFireAtNoon ( ) throws Exception { assertExpression ( \"0 0 12 * * ?\" , \"at 12:00\" ) ; } @ Test public void testEveryDayFireAtTenFifteen ( ) throws Exception { String description = \"at 10:15\" ; assertExpression ( \"0 15 10 ? * *\" , description ) ; assertExpression ( \"0 15 10 * * ?\" , description ) ; assertExpression ( \"0 15 10 * * ? *\" , description ) ; } @ Test public void testEveryDayFireAtTenFifteenYear2005 ( ) throws Exception { assertExpression ( \"0 15 10 * * ? 2005\" , \"at 10:15 at 2005 year\" ) ; } @ Test public void testEveryMinuteBetween14and15EveryDay ( ) throws Exception { assertExpression ( \"0 * 14 * * ?\" , \"at 14 hour\" ) ; } @ Test public void testEveryFiveMinutesBetween14and15EveryDay ( ) throws Exception { assertExpression ( \"0 0/5 14 * * ?\" , \"every 5 minutes at 14 hour\" ) ; } private void assertExpression ( String cron , String description ) { assertEquals ( description , descriptor . describe ( parser . parse ( cron ) ) ) ;", "del_tokens": "assertEquals ( \"every 45 seconds\" , descriptor . describe ( parser . parse ( \"*/45 * * * * *\" ) ) ) ; assertEquals ( \"every hour\" , descriptor . describe ( parser . parse ( \"0 0 * * * ?\" ) ) ) ; assertEquals ( \"every hour\" , descriptor . describe ( parser . parse ( \"0 0 0/1 * * ?\" ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "tests", "for", "improving", "code", "coverage"], "add_tokens": "import static org . valid4j . matchers . ConstructionHelper . tryToInstantiate ; import static org . valid4j . matchers . ConstructorMatchers . classWithPrivateConstructor ; import static org . valid4j . matchers . ExceptionMatchers . preventInstantiationViolation ; assertThat ( Validation . class , classWithPrivateConstructor ( ) ) ; thrown . expectCause ( preventInstantiationViolation ( ) ) ; tryToInstantiate ( Validation . class ) ;", "del_tokens": "import org . valid4j . exceptions . NeverGetHereViolation ; import java . lang . reflect . Constructor ; import java . lang . reflect . Modifier ; import static org . hamcrest . Matchers . * ; import static org . junit . internal . matchers . ThrowableMessageMatcher . hasMessage ; Constructor < ? > [ ] constructors = Validation . class . getDeclaredConstructors ( ) ; assertThat ( constructors . length , equalTo ( 1 ) ) ; assertThat ( Modifier . isPrivate ( constructors [ 0 ] . getModifiers ( ) ) , is ( true ) ) ; thrown . expectCause ( allOf ( isA ( NeverGetHereViolation . class ) , hasMessage ( containsString ( \"Prevent instantiation\" ) ) ) ) ; Constructor < ? > constructor = Validation . class . getDeclaredConstructor ( ) ; constructor . setAccessible ( true ) ; try { constructor . newInstance ( ) ; } finally { constructor . setAccessible ( false ) ; }", "commit_type": "add"}
{"commit_tokens": ["Allow", "provided", "scoped", "dependencies", "to", "be", "deployed", "as", "artifacts", "."], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) // Allows provided dependencies to be seen dependencies . addAll ( project . getDependencyArtifacts ( ) ) ;", "del_tokens": "@ SuppressWarnings ( \"unchecked\" )", "commit_type": "allow"}
{"commit_tokens": ["Add", "more", "logging", "to", "simplify", "debugging"], "add_tokens": "import io . grpc . StatusRuntimeException ; public String sendMessage ( final String name ) { try { final SimpleGrpc . SimpleBlockingStub stub = SimpleGrpc . newBlockingStub ( this . serverChannel ) ; final HelloReply response = stub . sayHello ( HelloRequest . newBuilder ( ) . setName ( name ) . build ( ) ) ; return response . getMessage ( ) ; } catch ( final StatusRuntimeException e ) { e . printStackTrace ( ) ; return \"FAILED with \" + e . getStatus ( ) . getCode ( ) ; }", "del_tokens": "public String sendMessage ( String name ) { SimpleGrpc . SimpleBlockingStub stub = SimpleGrpc . newBlockingStub ( serverChannel ) ; HelloReply response = stub . sayHello ( HelloRequest . newBuilder ( ) . setName ( name ) . build ( ) ) ; return response . getMessage ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "so", "that", "awaitility", "works", "in", "Java5"], "add_tokens": "* The Class Awaitility . /** The default poll interval. */ /** The default timeout. */ /** The default catch uncaught exceptions. */", "del_tokens": "*", "commit_type": "fix"}
{"commit_tokens": ["Fix", "test", "when", "it", "runs", "as", "well"], "add_tokens": "// will read stubs classpath . baseUrl ( \"http://example.org\" ) . stubs ( \"classpath:/stubs/resource.json\" ) ;", "del_tokens": "// will read stubs from default /resources/stubs location . baseUrl ( \"http://example.org\" ) . stubs ( \"resource\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "processing", "of", "simple", "types", "in", "IS24", "-", "XML", "format"], "add_tokens": "return value . toExternalForm ( ) ;", "del_tokens": "return value . toString ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["use", "Lucene", "StandardAnalalyzer", "to", "split", "terms"], "add_tokens": ". setProperty ( \"propWithNonAlphaCharacters\" , \"hyphen-word, etc.\" , VISIBILITY_A ) . has ( \"propWithNonAlphaCharacters\" , TextPredicate . CONTAINS , \"hyphen-word, etc.\" )", "del_tokens": ". setProperty ( \"propWithHyphen\" , \"hyphen-word\" , VISIBILITY_A ) . has ( \"propWithHyphen\" , TextPredicate . CONTAINS , \"hyphen-word\" )", "commit_type": "use"}
{"commit_tokens": ["Added", "query", "strings", "params", "to", "debug", "logging"], "add_tokens": "String queryString = null ; try { queryString = createQuery ( mQueryMap ) ; } catch ( UnsupportedEncodingException e ) { // Do nothing } String urlString = ! SdkUtils . isBlank ( queryString ) ? String . format ( Locale . ENGLISH , \"%s?%s\" , mRequestUrlString , queryString ) : mRequestUrlString ; BoxLogUtils . i ( BoxConstants . TAG , String . format ( Locale . ENGLISH , \"Request (%s): %s\" , mRequestMethod , urlString ) ) ;", "del_tokens": "BoxLogUtils . i ( BoxConstants . TAG , String . format ( Locale . ENGLISH , \"Request (%s): %s\" , mRequestMethod , mRequestUrlString ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "mapping", "for", "nested", "objects"], "add_tokens": "import java . util . Map ; final ParameterValueProvider < ArangoPersistentProperty > provider = null ; // TODO accessor . setProperty ( property , Optional . ofNullable ( read ( source , property . getTypeInformation ( ) ) ) ) ; } @ SuppressWarnings ( \"unchecked\" ) protected < T > T read ( final Object source , final TypeInformation < ? > type ) { if ( source == null ) { return null ; } if ( conversions . hasCustomReadTarget ( source . getClass ( ) , type . getType ( ) ) ) { return ( T ) conversionService . convert ( source , type . getType ( ) ) ; } else if ( Map . class . isAssignableFrom ( source . getClass ( ) ) ) { return ( T ) read ( type , new DBEntity ( ( Map < ? extends String , ? extends Object > ) source ) ) ; } return ( T ) source ;", "del_tokens": "final ParameterValueProvider < ArangoPersistentProperty > provider = null ; accessor . setProperty ( property , Optional . ofNullable ( source ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "JAWR", "-", "318", "catching", "container", "specific", "browser", "abort", "excpetions"], "add_tokens": "import net . jawr . web . servlet . util . ClientAbortExceptionReoslver ; LOGGER . error ( \"Unable to write resource \" + request . getRequestURI ( ) , ex ) ; LOGGER . error ( \"No binary extension match the extension '\" + extension + \"' for the request URI : \" + requestUri ) ; } catch ( IOException e ) { if ( ClientAbortExceptionReoslver . isClientAbortException ( e ) ) { LOGGER . debug ( \"Browser cut off response\" , e ) ; } else { throw e ; } String [ ] resourceInfo = PathNormalizer . extractBinaryResourceInfo ( realFilePath ) ;", "del_tokens": "LOGGER . error ( \"Unable to write resource \" + request . getRequestURI ( ) , ex ) ; LOGGER . error ( \"No binary extension match the extension '\" + extension + \"' for the request URI : \" + requestUri ) ; String [ ] resourceInfo = PathNormalizer . extractBinaryResourceInfo ( realFilePath ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "Other", "Charts", "-", "Radar"], "add_tokens": "private Double aspectRatio ; private Position position ;", "del_tokens": "private Double aspectRatio ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "bug", "in", "AckProcessor", "."], "add_tokens": "if ( version . getXid ( ) == 0 ) { // Means the COP is the first transaction in this epoch, no // transactions before COP needs to be committed. zxidCanCommit = lastCommittedZxid ; } else { // We can commit the transaction up to the one before COP. zxidCanCommit = new Zxid ( version . getEpoch ( ) , version . getXid ( ) - 1 ) ; }", "del_tokens": "zxidCanCommit = new Zxid ( version . getEpoch ( ) , version . getXid ( ) - 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "JSNI", "problem", "in", "HtmlJson", ".", "Array", "getNumber", "(", "patch", "by", "Matt", "Mastracci", ")"], "add_tokens": "return parseFloat ( this [ index ] ) ;", "del_tokens": "return parseFloat ( this [ key ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "some", "synchronization", "to", "prevent", "multithreading", "issues"], "add_tokens": "private volatile InApplicationMonitorJMXConnector inApplicationMonitorJMXConnector ; private static final String semaphore = \"CorePluginSemaphore\" ; synchronized ( semaphore ) { if ( keyHandler != null ) { this . keyHandler = keyHandler ; } else { this . keyHandler = new TransparentKeyHandler ( ) ; } if ( jmxAppMon4JNamingStrategy != null ) { inApplicationMonitorJMXConnector = new InApplicationMonitorJMXConnector ( this , jmxAppMon4JNamingStrategy ) ; } initDefaultStateValues ( ) ; synchronized ( semaphore ) { if ( isJMXInitialized ( ) ) { inApplicationMonitorJMXConnector . shutdown ( ) ; inApplicationMonitorJMXConnector = null ; } private boolean isJMXInitialized ( ) {", "del_tokens": "private InApplicationMonitorJMXConnector inApplicationMonitorJMXConnector ; if ( keyHandler != null ) { this . keyHandler = keyHandler ; } else { this . keyHandler = new TransparentKeyHandler ( ) ; if ( jmxAppMon4JNamingStrategy != null ) { inApplicationMonitorJMXConnector = new InApplicationMonitorJMXConnector ( this , jmxAppMon4JNamingStrategy ) ; } initDefaultStateValues ( ) ; if ( isJMXInitialized ( ) ) { inApplicationMonitorJMXConnector . shutdown ( ) ; inApplicationMonitorJMXConnector = null ; public boolean isJMXInitialized ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "argument", "position", "detection", "for", "functors", "too", "."], "add_tokens": "/** The symbol table key for functor position of occurrence. */ public static final String SYMKEY_FUNCTOR_NON_ARG = \"functor_non_arg\" ; * < p / > Checks if a functor ever appears in an argument position . * * arguments . This set at the end , so that subsequent calls to this will pick up the state of this flag at the * point immediately below a top - level functor . // Get the nonArgPosition flag, or initialize it to true. Boolean nonArgPositionOnly = ( Boolean ) symbolTable . get ( functor . getName ( ) , SYMKEY_FUNCTOR_NON_ARG ) ; nonArgPositionOnly = ( nonArgPositionOnly == null ) ? true : nonArgPositionOnly ; // Clear the nonArgPosition flag is the variable occurs in an argument position. nonArgPositionOnly = inTopLevelFunctor ? false : nonArgPositionOnly ; symbolTable . put ( functor . getName ( ) , SYMKEY_FUNCTOR_NON_ARG , nonArgPositionOnly ) ; /*log.fine(\"Functor \" + functor + \" nonArgPosition is \" + nonArgPositionOnly + \".\");*/ // Set the in top level flag, so that any term immediately below this can detect that it is in an // argument position.", "del_tokens": "* arguments .", "commit_type": "add"}
{"commit_tokens": ["Add", "language", "property", "and", "use", "it", "from", "START", "message"], "add_tokens": "public String lang = \"en\" ; // XXX: Getter? // Read the first START message. Map < String , Object > m = pipe . recv ( ) ; if ( m . containsKey ( \"cmd\" ) && m . get ( \"cmd\" ) . equals ( \"START\" ) ) { if ( m . containsKey ( \"lang\" ) && m . get ( \"lang\" ) . toString ( ) . matches ( \"\\\\p{Lower}{2}\" ) ) { lang = ( String ) m . get ( \"lang\" ) ; } return ; } else { throw new IOException ( \"Invalid START message\" ) ;", "del_tokens": "// Read the first START message. FIXME try { pipe . recv ( ) ; } catch ( IOException e ) { // TODO Auto-generated catch block e . printStackTrace ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "extra", "attributes", "and", "WordSense", "layer"], "add_tokens": "public interface WordSense extends ExtraAtrributes {", "del_tokens": "public interface WordSense {", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "tests", "and", "a", "factory", "to", "retrieve", "the", "correct", "scanner", "class", "for", "a", "scheme"], "add_tokens": "import org . cognitor . cassandra . migration . resolver . ScannerFactory ; private final ScannerFactory scannerFactory ; this . scannerFactory = new ScannerFactory ( ) ; ClassPathLocationScanner scanner = scannerFactory . getScanner ( script . getScheme ( ) ) ;", "del_tokens": "ClassPathLocationScanner scanner ; if ( script . getScheme ( ) . equals ( \"jar\" ) ) { scanner = new JarLocationScanner ( ) ; } else { scanner = new FileSystemLocationScanner ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Bug", "in", "checking", "if", "we", "should", "move", "from", "hasMany", "to", "hasOne", "by"], "add_tokens": "import java . util . Map . Entry ; import java . util . TreeMap ; StringBuilder sb = new StringBuilder ( ) ; Map < String , Object > map = toHashMap ( ) ; sb . append ( \"\\n\" + getTableName ( ) + \": {\" ) ; for ( Entry < String , Object > entry : map . entrySet ( ) ) { sb . append ( \"\\n\\t\" + entry . getKey ( ) + \" : \" + entry . getValue ( ) ) ; } sb . append ( \"\\n}\" ) ; return sb . toString ( ) ; Map < String , Object > map = new TreeMap < String , Object > ( ) ; //if(description != null){ // map.put(\"description\", description); //} //if(attributeComments != null && attributeComments.length > 0){ // map.put(\"attributeComments\", Arrays.asList(attributeComments)); //} // if(subClass != null){ // map.put(\"subClass\", subClass); // }", "del_tokens": "return toHashMap ( ) . toString ( ) ; Map < String , Object > map = new HashMap < String , Object > ( ) ; if ( description != null ) { map . put ( \"description\" , description ) ; } if ( attributeComments != null && attributeComments . length > 0 ) { map . put ( \"attributeComments\" , Arrays . asList ( attributeComments ) ) ; } if ( subClass != null ) { map . put ( \"subClass\" , subClass ) ; }", "commit_type": "fix"}
{"commit_tokens": ["make", "more", "use", "of", "junit", "4"], "add_tokens": "import static org . junit . Assert . * ; import org . junit . Test ; public class ID3v2ChapterFrameDataTest { @ Test public void shouldConsiderTwoEquivalentObjectsEqual ( ) throws Exception { @ Test public void shouldConvertFrameDataToBytesAndBackToEquivalentObject ( ) throws Exception { assertArrayEquals ( expectedBytes , bytes ) ;", "del_tokens": "import java . util . Arrays ; import junit . framework . TestCase ; public class ID3v2ChapterFrameDataTest extends TestCase { public void testShouldConsiderTwoEquivalentObjectsEqual ( ) throws Exception { public void testShouldConvertFrameDataToBytesAndBackToEquivalentObject ( ) throws Exception { assertTrue ( Arrays . equals ( expectedBytes , bytes ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "new", "types", ":", "ShowBackground", "(", "TV", ")", "MovieBackground", "(", "Movie", ")", "and", "MovieThumb", "(", "Movie", ")"], "add_tokens": "import java . io . Serializable ; public class FanartTvArtwork implements Serializable { private static final long serialVersionUID = 1L ;", "del_tokens": "public class FanartTvArtwork {", "commit_type": "add"}
{"commit_tokens": ["Adding", "authors", "to", "pages", "."], "add_tokens": "* When name not provided , and page provided , uses page title as the author name .", "del_tokens": "* When name not provided , and page is accessible , uses page title as the author name .", "commit_type": "add"}
{"commit_tokens": ["Update", "javadoc", "by", "adding", "all", "available", "props"], "add_tokens": "* [ propertyPrefix ] . majorVersion * [ propertyPrefix ] . minorVersion * [ propertyPrefix ] . incrementalVersion List < ArtifactVersion > versions = artifactMetadataSource . retrieveAvailableVersions ( artifact , localRepository , remoteArtifactRepositories ) ; props . setProperty ( propertyPrefix + \".version\" , releasedVersionValue ) ; props . setProperty ( propertyPrefix + \".majorVersion\" , Integer . toString ( releasedVersion . getMajorVersion ( ) ) ) ; props . setProperty ( propertyPrefix + \".minorVersion\" , Integer . toString ( releasedVersion . getMinorVersion ( ) ) ) ;", "del_tokens": "List < ArtifactVersion > versions = artifactMetadataSource . retrieveAvailableVersions ( artifact , localRepository , remoteArtifactRepositories ) ; props . setProperty ( propertyPrefix + \".version\" , releasedVersionValue ) ; props . setProperty ( propertyPrefix + \".majorVersion\" , Integer . toString ( releasedVersion . getMajorVersion ( ) ) ) ; props . setProperty ( propertyPrefix + \".minorVersion\" , Integer . toString ( releasedVersion . getMinorVersion ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "size", "of", "constant", "for", "Long", "size"], "add_tokens": "offset = ( int ) ( ( position - this . range . getStart ( ) ) * SIZE_OF_LONG ) ;", "del_tokens": "offset = ( int ) ( ( position - this . range . getStart ( ) ) * 8 ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "from", "jackson", "to", "gson", "and", "cleaned", "up", "JSON", "marshaller"], "add_tokens": "@ Target ( ElementType . FIELD )", "del_tokens": "@ Target ( ElementType . METHOD )", "commit_type": "change"}
{"commit_tokens": ["move", "the", "service", "constants", "up", "a", "level"], "add_tokens": "import org . andnav . osm . services . constants . OpenStreetMapServiceConstants ;", "del_tokens": "import org . andnav . osm . services . util . constants . OpenStreetMapServiceConstants ;", "commit_type": "move"}
{"commit_tokens": ["Added", "changes", "for", "listFavorites", ".", "Updated", "test", "and", "comments", "."], "add_tokens": "/ * * * Represents ID of the favorited item . * / private Long objectId ; / * * * Gets the ID of the favorited item . * * @ return the objectId * / / * * * Sets the ID of the favorited item . * * @ param objectId ID of the favorited item . * / * A convenience class for making a { @ link Favorite } object with the appropriate fields for adding to a { @ link Favorite } . }", "del_tokens": "private Long objectId ; * A convenience class for making a { @ link GroupMember } object with the appropriate fields for adding to a { @ link Group } . }", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "case", "to", "validate", "automatic", "column", "addition", "."], "add_tokens": "super ( SimpleContractVersionOne . class ) ; public static class SimpleContractVersionOne { @ Id @ Column ( type = Type . INTEGER ) public static final String COLUMN_ID = \"_id\" ; @ Column ( type = Type . INTEGER ) public static final String COLUMN_INT = \"int\" ; @ ContentUri public static final Uri CONTENT_URI = Uri . parse ( \"content://com.test.simple/table_name_simple\" ) ; } @ Contract ( version = 2 ) public static class SimpleContractVersionTwo {", "del_tokens": "super ( SimpleContract . class ) ; public static class SimpleContract {", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "NaN", "casting"], "add_tokens": "assert Double . isNaN ( ( Double ) s . eval ( \"NaN\" ) ) : r . eval ( \"NaN\" ) ; assert Double . isNaN ( ( Double ) r . eval ( \"NaN\" ) ) : r . eval ( \"NaN\" ) ; assert r . eval ( \"n\" ) . toString ( ) . equals ( \"{a=null}\" ) : \"Bad print of object: \" + r . eval ( \"n\" ) . toString ( ) ; assert s . eval ( \"n\" ) . toString ( ) . equals ( \"{a=null}\" ) : \"Bad print of object: \" + s . eval ( \"n\" ) . toString ( ) ;", "del_tokens": "assert r . eval ( \"n\" ) . toString ( ) . equals ( \"{a=null}\" ) : \"Bad print of object: \" + r . eval ( \"n\" ) . toString ( ) ; assert s . eval ( \"n\" ) . toString ( ) . equals ( \"{a=null}\" ) : \"Bad print of object: \" + s . eval ( \"n\" ) . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "check", "for", "3rd", "party", "classloader", "exchange"], "add_tokens": "* @ see TinyPlugzFilter", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Added", "improvement", "after", "code", "review", ":", "stripFirstChar", "()", "."], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "cache", "optimize", "in", "a", "bit"], "add_tokens": ". multicast ( EmitterProcessor . replay ( 1 ) )", "del_tokens": ". publish ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "popssible", "NPE", "when", "configuration", "parsing", "fails", "before", "having", "a", "ConfigOrigin", "set"], "add_tokens": "ConfigOrigin origin = e . origin ( ) ; if ( origin != null ) { builder . setLocation ( origin . lineNumber ( ) , 0 ) ; }", "del_tokens": "ConfigOrigin origin = e . origin ( ) ; builder . setLocation ( origin . lineNumber ( ) , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "backported", "public", "domain", "implementation", "of", "ThreadLocalRandom", "by", "from", "http", ":", "//", "gee", ".", "cs", ".", "oswego", ".", "edu", "/", "cgi", "-", "bin", "/", "viewcvs", ".", "cgi", "/", "jsr166", "/", "src", "/", "main", "/", "java", "/", "util", "/", "concurrent", "/", "ThreadLocalRandom", ".", "java?view", "=", "markup"], "add_tokens": "* Created by Tobias Gindler , holisticon AG", "del_tokens": "import java . util . concurrent . ThreadLocalRandom ; * Created by Tobias Gindler , holisticon AG on 11.12 . 13.", "commit_type": "add"}
{"commit_tokens": ["Change", "null", "or", "empty", "check", "in", "CloudQueueTests"], "add_tokens": "assertFalse ( originalMessage . getId ( ) == null || originalMessage . getId ( ) . isEmpty ( ) ) ; assertFalse ( originalMessage . getPopReceipt ( ) == null || originalMessage . getPopReceipt ( ) . isEmpty ( ) ) ;", "del_tokens": "import com . microsoft . azure . keyvault . extensions . Strings ; assertFalse ( Strings . isNullOrEmpty ( originalMessage . getId ( ) ) ) ; assertFalse ( Strings . isNullOrEmpty ( originalMessage . getPopReceipt ( ) ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "in", "equallity", "the", "term", "filter", "is", "not", "analyzed", "searching", "for", "Nogal", "city", "failed", "the", "test", "...", "adding", "2", "tests", "for", "equallity", "operator"], "add_tokens": "// TODO, maybe use term filter when not analayzed field avalaible to make exact matching? // using matchPhrase to achieve equallity. // matchPhrase still have some disatvantegs, f.e search for 'word' will match 'some word' MatchQueryBuilder matchPhraseQuery = QueryBuilders . matchPhraseQuery ( name , value ) ; x = isQuery ? matchPhraseQuery : FilterBuilders . queryFilter ( matchPhraseQuery ) ;", "del_tokens": "if ( isQuery ) x = QueryBuilders . termQuery ( name , value ) ; else x = FilterBuilders . termFilter ( name , value ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "test", "to", "run", "successfully", "on", "systems", "with", "non", "-", "GMT", "default", "timezones", "."], "add_tokens": "TimeZone . setDefault ( TimeZone . getTimeZone ( \"GMT\" ) ) ;", "del_tokens": "TimeZone . setDefault ( TimeZone . getTimeZone ( \"GMT\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "documentation", "to", "the", "most", "important", "commands", "."], "add_tokens": "assertTrue ( d1 . resetConsumable ( VacuumConsumableStatus . Names . MAIN_BRUSH ) ) ;", "del_tokens": "d1 . resetConsumable ( VacuumConsumableStatus . Names . MAIN_BRUSH ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "OSCache", "concurrency", "problem", "was", "getting", "this", "sometimes", ":"], "add_tokens": "try { administrator . cancelUpdate ( key ) ; } catch ( Exception e ) { return null ; }", "del_tokens": "administrator . cancelUpdate ( key ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "parallel", "stream", "for", "round", "trips", "."], "add_tokens": "Sets . powerSet ( shares ) . stream ( ) . filter ( s -> ! s . isEmpty ( ) ) . parallel ( )", "del_tokens": "Sets . powerSet ( shares ) . stream ( ) . filter ( s -> ! s . isEmpty ( ) )", "commit_type": "use"}
{"commit_tokens": ["Adding", "testcase", "for", "Main", "class"], "add_tokens": "import com . google . common . annotations . VisibleForTesting ; private Class moduleClass ; public Main ( ) { this ( PipelineAgentModule . class ) ; } @ VisibleForTesting Main ( Class moduleClass ) { this . moduleClass = moduleClass ; } @ VisibleForTesting Runtime getRuntime ( ) { return Runtime . getRuntime ( ) ; } public int doMain ( ) { ObjectGraph dagger = ObjectGraph . create ( moduleClass ) ; getRuntime ( ) . addShutdownHook ( shutdownHookThread ) ; getRuntime ( ) . removeShutdownHook ( shutdownHookThread ) ; return 0 ; return 1 ; public static void main ( String [ ] args ) throws Exception { System . exit ( new Main ( ) . doMain ( ) ) ; }", "del_tokens": "public static void main ( String [ ] args ) throws Exception { ObjectGraph dagger = ObjectGraph . create ( PipelineAgentModule . class ) ; Runtime . getRuntime ( ) . addShutdownHook ( shutdownHookThread ) ; Runtime . getRuntime ( ) . removeShutdownHook ( shutdownHookThread ) ; System . exit ( 0 ) ; System . exit ( 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "propagateException", "parameter", "to", "AbstractMessageService", "."], "add_tokens": "import org . nightcode . common . base . Throwables ; private final boolean propagateException ; this ( serviceName , false ) ; } protected AbstractMessageService ( String serviceName , boolean propagateException ) { this . propagateException = propagateException ; if ( ! propagateException ) { LOGGER . log ( Level . WARNING , ex , ( ) -> String . format ( \"[%s]: exception occurred while submitting message <%s>\" , serviceName ( ) , message ) ) ; return false ; } throw Throwables . propagate ( ex ) ;", "del_tokens": "LOGGER . log ( Level . WARNING , ex , ( ) -> String . format ( \"[%s]: exception occurred while submitting message <%s>\" , serviceName ( ) , message ) ) ; return false ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "Class", "Comments", "to", "BooleanBucketer", "."], "add_tokens": "* BooleanBucketer * You can use this bucketer for cases where : * - You have a cube coordinate that is boolean * - You want to store that boolean as a byte [ 0 ] for false or a byte [ 1 ] for true .", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Add", "languagesettings", "test", "and", "tweak", "xsds"], "add_tokens": "new Object [ ] { LanguageSettingsResponseData . class , \"/languageSettings.xml\" } ,", "del_tokens": "// new Object[]{LanguageSettingsResponseData.class, \"\"},", "commit_type": "add"}
{"commit_tokens": ["Added", "datatables", "to", "testng", "scenario", "summary"], "add_tokens": "import gherkin . formatter . model . DataTableRow ; if ( steps . get ( i ) . getRows ( ) != null ) { for ( DataTableRow row : steps . get ( i ) . getRows ( ) ) { String strrow = \"| \" ; for ( String cell : row . getCells ( ) ) { strrow += cell + \" | \" ; } sb . append ( \"\\n\\t\\t\" + strrow ) ; } do { sb . append ( \".\" ) ; } while ( sb . length ( ) - length < 201 ) ; //98 } } while ( sb . length ( ) - length < 130 ) ;", "del_tokens": "} while ( sb . length ( ) - length < 106 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "query", "UI", "through", "the", "HTTP", "interface", "."], "add_tokens": "+ \" --staticroot=PATH --cachedir=PATH\\n\" argp . addOption ( \"--cachedir\" , \"PATH\" , \"Directory under which to cache result of requests.\" ) ; || ! argp . has ( \"--staticroot\" ) || ! argp . has ( \"--cachedir\" ) ) { setDirectoryInSystemProps ( \"tsd.http.cachedir\" , argp . get ( \"--cachedir\" ) , CREATE_IF_NEEDED ) ;", "del_tokens": "+ \" --staticroot=PATH\\n\" || ! argp . has ( \"--staticroot\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "optional", "EnsembleProvider"], "add_tokens": "import org . apache . curator . ensemble . EnsembleProvider ; import org . springframework . beans . factory . annotation . Autowired ; @ Autowired ( required = false ) private EnsembleProvider ensembleProvider ; CuratorFrameworkFactory . Builder builder = CuratorFrameworkFactory . builder ( ) ; if ( ensembleProvider != null ) { builder . ensembleProvider ( ensembleProvider ) ; } CuratorFramework curator = builder . connectString ( zookeeperProperties ( ) . getConnectString ( ) ) . build ( ) ;", "del_tokens": "CuratorFramework curator = CuratorFrameworkFactory . builder ( ) // TODO: support ensembleProvider via ExhibitorEnsembleProvider // .ensembleProvider(new ExhibitorEnsembleProvider()) . connectString ( zookeeperProperties ( ) . getConnectString ( ) ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "uri", "bug", "with", "+", "escapes", "in", "zendesk", "API", "...", "take", "2"], "add_tokens": "return new PagedIterable < Ticket > ( tmpl ( \"/search.json{?query}\" ) . set ( \"query\" , searchTerm + \"+type:ticket\" ) , builder . setUrl ( template . toString ( ) . replace ( \"%2B\" , \"+\" ) ) ; //replace out %2B with + due to API restriction", "del_tokens": "return new PagedIterable < Ticket > ( tmpl ( \"/search.json{?query}\" ) . set ( \"query\" , searchTerm + \"\\\\+type:ticket\" ) , builder . setUrl ( template . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "set", "method", "for", "sockopt", "ZMQ_XPUB_VERBOSE"], "add_tokens": "import zmq . EncoderBase ; / * * * Sets the XPUB socket behavior on new subscriptions and unsubscriptions . * * @ param verbose A value of false is the default and passes only new subscription messages to upstream . * A value of true passes all subscription messages upstream . * / public final void setXpubVerbose ( boolean verbose ) { base . setsockopt ( zmq . ZMQ . ZMQ_XPUB_VERBOSE , verbose ? 1 : 0 ) ; mayRaiseNot ( ZError . ETERM ) ; }", "del_tokens": "import java . io . IOException ; import java . nio . channels . Selector ; import zmq . EncoderBase ;", "commit_type": "add"}
{"commit_tokens": ["Add", "isReady", "()", "to", "HistoryDetails", "that", "returns", "false", "iff", "any", "jobs", "are", "running", "or", "queued", ".", "Use", "this", "to", "improve", "testing", "."], "add_tokens": "public boolean isReady ( ) { return ! ( state . equals ( \"running\" ) || state . equals ( \"queued\" ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "so", "that", "you", "can", "just", "brackets", "in", "html", "expectations"], "add_tokens": "import static com . jayway . restassured . RestAssured . get ; @ Test public void canGetSpecificEntityFromListHtmlDocument ( ) throws Exception { expect ( ) . body ( \"html.body.p[0]\" , equalTo ( \"paragraph 1\" ) ) . when ( ) . get ( \"/textHTML\" ) ; } @ Test public void canGetSpecificEntityFromListHtmlDocumentUsingGetAt ( ) throws Exception { expect ( ) . body ( \"html.body.p.getAt(0)\" , equalTo ( \"paragraph 1\" ) ) . when ( ) . get ( \"/textHTML\" ) ; } when ( ) . get ( \"/greetXMLAttribute?firstName=John&lastName=Doe\" ) ;", "del_tokens": "when ( ) . get ( \"/greetXMLAttribute?firstName=John&lastName=Doe\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "ignoring", "specific", "hosts", "and", "capturing", "metrics", "when", "zone", "and", "server", "group", "data", "is", "missing", "from", "discovery"], "add_tokens": "import com . netflix . config . DynamicStringSetProperty ; import com . netflix . evcache . metrics . EVCacheMetricsFactory ; private final DynamicStringSetProperty ignoreHosts ; ignoreHosts = new DynamicStringSetProperty ( appName + \".ignore.hosts\" , \"\" ) ; if ( zone == null ) { EVCacheMetricsFactory . increment ( _appName , null , \"EVCacheClient-DiscoveryNodeListProvider-NULL_ZONE\" ) ; continue ; } if ( rSetName == null ) { EVCacheMetricsFactory . increment ( _appName , null , \"EVCacheClient-DiscoveryNodeListProvider-NULL_SERVER_GROUP\" ) ; continue ; } final String localIp = ( isInCloud ) ? amznInfo . get ( AmazonInfo . MetaDataKey . localIpv4 ) : amznInfo . get ( AmazonInfo . MetaDataKey . publicIpv4 ) ; if ( ignoreHosts . get ( ) . contains ( localIp ) ) continue ; if ( ignoreHosts . get ( ) . contains ( localIp ) ) continue ; if ( ignoreHosts . get ( ) . contains ( localIp ) ) continue ;", "del_tokens": "final String localIp = ( isInCloud ) ? amznInfo . get ( AmazonInfo . MetaDataKey . localIpv4 ) : amznInfo . get ( AmazonInfo . MetaDataKey . publicIpv4 ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "ArrayAdapter", "implement", "List", "use", "the", "given", "list", "reference", "as", "default", "."], "add_tokens": "* An EXPERIMENTAL adapter for inserting rows into the { @ link android . widget . AbsListView } with an animation . The root { @ link BaseAdapter } should implement { @ link Insertable } ,", "del_tokens": "* An adapter for inserting rows into the { @ link android . widget . AbsListView } with an animation . The root { @ link BaseAdapter } should implement { @ link Insertable } , * * @ param < T >", "commit_type": "make"}
{"commit_tokens": ["Changed", "the", "implementation", "of", "AESCipher#setKey", "(", "String", ")", "to", "fix", "a", "really", "bad", "security", "bug", "."], "add_tokens": "byte [ ] iv2 = ensureSize ( iv , 16 ) ; byte [ ] iv2 = getBytesUTF8 ( iv ) ; * This method is an alias of { @ link # setKey ( String , String ) setKey ( key , null ) } . * Secret key . return setKey ( key , null ) ;", "del_tokens": "byte [ ] iv2 ; if ( key == iv ) { iv2 = key2 ; } else { iv2 = ensureSize ( iv , 16 ) ; } byte [ ] iv2 ; if ( key == iv ) { iv2 = key2 ; } else { iv2 = getBytesUTF8 ( key ) ; } * This method is an alias of { @ link # setKey ( String , String ) setKey ( key , key ) } . * Secret key . This is used as initial vector , too . return setKey ( key , key ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "Javadoc", "on", "Territory", ".", "fromString", "()"], "add_tokens": "* Get a territory from a mapcode territory abbreviatiobn code . Note that this is NOT strictly an ISO code . * This method has been optimized to prefer to return local states , rather than countries , if the * local territory code for a state is the same as a country code . * * For example , fromString ( \"AS\" ) returns { @ link Territory # IN_AS } rather than { @ link Territory # ASM } and * fromString ( \"BR\" ) returns { @ link Territory # IN_BR } rather than { @ link Territory # BRA } . * * This behavior is intentional as local mapcodes are designed to be as short as possible . A mapcode within * the Indian state Bihar should therefore be able to specified as \"BR 49.46M3\" rather \"IN-BR 49.46M3\" . * * Brazilian mapcodes , on the other hand , would be specified as \"BRA BDHP.JK39-1D\" , using the ISO 3 letter code . * @ param name Territory name . See { @ link # fromString ( String ) } for an explanation of the format for * this name . ( This is NOT strictly an ISO code ! )", "del_tokens": "* Get a territory from a name . * @ param name Territory name .", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "source", "type", "for", "the", "artwork", "type", "to", "determine", "what", "the", "artwork", "type", "can", "be", "used", "for"], "add_tokens": "ALL ( FTSourceType . ALL ) , CLEARART ( FTSourceType . TV ) , CLEARLOGO ( FTSourceType . TV ) , SEASONTHUMB ( FTSourceType . TV ) , TVTHUMB ( FTSourceType . TV ) , CHARACTERART ( FTSourceType . TV ) , MOVIELOGO ( FTSourceType . MOVIE ) , MOVIEDISC ( FTSourceType . MOVIE ) , MOVIEART ( FTSourceType . MOVIE ) , CDART ( FTSourceType . MUSIC ) , ARTISTBACKGROUND ( FTSourceType . MUSIC ) , ALBUMCOVER ( FTSourceType . MUSIC ) , MUSICLOGO ( FTSourceType . MUSIC ) ; private FTSourceType sourceType ; private FTArtworkType ( FTSourceType sourceType ) { this . sourceType = sourceType ; } / * * * Get the source type for the artwork type * * @ return * / public FTSourceType getSourceType ( ) { return sourceType ; } / * * * Get the source type for the artwork type * * @ return * / public FTSourceType source ( ) { return getSourceType ( ) ; }", "del_tokens": "ALL , CLEARART , CLEARLOGO , SEASONTHUMB , TVTHUMB , CHARACTERART , MOVIELOGO , MOVIEDISC , MOVIEART , CDART , ARTISTBACKGROUND , ALBUMCOVER , MUSICLOGO ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "use", "of", "==", "to", "compare", "strings"], "add_tokens": "boolean negated = \"without\" . equals ( ctx . getChild ( 0 ) . getText ( ) ) ; && ( current . getName ( ) . equals ( identifier ) ) ) { if ( current instanceof FunctionDef && current . getName ( ) . equals ( identifier ) ) { if ( current . getName ( ) . equals ( identifier ) ) { if ( current . getName ( ) . equals ( identifier ) ) {", "del_tokens": "boolean negated = ctx . getChild ( 0 ) . equals ( \"without\" ) ; && ( current . getName ( ) == identifier ) ) { if ( current instanceof FunctionDef && current . getName ( ) == identifier ) { if ( current . getName ( ) == identifier ) { if ( current . getName ( ) == identifier ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "refetch", "query", "to", "be", "adaptive", "if", "cached", "results", "are", "no", "longer", "in", "memory"], "add_tokens": "return AdaptiveResultSet . executeAdaptiveQuery ( placement . getKeyspace ( ) . getCqlSession ( ) , statement , _driverConfig . getSingleRowFetchSize ( ) ) ;", "del_tokens": ". setFetchSize ( _driverConfig . getSingleRowFetchSize ( ) ) return placement . getKeyspace ( ) . getCqlSession ( ) . execute ( statement ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "Analytics", "events", "to", "be", "pushed", "with", "a", "give", "user", "/", "session", "sample", "rate"], "add_tokens": "public void logEvent ( String event , float sampleRate ) { ForPlay . log ( ) . debug ( \"Analytics#logEvent(\" + event + \", \" + sampleRate + \")\" ) ;", "del_tokens": "public void logEvent ( String event ) { ForPlay . log ( ) . debug ( \"Analytics Event : \" + event ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "options", "to", "choose", "cipher", "to", "SHEStream"], "add_tokens": "public static SHEStream getInstance ( ) { return new SHEStream ( \"SHA-512\" ) ; return null ; } public static SHEStream getInstance ( String algorithm ) throws NoSuchAlgorithmException { return new SHEStream ( algorithm ) ; } protected SHEStream ( String algorithm ) throws NoSuchAlgorithmException { mD = MessageDigest . getInstance ( algorithm ) ; blockSize = mD . getDigestLength ( ) ;", "del_tokens": "public SHEStream ( ) { blockSize = 64 ; //keySize = 32; mD = MessageDigest . getInstance ( \"SHA-512\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "content", "to", "the", "readme", "and", "fix", "a", "couple", "minor", "bugs"], "add_tokens": "log . debug ( \"DDL: \" + metric . getMessage ( ) + \" \" + sql ) ; return \"Error executing SQL: \" + sql ;", "del_tokens": "log . debug ( \"Update: \" + metric . getMessage ( ) + \" \" + new DebugSql ( sql , null ) ) ; return \"Error executing SQL: \" + new DebugSql ( sql , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "preferences", "and", "conditionals", "to", "response", "resolver", "."], "add_tokens": "import org . httpcache4j . HTTPUtils ; return HTTPUtils . toHeader ( getHeaderName ( ) , Arrays . asList ( this ) ) ;", "del_tokens": "import java . util . List ; return toHeader ( getHeaderName ( ) , Arrays . < Preference > asList ( this ) ) ; protected static Header toHeader ( String headerName , List < Preference > preferences ) { StringBuilder builder = new StringBuilder ( ) ; for ( Preference preference : preferences ) { builder . append ( preference . toString ( ) ) ; builder . append ( \", \" ) ; } builder . delete ( builder . length ( ) - 2 , builder . length ( ) ) ; //remove last comma and space return new Header ( headerName , builder . toString ( ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Moved", "some", "constants", "to", "ApiConstructs", "to", "prepare", "for", "customization", "possibility"], "add_tokens": "public static final String CLONE_METHOD_NAME = \"clone\" ; public static final String COPY_METHOD_NAME = \"createCopy\" ; public static final String COPY_EXCEPT_METHOD_NAME = \"copyExcept\" ; public static final String COPY_ONLY_METHOD_NAME = \"copyOnly\" ; public static final String BUILD_COPY_METHOD_NAME = \"copyOf\" ; public static final String NEW_BUILDER_METHOD_NAME = \"builder\" ; public final String cloneMethodName ; public final String copyMethodName ; public final String copyExceptMethodName ; public final String copyOnlyMethodName ; public final String buildCopyMethodName ; public final String newBuilderMethodName ; this . cloneMethodName = ApiConstructs . CLONE_METHOD_NAME ; this . copyMethodName = ApiConstructs . COPY_METHOD_NAME ; this . copyExceptMethodName = ApiConstructs . COPY_EXCEPT_METHOD_NAME ; this . copyOnlyMethodName = ApiConstructs . COPY_ONLY_METHOD_NAME ; this . buildCopyMethodName = ApiConstructs . BUILD_COPY_METHOD_NAME ; this . newBuilderMethodName = ApiConstructs . NEW_BUILDER_METHOD_NAME ;", "del_tokens": "public static final String BUILDER_METHOD_NAME = \"builder\" ; private static final String CLONE_METHOD_NAME = \"clone\" ; private static final String COPY_METHOD_NAME = \"createCopy\" ; private static final String COPY_EXCEPT_METHOD_NAME = \"copyExcept\" ; private static final String COPY_ONLY_METHOD_NAME = \"copyOnly\" ; public final String cloneMethod ; public final String copyMethod ; public final String copyExceptMethod ; public final String copyOnlyMethod ; this . cloneMethod = ApiConstructs . CLONE_METHOD_NAME ; this . copyMethod = ApiConstructs . COPY_METHOD_NAME ; this . copyExceptMethod = ApiConstructs . COPY_EXCEPT_METHOD_NAME ; this . copyOnlyMethod = ApiConstructs . COPY_ONLY_METHOD_NAME ;", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "returning", "a", "TweakedModule"], "add_tokens": "import com . nesscomputing . testing . tweaked . TweakedModule ; new MapConfiguration ( getConfigurationTweak ( dbModuleName ) ) ) ; / * * * @ return a { @ link TweakedModule } which gives services database URLs * / public TweakedModule getTweakedModule ( final String dbModuleName ) { return new TweakedModule ( ) { @ Override public Map < String , String > getServiceConfigTweaks ( ) { return getConfigurationTweak ( dbModuleName ) ; } } ; } private ImmutableMap < String , String > getConfigurationTweak ( String dbModuleName ) { return ImmutableMap . of ( \"ness.db.\" + dbModuleName + \".uri\" , cluster . getNextDbUri ( ) ) ; }", "del_tokens": "new MapConfiguration ( ImmutableMap . of ( \"ness.db.\" + dbModuleName + \".uri\" , cluster . getNextDbUri ( ) ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "test", "resources", "under", "the", "proper", "package"], "add_tokens": "this . moduleBuilder . addConfigurationReader ( new PropertiesURLReader ( \"/org/nnsoft/guice/rocoto/configuration/ldap.properties\" ) ) ;", "del_tokens": "this . moduleBuilder . addConfigurationReader ( new PropertiesURLReader ( \"/com/googlecode/rocoto/simpleconfig/ldap.properties\" ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "containers", "in", "test", "case"], "add_tokens": "remove ( ) . image ( \"wildflyext/wildfly-camel\" ) . cmd ( \"/opt/jboss/wildfly/bin/jboss-cli.sh\" ) ; args ( \"-c\" , \"-u=\" + username , \"-p=\" + password , \"--controller=\" + host + \":\" + port ) ;", "del_tokens": "rm ( ) . image ( \"wildflyext/wildfly-camel\" ) . cmd ( \"/opt/jboss/wildfly/bin/jboss-cli.sh\" ) ; args . add ( \"-c\" ) ; args . add ( \"-u=\" + username ) ; args . add ( \"-p=\" + password ) ; args . add ( \"--controller=\" + host + \":\" + port ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "jamesagnew", "/", "hapi", "-", "fhir", "/", "issues", "/", "42"], "add_tokens": "assertEquals ( \"ResourceWithExtensionsA.extension\" , element . get ( 5 ) . getPath ( ) . getValue ( ) ) ; assertEquals ( \"ResourceWithExtensionsA.modifierExtension\" , element . get ( 6 ) . getPath ( ) . getValue ( ) ) ; assertEquals ( \"ResourceWithExtensionsA.identifier\" , element . get ( 13 ) . getPath ( ) . getValue ( ) ) ;", "del_tokens": "assertEquals ( \"ResourceWithExtensionsA.modifierExtension\" , element . get ( 5 ) . getPath ( ) . getValue ( ) ) ; assertEquals ( \"ResourceWithExtensionsA.identifier\" , element . get ( 12 ) . getPath ( ) . getValue ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "compare", "and", "equals", "to", "Instant"], "add_tokens": "/ * * * Safely compare one long with another . * * @ param a the first value * @ param b the second value * @ return negative if a is less than b , positive if a is greater than b , zero if equal * / public static int safeCompare ( long a , long b ) { if ( a < b ) { return - 1 ; } if ( a > b ) { return 1 ; } return 0 ; }", "del_tokens": "* @ throws ArithmeticException if the result overflows an int", "commit_type": "add"}
{"commit_tokens": ["Updated", "Vector", "implementations", "to", "cache", "certain", "commonly", "used", "values", "instead", "of", "computing", "them", "every", "time", "."], "add_tokens": "private Double sumCache = null ; private Double varianceCache = null ; private Double minCache = null ; private Double maxCache = null ; / * * * nulls out the cached summary statistics , should be called every time the data set changes * / private void clearCaches ( ) { sumCache = null ; varianceCache = null ; minCache = null ; maxCache = null ; } clearCaches ( ) ; if ( minCache != null ) return minCache ; return ( minCache = result ) ; if ( maxCache != null ) return maxCache ; return ( maxCache = result ) ; if ( sumCache != null ) return sumCache ; return ( sumCache = sum ) ; if ( varianceCache != null ) return varianceCache ; return ( varianceCache = tmp ) ;", "del_tokens": "return result ; return result ; return sum ; return tmp ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "the", "port", "generating", "script"], "add_tokens": "try { if ( p != null ) testingServerPort = Integer . parseInt ( p ) ; } catch ( NumberFormatException nfe ) { System . out . println ( \"Bad port number format, default port will be used: \" + testingServerPort ) ; }", "del_tokens": "if ( p != null ) testingServerPort = Integer . parseInt ( p ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "new", "jdbc", "query", "interface"], "add_tokens": "import cn . edu . tsinghua . tsfile . timeseries . read . support . Path ; import cn . edu . tsinghua . tsfile . timeseries . readV2 . datatype . TsPrimitiveType ; import java . util . Map . Entry ; List < String > arraySplited = Arrays . asList ( splited ) ; int i = 0 ; for ( Entry < Path , TsPrimitiveType > entry : record . getFields ( ) . entrySet ( ) ) { i ++ ; if ( i == tmp - 1 ) { return entry . getValue ( ) . getStringValue ( ) ; } } return null ;", "del_tokens": "import cn . edu . tsinghua . tsfile . timeseries . read . support . Field ; import cn . edu . tsinghua . tsfile . timeseries . readV2 . query . QueryDataSet ; List arraySplited = Arrays . asList ( splited ) ; Field field = record . fields . get ( tmp - 2 ) ; if ( field == null || field . getStringValue ( ) == null ) return null ; return field . getStringValue ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "as", "per", "commemnts", "to", "not", "override", "the", "method", "parameters", "value", "and", "instead", "to", "use", "ocal", "variable"], "add_tokens": "public License read ( final String license ) { String trimmedLicense = license . trim ( ) ; if ( sLicenses . containsKey ( trimmedLicense ) ) { return sLicenses . get ( trimmedLicense ) ; throw new IllegalStateException ( \"no such license available: \" + trimmedLicense + \", did you forget to register it?\" ) ;", "del_tokens": "public License read ( String license ) { license = license . trim ( ) ; if ( sLicenses . containsKey ( license ) ) { return sLicenses . get ( license ) ; throw new IllegalStateException ( \"no such license available: \" + license + \", did you forget to register it?\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "functor", "from", "public", "API", "and", "shade", "internal", "functor", "use"], "add_tokens": "/ * * * Callback interface . * * @ param < T > * / public interface Callback < T > { void handle ( T arg ) ; } / * * * Job interface . * * @ param < T > * / public interface Job < T > { T evaluate ( TherianContext context ) ; } public synchronized < T > T doWithHints ( Job < T > function , Hint ... hints ) { final Callback < ? super RESULT > callback ) { callback . handle ( result ) ;", "del_tokens": "import org . apache . commons . functor . Function ; import org . apache . commons . functor . Procedure ; public synchronized < T > T doWithHints ( Function < TherianContext , T > function , Hint ... hints ) { final Procedure < ? super RESULT > callback ) { callback . run ( result ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "mac", "elastic", "scrolling", "made", "scrolling", "smoother", "on", "mac"], "add_tokens": "private static final String ACTIVE_DIR = \".active\" ; private static final String ARCHIVE_DIR = \".archive\" ; File activePath = new File ( basePath , ACTIVE_DIR ) ; File archivePath = new File ( basePath , ARCHIVE_DIR ) ; File activeFlows = new File ( basePath , ACTIVE_DIR ) ; if ( activeFlowDirs == null ) { return ; } File baseActiveDir = new File ( basePath , ACTIVE_DIR ) ; File baseArchiveDir = new File ( basePath , ARCHIVE_DIR ) ; File activeDirectory = new File ( basePath , ACTIVE_DIR ) ; String activeReferencePath = ACTIVE_DIR + File . separator + exFlow . getExecutionId ( ) ; String archiveReferencePath = ARCHIVE_DIR + File . separator + exFlow . getExecutionId ( ) ;", "del_tokens": "File activePath = new File ( basePath , \".active\" ) ; File archivePath = new File ( basePath , \".archive\" ) ; File activeFlows = new File ( basePath , \"active\" ) ; File baseActiveDir = new File ( basePath , \"active\" ) ; File baseArchiveDir = new File ( basePath , \"archive\" ) ; File activeDirectory = new File ( basePath , \"active\" ) ; String activeReferencePath = \"active\" + File . separator + exFlow . getExecutionId ( ) ; String archiveReferencePath = \"archive\" + File . separator + exFlow . getExecutionId ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "newest", "versions", "in", "Met", "api", "v3"], "add_tokens": "Assert . assertTrue ( ! sunriseDate . getSun ( ) . getNeverSet ( ) ) ;", "del_tokens": "Assert . assertTrue ( sunriseDate . getSun ( ) . getNeverSet ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "indices", "and", "metadata", "(", "and", "fixed", "test", "fails", ")"], "add_tokens": "String sql = \"SELECT '' AS TABLE_CAT, '' AS TABLE_SCHEM, '' AS TABLE_NAME, '' AS SUPERTABLE_NAME \"", "del_tokens": "String sql = \"'' AS TABLE_CAT, '' AS TABLE_SCHEM, '' AS TABLE_NAME, '' AS SUPERTABLE_NAME \"", "commit_type": "add"}
{"commit_tokens": ["Removed", "recognition", "of", "webProfile6", "runtime"], "add_tokens": "String value = selected . getProperty ( type ) ; throw new BuildException ( \"Archive type \" + type + \" is not available for Liberty version \" + selected . getVersion ( ) ) ;", "del_tokens": "String propertyName = ( \"webProfile6\" . equalsIgnoreCase ( type ) ) ? \"uri\" : type ; String value = selected . getProperty ( propertyName ) ; throw new BuildException ( \"Archive type \" + propertyName + \" is not available for Liberty version \" + selected . getVersion ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "readme", ".", "md", "and", "update", "test"], "add_tokens": "System . out . println ( all ) ;", "del_tokens": "System . out . println ( \"===========\\t\" + all ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "@TestDocs", "and", "@Pages", "test"], "add_tokens": "import org . sahagin . runlib . external . Locale ; private void testMain ( String methodName , Locale userLocale ) { AcceptableLocales locales = AcceptableLocales . getInstance ( userLocale ) ; testMain ( \"variousData\" , null ) ; testMain ( \"utf8Character\" , null ) ; } @ Test public void defaultLocale ( ) { testMain ( \"defaultLocale\" , null ) ; } @ Test public void jaJpLocale ( ) { testMain ( \"jaJpLocale\" , Locale . JA_JP ) ;", "del_tokens": "private void testMain ( String methodName ) { AcceptableLocales locales = AcceptableLocales . getInstance ( null ) ; testMain ( \"variousData\" ) ; testMain ( \"utf8Character\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "registering", "new", "custom", "types"], "add_tokens": "assertEquals ( Status . BAD_REQUEST . getStatusCode ( ) , getCreateResponse ( null , null , null ) . getStatus ( ) ) ;", "del_tokens": "assertEquals ( Status . BAD_REQUEST . getStatusCode ( ) , getCreateResponse ( null , null ) . getStatus ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "javadoc", "in", "deletion", "move"], "add_tokens": "* @ return 1", "del_tokens": "* @ return * * @ param solution", "commit_type": "update"}
{"commit_tokens": ["added", "SuppressWarnings", "annotation", "for", "unchecked", "cast"], "add_tokens": "* @ return list of HTML elements", "del_tokens": "* @ return List of HTML elements", "commit_type": "add"}
{"commit_tokens": ["Add", "stuff", "to", "bench", "the", "cache", "."], "add_tokens": "long start = System . currentTimeMillis ( ) ; long end = System . currentTimeMillis ( ) ; long time = end - start ; mTextViewDataTime . setText ( \"Last access time : \" + time + \" ms\" ) ; long start = System . currentTimeMillis ( ) ; long end = System . currentTimeMillis ( ) ; long time = end - start ; mTextViewDataTime . setText ( \"Last access time : \" + time + \" ms\" ) ;", "del_tokens": "VBLibCacheLogUtils . enableLog ( ) ; VBLibCacheContextUtils . setContext ( getApplicationContext ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "handling", "empty", "artwork", "."], "add_tokens": "if ( artwork != null ) { artwork . rewind ( ) ; return artwork . slice ( ) ; } return null ;", "del_tokens": "artwork . rewind ( ) ; return artwork . slice ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "parameter", "to", "avoid", "overwrite", "generated", "files"], "add_tokens": "private final boolean overwrite ; boolean listGeneratedFiles , boolean overwrite , JsonObject config ) throws IOException { this . overwrite = overwrite ; boolean generateFile = ! outputFile . exists ( ) ; if ( outputFile . exists ( ) && overwrite ) { generateFile = true ;", "del_tokens": "boolean listGeneratedFiles , JsonObject config ) throws IOException { boolean generateFile = true ; if ( outputFile . exists ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "Javadoc", "after", "ID", "review", "."], "add_tokens": "* Enable displaying all Bluemix Mobile Services SDK debug and info logs in Logcat . * By default , only errors , warnings , and fatal messages are displayed in Logcat . * @ param enabled Determines whether to display Bluemix Mobile Services SDK debug and info logs in Logcat .", "del_tokens": "* Enable the logging of any debug and INFO - level messages coming from the Bluemix Mobile Services SDKs . * By default , only errors , warnings , and fatal messages will be logged for these SDKs . * @ param enabled whether to log internal debug and info messages", "commit_type": "change"}
{"commit_tokens": ["Adding", "the", "solo", "window", "functionality"], "add_tokens": "if ( hasSoloWindowAbove ( windowPlacement ) ) private boolean hasSoloWindowAbove ( WindowPlacement windowPlacement ) { int index = windowStack . indexOf ( windowPlacement ) ; for ( int i = index + 1 ; i < windowStack . size ( ) ; i ++ ) { if ( windowStack . get ( i ) . window . isSoloWindow ( ) ) return true ; } return false ; }", "del_tokens": "if ( windowPlacement . getWindow ( ) . isHideWhenNotTopLevel ( ) && windowPlacement != windowStack . getLast ( ) )", "commit_type": "add"}
{"commit_tokens": ["Uses", "new", "OpenSearchQueryParser", "to", "parse", "queries", "instead", "of", "only", "parsing", "the", "advanced", "search", "form", "CGI", "arguments"], "add_tokens": "private OpenSearchQueryParser qp = new OpenSearchQueryParser ( ) ; // TODO initialize renderer? wbRequest = qp . parseQuery ( httpRequest . getParameterMap ( ) ) ; //wbRequest = parseCGIRequest(httpRequest);", "del_tokens": "import java . util . Iterator ; import java . util . Map ; import java . util . Set ; // TODO initialize renderer private String getMapParam ( Map queryMap , String field ) { String arr [ ] = ( String [ ] ) queryMap . get ( field ) ; if ( arr == null || arr . length == 0 ) { return null ; } return arr [ 0 ] ; } public WaybackRequest parseCGIRequest ( HttpServletRequest httpRequest ) throws BadQueryException { WaybackRequest wbRequest = new WaybackRequest ( ) ; Map queryMap = httpRequest . getParameterMap ( ) ; Set keys = queryMap . keySet ( ) ; Iterator itr = keys . iterator ( ) ; while ( itr . hasNext ( ) ) { String key = ( String ) itr . next ( ) ; String val = getMapParam ( queryMap , key ) ; wbRequest . put ( key , val ) ; } return wbRequest ; } wbRequest = parseCGIRequest ( httpRequest ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "test", "case", "to", "tolerate", "Jenkins", "special", "character", "issue"], "add_tokens": "// On the Jenkins build, test resources with special characters in the // name are not extracted from github. Only check for the existence of // the class file if the JSP file exists. File srcJspDir = new File ( url ) . getParentFile ( ) ; if ( ( new File ( srcJspDir , \"X-_+.%.jsp\")) . e x ists() ) { f = new File ( compileDir , \"_X_2D__5F__2B__2E__20AC__25_.class\" ) ; assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; f = new File ( compileDir , \"childDir/_X_2D__5F__2B__2E__20AC__25_.class\" ) ; assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; } if ( ( new File ( srcJspDir , \".jsp\")).exis t s ( )) { f = new File ( compileDir , \"_.class\"); assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; f = new File ( compileDir , \"childDir/_.class\"); assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; }", "del_tokens": "f = new File ( compileDir , \"_X_2D__5F__2B__2E__20AC__25_.class\" ) ; assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; f = new File ( compileDir , \"childDir/_X_2D__5F__2B__2E__20AC__25_.class\" ) ; assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; f = new File ( compileDir , \"_.class\"); assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ; f = new File ( compileDir , \"childDir/_.class\"); assertTrue ( \"The compiled JSP should exist: \" + f , f . exists ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "properties", "setProperty", "instead", "of", "put", "."], "add_tokens": "nextProj . getProperties ( ) . setProperty ( this . timestampPropertyName , timestampString ) ;", "del_tokens": "nextProj . getProperties ( ) . put ( this . timestampPropertyName , timestampString ) ;", "commit_type": "use"}
{"commit_tokens": ["moved", "cached", "-", "droid", "-", "sugar", "-", "classes", ".", "jar", "to", "local", "tmp", "directory", "."], "add_tokens": "import java . io . File ; public void saveAllClassesToCache ( File file ) { File cacheJarDir = file . getParentFile ( ) ; if ( ! cacheJarDir . exists ( ) ) { //noinspection ResultOfMethodCallIgnored cacheJarDir . mkdirs ( ) ; } jarOutputStream = new JarOutputStream ( new FileOutputStream ( file , true ) ) ;", "del_tokens": "public void saveAllClassesToCache ( String filename ) { jarOutputStream = new JarOutputStream ( new FileOutputStream ( filename , true ) ) ;", "commit_type": "move"}
{"commit_tokens": ["updated", "LifecycleTestDriver", "to", "catch", "@Before", "/", "@After", "execution", "failures"], "add_tokens": "import org . jboss . arquillian . warp . impl . shared . ResponsePayload ; * * * @ Inject private Instance < ResponsePayload > responsePayload ; for ( final Object assertionObject : registry ( ) . getAssertions ( ) ) { executeTest ( assertionObject , testMethod ) ; } } } private void executeTest ( Object assertionObject , Method testMethod ) { try { before . fire ( new Before ( assertionObject , testMethod ) ) ; test . fire ( new Test ( new LifecycleMethodExecutor ( assertionObject , testMethod ) ) ) ; after . fire ( new After ( assertionObject , testMethod ) ) ; } catch ( Throwable e ) { responsePayload . get ( ) . setThrowable ( e ) ; private AssertionRegistry registry ( ) {", "del_tokens": "* * * final AssertionRegistry registry = getRegistry ( ) ; for ( final Object assertionObject : registry . getAssertions ( ) ) { before . fire ( new Before ( assertionObject , testMethod ) ) ; test . fire ( new Test ( new LifecycleMethodExecutor ( assertionObject , testMethod ) ) ) ; after . fire ( new After ( assertionObject , testMethod ) ) ; } private AssertionRegistry getRegistry ( ) {", "commit_type": "update"}
{"commit_tokens": ["removing", "useless", "code", "and", "unused", "imports"], "add_tokens": "* A deployer that locates or generates CXF configuration file URL cxfURL = getCXFConfigFromDeployment ( dep ) ; cxfURL = generateCXFConfigFromDeployment ( dep ) ; putCXFConfigToDeployment ( dep , cxfURL ) ;", "del_tokens": "* A deployer that locates or generates cxf . xml URL cxfURL = getCXFConfigFromClassLoader ( dep ) ; cxfURL = getCXFConfigFromDeployment ( dep ) ; if ( cxfURL == null ) { cxfURL = generateCXFConfigFromDeployment ( dep ) ; } putCXFConfigToDeployment ( dep , cxfURL ) ; / * * * Looks for < b > cxf . xml < / b > in classloader * @ param dep deployment which initial classloader will be used * @ return < b > cxf . xml URL < / b > or < b > null < / b > if not found * / private static URL getCXFConfigFromClassLoader ( Deployment dep ) { ClassLoader initCL = dep . getInitialClassLoader ( ) ; URL cxfURL = initCL . getResource ( \"cxf.xml\" ) ; if ( cxfURL != null ) { log . info ( \"CXF configuration found: \" + cxfURL ) ; } return cxfURL ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "methods", "to", "get", "header", "values"], "add_tokens": "public Map < String , List < String > > getHeaders ( ) {", "del_tokens": "public Map < String , List < String > > getAllHeaders ( ) { / * * * Get the given HTTP header of the response * / @ Override public String getHeader ( String key ) { return ahcResponse . getHeader ( key ) ; }", "commit_type": "add"}
{"commit_tokens": ["remove", "API", "token", "after", "test", "before", "deleting", "the", "workspace", "."], "add_tokens": "protected UUID apiTokenId ; String apiToken = addUserToWorkspace ( account , workspace ) ; this . leanixApiClient = createLeanixApiClient ( workspace . getName ( ) , apiToken , getApiMtmHostName ( ) ) ; this . deleteApiToken ( this . apiTokenId ) ; apiTokenId = token . getId ( ) ; protected void deleteApiToken ( UUID apiTokenId ) { Retrofit retrofit = getRetrofit ( mtmApiClient . getBasePath ( ) , readAccessToken ( mtmApiClient ) ) ; PersonalAccessTokenApi tokenApi = retrofit . create ( PersonalAccessTokenApi . class ) ; try { tokenApi . deletePersonalAccessToken ( apiTokenId ) . execute ( ) ; } catch ( IOException e ) { throw new RuntimeException ( \"cannot delete api token\" , e ) ; } }", "del_tokens": "protected String getPersonalAccessToken ( ) { return getProperty ( \"api.pat\" ) ; } String apiKey = addUserToWorkspace ( account , workspace ) ; this . leanixApiClient = createLeanixApiClient ( workspace . getName ( ) , apiKey , getApiMtmHostName ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "related", "to", "null", ".", "(", "New", "producer", ")"], "add_tokens": "return CompletableFuture . completedFuture ( null ) ;", "del_tokens": "return null ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "MetricNameMapper", "concept", "to", "allow", "parsing", "strings", "into", "metric", "names", "in", "creative", "ways"], "add_tokens": "private final MetricNameMapper mapper ; this ( writer , registry , MetricNameMapper . PASSTHROUGH_MAPPER ) ; } public PcpMonitorBridge ( PcpWriter writer , MonitorableRegistry registry , MetricNameMapper mapper ) { Preconditions . checkNotNull ( mapper ) ; this . mapper = mapper ; pcpWriter . addMetric ( mapper . map ( monitorable . getName ( ) ) , monitorable pcpWriter . updateMetric ( mapper . map ( monitorable . getName ( ) ) , monitorable . get ( ) ) ;", "del_tokens": "import com . custardsource . parfait . dxm . MetricName ; pcpWriter . addMetric ( MetricName . parse ( monitorable . getName ( ) ) , monitorable pcpWriter . updateMetric ( MetricName . parse ( monitorable . getName ( ) ) , monitorable . get ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implementing", "some", "improvements", "in", "CORS", "filter"], "add_tokens": "import org . jcors . config . ConfigLoader ; import org . jcors . config . JCorsConfig ; private JCorsConfig config ; this . config = ConfigLoader . load ( ) ; log . error ( \"Error while handling a request\" , ex ) ; httpResponse . sendError ( HttpServletResponse . SC_BAD_REQUEST , ex . getMessage ( ) ) ; return ;", "del_tokens": "import org . jcors . config . JCorsConfiguration ; private JCorsConfiguration config ; //TODO: parse XML configuration file, if existing in classpath this . config = new JCorsConfiguration ( ) ; log . error ( \"Error while handling a request\" ) ; throw new ServletException ( ex . getMessage ( ) , ex ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "ForeachUpdate", "and", "ForeachUpdateRemove", "statements", "by", "adding", "missing", "double", "quotes"], "add_tokens": "json . append ( \"\\\"$foreach\\\":{\" ) ; json . append ( \"\\\"\" + this . path + \"\\\"\" ) ; json . append ( \", \\\"$update\\\" :\" ) ;", "del_tokens": "json . append ( \"$foreach:{\" ) ; json . append ( this . path ) ; json . append ( \", $update :\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "doc", "to", "param", "injectors"], "add_tokens": "docParameter . belongs = \"url\" ;", "del_tokens": "docParameter . belongs = \"url-query\" ;", "commit_type": "add"}
{"commit_tokens": ["remove", "redundancy", "in", "IOUtils", ".", "getContenType"], "add_tokens": "return Files . probeContentType ( file . toPath ( ) ) ;", "del_tokens": "return Files . probeContentType ( Paths . get ( file . getPath ( ) ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "issue", "with", "class", "loading", "for", "aw", "core", "stuff"], "add_tokens": "//TODO - improve/refactor classloading if ( name . startsWith ( \"activeweb.\" ) ) {", "del_tokens": "if ( \"activeweb.AppController\" . equals ( name ) ) {", "commit_type": "fix"}
{"commit_tokens": ["changed", "access", "level", "of", "constructors", "of", "CommandLineRunner", "to", "protected"], "add_tokens": "protected CommandLineRunner ( String [ ] args ) { protected CommandLineRunner ( String [ ] args , PrintStream out , PrintStream err ) {", "del_tokens": "public CommandLineRunner ( String [ ] args ) { public CommandLineRunner ( String [ ] args , PrintStream out , PrintStream err ) {", "commit_type": "change"}
{"commit_tokens": ["Change", "name", "of", "Decorator", "to", "Events"], "add_tokens": "public interface Events < Id > { public final < Id > HttpObject onEvents ( Events < Id > events ) { return eventsResource ( this , events ) ; private static < Id > HttpObject eventsResource ( final HttpObject resource , final Events < Id > events ) { Id id = events . onRequest ( req ) ; events . onResponse ( id , res ) ; events . onError ( err ) ;", "del_tokens": "public interface Decorator < Id > { public final < Id > HttpObject decorate ( Decorator < Id > decorator ) { return decorateResource ( this , decorator ) ; private static < Id > HttpObject decorateResource ( final HttpObject resource , final Decorator < Id > decorator ) { Id id = decorator . onRequest ( req ) ; decorator . onResponse ( id , res ) ; decorator . onError ( err ) ;", "commit_type": "change"}
{"commit_tokens": ["fixes", "bad", "blending", "with", "alpha", "channels", "(", "e", ".", "g", ".", "DIFFERENCE", "would", "lead", "to", "0", "alpha", ")"], "add_tokens": "float a = Math . min ( visibility * ( temp = a ( topRGBA ) ) + a ( bottomRGBA ) , 0xff ) ; visibility = Math . max ( visibility - ( 1 - ( temp / 255.0f ) ) , 0 ) ;", "del_tokens": "float a = visibility * func . blend ( temp = a ( bottomRGBA ) , a ( topRGBA ) ) + temp * ( 1 - visibility ) ; visibility = Math . max ( visibility - ( 1 - ( a ( topRGBA ) / 255.0f ) ) , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "if", "instead", "of", "iff"], "add_tokens": "* @ return true if this is equal to the specified monetary value * @ return true if this is greater than the specified monetary value * @ return true if this is less than the specified monetary value", "del_tokens": "* @ return true iff this is equal to the specified monetary value * @ return true iff this is greater than the specified monetary value * @ return true iff this is less than the specified monetary value", "commit_type": "use"}
{"commit_tokens": ["Added", "comment", "explaining", "the", "environment", "trimming", "ordering", "and", "counting", "of", "permanent", "variables", "remaining", "."], "add_tokens": "* Allocates stack slots where need to the variables in a program clause . The algorithm here is fairly complex . * < p / > In addition to working out which variables are permanent , the variables are also ordered by reverse position * of last body of occurrence , and assigned to allocation slots in this order . The number of permanent variables * remaining at each body call is also calculated and recorded against the body functor in the symbol table using * column { @ link # SYMKEY_PERM_VARS_REMAINING } . This allocation ordering of the variables and the count of the number * remaining are used to implement environment trimming . *", "del_tokens": "* Allocates stack slots where need to the variables in a program clause .", "commit_type": "add"}
{"commit_tokens": ["Remove", "non", "-", "existant", "card", "types"], "add_tokens": "payIn . PaymentDetails . CardType = card . CardType ;", "del_tokens": "if ( card . CardType . equals ( \"CB\" ) || card . CardType . equals ( \"VISA\" ) || card . CardType . equals ( \"MASTERCARD\" ) ) ( ( PayInPaymentDetailsCard ) payIn . PaymentDetails ) . CardType = \"CB_VISA_MASTERCARD\" ; else if ( card . CardType . equals ( \"AMEX\" ) ) ( ( PayInPaymentDetailsCard ) payIn . PaymentDetails ) . CardType = \"AMEX\" ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "that", "caused", "DeepCqlRecordWriter", "no", "to", "be", "closed", "correctly"], "add_tokens": "public void close ( ) { sessionWithHost . left . execute ( cql , bindVariables . toArray ( new Object [ bindVariables . size ( ) ] ) ) ;", "del_tokens": "public void close ( ) throws IOException { sessionWithHost . left . execute ( cql , bindVariables ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "MiddlewaresFactory#create", "to", "throw", "Exception"], "add_tokens": "try { this . middlewares = middlewareFactory . create ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } return middlewares ;", "del_tokens": "this . middlewares = middlewareFactory . create ( ) ; return middlewareFactory . create ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["adding", "a", "new", "pair", "of", "tags", "to", "format", "a", "message", "resource", "by", "using", "a", "nested", "structure", "."], "add_tokens": "if ( resourceBundle == null ) resourceBundle = ResourceBundle . load ( locator . getSystemId ( ) ) ;", "del_tokens": "if ( resourceBundle == null ) { String scriptUrl = locator . getSystemId ( ) ; if ( scriptUrl . endsWith ( \".jelly\" ) ) // cut the trailing .jelly scriptUrl = scriptUrl . substring ( 0 , scriptUrl . length ( ) - \".jelly\" . length ( ) ) ; JellyFacet facet = WebApp . getCurrent ( ) . getFacet ( JellyFacet . class ) ; resourceBundle = facet . resourceBundleFactory . create ( scriptUrl ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "bulk", "jmx", "attributes", "request"], "add_tokens": "import javax . management . Attribute ; import javax . management . AttributeList ; Map < String , MBeanAttributeInfo > name2AttrInfo = new LinkedHashMap < String , MBeanAttributeInfo > ( ) ; name2AttrInfo . put ( attr . getName ( ) , attr ) ; } final AttributeList attributes ; try { attributes = beanConn . getAttributes ( mbeanName , name2AttrInfo . keySet ( ) . toArray ( new String [ 0 ] ) ) ; } catch ( Exception e ) { logScrape ( mbeanName , name2AttrInfo . keySet ( ) , \"Fail: \" + e ) ; return ; } for ( Attribute attribute : attributes . asList ( ) ) { MBeanAttributeInfo attr = name2AttrInfo . get ( attribute . getName ( ) ) ; attribute . getValue ( ) ) ; private static void logScrape ( ObjectName mbeanName , Set < String > names , String msg ) { logScrape ( mbeanName + \"_\" + names , msg ) ; }", "del_tokens": "Object value ; try { value = beanConn . getAttribute ( mbeanName , attr . getName ( ) ) ; } catch ( Exception e ) { logScrape ( mbeanName , attr , \"Fail: \" + e ) ; continue ; } value ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "missing", "query", "statement", "in", "batch"], "add_tokens": "super ( preparedStatement , query , dbType , dbUser , withActiveSpanOnly ) ;", "del_tokens": "super ( preparedStatement , dbType , dbUser , withActiveSpanOnly ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "possibility", "to", "put", "value", "with", "custom", "ttl"], "add_tokens": "put ( key , value , ttl ) ; } public void put ( final K key , final V value , long ttl ) { updateTimingCache ( h , ttl ) ; return putIfAbsent ( key , value , ttl ) ; } public boolean putIfAbsent ( final K key , final V value , long ttl ) { updateTimingCache ( h , ttl ) ; updateTimingCache ( key , ttl ) ; } private void updateTimingCache ( final Holder < K , V > key , long ttl ) {", "del_tokens": "updateTimingCache ( h ) ; updateTimingCache ( h ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "issue", "where", "classpath", "items", "that", "didn", "t", "exist", "would", "result", "in", "illegalstate", "exception"], "add_tokens": "public static ResourceProvider < Resource . InputStreaming > getProvider ( List < URL > urls ) { return new URLArrayResourceProvider ( urls ) ; } return getProvider ( urls ) ;", "del_tokens": "return new URLArrayResourceProvider ( urls ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "version", "in", "the", "URI"], "add_tokens": "private UriParser uriParser ; public void setUriParser ( UriParser uriParser ) { this . uriParser = uriParser ; } // special case where version is in the URI String version = uriRequestResult . getVersion ( ) ; { version = request . getFirstParameter ( hyperionEndpointConfiguration . getVersionParameterName ( ) ) ; if ( version == null || version . length ( ) == 0 ) version = request . getFirstHeader ( hyperionEndpointConfiguration . getVersionHeaderName ( ) ) ; if ( hyperionEndpointConfiguration . isRequireVersion ( ) && httpMethod != HttpMethod . DELETE && ( version == null || version . length ( ) == 0 ) ) throw new BadRequestException ( String . format ( \"The %s parameter must be specified\" , hyperionEndpointConfiguration . getVersionParameterName ( ) ) ) ; }", "del_tokens": "private UriParser uriParser = new UriParser ( ) ; String version = request . getFirstParameter ( hyperionEndpointConfiguration . getVersionParameterName ( ) ) ; version = request . getFirstHeader ( hyperionEndpointConfiguration . getVersionHeaderName ( ) ) ; if ( hyperionEndpointConfiguration . isRequireVersion ( ) && httpMethod != HttpMethod . DELETE && ( version == null || version . length ( ) == 0 ) ) throw new BadRequestException ( String . format ( \"The %s parameter must be specified\" , hyperionEndpointConfiguration . getVersionParameterName ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "security", "group", "again", "since", "ec2", "needs", "it"], "add_tokens": ". runScript ( AdminAccess . standard ( ) ) . securityGroups ( securityGroup ) ;", "del_tokens": ". runScript ( AdminAccess . standard ( ) ) ; //.securityGroups(securityGroup);", "commit_type": "add"}
{"commit_tokens": ["allow", "evaluation", "by", "recognizer", "of", "command", "execution", "response"], "add_tokens": "import org . openengsb . labs . endtoend . recognizer . Recognizer ; public class KarafClientShell extends AbstractKarafShell implements RemoteShell { protected OutputHandler getOutputHandler ( ) { return outputHandler ; protected PrintWriter getPrintWriter ( ) { return pw ;", "del_tokens": "import org . openengsb . labs . endtoend . util . OS ; public class KarafClientShell implements RemoteShell { @ Override public void waitForPrompt ( Long timeout , TimeUnit timeUnit ) throws TimeoutException { outputHandler . waitForPrompt ( timeout , timeUnit ) ; } public String execute ( String command , Long timeout , TimeUnit timeUnit ) throws CommandTimeoutException { this . pw . println ( command ) ; this . pw . flush ( ) ; try { return this . outputHandler . getOutput ( timeout , timeUnit ) ; } catch ( TimeoutException e ) { throw new CommandTimeoutException ( command , e ) ; } public void execute ( String command ) { this . pw . println ( command ) ; this . pw . flush ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixing", "the", "sampler", "[", "ci", "skip", "]"], "add_tokens": "grammar . expandRules ( ) ; GrammarRules rules = grammar . toGrammarRulesData ( ) ;", "del_tokens": "GrammarRules rules = grammar . toGrammarRulesData ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "lifecycle", "properties", "for", "making", "service", "registration", "optional"], "add_tokens": "@ Autowired private LifecycleProperties lifecycleProperties ; return lifecycleProperties . isEnabled ( ) ;", "del_tokens": "return properties . isEnabled ( ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "message", "size", "validation", "to", "worker", "pool", "dispatching", "source", "handler"], "add_tokens": "protected CarbonMessage createRejectResponse ( ) {", "del_tokens": "private CarbonMessage createRejectResponse ( ) {", "commit_type": "add"}
{"commit_tokens": ["use", "xor", "operator", "and", "remove", "redundant", "interface"], "add_tokens": "// only one source should be defined Preconditions . checkArgument ( ( source != null ) ^ ( source2 != null ) ) ; @ SuppressWarnings ( { \"serial\" } ) private static abstract class BufferToFileSubscriber < T > extends AtomicInteger implements Runnable { // `error` set just before the volatile `done` is set and read just after abstract public void cancelUpstream ( ) ;", "del_tokens": "Preconditions . checkArgument ( source != null && source2 == null || source == null && source2 != null ) ; private interface HasUpstream { void cancelUpstream ( ) ; } @ SuppressWarnings ( { \"serial\" } ) private static abstract class BufferToFileSubscriber < T > extends AtomicInteger implements Runnable , HasUpstream { // Is set just before the volatile `done` is set and read just after", "commit_type": "use"}
{"commit_tokens": ["fix", "parsing", "of", "identifiers", "containing", "boolean", "constants", "as", "substrings"], "add_tokens": "import org . sonar . cxx . api . CxxKeyword ; // C++ Standard, Section 2.14.6 \"Boolean literals\" bool . is ( or ( CxxKeyword . TRUE , CxxKeyword . FALSE ) ) ; NUMBER , bool )", "del_tokens": "NUMBER )", "commit_type": "fix"}
{"commit_tokens": ["making", "the", "server", "location", "in", "the", "JFatCatClient", "optional"], "add_tokens": "import org . biojava . bio . structure . align . client . FarmJobParameters ; String serverLocation = FarmJobParameters . DEFAULT_SERVER_URL ; SortedSet < String > repre = JFatCatClient . getRepresentatives ( serverLocation , 40 ) ;", "del_tokens": "SortedSet < String > repre = JFatCatClient . getRepresentatives ( 50 ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "need", "for", "synthetic", "accessors"], "add_tokens": "static final SimpleDateFormat SCREENSHOT_FILE_FORMAT = final MediaProjectionManager projectionManager ; final WindowManager windowManager ; Lens lens ; float progressFraction ; float doneFraction ; boolean saving ; void trigger ( ) { void checkLens ( ) { void captureCanvasScreenshot ( ) { void capturingEnd ( ) { View getTargetView ( ) { static File getScreenshotFolder ( Context context ) { void unregisterRequestCaptureReceiver ( ) { static Handler getBackgroundHandler ( ) { @ TargetApi ( LOLLIPOP ) void captureNativeScreenshot ( final MediaProjection projection ) {", "del_tokens": "private static final SimpleDateFormat SCREENSHOT_FILE_FORMAT = private final MediaProjectionManager projectionManager ; private final WindowManager windowManager ; private Lens lens ; private float progressFraction ; private float doneFraction ; private boolean saving ; private void trigger ( ) { private void checkLens ( ) { private void captureCanvasScreenshot ( ) { private void capturingEnd ( ) { private View getTargetView ( ) { private static File getScreenshotFolder ( Context context ) { private void unregisterRequestCaptureReceiver ( ) { private static Handler getBackgroundHandler ( ) { @ TargetApi ( LOLLIPOP ) private void captureNativeScreenshot ( final MediaProjection projection ) {", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "number", "of", "minor", "bugs", "uncovered", "in", "new", "integration", "tests"], "add_tokens": "return Collections . emptyList ( ) ;", "del_tokens": "throw new OperationNotSupportedException ( version + \" is not supported in \" + provider . getCloudName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "identity", "map", "to", "link", "nodes", "to", "resolved", "names", "and", "output", "schemas"], "add_tokens": "import java . util . IdentityHashMap ; private final IdentityHashMap < QualifiedNameReference , QualifiedName > resolvedNameReferences ; private final IdentityHashMap < Node , Schema > outputSchemas ; public TreePrinter ( IdentityHashMap < QualifiedNameReference , QualifiedName > resolvedNameReferences , IdentityHashMap < Node , Schema > outputSchemas , this . resolvedNameReferences = new IdentityHashMap < > ( resolvedNameReferences ) ; this . outputSchemas = new IdentityHashMap < > ( outputSchemas ) ;", "del_tokens": "import com . google . common . collect . ImmutableMap ; import java . util . Map ; private final Map < QualifiedNameReference , QualifiedName > resolvedNameReferences ; private final ImmutableMap < Node , Schema > outputSchemas ; public TreePrinter ( Map < QualifiedNameReference , QualifiedName > resolvedNameReferences , Map < Node , Schema > outputSchemas , this . resolvedNameReferences = ImmutableMap . copyOf ( resolvedNameReferences ) ; this . outputSchemas = ImmutableMap . copyOf ( outputSchemas ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "string", "comparison", "of", "secureDistribution"], "add_tokens": "sharedDomain = sharedDomain || Cloudinary . SHARED_CDN . equals ( secureDistribution ) ;", "del_tokens": "sharedDomain = sharedDomain || secureDistribution == Cloudinary . SHARED_CDN ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "auto", "UOM"], "add_tokens": "/** '*' value provided */ STAR ( \"star\" ) , /** Automatic scaling */ AUTO ( \"auto\" ) ; / * * * @ return < code > true < / code > if this unit of measure depends on the width of * the surrounding element , < code > false < / code > if this unit of measure * defines the width based on the content of this element . * / public boolean isOuterElementDependent ( ) { return this == ABSOLUTE || this == PERCENTAGE || this == STAR ; }", "del_tokens": "/** * value provided */ STAR ( \"star\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "Do", "NOT", "require", "Java", "7", "in", "HttpMockServer", "class", "."], "add_tokens": "} catch ( IOException e ) { LOGGER . log ( Level . SEVERE , \"MockServer error:\" , e ) ; } catch ( JSONException e ) {", "del_tokens": "} catch ( IOException | JSONException e ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "async", "processors"], "add_tokens": "import org . apache . camel . AsyncCallback ; import org . apache . camel . AsyncProcessor ; final Processor currentProcessor = getProcessor ( ) ; if ( currentProcessor instanceof AsyncProcessor ) { ( ( AsyncProcessor ) currentProcessor ) . process ( exchange , new AsyncCallback ( ) { @ Override public void done ( boolean doneSync ) { // we are not interested in this event } } ) ; } else { currentProcessor . process ( exchange ) ; }", "del_tokens": "getProcessor ( ) . process ( exchange ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "exitCheckPause", "into", "TestManager", "and", "the", "ability", "to", "set", "it", "."], "add_tokens": "private int exitCheckPause = 2000 ; public void setExitCheckPause ( int value ) { if ( value < 2000 ) return ; this . exitCheckPause = value ; } try { //Wait for JMeter to clean up threads. Thread . sleep ( this . exitCheckPause ) ; } catch ( InterruptedException e ) { } }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "timestamp", "provider", "instead", "of", "instantiating", "a", "new", "java", ".", "util", ".", "Date"], "add_tokens": "import org . grails . datastore . gorm . timestamp . DefaultTimestampProvider ; DefaultTimestampProvider timestampProvider ; if ( timestampProvider == null ) { timestampProvider = new DefaultTimestampProvider ( ) ; } properties . put ( GormProperties . LAST_UPDATED , timestampProvider . createTimestamp ( lastUpdated . getType ( ) ) ) ;", "del_tokens": "properties . put ( GormProperties . LAST_UPDATED , new Date ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "Jesque", "-", "Web", "Issue", "8"], "add_tokens": "import java . text . DateFormat ; import net . greghaines . jesque . utils . CompositeDateFormat ; final DateFormat jsonDateFormat = new CompositeDateFormat ( ) ; mapper . getDeserializationConfig ( ) . with ( jsonDateFormat ) ; mapper . getSerializationConfig ( ) . with ( jsonDateFormat ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Added", "very", "basic", "Twitter", "sample", "app", "."], "add_tokens": "connectionRepository . disconnect ( accountIdResolver . resolveAccountId ( ) , getName ( ) , providerAccountId ) ;", "del_tokens": "connectionRepository . disconnect ( accountIdResolver . resolveAccountId ( ) , getName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "buffersortable", "with", "memory", "guarantees"], "add_tokens": "private static final int RECSIZE = ( ACCTSIZE + 1 ) * 4 ; // acct bytes per record // TODO why +1? (en) // -> kvend = kvstart of next pair // -> 4 = kv-length -> see write(...)", "del_tokens": "private static final int RECSIZE = ( ACCTSIZE + 1 ) * 4 ; // acct bytes per record", "commit_type": "add"}
{"commit_tokens": ["Removed", "an", "unreachable", "block", "."], "add_tokens": "logger . debug ( \"opened connection to {} got #{}\" , url , connection . hashCode ( ) ) ; return connection ;", "del_tokens": "if ( connection == null ) { // may never get here but let's be careful throw new SQLException ( \"Could not establish connection to database URL: \" + url ) ; } else { logger . debug ( \"opened connection to {} got #{}\" , url , connection . hashCode ( ) ) ; return connection ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "<", ">", "when", "its", "needed"], "add_tokens": "public static SmartHandle findStaticQuiet ( Lookup lookup , Class < ? > target , String name , Signature signature ) { public SmartHandle drop ( String beforeName , String newName , Class < ? > type ) { public SmartHandle drop ( int index , String newName , Class < ? > type ) { public SmartHandle dropLast ( String newName , Class < ? > type ) { public SmartHandle convert ( Class < ? > returnType , Class < ? > ... argTypes ) { public SmartHandle cast ( Class < ? > returnType , Class < ? > ... argTypes ) { public SmartHandle returnValue ( Class < ? > type , Object value ) {", "del_tokens": "public static SmartHandle findStaticQuiet ( Lookup lookup , Class target , String name , Signature signature ) { public SmartHandle drop ( String beforeName , String newName , Class type ) { public SmartHandle drop ( int index , String newName , Class type ) { public SmartHandle dropLast ( String newName , Class type ) { public SmartHandle convert ( Class returnType , Class ... argTypes ) { public SmartHandle cast ( Class returnType , Class ... argTypes ) { public SmartHandle returnValue ( Class type , Object value ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "possibility", "to", "set", "an", "initial", "selected", "position", "on", "SpinnerAction"], "add_tokens": "private final static int SPINNER_DEFAULT_POSITION = 0 ; private int selectedPosition = SPINNER_DEFAULT_POSITION ; this ( getTitles ( values ) , values , listener , SPINNER_DEFAULT_POSITION ) ; } public SpinnerAction ( List < T > values , OnItemSelectedListener < T > listener , int initialSelectedPosition ) { this ( getTitles ( values ) , values , listener , initialSelectedPosition ) ; public SpinnerAction ( List < String > titles , List < T > values , OnItemSelectedListener < T > listener , int initialSelectedPosition ) { if ( initialSelectedPosition >= 0 && initialSelectedPosition < values . size ( ) ) { this . selectedPosition = initialSelectedPosition ; } @ Override public void onItemSelected ( AdapterView < ? > parent , View view , int position , long id ) { @ Override public void onNothingSelected ( AdapterView < ? > parent ) {", "del_tokens": "private int selectedPosition = 0 ; this ( getTitles ( values ) , values , listener ) ; public SpinnerAction ( List < String > titles , List < T > values , OnItemSelectedListener < T > listener ) { @ Override public void onItemSelected ( AdapterView < ? > parent , View view , int position , long id ) { @ Override public void onNothingSelected ( AdapterView < ? > parent ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "child", "view", "removal", "when", "new", "render", "cycle", "requires", "less", "child", "views", "than", "the", "previous", "one", ";", "removed", "some", "logs"], "add_tokens": "if ( viewIndex != 0 && vg . getChildCount ( ) > viewIndex ) { vg . removeViews ( viewIndex , vg . getChildCount ( ) - viewIndex ) ;", "del_tokens": "if ( viewIndex != 0 && vg . getChildCount ( ) >= viewIndex ) { vg . removeViews ( viewIndex - 1 , vg . getChildCount ( ) - viewIndex ) ; System . out . println ( \"onSaveInstanceState\" ) ; System . out . println ( \"onRestoreInstanceState\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "incorrect", "rule", "name", "resolution", "of", "rule", "constraints", "inside", "composite", "nodes"], "add_tokens": "( ( Node ) connection . getTo ( ) ) . getUniqueId ( ) + \"-\" + connection . getToType ( ) ;", "del_tokens": "( ( Node ) connection . getTo ( ) ) . getId ( ) + \"-\" + connection . getToType ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "to", "verify", "that", "Value", "Distribution", "handles", "nulls", "correctly", "."], "add_tokens": "if ( isDetailsEnabled ( ) ) { for ( i = 0 ; i < matrixValues . length ; i ++ ) { MatrixValue matrixValue = matrixValues [ i ] ; if ( matrixValue . getValue ( ) != null ) { generateDetailSources ( matrixValue , column , detailOperands [ i ] ) ; } if ( isDetailsEnabled ( ) ) { Query q = getBaseQuery ( column ) . having ( new FilterItem ( SelectItem . getCountAllItem ( ) , OperatorType . EQUALS_TO , 1 ) ) ; matrixValues [ matrixValues . length - 1 ] . setDetailSource ( q ) ; }", "del_tokens": "for ( i = 0 ; i < matrixValues . length ; i ++ ) { MatrixValue matrixValue = matrixValues [ i ] ; if ( matrixValue . getValue ( ) != null ) { generateDetailSources ( matrixValue , column , detailOperands [ i ] ) ; Query q = getBaseQuery ( column ) . having ( new FilterItem ( SelectItem . getCountAllItem ( ) , OperatorType . EQUALS_TO , 1 ) ) ; matrixValues [ matrixValues . length - 1 ] . setDetailSource ( q ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "some", "Entity", "factory", "transfer", "/", "export", "count", "issues"], "add_tokens": "entityIDs . remove ( ce . getID ( ) ) ; return entityIDs . size ( ) ; if ( entityIDs . size ( ) >= entityLimit ) { return \"DefaultEntityFactory [entityLimit=\" + entityLimit + \", entityCount=\" + getEntityCount ( ) + \"]\" ; Entities . walkEntities ( de ) . map ( DefaultEntity . class :: cast ) . forEach ( ve -> { entityIDs . add ( eID ) ; ve . setEngine ( engine ) ; } ) ;", "del_tokens": "private int entityCount ; entityCount = 0 ; return entityCount ; if ( entityCount >= entityLimit ) { entityCount ++ ; return \"DefaultEntityFactory [entityLimit=\" + entityLimit + \", entityCount=\" + entityCount + \"]\" ; Entities . walkEntities ( de ) . map ( DefaultEntity . class :: cast ) . forEach ( ve -> ve . setEngine ( engine ) ) ; entityCount -- ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "duplicate", "comma", "in", "statements", "with", "deferrable", "constraints"], "add_tokens": "fkConstraints . append ( \" DEFERRABLE\" ) ;", "del_tokens": "fkConstraints . append ( \" DEFERRABLE,\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixing", "bug", "with", "prefix", "and", "suffix", "generation"], "add_tokens": "if ( word . length ( ) == 1 ) { return ; } int maxPrefixIndex = Math . min ( word . length ( ) , maxPrefixLength ) ; for ( int i = 1 ; i <= maxPrefixIndex ; i ++ ) { int minSuffixIndex = Math . max ( 0 , len - maxSuffixLength ) ; for ( int i = len - 1 ; i >= minSuffixIndex ; i -- ) {", "del_tokens": "for ( int i = 1 ; i <= maxPrefixLength ; i ++ ) { for ( int i = len - 1 ; i >= len - maxSuffixLength ; i -- ) {", "commit_type": "fix"}
{"commit_tokens": ["Created", "file", "print", "streams", "without", "append", "mode", "as", "it", "is", "no", "longer", "required", "."], "add_tokens": "return new FilePrintStream ( outputFile , false ) ;", "del_tokens": "return new FilePrintStream ( outputFile , true ) ; public File getOutputFile ( ) { return outputFile ; } public boolean isAppend ( ) { return append ; }", "commit_type": "create"}
{"commit_tokens": ["remove", "obsolete", "file", "inc", "version"], "add_tokens": "os . println ( \"JP@GC Tools v. 1.0.1\" ) ; // TODO: keep in sync automatically", "del_tokens": "os . println ( \"JP@GC Tools v. 1.0.0\" ) ; // TODO: keep in sync automatically", "commit_type": "remove"}
{"commit_tokens": ["Use", "repo", "and", "owner", "names", "from", "JSON", "object", "instead", "of", "URL", "regex"], "add_tokens": "String repoName = repository . getString ( \"name\" ) ; // 'foo' portion of the above URL String ownerName = repository . getJSONObject ( \"owner\" ) . getString ( \"name\" ) ; // 'kohsuke' portion of the above URL GitHubRepositoryName changedRepository = new GitHubRepositoryName ( matcher . group ( 1 ) , ownerName , repoName ) ;", "del_tokens": "GitHubRepositoryName changedRepository = new GitHubRepositoryName ( matcher . group ( 1 ) , matcher . group ( 2 ) , matcher . group ( 3 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "excessive", "internal", "listener", "fix", "tests", "comments"], "add_tokens": "if ( throwable != null ) { return throwable ; } switch ( iTestResult . getStatus ( ) ) { case ITestResult . SKIP : return new SkipException ( \"The test was skipped for some reason\" ) ; default : return null ;", "del_tokens": "import java . lang . annotation . Annotation ; public Annotation [ ] getAnnotations ( ) { return iTestResult . getMethod ( ) . getConstructorOrMethod ( ) . getMethod ( ) . getAnnotations ( ) ; } if ( throwable == null ) { if ( iTestResult . getStatus ( ) == ITestResult . SKIP ) { throwable = new SkipException ( \"The test was skipped for some reason\" ) ; } return throwable ;", "commit_type": "remove"}
{"commit_tokens": ["add", "more", "logs", "during", "exceptional", "cases"], "add_tokens": "handlerFuture . whenComplete ( ( ignore , throwable ) -> { if ( throwable != null ) { log . error ( \"Message handling threw exception\" , throwable ) ; } handlerFuture . thenAccept ( acker :: acknowledge ) . exceptionally ( throwable -> { log . error ( \"Acking pubsub threw exception\" , throwable ) ; return null ; } ) ;", "del_tokens": "handlerFuture . whenComplete ( ( ignore , e ) -> { handlerFuture . thenAccept ( acker :: acknowledge ) ;", "commit_type": "add"}
{"commit_tokens": ["improved", "error", "message", "in", "case", "the", "project", "name", "doesn", "t", "match", "the", "artifact", "id"], "add_tokens": "\"The folder \\\"\" + \"\\\" must contain folder named \\\"\" + \"\\\". This folder is expected to hold the xcode project configuration. The xcode project must have the same name as the maven artifactId\" ) ;", "del_tokens": "\"Inside folder \\\"\" + \"\\\" there exists no folder named \\\"\" + \"\\\". This folder is expected to hold the xcode project configuration. The xcode project is expected to have the same name than the maven artifactId.\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Changed", "some", "static", "variables", "to", "use", "a", "normal", "Pattern", "instead", "of", "the"], "add_tokens": "public static final Pattern TRAILING_WHITESPACE_SIMPLE_RE_PATTERN = Pattern . compile ( TRAILING_WHITESPACE_SIMPLE_RE , Pattern . MULTILINE | Pattern . DOTALL ) ; public static final Pattern PRECEEDING_WHITESPACE_SIMPLE_RE_PATTERN = Pattern . compile ( PRECEEDING_WHITESPACE_SIMPLE_RE , Pattern . MULTILINE | Pattern . DOTALL ) ;", "del_tokens": "public static final NamedPattern TRAILING_WHITESPACE_SIMPLE_RE_PATTERN = NamedPattern . compile ( TRAILING_WHITESPACE_SIMPLE_RE , Pattern . MULTILINE | Pattern . DOTALL ) ; public static final NamedPattern PRECEEDING_WHITESPACE_SIMPLE_RE_PATTERN = NamedPattern . compile ( PRECEEDING_WHITESPACE_SIMPLE_RE , Pattern . MULTILINE | Pattern . DOTALL ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "the", "sample", "for", "some", "better", "testing", "."], "add_tokens": "public ComponentType ( ) { type = new ComponentType ( ) ;", "del_tokens": "private final Class < ? extends Component > type ; public ComponentType ( Class < ? extends Component > type ) { this . type = type ; type = new ComponentType ( c ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "dependency", "on", "osgl", "-", "tool", "add", "current", "response", "to", "session", "manager"], "add_tokens": "import org . osgl . util . Crypto ; resp . set ( response ) ; return Crypto . sign ( s , RythmConfigurer . getSecretKey ( ) . getBytes ( ) ) ; private static ThreadLocal < HttpServletResponse > resp = new ThreadLocal < HttpServletResponse > ( ) ; public static HttpServletResponse response ( ) { return resp . get ( ) ; }", "del_tokens": "import org . rythmengine . spring . utils . Crypto ; return Crypto . sign ( s ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "Content", "-", "Type", "for", "400", "and", "500", "errors"], "add_tokens": "response . contentType ( \"text/html; charset=UTF-8\" ) ;", "del_tokens": "response . contentType ( \"text/plain; charset=UTF-8\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "inner", "class", "breaking", "the", "class", "collection", "utility", "method"], "add_tokens": "String className = entry . getName ( ) . replace ( \".class\" , \"\" ) . replace ( '/' , '.' ) ; String className = line . replace ( \".class\" , \"\" ) . replace ( '/' , '.' ) ; try { Class < ? > aClass = getClass ( packagePrefix + className ) ; return aClass ; } catch ( Exception e ) { log . error ( \"Failed to find {}\" , line , e ) ; } return null ;", "del_tokens": "String className = entry . getName ( ) . replace ( \".class\" , \"\" ) . replace ( '$' , '.' ) . replace ( '/' , '.' ) ; String className = line . replace ( \".class\" , \"\" ) . replace ( '$' , '.' ) . replace ( '/' , '.' ) ; Class < ? > aClass = getClass ( packagePrefix + className ) ; return aClass ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "save", "(", "with", "and", "without", "categories", ")", "and", "unsave", "."], "add_tokens": "* @ author Jonny Krysh", "del_tokens": "* @ autho Jonny Krysh", "commit_type": "implement"}
{"commit_tokens": ["Fix", "typo", "in", "method", "name", "generateForOutput", "()", "adjust", "test", "accordingly"], "add_tokens": "public static User generateForOutput ( User user ) {", "del_tokens": "public static User generateForOuput ( User user ) {", "commit_type": "fix"}
{"commit_tokens": ["Using", "Objenesis", "to", "generate", "blank", "instances", "for", "nullification", "."], "add_tokens": "public static class BaseClass {", "del_tokens": "public abstract static class BaseClass {", "commit_type": "use"}
{"commit_tokens": ["Added", "proxy", "support", "that", "is", "local", "to", "the", "Resty", "-", "instance", "instead", "of", "using", "System", ".", "setProperty", "(", "http", ".", "proxyHost", ")", "with", "friends", "who", "are", "JVM", "-", "global", "."], "add_tokens": "import java . net . InetSocketAddress ; import java . net . Proxy ; private Proxy proxy = Proxy . NO_PROXY ; URLConnection con = anUri . toURL ( ) . openConnection ( proxy ) ; public void setProxy ( String proxyhost , int proxyport ) { proxy = new Proxy ( Proxy . Type . HTTP , new InetSocketAddress ( proxyhost , proxyport ) ) ; }", "del_tokens": "URLConnection con = anUri . toURL ( ) . openConnection ( ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "todo", "or", "color", "api", "in", "item", "detail"], "add_tokens": "long color_id ;", "del_tokens": "long color_id ; //TODO /v2/color", "commit_type": "remove"}
{"commit_tokens": ["Added", "the", "ability", "to", "pull", "-", "snapshots", "using", "revisions", "and", "build", "using"], "add_tokens": "spec . setSpecRevision ( specRev ) ;", "del_tokens": "spec . setRevision ( specRev ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "STARTTLS", "and", "add", "unit", "tests", "for", "it", "."], "add_tokens": "public final static String STARTTLS_EXTENSION = \"STARTTLS\" ;", "del_tokens": "public final static String STARTTLS_EXTENSION = \"STARTTLS_EXTENSION\" ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "currency", "to", "the", "list", "of", "types", "that", "are", "serialized", "as", "attributes", "currency", "is", "serialized", "using", "the", "currencyCode", "(", "toString", "()", ")", ".", "This", "is", "just", "a", "little", "optimization", "as", "less", "elements", "are", "created", "then", "and", "an", "attribute", "is", "cheaper", "."], "add_tokens": "import java . util . Currency ; || Number . class . isAssignableFrom ( fieldType ) || fieldType == Currency . class ) { || clazz == Character . class || clazz == Byte . class || clazz == Currency . class ; } else if ( fieldType == Currency . class ) { field . set ( obj , Currency . getInstance ( object . toString ( ) ) ) ;", "del_tokens": "|| Number . class . isAssignableFrom ( fieldType ) ) { || clazz == Character . class || clazz == Byte . class ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "SnackbarCustomiser", "."], "add_tokens": "TextView getMessageView ( ) { Compatibility . getInstance ( ) . setAllCaps ( getActionView ( ) , actionAllCaps ) ; Button getActionView ( ) { return ( Button ) snackbar . getView ( ) . findViewById ( R . id . snackbar_action ) ; }", "del_tokens": "private TextView getMessageView ( ) { Button action = ( Button ) snackbar . getView ( ) . findViewById ( R . id . snackbar_action ) ; Compatibility . getInstance ( ) . setAllCaps ( action , actionAllCaps ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "resources", "out", "of", "semanticcms", "-", "core", "-", "model", "into", "new", "semanticcms", "-", "core", "-", "resources"], "add_tokens": "import com . semanticcms . core . resources . ResourceConnection ; import com . semanticcms . core . resources . ResourceStore ;", "del_tokens": "import com . semanticcms . core . model . ResourceConnection ; import com . semanticcms . core . model . ResourceStore ;", "commit_type": "move"}
{"commit_tokens": ["Updated", "for", "content", "type", "issue", "."], "add_tokens": "writer . append ( \"--\" + boundary ) . append ( LINE_FEED ) ; writer . append ( new String ( attachmentAndType . getAttachment ( ) ) ) . append ( LINE_FEED ) ; writer . append ( \"--\" + boundary + \"--\" ) ;", "del_tokens": "System . out . println ( \"base \" + data ) ; System . out . println ( attachmentData . size ( ) ) ; writer . append ( \"--\" + boundary ) . append ( LINE_FEED ) ; System . out . println ( Arrays . toString ( attachmentAndType . getAttachment ( ) ) ) ; writer . append ( new String ( attachmentAndType . getAttachment ( ) ) ) . append ( LINE_FEED ) ; writer . append ( \"--\" + boundary + \"--\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", ".", "as", "character", "after", "artifact", "code", "if", "base", "URI", "already", "has", "#"], "add_tokens": "if ( suffix . length ( ) > 2 && suffix . charAt ( 0 ) == RdfUtils . getPostAcChar ( baseURI ) && suffix . charAt ( 1 ) == RdfUtils . bnodeChar && ! ( RdfUtils . bnodeChar + \"\" ) . matches ( \"[A-Za-z0-9\\\\-_]\" ) ) {", "del_tokens": "UriTransformConfig c = UriTransformConfig . getDefault ( ) ; if ( suffix . length ( ) > 2 && suffix . charAt ( 0 ) == c . getPostHashChar ( ) && suffix . charAt ( 1 ) == c . getBnodeChar ( ) && ! ( c . getBnodeChar ( ) + \"\" ) . matches ( \"[A-Za-z0-9\\\\-_]\" ) ) {", "commit_type": "use"}
{"commit_tokens": ["updated", "syntax", "for", "key", "reference"], "add_tokens": "* \"value\" : \"SecondaryRatings.&1.Value\" , // rating.[*-match].value from the input goes to output.SecondaryRatings.[*-match].Value * \"max\" : \"SecondaryRatings.&1.Range\" , // rating.[*-match].max from the input goes to output.SecondaryRatings.[*-match].Range * \"&\" : \"SecondaryRatings.&1.Id\" // [*-match] goes to output.SecondaryRatings.[*-match].Id * \"quality\" : { // \"quality\" (rating.*.&) goes to output.SecondaryRatings.quality.Id * - \"&[index]\" within a path is a zero - major reference to the keys in the input document starting with current . thus $$ 0 evaluates to the key if ( fromIdx >= 0 ) { // there was &[index], let's use that index to reference the input path else { // no &[index] if ( item . startsWith ( \"&\" ) ) { String indexStr = item . substring ( 1 ) ; if ( \"\" . equals ( indexStr ) ) { return 0 ; } return Integer . parseInt ( indexStr ) ;", "del_tokens": "* \"value\" : \"SecondaryRatings.$$1.Value\" , // rating.[*-match].value from the input goes to output.SecondaryRatings.[*-match].Value * \"max\" : \"SecondaryRatings.$$1.Range\" , // rating.[*-match].max from the input goes to output.SecondaryRatings.[*-match].Range * \"&\" : \"SecondaryRatings.$$1.Id\" // [*-match] goes to output.SecondaryRatings.[*-match].Id * \"quality\" : { // \"quality\" (rating.*.$$) goes to output.SecondaryRatings.quality.Id * - \"$$[index]\" within a path is a zero - major reference to the keys in the input document starting with current . thus $$ 0 evaluates to the key if ( fromIdx >= 0 ) { // there was $$[index], let's use that index to reference the input path else { // no $$[index] if ( item . startsWith ( \"$$\" ) ) { return Integer . parseInt ( item . substring ( 2 ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "unboxing", "bug", "for", "generated", "constants"], "add_tokens": "if ( type . isBuiltin ( ) && type != ThriftType . STRING ) {", "del_tokens": "if ( type . isBuiltin ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "issues", "reported", "by", "SonarCloud"], "add_tokens": "m_lastSnapshotTxId = tx ; return tx ;", "del_tokens": "return m_lastSnapshotTxId = tx ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "some", "of", "the", "mechanisms", "being", "used", "to", "parse", "the", "entries", ".", "Also"], "add_tokens": "// NOTE: the backspace is taken care of by checking the format string prefix above private final static Pattern FORMAT_PATTERN = Pattern . compile ( \"([^%]*)(%[-+0-9# .\" + PATTERN_MODIFIERS + \"]*[\" + FINAL_PATTERN_CHARS + \"])?(.*)\" ) ; String prefixMatch = matcher . group ( 1 ) ; String percentMatch = matcher . group ( 2 ) ; String suffixMatch = matcher . group ( 3 ) ;", "del_tokens": "/ * * * TODO : Whether or not the format starts with \\ b or \\ 010 ( ^ H ) . Not sure what to do with this . Backing up a * character does _not_ seem to give proper results . * / @ SuppressWarnings ( \"unused\" ) private final boolean backSpace ; private final static Pattern FORMAT_PATTERN = Pattern . compile ( \"(\\\\b|\\010)?([^%]*)(%[-+0-9# .\" + PATTERN_MODIFIERS + \"]*[\" + FINAL_PATTERN_CHARS + \"])?(.*)\" ) ; backSpace = false ; String backSpaceMatch = matcher . group ( 2 ) ; String prefixMatch = matcher . group ( 2 ) ; String percentMatch = matcher . group ( 3 ) ; String suffixMatch = matcher . group ( 4 ) ; if ( backSpaceMatch != null && backSpaceMatch . length ( ) > 0 ) { backSpace = true ; } else { backSpace = false ; }", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "a", "broken", "test", "where", "the", "resource", "file", "was", "not", "found", "(", "expected"], "add_tokens": "import java . util . Locale ; ResourceBundle . getBundle ( \"ExamplePane\" , Locale . ENGLISH ) ) ;", "del_tokens": "ResourceBundle . getBundle ( \"ExamplePane\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "the", "class", "public", "to", "be", "consistent", "with", "BdbPersistentStore", "."], "add_tokens": "public final class BdbCache < K , V > extends BdbMap < K , V > {", "del_tokens": "final class BdbCache < K , V > extends BdbMap < K , V > {", "commit_type": "make"}
{"commit_tokens": ["Remove", "hack", "which", "is", "obsolete", "through", "LIST", "data", "type"], "add_tokens": "vars . put ( keyValue . get ( 0 ) . toString ( ) , ValueExpression . eval ( formatter , keyValue . get ( 1 ) ) ) ; vars . put ( param . toString ( ) , ValueExpression . eval ( formatter , value ) ) ; vars . put ( keyValue . get ( 0 ) . toString ( ) , ValueExpression . eval ( formatter , value ) ) ;", "del_tokens": "vars . put ( keyValue . get ( 0 ) . toString ( ) , ( Expression ) ValueExpression . eval ( formatter , keyValue . get ( 1 ) ) ) ; vars . put ( param . toString ( ) , ( Expression ) ValueExpression . eval ( formatter , value ) ) ; vars . put ( keyValue . get ( 0 ) . toString ( ) , ( Expression ) ValueExpression . eval ( formatter , value ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "getDevice", "-", "type", "method", "to", "class", "DisplayUtil", "."], "add_tokens": "/ * * * Tests the functionality of the method , which allows to retrieve the type of the device , * depending on its screen size . * / public final void testGetDeviceType ( ) { String value = getContext ( ) . getString ( R . string . device_type ) ; DeviceType deviceType = DeviceType . fromValue ( value ) ; assertEquals ( deviceType , DisplayUtil . getDeviceType ( getContext ( ) ) ) ; }", "del_tokens": "return ; return ; return ; return ; return ; return ; return ; return ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "the", "new", "peppol", "-", "smp", "-", "client"], "add_tokens": "if ( true ) if ( false )", "del_tokens": "if ( false ) if ( true )", "commit_type": "update"}
{"commit_tokens": ["Fix", "off", "by", "one", "error", "when", "encoding", "urls", "in", "manifest", "."], "add_tokens": "( ch >= 'a' && ch <= 'z' ) ||", "del_tokens": "( ch >= 'a' && ch < 'z' ) ||", "commit_type": "fix"}
{"commit_tokens": ["fix", "hard", "-", "coded", "entity", "types", "in", "connectEntity", "and", "disconnectEntity"], "add_tokens": "return apiRequest ( HttpMethod . POST , null , null , applicationId , connectingEntityType , connectingEntityId , connectionType , connectedEntityId ) ; connectingEntityType , connectingEntityId , connectionType , connectedEntityId ) ;", "del_tokens": "return apiRequest ( HttpMethod . POST , null , null , applicationId , \"groups\" , connectingEntityId , connectionType , connectedEntityId ) ; \"groups\" , connectingEntityId , connectionType , connectedEntityId ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "the", "correct", "termination", "log", "file"], "add_tokens": ". withValue ( \"/dev/termination-log\" )", "del_tokens": ". withValue ( \"/termination-log\" )", "commit_type": "use"}
{"commit_tokens": ["Added", "more", "documentation", "and", "corrected", "some", "name", "changes", "missed", "in", "the", "first", "pass", "."], "add_tokens": "private final static String MBEAN_SUFFIX = \"IceMBean\" ;", "del_tokens": "private final static String MBEAN_SUFFIX = \"IfcMBean\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "return", "of", "primitive", "types", "by", "removing", "explicit", "cast", "add", "tests", "to", "prevent", "regressions"], "add_tokens": "@ SuppressWarnings ( { \"unchecked\" } ) return ( T ) extractColumnValue ( 1 , typeId ) ;", "del_tokens": "return _returnTypeClass . cast ( extractColumnValue ( 1 , typeId ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "type", "from", "XML", "and", "do", "not", "serialize", "empty", "lists"], "add_tokens": "import com . fasterxml . jackson . annotation . JsonInclude ; @ JsonInclude ( JsonInclude . Include . NON_EMPTY )", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Using", "a", "MetricFilter", "instead", "of", "a", "regex", "for", "percolations"], "add_tokens": "MetricFilter percolationFilter = new MetricFilter ( ) { @ Override public boolean matches ( String name , Metric metric ) { return name . startsWith ( prefix + \".foo\" ) ; } } ; . percolationFilter ( percolationFilter ) . percolationNotifier ( notifier )", "del_tokens": ". percolateMetrics ( prefix + \".foo\" ) . percolateNotifier ( notifier )", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "for", "RubyEnumerable", "::", "none?"], "add_tokens": "return false ;", "del_tokens": "bool = false ;", "commit_type": "add"}
{"commit_tokens": ["created", "a", "new", "package", "for", "android", "support"], "add_tokens": "package org . ektorp . android . http ;", "del_tokens": "package org . ektorp . http ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "reading", "/", "writing", "of", "longs", "(", "and", "thus", "msg", "checksums", ")", "add", "some", "logging", "some", "synchronization"], "add_tokens": "status = cb . getStatus ( ) ; if ( cb . getChecksum ( ) != cb . getExpectedChecksum ( ) ) { logger . error ( \"Incorrect checksum from process \" + sourceProcess ) ; // FIXME deal with invalid checksum } else { }", "del_tokens": "// if (cb.getChecksum() != cb.getExpectedChecksum()) { // // FIXME deal with invalid checksum // } // else { // }", "commit_type": "fix"}
{"commit_tokens": ["Added", "album", "author", "and", "number", "of", "photos", "in", "example", "application", "."], "add_tokens": "return new ModelAndView ( \"album\" , \"command\" , new AlbumForm ( ) ) ; return new ModelAndView ( \"album\" ) . addObject ( \"album\" , album )", "del_tokens": "return new ModelAndView ( \"album\" , \"album\" , new AlbumForm ( ) ) ; return new ModelAndView ( \"album\" , \"album\" , album )", "commit_type": "add"}
{"commit_tokens": ["use", "fluent", "-", "reflection", "to", "simplify", "implementation"], "add_tokens": "import static com . lexicalscope . fluentreflection . ReflectionMatchers . * ; private final ReflectedClass < ? > klass ; this . klass = klass ; final ReflectedMethod optionalityMethod = findCorrespondingOptionalityMethod ( baseName , klass ) ; optionSpecificationBuilder . setOptionalityMethod ( optionalityMethod . methodUnderReflection ( ) ) ; private final ReflectedMethod findCorrespondingOptionalityMethod ( final String name , final ReflectedClass < ? > klass ) { final List < ReflectedMethod > methods = klass . methods ( callableHasName ( addPrefix ( \"is\" , name ) ) . and ( isExistence ( ) ) ) ; if ( ! methods . isEmpty ( ) ) { return methods . get ( 0 ) ; return null ;", "del_tokens": "private final Class < ? > klass ; this . klass = klass . classUnderReflection ( ) ; final Method optionalityMethod = findCorrespondingOptionalityMethod ( baseName , klass ) ; optionSpecificationBuilder . setOptionalityMethod ( optionalityMethod ) ; private final Method findCorrespondingOptionalityMethod ( final String name , final Class < ? > klass ) { try { final Method method = klass . getMethod ( addPrefix ( \"is\" , name ) , new Class [ ] { } ) ; if ( isBoolean ( method . getReturnType ( ) ) ) { return method ; } return null ; } catch ( final NoSuchMethodException e ) { return null ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "method", "name"], "add_tokens": "public void messageTtlValues ( ) {", "del_tokens": "public void messgaeTtlValues ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "comment", "and", "renamed", "DISCUSSION_FLAG", "to", "DISCUSSION_PREFIX", "to", "be", "in", "line", "with", "wikipedia", ".", "api", ":", "WikiConstants"], "add_tokens": "// Is also defined in wikipedia.api:WikiConstants.DISCUSSION_PREFIX // It just doesn't make sense to add a dependency just for the constant private static final String DISCUSSION_PREFIX = \"Discussion:\" ; page_title = DISCUSSION_PREFIX + page_title ;", "del_tokens": "// We should make this configurable. private static final String DISCUSSION_FLAG = \"Discussion:\" ; page_title = DISCUSSION_FLAG + page_title ;", "commit_type": "update"}
{"commit_tokens": ["fix", "table", "short", "name", "override", "in", "cases", "like", "constraint", "renaming", "via", "NamingStrategy"], "add_tokens": "return tableShortName ( generateShortName ( tableName , null , null ) ) ;", "del_tokens": "return generateShortName ( tableName , null , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "logger", "in", "MOJO", "s", "."], "add_tokens": "getLog ( ) . error ( e ) ; getLog ( ) . error ( e ) ; getLog ( ) . error ( \"Analyze: \" + each ) ;", "del_tokens": "e . printStackTrace ( ) ; e . printStackTrace ( ) ; System . err . println ( \"Analyze: \" + each ) ;", "commit_type": "use"}
{"commit_tokens": ["removing", "the", "default", "value", "from", "the", "@Value", "annotation", "seems", "like", "is", "not"], "add_tokens": "@ Value ( \"${hawkbit.server.controller.security.authentication.anonymous.enabled}\" )", "del_tokens": "@ Value ( \"${hawkbit.server.controller.security.authentication.anonymous.enabled:false}\" )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "two", "bugs", "(", "unit", "tests", "don", "t", "help", "if", "you", "make", "changes", "but", "don", "t", "run", "them!", ")"], "add_tokens": "@ Test Assert . assertEquals ( \"Value should equal current because undo is not possible\" , stack . getCurrentValue ( ) , stack . undo ( ) ) ; @ Test Assert . assertEquals ( \"Value should equal current because redo is not possible\" , stack . getCurrentValue ( ) , stack . redo ( ) ) ;", "del_tokens": "@ Test ( expected = IllegalStateException . class ) stack . undo ( ) ; @ Test ( expected = IllegalStateException . class ) stack . redo ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "choose", "between", "interface", "and", "reflection", "as", "per", "https", ":", "//", "github", ".", "com", "/", "chrisjenx", "/", "Calligraphy", "/", "pull", "/", "210", "discussion"], "add_tokens": ". addCustomViewWithSetTypeface ( CustomViewWithTypefaceSupport . class )", "del_tokens": ". setCustomViewTypefaceSupport ( true )", "commit_type": "add"}
{"commit_tokens": ["add", "remove", "element", "collection", "support"], "add_tokens": "import javax . persistence . ElementCollection ; import javax . persistence . JoinTable ; * TODO separate delete into its own class else { // entityManager.refresh(entity); } // TODO combine these two // delete many to many tables // delete element collection Iterable < Settable > elementCollection = Iterables . filter ( entityClass . getElements ( ) , HasAnnotationPredicate . has ( ElementCollection . class ) ) ; for ( Settable settable : elementCollection ) { String table = settable . getAnnotation ( JoinTable . class ) . name ( ) ; deleteTable ( entityManager , table ) ; } // TODO element collection", "del_tokens": "// else // { // }", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "javadoc", "comments", "."], "add_tokens": "* This class provides a globally unique identifier that can be used to reference anything * without requiring a centralized generator . The tag is \"self hashing\" making it very * efficient as a key .", "del_tokens": "* This class provides a globally unique identifier that can be used to reference anything without requiring * a centralized generator . The tag is \"self hashing\" making it very efficient as a key .", "commit_type": "add"}
{"commit_tokens": ["added", "CRs", "to", "expected", "solr", "xpath", "response", "value"], "add_tokens": "assertXpathEvaluatesTo ( \"\\niso639\\n\" , FACET_PATH , xmlResult ) ;", "del_tokens": "assertXpathEvaluatesTo ( \"iso639\" , FACET_PATH , xmlResult ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "replaceText", "(", "String", ")", "."], "add_tokens": "/ * * * Replaces the entire text content with the given text . * / public void replaceText ( String replacement ) { if ( replacement == null ) { throw new NullPointerException ( ) ; } codeArea . replaceText ( 0 , codeArea . getLength ( ) , replacement ) ; } * and the given replacement text is inserted .", "del_tokens": "* and the given replacement text inserted .", "commit_type": "add"}
{"commit_tokens": ["fixed", "offset", "bug", "in", "FileUtils", ".", "listMatchingDirectories"], "add_tokens": "FileUtils . listMatchingDirectories ( completeOperation , word , new File ( System . getProperty ( \"user.dir\" ) ) ) ;", "del_tokens": "completeOperation . addCompletionCandidates ( FileUtils . listMatchingDirectories ( word , new File ( System . getProperty ( \"user.dir\" ) ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "legacy", "id", "verification", "to", "signature", "parsing"], "add_tokens": "import java . util . Arrays ; private static final int LEGACY_ID_LENGTH = 29 ; private static final byte [ ] LEGACY_ID_PREFIX = new byte [ ] { 0x03 , 0x00 } ; private static final int LEGACY_ID_OCTET_STRING_MAX_LENGTH = 25 ; verifyLegacyId ( legacyId ) ; private void verifyLegacyId ( byte [ ] legacyId ) throws InvalidAggregationHashChainException { if ( legacyId . length != LEGACY_ID_LENGTH ) { throw new InvalidAggregationHashChainException ( \"Invalid legacyId length\" ) ; } if ( ! Arrays . equals ( LEGACY_ID_PREFIX , Arrays . copyOfRange ( legacyId , 0 , 2 ) ) ) { throw new InvalidAggregationHashChainException ( \"Invalid legacyId prefix\" ) ; } int length = Util . toShort ( legacyId , 1 ) ; if ( length > LEGACY_ID_OCTET_STRING_MAX_LENGTH ) { throw new InvalidAggregationHashChainException ( \"Invalid legacyId embedded data length\" ) ; } int contentLength = length + 3 ; if ( ! Arrays . equals ( new byte [ LEGACY_ID_LENGTH - contentLength ] , Arrays . copyOfRange ( legacyId , contentLength , legacyId . length ) ) ) { throw new InvalidAggregationHashChainException ( \"Invalid legacyId padding\" ) ; } }", "del_tokens": "if ( len > 25 ) { throw new InvalidSignatureException ( \"Decoding link identity from legacy id failed. Invalid legacy id length\" ) ; } public byte [ ] getLegacyId ( ) { return legacyId ; }", "commit_type": "move"}
{"commit_tokens": ["Add", "precondition", "to", "catch", "when", "logging", "collection", "is", "not", "reset"], "add_tokens": "import static com . google . common . base . Preconditions . checkState ; checkState ( ! originalListener . getClass ( ) . getSimpleName ( ) . equals ( \"WrappedOutputEventListener\" ) , \"Output event listener is already wrapped. A previous build against this daemon did not clean reset the logging collection\" ) ;", "del_tokens": "import org . omg . CORBA . INV_FLAG ;", "commit_type": "add"}
{"commit_tokens": ["fix", "ErrorResult", ".", "of", "(", "status", "message", ")", "issue"], "add_tokens": "touchPayload ( ) . status ( status ) . message ( S . fmt ( message , args ) ) ; return _INSTANCE ;", "del_tokens": "touchPayload ( ) . message ( S . fmt ( message , args ) ) ; return of ( status ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "syntax", "error", "in", "method", "with", "return", "type", "in", "ScalaWriter"], "add_tokens": ". append ( \": \" ) . append ( getGenericName ( true , returnType ) ) . append ( \" = {\" ) . nl ( ) ;", "del_tokens": ". append ( \": \" ) . append ( getGenericName ( true , returnType ) ) . append ( \" {\" ) . nl ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "final", "operator", "to", "fix", "error", "in", "SecSy"], "add_tokens": "throw new UnsupportedOperationException ( \"Not supported.\" ) ;", "del_tokens": "throw new UnsupportedOperationException ( \"Not supported yet.\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "the", "ability", "to", "turn", "proxy", "usage", "on", "and", "off"], "add_tokens": "/ * * * < h3 > If the environmental variables http_proxy , or https_proxy are set they will be used for http / https calls < / h3 > * < p > & lt ; useSystemProxy & gt ; true & lt ; / useSystemProxy & gt ; < / p > * / @ Parameter ( defaultValue = \"true\" ) protected boolean useSystemProxy ; this . checkFileHashes , this . useSystemProxy ) ;", "del_tokens": "this . checkFileHashes ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "to", "static", "factory", "method", "for", "NativePluginLoader", "."], "add_tokens": "return NativePluginLoader . newLoader ( ) ;", "del_tokens": "return new NativePluginLoader ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "some", "possible", "NPEs", "in", "Files", "."], "add_tokens": "if ( file == null ) { throw new FileNotFoundException ( \"No file specified\" ) ; } if ( file == null ) { throw new FileNotFoundException ( \"No file specified.\" ) ; } else if ( ! file . exists ( ) && ! file . getParentFile ( ) . exists ( ) && ! file . getParentFile ( ) . mkdirs ( ) ) {", "del_tokens": "static final String TMP_DIR_PROPERTY = \"java.io.tmpdir\" ; if ( ! file . exists ( ) && ! file . getParentFile ( ) . exists ( ) && ! file . getParentFile ( ) . mkdirs ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "exception", "logging", "on", "fail"], "add_tokens": "try { execute ( ) ; } catch ( Exception e ) { failed ( e . getMessage ( ) , e ) ; } public void failed ( String reason , Exception ex ) { if ( listener != null ) listener . failed ( reason , ex ) ; }", "del_tokens": "execute ( ) ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "minimum", "delta", "stop", "criterion"], "add_tokens": "* Stop criterion that limits the number of steps of a search run .", "del_tokens": "* Stop criterion that limits number of steps of a search run .", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "RevocationRequestHandler", ".", "When", "the", "action"], "add_tokens": "return ResponseUtil . javaScript ( content ) ;", "del_tokens": "return ResponseUtil . ok ( content ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "HTTP", "Status", "Code", "for", "error", "responses", "per", "JSON", "over", "HTTP", "specification", "at", "http", ":", "//", "www", ".", "jsonrpc", ".", "org", "/", "historical", "/", "json", "-", "rpc", "-", "over", "-", "http", ".", "html#errors"], "add_tokens": "//fix to not flush within handle() but outside so http status code can be set output . flush ( ) ; //fix to set HTTP status correctly int result = handle ( input , output ) ; if ( result != 0 ) { if ( result == - 32700 || result == - 32602 || result == - 32603 || ( result <= - 32000 && result >= - 32099 ) ) { response . setStatus ( HttpServletResponse . SC_INTERNAL_SERVER_ERROR ) ; } else if ( result == - 32600 ) { response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ) ; } else if ( result == - 32601 ) { response . setStatus ( HttpServletResponse . SC_NOT_FOUND ) ; } } //fix to not flush within handle() but outside so http status code can be set output . flush ( ) ;", "del_tokens": "handle ( input , output ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "finally", "WebSocketServerEchoRunner", ";", "had", "to", "send", "back", "websocket", "frame", "of", "the", "same", "type", "as", "incoming", "one"], "add_tokens": "import io . netty . handler . codec . http . websocketx . TextWebSocketFrame ; import io . netty . handler . codec . http . websocketx . WebSocketFrame ; . map ( ( WebSocketFrame frame ) -> { . map ( TextWebSocketFrame :: new ) . log ( ) )", "del_tokens": "import io . netty . handler . codec . http . websocketx . BinaryWebSocketFrame ; WebsocketInbound getInbound ( ) { return inbound ; } WebsocketOutbound getOutbound ( ) { return outbound ; } . map ( frame -> { . map ( BinaryWebSocketFrame :: new ) . log ( ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "the", "requires", "option", "on", "Option", "object", "to", "create", "dependencies", "between", "options"], "add_tokens": "MAP_HAS_NO_KEY , REQUIRES_OPTION_MISSING", "del_tokens": "MAP_HAS_NO_KEY", "commit_type": "add"}
{"commit_tokens": ["fixed", "broken", "checksum", "service", "test"], "add_tokens": "@ Test", "del_tokens": "import software . coolstuff . springframework . owncloud . exception . resource . OwncloudLocalResourceChecksumServiceException ; @ Test ( expected = OwncloudLocalResourceChecksumServiceException . class )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "sha", "-", "224", "hash", "algorithm", ".", "Renamed", "metahash", "to", "legacyId", "."], "add_tokens": "private static final int ELEMENT_TYPE_LEGACY_ID = 0x03 ; private byte [ ] legacyId ; case ELEMENT_TYPE_LEGACY_ID : this . legacyId = readOnce ( child ) . getContent ( ) ; if ( siblingHash == null && legacyId == null && metadata == null ) { if ( siblingHash != null && legacyId != null ) { if ( legacyId != null && metadata != null ) { if ( legacyId != null ) { byte [ ] data = legacyId ; if ( legacyId != null ) { return legacyId ;", "del_tokens": "private static final int ELEMENT_TYPE_META_HASH = 0x03 ; private DataHash metaHash ; case ELEMENT_TYPE_META_HASH : this . metaHash = readOnce ( child ) . getDecodedDataHash ( ) ; if ( siblingHash == null && metaHash == null && metadata == null ) { if ( siblingHash != null && metaHash != null ) { if ( metaHash != null && metadata != null ) { if ( metaHash != null ) { byte [ ] data = metaHash . getImprint ( ) ; if ( metaHash != null ) { return metaHash . getImprint ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "comment", "errors", "in", "Enforcer", "class", "."], "add_tokens": "* Enforcer is the default constructor . * Enforcer initializes an enforcer with a model file and a policy file . * Enforcer initializes an enforcer with a database adapter . * Enforcer initializes an enforcer with a model and a database adapter . * Enforcer initializes an enforcer with a model . * Enforcer initializes an enforcer with a model file . * Enforcer initializes an enforcer with a model file , a policy file and an enable log flag .", "del_tokens": "* CoreEnforcer is the default constructor . * CoreEnforcer initializes an enforcer with a model file and a policy file . * CoreEnforcer initializes an enforcer with a database adapter . * CoreEnforcer initializes an enforcer with a model and a database adapter . * CoreEnforcer initializes an enforcer with a model . * CoreEnforcer initializes an enforcer with a model file . * CoreEnforcer initializes an enforcer with a model file , a policy file and an enable log flag .", "commit_type": "fix"}
{"commit_tokens": ["Use", "Util", ".", "valueOfIgnoreCase", "()", "in", "RegexpOnFilenameOption"], "add_tokens": "mode = RegexpOnFilenameOption . valueOfIgnoreCase ( pMode ) ;", "del_tokens": "mode = Enum . valueOf ( RegexpOnFilenameOption . class , pMode . trim ( ) . toUpperCase ( Locale . ENGLISH ) ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "the", "viewStateById", "map", "private"], "add_tokens": "@ NonNull private Map < Integer , SparseArray < Parcelable > > viewStateById = new LinkedHashMap < > ( ) ;", "del_tokens": "// TODO shouldn't this be private? @ NonNull Map < Integer , SparseArray < Parcelable > > viewStateById = new LinkedHashMap < > ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "broken", "tests", "in", "Java", "8"], "add_tokens": "TapProducer producer = new TapProducer ( ) ; assertNotNull ( producer ) ; Representer representer = new Tap13Representer ( ) ; producer = new TapProducer ( representer ) ; assertNotNull ( producer ) ;", "del_tokens": "final Constructor < ? > c = TapProducer . class . getDeclaredConstructors ( ) [ 0 ] ; c . setAccessible ( true ) ; final Object o = c . newInstance ( ( Object [ ] ) null ) ; assertNotNull ( o ) ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "union", "all", "statement", "into", "constant"], "add_tokens": "private static final String UNION_ALL = \"UNION ALL\\n\" ; + UNION_ALL + UNION_ALL + UNION_ALL + UNION_ALL + UNION_ALL + UNION_ALL", "del_tokens": "+ \"UNION ALL\\n\" + \"UNION ALL\\n\" + \"UNION ALL\\n\" + \"UNION ALL\\n\" + \"UNION ALL\\n\" + \"UNION ALL\\n\"", "commit_type": "change"}
{"commit_tokens": ["Fixed", "isValidMapcodeFormat", "to", "trim", "string", "and", "check", "for", "null"], "add_tokens": "public static boolean isValidMapcodeFormat ( @ Nullable final String mapcode ) throws IllegalArgumentException { if ( mapcode == null ) { return false ; } getPrecisionFormat ( mapcode . trim ( ) . toUpperCase ( ) ) ; return PATTERN_TERRITORY . matcher ( mapcode . trim ( ) . toUpperCase ( ) ) . find ( ) ;", "del_tokens": "import static com . mapcode . CheckArgs . checkNonnull ; public static boolean isValidMapcodeFormat ( @ Nonnull final String mapcode ) throws IllegalArgumentException { checkNonnull ( \"mapcode\" , mapcode ) ; getPrecisionFormat ( mapcode . toUpperCase ( ) ) ; return PATTERN_TERRITORY . matcher ( mapcode . toUpperCase ( ) . trim ( ) ) . find ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "criteria", "for", "handling", "non", "-", "abstract", "interface", "methods", "(", "Java", "8", "only", ")", "for", "the", "creation", "of", "super", "type", "proxies", "."], "add_tokens": "Entry methodCall = targetMethod . isAbstract ( ) || targetMethod . getDeclaringType ( ) . isInterface ( ) // covers Java 8 default methods || targetMethod . getDeclaringType ( ) . equals ( instrumentedType )", "del_tokens": "Entry methodCall = targetMethod . isAbstract ( ) || targetMethod . getDeclaringType ( ) . equals ( instrumentedType )", "commit_type": "add"}
{"commit_tokens": ["Moved", "logic", "into", "the", "ReportEngine", "from", "the", "WindupEngine", "."], "add_tokens": "* Main processing method .", "del_tokens": "* Main processing method . This", "commit_type": "move"}
{"commit_tokens": ["Add", "Batch", "support", "to", "java", "client", "imp", ".", "Update", "conformance", "test", "runner", "."], "add_tokens": "import java . util . List ; public List < RpcResponse > request ( List < RpcRequest > reqList ) ;", "del_tokens": "import java . io . IOException ;", "commit_type": "add"}
{"commit_tokens": ["adding", "an", "AppManifest", "for", "fixtures"], "add_tokens": "public class AuditAppManifest implements AppManifest {", "del_tokens": "public final class AuditAppManifest implements AppManifest {", "commit_type": "add"}
{"commit_tokens": ["Add", "class", "member", "constant", "referencing", "the", "System", "PATH", "separator", ".", "Remove", "the", "CURRENT_DIRECTORY", "pathname", "file", "system", "reference", "."], "add_tokens": "// define $PATH separator public static final String PATH_SEPARATOR = System . getProperty ( \"path.separator\" ) ;", "del_tokens": "// Present Working Directory (PWD) public static final String CURRENT_DIRECTORY = System . getProperty ( \"user.dir\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "workspace", "ID", "parameter", "to", "StructurizrClient", ".", "putWorkspace", "()", "to", "make", "it", "consistent", "with", "get", "and", "merge", ".", "I", "also", "added", "the", "ability", "to", "archive", "workspaces", "when", "they", "are", "retrieved", "from", "the", "server", "(", "this", "feature", "is", "on", "by", "default", ")", "."], "add_tokens": "structurizrClient . putWorkspace ( 1234 , null ) ; structurizrClient . putWorkspace ( 0 , workspace ) ;", "del_tokens": "structurizrClient . putWorkspace ( null ) ; structurizrClient . putWorkspace ( workspace ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "loading", "logic", "of", "AutoActive", "."], "add_tokens": "private static final Logger LOGGER = LoggerFactory . getLogger ( RouterChain . class ) ; private final static Map < String , ExtensionClass < Router > > PROVIDER_AUTO_ACTIVES = Collections . synchronizedMap ( new ConcurrentHashMap < String , ExtensionClass < Router > > ( ) ) ; private final static Map < String , ExtensionClass < Router > > CONSUMER_AUTO_ACTIVES = Collections . synchronizedMap ( new ConcurrentHashMap < String , ExtensionClass < Router > > ( ) ) ; private final static ExtensionLoader < Router > EXTENSION_LOADER = buildLoader ( ) ; } if ( autoActive . consumerSide ( ) ) {", "del_tokens": "import java . util . concurrent . ConcurrentMap ; private static final Logger LOGGER = LoggerFactory . getLogger ( RouterChain . class ) ; private final static ConcurrentMap < String , ExtensionClass < Router > > PROVIDER_AUTO_ACTIVES = new ConcurrentHashMap < String , ExtensionClass < Router > > ( ) ; private final static ConcurrentMap < String , ExtensionClass < Router > > CONSUMER_AUTO_ACTIVES = new ConcurrentHashMap < String , ExtensionClass < Router > > ( ) ; private final static ExtensionLoader < Router > EXTENSION_LOADER = buildLoader ( ) ; } else if ( autoActive . consumerSide ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "the", "case", "of", "self", "referencing", "{", "@value", "}"], "add_tokens": "return e . getValue ( ) . getReferencedMemberName ( ) == null ? \"{@value}\" : \"{@value \" + e . getValue ( ) + \"}\" ;", "del_tokens": "return \"{@value \" + e . getValue ( ) + \"}\" ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Collection", "support", "for", "concrete", "collection", "implementation"], "add_tokens": "import java . util . LinkedHashSet ; import java . util . LinkedList ; import static org . hamcrest . CoreMatchers . instanceOf ; @ DefaultValue ( COLORS ) LinkedHashSet < String > colorLinkedHashSet ( ) ; @ DefaultValue ( INTEGERS ) LinkedList < Integer > integerLinkedList ( ) ; @ Test public void itShouldReadConcreteSetImplementation ( ) throws Exception { assertThat ( cfg . colorLinkedHashSet ( ) , instanceOf ( LinkedHashSet . class ) ) ; assertThat ( cfg . colorLinkedHashSet ( ) , contains ( \"pink\" , \"black\" ) ) ; } @ Test public void itShouldReadConcreteListImplementation ( ) throws Exception { assertThat ( cfg . integerLinkedList ( ) , instanceOf ( LinkedList . class ) ) ; assertThat ( cfg . integerLinkedList ( ) , contains ( 1 , 2 , 3 ) ) ; }", "del_tokens": "import java . util . Arrays ; import static org . hamcrest . CoreMatchers . is ; assertThat ( cfg . colors ( ) . size ( ) , is ( 2 ) ) ; assertThat ( cfg . colorSet ( ) . size ( ) , is ( 2 ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Implemented", "video", "filter", "support", "and", "new", "MultimediaObject"], "add_tokens": "* @ param multimediaObject Source MultimediaObject @ see MultimediaObject public void render ( MultimediaObject multimediaObject , int width , int height , int seconds , File outputDir , ffmpeg . addArgument ( multimediaObject . getFile ( ) . getAbsolutePath ( ) ) ;", "del_tokens": "* @ param inputFile Source file public void render ( File inputFile , int width , int height , int seconds , File outputDir , ffmpeg . addArgument ( inputFile . getAbsolutePath ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "note", "to", "Simon", "(", "human", "readable", "information", ")", "added", "some", "javadocs", "added", "test", "for", "unknown", "simon", "replacement", "."], "add_tokens": "( ( AbstractSimon ) simon . getParent ( ) ) . replaceChild ( simon , newSimon ) ;", "del_tokens": "( ( AbstractSimon ) simon . getParent ( ) ) . replace ( simon , newSimon ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "critical", "issue", "making", "successive", "calls", "to", "Hyaline", "non", "idempotent"], "add_tokens": "targetField = CtField . make ( \"private \" + description . getType ( ) . getName ( ) + \" target;\" ,", "del_tokens": "targetField = CtField . make ( \"private \" + description . getTarget ( ) . getClass ( ) . getName ( ) + \" target;\" ,", "commit_type": "fix"}
{"commit_tokens": ["fixed", "standalone", "uima", "context", "language", "passing"], "add_tokens": "language . getName ( ) ) ;", "del_tokens": "language . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "branch", "coverage", "and", "fix", "PersistenceUtilsTest"], "add_tokens": "@ Test public void Test_restoreAllMockEc2InstancesNull ( ) { MockEc2Controller controller = Mockito . spy ( MockEc2Controller . class ) ; // nothing to return controller . restoreAllMockEc2Instances ( null ) ; Collection < AbstractMockEc2Instance > returnedInstances = controller . getAllMockEc2Instances ( ) ; Assert . assertTrue ( returnedInstances . size ( ) == 0 ) ; } DefaultMockEc2Instance ec2Mocked3 = new DefaultMockEc2Instance ( ) ; ec2Mocked3 . setInstanceType ( InstanceType . C3_8XLARGE ) ; allMockEc2Instances . put ( ec2Mocked3 . getInstanceID ( ) , ec2Mocked3 ) ; // this will not be termianted controller . terminateInstances ( instanceIDs ) ; // instances should now be in terminated state excepting the last one added Assert . assertTrue ( controller . getAllMockEc2Instances ( ) . size ( ) == 1 ) ; // as ec2Mocked3 is not terminated and is returned", "del_tokens": "controller . terminateInstances ( instanceIDs ) ; // instances should now be in terminated state Assert . assertTrue ( controller . getAllMockEc2Instances ( ) . size ( ) == 0 ) ;", "commit_type": "improve"}
{"commit_tokens": ["Make", "constant", "containing", "default", "CSS", "rules", "public"], "add_tokens": "public static final String DEFAULT_CSS =", "del_tokens": "private static final String DEFAULT_CSS =", "commit_type": "make"}
{"commit_tokens": ["Added", "handling", "of", "creating", "database", "tables", "in", "DatabaseInitializer", "if", "tables", "already", "exist", "."], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger LOGGER = LoggerFactory . getLogger ( DatabaseInitializer . class ) ; try { initializer . afterPropertiesSet ( ) ; } catch ( Exception e ) { Throwable rootCause = getRootCause ( e ) ; // The database initialization SQL scripts create the necessary // tables. If the exception indicates that the database already // contains tables then ignore the exception and continue on, // otherwise throw the exception. if ( rootCause . getMessage ( ) . contains ( \"already exists\" ) ) { LOGGER . info ( \"Database initialization - tables already exist: {}\" , rootCause . getMessage ( ) ) ; } else { throw e ; } } private Throwable getRootCause ( Throwable throwable ) { if ( throwable . getCause ( ) != null ) { return getRootCause ( throwable . getCause ( ) ) ; } return throwable ; }", "del_tokens": "initializer . afterPropertiesSet ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "compile", "error", "using", "new", "ProtoUtils"], "add_tokens": "import com . google . net . stubby . proto . ProtoUtils ; ProtoUtils . keyForProto ( Messages . SimpleContext . getDefaultInstance ( ) ) ;", "del_tokens": "import com . google . net . stubby . stub . MetadataUtils ; MetadataUtils . keyForProto ( Messages . SimpleContext . getDefaultInstance ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "isEmpty", "()", "instead", "of", "size", "()", "==", "0"], "add_tokens": "return ! peekContextualTransforms . isEmpty ( ) ;", "del_tokens": "return peekContextualTransforms . size ( ) != 0 ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "getOptions", "method", "for", "custom", "-", "delimiter", "property"], "add_tokens": "result . add ( \"\" + getCustomDelimiter ( ) ) ;", "del_tokens": "result . add ( \"\" + getList ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "basic", "color", "manipulation", "functions"], "add_tokens": "return new Color ( tokenizer . consume ( ) . getSource ( ) ) ;", "del_tokens": "return new Value ( tokenizer . consume ( ) . getSource ( ) ) ; //TODO encode color", "commit_type": "add"}
{"commit_tokens": ["Add", "heartbeat", "emitter", "interfaces", "and", "implementations", "."], "add_tokens": "this . eventBus = vertx . eventBus ( ) ; private Handler < Message < Boolean > > handler = new Handler < Message < Boolean > > ( ) { public void handle ( Message < Boolean > message ) {", "del_tokens": "private Handler < Message < Void > > handler = new Handler < Message < Void > > ( ) { public void handle ( Message < Void > event ) {", "commit_type": "add"}
{"commit_tokens": ["added", "(", "delegated", ")", "readonly", "support"], "add_tokens": "import com . sksamuel . jqm4gwt . HasReadOnly ; public class JQMText extends JQMWidget implements HasText < JQMText > , HasFocusHandlers , HasClickHandlers , HasChangeHandlers , HasValue < String > , HasReadOnly , @ Override public boolean isReadOnly ( ) { return input . isReadOnly ( ) ; } @ Override public void setReadOnly ( boolean readOnly ) { input . setReadOnly ( readOnly ) ; }", "del_tokens": "public class JQMText extends JQMWidget implements HasText < JQMText > , HasFocusHandlers , HasClickHandlers , HasChangeHandlers , HasValue < String > ,", "commit_type": "add"}
{"commit_tokens": ["add", "a", "probably", "fine", "naive", "map", "harness", "multiget", "implementation"], "add_tokens": "List < Optional < T >> multiGet ( List < Address > addresses ) throws IOException , InterruptedException ;", "del_tokens": "List < Optional < T >> multiGet ( List < Address > addresses ) throws IOException ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "RatingModule", "to", "have", "a", "public", "interface", "for", "rating", "providers", "so", "that", "it", "is", "pluggable", "*", "without", "*", "requiring", "changes", "to", "the", "apptentive", "classes", "."], "add_tokens": "* Copyright ( c ) 2011 , Apptentive , Inc . All Rights Reserved . * Please refer to the LICENSE file for the terms and conditions * under which redistribution and use of this file is permitted . }", "del_tokens": "* InsufficientRatingArgumentsException . java * * Created by Dr . Cocktor on 2011 - 11 - 29. * Copyright 2011 MiKandi , LLC . All rights reserved . }", "commit_type": "update"}
{"commit_tokens": ["Changed", "FastaParser", "Main", "to", "use", "the", "package", "test", "resources", "instead", "of", "developer", "-", "specific", "directory", ".", "Added", "Pfam", "selex", "seed", "multiple", "sequence", "alignment", "to", "biojava3", ".", "core", ".", "sequence", "test", "resources", "to", "start", "building", "a", "parser", "for", "this", "."], "add_tokens": "String inputFile = \"src/test/resources/PF00104_small.fasta\" ; FileInputStream is = new FileInputStream ( inputFile ) ; File file = new File ( inputFile ) ;", "del_tokens": "FileInputStream is = new FileInputStream ( \"/Users/Scooter/mutualinformation/project/nuclear_receptor/PF00104_small.fasta\" ) ; File file = new File ( \"/Users/Scooter/mutualinformation/project/nuclear_receptor/PF00104_small.fasta\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "spelling", "of", "dependency", "."], "add_tokens": "public AppNameCommand ( DependencyHandler dependencyHandler ) { appName = dependencyHandler . getAppName ( ) != null ? dependencyHandler . getAppName ( ) : \"LibertyProject\" ;", "del_tokens": "public AppNameCommand ( DependencyHandler depdendencyHandler ) { appName = depdendencyHandler . getAppName ( ) != null ? depdendencyHandler . getAppName ( ) : \"LibertyProject\" ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "Assertj", "DiffAssertions", "class", "which", "can", "be", "used", "to", "compare", "the", "generated", "AsciiDoc", "/", "Markdown", "files", "with", "files", "which", "contain", "the", "expected", "conten", "."], "add_tokens": "import io . github . robwin . swagger2markup . assertions . DiffAssertions ; Path actual = outputDirectory . resolve ( \"overview.adoc\" ) ; Path expected = Paths . get ( Swagger2MarkupConverterTest . class . getResource ( \"/results/asciidoc/default/overview.adoc\" ) . toURI ( ) ) ; DiffAssertions . assertThat ( actual ) . isEqualTo ( expected , \"testSwagger2AsciiDocConversion.html\" ) ; String [ ] files = outputDirectory . toFile ( ) . list ( ) ; assertThat ( files ) . hasSize ( 4 ) . containsAll (", "del_tokens": "String [ ] directories = outputDirectory . toFile ( ) . list ( ) ; assertThat ( directories ) . hasSize ( 4 ) . containsAll (", "commit_type": "add"}
{"commit_tokens": ["creating", "new", "release", "without", "resource", "code"], "add_tokens": "try ( InputStream inputStream = this . getClass ( ) . getResourceAsStream ( keyFile ) ) {", "del_tokens": "import com . blackducksoftware . integration . util . ResourceUtil ; try ( InputStream inputStream = ResourceUtil . getResourceAsStream ( this . getClass ( ) , keyFile ) ) {", "commit_type": "create"}
{"commit_tokens": ["fixed", "issue", "with", "target", "/", "classes", "folder", "not", "being", "added", "to", "JSPC", "classpath", "when", "it", "contained", ".", "TLD", "files"], "add_tokens": "protected MavenProject project ;", "del_tokens": "private MavenProject project ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "register", "()", "and", "fixed", "Xnio", "worker", "shutdown"], "add_tokens": "import io . joshworks . snappy . property . AppProperties ; String port = AppProperties . getProperty ( PropertyKeys . SSR_REGISTRY_PORT ) ; String port = AppProperties . getProperty ( PropertyKeys . SSR_SERVICE_PORT ) ; String useHost = AppProperties . getProperty ( PropertyKeys . SSR_USE_HOST ) ; String host = AppProperties . getProperty ( key ) ; AppProperties . getProperties ( ) . put ( key , defaultHost ) ; return AppProperties . getProperty ( key ) ; return Boolean . parseBoolean ( AppProperties . getProperty ( PropertyKeys . SSR_AWS ) ) ; // String fromFile = AppProperties.getProperty(key);", "del_tokens": "import io . joshworks . snappy . property . PropertyLoader ; String port = PropertyLoader . getProperty ( PropertyKeys . SSR_REGISTRY_PORT ) ; String port = PropertyLoader . getProperty ( PropertyKeys . SSR_SERVICE_PORT ) ; String useHost = PropertyLoader . getProperty ( PropertyKeys . SSR_USE_HOST ) ; String host = PropertyLoader . getProperty ( key ) ; PropertyLoader . getProperties ( ) . put ( key , defaultHost ) ; return PropertyLoader . getProperty ( key ) ; return Boolean . parseBoolean ( PropertyLoader . getProperty ( PropertyKeys . SSR_AWS ) ) ; // String fromFile = PropertyLoader.getProperty(key);", "commit_type": "add"}
{"commit_tokens": ["Making", "two", "scroll", "factors", ".", "One", "for", "swiping", "and", "one", "for", "autoscrolling", "."], "add_tokens": "/** scroll factor for auto scroll animation, default is 1.0 **/ private double autoScrollFactor = 1.0 ; /** scroll factor for swipe scroll animation, default is 1.0 **/ private double swipeScrollFactor = 1.0 ; * set the factor by which the duration of sliding animation will change when swiping public void setSwipeScrollDurationFactor ( double scrollFactor ) { swipeScrollFactor = scrollFactor ; / * * * set the factor by which the duration of sliding animation will change when autoscrolling * / public void setAutoScrollDurationFactor ( double scrollFactor ) { autoScrollFactor = scrollFactor ; } scroller . setScrollDurationFactor ( autoScrollFactor ) ; scroller . setScrollDurationFactor ( swipeScrollFactor ) ;", "del_tokens": "* set the factor by which the duration of sliding animation will change public void setScrollDurationFactor ( double scrollFactor ) {", "commit_type": "make"}
{"commit_tokens": ["Allow", "serialization", "of", "Object", "in", "collections", ".", "This", "used", "to", "be", "supported", "before", "restructuring", "the", "Collection", "type", "handling", "."], "add_tokens": "Type childType = ( childGenericType == null || childGenericType == Object . class ) ? child . getClass ( ) : childGenericType ;", "del_tokens": "Type childType = ( childGenericType == null ) ? childType = child . getClass ( ) : childGenericType ;", "commit_type": "allow"}
{"commit_tokens": ["Remove", "trailing", "slash", "from", "URLs"], "add_tokens": "public static final String LIKES_BY_MEDIA_ID = \"/media/%s/likes\" ; public static final String LOCATIONS_RECENT_MEDIA_BY_ID = \"/locations/%s/media/recent\" ;", "del_tokens": "public static final String LIKES_BY_MEDIA_ID = \"/media/%s/likes/\" ; public static final String LOCATIONS_RECENT_MEDIA_BY_ID = \"/locations/%s/media/recent/\" ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "the", "ContentSpec", "query", "method", "that", "was", "causing", "it", "to", "return", "all", "content", "specs", "."], "add_tokens": "import org . jboss . pressgang . ccms . filter . ContentSpecFieldFilter ; CommonFilterConstants . CATEORY_EXTERNAL_LOGIC , CommonFilterConstants . MATCH_LOCALE , new ContentSpecFieldFilter ( ) ) ;", "del_tokens": "import org . jboss . pressgang . ccms . filter . TopicFieldFilter ; CommonFilterConstants . CATEORY_EXTERNAL_LOGIC , CommonFilterConstants . MATCH_LOCALE , new TopicFieldFilter ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "unit", "tests", "for", "Position"], "add_tokens": "public final void testContinuous ( ) { { Position a = new Position ( - 35 , - 2 ) ; Position b = new Position ( - 35 , - 3 ) ; Position c = b . ensureContinuous ( a ) ; Assert . assertEquals ( - 3.0 , c . getLon ( ) , 0.0001 ) ; }", "del_tokens": "public final void testEnsureContinuous ( ) {", "commit_type": "add"}
{"commit_tokens": ["implemented", "special", "case", "of", "abbrev", "when", "it", "s", "==", "0", "return", "just", "the", "tag", "and", "dirty", "marker"], "add_tokens": "List < String > parts ; if ( abbrevZeroHidesCommitsPartOfDescribe ( ) ) { parts = newArrayList ( tag ( ) , dirtyMarker ( ) ) ; } else { parts = newArrayList ( tag ( ) , commitsAwayFromTag ( ) , prefixedCommitId ( ) , dirtyMarker ( ) ) ; } private boolean abbrevZeroHidesCommitsPartOfDescribe ( ) { return abbrev == 0 ; }", "del_tokens": "List < String > parts = newArrayList ( tag ( ) , commitsAwayFromTag ( ) , prefixedCommitId ( ) , dirtyMarker ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Removed", "the", "exceptions", "that", "the", "methods", "throw", "and", "just", "added", "it", "to", "the", "docs", "that", "those", "exceptions", "are", "thrown", "."], "add_tokens": "* @ throws IndexOutOfBoundsException if the row is out of range default ReplyKeyboardMarkup setRow ( int row , String ... cellValues ) { * @ throws IndexOutOfBoundsException if the row is out of range default ReplyKeyboardMarkup setRow ( int row , List < String > cellValues ) { * @ throws IndexOutOfBoundsException if the row or column is out of range default ReplyKeyboardMarkup setCell ( int row , int column , String cellValue ) {", "del_tokens": "default ReplyKeyboardMarkup setRow ( int row , String ... cellValues ) throws ArrayIndexOutOfBoundsException { default ReplyKeyboardMarkup setRow ( int row , List < String > cellValues ) throws ArrayIndexOutOfBoundsException { default ReplyKeyboardMarkup setCell ( int row , int column , String cellValue ) throws ArrayIndexOutOfBoundsException {", "commit_type": "remove"}
{"commit_tokens": ["Allow", "booleans", "and", "number", "to", "be", "deserialized", "into", "a", "String", "field", "/", "object", "."], "add_tokens": "if ( isNumber ( ) ) { return getAsNumber ( ) . toString ( ) ; } else if ( isBoolean ( ) ) { return getAsBooleanWrapper ( ) . toString ( ) ; } else { return ( String ) value ; }", "del_tokens": "return ( String ) value ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "generic", "yes", "no", "cancel", "dialog"], "add_tokens": "GENERIC_YES_NO ( \"/fxml/YesNoDialog.fxml\" ) , / * * * Generic YES , NO and CANCEL dialog * / GENERIC_YES_NO_CANCEL ( \"/fxml/YesNoCancelDialog.fxml\" ) ;", "del_tokens": "GENERIC_YES_NO ( \"/fxml/YesNoDialog.fxml\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "up", "some", "status", "issues", ".", "Wrote", "tests", "for", "cancelling", "of", "flows", "."], "add_tokens": "private static final Layout DEFAULT_LAYOUT = new PatternLayout ( \"%d{dd-MM-yyyy HH:mm:ss z} %c{1} %p - %m\\n\" ) ; node . setStatus ( Status . FAILED ) ; System . out . println ( \"Setting FAILED to \" + node . getId ( ) ) ; logError ( e . getMessage ( ) ) ; logError ( \"Failed trying to cancel job. Maybe it hasn't started running yet or just finished.\" ) ;", "del_tokens": "private static final Layout DEFAULT_LAYOUT = new PatternLayout ( \"%d{dd-MM-yyyy HH:mm:ss z} %c{1} %p - %m\\n\" ) ; node . setStatus ( Status . FAILED ) ; logError ( \"Failed trying to cancel job!\" ) ; e . printStackTrace ( ) ; } // will just interrupt, I guess, until the code is finished. this . notifyAll ( ) ; if ( node . getStatus ( ) != Status . FAILED ) { node . setStatus ( Status . KILLED ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "X", "-", "Load", "-", "Impact_Agent", "request", "header", "showing", "the", "sdk", "version"], "add_tokens": "return getBuildData ( ) . getProperty ( \"version\" , \"0.0.0\" ) ;", "del_tokens": "return getBuildData ( ) . getProperty ( \"version\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "JMX", "exception", "when", "cb4j", "is", "executed", "repeatedly", "using", "quartz", ":", "Do", "not", "register", "cb4j", "MBean", "if", "it", "is", "already", "registered"], "add_tokens": "if ( ! mbs . isRegistered ( name ) ) { BatchMonitorMBean batchMonitorMBean = new BatchMonitor ( batchReporter ) ; mbs . registerMBean ( batchMonitorMBean , name ) ; logger . info ( \"CB4J JMX MBean registered successfully as: \" + name . getCanonicalName ( ) ) ; }", "del_tokens": "BatchMonitorMBean batchMonitorMBean = new BatchMonitor ( batchReporter ) ; mbs . registerMBean ( batchMonitorMBean , name ) ; logger . info ( \"CB4J JMX MBean registered successfully as: \" + name . getCanonicalName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "activity", "base", "class", "which", "will", "automatically", "facilitate", "the", "inflation", "of", "XML", "menu", "files", "to", "either", "the", "native", "action", "bar", "or", "pass", "via", "a", "callback", "to", "the", "handler", "(", "assuming", "they", "implement", "an", "interface", ")", "for", "the", "manual", "adding", "of", "buttons", "."], "add_tokens": "import android . content . Intent ; import com . jakewharton . android . actionbarsherlock . ActionBarSherlock . ActionBarMenuHandler ; import com . jakewharton . android . actionbarsherlock . ActionBarSherlock . ActionBarMenuItem ; public static class Handler extends ActionBarHandler < ActionBar > implements ActionBarMenuHandler { @ Override public void addItem ( ActionBarMenuItem item ) { this . getActionBar ( ) . addAction ( new ActionBar . IntentAction ( this . getActivity ( ) , new Intent ( ) , item . getIconId ( ) ) ) ; }", "del_tokens": "public static class Handler extends ActionBarHandler < ActionBar > {", "commit_type": "add"}
{"commit_tokens": ["Add", "unit", "test", "for", "indexOf"], "add_tokens": "* @ return position of the first occurence . '-1' means that it was not * found . if ( result . size ( ) > 0 ) { return result . get ( 0 ) ; } else { return - 1L ; }", "del_tokens": "* @ return return result . get ( 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "ensure", "the", "UTC", "DateTime", "type", "always", "uses", "UTC", "for", "presentation"], "add_tokens": "import org . jadira . usertype . dateandtime . joda . columnmapper . TimestampColumnUtcDateTimeMapper ; public class PersistentDateTime extends AbstractUserType < DateTime , Timestamp , TimestampColumnUtcDateTimeMapper > {", "del_tokens": "import org . jadira . usertype . dateandtime . joda . columnmapper . TimestampColumnDateTimeMapper ; public class PersistentDateTime extends AbstractUserType < DateTime , Timestamp , TimestampColumnDateTimeMapper > {", "commit_type": "change"}
{"commit_tokens": ["removing", "---", ">", "found", "in", "the", "javadoc"], "add_tokens": "* http : //uaimockserver.com?queryParam=A returns 201 * http : //uaimockserver.com?queryParam=B returns 204", "del_tokens": "* http : //uaimockserver.com?queryParam=A ----> return 201 * http : //uaimockserver.com?queryParam=B ----> return 204", "commit_type": "remove"}
{"commit_tokens": ["Move", "QR", "code", "generation", "logic", "to", "dedicated", "class", "."], "add_tokens": "String otpAuthURL = GoogleAuthenticatorQRGenerator . getOtpAuthURL ( \"Test Org.\" , \"test@prova.org\" , key ) ; System . out . println ( \"Please register (otpauth uri): \" + otpAuthURL ) ; String otpAuthURL = GoogleAuthenticatorQRGenerator . getOtpAuthURL ( \"Test Org.\" , \"test@prova.org\" , key ) ; System . out . println ( \"Please register (otpauth uri): \" + otpAuthURL ) ;", "del_tokens": "String otpAuthURL = GoogleAuthenticatorKey . getOtpAuthURL ( \"Test Org.\" , \"test@prova.org\" , secret ) ; System . out . println ( \"Please register (otpauth uri)\" + otpAuthURL ) ; String otpAuthURL = GoogleAuthenticatorKey . getOtpAuthURL ( \"Test Org.\" , \"test@prova.org\" , secret ) ; System . out . println ( \"Please register \" + otpAuthURL ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "issues", ".", "infn", ".", "it", "/", "jira", "/", "browse", "/", "VOMS", "-", "296", "and", "same", "thing", "in", "voms", "-", "proxy", "-", "init"], "add_tokens": "String proxyFilePath = VOMSProxyPathBuilder . buildProxyPath ( ) ; String envProxyPath = System . getenv ( \"X509_USER_PROXY\" ) ; if ( envProxyPath != null ) proxyFilePath = envProxyPath ; if ( params . getProxyFile ( ) != null ) proxyFilePath = params . getProxyFile ( ) ; proxyInputStream = new FileInputStream ( proxyFilePath ) ; File proxyFile = new File ( proxyFilePath ) ; printProxyStandardInfo ( proxyFile ) ; printProxyStandardInfo ( proxyFile ) ; checkProxyBasicOptions ( params , attributes , proxyFile , proxyChain ) ; checkVOMSOptions ( params , attributes , proxyChain , proxyFile ) ;", "del_tokens": "if ( params . getProxyFile ( ) == null ) params . setProxyFile ( VOMSProxyPathBuilder . buildProxyPath ( ) ) ; proxyInputStream = new FileInputStream ( params . getProxyFile ( ) ) ; File proxyFilePath = new File ( params . getProxyFile ( ) ) ; printProxyStandardInfo ( proxyFilePath ) ; printProxyStandardInfo ( proxyFilePath ) ; checkProxyBasicOptions ( params , attributes , proxyFilePath , proxyChain ) ; checkVOMSOptions ( params , attributes , proxyChain , proxyFilePath ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "to", "return", "boolean", "browseWithAutoIT"], "add_tokens": "return \"//*[contains(@class, '\" + getBaseCls ( ) + \"-body')]\" ; return new ExtJsComponent ( this , getBodyPath ( ) ) ;", "del_tokens": "String selector = \"//*[contains(@class, '\" + getBaseCls ( ) + \"-body')]\" ; return selector ; ExtJsComponent body = new ExtJsComponent ( this , getBodyPath ( ) ) ; return body ;", "commit_type": "make"}
{"commit_tokens": ["Implemented", "@AutoreleasePool", "generation", "for", "ARC", "and", "suppressed", "it", "for"], "add_tokens": "if ( Options . useReferenceCounting ( ) ) { // TODO(user): use @autoreleasepool like ARC when iOS 5 is minimum. return reindent ( \"{\\nNSAutoreleasePool *pool__ = [[NSAutoreleasePool alloc] init];\\n\" + methodBody + \"[pool__ release];\\n}\" ) ; } else if ( Options . useARC ( ) ) { return reindent ( \"{\\n@autoreleasepool {\\n\" + methodBody + \"}\\n}\" ) ; } else { J2ObjC . warning ( m , \"@AutoreleasePool ignored in GC mode\" ) ; } return methodBody ; printIndent ( ) ; println ( \"int exitCode = 0;\" ) ; // TODO(user): use @autoreleasepool like ARC when iOS 5 is minimum. } else if ( Options . useARC ( ) ) { printIndent ( ) ; println ( \"@autoreleasepool {\" ) ; indent ( ) ; printf ( \"exitCode = [JUnitRunner runTests:[%s class]\" , typeName ) ; } else if ( Options . useARC ( ) ) { unindent ( ) ; printIndent ( ) ; println ( \"}\" ) ;", "del_tokens": "return reindent ( \"{\\nNSAutoreleasePool *pool__ = [[NSAutoreleasePool alloc] init];\\n\" + methodBody + \"[pool__ release];\\n}\" ) ; } else { return methodBody ; printf ( \"int exitCode = [JUnitRunner runTests:[%s class]\" , typeName ) ; } else { printIndent ( ) ; println ( \"int exitCode = 0;\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "support", "for", "more", "than", "just", "200", "as", "a", "successful", "return", "code", "."], "add_tokens": "return ! this . method . isExpected ( response . getStatusCode ( ) ) ; }", "del_tokens": "if ( this . method . expectedStatus < 0 ) { return false ; } return response . getStatusCode ( ) != this . method . expectedStatus ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "handling", "for", "null", "results", ".", "It", "will", "now", "respect", "the", "default", "value", "specified", "on", "the", "pojo", "."], "add_tokens": "private int mVariableCount ; // Used to avoid naming conflicts. mVariableCount = 0 ; boolean callToString = false ; codeBlock . addStatement ( \"com.google.gson.JsonElement safeValue$L = mGson.getAdapter(com.google.gson.JsonElement.class).read(in)\" , mVariableCount ) ; callToString = true ; codeBlock . addStatement ( \"$L safeValue$L = get$LSafely(in)\" , gsonMethodType , mVariableCount , gsonMethodType ) ; codeBlock . addStatement ( \"$L safeValue$L = mGson.getAdapter($L.class).read(in)\" , gsonMethodType , mVariableCount , gsonMethodType ) ; codeBlock . beginControlFlow ( \"if (safeValue$L != null)\" , mVariableCount ) ; codeBlock . addStatement ( \"result.$L = safeValue$L$L\" , field . getSimpleName ( ) . toString ( ) , mVariableCount , callToString ? \".toString()\" : \"\" ) ; codeBlock . endControlFlow ( ) ; mVariableCount ++ ;", "del_tokens": "codeBlock . addStatement ( \"result.$L = mGson.getAdapter(com.google.gson.JsonElement.class).read(in).toString()\" , field . getSimpleName ( ) . toString ( ) ) ; codeBlock . addStatement ( \"result.$L = get$LSafely(in)\" , field . getSimpleName ( ) . toString ( ) , gsonMethodType ) ; codeBlock . addStatement ( \"result.$L = mGson.getAdapter($L.class).read(in)\" , field . getSimpleName ( ) . toString ( ) , gsonMethodType ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "serializer", "benchmark", "tests", "into", "integration", "tests", "package", "."], "add_tokens": "package js . dom . w3c . unit ; import junit . framework . TestCase ; public class EListUnitTest extends TestCase { public void test ( ) { } }", "del_tokens": "package js . dom . w3c ; import junit . framework . TestCase ; public class EListUnitTest extends TestCase { public void test ( ) { } }", "commit_type": "move"}
{"commit_tokens": ["Added", "getter", "/", "setter", "/", "chainer", "for", "content", "-", "type", "in", "GeneratePresignedUrlRequest"], "add_tokens": "* @ param credentialsProvider * @ param credentialsProvider if ( generatePresignedUrlRequest . getContentType ( ) != null ) { request . addHeader ( \"content-type\" , generatePresignedUrlRequest . getContentType ( ) ) ; }", "del_tokens": "* @ param awsCredentialsProvider * @ param awsCredentialsProvider", "commit_type": "add"}
{"commit_tokens": ["fixed", "tifn", "project", "it", "now", "runs", "on", "a", "vm"], "add_tokens": "FillMetadata . fillMetadata ( db , false , \"SimpleUserLoginPlugin\" ) ;", "del_tokens": "FillMetadata . fillMetadata ( db , false ) ; System . out . println ( \"BLAAT\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "in", "Select", "if", "using", "groups"], "add_tokens": "if ( groups . isEmpty ( ) ) { setValueForEntryList ( entries , value ) ; } else { groups . forEach ( group -> setValueForEntryList ( group . getEntries ( ) , value ) ) ; } } private void setValueForEntryList ( List < SelectInputEntry > entryList , String value ) { for ( SelectInputEntry entry : entryList ) {", "del_tokens": "for ( SelectInputEntry entry : entries ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "h2", "mvstore", "as", "default", "db"], "add_tokens": "createTable = ! new File ( dataDir + \"/metric.mv.db\" ) . exists ( ) ; \"/metric;mode=mysql;cache_size=0\" ;", "del_tokens": "createTable = ! new File ( dataDir + \"/metric.h2.db\" ) . exists ( ) ; \"/metric;mode=mysql;mv_store=false;cache_size=0\" ; DB . setFetchSize ( 256 ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "Server", "does", "not", "close", "properly"], "add_tokens": "} while ( ! myServerSocket . isClosed ( ) ) ;", "del_tokens": "} while ( true ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improving", "quality", "code", ":", "experiments", "package"], "add_tokens": "for ( int i = 0 ; i < experiment_ . getProblemList ( ) . length ; i ++ ) { String referenceFrontDirectory = experiment_ . getExperimentBaseDirectory ( ) + \"/referenceFronts\" ; String referenceParetoFront = referenceFrontDirectory + \"/\" + experiment_ . getProblemList ( ) [ problemIndex ] + \".pf\" ; for ( String anAlgorithmNameList_ : experiment_ . getAlgorithmNameList ( ) ) { String problemDirectory = experiment_ . getExperimentBaseDirectory ( ) + \"/data/\" + anAlgorithmNameList_ + \"/\" + experiment_ . getProblemList ( ) [ problemIndex ] ; for ( int numRun = 0 ; numRun < experiment_ . getIndependentRuns ( ) ; numRun ++ ) {", "del_tokens": "for ( int i = 0 ; i < experiment_ . problemList_ . length ; i ++ ) { String referenceFrontDirectory = experiment_ . experimentBaseDirectory_ + \"/referenceFronts\" ; String referenceParetoFront = referenceFrontDirectory + \"/\" + experiment_ . problemList_ [ problemIndex ] + \".pf\" ; for ( String anAlgorithmNameList_ : experiment_ . algorithmNameList_ ) { String problemDirectory = experiment_ . experimentBaseDirectory_ + \"/data/\" + anAlgorithmNameList_ + \"/\" + experiment_ . problemList_ [ problemIndex ] ; for ( int numRun = 0 ; numRun < experiment_ . independentRuns_ ; numRun ++ ) {", "commit_type": "improve"}
{"commit_tokens": ["add", "min", "and", "max", "columns"], "add_tokens": "private ProfileTime minTime ; private ProfileTime maxTime ; public ProfileTime getMinTime ( ) { return minTime ; } public void setMinTime ( ProfileTime minTime ) { this . minTime = minTime ; } public ProfileTime getMaxTime ( ) { return maxTime ; } public void setMaxTime ( ProfileTime maxTime ) { this . maxTime = maxTime ; }", "del_tokens": "time = new ProfileTime ( 0L ) ; timePerCall = new ProfileTime ( 0L ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "api", "errors"], "add_tokens": "@ com . mangofactory . swagger . ApiErrors ( NotFoundException . class )", "del_tokens": "@ ApiErrors ( value = { @ ApiError ( code = 400 , reason = \"Invalid ID supplied\" ) , @ ApiError ( code = 404 , reason = \"Pet not found\" ) } )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", ":", "ArrayOutOfBoundsException", "occurs"], "add_tokens": "String [ ] splited = tag . split ( \"\\\\.\" ) ; String [ ] splited = entry . getKey ( ) . split ( \"\\\\.\" ) ;", "del_tokens": "String [ ] splited = tag . split ( \".\" ) ; String [ ] splited = entry . getKey ( ) . split ( \".\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "(", "hopefully", ")", "integer", "overflow"], "add_tokens": "long c ;", "del_tokens": "int c ;", "commit_type": "fix"}
{"commit_tokens": ["add", "both", "orders", "as", "we", "might", "want", "to", "change", "our", "encoding", "in", "the", "future"], "add_tokens": "{ final IntPacker packer = LemireBitPackingBE . getPacker ( i ) ; packer . pack32Values ( values , 0 , packed , 0 ) ; packer . unpack32Values ( packed , 0 , unpacked , 0 ) ; System . out . println ( \"Output BE: \" + TestBitPacking . toString ( unpacked ) ) ; Assert . assertArrayEquals ( \"BE width \" + i , values , unpacked ) ; } { final IntPacker packer = LemireBitPackingLE . getPacker ( i ) ; packer . pack32Values ( values , 0 , packed , 0 ) ; packer . unpack32Values ( packed , 0 , unpacked , 0 ) ; System . out . println ( \"Output LE: \" + TestBitPacking . toString ( unpacked ) ) ; Assert . assertArrayEquals ( \"LE width \" + i , values , unpacked ) ; }", "del_tokens": "final IntPacker packer = LemireBitPackingBE . getPacker ( i ) ; packer . pack32Values ( values , 0 , packed , 0 ) ; packer . unpack32Values ( packed , 0 , unpacked , 0 ) ; System . out . println ( \"Output: \" + TestBitPacking . toString ( unpacked ) ) ; Assert . assertArrayEquals ( \"width \" + i , values , unpacked ) ;", "commit_type": "add"}
{"commit_tokens": ["changing", "default", "dialog", "timeout", "in", "sip", "ra", "6min", "-", ">", "2h"], "add_tokens": "// default of 2h private static long dialogTimeout = 7200000 ;", "del_tokens": "private static long dialogTimeout = 360000 ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "in", "connection", "pooling", "-", "new", "connections", "were", "being", "created", "like", "crazy", "b", "/", "c", "of", "wrong", "pool", "key"], "add_tokens": "CassandraClientPoolByHost pool = pools . get ( key . ip ) ;", "del_tokens": "CassandraClientPoolByHost pool = pools . get ( key ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "textFile", "(", "Resource", ")"], "add_tokens": "import com . davidbracewell . stream . accumulator . Accumulatable ; import com . davidbracewell . stream . accumulator . DoubleAccumulatable ; import com . davidbracewell . stream . accumulator . IntAccumulatable ; import com . davidbracewell . stream . accumulator . JavaAccumulator ; import com . davidbracewell . stream . accumulator . MAccumulator ; return textFile ( Resources . from ( location ) ) ; } @ Override public MStream < String > textFile ( Resource resource ) { if ( resource == null ) { return empty ( ) ; }", "del_tokens": "import com . davidbracewell . stream . accumulator . * ; Resource resource = Resources . from ( location ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "loading", "of", "other", "scripts", "in", "javascript", "executor"], "add_tokens": "import java . io . File ; import net . mindengine . galen . suite . actions . javascript . ScriptExecutor ; File file = GalenUtils . findFile ( javascriptPath ) ; Reader scriptFileReader = new FileReader ( file ) ; engine . put ( \"global\" , new ScriptExecutor ( engine , file . getParent ( ) ) ) ;", "del_tokens": "Reader scriptFileReader = new FileReader ( GalenUtils . findFile ( javascriptPath ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "name", "resolver", "uri", "scheme", "usage", "and", "adjust", "documentation", "accordingly", "."], "add_tokens": "final String serviceName = targetUri . getPath ( ) ; if ( serviceName == null || serviceName . length ( ) <= 1 || ! serviceName . startsWith ( \"/\" ) ) { throw new IllegalArgumentException ( \"Incorrectly formatted target uri; \" + \"expected: '\" + DISCOVERY_SCHEME + \":[//]/<service-name>'; \" + \"but was '\" + targetUri . toString ( ) + \"'\" ) ; } new DiscoveryClientNameResolver ( serviceName . substring ( 1 ) , this . client ,", "del_tokens": "new DiscoveryClientNameResolver ( targetUri . getAuthority ( ) , this . client ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "testing", "for", "OSGi", "LogService", "adapter", "osgi", "-", "over", "-", "slf4j", "."], "add_tokens": "* < code > LogServiceBundleTest < / code > starts up an OSGi environment ( equinox ,", "del_tokens": "* < code > SimpleBundleTest < / code > starts up an OSGi environment ( equinox ,", "commit_type": "add"}
{"commit_tokens": ["added", "VAR", "and", "CUSTOM", "var", "procesing", "into", "expression", "decoder"], "add_tokens": "final JBBPParser parser = JBBPParser . prepare ( \"bit:3 bitf; var somevar; bool bbb; long aaa; ubyte kkk; {{{int [(aaa*1*(2*somevar-4))/(100%9>>bitf)&56|~kkk^78&bbb];}}}\" ) ;", "del_tokens": "final JBBPParser parser = JBBPParser . prepare ( \"bool bbb; long aaa; ubyte kkk; int [(aaa*1*(2-4))/(100%9>>1)&56|~kkk^78&bbb];\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "integration", "tests", "that", "demonstrates", "how", "to", "retrieve", "multi", "-", "valued", "attributes", "."], "add_tokens": "import org . springframework . ldap . support . DirContextAdapter ; / * * * Demonstrates how to retrieve all values of a multi - value attribute . * * @ see LdapTemplateAttributesMapperITest # testSearch_AttributesMapper_MultiValue ( ) * / public void testSearch_ContextMapper_MultiValue ( ) throws Exception { ContextMapper mapper = new ContextMapper ( ) { public Object mapFromContext ( Object ctx ) { DirContextAdapter adapter = ( DirContextAdapter ) ctx ; String [ ] members = adapter . getStringAttributes ( \"uniqueMember\" ) ; return members ; } } ; List result = tested . search ( \"ou=groups\" , \"(objectclass=groupOfUniqueNames)\" , mapper ) ; assertEquals ( 2 , result . size ( ) ) ; assertEquals ( 1 , ( ( String [ ] ) result . get ( 0 ) ) . length ) ; assertEquals ( 5 , ( ( String [ ] ) result . get ( 1 ) ) . length ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "access", "of", "plugin", "resources"], "add_tokens": "final InputStream script = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( \"execute_asciidoctor.rb\" ) ;", "del_tokens": "final InputStream script = AbstractMojo . class . getClassLoader ( ) . getResourceAsStream ( \"execute_asciidoctor.rb\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "date", "format", "."], "add_tokens": "String DATE_FORMAT = \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\" ;", "del_tokens": "String DATE_FORMAT = \"EEE MMM dd yyyy HH:mm:ss 'GMT'Z (z)\" ;", "commit_type": "change"}
{"commit_tokens": ["added", "javadoc", "overview", ".", "html", "and", "custom", "footer", "for", "all", "javadoc", "pages"], "add_tokens": "* The current ( completed or not ) value of the future . < br > * This is a non - blocking method , it will return the current state / value of the Future . < br >", "del_tokens": "* The value of the future . < br >", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "casees", "and", "beacon", "model"], "add_tokens": "@ JsonSubTypes . Type ( PostbackEvent . class ) , @ JsonSubTypes . Type ( BeaconEvent . class )", "del_tokens": "@ JsonSubTypes . Type ( PostbackEvent . class )", "commit_type": "add"}
{"commit_tokens": ["Add", "ST_Extent", "with", "unit", "test"], "add_tokens": "import org . h2gis . h2spatialext . function . spatial . aggregate . ST_Extent ; return new Function [ ] { new ST_Extent ( ) , new ST_Explode ( ) } ;", "del_tokens": "return new Function [ ] { new ST_Explode ( ) } ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "pause", "for", "a", "column", "family", "."], "add_tokens": "import java . util . Arrays ; import org . apache . commons . lang . StringUtils ; public static final String PAUSED = \"PAUSED\" ; @ SuppressWarnings ( { \"unchecked\" , \"rawtypes\" } ) rowsLoop : if ( PAUSED . equals ( StringUtils . upperCase ( className ) ) ) { if ( ENABLED . equals ( enabled ) ) { triggerMap . put ( columnFamily , new ArrayList ( Arrays . asList ( new Trigger [ ] { new PausedTrigger ( ) } ) ) ) ; continue rowsLoop ; } else { continue ; } } else { if ( enabled . equals ( ENABLED ) ) { }", "del_tokens": "if ( enabled . equals ( ENABLED ) ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "TPC", "-", "E", "can", "be", "used", "in", "the", "server", "-", "side"], "add_tokens": "import org . vanilladb . bench . server . procedure . tpce . TpceStoredProcFactory ; if ( logger . isLoggable ( Level . INFO ) ) logger . info ( \"using TPC-E stored procedures\" ) ; factory = new TpceStoredProcFactory ( ) ; break ;", "del_tokens": "throw new UnsupportedOperationException ( \"No TPC-E for now\" ) ;", "commit_type": "make"}
{"commit_tokens": ["updated", "to", "use", "jbel", "to", "generate", "Java", "8", "code"], "add_tokens": "Feature [ ] features = featuresSorted ( Collections . emptySet ( ) ) ; List < String > lines = new ArrayList < > ( Arrays . asList ( s . split ( \"\\n\" ) ) ) ; serialized ( new HashSet < > ( Arrays . asList ( SIGNATURE_KEY , DIGEST_KEY ) ) ) ) ) ; return serialized ( Collections . emptySet ( ) ) ; return serialized ( new HashSet < > ( Arrays . asList ( SIGNATURE_KEY ) ) ) ;", "del_tokens": "Feature [ ] features = featuresSorted ( Set . of ( ) ) ; List < String > lines = new ArrayList < > ( List . of ( s . split ( \"\\n\" ) ) ) ; serialized ( Set . of ( SIGNATURE_KEY , DIGEST_KEY ) ) ) ) ; return serialized ( Set . of ( ) ) ; return serialized ( Set . of ( SIGNATURE_KEY ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "covered", "-", "cell", "issue"], "add_tokens": "this . columnsSpanned . set ( colIndex + c , - 1 ) ;", "del_tokens": "this . columnsSpanned . set ( colIndex , - 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "documentation", "and", "fixed", "typos", "."], "add_tokens": "* @ param pProvider the { @ code ImageReaderSpi } that is invoking this constructor , or { @ code null } . protected ImageReaderBase ( final ImageReaderSpi pProvider ) { super ( pProvider ) ; public void setInput ( final Object pInput , final boolean pSeekForwardOnly , final boolean pIgnoreMetadata ) { * @ throws IndexOutOfBoundsException if not { @ code minIndex < = pIndex < numImages } * Or , if the resulting image would have a width or height less than 1 , * or if the product of { @ code pWidth } and { @ code pHeight } is greater than", "del_tokens": "* @ param pOriginatingProvider the { @ code ImageReaderSpi } that is * invoking this constructor , or { @ code null } . protected ImageReaderBase ( final ImageReaderSpi pOriginatingProvider ) { super ( pOriginatingProvider ) ; public void setInput ( Object pInput , boolean pSeekForwardOnly , boolean pIgnoreMetadata ) { * @ throws IndexOutOfBoundsException if not * < tt > minIndex <= pIndex < numImages < / tt > * Or , if the resulting image would * have a width or height less than 1 , * or if the product of * { @ code pWidth } and { @ code pHeight } is greater than", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "legacy", "url", "for", "met", "api"], "add_tokens": "private static final String API_MET_NO_SERVICE_PREFIX = \"http://legacy.api.met.no/weatherapi/\" ;", "del_tokens": "private static final String API_MET_NO_SERVICE_PREFIX = \"http://api.met.no/weatherapi/\" ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "DelegatingClassResolver"], "add_tokens": "public Class < ? > resolveClass ( final String classname ) Class < ? > candidate = resolver . resolveClass ( classname ) ; catch ( ClassNotFoundException e ) { LOGGER . warn ( \"ClassResolver \" + resolver + \" could not find class: \" + classname ) ; } LOGGER . warn ( \"ClassResolver \" + resolver + \" threw an unexpected exception.\" , e ) ;", "del_tokens": "public Class resolveClass ( final String classname ) Class candidate = resolver . resolveClass ( classname ) ; LOGGER . warn ( \"ClassResolver\" + resolver + \" threw an unexpected exception.\" , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "integration", "-", "test", "for", "running", "a", "load", "-", "test", "."], "add_tokens": "do { //TODO: use waitFor() instead", "del_tokens": "@ Before public void debug ( ) { client . setDebug ( true ) ; } do {", "commit_type": "add"}
{"commit_tokens": ["Made", "Sections", "and", "Markers", "comparable"], "add_tokens": "public class Marker implements Comparable < Marker > { @ Override public int compareTo ( final Marker MARKER ) { if ( Double . compare ( getValue ( ) , MARKER . getValue ( ) ) < 0 ) return - 1 ; if ( Double . compare ( getValue ( ) , MARKER . getValue ( ) ) > 0 ) return 1 ; return 0 ; }", "del_tokens": "public class Marker {", "commit_type": "make"}
{"commit_tokens": ["added", "more", "convenient", "helpers", "for", "ConfigurationBuilder", "and", "FilterBuilder"], "add_tokens": "import java . util . Collection ; import java . util . List ; import java . util . Set ; @ SuppressWarnings ( \"unchecked\" ) filter . includePackage ( ( String ) param ) ; public ConfigurationBuilder forPackages ( String ... packages ) { for ( String pkg : packages ) { addUrls ( ClasspathHelper . forPackage ( pkg ) ) ; } return this ; }", "del_tokens": "import java . util . * ; import static org . reflections . util . FilterBuilder . prefix ; filter . include ( prefix ( ( String ) param ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "swipe", "right", "event"], "add_tokens": "* A panel that allows any of its nested children to be swiped away . SwipeRightEvent . fire ( MaterialSwipeablePanel . this , target ) ;", "del_tokens": "* A panel that alows any of its nested children to be swiped away . SwipeLeftEvent . fire ( MaterialSwipeablePanel . this , target ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "null", "pointer", "exception", "."], "add_tokens": "if ( session . getAuthInfo ( ) . accessToken ( ) == null || ! session . getAuthInfo ( ) . accessToken ( ) . equals ( info . accessToken ( ) ) || System . currentTimeMillis ( ) - info . getRefreshTime ( ) < 15000 ) {", "del_tokens": "if ( ! session . getAuthInfo ( ) . accessToken ( ) . equals ( info . accessToken ( ) ) || System . currentTimeMillis ( ) - info . getRefreshTime ( ) < 15000 ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "color", "to", "text", "above", "thumbs"], "add_tokens": "private int mTextAboveThumbsColor ; mTextAboveThumbsColor = Color . WHITE ; mTextAboveThumbsColor = a . getColor ( R . styleable . RangeSeekBar_textAboveThumbsColor , Color . WHITE ) ; paint . setColor ( mTextAboveThumbsColor ) ;", "del_tokens": "paint . setColor ( Color . WHITE ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "appGroupName", "as", "cluster", "rather", "than", "asgName"], "add_tokens": "//TODO: make ASG configurable return iInfo.getASGName(); //AppGroupName is UPPERCASE from eureka return iInfo . getAppGroupName ( ) ;", "del_tokens": "return iInfo . getASGName ( ) ; //TODO: why did this break things? return iInfo.getAppGroupName();", "commit_type": "use"}
{"commit_tokens": ["added", "output", "for", "stored", "last", "update", "timestamp"], "add_tokens": "log . debug ( \"Checking source: \" + source + \", lastUpdateFromLoader= \" + NumberUtils . makeISO8601TimestampString ( lastUpdate ) + \", storedLastUpdate=\" + NumberUtils . makeISO8601TimestampString ( source . getLastChangeTimestamp ( ) ) ) ;", "del_tokens": "log . debug ( \"Checking source: \" + source + \", lastUpdateonFs= \" + NumberUtils . makeISO8601TimestampString ( lastUpdate ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "column", "name", "annotation", "issue", "."], "add_tokens": "import static com . google . common . base . Strings . isNullOrEmpty ; if ( col != null && ! isNullOrEmpty ( col . name ( ) ) )", "del_tokens": "if ( col != null )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "CloudStack", "to", "load", "balancer", "refactor", "and", "new", "tests"], "add_tokens": "import org . dasein . cloud . test . GlobalTestSuite ; public class TestSuite extends GlobalTestSuite {", "del_tokens": "import junit . framework . Test ; import org . dasein . cloud . test . ComprehensiveTestSuite ; import org . dasein . cloud . test . TestConfigurationException ; public class CloudstackTestSuite { static public Test suite ( ) throws TestConfigurationException { return new ComprehensiveTestSuite ( CSCloud . class ) ; }", "commit_type": "update"}
{"commit_tokens": ["Add", "appendToResponse", "to", "person", "methods"], "add_tokens": "public Person getPersonInfo ( int personId , String ... appendToResponse ) throws MovieDbException { apiUrl . appendToResponse ( appendToResponse ) ; public TmdbResultsList < PersonCredit > getPersonCredits ( int personId , String ... appendToResponse ) throws MovieDbException { apiUrl . appendToResponse ( appendToResponse ) ;", "del_tokens": "public Person getPersonInfo ( int personId ) throws MovieDbException { public TmdbResultsList < PersonCredit > getPersonCredits ( int personId ) throws MovieDbException {", "commit_type": "add"}
{"commit_tokens": ["Added", "querying", "the", "default", "mime", "type"], "add_tokens": "@ Override public final EnhancedMimeType getDefaultMimeType ( final String type ) { Contract . requireArgNotNull ( \"type\" , type ) ; final String contentType = contentTypes . get ( type ) ; if ( contentType == null ) { return null ; } return EnhancedMimeType . create ( contentType ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "hidden", "authorize", "fragment", "on", "rotation"], "add_tokens": "private static final String IS_USER_AUTHORIZED_STATE = \"is_user_authorized_state\" ; private static final String FOLDER_CLIENT_CODE_STATE = \"folder_client_code_state\" ; // True is user is authorized to the current node private boolean mIsUserAuthorized ; // The code of the folder's client returned from API private String mFolderClientCode ; if ( ! mIsUserAuthorized ) { showAuthFragment ( ) ; } else { refreshFragment ( false ) ; } mIsUserAuthorized = savedInstanceState . getBoolean ( IS_USER_AUTHORIZED_STATE ) ; mFolderClientCode = savedInstanceState . getString ( FOLDER_CLIENT_CODE_STATE ) ; outState . putString ( FOLDER_CLIENT_CODE_STATE , mFolderClientCode ) ; // TODO change so only animation are in if/else mIsUserAuthorized = folder . auth ; mFolderClientCode = event . folder . client ; if ( mIsUserAuthorized ) { showAuthFragment ( ) ; private void showAuthFragment ( ) { AuthFragment . newInstance ( mFolderClientCode ) , AUTH_FRAGMENT_TAG )", "del_tokens": "// private String mViewType; // private Node node; refreshFragment ( false ) ; if ( folder . auth ) { showAuthFragment ( folder . client ) ; private void showAuthFragment ( String providerUrl ) { AuthFragment . newInstance ( providerUrl ) , AUTH_FRAGMENT_TAG )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "data", "field", "in", "response", "errors", "."], "add_tokens": "\" \\\"message\\\":\\\"Invalid address length, expected 40 got 64 bytes\\\",\" + \" \\\"data\\\":null\" +", "del_tokens": "\" \\\"message\\\":\\\"Invalid address length, expected 40 got 64 bytes\\\"\" +", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "inline", "XML", "elements"], "add_tokens": "public static final String INLINE_XML_ELEMENTS = \"code,prompt,command,firstterm,ulink,guilabel,filename,replaceable,parameter,literal,classname,sgmltag,guibutton,guimenuitem,guimenu,menuchoice,citetitle,revnumber,application,systemitem\" ;", "del_tokens": "public static final String INLINE_XML_ELEMENTS = \"code,prompt,command,firstterm,ulink,guilabel,filename,replaceable,parameter,literal,classname,sgmltag,guibutton,guimenuitem,guimenu,menuchoice,citetitle,revnumber\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "cloning", "support", "to", "InterceptorContext"], "add_tokens": "final int oldNext = context . getNextInterceptorIndex ( ) ; final List < Interceptor > old = context . getInterceptors ( ) ; context . setInterceptors ( interceptors ) ; context . setInterceptors ( old , oldNext ) ;", "del_tokens": "final ListIterator < Interceptor > old = context . getInterceptorIterator ( ) ; context . setInterceptorIterator ( interceptors . listIterator ( ) ) ; context . setInterceptorIterator ( old ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "custom", "exception", "types", "."], "add_tokens": "throw new RuntimeException ( \"Unable to reset views for \" + target , e ) ; throw new RuntimeException ( \"Unable to inject views for \" + target , e ) ;", "del_tokens": "* @ throws UnableToInjectException if injection could not be performed . * @ throws UnableToResetException if views could not be reset . throw new UnableToResetException ( \"Unable to reset views for \" + target , e ) ; throw new UnableToInjectException ( \"Unable to inject views for \" + target , e ) ; public static class UnableToInjectException extends RuntimeException { UnableToInjectException ( String message , Throwable cause ) { super ( message , cause ) ; } } public static class UnableToResetException extends RuntimeException { UnableToResetException ( String message , Throwable cause ) { super ( message , cause ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["Made", "the", "change", "the", "world", "timeout", "configurable", "and", "the", "default", "10", "seconds", "not", "1", "so", "it", "works", "better", "when", "talking", "from", "the", "office", "to", "the", "server"], "add_tokens": "import org . apache . commons . lang3 . StringUtils ; if ( waitForWorldChange ( discoveryConfig . getWorldChangeTimeout ( ) , TimeUnit . SECONDS ) ) {", "del_tokens": "import org . apache . commons . lang3 . StringUtils ; if ( waitForWorldChange ( 1 , TimeUnit . SECONDS ) ) {", "commit_type": "make"}
{"commit_tokens": ["fix", "a", "bug", "which", "causes", "NotSerializableException"], "add_tokens": "GcsService gcsService = GcsServiceFactory . createGcsService ( ) ;", "del_tokens": "private final GcsService gcsService = GcsServiceFactory . createGcsService ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "few", "more", "things"], "add_tokens": "import com . google . common . base . Function ; private static final CastToSuper CAST_TO_SUPER = new CastToSuper ( ) ; public void setOptionalTypeInfoField ( Optional < ? extends StoredAsJsonTypeInfoBean > optionalTypeInfoField ) { this . optionalTypeInfoField = optionalTypeInfoField . transform ( CAST_TO_SUPER ) ; public void setOptionalTypeInfoGetter ( Optional < ? extends StoredAsJsonTypeInfoBean > optionalTypeInfoGetter ) { this . optionalTypeInfoGetter = optionalTypeInfoGetter . transform ( CAST_TO_SUPER ) ; public void setOptionalTypeInfoSetter ( Optional < ? extends StoredAsJsonTypeInfoBean > optionalTypeInfoSetter ) { this . optionalTypeInfoSetter = optionalTypeInfoSetter . transform ( CAST_TO_SUPER ) ; private static class CastToSuper < U extends T , T > implements Function < U , T > { @ Override public T apply ( U input ) { return input ; } }", "del_tokens": "public void setOptionalTypeInfoField ( Optional < StoredAsJsonTypeInfoBean > optionalTypeInfoField ) { this . optionalTypeInfoField = optionalTypeInfoField ; public void setOptionalTypeInfoGetter ( Optional < StoredAsJsonTypeInfoBean > optionalTypeInfoGetter ) { this . optionalTypeInfoGetter = optionalTypeInfoGetter ; public void setOptionalTypeInfoSetter ( Optional < StoredAsJsonTypeInfoBean > optionalTypeInfoSetter ) { this . optionalTypeInfoSetter = optionalTypeInfoSetter ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "stats", "resources", "with", "version", "/", "built", "-", "on", "/", "built", "-", "by", "/", "commit", "-", "id", "for", "starters", "...", "then", "using", "that", "in", "UI", "footer"], "add_tokens": "import org . commonjava . aprox . core . stats . AProxVersioning ; @ Inject private AProxVersioning versioning ; logger . info ( \"\\n\\n\\n\\n\\n STARTING AProx\\n Version: %s\\n Built-By: %s\\n Commit-ID: %s\\n Built-On: %s\\n\\n\\n\\n\\n\" , versioning . getVersion ( ) , versioning . getBuilder ( ) , versioning . getCommitId ( ) , versioning . getTimestamp ( ) ) ; logger . info ( \"Verfiying that AProx DB + basic data is installed...\" ) ; logger . info ( \"\\n\\n\\n\\n\\n SHUTTING DOWN AProx\\n Version: %s\\n Built-By: %s\\n Commit-ID: %s\\n Built-On: %s\\n\\n\\n\\n\\n\" , versioning . getVersion ( ) , versioning . getBuilder ( ) , versioning . getCommitId ( ) , versioning . getTimestamp ( ) ) ;", "del_tokens": "logger . info ( \"Verfiying that AProx CouchDB + applications + basic data is installed...\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "variable", "typo", "(", "transtition", "-", ">", "transition", ")", "."], "add_tokens": "protected final CompactIntArray d_transitionTo ; return d_transitionTo . get ( trans ) ; state , d_transitionTo . get ( trans ) , d_transitionChars [ trans ] ) ) ; d_stack . push ( new StateStringPair ( d_transitionTo . get ( trans ) , string + d_transitionChars [ trans ] ) ) ; d_transitionTo = transitionTo ;", "del_tokens": "protected final CompactIntArray d_transtitionTo ; return d_transtitionTo . get ( trans ) ; state , d_transtitionTo . get ( trans ) , d_transitionChars [ trans ] ) ) ; d_stack . push ( new StateStringPair ( d_transtitionTo . get ( trans ) , string + d_transitionChars [ trans ] ) ) ; d_transtitionTo = transitionTo ;", "commit_type": "fix"}
{"commit_tokens": ["make", "Operation", "an", "interface", "not", "an", "abstract", "class"], "add_tokens": "private interface Operation { / * * * Performs the operation on the given cassandra instance . * / private class InsertOperation implements Operation {", "del_tokens": "private abstract class Operation { private class InsertOperation extends Operation {", "commit_type": "make"}
{"commit_tokens": ["Make", "ValidationErrorMessage", ".", "Error", "class", "public"], "add_tokens": "public static class Error {", "del_tokens": "static class Error {", "commit_type": "make"}
{"commit_tokens": ["Add", "integration", "test", "for", "CronMapper"], "add_tokens": "for ( int j = 0 ; j < expressions . size ( ) ; j ++ ) { builder . append ( expressions . get ( j ) . asString ( ) ) ; if ( j < expressions . size ( ) - 1 ) { builder . append ( \",\" ) ; }", "del_tokens": "for ( int j = 0 ; j < expressions . size ( ) ; j ++ ) { builder . append ( expressions . get ( j ) . asString ( ) ) . append ( \",\" ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "constructor", "with", "2", "keys", ".", "Keep", "keyProvider", "signature"], "add_tokens": "ECKeyProvider provider = ECDSAAlgorithm . providerForKeys ( publicKey , privateKey ) ; Algorithm algorithm = new ECDSAAlgorithm ( \"ES256\" , \"SHA256withECDSA\" , 128 , provider ) ;", "del_tokens": "Algorithm algorithm = new ECDSAAlgorithm ( \"ES256\" , \"SHA256withECDSA\" , 128 , publicKey , privateKey ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "population", "of", "destinationConfigPath", "on", "ConsistencyChecker"], "add_tokens": "checker . setDestinationConfigPath ( System . getProperty ( \"destinationconfig\" ) ) ;", "del_tokens": "checker . setDestinationConfigPath ( System . getProperty ( \"config\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "optimisation", "for", "checking", "data", "property", "assertions"], "add_tokens": "OWLNamedIndividual subject = asIndividual ( arg0 ) ; OWLDataProperty property = asDataProperty ( arg1 ) ; OWLLiteral object = asLiteral ( arg2 ) ; OWLDataPropertyAssertionAxiom ax = factory . getOWLDataPropertyAssertionAxiom ( property , subject , object ) ; if ( reasoner . getRootOntology ( ) . containsAxiom ( ax ) ) { return true ; } // Not sure about this for ( OWLLiteral l : reasoner . getDataPropertyValues ( subject , property ) ) {", "del_tokens": "for ( OWLLiteral l : reasoner . getDataPropertyValues ( asIndividual ( arg0 ) , asDataProperty ( arg1 ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["allow", "to", "stream", "from", "beginning", "to", "now"], "add_tokens": ". hostnames ( \"localhost\" ) // String key = DcpMutationMessage.key(event).toString(CharsetUtil.UTF_8); // String content = DcpMutationMessage.content(event).toString(CharsetUtil.UTF_8); // System.out.println(\"Found Key \" + key + \" with Content \" + content); client . initializeFromBeginningToNow ( ) . await ( ) ; client . startStreams ( ) . await ( ) ; while ( true ) { Thread . sleep ( 1000 ) ; System . out . println ( \"Found \" + numDocsFound . get ( ) + \" number of docs so far.\" ) ; if ( client . sessionState ( ) . isAtEnd ( ) ) { break ; } } System . err . println ( \"DONE\" ) ;", "del_tokens": ". hostnames ( \"10.142.150.101\" ) String key = DcpMutationMessage . key ( event ) . toString ( CharsetUtil . UTF_8 ) ; String content = DcpMutationMessage . content ( event ) . toString ( CharsetUtil . UTF_8 ) ; System . out . println ( \"Found Key \" + key + \" with Content \" + content ) ; Thread . sleep ( 10000 ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "monster", "egg", "block", "variants", "."], "add_tokens": "import net . minecraft . block . BlockFlower . EnumFlowerType ; FlowerTypes var = FlowerTypes . fromValue ( part ) ; EntityTypes var = EntityTypes . fromValue ( part ) ; if ( var != null ) { Variation bv = new Variation ( ) ; bv . setValue ( var . value ( ) ) ; return bv ; } } catch ( Exception e ) { // Does nothing. } try { MonsterEggTypes var = MonsterEggTypes . fromValue ( part ) ;", "del_tokens": "FlowerTypes var = FlowerTypes . valueOf ( part . toUpperCase ( ) ) ; EntityTypes var = EntityTypes . valueOf ( part . toUpperCase ( ) ) ; int metadata = is . getMetadata ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "isMultiValue", "flag", "on", "PropertyType"], "add_tokens": "import static fr . doan . achilles . entity . metadata . PropertyType . SIMPLE ; if ( propertyMeta . type ( ) != SIMPLE || propertyMeta . type ( ) != JOIN_SIMPLE )", "del_tokens": "if ( propertyMeta . type ( ) . isMultiValue ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "wrong", "class", "description", "of", "GuildMemberUpdateHandler"], "add_tokens": "* Handles the guild member update packet .", "del_tokens": "* Handles the guild member add packet .", "commit_type": "fix"}
{"commit_tokens": ["Add", "C#", "/", "Java", "generator", "behaviour", "for", "private", "attribute"], "add_tokens": "final class TestSimpleTableWithEnum extends Table {", "del_tokens": "public final class TestSimpleTableWithEnum extends Table {", "commit_type": "add"}
{"commit_tokens": ["Moved", "null", "checks", "to", "SerializationUtils"], "add_tokens": "context . scan ( \"be.bagofwords\" ) ;", "del_tokens": "context . scan ( \"be/bow\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "text", "color", "of", "12pm", "in", "12", "hour", "mode"], "add_tokens": "mHourRadialTextsView . setSelection ( is24HourMode ? initialHoursOfDay : hours [ initialHoursOfDay % 12 ] ) ;", "del_tokens": "mHourRadialTextsView . setSelection ( is24HourMode ? initialHoursOfDay : initialHoursOfDay % 12 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "the", "need", "for", "the", "Zanata", "Utilities", "Library", ".", "Minor", "fixes", "to", "the"], "add_tokens": "import org . jboss . pressgang . ccms . utils . common . VersionUtilities ; // Get the Version Details from the Zanata Common API library. final VersionInfo versionInfo = new VersionInfo ( ) ; versionInfo . setVersionNo ( VersionUtilities . getAPIVersion ( LocaleId . class ) ) ; versionInfo . setBuildTimeStamp ( VersionUtilities . getAPIBuildTimestamp ( LocaleId . class ) ) ;", "del_tokens": "import org . zanata . util . VersionUtility ; final VersionInfo versionInfo = VersionUtility . getVersionInfo ( LocaleId . class ) ; if ( versionInfo . getVersionNo ( ) == null || versionInfo . getVersionNo ( ) . isEmpty ( ) || versionInfo . getVersionNo ( ) . equals ( \"unknown\" ) ) versionInfo . setVersionNo ( \"1.6.0\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "usage", "of", "Content", "-", "Range", "header"], "add_tokens": "end = file . length ( ) ; res . setResponseLength ( end - start ) ; res . addHeader ( HttpHeader . CONTENT_RANGE , start + \"-\" + end + \"/\" + file . length ( ) ) ;", "del_tokens": "System . out . println ( \"Range request: \" + range ) ; res . setResponseLength ( ( end == - 1 ? file . length ( ) : end ) - start ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "reading", "mongodb", "example", "and", "deleted", "ESRDD"], "add_tokens": "return new DeepJobConfigES ( Cells . class ) ; return new DeepJobConfigES < > ( entityClass ) ;", "del_tokens": "return new CellDeepJobConfigES ( ) ; return new EntityDeepJobConfigES < > ( entityClass ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "command", "for", "realtime", "-", "android"], "add_tokens": "public static AVIMClientStatus getClientStatus ( int code ) {", "del_tokens": "static AVIMClientStatus getClientStatus ( int code ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "JavaScript", "engines", "that", "don", "t", "support", "E4X"], "add_tokens": "if ( runner . supportsE4X ( ) ) { runner . loadScript ( getClass ( ) . getResource ( \"xmle4x.js\" ) ) ; } else { runner . loadScript ( getClass ( ) . getResource ( \"xml2javabridge.js\" ) ) ; runner . loadScript ( getClass ( ) . getResource ( \"xmldom.js\" ) ) ; }", "del_tokens": "runner . loadScript ( getClass ( ) . getResource ( \"xmle4x.js\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "incorrect", "file", "size", "of", "logo", "."], "add_tokens": "assertEquals ( 3253 , image . length ) ;", "del_tokens": "assertEquals ( 5400 , image . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "flush", "multi", "threading", "issues"], "add_tokens": "@ GuardedBy ( \"freeMap\" ) @ GuardedBy ( \"commitLock\" ) long _freed = 0 ; _freed += s . getSize ( ) ; freedLastCommit = _freed ; long _spaceToFree = 0 ; synchronized ( commitLock ) { _spaceToFree = calculateSpaceToFree ( ) ; } \"spaceToFree=\" + _spaceToFree + \", \" +", "del_tokens": "freedLastCommit = _before - freeMap . getFreeSpace ( ) ; \"calculatedUsedSpace=\" + calculateUsedSpace ( ) + \", \" + \"spaceToFree=\" + calculateSpaceToFree ( ) + \", \" +", "commit_type": "fix"}
{"commit_tokens": ["added", "null", "check", "and", "trigger", "condition", "in", "unit", "test", "for", "issue", "5"], "add_tokens": "if ( cs == null ) continue ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "Timer", "and", "update", "IndexSelector"], "add_tokens": "if ( subTimers . get ( EXE_TIME_KEY ) != null ) sb . append ( String . format ( \"%-40s: %d us\\n\" , EXE_TIME_KEY , subTimers . get ( EXE_TIME_KEY ) . getTotalTime ( ) ) ) ;", "del_tokens": "sb . append ( String . format ( \"%-40s: %d us\\n\" , EXE_TIME_KEY , subTimers . get ( EXE_TIME_KEY ) . getTotalTime ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "version", "on", "metadata", "URL", "for", "code", "generator"], "add_tokens": "url = new URL ( urlString != null ? urlString : \"https://api.softlayer.com/metadata/v3.1\" ) ;", "del_tokens": "url = new URL ( urlString != null ? urlString : \"https://api.softlayer.com/metadata\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "toString", "and", "mask", "get", "with", "0xff"], "add_tokens": "return ( byte ) ( buffer . get ( rawGet ( mark ) ) & 0xff ) ;", "del_tokens": "return buffer . get ( rawGet ( mark ) ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "in", "line", "with", "Hibernate", "metadata", "loader"], "add_tokens": "TABLE , SEQUENCE , IDENTITY , AUTO , NONE", "del_tokens": "ASSIGNED , TABLE , SEQUENCE , IDENTITY , AUTO", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "missing", "space", "."], "add_tokens": "LOGGER . debug ( \"properties file \" + propFileName + \" loaded succesfully\" ) ;", "del_tokens": "LOGGER . debug ( \"properties file \" + propFileName + \"loaded succesfully\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "handlers", "events", "and", "listening", "for", "the", "GUILD_ROLE_CREATE", "and", "GUILD_ROLE_DELETE", "responses", ".", "Events", "are", "named", "GuildRoleCreateEvent", "and", "GuildRoleDeleteEvent", "respectively", "."], "add_tokens": "import net . dv8tion . jda . handle . GuildRoleCreateHandler ; import net . dv8tion . jda . handle . GuildRoleDeleteHandler ; new GuildRoleCreateHandler ( api , responseTotal ) . handle ( content ) ; new GuildRoleDeleteHandler ( api , responseTotal ) . handle ( content ) ;", "del_tokens": "if ( printUnimplemented ) System . out . println ( message ) ; if ( printUnimplemented ) System . out . println ( message ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "isChecked", "()", "for", "Checkboxes"], "add_tokens": "public void assertCheckedOnCheckedCheckBox ( ) { public void assertCheckedOnUncheckedCheckBox ( ) { public void assertCheckedWithValueTrueOnCheckedCheckBox ( ) { public void assertCheckedWithValueFalseOnUncheckedCheckBox ( ) { public void assertCheckedWithValueTrueOnUnCheckedCheckBox ( ) { public void assertCheckedWithValueFalseOnCheckedCheckBox ( ) { @ Test public void checkedOnCheckedCheckBox ( ) { assertEquals ( true , guiTestUIMap . secondCheckBox ( ) . isChecked ( ) ) ; } @ Test public void checkedOnUncheckedCheckBox ( ) { guiTestUIMap . firstCheckBox ( ) . select ( \"false\" ) ; assertEquals ( false , guiTestUIMap . firstCheckBox ( ) . isChecked ( ) ) ; } @ Test public void checkedOnDisabledCheckBox ( ) { guiTestUIMap . disabledCheckBox ( ) . select ( \"false\" ) ; assertEquals ( false , guiTestUIMap . disabledCheckBox ( ) . isChecked ( ) ) ; }", "del_tokens": "public void isCheckedOnCheckedCheckBox ( ) { public void isCheckedOnUncheckedCheckBox ( ) { public void isCheckedWithValueTrueOnCheckedCheckBox ( ) { public void isCheckedWithValueFalseOnUncheckedCheckBox ( ) { public void isCheckedWithValueTrueOnUnCheckedCheckBox ( ) { public void isCheckedWithValueFalseOnCheckedCheckBox ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "getPredictionForInstance", "was", "not", "getting", "called", "."], "add_tokens": "public void addResult ( Example < Instance > example , double [ ] p_y ) { //Ah muy bien, con valueOutputAttribute(int attributeIndex); p_y numOutputAttributes(); se puede comparar directamente con la Prediction. As ir soltando cdigo antiguo que ya no vamos a necesitar ... int L = p_y . length ; if ( p_y . length < 2 ) { System . err . println ( \"p_y.length too short (\" + p_y . length + \"). We've lost track of L at some point, unable to continue\" ) ; System . out . println ( \"p(y) = \" + Arrays . toString ( p_y ) ) ; int y [ ] = new int [ L ] ; for ( int j = 0 ; j < L ; j ++ ) { y [ j ] = ( p_y [ j ] > t ) ? 1 : 0 ; } System . out . println ( \"y = \" + Arrays . toString ( y ) ) ; //int y_pred = (p_y[j] > t) ? 1 : 0;", "del_tokens": "public void addResult ( Example < Instance > example , double [ ] y ) { //Ah muy bien, con valueOutputAttribute(int attributeIndex); y numOutputAttributes(); se puede comparar directamente con la Prediction. As ir soltando cdigo antiguo que ya no vamos a necesitar ... int L = y . length ; if ( y . length < 2 ) { System . err . println ( \"y.length too short (\" + y . length + \"). We've lost track of L at some point, unable to continue\" ) ; System . out . println ( \"y = h(x) = \" + Arrays . toString ( y ) ) ; int y_pred = ( y [ j ] > t ) ? 1 : 0 ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "logic", "from", "WroFilter", "&", "remove", "WroProcessResult", "class"], "add_tokens": "import ro . isdc . wro . http . DelegatingServletOutputStream ; import ro . isdc . wro . manager . impl . ServletContextAwareWroManagerFactory ; final WroManagerFactory factory = new ServletContextAwareWroManagerFactory ( ) ; final HttpServletRequest request = Context . get ( ) . getRequest ( ) ; final HttpServletResponse response = Context . get ( ) . getResponse ( ) ; Mockito . when ( response . getOutputStream ( ) ) . thenReturn ( new DelegatingServletOutputStream ( System . out ) ) ; manager . process ( request , response ) ;", "del_tokens": "import ro . isdc . wro . manager . impl . StandAloneWroManagerFactory ; final WroManagerFactory factory = new StandAloneWroManagerFactory ( ) ; final HttpServletRequest request = Mockito . mock ( HttpServletRequest . class ) ; final WroProcessResult result = manager . process ( request ) ; // final Writer writer = new StringWriter(); // IOUtils.copy(result.getInputStream(), writer); // System.out.println(\"Processing result: \" + writer.toString());", "commit_type": "remove"}
{"commit_tokens": ["add", "metaData", "functionality", "for", "DirectStore"], "add_tokens": "import java . util . Map ; import org . codehaus . jackson . annotate . JsonPropertyOrder ; import org . codehaus . jackson . map . annotate . JsonSerialize ; import org . codehaus . jackson . map . annotate . JsonSerialize . Inclusion ; @ JsonSerialize ( include = Inclusion . NON_NULL ) @ JsonPropertyOrder ( value = { \"metaData\" , \"success\" , \"total\" , \"records\" } ) private MetaData metaData ; public Map < String , Object > getMetaData ( ) { return metaData . getMetaData ( ) ; } public void setMetaData ( MetaData metaData ) { this . metaData = metaData ; }", "del_tokens": "import org . codehaus . jackson . annotate . JsonWriteNullProperties ; @ JsonWriteNullProperties ( false )", "commit_type": "add"}
{"commit_tokens": ["Added", "and", "corrected", "tests", "for", "the", "configuration", "tool", "changes"], "add_tokens": "skinNode . addChild ( valueNode ) ;", "del_tokens": "final Xpp3Dom pageNode ; // Current page node // Creates page node pageNode = new Xpp3Dom ( currentFile ) ; pageNode . addChild ( valueNode ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "service", "client", "generic", "arg", "restraints"], "add_tokens": "public abstract class ServiceClient < TClient > implements Closeable {", "del_tokens": "public abstract class ServiceClient < TClient extends ServiceClient > implements Closeable {", "commit_type": "fix"}
{"commit_tokens": ["Made", "no", "arg", "constructor", "protected", "to", "enable", "unit", "test", "coverage", "."], "add_tokens": "protected PrincipalAcegiUserToken ( ) {", "del_tokens": "private PrincipalAcegiUserToken ( ) {", "commit_type": "make"}
{"commit_tokens": ["fix", "a", "bug", "related", "to", "feedback", "and", "devices"], "add_tokens": "public static Map < byte [ ] , Integer > parseFeedbackStreamRaw ( InputStream in ) { Map < byte [ ] , Integer > result = new HashMap < byte [ ] , Integer > ( ) ; result . put ( deviceToken , time ) ; Map < byte [ ] , Integer > raw = parseFeedbackStreamRaw ( in ) ; for ( Map . Entry < byte [ ] , Integer > entry : raw . entrySet ( ) ) { byte [ ] dtArray = entry . getKey ( ) ; int time = entry . getValue ( ) ; // in seconds", "del_tokens": "public static Map < Integer , byte [ ] > parseFeedbackStreamRaw ( InputStream in ) { Map < Integer , byte [ ] > result = new HashMap < Integer , byte [ ] > ( ) ; result . put ( time , deviceToken ) ; Map < Integer , byte [ ] > raw = parseFeedbackStreamRaw ( in ) ; for ( Map . Entry < Integer , byte [ ] > entry : raw . entrySet ( ) ) { int time = entry . getKey ( ) ; // in seconds byte [ ] dtArray = entry . getValue ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "transport", "from", "KUBE_PING", ":", "already", "defined", "in", "superclass"], "add_tokens": "private static boolean isPropertyDefined ( String property_name ) {", "del_tokens": "import org . jgroups . protocols . TP ; TP transport = getTransport ( ) ; private boolean isPropertyDefined ( String property_name ) {", "commit_type": "remove"}
{"commit_tokens": ["Make", "other", "processors", "cancel", "-", "aware"], "add_tokens": "LOGGER . debug ( \"Starting to execute processor graph: \\n\" + graph ) ;", "del_tokens": "LOGGER . debug ( \"Starting to execute processor graph 1: \\n\" + graph ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "signature", "of", "the", "JSON", "jobs", "/", "builds"], "add_tokens": "client . goTo ( \"job/\" + projectName + \"/octane/run\" , \"\" ) ;", "del_tokens": "client . goTo ( \"job/\" + projectName + \"/octane/run\" , \"\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "TreeBasedTable", "to", "return", "columns", "in", "globally", "sorted", "order", "."], "add_tokens": "return createColumnKeyIterator ( ) ; / * * * Creates an iterator that returns each column value with duplicates * omitted . * / Iterator < C > createColumnKeyIterator ( ) { return new ColumnKeyIterator ( ) ; }", "del_tokens": "return new ColumnKeyIterator ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "everything", "up", "to", "the", "top", "level", "directory", "now", "that", "we", "don", "t", "have", "a", "separate", "demo", "project"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import java . util . Map ; import java . util . TreeMap ;", "del_tokens": "import java . util . ArrayList ; import java . util . List ; import java . util . Map ; import java . util . TreeMap ;", "commit_type": "move"}
{"commit_tokens": ["Implemented", "DatabaseField", "annotation", "parameter", "that", "allows", "to", "specify", "more", "java", "side", "field", "than", "in", "postgres", "type"], "add_tokens": "if ( databaseType == null || ! databaseType . partial ( ) ) { if ( databaseType == null || ! databaseType . partial ( ) ) {", "del_tokens": "if ( ! databaseFieldDescriptor . isOptional ( ) ) { if ( ! databaseFieldDescriptor . isOptional ( ) ) {", "commit_type": "implement"}
{"commit_tokens": ["Move", "Localytics", "into", "its", "own", "module"], "add_tokens": "package com . segment . android ; private static final String APP_KEY = \"appKey\" ; if ( isNullOrEmpty ( settings . getString ( APP_KEY ) ) ) { throw new InvalidSettingsException ( APP_KEY , \"Localytics requires the appKey setting.\" ) ; String appKey = settings . getString ( APP_KEY ) ;", "del_tokens": "package com . segment . android . integrations ; private static class SettingKey { private static final String APP_KEY = \"appKey\" ; } if ( isNullOrEmpty ( settings . getString ( SettingKey . APP_KEY ) ) ) { throw new InvalidSettingsException ( SettingKey . APP_KEY , \"Localytics requires the appKey setting.\" ) ; String appKey = settings . getString ( SettingKey . APP_KEY ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "JAWR", "-", "318", "catching", "container", "specific", "browser", "abort", "excpetions"], "add_tokens": "import net . jawr . web . servlet . util . ClientAbortExceptionReoslver ; LOGGER . error ( \"Unable to write resource \" + request . getRequestURI ( ) , ex ) ; LOGGER . error ( \"No binary extension match the extension '\" + extension + \"' for the request URI : \" + requestUri ) ; } catch ( IOException e ) { if ( ClientAbortExceptionReoslver . isClientAbortException ( e ) ) { LOGGER . debug ( \"Browser cut off response\" , e ) ; } else { throw e ; } String [ ] resourceInfo = PathNormalizer . extractBinaryResourceInfo ( realFilePath ) ;", "del_tokens": "LOGGER . error ( \"Unable to write resource \" + request . getRequestURI ( ) , ex ) ; LOGGER . error ( \"No binary extension match the extension '\" + extension + \"' for the request URI : \" + requestUri ) ; String [ ] resourceInfo = PathNormalizer . extractBinaryResourceInfo ( realFilePath ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "instance", "-", "no", "field", "."], "add_tokens": "static final String HOST_NAME , INSTANCE_NO ; // If not present, will be null, and not make it through buzzsaw. INSTANCE_NO = System . getenv ( \"INSTANCE_NO\" ) ; LOG . info ( \"Determined instance-no '{}'\" , INSTANCE_NO ) ;", "del_tokens": "static final String HOST_NAME ;", "commit_type": "add"}
{"commit_tokens": ["Added", "logic", "for", "prompting", "command", "typed", "by", "user"], "add_tokens": "String str = readLine ( r ) ; private String readLine ( BufferedReader r ) throws IOException { StringBuffer str = new StringBuffer ( ) ; int ch = r . read ( ) ; this . out . write ( ch ) ; this . out . flush ( ) ; while ( ( char ) ch != '\\n' && ( ( char ) ch != '\\r' ) ) { str . append ( ( char ) ch ) ; ch = r . read ( ) ; this . out . write ( ch ) ; this . out . flush ( ) ; } for ( int i = 0 ; i < ENDLINE . length ( ) ; i ++ ) { this . out . write ( ENDLINE . charAt ( i ) ) ; } this . out . flush ( ) ; return str . toString ( ) ; }", "del_tokens": "String str = r . readLine ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "request", "codes"], "add_tokens": "public int requestCode ; public void onBrowserSwitchResult ( int requestCode , BrowserSwitchResult result , @ Nullable Uri returnUri ) { this . requestCode = requestCode ;", "del_tokens": "public void onBrowserSwitchResult ( BrowserSwitchResult result , @ Nullable Uri returnUri ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "OkBuffer", "in", "SpdyStream", "."], "add_tokens": "private final BufferedSource source ; this ( new BufferedSource ( source , new OkBuffer ( ) ) , inflater ) ; / * * * This package - private constructor shares a buffer with its trusted caller . * In general we can 't share a BufferedSource because the inflater holds input * bytes until they are inflated . * / InflaterSource ( BufferedSource source , Inflater inflater ) { // If there are compressed bytes in the source, assign them to the inflater. if ( source . exhausted ( deadline ) ) return true ; Segment head = source . buffer . head ; source . buffer . skip ( toRelease ) ;", "del_tokens": "private final Source source ; /** This holds bytes read from the source, but not yet inflated. */ private final OkBuffer buffer ; this ( source , inflater , new OkBuffer ( ) ) ; InflaterSource ( Source source , Inflater inflater , OkBuffer buffer ) { this . buffer = buffer ; // Refill the buffer with compressed data from the source. if ( buffer . byteCount == 0 ) { if ( source . read ( buffer , Segment . SIZE , deadline ) == - 1 ) return true ; } Segment head = buffer . head ; buffer . skip ( toRelease ) ; buffer . clear ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "shared", "object", "name", "mapping", "in", "SoLoader"], "add_tokens": "String mergedLibName = MergedSoMapping . mapLibName ( shortName ) ; String nameToLoad = mergedLibName != null ? mergedLibName : shortName ; loadLibraryBySoName ( System . mapLibraryName ( nameToLoad ) , loadFlags ) ; if ( mergedLibName != null ) { MergedSoMapping . invokeJniOnload ( shortName ) ; }", "del_tokens": "loadLibraryBySoName ( System . mapLibraryName ( shortName ) , loadFlags ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "duplicate", "License", "Header", "explicit", "NamingEnumeration", "."], "add_tokens": "Copyright ( C ) 2012 innoQ Deutschland GmbH NamingEnumeration < SearchResult > results = ctx . search ( \"\" , query , controls ) ; NamingEnumeration < ? > members = attributes . get ( groupMemberAttribut ) . getAll ( ) ; NamingEnumeration < ? > objectClasses = attributes . get ( LdapKeys . OBJECT_CLASS ) . getAll ( ) ;", "del_tokens": "Copyright ( C ) 2014 innoQ Deutschland GmbH Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; you may not use this file except in compliance with the License . You may obtain a copy of the License at http : //www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing , software distributed under the License is distributed on an \"AS IS\" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the License for the specific language governing permissions and limitations under the License . * //* Copyright ( C ) 2014 innoQ Deutschland GmbH NamingEnumeration results = ctx . search ( \"\" , query , controls ) ; NamingEnumeration members = attributes . get ( groupMemberAttribut ) . getAll ( ) ; NamingEnumeration objectClasses = attributes . get ( LdapKeys . OBJECT_CLASS ) . getAll ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "no", "longer", "valid", "JavaDoc", "syntax"], "add_tokens": "*", "del_tokens": "* < p > * < / p > * < code > * < table > * < tr valign = baseline > * < td align = right > PackageDeclaration < / td > * < td align = center > :: = < / td > * < td align = left > * ( { @ link AnnotationExpr } ) * \"package\" { @ link NameExpr } ) \";\" * < / td > * < / tr > * < / table > * < / code >", "commit_type": "remove"}
{"commit_tokens": ["Add", "custom", "thank", "you", "logic"], "add_tokens": "import com . wootric . androidsdk . objects . CustomThankYou ; public void setCustomThankYou ( CustomThankYou customThankYou ) { settings . setCustomThankYou ( customThankYou ) ;", "del_tokens": "import com . wootric . androidsdk . objects . CustomThankYouMessage ; public void setCustomThankYouMessage ( CustomThankYouMessage customThankYouMessage ) { settings . setCustomThankYouMessage ( customThankYouMessage ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "TODO", "for", "support", "BOTH", "directions"], "add_tokens": "mCurrentTargetOffsetTop = mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; if ( ! isEnabled ( ) || mReturningToStart || canChildScrollDown ( ) || mRefreshing ) { yDiff = mInitialMotionY - y ; if ( ! isEnabled ( ) || mReturningToStart || canChildScrollDown ( ) || mRefreshing ) { overscrollTop = ( mInitialMotionY - y ) * DRAG_RATE ; overscrollTop = ( mInitialMotionY - y ) * DRAG_RATE ; endTarget = getMeasuredHeight ( ) - ( int ) ( mSpinnerFinalOffset ) ; mCurrentTargetOffsetTop = mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ;", "del_tokens": "mCurrentTargetOffsetTop = mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; // TODO if ( ! isEnabled ( ) || mReturningToStart || canChildScrollDown ( ) || mRefreshing ) { // TODO yDiff = mInitialMotionY - y ; // TODO if ( ! isEnabled ( ) || mReturningToStart || canChildScrollDown ( ) || mRefreshing ) { // TODO overscrollTop = ( mInitialMotionY - y ) * DRAG_RATE ; // TODO overscrollTop = ( mInitialMotionY - y ) * DRAG_RATE ; //TODO endTarget = getMeasuredHeight ( ) - ( int ) ( mSpinnerFinalOffset ) ; // TODO mCurrentTargetOffsetTop = mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; // TODO", "commit_type": "add"}
{"commit_tokens": ["Implemented", "pageSize", "and", "page", "parameter", "updates", "to", "get", "report", "/", "reportasexcel", "/", "reportascsv", ".", "Also", "added", "ReportInclusion", "ENUM", ".", "Updated", "test", "."], "add_tokens": "Report report = reportResources . getReport ( 4583173393803140L , EnumSet . of ( ReportInclusion . ATTACHMENTS , ReportInclusion . DISCUSSIONS ) , 1 , 1 ) ; reportResources . getReportAsExcel ( 4583173393803140L , EnumSet . of ( ReportInclusion . ATTACHMENTS , ReportInclusion . DISCUSSIONS ) , 1 , 1 , output ) ; reportResources . getReportAsExcel ( 4583173393803140L , EnumSet . of ( ReportInclusion . ATTACHMENTS , ReportInclusion . DISCUSSIONS ) , 1 , 1 , output ) ;", "del_tokens": "PaginationParameters pagination = new PaginationParameters ( true , 1 , 1 ) ; Report report = reportResources . getReport ( 4583173393803140L , EnumSet . of ( ObjectInclusion . ATTACHMENTS , ObjectInclusion . DISCUSSIONS ) , pagination ) ; reportResources . getReportAsExcel ( 4583173393803140L , EnumSet . of ( ObjectInclusion . ATTACHMENTS , ObjectInclusion . DISCUSSIONS ) , 1 , 1 , output ) ; reportResources . getReportAsExcel ( 4583173393803140L , EnumSet . of ( ObjectInclusion . ATTACHMENTS , ObjectInclusion . DISCUSSIONS ) , 1 , 1 , output ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "a", "bug", "around", "Basic", "Authentication", "."], "add_tokens": ". append ( \"Authorization: Basic \" )", "del_tokens": ". append ( \"Authorization: \" )", "commit_type": "fix"}
{"commit_tokens": ["added", "equals", "(", "Object", ")", "and", "hashCode", "()", "for", "all", "impl", "entities"], "add_tokens": "import net . dv8tion . jda . entities . TextChannel ; / * * * Returns true if one of the following is true : * A ) The provided object is the same SelfInfo instance as this object * B ) The provided object is a SelfInfo object with the same id as this object . * C ) The provided object is a String that is equal to our id . * / @ Override public boolean equals ( Object o ) { if ( o instanceof SelfInfo ) { SelfInfo oSelfInfo = ( SelfInfo ) o ; return this == oSelfInfo || this . getId ( ) . equals ( oSelfInfo . getId ( ) ) ; } else if ( o instanceof String ) { String oString = ( String ) o ; return this . getId ( ) . equals ( oString ) ; } return false ; } @ Override public int hashCode ( ) { return getId ( ) . hashCode ( ) ; }", "del_tokens": "import net . dv8tion . jda . entities . TextChannel ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "containsWhitespace", "(", ":", "String", ")", "method", "to", "the", "StringUtils", "class", ".", "Minor", "touchups", "to", "the", "ClassUtils", "and", "ObjectUtils", "classes", "."], "add_tokens": "* @ SuppressWarnings ( \"unchecked\" )", "del_tokens": "* < p / >", "commit_type": "add"}
{"commit_tokens": ["Add", "android", "excemption", "for", "URL", "handler", "version", "check"], "add_tokens": "if ( ! \"http://www.android.com\" . equalsIgnoreCase ( System . getProperty ( \"java.vendor.url\" ) ) && ver < 1.7f ) {", "del_tokens": "if ( ver < 1.7f ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "bug", "where", "the", "bottom", "scroller", "tended", "to", "be", "displayed", "wrong", "."], "add_tokens": "// switch (mDirection) { // case BOTTOM: // mCurrentTargetOffsetTop = getMeasuredHeight() - mCircleView.getMeasuredHeight(); // break; // case TOP: // default: // mCurrentTargetOffsetTop = mCircleView.getTop(); // break; // } mCurrentTargetOffsetTop = mCircleView . getTop ( ) ;", "del_tokens": "switch ( mDirection ) { case BOTTOM : mCurrentTargetOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; break ; case TOP : default : mCurrentTargetOffsetTop = mCircleView . getTop ( ) ; break ; } // mCurrentTargetOffsetTop = mCircleView.getTop();", "commit_type": "fix"}
{"commit_tokens": ["Added", "automatic", "set", "retain", "instance", "to", "all", "fragments"], "add_tokens": "import android . annotation . SuppressLint ; @ SuppressLint ( \"ValidFragment\" )", "del_tokens": "setRetainInstance ( true ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "pointed", "out", "by", "Nicolas", "Rioux", "."], "add_tokens": "this . paramTypes = method . getGenericParameterTypes ( ) ;", "del_tokens": "this . paramTypes = method . getParameterTypes ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "ConfigrationProperties", "to", "support", "VendorProperties"], "add_tokens": "import java . util . HashMap ; import org . springframework . boot . context . properties . ConfigurationProperties ; / * * * To avoid error \"Cannot apply class transformer without LoadTimeWeaver specified\" * Need to : * add spring . jpa . eclipselink . eclipselink . weaving = false to disable loadTimeWeaver * Or : * Config loadTimeWeaver * @ author xufucheng * * / @ ConfigurationProperties ( prefix = \"spring.jpa.eclipselink\" ) private Map < String , Object > eclipselink = new HashMap < String , Object > ( ) ; public Map < String , Object > getEclipselink ( ) { return eclipselink ; } public void setEclipselink ( Map < String , Object > eclipselink ) { this . eclipselink = eclipselink ; } return eclipselink ;", "del_tokens": "import java . util . LinkedHashMap ; Map < String , Object > vendorProperties = new LinkedHashMap < String , Object > ( ) ; return vendorProperties ;", "commit_type": "add"}
{"commit_tokens": ["Added", "template", "methods", "before", "and", "after", "invocation"], "add_tokens": "beforeInvocation ( target , invocation , invoker , restriction ) ; try { Object result = invoke ( target , invocation , invoker , restriction ) ; sendResult ( os , result , serializer ) ; } catch ( Throwable e ) { sendThrownThrowingOnSerializationError ( os , e , serializer ) ; } } finally { afterInvocation ( target , invocation , invoker , restriction ) ; protected void beforeInvocation ( Object target , Invocation invocation , Invoker invoker , InvocationRestriction restriction ) { } protected void afterInvocation ( Object target , Invocation invocation , Invoker invoker , InvocationRestriction restriction ) { }", "del_tokens": "Object result = invoke ( target , invocation , invoker , restriction ) ; sendResult ( os , result , serializer ) ; } catch ( Throwable e ) { sendThrownThrowingOnSerializationError ( os , e , serializer ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "ArrayOrderObliviousDiffy", "so", "that", "it", "behaves", "better", "when", "it", "s", "inputs", "dont", "match", "."], "add_tokens": "return diffList ( ( List < Object > ) expected , ( List < Object > ) actual ) ; // Make a copy of the expected keySet so that we can remove things w/out concurrent mod exceptions String [ ] expectedKeys = expected . keySet ( ) . toArray ( new String [ expected . keySet ( ) . size ( ) ] ) ; for ( String key : expectedKeys ) { protected Result diffList ( List < Object > expected , List < Object > actual ) {", "del_tokens": "return diffList ( ( List ) expected , ( List ) actual ) ; for ( Object key : expected . keySet ( ) . toArray ( ) ) { protected Result diffList ( List expected , List actual ) {", "commit_type": "fix"}
{"commit_tokens": ["Move", "handler", "install", "/", "remove", "to", "EventHandlerHelper", "."], "add_tokens": "import javafx . beans . property . ObjectProperty ; public static < T extends Event > EventHandler < ? super T > chain ( EventHandler < ? super T > ... handlers ) { public static < T extends Event > EventHandler < ? super T > exclude ( EventHandler < T > handler , EventHandler < ? > subHandler ) { public static < T extends Event > void install ( ObjectProperty < EventHandler < ? super T > > property , EventHandler < ? super T > handler ) { EventHandler < ? super T > oldHandler = property . get ( ) ; property . set ( EventHandlerHelper . chain ( handler , oldHandler ) ) ; } public static < T extends Event > void remove ( ObjectProperty < EventHandler < ? super T > > property , EventHandler < ? super T > handler ) { EventHandler < ? super T > oldHandler = property . get ( ) ; property . set ( EventHandlerHelper . exclude ( oldHandler , handler ) ) ; }", "del_tokens": "static < T extends Event > EventHandler < ? super T > chain ( EventHandler < ? super T > ... handlers ) { static < T extends Event > EventHandler < ? super T > exclude ( EventHandler < T > handler , EventHandler < ? > subHandler ) {", "commit_type": "move"}
{"commit_tokens": ["Fix", "semi", "-", "transparent", "branded", "channels"], "add_tokens": "Pattern . compile ( \"pack-(brand|semi|anon)-([^\\\\-]+)::(.+)\" ) ;", "del_tokens": "Pattern . compile ( \"pack-(branded|semi|anon)-([^\\\\-]+)::(.+)\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "remote", "config", "to", "use", "complex", "object", "default", "setting", "."], "add_tokens": "* @ parameter default - value = \"${remoteConfig}\"", "del_tokens": "* @ parameter", "commit_type": "update"}
{"commit_tokens": ["Added", "menu", "items", "for", "remaining", "datastore", "types"], "add_tokens": "// TODO: Not yet functional JMenuItem dbaseMenuItem = new JMenuItem ( \"Dbase database-file\" , imageManager . getImageIcon ( IconUtils . DBASE_IMAGEPATH , IconUtils . ICON_SIZE_SMALL ) ) ; dbaseMenuItem . setEnabled ( false ) ; // TODO: Not yet functional JMenuItem odbMenuItem = new JMenuItem ( \"OpenOffice.org database-file\" , imageManager . getImageIcon ( IconUtils . ODB_IMAGEPATH , IconUtils . ICON_SIZE_SMALL ) ) ; odbMenuItem . setEnabled ( false ) ; popup . add ( dbaseMenuItem ) ; popup . add ( odbMenuItem ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "race", "test", "with", "job", "cancellation"], "add_tokens": "@ Test public void exception_in_schedule_should_not_alter_scheduler__races_test ( ) throws InterruptedException { for ( int i = 0 ; i < 1000 ; i ++ ) { exception_in_schedule_should_not_alter_scheduler ( ) ; } } scheduler . schedule ( \"job1\" , job1 , Schedules . fixedDelaySchedule ( Duration . ofMillis ( 3 ) ) ) ;", "del_tokens": "scheduler . schedule ( \"job1\" , job1 , Schedules . fixedDelaySchedule ( Duration . ofMillis ( 5 ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "with", "gradle", "instructions"], "add_tokens": "throw new MissingApiTokenException ( status . getReasonPhrase ( ) ) ;", "del_tokens": "throw new MissingApiTokenException ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "to", "Issue", "575", ":", "Origin", "-", "Host", "AVP", "Incorrect", "value", "type"], "add_tokens": "getAvps ( ) . addAvp ( Avp . ORIGIN_HOST , metaData . getLocalPeer ( ) . getUri ( ) . getFQDN ( ) , true , false , true ) ;", "del_tokens": "//getAvps().addAvp( // Avp.ORIGIN_HOST, // metaData.getLocalPeer().getUri().getFQDN(), // true, false, true //); getAvps ( ) . addAvp ( Avp . ORIGIN_HOST , metaData . getLocalPeer ( ) . getUri ( ) . toString ( ) , true , false , true ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "BitSetStrictLength", "class", "AsnInputStream", ".", "advanceElement", "()"], "add_tokens": "* @ author sergey vetyutnev @ Test public void testAdvanceElement ( ) throws Exception { AsnInputStream asnIs = new AsnInputStream ( definiteSeqData ( ) ) ; int tag = asnIs . readTag ( ) ; asnIs . advanceElement ( ) ; assertEquals ( 16 , tag ) ; assertEquals ( 0 , asnIs . available ( ) ) ; asnIs = new AsnInputStream ( definiteSeqData ( ) ) ; tag = asnIs . readTag ( ) ; int length = asnIs . readLength ( ) ; asnIs . advanceElementData ( length ) ; assertEquals ( 0 , asnIs . available ( ) ) ; asnIs = new AsnInputStream ( indefiniteSeqData ( ) ) ; tag = asnIs . readTag ( ) ; asnIs . advanceElement ( ) ; assertEquals ( 0 , asnIs . available ( ) ) ; asnIs = new AsnInputStream ( indefiniteSeqData ( ) ) ; tag = asnIs . readTag ( ) ; length = asnIs . readLength ( ) ; asnIs . advanceElementData ( length ) ; assertEquals ( 0 , asnIs . available ( ) ) ; }", "del_tokens": "import java . io . ByteArrayInputStream ;", "commit_type": "add"}
{"commit_tokens": ["added", "api", "for", "2", ".", "x", "raw"], "add_tokens": "long installBundle ( String location , InputStream stream ) ; long installBundle ( InputStream stream ) ;", "del_tokens": "long installBundle ( InputStream bundleUrl ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "CoordinateBolt", "works", "well", "with", "JStorm", "Batch", "mode"], "add_tokens": "import backtype . storm . task . ICollectorCallback ; OutputCollector _delegate ; public CoordinatedOutputCollector ( OutputCollector delegate ) { List < Integer > tasks = _delegate . emit ( stream , anchors , tuple , new CollectorCb ( tuple . get ( 0 ) ) ) ; // due to here do updateTaskCounts, so we do flush operation _delegate . flush ( ) ; class CollectorCb implements ICollectorCallback { Object id ; public CollectorCb ( Object id ) { this . id = id ; } @ Override public void execute ( List < Integer > outTasks ) { // TODO Auto-generated method stub updateTaskCounts ( id , outTasks ) ; } } _collector . flush ( ) ; _collector . flush ( ) ; } finally { _collector . flush ( ) ;", "del_tokens": "IOutputCollector _delegate ; public CoordinatedOutputCollector ( IOutputCollector delegate ) { List < Integer > tasks = _delegate . emit ( stream , anchors , tuple ) ; updateTaskCounts ( tuple . get ( 0 ) , tasks ) ;", "commit_type": "make"}
{"commit_tokens": ["Changing", "default", "config", "setting", "to", "clear", "the", "histogram", "data", "every", "minutes"], "add_tokens": "private static final int DEFAULT_FLUSH_TIMINGS_FREQ_SECONDS = 300 ;", "del_tokens": "private static final int DEFAULT_FLUSH_TIMINGS_FREQ_SECONDS = 0 ;", "commit_type": "change"}
{"commit_tokens": ["Added", "ability", "to", "add", "additional", "path", "to", "URL", ".", "In", "this", "case", "legacy", ".", "Also", "added", "ability", "to", "set", "socket", "timeouts", "to", "support", "client", "SLA", "s", "."], "add_tokens": "public static final String SDK_VERSION = \"0.1.2\" ;", "del_tokens": "public static final String SDK_VERSION = \"0.1.1\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "wrong", "fieldName", "property", "on", "@DeepField", "annotation"], "add_tokens": "import com . stratio . deep . entity . WronglyMappedTestEntity ; import com . stratio . deep . exception . DeepNoSuchFieldException ; @ Test ( dependsOnMethods = \"testValidation\" ) @ Test public void testWronglyMappedField ( ) { IDeepJobConfig < WronglyMappedTestEntity > djc = DeepJobConfigFactory . create ( WronglyMappedTestEntity . class ) . host ( Constants . DEFAULT_CASSANDRA_HOST ) . rpcPort ( CassandraServer . CASSANDRA_THRIFT_PORT ) . cqlPort ( CassandraServer . CASSANDRA_CQL_PORT ) . keyspace ( \"test_keyspace\" ) . columnFamily ( \"test_page\" ) ; try { djc . initialize ( ) ; fail ( ) ; } catch ( DeepNoSuchFieldException e ) { // ok log . info ( \"Correctly catched DeepNoSuchFieldException: \" + e . getLocalizedMessage ( ) ) ; } }", "del_tokens": "@ Test", "commit_type": "add"}
{"commit_tokens": ["Remove", "thread", "leak", "when", "stopping", "river"], "add_tokens": "import java . io . IOException ; private Parser parser ; WikiXMLParser xmlParser = WikiXMLParserFactory . getSAXParser ( this . url ) ; try { xmlParser . setPageCallback ( new PageCallback ( ) ) ; } catch ( Exception e ) { logger . error ( \"failed to create xmlParser\" , e ) ; return ; } parser = new Parser ( xmlParser ) ; thread = EsExecutors . daemonThreadFactory ( settings . globalSettings ( ) , \"wikipedia_slurper\" ) . newThread ( parser ) ; // Start wikipedia slurper if ( parser != null ) { parser . close ( ) ; } public void close ( ) { if ( parser != null ) { try { parser . close ( ) ; } catch ( IOException e ) { logger . error ( \"failed to close parser\" , e ) ; } } }", "del_tokens": "WikiXMLParser parser = WikiXMLParserFactory . getSAXParser ( url ) ; try { parser . setPageCallback ( new PageCallback ( ) ) ; } catch ( Exception e ) { logger . error ( \"failed to create parser\" , e ) ; return ; } thread = EsExecutors . daemonThreadFactory ( settings . globalSettings ( ) , \"wikipedia_slurper\" ) . newThread ( new Parser ( parser ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "the", "survivor", "fraction", "probability", "from", "the", "GA", ".", "This", "can", "lead", "to", "inconsistencies", "with", "the", "offspring", "fraction", ".", "The", "survivor", "fraction", "is", "deduced", "from", "the", "offspring", "fraction", "(", "sf", ":", "=", "1", "-", "of", ")", "."], "add_tokens": "* @ version $ Id : StringGenerator . java , v 1.23 2009 - 03 - 16 21 : 50 : 23 fwilhelm Exp $", "del_tokens": "* @ version $ Id : StringGenerator . java , v 1.22 2009 - 02 - 24 21 : 32 : 09 fwilhelm Exp $ ga . setSurvivorFraction ( Probability . valueOf ( 0.3 ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["updating", "ion", "-", "tests", "and", "global", "skip", "list"], "add_tokens": ", \"equivs/nonIVMNoOps.ion\" // TODO amzn/ion-java#114 , \"good/symbolZero.ion\" // TODO amzn/ion-java#103", "del_tokens": ", \"good/nopPad16Bytes.10n\" // TODO amzn/ion-java#97 , \"good/nopPadOneByte.10n\" // TODO amzn/ion-java#97 , \"bad/symbolWithTab.ion\" // remove after https://github.com/amzn/ion-tests/pull/32 is pushed", "commit_type": "update"}
{"commit_tokens": ["fix", "duplicate", "AttributeOverride", "generation", "with", "history", "entities", "under", "specific", "circumstances"], "add_tokens": "private void addAttributeOverride ( Map < String , String > overrides , String attributeOverride ) { if ( ! overrides . containsKey ( name ) && findAttributeOverride ( columnAnnotation , name ) < 0 ) {", "del_tokens": "private static void addAttributeOverride ( Map < String , String > overrides , String attributeOverride ) { if ( ! overrides . containsKey ( name ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "max", "header", "line", "width", "calculation", "."], "add_tokens": "columnWidths [ column ] = Math . max ( columnWidths [ column ] , headerLine . length ( ) ) ;", "del_tokens": "columnWidths [ column ] = headerLine . length ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "mockito", "to", "test", "suite", "event", "test"], "add_tokens": "testSuite . setLabels ( labels ) ;", "del_tokens": "testSuite . getLabels ( ) . addAll ( labels ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "workaround", "for", "java", "bug", "with", "DELETE", "method"], "add_tokens": "if ( method . equals ( \"DELETE\" ) ) { conn . setRequestMethod ( \"POST\" ) ; conn . setRequestProperty ( \"X-HTTP-Method-Override\" , \"DELETE\" ) ; } else { conn . setRequestMethod ( method ) ; }", "del_tokens": "conn . setRequestMethod ( method ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "LDAP", "-", "26", ":", "PagedResultsRequestControl", "failing", "when", "used", "with", "AD"], "add_tokens": "RuntimeException ex = null ; // Note that this may present problems if a DirContextProcessor was // supplied - there's no guarantee that the postProcess() operation // will go well after a NamingException has been thrown. It is // however quite possible that information will be available for // retrieval either way. ex = getExceptionTranslator ( ) . translate ( e ) ; ex = getExceptionTranslator ( ) . translate ( e ) ; try { processor . postProcess ( ctx ) ; } catch ( NamingException e ) { if ( ex == null ) { ex = getExceptionTranslator ( ) . translate ( e ) ; } else { // We already had an exception from above and should ignore // this one. log . debug ( \"Ignoring Exception from postProcess, \" + \"main exception thrown instead\" , e ) ; } } // If we got an exception it should be thrown. if ( ex != null ) { throw ex ; } * java . lang . String , int , * org . springframework . ldap . core . AttributesMapper ) * java . lang . String , int , * org . springframework . ldap . core . AttributesMapper )", "del_tokens": "processor . postProcess ( ctx ) ; throw getExceptionTranslator ( ) . translate ( e ) ; throw getExceptionTranslator ( ) . translate ( e ) ; * java . lang . String , int , org . springframework . ldap . core . AttributesMapper ) * java . lang . String , int , org . springframework . ldap . core . AttributesMapper )", "commit_type": "fix"}
{"commit_tokens": ["add", "decompress", "setting", "to", "disable", "auto", "decompress"], "add_tokens": "import java . util . Collections ; import java . util . List ; * @ deprecated using { @ link # url } @ Deprecated * @ deprecated using { @ link # statusCode } @ Deprecated * @ deprecated using { @ link # cookies } @ Deprecated / * * * Get all cookies returned by this response * / @ NotNull public List < Cookie > cookies ( ) { return cookies ; } * @ deprecated using { @ link # headers } @ Deprecated", "del_tokens": "import java . util . Collections ; import java . util . List ;", "commit_type": "add"}
{"commit_tokens": ["Use", "an", "empty", "set", "instead", "of", "null", "."], "add_tokens": "import java . util . Collections ; import graphql . Assert ; this ( queryType , null , Collections . < GraphQLType > emptySet ( ) ) ; assertNotNull ( dictionary , \"dictionary can't be null\" ) ; return build ( Collections . < GraphQLType > emptySet ( ) ) ; Assert . assertNotNull ( dictionary , \"dictionary can't be null\" ) ;", "del_tokens": "this ( queryType , null , null ) ; return build ( null ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "bundle", "as", "param", "in", "transaction", "method"], "add_tokens": "ResourceMetadataKeyEnum . LINK_SEARCH . put ( patient , linkSearch ) ;", "del_tokens": "ResourceMetadataKeyEnum . LINK_ALTERNATE . put ( patient , linkSearch ) ;", "commit_type": "allow"}
{"commit_tokens": ["Using", "new", "constant", "Connections", ".", "DEFAULT_TRANSACTION_ISOLATION"], "add_tokens": "import com . aoindustries . sql . Connections ; Connection conn = getConnection ( Connections . DEFAULT_TRANSACTION_ISOLATION , false ) ;", "del_tokens": "Connection conn = getConnection ( Connection . TRANSACTION_READ_COMMITTED , false ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "encoder", "interface", "fixed", "more", "stuff", "up", "."], "add_tokens": "// $Id: RipTest.java,v 1.2 2000/10/30 22:21:11 mdb Exp $ package robodj . convert ;", "del_tokens": "// $Id: RipTest.java,v 1.1 2000/10/30 21:08:53 mdb Exp $ package robodj . rip ;", "commit_type": "add"}
{"commit_tokens": ["added", "convenience", "method", "that", "returns", "a", "hyphenated", "string"], "add_tokens": "* @ param locale The locale / * * * Returns the fully hyphenated string . * The given hyphen is inserted at all possible hyphenation points . * @ param text The string to be hyphenated * @ param hyphen The character to be used as hyphenation mark * @ return * / public String hyphenate ( String text , char hyphen ) { boolean [ ] hyphens = hyphenate ( text ) ; StringBuffer hyphenatedText = new StringBuffer ( ) ; int i ; for ( i = 0 ; i < hyphens . length ; i ++ ) { hyphenatedText . append ( text . charAt ( i ) ) ; if ( hyphens [ i ] ) { hyphenatedText . append ( hyphen ) ; } } hyphenatedText . append ( text . charAt ( i ) ) ; return hyphenatedText . toString ( ) ; }", "del_tokens": "* @ param locale", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "unit", "test", "of", "DiskCacheStorage", "not", "releasing", "file"], "add_tokens": "* Default size of the internal memory buffer ( 1 megabyte ) . public static final int DEFAULT_BUFFER_SIZE = 1024 * 1024 ;", "del_tokens": "* Default size of the internal memory buffer . public static final int DEFAULT_BUFFER_SIZE = 4096 ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "work", "with", "transparent", "section", "headers"], "add_tokens": "if ( headerBottomPosition == ( clippingToPadding ? headerHeight + getPaddingTop ( ) : headerHeight ) && viewToWatch . getTop ( ) < ( clippingToPadding ? headerHeight + getPaddingTop ( ) : headerHeight ) ) { viewToWatch . findViewById ( R . id . header_view ) . setVisibility ( View . INVISIBLE ) ; } else { viewToWatch . findViewById ( R . id . header_view ) . setVisibility ( View . VISIBLE ) ; } if ( Build . VERSION . SDK_INT < 11 ) { //work around to fix bug with firstVisibleItem being to high", "del_tokens": "import android . util . Log ; Log . d ( \"FGYHUIJKOLPKOIJHUGYTF\" , \"FIRST: \" + firstChildDistance ) ; Log . d ( \"IJHUGYFTDRSFTYGHUIJHJ\" , \"SECOND: \" + secondChildDistance ) ; if ( Build . VERSION . SDK_INT < 14 ) { //work around to fix bug with firstVisibleItem being to high", "commit_type": "update"}
{"commit_tokens": ["Use", "agreed", "-", "upon", "environment", "variables"], "add_tokens": "projectId = System . getenv ( \"IRON_PROJECT_ID\" ) ; token = System . getenv ( \"IRON_TOKEN\" ) ;", "del_tokens": "projectId = System . getenv ( \"IRONIO_PROJECT_ID\" ) ; token = System . getenv ( \"IRONIO_TOKEN\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Change", "PathType", "to", "take", "a", "single", "String", "in", "parsePath", "."], "add_tokens": "import com . google . common . collect . Lists ; String joined = type . joiner ( ) . join ( Lists . asList ( first , more ) ) ; SimplePath path = type . parsePath ( joined ) ;", "del_tokens": "SimplePath path = type . parsePath ( first , more ) ;", "commit_type": "change"}
{"commit_tokens": ["Move", "integer", "asserts", "aside", "."], "add_tokens": "public IntSubject ( FailureStrategy failureStrategy , int i ) { super ( failureStrategy , i ) ; public Subject < Integer > isInclusivelyInRange ( int lower , int upper ) { if ( ! ( lower <= getSubject ( ) && getSubject ( ) <= upper ) ) { fail ( \"is inclusively in range\" , lower , upper ) ; } return this ; } public Subject < Integer > isBetween ( int lower , int upper ) { if ( ! ( lower < getSubject ( ) && getSubject ( ) < upper ) ) { fail ( \"is in between\" , lower , upper ) ; } return this ; }", "del_tokens": "public IntSubject ( FailureStrategy failureStrategy , int i ) { super ( failureStrategy , i ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "env", "dimension", "while", "initializing", "MetricsManager"], "add_tokens": "MetricsManager . init ( TEST_SERVICE_NAME , \"\" , TEST_HOST_NAME ) ;", "del_tokens": "MetricsManager . init ( TEST_SERVICE_NAME , TEST_HOST_NAME ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "getMode", "and", "getCurrentMode", "public"], "add_tokens": "/ * * * Get the mode that this view is currently in . This is only really useful * when using < code > MODE_BOTH < / code > . * * @ return int of either < code > MODE_PULL_DOWN_TO_REFRESH < / code > or * < code > MODE_PULL_UP_TO_REFRESH < / code > * / public final int getCurrentMode ( ) { return mCurrentMode ; } / * * * Get the mode that this view has been set to . If this returns * < code > MODE_BOTH < / code > , you can use < code > getCurrentMode ( ) < / code > to * check which mode the view is currently in * * @ return int of either < code > MODE_PULL_DOWN_TO_REFRESH < / code > , * < code > MODE_PULL_UP_TO_REFRESH < / code > or < code > MODE_BOTH < / code > * / public final int getMode ( ) { return mMode ; }", "del_tokens": "protected final int getCurrentMode ( ) { return mCurrentMode ; } protected final int getMode ( ) { return mMode ; }", "commit_type": "make"}
{"commit_tokens": ["adding", "Tuple2", "/", "3", "/", "4", "/", "5#fill", "to", "fill", "each", "tuple", "instance", "with", "a", "given", "value"], "add_tokens": "* @ param fn the function to apply * @ param < R > the return type of the function / * * * Given a value of type < code > A < / code > , produced an instance of this tuple with each slot set to that value . * * @ param a the value to fill the tuple with * @ param < A > the value type * @ return the filled tuple * / public static < A > Tuple2 < A , A > fill ( A a ) { return tuple ( a , a ) ; }", "del_tokens": "* @ param fn the function to apply * @ param < R > the return type of the function", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "static", "method", "."], "add_tokens": "MoveEventListener . add ( dialog ) ;", "del_tokens": "dialog . addEventListener ( Events . ON_MOVE , new MoveEventListener ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "optional", "feature", ":", "Use", "Jafama", "s", "FastMath", ".", "exp", "()", "for", "probability", "calculation"], "add_tokens": "import biz . k11i . xgboost . learner . ObjFunction ; import org . junit . After ; @ DataPoints public static final boolean [ ] USE_JAFAMA = { true , false } ; public void testPredict ( String modelName , boolean useJafama ) throws IOException { ObjFunction . useFastMathExp ( useJafama ) ; @ After public void tearDown ( ) { ObjFunction . useFastMathExp ( false ) ; }", "del_tokens": "public void testPredict ( String modelName ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "configuration", "model", "to", "use", "a", "properties", "POJO", "and", "one", "(", "or", "more", ")", "properties", "builder", "e", ".", "g", ".", "for", "extracting", "properties", "of", "a", "Map", "(", "provided", "in", "this", "implementation", ")", ".", "Library", "consumers", "can", "use", "their", "own", "mechanism", "to", "populate", "the", "properties", "POJO", "(", "e", ".", "g", ".", "Spring", "config", "a", "builder", "that", "uses", "Java", "Properties", "...", ")"], "add_tokens": "String jndiName = null ; ConnectionFactory . getConnection ( jndiName ) ;", "del_tokens": "ConnectionFactory . getConnection ( null ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "auto", "gen", "getter", "/", "setter", "capitalization", "errors", "."], "add_tokens": "private String hqMusicUrl ; public MusicDetail ( String title , String description , String musicUrl , String hqMusicUrl , String thumbMediaId ) { this . hqMusicUrl = hqMusicUrl ; public String getHqMusicUrl ( ) { return hqMusicUrl ; public void setHqMusicUrl ( String hqMusicUrl ) { this . hqMusicUrl = hqMusicUrl ;", "del_tokens": "private String hQMusicUrl ; public MusicDetail ( String title , String description , String musicUrl , String hQMusicUrl , String thumbMediaId ) { this . hQMusicUrl = hQMusicUrl ; public String gethQMusicUrl ( ) { return hQMusicUrl ; public void sethQMusicUrl ( String hQMusicUrl ) { this . hQMusicUrl = hQMusicUrl ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "old", "syntax", "drag", "and", "drop", "action"], "add_tokens": "if ( slideShapes == null || slideShapes . size ( ) == 0 ) { } else { System . err . println ( \"Error. Slide \" + slideNumber + \" contains multiple shapes.\\n\" + \"The slide must contain only one input action using the predefined shapes.\\n\" + \"You may use the new syntax to enable multiple targets per slide.\" ) ; System . exit ( 1 ) ;", "del_tokens": "if ( slideShapes == null ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "youtube", "url", "better", "support", "for", "one", "drive", "based", "document", "folders", "."], "add_tokens": "public static final String YOUTUBE_VIDEO_URL = \"https://youtu.be/NYYXh9iwI5s\" ;", "del_tokens": "public static final String YOUTUBE_VIDEO_URL = \"https://www.youtube.com/videoToBeDefined\" ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "constraints", "and", "related", "messages"], "add_tokens": "throw new IllegalArgumentException ( \"'configurationsDir' argument can't be null\" ) ; throw new RuntimeException ( \"Impossible to load configurations directory '\" + \"' because it doesn't exist\" ) ; if ( builders == null || builders . length == 0 ) { throw new RuntimeException ( \"At least one ConfigurationReaderBuilder is required\" ) ; }", "del_tokens": "throw new IllegalArgumentException ( \"'toScan' argument can't be null\" ) ; throw new RuntimeException ( \"Impossible to load configuration file '\" + \" because it doesn't exist\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "failure", "to", "increment", "messagesRequested", "in", "receive", "methods"], "add_tokens": "requestMessage ( ) ; try { // If message exists in queue poll. if ( ! messageQueue . isEmpty ( ) ) { messageManager = messageQueue . pollFirst ( ) ; } else { long startTime = System . currentTimeMillis ( ) ; } } finally { if ( messageManager == null ) { unrequestMessage ( ) ; } } if ( messageManager != null ) { requestMessage ( ) ; }", "del_tokens": "// If message exists in queue poll. if ( ! messageQueue . isEmpty ( ) ) { messageManager = messageQueue . pollFirst ( ) ; } else { requestMessage ( ) ; try { long startTime = System . currentTimeMillis ( ) ; } finally { if ( messageManager == null ) { unrequestMessage ( ) ; } } }", "commit_type": "fix"}
{"commit_tokens": ["Implement", "PUT", "and", "DELETE", "/", "api", "/", "users", "/", ":", "name"], "add_tokens": "if ( username == null ) { throw new IllegalArgumentException ( \"username cannot be null\" ) ; } if ( password == null || password . length == 0 ) { throw new IllegalArgumentException ( \"password cannot be null or empty\" ) ; } public void updateUser ( String username , char [ ] password , List < String > tags ) { if ( username == null ) { throw new IllegalArgumentException ( \"username cannot be null\" ) ; } Map < String , Object > body = new HashMap < > ( ) ; // only update password if provided if ( password != null ) { body . put ( \"password\" , new String ( password ) ) ; } body . put ( \"tags\" , joinStrings ( \",\" , tags ) ) ; final URI uri = uriWithPath ( \"./users/\" + encodePathSegment ( username ) ) ; this . rt . put ( uri , body ) ; } sb . append ( delimiter ) ; if ( tag != null ) { sb . append ( tag ) ; }", "del_tokens": "sb . append ( tag ) . append ( delimiter ) ;", "commit_type": "implement"}
{"commit_tokens": ["Changed", "to", "Daemon", "thread", "."], "add_tokens": "while ( true ) {", "del_tokens": "private static volatile boolean RUNNING = true ; private Thread mainThread = null ; mainThread = Thread . currentThread ( ) ; while ( RUNNING ) { try { mainThread . join ( ) ; } catch ( Exception e ) { logger . warn ( \"Trouble rejoining main thread.\" , e ) ; }", "commit_type": "change"}
{"commit_tokens": ["Changed", "CommandLineRunner", "to", "public", "as", "I", "believe", "that", "was", "the", "intention", "according", "to"], "add_tokens": "public class CommandLineRunner extends", "del_tokens": "class CommandLineRunner extends", "commit_type": "change"}
{"commit_tokens": ["Remove", "the", "unneeded", "connectionID", "parameters"], "add_tokens": "public void onConnect ( RespokeClient sender ) ; listener . onConnect ( RespokeClient . this ) ;", "del_tokens": "public void onConnect ( RespokeClient sender , String connectionID ) ; listener . onConnect ( RespokeClient . this , localConnectionID ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "minor", "typos", "in", "javadoc"], "add_tokens": "* @ return true iff this is greater than the specified monetary value * @ return true iff this is greater than the specified monetary value * @ return true iff this is less than the specified monetary value", "del_tokens": "* @ return true is this is greater than the specified monetary value * @ return true is this is greater than the specified monetary value * @ return true is this is less than the specified monetary value", "commit_type": "fix"}
{"commit_tokens": ["added", "invalidate", "to", "bulk", "deletes"], "add_tokens": "Map params = ObjectUtils . only ( options , \"keep_original\" , \"invalidate\" , \"next_cursor\" ) ; Map params = ObjectUtils . only ( options , \"keep_original\" , \"invalidate\" , \"next_cursor\" ) ; return callApi ( HttpMethod . DELETE , Arrays . asList ( \"resources\" , resourceType , \"tags\" , tag ) , ObjectUtils . only ( options , \"keep_original\" , \"invalidate\" , \"next_cursor\" ) , options ) ; Map filtered = ObjectUtils . only ( options , \"keep_original\" , \"invalidate\" , \"next_cursor\" ) ;", "del_tokens": "Map params = ObjectUtils . only ( options , \"keep_original\" , \"next_cursor\" ) ; Map params = ObjectUtils . only ( options , \"keep_original\" , \"next_cursor\" ) ; return callApi ( HttpMethod . DELETE , Arrays . asList ( \"resources\" , resourceType , \"tags\" , tag ) , ObjectUtils . only ( options , \"keep_original\" , \"next_cursor\" ) , options ) ; Map filtered = ObjectUtils . only ( options , \"keep_original\" , \"next_cursor\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "single", "threaded", "benchmarks", "more", "handrolled", "variants", "cleanup"], "add_tokens": "public int offerAndPoll ( ) { Integer result = null ; result = q . poll ( ) ; return result . intValue ( ) ;", "del_tokens": "public void offerAndPoll ( ) { q . poll ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "flaws", "when", "counting", "the", "executed", "test", "cases", "."], "add_tokens": "if ( currentStoryDescription . isTest ( ) ) testCounter ++ ; if ( currentStep . isTest ( ) ) testCounter ++ ;", "del_tokens": "testCounter ++ ; testCounter ++ ; testCounter ++ ; // testCounter++;", "commit_type": "fix"}
{"commit_tokens": ["Created", "a", "handler", "events", "and", "listening", "for", "CHANNEL_DELETE", ".", "Events", "represented", "by", "TextChannelDeleteEvent", "and", "VoiceChannelDeleteEvent", "."], "add_tokens": "return this ;", "del_tokens": "return null ;", "commit_type": "create"}
{"commit_tokens": ["Using", "the", "instance", "variable", "of", "InstantiatorImplFactory", "rather", "than", "passing", "as", "argument", ".", "This", "makes", "testing", "slightly", "more", "verbose", "but", "is", "much", "clearer", "from", "a", "coding", "perspective", "."], "add_tokens": "for ( Constructor < T > constructor : getConstructor ( ) ) { Option < Constructor < T >> getConstructor ( ) { ( Constructor < T > [ ] ) klass . getDeclaredConstructors ( ) ; errors . moreThanOnceConstructorWithInstantiate ( klass ) ; throw new IllegalArgumentException ( klass . toString ( ) + throw new IllegalArgumentException ( \"No constructor found in \" + klass ) ;", "del_tokens": "for ( Constructor < T > constructor : getConstructor ( klass ) ) { Option < Constructor < T >> getConstructor ( Class < ? > clazz ) { ( Constructor < T > [ ] ) clazz . getDeclaredConstructors ( ) ; errors . moreThanOnceConstructorWithInstantiate ( clazz ) ; throw new IllegalArgumentException ( clazz . toString ( ) + throw new IllegalArgumentException ( \"No constructor found in \" + clazz ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "two", "new", "query", "parameters", "and", "the", "new", "API", "Key", "system"], "add_tokens": "import java . io . UTFDataFormatException ; import java . nio . charset . Charset ; import org . apache . commons . codec . binary . Base64 ; * @ throws InvalidKeyException * @ deprecated Use ` generateSecuredApiKey ( String privateApiKey , Query query ) ` version @ Deprecated return generateSecuredApiKey ( privateApiKey , query , null ) ; * @ deprecated Use ` generateSecuredApiKey ( String privateApiKey , Query query , String userToken ) ` version @ Deprecated if ( userToken != null && userToken . length ( ) > 0 ) { query . setUserToken ( userToken ) ; } String queryStr = query . getQueryString ( ) ; String key = hmac ( privateApiKey , queryStr ) ; return Base64 . encodeBase64String ( String . format ( \"%s%s\" , key , queryStr ) . getBytes ( Charset . forName ( \"UTF8\" ) ) ) ;", "del_tokens": "* @ throws InvalidKeyException return generateSecuredApiKey ( privateApiKey , query . toString ( ) , null ) ; return hmac ( privateApiKey , query . toString ( ) + ( userToken != null ? userToken : \"\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "browseWithAutoIT", "(", "String", "[]", "filePath", "String", "uploadName", ")"], "add_tokens": "* Use only this : button . browseWithAutoIT ( new String [ ] { \"C:\\\\upload.exe\" , \"C:\\\\text.txt\" } , \"Open\" ) ; * @ param filePath path to upload . exe * @ param uploadName upload window name * @ return public boolean browseWithAutoIT ( String [ ] filePath , String uploadName ) { Process process = Runtime . getRuntime ( ) . exec ( filePath [ 0 ] + \" \" + filePath [ 1 ] + \" \" + uploadName ) ; / * * * Upload file with AutoIT exe * Use only this : button . browseWithAutoIT ( new String [ ] { \"C:\\\\upload.exe\" , \"C:\\\\text.txt\" } ) ; * / public boolean browseWithAutoIT ( String [ ] filePath ) { return browseWithAutoIT ( filePath , uploadName ( ) ) ; }", "del_tokens": "* Use only this : button . browseWithAutoIT ( new String [ ] { \"C:\\\\upload.exe\" , \"C:\\\\text.txt\" } ) ; public boolean browseWithAutoIT ( String [ ] filePath ) { Process process = Runtime . getRuntime ( ) . exec ( filePath [ 0 ] + \" \" + filePath [ 1 ] + \" \" + uploadName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "write", "a", "\\", "r", "\\", "n", ".", "\\", "r", "\\", "n", "to", "end", "the", "DATA", "command"], "add_tokens": "ctx . getChannel ( ) . write ( ChannelBuffers . wrappedBuffer ( \"\\r\\n.\\r\\n\" . getBytes ( ) ) ) ;", "del_tokens": "ctx . getChannel ( ) . write ( ChannelBuffers . wrappedBuffer ( \".\\r\\n\" . getBytes ( ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["removed", "ant", "style", "support", "through", "regexp"], "add_tokens": "Names . bindProperties ( this . binder ( ) , this . configuration ) ;", "del_tokens": "import java . util . regex . Matcher ; import java . util . regex . Pattern ; private static final Pattern VARIABLE_REPLACE_PATTERN = Pattern . compile ( \"\\\\$\\\\{(.*?)\\\\}\" ) ; String key ; String value ; String variableKey ; String variableValue ; StringBuffer buffer ; for ( Entry < Object , Object > entry : this . configuration . entrySet ( ) ) { key = entry . getKey ( ) . toString ( ) ; value = entry . getValue ( ) . toString ( ) ; Matcher matcher = VARIABLE_REPLACE_PATTERN . matcher ( value ) ; buffer = new StringBuffer ( ) ; while ( matcher . find ( ) ) { variableKey = matcher . group ( 1 ) ; variableValue = this . configuration . getProperty ( variableKey ) ; if ( variableValue != null ) { matcher . appendReplacement ( buffer , variableValue ) ; } } matcher . appendTail ( buffer ) ; this . bindConstant ( ) . annotatedWith ( Names . named ( key ) ) . to ( buffer . toString ( ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "sequence", "verification", "to", "WebSocket", "Example"], "add_tokens": "public int sequence ; sequence = Helpers . getInt ( o , \"sequence\" ) ;", "del_tokens": "public String sequence ; sequence = Helpers . getString ( o , \"sequence\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "cases", "for", "default", "handler", "and", "helper", "classes", "."], "add_tokens": "RuntimeType . Verifier . check ( target ) ) ;", "del_tokens": "target . isAnnotationPresent ( RuntimeType . class ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "ZoomAnimator", "going", "beyond", "allowed", "zoom", "range"], "add_tokens": "this . zoomAnimator . startAnimation ( this . getScaleFactor ( ) , Math . pow ( 2 , this . zoomLevel ) ) ;", "del_tokens": "this . zoomAnimator . startAnimation ( this . getScaleFactor ( ) , Math . pow ( 2 , zoomLevel ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "duplicate", "XML", "attribute", "IDs", "."], "add_tokens": "final String idAttributeValue = idAttribute . getNodeValue ( ) ; String fixedIdAttributeValue = idAttributeValue ; fixedIdAttributeValue += \"-\" + specTopic . getDuplicateId ( ) ; fixedIdAttributeValue += \"-\" + specTopic . getStep ( ) ; setUniqueIdReferences ( node , idAttributeValue , fixedIdAttributeValue ) ; idAttribute . setNodeValue ( fixedIdAttributeValue ) ;", "del_tokens": "String idAttributeValue = idAttribute . getNodeValue ( ) ; idAttributeValue += \"-\" + specTopic . getDuplicateId ( ) ; idAttributeValue += \"-\" + specTopic . getStep ( ) ; setUniqueIdReferences ( node , idAttribute . getNodeValue ( ) , idAttributeValue ) ; idAttribute . setNodeValue ( idAttributeValue ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "addHeader", "is", "conditional", "as", "intended", "."], "add_tokens": "if ( allowMultiples || ! httpResponse . containsHeader ( name ) ) { httpResponse . addHeader ( name , entry . getValue ( ) ) ;", "del_tokens": "boolean doAdd ; if ( allowMultiples ) { doAdd = true ; } else { // Only add if not present doAdd = httpResponse . getHeader ( name ) == null ; httpResponse . addHeader ( name , entry . getValue ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "accessors", "for", "method", "definition"], "add_tokens": "public String getMethodName ( ) { return methodName ; } public int getModifiers ( ) { return modifiers ; } public MethodBody getMethodBody ( ) { return methodBody ; } public String getSignature ( ) { return signature ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "category", "restricted", "search", "endpoint", "for", "TV", "shows", "."], "add_tokens": "GetGlueObjects searchAnyObject ( @ Query ( \"q\" ) String query ) ; @ GET ( \"/search/objects?category=tv_shows\" ) GetGlueObjects searchTvShow (", "del_tokens": "GetGlueObjects search (", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "docs", "for", "session", "timeout", "."], "add_tokens": "* Property < tt > jcifs . smb . client . sessionTimeout < / tt > ( int , default 35000 )", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Moved", "proxy", "initialization", "into", "follow", "-", "on", "injection", "fragment", "generation"], "add_tokens": "if ( proxyAspect != null && proxyAspect . isProxyRequired ( ) && ! proxyAspect . isProxyDefined ( ) ) { proxyAspect . setProxyExpression ( variable ) ; injectionBuilderContext . getProxyLoad ( ) . add ( injectionNode ) ;", "del_tokens": "if ( proxyAspect != null && proxyAspect . isProxyRequired ( ) ) { injectionNode . addAspect ( new LateInit ( variable ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Making", "ArrayByte", "writeable", "and", "adding", "tests", "."], "add_tokens": "private final boolean readOnly ; * A new read - only { @ code ArrayByte } that wraps around the given array . this ( array , true ) ; } / * * * A new { @ code ArrayByte } that wraps around the given array . * * @ param array an array * @ param readOnly if false the wrapper allows writes to the array * / public ArrayByte ( byte [ ] array , boolean readOnly ) { this . readOnly = readOnly ; @ Override public void setByte ( int index , byte value ) { if ( ! readOnly ) { array [ index ] = value ; } else { throw new UnsupportedOperationException ( \"Read only list.\" ) ; } }", "del_tokens": "* A new { @ code ArrayByte } that wraps around the given array .", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "rename", "extracted", "file", "(", "e", ".", "g", ".", "cat", "to", "mycat", ")"], "add_tokens": "File catExeFile = JNE . findExecutable ( \"cat\" , \"prime-cat\" ) ;", "del_tokens": "File catExeFile = JNE . findExecutable ( \"cat\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "to", "the", "XMLFileFilter", "to", "match", "by", "namespace", "and", "root", "element", "."], "add_tokens": "case XMLStreamConstants . START_ELEMENT : String rootElement = reader . getLocalName ( ) ; return expectedRootElement . equals ( rootElement ) ;", "del_tokens": "case XMLStreamConstants . START_ELEMENT : String rootElement = reader . getLocalName ( ) ; return expectedRootElement . equals ( rootElement ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "slashes", "in", "baseDir", "property", "to", "PropertyCatalogTest"], "add_tokens": "import java . io . File ; import java . io . IOException ; @ Test public void testPropertyFileTemplateBasedir ( ) throws IOException { PropertyCatalogCheck check = new PropertyCatalogCheck ( getPath ( \"misc/InputPropertyCatalog1.java\" ) ) ; check . setBaseDir ( \"src\" ) ; check . setPropertyFile ( \"|{0}|{1}|{2}|{3}|{4}|{5}|{6}|{7}|{8}|{9}|{10}|\" ) ; String s = check . buildPropertyFilePath ( new BinaryName ( \"com.foo\" , \"Bar\" , \"Inner\" ) ) ; Assert . assertEquals ( \"|com.foo.Bar$Inner|com/foo/Bar/Inner|com.foo.Bar|com/foo/Bar|../../..|com/foo|Bar|Inner|\" + \"test|resources|com|\" , s ) ; check . setBaseDir ( \"src/test\" ) ; // forward slash s = check . buildPropertyFilePath ( new BinaryName ( \"com.foo\" , \"Bar\" , \"Inner\" ) ) ; Assert . assertEquals ( \"|com.foo.Bar$Inner|com/foo/Bar/Inner|com.foo.Bar|com/foo/Bar|../../..|com/foo|Bar|Inner|\" + \"resources|com|thomasjensen|\" , s ) ; check . setBaseDir ( \"src\\\\test\" ) ; // backslash s = check . buildPropertyFilePath ( new BinaryName ( \"com.foo\" , \"Bar\" , \"Inner\" ) ) ; Assert . assertEquals ( \"|com.foo.Bar$Inner|com/foo/Bar/Inner|com.foo.Bar|com/foo/Bar|../../..|com/foo|Bar|Inner|\" + \"resources|com|thomasjensen|\" , s ) ; }", "del_tokens": "import java . io . File ; import java . io . IOException ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "and", "explanation", "in", "Repository", "javadoc"], "add_tokens": "* Persists the given entity . This is an upsert / merge command ( i . e . creates non - persistent and updates existing * entities ) . * Persists the given collection of entities . This is an upsert / merge command ( i . e . creates non - persistent and * updates existing entities ) .", "del_tokens": "* Persists the given entity . This is an \"upersert\" command . * Persists the given collection of entities . This is an \"upersert\" command .", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "connection", "and", "error", "listener", "in", "factory", "."], "add_tokens": "import io . nats . client . ConnectionListener ; import io . nats . client . ErrorListener ; private ConnectionListener connListener ; private ErrorListener errListener ; . natsConn ( natsConn ) . natsUrl ( natsUrl ) . connectionListener ( connListener ) . errorListener ( errListener ) . build ( ) ; / * * * @ return the connection listener configured for this factory * / public ConnectionListener getConnectionListener ( ) { return this . connListener ; } / * * * Set a connection listener for the underlying nats connection . * * @ param l The new connection listener * / public void setConnectionListener ( ConnectionListener l ) { this . connListener = l ; } / * * * * @ return the error listener associated with this factory * / public ErrorListener getErrorListener ( ) { return this . errListener ; } / * * * Set a error listener for the underlying nats connection . * * @ param l The new error listener * / public void setErrorListener ( ErrorListener l ) { this . errListener = l ; }", "del_tokens": ". natsConn ( natsConn ) . natsUrl ( natsUrl ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "diamond", "path", "1", "producer", "and", "3", "consumer", "performance", "test", "."], "add_tokens": "private final FunctionStep functionStep ; public FunctionHandler ( final FunctionStep functionStep ) this . functionStep = functionStep ; switch ( functionStep ) case ONE : case TWO : case THREE :", "del_tokens": "private final Function function ; public FunctionHandler ( final Function function ) this . function = function ; switch ( function ) case STEP_ONE : case STEP_TWO : case STEP_THREE :", "commit_type": "add"}
{"commit_tokens": ["add", "legacy", "date", "convenient", "method"], "add_tokens": "import java . time . ZoneId ; import java . util . Date ; / * * * Get internal Date as Date ( Please avoid this , because LocalDate is far better . ) * @ return * / public Date getLegacyDateValue ( ) { return Date . from ( internalDate . atStartOfDay ( ZoneId . systemDefault ( ) ) . toInstant ( ) ) ; }", "del_tokens": "import de . jformchecker . FormChecker ;", "commit_type": "add"}
{"commit_tokens": ["Change", "name", "of", "Api", "Token", "to", "Api", "Key"], "add_tokens": "private String apiKey ; public AIConfiguration ( final String apiKey , final String language ) { this . apiKey = apiKey ; public AIConfiguration ( final String apiKey , final String language , final RecognitionEngine recognitionEngine ) { this . apiKey = apiKey ; public String getApiKey ( ) { return apiKey ; public void setApiKey ( final String apiKey ) { this . apiKey = apiKey ;", "del_tokens": "private String accessToken ; public AIConfiguration ( final String accessToken , final String language ) { this . accessToken = accessToken ; public AIConfiguration ( final String accessToken , final String language , final RecognitionEngine recognitionEngine ) { this . accessToken = accessToken ; public String getAccessToken ( ) { return accessToken ; public void setAccessToken ( final String accessToken ) { this . accessToken = accessToken ;", "commit_type": "change"}
{"commit_tokens": ["changed", "XML", "prefix", "for", "xAL", "to", "follow", "recommendation", "in", "CityGML", "spec"], "add_tokens": "\"xAL\" ,", "del_tokens": "\"xal\" ,", "commit_type": "change"}
{"commit_tokens": ["moving", "all", "check", "calls", "to", "DASourceClassChecker"], "add_tokens": "checker . check ( daSourceClass ) ;", "del_tokens": "checker . checkModifiers ( daSourceClass . getModifiers ( ) ) ; checker . checkInterfaces ( daSourceClass . getInterfaces ( ) ) ; checker . checkMethods ( daSourceClass . getMethods ( ) ) ; // retrieve instantiation type from @Mapper annotation // - CONSTRUCTOR : check public/protected default constructor exists sinon erreur de compilation // - SINGLETON_ENUM : check @Mapper class is an enum + check there is only one value sinon erreur de compilation // - SPRING_COMPONENT : TOFINISH quelles vrifications sur la class si le InstantiationType est SPRING_COMPONENT ? checker . checkInstantiationTypeRequirements ( daSourceClass ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "class", "visibility", "from", "package", "to", "public"], "add_tokens": "public class NoEventBusListenerMethodFilter implements EventBusListenerMethodFilter {", "del_tokens": "class NoEventBusListenerMethodFilter implements EventBusListenerMethodFilter {", "commit_type": "change"}
{"commit_tokens": ["removing", "training", "method", "from", "CLI"], "add_tokens": "outModel = FilenameUtils . removeExtension ( trainSet ) + \"-\" + \"-model\" Properties props = setTrainProperties ( dictPath ) ; private Properties setTrainProperties ( String dictPath ) {", "del_tokens": "String trainMethod = parsedArguments . getString ( \"trainMethod\" ) ; outModel = FilenameUtils . removeExtension ( trainSet ) + \"-\" + trainMethod + \"-model\" Properties props = setTrainProperties ( dictPath , trainMethod ) ; private Properties setTrainProperties ( String dictPath , String trainMethod ) { trainProperties . setProperty ( \"trainMethod\" , trainMethod ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "main", "content", "invisible", "bug"], "add_tokens": "void setAllChildrenVisible ( ) { for ( int i = 0 , childCount = getChildCount ( ) ; i < childCount ; i ++ ) { final View child = getChildAt ( i ) ; if ( child . getVisibility ( ) == INVISIBLE ) { child . setVisibility ( VISIBLE ) ; } } } setAllChildrenVisible ( ) ; public void onViewCaptured ( View capturedChild , int activePointerId ) { setAllChildrenVisible ( ) ; }", "del_tokens": "public void onViewCaptured ( View capturedChild , int activePointerId ) { }", "commit_type": "fix"}
{"commit_tokens": ["added", "comments", "on", "usage", "semantics", "updated", "noarg", "borrowClient", "to", "use", "loadbalanced", "borrowClient", "plumbing"], "add_tokens": "* @ author Nate McCall ( nate @ vervewireless . com ) PoolExhaustedException , Exception { String [ ] clients = new String [ pools . size ( ) ] ; int x = 0 ; for ( PoolKey poolKey : pools . keySet ( ) ) { clients [ x ] = poolKey . getUrlPort ( ) ; x ++ ; return borrowClient ( clients ) ; private String getUrlPort ( ) { return new StringBuilder ( 32 ) . append ( url ) . append ( ':' ) . append ( port ) . toString ( ) ; }", "del_tokens": "PoolExhaustedException , Exception { List < CassandraClientPoolByHost > clients = new ArrayList < CassandraClientPoolByHost > ( pools . values ( ) ) ; while ( ! clients . isEmpty ( ) ) { int rand = ( int ) ( Math . random ( ) * clients . size ( ) ) ; try { return clients . get ( rand ) . borrowClient ( ) ; } catch ( Exception e ) { if ( clients . size ( ) > 0 ) { log . warn ( \"Unable to obtain previously existing client \" + clients . get ( rand ) + \" will try the next client\" , e ) ; clients . remove ( rand ) ; } else { throw e ; } } return null ;", "commit_type": "add"}
{"commit_tokens": ["move", "getAttributes", "from", "SQLExpr", "to", "SQLVariantRefExpr"], "add_tokens": "( ( SQLVariantRefExpr ) sqlExprs . get ( count ) ) . getAttributes ( ) . put ( SQLEvalConstants . EVAL_VALUE , parameters . get ( parameterCount ) ) ; ( ( SQLVariantRefExpr ) sqlExprs . get ( count ) ) . getAttributes ( ) . put ( SQLEvalConstants . EVAL_VAR_INDEX , parameterCount ) ;", "del_tokens": "sqlExprs . get ( count ) . getAttributes ( ) . put ( SQLEvalConstants . EVAL_VALUE , parameters . get ( parameterCount ) ) ; sqlExprs . get ( count ) . getAttributes ( ) . put ( SQLEvalConstants . EVAL_VAR_INDEX , parameterCount ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "update", "method", "in", "web", "pages", "DAO"], "add_tokens": "updateWebPageShares ( webPageURL , 1 ) ; } @ Override public void updateWebPageShares ( String webPageURL , int shares ) { update . incField ( \"shares\" , shares ) ;", "del_tokens": "update . incField ( \"shares\" , 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "cancelAnimation", "method", "to", "ChartAnimator", "."], "add_tokens": "import android . util . Log ; float mScale ; @ Override public void cancelAnimation ( ) { mObjectAnimator . cancel ( ) ; } Log . v ( \"TAG\" , \"Updatign by scale \" + ( Float ) animation . getAnimatedValue ( ) ) ;", "del_tokens": "private float mScale ;", "commit_type": "add"}
{"commit_tokens": ["use", "word", ":", "LCM", "to", "understand", "easily"], "add_tokens": "inlength = Util . lcm ( inlength , 128 ) ;", "del_tokens": "inlength = inlength / 128 * 128 ;", "commit_type": "use"}
{"commit_tokens": ["add", "keyword", "to", "userdefine", "library"], "add_tokens": "import org . ansj . util . FilterModifWord ; POS_SCORE . put ( \"m\" , 0.0 ) ; POS_SCORE . put ( \"kw\" , 6.0 ) ; // parse = FilterModifWord . modifResult ( parse ) ;", "del_tokens": "//  char c = WordAlert . CharCover ( term . getName ( ) . charAt ( 0 ) ) ; if ( c >= '0' && c <= '9' ) { continue ; }", "commit_type": "add"}
{"commit_tokens": ["move", "toOperator", "(", "Transformer", ")", "to", "this", "project", "from", "rxjava", "-", "jdbc"], "add_tokens": "import com . github . davidmoten . rx . operators . OperatorFromTransformer ; import rx . Observable . Operator ; public final class Transformers { public static < T , R > Operator < R , T > toOperator ( Transformer < T , R > transformer ) { return OperatorFromTransformer . toOperator ( transformer ) ; }", "del_tokens": "public final class Transformations {", "commit_type": "move"}
{"commit_tokens": ["Fixed", "AVC", "MP4", "mux", "sample", "and", "the", "documentation"], "add_tokens": "import java . util . HashMap ; import org . jcodec . common . tools . MainUtils ; import org . jcodec . common . tools . MainUtils . Cmd ; Cmd cmd = MainUtils . parseArguments ( args ) ; if ( cmd . argsLength ( ) < 2 ) { MainUtils . printHelp ( new HashMap < String , String > ( ) { { put ( \"q\" , \"Look for stream parameters only in the beginning of stream\" ) ; } } , \"in.264\" , \"out.mp4\" ) ; System . exit ( - 1 ) ; File in = new File ( cmd . getArg ( 0 ) ) ; File out = new File ( cmd . getArg ( 1 ) ) ; ByteBuffer data = NIOUtils . cloneBuffer ( frame . getData ( ) ) ;", "del_tokens": "if ( args . length < 2 ) { System . out . println ( \"Syntax: <in.264> <out.mp4>\\n\" + \"\\tWhere:\\n\" + \"\\t-q\\tLook for stream parameters only in the beginning of stream\" ) ; return ; File in = new File ( args [ 0 ] ) ; File out = new File ( args [ 1 ] ) ; ByteBuffer data = frame . getData ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "DefaultStatusBar", "public", "and", "non", "-", "final", "."], "add_tokens": "public class DefaultStatusBar extends PixelInfoStatusBar implements ImageMouseMotionListener {", "del_tokens": "final class DefaultStatusBar extends PixelInfoStatusBar implements ImageMouseMotionListener {", "commit_type": "make"}
{"commit_tokens": ["Use", "/", "instead", "of", ".", "as", "the", "separator", "between", "service", "name", "and", "client", "name", "."], "add_tokens": "return MethodDescriptor . create ( method . getType ( ) , fullServiceName + \"/\" + method . getName ( ) ,", "del_tokens": "return MethodDescriptor . create ( method . getType ( ) , fullServiceName + \".\" + method . getName ( ) ,", "commit_type": "use"}
{"commit_tokens": ["Added", "path", "property", "to", "baseUri"], "add_tokens": "String path = props . getPath ( ) != null ? props . getPath ( ) : \"\" ; this . baseURI = builder ( ) . scheme ( props . getProtocol ( ) ) . host ( props . getHost ( ) ) . port ( props . getPort ( ) ) . path ( \"/\" ) . path ( path ) . build ( ) ; this . dbURI = builder ( baseURI ) . path ( props . getDbName ( ) ) . path ( \"/\" ) . build ( ) ;", "del_tokens": "baseURI = builder ( ) . scheme ( props . getProtocol ( ) ) . host ( props . getHost ( ) ) . port ( props . getPort ( ) ) . path ( \"/\" ) . build ( ) ; dbURI = builder ( baseURI ) . path ( props . getDbName ( ) ) . path ( \"/\" ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "tests", "to", "NoxItemCatalog"], "add_tokens": ". useCircularTransformation ( )", "del_tokens": ". useCircularTransformation ( )", "commit_type": "add"}
{"commit_tokens": ["Remove", "@Json", "and", "@Smile", "bound", "serializers", "since", "they", "collide", "for", "the", "String", "type", "..."], "add_tokens": "bindDeserializers ( JsonDeserializerFunction . class , SmileDeserializerFunction . class , true ) ;", "del_tokens": "if ( String . class != type . getType ( ) ) { bindSerializers ( Json . class , Smile . class ) ; } if ( String . class != type . getType ( ) ) { bindDeserializers ( Json . class , Smile . class , false ) ; } bindDeserializers ( JsonDeserializer . class , SmileDeserializer . class , true ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "preview", "for", "no", "check", "."], "add_tokens": "if ( mCheckedImages . size ( ) > 0 ) { AlbumPreviewFragment previewFragment = NoFragment . instantiate ( getContext ( ) , AlbumPreviewFragment . class , getArguments ( ) ) ; previewFragment . bindAlbumImages ( mCheckedImages , mCheckedImages , 0 ) ; startFragmentForResquest ( previewFragment , REQUEST_CODE_FRAGMENT_PREVIEW ) ; }", "del_tokens": "AlbumPreviewFragment previewFragment = NoFragment . instantiate ( getContext ( ) , AlbumPreviewFragment . class , getArguments ( ) ) ; previewFragment . bindAlbumImages ( mCheckedImages , mCheckedImages , 0 ) ; startFragmentForResquest ( previewFragment , REQUEST_CODE_FRAGMENT_PREVIEW ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "command", "to", "synchronize", "with", "Mendeley", "server"], "add_tokens": "MENDELEY_SYNC , . add ( OID . MENDELEY_SYNC , \"mendeley-sync\" , \"synchronize with Mendeley server\" ) boolean mendeleySync = false ; case MENDELEY_SYNC : mendeleySync = true ; break ; provider = readMendeley ( mendeleySync ) ; * @ param sync true if synchronization should be forced private ItemDataProvider readMendeley ( boolean sync ) { //clear cache if necessary if ( sync ) { mc . clear ( ) ; }", "del_tokens": "provider = readMendeley ( ) ; private ItemDataProvider readMendeley ( ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "check", "to", "ensure", "custom", "drivers", "set", "custom", "url", "."], "add_tokens": "import org . apache . commons . io . FilenameUtils ; import com . redhat . victims . VictimsConfig ; return \"org.h2.Driver\" ; String cache = \"\" ; try { cache = VictimsConfig . cache ( ) . toString ( ) ; } catch ( IOException e ) { // Ignore and use cwd } return String . format ( \"jdbc:h2:%s;MVCC=true\" , FilenameUtils . concat ( cache , \"victims\" ) ) ; if ( ! VictimsConfig . dbDriver ( ) . equals ( defaultDriver ( ) ) && VictimsConfig . dbUrl ( ) . equals ( defaultURL ( ) ) ) { // Custom drivers require custom urls throw new VictimsException ( \"A custome JDBC driver was specified without setting \" + VictimsConfig . Key . DB_URL ) ; }", "del_tokens": "protected static DatabaseType defaultDB = new VictimsH2 ( ) ; return defaultDB . driver ( ) ; return defaultDB . url ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "newlines", "which", "the", "AWS", "SDK", "rejects"], "add_tokens": "\"</AccessControlPolicy>\" ) ; writer . write ( \"</CopyObjectResult>\" ) ; \"</Error>\" ) ;", "del_tokens": "\"</AccessControlPolicy>\\r\\n\" ) ; writer . write ( \"</CopyObjectResult>\\r\\n\" ) ; \"</Error>\\r\\n\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "adding", "files", "from", "directory", "based", "on", "accept", "filter", "it", "also", "fixed", "test", "(", "that", "failed", "only", "on", "windows", ")", ":", "ZipsTest", ".", "testAddEntryFilter", "()"], "add_tokens": "if ( File . separator . equals ( \"\\\\\" ) ) { // replace directory separators on windows as at least 7zip packs zip with entries having \"/\" like on linux entryPath = entryPath . replace ( '\\\\' , '/' ) ; } handleInPlaceActions ( destinationFile ) ;", "del_tokens": "handleInPlaceActions ( destinationFile ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "RowVO", "instead", "of", "LinkedHashMap<String", "Object", ">"], "add_tokens": "public List < RowVO > toListOfMap ( ) { List < RowVO > list = new ArrayList < > ( ) ; RowVO rowAsMap = new RowVO ( ) ;", "del_tokens": "import java . util . LinkedHashMap ; import java . util . Map ; public List < Map < String , Object > > toListOfMap ( ) { List < Map < String , Object > > list = new ArrayList < > ( ) ; Map < String , Object > rowAsMap = new LinkedHashMap < > ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bugs", "that", "were", "breaking", "the", "injector", "s", "first", "client", "."], "add_tokens": "} else if ( name . startsWith ( packagePrefix ) && name . indexOf ( '.' , packagePrefix . length ( ) ) == - 1 ) {", "del_tokens": "} else if ( name . startsWith ( packagePrefix ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "all", "test", "and", "add", "API", "Versioning", "test"], "add_tokens": "objectMap . put ( \"results\" , \"2\" ) ; // one result per page assertEquals ( ParcelCollection . getData ( ) . size ( ) , 2 ) ;", "del_tokens": "objectMap . put ( \"results\" , \"1\" ) ; // one result per page assertEquals ( ParcelCollection . getData ( ) . size ( ) , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "standalone", "module", "structure", "."], "add_tokens": "System . out . println ( \"PDF-conversion server is up and running. Hit any key to shut down...\" ) ;", "del_tokens": "System . out . println ( \"PDF-conversion server is up and running. Hit enter to shut down...\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["fixed", "statusbar", "color", "where", "if", "the", "first", "color", "is", "not", "the", "primary", "color", "statusbar", "will", "be", "colored", "as", "the", "primaryColor", "."], "add_tokens": "* < p > onStatusBarColorChange ( color ) ; * < p > * < p >", "del_tokens": "* < p / > * < p / > * < p / >", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "match", "new", "strings", "in", "-", "12"], "add_tokens": "context = \"Encrypt1\" ; if ( objProtected . getType ( ) != CBORType . Map ) throw new CoseException ( \"Invalid Encrypt0 structure\" ) ; else if ( ! obj . get ( 2 ) . isNull ( ) ) throw new CoseException ( \"Invalid Encrypt0 structure\" ) ;", "del_tokens": "context = \"Encrypted\" ; else if ( ! obj . get ( 2 ) . isNull ( ) ) throw new CoseException ( \"Invalid Enrypt0 structure\" ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "APIs", "to", "get", "/", "set", "server", "list", "filters", "."], "add_tokens": "NiwsClientConfig niwsClientConfig ; public DynamicServerListLoadBalancer ( NiwsClientConfig niwsClientConfig ) { initWithNiwsConfig ( niwsClientConfig ) ; } public ServerListFilter < T > getFilter ( ) { return filter ; } public void setFilter ( ServerListFilter < T > filter ) { this . filter = filter ; }", "del_tokens": "NiwsClientConfig niwsClientConfig ;", "commit_type": "add"}
{"commit_tokens": ["Added", "multiple", "property", "names", "to", "CursorList", ".", "loadRelatedEntities"], "add_tokens": "import java . util . Set ; import com . google . common . collect . Sets ; * @ param propertyName the name of the properties to be used as Key public Map < Key , Object > loadRelatedEntities ( String ... propertyName ) { Set < Key > keys = Sets . newHashSet ( ) ; for ( String p : propertyName ) { keys . addAll ( Collections2 . transform ( data , new EntityToPropertyFunction ( persistentClass , p ) ) ) ; } return entityManager . get ( keys ) ;", "del_tokens": "* @ param propertyName the name of the property to be used as Key public CursorList < J > loadRelatedEntities ( String propertyName ) { entityManager . get ( Collections2 . transform ( data , new EntityToPropertyFunction ( persistentClass , propertyName ) ) ) ; return this ;", "commit_type": "add"}
{"commit_tokens": ["Add", "config", "class", "for", "parser"], "add_tokens": ". setConfig ( EmvParser . Config ( ) . setContactLess ( false ) ) //", "del_tokens": ". setContactLess ( false ) // . setReadAllAids ( true ) // . setReadTransactions ( true ) //", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "in", "casting", "stat", "to", "Long"], "add_tokens": "this . mConfig = mConfig ;", "del_tokens": "this . mConfig = mConfig ;", "commit_type": "fix"}
{"commit_tokens": ["added", "angular", "gauge", "to", "SimplePage"], "add_tokens": "import com . googlecode . wickedcharts . showcase . options . AngularGaugeOptions ; new ZoomableTimeSeriesOptions ( ) , new AngularGaugeOptions ( ) ) ;", "del_tokens": "new ZoomableTimeSeriesOptions ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "tests", "for", "spring", "extension"], "add_tokens": "import org . springframework . beans . factory . DisposableBean ; public class MetaqTemplate implements DisposableBean { @ Override public void destroy ( ) throws Exception { if ( this . sharedProducer != null ) { this . sharedProducer . shutdown ( ) ; this . sharedProducer = null ; } for ( FutureTask < MessageProducer > task : this . producers . values ( ) ) { try { MessageProducer producer = task . get ( 5000 , TimeUnit . MILLISECONDS ) ; if ( producer != null ) { producer . shutdown ( ) ; } } catch ( Exception e ) { // ignore } } this . producers . clear ( ) ; }", "del_tokens": "public class MetaqTemplate {", "commit_type": "add"}
{"commit_tokens": ["fix", "an", "issue", "in", "property", "get"], "add_tokens": "return setterViaField ( c , propName ) ; private PropertySetter setterViaField ( Class entityClass , String propName ) { while ( ! Object . class . equals ( entityClass ) ) { try { Field f = entityClass . getDeclaredField ( propName ) ; f . setAccessible ( true ) ; return newSetter ( entityClass , null , f ) ; } catch ( NoSuchFieldException e3 ) { entityClass = entityClass . getSuperclass ( ) ; } } throw E . unexpected ( \"Cannot find access method to field %s on %s\" , propName , entityClass ) ; } throw E . unexpected ( \"Cannot find access method to field %s on %s\" , propName , entityClass ) ;", "del_tokens": "try { Field f = c . getDeclaredField ( propName ) ; f . setAccessible ( true ) ; return newSetter ( c , null , f ) ; } catch ( NoSuchFieldException e ) { throw E . unexpected ( e , \"Cannot find access method to field %s on class %s\" , propName , c ) ; } throw E . unexpected ( e3 , \"Cannot find access method to field %s on class %s\" , propName , entityClass ) ; throw E . unexpected ( \"entity class is Object.class\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "app", "subdomain", "for", "OAuth", "token", "retrieval"], "add_tokens": "public static final String DEFAULT_OAUTH_TOKEN_URL = \"https://app.hellosign.com/oauth/token\" ;", "del_tokens": "public static final String DEFAULT_OAUTH_TOKEN_URL = \"https://www.hellosign.com/oauth/token\" ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "ECDSA", "Signing", "and", "verification", "to", "use", "R", "+", "S", "curve", "points", "as", "per", "spec", "https", ":", "//", "tools", ".", "ietf", ".", "org", "/", "html", "/", "rfc7515#page", "-", "45"], "add_tokens": "import io . jsonwebtoken . SignatureAlgorithm ; import io . jsonwebtoken . SignatureException ; import io . jsonwebtoken . lang . Assert ; byte [ ] derSignature = ECDSA . transcodeSignatureToDER ( signature ) ; return doVerify ( sig , publicKey , data , derSignature ) ;", "del_tokens": "import io . jsonwebtoken . SignatureAlgorithm ; import io . jsonwebtoken . SignatureException ; import io . jsonwebtoken . lang . Assert ; return doVerify ( sig , publicKey , data , signature ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "integration", "tests", "to", "verify", "that", "all", "rules", "are", "working", "with", "their", "default", "settings", "."], "add_tokens": "class TestUtils { private static final String SONAR_JAVA_PLUGIN_VERSION_KEY = \"test.sonar.plugin.version.java\" ; private static final String SONAR_VERSION_KEY = \"test.sonar.version\" ; static File projectPom ( String projectName ) { static String determineJavaPluginVersion ( ) { return System . getProperty ( SONAR_JAVA_PLUGIN_VERSION_KEY , \"DEV\" ) ; } static String determineSonarqubeVersion ( ) { return System . getProperty ( SONAR_VERSION_KEY , \"LATEST_RELEASE[6.7]\" ) ; } static String keyFor ( String projectKey , String srcDir , String pkgDir , String cls ) { return \"com.sonarsource.it.projects:\" + projectKey + \":\" + srcDir + pkgDir + cls ; } static String keyFor ( String projectKey , String pkgDir , String cls ) { return keyFor ( projectKey , \"src/main/java/\" , pkgDir , cls + \".java\" ) ; } static String keyForTest ( ) { return keyFor ( \"pmd-junit-rules\" , \"src/test/java/\" , \"\" , \"ProductionCodeTest\" + \".java\" ) ; }", "del_tokens": "public class TestUtils { public static File projectPom ( String projectName ) {", "commit_type": "add"}
{"commit_tokens": ["improve", "run", "story", "test", "loop", "."], "add_tokens": "while ( story . canContinue ( ) || story . getCurrentChoices ( ) . size ( ) > 0 ) { // 2) Game content, line by line while ( story . canContinue ( ) ) { String line = story . Continue ( ) ; System . out . println ( line ) ; text . append ( line ) ; } for ( String errorMsg : story . getCurrentErrors ( ) ) { System . out . println ( errorMsg ) ; } }", "del_tokens": "// 2) Game content, line by line while ( story . canContinue ( ) ) { String line = story . Continue ( ) ; System . out . println ( line ) ; text . append ( line ) ; for ( String errorMsg : story . getCurrentErrors ( ) ) { System . out . println ( errorMsg ) ; } }", "commit_type": "improve"}
{"commit_tokens": ["Fix", "for", "MASPECTJ", "-", "96", ":", "add", "skip"], "add_tokens": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * if ( isSkip ( ) ) { if ( getLog ( ) . isInfoEnabled ( ) ) { getLog ( ) . info ( \"Skipping execution because of 'skip' option\" ) ; } return ; } * addModulesArgument ( \"-inpath\" , ajcOptions , weaveDependencies , null , addModulesArgument ( \"-aspectpath\" , ajcOptions , aspectLibraries , getAdditionalAspectPaths ( ) , *", "del_tokens": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * addModulesArgument ( \"-inpath\" , ajcOptions , weaveDependencies , null , addModulesArgument ( \"-aspectpath\" , ajcOptions , aspectLibraries , getAdditionalAspectPaths ( ) , *", "commit_type": "fix"}
{"commit_tokens": ["fixed", "lower", "case", "issue", "in", "file", "name", "IoWriterFactory"], "add_tokens": "private final IoWriterFactory writerFactory ; public ObjectJavaIoWriter ( final IoWriterFactory writerFactory ) {", "del_tokens": "private final IOWriterFactory writerFactory ; public ObjectJavaIoWriter ( final IOWriterFactory writerFactory ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "implementation", "to", "onNewTraces", "inside", "LynxPresenter"], "add_tokens": "private static final int BUFFER_SIZE = 1000 ; this . traceBuffer = new TraceBuffer ( BUFFER_SIZE ) ; updateTraceBuffer ( traces ) ; List < Trace > tracesToNotify = getCurrentTraces ( ) ; view . showTraces ( tracesToNotify ) ; } private void updateTraceBuffer ( List < Trace > traces ) { traceBuffer . add ( traces ) ; } private List < Trace > getCurrentTraces ( ) { return traceBuffer . getTraces ( ) ;", "del_tokens": "this . traceBuffer = new TraceBuffer ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "the", "Xeger", "utils", "to", "the", "base", "consumer", "module", "so", "they", "can", "be", "shared", "by", "all", "consumers"], "add_tokens": "package xeger ; import dk . brics . automaton . RegExp ; import java . util . Random ;", "del_tokens": "package nl . flotsam . xeger ; import dk . brics . automaton . RegExp ; import java . util . Random ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "horrible", "two", "-", "days", "-", "I", "m", "-", "getting", "-", "crazy", "bug", "in", "position", "()", "that", "had", "major", "impact", "on", "index", "construction"], "add_tokens": "if ( newPosition < position + avail && newPosition >= position - pos ) {", "del_tokens": "if ( newPosition <= position + avail && newPosition >= position - pos ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "PUT", "DATA", "decoder", "."], "add_tokens": "new GetChallengeAPDUDecoder ( ) , new PutDataAPDUDecoder ( )", "del_tokens": "new GetChallengeAPDUDecoder ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "CBl", "-", "48", ":", "Fail", "copying", "an", "encrypted", "DB"], "add_tokens": "protected static void copy ( @ NonNull DatabaseConfiguration config , int algorithm , byte [ ] encryptionKey ) algorithm , encryptionKey ) ;", "del_tokens": "public static void copy ( @ NonNull DatabaseConfiguration config ) Preconditions . checkArgNotNull ( path , \"path\" ) ; Preconditions . checkArgNotNull ( name , \"name\" ) ; Preconditions . checkArgNotNull ( config , \"config\" ) ; C4Constants . EncryptionAlgorithm . NONE , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "test", "case", ".", "I", "m", "assuming", "that", "we", "changed", "something", "that", "made", "this", "test"], "add_tokens": "import java . util . Collections ; import hudson . model . Node . Mode ; import hudson . model . Slave ; import hudson . slaves . DumbSlave ; import hudson . slaves . RetentionStrategy ; import org . jvnet . hudson . test . HudsonTestCase ; public class SSHLauncherTest extends HudsonTestCase { public void testConfigurationRoundtrip ( ) throws Exception { SSHLauncher launcher = new SSHLauncher ( \"localhost\" , 123 , \"test\" , \"pass\" , \"xyz\" , \"def\" ) ; DumbSlave slave = new DumbSlave ( \"slave\" , \"dummy\" , createTmpDir ( ) . getPath ( ) , \"1\" , Mode . NORMAL , \"\" , launcher , RetentionStrategy . NOOP , Collections . EMPTY_LIST ) ; hudson . addNode ( slave ) ; submit ( createWebClient ( ) . getPage ( slave , \"configure\" ) . getFormByName ( \"config\" ) ) ; Slave n = ( Slave ) hudson . getNode ( \"slave\" ) ; assertNotSame ( n , slave ) ; assertNotSame ( n . getLauncher ( ) , launcher ) ; assertEqualDataBoundBeans ( n . getLauncher ( ) , launcher ) ; }", "del_tokens": "public class SSHLauncherTest extends TestCase {", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "and", "made", "some", "cleanup"], "add_tokens": "import junit . framework . Assert ;", "del_tokens": "import java . util . HashSet ; import java . util . Set ; import junit . framework . Assert ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "validation", "-", "api", "workaround", "as", "it", "s", "been", "fixed", "upstream", "for", "long", "."], "add_tokens": "File [ ] files = new File [ resolved . size ( ) + 1 ] ;", "del_tokens": "// FIXME gwt 2.3.0 don't declare dependency on javax.validation, should be fix in next release File [ ] files = new File [ resolved . size ( ) + 1 + 2 ] ; files [ i ++ ] = getArtifact ( \"javax.validation\" , \"validation-api\" ) . getFile ( ) ; files [ i ++ ] = getArtifact ( \"javax.validation\" , \"validation-api\" , \"sources\" ) . getFile ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "javadoc", "locale", ".", "Removed", "slf4j"], "add_tokens": "", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Moved", "highlighter", "related", "classes", "to", "new", "package", "."], "add_tokens": "package org . opoo . press . highlighter ;", "del_tokens": "package org . opoo . press . converter ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "the", "model", "to", "have", "unique", "usernames"], "add_tokens": "System . out . println ( \"[DEBUG] GET authentication \" + authentication ) ; Authentication authentication = authenticationRepository . findByUsername ( username ) ; if ( authentication . getUsername ( ) . equals ( username ) && authentication . getPassword ( ) . equals ( password ) ) { flag = true ;", "del_tokens": "import java . util . List ; List < Authentication > authenticationList = authenticationRepository . findByUsernameAndPassword ( username , password ) ; if ( authenticationList . size ( ) == 1 ) { if ( authenticationList . get ( 0 ) . getUsername ( ) . equals ( username ) && authenticationList . get ( 0 ) . getPassword ( ) . equals ( password ) ) { flag = true ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "v1", "resources", ".", "social", "button", "is", "now", "configurable"], "add_tokens": "SocialView sv = new SocialView ( this , lockBus , config , SocialView . Mode . List ) ;", "del_tokens": "SocialView sv = new SocialView ( this , lockBus , config , SocialView . Mode . Grid ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "with", "type", "mappings"], "add_tokens": "public UnnamedConstructorConverterSerialization ( @ ParcelPropertyConverter ( StringWriterConverter . class ) @ ASTClassFactory . ASTParameterName ( \"value\" ) String value ) {", "del_tokens": "public UnnamedConstructorConverterSerialization ( @ ParcelPropertyConverter ( StringWriterConverter . class ) @ ASTClassFactory . ASTParameterName ( \"value\" ) String value ) {", "commit_type": "update"}
{"commit_tokens": ["used", "setup", "and", "teardown", "methods", "for", "srcDir", "and", "targetDir"], "add_tokens": "* ( C ) Copyright IBM Corporation 2019.", "del_tokens": "* ( C ) Copyright IBM Corporation 2018.", "commit_type": "use"}
{"commit_tokens": ["Added", "mapping", "methods", "for", "currency", "namespaces", "."], "add_tokens": "* This method maps the given { @ link CurrencyUnit } to another * { @ link CurrencyUnit } with the given target namespace . * @ param unit * The source unit , never { @ code null } . Hereby the unit will * match the namespace as defined by { @ link # getNamespace ( ) } . * @ param targetNamespace * the target namespace , never { @ code null } . * @ return The mapped { @ link CurrencyUnit } , or null . public CurrencyUnit map ( CurrencyUnit unit , String targetNamespace ) ;", "del_tokens": "import javax . money . AmountAdjuster ; * Get the { @ link AmountAdjuster } to be used for rounding amounts of the * given currency instance . * @ param currency * The currency * @ return the { @ link AmountAdjuster } to be applied , or null for determining * rounding based on the * { @ link CurrencyUnit # getDefaultFractionDigits ( ) } . public AmountAdjuster getRounding ( CurrencyUnit currency ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "modifiers", "of", "several", "methods", "in", "HttpSenderThread", ".", "java", "for", "unit", "testing"], "add_tokens": "void upload ( ) { boolean tryFlush ( ) { uploadEvent ( ev ) ; void uploadEvent ( QueueEvent ev ) throws IOException , ClientException {", "del_tokens": "private void upload ( ) { private boolean tryFlush ( ) { upload ( ev ) ; private void upload ( QueueEvent ev ) throws IOException , ClientException {", "commit_type": "change"}
{"commit_tokens": ["Add", "some", "more", "tests", "to", "increase", "coverage", "of", "MockRESTServer"], "add_tokens": "private static int getNextFreePort ( ) throws IOException {", "del_tokens": "private static final int getNextFreePort ( ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["fix", "logging", "of", "initial", "eureka", "status"], "add_tokens": "logger . info ( \"Registering application {} with eureka with status {}\" , instanceConfig . getAppname ( ) , instanceConfig . getInitialStatus ( ) ) ;", "del_tokens": "logger . info ( \"Registering application {} with eureka with status UP\" , instanceConfig . getAppname ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "OS", "family", "enum", "value", "iPhone", "OS", "to", "iOS", "to", "work", "with", "the"], "add_tokens": "IOS ( \"iOS\" ) ,", "del_tokens": "IOS ( \"iPhone OS\" ) ,", "commit_type": "change"}
{"commit_tokens": ["added", "dynamic", "huffman", "and", "PairHMM", "edits"], "add_tokens": "if ( operSys . contains ( \"nix\" ) || operSys . contains ( \"nux\" ) || operSys . contains ( \"aix\" ) ) isMAC = false ; else isMAC = true ;", "del_tokens": "if ( operSys . contains ( \"mac\" ) ) isMAC = true ; else isMAC = false ;", "commit_type": "add"}
{"commit_tokens": ["Use", "different", "User", "-", "Agent", "strings", "for", "V1", "and", "V2", "clients", "."], "add_tokens": "private static final String USER_AGENT_ID = \"OfficialDropboxJavaSDKv2\" ; response = DbxRequestUtil . startPostRaw ( requestConfig , USER_AGENT_ID , host , path , body , headers ) ; response = DbxRequestUtil . startPostRaw ( requestConfig , USER_AGENT_ID , host , path , body , headers ) ; headers = DbxRequestUtil . addUserAgentHeader ( headers , requestConfig , USER_AGENT_ID ) ;", "del_tokens": "response = DbxRequestUtil . startPostRaw ( requestConfig , host , path , body , headers ) ; response = DbxRequestUtil . startPostRaw ( requestConfig , host , path , body , headers ) ; headers = DbxRequestUtil . addUserAgentHeader ( headers , requestConfig ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "NPE", "in", "VerifyHostnameSetIT", "(", "missing", "logger", ")"], "add_tokens": "import org . apache . maven . plugin . logging . Log ; import org . junit . Assert ; import org . junit . Test ; import org . mockito . Mockito ; Log log = Mockito . mock ( Log . class ) ; dockerProvider . setLogger ( log ) ;", "del_tokens": "import org . junit . Assert ; import org . junit . Test ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "auto", "closeable", "into", "base", "interfaces"], "add_tokens": "public interface EventStoreSync extends WritableEventStoreSync , ReadableEventStoreSync {", "del_tokens": "public interface EventStoreSync extends AutoCloseable , WritableEventStoreSync , ReadableEventStoreSync {", "commit_type": "move"}
{"commit_tokens": ["Changed", "access", "failure", "log", "message", "to", "be", "formatted", "for", "log4j", "instead", "of", "slf4j", "."], "add_tokens": "String controllerClassName = getControllerClass ( ) . getName ( ) ; Logger . debug ( \"Deadbolt: Access failure on [%s]\" , controllerClassName ) ; controllerClassName ) ;", "del_tokens": "Class < ? extends Controller > controllerClass = getControllerClass ( ) ; Logger . error ( \"Access failure on [{}]\" , controllerClass . getName ( ) ) ; Class . class ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "null", "behavior", "test", "to", "reflect", "shaded", "collection", "dependencies"], "add_tokens": "assertNull ( result . sub ) ; assertEquals ( result . subSomething , 5 ) ; // Value not overriden since this is shaded by S1.sub // being null", "del_tokens": "assertNull ( result . sub . items ) ; assertEquals ( result . subSomething , 0 ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "unit", "tests", "for", "LaunchRunner", "and", "fix", "bugs", "in", "LaunchRunner"], "add_tokens": "// invoke the post launch sequence try { if ( ! launcher . postLaunch ( packedPlan ) ) { throw new RuntimeException ( launcher . getClass ( ) . getName ( ) + \" failed \" ) ; } } catch ( RuntimeException e ) { statemgr . deleteExecutionState ( topologyName ) ; statemgr . deleteTopology ( topologyName ) ;", "del_tokens": "// invoke the post launch sequence if ( ! launcher . postLaunch ( packedPlan ) ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "toString", "method", "on", "route"], "add_tokens": "* < p / > * < p / > * @ param uri The whole encoded uri . @ Override public String toString ( ) { return \"{\" + String . valueOf ( getHttpMethod ( ) ) + \" \" + uri + \" => \" + controller . getClass ( ) . toString ( ) + \"#\" + controllerMethod . getName ( ) + \"}\" ; }", "del_tokens": "* * * * * @ param uri * The whole encoded uri .", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "Registration", "Form", "and", "prettify", "the", "site"], "add_tokens": ". antMatchers ( \"/\" ) . permitAll ( )", "del_tokens": ". antMatchers ( \"/index.jsp\" ) . permitAll ( )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "was", "throwing", "an", "UnsupportedOperationException", "."], "add_tokens": "isRevisionEntity ( ) , getProxyEntity ( ) , PropertyTagInContentSpecWrapper . class ) ;", "del_tokens": "isRevisionEntity ( ) , PropertyTagInContentSpecWrapper . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "package", "name", "typo", "in", "tests"], "add_tokens": "package com . github . adamyork . wiremock . transformer ;", "del_tokens": "package com . github . adamyork . wiremock . trasnformer ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "about", "interfaces", "changes", "that", "need", "to", "happen", "."], "add_tokens": "import com . openxc . measurements . NoValueException ; public void testGetMocked ( ) throws UnrecognizedMeasurementTypeException , NoValueException , RemoteException { // TODO see the VehicleService for how this needs to change // TODO ah, we actually need to send this value to the // RemoteVehicleListener since that's the one that will be caching the // last value received service . mRemoteListener . receiveNumerical ( VehicleSpeed . class . getName ( ) , 42 ) ; assertEquals ( measurement . getValue ( ) , 42 ) ;", "del_tokens": "public void testGetMocked ( ) throws UnrecognizedMeasurementTypeException {", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "Spring", "MVC", "example", "to", "reflect", "the", "version", "I", "used", "/", "created", "during", "my", "JetBrains", "webinar", "."], "add_tokens": "package com . structurizr . example . spring . mysystem . service ;", "del_tokens": "package com . structurizr . example . spring . mvc ;", "commit_type": "update"}
{"commit_tokens": ["Add", "/", "api", "/", "servlet", "to", "list", "of", "services", "servlet", "paths", "that", "do", "not", "redirect"], "add_tokens": "else if ( path . startsWith ( \"/services/\" ) || path . startsWith ( \"/REST/\" ) || path . startsWith ( \"/asset/\" ) || path . startsWith ( \"/api/\" ) ) {", "del_tokens": "else if ( path . startsWith ( \"/services/\" ) || path . startsWith ( \"/REST/\" ) || path . startsWith ( \"/asset/\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "handling", "of", "positive", "decimal", "values", "in", "OpenImmo"], "add_tokens": "// OpenImmo specifies positive decimal values including 0 if ( value == null || value . compareTo ( BigDecimal . ZERO ) < 0 ) // OpenImmo specifies positive integer values excluding 0", "del_tokens": "if ( value == null || value . compareTo ( BigDecimal . ZERO ) < 1 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "thread", "factory", "to", "SchedulerServiceHolder"], "add_tokens": "new ThreadPoolBasedScheduler ( Configuration . getSchedulerCoreSize ( ) , new ThreadFactory ( ) { private final AtomicInteger threadNumber = new AtomicInteger ( 0 ) ; @ Override public Thread newThread ( final Runnable r ) { final Thread t = new Thread ( r , \"ob1k-scheduler-service-pool-thread-\" + threadNumber . getAndIncrement ( ) ) ; t . setDaemon ( true ) ; return t ; } } ) ;", "del_tokens": "new ThreadPoolBasedScheduler ( Configuration . getSchedulerCoreSize ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "example", "with", "a", "fragment"], "add_tokens": "import android . app . Fragment ; @ HensonNavigable ( model = SampleModelActivity . Model . class ) public class SampleModelActivity extends Activity { public static final String TAG_SAMPLE_FRAGMENT = \"SampleFragment\" ; @ Override protected void onCreate ( Bundle savedInstanceState ) { @ Override protected void onResume ( ) { super . onResume ( ) ; Fragment sampleFragment = getFragmentManager ( ) . findFragmentByTag ( TAG_SAMPLE_FRAGMENT ) ; if ( sampleFragment == null ) { getFragmentManager ( ) . beginTransaction ( ) . add ( new SampleFragment ( ) , TAG_SAMPLE_FRAGMENT ) . commit ( ) ; } }", "del_tokens": "@ HensonNavigable ( model = SampleModelActivity . Model . class ) public class SampleModelActivity extends Activity { @ Override protected void onCreate ( Bundle savedInstanceState ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "CSS", "guard", "with", "multiple", "CSS", "selectors", "."], "add_tokens": "int idx = builder . lastIndexOf ( \" when\" ) ; if ( idx < 0 || ( idx + 5 != builder . length ( ) && builder . indexOf ( \" when \" ) < 0 ) ) { if ( isSelector ( builder ) || ! reader . nextIsMixinParam ( true ) ) { builder . append ( ch ) ; break ; }", "del_tokens": "if ( ( isSelector ( builder ) || ! reader . nextIsMixinParam ( true ) ) && builder . indexOf ( \" when \" ) < 0 ) { builder . append ( ch ) ; break ; int idx = name . indexOf ( ' ' ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "constructors", "in", "list", "part", "of", "queries"], "add_tokens": "import java . util . ArrayList ; import java . util . Arrays ; import com . mysema . query . grammar . types . Constructor ; _append ( ops . select ( ) ) ; List < Expr < ? > > sqlSelect = new ArrayList < Expr < ? > > ( ) ; for ( Expr < ? > selectExpr : select ) { if ( selectExpr instanceof Constructor ) { // transforms constructor arguments into individual select // expressions sqlSelect . addAll ( Arrays . < Expr < ? > > asList ( ( ( Constructor < ? > ) selectExpr ) . getArgs ( ) ) ) ; } else { sqlSelect . add ( selectExpr ) ; } } _append ( \", \" , sqlSelect ) ;", "del_tokens": "_append ( ops . select ( ) ) . _append ( \", \" , select ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "adding", "file", "comments", "in", "generated", "classes"], "add_tokens": "private final String fileComment ; this . fileComment = builder . fileComment ; JavaFile . Builder javaFileBuilder = JavaFile . builder ( packageName , casesClass ) ; if ( fileComment != null ) { javaFileBuilder . addFileComment ( fileComment ) ; } javaFileBuilder . addFileComment ( \"\\nGenerated by Motif. Do Not Edit!\\n\" ) ; JavaFile javaFile = javaFileBuilder . build ( ) ; private String fileComment ; public Builder addFileComment ( String fileComment ) { this . fileComment = fileComment ; return this ; }", "del_tokens": "JavaFile javaFile = JavaFile . builder ( packageName , casesClass ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["removes", "GetSnapshotListBridgeParameters", "references", ":", "not", "necessary", "."], "add_tokens": "import javax . ws . rs . QueryParam ; public Response list ( @ QueryParam ( \"host\" ) String host ) { this . snapshotRepo . findBySourceHost ( host ) ;", "del_tokens": "import org . duracloud . snapshot . dto . bridge . GetSnapshotListBridgeParameters ; public Response list ( GetSnapshotListBridgeParameters params ) { this . snapshotRepo . findBySourceHost ( params . getHost ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "to", "avoid", "problems", "when", "no", "data", "is", "available", "."], "add_tokens": "m_data = varData ; byte [ ] data = varData . getByteArray ( offset ) ; if ( data != null ) {", "del_tokens": "if ( offset >= 0 ) { m_data = varData ; byte [ ] data = varData . getByteArray ( offset ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "offset", "and", "length", "to", "KoreanToken"], "add_tokens": "public CharSequence stem ( CharSequence text ) {", "del_tokens": "import com . twitter . penguin . korean . TwitterKoreanProcessor . KoreanSegment ; import com . twitter . penguin . korean . TwitterKoreanProcessor . KoreanSegmentWithText ; public KoreanStemmer . StemmedTextWithTokens stem ( CharSequence text ) { / * * * Tokenize into KoreanSegments , which includes the indices * * @ param text Input text . * @ return A list of KoreanSegments . * / public List < KoreanSegment > tokenizeWithIndex ( CharSequence text ) { return JavaConversions . seqAsJavaList ( TwitterKoreanProcessor . tokenizeWithIndex ( text ) ) ; } / * * * Tokenize into KoreanSegmentWithText , which includes * the stemmed text and the KoreanSegments * * @ param text Input text . * @ return KoreanSegmentWithText ( text , KoreanSegments ) * / public KoreanSegmentWithText tokenizeWithIndexWithStemmer ( CharSequence text ) { return TwitterKoreanProcessor . tokenizeWithIndexWithStemmer ( text ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "id", "s", "to", "some", "of", "the", "main", "nodes", "in", "order", "to", "more", "easily", "manipulate", "them"], "add_tokens": "writer . writeln ( \"id: 'main-lookAt',\" ) ; writer . writeln ( \"id: 'main-camera',\" ) ; writer . writeln ( \"id: 'main-renderer',\" ) ; writer . writeln ( \"id: 'sun-light',\" ) ;", "del_tokens": "writer . writeln ( \"id: 'sunlight',\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "type", "from", "int", "to", "long"], "add_tokens": "JavaPairRDD < String , Long > noOfTransactionPair = bitcoinBlocksRDD . mapToPair ( new PairFunction < Tuple2 < BytesWritable , BitcoinBlock > , String , Long > ( ) { public Tuple2 < String , Long > call ( Tuple2 < BytesWritable , BitcoinBlock > tupleBlock ) { return new Tuple2 < String , Long > ( \"No of transactions: \" , new Long ( tupleBlock . _2 ( ) . getTransactions ( ) . length ) ) ; JavaPairRDD < String , Long > totalCount = noOfTransactionPair . reduceByKey ( new Function2 < Long , Long , Long > ( ) { public Long call ( Long a , Long b ) {", "del_tokens": "JavaPairRDD < String , Integer > noOfTransactionPair = bitcoinBlocksRDD . mapToPair ( new PairFunction < Tuple2 < BytesWritable , BitcoinBlock > , String , Integer > ( ) { public Tuple2 < String , Integer > call ( Tuple2 < BytesWritable , BitcoinBlock > tupleBlock ) { return new Tuple2 < String , Integer > ( \"No of transactions: \" , tupleBlock . _2 ( ) . getTransactions ( ) . length ) ; JavaPairRDD < String , Integer > totalCount = noOfTransactionPair . reduceByKey ( new Function2 < Integer , Integer , Integer > ( ) { public Integer call ( Integer a , Integer b ) {", "commit_type": "change"}
{"commit_tokens": ["Removed", "an", "unwanted", "system", "out"], "add_tokens": "final long totalMillisTaken = afterMillis - beforeMillis ; if ( totalMillisTaken > 100 ) { Assert . fail ( testName . getMethodName ( ) + \" took \" + totalMillisTaken + \"ms\" ) ;", "del_tokens": "if ( ( afterMillis - beforeMillis ) > 100 ) { Assert . fail ( testName . getMethodName ( ) + \" took \" + ( afterMillis - beforeMillis ) + \"ms\" ) ; System . out . println ( beforeMillis ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "getMessage", "when", "waitSeconds", "==", "0", "to", "not", "show", "log"], "add_tokens": "String msg ; if ( waitSeconds == 0 ) { msg = mbTextElement . getHtmlText ( true ) ; } else { msg = mbTextElement . waitTextToRender ( waitSeconds ) ; } return msg ;", "del_tokens": "return mbTextElement . waitTextToRender ( waitSeconds ) ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "sure", "TimeInterval", "can", "handle", "ranges", "with", "only", "one", "side", "."], "add_tokens": "return ( start == null || start . compareTo ( instant ) <= 0 ) && ( end == null || end . compareTo ( instant ) >= 0 ) ;", "del_tokens": "return start . compareTo ( instant ) <= 0 && end . compareTo ( instant ) >= 0 ;", "commit_type": "make"}
{"commit_tokens": ["removes", "duplicative", "TextChunk", "merging", "code", ";", "it", "s", "covered", "also", "in", "the", "parent", "class", "(", "which", "gets", "called", "hence", "the", "duplication", ")"], "add_tokens": "", "del_tokens": "if ( this . compareTo ( other ) < 0 ) { this . textElements . addAll ( other . textElements ) ; } else { this . textElements . addAll ( 0 , other . textElements ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Remove", "unnecessary", "dependency", "on", "Guice"], "add_tokens": "import com . facebook . swift . codec . metadata . MetadataErrors . Monitor ; private final MetadataErrors . Monitor monitor ; this ( MetadataErrors . NULL_MONITOR ) ;", "del_tokens": "import com . facebook . swift . codec . metadata . Problems . Monitor ; private final Problems . Monitor monitor ; this ( Problems . NULL_MONITOR ) ;", "commit_type": "remove"}
{"commit_tokens": ["improved", "validness", "check", "using", "constant", "math", "model", "if", "none", "is", "found", "to", "be", "valid", "(", "which", "happens", "for", "constant", "data", ")"], "add_tokens": "return Math . abs ( parameters [ 0 ] ) >= 0.001 && rSquared != Double . NEGATIVE_INFINITY && ! Double . isNaN ( rSquared ) ;", "del_tokens": "return Math . abs ( parameters [ 0 ] ) >= 0.001 ;", "commit_type": "improve"}
{"commit_tokens": ["added", "powermock", "to", "mock", "the", "hostname", "returned", "for", "testing", "."], "add_tokens": "import org . junit . runner . RunWith ; import org . powermock . api . mockito . PowerMockito ; import org . powermock . core . classloader . annotations . PrepareForTest ; import org . powermock . modules . junit4 . PowerMockRunner ; import static org . mockito . Mockito . mock ; import static org . mockito . Mockito . when ; @ RunWith ( PowerMockRunner . class ) @ PrepareForTest ( HostAwareGraphiteReporterFactory . class ) private HostAwareGraphiteReporterFactory buildReporter ( String hostName ) throws UnknownHostException { InetAddress localHost = mock ( InetAddress . class ) ; when ( localHost . getHostName ( ) ) . thenReturn ( hostName ) ; PowerMockito . mockStatic ( InetAddress . class ) ; when ( InetAddress . getLocalHost ( ) ) . thenReturn ( localHost ) ; return new HostAwareGraphiteReporterFactory ( ) ; String hostName = \"myhostname\" ; HostAwareGraphiteReporterFactory reporterFactory = buildReporter ( hostName ) ;", "del_tokens": "private HostAwareGraphiteReporterFactory reporterFactory = new HostAwareGraphiteReporterFactory ( ) ; private String expectedHostName ( ) throws UnknownHostException { return InetAddress . getLocalHost ( ) . getHostName ( ) ; String hostName = expectedHostName ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "sample", "to", "demonstrate", "custom", "timeout", "."], "add_tokens": "import com . github . andrewlord1990 . snackbarbuilder . callback . SnackbarCallback ; samples . put ( \"Custom timeout\" , new OnClickListener ( ) { @ Override public void onClick ( View v ) { new SnackbarBuilder ( SampleActivity . this ) . message ( \"This has a custom timeout\" ) . duration ( 10000 ) . build ( ) . show ( ) ; } } ) ; for ( String sample : samples . keySet ( ) ) { adapter . add ( sample ) ;", "del_tokens": "import com . github . andrewlord1990 . snackbarbuilder . SnackbarCallback ; import java . util . Map . Entry ; for ( Entry < String , OnClickListener > sample : samples . entrySet ( ) ) { adapter . add ( sample . getKey ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "couple", "of", "failing", "unittests"], "add_tokens": "assertEquals ( \"No suitable driver found for jdbc:eobjects-dummy:foobar\" , e . getMessage ( ) ) ;", "del_tokens": "assertEquals ( \"No suitable driver\" , e . getMessage ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "for", "lenient", "date", "parsing", "(", "the", "thread", "-", "safety", "fix", "for", "this", "issue", "was", "made", "earlier", ")", ".", "I", "also", "fixed", "the", "stacktrace", "of", "the", "exceptions", "so", "they", "print", "the", "classname", "(", "which", "is", "the", "normal", "behaviour", "of", "exceptions", ")", "."], "add_tokens": "return String . format ( \"%s: %s\\noffending processor=%s\\ncontext=%s\" , getClass ( ) . getName ( ) , getMessage ( ) , offendingProcessor , csvContext ) ;", "del_tokens": "return String . format ( \"%s\\noffending processor=%s\\ncontext=%s\" , getMessage ( ) , offendingProcessor , csvContext ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "duplicate", "operation", "for", "removing", "task", "from", "a", "queue"], "add_tokens": "logger . debug ( \"Task with id \" + tuple . getId ( ) + \" not found to remove\" ) ;", "del_tokens": "exceptions . add ( new TaskQueueException ( \"Task with id \" + tuple . getId ( ) + \" not found to remove\" ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "port", "bindings", "configuration", "option"], "add_tokens": "private Set < String > portBindings ; public Set < String > getPortBindings ( ) { return portBindings ; } public void setPortBindings ( final Set < String > portBindings ) { this . portBindings = portBindings ; } public boolean hasNoPortBindings ( ) { return portBindings == null || portBindings . isEmpty ( ) ; } public boolean hasPortBindings ( ) { return ! hasNoPortBindings ( ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "monitoring", "capability", "for", "missed", "server", "list", "update", "cycles", "."], "add_tokens": "protected volatile boolean serverRefreshEnabled = false ; serverRefreshEnabled = true ; if ( ! serverRefreshEnabled ) { return 0 ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["changed", "MovieDbException", "to", "store", "also", "the", "url", "causing", "the", "exception"], "add_tokens": "import java . net . URL ; private final String url ; public MovieDbException ( final MovieDbExceptionType exceptionType , final String response , final String url ) { this . url = url ; public MovieDbException ( final MovieDbExceptionType exceptionType , final String response , final URL url ) { super ( ) ; this . exceptionType = exceptionType ; this . response = response ; this . url = url . toExternalForm ( ) ; } public MovieDbException ( final MovieDbExceptionType exceptionType , final String response , final String url , final Throwable cause ) { this . url = url ; public MovieDbException ( final MovieDbExceptionType exceptionType , final String response , final URL url , final Throwable cause ) { super ( cause ) ; this . exceptionType = exceptionType ; this . response = response ; this . url = url . toExternalForm ( ) ; } public String getUrl ( ) { return url ; }", "del_tokens": "public MovieDbException ( final MovieDbExceptionType exceptionType , final String response ) { public MovieDbException ( final MovieDbExceptionType exceptionType , final String response , final Throwable cause ) {", "commit_type": "change"}
{"commit_tokens": ["Changed", "the", "socket", ".", "io", "lib"], "add_tokens": "import com . github . nkzawa . emitter . Emitter ; public class MiniRoxCallback implements Emitter . Listener { @ Override public void call ( Object ... args ) { synchronized ( this ) {", "del_tokens": "import io . socket . IOAcknowledge ; import io . socket . IOCallback ; import io . socket . SocketIOException ; import org . json . JSONObject ; public class MiniRoxCallback implements IOCallback { // private static final Logger LOGGER = LoggerFactory.getLogger(MiniRoxCallback.class); @ Override public void onMessage ( JSONObject json , IOAcknowledge ack ) { } @ Override public void onMessage ( String data , IOAcknowledge ack ) { } @ Override public void onError ( SocketIOException socketIOException ) { synchronized ( this ) { @ Override public void onDisconnect ( ) { synchronized ( this ) { this . notify ( ) ; } } @ Override public void onConnect ( ) { synchronized ( this ) { this . notify ( ) ; } } @ Override public void on ( String event , IOAcknowledge ack , Object ... args ) { }", "commit_type": "change"}
{"commit_tokens": ["Added", "security", "section", "to", "reference", "manual", "+", "new", "constructor", "for", "AgentServlet", "."], "add_tokens": "// Restrictor to use as given in the constructor private Restrictor restrictor ; / * * * No argument constructor , used e . g . by an servlet * descriptor when creating the servlet out of web . xml * / public AgentServlet ( ) { this ( null ) ; } / * * * Constructor taking a restrictor to use * * @ param pRestrictor restrictor to use or < code > null < / code > if the restrictor * should be created in the default way ( { @ link # createRestrictor ( Map , LogHandler ) } ) * / public AgentServlet ( Restrictor pRestrictor ) { restrictor = pRestrictor ; } if ( restrictor == null ) { restrictor = createRestrictor ( config , logHandler ) ; } else { logHandler . info ( \"Using custom access restriction provided by \" + restrictor ) ; } backendManager = new BackendManager ( config , logHandler , restrictor ) ;", "del_tokens": "backendManager = new BackendManager ( config , logHandler , createRestrictor ( config , logHandler ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "addView", "exception", "when", "reuse", "native", "layout"], "add_tokens": "if ( v . getParent ( ) == null ) { LayoutParams layoutParams = new LayoutParams ( view . getComLayoutParams ( ) . mLayoutWidth , view . getComLayoutParams ( ) . mLayoutHeight ) ; addView ( v , layoutParams ) ; } else { LayoutParams layoutParams = v . getLayoutParams ( ) ; layoutParams . width = view . getComLayoutParams ( ) . mLayoutWidth ; layoutParams . height = view . getComLayoutParams ( ) . mLayoutHeight ; v . setLayoutParams ( layoutParams ) ; } if ( v . getParent ( ) == null ) { LayoutParams layoutParams = new LayoutParams ( view . getComLayoutParams ( ) . mLayoutWidth , view . getComLayoutParams ( ) . mLayoutHeight ) ; addView ( v , layoutParams ) ; } else { LayoutParams layoutParams = v . getLayoutParams ( ) ; layoutParams . width = view . getComLayoutParams ( ) . mLayoutWidth ; layoutParams . height = view . getComLayoutParams ( ) . mLayoutHeight ; v . setLayoutParams ( layoutParams ) ; }", "del_tokens": "LayoutParams layoutParams = new LayoutParams ( view . getComLayoutParams ( ) . mLayoutWidth , view . getComLayoutParams ( ) . mLayoutHeight ) ; addView ( v , layoutParams ) ; LayoutParams layoutParams = new LayoutParams ( view . getComLayoutParams ( ) . mLayoutWidth , view . getComLayoutParams ( ) . mLayoutHeight ) ; addView ( v , layoutParams ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "b2c", "Oidc", "login", "Configurer", "."], "add_tokens": "import com . microsoft . azure . spring . autoconfigure . b2c . AADB2COidcLoginConfigurer ; private final AADB2COidcLoginConfigurer configurer ; public WebSecurityConfiguration ( AADB2COidcLoginConfigurer configurer ) { this . configurer = configurer ; . anyRequest ( ) . authenticated ( ) . apply ( configurer ) ;", "del_tokens": "import com . microsoft . azure . spring . autoconfigure . b2c . AADB2CAuthorizationRequestResolver ; import com . microsoft . azure . spring . autoconfigure . b2c . AADB2CLogoutSuccessHandler ; import com . microsoft . azure . spring . autoconfigure . b2c . AADB2CProperties ; private AADB2CProperties properties ; private AADB2CLogoutSuccessHandler logoutSuccessHandler ; private AADB2CAuthorizationRequestResolver requestResolver ; public WebSecurityConfiguration ( AADB2CProperties properties , AADB2CLogoutSuccessHandler logoutSuccessHandler , AADB2CAuthorizationRequestResolver requestResolver ) { this . properties = properties ; this . logoutSuccessHandler = logoutSuccessHandler ; this . requestResolver = requestResolver ; . anyRequest ( ) . authenticated ( ) . and ( ) // Expire the token from b2c side. . logout ( ) . logoutSuccessHandler ( logoutSuccessHandler ) . oauth2Login ( ) // Customize oauth2 processing url from b2c configuration. . loginProcessingUrl ( properties . getLoginProcessingUrl ( ) ) // Customize oauth2 authorization request. . authorizationEndpoint ( ) . authorizationRequestResolver ( requestResolver ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "lambdas", "instead", "of", "anonymous", "inner", "classes", "."], "add_tokens": "return segments . stream ( ) . mapToInt ( s -> s . length ( ) ) . sum ( ) ;", "del_tokens": "import java . util . function . ToIntFunction ; return segments . stream ( ) . mapToInt ( new ToIntFunction < StyledString < S > > ( ) { @ Override public int applyAsInt ( StyledString < S > t ) { return t . length ( ) ; } } ) . sum ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "file", "name", "lower", "case"], "add_tokens": "public class ConditionalSequenceFlowTest {", "del_tokens": "public class ConditionalSequenceflowTest {", "commit_type": "fix"}
{"commit_tokens": ["add", "fix", "for", "Issue", "6"], "add_tokens": "Map < String , Class < ? > > beanDefinitions = getAllBeanClasses ( ) ; for ( Entry < String , Class < ? > > entry : beanDefinitions . entrySet ( ) ) { Class < ? > beanClass = entry . getValue ( ) ; Method [ ] methods = beanClass . getMethods ( ) ; private Map < String , Class < ? > > getAllBeanClasses ( ) { Map < String , Class < ? > > beanClasses = new HashMap < String , Class < ? > > ( ) ; beanClasses . put ( beanName , currentCtx . getType ( beanName ) ) ; return beanClasses ;", "del_tokens": "Map < String , Object > beanDefinitions = getAllBeanDefinitions ( ) ; for ( Entry < String , Object > entry : beanDefinitions . entrySet ( ) ) { Object bean = entry . getValue ( ) ; Method [ ] methods = bean . getClass ( ) . getMethods ( ) ; private Map < String , Object > getAllBeanDefinitions ( ) { Map < String , Object > beanDefinitions = new HashMap < String , Object > ( ) ; beanDefinitions . put ( beanName , currentCtx . getBean ( beanName ) ) ; return beanDefinitions ;", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "check", "when", "converting", "Integer", "to", "String"], "add_tokens": "Integer cId = diff . getContributorId ( ) ; String contributorId = cId == null ? null : \"'\" + cId . toString ( ) + \"'\" ;", "del_tokens": "String contributorId = diff . getContributorId ( ) . toString ( ) ; if ( contributorId != null ) { contributorId = \"'\" + contributorId + \"'\" ; }", "commit_type": "add"}
{"commit_tokens": ["made", "some", "changes", "in", "command", "-", "line", "processing"], "add_tokens": "return StringSupport . split ( line , \"()\" , \"\" ) . toArray ( new String [ 0 ] ) ; return StringSupport . split ( line , \", \" , \"\\\"\" ) . toArray ( new String [ 0 ] ) ; return StringSupport . split ( line , \".\" , \"\\\"\" ) . toArray ( new String [ 0 ] ) ; //TODO decent exceptions", "del_tokens": "return ( String [ ] ) StringSupport . split ( line , \"()\" , \"\" ) . toArray ( new String [ 0 ] ) ; return ( String [ ] ) StringSupport . split ( line , \", \" , \"\\\"\" ) . toArray ( new String [ 0 ] ) ; return ( String [ ] ) StringSupport . split ( line , \".\" , \"\\\"\" ) . toArray ( new String [ 0 ] ) ;", "commit_type": "make"}
{"commit_tokens": ["Improved", "Iban", "country", "code", "validation"], "add_tokens": "throw new IbanFormatException ( \"Iban country code must contain upper case letters\" ) ; Assert . notNull ( CountryCode . getByCode ( countryCode ) , \"Iban contains non existing country code.\" ) ; throw new IbanFormatException ( \"Iban length can't be less than \" + MIN_IBAN_SIZE ) ; return BbanStructure . forCountry ( CountryCode . getByCode ( countryCode ) ) ;", "del_tokens": "throw new IllegalArgumentException ( \"Iban country code must contain upper case letters\" ) ; throw new IllegalArgumentException ( \"Iban length can't be less than \" + MIN_IBAN_SIZE ) ; return BbanStructure . forCountry ( CountryCode . valueOf ( countryCode ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "default", "value", "for", "properties"], "add_tokens": "import java . util . StringTokenizer ; private static final String PIPE_SEPARATOR = \"|\" ; StringTokenizer keyTokenizer = new StringTokenizer ( pattern . substring ( pos + 2 , endName ) , PIPE_SEPARATOR ) ; String key = keyTokenizer . nextToken ( ) ; String defaultValue = null ; if ( keyTokenizer . hasMoreTokens ( ) ) { defaultValue = keyTokenizer . nextToken ( ) . trim ( ) ; } this . appenders . add ( new KeyAppender ( key , defaultValue ) ) ;", "del_tokens": "String key = pattern . substring ( pos + 2 , endName ) ; this . appenders . add ( new KeyAppender ( key ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "Refresh", "failure", "logic", "and", "add", "ErrorTypes", "for", "easier", "checking", "of", "different", "exceptions", "."], "add_tokens": "public boolean onException ( BoxRequest request , BoxHttpResponse response , BoxException ex ) throws BoxException . RefreshFailure { } else if ( refreshResponse . getException ( ) != null ) { if ( refreshResponse . getException ( ) instanceof BoxException . RefreshFailure ) { throw ( BoxException . RefreshFailure ) refreshResponse . getException ( ) ; } else { return false ; } } catch ( InterruptedException e ) { BoxLogUtils . e ( \"oauthRefresh\" , \"Interrupted Exception\" , e ) ; } catch ( ExecutionException e1 ) { BoxLogUtils . e ( \"oauthRefresh\" , \"Interrupted Exception\" , e1 ) ;", "del_tokens": "public boolean onException ( BoxRequest request , BoxHttpResponse response , BoxException ex ) throws BoxException { } else if ( refreshResponse . getException ( ) != null ) { throw refreshResponse . getException ( ) ; } catch ( Exception e ) { if ( e . getCause ( ) instanceof BoxException ) { throw ( BoxException ) e . getCause ( ) ; }", "commit_type": "update"}
{"commit_tokens": ["Improve", "error", "message", "when", "creating", "a", "too", "long", "OtpErlangAtom"], "add_tokens": "+ maxAtomLength + \" characters: \" + atom ) ;", "del_tokens": "+ maxAtomLength + \" characters\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["making", "more", "of", "that", "test"], "add_tokens": "import static org . junit . Assert . assertEquals ; import static org . junit . Assert . fail ; // GrammarRules rules = r.toGrammarRulesData(); GrammarRules rules = SequiturFactory . series2SequiturRules ( data , 3 , 2 , 3 , NumerosityReductionStrategy . NONE , 0.5 ) ;", "del_tokens": "import static org . junit . Assert . * ; import net . seninp . gi . repair . RePairFactory ; import net . seninp . gi . repair . RePairGrammar ; import net . seninp . jmotif . sax . SAXException ; GrammarRules rules = r . toGrammarRulesData ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "compilation", "printing", "to", "standard", "java", "vm", "."], "add_tokens": "return Lists . newArrayList ( \"-Xbatch\" , \"-XX:+UseSerialGC\" , \"-XX:+PrintCompilation\" ) ;", "del_tokens": "return Lists . newArrayList ( \"-Xbatch\" , \"-XX:-UseSerialGC\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "configurable", "ordering", "for", "properties", "parameters", "and", "responses"], "add_tokens": "import com . google . common . collect . Ordering ; protected Comparator < String > propertyOrdering ; this . propertyOrdering = swagger2MarkupConfig . getPropertyOrdering ( ) ; Set < String > propertyNames ; if ( this . propertyOrdering == null ) propertyNames = new LinkedHashSet < > ( ) ; else propertyNames = new TreeSet < > ( this . propertyOrdering ) ; propertyNames . addAll ( type . getProperties ( ) . keySet ( ) ) ; for ( String propertyName : propertyNames ) { Property property = type . getProperties ( ) . get ( propertyName ) ;", "del_tokens": "for ( Map . Entry < String , Property > propertyEntry : type . getProperties ( ) . entrySet ( ) ) { Property property = propertyEntry . getValue ( ) ; String propertyName = propertyEntry . getKey ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "MAJ", "-", "740", "+", "version", "change"], "add_tokens": "return \"1.5.4\" ;", "del_tokens": "return \"1.5.3\" ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "wrong", "DN", "in", "User", "/", "Group", "Listing"], "add_tokens": "String value , identifyer ; value = LdapHelper . getIdentifyerValueFromDN ( inputs [ count ] ) ; identifyer = LdapHelper . getIdentifyerFromDN ( inputs [ count ] ) ; assertEquals ( value , outputs [ count ] ) ; assertEquals ( identifyer , keys [ count ] ) ;", "del_tokens": "String result ; result = LdapHelper . getIdentifyerFromDN ( inputs [ count ] , keys [ count ] ) ; assertEquals ( result , outputs [ count ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "jdk", "installer", "parameter", "to", "SSHConnector"], "add_tokens": "import hudson . tools . JDKInstaller ; * Field jdk * / public final JDKInstaller jdkInstaller ; / * * * @ see SSHLauncher # SSHLauncher ( String , int , String , String , String , String , String ) this ( port , username , password , privatekey , jvmOptions , javaPath , null ) ; } / * * * @ see SSHLauncher # SSHLauncher ( String , int , String , String , String , String , String , JDKInstaller ) * / public SSHConnector ( int port , String username , String password , String privatekey , String jvmOptions , String javaPath , JDKInstaller jdkInstaller ) { this . jdkInstaller = jdkInstaller ; return new SSHLauncher ( host , port , username , Secret . toString ( password ) , privatekey , jvmOptions , javaPath , jdkInstaller ) ;", "del_tokens": "* Constructor SSHLauncher creates a new SSHLauncher instance . * * @ param port The port to connect on . * @ param username The username to connect as . * @ param password The password to connect with . * @ param privatekey The ssh privatekey to connect with . * @ param jvmOptions return new SSHLauncher ( host , port , username , Secret . toString ( password ) , privatekey , jvmOptions , javaPath ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "efficient", "string", "for", "object", "keys", ";", "this", "should", "save", "massive", "amount", "of", "memory", "but", "costs", "in", "terms", "of", "some", "operations", "being", "slightly", "more", "expensive", "."], "add_tokens": "", "del_tokens": "import java . util . Set ; public void shouldSortOnKey ( ) { JsonObject unsorted = object ( ) . put ( \"c\" , \"c\" ) . put ( \"a\" , \"a\" ) . put ( \"b\" , \"b\" ) . get ( ) ; JsonObject sorted = unsorted . sort ( ) ; Set < String > ks = sorted . keySet ( ) ; int i = 0 ; String [ ] keys = new String [ ] { \"a\" , \"b\" , \"c\" } ; for ( String k : ks ) { Assert . assertTrue ( k . equals ( keys [ i ++ ] ) ) ; } }", "commit_type": "use"}
{"commit_tokens": ["fixes", "to", "init", "and", "more", "unit", "tests", "for", "timeseries"], "add_tokens": "// if any zpath overrides are set in properties, they must start with / if ( zpathOverrideCount == 0 ) { if ( zpathValidateFailed ) { System . err . println ( \"When overriding zk zpaths, with properties like druid.zk.paths.*Path \" + \"the znode path must start with '/' (slash) ; problem overrides:\" ) ; System . err . print ( sbErrors . toString ( ) ) ; }", "del_tokens": "// if any zpath overrides are set in properties, all must be set, and they must start with / boolean zpathOverridesNotAbs = false ; zpathOverridesNotAbs = true ; zpathOverridesNotAbs = true ; if ( zpathOverridesNotAbs ) { System . err . println ( \"When overriding zk zpaths, with properties like druid.zk.paths.*Path \" + \"the znode path must start with '/' (slash) ; problem overrides:\" ) ; System . err . print ( sbErrors . toString ( ) ) ; } if ( zpathOverrideCount > 0 ) { if ( zpathOverrideCount < SUB_PATH_PROPS . length ) { zpathValidateFailed = true ; System . err . println ( \"When overriding zk zpaths, with properties of form druid.zk.paths.*Path \" + \"all must be overridden together; missing overrides:\" ) ; for ( int i = 0 ; i < SUB_PATH_PROPS . length ; i ++ ) { String val = props . getProperty ( SUB_PATH_PROPS [ i ] ) ; if ( val == null ) { System . err . println ( \" \" + SUB_PATH_PROPS [ i ] ) ; } } } else { // proper overrides // do not prefix with property druid.zk.paths.base ; // fallthru } } else { // no overrides", "commit_type": "fix"}
{"commit_tokens": ["Added", "utf", "-", "8", "support", "to", "iotils"], "add_tokens": "return new String ( readBytes ( in ) , \"UTF-8\" ) ;", "del_tokens": "return new String ( readBytes ( in ) ) ;", "commit_type": "add"}
{"commit_tokens": ["made", "test", "more", "robust", "to", "environment", "changes"], "add_tokens": "+ \"~\\\\[.+/:na]$\" ) ) ;", "del_tokens": "+ \"~\\\\[test/:na]$\" ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "the", "Java", "DSL", "to", "support", "body", "matching", "in", "a", "similar", "way", "to", "ruby", "pact"], "add_tokens": ". body ( ConsumerPactBuilder . jsonBody ( ) . booleanValue ( \"responsetest\" , true ) ) assertEquals ( new ConsumerClient ( url ) . get ( \"/\" ) , \"{\\\"responsetest\\\":true,\\\"responseMatchers\\\":{}}\" ) ;", "del_tokens": ". body ( \"{\\\"responsetest\\\":true}\" ) assertEquals ( new ConsumerClient ( url ) . get ( \"/\" ) , \"{\\\"responsetest\\\":true}\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "code", "for", "extracting", "the", "current", "namespace", "."], "add_tokens": "String currentNamespace ; currentNamespace = ( String ) currentContext . get ( \"namespace\" ) ; public String getNamespace ( ) { return currentNamespace ; }", "del_tokens": "System . out . println ( auth + \" for \" + name ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "ability", "to", "output", "to", "ini", "format", "that", "should", "be", "compatible", "with", "Python", "s", "ConfigParser"], "add_tokens": "import com . davidbracewell . collection . Sorting ; import java . io . BufferedWriter ; public static Resource toPythonConfigParser ( @ NonNull Resource output ) throws IOException { return toPythonConfigParser ( \"default\" , output ) ; } public static Resource toPythonConfigParser ( @ NonNull String sectionName , @ NonNull Resource output ) throws IOException { try ( BufferedWriter writer = new BufferedWriter ( output . writer ( ) ) ) { writer . write ( \"[\" ) ; writer . write ( sectionName ) ; writer . write ( \"]\\n\" ) ; for ( Map . Entry < String , String > e : Sorting . sortMapEntries ( getInstance ( ) . properties , Map . Entry . comparingByKey ( ) ) ) { writer . write ( e . getKey ( ) ) ; writer . write ( \" : \" ) ; writer . write ( e . getValue ( ) . replaceAll ( \"\\n\" , \"\\n\\t\\t\\t\" ) ) ; writer . write ( \"\\n\" ) ; } } return output ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "marker", "listeners", "sync", "issue"], "add_tokens": "synchronized ( markerListeners ) { for ( RequestListener . MarkerListener markerListener : markerListeners ) { markerListener . onMarker ( marker , args ) ; } synchronized ( errorListeners ) { errorListeners . clear ( ) ; } synchronized ( responseListeners ) { responseListeners . clear ( ) ; } if ( ! this . response . intermediate ) { responseListeners . clear ( ) ; } if ( ! this . response . intermediate ) { synchronized ( errorListeners ) { errorListeners . clear ( ) ; }", "del_tokens": "for ( RequestListener . MarkerListener markerListener : markerListeners ) { markerListener . onMarker ( marker , args ) ; responseListeners . clear ( ) ; synchronized ( errorListeners ) { errorListeners . clear ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "version", "and", "buildnumber", "extraction", "from", "jar"], "add_tokens": "import java . net . URL ; private String version ; private String buildNumber ; Class _myClass = this . getClass ( ) ; String _classPath = _myClass . getResource ( _myClass . getSimpleName ( ) + \".class\" ) . toString ( ) ; if ( _classPath != null && _classPath . startsWith ( \"jar\" ) ) { String _manifestUrl = _classPath . substring ( 0 , _classPath . lastIndexOf ( \"!\" ) + 1 ) + \"/META-INF/MANIFEST.MF\" ; Manifest m = new Manifest ( new URL ( _manifestUrl ) . openStream ( ) ) ; version = _version = m . getMainAttributes ( ) . getValue ( \"Implementation-Version\" ) ; buildNumber = _buildNumber = m . getMainAttributes ( ) . getValue ( \"Implementation-Build\" ) ; } public String getVersion ( ) { return version ; } public String getBuildNumber ( ) { return buildNumber ; }", "del_tokens": "static final String META_INF_MANIFEST_MF = \"/META-INF/MANIFEST.MF\" ; InputStream in = this . getClass ( ) . getResourceAsStream ( META_INF_MANIFEST_MF ) ; Manifest m = new Manifest ( in ) ; _version = m . getMainAttributes ( ) . getValue ( \"Implementation-Version\" ) ; _buildNumber = m . getMainAttributes ( ) . getValue ( \"Implementation-Build\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "SDK", "validation", "for", "Vars"], "add_tokens": "notifyExperimentsUpdated ( ) ; JSONObject var = vars . getJSONObject ( i ) ;", "del_tokens": "JSONObject var = ( JSONObject ) vars . get ( i ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "javadoc", "of", "pressSpinnerItem", "()", "."], "add_tokens": "* @ param itemIndex the index of the spinner item to be pressed relative to the current selected item . * A Negative number moves up on the spinner , positive down", "del_tokens": "* @ param itemIndex the index of the spinner item to be pressed", "commit_type": "update"}
{"commit_tokens": ["Remove", "knowledge", "of", "phones", "and", "tablets", "."], "add_tokens": "result . addTest ( explodeTest ( testCaseClass , method , isTablet ) ) ;", "del_tokens": "import com . squareup . instrumentation . constraints . PhoneOnly ; import com . squareup . instrumentation . constraints . TabletOnly ; if ( ! shouldSkipMethod ( method , isTablet ) ) { result . addTest ( explodeTest ( testCaseClass , method , isTablet ) ) ; } private boolean shouldSkipMethod ( Method method , boolean isTablet ) { boolean tabletOnly = method . isAnnotationPresent ( TabletOnly . class ) || method . getDeclaringClass ( ) . isAnnotationPresent ( TabletOnly . class ) ; boolean phoneOnly = method . isAnnotationPresent ( PhoneOnly . class ) || method . getDeclaringClass ( ) . isAnnotationPresent ( PhoneOnly . class ) ; return ( phoneOnly && isTablet ) || ( tabletOnly && ! isTablet ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Added", "more", "Assertions", "and", "checkComparison", "to", "EquivalenceTester"], "add_tokens": "public final class EquivalenceTester private EquivalenceTester ( ) { } @ SuppressWarnings ( { \"ObjectEqualsNull\" } ) for ( Collection < ? > congruenceClass : equivalenceClasses ) { for ( Collection < ? > congruenceClass : equivalenceClasses ) { public static < T extends Comparable < T >> void checkComparison ( Collection < T > ... equivalenceClasses ) { check ( equivalenceClasses ) ; for ( int i = 0 ; i < equivalenceClasses . length ; i ++ ) { Collection < T > lesserBag = equivalenceClasses [ i ] ; for ( int j = i + 1 ; j < equivalenceClasses . length ; j ++ ) { Collection < T > greaterBag = equivalenceClasses [ j ] ; checkComparison ( lesserBag , greaterBag ) ; } } } private static < T extends Comparable < T >> void checkComparison ( Collection < T > lesserBag , Collection < T > greaterBag ) { for ( T lesser : lesserBag ) { for ( T greater : greaterBag ) { Assertions . assertLessThan ( lesser , greater ) ; Assertions . assertGreaterThan ( greater , lesser ) ; } } }", "del_tokens": "public class EquivalenceTester for ( Collection < ? extends Object > congruenceClass : equivalenceClasses ) { for ( Collection < ? extends Object > congruenceClass : equivalenceClasses ) {", "commit_type": "add"}
{"commit_tokens": ["Improved", "some", "the", "names", "."], "add_tokens": "RuntimeCounter counter = new RuntimeCounter ( ) ; // register our object jmxServer . register ( counter ) ; jmxServer . unregister ( counter ) ; @ JmxOperation ( description = \"Reset our start time to the current millis\" ) public String resetStartTime ( ) { return \"Timer has been reset to current millis\" ;", "del_tokens": "RuntimeCounter lookupCache = new RuntimeCounter ( ) ; // register our lookupCache object defined below jmxServer . register ( lookupCache ) ; jmxServer . unregister ( lookupCache ) ; @ JmxOperation ( description = \"Restart our timer\" ) public String restartTimer ( ) { return \"Timer has been restarted\" ;", "commit_type": "improve"}
{"commit_tokens": ["addes", "CollisionRaster", ".", "lineIsTransparent", "to", "improved", "padding"], "add_tokens": "final CollisionRaster rasterOfCollidable = collidable . getCollisionRaster ( ) ; final int yOfCollidable = y - position . y ; if ( rasterOfCollidable . lineIsTransparent ( yOfCollidable ) ) { continue ; } ! rasterOfCollidable . isTransparent ( x - position . x , yOfCollidable ) ) {", "del_tokens": "! collidable . getCollisionRaster ( ) . isTransparent ( x - position . x , y - position . y ) ) {", "commit_type": "add"}
{"commit_tokens": ["add", "auto", "-", "close", "to", "LookupManager"], "add_tokens": "public interface LookupManager extends AutoCloseable { / * * * Close the Lookup * The LookupManager support JDK - 7 try - with - resource * @ throws ServiceException * / @ Override void close ( ) throws ServiceException ; / * * * If the Lookup Manager is started * @ return true if the manager is started , or false if not * @ throws ServiceException * / boolean isStarted ( ) throws ServiceException ;", "del_tokens": "public interface LookupManager {", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "new", "ecmascript", "service"], "add_tokens": "windowManager = new WindowManager ( services , getVersionForService ( serviceList , \"window-manager\" ) ) ; / * if ( findServiceNamed ( serviceList , \"ecmascript\" ) != null ) { String ecmascriptVersion = getVersionForService ( serviceList , \"ecmascript\" ) ; debugger = new EcmascriptService ( services , ecmascriptVersion ) ; } else { * / String esdbgVersion = getVersionForService ( serviceList , \"ecmascript-debugger\" ) ; if ( VersionUtil . compare ( esdbgVersion , \"6.0\" ) >= 0 ) debugger = new EcmaScriptDebugger6 ( services , esdbgVersion ) ; else debugger = new EcmaScriptDebugger ( services , esdbgVersion ) ; /* } */ exec = new OperaExec ( services , getVersionForService ( serviceList , \"exec\" ) ) ;", "del_tokens": "windowManager = new WindowManager ( services , getVersionForService ( serviceList , \"window-manager\" ) ) ; String esdbgVersion = getVersionForService ( serviceList , \"ecmascript-debugger\" ) ; if ( VersionUtil . compare ( esdbgVersion , \"6.0\" ) >= 0 ) debugger = new EcmaScriptDebugger6 ( services , esdbgVersion ) ; else debugger = new EcmaScriptDebugger ( services , esdbgVersion ) ; exec = new OperaExec ( services , getVersionForService ( serviceList , \"exec\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "non", "zero", "exit", "listener", "that", "throws", "exception"], "add_tokens": "this . exitCode = exitCode ;", "del_tokens": "exitCode = exitCode ;", "commit_type": "add"}
{"commit_tokens": ["added", "sum", "and", "count", "aggregation"], "add_tokens": "avg ( \"avg\" ) , /** Sum.*/ sum ( \"sum\" ) , /** Count. */ count ( \"count\" ) ;", "del_tokens": "avg ( \"avg\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "ReactiveSocketFactory", ".", "callAndWait"], "add_tokens": "import java . util . NoSuchElementException ; import java . util . concurrent . CompletableFuture ; CompletableFuture < R > future = new CompletableFuture < > ( ) ; future . complete ( reactiveSocket ) ; future . completeExceptionally ( t ) ; future . completeExceptionally ( new NoSuchElementException ( \"Sequence contains no elements\" ) ) ; return future . join ( ) ;", "del_tokens": "import java . util . concurrent . CountDownLatch ; import java . util . concurrent . atomic . AtomicReference ; AtomicReference < R > reference = new AtomicReference < > ( ) ; AtomicReference < Throwable > error = new AtomicReference < > ( ) ; CountDownLatch latch = new CountDownLatch ( 1 ) ; reference . set ( reactiveSocket ) ; error . set ( t ) ; latch . countDown ( ) ; latch . countDown ( ) ; if ( error . get ( ) != null ) { throw new RuntimeException ( error . get ( ) ) ; } else { return reference . get ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "handling", "of", "missing", "field", "values", "in", "SimpleSetPredicate"], "add_tokens": "return null ;", "del_tokens": "throw new MissingFieldException ( simpleSetPredicate . getField ( ) , simpleSetPredicate ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "getSqlType", "for", "suitable", "JDBC", "access", "."], "add_tokens": "* Supports { @ link java . time . LocalDateTime } and { @ link java . time . LocalDate } of JSR - 310. * * @ see org . springframework . jdbc . core . namedparam . BeanPropertySqlParameterSource @ Override public int getSqlType ( String paramName ) { int sqlType = super . getSqlType ( paramName ) ; if ( sqlType != TYPE_UNKNOWN ) { return sqlType ; } Class < ? > propType = null ; if ( privateFields . contains ( paramName ) ) { propType = beanWrapper . getPropertyType ( paramName ) ; } else if ( publicFeilds . containsKey ( paramName ) ) { propType = publicFeilds . get ( paramName ) . getType ( ) ; } if ( propType == null ) { return TYPE_UNKNOWN ; } return Jsr310JdbcUtils . getSqlType ( propType ) ; }", "del_tokens": "* Supports { @ link java . time . LocalDateTime } and { @ link java . time . LocalDate } of JSR - 310 // TODO: Override getSqlType", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "border", "to", "an", "integration", "test"], "add_tokens": "\"<style:style style:name=\\\"tcs\\\" style:family=\\\"table-cell\\\" style:parent-style-name=\\\"Default\\\">\" + \"<style:paragraph-properties fo:margin-bottom=\\\"12pt\\\" fo:margin-left=\\\"13pt\\\" \" + \"fo:margin-right=\\\"11pt\\\" fo:margin-top=\\\"10pt\\\"/>\" + \"</style:style>\" , @ Test public void testDefaultCellStyle ( ) throws IOException { final StringBuilder sb = new StringBuilder ( ) ; TableCellStyle . DEFAULT_CELL_STYLE . appendXMLRepresentation ( this . util , sb ) ; DomTester . assertEquals ( \"<style:style style:name=\\\"Default\\\" style:family=\\\"table-cell\\\">\" + \"<style:table-cell-properties style:vertical-align=\\\"top\\\"/>\" + \"<style:paragraph-properties fo:text-align=\\\"start\\\" fo:margin=\\\"0mm\\\"/>\" + \"</style:style>\" , sb . toString ( ) ) ; }", "del_tokens": "\"<style:style style:name=\\\"tcs\\\" style:family=\\\"table-cell\\\" style:parent-style-name=\\\"Default\\\">\" + \"<style:paragraph-properties fo:margin-bottom=\\\"12pt\\\" fo:margin-left=\\\"13pt\\\" \" + \"fo:margin-right=\\\"11pt\\\" fo:margin-top=\\\"10pt\\\"/>\" + \"</style:style>\" ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "warning", "about", "deprecated", "RuleSetFactory", "constructor", "."], "add_tokens": "import net . sourceforge . pmd . RulesetsFactoryUtils ; RuleSetFactory ruleSetFactory = RulesetsFactoryUtils . defaultFactory ( ) ;", "del_tokens": "RuleSetFactory ruleSetFactory = new RuleSetFactory ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "reliability", "features", "from", "seed", "-", "to", "-", "seed", "communication", "interfaces", "."], "add_tokens": "publisher . publish ( message ) ;", "del_tokens": "publisher . publish ( message , new Handler < AsyncResult < Void > > ( ) { @ Override public void handle ( AsyncResult < Void > result ) { if ( result . failed ( ) ) { future . setFailure ( result . cause ( ) ) ; } } } ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "background", "-", "position", "processing", "to", "report", "error", "correctly"], "add_tokens": "int assigned = 0 ; { { assigned ++ ; } } // no values could be used if ( assigned == 0 ) else if ( assigned == 2 ) iteration . inc ( ) ;", "del_tokens": "if ( list . isEmpty ( ) ) // copy element if only one present else if ( list . size ( ) == 1 ) list . add ( 1 , list . get ( 0 ) ) ; else if ( list . size ( ) == 2 ) iteration . inc ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "possible", "to", "have", "a", "different", "location", "that", "the", "dataset", "URI"], "add_tokens": "import org . aksw . rdfunit . io . TripleDereferenceReader ; import org . aksw . rdfunit . io . TripleReader ; import org . aksw . rdfunit . io . TripleReaderFactory ; private final TripleReader dumpReader ; this ( prefix , uri , new TripleDereferenceReader ( uri ) , null ) ; } public DumpSource ( String prefix , String uri , String location ) { this ( prefix , uri , new TripleDereferenceReader ( location ) , null ) ; } public DumpSource ( String prefix , String uri , TripleReader dumpReader ) { this ( prefix , uri , dumpReader , null ) ; this ( prefix , uri , new TripleDereferenceReader ( uri ) , schemata ) ; } public DumpSource ( String prefix , String uri , TripleReader dumpReader , List < SchemaSource > schemata ) { this . dumpReader = dumpReader ; dumpReader . read ( model ) ;", "del_tokens": "this ( prefix , uri , null ) ; model . read ( getUri ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "JavaDoc", "notice", "on", "Apache", "s", "Common", "-", "Codec", "(", "re", ")", "usage"], "add_tokens": "* < p / > * This class contains code from the Apache Common - Codec project", "del_tokens": "* * @ version $ Id $ * @ since 1.1", "commit_type": "add"}
{"commit_tokens": ["Updated", "tools", "&", "Lollipop", "Constructor"], "add_tokens": "public CircularImageView ( Context context , AttributeSet attrs , int defStyleAttr ) { super ( context , attrs , defStyleAttr ) ; init ( context , attrs , defStyleAttr ) ; } @ TargetApi ( Build . VERSION_CODES . LOLLIPOP ) public CircularImageView ( Context context , AttributeSet attrs , int defStyleAttr , int defStyleRes ) { super ( context , attrs , defStyleAttr , defStyleRes ) ; init ( context , attrs , defStyleAttr ) ;", "del_tokens": "public CircularImageView ( Context context , AttributeSet attrs , int defStyle ) { super ( context , attrs , defStyle ) ; init ( context , attrs , defStyle ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "againLocate", "if", "we", "use", "findElement", "in", "SearchContext"], "add_tokens": "try { List < WebElement > elements = finds ( by ) ; List < WebElement > result = new ArrayList < > ( elements . size ( ) ) ; for ( int i = 0 ; i < elements . size ( ) ; i ++ ) { WebElement element = elements . get ( i ) ; result . add ( OurWebElementFactory . wrap ( this , element , by , i ) ) ; } return result ; } catch ( UndeclaredThrowableException e ) { againLocate ( ) ; return findElements ( by ) ; try { return OurWebElementFactory . wrap ( this , getWrappedWebElement ( ) . findElement ( by ) , by ) ; } catch ( UndeclaredThrowableException e ) { againLocate ( ) ; return findElement ( by ) ; }", "del_tokens": "List < WebElement > elements = finds ( by ) ; List < WebElement > result = new ArrayList < > ( elements . size ( ) ) ; for ( int i = 0 ; i < elements . size ( ) ; i ++ ) { WebElement element = elements . get ( i ) ; result . add ( OurWebElementFactory . wrap ( element , by , i ) ) ; return result ; return OurWebElementFactory . wrap ( getWrappedWebElement ( ) . findElement ( by ) , by ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "JavaDoc", "elements", "."], "add_tokens": "* Get the address on which this device was seen . * * @ return the network address from which the device is communicating . * * @ return the millisecond timestamp at which we last received an announcement from this device . * * @ return the device name . * * @ return the player number found in the device announcement packet . * * @ return the device 's Ethernet address. * * @ return the data sent by the device to announce its presene on the network .", "del_tokens": "* The address on which this device was seen .", "commit_type": "add"}
{"commit_tokens": ["add", "Unsafe", "test", "and", "benchmark"], "add_tokens": "protected static void eq ( Object [ ] a1 , Object [ ] a2 ) { protected static void eq ( Object o1 , Object o2 ) { protected static void yes ( Boolean expr , String msg , Object ... args ) { protected static void yes ( Boolean expr ) { protected static void no ( Boolean expr , String msg , Object ... args ) { protected static void no ( Boolean expr ) { protected static void fail ( String msg , Object ... args ) {", "del_tokens": "protected void eq ( Object [ ] a1 , Object [ ] a2 ) { protected void eq ( Object o1 , Object o2 ) { protected void yes ( Boolean expr , String msg , Object ... args ) { protected void yes ( Boolean expr ) { protected void no ( Boolean expr , String msg , Object ... args ) { protected void no ( Boolean expr ) { protected void fail ( String msg , Object ... args ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "async", "poll", "stuff", "for", "register", "template", "and", "assign", "ip", "into", "vlan"], "add_tokens": "if ( matches . getLength ( ) == 0 ) { matches = doc . getElementsByTagName ( \"jobid\" ) ; //4.1 } Document responseDoc = provider . waitForJob ( doc , ASSOCIATE_IP_ADDRESS ) ; if ( responseDoc != null ) { NodeList nodeList = responseDoc . getElementsByTagName ( \"ipaddress\" ) ; if ( nodeList . getLength ( ) > 0 ) { Node ipAddress = nodeList . item ( 0 ) ; NodeList attributes = ipAddress . getChildNodes ( ) ; for ( int i = 0 ; i < attributes . getLength ( ) ; i ++ ) { Node attribute = attributes . item ( i ) ; String tmpname = attribute . getNodeName ( ) . toLowerCase ( ) ; String value ; if ( attribute . getChildNodes ( ) . getLength ( ) > 0 ) { value = attribute . getFirstChild ( ) . getNodeValue ( ) ; } else { value = null ; } if ( tmpname . equalsIgnoreCase ( \"id\" ) ) { id = value ; break ; } } } }", "del_tokens": "provider . waitForJob ( doc , ASSOCIATE_IP_ADDRESS ) ;", "commit_type": "fix"}
{"commit_tokens": ["implemented", "clear", "()", "and", "refactoring"], "add_tokens": "class PropertiesManager implements Reloadable , Listable , Modifiable { public void reload ( ) { writeLock . lock ( ) ; try { clear ( ) ; load ( ) ; } finally { writeLock . unlock ( ) ; } } public void clear ( ) { writeLock . lock ( ) ; try { properties . clear ( ) ; } finally { writeLock . unlock ( ) ; } }", "del_tokens": "class PropertiesManager implements Reloadable , Listable { return load ( false ) ; } public void reload ( ) { load ( true ) ; } private Properties load ( boolean clear ) { if ( clear ) properties . clear ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "parameter", "index", "to", "context", ".", "This", "will", "be", "useful", "if", "a", "custom", "factory", "wants", "to", "change", "behavior", "based", "on", "annotations", "on", "parameters", "."], "add_tokens": "int index = 0 ; parameterInjectors . add ( createParameterInjector ( key , member , index ++ ) ) ; Key < T > key , Member member , int index ) throws MissingDependencyException { ExternalContext . newInstance ( member , index , key , this ) ;", "del_tokens": "parameterInjectors . add ( createParameterInjector ( key , member ) ) ; Key < T > key , Member member ) throws MissingDependencyException { ExternalContext . newInstance ( member , key , this ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "scala", "handling", "of", "primitive", "types"], "add_tokens": "Arrays . asList ( \"boolean\" , \"byte\" , \"char\" , \"int\" , \"long\" , \"short\" , \"double\" , \"float\" ) ) ;", "del_tokens": "Arrays . asList ( \"byte\" , \"char\" , \"int\" , \"long\" , \"short\" , \"double\" , \"float\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "compatible", "with", "java", "7"], "add_tokens": "import java . util . * ; for ( InterfaceAddress address : networkInterface . getInterfaceAddresses ( ) ) { if ( address == null ) continue ; InetAddress broadcast = address . getBroadcast ( ) ; if ( broadcast != null ) { broadcastList . add ( broadcast ) ; } }", "del_tokens": "import java . util . ArrayList ; import java . util . Enumeration ; import java . util . List ; import java . util . Objects ; networkInterface . getInterfaceAddresses ( ) . stream ( ) . map ( InterfaceAddress :: getBroadcast ) . filter ( Objects :: nonNull ) . forEach ( broadcastList :: add ) ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "migration", "job", "test", "to", "throw", "checked", "exception", "instead", "of", "unchecked"], "add_tokens": "protected Map < String , JsonNode > getSourceDocuments ( ) throws SQLException { throw new SQLException ( \"forced failure for testing\" ) ; Assert . assertTrue ( outstandingThreadCount . intValue ( ) > ( JOB_COUNT / 5 ) ) ; protected Map < String , JsonNode > getSourceDocuments ( ) throws SQLException { throw new SQLException ( \"forced failure for testing\" ) ;", "del_tokens": "protected Map < String , JsonNode > getSourceDocuments ( ) { throw new RuntimeException ( \"forced failure for testing\" , new SQLException ( \"foo\" ) ) ; Assert . assertTrue ( outstandingThreadCount . intValue ( ) > ( JOB_COUNT / 2 ) ) ; protected Map < String , JsonNode > getSourceDocuments ( ) { throw new RuntimeException ( \"forced failure for testing\" , new SQLException ( \"foo\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["adding", "standard", "and", "custom", "dialogs"], "add_tokens": "* Copyright ( C ) 2008 - 2015 Carlos Eduardo Leite de Andrade public final class GUIImages { . getResource ( \"/images/jpr_clp_black.png\" ) ; . getResource ( \"/images/jpr_exp_black.png\" ) ; . getResource ( \"/images/jpr_clp_white.png\" ) ; . getResource ( \"/images/jpr_exp_white.png\" ) ; . getResource ( \"/images/jpr_calendar.png\" ) ; . getResource ( \"/images/jpr_link_hand.gif\" ) ; public static final URL WARNING = GUIImages . class . getResource ( \"/images/jpr_alert.png\" ) ; public static final URL INFORMATION = GUIImages . class . getResource ( \"/images/jpr_info.png\" ) ; public static final URL ERROR = GUIImages . class . getResource ( \"/images/jpr_error.png\" ) ; public static final URL QUESTION = GUIImages . class . getResource ( \"/images/jpr_question.png\" ) ;", "del_tokens": "* Copyright ( C ) 2008 - 2013 Carlos Eduardo Leite de Andrade public final class GUIImages { . getResource ( \"/images/jpr_clp_black.png\" ) ; . getResource ( \"/images/jpr_exp_black.png\" ) ; . getResource ( \"/images/jpr_clp_white.png\" ) ; . getResource ( \"/images/jpr_exp_white.png\" ) ; . getResource ( \"/images/jpr_calendar.png\" ) ; . getResource ( \"/images/jpr_link_hand.gif\" ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "setCursor", "and", "started", "DeepDive05", "w", "/", "Jim"], "add_tokens": "import org . teachingkidsprogramming . section04mastery . DeepDive04Mastery ; DeepDive04Mastery h = new DeepDive04Mastery ( ) ; DeepDive04Mastery . class . getMethod ( methodName ) . invoke ( h ) ; DeepDive04Mastery h = new DeepDive04Mastery ( ) ; DeepDive04Mastery . class . getMethod ( methodName ) . invoke ( h ) ;", "del_tokens": "import org . teachingkidsprogramming . section03ifs . DeepDive03Ifs ; DeepDive03Ifs h = new DeepDive03Ifs ( ) ; DeepDive03Ifs . class . getMethod ( methodName ) . invoke ( h ) ; DeepDive03Ifs h = new DeepDive03Ifs ( ) ; DeepDive03Ifs . class . getMethod ( methodName ) . invoke ( h ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "PanelHeader", "to", "add", "panel", "-", "title", "style", "when", "using", "HeadingPanel"], "add_tokens": "import com . google . gwt . user . client . ui . Widget ; if ( ( child instanceof Heading ) || ( child instanceof HeadingPanel ) ) {", "del_tokens": "import com . google . gwt . user . client . ui . Widget ; if ( ( child instanceof Heading ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "variables", ":", "messageTitle", "messageBody", "messageItems"], "add_tokens": "import java . util . List ; private final String messageTitle ; private final String messageBody ; private final List < String > messageBodyItems ; String hash , String messageTitle , String messageBody , List < String > messageBodyItems ) { this . messageTitle = checkNotNull ( messageTitle , \"messageTitle\" ) ; this . messageBody = checkNotNull ( messageBody , \"messageBody\" ) ; this . messageBodyItems = checkNotNull ( messageBodyItems , \"messageBodyItems\" ) ; public String getMessageBody ( ) { return messageBody ; } public List < String > getMessageBodyItems ( ) { return messageBodyItems ; } public String getMessageTitle ( ) { return messageTitle ; }", "del_tokens": "String hash ) {", "commit_type": "add"}
{"commit_tokens": ["added", "reuse", "option", "for", "root", "objects"], "add_tokens": "public static Monster getRootAsMonster ( ByteBuffer _bb ) { return getRootAsMonster ( _bb , new Monster ( ) ) ; } public static Monster getRootAsMonster ( ByteBuffer _bb , Monster obj ) { _bb . order ( ByteOrder . LITTLE_ENDIAN ) ; return ( obj . __init ( _bb . getInt ( _bb . position ( ) ) + _bb . position ( ) , _bb ) ) ; }", "del_tokens": "public static Monster getRootAsMonster ( ByteBuffer _bb ) { _bb . order ( ByteOrder . LITTLE_ENDIAN ) ; return ( new Monster ( ) ) . __init ( _bb . getInt ( _bb . position ( ) ) + _bb . position ( ) , _bb ) ; }", "commit_type": "add"}
{"commit_tokens": ["Made", "LoggerFormatter", ".", "getFullThrowableMsg", "public"], "add_tokens": "public static String getFullThrowableMsg ( Throwable t ) {", "del_tokens": "private static String getFullThrowableMsg ( Throwable t ) {", "commit_type": "make"}
{"commit_tokens": ["added", "and", "and", "through", "as", "conjunctions"], "add_tokens": "_defaultTimeZone = TimeZone . getDefault ( ) ;", "del_tokens": "_defaultTimeZone = TimeZone . getTimeZone ( \"America/New_York\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "hack", "to", "the", "test", "to", "by", "-", "pass", "datastore", "issue", "with", "projection", "query"], "add_tokens": "return new DatastoreServiceImpl ( options , options . datastore ( ) ) ;", "del_tokens": "import com . google . api . services . datastore . client . Datastore ; import com . google . api . services . datastore . client . DatastoreFactory ; import com . google . api . services . datastore . client . DatastoreOptions ; DatastoreOptions dsOptions = options . toDatastoreOptions ( ) ; Datastore datastore = DatastoreFactory . get ( ) . create ( dsOptions ) ; return new DatastoreServiceImpl ( options , datastore ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "CORE_SWITCH", "in", "AMF0", "Input", "to", "indicate", "that", "AMF3", "should", "be", "used", "instead", ".", "Set", "AMF3", "readMap", "to", "use", "AMF0", "readMap", "."], "add_tokens": "return DataTypes . CORE_SWITCH ;", "del_tokens": "break ;", "commit_type": "add"}
{"commit_tokens": ["add", "initial", "data", "explorer", "template"], "add_tokens": "@ RequestMapping ( \"/plugin/dataexplorer\" ) return \"dataexplorer\" ;", "del_tokens": "@ RequestMapping ( \"/explorer\" ) model . addAttribute ( \"message\" , \"Hey dude\" ) ; List < DataSet > dataSets = database . find ( DataSet . class ) ; if ( ! dataSets . isEmpty ( ) ) { model . addAttribute ( \"dataset\" , dataSets . get ( 0 ) . getName ( ) ) ; } return \"explorer\" ;", "commit_type": "add"}
{"commit_tokens": ["make", "stackoverflow", "questions", "not", "answered"], "add_tokens": "import java . util . stream . Collectors ; final List < Question > questions = client . getTaggedQuestions ( tag ) . getItems ( ) . stream ( ) . filter ( q -> ! q . isAnswered ( ) ) . collect ( Collectors . toList ( ) ) ;", "del_tokens": "final List < Question > questions = client . getTaggedQuestions ( tag ) . getItems ( ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "missing", "Content", "-", "Type", "header!"], "add_tokens": "import java . io . IOException ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["create", "instead", "of", "of", "for", "consistency"], "add_tokens": "public static Link create ( URI href , String rel ) { return create ( href , rel , Optional . < String > none ( ) , Optional . < Render > none ( ) ) ; public static Link create ( URI href , String rel , Optional < String > prompt ) { return create ( href , rel , prompt , Optional . < Render > none ( ) ) ; } public static Link create ( URI href , String rel , Optional < String > prompt , Optional < Render > render ) {", "del_tokens": "public static Link of ( URI href , String rel , Optional < String > prompt ) { return of ( href , rel , prompt , Optional . < Render > none ( ) ) ; public static Link of ( URI href , String rel , Optional < String > prompt , Optional < Render > render ) {", "commit_type": "create"}
{"commit_tokens": ["Updated", "names", "from", "goToActivity", "to", "navigateToActivity"], "add_tokens": "QuickUtils . misc . navigateToActivityByClassName ( MainActivity . this , StringClassname ) ;", "del_tokens": "QuickUtils . misc . goToActivityByClassName ( MainActivity . this , StringClassname ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "abstract", "parameter", "validation", "method"], "add_tokens": "import com . tikinou . schedulesdirect . core . exceptions . ValidationException ; protected abstract void validateParameters ( P parameters ) throws ValidationException ;", "del_tokens": "@ Override public void execute ( SchedulesDirectClient client ) { }", "commit_type": "add"}
{"commit_tokens": ["changed", "fields", "likes", "and", "shares", "from", "int", "to", "long"], "add_tokens": "protected Long likes = 0L ; protected Long shares = 0L ; public Long getLikes ( ) { public Long getShares ( ) { public void setLikes ( Long likes ) { public void setShares ( Long shares ) {", "del_tokens": "protected Integer likes = 0 ; protected Integer shares = 0 ; public int getLikes ( ) { public int getShares ( ) { public void setLikes ( int likes ) { public void setShares ( int shares ) {", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "Precondition", "checks", "."], "add_tokens": "Preconditions . checkNotNull ( src ) ; Preconditions . checkArgument ( len % COPY_STRIDE != 0 , \"Length (%d) is not a multiple of stride\" , len ) ; Preconditions . checkArgument ( destOffset % COPY_STRIDE != 0 , \"Dest offset (%d) is not stride aligned\" , destOffset ) ; // TODO maybe support Wrapper classes Preconditions . checkArgument ( type . isPrimitive ( ) , \"Only primitives are supported\" ) ; throw new IllegalArgumentException ( \"Type not supported yet: \" + type ) ; Preconditions . checkNotNull ( clazz ) ;", "del_tokens": "if ( src != null ) { throw new RuntimeException ( \"Src must be null\" ) ; } if ( len % COPY_STRIDE != 0 ) { throw new RuntimeException ( \"Length (\" + len + \") is not a multiple of stride\" ) ; } if ( destOffset % COPY_STRIDE != 0 ) { throw new RuntimeException ( \"Dest offset (\" + destOffset + \") is not stride aligned\" ) ; } if ( ! type . isPrimitive ( ) ) { // TODO maybe support Wrapper classes throw new RuntimeException ( \"Only primitives are supported\" ) ; } throw new RuntimeException ( \"Not built yet \" + type ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "custom", "tintMode", "attribute", "instead", "of", "API", "21", "s", "."], "add_tokens": "if ( a . hasValue ( R . styleable . MaterialProgressBar_mpb_tintMode ) ) { R . styleable . MaterialProgressBar_mpb_tintMode , - 1 ) , null ) ;", "del_tokens": "if ( a . hasValue ( R . styleable . MaterialProgressBar_android_tintMode ) ) { R . styleable . MaterialProgressBar_android_tintMode , - 1 ) , null ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "optional", "automatic", "deregistration", "on", "shutdown", "-", "turned", "off", "by", "default", ";", "only", "periodically", "try", "to", "register", "when", "the", "context", "is", "active"], "add_tokens": "private boolean autoDeregistration ; * * * / * * * * @ return wether the application deregisters automatically on shutdown . * / public boolean isAutoDeregistration ( ) { return autoDeregistration ; } public void setAutoDeregistration ( boolean autoDeregistration ) { this . autoDeregistration = autoDeregistration ; }", "del_tokens": "* * *", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "Link", "without", "header"], "add_tokens": "import java . util . Collections ; @ Nullable this . header = header == null ? Collections . < String , String > emptyMap ( ) : new TreeMap < > ( header ) ;", "del_tokens": "@ NotNull this . header = new TreeMap < > ( header ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "aspect", "allowing", "flexible", "metrics", "log", "assignments"], "add_tokens": "import com . truward . brikar . common . log . metric . Metrics ; import com . truward . time . support . StandardTimeSource ; import javax . annotation . ParametersAreNonnullByDefault ; import static java . util . Objects . requireNonNull ; @ ParametersAreNonnullByDefault private TimeSource timeSource = StandardTimeSource . INSTANCE ; public final void setTimeSource ( TimeSource timeSource ) { this . timeSource = requireNonNull ( timeSource ) ; } public final TimeSource getTimeSource ( ) { return timeSource ; } protected final Object invokeAndLog ( ProceedingJoinPoint jp , LogLapse logLapse ) throws Throwable { logMetrics ( lapse ) ; protected abstract void logMetrics ( Metrics metrics ) ;", "del_tokens": "import com . truward . brikar . common . log . LogUtil ; import org . slf4j . Logger ; protected final Object around ( Logger log , ProceedingJoinPoint jp , LogLapse logLapse ) throws Throwable { LogUtil . propagateOrLogInfo ( lapse , log ) ; protected abstract TimeSource getTimeSource ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "static", "util", "methods", "to", "dedicated", "classes"], "add_tokens": "import org . codehaus . jackson . map . ObjectMapper ; import java . io . IOException ; import java . io . StringWriter ; import java . io . Writer ; public class DBObjectConvertor { private final ObjectMapper mapper ; public DBObjectConvertor ( ) { this . mapper = ObjectMapperFactory . createConfLessMapper ( ) ; } public DBObject convert ( String jsonQuery ) { return ( ( DBObject ) JSON . parse ( jsonQuery ) ) ; } public DBObject convert ( Object obj ) throws IOException { Writer writer = new StringWriter ( ) ; mapper . writeValue ( writer , obj ) ; return convert ( writer . toString ( ) ) ;", "del_tokens": "public class DBObjectConvertor { public static DBObject from ( String query ) { return ( ( DBObject ) JSON . parse ( query ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "some", "tests", "for", "AsyncLogger", "and", "also", "added", "id", "to", "be", "sent", "before", "first", "log"], "add_tokens": "/** Identifier for this client library */ private static final String LIBRARY_ID = \"###J01###\" ; boolean debug = false ; boolean local = false ; boolean started = false ; queue = new ArrayBlockingQueue < String > ( QUEUE_SIZE ) ; // Fill the queue with an identifier message for first entry sent to server queue . offer ( LIBRARY_ID ) ; try { UUID u = UUID . fromString ( uuid ) ; } catch ( IllegalArgumentException e ) { return false ; } return true ;", "del_tokens": "boolean debug ; boolean local ; boolean started ; queue = new ArrayBlockingQueue < String > ( QUEUE_SIZE ) ; UUID u = UUID . fromString ( uuid ) ; return u . toString ( ) . equals ( uuid ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "initial", "test", "cases", "foundation"], "add_tokens": "import java . util . Collections ; return Collections . unmodifiableList ( webcams ) ;", "del_tokens": "return webcams ;", "commit_type": "add"}
{"commit_tokens": ["Change", "By", "to", "an", "interface", ".", "Add", "query", "classes", "."], "add_tokens": "return frank . map ( query . language ( ) , query . pattern ( ) , name , arguments ) ;", "del_tokens": "return frank . map ( query . engine ( ) , query . pattern ( ) , name , arguments ) ;", "commit_type": "change"}
{"commit_tokens": ["Implement", "solution", "-", "level", "mutation"], "add_tokens": "public static void apply ( Solution solution1 , Solution solution2 , TreeGP manager )", "del_tokens": "public void apply ( Solution solution1 , Solution solution2 , TreeGP manager )", "commit_type": "implement"}
{"commit_tokens": ["Allow", "digits", "in", "URL", "schemes"], "add_tokens": "import org . scribe . builder . api . EvernoteApi ; @ SuppressWarnings ( \"unchecked\" ) if ( evernoteHost . equals ( \"sandbox.evernote.com\" ) ) { apiClass = EvernoteApi . Sandbox . class ; new EvernoteAuthToken ( service . getAccessToken ( reqToken , verifier ) ) ;", "del_tokens": "import com . evernote . client . oauth . EvernoteApi ; import com . evernote . client . oauth . EvernoteSandboxApi ; if ( evernoteHost . equals ( EvernoteSandboxApi . evernoteHost ) ) { apiClass = EvernoteSandboxApi . class ; // TODO communicate this back to the caller ( EvernoteAuthToken ) service . getAccessToken ( reqToken , verifier ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "type", "field", "to", "Transaction", "."], "add_tokens": "this . logStream . writeInt ( txn . getType ( ) ) ; int type ; type = in . readInt ( ) ; this . lastTransactionLength = Zxid . getZxidLength ( ) + 4 + 4 + bodyLength ; return new Transaction ( zxid , ByteBuffer . wrap ( bodyBuffer ) , type ) ;", "del_tokens": "this . lastTransactionLength = Zxid . getZxidLength ( ) + 4 + bodyLength ; return new Transaction ( zxid , ByteBuffer . wrap ( bodyBuffer ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "UpdateUSer", "and", "refactoring", "Services"], "add_tokens": "import org . osiam . client . update . UpdateUser ; public User updateUser ( UUID id , UpdateUser updateUser , AccessToken accessToken ) { return updateResource ( id , updateUser . getUserToUpdate ( ) , accessToken ) ;", "del_tokens": "public User updateUser ( UUID id , User updateUser , AccessToken accessToken ) { return updateResource ( id , updateUser , accessToken ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "authenticate", "method", "in", "ISecurityManager", "to", "be", "void", "and", "throw", "an", "AuthenticationException"], "add_tokens": "import ca . uhn . fhir . rest . server . exceptions . AuthenticationException ; public void authenticate ( HttpServletRequest request ) throws AuthenticationException ;", "del_tokens": "public boolean authenticate ( HttpServletRequest request ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "snake", "case", "for", "parameters", "in", "the", "params", "map"], "add_tokens": "if ( params . containsKey ( \"include_raw\" ) ) request . withQuery ( \"include_raw\" , params . get ( \"include_raw\" ) ) ; if ( params . containsKey ( \"accept_language\" ) ) request . withHeader ( \"Accept-Language\" , params . get ( \"accept_language\" ) ) ;", "del_tokens": "if ( params . containsKey ( \"includeRaw\" ) ) request . withQuery ( \"include_raw\" , params . get ( \"includeRaw\" ) ) ; if ( params . containsKey ( \"acceptLanguage\" ) ) request . withHeader ( \"Accept-Language\" , params . get ( \"acceptLanguage\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "file", "name", "of", "plugins", ".", "json", "configurable"], "add_tokens": "private String pluginsJsonFileName = \"plugins.json\" ; public DefaultUpdateRepository ( String id , String url , String pluginsJsonFileName ) { this ( id , url ) ; this . pluginsJsonFileName = pluginsJsonFileName ; } URL pluginsUrl = new URL ( new URL ( url ) , pluginsJsonFileName ) ; public String getPluginsJsonFileName ( ) { return pluginsJsonFileName ; } / * * * Choose another file name than plugins . json * @ param pluginsJsonFileName the name ( relative ) of plugins . json file * / public void setPluginsJsonFileName ( String pluginsJsonFileName ) { this . pluginsJsonFileName = pluginsJsonFileName ; }", "del_tokens": "private static final String DEFAULT_PLUGINS_JSON = \"plugins.json\" ; URL pluginsUrl = new URL ( new URL ( url ) , DEFAULT_PLUGINS_JSON ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "method", "info", "gathering", "for", "built", "-", "in", "overrides"], "add_tokens": "import com . groupon . odo . plugin . HttpRequestInfo ; import com . groupon . odo . plugin . PluginArguments ; import com . groupon . odo . plugin . PluginHelper ; import com . groupon . odo . plugin . PluginResponse ; import org . apache . commons . httpclient . * ; // other built-in overrides if ( endpoint . getOverrideId ( ) < 0 ) { continue ; }", "del_tokens": "import com . groupon . odo . plugin . * ; import com . groupon . odo . plugin . RequestOverride ; import com . groupon . odo . plugin . ResponseOverride ; import org . apache . commons . httpclient . Header ; import org . apache . commons . httpclient . HttpClient ; import org . apache . commons . httpclient . HttpMethod ; import org . apache . commons . httpclient . HttpMethodRetryHandler ; import org . apache . commons . httpclient . NoHttpResponseException ; import org . apache . commons . httpclient . URIException ; return ; * @ param outStream", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typos", "in", "comments", "."], "add_tokens": "* < p / > The grammar to parse looks like : * < p / > Augment the grammar with a start state and number the rules : * Implements a reduction by rule 2 of the grammar . This consumes two states from the state stack , and expects the * Implements a reduction by rule 3 of the grammar . This consumes two states from the state stack , and expects the * Implements a reduction by rule 3 of the grammar . This consumes three states from the state stack , and expects the", "del_tokens": "* < p / > The grammer to parse looks like : * < p / > Augment the grammer with a start state and number the rules : * Implements a reduction by rule 2 of the grammer . This consumes two states from the state stack , and expects the * Implements a reduction by rule 3 of the grammer . This consumes two states from the state stack , and expects the * Implements a reduction by rule 3 of the grammer . This consumes three states from the state stack , and expects the", "commit_type": "fix"}
{"commit_tokens": ["Fix", "switching", "servers", "for", "clients"], "add_tokens": "List < ServerRedirect > servers = serverRedirectService . tableServers ( requestInformation . get ( ) . client . getId ( ) ) ; . tableServers ( requestInformation . get ( ) . client . getId ( ) ) ;", "del_tokens": "List < ServerRedirect > servers = serverRedirectService . tableServers ( requestInformation . get ( ) . profile . getId ( ) ) ; . tableServers ( requestInformation . get ( ) . profile . getId ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "handling", "of", "404", "in", "get", "operations", "."], "add_tokens": "import io . fabric8 . kubernetes . api . model . StatusBuilder ; throw new KubernetesClientException ( e . getMessage ( ) , statusCode , new StatusBuilder ( ) . withCode ( statusCode ) . withMessage ( e . getMessage ( ) ) . build ( ) ) ;", "del_tokens": "throw KubernetesClientException . launderThrowable ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "the", "issue", "4", "."], "add_tokens": "boolean added = block . add ( addIndex , data ) ;", "del_tokens": "boolean added = block . add ( addIndex , data ) ; // System.out.println(addIndex + \" backup added \" + added);", "commit_type": "fix"}
{"commit_tokens": ["Use", "Spring", "test", "features", "in", "SpringTest"], "add_tokens": "import org . activiti . DbProcessEngineBuilder ; private String configurationResource = \"activiti.properties\" ; public void setConfigurationResource ( String configurationResource ) { this . configurationResource = configurationResource ; } public Object getObject ( ) throws Exception { // ProcessEngines is not very friendly for configuration // ProcessEngines.init(); // return ProcessEngines.getDefaultProcessEngine(); return new DbProcessEngineBuilder ( ) . configureFromPropertiesResource ( configurationResource ) . buildProcessEngine ( ) ; } public Class < ? > getObjectType ( ) { return ProcessEngine . class ; } public boolean isSingleton ( ) { return true ; }", "del_tokens": "import org . activiti . ProcessEngines ; public Object getObject ( ) throws Exception { ProcessEngines . init ( ) ; return ProcessEngines . getDefaultProcessEngine ( ) ; } public Class < ? > getObjectType ( ) { return ProcessEngine . class ; } public boolean isSingleton ( ) { return true ; }", "commit_type": "use"}
{"commit_tokens": ["Fix", "configuration", "locale", "not", "update", "after", "attachBaseContext"], "add_tokens": "if ( android . os . Build . VERSION . SDK_INT >= android . os . Build . VERSION_CODES . JELLY_BEAN_MR1 ) { applyOverrideConfiguration ( localizationDelegate . updateConfigurationLocale ( newBase ) ) ; super . attachBaseContext ( newBase ) ; } else { super . attachBaseContext ( localizationDelegate . attachBaseContext ( newBase ) ) ; }", "del_tokens": "super . attachBaseContext ( localizationDelegate . attachBaseContext ( newBase ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "MarkdownTestTester", "cases", "on", "Windows"], "add_tokens": "import java . io . BufferedReader ; BufferedReader in = new BufferedReader ( new FileReader ( file ) ) ; StringBuilder sb = new StringBuilder ( ) ; String line ; while ( ( line = in . readLine ( ) ) != null ) { sb . append ( line ) . append ( \"\\n\" ) ; in . close ( ) ;", "del_tokens": "FileReader in = new FileReader ( file ) ; StringBuffer sb = new StringBuffer ( ) ; int ch ; while ( ( ch = in . read ( ) ) != - 1 ) { sb . append ( ( char ) ch ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "problems", "with", "services", "starts"], "add_tokens": "ISnapshotArchiver archiver = null ; archiver = ( ISnapshotArchiver ) archiverClass . getConstructor ( getClassesArray ( archiverParams ) ) . newInstance ( archiverParams ) ; //throw new RuntimeException(\"Failed to create stats archiver from configureme config file\", e); System . err . println ( \"Failed to create stats archiver from configureme config file\" ) ; e . printStackTrace ( ) ; return archiver ;", "del_tokens": "ISnapshotArchiver archiver = ( ISnapshotArchiver ) archiverClass . getConstructor ( getClassesArray ( archiverParams ) ) . newInstance ( archiverParams ) ; return archiver ; throw new RuntimeException ( \"Failed to create stats archiver from configureme config file\" , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "regex", "for", "DB2", "and", "AS400", "URL", "Parser"], "add_tokens": ". compile ( \"jdbc:as400:\\\\/\\\\/(?<host>[^\\\\/;]+)(\\\\/(?<instance>[^;\\\\/]*))?\\\\/?(;(?<options>.*))?\" ) ;", "del_tokens": ". compile ( \"jdbc:as400:\\\\/\\\\/(?<host>[^\\\\/^;]+)(\\\\/(?<instance>[^;^\\\\/]*))?\\\\/?(;(?<options>.*))?\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Allow", "unquoted", "fields", "in", "RequireJs", "configuration", "."], "add_tokens": "import static com . fasterxml . jackson . core . JsonParser . Feature . ALLOW_UNQUOTED_FIELD_NAMES ; ObjectMapper mapper = new ObjectMapper ( ) . configure ( ALLOW_UNQUOTED_FIELD_NAMES , true ) ;", "del_tokens": "ObjectMapper mapper = new ObjectMapper ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "support", "for", "empty", "graphs"], "add_tokens": "public void readEmptyGraphTest ( ) { GDLLoader loader = getLoaderFromGDLString ( \"[]\" ) ; validateCollectionSizes ( loader , 1 , 0 , 0 ) ; validateCacheSizes ( loader , 0 , 0 , 0 ) ; } @ Test public void readSimpleGraphTest ( ) {", "del_tokens": "public void readGraphTest ( ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "of", "matcher", "when", "using", "*", "wildcard"], "add_tokens": "patternChar = pattern [ patternIndex ] ; if ( patternChar == '\\0' ) { // If the pattern ends with \"*\", completed. return true ; } if ( patternChar == '\\0' || patternChar == '*' || patternChar == '?' ) {", "del_tokens": "if ( patternChar == '\\0' ) { // Completed. return true ; } if ( patternChar == '*' || patternChar == '?' ) {", "commit_type": "fix"}
{"commit_tokens": ["Improve", "test", "and", "remove", "support", "for", "native", "libraries"], "add_tokens": "import java . io . IOException ; import java . net . URL ; import java . util . Enumeration ; import de . skuzzle . tinyplugz . Require ; public Plugin1HostInterfaceImpl ( ) throws ClassNotFoundException , IOException { final ClassLoader cl = getClass ( ) . getClassLoader ( ) ; cl . loadClass ( \"de.skuzzle.tinyplugz.test.testplugin1.Plugin1SampleService\" ) ; // check if we can access own resource final URL plugin1 = cl . getResource ( \"plugin1.txt\" ) ; final URL plugin2 = cl . getResource ( \"plugin2.txt\" ) ; final Enumeration < URL > both = cl . getResources ( \"both.txt\" ) ; Require . nonNull ( plugin1 , \"plugin1\" ) ; Require . nonNull ( plugin2 , \"plugin1\" ) ; both . nextElement ( ) ; both . nextElement ( ) ; Require . condition ( ! both . hasMoreElements ( ) , \"\" ) ;", "del_tokens": "public Plugin1HostInterfaceImpl ( ) throws ClassNotFoundException { getClass ( ) . getClassLoader ( ) . loadClass ( \"de.skuzzle.tinyplugz.test.testplugin1.Plugin1SampleService\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["changed", "method", "signatures", "updated", "readme", "and", "binary"], "add_tokens": "public Double squareoff ; public Double stoploss ; / * * * Tag : field for users to tag orders . It accepts alphanumeric 8 character String values . * / public String tag ; / * * * Parent order id is used to send order modify request . * / public String parentOrderId ;", "del_tokens": "public Double squareoffValue ; public Double stoplossValue ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "Double", "to", "Integer", "conversion", "in", "com", "/", "genesys", "/", "workspace", "/", "models", "/", "targets", "/", "Target", ".", "java"], "add_tokens": "Integer readyAgents = ( ( Double ) availabilityData . get ( \"readyAgents\" ) ) . intValue ( ) ; Integer waitingCalls = ( ( Double ) availabilityData . get ( \"waitingCalls\" ) ) . intValue ( ) ;", "del_tokens": "Integer readyAgents = ( Integer ) availabilityData . get ( \"readyAgents\" ) ; Integer waitingCalls = ( Integer ) availabilityData . get ( \"waitingCalls\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "from", "TokenMgrError", "to", "IllegalArgumentException", "even", "though", "this"], "add_tokens": "throw new IllegalArgumentException ( \"Identifier may not start with a hyphen and a digit: \" + aPattern ) ; throw new IllegalArgumentException ( \"Identifier may not start with a digit: \" + aPattern ) ; throw new IllegalArgumentException ( \"Identifier may not start with two hyphens: \" + aPattern ) ;", "del_tokens": "throw new TokenMgrError ( \"Identifier may not start with a hyphen and a digit: \" + aPattern , TokenMgrError . LEXICAL_ERROR ) ; throw new TokenMgrError ( \"Identifier may not start with a digit: \" + aPattern , TokenMgrError . LEXICAL_ERROR ) ; throw new TokenMgrError ( \"Identifier may not start with two hyphens: \" + aPattern , TokenMgrError . LEXICAL_ERROR ) ;", "commit_type": "change"}
{"commit_tokens": ["moved", "exception", "handler", "to", "upper", "level"], "add_tokens": "package com . baasbox . android ;", "del_tokens": "package com . baasbox . android . impl ; import com . baasbox . android . Logger ;", "commit_type": "move"}
{"commit_tokens": ["Add", "errors", "for", "firmware", "upload", "states"], "add_tokens": "* Timed out during sketch programming , before sending chunks : Bean took too long to update its * current state / * * * Timed out configuring OAD characteristics * / OAD_CONFIG_TIMEOUT , / * * * Timed out requesting current firmware version * / CURR_FW_VER_TIMEOUT , / * * * Timed out starting firmware download * / FW_START_TIMEOUT , / * * * Timed out while sending firmware packets * / FW_DOWNLOAD_TIMEOUT ,", "del_tokens": "* Timed out while waiting for state to update during programming , but before sending chunks", "commit_type": "add"}
{"commit_tokens": ["Use", "GrailsFormAction", "and", "set", "default", "method", "to", "bindAndValidate"], "add_tokens": "import org . codehaus . groovy . grails . web . pageflow . action . GrailsFormAction ; private static final String BIND_AND_VALIDATE = \"bindAndValidate\" ; GrailsFormAction formAction = new GrailsFormAction ( ) ; } else { action . setProperty ( METHOD , BIND_AND_VALIDATE ) ;", "del_tokens": "import java . lang . String ; import java . lang . UnsupportedOperationException ; import org . springframework . webflow . action . FormAction ; FormAction formAction = new FormAction ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Removed", "some", "tabs", "from", "source"], "add_tokens": "\"If you don't want to add any headers, \" + \"pass an empty list instead\" ) ;", "del_tokens": "\"If you don't want to add any headers, \" + \"pass an empty list instead\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["improved", "mapping", "added", "ignoring", "of", "transient", "fields"], "add_tokens": "if ( Modifier . isTransient ( mappingField . getModifiers ( ) ) ) { continue ; } * Makes an instance of a class without call of its constructor , just allocate * memory * * @ throws JBBPMapperException it will be thrown if it is impossible to make * an instance", "del_tokens": "* Makes an instance of a class without call of its constructor , just allocate memory * @ throws JBBPMapperException it will be thrown if it is impossible to make an instance", "commit_type": "improve"}
{"commit_tokens": ["Add", "variant", "with", "string", "parameter", "to", "converter", "from", "enumeration"], "add_tokens": "public static String enumToMemberName ( String enumName ) String [ ] words = enumName . split ( \"_\" ) ; / * * * Typed variant of { @ link # enumToMemberName ( String ) } . * * @ param enumName enumeration constant . * @ return camel case member name . * / public static String enumToMemberName ( Enum < ? > enumName ) { if ( enumName == null ) { return null ; } return enumToMemberName ( enumName . name ( ) ) ; }", "del_tokens": "public static String enumToMemberName ( Enum < ? > enumName ) String [ ] words = enumName . name ( ) . split ( \"_\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "getter", "for", "server", "setup"], "add_tokens": "import com . icegreen . greenmail . util . Service ; import javax . net . ssl . SSLServerSocket ; ret = ( SSLServerSocket ) DummySSLServerSocketFactory . getDefault ( ) . createServerSocket ( setup . getPort ( ) , 0 , bindTo ) ; public ServerSetup getServerSetup ( ) { return setup ; }", "del_tokens": "import com . icegreen . greenmail . util . Service ; import javax . net . ssl . SSLServerSocket ; import java . net . Socket ; ret = ( SSLServerSocket ) DummySSLServerSocketFactory . getDefault ( ) . createServerSocket ( setup . getPort ( ) , 0 , bindTo ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "a", "TEST", "runtime", "mode"], "add_tokens": "* The runtime mode . Must currently be either DEV , TEST , or PROD .", "del_tokens": "* The runtime mode . Must currently be either DEV or PROD .", "commit_type": "add"}
{"commit_tokens": ["Remove", "last", "slash", "on", "entry", "directory", "."], "add_tokens": "if ( isDirectory && vfsUrlString . endsWith ( \"/\" ) == false )", "del_tokens": "if ( isDirectory )", "commit_type": "remove"}
{"commit_tokens": ["added", "reference", "of", "special", "variables", "into", "help"], "add_tokens": "import com . igormaznitsa . jcp . context . JCPSpecialVariableProcessor ; import com . igormaznitsa . jcp . context . SpecialVariableProcessor ; for ( final JCPSpecialVariableProcessor . NameReferencePair p : JCPSpecialVariableProcessor . getReference ( ) ) { result . add ( makeSpecialVariableReference ( p ) ) ; } private static String makeSpecialVariableReference ( final JCPSpecialVariableProcessor . NameReferencePair p ) { final String name = p . getName ( ) ; final String ref = p . getReference ( ) ; return makeColumns ( name , ref , 24 ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Removed", "explicit", "thumbnail", "properties", "and", "kept", "only", "generic", "image", "template", "."], "add_tokens": "private String freeSizePath ; private String formatPath ; public String getFreeSizePath ( ) { return freeSizePath ; public void setFreeSizePath ( String freeSizePath ) { this . freeSizePath = freeSizePath ; public String getFormatPath ( ) { return formatPath ; public void setFormatPath ( String formatPath ) { this . formatPath = formatPath ; public String getFilename ( ) { return filename ; public void setFilename ( String filename ) { this . filename = filename ;", "del_tokens": "private String mediaPath ; private String thumbnailPath ; public String getMediaPath ( ) { return mediaPath ; public void setMediaPath ( String mediaPath ) { this . mediaPath = mediaPath ; public String getFilename ( ) { return filename ; public void setFilename ( String filename ) { this . filename = filename ; public void setThumbnailPath ( String thumbnailPath ) { this . thumbnailPath = thumbnailPath ; public String getThumbnailPath ( ) { return thumbnailPath ;", "commit_type": "remove"}
{"commit_tokens": ["add", "passwordless", "view", "and", "event"], "add_tokens": "import com . auth0 . android . lock . enums . PasswordlessMode ; Button btnPasswordlessEmailLink = ( Button ) findViewById ( R . id . btn_passwordless_email_link ) ; btnPasswordlessEmailLink . setOnClickListener ( this ) ; case R . id . btn_passwordless_email_link : passwordlessLogin ( PasswordlessMode . EMAIL_LINK ) ; private void passwordlessLogin ( PasswordlessMode mode ) {", "del_tokens": "Button btnPasswordlessLink = ( Button ) findViewById ( R . id . btn_social_browser ) ; btnPasswordlessLink . setOnClickListener ( this ) ; case R . id . btn_passwordless_link : passwordlessLink ( ) ; private void passwordlessLink ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "in", "flight", "batchs", "gauge", "per", "relay", "target", "-", "fixed", "metric", "name"], "add_tokens": "metricFactory . registerGauge ( getClass ( ) . getSimpleName ( ) , graphiteCompatibleHostName + \".inFlightBatches\" , new Gauge < Integer > ( ) {", "del_tokens": "metricFactory . registerGauge ( getClass ( ) . getSimpleName ( ) , graphiteCompatibleHostName + \"inFlightBatches\" , new Gauge < Integer > ( ) {", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "function", "svg", "-", "gradient"], "add_tokens": "ColorUtils . appendColor ( output , value ) ;", "del_tokens": "output . append ( '#' ) ; String hex = Integer . toHexString ( value & 0xFFFFFF ) ; for ( int i = hex . length ( ) ; i < 6 ; i ++ ) { output . append ( '0' ) ; } output . append ( hex ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "contact", "delete", "method", "and", "JavaDoc", "."], "add_tokens": "return new ModelAndView ( \"redirect:/groups\" ) ; return \"redirect:/groups\" ; } @ RequestMapping ( value = \"/contact\" , method = POST , params = \"delete\" ) public String deleteContact ( String url ) { google . contactOperations ( ) . deleteContact ( url ) ;", "del_tokens": "return new ModelAndView ( \"redirect:/contacts\" ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "recursion", "to", "loop", "method"], "add_tokens": "private int tblNum ; private int binaryCode ; public TablePlanner ( String tblName , Predicate pred , Transaction tx , int tblNum ) { this . tblNum = tblNum ; this . binaryCode = ( int ) Math . pow ( 2 , tblNum ) ; // set an unique number to this table planner public int getTblNum ( ) { return tblNum ; } // use binary to represent the combination public int getBinaryCode ( ) { return binaryCode ;", "del_tokens": "private int indexNum ; public TablePlanner ( String tblName , Predicate pred , Transaction tx , int indexNum ) { this . indexNum = indexNum ; // method for Selinger opt. public int getIndexNum ( ) { return indexNum ;", "commit_type": "change"}
{"commit_tokens": ["added", "header", "()", "method", "to", "RequestBuilder", "added", "detection", "of", "Ajax", "request", "for", "errors", "references", ":", "http", ":", "//", "code", ".", "google", ".", "com", "/", "p", "/", "activeweb", "/", "issues", "/", "detail?id", "=", "10"], "add_tokens": "}", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["changed", "replace", "to", "put", "to", "be", "compatible", "with", "jdk7"], "add_tokens": "resourceMap . put ( resourceDir , true ) ; resourceMap . put ( resourceDir , true ) ;", "del_tokens": "resourceMap . replace ( resourceDir , true ) ; resourceMap . replace ( resourceDir , true ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "TypeVisitor", "more", "and", "add", "test"], "add_tokens": "return TypeVisitor . of ( from , b -> b . onParameterizedType ( pt -> TypeVisitor . of ( pt . getRawType ( ) , bb -> bb . result ( ) ) ) . result ( ) ) ;", "del_tokens": "return TypeVisitor . < Boolean > create ( from ) . onParameterizedType ( pt -> TypeVisitor . < Boolean > create ( pt . getRawType ( ) ) . result ( ) ) . result ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "new", "search", "methods", "to", "client"], "add_tokens": "//service = new ArdoqClient(System.getenv(\"ardoqHost\"), System.getenv(\"ardoqToken\")).setOrganization(TestUtils.getTestPropery(\"organization\")).workspace(); service = new ArdoqClient ( System . getenv ( \"ardoqHost\" ) , System . getenv ( \"ardoqToken\" ) ) . setOrganization ( \"ardoq\" ) . workspace ( ) ; @ Test public void findWorkspacesByNameTest ( ) { Workspace result = service . createWorkspace ( testWorkspace ) ; List < Workspace > results = service . findWorkspacesByName ( result . getName ( ) ) ; for ( Workspace workspace : results ) { assertEquals ( result . getName ( ) , workspace . getName ( ) ) ; } }", "del_tokens": "service = new ArdoqClient ( System . getenv ( \"ardoqHost\" ) , System . getenv ( \"ardoqToken\" ) ) . setOrganization ( TestUtils . getTestPropery ( \"organization\" ) ) . workspace ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Upgraded", "the", "Preview", "to", "have", "a", "Material", "Design", "specs", "."], "add_tokens": "import com . google . gwt . dom . client . Style ; private MaterialIcon previewIcon = new MaterialIcon ( IconType . INSERT_DRIVE_FILE ) ; previewIcon . setFloat ( Style . Float . LEFT ) ; previewIcon . addStyleName ( \"preview-icon\" ) ; dropInfo . add ( previewIcon ) ; btnClear . setBackgroundColor ( \"transparent\" ) ; btnClear . setShadow ( 0 ) ; btnClear . setWaves ( WavesType . DEFAULT ) ; btnClear . setCircle ( true ) ;", "del_tokens": "btnClear . setBackgroundColor ( \"red\" ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "log", "messages", "delete", "life", ".", "iml", "from", "repo"], "add_tokens": "Log . d ( GameActivity . TAG , \"onBuyChanges in BillingHelper\" ) ; Log . d ( GameActivity . TAG , \"onBuyOrangeCells in BillingHelper\" ) ; Log . d ( GameActivity . TAG , \"onBuyFigures in BillingHelper\" ) ;", "del_tokens": "Log . e ( GameActivity . TAG , \"onBuyChanges\" ) ; Log . e ( GameActivity . TAG , \"onBuyOrangeCells\" ) ; Log . e ( GameActivity . TAG , \"onBuyFigures\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "path", "for", "traversing", "jsonnode"], "add_tokens": "public JsonNode value ( String property ) { return getValue ( node , property ) ; } value = node . path ( property ) ; if ( value . isMissingNode ( ) ) {", "del_tokens": "value = node . get ( property ) ; if ( value == null ) {", "commit_type": "use"}
{"commit_tokens": ["Using", "the", "latest", "envelope", "id", "in", "unit", "tests"], "add_tokens": "public static String EnvelopeId = \"fc37871d-862d-4c49-ad83-b435409b601b\" ; // JUnit 4.12 runs test cases in parallel, so the envelope ID needs to be initiated as well. EnvelopeId = envelopeSummary . getEnvelopeId ( ) ;", "del_tokens": "public static String EnvelopeId = \"50bc6a77-c324-49c0-b53d-a86139192e47\" ; // JUnit 4.12 runs test cases in parallel, so the envelope ID needs to be initiated as well.", "commit_type": "use"}
{"commit_tokens": ["Changed", "JSONTermIndexIO", "options", "API", "(", "Added", "LoadOptions", "and", "SaveOptions", ")"], "add_tokens": "import eu . project . ttc . models . index . io . LoadOptions ; LoadOptions loadOptions = new LoadOptions ( ) . withContexts ( true ) ; JSONTermIndexIO . load ( new FileReader ( line . getOptionValue ( SOURCE_TERMINO ) ) , loadOptions ) JSONTermIndexIO . load ( new FileReader ( line . getOptionValue ( TARGET_TERMINO ) ) , loadOptions )", "del_tokens": "JSONTermIndexIO . load ( new FileReader ( line . getOptionValue ( SOURCE_TERMINO ) ) , true ) JSONTermIndexIO . load ( new FileReader ( line . getOptionValue ( TARGET_TERMINO ) ) , true )", "commit_type": "change"}
{"commit_tokens": ["adding", "logging", "to", "json", "gl", "client"], "add_tokens": "* Caching support for gl client implementations .", "del_tokens": "* ...", "commit_type": "add"}
{"commit_tokens": ["Use", "java", ".", "net", ".", "URI", "instead", "of", "java", ".", "net", ".", "URL", "in", "daft", ".", "ie", "XML", "-", "format"], "add_tokens": "import java . net . URI ; extends XmlAdapter < String , URI > public URI unmarshal ( String value ) { return ( org . openestate . io . daft_ie . DaftIeUtils . parseURI ( value ) ) ; public String marshal ( URI value ) { return ( org . openestate . io . daft_ie . DaftIeUtils . printURI ( value ) ) ;", "del_tokens": "import java . net . URL ; extends XmlAdapter < String , URL > public URL unmarshal ( String value ) { return ( org . openestate . io . daft_ie . DaftIeUtils . parseURL ( value ) ) ; public String marshal ( URL value ) { return ( org . openestate . io . daft_ie . DaftIeUtils . printURL ( value ) ) ;", "commit_type": "use"}
{"commit_tokens": ["updating", "to", "changed", "variable", "persistence"], "add_tokens": "import org . drools . impl . EnvironmentFactory ; return EnvironmentFactory . newEnvironment ( ) ;", "del_tokens": "import org . drools . impl . EnvironmentImpl ; return new EnvironmentImpl ( ) ; //EnvironmentFactory.newEnvironment();", "commit_type": "update"}
{"commit_tokens": ["Add", "basic", "unit", "test", "for", "VersionInfoConfiguration"], "add_tokens": "private String companyName ; private String copyright ;", "del_tokens": "protected String companyName ; protected String copyright ;", "commit_type": "add"}
{"commit_tokens": ["fix", "logic", "of", "tag", ":", "empty", "filter", "out", "end", "tags", "from", "doc", "output"], "add_tokens": "import com . hubspot . jinjava . lib . tag . EndTag ; if ( t instanceof EndTag ) { continue ; } doc . addTag ( new JinjavaDocTag ( t . getName ( ) , StringUtils . isBlank ( t . getEndTagName ( ) ) , \"\" , \"\" ) ) ; doc . addTag ( new JinjavaDocTag ( t . getName ( ) , StringUtils . isBlank ( t . getEndTagName ( ) ) , docAnnotation . value ( ) , docAnnotation . aliasOf ( ) , extractParams ( docAnnotation . params ( ) ) ) ) ;", "del_tokens": "import com . hubspot . jinjava . doc . JinjavaDoc ; doc . addTag ( new JinjavaDocTag ( t . getName ( ) , StringUtils . isNotBlank ( t . getEndTagName ( ) ) , \"\" , \"\" ) ) ; doc . addTag ( new JinjavaDocTag ( t . getName ( ) , StringUtils . isNotBlank ( t . getEndTagName ( ) ) , docAnnotation . value ( ) , docAnnotation . aliasOf ( ) , extractParams ( docAnnotation . params ( ) ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "all", "plugins", "and", "dependencies", "."], "add_tokens": "@ PrepareForTest ( Search . class )", "del_tokens": "@ PrepareForTest ( Search . class ) @ PrepareForTest ( Search . class ) / * * * Assert that reloading does nothing . * / @ Test public void testOnReload ( ) { SessionFactory sessionFactory = locator . getService ( SessionFactory . class ) ; SearchIndexContextListener listener = new SearchIndexContextListener ( sessionFactory ) ; Container mockContainer = mock ( Container . class ) ; listener . onReload ( mockContainer ) ; verifyZeroInteractions ( mockContainer ) ; } / * * * Assert that shutting down does nothing . * / @ Test public void testOnShutdown ( ) { SessionFactory sessionFactory = locator . getService ( SessionFactory . class ) ; SearchIndexContextListener listener = new SearchIndexContextListener ( sessionFactory ) ; Container mockContainer = mock ( Container . class ) ; listener . onShutdown ( mockContainer ) ; verifyZeroInteractions ( mockContainer ) ; }", "commit_type": "update"}
{"commit_tokens": ["Made", "it", "possible", "to", "register", "custom", "servlets", "by", "making", "them", "available", "as", "Spring", "managed", "beans", ".", "Also", "changed", "some", "debug", "logging", "."], "add_tokens": "import com . vaadin . server . Constants ; logger . debug ( \"{} initialized\" , getClass ( ) . getName ( ) ) ; logger . info ( \"Registering servlet for serving static Vaadin content\" ) ; // TODO Make this configurable as well registrationBean . addInitParameter ( Constants . SERVLET_PARAMETER_PRODUCTION_MODE , \"true\" ) ; logger . debug ( \"{} initialized\" , getClass ( ) . getName ( ) ) ;", "del_tokens": "logger . debug ( getClass ( ) . getName ( ) + \" has finished running\" ) ; logger . debug ( \"Registering Vaadin servlet for serving static content\" ) ; logger . debug ( getClass ( ) . getName ( ) + \" has finished running\" ) ;", "commit_type": "make"}
{"commit_tokens": ["removed", "horrible", "hack", "by", "using", "setAccessible", "()", "and", "made", "it", "optional"], "add_tokens": "if ( registry . useAccessible ( ) ) { method . setAccessible ( true ) ; }", "del_tokens": "/** @todo a dirty hack - no idea why getKey() fails on HashMaps' entry class */ if ( object instanceof Map . Entry ) { String name = method . getName ( ) ; if ( name . equals ( \"getKey\" ) ) { return ( ( Map . Entry ) object ) . getKey ( ) ; } else if ( name . equals ( \"getValue\" ) ) { return ( ( Map . Entry ) object ) . getValue ( ) ; } else if ( name . equals ( \"setValue\" ) ) { return ( ( Map . Entry ) object ) . setValue ( argumentArray [ 0 ] ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["Added", "possibility", "to", "configure", "a", "init", ".", "yaml", "file", "(", "in", "conf", "directory", ")", "that", "can", "be", "used", "to", "load", "sensors", "on", "startup"], "add_tokens": "import de . uniulm . omi . cloudiator . visor . rest . RestServerModule ; this . modules . add ( new RestServerModule ( ) ) ; this . modules . add ( new InitModule ( ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "some", "comments", "and", "change", "name", "of", "event", "logger", "methods"], "add_tokens": "public void infoEvent ( final LoggingEvent e ) { public void debugEvent ( final LoggingEvent e ) { public void errorEvent ( final LoggingEvent e ) { public void warnEvent ( final LoggingEvent e ) { public void traceEvent ( final LoggingEvent e ) { public void auditEvent ( final LoggingEvent e ) {", "del_tokens": "public void info ( final LoggingEvent e ) { public void debug ( final LoggingEvent e ) { public void error ( final LoggingEvent e ) { public void warn ( final LoggingEvent e ) { public void trace ( final LoggingEvent e ) { public void audit ( final LoggingEvent e ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "git", "status", "a", "bit", "by", "adding", "an", "ability", "to", "get", "status", "of", "a", "single", "file", "(", "for", "efficiency", ")", "and", "incorporated", "it", "in", "GitFile", ".", "Created", "a", "unit", "test", "to", "test", "Git", "file", "system", "operations", "and"], "add_tokens": "//TODO(ma1683): temporary solution try { rootDir = new GitDirectory ( path ) ; } catch ( JavaGitException e ) { } public GitDirectory addDirectory ( String dir ) throws JavaGitException { return new GitDirectory ( new File ( dir ) ) ; // TODO (ma1683): Implement this method // TODO (ma1683): Implement this method // TODO (ma1683): Implement this method // TODO (ma1683): Implement this method", "del_tokens": "// TODO (rs2705): Ensure that these arguments are valid (not null, not empty) rootDir = new GitDirectory ( path , DotGit . getInstance ( path ) , null ) ; public GitDirectory addDirectory ( String dir ) { // createDir(dir); // TODO (rs2705): Fix the call below. Currently it does nothing - just need it to compile. return new GitDirectory ( new File ( dir ) , null , null ) ; // GitCheckout.checkout(path, sha1); // GitBranch // GitLog.log(path); / * * * Show commit logs * * @ return List of commits for the working directory * / public List < Commit > log ( ) { // GitLog.log(path); return null ; }", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "where", "IDs", "were", "not", "quoted", "when", "converting", "queries", "to", "strings"], "add_tokens": "/ * * * @ param string a string to quote and escape * @ return a string , surrounded with double quotes and escaped * / private static String quoteString ( String string ) { return \"\\\"\" + escapeString ( string ) + \"\\\"\" ; } return quoteString ( ( String ) value ) ; / * * * @ param id an id of a concept * @ return * The id of the concept correctly escaped in graql . * If the ID doesn 't begin with a number and is only comprised of alphanumeric characters, underscores and dashes, * then it will be returned as - is , otherwise it will be quoted and escaped . * / public static String idToString ( String id ) { if ( id . matches ( \"^[a-zA-Z_][a-zA-Z0-9_-]*$\" ) ) { return id ; } else { return quoteString ( id ) ; } }", "del_tokens": "return \"\\\"\" + escapeString ( ( String ) value ) + \"\\\"\" ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "rename", "table", "ddl", "parser", "tablename", "and", "schemaname", "error"], "add_tokens": "public static final String RENAME_PATTERN = \"^\\\\s*RENAME\\\\s+TABLE\\\\s+(.+?)\\\\s+TO\\\\s+(.+?)$\" ; public static final String RENAME_REMNANT_PATTERN = \"^\\\\s*(.+?)\\\\s+TO\\\\s+(.+?)$\" ;", "del_tokens": "public static final String RENAME_PATTERN = \"^\\\\s*RENAME\\\\s*TABLE\\\\s*(.*?)\\\\s*TO\\\\s*(.*?)$\" ; public static final String RENAME_REMNANT_PATTERN = \"^\\\\s*(.*?)\\\\s*TO\\\\s*(.*?)$\" ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "project", "file", "and", "test", "code", "for", "https", ":", "//", "github", ".", "com", "/", "couchbaselabs", "/", "cbforest", "/", "pull", "/", "48"], "add_tokens": "protected Indexer indexer = null ; View [ ] views = { view } ; indexer = new Indexer ( views ) ; DocumentIterator itr = indexer . iterateDocuments ( ) ; indexer . emit ( doc , 0 , keys , values ) ; indexer . endIndex ( commit ) ; View [ ] views = { view } ; indexer = new Indexer ( views ) ; DocumentIterator itr = indexer . iterateDocuments ( ) ; indexer . emit ( doc , 0 , keys , values ) ; indexer . emit ( doc , 0 , new Object [ 0 ] , null ) ; indexer . endIndex ( commit ) ;", "del_tokens": "view . beginIndex ( ) ; DocumentIterator itr = view . enumerator ( ) ; view . emit ( doc , keys , values ) ; view . endIndex ( commit ) ; view . beginIndex ( ) ; DocumentIterator itr = view . enumerator ( ) ; view . emit ( doc , keys , values ) ; view . emit ( doc , new Object [ 0 ] , null ) ; view . endIndex ( commit ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "possibility", "to", "retrieve", "stats", "about", "the", "crawl", "progress"], "add_tokens": "import com . github . peterbencze . serritor . internal . stats . StatsCounter ; private final StatsCounter statsCounter ; * @ param config the crawler configuration * @ param statsCounter the stats counter which accumulates statistics during the operation of * the crawler public CrawlFrontier ( final CrawlerConfiguration config , final StatsCounter statsCounter ) { this . statsCounter = statsCounter ; boolean inCrawlDomain = config . getAllowedCrawlDomains ( ) . stream ( ) . anyMatch ( crawlDomain -> crawlDomain . contains ( request . getDomain ( ) ) ) ; statsCounter . recordOffsiteRequest ( ) ; statsCounter . recordDuplicateRequest ( ) ; statsCounter . recordCrawlDepthLimitExceedingRequest ( ) ; statsCounter . recordRemainingCrawlCandidate ( ) ; config . getCrawlSeeds ( ) . forEach ( ( CrawlRequest request ) -> feedRequest ( request , true ) ) ;", "del_tokens": "* @ param config the crawler configuration public CrawlFrontier ( final CrawlerConfiguration config ) { boolean inCrawlDomain = false ; for ( CrawlDomain allowedCrawlDomain : config . getAllowedCrawlDomains ( ) ) { if ( allowedCrawlDomain . contains ( request . getDomain ( ) ) ) { inCrawlDomain = true ; break ; } } config . getCrawlSeeds ( ) . forEach ( ( CrawlRequest request ) -> { feedRequest ( request , true ) ; } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "validation", "of", "helm2", "parser", "objects"], "add_tokens": "for ( String node : nodes ) {", "del_tokens": "for ( String node : nodes ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "AIOOB", "when", "vector", "is", "smaller", "that", "ordinal"], "add_tokens": "return ( wordIndex < vector . length ) && ( ( vector [ wordIndex ] >>> bitIndex ) & 1 ) != 0 ;", "del_tokens": "return ( ( vector [ wordIndex ] >>> bitIndex ) & 1 ) != 0 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "test", "boundaries", "to", "the", "session", "log", "so", "we", "can", "work", "out", "what", "s", "going", "on"], "add_tokens": "final NioLogger nioLogger = new NioLogger ( \"ALL\" ) ;", "del_tokens": "final NioLogger nioLogger = new NioLogger ( \"NONE\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "default", "to", "not", "use", "Objenesis", "."], "add_tokens": "private InstantiatorStrategy strategy ;", "del_tokens": "private InstantiatorStrategy strategy = new StdInstantiatorStrategy ( ) ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "few", "build", "breaks", "."], "add_tokens": "package org . dihedron . commons . visitor . nodes ; import org . dihedron . commons . visitor . Node ;", "del_tokens": "package org . dihedron . commons . visitor ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "System", ".", "arraycopy", "instead", "of", "for", "loop"], "add_tokens": "System . arraycopy ( buf , 0 , nbuf , 0 , buf . length ) ;", "del_tokens": "for ( int i = 0 ; i < buf . length ; i ++ ) { nbuf [ i ] = buf [ i ] ; }", "commit_type": "use"}
{"commit_tokens": ["Made", "Match", "constructors", "protected", "."], "add_tokens": "protected Match ( ) { protected Match ( int size ) { protected Match ( Match < E > match ) { protected final static class FinalMatch < E > extends Match < E > { protected FinalMatch ( Match < E > m ) { protected final static class IntermediateMatch < E > extends Match < E > { protected IntermediateMatch ( ) { }", "del_tokens": "public Match ( ) { public Match ( int size ) { public Match ( Match < E > match ) { protected static class FinalMatch < E > extends Match < E > { public FinalMatch ( Match < E > m ) { protected static class IntermediateMatch < E > extends Match < E > {", "commit_type": "make"}
{"commit_tokens": ["Move", "more", "of", "the", "date", "setting", "into", "the", "DAOs", "."], "add_tokens": "} @ Override public E create ( E entity ) { Date now = new Date ( ) ; entity . setCreatedAt ( now ) ; entity . setEffectiveAt ( now ) ; entity . setExpiredAt ( null ) ; return super . create ( entity ) ; return getDatabaseSupport ( ) . getCurrent ( getEntityClass ( ) ) ; entity . setCreatedAt ( oldEntity . getCreatedAt ( ) ) ;", "del_tokens": "private final Class < E > entityClass ; this . entityClass = inEntityClass ; return getDatabaseSupport ( ) . getCurrent ( this . entityClass ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "some", "format", "statements", "more", "concise"], "add_tokens": "\"$1N.writeMapBegin($2T.$3L, $2T.$4L, $5L.size())\" , read . addStatement ( \"$1T $2N = $1T.fromCode(protocol.readI32())\" , enumType , target ) ; read . beginControlFlow ( \"for (int $1N = 0; $1N < $2N.size; ++$1N)\" , idx , listInfo ) ; read . beginControlFlow ( \"for (int $1N = 0; $1N < $2N.size; ++$1N)\" , idx , setInfo ) ; read . beginControlFlow ( \"for (int $1N = 0; $1N < $2N.size; ++$1N)\" , idx , mapInfo ) ; read . addStatement ( \"$1T $2N = $1T.ADAPTER.read(protocol)\" , typeName , nameStack . peek ( ) ) ;", "del_tokens": "\"$N.writeMapBegin($T.$L, $T.$L, $L.size())\" , TTYPE , read . addStatement ( \"$T $N = $T.fromCode(protocol.readI32())\" , enumType , target , enumType ) ; read . beginControlFlow ( \"for (int $N = 0; $N < $N.size; ++$N)\" , idx , idx , listInfo , idx ) ; read . beginControlFlow ( \"for (int $N = 0; $N < $N.size; ++$N)\" , idx , idx , setInfo , idx ) ; read . beginControlFlow ( \"for (int $N = 0; $N < $N.size; ++$N)\" , idx , idx , mapInfo , idx ) ; read . addStatement ( \"$T $N = $T.ADAPTER.read(protocol)\" , typeName , nameStack . peek ( ) , typeName ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "UsedConvertersTest", "to", "the", "test", "suite"], "add_tokens": "import net . entropysoft . transmorph . context . UsedConvertersTest ; suite . addTestSuite ( UsedConvertersTest . class ) ;", "del_tokens": "import net . entropysoft . transmorph . signature . ClassFactoryTest ; import net . entropysoft . transmorph . signature . JavaTypeToTypeSignatureTest ; import net . entropysoft . transmorph . signature . TypeSignatureFactoryTest ; import net . entropysoft . transmorph . signature . TypeSignatureParserTest ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "default", "PDATE", "rule", "for", "the", "case", "that", "there", "is", "no", "enough", "days", "in", "the", "weather", "data", "."], "add_tokens": "import org . agmip . common . Functions ; if ( startYear > 0 ) { lastDay = ( startYear + i ) + lDate ; } else if ( windows [ i ] . end >= dailyData . size ( ) ) {", "del_tokens": "if ( windows [ i ] . end >= dailyData . size ( ) ) {", "commit_type": "update"}
{"commit_tokens": ["Adding", "documentation", "annotations", "for", "generating", "JavaDocs"], "add_tokens": "import com . manusunny . pinlock . PinListener ; if ( resultCode == PinListener . SUCCESS ) { } else if ( resultCode == PinListener . CANCELLED ) { if ( resultCode == PinListener . SUCCESS ) { } else if ( resultCode == PinListener . CANCELLED ) { if ( resultCode == PinListener . SUCCESS ) { } else if ( resultCode == PinListener . CANCELLED ) {", "del_tokens": "import com . manusunny . pinlock . PinLock ; if ( resultCode == PinLock . SUCCESS ) { } else if ( resultCode == PinLock . CANCELLED ) { if ( resultCode == PinLock . SUCCESS ) { } else if ( resultCode == PinLock . CANCELLED ) { if ( resultCode == PinLock . SUCCESS ) { } else if ( resultCode == PinLock . CANCELLED ) {", "commit_type": "add"}
{"commit_tokens": ["add", "balance", "with", "roundrobin", "for", "now"], "add_tokens": "void subscribe ( String serviceName , Notifier notifier ) ; void unsubscribe ( String serviceName , Notifier notifier ) ; List < URL > discover ( String serviceName ) ;", "del_tokens": "void subscribe ( URL url , Notifier notifier ) ; void unsubscribe ( URL url , Notifier notifier ) ; List < URL > discover ( URL url ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "hadoop_version", "able", "to", "take", "a", "jar", "directory"], "add_tokens": "import java . io . File ; import H2OInit . Boot ; if ( Boot . _init . fromJar ( ) ) { File f = new File ( version ) ; if ( f . exists ( ) ) { Boot . _init . addExternalJars ( f ) ; } else { Boot . _init . addInternalJars ( \"hadoop/\" + version + \"/\" ) ; } }", "del_tokens": "import H2OInit . Boot ; if ( Boot . _init . fromJar ( ) ) Boot . _init . addInternalJars ( \"hadoop/\" + version + \"/\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Implement", "net", "open", "that", "I", "d", "previously", "forgotten", "to", "do", "."], "add_tokens": "String response = resp_array . get ( resp_array . size ( ) - 1 ) ;", "del_tokens": "String response = resp_array . get ( 0 ) ;", "commit_type": "implement"}
{"commit_tokens": ["Changed", "FFmpeg", ".", "version", "()", "to", "cache", "the", "value", "."], "add_tokens": "version ( ) ; if ( this . version == null ) { Process p = runFunc . run ( ImmutableList . of ( path , \"-version\" ) ) ; try { BufferedReader r = wrapInReader ( p ) ; this . version = r . readLine ( ) ; IOUtils . copy ( r , new NullOutputStream ( ) ) ; // Throw away rest of the output FFmpegUtils . throwOnError ( FFMPEG , p ) ; } finally { p . destroy ( ) ; } return version ;", "del_tokens": "this . version = version ( ) ; String readVersion ; Process p = runFunc . run ( ImmutableList . of ( path , \"-version\" ) ) ; try { BufferedReader r = wrapInReader ( p ) ; readVersion = r . readLine ( ) ; IOUtils . copy ( r , new NullOutputStream ( ) ) ; // Throw away rest of the output FFmpegUtils . throwOnError ( \"ffmpeg\" , p ) ; } finally { p . destroy ( ) ; return readVersion ;", "commit_type": "change"}
{"commit_tokens": ["Added", "original", "size", "parameter", "for", "resize"], "add_tokens": "/** Original size for image width or height. **/ public static final int ORIGINAL_SIZE = Integer . MIN_VALUE ; if ( width < 0 && width != ORIGINAL_SIZE ) { if ( height < 0 && height != ORIGINAL_SIZE ) { if ( resizeWidth == ORIGINAL_SIZE ) { builder . append ( \"orig\" ) ; } else { builder . append ( resizeWidth ) ; } builder . append ( \"x\" ) ; if ( resizeHeight == ORIGINAL_SIZE ) { builder . append ( \"orig\" ) ; } else { builder . append ( resizeHeight ) ; }", "del_tokens": "if ( width < 0 ) { if ( height < 0 ) { builder . append ( resizeWidth ) . append ( \"x\" ) ; builder . append ( resizeHeight ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "https", "lookup", "NPE", "bugfix"], "add_tokens": "byte [ ] body = server . errorPages . apply ( status ) ; new HttpPacket ( status , getReason ( status ) , body , \"Connection\" , \"close\" ) . write ( handler , true , false ) ; handler . setBufferSize ( MAX_BUFFER_SIZE ) ; server . proxyTimeoutQueue . offer ( this ) ; read ( ) ; handler . disconnect ( ) ; onDisconnect ( ) ;", "del_tokens": "// \"lookup\" starting with \"https://\" means a secure host if ( host . startsWith ( \"https://\" ) ) { host = host . substring ( 8 ) ; secure = true ; } if ( handler != null ) { byte [ ] body = server . errorPages . apply ( status ) ; new HttpPacket ( status , getReason ( status ) , body , \"Connection\" , \"close\" ) . write ( handler , true , false ) ; } // \"proxy\" may be disconnected before reset if ( handler != null ) { handler . setBufferSize ( MAX_BUFFER_SIZE ) ; server . proxyTimeoutQueue . offer ( this ) ; } if ( handler != null ) { read ( ) ; } handler = null ; if ( handler != null ) { handler . disconnect ( ) ; onDisconnect ( ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Updated", "dependency", "and", "plugin", "versions"], "add_tokens": "LockVariables (", "del_tokens": "public LockVariables (", "commit_type": "update"}
{"commit_tokens": ["Added", "ProcessInitException", "to", "expose", "error", "code", "."], "add_tokens": "String message = getExecutingErrorMessage ( ) ; ProcessInitException p = ProcessInitException . newInstance ( message , e ) ; if ( p != null ) { throw p ; } throw new IOException ( message , e ) ;", "del_tokens": "throw new IOException ( getExecutingErrorMessage ( ) , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "printing", "for", "a", "constructor", "if", "it", "is", "the", "default", "(", "generated", ")", "constructor", "or", "not", "."], "add_tokens": "import com . sun . tools . javac . code . Flags ; final String type ; if ( method . name . contentEquals ( \"<init>\" ) ) { if ( ( method . mods . flags & Flags . GENERATEDCONSTR ) != 0 ) { type = \"DEFAULTCONSTRUCTOR\" ; } else type = \"CONSTRUCTOR\" ; } else type = \"METHOD\" ; print ( \"<%s %s> returns: %s\" , type , method . name , method . restype ) ; print ( \"</%s %s>\" , \"XMETHOD\" , method . name ) ;", "del_tokens": "String type = method . name . contentEquals ( \"<init>\" ) ? \"CONSTRUCTOR\" : \"METHOD\" ; print ( \"<%s %s>\" , type , method . name ) ; String type = method . name . contentEquals ( \"<init>\" ) ? \"CONSTRUCTOR\" : \"METHOD\" ; print ( \"</%s %s>\" , type , method . name ) ;", "commit_type": "add"}
{"commit_tokens": ["Used", "ColorHelper", "from", "core", "helper", "classes", "to", "convert", "material", "colors", "to", "raw", "colors", "."], "add_tokens": "import gwt . material . design . client . base . helper . ColorHelper ; String computed = ColorHelper . setupComputedBackgroundColor ( backgroundColor ) ;", "del_tokens": "RootPanel . get ( ) . add ( temp ) ; String computed = getComputedBackgroundColor ( temp . getElement ( ) ) . toLowerCase ( ) ; // remove from the DOM after the evaluation temp . removeFromParent ( ) ; / * * * Native call to getComputedStyle . * / private native String getComputedBackgroundColor ( Element e ) / * - { var cs = $ wnd . document . defaultView . getComputedStyle ( e , null ) ; return cs . getPropertyValue ( 'background-color' ) ; } - * / ;", "commit_type": "use"}
{"commit_tokens": ["Added", "special", "null", "safe", "string", "comparators"], "add_tokens": "import javax . annotation . Nullable ; * A { @ link Comparator } for { @ link Comparable } objects that can handle * < code > null < / code > values . protected final int mainCompare ( @ Nullable final DATATYPE aElement1 , @ Nullable final DATATYPE aElement2 ) return CompareHelper . compare ( aElement1 , aElement2 , isNullValuesComeFirst ( ) ) ;", "del_tokens": "import javax . annotation . Nonnull ; * This is another * lol * class : a { @ link Comparator } for { @ link Comparable } * objects . protected final int mainCompare ( @ Nonnull final DATATYPE aElement1 , @ Nonnull final DATATYPE aElement2 ) return aElement1 . compareTo ( aElement2 ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "rxjava", "-", "extras", "to", "test", "StringSplitOperator", "fully"], "add_tokens": "import au . gov . amsa . streams . Strings ; return Strings . split ( StringObservable", "del_tokens": "return StringObservable . split ( StringObservable", "commit_type": "use"}
{"commit_tokens": ["changing", "the", "internal", "implementation", "of", "SAXRecord", "store", "from", "ArrayList"], "add_tokens": "import java . util . Collection ; import java . util . HashSet ; private HashSet < Integer > occurrences ; this . occurrences = new HashSet < Integer > ( ) ; public Collection < Integer > getIndexes ( ) {", "del_tokens": "private ArrayList < Integer > occurrences ; this . occurrences = new ArrayList < Integer > ( ) ; public ArrayList < Integer > getIndexes ( ) {", "commit_type": "change"}
{"commit_tokens": ["use", "TreeMap", "with", "String", ".", "CASE_INSENSITIVE_ORDER", "instead", "of", "CaseInsesitiveMap", "implementation", "."], "add_tokens": "import java . util . Map ; import java . util . TreeMap ; // CaseInsensitiveMap private Map < String , Object > args = new TreeMap < > ( String . CASE_INSENSITIVE_ORDER ) ; // CaseInsensitiveMap private Map < String , Class < ? > > argTypes = new TreeMap < > ( String . CASE_INSENSITIVE_ORDER ) ;", "del_tokens": "import com . miragesql . miragesql . util . CaseInsensitiveMap ; private CaseInsensitiveMap args = new CaseInsensitiveMap ( ) ; private CaseInsensitiveMap argTypes = new CaseInsensitiveMap ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "non", "-", "standard", "new", "-", "line", "delimiters", "such", "as", "\\", "r", "\\", "n", "work", "."], "add_tokens": "import java . io . PushbackInputStream ; private final PushbackInputStream inputStream ; this . inputStream = new PushbackInputStream ( new GZIPInputStream ( new FileInputStream ( file ) ) ) ; this . inputStream = new PushbackInputStream ( new FileInputStream ( file ) ) ; this . inputStream = new PushbackInputStream ( stream ) ; readHeader ( this . inputStream ) ; private void readHeader ( final PushbackInputStream stream ) throws IOException {", "del_tokens": "private final InputStream inputStream ; this . inputStream = new GZIPInputStream ( new FileInputStream ( file ) ) ; this . inputStream = new FileInputStream ( file ) ; this . inputStream = stream ; readHeader ( stream ) ; private void readHeader ( final InputStream stream ) throws IOException {", "commit_type": "make"}
{"commit_tokens": ["fixed", "bug", "when", "nextPage", "and", "previousPage", "methods", "always", "return", "first", "page"], "add_tokens": "private int pageSize = 100 ;", "del_tokens": "private int pageSize = 0 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "followers", "to", "user", "response"], "add_tokens": "import static junit . framework . TestCase . assertNotNull ; assertEquals ( \"Michael\" , user . getDisplayName ( ) ) ; assertEquals ( \"thelinmichael+test@gmail.com\" , user . getEmail ( ) ) ; assertEquals ( \"https://open.spotify.com/user/thelinmichael\" , user . getExternalUrls ( ) . get ( \"spotify\" ) ) ; assertEquals ( \"SE\" , user . getCountry ( ) ) ; assertNotNull ( user . getFollowers ( ) ) ; assertEquals ( \"Michael\" , user . getDisplayName ( ) ) ; assertEquals ( \"thelinmichael+test@gmail.com\" , user . getEmail ( ) ) ; assertEquals ( \"https://open.spotify.com/user/thelinmichael\" , user . getExternalUrls ( ) . get ( \"spotify\" ) ) ; assertEquals ( \"SE\" , user . getCountry ( ) ) ; assertNotNull ( user . getFollowers ( ) ) ;", "del_tokens": "assertNull ( user . getDisplayName ( ) ) ; assertEquals ( \"thelinmichael@gmail.com\" , user . getEmail ( ) ) ; assertEquals ( \"https://open.spotify.com/user/thelinmichael\" , user . getExternalUrls ( ) . get ( \"spotify\" ) ) ; assertNull ( user . getDisplayName ( ) ) ; assertEquals ( \"thelinmichael@gmail.com\" , user . getEmail ( ) ) ; assertEquals ( \"https://open.spotify.com/user/thelinmichael\" , user . getExternalUrls ( ) . get ( \"spotify\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "Deque", "instead", "of", "Stack", "."], "add_tokens": "import java . util . Deque ; import java . util . LinkedList ; private Deque < Import > stack = new LinkedList < > ( ) ;", "del_tokens": "import java . util . Stack ; private Stack < Import > stack = new Stack < > ( ) ;", "commit_type": "use"}
{"commit_tokens": ["use", "transition", "listener", "to", "check", "for", "leader", "election", "when", "testing", "consistency"], "add_tokens": "import org . robotninjas . barge . state . StateTransitionListener ; executor . submit ( new Callable < ListenableFuture < Object > > ( ) { @ Override public ListenableFuture < Object > call ( ) throws Exception { return ctx . commitOperation ( operation ) ; } } ) ; private void addTransitionListener ( StateTransitionListener listener ) { ctx . addTransitionListener ( listener ) ; } private StateTransitionListener listener ; NettyRaftService nettyRaftService = Guice . createInjector ( new NettyRaftModule ( config , logDir , stateMachine , timeout ) ) . getInstance ( NettyRaftService . class ) ; nettyRaftService . addTransitionListener ( listener ) ; return nettyRaftService ; public Builder transitionListener ( StateTransitionListener listener ) { this . listener = listener ; return this ; }", "del_tokens": "executor . submit ( new Callable < ListenableFuture < Object > > ( ) { @ Override public ListenableFuture < Object > call ( ) throws Exception { return ctx . commitOperation ( operation ) ; } } ) ; return Guice . createInjector ( new NettyRaftModule ( config , logDir , stateMachine , timeout ) ) . getInstance ( NettyRaftService . class ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "timezone", "sensitive", "unit", "test"], "add_tokens": "import org . joda . time . DateTimeZone ; DateTime dt = new DateTime ( ) . withZone ( DateTimeZone . forTimeZone ( TimeZone . getTimeZone ( \"GMT+2\" ) ) ) . withHourOfDay ( 13 ) . withMinuteOfHour ( 14 ) ;", "del_tokens": "DateTime dt = new DateTime ( ) . withHourOfDay ( 13 ) . withMinuteOfHour ( 14 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "use", "of", "com", ".", "google", ".", "common", ".", "io", ".", "ByteStreams"], "add_tokens": "SliceStreamUtils . copyStream ( this , out , length ) ;", "del_tokens": "import com . google . common . io . ByteStreams ; import com . google . common . io . CountingInputStream ; ByteStreams . copy ( ByteStreams . limit ( countingInputStream , length ) , out ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "enumeration", "for", "transaction", "isolation", "levels", "."], "add_tokens": "/** Transaction isolation level to use, or null to indicate default */ @ Nullable private Isolation transactionIsolation = null ; Isolation isolation = transactionIsolation ; if ( isolation != null ) connection . setTransactionIsolation ( isolation . level ) ; / * * * Returns the used transaction isolation level , or null for default leve . * / @ Nullable public Isolation getTransactionIsolation ( ) { * Sets the transaction isolation level to use , or null for default level public void setTransactionIsolation ( @ Nullable Isolation isolation ) { this . transactionIsolation = isolation ;", "del_tokens": "/** Transaction isolation level to use, or -1 to indicate default */ private int transactionIsolation = - 1 ; if ( transactionIsolation != - 1 ) connection . setTransactionIsolation ( transactionIsolation ) ; public int getTransactionIsolation ( ) { * Sets the transaction - isolation level to use . * * @ see Connection # TRANSACTION_NONE * @ see Connection # TRANSACTION_READ_UNCOMMITTED * @ see Connection # TRANSACTION_READ_COMMITTED * @ see Connection # TRANSACTION_REPEATABLE_READ * @ see Connection # TRANSACTION_SERIALIZABLE public void setTransactionIsolation ( int level ) { if ( level != - 1 && level != Connection . TRANSACTION_NONE && level != Connection . TRANSACTION_READ_COMMITTED && level != Connection . TRANSACTION_READ_UNCOMMITTED && level != Connection . TRANSACTION_REPEATABLE_READ && level != Connection . TRANSACTION_SERIALIZABLE ) throw new IllegalArgumentException ( \"invalid isolation level: \" + level ) ; this . transactionIsolation = level ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "missing", "SERVO", "mode", "."], "add_tokens": "} else if ( currentMode == Mode . ANALOG || currentMode == Mode . PWM || currentMode == Mode . SERVO ) {", "del_tokens": "} else if ( currentMode == Mode . ANALOG || currentMode == Mode . PWM ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "passing", "-", "XdisableRunAsync", "to", "GWT", "compiler", "."], "add_tokens": "/ * * * EXPERIMENTAL : Disables code - splitting . * < p > * Can be set from command line using '-Dgwt.disableRunAsync=true' . * < / p > * * @ parameter default - value = \"false\" expression = \"${gwt.disableRunAsync}\" * / private boolean disableRunAsync ; . arg ( disableCastChecking , \"-XdisableCastChecking\" ) . arg ( disableRunAsync , \"-XdisableRunAsync\" ) . arg ( strict , \"-strict\" )", "del_tokens": ". arg ( disableCastChecking , \"-XdisableCastChecking\" ) . arg ( strict , \"-strict\" )", "commit_type": "add"}
{"commit_tokens": ["Use", "heap", "buffers", "in", "all", "log", "usage", "."], "add_tokens": "import io . atomix . catalyst . buffer . Buffer ; import io . atomix . catalyst . buffer . FileBuffer ; import io . atomix . catalyst . buffer . HeapBuffer ; import io . atomix . catalyst . buffer . MappedBuffer ; Buffer buffer = HeapBuffer . allocate ( 1024 * 1024 , descriptor . maxSegmentSize ( ) + SegmentDescriptor . BYTES ) ; Buffer buffer = HeapBuffer . allocate ( Math . min ( 1024 * 1024 , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) ;", "del_tokens": "import io . atomix . catalyst . buffer . * ; Buffer buffer = DirectBuffer . allocate ( 1024 * 1024 , descriptor . maxSegmentSize ( ) + SegmentDescriptor . BYTES ) ; Buffer buffer = DirectBuffer . allocate ( Math . min ( 1024 * 1024 , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) , storage . maxSegmentSize ( ) + storage . maxEntrySize ( ) + SegmentDescriptor . BYTES ) ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "some", "handy", "methods", "to", "copy", "URL", "with", "Service", "and", "Characteristic"], "add_tokens": "url = url . copyWithService ( \"0000180f-0000-1000-8000-00805f9b34fb\" ) ; assertEquals ( new URL ( \"tinyb://54:60:09:95:86:01/11:22:33:44:55:66/0000180f-0000-1000-8000-00805f9b34fb\" ) , url ) ; url = url . copyWithCharacteristic ( \"00002a19-0000-1000-8000-00805f9b34fb\" ) ; url = url . copyWith ( \"0000180f-0000-1000-8000-00805f9b34fc\" , \"00002a19-0000-1000-8000-00805f9b34fc\" ) ; assertEquals ( new URL ( \"tinyb://54:60:09:95:86:01/11:22:33:44:55:66/0000180f-0000-1000-8000-00805f9b34fc/00002a19-0000-1000-8000-00805f9b34fc\" ) , url ) ; url = url . copyWith ( \"0000180f-0000-1000-8000-00805f9b34fd\" , \"00002a19-0000-1000-8000-00805f9b34fd\" , \"Level\" ) ; assertEquals ( new URL ( \"tinyb://54:60:09:95:86:01/11:22:33:44:55:66/0000180f-0000-1000-8000-00805f9b34fd/00002a19-0000-1000-8000-00805f9b34fd/Level\" ) , url ) ; assertEquals ( new URL ( \"tinyb://54:60:09:95:86:01/11:22:33:44:55:66/0000180f-0000-1000-8000-00805f9b34fd/00002a19-0000-1000-8000-00805f9b34fd/Power\" ) , url ) ;", "del_tokens": "url = url . copyWith ( \"0000180f-0000-1000-8000-00805f9b34fb\" , \"00002a19-0000-1000-8000-00805f9b34fb\" ) ; url = url . copyWith ( \"0000180f-0000-1000-8000-00805f9b34fb\" , \"00002a19-0000-1000-8000-00805f9b34fb\" , \"Level\" ) ; assertEquals ( new URL ( \"tinyb://54:60:09:95:86:01/11:22:33:44:55:66/0000180f-0000-1000-8000-00805f9b34fb/00002a19-0000-1000-8000-00805f9b34fb/Level\" ) , url ) ; assertEquals ( new URL ( \"tinyb://54:60:09:95:86:01/11:22:33:44:55:66/0000180f-0000-1000-8000-00805f9b34fb/00002a19-0000-1000-8000-00805f9b34fb/Power\" ) , url ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "all", "the", "inconsistencies", "I", "could", "find"], "add_tokens": "log . debug ( \"getManager: {}\" , path ) ; if ( log . isTraceEnabled ( ) ) { log . trace ( \"Path parts: {}\" , Arrays . toString ( parts ) ) ; } if ( appScope . getName ( ) . equals ( parts [ 1 ] ) ) { log . debug ( \"Application scope name matches path: {}\" , parts [ 1 ] ) ; } else if ( log . isTraceEnabled ( ) ) { log . trace ( \"Application scope name: {} didnt match path: {}\" , appScope . getName ( ) , parts [ 1 ] ) ; / * * * Removes and returns the WebSocketScopeManager for the given scope if it exists and returns null if it does not . * * @ param scope Scope for which the manager is registered * @ return WebSocketScopeManager if registered for the given path and null otherwise * / public WebSocketScopeManager removeManager ( IScope scope ) { return managerMap . remove ( scope ) ; }", "del_tokens": "log . debug ( \"Path parts: {}\" , Arrays . toString ( parts ) ) ; if ( appScope . getName ( ) . equals ( parts [ 0 ] ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "wrlog", "and", "zscore", "to", "json"], "add_tokens": "private Optional < Float > wr = Optional . absent ( ) ; private Optional < Float > wrLog = Optional . absent ( ) ; private Optional < Float > wrLogZScore = Optional . absent ( ) ; if ( wr . isPresent ( ) ) term . setWR ( wr . get ( ) ) ; if ( wrLog . isPresent ( ) ) term . setWRLog ( wrLog . get ( ) ) ; if ( wrLogZScore . isPresent ( ) ) term . setWRLogZScore ( wrLogZScore . get ( ) ) ; public TermBuilder setWRLog ( float wrLog ) { this . wrLog = Optional . of ( wrLog ) ; return this ; } public TermBuilder setWRLogZScore ( float wrLogZScore ) { this . wrLogZScore = Optional . of ( wrLogZScore ) ; return this ; } public TermBuilder setWR ( float wr ) { this . wr = Optional . of ( wr ) ;", "del_tokens": "private Optional < Float > specificity = Optional . absent ( ) ; if ( specificity . isPresent ( ) ) term . setWR ( specificity . get ( ) ) ; public TermBuilder setSpecificity ( float spec ) { this . specificity = Optional . of ( spec ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "new", "filter", "method", "-", "Cassandra"], "add_tokens": "import static com . datastax . driver . core . querybuilder . QueryBuilder . eq ; import com . datastax . driver . core . querybuilder . Clause ; import com . datastax . driver . core . querybuilder . QueryBuilder ; import com . stratio . deep . commons . filter . FilterOperator ; private Filter [ ] filters ; filters ( extractorConfig . getFilterArray ( ExtractorConstants . FILTER_QUERY ) ) ; @ Override public ICassandraDeepJobConfig < T > filters ( Filter ... filters ) { this . filters = filters ; return this ; } @ Override public Filter [ ] getFilters ( ) { return filters ; } / * * * { @ inheritDoc } * /", "del_tokens": "//TODO: add operations Filter [ ] filters = extractorConfig . getFilterArray ( ExtractorConstants . FILTER_QUERY ) ; for ( int i = 0 ; i < filters . length ; i ++ ) { filterByField ( filters [ i ] . getField ( ) , filters [ i ] . getValue ( ) ) ; } / * * * { @ inheritDoc } * /", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "convenience", "constructor", "to", "FacebookTemplate", "to", "construct", "the", "FacebookTemplate", "from", "a", "given", "access", "token", "."], "add_tokens": "import java . util . Arrays ; import org . springframework . http . MediaType ; import org . springframework . http . converter . json . MappingJacksonHttpMessageConverter ; RestTemplate restTemplate = new RestTemplate ( new OAuthSigningClientHttpRequestFactory ( new FacebookRequestSigner ( MappingJacksonHttpMessageConverter json = new MappingJacksonHttpMessageConverter ( ) ; json . setSupportedMediaTypes ( Arrays . asList ( new MediaType ( \"text\" , \"javascript\" ) ) ) ; restTemplate . getMessageConverters ( ) . add ( json ) ; this . restOperations = restTemplate ;", "del_tokens": "this . restOperations = new RestTemplate ( new OAuthSigningClientHttpRequestFactory ( new FacebookRequestSigner (", "commit_type": "add"}
{"commit_tokens": ["Make", "BasePresentationModel", ".", "setDirty", "public", "so", "that", "it", "can", "be", "changed", "from", "the", "outside"], "add_tokens": "public void setDirty ( boolean dirty ) {", "del_tokens": "private void setDirty ( boolean dirty ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "an", "html", "ansi", "output", "stream", "fixed", "default", "foreground", "/", "background", "processing", "."], "add_tokens": "processDefaultTextColor ( ) ; break ; processDefaultBackgroundColor ( ) ; break ; case 0 : processAttributeRest ( ) ; break ; protected void processDefaultTextColor ( ) throws IOException { } protected void processDefaultBackgroundColor ( ) throws IOException { }", "del_tokens": "case 0 : processAttributeRest ( ) ; break ;", "commit_type": "add"}
{"commit_tokens": ["removed", "useless", "methods", "+", "update", "readme", "and", "version"], "add_tokens": "private void show ( ) {", "del_tokens": "public void setTitle ( String title ) { this . title = title ; } public void setTitle ( int resTitle ) { this . title = context . getResources ( ) . getString ( resTitle ) ; } public void setMessage ( String message ) { this . message = message ; } public void setMessage ( int resMessage ) { this . message = context . getResources ( ) . getString ( resMessage ) ; } public void setFingerprintCallback ( FingerprintCallback fingerprintCallback ) { this . fingerprintCallback = fingerprintCallback ; } public void show ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "POMs", "to", "generate", "JavaDoc", "for", "-", "Prelease", "profile", "."], "add_tokens": "* REST - assured filter that signs a request usings EdgeGrid V1 signing algorithm . Signing is a process of adding an Authorization header with a request signature . * Creates a REST - assured filter that will sign a request with a given credential using a custom signer .", "del_tokens": "* REST - zssured filter that signs a request usings EdgeGrid V1 signing algorithm . Signing is a process of adding to * a request an Authorization header with a signature of a request . * Creates a REST - assured filter that will sign a request with a given credential using a given customer signer .", "commit_type": "fix"}
{"commit_tokens": ["Fix", "broken", "tests", ":", "incorrect", "DB", "name"], "add_tokens": "graph = new OrientGraph ( \"memory:ETLBaseTest\" ) ;", "del_tokens": "graph = new OrientGraph ( \"memory:EtlTest\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["improve", "test", "coverage", "for", "Media", "Services"], "add_tokens": "mediaServicesProperties . MEDIA_SERVICE_URI , mediaServicesProperties . OAUTH_URI , mediaServicesProperties . SCOPE ) ;", "del_tokens": "mediaServicesProperties . getMediaServiceUri ( ) , mediaServicesProperties . getoAuthUri ( ) , mediaServicesProperties . getScope ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "support", "reading", "private", "keys", "and", "certificates", "for", "signing"], "add_tokens": "import java . security . Key ; import java . security . UnrecoverableKeyException ; import java . security . cert . Certificate ; public void createKeyStoreforPasswords ( ) throws IOException , NoSuchAlgorithmException , CertificateException , KeyStoreException , InvalidKeySpecException , UnrecoverableEntryException { @ Test public void getPrivateKeyAndCertificate ( ) throws IOException , UnrecoverableKeyException , KeyStoreException , NoSuchAlgorithmException , CertificateException { Configuration conf = new Configuration ( HadoopKeyStoreManagerTest . defaultConf ) ; ClassLoader classLoader = getClass ( ) . getClassLoader ( ) ; String fileName = \"testsigning.pfx\" ; String fileNameKeyStore = classLoader . getResource ( fileName ) . getFile ( ) ; Path file = new Path ( fileNameKeyStore ) ; HadoopKeyStoreManager hksm = new HadoopKeyStoreManager ( conf ) ; hksm . openKeyStore ( file , \"PKCS12\" , \"changeit\" ) ; // load private key Key privateKey = hksm . getPrivateKey ( \"testalias\" , \"changeit\" ) ; assertNotNull ( privateKey , \"Private key could be loaded\" ) ; // load certificate Certificate certificate = hksm . getCertificate ( \"testalias\" ) ; assertNotNull ( certificate , \"Certificate for private key could be loaded\" ) ; }", "del_tokens": "public void createKeyStore ( ) throws IOException , NoSuchAlgorithmException , CertificateException , KeyStoreException , InvalidKeySpecException , UnrecoverableEntryException {", "commit_type": "add"}
{"commit_tokens": ["fixing", "typo", "+", "removing", "obsolete", "method"], "add_tokens": "normalizeWhitespace ( expElement , ignoreWhitespace ) ; normalizeWhitespace ( wasElement , ignoreWhitespace ) ; private static void normalizeWhitespace ( Element element , boolean ignoreWhitespace ) normalizeWhitespace ( ( Element ) node , ignoreWhitespace ) ;", "del_tokens": "public boolean hasJDK15 ( ) { try { Class . forName ( \"java.lang.Enum\" ) ; return true ; } catch ( ClassNotFoundException ex ) { return false ; } } normalizeWhitspace ( expElement , ignoreWhitespace ) ; normalizeWhitspace ( wasElement , ignoreWhitespace ) ; private static void normalizeWhitspace ( Element element , boolean ignoreWhitespace ) normalizeWhitspace ( ( Element ) node , ignoreWhitespace ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "intent", "to", "open", "Gmail"], "add_tokens": "intent . setClassName ( \"com.google.android.gm\" , \"com.google.android.gm.ComposeActivityGmail\" ) ; startActivity ( Intent . createChooser ( intent , \"\" ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["make", "what", "can", "be", "final", "in", "SlackApi"], "add_tokens": "final URL url = new URL ( this . service ) ; final String payload = \"payload=\" final DataOutputStream wr = new DataOutputStream ( final InputStream is = connection . getInputStream ( ) ; final BufferedReader rd = new BufferedReader ( new InputStreamReader ( is ) ) ;", "del_tokens": "URL url ; url = new URL ( this . service ) ; String payload = \"payload=\" DataOutputStream wr = new DataOutputStream ( InputStream is = connection . getInputStream ( ) ; BufferedReader rd = new BufferedReader ( new InputStreamReader ( is ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "request", "cookies"], "add_tokens": "@ Test public void requestSpecificationAllowsSpecifyingCookie ( ) throws Exception { given ( ) . cookies ( \"username\" , \"John\" , \"token\" , \"1234\" ) . then ( ) . expect ( ) . body ( equalTo ( \"username, token\" ) ) . when ( ) . post ( \"/cookie\" ) ; }", "del_tokens": "import static groovyx . net . http . ContentType . TEXT ;", "commit_type": "add"}
{"commit_tokens": ["updated", "docs", "on", "new", "plugin", "resource", "API", "/", "constraints"], "add_tokens": "import java . lang . annotation . Retention ; import java . lang . annotation . Target ; * Signals to the framework that the annotated plugin or command should be * favored over the default implementation when a { @ link Resource } of the type * requested by a { @ link ResourceScope } is currently in scope . * < p > * Scopes and overloads are checked at boot time ; if conflicts are detected , the * shell will fail to boot . ( No two plugins or commands can declare the same * { @ link OverloadedName } and { @ link ResourceScope } ) * @ Target ( { TYPE , METHOD } )", "del_tokens": "import org . jboss . seam . forge . project . Resource ; import java . lang . annotation . Retention ; import java . lang . annotation . Target ; * A special plugin for facilitating plugins with overloaded names . * @ Target ( { TYPE , METHOD } )", "commit_type": "update"}
{"commit_tokens": ["Changed", "method", "name", "to", "be", "consistent", "with", "other", "clustering", "algorithms", ".", "Include", "check", "to", "prevent", "incorrect", "use", "case", "."], "add_tokens": "* Returns the cluster labels for each neuron . If the neurons have * not been clustered , throws an Illegal State Exception . public int [ ] [ ] getClusterLabel ( ) { if ( y == null ) { throw new IllegalStateException ( ) ; } int [ ] [ ] classLabels = new int [ height ] [ width ] ; classLabels [ i ] [ j ] = y [ i * width + j ] ; return classLabels ;", "del_tokens": "* Returns the cluster labels for each Neuron . public int [ ] [ ] clabels ( ) { int [ ] [ ] clabels = new int [ height ] [ width ] ; clabels [ i ] [ j ] = y [ i * width + j ] ; return clabels ;", "commit_type": "change"}
{"commit_tokens": ["Make", "sure", "we", "set", "the", "value", "to", "shared", "when", "AHC", "is", "passed"], "add_tokens": "return runtime ( client , true ) ;", "del_tokens": "return runtime ( client , false ) ;", "commit_type": "make"}
{"commit_tokens": ["changing", "nullable", "flag", "to", "isNullable"], "add_tokens": "boolean nullable = schemaNode . has ( \"isNullable\" ) ? schemaNode . get ( \"isNullable\" ) . getAsBoolean ( ) : false ;", "del_tokens": "boolean nullable = schemaNode . has ( \"nullable\" ) ? schemaNode . get ( \"nullable\" ) . getAsBoolean ( ) : false ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "immediate", "re", "-", "ask"], "add_tokens": "private static final String KEY_ASK_LATER_DATE = \"rta_ask_later_date\" ; private static Date mAskLaterDate = new Date ( ) ; mAskLaterDate = new Date ( pref . getLong ( KEY_ASK_LATER_DATE , 0 ) ) ; if ( new Date ( ) . getTime ( ) - mInstallDate . getTime ( ) >= threshold && new Date ( ) . getTime ( ) - mAskLaterDate . getTime ( ) >= threshold ) { storeAskLaterDate ( context ) ; storeAskLaterDate ( context ) ; / * * * Store the date the user asked for being asked again later . * @ param context * / private static void storeAskLaterDate ( final Context context ) { SharedPreferences pref = context . getSharedPreferences ( PREF_NAME , Context . MODE_PRIVATE ) ; Editor editor = pref . edit ( ) ; editor . putLong ( KEY_ASK_LATER_DATE , System . currentTimeMillis ( ) ) ; editor . commit ( ) ; }", "del_tokens": "if ( new Date ( ) . getTime ( ) - mInstallDate . getTime ( ) >= threshold ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "push", "client", "id", "from", "Integer", "to", "String"], "add_tokens": "* LastModified : Aug 11 , 2015 * void subscribe ( String topic , String id , HproseService service ) ; void unsubscribe ( String topic , String id , HproseService service ) ;", "del_tokens": "* LastModified : May 3 , 2015 * void subscribe ( String topic , int id , HproseService service ) ; void unsubscribe ( String topic , int id , HproseService service ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "class", "resolution", "of", "primitive", "arrays", "."], "add_tokens": "static Class < ? > loadClass ( String paramType , ClassLoader classLoader ) { Class < ? > clazz = Type . findPrimitiveClass ( paramType ) ; if ( clazz == null ) { try { clazz = classLoader . loadClass ( paramType ) ; } catch ( ClassNotFoundException e ) { throw new RuntimeException ( e ) ; }", "del_tokens": "private Class < ? > loadClass ( String paramType , ClassLoader classLoader ) { Class < ? > clazz ; try { clazz = classLoader . loadClass ( paramType ) ; } catch ( ClassNotFoundException e ) { throw new RuntimeException ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "replacedImagesWithAlt", "configuration", "option", "(", "hidden", "for", "now", ")"], "add_tokens": "/** Replace the images with their {@code alt} text */ protected boolean replaceImagesWithAlt ; public CSSBoxTreeBuilder ( Dimension pageSize , boolean useVisualBounds , boolean replaceImagesWithAlt ) this . replaceImagesWithAlt = replaceImagesWithAlt ; contentCanvas . getConfig ( ) . setReplaceImagesWithAlt ( replaceImagesWithAlt ) ;", "del_tokens": "public CSSBoxTreeBuilder ( Dimension pageSize , boolean useVisualBounds ) contentCanvas . getConfig ( ) . setReplaceImagesWithAlt ( true ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "compareDestination", "=", "true", "detect", "non", "-", "existing", "files", "in", "preprocessing", "mode"], "add_tokens": "boolean needWrite = true ; // better write than not final byte [ ] contentInBinaryForm = content . getBytes ( globalOutCharacterEncoding ) ; if ( outFile . isFile ( ) && outFile . length ( ) == contentInBinaryForm . length ) { // If file exists and has the same content, then skip overwriting it InputStream currentFileInputStream = null ; try { currentFileInputStream = new BufferedInputStream ( new FileInputStream ( outFile ) , Math . max ( 16384 , ( int ) outFile . length ( ) ) ) ; needWrite = ! IOUtils . contentEquals ( currentFileInputStream , new ByteArrayInputStream ( contentInBinaryForm ) ) ; } finally { IOUtils . closeQuietly ( currentFileInputStream ) ; if ( needWrite ) { FileUtils . writeByteArrayToFile ( outFile , contentInBinaryForm , false ) ; wasSaved = true ; }", "del_tokens": "if ( outFile . isFile ( ) ) { final byte [ ] contentInBinaryForm = content . getBytes ( globalOutCharacterEncoding ) ; final InputStream currentFileInputStream = new BufferedInputStream ( new FileInputStream ( outFile ) , Math . max ( 16384 , ( int ) outFile . length ( ) ) ) ; if ( ! IOUtils . contentEquals ( currentFileInputStream , new ByteArrayInputStream ( contentInBinaryForm ) ) ) { currentFileInputStream . close ( ) ; FileUtils . writeByteArrayToFile ( outFile , contentInBinaryForm , false ) ; wasSaved = true ;", "commit_type": "make"}
{"commit_tokens": ["removed", "unused", "imports", "and", "added", "license", "in", "files"], "add_tokens": "import com . github . pwittchen . networkevents . library . internet . OnlineCheckerImpl ;", "del_tokens": "import com . github . pwittchen . networkevents . library . internet . OnlineChecker ; import com . github . pwittchen . networkevents . library . internet . OnlineCheckerImpl ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "@Generated", "annotation", "to", "the", "output", "of", "AutoValueProcessor", "."], "add_tokens": "// @Generated annotation \"@javax.annotation.Generated(\\\"com.google.auto.value.processor.AutoValueProcessor\\\")\" , }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["add", "missing", "acquiresResource", "identifier", "to", "Semaphore", ".", "increasePermits"], "add_tokens": "* Increases the number of available permits by the indicated amount . This method differs from { @ code release } * / @ Request ( id = 8 , retryable = false , response = ResponseMessageConst . VOID , partitionIdentifier = \"name\" , acquiresResource = true )", "del_tokens": "* Increases the number of available permits by the indicated amount . This method differs from { @ code release } * / @ Request ( id = 8 , retryable = false , response = ResponseMessageConst . VOID , partitionIdentifier = \"name\" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "drawable", "states", "in", "decorators"], "add_tokens": "imageDecorator . setup ( resultW , resultH , getDrawableState ( ) , d . getLevel ( ) ) ;", "del_tokens": "imageDecorator . setup ( resultW , resultH , d . getState ( ) , d . getLevel ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "logger", "name", "and", "placement"], "add_tokens": "private static final Logger log = Logger . getLogger ( ClientBuilder . class ) ;", "del_tokens": "private static final Logger log = Logger . getLogger ( Config . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "one", "more", "test", "by", "skipping", "bridge", "/", "synth", "methods"], "add_tokens": "// 13-Jun-2015, tatu: Skip synthetic, bridge methods altogether, for now // at least (add more complex handling only if absolutely necessary) if ( Modifier . isStatic ( flags ) || m . isSynthetic ( ) || m . isBridge ( ) ) {", "del_tokens": "if ( Modifier . isStatic ( flags ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "where", "online", "sections", "were", "not", "being", "parsed", "correctly", "."], "add_tokens": "Optional < String > online = Optional . ofNullable ( this . nytdoc . getOnlineSection ( ) ) ; onlineSectionList . add ( s . trim ( ) ) ;", "del_tokens": "Optional < String > online = Optional . ofNullable ( this . nytdoc . getSection ( ) ) ; onlineSectionList . add ( s ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "Content", "-", "Length", "header", "even", "if", "the", "response", "has", "no", "content", "data", "."], "add_tokens": "int pending = data != null ? data . available ( ) : 0 ; // This is to support partial sends, see serveFile() pw . print ( \"Connection: keep-alive\\r\\n\" ) ; pw . print ( \"Content-Length: \" + pending + \"\\r\\n\" ) ;", "del_tokens": "int pending = data != null ? data . available ( ) : - 1 ; // This is to support partial sends, see serveFile() if ( pending > 0 ) { pw . print ( \"Connection: keep-alive\\r\\n\" ) ; pw . print ( \"Content-Length: \" + pending + \"\\r\\n\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "BD", "-", "39", ":", "do", "not", "suppress", "the", "groups", "when", "the", "metric", "field", "is", "null"], "add_tokens": "String [ ] values = value == null ? new String [ ] { value } : value . split ( CommonDefs . MV_SCALAR_SEP_CHAR ) ; for ( String collectionValue : values ) { for ( Integer groupIndex : entry . matchingGroupIndexes ) { groupKeys [ groupIndex ] . clear ( ) ; groupSetEntry . m_groupPaths [ groupIndex ] . addValueKeys ( groupKeys [ groupIndex ] , collectionValue ) ; updateMetric ( collectionValue , groupSetEntry , groupKeys ) ;", "del_tokens": "if ( value != null ) { String [ ] values = value . split ( CommonDefs . MV_SCALAR_SEP_CHAR ) ; for ( String collectionValue : values ) { for ( Integer groupIndex : entry . matchingGroupIndexes ) { groupKeys [ groupIndex ] . clear ( ) ; groupSetEntry . m_groupPaths [ groupIndex ] . addValueKeys ( groupKeys [ groupIndex ] , collectionValue ) ; } updateMetric ( collectionValue , groupSetEntry , groupKeys ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "pretty", "printing", "option", "in", "json", "serialization"], "add_tokens": "return toJsonString ( o , false ) ; } public String toJsonString ( Object o , boolean pretty ) { JsonPrinter p = new JsonPrinter ( sw , pretty ) ; JsonPrinter p = new JsonPrinter ( sw , pretty ) ;", "del_tokens": "JsonPrinter p = new JsonPrinter ( sw , false ) ; JsonPrinter p = new JsonPrinter ( sw , false ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "up", "merge", "mess", "again", ":", "(", "and", "fixing", "a", "miss", "behavior", "of", "getChidren", "in", "the", "inMemoryConnection"], "add_tokens": "children . add ( stack [ stack . length - 1 ] ) ;", "del_tokens": "children . add ( string ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "fluent", "builder", "always", "copy", "child", "objects", "where", "possible", "i", ".", "e", ".", "where", "they", "are", "generated", "in", "the", "same", "compilation", "context"], "add_tokens": "classOutline . implClass . _class ( JMod . PUBLIC | JMod . STATIC | ( classOutline . implClass . isAbstract ( ) ? JMod . ABSTRACT : 0 ) , this . builderClassName , ClassType . CLASS ) ) ;", "del_tokens": "classOutline . implClass . _class ( JMod . PUBLIC | JMod . STATIC , this . builderClassName , ClassType . CLASS ) ) ;", "commit_type": "make"}
{"commit_tokens": ["make", "ExampleOAuth", "work", "for", "users", "w", "/", "o", "photos", "..."], "add_tokens": "if ( user . photo != null ) System . out . println ( user . photo . image_128x128 ) ;", "del_tokens": "System . out . println ( user . photo . image_128x128 ) ;", "commit_type": "make"}
{"commit_tokens": ["make", "version", "dynamic", "in", "startup", "debug", "line"], "add_tokens": "import com . radiusnetworks . ibeacon . BuildConfig ; Log . i ( TAG , \"iBeaconService version \" + BuildConfig . VERSION_NAME + \" is starting up\" ) ;", "del_tokens": "Log . i ( TAG , \"iBeaconService version is starting up\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "@RequestParams", "and", "mixing", "@RP", "with", "regular", "args"], "add_tokens": "@ Target ( value = { ElementType . METHOD , ElementType . TYPE , ElementType . FIELD , ElementType . PARAMETER } )", "del_tokens": "@ Target ( value = { ElementType . METHOD , ElementType . TYPE } )", "commit_type": "add"}
{"commit_tokens": ["add", "temp", "token", "with", "userprofile", "before", "userdetailsservice", "and", "check"], "add_tokens": "* This provider authenticates OAuth credentials stored in ( { @ link com . github . leleuj . ss . oauth . client . authentication . OAuthAuthenticationToken } ) * to get the user profile and finally the user details ( and authorities ) . public final class OAuthAuthenticationProvider implements AuthenticationProvider , InitializingBean { private static final Logger logger = LoggerFactory . getLogger ( OAuthAuthenticationProvider . class ) ; public Authentication authenticate ( Authentication authentication ) throws AuthenticationException { logger . debug ( \"unsupported provider type, expected : {} / returned : {}\" , provider . getType ( ) , credential . getProviderType ( ) ) ; OAuthAuthenticationToken tmpToken = new OAuthAuthenticationToken ( credential , userProfile , null ) ; UserDetails userDetails = oauthUserDetailsService . loadUserDetails ( tmpToken ) ;", "del_tokens": "* This provider authenticates OAuth credentials stored in ( * { @ link com . github . leleuj . ss . oauth . client . authentication . OAuthAuthenticationToken } ) to get the user profile and finally the user details * ( and authorities ) . public final class OAuthAuthenticationProvider implements AuthenticationProvider , InitializingBean { private static final Logger logger = LoggerFactory . getLogger ( OAuthAuthenticationProvider . class ) ; public Authentication authenticate ( Authentication authentication ) throws AuthenticationException { logger . debug ( \"unsupported provider type, expected : {} / returned : {}\" , provider . getType ( ) , credential . getProviderType ( ) ) ; UserDetails userDetails = oauthUserDetailsService . loadUserDetails ( ( OAuthAuthenticationToken ) authentication ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "proto", "generator", "template", "according", "to", "latest", "changes", "in", "the", "model", "."], "add_tokens": "return location -> System . out ;", "del_tokens": "return location -> new ByteArrayOutputStream ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "not", "method", "to", "invert", "condition", "(", "does", "not", "work", "with", "IN", ")"], "add_tokens": "AND { @ Override public LogicalOperator not ( ) { return OR ; } } , OR { @ Override public LogicalOperator not ( ) { return AND ; } } ; public abstract LogicalOperator not ( ) ;", "del_tokens": "AND , OR ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "IBinder", "test", "+", "remove", "redundant", "cast", "in", "IBinderProperty"], "add_tokens": "block . addStatement ( \"$N = $N.readStrongBinder()\" , getName ( ) , in ) ;", "del_tokens": "import com . squareup . javapoet . TypeName ; TypeName wrappedTypeName = getPropertyType ( ) . getWrappedTypeName ( ) ; block . addStatement ( \"$N = ($T) $N.readStrongBinder()\" , getName ( ) , wrappedTypeName , in ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "new", "slf4j", "and", "switch", "back", "to", "nio", "and", "not", "restrict", "connections"], "add_tokens": "import static java . util . concurrent . Executors . newCachedThreadPool ; import static java . util . concurrent . Executors . newSingleThreadExecutor ; AsyncHttpClientConfig . Builder cf = createClientConfig ( configuration ) ; // A Bug exists in the AsyncConnection library that leak permits on a // Connection exception (i.e. when host not listening .. hard fail) // So we do not enable connection tracking. Which is fine as the ring // buffer does the job of having a single thread talking to the backend repo (ES) // So the connection should not grow in an unmanaged way, as the ring buffer // is restricting the connections // cf.setMaximumConnectionsTotal(numberOfHostsBeingConnectedTo); cf . setMaximumConnectionsTotal ( - 1 ) ; cf . setMaximumConnectionsPerHost ( - 1 ) ; // We use nio, instead of having a thread per backend ES server node. // providerConfig.addProperty(NettyAsyncHttpProviderConfig.USE_BLOCKING_IO,true); providerConfig . addProperty ( NettyAsyncHttpProviderConfig . EXECUTE_ASYNC_CONNECT , false ) ; cf . setIOThreadMultiplier ( 1 ) ; // Cached thread pool is used. As we cannot control the number of workers // for netty. Which is determine via the number of processors available on the machine // The number of items on the queue of requests for the executor is bounded by the // ring buffer. // // return newCachedThreadPool ( new DefaultNameableThreadFactory ( \"EsHttpSearchExecutor\" ) ) ;", "del_tokens": "AsyncHttpClientConfig . Builder cf = createClientConfig ( configuration ) . setMaximumConnectionsTotal ( numberOfHostsBeingConnectedTo ) ; providerConfig . addProperty ( NettyAsyncHttpProviderConfig . USE_BLOCKING_IO , true ) ; return newFixedThreadPool ( numberOfHostsBeingConnectedTo , new DefaultNameableThreadFactory ( \"EsHttpSearchExecutor\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Updated", "startActivity", "()", "method", "signature", "and", "implementation", "to", "allow", "starting", "activity", "without", "killing", "target", "app", "."], "add_tokens": "/ * * * This method should start arbitrary activity during a test . If the activity belongs to * another application , that application is started and the activity is opened . * * @ param appPackage The package containing the activity . [ Required ] * @ param appActivity The activity to start . [ Required ] * @ param appWaitPackage Automation will begin after this package starts . [ Optional ] * @ param appWaitActivity Automation will begin after this activity starts . [ Optional ] * @ param stopApp If true , target app will be stopped . [ Optional ] * @ example * * . startActivity ( \"com.foo.bar\" , \".MyActivity\" , null , null , true ) ; * / void startActivity ( String appPackage , String appActivity , String appWaitPackage , String appWaitActivity , boolean stopApp ) throws IllegalArgumentException ; void startActivity ( String appPackage , String appActivity , String appWaitPackage , String appWaitActivity ) * / void startActivity ( String appPackage , String appActivity )", "del_tokens": "public void startActivity ( String appPackage , String appActivity , String appWaitPackage , String appWaitActivity ) * / public void startActivity ( String appPackage , String appActivity )", "commit_type": "update"}
{"commit_tokens": ["Fix", "the", "stack", "overflow", "bug", "in", "KEEP_ARRAYS", "mode", "when", "empty", "object", "occurs"], "add_tokens": "if ( val . asObject ( ) . iterator ( ) . hasNext ( ) ) { return new JsonFlattener ( val . toString ( ) ) . withFlattenMode ( flattenMode ) . flattenAsMap ( ) ; } else { return newJsonifyLinkedHashMap ( ) ; }", "del_tokens": "return new JsonFlattener ( val . toString ( ) ) . withFlattenMode ( flattenMode ) . flattenAsMap ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "assertion", "failure", "stuff", ";", "thats", "for", "unit", "tests", "and", "not", "source", "printers", "."], "add_tokens": "String rawSource = FileUtils . readFileToString ( new File ( args [ 1 ] ) , \"UTF-8\" ) ;", "del_tokens": "String rawSource = FileUtils . readFileToString ( new File ( args [ 0 ] ) , \"UTF-8\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "guard", "flag", "to", "avoid", "infinite", "loops", "in", "publish", "function", "."], "add_tokens": "import java . util . concurrent . atomic . AtomicBoolean ; private final AtomicBoolean publishing = new AtomicBoolean ( ) ; if ( record != null && this . publishing . compareAndSet ( false , true ) && testThread ( Thread . currentThread ( ) ) && testRecord ( record ) ) { this . publishing . set ( false ) ;", "del_tokens": "if ( record != null && testThread ( Thread . currentThread ( ) ) && testRecord ( record ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "Delete", "user", "param"], "add_tokens": "@ Path ( \"{id}\" )", "del_tokens": "@ Path ( \"id\" )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "for", "ao", "-", "net", "-", "types", "compatibility", "."], "add_tokens": "* Copyright ( C ) 2013 , 2014 , 2015 , 2016 , 2017 , 2019 AO Industries , Inc . import com . aoindustries . net . URIParameters ; import com . aoindustries . net . UnmodifiableURIParameters ; private volatile URIParameters params ; params = UnmodifiableURIParameters . wrap ( params ) ; public URIParameters getParams ( ) { public void setParams ( URIParameters params ) {", "del_tokens": "* Copyright ( C ) 2013 , 2014 , 2015 , 2016 , 2017 AO Industries , Inc . import com . aoindustries . net . HttpParameters ; import com . aoindustries . net . UnmodifiableHttpParameters ; private volatile HttpParameters params ; params = UnmodifiableHttpParameters . wrap ( params ) ; public HttpParameters getParams ( ) { public void setParams ( HttpParameters params ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "donation", "+", "Add", "proguard", "+", "add", "library", "name"], "add_tokens": "this , /* host Activity */ mDrawerLayout , /* DrawerLayout object */ R . drawable . ic_drawer , /* nav drawer icon to replace 'Up' caret */ R . string . navigation_menu_open , /* \"open drawer\" description */ R . string . navigation_menu_close /* \"close drawer\" description */ ) ; . display ( HomeActivity . this , getResources ( ) . getText ( R . string . error_communication_nfc ) , CoutonColor . BLACK ) ; Fragment fragment = getSupportFragmentManager ( ) . findFragmentById ( R . id . content_frame ) ; BillingFragment billing = ( BillingFragment ) fragment . getChildFragmentManager ( ) . findFragmentById ( R . id . about_inapp_content ) ; if ( billing != null ) { billing . onActivityResult ( requestCode , resultCode , data ) ; }", "del_tokens": "this , /* host Activity */ mDrawerLayout , /* DrawerLayout object */ R . drawable . ic_drawer , /* nav drawer icon to replace 'Up' caret */ R . string . navigation_menu_open , /* \"open drawer\" description */ R . string . navigation_menu_close /* \"close drawer\" description */ ) ; . display ( HomeActivity . this , getResources ( ) . getText ( R . string . error_communication_nfc ) , CoutonColor . BLACK ) ; Fragment fragment = getSupportFragmentManager ( ) . findFragmentById ( R . id . about_inapp_content ) ; ( ( BillingFragment ) fragment ) . onActivityResult ( requestCode , resultCode , data ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "alphabetic", "constant", "value", "and", "Tiny", "Type", "generators"], "add_tokens": "* Utility class listing all generators for convenience public static final Generator < String > alphabetic10 = new RandomAlphabeticStringGenerator ( 10 ) ; public static Generator < String > alphabetic ( int length ) { return new RandomAlphabeticStringGenerator ( length ) ; }", "del_tokens": "* Utility class listing all generators for convenience *", "commit_type": "implement"}
{"commit_tokens": ["add", "support", "for", "test", "file", "charset"], "add_tokens": "import java . nio . charset . Charset ; private Charset charset ; public void setCharset ( Charset charset ) { this . charset = charset ; } InputStreamReader streamReader ; if ( this . charset != null ) { streamReader = new InputStreamReader ( is , charset ) ; } else { streamReader = new InputStreamReader ( is ) ; } Reader reader = new BufferedReader ( streamReader ) ;", "del_tokens": "Reader reader = new BufferedReader ( new InputStreamReader ( is ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "inerfaces", "to", "be", "implemented"], "add_tokens": "@ SuppressWarnings ( \"all\" ) final class EnvironmentVariableImpl extends AbstractInitParamImpl implements EnvironmentVariable {", "del_tokens": "final class EnvironmentVariableImpl extends AbstractInitParamImpl {", "commit_type": "add"}
{"commit_tokens": ["add", "comments", "and", "tese", "case"], "add_tokens": "sb . append ( d ) . append ( \"day\" ) ; sb . append ( h ) . append ( \"hour\" ) ; sb . append ( m ) . append ( \"min\" ) ; sb . append ( s ) . append ( \"sec\" ) ;", "del_tokens": "sb . append ( d ) . append ( \"\"); sb . append ( h ) . append ( \"\"); sb . append ( m ) . append ( \"\"); sb . append ( s ) . append ( \"\");", "commit_type": "add"}
{"commit_tokens": ["Remove", "throwing", "()", "from", "Event", "replace", "with", "FailEvent"], "add_tokens": "public interface FailPollEvent < T > extends FailEvent < T > , PollEvent < T > {", "del_tokens": "import java . util . concurrent . TimeUnit ; public class FailPollEvent < T > extends FailEvent < T > implements PollEvent < T > { public FailPollEvent ( PollEvent < ? > original , Throwable throwable ) { super ( original , throwable ) ; } @ SuppressWarnings ( \"unchecked\" ) @ Override public PollEvent < T > pollingEvery ( long pollingInterval , TimeUnit pollingUnit ) { ( ( PollEvent < T > ) original ) . pollingEvery ( pollingInterval , pollingUnit ) ; return this ; } @ SuppressWarnings ( \"unchecked\" ) @ Override public PollEvent < T > ignoring ( Class < ? extends Exception > exception ) { ( ( PollEvent < T > ) original ) . ignoring ( exception ) ; return this ; }", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "to", "disable", "horizontal", "drag", "in", "list"], "add_tokens": "mDragListView . setCanDragVertically ( true ) ; mDragListView . setCanDragVertically ( true ) ; mDragListView . setCanDragVertically ( true ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "constructors", "to", "allow", "a", "Zanata", "Interface", "to", "be", "constructed", "without", "having", "to", "set", "system", "properties", "."], "add_tokens": "this ( minZanataRESTCallInterval , new ZanataDetails ( DEFAULT_DETAILS ) , projectOverride ) ; } / * * * Constructs the interface with a custom project * * @ param minZanataRESTCallInterval The minimum amount of time that should be waited in between calls to Zanata . This value * is specified in seconds . * @ param zanataDetails The zanata details to be used for this interface . * / protected ZanataInterface ( final double minZanataRESTCallInterval , final ZanataDetails zanataDetails ) { this ( minZanataRESTCallInterval , zanataDetails , null ) ; } / * * * Constructs the interface with a custom project * * @ param minZanataRESTCallInterval The minimum amount of time that should be waited in between calls to Zanata . This value * is specified in seconds . * @ param zanataDetails The zanata details to be used for this interface . * @ param projectOverride The name of the Zanata project to work with , which will override the default specified . * / protected ZanataInterface ( final double minZanataRESTCallInterval , final ZanataDetails zanataDetails , final String projectOverride ) { details = zanataDetails ; if ( projectOverride != null ) { details . setProject ( projectOverride ) ; }", "del_tokens": "details = new ZanataDetails ( DEFAULT_DETAILS ) ; details . setProject ( projectOverride ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "component", "look", "better", "when", "they", "are", "disabled"], "add_tokens": "if ( isDisabled ( ) == false ) FocusManager . requestFocus ( VisTextButton . this ) ;", "del_tokens": "FocusManager . requestFocus ( VisTextButton . this ) ;", "commit_type": "make"}
{"commit_tokens": ["changed", ">", "to", "&gt", ";", "in", "ArgumentSplitter", "s", "javadoc"], "add_tokens": "* foo ( 'a' ) , 'b' - & gt ; [ \"foo('a')\" , \"b\" ]", "del_tokens": "* foo ( 'a' ) , 'b' - > [ \"foo('a')\" , \"b\" ]", "commit_type": "change"}
{"commit_tokens": ["Added", "fetchSingle", "method", "on", "Query", "class", ".", "Fixed", "multiple", "small", "bugs", "."], "add_tokens": "public < T > List < T > fetch ( ) { rs . close ( ) ; statement . getStatement ( ) . getConnection ( ) . close ( ) ; public < T > T fetchFirst ( ) { List l = this . fetch ( ) ; if ( l . size ( ) == 0 ) { return null ; } else { return ( T ) l . get ( 0 ) ; } }", "del_tokens": "public List fetch ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "test", "so", "that", "it", "will", "be", "skipped", "if", "not", "run", "in", "EC2", "."], "add_tokens": "import org . testng . annotations . BeforeTest ; import java . net . URL ; import static org . testng . Assert . assertTrue ; @ BeforeTest public void checkEc2 ( ) throws Exception { URL testEc2Url = new URL ( \"http://169.254.169.254/latest/meta-data\" ) ; testEc2Url . getContent ( ) ; } public void testGetZone ( ) throws Exception { @ Test ( groups = { \"aws\" } , enabled = false ) public void testAmiId ( ) throws Exception { public void testGetInstanceType ( ) throws Exception { public void testGetLocalHostname ( ) throws Exception { public void testGetLocalIpv4 ( ) throws Exception { public void testGetPublicHostname ( ) throws Exception { public void testGetPublicIpv4 ( ) throws Exception { public void testGetInstanceId ( ) throws Exception {", "del_tokens": "import static org . testng . Assert . * ; public void testGetZone ( ) throws Exception { @ Test ( groups = { \"aws\" } ) public void testAmiId ( ) throws Exception { public void testGetInstanceType ( ) throws Exception { public void testGetLocalHostname ( ) throws Exception { public void testGetLocalIpv4 ( ) throws Exception { public void testGetPublicHostname ( ) throws Exception { public void testGetPublicIpv4 ( ) throws Exception { public void testGetInstanceId ( ) throws Exception {", "commit_type": "fix"}
{"commit_tokens": ["Added", "docs", "for", "BiDiGzipHandler", "."], "add_tokens": "/ * * * A Jetty { @ link Handler } which both compresses response entities to requests with { @ code gzip } as * an acceptable content - encoding and decompresses request entities with { @ code gzip } as the given * content - encoding . * / / * * * Creates a new { @ link BiDiGzipHandler } which forwards requests to the given handler . * * @ param underlying the underlying handler * /", "del_tokens": "// TODO: 10/12/11 <coda> -- write docs for BiDiGzipHandler", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "handling", "for", "CTWN", "function", "to", "temporarily", "save", "the", "climate", "ID", "in", "a", "separated", "position", "rather", "than", "change", "the", "data", "link"], "add_tokens": "Event event = new Event ( getBucket ( data , \"management\" ) . getDataList ( ) , \"fertilizer\" ) ; ArrayList < HashMap > fertEvents = new ArrayList ( ) ; String totAmtN = \"0\" ; { HashMap fertEvent ; while ( ( fertEvent = event . getNextEvent ( ) ) != null ) { fertEvents . add ( fertEvent ) ; totAmtN = Functions . sum ( totAmtN , MapUtil . getValueOr ( fertEvent , \"feamn\" , \"0\" ) ) ; } } if ( ! Functions . compare ( totAmtN , \"0\" , CompareMode . EQUAL ) ) { for ( HashMap fertEvent : fertEvents ) { String feamn = MapUtil . getValueOr ( fertEvent , \"feamn\" , \"0\" ) ; String rate = Functions . divide ( feamn , totAmtN , 3 ) ; feamn = Functions . round ( Functions . multiply ( fenTot , rate ) , 1 ) ; fertEvent . put ( \"feamn\" , feamn ) ; } } data . put ( \"ctwn_clim_id\" , climId . toUpperCase ( ) ) ;", "del_tokens": "data . put ( \"clim_id\" , climId . toUpperCase ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "way", "to", "set", "the", "style", "in", "the", "spec", ".", "json"], "add_tokens": "import javax . annotation . Nullable ; private Function < FeatureSource , Style > styleSupplier ; public final void setStyle ( final Style style ) { this . styleSupplier = new Function < FeatureSource , Style > ( ) { @ Nullable @ Override public Style apply ( @ Nullable final FeatureSource featureCollection ) { return style ; } } ; }", "del_tokens": "private final Function < FeatureSource , Style > styleSupplier ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "counter", "of", "moves", "in", "the", "MetaConstraintSolver", "--", "Mau"], "add_tokens": "private int counterMoves ; this . counterMoves = 0 ; logger . finest ( \"I am incrementing the metaconstraintsolver counterMoves!!!\" ) ; this . counterMoves ++ ; this . counterMoves -- ; logger . finest ( \"I am decrementing the metaconstraintsolver counterMoves!!!\" ) ; logger . finest ( \"I am incrementing the metaconstraintsolver counterMoves!!!\" ) ; this . counterMoves ++ ; this . resolvers . remove ( mostProblematicNetwork ) ; logger . finest ( \"I am decrementing the metaconstraintsolver counterMoves!!!\" ) ; this . counterMoves -- ; public int getCounterMoves ( ) { return counterMoves ; } public void setCounterMoves ( int counterMoves ) { this . counterMoves = counterMoves ; }", "del_tokens": "this . resolvers . remove ( mostProblematicNetwork ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "modifiers", "of", "validate", "{", "Database", "Table", "}", "Name", "methods", ":", "public", "-", ">", "public", "static"], "add_tokens": "private static Pattern databasePat ; public static boolean validateDatabaseName ( String name ) { public static boolean validateTableName ( String name ) {", "del_tokens": "private Pattern databasePat ; public boolean validateDatabaseName ( String name ) { public boolean validateTableName ( String name ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "of", "a", "combination", "master", "password", "+", "key", "file"], "add_tokens": "import de . slackspace . openkeepass . domain . KeePassHeader ; import de . slackspace . openkeepass . util . StreamUtils ; return Sha256 . hash ( stream . toByteArray ( ) ) ;", "del_tokens": "import de . slackspace . openkeepass . domain . KeePassHeader ; import de . slackspace . openkeepass . util . StreamUtils ; byte [ ] aesKey = Sha256 . hash ( stream . toByteArray ( ) ) ; return aesKey ;", "commit_type": "add"}
{"commit_tokens": ["add", "#cls", ".", "alias", "(", "status", ")", "for", "non", "-", "required", "property"], "add_tokens": "* Get classification alias . / * * * Get classification alias or default value if the classification is null . * @ param cls The instance of classification to get code . ( NotNull ) * @ param defaultValue The default value for no classification . ( NotNull , EmptyAllowed ) * @ return The alias of classification . ( NotNull : if not classification , throws exception ) * / public String alias ( Object cls , String defaultValue ) { assertArgumentNotNull ( \"defaultValue\" , defaultValue ) ; if ( cls != null ) { return alias ( cls ) ; } else { return defaultValue ; } } // #hope locale from request manager, how to set? by jflute (2017/03/19) final IProcessingContext context = getProcessingContext ( ) ; // null check just in case?", "del_tokens": "* Get Classification alias . final IProcessingContext context = getProcessingContext ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "asttest", "set", "propery", "return", "type", "on", "context", "when", "it", "is", "known", "."], "add_tokens": "context . setCurrentType ( mismatched ? Object . class : secondType ) ;", "del_tokens": "context . setCurrentType ( Object . class ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "handling", "for", "Thread", "state", "in", "Retryable"], "add_tokens": "while ( Thread . currentThread ( ) . isAlive ( ) ) { throw new InterruptedException ( \"Thread with retry is not longer alive\" ) ; // Edge-case where Thread was killed and the Exception was catched by the caller", "del_tokens": "while ( true ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "in", "shotgun", ".", "And", "add", "tests"], "add_tokens": "import java . util . Arrays ; ResilientActionWithContext < T , C > actionWithContext = new ResilientActionWithContext < > ( action ) ; MultiService service = services [ serviceIndex ] ; service . submitAndComplete ( actionWithContext , promise , callback , millisTimeout ) ;", "del_tokens": "ResilientActionWithContext < T , C > actionWithContext = new ResilientActionWithContext < > ( action ) ; services [ serviceIndex ] . submitAndComplete ( actionWithContext , promise , callback , millisTimeout ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "the", "Lookup", "API"], "add_tokens": "private final String clientVersion = \"1.2.0\" ; // Make rest of GET request", "del_tokens": "private final String clientVersion = \"1.1.0\" ; // Make rest of get request", "commit_type": "add"}
{"commit_tokens": ["Fix", "bogus", "header", "and", "switch", "test", "to", "JUnit4", "style", "."], "add_tokens": "import org . junit . Test ; import static org . junit . Assert . * ; public class BinderTest { @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test @ Test", "del_tokens": "/ * * To change this template , choose Tools | Templates * and open the template in the editor . * / import junit . framework . TestCase ; public class BinderTest extends TestCase { public BinderTest ( String testName ) { super ( testName ) ; } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; } @ Override protected void tearDown ( ) throws Exception { super . tearDown ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["added", "several", "tests", "for", "where", "clause", "requirements", "for", "update", "statements"], "add_tokens": "private static final String INVALID_WHERE_CLAUSE_DELETE_MESSAGE = \"The DELETE statement does not contain a valid WHERE clause. DELETE statements must contain a WHERE clause specifying the value of the primary key of the record(s) to be deleted in the form 'ID=value' or 'ID1=value1 AND ID2=value2'\" ; private static final String INVALID_WHERE_CLAUSE_UPDATE_MESSAGE = \"The UPDATE statement does not contain a valid WHERE clause. UPDATE statements must contain a WHERE clause specifying the value of the primary key of the record(s) to be deleted in the form 'ID=value' or 'ID1=value1 AND ID2=value2'\" ; throw new SQLException ( INVALID_WHERE_CLAUSE_DELETE_MESSAGE ) ; private void visitUpdateWhereClause ( Expression where , WriteBuilder builder ) throws SQLException DMLWhereClauseVisitor whereClauseVisitor = new DMLWhereClauseVisitor ( getParameterStore ( ) ) } ; where . accept ( whereClauseVisitor ) ; if ( ! whereClauseVisitor . isValid ( ) ) { throw new SQLException ( INVALID_WHERE_CLAUSE_UPDATE_MESSAGE ) ; } } else { throw new SQLException ( INVALID_WHERE_CLAUSE_UPDATE_MESSAGE ) ;", "del_tokens": "throw new SQLException ( \"The DELETE statement does not contain a valid WHERE clause. DELETE statements must contain a WHERE clause specifying the value of the primary key of the record(s) to be deleted in the form ID=value or ID IN (value1, value2, ...)\" ) ; private void visitUpdateWhereClause ( Expression where , WriteBuilder builder ) where . accept ( new DMLWhereClauseVisitor ( getParameterStore ( ) ) } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "methods", "to", "RNAUtility"], "add_tokens": "System . out . println ( compList . get ( 0 ) . getNaturalAnalog ( ) ) ; System . out . println ( compList . get ( 0 ) . getNotation ( ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "tests", "to", "work", "with", "latest", "exception", "changes"], "add_tokens": "throw new ResourceException ( \"Path is empty\" ) ; //TODO: Throw different exception? element name can be null..", "del_tokens": "// TODO: HAndle exception throw new IllegalArgumentException ( \"Path is empty\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "to", "use", "builder", "mock", "API"], "add_tokens": "import org . jmock . builder . Mock ; mockSubscriber . method ( \"receive\" ) . passed ( message ) . isVoid ( ) . expectOnce ( ) ;", "del_tokens": "import org . jmock . dynamock . Mock ; mockSubscriber . expectVoid ( \"receive\" , message ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "possibility", "for", "constructing", "empty", "format", "attributes"], "add_tokens": "import net . time4j . format . Attributes ; Attributes . empty ( )", "del_tokens": "null", "commit_type": "add"}
{"commit_tokens": ["Add", "token", "validation", "in", "user", "registration", "."], "add_tokens": "import ca . carleton . gcrc . couch . user . db . UserRepository ; import ca . carleton . gcrc . couch . user . db . UserRepositoryCouchDb ; UserRepository userRepository = new UserRepositoryCouchDb ( userDb , userDesignDocument ) ; actions = new UserServletActions ( userRepository , userMailNotification ) ; } else if ( path . size ( ) == 1 && path . get ( 0 ) . equals ( \"validateUserCreation\" ) ) { String [ ] tokenStrings = req . getParameterValues ( \"token\" ) ; if ( null == tokenStrings || tokenStrings . length < 1 ) { throw new Exception ( \"'token' parameter must be specified\" ) ; } if ( tokenStrings . length > 1 ) { throw new Exception ( \"'token' parameter must be specified exactly once\" ) ; } JSONObject result = actions . validateUserCreation ( tokenStrings [ 0 ] ) ; sendJsonResponse ( resp , result ) ;", "del_tokens": "actions = new UserServletActions ( userDb , userDesignDocument , userMailNotification ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "4", "new", "methods", ":"], "add_tokens": "* Company information private static final String DEFAULT_STRING = \"\" ; private int companyId = 0 ; private String name = DEFAULT_STRING ; private String description = DEFAULT_STRING ; private String headquarters = DEFAULT_STRING ; private String homepage = DEFAULT_STRING ; private String logoPath = DEFAULT_STRING ; private String parentCompany = DEFAULT_STRING ; @ Override public String toString ( ) { return \"Company{\" + \"companyId=\" + companyId + \", name=\" + name + \", description=\" + description + \", headquarters=\" + headquarters + \", homepage=\" + homepage + \", logoPath=\" + logoPath + \", parentCompany=\" + parentCompany + '}' ; }", "del_tokens": "private int companyId ; private String name ; private String description ; private String headquarters ; private String homepage ; private String logoPath ; private String parentCompany ;", "commit_type": "add"}
{"commit_tokens": ["make", "init", "and", "reset", "methods", "public", "to", "allow", "usage", "in", "Test", "Classes"], "add_tokens": "public static InApplicationMonitor initInstanceForTesting ( CorePlugin corePlugin , KeyHandler keyHandler ) { public static void resetInstanceForTesting ( ) {", "del_tokens": "protected static InApplicationMonitor initInstanceForTesting ( CorePlugin corePlugin , KeyHandler keyHandler ) { protected static void resetInstanceForTesting ( ) {", "commit_type": "make"}
{"commit_tokens": ["Upgraded", "to", "support", "user", "push", "IDs", "."], "add_tokens": "return authorize ( username , false , false ) ; } / * * * Call to authorize a username via LaunchKey * * @ param username * @ param userPushId * / public AuthorizeResult authorize ( final String username , boolean userPushId ) throws AuthenticationException { return authorize ( username , false , userPushId ) ; * @ param userPushId public AuthorizeResult authorize ( final String username , boolean transactional , boolean userPushId ) throws AuthenticationException { JSONResponse authsPostResponse = authController . authsPost ( launchkeyTime , _publicKey , username , ! transactional , userPushId ) ; String userPushId = pollGetResponse . getJson ( ) . getString ( \"user_push_id\" ) ; return logsPutAuthenticate ( userHash , authRequest , appPins , deviceId , userPushId , action ) ; * @ param userPushId private PollResult logsPutAuthenticate ( String userHash , String authRequest , String appPins , String deviceId , String userPushId , pollResult . setUserPushId ( userPushId ) ;", "del_tokens": "return authorize ( username , false ) ; public AuthorizeResult authorize ( final String username , boolean transactional ) throws AuthenticationException { JSONResponse authsPostResponse = authController . authsPost ( launchkeyTime , _publicKey , username , ! transactional ) ; return logsPutAuthenticate ( userHash , authRequest , appPins , deviceId , action ) ; private PollResult logsPutAuthenticate ( String userHash , String authRequest , String appPins , String deviceId ,", "commit_type": "upgrade"}
{"commit_tokens": ["update", "PCGMatrix", "due", "to", "the", "changes", "of", "IMatrix"], "add_tokens": "@ Override public double apply ( int i , int j ) { throw new UnsupportedOperationException ( \"Not supported yet.\" ) ; } / * * /", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Add", "basic", "utilities", "for", "field", "/", "method", "reflection"], "add_tokens": "import java . lang . reflect . InvocationTargetException ; import java . util . Locale ; String name = errorCode . toString ( ) . toLowerCase ( Locale . ENGLISH ) . replace ( \"_\" , \" \" ) ; name . substring ( 0 , 1 ) . toUpperCase ( Locale . ENGLISH ) + name . substring ( 1 ) return errorCode . getClass ( ) . getSimpleName ( ) . replace ( \"ErrorCodes\" , \"\" ) . replace ( \"ErrorCode\" , \"\" ) . toUpperCase ( Locale . ENGLISH ) ; } catch ( NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e ) { } catch ( NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e ) {", "del_tokens": "String name = errorCode . toString ( ) . toLowerCase ( ) . replace ( \"_\" , \" \" ) ; name . substring ( 0 , 1 ) . toUpperCase ( ) + name . substring ( 1 ) return errorCode . getClass ( ) . getSimpleName ( ) . replace ( \"ErrorCodes\" , \"\" ) . replace ( \"ErrorCode\" , \"\" ) . toUpperCase ( ) ; } catch ( Exception e ) { } catch ( Exception e ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "filename", "endings", "for", "filenames", "containing", "."], "add_tokens": "String fileName = file . getName ( ) ; if ( fileName . endsWith ( ending ) ) { if ( fileName . endsWith ( \".spi\" ) || fileName . endsWith ( \".spl\" ) ) { return new File ( file . getParentFile ( ) , changeEnding ( fileName , ending ) ) ; } if ( fileName . endsWith ( \".\" ) ) { return new File ( file . getParentFile ( ) , fileName . substring ( 0 , fileName . length ( ) - 1 ) + ending ) ; } return new File ( file . getParentFile ( ) , fileName + ending ) ;", "del_tokens": "if ( file . getName ( ) . endsWith ( ending ) ) { return new File ( file . getParentFile ( ) , changeEnding ( file . getName ( ) , ending ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", "where", "we", "generate", "the", "event", "interface", "more", "than", "once", "."], "add_tokens": "* so that we don 't generate them as invocable interfaces, * and we don 't generate them twice. if ( eventInterfaces . add ( it ) ) { IDispInterfaceDecl di = it . queryInterface ( IDispInterfaceDecl . class ) ; if ( di != null ) // can this ever be null? new EventInterfaceGenerator ( this , di ) . generate ( ) ; }", "del_tokens": "import java . util . List ; * so that we don 't generate them as invocable interfaces. eventInterfaces . add ( it ) ; IDispInterfaceDecl di = it . queryInterface ( IDispInterfaceDecl . class ) ; if ( di != null ) // can this ever be null? new EventInterfaceGenerator ( this , di ) . generate ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "Md5FileNameGenerator", ".", "Made", "DefaultImageDownloader", "public", "."], "add_tokens": "}", "del_tokens": "import java . net . URLConnection ; import com . nostra13 . universalimageloader . core . assist . FlushedInputStream ; } /** Default implementation of ImageDownloader. Uses {@link URLConnection} for image stream retrieving. */ class DefaultImageDownloader extends ImageDownloader { private int connectTimeout ; private int readTimeout ; public DefaultImageDownloader ( int connectTimeout , int readTimeout ) { this . connectTimeout = connectTimeout ; this . readTimeout = readTimeout ; } @ Override public InputStream getStreamFromNetwork ( URL imageUrl ) throws IOException { URLConnection conn = imageUrl . openConnection ( ) ; conn . setConnectTimeout ( connectTimeout ) ; conn . setReadTimeout ( readTimeout ) ; return new FlushedInputStream ( new BufferedInputStream ( conn . getInputStream ( ) ) ) ; } }", "commit_type": "implement"}
{"commit_tokens": ["improve", "mass", "message", "to", "topic"], "add_tokens": "public void publish ( String topic , int nb ) { for ( int i = 0 ; i < nb ; i ++ ) { MessageToClient messageToClient = new MessageToClient ( ) ; messageToClient . setId ( topic ) ; messageToClient . setResult ( \"Message From server \" + 1 ) ; wsEvent . fire ( messageToClient ) ; }", "del_tokens": "import javax . ejb . Schedule ; public void publish ( ) { MessageToClient messageToClient = new MessageToClient ( ) ; messageToClient . setId ( \"mytopic\" ) ; messageToClient . setResult ( \"Message From server\" ) ; wsEvent . fire ( messageToClient ) ;", "commit_type": "improve"}
{"commit_tokens": ["fixed", "final", "last", "missing", "tests", "and", "cleaned", "up", "plugin", "code"], "add_tokens": "import com . google . common . annotations . VisibleForTesting ; @ VisibleForTesting static MockServerRunner MOCK_SERVER_RUNNER = new MockServerRunner ( ) ; MOCK_SERVER_RUNNER . overrideLogLevel ( logLevel ) ; public boolean stop ( final int stopPort , final String stopKey , final int stopWait , final String logLevel ) { MOCK_SERVER_RUNNER . overrideLogLevel ( logLevel ) ; return MOCK_SERVER_RUNNER . stop ( \"127.0.0.1\" , stopPort , stopKey , stopWait ) ; }", "del_tokens": "private static final MockServerRunner MOCK_SERVER_RUNNER = new MockServerRunner ( ) ; MockServerRunner . overrideLogLevel ( logLevel ) ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "HttpClientAdaptor", "class", "according", "to", "change", "of", "td", "-", "api"], "add_tokens": "throw new IllegalArgumentException ( \"query is null\" ) ; //Job.Type type = Job.toType(jobMap.get(\"type\")); //String url = (String) jobMap.get(\"url\"); //job.setURL(url);", "del_tokens": "throw new NullPointerException ( \"query is null\" ) ; Job . Type type = Job . toType ( jobMap . get ( \"type\" ) ) ; String url = ( String ) jobMap . get ( \"url\" ) ; job . setURL ( url ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "type", "of", "goalId", "from", "string", "to", "integer"], "add_tokens": "setGoalId ( 0 ) ; if ( getGoalId ( ) == null || getGoalId ( ) != 0 ) { public Integer getGoalId ( ) { return ( Integer ) getParameter ( GOAL_ID ) ; public void setGoalId ( Integer goalId ) { * Specify a search category with this parameter . SearchQuery must first be * set . * We recommend to set the * the \"No Result Search Keyword\" report . SearchQuery must first be set .", "del_tokens": "setGoalId ( \"0\" ) ; if ( ! \"0\" . equals ( getGoalId ( ) ) ) { public String getGoalId ( ) { return ( String ) getParameter ( GOAL_ID ) ; public void setGoalId ( String goalId ) { * When < strong > Query < / strong > is specified , you can optionally specify a search category * with this parameter . * When < strong > Query < / strong > is specified , we also recommend to set the * the \"No Result Search Keyword\" report .", "commit_type": "change"}
{"commit_tokens": ["fix", "method", "name", "on", "BeanManager"], "add_tokens": "public boolean isInterceptorBinding ( Class < ? extends Annotation > annotationType ) ;", "del_tokens": "public boolean isInterceptorBindingType ( Class < ? extends Annotation > annotationType ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "--", "no", "-", "package", "-", "directories", "option", "which", "generates", "non", "-", "JRE", "outputs"], "add_tokens": "import org . eclipse . jdt . core . dom . PackageDeclaration ; * Objective - C implementation files . If -- no - package - directories is * specified , though , the output file is $ ( OUTPUT_DIR ) / Mumble . m . PackageDeclaration pkg = node . getPackage ( ) ; if ( Options . usePackageDirectories ( ) || pkg == null ) { return javaName . replace ( '.' , '/' ) + getSuffix ( ) ; } else { String pkgName = pkg . getName ( ) . getFullyQualifiedName ( ) ; return javaName . substring ( pkgName . length ( ) + 1 ) + getSuffix ( ) ; }", "del_tokens": "* Objective - C implementation files . return javaName . replace ( '.' , '/' ) + getSuffix ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "tests", "for", "message", "formatting"], "add_tokens": "Object m = MessageBuilder . from ( \"Some %s %d\" , \"message\" , \"with invalid formatting\" ) ; @ Test public void shouldBuildMessageFromTooFewArguments ( ) { Object m = MessageBuilder . from ( \"Some %s %s\" , \"message with too few arguments\" ) ; assertThat ( m . toString ( ) , containsString ( \"Some %s %s\" ) ) ; assertThat ( m . toString ( ) , containsString ( \"message with too few arguments\" ) ) ; } @ Test public void shouldBuildMessageFromTooManyArguments ( ) { Object m = MessageBuilder . from ( \"Some %s\" , \"message\" , \"with too many arguments\" ) ; assertThat ( m . toString ( ) , containsString ( \"Some message\" ) ) ; } @ Test public void shouldBuildMessageWithNullArguments ( ) { Object m = MessageBuilder . from ( \"Some %s %d %b\" , ( Object ) null , ( Object ) null , ( Object ) null ) ; assertThat ( m . toString ( ) , containsString ( \"Some null null false\" ) ) ; }", "del_tokens": "Object m = MessageBuilder . from ( \"Some %s %d\" , \"message\" , \"with invalid formatting\" , 4 ) ; assertThat ( m . toString ( ) , containsString ( \"4\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "test", "of", "native", "send", "keys", "functionality"], "add_tokens": "import java . util . List ; import com . google . common . collect . Lists ; import com . google . gson . JsonArray ; JsonArray valueArr = value . getAsJsonArray ( ) ; List < CharSequence > temp = Lists . newArrayList ( ) ; for ( int i = 0 ; i < valueArr . size ( ) ; i ++ ) { temp . add ( valueArr . get ( i ) . getAsString ( ) ) ; } String [ ] keysToSend = temp . toArray ( new String [ 0 ] ) ; getAndroidDriver ( ) . getKeyboard ( ) . sendKeys ( keysToSend ) ;", "del_tokens": "System . out . println ( \"send key payload: \" + payload ) ; getAndroidDriver ( ) . getKeyboard ( ) . sendKeys ( value . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "isLeapYear", "calc", "safe", "for", "negative", "years", "ending", "in", "99!"], "add_tokens": "return Math . abs ( lastTwoDigits ) == 99 || ( lastTwoDigits % 6 == 0 ) || ( lastTwoDigits == 0 && prolepticYear % 400 != 0 ) ;", "del_tokens": "return lastTwoDigits == 99 || ( lastTwoDigits % 6 == 0 ) || ( lastTwoDigits == 0 && prolepticYear % 400 != 0 ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "hook", "to", "JDK", "shutdown", "for", "Local", "BMOBProxy", "."], "add_tokens": "* NOTE : Only one Local BrowserMob Proxy running per host is supported , * as this is how BrowserMob Proxy is designed to work . * * In case client code doesn 't, the BrowserMob Proxy process will be * shutdown with the JVM ( i . e . Runtime Shutdown Hook ) . * * In case client code doesn 't, the BrowserMob Proxy process will be * shutdown with the JVM ( i . e . Runtime Shutdown Hook ) . // Register JVM Shutdown Hook to ensure we stop the // Local BrowserMob Proxy if client code doesn't Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( new Runnable ( ) { @ Override public void run ( ) { BMPCLocalLauncher . stop ( ) ; } } ) ) ;", "del_tokens": "* NOTE : Only one Local BrowserMob Proxy running per host is supported .", "commit_type": "add"}
{"commit_tokens": ["Updated", "Topics", "to", "auto", "expand", "tags", "and", "properties", "since", "they", "are", "used", "a", "lot", "."], "add_tokens": "RESTTranslatedTopicV1 . TAGS_NAME , RESTTranslatedTopicV1 . PROPERTIES_NAME ) ) ; RESTTranslatedTopicV1 . TAGS_NAME , RESTTranslatedTopicV1 . PROPERTIES_NAME ) ) ; final String expandString = super . getExpansionString ( Arrays . asList ( RESTTranslatedTopicV1 . TOPIC_NAME , RESTTranslatedTopicV1 . TAGS_NAME , RESTTranslatedTopicV1 . PROPERTIES_NAME ) ) ; final RESTTranslatedTopicV1 updatedTopic = getRESTClient ( ) . createJSONTranslatedTopic ( expandString , final String expandString = super . getExpansionString ( Arrays . asList ( RESTTranslatedTopicV1 . TOPIC_NAME , RESTTranslatedTopicV1 . TAGS_NAME , RESTTranslatedTopicV1 . PROPERTIES_NAME ) ) ; final RESTTranslatedTopicV1 updatedTopic = getRESTClient ( ) . updateJSONTranslatedTopic ( expandString , final String expandString = getExpansionString ( RESTv1Constants . TRANSLATEDTOPICS_EXPANSION_NAME , Arrays . asList ( RESTTranslatedTopicV1 . TOPIC_NAME , RESTTranslatedTopicV1 . TAGS_NAME , RESTTranslatedTopicV1 . PROPERTIES_NAME ) ) ; final String expandString = getExpansionString ( RESTv1Constants . TRANSLATEDTOPICS_EXPANSION_NAME , Arrays . asList ( RESTTranslatedTopicV1 . TOPIC_NAME , RESTTranslatedTopicV1 . TAGS_NAME , RESTTranslatedTopicV1 . PROPERTIES_NAME ) ) ;", "del_tokens": "RESTTranslatedTopicV1 . TAGS_NAME ) ) ; RESTTranslatedTopicV1 . TAGS_NAME ) ) ; final RESTTranslatedTopicV1 updatedTopic = getRESTClient ( ) . createJSONTranslatedTopic ( \"\" , final RESTTranslatedTopicV1 updatedTopic = getRESTClient ( ) . updateJSONTranslatedTopic ( \"\" , final String expandString = getExpansionString ( RESTv1Constants . TRANSLATEDTOPICS_EXPANSION_NAME ) ; final String expandString = getExpansionString ( RESTv1Constants . TRANSLATEDTOPICS_EXPANSION_NAME ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "Args", "for", "null", "checking", "."], "add_tokens": "import org . jfree . graphics2d . Args ; Args . nullNotPermitted ( href , \"href\" ) ; Args . nullNotPermitted ( image , \"image\" ) ;", "del_tokens": "if ( href == null ) { throw new IllegalArgumentException ( \"Null 'href' argument.\" ) ; } if ( image == null ) { throw new IllegalArgumentException ( \"Null 'image' argument.\" ) ; }", "commit_type": "use"}
{"commit_tokens": ["Fixing", "bug", "in", "how", "content", "type", "was", "moved", "from", "response", "to", "Message"], "add_tokens": "import com . sun . jersey . api . client . WebResource . Builder ; Builder request = getResource ( ) . path ( \"messages\" ) . getRequestBuilder ( ) ; request = request . type ( message . getContentType ( ) ) ; request = request . header ( \"BrokerProperties\" , mapper . toString ( message . getProperties ( ) ) ) ; request . post ( message . getBody ( ) ) ; result . setContentType ( contentType . toString ( ) ) ;", "del_tokens": "WebResource resource = getResource ( ) . path ( \"messages\" ) ; resource . type ( message . getContentType ( ) ) ; resource . header ( \"BrokerProperties\" , mapper . toString ( message . getProperties ( ) ) ) ; resource . post ( message . getBody ( ) ) ; result . setContentType ( clientResult . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "for", "the", "key", "regex", "."], "add_tokens": "private static final Pattern pemPattern = Pattern . compile ( \"-----BEGIN PRIVATE KEY-----\" + // File header \"(.*\\\\n)\" + // Key data \"-----END PRIVATE KEY-----\" + // File footer \"\\\\n?\" , // Optional trailing line break Pattern . MULTILINE | Pattern . DOTALL ) ;", "del_tokens": "private static final Pattern pemPattern = Pattern . compile ( \"-----BEGIN PRIVATE KEY-----\" + \"(.*\\\\n)\" + \"-----END PRIVATE KEY-----\\\\n?\" , Pattern . MULTILINE | Pattern . DOTALL ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "NPE", "in", "minaio", "handler", "that", "can", "occur", "on", "close", "/", "cleanup", ".", "Also", "fixed", "NPE", "on", "rtmp", "encode", "if", "null", "message", "is", "passed", "."], "add_tokens": "if ( obj != null ) { log . debug ( \"Attribute: {}\" , obj . getClass ( ) . getName ( ) ) ; if ( obj instanceof IoProcessor ) { log . debug ( \"Flushing session in processor\" ) ; ( ( IoProcessor ) obj ) . flush ( session ) ; log . debug ( \"Removing session from processor\" ) ; ( ( IoProcessor ) obj ) . remove ( session ) ; } else if ( obj instanceof IoBuffer ) { log . debug ( \"Clearing session buffer\" ) ; ( ( IoBuffer ) obj ) . clear ( ) ; ( ( IoBuffer ) obj ) . free ( ) ; }", "del_tokens": "log . debug ( \"Attribute: {}\" , obj . getClass ( ) . getName ( ) ) ; if ( obj instanceof IoProcessor ) { log . debug ( \"Flushing session in processor\" ) ; ( ( IoProcessor ) obj ) . flush ( session ) ; log . debug ( \"Removing session from processor\" ) ; ( ( IoProcessor ) obj ) . remove ( session ) ; } else if ( obj instanceof IoBuffer ) { log . debug ( \"Clearing session buffer\" ) ; ( ( IoBuffer ) obj ) . clear ( ) ; ( ( IoBuffer ) obj ) . free ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "initial", "version", "of", "multimaps"], "add_tokens": "import static com . davidbracewell . collection . set . Sets . set ;", "del_tokens": "import static com . davidbracewell . collection . Sets . set ;", "commit_type": "add"}
{"commit_tokens": ["Added", "javadoc", ".", "Escape", "backslash", "as", "well", "as", "dollar", "when", "reverting", "ignored", "sections", "."], "add_tokens": "* Replaces ignored sections with a token . The ignored sections look like this : * < ? sortpom ignore ? > ... whatever ... < ? sortpom resume ? > * < p / > * The tokens look like this : * < ? sortpom token = '0' ? > * < p / > * The number in the token identifies the ignored section so that it can find it in a stored list . * class IgnoredSectionsStore { private ArrayList < String > ignoredSections = new ArrayList < String > ( ) ; ignoredSections . add ( matcher . group ( ) ) ; String replacement = ignoredSections . get ( index ) ; String oneBackslashBeforeBackslash = replacement . replace ( \"\\\\\" , \"\\\\\\\\\" ) ; String oneBackslashBeforeDollar = oneBackslashBeforeBackslash . replace ( \"$\" , \"\\\\$\" ) ; matcher . appendReplacement ( returnValue , oneBackslashBeforeDollar ) ;", "del_tokens": "class IgnoredSectionsMap { ArrayList < String > ignoredSections = new ArrayList < String > ( ) ; String contentWithOneBackslashBeforeDollar = matcher . group ( ) . replaceAll ( \"[$]\" , \"\\\\\\\\\\\\$\" ) ; ignoredSections . add ( contentWithOneBackslashBeforeDollar ) ; matcher . appendReplacement ( returnValue , ignoredSections . get ( index ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Glassfish", "test", "case", "for", "DataSourceDescriptor"], "add_tokens": "import javax . management . MBeanInfo ; import javax . management . ObjectName ; . addClasses ( DataSourceConfiguration . class )", "del_tokens": "import javax . management . * ;", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "check", "to", "type", "discovery", "in", "MetaDataRegistry"], "add_tokens": "String typeName ; { typeName = \"Collection\" ; } else { typeName = \"Collection<\" + NameUtil . getFormalName ( collectionValueType ) + \">\" ; }", "del_tokens": "continue ; String typeName = NameUtil . getFormalName ( collectionValueType ) + \"[]\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "the", "new", "frame", "decoder"], "add_tokens": "ChannelBuffer messageBuffer = tryDecodeUnframedMessage ( ctx , channel , buffer , inputProtocolFactory ) ; if ( messageBuffer == null ) { return null ; } return new ThriftMessage ( messageBuffer , ThriftTransportType . UNFRAMED ) ; ChannelBuffer messageBuffer = tryDecodeFramedMessage ( ctx , channel , buffer , true ) ; if ( messageBuffer == null ) { return null ; } return new ThriftMessage ( messageBuffer , ThriftTransportType . FRAMED ) ;", "del_tokens": "return new ThriftMessage ( tryDecodeUnframedMessage ( ctx , channel , buffer , inputProtocolFactory ) , ThriftTransportType . UNFRAMED ) ; return new ThriftMessage ( tryDecodeFramedMessage ( ctx , channel , buffer , true ) , ThriftTransportType . FRAMED ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "failing", "test", ".", "Started", "on", "ant", "example", "."], "add_tokens": "result = input . expect ( SMALL_TIMEOUT , times ( 10 , contains ( \"c\" ) ) ) ; assertFalse ( result . getResults ( ) . get ( 8 ) . isSuccessful ( ) ) ; assertFalse ( result . getResults ( ) . get ( 9 ) . isSuccessful ( ) ) ;", "del_tokens": "result = input . expect ( SMALL_TIMEOUT , times ( 5 , contains ( \"c\" ) ) ) ; assertFalse ( result . getResults ( ) . get ( 3 ) . isSuccessful ( ) ) ; assertFalse ( result . getResults ( ) . get ( 4 ) . isSuccessful ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "explicit", "module", "config", "for", "headless", "web", "services", "(", "alternative", "to", "the", "@Service", "annotation", ")", "."], "add_tokens": "import com . google . sitebricks . headless . Service ; Strings . nonEmpty ( header , \"invalid request header string for negotiation.\" ) ; Preconditions . checkArgument ( ! clazz . isAnnotationPresent ( Service . class ) , \"Cannot show() a headless web service. Did you mean to call serve() instead?\" ) ; this . bindingKind = BindingKind . PAGE ; Preconditions . checkArgument ( ! clazz . isAnnotationPresent ( Show . class ) , \"Cannot serve() a template page. Did you mean to call show() instead?\" ) ; this . bindingKind = BindingKind . SERVICE ;", "del_tokens": "Preconditions . checkArgument ( ! Strings . empty ( header ) , \"invalid request header string for negotiation.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "methods", "from", "CDAService", ".", "java"], "add_tokens": "/ * TBD * /", "del_tokens": "import com . contentful . java . lib . Utils ; // TBD", "commit_type": "remove"}
{"commit_tokens": ["Adds", "more", "Integration", "Tests", "for", "IdentityStrategy"], "add_tokens": "import java . util . Iterator ; this . referenceItem = referenceItem ; final CollectionItemElementSelector selector = new CollectionItemElementSelector ( referenceItem ) ; return identityStrategy == null ? selector : selector . copyWithIdentityStrategy ( identityStrategy ) ; unset ( target ) ; final Collection < ? > targetCollection = objectAsCollection ( target ) ; if ( targetCollection == null ) { return ; } final Iterator < ? > iterator = targetCollection . iterator ( ) ; while ( iterator . hasNext ( ) ) final Object item = iterator . next ( ) ; if ( item != null && identityStrategy . equals ( item , referenceItem ) ) { iterator . remove ( ) ; break ; }", "del_tokens": "this . referenceItem = referenceItem ; return new CollectionItemElementSelector ( referenceItem ) . copyWithIdentityStrategy ( identityStrategy ) ; // TODO IdentityStrategy? targetCollection . remove ( previous ) ; // TODO IdentityStrategy? final Collection targetCollection = objectAsCollection ( target ) ; if ( targetCollection != null ) // TODO IdentityStrategy? targetCollection . remove ( referenceItem ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "compact", "integer", "arrays", "for", "state", "and", "transition", "tables", "."], "add_tokens": "package eu . danieldk . fsadict ; import java . io . Serializable ; class CompactIntArray implements Serializable { private static final long serialVersionUID = 1L ; private static int INT_SIZE = 32 ; if ( d_bitsPerElem == 0 ) return 0 ; if ( d_bitsPerElem == 0 ) return ; / * * * Get the size of the array . * @ return The size . * / public int size ( ) { return d_size ; } public static int width ( int n ) { return INT_SIZE - Integer . numberOfLeadingZeros ( n ) ; }", "del_tokens": "package eu . danieldk . fsadict . collections ; class CompactIntArray { private int INT_SIZE = 32 ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "encodedImage", "to", "take", "FileInputStream", "instead", "of", "InputStream"], "add_tokens": "import java . io . FileInputStream ; // Only one of this will be set. The EncodedImage can either be backed by a ByteBuffer or a // Supplier of InputStream, but not both. private final @ Nullable CloseableReference < PooledByteBuffer > mPooledByteBufferRef ; private final @ Nullable Supplier < FileInputStream > mInputStreamSupplier ; public EncodedImage ( Supplier < FileInputStream > inputStreamSupplier ) { public EncodedImage ( Supplier < FileInputStream > inputStreamSupplier , int streamSize ) { this ( inputStreamSupplier ) ; CloseableReference < PooledByteBuffer > pooledByteBufferRef = CloseableReference . cloneOrNull ( mPooledByteBufferRef ) ; CloseableReference < PooledByteBuffer > pooledByteBufferRef = CloseableReference . cloneOrNull ( mPooledByteBufferRef ) ; return ( mPooledByteBufferRef != null ) ? mPooledByteBufferRef . getUnderlyingReferenceTestOnly ( ) : null ;", "del_tokens": "private final CloseableReference < PooledByteBuffer > mPooledByteBufferRef ; private final Supplier < InputStream > mInputStreamSupplier ; public EncodedImage ( Supplier < InputStream > inputStreamSupplier ) { public EncodedImage ( Supplier < InputStream > inputStreamSupplier , int streamSize ) { Preconditions . checkNotNull ( inputStreamSupplier ) ; this . mPooledByteBufferRef = null ; this . mInputStreamSupplier = inputStreamSupplier ; CloseableReference < PooledByteBuffer > pooledByteBufferRef = mPooledByteBufferRef . cloneOrNull ( ) ; CloseableReference < PooledByteBuffer > pooledByteBufferRef = mPooledByteBufferRef . cloneOrNull ( ) ; return mPooledByteBufferRef . getUnderlyingReferenceTestOnly ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Made", "call", "()", "call", "getTarget", "()", "to", "facilitate", "subclassing", "getTarget", "method", "."], "add_tokens": "* Copyright ( c ) Nmote Ltd . 2003 - 2014. All rights reserved . return getTarget ( ) . call ( call ) ;", "del_tokens": "* Copyright ( c ) Nmote Ltd . 2003 - 2014. All rights reserved . return target . call ( call ) ;", "commit_type": "make"}
{"commit_tokens": ["Adds", "equals", "method", "to", "SubscriptionOptions", "to", "allow", "easier", "asserts", "in"], "add_tokens": "testOpts = buildSubscriptionOptions ( ) ; } private static SubscriptionOptions buildSubscriptionOptions ( ) { return new SubscriptionOptions . Builder ( ) . ackWait ( Duration . ofMillis ( 500 ) ) @ Test public void testEquals ( ) { assertEquals ( buildSubscriptionOptions ( ) , buildSubscriptionOptions ( ) ) ; } @ Test public void testHashcode ( ) { assertEquals ( buildSubscriptionOptions ( ) . hashCode ( ) , buildSubscriptionOptions ( ) . hashCode ( ) ) ; }", "del_tokens": "testOpts = new SubscriptionOptions . Builder ( ) . ackWait ( Duration . ofMillis ( 500 ) )", "commit_type": "add"}
{"commit_tokens": ["made", "some", "methods", "in", "ResultSetUtility", "public"], "add_tokens": "public Map < String , Object > convertToMap ( ResultSet rs , Map < String , String > alreadyDeterminedMappings ) throws SQLException { public Map < String , String > createColumnToPropertyMappings ( final ResultSetMetaData rsmd ) throws SQLException { / * * * Get the label or name of a column * @ param rsmd * @ param col * @ return * @ throws SQLException * / public String columnLabelOrName ( ResultSetMetaData rsmd , int col ) throws SQLException {", "del_tokens": "protected Map < String , Object > convertToMap ( ResultSet rs , Map < String , String > alreadyDeterminedMappings ) throws SQLException { protected Map < String , String > createColumnToPropertyMappings ( final ResultSetMetaData rsmd ) throws SQLException { protected String columnLabelOrName ( ResultSetMetaData rsmd , int col ) throws SQLException {", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "validations", "for", "event", "handlers"], "add_tokens": "ObservableQueue q = EventQueues . getQueue ( event , false ) ;", "del_tokens": "ObservableQueue q = EventQueues . getQueue ( event ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "appointment", "attendees", "to", "guests", ".", "Renamed", "association", "to", "guests", "too", "."], "add_tokens": "private final AssociationField < Appointment , AppointmentAttendee > guests = instantiateAssociationField ( \"guests\" , public AssociationField < Appointment , AppointmentAttendee > guests ( ) { return guests ; allAssociations . add ( guests ( ) ) ;", "del_tokens": "private final AssociationField < Appointment , AppointmentAttendee > attendees = instantiateAssociationField ( \"guests\" , public AssociationField < Appointment , AppointmentAttendee > attendees ( ) { return attendees ; allAssociations . add ( attendees ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["implemented", "POST", "on", "basis", "of"], "add_tokens": "class HttpEntityEnclosingHeadersHandler extends ClientHeadersHandler { public HttpEntityEnclosingHeadersHandler ( UrlRewriter urlRewriter ) {", "del_tokens": "class PostClientHeadersHandler extends ClientHeadersHandler { public PostClientHeadersHandler ( UrlRewriter urlRewriter ) {", "commit_type": "implement"}
{"commit_tokens": ["Added", "more", "tests", "fixed", "more", "bugs", "."], "add_tokens": "if ( i > 0 ) { sB . append ( \",\" ) ; } if ( i > 4 ) { break ; } //null == already contains key if ( t == null ) { //note only get same collection on identity of val, not equals() if ( foundNode . val ( ) == val ) { }", "del_tokens": "if ( i > 0 ) { sB . append ( \",\" ) ; } else if ( i > 5 ) { break ; } if ( t == null ) //null == already contains key { if ( foundNode . val ( ) == val ) //note only get same collection on identity of val, not equals()", "commit_type": "add"}
{"commit_tokens": ["Made", "Time", "throw", "InterruptedExceptions", "on", "sleep"], "add_tokens": "public void sleep ( long ms ) throws InterruptedException ;", "del_tokens": "public void sleep ( long ms ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "parent", "lookup"], "add_tokens": "private Context parent ; parent = ctx . parent ; String value = values . get ( key ) ; if ( value == null && parent != null ) { return parent . get ( key ) ; } return value ; Context child = new Context ( ) ; child . parent = this ; children . put ( name , child ) ; Context childContext = children . get ( child ) ; if ( childContext == null ) { return ; } childContext . parent = null ;", "del_tokens": "return values . get ( key ) ; children . put ( name , new Context ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "javadoc", "correct", "version", "stamping"], "add_tokens": "/ * * * Maestrano API Service , related to all Maestrano API * / this . id = MnoPropertiesHelper . getProperty ( \"api.id\" , props ) ; this . key = MnoPropertiesHelper . getProperty ( \"api.key\" , props ) ; this . accountBase = MnoPropertiesHelper . getProperty ( \"api.accountBase\" , props ) ; this . accountHost = getAccountHost ( appService , props ) ; this . connecBase = getConnecBase ( appService , props ) ; this . connecHost = getConnecHost ( appService , props ) ; this . verifySslCerts = MnoPropertiesHelper . getBooleanProperty ( \"api.verifySslCerts\" , props ) ;", "del_tokens": "id = MnoPropertiesHelper . getProperty ( \"api.id\" , props ) ; key = MnoPropertiesHelper . getProperty ( \"api.key\" , props ) ; accountBase = MnoPropertiesHelper . getProperty ( \"api.accountBase\" , props ) ; accountHost = getAccountHost ( appService , props ) ; connecBase = getConnecBase ( appService , props ) ; connecHost = getConnecHost ( appService , props ) ; verifySslCerts = MnoPropertiesHelper . getBooleanProperty ( \"api.verifySslCerts\" , props ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "LRUMap", "to", "net", ".", "entropysoft", ".", "transmorph", ".", "utils"], "add_tokens": "import net . entropysoft . transmorph . utils . LRUMap ;", "del_tokens": "import net . entropysoft . transmorph . cache . LRUMap ;", "commit_type": "move"}
{"commit_tokens": ["add", "raw", "()", "method", "for", "windows", "builder"], "add_tokens": ". raw ( )", "del_tokens": ". type ( Type . raw )", "commit_type": "add"}
{"commit_tokens": ["fix", "failing", "MRSuite", "(", "not", "using", "the", "proper", "Embedded", "ES", "port", ")"], "add_tokens": "import org . elasticsearch . hadoop . integration . TestSettings ; import org . elasticsearch . hadoop . util . TestUtils ; TestUtils . addProperties ( conf , TestSettings . TESTING_PROPS ) ;", "del_tokens": "import org . apache . hadoop . mapred . JobClient ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "compile", "breakage", "against", "OpenJDK7", "."], "add_tokens": "public JavaCompiler make ( Context context ) {", "del_tokens": "public JavaCompiler make ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "the", "@Mock", "qualifier", "and", "rely", "on", "the", "@Uri", "only"], "add_tokens": "import io . astefanutti . camel . cdi . bean . UriEndpointRoute ; public class UriEndpointRouteTest { @ Uri ( \"mock:outbound\" ) . addClass ( UriEndpointRoute . class )", "del_tokens": "import io . astefanutti . camel . cdi . bean . SimpleRoute ; public class SimpleRouteTest { @ Mock ( \"mock:outbound\" ) . addClass ( SimpleRoute . class )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "also", "headers", "option", "for", "the", "head", "method"], "add_tokens": "public ComposableFuture < Response > httpHead ( final String url , final Header ... headers ) { if ( headers != null && headers . length > 0 ) { for ( final Header header : headers ) { requestBuilder . addHeader ( header . key , header . value ) ; } }", "del_tokens": "public ComposableFuture < Response > httpHead ( final String url ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "with", "collapsing", "when", "searching", "in", "scenario", "content"], "add_tokens": "if ( hasMultipleExplicitCases ( ) ) { writer . println ( \"<div class='case-content collapsed' id='\" + getCaseId ( ) + \"'>\" ) ; } private boolean hasMultipleExplicitCases ( ) { return ! this . scenarioCase . getExplicitArguments ( ) . isEmpty ( ) && ! scenarioModel . isCasesAsTable ( ) ; } if ( hasMultipleExplicitCases ( ) ) { writer . println ( \"</div><!-- case-content -->\" ) ; }", "del_tokens": "String collapsed = scenarioCase . getExplicitArguments ( ) . isEmpty ( ) || scenarioModel . isCasesAsTable ( ) ? \"\" : \" collapsed\" ; writer . println ( \"<div class='case-content\" + collapsed + \"' id='\" + getCaseId ( ) + \"'>\" ) ; writer . println ( \"</div><!-- case-content -->\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "lazy", "-", "loading", "behaviour", "from", "getter", "methods"], "add_tokens": "public Map < FieldName , ? > evaluate ( Map < FieldName , ? > predictions , ModelEvaluationContext context ) { Output output = modelManager . getOutput ( ) ; if ( output == null ) { return predictions ; }", "del_tokens": "public Map < FieldName , Object > evaluate ( Map < FieldName , ? > predictions , ModelEvaluationContext context ) { Output output = modelManager . getOrCreateOutput ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "check", "to", "avoid", "setting", "default", "configuration", "with", "DynamicPropertyFactory", "given", "a", "system", "property", "."], "add_tokens": "if ( dynamicPropertySupportImpl == null ) { DynamicPropertyFactory . getInstance ( ) ; }", "del_tokens": "// DynamicPropertyFactory.getInstance();", "commit_type": "add"}
{"commit_tokens": ["Fix", "regression", ":", "wrong", "method", "chosen", "as", "evaluator"], "add_tokens": "method = findEvalMethod ( clazz ) ; protected Method findEvalMethod ( Class < ? > clazz ) { / * * Note 1 : * Some Java instrumentation tools ( e . g . JaCoCo ) insert code into * classes at runtime . This means that the static eval ( ) method * could * * not be the first method of our runtime generated classes anymore . * * Note 2 : * We can 't use clazz.getDeclaredMethod(name, classes), as the argument * types of the eval ( ) method could be normalized ( see createSource ( ) ) . * / for ( Method method : clazz . getDeclaredMethods ( ) ) { if ( \"eval\" . equals ( method . getName ( ) ) ) { return method ; } } throw new IllegalArgumentException ( \"Couldn't find eval method!\" ) ; }", "del_tokens": "method = clazz . getDeclaredMethods ( ) [ 0 ] ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "in", "an", "onZooKeeperReset", "listener", "callback", "and", "changing", "the", "return", "type", "of", "getNodes", "()"], "add_tokens": "import java . util . Collections ; public Map < String , T > getNodes ( ) { return Maps . transformValues ( Collections . unmodifiableMap ( _nodes ) , new Function < Optional < T > , T > ( ) { fireResetEvent ( ) ; private void fireResetEvent ( ) { for ( NodeListener < T > listener : _listeners ) { listener . onZooKeeperReset ( ) ; } }", "del_tokens": "import com . google . common . collect . Iterables ; public Iterable < T > getNodes ( ) { return Iterables . transform ( Iterables . unmodifiableIterable ( _nodes . values ( ) ) , new Function < Optional < T > , T > ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "cloud", "sdk", "logging", "verbose", "progress", "at", "the", "quiet", "level"], "add_tokens": "ConsoleListener consoleListener = new DownloadCloudSdkTaskConsoleListener ( getProject ( ) ) ;", "del_tokens": "ConsoleListener consoleListener = new DownloadCloudSdkTaskConsoleListener ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "initial", "/", "crash", "configuration", "inspection", "was", "done", "on", "the", "same", "instance", "at", "the", "crash", "instant", "...", "so", "there", "were", "no", "differences", "between", "the", "two", "fields", "content", "in", "the", "report", "."], "add_tokens": "private String mInitialConfiguration ; // If mDfltExceptionHandler is not null, initialization is already done. mInitialConfiguration = ConfigurationInspector . toString ( mContext . getResources ( ) . getConfiguration ( ) ) ; mCrashProperties . put ( INITIAL_CONFIGURATION_KEY , mInitialConfiguration ) ;", "del_tokens": "private Configuration mInitialConfiguration ; // If mDfltExceptionHandler is not null, initialisation is already done. mInitialConfiguration = mContext . getResources ( ) . getConfiguration ( ) ; mCrashProperties . put ( INITIAL_CONFIGURATION_KEY , ConfigurationInspector . toString ( mInitialConfiguration ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "custom", "maven", "and", "npm", "versions", "in", "import", "section", "in", "kmd"], "add_tokens": "if ( importEntry . getMavenVersion ( ) == null ) { importEntry . setMavenVersion ( dependencyModule . getCode ( ) . getApi ( ) . get ( \"java\" ) . get ( \"mavenVersion\" ) ) ; } if ( importEntry . getNpmVersion ( ) == null ) { importEntry . setNpmVersion ( dependencyModule . getCode ( ) . getApi ( ) . get ( \"js\" ) . get ( \"npmVersion\" ) ) ; }", "del_tokens": "// The virtual module \"kurento\" is allways resolved if ( importEntry . getModule ( ) != null ) { continue ; }", "commit_type": "allow"}
{"commit_tokens": ["Removes", "println", "that", "was", "breaking", "test"], "add_tokens": "import feign . Request . HttpMethod ; import java . util . Collection ; import java . util . Map ; import static org . hamcrest . Matchers . contains ; public void setUp ( ) { requestTemplate = new RequestTemplate ( ) . method ( HttpMethod . GET ) ; public void applyAuthorizationHeader ( ) {", "del_tokens": "import static org . hamcrest . Matchers . * ; import java . util . Collection ; import java . util . Map ; public void setUp ( ) throws Exception { requestTemplate = new RequestTemplate ( ) . method ( \"GET\" ) ; public void applyAuthorizationHeader ( ) throws Exception { System . out . println ( requestTemplate ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "an", "adapter", "to", "make", "construction", "of", "listeners", "easier"], "add_tokens": "extends WebSocketListenerAdapter static final NullWebSocketListener LISTENER = new NullWebSocketListener ( ) ; private NullWebSocketListener ( )", "del_tokens": "import com . google . gwt . typedarrays . shared . ArrayBuffer ; import javax . annotation . Nonnull ; import javax . annotation . Nullable ; implements WebSocketListener static final NullWebSocketListener LISTENER = new NullWebSocketListener ( ) ; @ Override public void onOpen ( @ Nonnull final WebSocket webSocket ) { } @ Override public void onClose ( @ Nonnull final WebSocket webSocket , final boolean wasClean , final int code , @ Nullable final String reason ) { } @ Override public void onMessage ( @ Nonnull final WebSocket webSocket , @ Nonnull final String data ) { } @ Override public void onMessage ( @ Nonnull final WebSocket webSocket , @ Nonnull final ArrayBuffer data ) { } @ Override public void onError ( @ Nonnull final WebSocket webSocket )", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "VerticalTextView", "to", "alternative", "version"], "add_tokens": "import android . graphics . Paint ; import android . text . TextPaint ; import android . util . Log ; * * http : //stackoverflow.com/a/7855852 protected void onDraw ( Canvas canvas ) { TextPaint textPaint = getPaint ( ) ; textPaint . setColor ( getCurrentTextColor ( ) ) ; textPaint . drawableState = getDrawableState ( ) ; canvas . save ( ) ; canvas . translate ( getWidth ( ) , 0 ) ; canvas . translate ( 0 , getHeight ( ) ) ; canvas . translate ( getCompoundPaddingLeft ( ) , getExtendedPaddingTop ( ) ) ; getLayout ( ) . draw ( canvas ) ; canvas . restore ( ) ;", "del_tokens": "protected boolean setFrame ( int l , int t , int r , int b ) { return super . setFrame ( l , t , l + ( b - t ) , t + ( r - l ) ) ; } @ Override public void draw ( Canvas canvas ) { canvas . translate ( getHeight ( ) , 0 ) ; canvas . translate ( 0 , getWidth ( ) ) ; canvas . clipRect ( 0 , 0 , getWidth ( ) , getHeight ( ) , android . graphics . Region . Op . REPLACE ) ; super . draw ( canvas ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["upgrade", "rxjava", "and", "use", "properties", "in", "parent"], "add_tokens": "( Observable < T > ) o1 . filter ( com . github . davidmoten . rx . Functions . alwaysFalse ( ) ) , o2 ) ;", "del_tokens": "import rx . functions . Functions ; import au . gov . amsa . ais . rx . operators . OperationLog ; ( Observable < T > ) o1 . filter ( Functions . alwaysFalse ( ) ) , o2 ) ; public static < T > Observable < T > log ( Observable < T > source ) { return Observable . create ( OperationLog . log ( source ) ) ; }", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "custom", "url", "to", "config"], "add_tokens": "import android . text . TextUtils ; String url = \"https://play.google.com/store/apps/details?id=\" + appPackage ; if ( ! TextUtils . isEmpty ( sConfig . mUrl ) ) { url = sConfig . mUrl ; } Intent intent = new Intent ( Intent . ACTION_VIEW , Uri . parse ( url ) ) ; private String mUrl = null ; / * * * Set navigation url when user clicks rate button . * Typically , url will be https : //play.google.com/store/apps/details?id=PACKAGE_NAME for Google Play. * @ param url * / public void setUrl ( String url ) { this . mUrl = url ; }", "del_tokens": "Intent intent = new Intent ( Intent . ACTION_VIEW , Uri . parse ( \"https://play.google.com/store/apps/details?id=\" + appPackage ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "callback", "notification", "after", "return", "."], "add_tokens": "private Consumer < BuildResult > onBuildComplete ; this . onBuildComplete = onBuildComplete ; return ; //TODO private void notifyBuildComplete ( ) { //notify build complete onBuildComplete . accept ( new BuildResult ( ) ) ; }", "del_tokens": "//notify build complete onBuildComplete . accept ( new BuildResult ( ) ) ;", "commit_type": "move"}
{"commit_tokens": ["fix", "tests", "on", "http", "worker"], "add_tokens": "public static class CustomTrustManager implements X509TrustManager {", "del_tokens": "private static class CustomTrustManager implements X509TrustManager {", "commit_type": "fix"}
{"commit_tokens": ["Use", "logging", "API", "for", "string", "replacement"], "add_tokens": "LOG . debug ( \"Added Directory {}\" , pDirectory ) ;", "del_tokens": "if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( format ( \"Added Directory %s\" , pDirectory ) ) ; }", "commit_type": "use"}
{"commit_tokens": ["move", "Launcher", "to", "com", ".", "github", ".", "to2mbn", ".", "jmccc", ".", "launch"], "add_tokens": "package com . github . to2mbn . jmccc . launch ; * You can use { @ link Jmccc # getLauncher ( ) } to get a launcher object . * subprocess and report them to the given listener . * We recommend you NOT to call { @ link ProcessMonitor # stop ( ) } unless you are going to exit the jvm and", "del_tokens": "package com . github . to2mbn . jmccc ; import com . github . to2mbn . jmccc . launch . Jmccc ; import com . github . to2mbn . jmccc . launch . LaunchException ; import com . github . to2mbn . jmccc . launch . LaunchResult ; * You can use { @ link Jmccc # getLauncher ( ) } to get a Launcher object . * subprocess and reported them to the given listener . * We recommend you NOT to call { @ link ProcessMonitor # stop ( ) } unless you are going to exit the and", "commit_type": "move"}
{"commit_tokens": ["Add", "charset", "to", "compileString", "to", "control", "the", "passed", "string", "encoding", "."], "add_tokens": "import org . apache . commons . io . Charsets ; import java . nio . charset . Charset ; * @ param charset The charset of the input string . public Output compileString ( String string , Charset charset , File inputPath , File outputPath , Options options ) throws CompilationException { byte [ ] bytes = string . getBytes ( charset ) ; memory . setByte ( bytes . length , ( byte ) 0 ) ;", "del_tokens": "import java . nio . ByteBuffer ; import java . nio . charset . StandardCharsets ; public Output compileString ( String string , File inputPath , File outputPath , Options options ) throws CompilationException { byte [ ] bytes = string . getBytes ( ) ; memory . setByte ( bytes . length , ( byte ) 0 ) ; // TODO casting", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "broken", "test", "."], "add_tokens": "return Math . round ( event . getMetric ( ) ) ;", "del_tokens": "return event . getMetric ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "item", "decoration", "issue", "on", "configuration", "change", "."], "add_tokens": "private GridSpacesItemDecoration gridSpacesItemDecoration ; recyclerView . removeItemDecoration ( gridSpacesItemDecoration ) ; gridSpacesItemDecoration = new GridSpacesItemDecoration ( ImageGalleryUtils . dp2px ( getActivity ( ) , 2 ) , numOfColumns ) ; recyclerView . addItemDecoration ( gridSpacesItemDecoration ) ;", "del_tokens": "recyclerView . addItemDecoration ( new GridSpacesItemDecoration ( ImageGalleryUtils . dp2px ( getActivity ( ) , 2 ) , numOfColumns ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "signing", "of", "YUM", "repositories"], "add_tokens": "import java . util . Comparator ; files . sort ( Comparator . comparing ( CacheEntryInformation :: getName ) ) ; final Optional < String > name = segs . length > 2 ? Optional . ofNullable ( segs [ segs . length - 1 ] ) : Optional . empty ( ) ;", "del_tokens": "final Optional < String > name = segs . length > 2 ? Optional . of ( segs [ segs . length - 1 ] ) : Optional . empty ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "mapping", "of", "Tuple2", "...", "vararg"], "add_tokens": "public static < T1 , T2 > Map < T1 , T2 > map ( Tuple2 < T1 , T2 > ... keyValues ) { return map ( Arrays . asList ( keyValues ) ) ;", "del_tokens": "public static < T1 , T2 > Map < T1 , Tuple1 < T2 >> map ( Tuple2 < T1 , T2 > ... keyValues ) { return map2 ( Arrays . asList ( keyValues ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "data", "from", "System", ".", "in", "was", "being", "read", "in", "that", "should", "have", "been", "ignored", "."], "add_tokens": "import java . io . InputStream ; final InputStream is = System . in ; int c ; // Wait for some data to become available waitForInputStreamData ( is ) ; while ( ( c = is . read ( ) ) != '\\n' ) { buf [ offset ++ ] = ( char ) c ; // No new line found yet so check and wait for the stream to have more data waitForInputStreamData ( is ) ; final InputStream is = System . in ; int c ; // Wait for some data to become available waitForInputStreamData ( is ) ; while ( ( c = is . read ( ) ) != '\\n' ) { line . append ( ( char ) c ) ; // No new line found yet so check and wait for the stream to have more data waitForInputStreamData ( is ) ; private void waitForInputStreamData ( InputStream is ) throws IOException { // Wait for some input if there is none available while ( is . available ( ) <= 0 ) { try { Thread . sleep ( 500 ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( e ) ; } } }", "del_tokens": "char c ; while ( ( c = ( char ) System . in . read ( ) ) != '\\n' ) { buf [ offset ++ ] = c ; char c ; while ( ( c = ( char ) System . in . read ( ) ) != '\\n' ) { line . append ( c ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "guava", "Hashing", ".", "sha1", "()", "to", "replace", "DigestUtils", ".", "sha1Hex", "()"], "add_tokens": "import com . google . common . base . Charsets ; import com . google . common . hash . Hashing ; String sign = Hashing . sha1 ( ) . hashString ( buildSignatureText ( signature ) , Charsets . UTF_8 ) . toString ( ) ;", "del_tokens": "import org . apache . commons . codec . digest . DigestUtils ; String sign = DigestUtils . sha1Hex ( buildSignatureText ( signature ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "hook", "for", "creating", "invocation", "context", "in", "InterceptorInvocationHandler"], "add_tokens": "import javax . interceptor . InvocationContext ; public class InterceptorInvocationHandler implements InvocationHandler , Serializable { return interceptor . processInvocation ( createInvocationContext ( proxy , method , args ) ) ; } / * * * Get the invocation context to use . * * @ param proxy the proxy object * @ param method the invoked method * @ param args the method parameters * @ return the invocation context * / protected InvocationContext createInvocationContext ( final Object proxy , final Method method , final Object [ ] args ) { return new SimpleInvocationContext ( proxy , method , args , null ) ;", "del_tokens": "public final class InterceptorInvocationHandler implements InvocationHandler , Serializable { return interceptor . processInvocation ( new SimpleInvocationContext ( proxy , method , args , null ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "sync", "check", "ret", "code", "1102"], "add_tokens": "Arrays . asList ( \"wx2.qq.com\" , \"wx8.qq.com\" , \"wx.qq.com\" , \"web2.wechat.com\" , \"web.wechat.com\" ) ) ;", "del_tokens": "Arrays . asList ( \"webpush.wx2.qq.com\" , \"webpush.wx8.qq.com\" , \"webpush.wx.qq.com\" , \"webpush.web2.wechat.com\" , \"webpush.web.wechat.com\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "defautl", "for", "the", "caching", "proxy"], "add_tokens": "clientCache . createClientRegionFactory ( ClientRegionShortcut . CACHING_PROXY_HEAP_LRU ) ) ; boolean cachingProxy = Config . getPropertyBoolean ( GeodeConfigConstants . USE_CACHING_PROXY_PROP , false ) . booleanValue ( ) ; geodeClient = new GeodeClient ( cachingProxy , Config . getProperty ( GeodeConfigConstants . PDX_CLASS_PATTERN_PROP , \".*\" ) ) ;", "del_tokens": "clientCache . createClientRegionFactory ( ClientRegionShortcut . CACHING_PROXY ) ) ; geodeClient = new GeodeClient ( true , Config . getProperty ( GeodeConfigConstants . PDX_CLASS_PATTERN_PROP , \".*\" ) ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "jacoco", "plugin", "and", "configure", "it", "add", "scratch", "for", "new", "plugin"], "add_tokens": "public static final String KEY_PAIR_JSON_PATH = \"$.instancesSet.items[*].keyName\" ; public static final String ROLE_NAME_JSON_PATH = \"$.instancesSet.items[*].roleName\" ; return JsonPath . read ( parameters , KEY_PAIR_JSON_PATH ) ; / * * + * Extract the 'roleName' . + * / public static List < String > readRoleName ( final String parameters ) { if ( parameters == null ) { return null ; } return JsonPath . read ( parameters , ROLE_NAME_JSON_PATH ) ; }", "del_tokens": "return JsonPath . read ( parameters , \"$.instancesSet.items[*].keyName\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "NullPointerException", "in", "getView", "of", "ContextualUndoAdapter"], "add_tokens": "if ( mCountDownFormatter != null ) { mCurrentRemovedView . updateCountDownTimer ( mCountDownFormatter . getCountDownString ( millisLeft ) ) ; }", "del_tokens": "mCurrentRemovedView . updateCountDownTimer ( mCountDownFormatter . getCountDownString ( millisLeft ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["made", "public", "things", "vars", "protected", "moved", "accessor", "to", "fullname", "to", "thing"], "add_tokens": "protected String kind ; protected String fullName ; public String getKind ( ) { return kind ; } public String getFullName ( ) { return fullName ; }", "del_tokens": "public String kind ; public String fullName ;", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "bit", "more", "testing", ".", "Not", "done", "yet", "but", "getting", "closer", "."], "add_tokens": "if ( this . key2Result . get ( key ) == null ) {", "del_tokens": "if ( key2Result . get ( key ) == null ) {", "commit_type": "add"}
{"commit_tokens": ["Adds", "more", "checks", "for", "notray", "and", "locally", "headless", "systems"], "add_tokens": "import static org . junit . Assume . assumeTrue ; import java . awt . Desktop ; import java . awt . SystemTray ; import org . junit . Before ; } else { assumeTrue ( SystemTray . isSupported ( ) ) ; assumeTrue ( Desktop . isDesktopSupported ( ) ) ;", "del_tokens": "import org . junit . Before ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "/", "batch", "api", "implementation"], "add_tokens": "import com . lookfirst . wepay . api . Call ; import com . lookfirst . wepay . api . Calls ; import java . util . List ; public class BatchCreateRequest extends WePayRequest < Calls > {", "del_tokens": "import java . util . List ; import com . lookfirst . wepay . api . Call ; public class BatchCreateRequest extends WePayRequest < Call > {", "commit_type": "fix"}
{"commit_tokens": ["Use", "corrent", "double", "-", "check", "lazy", "initializer"], "add_tokens": "private volatile Object object ; Object result = object ; if ( result == null ) { result = object ; if ( result == null ) { object = ( result = doGetObject ( ) ) ; return result ;", "del_tokens": "private Object object ; if ( object == null ) { if ( object == null ) { object = doGetObject ( ) ; return object ;", "commit_type": "use"}
{"commit_tokens": ["Added", "the", "senBotContext", ".", "cucumberManager", ".", "defaultCucumberOptions", "option", "to", "the", "spring", "properties", "file", "to", "allow", "for", "a", "default", "features", "location", "and", "cucumber", ".", "options", "prop", "so", "the", "mvn", "commandline", "commands", "can", "yet", "be", "shorter", "again"], "add_tokens": "public CucumberManager ( String scenarioGlobalsCreationHookClass , String defaultCucumberOptionsString ) throws SecurityException , NoSuchMethodException , ClassNotFoundException , IllegalArgumentException , InstantiationException , IllegalAccessException , InvocationTargetException { if ( System . getProperty ( \"cucumber.options\" ) == null ) { String overwrite = null ; overwrite = System . getProperty ( \"features\" ) ; } else if ( ! StringUtils . isBlank ( defaultCucumberOptionsString ) ) { overwrite = defaultCucumberOptionsString ; } if ( overwrite != null ) { System . setProperty ( \"cucumber.options\" , overwrite ) ;", "del_tokens": "public CucumberManager ( String scenarioGlobalsCreationHookClass ) throws SecurityException , NoSuchMethodException , ClassNotFoundException , IllegalArgumentException , InstantiationException , IllegalAccessException , InvocationTargetException { if ( System . getProperty ( \"cucumber.options\" ) == null ) { System . setProperty ( \"cucumber.options\" , System . getProperty ( \"features\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "thread", "pool", "to", "allow", "asynchronous", "notification", "to", "Bugsnag"], "add_tokens": "protected NotificationWorker notificationWorker ; notificationWorker = new NotificationWorker ( config ) ; public void setAsynchronousNotification ( boolean asynchronousNotification ) { config . setAsynchronousNotification ( asynchronousNotification ) ; } if ( ! config . shouldNotify ( ) ) return ; if ( error . shouldIgnore ( ) ) return ; if ( ! beforeNotify ( error ) ) return ; Notification notif = new Notification ( config , error ) ; if ( config . asynchronousNotification ) { notificationWorker . notifyAsync ( notif ) ; } else {", "del_tokens": "if ( ! config . shouldNotify ( ) ) return ; if ( error . shouldIgnore ( ) ) return ; if ( ! beforeNotify ( error ) ) return ; try { Notification notif = new Notification ( config , error ) ; } catch ( NetworkException ex ) { config . logger . warn ( \"Error notifying Bugsnag\" , ex ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "any", "attribute", "and", "ordering", "to", "dependency", "layer"], "add_tokens": "public interface Dependency extends AnyAtrributes {", "del_tokens": "public interface Dependency {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "constructor", "for", "signed", "functions", "and", "dictionaries"], "add_tokens": "new FlaggedOption ( \"signatureWidth\" , JSAP . INTEGER_PARSER , JSAP . NO_DEFAULT , JSAP . NOT_REQUIRED , 's' , \"signature-width\" , \"If specified, the signature width in bits; if negative, the generated function will be a dictionary.\" ) , final int signatureWidth = jsapResult . getInt ( \"signatureWidth\" , 0 ) ; BinIO . storeObject ( new MWHCFunction < CharSequence > ( collection , transformationStrategy , signatureWidth , BinIO . asLongIterable ( values ) , dataWidth , jsapResult . getFile ( \"tempDir\" ) , null , false ) , functionName ) ; else BinIO . storeObject ( new MWHCFunction < CharSequence > ( collection , transformationStrategy , signatureWidth , null , - 1 , jsapResult . getFile ( \"tempDir\" ) , null , false ) , functionName ) ;", "del_tokens": "new FlaggedOption ( \"width\" , JSAP . INTEGER_PARSER , JSAP . NO_DEFAULT , JSAP . NOT_REQUIRED , 'w' , \"width\" , \"If specified, the signature width in bits.\" ) , final int signatureWidth = jsapResult . getInt ( \"width\" , 0 ) ; BinIO . storeObject ( new MWHCFunction < CharSequence > ( collection , transformationStrategy , BinIO . asLongIterable ( values ) , dataWidth , jsapResult . getFile ( \"tempDir\" ) ) , functionName ) ; else BinIO . storeObject ( new MWHCFunction < CharSequence > ( collection , transformationStrategy , jsapResult . getFile ( \"tempDir\" ) ) , functionName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "path", "based", "topic", "subscribers"], "add_tokens": "Method [ ] methods = subscriber . getClass ( ) . getMethods ( ) ; if ( m . getName ( ) . equals ( \"receive\" ) && ! m . isSynthetic ( ) && ! m . isBridge ( ) ) { break ; List < SubscriberParent > list = new CopyOnWriteArrayList < > ( ) ; SubscriberParent p = getSubParent ( subscriber ) ; list . add ( p ) ; if ( mapping . putIfAbsent ( type , list ) != null ) { mapping . get ( type ) . add ( p ) ; }", "del_tokens": "Method [ ] methods = subscriber . getClass ( ) . getDeclaredMethods ( ) ; if ( m . getName ( ) . equals ( \"receive\" ) && ! m . isSynthetic ( ) && ! m . isBridge ( ) ) { subscribe ( mapping , subscriber , type ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "-", "regisration", "-", "area"], "add_tokens": "throw new RuntimeException ( \"Tags list must be a multiple of 2. It is converted into a map\" ) ;", "del_tokens": "/ * * * This exists only to make the message routing spring configuration a bit easier to follow . ( its not \"fast\" ) * @ param tpl * @ param tags * @ return * / throw new RuntimeException ( \"Tags list must be a multiple of 2 as it is converted into a map\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "sign", "extend", "bug", "."], "add_tokens": "scratchCode = ( scratchCode << 8 ) + ( scratchCodeBuffer [ i ] & 0xff ) ;", "del_tokens": "scratchCode <<= 8 ; scratchCode += scratchCodeBuffer [ i ] ;", "commit_type": "fix"}
{"commit_tokens": ["added", "setPosition", "setPositionAtStart", "and", "setPositionAtEnd", "to", "animations"], "add_tokens": "public class ColorAnimation extends TractionAnimation {", "del_tokens": "import com . google . gwt . animation . client . Animation ; public class ColorAnimation extends Animation {", "commit_type": "add"}
{"commit_tokens": ["add", "fetch", "hints", "to", "Accumulo", "input", "format"], "add_tokens": "import org . apache . accumulo . core . client . mapreduce . AccumuloInputFormat ; import org . apache . accumulo . core . util . Pair ; import org . vertexium . * ; import java . util . * ; public static void setFetchHints ( Job job , ElementType elementType , EnumSet < FetchHint > fetchHints ) { Iterable < Text > columnFamiliesToFetch = AccumuloGraph . getColumnFamiliesToFetch ( elementType , fetchHints ) ; Collection < Pair < Text , Text > > columnFamilyColumnQualifierPairs = new ArrayList < > ( ) ; for ( Text columnFamilyToFetch : columnFamiliesToFetch ) { columnFamilyColumnQualifierPairs . add ( new Pair < Text , Text > ( columnFamilyToFetch , null ) ) ; } AccumuloInputFormat . fetchColumns ( job , columnFamilyColumnQualifierPairs ) ; }", "del_tokens": "import org . vertexium . Authorizations ; import org . vertexium . Element ; import org . vertexium . GraphFactory ; import java . util . List ; import java . util . Map ;", "commit_type": "add"}
{"commit_tokens": ["removed", "state", "item", "from", "defaults"], "add_tokens": "protected int queryState = QUERY_CREATED ;", "del_tokens": "protected int queryState = DbDefault . queryState ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "problem", "with", "discrete", "movement", "failing", "for", "x", "/", "z", "co", "-", "ords", "<", "0"], "add_tokens": "double desiredX = ( ( int ) ( Math . abs ( newX ) ) + 0.5 ) * ( newX >= 0 ? 1 : - 1 ) ; double desiredZ = ( ( int ) ( Math . abs ( newZ ) ) + 0.5 ) * ( newZ >= 0 ? 1 : - 1 ) ;", "del_tokens": "double desiredX = ( int ) newX + 0.5 ; double desiredZ = ( int ) newZ + 0.5 ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "an", "issue", "with", "date_range", "mapping"], "add_tokens": "register ( \"date_range\" , new DateRangeAggregationConverter ( ) ) ;", "del_tokens": "register ( \"daterange\" , new DateRangeAggregationConverter ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "various", "tests", "and", "added", "checks", "for", "unparseable", "expressions"], "add_tokens": "CustomOperator factorial = new CustomOperator ( \"!\" , Operators . PRECEDENCE_EXPONENTATION + 100 , 1 , true ) { assertEquals ( ( Float ) 4f , calc . calculate ( ) ) ; expr = \"ceil(x) + 1 / y * abs(1.4)\" ; expected = ( float ) Math . ceil ( x ) + ( float ) 1f / y * ( float ) Math . abs ( 1.4f ) ; assertEquals ( ( Float ) expected , ( Float ) actual ) ;", "del_tokens": "CustomOperator factorial = new CustomOperator ( \"!\" , 6 , 1 , true ) { assertTrue ( 4f == calc . calculate ( ) ) ; @ Ignore @ Ignore @ Ignore @ Ignore expr = \"ceil(x) + 1 / y * abs(1.4)\" ; expected = ( float ) Math . ceil ( x ) + ( ( float ) 1f / y ) * ( float ) Math . abs ( 1.4f ) ; assertTrue ( expected == actual ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "an", "issue", "where", "getProperties", "()", "was", "not", "respecting", "the", "isSavingDefaults", "()", "flag"], "add_tokens": "/ * * Retrieve values from the lower level properties to avoid any * auto - trim issues . * / copy . setProperty ( property , properties . getProperty ( getTranslator ( ) . getPropertyName ( property ) ) ) ; * by this instance . < br > Properties propertiesCopy = properties . getProperties ( isSavingDefaults ( ) ) ;", "del_tokens": "copy . setProperty ( property , getRawProperty ( property ) ) ; * by this instance . This object will contain default values directly . In * other words , if one of the store ( ) methods in the { @ link Properties } * returned by this method is called , default values will be included . This * is true regardless of the value of { @ link # isSavingDefaults ( ) } . < br > Properties propertiesCopy = properties . getProperties ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "comment", "describing", "how", "the", "transmissionProbability", "pipeline", "works", "."], "add_tokens": "// The below pipeline works as follows: // - Fetch the variants, // - For each variant, see which parent transferred the variant to the // child. // - Groups Transmission sources by Variant, // - Calculate transmission Probability for each variant // - Print calculated values to a file.", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "minor", "merge", "-", "bug"], "add_tokens": "Element returnedElement = new MethodSimulator ( ) . simulate ( visitedInstructions ) ;", "del_tokens": "private final MethodSimulator methodSimulator = new MethodSimulator ( ) ; Element returnedElement = methodSimulator . simulate ( visitedInstructions ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "check", "for", "Toolbar", "on", "classpath", "for", "people", "not", "targeting", "21", "yet", "."], "add_tokens": "return CalligraphyUtils . canCheckForToolbar ( ) && view . getParent ( ) != null && ( view . getParent ( ) instanceof Toolbar ) ; if ( CalligraphyUtils . canCheckForToolbar ( ) && view instanceof android . support . v7 . widget . Toolbar ) {", "del_tokens": "return view . getParent ( ) != null && ( view . getParent ( ) instanceof android . support . v7 . widget . Toolbar ) ; if ( view instanceof android . support . v7 . widget . Toolbar ) {", "commit_type": "add"}
{"commit_tokens": ["Made", "request", "attribute", "setting", "configurable", "."], "add_tokens": "/ * * * Determines if the request should be decorated or not . * / private boolean decorateRequest ; if ( decorateRequest ) { CORSFilter . decorateCORSProperties ( request , requestType ) ; } DEFAULT_LOGGING_ENABLED , DEFAULT_DECORATE_REQUEST ) ; String configDecorateRequest = filterConfig . getInitParameter ( PARAM_CORS_REQUEST_DECORATE ) ; configLoggingEnabled , configDecorateRequest ) ; final String preflightMaxAge , final String loggingEnabled , final String decorateRequest ) if ( decorateRequest != null ) { // For any value other then 'true' this will be false. boolean shouldDecorateRequest = Boolean . parseBoolean ( decorateRequest ) ; this . decorateRequest = shouldDecorateRequest ; } / * * * By default , request is decorated with CORS attributes . * / public static final String DEFAULT_DECORATE_REQUEST = \"true\" ; / * * * Key to determine if request should be decorated . * / public static final String PARAM_CORS_REQUEST_DECORATE = \"cors.request.decorate\" ;", "del_tokens": "CORSFilter . decorateCORSProperties ( request , requestType ) ; DEFAULT_LOGGING_ENABLED ) ; configLoggingEnabled ) ; final String preflightMaxAge , final String loggingEnabled )", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "ability", "to", "easily", "run", "the", "sample", "stream"], "add_tokens": "public static void oauth ( String consumerKey , String consumerSecret , String token , String secret ) throws InterruptedException { public static void main ( String [ ] args ) { try { SampleStreamExample . oauth ( args [ 0 ] , args [ 1 ] , args [ 2 ] , args [ 3 ] ) ; } catch ( InterruptedException e ) { System . out . println ( e ) ; } }", "del_tokens": "public void oauth ( String consumerKey , String consumerSecret , String token , String secret ) throws InterruptedException {", "commit_type": "add"}
{"commit_tokens": ["Added", "tag", "nodes", "for", "each", "of", "the", "materials", "in", "order", "to", "toggle", "the", "corresponding", "layers", "on", "and", "off"], "add_tokens": "writer . writeln ( \"r: 0.2,\" ) ; writer . writeln ( \"g: 0.2,\" ) ; writer . writeln ( \"b: 0.2,\" ) ; writer . writeln ( \"r: 0.8,\" ) ; writer . writeln ( \"g: 0.8,\" ) ; writer . writeln ( \"b: 0.8,\" ) ; writer . writeln ( \"type: 'tag',\" ) ; writer . writeln ( \"tag: '\" + materialId + \"',\" ) ; writer . writeln ( \"nodes: [\" ) ; writer . indent ( ) ; writer . writeln ( \"{\" ) ; writer . indent ( ) ; writer . unindent ( ) ; writer . writeln ( \"],\" ) ; writer . unindent ( ) ; writer . writeln ( \"},\" ) ; // tag", "del_tokens": "writer . writeln ( \"r: 0.0,\" ) ; writer . writeln ( \"g: 0.0,\" ) ; writer . writeln ( \"b: 0.0,\" ) ; writer . writeln ( \"r: 1.0,\" ) ; writer . writeln ( \"g: 1.0,\" ) ; writer . writeln ( \"b: 1.0,\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "default", "capping", "hydrogen", "."], "add_tokens": "rGroup = rGroup . replace ( matcher . group ( ) , \"[*:\" + rgroupInformation . get ( index ) + \"]\" ) ;", "del_tokens": "rGroup = rGroup . replace ( matcher . group ( ) , \"[H:\" + rgroupInformation . get ( index ) + \"]\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "jboss", "-", "marshaling", "dependency", "from", "MethodIndentifier"], "add_tokens": "private final int hashCode ;", "del_tokens": "import org . jboss . marshalling . FieldSetter ; private static final FieldSetter hashCodeSetter = FieldSetter . get ( MethodIdentifier . class , \"hashCode\" ) ; private final transient int hashCode ; hashCodeSetter . setInt ( this , calculateHash ( name , name , parameterTypes ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "support", "for", "malformed", "properties", "file", "in", "classpath", "source"], "add_tokens": "} catch ( IOException | IllegalArgumentException e ) {", "del_tokens": "} catch ( IOException e ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "supporting", "classes", "and", "interfaces", "for", "integrating", "with", "Netty", "4"], "add_tokens": "import io . sipstack . netty . codec . sip . SipMessageEvent ; public final class SipHandler extends SimpleChannelInboundHandler < SipMessageEvent > { protected void channelRead0 ( final ChannelHandlerContext ctx , final SipMessageEvent event ) throws Exception { final SipMessage msg = event . getMessage ( ) ; final SipResponse response = msg . createResponse ( 200 ) ; event . getConnection ( ) . send ( response ) ;", "del_tokens": "import io . pkts . packet . sip . SipMessageFactory ; public final class SipHandler extends SimpleChannelInboundHandler < SipMessage > { private final SipMessageFactory messageFactory ; public SipHandler ( final SipMessageFactory messageFactory ) { this . messageFactory = messageFactory ; } protected void channelRead0 ( final ChannelHandlerContext ctx , final SipMessage msg ) throws Exception { final SipResponse response = this . messageFactory . createResponse ( 200 , msg . toRequest ( ) ) ; ctx . writeAndFlush ( response ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "using", "OkHttp", "as", "the", "underlying", "HTTP", "client", "."], "add_tokens": "conn . setConnectTimeout ( DefaultTimeoutMillis ) ; conn . setReadTimeout ( DefaultTimeoutMillis ) ;", "del_tokens": "/ * * * We pass this value to { @ link HttpsURLConnection # setConnectTimeout } . You can * change this setting by creating a subclass and overriding * { @ link # configureConnection } . * / public static final int DefaultConnectTimeoutMillis = 35 * 1000 ; / * * * We pass this value to { @ link HttpsURLConnection # setReadTimeout } . You can * change this setting by creating a subclass and overriding * { @ link # configureConnection } . * / public static final int DefaultReadTimeoutMillis = 35 * 1000 ; conn . setConnectTimeout ( DefaultConnectTimeoutMillis ) ; conn . setReadTimeout ( DefaultReadTimeoutMillis ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "support", "to", "generate", "model", "schemas", "from", "non", "-", "generic", "known", "concrete", "types"], "add_tokens": "JsonSchema jsonSchema ;", "del_tokens": "JsonSchema jsonSchema = null ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "user", "to", "choose", "to", "output", "all", "errors", "in", "bean", "comparison"], "add_tokens": "//----------------------------------------------------------------------- throw new BeanComparisonError ( message , 10 , expected , actual ) ; } } //----------------------------------------------------------------------- / * * * Asserts that two beans are equal , providing a better error message . * * @ param expected the expected value , not null * @ param actual the actual value , not null * / public static void assertBeanEqualsFullDetail ( final Bean expected , final Bean actual ) { assertBeanEqualsFullDetail ( null , expected , actual ) ; } / * * * Asserts that two beans are equal , providing a better error message , with * an unlimited number of errors reported . * * @ param expected the expected value , not null * @ param actual the actual value , not null * / public static void assertBeanEqualsFullDetail ( final String message , final Bean expected , final Bean actual ) { if ( expected == null ) { throw new AssertionError ( message + \": Expected bean must not be null\" ) ; } if ( actual == null ) { throw new AssertionError ( message + \": Actual bean must not be null\" ) ; } if ( expected . equals ( actual ) == false ) { throw new BeanComparisonError ( message , Integer . MAX_VALUE , expected , actual ) ;", "del_tokens": "throw new BeanComparisonError ( message , expected , actual ) ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "JPMML", "-", "Model", "dependency"], "add_tokens": "FieldName name = bayesInput . getFieldName ( ) ; FieldName name = bayesInput . getFieldName ( ) ;", "del_tokens": "FieldName name = FieldName . create ( bayesInput . getFieldName ( ) ) ; FieldName name = FieldName . create ( bayesInput . getFieldName ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "result", "naming", "issue", "when", "the", "metric", "is", "the", "key", "of", "a", "composite", "mbean", "and", "resultAlias", "is", "set", "."], "add_tokens": "if ( key == null ) { result = escapeObjectName ( objectName ) + \".\" + query . getAttribute ( ) ; } else { result = escapeObjectName ( objectName ) + \".\" + query . getAttribute ( ) + \".\" + key ; } return result ;", "del_tokens": "StringBuilder result = _getResultName ( query , objectName ) ; if ( key != null ) { result . append ( \".\" ) ; result . append ( key ) ; } return result . toString ( ) ; } @ Nonnull protected StringBuilder _getResultName ( @ Nonnull Query query , @ Nonnull ObjectName objectName ) { result = escapeObjectName ( objectName ) + \".\" + query . getAttribute ( ) ; return new StringBuilder ( result ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "rpc", "type", "finder", "test", "case"], "add_tokens": "/ * * Copyright 2013 Xi CHEN * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * /", "del_tokens": "* Date Time : 20 / 08 / 13 23 : 56", "commit_type": "add"}
{"commit_tokens": ["Added", "getBuffer", "()", "and", "equalsWithEpsilon", "()", "."], "add_tokens": "import java . nio . FloatBuffer ; FloatBuffer getBuffer ( ) ; boolean equalsWithEpsilon ( final Vec obj , final float epsilon ) ;", "del_tokens": "// FloatBuffer getFloatBuffer();", "commit_type": "add"}
{"commit_tokens": ["Add", "functions", "Matrix", ".", "error", "(", "Matrix", ")", "Matrix", ".", "normalize", "()", "and"], "add_tokens": "return Math . hypot ( x , y ) ; @ Override public Vector2 normalized ( ) { return ( Vector2 ) VectorOp . normalized ( this ) ; } @ Override public double error ( Matrix m ) { return VectorOp . error ( this , m ) ; } @ Override public void normalize ( ) { VectorOp . normalize ( this ) ; }", "del_tokens": "return Math . sqrt ( x * x + y * y ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "call", "capability", "to", "drools"], "add_tokens": "import javax . jbi . messaging . MessagingException ; import javax . jbi . messaging . NormalizedMessage ; NormalizedMessage inMessage = exchange . getMessage ( \"in\" ) ; String contextId = ( String ) inMessage . getProperty ( \"contextId\" ) ; Event e = XmlHelper . parseEvent ( inMessage ) ; DroolsExecutionContext drools = new DroolsExecutionContext ( this , objects , contextId ) ; @ Override protected void sendSync ( MessageExchange me ) throws MessagingException { super . sendSync ( me ) ; }", "del_tokens": "Event e = XmlHelper . parseEvent ( exchange . getMessage ( \"in\" ) ) ; DroolsExecutionContext drools = new DroolsExecutionContext ( this , objects ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "helper", "method", "to", "get", "or", "create", "a", "client", "with", "a", "custom", "config", "class"], "add_tokens": "return getNamedClient ( name , DefaultClientConfigImpl . class ) ; } / * * * Return the named client from map if already created . Otherwise creates the client using the configuration returned by { @ link # createNamedClient ( String , Class ) } . * * @ throws RuntimeException if an error occurs in creating the client . * / public static synchronized IClient getNamedClient ( String name , Class < ? extends IClientConfig > configClass ) { return simpleClientMap . get ( name ) ; return createNamedClient ( name , configClass ) ; throw new RuntimeException ( \"Unable to create client\" , e ) ;", "del_tokens": "return simpleClientMap . get ( name ) ; IClientConfig niwsClientConfig = getNamedConfig ( name ) ; return registerClientFromProperties ( name , niwsClientConfig ) ; throw new RuntimeException ( \"Unable to create client\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "javadoc", "tasks", "for", "gradle", "."], "add_tokens": "* @ param context the Context from which the navigation should be performed . * @ param destinationUrl the destination URL for the App Link . * @ param resolver the resolver to use for fetching App Link metadata . * @ param context the Context from which the navigation should be performed . * @ param destinationUrl the destination URL for the App Link .", "del_tokens": "* @ param context the Context from which the navigation should be performed . * @ param destination the destination URL for the App Link . * @ param resolver the resolver to use for fetching App Link metadata . * @ param context the Context from which the navigation should be performed . * @ param destination the destination URL for the App Link .", "commit_type": "add"}
{"commit_tokens": ["Updating", "README", "for", "library", "module"], "add_tokens": "private List < TableRowSpan . Cell > pendingTableRow ; private boolean tableRowIsHeader ; private int tableRows ;", "del_tokens": "private List < TableRowSpan . Cell > pendingTableRow ; private boolean tableRowIsHeader ; private int tableRows ;", "commit_type": "update"}
{"commit_tokens": ["Added", "abstract", "modifier", "to", "response", "class", "like", "in", "other", "message", "classes"], "add_tokens": "abstract class Response {", "del_tokens": "class Response {", "commit_type": "add"}
{"commit_tokens": ["added", "dynamic", "huffman", "and", "PairHMM", "edits", "and", "class", "changes"], "add_tokens": "@ Test ( enabled = true )", "del_tokens": "@ Test ( enabled = false )", "commit_type": "add"}
{"commit_tokens": ["Fix", "token", "aware", "not", "picking", "up", "changes", "in", "the", "token", "assignment"], "add_tokens": "public synchronized Host setTokenRanges ( List < TokenRange > ranges ) { public synchronized List < TokenRange > getTokenRanges ( ) {", "del_tokens": "public Host setTokenRanges ( List < TokenRange > ranges ) { public List < TokenRange > getTokenRanges ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "description", "of", "Source", "en", "Destination", "RoleIDCode", "to", "value", "according", "to", "ITI", "spec"], "add_tokens": "super ( \"110152\" , \"Destination\" ) ; super ( \"110153\" , \"Source\" ) ;", "del_tokens": "super ( \"110152\" , \"Destination Role ID\" ) ; super ( \"110153\" , \"Source Role ID\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Update", "to", "log", "queue", "size", "periodically", "in", "TaskWorkerManager", "."], "add_tokens": "private TaskQueue deadLetterQueue = null ; TaskQueue deadLetterQueue , if ( deadLetterQueue == null ) { throw new IllegalArgumentException ( \"deadLetterQueue must be non-null\" ) ; } this . deadLetterQueue = deadLetterQueue ; \"Status: max_workers={} running_workers={}\" + \" completed_workers={} dup_lp_qsize={}\" + \" dup_hp_qsize={} dup_dl_qsize={}\" , executor . getActiveCount ( ) , executor . getCompletedTaskCount ( ) , lowPriorityQueue . size ( ) , highPriorityQueue . size ( ) , deadLetterQueue . size ( ) } ) ;", "del_tokens": "\"Status: max worker pool size: {}, currently running workers: {}, completed workers {}\" , executor . getActiveCount ( ) , executor . getCompletedTaskCount ( ) } ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "wrap", "cell", "card", "and", "update", "vlayout", "version", "."], "add_tokens": "String cardType = parseCardType ( data ) ; cardType = TangramBuilder . TYPE_CONTAINER_1C_FLOW ; JSONObject wrapCardJson = new JSONObject ( ) ; wrapCardJson . put ( \"type\" , TangramBuilder . TYPE_CONTAINER_1C_FLOW ) ; JSONArray itemArray = new JSONArray ( ) ; itemArray . add ( data ) ; wrapCardJson . put ( \"items\" , itemArray ) ; data = wrapCardJson ;", "del_tokens": "final String cardType = parseCardType ( data ) ; card . setStringType ( TangramBuilder . TYPE_CONTAINER_1C_FLOW ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "closed", "sessions", "after", "test", "during", "send", "message", "to", "topic"], "add_tokens": "import java . util . ArrayList ; logger . debug ( \"Sending message to topic {}...\" , msg . toJson ( ) ) ; Collection < Session > closed = new ArrayList < > ( ) ; if ( ! sessions . isEmpty ( ) ) { } else { closed . add ( session ) ; logger . debug ( \"Session closed to remove '{}'\" , closed . size ( ) ) ; sessions . removeAll ( closed ) ;", "del_tokens": "logger . debug ( \"Sending message/response to topic {}\" , msg . toJson ( ) ) ; if ( sessions != null && ! sessions . isEmpty ( ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "was", "causing", "subclasses", "of", "Set", "and", "List", "to", "only", "have", "one", "option", "set", "."], "add_tokens": "List < String > result = Lists . newLinkedList ( ) ;", "del_tokens": "List < String > result = Lists . newArrayList ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "bug", "where", "inner", "enum", "types", "inside", "other", "enum", "types", "were", "not", "named", "correctly", ".", "They", "should", "have", "the", "Enum", "suffix", "just", "like", "the", "outer", "enum", "e", ".", "g", ".", "FooEnum_InnerEnum", ".", "Previously", "they", "did", "not", ";", "this", "was", "to", "support", "anonymous", "inner", "value", "classes", "in", "enum", "types", "e", ".", "g", ".", "FooEnum_$1", ".", "The", "solution", "is", "to", "only", "strip", "the", "Enum", "suffix", "from", "the", "inner", "type", "if", "it", "is", "anonymous", "."], "add_tokens": "return ( outerBinding . isEnum ( ) && binding . isAnonymous ( ) ) ? baseName : baseName + suffix ;", "del_tokens": "return outerBinding . isEnum ( ) ? baseName : baseName + suffix ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "German", "translation", "for", "command", "line", "options", "."], "add_tokens": "// Load translations of command line descriptions cmdlineParser . setResourceBundle ( Main . class . getPackage ( ) . getName ( ) + \".Messages\" , Main . class . getClassLoader ( ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "mutli", "-", "line", "issue", "server", "-", "side", "changes", "required", "also"], "add_tokens": "package org . apache . log4j ; // Replace newlines with line separator character to format multi-line events nicely in Logentries UI String [ ] stack = event . getThrowableStrRep ( ) ; int len = stack . length ; formattedEvent += \", \" ; for ( int i = 0 ; i < len ; i ++ ) { formattedEvent += stack [ i ] ; if ( i < len - 1 ) formattedEvent += \"\\u2028\" ; }", "del_tokens": "package com . logentries . log4j ; // Replace newlines with line separator to format multi-line events nicely final String [ ] stack = event . getThrowableStrRep ( ) ; formattedEvent += stack . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "visibility", "modifiers", "reordered", "methods", "to", "follow", "checkstyle", "standards", "added", "builder", "pattern", "to", "Card", "model"], "add_tokens": "public TokenCreator tokenCreator = new TokenCreator ( ) { public TokenRequester tokenRequester = new TokenRequester ( ) {", "del_tokens": "TokenCreator tokenCreator = new TokenCreator ( ) { TokenRequester tokenRequester = new TokenRequester ( ) {", "commit_type": "add"}
{"commit_tokens": ["Removing", "@Ignore", "from", "valid", "test"], "add_tokens": "/ * * * According to the spec malformed symbol entries must be interpreted as null , this test * verifies this behavior * /", "del_tokens": "// TODO amzn/ion-java#44 current binary writer doesn't support this (ignores this) // we need to determine if we want the **writer** to support emitting // malformed symbol data and support it appropriately. @ Ignore", "commit_type": "remove"}
{"commit_tokens": ["Allow", "Android", "SDK", "to", "pass", "external_id", "and", "phone_number"], "add_tokens": "if ( this . endUser . hasProperties ( ) || this . endUser . hasExternalId ( ) || this . endUser . hasPhoneNumber ( ) ) { Log . e ( Constants . TAG , \"API error: \" + error ) ;", "del_tokens": "if ( this . endUser . hasProperties ( ) ) { Log . d ( Constants . TAG , error . getLocalizedMessage ( ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "a", "bug", "where", "quotes", "were", "not", "escaped", "in", "string", "default", "values"], "add_tokens": "return \"\\\"\" + super . asString ( value ) . replace ( \"\\\"\" , \"\\\\\\\"\" ) + \"\\\"\" ;", "del_tokens": "return \"\\\"\" + super . asString ( value ) + \"\\\"\" ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "the", "Baserequest", "::", "send", "methods", "to", "be", "protected"], "add_tokens": "protected void send ( ResponseListener listener ) { protected void send ( final String requestBody , final ResponseListener listener ) { protected void send ( Map < String , String > formParameters , ResponseListener listener ) { protected void send ( JSONObject json , ResponseListener listener ) { protected void send ( byte [ ] data , ResponseListener listener ) {", "del_tokens": "public void send ( ResponseListener listener ) { public void send ( final String requestBody , final ResponseListener listener ) { public void send ( Map < String , String > formParameters , ResponseListener listener ) { public void send ( JSONObject json , ResponseListener listener ) { public void send ( byte [ ] data , ResponseListener listener ) {", "commit_type": "change"}
{"commit_tokens": ["updating", "junit", "test", "processes", "to", ".", "bpmn2"], "add_tokens": "kbuilder . add ( ResourceFactory . newClassPathResource ( \"BPMN2-MinimalProcess.bpmn2\" ) , ResourceType . BPMN2 ) ;", "del_tokens": "kbuilder . add ( ResourceFactory . newClassPathResource ( \"BPMN2-MinimalProcess.xml\" ) , ResourceType . BPMN2 ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "more", "debug", "during", "an", "host", "unreachable", "error"], "add_tokens": "errors . put ( host , String . format ( \"%s=%s\" , e . getClass ( ) . getName ( ) , e . getMessage ( ) ) ) ;", "del_tokens": "errors . put ( host , e . getClass ( ) . getName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "@Unmatched", "and", "@Positional", "on", "the", "same", "field"], "add_tokens": "import java . lang . reflect . Field ; for ( Entry < Field , Parser < ? > > entry : parsers . entrySet ( ) ) { entry . getKey ( ) . set ( instance , value ) ; + entry . getKey ( ) + \"' to \" + value , e ) ; Parser < ? > parser = parsers . get ( argDesc . field ) ; parsers . put ( argDesc . field , parser ) ; protected final Map < Field , Parser < ? > > parsers = new HashMap < Field , Parser < ? > > ( ) ;", "del_tokens": "for ( Entry < Argument , Parser < ? > > entry : parsers . entrySet ( ) ) { entry . getKey ( ) . field . set ( instance , value ) ; + entry . getKey ( ) . field + \"' to \" + value , e ) ; Parser < ? > parser = parsers . get ( argDesc ) ; parsers . put ( argDesc , parser ) ; protected final Map < Argument , Parser < ? > > parsers = new HashMap < Argument , Parser < ? > > ( ) ; ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "to", "new", "collection", "API"], "add_tokens": "import com . helger . commons . collection . iterate . IterableIterator ; for ( final UserFunction aUserFunc : new IterableIterator < > ( ( ( ExecutableFunctionLibrary ) aNestedFuncLib ) . iterateFunctions ( ) ) ) for ( final XQueryFunction aXQueryFunction : new IterableIterator < > ( aRealFuncLib . getFunctionDefinitions ( ) ) )", "del_tokens": "import com . helger . commons . collection . CollectionHelper ; for ( final UserFunction aUserFunc : CollectionHelper . newList ( ( ( ExecutableFunctionLibrary ) aNestedFuncLib ) . iterateFunctions ( ) ) ) for ( final XQueryFunction aXQueryFunction : CollectionHelper . newList ( aRealFuncLib . getFunctionDefinitions ( ) ) )", "commit_type": "update"}
{"commit_tokens": ["Change", "setUserAgent", "to", "addUserAgent", "to", "support", "app", "name", "version", "and", "comments"], "add_tokens": "private String userAgent = \"objectstorage-java/0.0.1\" + \" (\" + System . getProperty ( \"os.arch\" ) + System . getProperty ( \"os.name\" ) + \") \" ; * Add additional user agent string of the app - http : //www.w3.org/Protocols/rfc2616/rfc2616-sec14.html * @ param name name of your application * @ param version version of your application * @ param comments optional list of comments public void addUserAgent ( String name , String version , String ... comments ) { if ( name != null && version != null ) { String newUserAgent = name + \"/\" + version + \" (\" ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = 0 ; i < comments . length ; i ++ ) { sb . append ( comments [ i ] ) . append ( \", \" ) ; } this . userAgent = this . userAgent + newUserAgent + sb . toString ( ) + \") \" ; }", "del_tokens": "private String userAgent = \"objectstorage-java/0.0.1\" ; if ( userAgent != null ) { request . getHeaders ( ) . setUserAgent ( userAgent ) ; } * Set user agent of the client * @ param userAgent Sets the user agent of the request . public void setUserAgent ( String userAgent ) { this . userAgent = \"objectstorage-java/0.0.1 (\" + userAgent + \")\" ;", "commit_type": "change"}
{"commit_tokens": ["added", "generation", "of", "token", "constants"], "add_tokens": "EObject grammar = ( EObject ) parse ( bootGrammar , new XtextGrammarTestASTFactory ( ) , null ) ;", "del_tokens": "EObject grammar = ( EObject ) parse ( bootGrammar , new XtextGrammarTestASTFactory ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "samples", "from", "SemVer", ".", "org", "as", "reference", "tests"], "add_tokens": "return - 1 ; return 1 ;", "del_tokens": "return 1 ; return - 1 ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "enumeration", "generation", "for", "enums", "starting", "with", "a", "number", "."], "add_tokens": "boolean first = true ; case '0' : case '1' : case '2' : case '3' : case '4' : case '5' : case '6' : case '7' : case '8' : case '9' : { if ( first ) { sb . append ( \"_\" ) ; } sb . append ( c ) ; break ; } first = false ; final EnumConstantSource constantSource = enumType . addEnumConstant ( fixSingleDigitsInEnumName ( sb . toString ( ) ) ) ; static String fixSingleDigitsInEnumName ( String input ) { return input . replaceAll ( \"^_1_\" , \"ONE_\" ) . replaceAll ( \"^_2_\" , \"TWO_\" ) . replaceAll ( \"^_3_\" , \"THREE_\" ) . replaceAll ( \"^_4_\" , \"FOUR_\" ) . replaceAll ( \"^_5_\" , \"FIVE_\" ) . replaceAll ( \"^_6_\" , \"SIX_\" ) . replaceAll ( \"^_7_\" , \"SEVEN_\" ) . replaceAll ( \"^_8_\" , \"EIGHT_\" ) . replaceAll ( \"^_9_\" , \"NINE_\" ) . replaceAll ( \"^_10_\" , \"TEN_\" ) ; }", "del_tokens": "import org . jboss . forge . roaster . model . JavaType ; import static org . jboss . as . controller . descriptions . ModelDescriptionConstants . ALLOWED ; final EnumConstantSource constantSource = enumType . addEnumConstant ( sb . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "Javadoc", "class", "description", ".", "There", "was", "a", "copy", "paste", "error", "."], "add_tokens": "* Telestax , Open Source Cloud Communications * Copyright 2013 , Telestax , Inc . and individual contributors * Implements Out of Band events input for compound components", "del_tokens": "* JBoss , Home of Professional Open Source * Copyright 2011 , Red Hat , Inc . and individual contributors * Implements input for compound components", "commit_type": "fix"}
{"commit_tokens": ["allow", "blacklist", "to", "blacklist", "core", "classes"], "add_tokens": "Class c = extractClass ( ) ; c ) , extractClass ( ) , new MicroserverConfigurer ( ) . vetClasses ( c , modules [ 0 ] . getSpringConfigurationClasses ( ) ) ) new MicroserverConfigurer ( ) . vetClasses ( c , modules [ 0 ] . getSpringConfigurationClasses ( ) ) )", "del_tokens": "extractClass ( ) ) , extractClass ( ) , modules [ 0 ] . getSpringConfigurationClasses ( ) ) modules [ 0 ] . getSpringConfigurationClasses ( ) )", "commit_type": "allow"}
{"commit_tokens": ["Improve", "tmpl", "to", "support", "javadoc", "format", "comment"], "add_tokens": "public static String SDK_VERSION = \"2.3.2\" ;", "del_tokens": "public static String SDK_VERSION = \"2.3.1\" ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "support", "to", "parse", "sql", "where", "conditions", "(", "expression", "("], "add_tokens": "registerjdbcSQLType ( InputStream . class , new TypeRef < InputStream > ( java . sql . Types . LONGVARBINARY ,", "del_tokens": "registerjdbcSQLType ( InputStream . class , new TypeRef < InputStream > ( java . sql . Types . BLOB ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "web", "resources", "variable", "as", "it", "is", "now", "the", "same", "as", "base", "path"], "add_tokens": "assertThat ( response ) . contains ( \"\\\"components-path\\\":\\\"\" + prefix + \"/bower_components\\\"\" ) ; assertThat ( response ) . contains ( \"\\\"components-path-slash\\\":\\\"\" + prefix + \"/bower_components/\\\"\" ) ;", "del_tokens": "assertThat ( response ) . contains ( \"\\\"seed-webresources-path\\\":\\\"\" + prefix + \"/resources\\\"\" ) ; assertThat ( response ) . contains ( \"\\\"seed-webresources-path-slash\\\":\\\"\" + prefix + \"/resources/\\\"\" ) ; assertThat ( response ) . contains ( \"\\\"components-path\\\":\\\"\" + prefix + \"/resources/bower_components\\\"\" ) ; assertThat ( response ) . contains ( \"\\\"components-path-slash\\\":\\\"\" + prefix + \"/resources/bower_components/\\\"\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Moved", "back", "to", "Resource", "{", "Enricher", "-", ">", "Processor", "}", "to", "allow", "exchanging", "the", "Resource", "."], "add_tokens": "* SPI interface to allow components to process the { @ link ResourceSupport } instances returned from Spring MVC public interface ResourceProcessor < T extends ResourceSupport > { * Processes the given resource , add links , alter the domain data etc . * @ return the processed resource T enrich ( T resource ) ;", "del_tokens": "* SPI interface to allow components to enrich the { @ link ResourceSupport } instances returned from Spring MVC public interface ResourceEnricher < T extends ResourceSupport > { * Enriches the given resource , add links , alter the domain data etc . void enrich ( T resource ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "underlying", "code", "for", "Weighted", "training"], "add_tokens": "private double weight ; { this ( numericalValues , categoricalValues , categoricalData , 1 ) ; } public DataPoint ( Vec numericalValues , int [ ] categoricalValues , CategoricalData [ ] categoricalData , double weight ) this . weight = weight ; } public double getWeight ( ) { return weight ; } public void setWeight ( double weight ) { this . weight = weight ; // public DataPoint copy() // { // // }", "del_tokens": "import jsat . linear . DenseVector ;", "commit_type": "add"}
{"commit_tokens": ["Make", "our", "confirmation", "popup", "more", "customizable", "."], "add_tokens": "setEnabled ( false ) ; displayConfirmPopup ( ) ; } protected void displayConfirmPopup ( ) { onAborted ( ) ; onConfirmed ( ) ; protected void onConfirmed ( ) { takeAction ( true ) ; } protected void onAborted ( ) { setEnabled ( true ) ; }", "del_tokens": "takeAction ( true ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "releaseVersion", "parameter", "to", "the", "release", "goal"], "add_tokens": "* Release version to use instead of the default next release version in non * interactive mode . *", "del_tokens": "* Release version . * < br / > * * Note : Work only in non interactive mode . *", "commit_type": "add"}
{"commit_tokens": ["Added", "copyright", "in", "header", "."], "add_tokens": "/ * * Copyright ( c ) 2018 https : //www.thecoderscorner.com (Nutricherry LTD). * This product is licensed under an Apache license , see the LICENSE file in the top - level directory . * / vbox . getChildren ( ) . add ( new Label ( \"tcMenu designer (C) 2018 by thecoderscorner.com.\" ) ) ;", "del_tokens": "vbox . getChildren ( ) . add ( new Label ( \"Version: \" + BuildVersionUtil . getVersion ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "buildFromMap", "with", "template", "values", "to", "UriBuilder"], "add_tokens": "import java . util . stream . Collectors ; return pathStringToSegments ( getPath ( decode ) , false ) . collect ( Collectors . toList ( ) ) ; static Stream < MuPathSegment > pathStringToSegments ( String path , boolean encodeSlashes ) { } ) ;", "del_tokens": "return pathStringToSegments ( getPath ( decode ) , false ) ; static List < PathSegment > pathStringToSegments ( String path , boolean encodeSlashes ) { } ) . collect ( toList ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "smurf", "-", "naming", "prefix", "from", "JpaCriteriaMapper"], "add_tokens": "public class CriteriaMapper { public CriteriaMapper ( Root < ? > root , CriteriaBuilder criteriaBuilder ) {", "del_tokens": "public class JpaCriteriaMapper { public JpaCriteriaMapper ( Root < ? > root , CriteriaBuilder criteriaBuilder ) {", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "eureka", ".", "webapp", ".", "demomode", "application", "property", ".", "The", "eureka", "-", "webapp", "and", "cas", "-", "server", "modules", "pick", "up", "this", "property", "and", "hide", "all", "text", "that", "is", "specific", "to", "the", "demonstration", "website", "unless", "the", "property", "is", "set", "to", "true", "in", "/", "etc", "/", "eureka", "/", "application", ".", "properties", ".", "We", "may", "need", "something", "finer", "grained", "than", "this", "(", "e", ".", "g", ".", "some", "institutional", "deployments", "may", "want", "the", "warnings", "about", "uploading", "PHI", "turned", "on", ")", "but", "it", "is", "a", "starting", "point", "."], "add_tokens": "public boolean isDemoMode ( ) { return Boolean . parseBoolean ( getValue ( \"eureka.webapp.demomode\" ) ) ; }", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["added", "changes", "in", "to", "pom"], "add_tokens": "/ * * Copyright 2014 Janith Bandara , This source is a part of Audit4j - * An open - source audit platform for Enterprise java platform . * http : //mechanizedspace.com/audit4j * http : //audit4j.org * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / manager . audit ( clazz , method , pjp . getArgs ( ) ) ;", "del_tokens": "import org . apache . commons . logging . Log ; import org . apache . commons . logging . LogFactory ; /** The log. */ private final Log log = LogFactory . getLog ( AuditAspect . class ) ; manager . auditWithAnnotation ( clazz , method , pjp . getArgs ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "Client", "to", "gracefully", "handle", "missing", "failure", "reasons"], "add_tokens": "String reason = result . has ( Constants . RESULT_REASON ) ? result . getString ( Constants . RESULT_REASON ) : \"No reason provided\" ; throw new Exception ( \"Client::map:: \" + \"failed because: \" + reason ) ;", "del_tokens": "throw new Exception ( \"Client::map:: \" + \"failed because: \" + result . getString ( Constants . RESULT_REASON ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Updated", "to", "add", "support", "for", "additional", "fields", "."], "add_tokens": "return ( getDoubleValue ( ( Number ) get ( key ) ) ) ; } / * * * Given a number , this method returns a double value . If the * number parameter is null , then zero is returned . * * @ param value Number value * @ return double value * / protected double getDoubleValue ( Number value ) { return ( result ) ;", "del_tokens": "Number value = ( Number ) get ( key ) ; return ( result ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "histogram", "support", "for", "calculating", "mean", "."], "add_tokens": "import java . math . BigDecimal ; import static org . junit . Assert . assertTrue ; final BigDecimal disruptorMeanLatency = histogram . getMeanObservation ( ) ; System . out . format ( \"%s run %d Disruptor mean latency = %s\\n\" , getClass ( ) . getSimpleName ( ) , Long . valueOf ( i ) , disruptorMeanLatency ) ; final BigDecimal queueMeanLatency = histogram . getMeanObservation ( ) ; System . out . format ( \"%s run %d Queues mean latency = %s\\n\" , getClass ( ) . getSimpleName ( ) , Long . valueOf ( i ) , queueMeanLatency ) ; assertTrue ( queueMeanLatency . compareTo ( disruptorMeanLatency ) > 0 ) ;", "del_tokens": "System . out . format ( \"%s run %d Disruptor\\n\" , getClass ( ) . getSimpleName ( ) , Long . valueOf ( i ) ) ; System . out . format ( \"%s run %d Queues\\n\" , getClass ( ) . getSimpleName ( ) , Long . valueOf ( i ) ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "interface", "implementation", "to", "right", "level"], "add_tokens": "public abstract class BaseFluentWebDriver implements FluentWebDriver {", "del_tokens": "public abstract class BaseFluentWebDriver {", "commit_type": "move"}
{"commit_tokens": ["Change", "to", "stopwatch", "api", "."], "add_tokens": "Stopwatch overallStopwatch = Stopwatch . createStarted ( ) ;", "del_tokens": "Stopwatch overallStopwatch = new Stopwatch ( ) . start ( ) ;", "commit_type": "change"}
{"commit_tokens": ["using", "an", "ElementFinder", "extension", "to", "let", "IDEA", "know", "of", "generated", "interfaces"], "add_tokens": "import com . google . common . collect . Lists ; * DAMappingAugmentProvider - IDEA extension responsible for providing feedback to the developer on whether her usage * of the @ Mapper annotation is valid or not . return createMapper ( psiClass , project , element ) ; // JavaPsiFacade.getElementFactory(project) // .createClassFromText(mapperSrc, element /*TODO verify what is this second argument*/); // //// PsiClass res = new LightClass(JavaPsiFacade.getElementFactory(project).createClass(psiClass.getName() + //// \"Mapper\")); // // return Collections.emptyList(); private < Psi extends PsiElement > List < Psi > createMapper ( PsiClass psiClass , final Project project , final PsiElement element ) { final List < Psi > res = Lists . newArrayList ( ) ; PsiClass classFromText = JavaPsiFacade . getElementFactory ( project ) . createClassFromText ( buffer . toString ( ) , element /*TODO verify what is this second argument*/ ) ; // res.add(classFromText); // generatedFile(sourceGenerator.fileName(context), buffer.toString(), context); return res ;", "del_tokens": "* DAMappingAugmentProvider - String mapperSrc = createMapper ( psiClass ) ; JavaPsiFacade . getElementFactory ( project ) . createClassFromText ( mapperSrc , element /*TODO verify what is this second argument*/ ) ; // PsiClass res = new LightClass(JavaPsiFacade.getElementFactory(project).createClass(psiClass.getName() + // \"Mapper\")); return Collections . emptyList ( ) ; private String createMapper ( PsiClass psiClass ) { generatedFile ( sourceGenerator . fileName ( context ) , buffer . toString ( ) , context ) ; return \"\" ;", "commit_type": "use"}
{"commit_tokens": ["Making", "getConnection", "public", "so", "triggers", "can", "use", "the", "connection", "if", "need", "be", "."], "add_tokens": "public Cassandra . Iface getConnection ( String keyspace ) throws Exception {", "del_tokens": "Cassandra . Iface getConnection ( String keyspace ) throws Exception {", "commit_type": "make"}
{"commit_tokens": ["Updated", "what", "is", "expected", "during", "unit", "tests", ";", "they", "now", "succeed", "again", "."], "add_tokens": "@ Override @ Override public boolean isLocaleSupported ( String locale ) { @ Override public void setLocale ( String newLocale ) {", "del_tokens": "@ Override @ Override protected boolean isLocaleSupported ( String locale ) { @ Override protected void setLocale ( String newLocale ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "javadoc", "for", "black", ".", "door", ".", "crypto", ".", "SHECipher"], "add_tokens": "* @ param iv An initialization vector to use for the cipher .", "del_tokens": "* @ param IV An initialization vector to use for the cipher .", "commit_type": "fix"}
{"commit_tokens": ["Fix", "generic", "servlet", "initialization", "by", "calling", "super", ".", "init", "."], "add_tokens": "* @ throws ServletException if servlet configuration fails . * @ throws UnavailableException if container reference is not on servlet context attributes . public void init ( ServletConfig config ) throws ServletException { super . init ( config ) ;", "del_tokens": "* @ throws UnavailableException if tiny container is not properly initialized . public void init ( ServletConfig config ) throws UnavailableException {", "commit_type": "fix"}
{"commit_tokens": ["Added", "alias", "creation", "to", "NodeExample", ".", "java"], "add_tokens": "// Create an alias String txId = node . alias ( alice , \"alice\" , 'T' , FEE ) ; txId = node . reissueAsset ( alice , assetId , 100 * TOKEN , true , ISSUE_FEE ) ;", "del_tokens": "String txId = node . reissueAsset ( alice , assetId , 100 * TOKEN , true , ISSUE_FEE ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "all", "canary", "stuff", "."], "add_tokens": "import net . larry1123 . util . api . plugin . commands . CommandData ;", "del_tokens": "import net . larry1123 . util . plugin . commands . CommandData ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "some", "missing", "stdout", "messages", "."], "add_tokens": "if ( entity . trim ( ) . length ( ) != 0 ) log . info ( entity ) ;", "del_tokens": "if ( entity . trim ( ) . length ( ) != 0 ) System . out . println ( entity ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "two", "convienience", "method", "to", "check", "first", "/", "last", "subfield", "value", "add", "MARC", "round", "trip", "test"], "add_tokens": "repeatCounter = 99 ; logger . log ( Level . WARNING , \"counter > 99, overflow in %s\" , marcField ) ;", "del_tokens": "logger . log ( Level . WARNING , \"counter > 99, overflow in \" + marcField ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "url", "protocol", "mvn", "-", "NPE"], "add_tokens": "@ ContextName ( \"simple\" )", "del_tokens": "import org . apache . camel . cdi . CdiCamelContext ; //@ContextName(\"simple\")", "commit_type": "fix"}
{"commit_tokens": ["Fix", "infinite", "recursion", "when", "scanning", "Kotlin", "annotations"], "add_tokens": "private static final String KOTLIN_ANNOTATION = \"kotlin.annotation\" ; Class < ? extends Annotation > annotationType = annotation . annotationType ( ) ; String annotationPackageName = annotationType . getPackage ( ) . getName ( ) ; if ( ! annotationPackageName . startsWith ( JAVA_LANG ) && ! annotationPackageName . startsWith ( KOTLIN_ANNOTATION ) && ! annotationType . equals ( annotatedElement ) ) { findAnnotations ( annotationType , list ) ;", "del_tokens": "if ( ! annotation . annotationType ( ) . getPackage ( ) . getName ( ) . startsWith ( JAVA_LANG ) ) { findAnnotations ( annotation . annotationType ( ) , list ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "strong", "instead", "of", "weak", "reference", "for", "MvpView"], "add_tokens": "private V view ; this . view = view ; if ( view == null ) { return view ; if ( view != null ) { //noinspection unchecked Class < V > viewClass = ( Class < V > ) view . getClass ( ) . getGenericInterfaces ( ) [ 0 ] ; view = NoOp . of ( viewClass ) ;", "del_tokens": "import java . lang . ref . WeakReference ; private WeakReference < V > viewRef ; viewRef = new WeakReference < V > ( view ) ; if ( viewRef == null ) { return viewRef . get ( ) ; if ( viewRef != null ) { //noinspection unchecked,ConstantConditions Class < V > viewClass = ( Class < V > ) viewRef . get ( ) . getClass ( ) . getGenericInterfaces ( ) [ 0 ] ; V noOp = NoOp . of ( viewClass ) ; viewRef = new WeakReference < V > ( noOp ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "comparing", "loosely", "built", "requirements"], "add_tokens": "return this . isSatisfiedBy ( new Semver ( version , this . version . getType ( ) ) ) ;", "del_tokens": "return this . isSatisfiedBy ( new Semver ( version ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "nullpointerexception", "in", "streamStatusDao", ".", "getEnabledActions"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import java . util . HashSet ; import java . util . Map ; import java . util . Set ; import java . util . concurrent . ConcurrentHashMap ; Set < StreamAction > enabledActions = new HashSet < > ( ) ; if ( streamStatus != null ) { enabledActions = streamStatus . getActionsEnabled ( ) ; } return enabledActions ;", "del_tokens": "import java . util . Map ; import java . util . Set ; import java . util . concurrent . ConcurrentHashMap ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; return streamStatus . getActionsEnabled ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "include", "new", "delivery", "endpoint"], "add_tokens": "import me . xhsun . guildwars2wrapper . model . commerce . Delivery ; @ GET ( \"/v2/commerce/delivery\" ) //TODO class Call < List < Delivery >> getTPDeliveryInfo ( @ Query ( \"access_token\" ) String token ) ; Call < List < Integer >> getAllTPListingIDs ( ) ; Call < List < Prices >> getTPListingInfo ( @ Query ( \"ids\" ) String ids ) ; Call < List < Transaction >> getTPTransaction ( @ Path ( \"time\" ) String time , @ Path ( \"type\" ) String type , @ Query ( \"access_token\" ) String token ) ; Call < List < Integer >> getAllTPPriceIDs ( ) ; Call < List < Prices >> getTPPriceInfo ( @ Query ( \"ids\" ) String ids ) ;", "del_tokens": "Call < List < Integer >> getAllListingIDs ( ) ; Call < List < Prices >> getListingInfo ( @ Query ( \"ids\" ) String ids ) ; Call < List < Transaction >> getListing ( @ Path ( \"time\" ) String time , @ Path ( \"type\" ) String type , @ Query ( \"access_token\" ) String token ) ; Call < List < Integer >> getAllPriceIDs ( ) ; Call < List < Prices >> getPriceInfo ( @ Query ( \"ids\" ) String ids ) ;", "commit_type": "update"}
{"commit_tokens": ["Moved", "duplicate", "constructor", "code", "to", "init", "method"], "add_tokens": "this . init ( mapper , schemaNode ) ; this . init ( mapper , schemaNode ) ; private void init ( ObjectMapper mapper , JsonNode schemaNode ) { this . mapper = mapper ; this . validators = new LinkedHashMap < String , JsonValidator > ( ) ; this . read ( schemaNode ) ; }", "del_tokens": "this . mapper = mapper ; validators = new LinkedHashMap < String , JsonValidator > ( ) ; read ( schemaNode ) ; this . mapper = mapper ; validators = new LinkedHashMap < String , JsonValidator > ( ) ; read ( schemaNode ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "glossary", "resources"], "add_tokens": "SEERRX , SEER_TRAINING , LYMPH_NODES @ JsonProperty ( \"resource\" ) protected List < GlossaryResource > _resources ; public List < GlossaryResource > getResources ( ) { return _resources ; } public void setResources ( List < GlossaryResource > resources ) { _resources = resources ; }", "del_tokens": "SEERRX", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "in", "the", "jdom", "traversal"], "add_tokens": "Element o = new Element ( objectDescriptor . getName ( ) ) ; root . addContent ( o ) ; Element o = new Element ( fieldDescriptor . getName ( ) ) ; root . addContent ( o ) ;", "del_tokens": "Element o = root . addContent ( new Element ( objectDescriptor . getName ( ) ) ) ; Element o = root . addContent ( new Element ( fieldDescriptor . getName ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "io", ".", "spark", ".", "ddf", ".", "content", ".", "PersistenceHandler"], "add_tokens": "protected String getFilePath ( String namespace , String name , String postfix ) throws DDFException {", "del_tokens": "private String getFilePath ( String namespace , String name , String postfix ) throws DDFException {", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "at", "one", "byte", "size", "frame"], "add_tokens": "private boolean one_byte_size_ready ( ) { int size = tmpbuf [ 0 ] ; if ( size < 0 ) size = ( 0xff ) & size ; if ( size > maxmsgsize ) { in_progress = new Msg ( size ) ;", "del_tokens": "private boolean one_byte_size_ready ( ) { if ( tmpbuf [ 0 ] > maxmsgsize ) { in_progress = new Msg ( tmpbuf [ 0 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Html", "root", "field", "definition", "in", "HtmlView", "to", "include", "generic", "parent", "as", "Html<Elemment", ">", ".", "This", "enables", "complete", "use", "of", "Fluent", "API", "."], "add_tokens": "import org . xmlet . htmlapi . Element ; private Html < Element > root = new Html < Element > ( ) ; public Head < Html < Element > > head ( ) { public Body < Html < Element > > body ( ) {", "del_tokens": "private Html root = new Html ( ) ; public Head < Html > head ( ) { public Body < Html > body ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "unit", "tests", "for", "sending", "messages", "action"], "add_tokens": "throw new CitrusRuntimeException ( \"Unknown variable '\" + variableExpression + \"'\" ) ;", "del_tokens": "throw new CitrusRuntimeException ( \"Unknown variable \" + variableExpression ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "test", "more", "explicit", "."], "add_tokens": "String str2 = new String ( new byte [ ] { - 61 , - 123 , - 61 , - 123 } ) ; String pat2 = new String ( new byte [ ] { '^' , - 61 , - 123 , '{' , '2' , '}' , '$' } ) ; x2s ( pat2 , str2 , 4 , 4 ) ; x2s ( pat2 , str2 , 4 , 4 , Option . IGNORECASE ) ;", "del_tokens": "x2s ( \"^{2}$\", \", 4 , 4 ) x2s ( \"^{2}$\", \", 4 , 4 , O p ion.IG N ORECASE);", "commit_type": "make"}
{"commit_tokens": ["fix", "bug", "about", "vector", "extension", "."], "add_tokens": "byte [ ] n = new byte [ ( int ) ( vector . length * 1.2 ) + 1 ] ;", "del_tokens": "byte [ ] n = new byte [ ( int ) ( vector . length * 1.2 ) ] ;", "commit_type": "fix"}
{"commit_tokens": ["add", "round", "robin", "dns", "resolver", "for", "udp", "as", "well"], "add_tokens": "private DatagramChannel channel ; private AddressResolver addressResolver ; addressResolver = new AddressResolver ( getGraylogHost ( ) ) ; final InetSocketAddress remote = new InetSocketAddress ( addressResolver . resolve ( ) , getGraylogPort ( ) ) ;", "del_tokens": "private DatagramChannel channel ; final InetSocketAddress remote = new InetSocketAddress ( getGraylogHost ( ) , getGraylogPort ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "packaging", "and", "i2b2", "handler", "."], "add_tokens": "private final boolean rejected ; String sourceSystem , boolean rejected ) { //if (startDate == null) { // throw new IllegalArgumentException(\"startDate cannot be null\"); //} this . rejected = rejected ; public boolean isRejected ( ) { return rejected ; }", "del_tokens": "String sourceSystem ) { if ( startDate == null ) { throw new IllegalArgumentException ( \"startDate cannot be null\" ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "introduced", "in", "the", "previous", "commit", "(", "being", "incompatible", "with", "immutable", "random", "variable", ")", "."], "add_tokens": "accrualAccount = accrualAccount . accrue ( liborOverSubPeriod , subPeriodLength ) ;", "del_tokens": "accrualAccount . accrue ( liborOverSubPeriod , subPeriodLength ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "warning", "about", "adding", "handlers", "before", "init"], "add_tokens": "if ( rtmpClient != null ) { rtmpClient . setConnectionClosedHandler ( connectionClosedHandler ) ; } else { log . warn ( \"Internal client is null, ensure that init() is called before adding handlers\" ) ; } if ( rtmpClient != null ) { rtmpClient . setExceptionHandler ( exceptionHandler ) ; } else { log . warn ( \"Internal client is null, ensure that init() is called before adding handlers\" ) ; }", "del_tokens": "rtmpClient . setConnectionClosedHandler ( connectionClosedHandler ) ; rtmpClient . setExceptionHandler ( exceptionHandler ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "removeTags", "(", "..", ")", "support", "to", "AMI", "and", "EC2Instance", "."], "add_tokens": "updateTags ( new String [ ] { imageId } , tags ) ; @ Override public void updateTags ( @ Nonnull String [ ] imageIds , @ Nonnull Tag ... tags ) throws CloudException , InternalException { provider . createTags ( imageIds , tags ) ; } @ Override public void removeTags ( @ Nonnull String imageId , @ Nonnull Tag ... tags ) throws CloudException , InternalException { removeTags ( new String [ ] { imageId } , tags ) ; } @ Override public void removeTags ( @ Nonnull String [ ] imageIds , @ Nonnull Tag ... tags ) throws CloudException , InternalException { provider . removeTags ( imageIds , tags ) ; } private void waitForBundle ( @ Nonnull String bundleId , @ Nonnull String manifest , @ Nonnull Platform platform , @ Nonnull String name , @ Nonnull String description , AsynchronousTask < MachineImage > task ) {", "del_tokens": "provider . createTags ( imageId , tags ) ; private void waitForBundle ( @ Nonnull String bundleId , @ Nonnull String manifest , @ Nonnull Platform platform , @ Nonnull String name , @ Nonnull String description , AsynchronousTask < MachineImage > task ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "and", "added", "doc", "/", "code"], "add_tokens": "if ( this . colNumber != ( this . ar . length ) ) {", "del_tokens": "if ( this . colNumber != ( this . ar . length - 1 ) ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "redis", "expire", "command", "instead", "of", "set", "nx", "ex"], "add_tokens": "public static JedisCommands proxyJedisCommands ( JedisPool pool ) { val result = redis . set ( redisKey , json ) ; redis . expire ( redisKey , ( int ) duration ) ; return result ;", "del_tokens": "import com . github . bingoohuang . westcache . manager . RedisCacheManager ; private static JedisCommands proxyJedisCommands ( JedisPool pool ) { return redis . set ( redisKey , json , \"NX\" , \"EX\" , duration ) ;", "commit_type": "use"}
{"commit_tokens": ["Adds", "protections", "against", "improper", "use", "."], "add_tokens": "TableMetaData read ( TableConfiguration cfg , DatabaseMetaData dmd ) throws TableNotFoundException , MissingIdentifierException { private void setIdentifier ( TableConfiguration cfg , DatabaseMetaData dmd , TableMetaData cInfo ) throws MissingIdentifierException { private void setGeometry ( TableConfiguration cfg , TableMetaData cInfo ) throws MissingIdentifierException { private void readColums ( TableConfiguration cfg , DatabaseMetaData dmd , TableMetaData tableMetaData ) throws TableNotFoundException { private boolean columnToSkip ( TableConfiguration cfg , String colName ) {", "del_tokens": "TableMetaData read ( TableConfig cfg , DatabaseMetaData dmd ) throws TableNotFoundException , MissingIdentifierException { private void setIdentifier ( TableConfig cfg , DatabaseMetaData dmd , TableMetaData cInfo ) throws MissingIdentifierException { private void setGeometry ( TableConfig cfg , TableMetaData cInfo ) throws MissingIdentifierException { private void readColums ( TableConfig cfg , DatabaseMetaData dmd , TableMetaData tableMetaData ) throws TableNotFoundException { private boolean columnToSkip ( TableConfig cfg , String colName ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "type", "rename", "for", "Cdir", "-", ">", "Cidr"], "add_tokens": "import io . ebean . types . Cidr ; * Cidr property . public class PCidr < R > extends PBaseValueEqual < R , Cidr > { public PCidr ( String name , R root ) { public PCidr ( String name , R root , String prefix ) {", "del_tokens": "import io . ebean . types . Cdir ; * Cdir property . public class PCdir < R > extends PBaseValueEqual < R , Cdir > { public PCdir ( String name , R root ) { public PCdir ( String name , R root , String prefix ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "example", "code", "for", "verification"], "add_tokens": "public static final int INPUT_STREAM_FAILED = 18 ; public static final int SIGNATURE_NOT_FOUND = 19 ; public static final int SIGNATURE_INVALID = 20 ; public static final int MESSAGE_INVALID = 21 ; public static final int INVALID_PUBLIC_KEY = 22 ; else if ( code == INPUT_STREAM_FAILED ) return \"The provided inputs could not be converted into input streams.\" ; else if ( code == SIGNATURE_NOT_FOUND ) return \"A signature matching the provided key could not be found.\" ; else if ( code == SIGNATURE_INVALID ) return \"The signature stream does not contain a valid signature.\" ; else if ( code == MESSAGE_INVALID ) return \"The message stream could not be parsed.\" ; else if ( code == INVALID_PUBLIC_KEY ) return \"The public key stream does not contain a valid public key.\" ; else return \"An unknown error has ocurred.\" ;", "del_tokens": "else return \"An unknown error has ocurred\" ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Merger", "in", "AtomicMap", "updates"], "add_tokens": "private < T > T apply ( final Function < MutableSet < E > , T > f ) {", "del_tokens": "public < T > T apply ( final Function < MutableSet < E > , T > f ) {", "commit_type": "use"}
{"commit_tokens": ["update", "consul", "to", "replace", "group", "with", "serviceName"], "add_tokens": "public String lookupCommand ( String serviceName ) { Response < GetValue > response = client . getKVValue ( ConsulConstants . CONSUL_LIGHT_COMMAND + serviceName ) ; if ( logger . isInfoEnabled ( ) ) logger . info ( \"no command in serviceName: \" + serviceName ) ;", "del_tokens": "public String lookupCommand ( String group ) { Response < GetValue > response = client . getKVValue ( ConsulConstants . CONSUL_LIGHT_COMMAND + ConsulUtils . convertGroupToServiceName ( group ) ) ; if ( logger . isInfoEnabled ( ) ) logger . info ( \"no command in group: \" + group ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "missing", "get", "methods", "and", "parameter", "passing", "+", "maven", "pom", "."], "add_tokens": "public class Messages { public Messages ( Message ... msgs ) { public Message getMessage ( int i ) { public Message [ ] getMessages ( ) { return messages ; }", "del_tokens": "class Messages { Messages ( Message ... msgs ) { Message getMessage ( int i ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "sl4j", "and", "logging", "traces"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static Logger LOGGER = LoggerFactory . getLogger ( Application . class ) ; LOGGER . info ( \"Configuring Rollbar\" ) ; LOGGER . info ( \"Initializing Rollbar\" ) ; LOGGER . info ( \"Starting application\" ) ; LOGGER . info ( \"Executing application\" ) ; LOGGER . info ( \"Finished application\" ) ;", "del_tokens": "throw new RuntimeException ( \"Exception finishing execution.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "up", "a", "stray", "test", "whose", "expected", "text", "changed", "when", "it", "was", "moved", "and", "make", "another", "test", "less", "brittle", "."], "add_tokens": "ClassName . create ( \"dagger.internal.codegen.writer\" , . isEqualTo ( \"dagger.internal.codegen.writer.Foo\" ) ; . isEqualTo ( \"dagger.internal.codegen.writer.ClassNameTest.Foo\" ) ; . isEqualTo ( \"dagger.internal.codegen.writer.ClassNameTest.OuterClass.Foo\" ) ;", "del_tokens": "ClassName . create ( \"dagger.internal.codegen\" , . isEqualTo ( \"dagger.internal.codegen.Foo\" ) ; . isEqualTo ( \"dagger.internal.codegen.ClassNameTest.Foo\" ) ; . isEqualTo ( \"dagger.internal.codegen.ClassNameTest.OuterClass.Foo\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "deadlock", "in", "the", "abstracttask"], "add_tokens": "import java . util . Deque ; private Deque < T > objects ; boolean wasInstanciated = false ; wasInstanciated = true ; if ( wasInstanciated ) { poolable . reset ( ) ; }", "del_tokens": "import java . util . Queue ; private Queue < T > objects ;", "commit_type": "fix"}
{"commit_tokens": ["Allowed", "set", "Device", "dimensions", "and", "keep", "longer", "presing", "the", "android", "screen"], "add_tokens": "private Vector3f dimensions = new Vector3f ( 0.048f , 0.08f , 0.002f ) ; smartphone = SmartPhoneFactory . createSmartphone ( smartphoneId , dimensions ) ; public CreateSmartphoneCommand setDimensions ( float width , float height , float depth ) { dimensions . set ( width , height , depth ) ; return this ; } public Vector3f getDimensions ( ) { return dimensions ; }", "del_tokens": "smartphone = SmartPhoneFactory . createSmartphone ( smartphoneId ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "squid", ":", "S1444", "-", "public", "static", "fields", "should", "be", "constant", "."], "add_tokens": "public static final long TERMINATION_TIMEOUT = Long", "del_tokens": "public static long TERMINATION_TIMEOUT = Long", "commit_type": "fix"}
{"commit_tokens": ["Add", "name", "suite", "to", "prevent", "test", "name", "colision"], "add_tokens": "private final String contextName ; public TestContext ( String contextName , Marshaller marshaller , Unmarshaller unmarshaller ) { this . contextName = contextName ; public String getContextName ( ) { return contextName ; }", "del_tokens": "public TestContext ( Marshaller marshaller , Unmarshaller unmarshaller ) {", "commit_type": "add"}
{"commit_tokens": ["added", "feature", "to", "calculate", "transaction", "hash", "of", "transactions", "containing"], "add_tokens": "BitcoinScriptWitnessItem currentItem = transaction . getBitcoinScriptWitness ( ) . get ( k ) ; transactionBAOS . write ( currentItem . getStackItemCounter ( ) ) ; for ( int l = 0 ; l < currentItem . getScriptWitnessList ( ) . size ( ) ; l ++ ) { transactionBAOS . write ( currentItem . getScriptWitnessList ( ) . get ( k ) . getWitnessScriptLength ( ) ) ; transactionBAOS . write ( currentItem . getScriptWitnessList ( ) . get ( k ) . getWitnessScript ( ) ) ; }", "del_tokens": "transactionBAOS . write ( transaction . getBitcoinScriptWitness ( ) . get ( k ) . getWitnessScriptLength ( ) ) ; transactionBAOS . write ( transaction . getBitcoinScriptWitness ( ) . get ( k ) . getWitnessScript ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "requests", "fields", "access", "modifiers", "to", "allow"], "add_tokens": "protected Collection < DependencyInfo > dependencies ;", "del_tokens": "private Collection < DependencyInfo > dependencies ;", "commit_type": "change"}
{"commit_tokens": ["change", "name", "of", "constructor", "parameter", "that", "springs", "auto", "createion", "works"], "add_tokens": "public JobInfo ( final JobType jobType , this . jobType = jobType ;", "del_tokens": "public JobInfo ( final JobType type , this . jobType = type ;", "commit_type": "change"}
{"commit_tokens": ["Allow", "changing", "of", "lambda", "SAM", "types", "(", "alter", "method", "descriptor", ")"], "add_tokens": "if ( GlobalConfiguration . isJava18orHigher ) { // if the target is a generated lambda callsite object then calling __execute isn't going to work as those // types don't have the method in them! mv . visitMethodInsn ( INVOKESTATIC , tRegistryType , \"iiIntercept\" , \"(Ljava/lang/Object;[Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/String;)Ljava/lang/Object;\" ) ; } else { // calling __execute(params array, this, name+desc) mv . visitMethodInsn ( INVOKEINTERFACE , owner , mDynamicDispatchName , mDynamicDispatchDescriptor ) ; }", "del_tokens": "// calling __execute(params array, this, name+desc) mv . visitMethodInsn ( INVOKEINTERFACE , owner , mDynamicDispatchName , mDynamicDispatchDescriptor ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "integration", "tests", "for", "deployAll"], "add_tokens": "import com . google . cloud . tools . appengine . api . AppEngineException ; import com . google . common . annotations . VisibleForTesting ; public class DeployAllMojo extends AbstractDeployMojo { if ( ! \"war\" . equals ( getPackaging ( ) ) && ! \"jar\" . equals ( getPackaging ( ) ) ) { getLog ( ) . info ( \"deployAll is only executed for war and jar modules.\" ) ; return ; } // execute stage super . execute ( ) ; doDeployAll ( ) ; } /** Performs the deployAll goal using the staged directory */ @ VisibleForTesting public void doDeployAll ( ) throws MojoExecutionException { Path configPath = isStandardStaging ( ) ? stagingDirectory . toPath ( ) . resolve ( \"WEB-INF\" ) . resolve ( \"appengine-generated\" ) : appEngineDirectory . toPath ( ) ; try { getAppEngineFactory ( ) . deployment ( ) . deploy ( this ) ; } catch ( AppEngineException ex ) { throw new RuntimeException ( ex ) ; }", "del_tokens": "public class DeployAllMojo extends DeployMojo { Path configPath = isStandardStaging ( ) ? stagingDirectory . toPath ( ) : appEngineDirectory . toPath ( ) ; super . execute ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "builder", "methods", "based", "on", "meta", "-", "property"], "add_tokens": "import org . joda . beans . MetaProperty ; return set ( bean . metaBean ( ) . metaProperty ( propertyName ) , value ) ; } @ Override public BeanBuilder < T > set ( MetaProperty < Object > property , Object value ) { property . set ( bean , value ) ; return setString ( bean . metaBean ( ) . metaProperty ( propertyName ) , value ) ; } @ Override public BeanBuilder < T > setString ( MetaProperty < Object > property , String value ) { property . setString ( bean , value ) ;", "del_tokens": "bean . property ( propertyName ) . set ( value ) ; bean . metaBean ( ) . metaProperty ( propertyName ) . setString ( bean , value ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "visibility", "of", "Jedis", "client", "in", "the", "pool"], "add_tokens": "public MockJedis client = null ;", "del_tokens": "protected MockJedis client = null ;", "commit_type": "change"}
{"commit_tokens": ["Removed", "senseless", "instanceof", "check", ".", "Thanks", "finbugs!"], "add_tokens": "TestView view = new ViewWithMulitpleInterfaces ( ) ;", "del_tokens": "ViewWithMulitpleInterfaces view = new ViewWithMulitpleInterfaces ( ) ; Assert . assertTrue ( presenter . getView ( ) instanceof TestView ) ;", "commit_type": "remove"}
{"commit_tokens": ["Changed", "tracking", "test", "carrier", "to", "shippo", "."], "add_tokens": "final static String carrier = \"shippo\" ;", "del_tokens": "final static String carrier = \"usps\" ;", "commit_type": "change"}
{"commit_tokens": ["Added", "UTF", "-", "32", "support", "to", "Lcp", "MMPH"], "add_tokens": "if ( prev . getBoolean ( prefix ) ) throw new IllegalArgumentException ( \"The input bit vectors are not lexicographically sorted @\" + ( b * bucketSize + i ) + \"(\" + curr + \" < \" + prev + \")\" ) ; new Switch ( \"utf32\" , JSAP . NO_SHORTFLAG , \"utf-32\" , \"Use UTF-32 internally (handles surrogate pairs).\" ) , final boolean utf32 = jsapResult . getBoolean ( \"utf32\" ) ; : utf32 ? TransformationStrategies . prefixFreeUtf32 ( ) : TransformationStrategies . prefixFreeUtf16 ( ) ;", "del_tokens": "if ( prev . getBoolean ( prefix ) ) throw new IllegalArgumentException ( \"The input bit vectors are not lexicographically sorted\" ) ; : TransformationStrategies . prefixFreeUtf16 ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "CaseInsensitiveBytesHash", "to", "unicode", "properties", "template"], "add_tokens": "import org . jcodings . util . CaseInsensitiveBytesHash ; private static CaseInsensitiveBytesHash < Integer > initializeCTypeNameTable ( ) { CaseInsensitiveBytesHash < Integer > table = new CaseInsensitiveBytesHash < Integer > ( ) ; static final CaseInsensitiveBytesHash < Integer > CTypeNameHash = initializeCTypeNameTable ( ) ;", "del_tokens": "import org . jcodings . util . BytesHash ; private static BytesHash < Integer > initializeCTypeNameTable ( ) { BytesHash < Integer > table = new BytesHash < Integer > ( ) ; static final BytesHash < Integer > CTypeNameHash = initializeCTypeNameTable ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "getInputFormatClass", "to", "the", "mapred", "version", "of", "the", "ProtobufBlockInputFormat"], "add_tokens": "import com . twitter . elephantbird . util . Protobufs ; public class DeprecatedLzoProtobufBlockInputFormat < M extends Message , W extends ProtobufWritable < M > > extends DeprecatedLzoInputFormat < M , W > { / * * * Returns { @ link DeprecatedLzoProtobufBlockInputFormat } class . * Sets an internal configuration in jobConf so that remote Tasks * instantiate appropriate object based on protoClass . * / @ SuppressWarnings ( \"unchecked\" ) public static < M extends Message > Class < DeprecatedLzoProtobufBlockInputFormat > getInputFormatClass ( Class < M > protoClass , JobConf jobConf ) { Protobufs . setClassConf ( jobConf , DeprecatedLzoProtobufBlockInputFormat . class , protoClass ) ; return DeprecatedLzoProtobufBlockInputFormat . class ; } if ( typeRef_ == null ) { typeRef_ = Protobufs . getTypeRef ( jobConf , DeprecatedLzoProtobufBlockInputFormat . class ) ; } if ( protobufWritable_ == null ) { protobufWritable_ = ( W ) new ProtobufWritable < M > ( typeRef_ ) ; }", "del_tokens": "public abstract class DeprecatedLzoProtobufBlockInputFormat < M extends Message , W extends ProtobufWritable < M > > extends DeprecatedLzoInputFormat < M , W > {", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "use", "default", "provider", "chain"], "add_tokens": "import com . amazonaws . auth . DefaultAWSCredentialsProviderChain ; / * * * Should the default provider chain be used ? * / public static final String USE_DEFAULT_PROVIDER_CHAIN_PROPERTY = \"useDefaultProviderChain\" ; boolean useDefaultProviderChain = init . getProperty ( USE_DEFAULT_PROVIDER_CHAIN_PROPERTY , \"false\" ) . equalsIgnoreCase ( \"true\" ) ; if ( useDefaultProviderChain ) { client = new AmazonCloudWatchAsyncClient ( new DefaultAWSCredentialsProviderChain ( ) ) ; } else if ( useInstanceCredentials ) {", "del_tokens": "if ( useInstanceCredentials ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "weaver", "for", "public", "enums", "."], "add_tokens": "\" ice.%s = %s[ab.get1()];\\n\" , \" _unsafe.putObject(ice,%dL,%s[ab.get1()]); //%s\\n\" , \" ice.%s = %s[ab.get1()];\\n\" , \" _unsafe.putObject(ice,%dL,%s[ab.get1()]); //%s\\n\" ,", "del_tokens": "\" ice.%s = $s[ab.get1()];\\n\" , \" _unsafe.putObject(ice,%dL,%s[ab.get1()]); //%s\\n\" , \" ice.%s = $s[ab.get1()];\\n\" , \" _unsafe.putObject(ice,%dL,%s[ab.get1()]); //%s\\n\" ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "getMetadata", "method", "private", "and", "expose", "other", "more", "higher", "level", "methods", "."], "add_tokens": "public Integer getCount ( ) { return Integer . parseInt ( this . metadata . get ( \"count\" ) . toString ( ) ) ; } public Integer getLimit ( ) { return Integer . parseInt ( this . metadata . get ( \"limit\" ) . toString ( ) ) ; } public String getMarker ( ) { return this . metadata . get ( \"marker\" ) . toString ( ) ; } public String getNextMarker ( ) { return this . metadata . get ( \"next_marker\" ) . toString ( ) ; } private Map < String , Object > getMetadata ( ) { return this . metadata ;", "del_tokens": "public Map < String , Object > getMetadata ( ) { return metadata ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "comma", "separated", "feature", "names", "in", "the", "name", "attribute", "."], "add_tokens": "* ( C ) Copyright IBM Corporation 2014 , 2017. // The name field can hold a comma separated list of features // Remove any spaces at the beginning, end or around the separator String [ ] names = name . trim ( ) . split ( \"\\\\s*,\\\\s*\" ) ; for ( String featureName : names ) { if ( ! name . isEmpty ( ) ) { command . add ( featureName ) ; } }", "del_tokens": "* ( C ) Copyright IBM Corporation 2014 , 2015. command . add ( name ) ;", "commit_type": "allow"}
{"commit_tokens": ["Update", "the", "default", "scheduler", "implementation", "to", "deploy", "workers", "randomly", "."], "add_tokens": "import org . vertx . java . core . AsyncResult ; import org . vertx . java . core . Handler ; * @ param stems * A collection of stems . * @ param resultHandler * A handler to be invoked with the address of the stem to which the * worker was assigned . public void assign ( WorkerContext context , Collection < Stem > stems , Handler < AsyncResult < String > > resultHandler ) ;", "del_tokens": "public void assign ( WorkerContext context , Collection < Stem > stems ) ; / * * * Releases a worker from a machine . * * @ param context * The worker context . * / public void release ( WorkerContext context , Collection < Stem > stems ) ;", "commit_type": "update"}
{"commit_tokens": ["remove", "deprecation", "-", "unlikely", "to", "be", "used", "with", "needle", "today"], "add_tokens": "import java . util . ArrayList ; import java . util . Objects ; import java . util . function . Supplier ; this . setCustomPostBPMNParseListeners ( new ArrayList < > ( ) ) ; this . setCustomJobHandlers ( new ArrayList < > ( ) ) ;", "del_tokens": "import java . util . ArrayList ; import java . util . Objects ; import java . util . function . Supplier ; * @ deprecated this class also exists in camunda - bpm - needle and should be * centralized . @ Deprecated this . setCustomPostBPMNParseListeners ( new ArrayList < BpmnParseListener > ( ) ) ; this . setCustomJobHandlers ( new ArrayList < JobHandler > ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "Flush", "action", "with", "integration", "tests", "(", "tests", "for", "refresh", "parameter", "is", "missing", "see", "the", "test", "class", ")", "."], "add_tokens": "import io . searchbox . AbstractAction ; import io . searchbox . AbstractMultiIndexActionBuilder ; * @ author cihat keser public class Flush extends AbstractAction { private Flush ( ) { } private Flush ( Builder builder ) { this . indexName = builder . getJoinedIndices ( ) ; this . addParameter ( \"refresh\" , builder . refresh ) ; setURI ( buildURI ( ) ) ; } @ Override protected String buildURI ( ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( super . buildURI ( ) ) . append ( \"/_flush\" ) ; return sb . toString ( ) ; } @ Override public String getRestMethodName ( ) { return \"POST\" ; } public static class Builder extends AbstractMultiIndexActionBuilder < Flush , Builder > { private boolean refresh ; public Builder refresh ( boolean refresh ) { this . refresh = refresh ; return this ; } @ Override public Flush build ( ) { return new Flush ( this ) ; } }", "del_tokens": "public class Flush {", "commit_type": "implement"}
{"commit_tokens": ["Implementing", "serialization", "for", "ArrayLong", "."], "add_tokens": "import java . io . Serializable ; public final class ArrayLong extends ListLong implements Serializable { private static final long serialVersionUID = 7493025761455302920L ;", "del_tokens": "public final class ArrayLong extends ListLong {", "commit_type": "implement"}
{"commit_tokens": ["Added", "isShutdown", "()", "getQueues", "()", "and", "getJobTypes", "()", "to", "Worker", "."], "add_tokens": "public boolean isShutdown ( ) { return WorkerState . SHUTDOWN . equals ( this . state . get ( ) ) ; } public Collection < String > getQueues ( ) { return Collections . unmodifiableCollection ( this . queueNames ) ; } public Set < Class < ? > > getJobTypes ( ) { return Collections . unmodifiableSet ( this . jobTypes ) ; }", "del_tokens": "/ * * * @ return an unmodifiable view of the queues this worker is listening to * / public Collection < String > getQueues ( ) { return Collections . unmodifiableCollection ( this . queueNames ) ; } / * * * @ return an unmodifiable view of the job types this worker will execute * / public Set < Class < ? > > getJobTypes ( ) { return Collections . unmodifiableSet ( this . jobTypes ) ; }", "commit_type": "add"}
{"commit_tokens": ["Made", "parser", "more", "tolerant", "against", "missing", "whitespaces"], "add_tokens": "import java . io . File ; Generator gen = new Generator ( ) { @ Override public void warn ( String message ) { System . err . println ( message ) ; } } ;", "del_tokens": "Generator gen = new Generator ( ) ;", "commit_type": "make"}
{"commit_tokens": ["removed", "pound", "sign", "in", "test", "which", "caused", "a", "utf", "-", "8", "test", "error"], "add_tokens": "Location location = locationLookupService . lookup ( \"$%$%^Y%^fgnsdlfk glfg\" ) ;", "del_tokens": "Location location = locationLookupService . lookup ( \"$%$%^Y%^fgnsdlfk glfg\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "incorrect", "java", "path", "when", "JAVA_HOME", "isn", "t", "empty"], "add_tokens": "private static final String DEFAULT_JAVA_HOME_PATH = \"/bin/java\" ; private static final String DEFAULT_JAVA_PATH = \"java\" ; final String java = buildJavaPath ( System . getenv ( \"JAVA_HOME\" ) ) ; private String buildJavaPath ( String javaHome ) { if ( ! ( javaHome == null || javaHome . isEmpty ( ) ) ) { return javaHome + DEFAULT_JAVA_HOME_PATH ; } return DEFAULT_JAVA_PATH ; }", "del_tokens": "final String javaHome = System . getenv ( \"JAVA_HOME\" ) ; final String java ; if ( javaHome != null && javaHome . equals ( \"\" ) ) { java = javaHome + \"/bin/java\" ; } else { java = \"java\" ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "/", "at", "the", "end", "of", "scanned", "path", "(", "if", "not", "already", "there", ")", "."], "add_tokens": "m_path = path == null ? \"/\" : ( path . endsWith ( \"/\" ) ? path : path + \"/\" ) ;", "del_tokens": "m_path = path == null ? \"/\" : path ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "issue", "39", "-", "mirrorList", "must", "be", "thread", "-", "safe"], "add_tokens": "import java . util . Collections ; this . list = Collections . unmodifiableList ( list ) ;", "del_tokens": "this . list = list ;", "commit_type": "fix"}
{"commit_tokens": ["use", "a", "for", "-", "each", "loop", "when", "configuring", "soapuiProperties"], "add_tokens": "for ( Object keyObject : this . soapuiProperties . keySet ( ) ) { String key = ( String ) keyObject ; System . out . println ( \"Setting \" + key + \" value \" + this . soapuiProperties . getProperty ( key ) ) ; System . setProperty ( key , this . soapuiProperties . getProperty ( key ) ) ;", "del_tokens": "import java . util . Iterator ; for ( Iterator iterator = this . soapuiProperties . keySet ( ) . iterator ( ) ; iterator . hasNext ( ) ; ) { Object key = iterator . next ( ) ; System . out . println ( \"Setting \" + ( ( String ) key ) + \" value \" + this . soapuiProperties . getProperty ( ( String ) key ) ) ; System . setProperty ( ( String ) key , this . soapuiProperties . getProperty ( ( String ) key ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "notifyAll", "()", "in", "remove", "methods", "for", "performance"], "add_tokens": "// $Id: Queue.java,v 1.10 2003/09/26 08:38:16 rds13 Exp $ /*wake up all the threads that are waiting for the lock to be released*/ add_mutex . notifyAll ( ) ; /*wake up all the threads that are waiting for the lock to be released*/ add_mutex . notifyAll ( ) ; /*at this point we actually did receive a value from the queue, return it*/ return retval ;", "del_tokens": "// $Id: Queue.java,v 1.9 2003/09/24 22:50:38 belaban Exp $ /*at this point we actually did receive a value from the queue, return it*/ return retval ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "different", "join", "types"], "add_tokens": "protected Criteria createCriteria ( Criteria parent , String associationPath , String alias , JoinType joinType ) { new SubCriteriaImpl ( this , parent , associationPath , alias , joinType ) ; return createCriteria ( this , associationPath , null , JoinType . INNER_JOIN ) ; } public Criteria createCriteria ( String associationPath , JoinType joinType ) { return createCriteria ( this , associationPath , null , joinType ) ; return createCriteria ( this , associationPath , alias , JoinType . INNER_JOIN ) ; } public Criteria createCriteria ( String associationPath , String alias , JoinType joinType ) { return createCriteria ( this , associationPath , alias , joinType ) ;", "del_tokens": "protected Criteria createCriteria ( Criteria parent , String associationPath , String alias ) { new SubCriteriaImpl ( this , parent , associationPath , alias ) ; return createCriteria ( this , associationPath , null ) ; return createCriteria ( this , associationPath , alias ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "clustered", "short", "options", "were", "not", "recognized", "when", "parsing", "varargs", "array", "added", "tests", "."], "add_tokens": "/ * * * Called when parsing varargs parameters for a multi - value option . * When an option is encountered , the remainder should not be interpreted as vararg elements . * @ param arg the string to determine whether it is an option or not * @ return true if it is an option , false otherwise * / if ( \"--\" . equals ( arg ) ) { return true ; } // not just arg prefix: we may be in the middle of parsing -xrvfFILE if ( optionName2Field . containsKey ( arg ) ) { // -v or -f or --file (not attached to param or other option) return true ; } int separatorIndex = arg . indexOf ( separator ) ; if ( separatorIndex > 0 ) { // -f=FILE or --file==FILE (attached to param via separator) if ( optionName2Field . containsKey ( arg . substring ( 0 , separatorIndex ) ) ) { return true ; } } return ( arg . length ( ) > 2 && arg . startsWith ( \"-\" ) && singleCharOption2Field . containsKey ( arg . charAt ( 1 ) ) ) ;", "del_tokens": "// FIXME not just arg prefix: we may be in the middle of parsing -xrvfFILE return optionName2Field . containsKey ( arg ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "method", "to", "wrap", "just", "the", "first", "found", "element", "."], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Using", "JDK8", "Comparators", "where", "applicable"], "add_tokens": "public class CollatingComparatorNetworkInterfaceDisplayName extends CollatingPartComparator < NetworkInterface > public CollatingComparatorNetworkInterfaceDisplayName ( @ Nullable final Locale aSortLocale ) public CollatingComparatorNetworkInterfaceDisplayName ( @ Nonnull final Collator aCollator ) public CollatingComparatorNetworkInterfaceDisplayName ( @ Nonnull final CollatingComparator aComparator )", "del_tokens": "public class ComparatorNetworkInterfaceDisplayName extends CollatingPartComparator < NetworkInterface > public ComparatorNetworkInterfaceDisplayName ( @ Nullable final Locale aSortLocale ) public ComparatorNetworkInterfaceDisplayName ( @ Nonnull final Collator aCollator ) public ComparatorNetworkInterfaceDisplayName ( @ Nonnull final CollatingComparator aComparator )", "commit_type": "use"}
{"commit_tokens": ["Add", "resource", "loading", "support", "."], "add_tokens": "TargetRequest ( Picasso picasso , String path , int resourceId , Target target , BitmapFactory . Options bitmapOptions , List < Transformation > transformations , RequestMetrics metrics , Type type , int errorResId , Drawable errorDrawable ) { super ( picasso , path , resourceId , null , bitmapOptions , transformations , metrics , type , errorResId , errorDrawable ) ;", "del_tokens": "TargetRequest ( Picasso picasso , String path , Target target , BitmapFactory . Options bitmapOptions , List < Transformation > transformations , RequestMetrics metrics , Type type , int errorResId , Drawable errorDrawable ) { super ( picasso , path , null , bitmapOptions , transformations , metrics , type , errorResId , errorDrawable ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Executors", ".", "newWorkStealingPool", "()"], "add_tokens": "public static final ExecutorService EXECUTOR_SERVICE = Executors . newWorkStealingPool ( ) ;", "del_tokens": "import java . util . concurrent . ForkJoinPool ; public static final ExecutorService EXECUTOR_SERVICE = new ForkJoinPool ( Runtime . getRuntime ( ) . availableProcessors ( ) * 2 , ForkJoinPool . defaultForkJoinWorkerThreadFactory , null , true ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "TabPanel", ".", "setActive", "()"], "add_tokens": "returnPath = \"//*[contains(@class,'x-tab-panel-header')]//*[text()=\" + getText ( ) + \"]\" ;", "del_tokens": "returnPath = \"//*[contains(@class,'x-tab-panel-header')]//*[text()='\" + getText ( ) + \"']\" ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "sleep", "()", "to", "thread", ".", "join", "()"], "add_tokens": "// $Id: ChannelMonoTest.java,v 1.2 2003/09/19 16:17:12 belaban Exp $ mythread . join ( ) ;", "del_tokens": "// $Id: ChannelMonoTest.java,v 1.1 2003/09/18 09:52:56 rds13 Exp $ Util . sleep ( 2000 ) ;", "commit_type": "change"}
{"commit_tokens": ["Move", "stream", "to", "iterator", "based", "."], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) static public class ArrayIterator < D > extends ImmutableIterator < D > { public ArrayIterator ( final D ... data ) { //NOPMD", "del_tokens": "private class ArrayIterator < D > extends ImmutableIterator < D > { private ArrayIterator ( final D [ ] data ) { //NOPMD", "commit_type": "move"}
{"commit_tokens": ["Fix", "Image", ".", "getColor", "()", "for", "scaled", "images"], "add_tokens": "public abstract class TestWithLWJGL {", "del_tokens": "public class TestWithLWJGL {", "commit_type": "fix"}
{"commit_tokens": ["Created", "admin", "task", "for", "reading", "default", "DFactory"], "add_tokens": "import com . wadpam . guja . admintask . AdminTask ; import java . util . Map ; public class Oauth2ClientAuthenticationFilter implements Filter , AdminTask { createDefaultFactory ( ) ; } } private void createDefaultFactory ( ) { try { // TODO Move values to a property file // Overwrite any existing record factoryDao . put ( DFactoryMapper . newBuilder ( ) . id ( FactoryResource . PROVIDER_ID_SELF ) . baseUrl ( \"https://wwww.self.com\" ) . clientId ( \"12345\" ) . clientSecret ( \"9876\" ) . build ( ) ) ; } catch ( IOException e ) { LOGGER . error ( \"Failed populating factory\" , e ) ; @ Override public Object processTask ( String taskName , Map < String , String [ ] > parameterMap ) { if ( \"createFactory\" . equalsIgnoreCase ( taskName ) ) { createDefaultFactory ( ) ; } return null ; }", "del_tokens": "public class Oauth2ClientAuthenticationFilter implements Filter { try { // TODO Move values to a property file factoryDao . put ( DFactoryMapper . newBuilder ( ) . id ( FactoryResource . PROVIDER_ID_SELF ) . baseUrl ( \"https://wwww.self.com\" ) . clientId ( \"12345\" ) . clientSecret ( \"9876\" ) . build ( ) ) ; } catch ( IOException e ) { LOGGER . error ( \"populating factory\" , e ) ; }", "commit_type": "create"}
{"commit_tokens": ["Adding", "another", "blob", "object", "that", "is", "not", "a", "byte", "array", "."], "add_tokens": "assertThat ( cursor . getCount ( ) ) . isEqualTo ( 4 ) ; assertThat ( cursor . moveToNext ( ) ) . isTrue ( ) ; assertThat ( cursor . getString ( TABLE_INFO_NAME_COLUMN ) ) . isEqualTo ( \"aTestBlobObject\" ) ; assertThat ( cursor . getString ( TABLE_INFO_TYPE_COLUMN ) ) . isEqualTo ( SQL_BLOB ) ; assertThat ( cursor . getString ( TABLE_INFO_NULLABLE_COLUMN ) ) . isEqualTo ( \"0\" ) ; assertThat ( cursor . getString ( TABLE_INFO_PRIMARAY_KEY_COLUMN ) ) . isEqualTo ( \"0\" ) ;", "del_tokens": "assertThat ( cursor . getCount ( ) ) . isEqualTo ( 3 ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", ":", "The", "main", "file", "access", "module", "."], "add_tokens": "* @ version $ Revision : 1.7 $ $ Date : 1999 / 12 / 23 16 : 47 : 39 $ / * * * Creates a new file from an given CmsFile object and a new filename . * * If the resourcetype is set to folder , a CmsException will be thrown . < BR / > * * @ param project The project in which the resource will be used . * @ param file The file to be written to the Cms . * @ param filename The complete nee name of the file ( including pathinformation ) . * * @ return file The created file . * * @ exception CmsException Throws CmsException if operation was not succesful * / public CmsFile createFile ( A_CmsProject project , CmsFile file , String filename ) throws CmsException ;", "del_tokens": "* @ version $ Revision : 1.6 $ $ Date : 1999 / 12 / 22 17 : 56 : 21 $", "commit_type": "update"}
{"commit_tokens": ["Fixed", "up", "read", "only", "property", "checking", "in", "returnIsTopicEmpty"], "add_tokens": "return false ; if ( source . getRevision ( ) != null ) return false ;", "del_tokens": "return false ; if ( source . getRevision ( ) != null ) return false ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "level", "of", "checking", "for", "Galaxy", "being", "up"], "add_tokens": "logger . trace ( \"Galaxy is not yet \" + ( up ? \"up on \" : \"down on \" )", "del_tokens": "logger . debug ( \"Galaxy is not yet \" + ( up ? \"up on \" : \"down on \" )", "commit_type": "change"}
{"commit_tokens": ["Use", "setStyleSpans", "in", "JavaKeywords", "demo", "."], "add_tokens": "import java . util . Collection ; import java . util . Collections ; import codearea . control . StyleSpansBuilder ; StyleSpansBuilder < Collection < String > > spansBuilder = new StyleSpansBuilder < > ( ) ; spansBuilder . add ( Collections . emptyList ( ) , matcher . start ( ) - lastKwEnd ) ; spansBuilder . add ( Collections . singleton ( \"keyword\" ) , matcher . end ( ) - matcher . start ( ) ) ; spansBuilder . add ( Collections . emptyList ( ) , newText . length ( ) - lastKwEnd ) ; codeArea . setStyleSpans ( 0 , spansBuilder . create ( ) ) ;", "del_tokens": "codeArea . clearStyle ( lastKwEnd , matcher . start ( ) ) ; codeArea . setStyleClass ( matcher . start ( ) , matcher . end ( ) , \"keyword\" ) ; codeArea . clearStyle ( lastKwEnd , newText . length ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["improve", "test", "coverage", "for", "Service", "Bus"], "add_tokens": "public static final String INVALID_CONNECTION_STRING = \"connection string\" ; public static final String CONNECTION_STRING = \"Endpoint=sb://test.servicebus.windows.net/;\" + \"SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=dummy-key\" ;", "del_tokens": "public static final String CONNECTION_STRING = \"connection string\" ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "a", "way", "to", "escape", "@", "at", "the", "start", "of", "a", "line", "."], "add_tokens": "final MarkdownRepair atCharacterRepair2 = new AtSymbolRepair2 ( ) ; //before.add(atCharacterRepair); before . add ( atCharacterRepair2 ) ; //after.add(atCharacterRepair);", "del_tokens": "before . add ( atCharacterRepair ) ; after . add ( atCharacterRepair ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "ScopeGenerator", "according", "to", "the", "changed", "PlacementConfigType"], "add_tokens": "public static ScopeType . Scope generateDeviceScope ( final DeviceConfig deviceConfig , final LocationConfig locationConfig ) throws CouldNotPerformException { if ( locationConfig == null ) { ScopeType . Scope . Builder scope = locationConfig . getScope ( ) . toBuilder ( ) ; public static ScopeType . Scope generateUnitScope ( final UnitConfig unitConfig , final LocationConfig locationConfig ) throws CouldNotPerformException { if ( locationConfig == null ) { ScopeType . Scope . Builder scope = locationConfig . getScope ( ) . toBuilder ( ) ;", "del_tokens": "public static ScopeType . Scope generateDeviceScope ( final DeviceConfig deviceConfig ) throws CouldNotPerformException { if ( ! deviceConfig . getPlacementConfig ( ) . hasLocationConfig ( ) ) { ScopeType . Scope . Builder scope = deviceConfig . getPlacementConfig ( ) . getLocationConfig ( ) . getScope ( ) . toBuilder ( ) ; public static ScopeType . Scope generateUnitScope ( final UnitConfig unitConfig ) throws CouldNotPerformException { if ( ! unitConfig . getPlacementConfig ( ) . hasLocationConfig ( ) ) { ScopeType . Scope . Builder scope = unitConfig . getPlacementConfig ( ) . getLocationConfig ( ) . getScope ( ) . toBuilder ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "placing", "the", "menu", "drawer", "at", "the", "top", ":"], "add_tokens": "/ * * * Position the menu above the content . * / public static final int MENU_POSITION_TOP = 2 ; / * * * The initial Y position of a drag . * / protected float mInitialMotionY ; MenuDrawer menuDrawer = createMenuDrawer ( activity , dragMode , gravity ) ; / * * * Constructs the appropriate MenuDrawer based on the gravity . * / private static MenuDrawer createMenuDrawer ( Activity activity , int dragMode , int gravity ) { switch ( gravity ) { case MenuDrawer . MENU_POSITION_LEFT : return new LeftDrawer ( activity , dragMode ) ; case MenuDrawer . MENU_POSITION_RIGHT : return new RightDrawer ( activity , dragMode ) ; case MenuDrawer . MENU_POSITION_TOP : return new TopDrawer ( activity , dragMode ) ; default : throw new IllegalArgumentException ( \"gravity must be one of MENU_POSITION_LEFT, MENU_POSITION_TOP or MENU_POSITION_RIGHT\" ) ; } } mLastMotionY = mInitialMotionY = ev . getY ( ) ; mLastMotionY = mInitialMotionY = ev . getY ( ) ;", "del_tokens": "MenuDrawer menuDrawer = gravity == MenuDrawer . MENU_POSITION_RIGHT ? new RightDrawer ( activity , dragMode ) : new LeftDrawer ( activity , dragMode ) ; mLastMotionY = ev . getY ( ) ; mLastMotionY = ev . getY ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Improving", "null", "transform", "error", "message", "adding", "tests", "fixing", "some", "tests"], "add_tokens": "Bitmap transformResult ( Request request , Bitmap result ) { throw new NullPointerException ( \"Transformation \" + t . key ( ) + \" returned null when transforming \" + request . path + \" after \" + i + \" previous transformations. Transformation list: \" + request . transformationKeys ( ) ) ;", "del_tokens": "private Bitmap transformResult ( Request request , Bitmap result ) { throw new NullPointerException ( \"Transformation \" + t . key ( ) + \" returned null.\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Adding", "some", "additional", "catalog", "-", "related", "checks", "and", "tests", "."], "add_tokens": "if ( ( serializedCatalog == null ) || ( serializedCatalog . length ( ) == 0 ) )", "del_tokens": "if ( serializedCatalog == null )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "jsessionid", "filtering", "when", "the", "url", "is", "not", "used", "inside", "an", "<a", "href", "=", "...", ">", "tag"], "add_tokens": "String jsessionid = RewriteUtils . getSessionId ( target ) ; content = removeSessionId ( jsessionid , content ) ; String sessionId = RewriteUtils . getSessionId ( target ) ; return removeSessionId ( sessionId , src ) ; } private String removeSessionId ( String sessionId , String src ) { if ( sessionId == null ) return src ; else return RewriteUtils . removeSessionId ( sessionId , src ) ;", "del_tokens": "import java . util . List ; import org . apache . http . cookie . Cookie ; String jsessionid = null ; if ( target . getUserContext ( ) != null ) { List < Cookie > cookies = target . getUserContext ( ) . getCookieStore ( ) . getCookies ( ) ; for ( Cookie cookie : cookies ) if ( \"jsessionid\" . equalsIgnoreCase ( cookie . getName ( ) ) ) { jsessionid = cookie . getValue ( ) ; break ; } } content = removeSessionId ( content ) ; return src . replaceAll ( \"[;]{0,1}jsessionid=([^?#&'\\\"]+)\" , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "RubyEnumerable", "::", "detect"], "add_tokens": "public RubyEnumerator < E > detect ( ) { return new RubyEnumerator < E > ( iter ) ; } public RubyEnumerator < E > dropWhile ( ) { RubyArray < E > rubyArray = newRubyArray ( ) ; for ( E item : iter ) { rubyArray . add ( item ) ; break ; } return new RubyEnumerator < E > ( rubyArray ) ; }", "del_tokens": "public RubyEnumerator < E > detect ( ) { return new RubyEnumerator < E > ( iter ) ; } public RubyEnumerator < E > dropWhile ( ) { RubyArray < E > rubyArray = newRubyArray ( ) ; for ( E item : iter ) { rubyArray . add ( item ) ; break ; } return new RubyEnumerator < E > ( rubyArray ) ; }", "commit_type": "add"}
{"commit_tokens": ["Make", "non", "-", "cached", "zk", "property", "source", "simpler", "."], "add_tokens": "private ConcurrentHashMap < String , ZookeeperTreeCachePropertySource > lifecycleSources = new ConcurrentHashMap < > ( ) ; PropertySource propertySource = create ( propertySourceContext ) ; for ( ZookeeperTreeCachePropertySource source : this . lifecycleSources . values ( ) ) { private PropertySource < CuratorFramework > create ( String context ) { if ( this . properties . isCacheEnabled ( ) ) { ZookeeperTreeCachePropertySource propertySource = new ZookeeperTreeCachePropertySource ( context , curator ) ; propertySource . start ( ) ; lifecycleSources . put ( propertySource . getName ( ) , propertySource ) ; return propertySource ; } return new ZookeeperPropertySource ( context , curator ) ;", "del_tokens": "private ConcurrentHashMap < String , ZookeeperPropertySource > sources = new ConcurrentHashMap < > ( ) ; ZookeeperPropertySource propertySource = create ( propertySourceContext ) ; propertySource . start ( ) ; sources . put ( propertySource . getName ( ) , propertySource ) ; for ( ZookeeperPropertySource source : this . sources . values ( ) ) { private ZookeeperPropertySource create ( String context ) { return new ZookeeperPropertySource ( context , curator , properties ) ;", "commit_type": "make"}
{"commit_tokens": ["Improve", "bug", "fix", "by", "removing", "unnecessary", "class", "hierarchy"], "add_tokens": "public class StructuredQueryBuilder {", "del_tokens": "public class StructuredQueryBuilder extends AbstractQueryDefinition { optionsUri = optionsName ;", "commit_type": "improve"}
{"commit_tokens": ["update", "BatchScheduler", "API", ":", "scheduleNowWithInterval", "should", "repeat", "the", "execution", "for", "ever", "without", "need", "to", "specify", "it", "with", "a", "parameter"], "add_tokens": "public void scheduleNowWithInterval ( int interval ) { simpleScheduleBuilder = simpleScheduleBuilder . repeatForever ( ) ;", "del_tokens": "* @ param repeatForever true if the trigger should repeat forever public void scheduleNowWithInterval ( int interval , boolean repeatForever ) { if ( repeatForever ) { simpleScheduleBuilder = simpleScheduleBuilder . repeatForever ( ) ; }", "commit_type": "update"}
{"commit_tokens": ["Add", "docker", "new", "option", "for", "publicUrl", "to", "use", "container", "IP"], "add_tokens": "private String openviduPublicUrl ; //local, ngrok, docker, FINAL_URL", "del_tokens": "private String openviduPublicUrl ; //local, ngrok, FINAL_URL", "commit_type": "add"}
{"commit_tokens": ["Add", "API", "DNSApiManager", ".", "getProvider", "()"], "add_tokens": "/ * * * Get the provider associated with this instance * / public final Provider getProvider ( ) { return provider ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "settable", "duration", "for", "the", "lcd", "value", "animation", "."], "add_tokens": "private long animationDuration ; animationDuration = 2000 ; timeline . setDuration ( animationDuration ) ; / * * * Sets the animation duration for setLcdValueAnimated ( ) call * @ param animationDuration time in ms * / public void setAnimationDuration ( long animationDuration ) { this . animationDuration = animationDuration ; }", "del_tokens": "timeline . setDuration ( ( long ) ( 2000 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "issue", "14", "(", "conflict", "with", "powermock", "on", "the", "classpath", ")", "by", "setting", "GwtMockito", "as", "the", "context", "class", "loader", "during", "initialization"], "add_tokens": "// Use this custom classloader as the context classloader during the rest of the initialization // process so that classes loaded via the context classloader will be compatible with the ones // used during test. ClassLoader originalClassLoader = Thread . currentThread ( ) . getContextClassLoader ( ) ; Thread . currentThread ( ) . setContextClassLoader ( gwtMockitoClassLoader ) ; } finally { Thread . currentThread ( ) . setContextClassLoader ( originalClassLoader ) ; try { super . run ( notifier ) ; } finally { Thread . currentThread ( ) . setContextClassLoader ( originalClassLoader ) ; }", "del_tokens": "super . run ( notifier ) ; Thread . currentThread ( ) . setContextClassLoader ( originalClassLoader ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "one", "more", "check", "for", "another", "flavor", "of", "introducing", "a", "new", "method", "."], "add_tokens": "} else if ( method . getModifiers ( ) . contains ( Modifier . FINAL ) && ! enclosingClass . getModifiers ( ) . contains ( Modifier . FINAL ) ) { difference = createDifference ( Code . METHOD_FINAL_METHOD_ADDED_TO_NON_FINAL_CLASS ) ; return Collections . singletonList ( difference ) ;", "del_tokens": "return difference == null ? null : Collections . singletonList ( difference ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "HTTPS", "connector", "and", "merge", "it", "with", "the", "HTTP", "connector"], "add_tokens": "p . setInitialSize ( 5 ) ; p . setMaxWait ( 30000 ) ;", "del_tokens": "p . setInitialSize ( 10 ) ; p . setMaxWait ( 10000 ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "logix", "with", "loading", "image"], "add_tokens": "final Drawable d = holder . getRequiredWidth ( ) > 0 && holder . getRequiredHeight ( ) > 0 ? getLoadingDrawable ( holder . context ) : null ; setImage ( holder , d ) ; imageHolder . reset ( ) ; public void reset ( ) { cachedImageId = - 1 ; }", "del_tokens": "if ( holder . getRequiredWidth ( ) > 0 && holder . getRequiredHeight ( ) > 0 ) { setImage ( holder , getLoadingDrawable ( holder . context ) ) ; } imageHolder . cachedImageId = - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "beforeNotify", "callback"], "add_tokens": "public void setBeforeNotify ( BeforeNotify beforeNotify ) { config . setBeforeNotify ( beforeNotify ) ; } beforeNotify ( error ) ; if ( error . shouldIgnore ( ) ) return ; private void beforeNotify ( Error error ) { if ( config . beforeNotify != null ) { config . beforeNotify . run ( error ) ; } }", "del_tokens": "if ( error . shouldIgnore ( ) ) return ;", "commit_type": "add"}
{"commit_tokens": ["Move", "ParboiledTest", "into", "test", "sources"], "add_tokens": "import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ;", "del_tokens": "import java . util . * ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "the", "constructor", "parameter", "to", "match", "the", "field", "name", "to", "help"], "add_tokens": "* @ param numericCode the numeric currency code , from 0 to 999 , - 1 if none CurrencyUnit ( String code , short numericCode , short decimalPlaces ) { this . numericCode = numericCode ;", "del_tokens": "* @ param numericCurrencyCode the numeric currency code , from 0 to 999 , - 1 if none CurrencyUnit ( String code , short numericCurrencyCode , short decimalPlaces ) { this . numericCode = numericCurrencyCode ;", "commit_type": "fix"}
{"commit_tokens": ["update", "es", "version", "and", "test", "cases"], "add_tokens": "} ) . build ( newConfigs ( ) . ramIndexStore ( ) . numOfNode ( 3 ) ) ; // order . startObject ( \"order\" ) // . field ( \"type\" , \"long\" ) // . endObject ( ) // // @timestamp . startObject ( \"@timestamp\" ) // . field ( \"type\" , \"date\" ) // . endObject ( ) // + i + \"\\\",\\\"order\\\":\" + i + \",\\\"@timestamp\\\":\\\"2000-01-01T00:00:00\\\"}\" ) ;", "del_tokens": "} ) . build ( newConfigs ( ) . ramIndexStore ( ) ) ; + i + \"\\\"}\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "the", "reconnect", "retry", "interval", "configurable", "."], "add_tokens": "import java . util . concurrent . atomic . AtomicLong ; private String lastWatch ; private AtomicLong retryInterval = new AtomicLong ( 1000 ) ; JSONObject watch = new JSONObject ( ) ; if ( responseClass == WatchObject . class ) { lastWatch = command ; } if ( lastWatch != null ) { // restore watch if we had one. this . syncCommand ( \"?WATCH=\" + lastWatch , WatchObject . class ) ; / * * * Set a retry interval for reconnecting to GPSD if the socket closes . * Default value is 1000 ms . * * @ param millis how long to wait between each reconnection attempts . * / public void setRetryInterval ( long millis ) { retryInterval . set ( millis ) ; }", "del_tokens": "private JSONObject watch ; watch = new JSONObject ( ) ; if ( watch != null ) { this . syncCommand ( \"?WATCH=\" + watch . toString ( ) , WatchObject . class ) ;", "commit_type": "make"}
{"commit_tokens": ["improved", "CustomResourcesHandler", "to", "handle", "all", "common", "HTTP", "requests"], "add_tokens": "* This method is called when a GET request to be handled . Response handleGet ( ContainerRequestContext ctx ) ; / * * * This method is called when a POST request to be handled . * @ param ctx the context object - contains all the details of the request and context * @ return a response * / Response handlePost ( ContainerRequestContext ctx ) ; / * * * This method is called when a PUT request to be handled . * @ param ctx the context object - contains all the details of the request and context * @ return a response * / Response handlePut ( ContainerRequestContext ctx ) ; / * * * This method is called when a DELETE request to be handled . * @ param ctx the context object - contains all the details of the request and context * @ return a response * / Response handleDelete ( ContainerRequestContext ctx ) ;", "del_tokens": "* This method is called when a custom resource needs to be handled . Response handle ( ContainerRequestContext ctx ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "tests", "for", "quoted", "identifiers"], "add_tokens": "private static final String [ ] TABLES = { \"TEST\" , \"TESTCHILD\" , \"TEST_QUOTED\" } ; { \"ID\" , \"CHILDID\" , \"DESCRIPTION\" } , { \"ID\" , \"UUID\" , \"ACTIVE\" , \"AMOUNT\" , \"DESCRIPTION\" , \"CREATED_DATE\" , \"LAST_UPDATED\" } } ; { Types . BIGINT , Types . BIGINT , Types . NVARCHAR } , { Types . BIGINT , Types . BINARY , Types . BOOLEAN , Types . DOUBLE , Types . NVARCHAR , Types . DATE , Types . TIMESTAMP } } ; INDEX_COLUMNS . put ( \"TEST_QUOTED.PRIMARY_KEY\" , new String [ ] { \"ID\" } ) ; INDEX_UNIQUE . put ( \"TEST_QUOTED.PRIMARY_KEY\" , Boolean . TRUE ) ; assertEquals ( 3 , count ) ; try ( ResultSet rs = metadata . getBestRowIdentifier ( \"\" , \"\" , table , DatabaseMetaData . bestRowTransaction , false ) )", "del_tokens": "private static final String [ ] TABLES = { \"TEST\" , \"TESTCHILD\" } ; { \"ID\" , \"CHILDID\" , \"DESCRIPTION\" } } ; { Types . BIGINT , Types . BIGINT , Types . NVARCHAR } } ; assertEquals ( 2 , count ) ; try ( ResultSet rs = metadata . getBestRowIdentifier ( \"\" , \"\" , table , DatabaseMetaData . bestRowTransaction , false ) )", "commit_type": "add"}
{"commit_tokens": ["Removed", "inheritance", "from", "constants", "class"], "add_tokens": "public final class ConfigToolConstants {", "del_tokens": "import org . apache . velocity . tools . generic . SafeConfig ; public final class ConfigToolConstants extends SafeConfig {", "commit_type": "remove"}
{"commit_tokens": ["remove", "neighbours", "of", "limit", "points", "unit", "test", "pending", "investigation", "of", "desired", "result"], "add_tokens": "Preconditions . checkArgument ( hash . length ( ) > 0 , \"adjacent has no meaning for a zero length hash that covers the whole world\" ) ; Preconditions . checkArgument ( hash != null , \"hash must be non-null\" ) ;", "del_tokens": "Preconditions . checkArgument ( hash != null && hash . length ( ) > 0 , \"hash must be non-null of length>0\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "ability", "to", "retrieve", "registered", "prefix", "ID", "of", "a", "Server"], "add_tokens": "public static final long UNREGISTERED = - 1 ; private long registeredPrefixId = UNREGISTERED ; / * * * { @ inheritDoc } * / @ Override public long getRegisteredPrefixId ( ) { return registeredPrefixId ; } return registeredPrefixId == UNREGISTERED ; registeredPrefixId = face . registerPrefix ( prefix , this , new OnRegisterFailed ( ) { registeredPrefixId = UNREGISTERED ;", "del_tokens": "private boolean registered = false ; return registered ; registered = true ; face . registerPrefix ( prefix , this , new OnRegisterFailed ( ) { registered = false ; registered = false ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "hyphen", "signs", "in", "build", "and", "pre", "release", "section"], "add_tokens": "String [ ] tokens ; if ( hasPreRelease ( value ) ) { tokens = value . split ( \"-\" , 2 ) ; } else { tokens = new String [ ] { value } ; } private boolean hasPreRelease ( String version ) { int firstIndexOfPlus = value . indexOf ( \"+\" ) ; int firstIndexOfHyphen = value . indexOf ( \"-\" ) ; if ( firstIndexOfHyphen == - 1 ) { return false ; } return firstIndexOfPlus == - 1 || firstIndexOfHyphen < firstIndexOfPlus ; }", "del_tokens": "String [ ] tokens = value . split ( \"-\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Created", "a", "real", "Add", "-", "on", "SASS", "stylesheet"], "add_tokens": "@ Theme ( \"demo\" )", "del_tokens": "@ Theme ( \"signaturefield\" )", "commit_type": "create"}
{"commit_tokens": ["fix", "support", "for", "nan", "and", "null", "set"], "add_tokens": "log ( HEAD_SET + varname + \" <- \" + var ) ; if ( var == null ) { rm ( varname ) ; } else if ( var instanceof RList ) {", "del_tokens": "log ( HEAD_SET + varname + \" <- \" + var . toString ( ) ) ; if ( var instanceof RList ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "a", "flag", "to", "indicate", "if", "full", "screen", "need", "hide", "title", "bar"], "add_tokens": "public final boolean hideFullScreenTitle ; * @ param horizontalProgress this ( fragmentManager , fullScreen , horizontalProgress , false ) ; } / * * * * @ param fragmentManager * @ param fullScreen * @ param horizontalProgress * / public DialogFragmentController ( android . app . FragmentManager fragmentManager , boolean fullScreen , boolean horizontalProgress ) { this ( fragmentManager , fullScreen , horizontalProgress , false ) ; } / * * * * @ param fragmentManager * @ param fullScreen * @ param horizontalProgress * @ param hideFullScreenTitle if you set this flag to true , { @ param horizontalProgress } will be ignored * / public DialogFragmentController ( android . support . v4 . app . FragmentManager fragmentManager , boolean fullScreen , boolean horizontalProgress , boolean hideFullScreenTitle ) { this . hideFullScreenTitle = hideFullScreenTitle ; * @ param horizontalProgress * @ param hideFullScreenTitle if you set this flag to true , { @ param horizontalProgress } will be ignored boolean horizontalProgress , boolean hideFullScreenTitle ) { this . hideFullScreenTitle = hideFullScreenTitle ;", "del_tokens": "boolean horizontalProgress ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "DObjectFactory", "to", "move", "DObjects", "over", "the", "wire", "."], "add_tokens": "// $Id: ObjectResponse.java,v 1.3 2001/05/29 03:28:50 mdb Exp $ import com . samskivert . cocktail . cher . dobj . DObjectFactory ; DObjectFactory . writeTo ( out , _dobj ) ; _dobj = ( DObject ) DObjectFactory . readFrom ( in ) ;", "del_tokens": "// $Id: ObjectResponse.java,v 1.2 2001/05/23 04:03:40 mdb Exp $ import com . samskivert . cocktail . cher . io . TypedObjectFactory ; TypedObjectFactory . writeTo ( out , _dobj ) ; _dobj = ( DObject ) TypedObjectFactory . readFrom ( in ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "function", "code", "in", "WriteMultipleCoils", "implementation", "."], "add_tokens": "return ModbusFunction . WRITE_MULTIPLE_COILS ;", "del_tokens": "return ModbusFunction . WRITE_MULTIPLE_REGISTERS ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "stub", "for", "text", "/", "plain", "output", "format"], "add_tokens": "public abstract void start ( String documentUri ) throws SAXException ;", "del_tokens": "public abstract void start ( ) throws SAXException ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problems", "with", "locale", "in", "ClockTileSkin", "and", "TimerControlSkin"], "add_tokens": "private DateTimeFormatter dateFormatter ; dateFormatter = DateTimeFormatter . ofPattern ( \"EE d\" , getSkinnable ( ) . getLocale ( ) ) ; dateText . setText ( dateFormatter . format ( TIME ) . toUpperCase ( ) ) ; dateFormatter = DateTimeFormatter . ofPattern ( \"EE d\" , getSkinnable ( ) . getLocale ( ) ) ;", "del_tokens": "private static final DateTimeFormatter DATE_FORMATER = DateTimeFormatter . ofPattern ( \"EE d\" ) ; dateText . setText ( DATE_FORMATER . format ( TIME ) . toUpperCase ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "CGLib", "support", "for", "proxying", "classes"], "add_tokens": "* Copyright 2009 < a href = \"http://www.powermock.org\" > PowerMock < / a > .", "del_tokens": "* Copyright 2009 the original author or authors .", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "PlantUML", "."], "add_tokens": "* A Doclet that allows the use of Markdown in JavaDoc and * [ PlantUML ] ( http : //plantuml.sourceforge.net/) comments. It uses * PlantUML * -- -- -- -- * * This Doclet has built - in support for PlantUML . Just use the ` @ uml ` tag : * * ``` * / * * * * Description . * * * * ! [ Example Diagram ] ( example . png ) * * * * @ uml example . png * * Alice -> Bob : Authentication Request * * Bob -- > Alice : Authentication Response * * / * ``` * * It 's also possible to use `@startuml` and `@enduml` instead, as usual. `@startuml` is * simply a synonym for ` @ uml ` and ` @ enduml ` will be ignored entirely . Use this for * compatibility with other tools , like e . g . the * [ PlantUML IDEA Plugin ] ( https : //github.com/esteinberg/plantuml4idea). * * * - overview < page > * - plantuml - config < file > * : A configuration file that will be included before each diagram . *", "del_tokens": "* A Doclet that allows the use of Markdown in JavaDoc comments . It uses * * - overview < page > *", "commit_type": "add"}
{"commit_tokens": ["Add", "serializers", "for", "StringBuilder", "and", "StringBuffer", ".", "They", "serialize", "the", "String", "representation", "so", "that", "not", "the", "internal", "char", "array", "is", "serialized", ".", "This", "reduces", "the", "number", "of", "serialized", "bytes", "."], "add_tokens": "_kryo . setSerializer ( StringBuffer . class , new StringBufferSerializer ( _kryo ) ) ; _kryo . setSerializer ( StringBuilder . class , new StringBuilderSerializer ( _kryo ) ) ; final StringBuffer stringBuffer = new StringBuffer ( \"<stringbuffer>with some content \\n& some lines...</stringbuffer>\" ) ; final StringBuilder stringBuilder = new StringBuilder ( \"<stringbuilder>with some content \\n& some lines...</stringbuilder>\" ) ;", "del_tokens": "final StringBuffer stringBuffer = new StringBuffer ( \"<string\\n&buffer/>\" ) ; final StringBuilder stringBuilder = new StringBuilder ( \"<string\\n&buffer/>\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "AO", "Fluent", "HTML", "for", "HTML", "generation", "."], "add_tokens": "* Copyright ( C ) 2016 , 2017 , 2019 , 2020 AO Industries , Inc . import com . aoindustries . html . Html ; public void doView ( ServletContext servletContext , HttpServletRequest request , HttpServletResponse response , Html html , Page page ) throws ServletException , IOException , SkipPageException {", "del_tokens": "* Copyright ( C ) 2016 , 2017 , 2019 AO Industries , Inc . public void doView ( ServletContext servletContext , HttpServletRequest request , HttpServletResponse response , Page page ) throws ServletException , IOException , SkipPageException {", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "custom", "jackson", "modules"], "add_tokens": "import com . fasterxml . jackson . databind . Module ; public MongoSearchDao ( DB db , String collectionName , Class < T > typeClass , Module ... modules ) { JacksonMapper . Builder mapperBuilder = new JacksonMapper . Builder ( ) ; mapperBuilder . registerModule ( new GeoJsonModule ( ) ) ; for ( Module module : modules ) { mapperBuilder . registerModule ( module ) ; }", "del_tokens": "public MongoSearchDao ( DB db , String collectionName , Class < T > typeClass ) { JacksonMapper . Builder mapperBuilder = new JacksonMapper . Builder ( ) . registerModule ( new GeoJsonModule ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "dedicated", "exception", "for", "method", "call", "not", "supported", "on", "automapped", "interface"], "add_tokens": "import org . davidmoten . rx . jdbc . exceptions . MethodCallNotSupportedException ; // TODO defer to a default method on the interface for example throw new MethodCallNotSupportedException ( \"extra methods like interface default methods not supported (yet): \" + method ) ;", "del_tokens": "// TODO invoke a default method on the interface for example throw new RuntimeException ( \"extra methods like interface default methods not supported (yet): \" + method ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "cursor", "manager", "updating", "of", "offsets"], "add_tokens": "import com . google . common . collect . Ordering ; Ordering < String > OFFSET_ORDERING = Ordering . natural ( ) . nullsFirst ( ) . onResultOf ( ( String offset ) -> \"BEGIN\" . equals ( offset ) ? null : Long . parseLong ( offset ) ) ; boolean isEmpty = OFFSET_ORDERING . compare ( partition . getOldestAvailableOffset ( ) , partition . getNewestAvailableOffset ( ) ) > 0 ; final String minAvailableOffset = isEmpty ? partition . getNewestAvailableOffset ( ) : partition . getOldestAvailableOffset ( ) ; if ( cursor == null || OFFSET_ORDERING . compare ( cursor . getOffset ( ) , minAvailableOffset ) < 0 ) { onSuccess ( eventName , new Cursor ( partition . getPartition ( ) , minAvailableOffset ) ) ;", "del_tokens": "if ( cursor == null || ! partition . isAvailable ( cursor . getOffset ( ) ) ) { onSuccess ( eventName , new Cursor ( partition . getPartition ( ) , partition . getOldestAvailableOffset ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improves", "ogr", "method", "to", "expand"], "add_tokens": "", "del_tokens": "", "commit_type": "improve"}
{"commit_tokens": ["added", "possibility", "to", "reload", "configuration"], "add_tokens": "reload ( ) ; @ Override public void reload ( ) {", "del_tokens": "loadProperties ( ) ; private void loadProperties ( ) {", "commit_type": "add"}
{"commit_tokens": ["Change", "setGroupMatch", "to", "public", "method"], "add_tokens": "public String setGroupMatch ( String groupOrder ) {", "del_tokens": "private String setGroupMatch ( String groupOrder ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "InvalidPathException", "on", "Windows"], "add_tokens": "import java . net . URISyntaxException ; try { return Paths . get ( location . toURI ( ) ) ; } catch ( URISyntaxException e ) { throw new IOException ( e ) ; }", "del_tokens": "import java . io . FileFilter ; import java . io . FileInputStream ; import java . io . IOError ; Path path = Paths . get ( location . getPath ( ) ) ; return path ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "MurmureHash", "as", "sharding", "algo", "."], "add_tokens": "private Hashing algo = Hashing . MD5 ; public Sharded ( List < ShardInfo > shards , Hashing algo ) { initialize ( shards ) ; } return algo . hash ( key ) ;", "del_tokens": "private static MessageDigest md5 = null ; // avoid recurring construction if ( md5 == null ) { try { md5 = MessageDigest . getInstance ( \"MD5\" ) ; } catch ( NoSuchAlgorithmException e ) { throw new IllegalStateException ( \"++++ no md5 algorythm found\" ) ; } } md5 . reset ( ) ; md5 . update ( key . getBytes ( ) ) ; byte [ ] bKey = md5 . digest ( ) ; long res = ( ( long ) ( bKey [ 3 ] & 0xFF ) << 24 ) | ( ( long ) ( bKey [ 2 ] & 0xFF ) << 16 ) | ( ( long ) ( bKey [ 1 ] & 0xFF ) << 8 ) | ( long ) ( bKey [ 0 ] & 0xFF ) ; return res ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "unmarshaling", "crash", "when", "restoring", "result", "receiver"], "add_tokens": "boolean hadReceiver = source . readByte ( ) == 1 ; if ( hadReceiver ) { groundy . mReceiver = source . readParcelable ( CallbacksReceiver . class . getClassLoader ( ) ) ; } dest . writeByte ( ( byte ) ( mReceiver == null ? 0 : 1 ) ) ; if ( mReceiver != null ) { dest . writeParcelable ( mReceiver , flags ) ; }", "del_tokens": "import android . os . ResultReceiver ; groundy . mReceiver = source . readParcelable ( ResultReceiver . class . getClassLoader ( ) ) ; dest . writeParcelable ( mReceiver , flags ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "app", ".", "xml", "embedded", "in", "launcher"], "add_tokens": "if ( Files . exists ( FXManifest . getPath ( ) ) ) { manifest = FXManifest . load ( ) ; } else { URL embeddedManifest = Launcher . class . getResource ( \"/app.xml\" ) ; if ( embeddedManifest != null ) manifest = JAXB . unmarshal ( embeddedManifest , FXManifest . class ) ; } if ( manifest == null ) throw new IllegalArgumentException ( String . format ( \"No %s in current or embedded in launcher!\" , FXManifest . filename ) ) ; try {", "del_tokens": "if ( ! Files . exists ( FXManifest . getPath ( ) ) ) throw new IllegalArgumentException ( String . format ( \"No %s in current directory\" , FXManifest . filename ) ) ; manifest = FXManifest . load ( ) ; try {", "commit_type": "add"}
{"commit_tokens": ["Added", "initial", "interface", "implementation", "currently", "not", "immutable"], "add_tokens": "predicateClause . generatesSources ( generatedSources [ 0 ] , Arrays . copyOfRange ( generatedSources , 1 , generatedSources . length ) ) ;", "del_tokens": "predicateClause . generatesSources ( generatedSources [ 0 ] , Arrays . copyOfRange ( generatedSources , 1 , generatedSources . length - 1 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "runExecute", "return", "int", "again", "after", "reading", "the", "docs", "more", "."], "add_tokens": "public int runExecute ( ) throws SQLException { if ( type != StatementType . EXECUTE ) { preparedStatement . execute ( ) ; return preparedStatement . getUpdateCount ( ) ;", "del_tokens": "public boolean runExecute ( ) throws SQLException { if ( type != StatementType . SELECT ) { return preparedStatement . execute ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "better", "date", "format", "for", "core"], "add_tokens": "return new GsonBuilder ( ) . setDateFormat ( \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\" ) . create ( ) . toJson ( this ) ;", "del_tokens": "return new GsonBuilder ( ) . create ( ) . toJson ( this ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "possible", "NPE", "."], "add_tokens": "if ( server == null ) { return \"\" ; } else { return server + ( server . endsWith ( \"/\" ) ? \"\" : \"/\" ) + \"seam/resource/restv1/projects/p/\" + project + \"/iterations/i/\" + version + \"/r\" ; }", "del_tokens": "return server + ( server . endsWith ( \"/\" ) ? \"\" : \"/\" ) + \"seam/resource/restv1/projects/p/\" + project + \"/iterations/i/\" + version + \"/r\" ;", "commit_type": "fix"}
{"commit_tokens": ["added", "the", "ability", "to", "supply", "query", "params", "to", "ChangesCommand"], "add_tokens": "assertEquals ( \"_changes?feed=continuous&since=10&filter=mydesigndoc%2Fmyfilter&include_docs=true&limit=1000&paramName=paramValue\" , . param ( \"paramName\" , \"paramValue\" )", "del_tokens": "assertEquals ( \"_changes?feed=continuous&since=10&filter=mydesigndoc%2Fmyfilter&include_docs=true&limit=1000\" ,", "commit_type": "add"}
{"commit_tokens": ["Move", "hystrix", "templates", "to", "/", "hystrix", "/", "*"], "add_tokens": "import org . springframework . web . bind . annotation . PathVariable ; return \"hystrix/index\" ; @ RequestMapping ( \"/hystrix/{path}\" ) public String monitor ( @ PathVariable String path , Model model , WebRequest request ) { return \"hystrix/\" + path ;", "del_tokens": "return \"index\" ; @ RequestMapping ( \"/hystrix/monitor\" ) public String monitor ( Model model , WebRequest request ) { return \"monitor\" ;", "commit_type": "move"}
{"commit_tokens": ["Added", "hasValue", "assertion", "with", "offset", "to", "NumberBindingAssert"], "add_tokens": "import javafx . beans . property . DoubleProperty ; import javafx . beans . property . SimpleDoubleProperty ; import static org . assertj . core . data . Offset . offset ; } @ Test public void testNumberBindingWithOffset ( ) { DoubleProperty valueA = new SimpleDoubleProperty ( 0.1 ) ; DoubleProperty valueB = new SimpleDoubleProperty ( 0.2 ) ; final NumberBinding binding = valueA . add ( valueB ) ; assertThat ( binding ) . hasValue ( 0.3 , offset ( 0.001 ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "perf", "problem", "with", "new", "String", "(", "bytes", "offset", "length", "encoding", ")"], "add_tokens": "import static parquet . bytes . BytesUtils . UTF8 ; return UTF8 . decode ( ByteBuffer . wrap ( value , offset , length ) ) . toString ( ) ; // TODO: figure out why the following line was much slower // return new String(value, offset, length, BytesUtils.UTF8);", "del_tokens": "return new String ( value , offset , length , BytesUtils . UTF8 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "duplicate", "value", "during", "parsing", "in", "case", "of", "references", "with", "opposite", "."], "add_tokens": "resolve ( eObject , processed . get ( eObject ) , resource ) ; void resolve ( EObject eObject , JsonNode node , Resource resource ) { values . add ( proxy ) ; URI objectURI = getEObjectURI ( node . get ( EJS_REF_KEYWORD ) , resource , deserializer . getNamespaces ( ) ) ;", "del_tokens": "resolve ( eObject , processed . get ( eObject ) , resource , processed ) ; void resolve ( EObject eObject , JsonNode node , Resource resource , Map < EObject , JsonNode > processed ) { values . addUnique ( proxy ) ; final URI objectURI = getEObjectURI ( node . get ( EJS_REF_KEYWORD ) , resource , deserializer . getNamespaces ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "close", "-", "hover", "-", "modified", "image", "."], "add_tokens": "public static final int BACKGROUND_MODIFIED_MOUSEOVER = 5 ; public static final int BACKGROUND_PRESSED = 6 ; public static final int BACKGROUND_ENABLED_WINDOWNOTFOCUSED = 7 ; public static final int BACKGROUND_MODIFIED_WINDOWNOTFOCUSED = 8 ; public static final int BACKGROUND_PRESSED_WINDOWNOTFOCUSED = 9 ; case BACKGROUND_MODIFIED_MOUSEOVER : return \"window_close_hover_modified\" ;", "del_tokens": "// package private integers representing the available states that // this painter will paint. These are used when creating a new instance // of // InternalFrameInternalFrameTitlePaneInternalFrameTitlePaneCloseButtonPainter // to determine which region/state is being painted by that instance. public static final int BACKGROUND_PRESSED = 5 ; public static final int BACKGROUND_ENABLED_WINDOWNOTFOCUSED = 6 ; public static final int BACKGROUND_MODIFIED_WINDOWNOTFOCUSED = 7 ; public static final int BACKGROUND_PRESSED_WINDOWNOTFOCUSED = 8 ;", "commit_type": "add"}
{"commit_tokens": ["Used", "switch", "and", "when", "instead", "of", "if", "/", "else", "if", "constructs", "."], "add_tokens": "switch ( widthMode ) { case MeasureSpec . EXACTLY : //Must be this size width = widthSize ; break ; case MeasureSpec . AT_MOST : //Can't be bigger than... width = Math . min ( mDesiredWidth , widthSize ) ; break ; case MeasureSpec . UNSPECIFIED : default : //Be whatever you want width = mDesiredWidth ; break ; switch ( heightMode ) { case MeasureSpec . EXACTLY : //Must be this size height = heightSize ; break ; case MeasureSpec . AT_MOST : //Can't be bigger than... height = Math . min ( mDesiredHeight , heightSize ) ; break ; case MeasureSpec . UNSPECIFIED : default : //Be whatever you want height = mDesiredHeight ; break ;", "del_tokens": "if ( widthMode == MeasureSpec . EXACTLY ) { //Must be this size width = widthSize ; } else if ( widthMode == MeasureSpec . AT_MOST ) { //Can't be bigger than... width = Math . min ( mDesiredWidth , widthSize ) ; } else { //Be whatever you want width = mDesiredWidth ; if ( heightMode == MeasureSpec . EXACTLY ) { //Must be this size height = heightSize ; } else if ( heightMode == MeasureSpec . AT_MOST ) { //Can't be bigger than... height = Math . min ( mDesiredHeight , heightSize ) ; } else { //Be whatever you want height = mDesiredHeight ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "various", "Java", "warnings", ".", "No", "functional", "changes", "."], "add_tokens": "database . callProcedure ( \"@Shutdown\" ) ;", "del_tokens": "VoltTable [ ] results ; results = database . callProcedure ( \"@Shutdown\" ) ; VoltTable [ ] results ; VoltTable [ ] results ; boolean knowncommand = false ; int i ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; knowncommand = true ; String tmpstr = s . trim ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "headless", "environment", "INFO", "log", "statements", ";", "log", "buildmessage", "failures", "with", "stacktrace", ";", "improve", "sampleapp", "pom"], "add_tokens": ". SetUser ( _user ) catch ( Throwable t ) Logger . getLogger ( \"Raygun4Java\" ) . throwing ( \"RaygunClient\" , \"BuildMessage\" , t ) ;", "del_tokens": ". SetUser ( _user ) catch ( Exception e ) Logger . getLogger ( \"Raygun4Java\" ) . warning ( \"Failed to build RaygunMessage: \" + e . getMessage ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Creating", "a", "separate", "nodes", ".", "md", "since", "in", "big", "installations", "this", "can", "be", "huge", "and", "overwhelms", "about", ".", "md", "."], "add_tokens": "} } ) ; container . add ( new PrintedContent ( \"nodes.md\" ) { @ Override protected void printTo ( PrintWriter out ) throws IOException { out . println ( \"===========\" ) ;", "del_tokens": "out . println ( ) ; out . println ( \"------------\" ) ;", "commit_type": "create"}
{"commit_tokens": ["adding", "cobertura", ".", "adding", "more", "tests", "."], "add_tokens": "public < P , O , V > Table < P , O , V > getTable ( String tableName , Serde < P > hashKeySerde , Serde < O > rangeKeySerde , Serde < V > valueSerde ) { tables . put ( tableName , new EzLevelDbTable < P , O , V > ( new File ( root , tableName ) , hashKeySerde , rangeKeySerde , valueSerde ) ) ;", "del_tokens": "public < P , O , V > Table < P , O , V > getTable ( String tableName , Serde < P > partitionKeySerde , Serde < O > orderKeySerde , Serde < V > valueSerde ) { tables . put ( tableName , new EzLevelDbTable < P , O , V > ( new File ( root , tableName ) , partitionKeySerde , orderKeySerde , valueSerde ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "full", "test", "suite", "for", "SliceInput"], "add_tokens": "if ( length == 0 ) { return 0 ; }", "del_tokens": "throws IOException @ Override public int read ( byte [ ] destination ) { return read ( destination , 0 , destination . length ) ; }", "commit_type": "add"}
{"commit_tokens": ["Remove", "overloaded", "acronym", "methods", "ob", "cb", "for", "openBracket", "closeBracket"], "add_tokens": "* @ param values that match unknown variable by name or by order * @ return { @ link AbstractCalculator }", "del_tokens": "* @ return * @ // // BRACKET'S // / * * * Open bracket * @ return * / public CALC ob ( ) { infix . add ( Bracket . OPEN ) ; return getThis ( ) ; } // --------------- / * * * Close bracket * * @ return * / public CALC cb ( ) { infix . add ( Bracket . CLOSE ) ; return getThis ( ) ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "service", "activity", "receiver", "parser"], "add_tokens": "private Icon icon ; private List < Service > services = new ArrayList < Service > ( ) ; private List < Activity > activities = new ArrayList < Activity > ( ) ; private List < Receiver > receivers = new ArrayList < Receiver > ( ) ; public Icon getIcon ( ) { public void setIcon ( Icon icon ) { public List < Service > getServices ( ) { return services ; } public void addService ( Service service ) { this . services . add ( service ) ; } public List < Activity > getActivities ( ) { return activities ; } public void addActivity ( Activity activity ) { this . activities . add ( activity ) ; } public List < Receiver > getReceivers ( ) { return receivers ; } public void addReceiver ( Receiver receiver ) { this . receivers . add ( receiver ) ; }", "del_tokens": "private String icon ; public String getIcon ( ) { public void setIcon ( String icon ) {", "commit_type": "add"}
{"commit_tokens": ["make", "field", "in", "Entry", "of", "PiffSampleEncryptionBox", "public", "to", "be", "able", "to", "access", "them", "from", "outside", "the", "package", "without", "getter", "/", "setter"], "add_tokens": "public byte [ ] iv ; public List < Pair > pairs = new LinkedList < Pair > ( ) ; public int clear ; public long encrypted ;", "del_tokens": "byte [ ] iv ; List < Pair > pairs = new LinkedList < Pair > ( ) ; int clear ; long encrypted ;", "commit_type": "make"}
{"commit_tokens": ["Add", "push", "token", "registration", "to", "the", "SDK", ".", "Add", "Google", "Play", "services", "integration", "to", "the", "demo", "app", "with", "push", "token", "retrieval", "code", "commented", "out", "for", "now", "."], "add_tokens": "public String baseURL ; public String contentType ; baseURL = \"https://\" + RESPOKE_BASE_URL ; contentType = \"application/x-www-form-urlencoded\" ; String fullUrl = baseURL + urlEndpoint ; connection . setRequestProperty ( \"Content-Type\" , contentType ) ; DataOutputStream outputStream = new DataOutputStream ( connection . getOutputStream ( ) ) ; outputStream . writeBytes ( params ) ; outputStream . flush ( ) ; outputStream . close ( ) ; finally { if ( connection != null ) { connection . disconnect ( ) ; } }", "del_tokens": "//for logging to console String fullUrl = \"https://\" + RESPOKE_BASE_URL + urlEndpoint ; connection . setRequestProperty ( \"Content-Type\" , \"application/x-www-form-urlencoded\" ) ; connection . setChunkedStreamingMode ( 0 ) ; writeToServer ( connection ) ; private void writeToServer ( HttpURLConnection connection ) throws IOException { DataOutputStream outputStream = new DataOutputStream ( connection . getOutputStream ( ) ) ; outputStream . writeBytes ( params ) ; outputStream . flush ( ) ; outputStream . close ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["allow", "HttpResponse", "to", "be", "used", "as", "an", "exception", "."], "add_tokens": "try { Object ret = bindAndInvoke ( node , req , rsp , headArgs ) ; if ( ret instanceof HttpResponse ) { // let the result render the response HttpResponse response = ( HttpResponse ) ret ; response . generateResponse ( req , rsp , node ) ; } } catch ( InvocationTargetException e ) { // exception as an HttpResponse Throwable te = e . getTargetException ( ) ; if ( te instanceof HttpResponse ) ( ( HttpResponse ) te ) . generateResponse ( req , rsp , node ) ;", "del_tokens": "Object ret = bindAndInvoke ( node , req , rsp , headArgs ) ; if ( ret instanceof HttpResponse ) { // let the result render the response HttpResponse response = ( HttpResponse ) ret ; response . generateResponse ( req , rsp , node ) ;", "commit_type": "allow"}
{"commit_tokens": ["Remove", "cyclic", "reference", "Cookies", "now", "only", "depends", "on", "HttpClient", "not", "MechanizeAgent", "."], "add_tokens": "private final Cookies cookies ; this ( new DefaultHttpClient ( ) ) ; this . cookies = new Cookies ( client ) ;", "del_tokens": "private final Cookies cookies = new Cookies ( this ) ; client = new DefaultHttpClient ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "Until", "type", "version", ".", "This", "new", "annotation", "allows", "you", "to", "remove", "members", "from", "the", "JSON", "output", "beginning", "at", "a", "certain", "version", "number", "."], "add_tokens": "import com . google . gson . annotations . Until ; if ( ! isValidSince ( annotation ) || ! isValidUntil ( annotation ) ) { return false ; } } return true ; } private boolean isValidSince ( Annotation annotation ) { if ( annotation instanceof Since ) { double annotationVersion = ( ( Since ) annotation ) . value ( ) ; if ( annotationVersion > version ) { return false ; } } return true ; } private boolean isValidUntil ( Annotation annotation ) { if ( annotation instanceof Until ) { double annotationVersion = ( ( Until ) annotation ) . value ( ) ; if ( annotationVersion <= version ) { return false ;", "del_tokens": "if ( annotation instanceof Since ) { double annotationVersion = ( ( Since ) annotation ) . value ( ) ; if ( annotationVersion > version ) { return false ; }", "commit_type": "add"}
{"commit_tokens": ["Moved", "PMMLObjectUtil", "utility", "class", "from", "pmml", "-", "evaluator", "module", "to", "pmml", "-", "manager", "module"], "add_tokens": "import org . jpmml . manager . PMMLObjectUtil ; // Older versions of several popular PMML producer software are known to omit the classificationMethod attribute. // The method SupportVectorMachineModel#getSvmRepresentation() replaces a missing value with the default value \"OneAgainstAll\", which may lead to incorrect behaviour. // The workaround is to bypass this method using Java Reflection API, and infer the correct classification method type based on evidence. SvmClassificationMethodType svmClassificationMethod = PMMLObjectUtil . getAttributeValue ( supportVectorMachineModel , \"classificationMethod\" ) ;", "del_tokens": "SvmClassificationMethodType svmClassificationMethod = PMMLObjectUtil . getField ( supportVectorMachineModel , \"classificationMethod\" ) ;", "commit_type": "move"}
{"commit_tokens": ["adding", "finish", "listener", "to", "layout"], "add_tokens": "private ViewDragHelper viewDragHelper ; public void setOnFinishListener ( OnFinishListener onFinishListener ) { viewDragHelper = ViewDragHelper . create ( this , 1.0f , new ViewDragHelperCallBack ( onFinishListener ) ) ; } private OnFinishListener onFinishListener = new OnFinishListener ( ) { @ Override public void onFinishState ( ) { finish ( ) ; } } ; public ViewDragHelperCallBack ( ) { } public ViewDragHelperCallBack ( OnFinishListener onFinishListener ) { this . onFinishListener = onFinishListener ; } onFinishListener . onFinishState ( ) ; public interface OnFinishListener { void onFinishState ( ) ; }", "del_tokens": "private final ViewDragHelper viewDragHelper ; finish ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "labels", "from", "the", "output", "of", "TransmissionProbability", "pipeline", "."], "add_tokens": "String output = pair . getKey ( ) + \"\\t\" + pair . getValue ( ) + \"\\n\" ;", "del_tokens": "String output = \"Id : \" + pair . getKey ( ) ; output += \"\\tValue:\" + pair . getValue ( ) + \"\\n\" ;", "commit_type": "remove"}
{"commit_tokens": ["Changing", "the", "commit", "log", "to", "only", "processing", "entries", "that", "are", "commited", "."], "add_tokens": "public synchronized boolean isAlreadyBeingProcessed ( String key ) { add ( key ) ; add ( key ) ; protected void add ( String key ) {", "del_tokens": "public boolean isAlreadyBeingProcessed ( String key ) { public void add ( String key ) {", "commit_type": "change"}
{"commit_tokens": ["fixing", "the", "jpathwatch", "dependency", "groupId", "in", "the", "osgi", "test"], "add_tokens": "wrappedBundle ( mavenBundle ( \"net.sf.jpathwatch\" , \"jpathwatch\" , \"0.95\" ) ) . startLevel ( Constants . START_LEVEL_SYSTEM_BUNDLES ) ,", "del_tokens": "wrappedBundle ( mavenBundle ( \"jpathwatch\" , \"jpathwatch\" , \"0.95\" ) ) . startLevel ( Constants . START_LEVEL_SYSTEM_BUNDLES ) ,", "commit_type": "fix"}
{"commit_tokens": ["change", "the", "name", "list", "filling", "method"], "add_tokens": "import java . util . LinkedList ; //_entries.addAll(Arrays.asList(files)); //Collections.sort(_entries, new Comparator<File>() { // public int compare(File f1, File f2) { // return f1.getName().toLowerCase().compareTo(f2.getName().toLowerCase()); // } //}); List < File > dirList = new LinkedList < > ( ) ; for ( File f : files ) { if ( f . isDirectory ( ) ) { if ( ! f . getName ( ) . startsWith ( \".\" ) ) { dirList . add ( f ) ; } } } sortByName ( dirList ) ; _entries . addAll ( dirList ) ; List < File > fileList = new LinkedList < > ( ) ; for ( File f : files ) { if ( ! f . isDirectory ( ) ) { if ( ! f . getName ( ) . startsWith ( \".\" ) ) { fileList . add ( f ) ; } } } sortByName ( fileList ) ; _entries . addAll ( fileList ) ; } void sortByName ( List < File > list ) { Collections . sort ( list , new Comparator < File > ( ) {", "del_tokens": "import java . util . Arrays ; _entries . addAll ( Arrays . asList ( files ) ) ; Collections . sort ( _entries , new Comparator < File > ( ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "IosView", ".", "query", "()", "method"], "add_tokens": "log . debug ( \"--> {} {}\" , query , message ) ; log . debug ( \"<-- {} {} returned {}\" , new Object [ ] { query , message , response . results } ) ; @ Override public By query ( ) { return query ; }", "del_tokens": "log . debug ( \"Send: {} {}\" , query , message ) ; log . debug ( \"{} {} returned {}\" , new Object [ ] { query , message , response . results } ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "users", "to", "configure", "the", "prefetch", "buffer", "size"], "add_tokens": "private final int bufferSize ; this ( file , separator , shardCount , 0 ) ; } public CloudStorageLineInput ( GcsFilename file , byte separator , int shardCount , int bufferSize ) { this . bufferSize = bufferSize ; result . add ( new CloudStorageLineInputReader ( file , startOffset , endOffset , separator , bufferSize ) ) ;", "del_tokens": "result . add ( new CloudStorageLineInputReader ( file , startOffset , endOffset , separator ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["update", "sdk", "to", "include", "core", "s", "latest", "changes", "."], "add_tokens": "notificationListener = new MFPPushNotificationListener ( ) { @ Override public void onReceive ( final MFPSimplePushNotification message ) { showNotification ( activity , message ) ; }", "del_tokens": "notificationListener = new MFPPushNotificationListener ( ) { @ Override public void onReceive ( final MFPSimplePushNotification message ) { showNotification ( activity , message ) ; }", "commit_type": "update"}
{"commit_tokens": ["remove", "disable", "style", "from", "any", "check", "box", "when", "clicking", "on", "Reset", "Fitlers"], "add_tokens": "clearCheckBox ( checkBox ) ; private void clearCheckBox ( CheckBox checkBox ) { checkBox . setValue ( false ) ; checkBox . setEnabled ( true ) ; checkBox . removeStyleName ( STYLE_DISABLED_CHECK_BOX ) ; }", "del_tokens": "final boolean isChecked = false ; checkBox . setValue ( isChecked ) ; checkBox . setEnabled ( true ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "metric", "for", "figuring", "out", "available", "messagetypes", "for", "host", "specific", "graphs"], "add_tokens": "import javax . servlet . GenericServlet ; public class MetricsServlet extends GenericServlet implements Servlet { private static final long serialVersionUID = - 6704365246281136504L ; metrics . put ( \"/types\" , MessageTypesMetric . class ) ; log ( \"Failed to create metric\" , e ) ;", "del_tokens": "public class MetricsServlet implements Servlet {", "commit_type": "add"}
{"commit_tokens": ["Use", "google", "-", "java", "-", "format", "on", "generated", "code"], "add_tokens": "import com . google . googlejavaformat . java . Formatter ; import com . google . googlejavaformat . java . FormatterException ; writer . append ( new Formatter ( ) . formatSource ( source . toString ( ) ) ) ; } catch ( FormatterException e ) { throw new RuntimeException ( e ) ;", "del_tokens": "writer . append ( source . toString ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "to", "new", "peppol", "-", "commons", "API"], "add_tokens": "import com . helger . peppol . identifier . generic . doctype . IDocumentTypeIdentifier ; import com . helger . peppol . identifier . generic . participant . IParticipantIdentifier ; import com . helger . peppol . identifier . generic . process . IProcessIdentifier ; import com . helger . peppol . identifier . peppol . doctype . IPeppolDocumentTypeIdentifier ; import com . helger . peppol . identifier . peppol . participant . IPeppolParticipantIdentifier ; if ( ! m_aPeppolSenderID . hasScheme ( IPeppolParticipantIdentifier . DEFAULT_SCHEME ) ) if ( ! m_aPeppolReceiverID . hasScheme ( IPeppolParticipantIdentifier . DEFAULT_SCHEME ) ) if ( ! m_aPeppolDocumentTypeID . hasScheme ( IPeppolDocumentTypeIdentifier . DEFAULT_SCHEME ) ) if ( ! m_aPeppolProcessID . hasScheme ( IPeppolParticipantIdentifier . DEFAULT_SCHEME ) )", "del_tokens": "import com . helger . peppol . identifier . IDocumentTypeIdentifier ; import com . helger . peppol . identifier . IParticipantIdentifier ; import com . helger . peppol . identifier . IProcessIdentifier ; if ( ! IdentifierHelper . hasDefaultParticipantIdentifierScheme ( m_aPeppolSenderID ) ) if ( ! IdentifierHelper . hasDefaultParticipantIdentifierScheme ( m_aPeppolReceiverID ) ) if ( ! IdentifierHelper . hasDefaultDocumentTypeIdentifierScheme ( m_aPeppolDocumentTypeID ) ) if ( ! IdentifierHelper . hasDefaultProcessIdentifierScheme ( m_aPeppolProcessID ) )", "commit_type": "update"}
{"commit_tokens": ["Use", "singletonList", "()", "instead", "of", "asList", "()", "when", "only", "one", "argument", "is", "passed", "."], "add_tokens": "exitListener . expectEvents ( Collections . singletonList ( GeoQueryEventTestListener . keyExited ( \"2\" ) ) ) ;", "del_tokens": "exitListener . expectEvents ( Arrays . asList ( GeoQueryEventTestListener . keyExited ( \"2\" ) ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "specifying", "additional", "Hibernate", "metadata"], "add_tokens": "private MetadataContributor metadataContributor ; if ( metadataContributor != null ) { return ( Collection < S > ) Arrays . asList ( domainBinder , metadataContributor ) ; } else { return Collections . singletonList ( ( S ) domainBinder ) ; } public void setMetadataContributor ( MetadataContributor metadataContributor ) { this . metadataContributor = metadataContributor ; }", "del_tokens": "return Collections . < S > singletonList ( ( S ) domainBinder ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "PortalContextAssociationManager", "to", "be", "usable", "from", "within", "the", "engine", "and", "fixed", "lazy", "loading", "for", "all", "cases"], "add_tokens": "package org . camunda . demo . liferay . tasklist . outtake ; import javax . enterprise . context . ConversationScoped ; //@ConversationScoped", "del_tokens": "package org . camunda . demo . liferay . tasklist ;", "commit_type": "fix"}
{"commit_tokens": ["added", "readme", "/", "howto", "for", "integration", "module"], "add_tokens": "* @ param dataset The RDF library specific input to parse", "del_tokens": "* @ param dataset", "commit_type": "add"}
{"commit_tokens": ["Updated", "parser", "to", "support", "namespaced", "attributes", "(", "i", ".", "e", "xml", ":", "lang", "=", "en", ")", "."], "add_tokens": "String key = tq . consumeAttributeKey ( ) ; if ( ! childTag . isEmpty ( ) ) stack . addLast ( child ) ;", "del_tokens": "String key = tq . consumeWord ( ) ; // todo (Must): allow \":\" in key for namespaced attr (e.g. xml:lang) stack . addLast ( child ) ;", "commit_type": "update"}
{"commit_tokens": ["Improve", "the", "logging", "when", "a", "rtmp", "encoder", "error", "occours"], "add_tokens": "Semaphore lock = conn . getEncoderLock ( ) ; if ( Thread . interrupted ( ) ) { log . info ( \"Released lock after encoding error\" ) ; }", "del_tokens": "final Semaphore lock = conn . getEncoderLock ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["Use", "variable", "resolver", "in", "init"], "add_tokens": "if ( variables == null ) { varMap = new HashMap < String , String > ( ) ; } else { varMap = new VariableResolver ( variables ) . getResolved ( ) ;", "del_tokens": "varMap = new HashMap < String , String > ( ) ; if ( variables != null ) { for ( final Variable var : variables ) { varMap . put ( var . getName ( ) , var . getValue ( ) ) ; }", "commit_type": "use"}
{"commit_tokens": ["Fix", "excessive", "backtracking", "bug", "on", "parsing", "larger", "blocks", "of", "opening", "-", "tags", "-", "only", "HTML"], "add_tokens": "", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Made", "removeVariablesSub", "methods", "final", "in", "MultiConstraintSolver", ";", "reinstated", "error", "when", "removing", "variable", "that", "is", "bound", "by", "constraint", ".", "--", "F", "."], "add_tokens": "// continue; throw new IllegalVariableRemoval ( var , this . theNetwork . getIncidentEdges ( var ) ) ;", "del_tokens": "continue ; // throw new IllegalVariableRemoval(var, this.theNetwork.getIncidentEdges(var));", "commit_type": "make"}
{"commit_tokens": ["Remove", "lambda", "and", "java", "8", "compatible", "from", "library"], "add_tokens": "public void onResume ( final Context context ) { new Handler ( ) . post ( new Runnable ( ) { @ Override public void run ( ) { checkLocaleChange ( context ) ; checkAfterLocaleChanging ( ) ; }", "del_tokens": "public void onResume ( Context context ) { new Handler ( ) . post ( ( ) -> { checkLocaleChange ( context ) ; checkAfterLocaleChanging ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "bugs", "related", "to", "RecentMediaFeed", "."], "add_tokens": "private long id ; @ SerializedName ( \"full_name\" ) private String fullName ; public long getId ( ) { public void setId ( long id ) { public String getFullName ( ) { return fullName ; } public void setFullName ( String fullName ) { this . fullName = fullName ; }", "del_tokens": "private int id ; public int getId ( ) { public void setId ( int id ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "failing", "test", "in", "Hudson"], "add_tokens": "public class AnalyzerBeanDescriptor implements Comparable < AnalyzerBeanDescriptor > { if ( analyzerClass == null ) { throw new IllegalArgumentException ( \"analyzerClass cannot be null\" ) ; } @ Override public int compareTo ( AnalyzerBeanDescriptor o ) { String thisAnalyzerClassName = this . getAnalyzerClass ( ) . toString ( ) ; String thatAnalyzerClassName = o . getAnalyzerClass ( ) . toString ( ) ; return thisAnalyzerClassName . compareTo ( thatAnalyzerClassName ) ; }", "del_tokens": "public class AnalyzerBeanDescriptor {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "IndexOutOfBoundsException", "that", "occurs", "when", "@ApplicationPath", "is", "set", "to"], "add_tokens": "while ( ( index > - 1 ) && ( index < builder . length ( ) ) ) { if ( index == builder . length ( ) ) { } } else { }", "del_tokens": "while ( index < builder . length ( ) ) { if ( index == builder . length ( ) ) } else", "commit_type": "fix"}
{"commit_tokens": ["Implementing", "receiveMessage", "operation", "for", "subscription"], "add_tokens": "Message message = receiveMessage ( options , resource ) ; return new ReceiveQueueMessageResult ( message ) ; } private Message receiveMessage ( ReceiveMessageOptions options , WebResource resource ) { return message ; return receiveSubscriptionMessage ( topicName , subscriptionName , ReceiveMessageOptions . DEFAULT ) ; WebResource resource = getResource ( ) . path ( topicName ) . path ( \"subscriptions\" ) . path ( subscriptionName ) . path ( \"messages\" ) . path ( \"head\" ) ; Message message = receiveMessage ( options , resource ) ; return new ReceiveSubscriptionMessageResult ( message ) ;", "del_tokens": "return new ReceiveQueueMessageResult ( message ) ; // TODO Auto-generated method stub return null ; // TODO Auto-generated method stub return null ;", "commit_type": "implement"}
{"commit_tokens": ["fix", "a", "possible", "NPE", "in", "jasper"], "add_tokens": "// STARTJR: fix possible NPE if ( jarFileUrl != null ) { ctxt . getTagFileJarUrls ( ) . put ( path , jarFileUrl ) ; } // ENDJR: fix possible NPE", "del_tokens": "ctxt . getTagFileJarUrls ( ) . put ( path , jarFileUrl ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "id", "for", "the", "sanity", "of", "hashCode", "()"], "add_tokens": "p2 . setId ( 2 ) ; p3 . setId ( 3 ) ; p4 . setId ( 4 ) ; p5 . setId ( 5 ) ; p6 . setId ( 6 ) ;", "del_tokens": "p1 . setId ( 2 ) ; p1 . setId ( 3 ) ; p1 . setId ( 4 ) ; p1 . setId ( 5 ) ; p1 . setId ( 6 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "TimeNode", "private", "methods", "package", "visible", "and", "annotate", "them", "as", "@VisibleForTesting", "."], "add_tokens": "import com . google . common . annotations . VisibleForTesting ; @ VisibleForTesting NearestValue getNearestForwardValue ( int reference , int shiftsToApply ) { @ VisibleForTesting NearestValue getNearestBackwardValue ( int reference , int shiftsToApply ) { @ VisibleForTesting int getValueFromList ( List < Integer > values , int index , AtomicInteger shift ) {", "del_tokens": "private NearestValue getNearestForwardValue ( int reference , int shiftsToApply ) { private NearestValue getNearestBackwardValue ( int reference , int shiftsToApply ) { private int getValueFromList ( List < Integer > values , int index , AtomicInteger shift ) {", "commit_type": "make"}
{"commit_tokens": ["add", "add", "resolution", "attribute", "make", "status", "page", "cleaner"], "add_tokens": "String deviceStr = StringUtils . replace ( StringUtils . substringBetween ( deviceInfo . toStringForDebug ( ) , \"[\" , \"]\" ) , \",\" , \"<br/>\" ) ;", "del_tokens": "String deviceStr = StringUtils . substringBetween ( deviceInfo . toStringForDebug ( ) , \"[\" , \"]\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "for", "spring", "package", "jvm", "options"], "add_tokens": "jvmOptions = jvmOptions . replaceAll ( \"\\n\" , \"\" ) ; jvmOptions = jvmOptions . replaceAll ( \"\\\\s+\" , \" \" ) ;", "del_tokens": "jvmOptions = StringUtils . strip ( jvmOptions , \"\\n\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "issue", "with", "incorrect", "response", "processing"], "add_tokens": "Assert . assertNotNull ( \"Received Object is null\" , to ) ; RecordedRequest request = server . takeRequest ( ) ; Assert . assertEquals ( \"Incorrect Request Line\" , \"GET / HTTP/1.1\" , request . getRequestLine ( ) ) ; } @ Test public void testGetResponse ( ) throws IOException , InterruptedException , ExecutionException { server . enqueue ( prepareResponse ( SERIALIZED_STRING ) ) ; Response < String > to = endpoint . get ( \"/\" , String . class ) . blockingGet ( ) ; Assert . assertNotNull ( \"Received Object is null\" , to ) ; Assert . assertNotNull ( \"Received Body is null\" , to ) ; Assert . assertNotNull ( \"Received Object is null\" , to ) ; Assert . assertNotNull ( \"Received Object is null\" , to ) ; Assert . assertNotNull ( \"Received Object is null\" , to ) ; Assert . assertNotNull ( \"Received Object is null\" , to . getBody ( ) ) ;", "del_tokens": "Assert . assertNotNull ( \"Recieved Object is null\" , to ) ; Assert . assertNotNull ( \"Recieved Object is null\" , to ) ; Assert . assertNotNull ( \"Recieved Object is null\" , to ) ; Assert . assertNotNull ( \"Recieved Object is null\" , to ) ; Assert . assertNotNull ( \"Recieved Object is null\" , to . getBody ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "another", "test", "to", "ensure", "proper", "exception", "gets", "thrown", "when", "no", "proper", "constructor", "can", "be", "found"], "add_tokens": "@ Test ( expected = com . moparisthebest . jdbc . MapperException . class ) public void testNoDefaultConstructorFails ( ) throws Throwable { qm . toObject ( \"SELECT 1, 2, 3 FROM person WHERE person_no = ?\" , Long . class , fieldPerson1 . getPersonNo ( ) ) ; }", "del_tokens": "import java . lang . reflect . Constructor ;", "commit_type": "add"}
{"commit_tokens": ["add", "some", "code", "to", "generate", "code", "that", "drives", "the", "JsonBuilder", ".", "Useful", "for", "generating", "code", "that", "generates", "json", "from", "json", "."], "add_tokens": "@ Override public String builderCode ( ) { StringBuilder buf = new StringBuilder ( ) ; for ( Entry < String , JsonElement > entry : this . entrySet ( ) ) { // buf.append(element.builderCode()); buf . append ( \"\\n_(\\\"\" + entry . getKey ( ) + \"\\\",\" + entry . getValue ( ) . builderCode ( ) + \")\" ) ; buf . append ( ',' ) ; } // remove last comma buf . deleteCharAt ( buf . length ( ) - 1 ) ; return \"$(\" + buf . toString ( ) + \")\\n\" ; } }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", "in", "the", "method"], "add_tokens": "return invokeURL ( format ( SERVICE_URL , uri ) , Equivalence . class ) ; return invokeURL ( format ( SERVICE_KEYWORD , keyword ) , EquivalenceList . class ) ; private < T > T invokeURL ( String toBeInvoked , Class < T > returnType ) throws SameAsServiceException {", "del_tokens": "return invokeULR ( format ( SERVICE_URL , uri ) , Equivalence . class ) ; return invokeULR ( format ( SERVICE_KEYWORD , keyword ) , EquivalenceList . class ) ; private < T > T invokeULR ( String toBeInvoked , Class < T > returnType ) throws SameAsServiceException {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "erroneous", "direct", "dependency", "resolver", "."], "add_tokens": "private static int count = 0 ; public static class Dependency { } public Dependency object ( ) { return new Dependency ( ) ; public Dependency dependency ;", "del_tokens": "static int count = 0 ; public Object object ( ) { return new Object ( ) ; public Object dependency ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "progression", "field", "to", "disease", "."], "add_tokens": "@ JsonProperty ( \"progression\" ) protected List < YearRangeString > _progression ; @ JsonProperty ( \"recurrence\" ) protected List < YearRangeString > _recurrence ; public List < YearRangeString > getProgression ( ) { return _progression ; } public void setProgression ( List < YearRangeString > progression ) { _progression = progression ; }", "del_tokens": "@ JsonProperty ( \"recurrence\" ) protected List < YearRangeString > _recurrence ;", "commit_type": "add"}
{"commit_tokens": ["fix", "line", "numbers", "in", "error", "messages", ".", "(", "start", "with", "1", ".", ")"], "add_tokens": "lineNumber = 1 ; // line number tokens have the line that was _ended_ by the // newline, so we have to add one. lineNumber = Tokens . getLineNumber ( t ) + 1 ;", "del_tokens": "lineNumber = 0 ; lineNumber = Tokens . getLineNumber ( t ) ;", "commit_type": "fix"}
{"commit_tokens": ["Create", "two", "methods", "in", "Utils", "class", "for", "waiting", "on", "replicator", "doc"], "add_tokens": "import com . cloudant . tests . util . Utils ; public void replicatorDB ( ) throws Exception { // we need the replication to finish before continuing Utils . waitForReplicatorToStart ( account , response . getId ( ) ) ; Utils . removeReplicatorTestDoc ( account , response . getId ( ) ) ; String docId = Utils . generateUUID ( ) ;", "del_tokens": "import org . junit . Ignore ; import java . util . UUID ; @ Ignore public void replicatorDB ( ) { // find replicator doc ReplicatorDocument replicatorDoc = account . replicator ( ) . replicatorDocId ( response . getId ( ) ) . find ( ) ; // cancel a replication account . replicator ( ) . replicatorDocId ( replicatorDoc . getId ( ) ) . replicatorDocRev ( replicatorDoc . getRevision ( ) ) . remove ( ) ; String docId = generateUUID ( ) ; private static String generateUUID ( ) { return UUID . randomUUID ( ) . toString ( ) . replace ( \"-\" , \"\" ) ; }", "commit_type": "create"}
{"commit_tokens": ["Added", "proper", "length", "check", "for", "incoming", "messages"], "add_tokens": "public static int getExpectedLength ( byte downlink_format ) { if ( downlink_format < 16 ) return 7 ; else return 14 ; } if ( length != 14 && length != 28 ) // initial test throw new BadFormatException ( \"Raw message has an invalid length of \" + length , raw_message ) ; if ( length != getExpectedLength ( downlink_format ) << 1 ) { throw new BadFormatException ( \"Downlink format \" + downlink_format + \" suggests length \" + getExpectedLength ( downlink_format ) + \" but input has length \" + length , raw_message ) ; }", "del_tokens": "if ( length != 14 && length != 28 ) throw new BadFormatException ( \"Raw message has invalid length\" , raw_message ) ;", "commit_type": "add"}
{"commit_tokens": ["Removing", "builder", "and", "using", "GenericInvokableBuilderImpl", "directly"], "add_tokens": "import com . qubole . qds . sdk . java . entities . CommandResponse ; public InvokableBuilder < CommandResponse > dbTapQuery ( String query , int db_tap_id ) ;", "del_tokens": "public DbTapQueryCommandBuilder dbTapQuery ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "in", "-", "memory", "data", "store", "[", "ci", "skip", "]"], "add_tokens": "return new InMemoryDataStoreServiceImpl < TestObject , String > ( ) { } ;", "del_tokens": "return new InMemoryDataStoreServiceImpl < TestObject , String > ( ) { } ;", "commit_type": "update"}
{"commit_tokens": ["Make", "Guice", "<", "-", ">", "Jackson", "cross", "injection", "more", "generic", "."], "add_tokens": "import com . netflix . suro . TypeHolder ; import java . util . Set ; public DefaultObjectMapper ( final Injector injector , Set < TypeHolder > crossInjectable ) if ( crossInjectable != null ) { for ( TypeHolder entry : crossInjectable ) { LOG . info ( \"Registering subtype : \" + entry . getName ( ) + \" -> \" + entry . getRawType ( ) . getCanonicalName ( ) ) ; registerSubtypes ( new NamedType ( entry . getRawType ( ) , entry . getName ( ) ) ) ;", "del_tokens": "import com . netflix . suro . sink . SinkType ; import java . util . Map ; import java . util . Map . Entry ; public DefaultObjectMapper ( final Injector injector , Map < String , SinkType > sinks ) if ( sinks != null ) { for ( Entry < String , SinkType > entry : sinks . entrySet ( ) ) { LOG . info ( \"Registering subtype : \" + entry . getKey ( ) + \" -> \" + entry . getValue ( ) . getRawType ( ) . getCanonicalName ( ) ) ; registerSubtypes ( new NamedType ( entry . getValue ( ) . getRawType ( ) , entry . getKey ( ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Make", "PojoSink", "methods", "protected", "to", "be", "able", "to", "override", "them"], "add_tokens": "* * protected Class target ; protected Class childrenType ; protected Consumer < Object > consumer ; protected String childrenFieldName = null ; protected final Consumer < Map < String , Object > > devNullConsumer ; protected Map < String , Object > unmappedFields ; protected Object convert ( Class pojoType , Row currentRow ) { protected void mapChildren ( Object parent , List < Row > children ) { protected Object newInstance ( Class clazz ) throws IllegalStateException { protected static Pair < String , Class < ? extends Object > > getChildInfo ( Class target ) {", "del_tokens": "* * private Class target ; private Class childrenType ; private Consumer < Object > consumer ; private String childrenFieldName = null ; private final Consumer < Map < String , Object > > devNullConsumer ; private Map < String , Object > unmappedFields ; Object convert ( Class pojoType , Row currentRow ) { void mapChildren ( Object parent , List < Row > children ) { Object newInstance ( Class clazz ) throws IllegalStateException { static Pair < String , Class < ? extends Object > > getChildInfo ( Class target ) {", "commit_type": "make"}
{"commit_tokens": ["Fixed", "the", "top", "gravity", "support", "and", "dimming"], "add_tokens": ": getPaddingTop ( ) - panelHeight + mPanelHeight + slidePixelOffset ; if ( drawScrim && mCoveredFadeColor != 0 ) {", "del_tokens": ": getPaddingTop ( ) + slidePixelOffset ; if ( drawScrim && mCoveredFadeColor > 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["moved", "calculate", "method", "to", "abstract", "class", "and", "made", "it", "generic", "for", "Double", "and", "Float", "and", "added", "tests", "for", "Double", "precision"], "add_tokens": "return Math . pow ( ( double ) args [ 0 ] , ( double ) args [ 1 ] ) ;", "del_tokens": "return ( double ) args [ 0 ] % ( double ) args [ 1 ] ;", "commit_type": "move"}
{"commit_tokens": ["Added", ":", "Update", "to", "newer", "snapshot", "of", "MockServer", "."], "add_tokens": "public InputStream getResponseConfigFromFile ( String relativePath ) throws IOException { return context . getAssets ( ) . open ( \"mock/\" + relativePath ) ; public InputStream getStaticFile ( String relativePath ) throws IOException { String path = getStaticFilePath ( relativePath ) ; return context . getAssets ( ) . open ( path ) ; } @ Override public boolean isFolder ( String relativePath ) { try { String path = getStaticFilePath ( relativePath ) ; return context . getAssets ( ) . list ( path ) . length > 0 ; } catch ( IOException e ) { return false ; } private String getStaticFilePath ( String relativePath ) { return \"mock/static\" + relativePath ;", "del_tokens": "import android . content . res . AssetManager ; public InputStream getResponseConfigFromFile ( String fileName ) throws IOException { return context . getAssets ( ) . open ( \"mock/\" + fileName ) ; public InputStream getStaticFile ( String fileName ) throws IOException { String path = \"mock/static\" + fileName ; AssetManager assets = context . getAssets ( ) ; if ( assets . list ( path ) . length > 0 ) { return assets . open ( path + \"/index.html\" ) ; return assets . open ( path ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "up", "tick", "and", "doSnapshotWorks", "so", "they", "will", "be", "invoked", "on", "a", "regular", "basis", "even", "if", "there", "is", "no", "incoming", "work", "at", "an", "execution", "site", "."], "add_tokens": "public void tick ( ) { doSnapshotWork ( ) ; // sing it: stay'n alive.. m_watchdog . pet ( ) ; } / * * * Set the txn id from the WorkUnit and set / release undo tokens as * necessary . The DTXN currently has no notion of maintaining undo * tokens beyond the life of a transaction so it is up to the execution * site to release the undo data in the EE up until the current point * when the transaction ID changes . * / public final void beginNewTxn ( long txnId , boolean readOnly ) {", "del_tokens": "/ * * * Set the txn id from the WorkUnit and set / release undo tokens as * necessary . The DTXN currently has no notion of maintaining undo * tokens beyond the life of a transaction so it is up to the execution * site to release the undo data in the EE up until the current point * when the transaction ID changes . * / public final void beginNewTxn ( long txnId , boolean readOnly ) { // sing it: stay'n alive.. m_watchdog . pet ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "another", "syntax", "for", "atMost"], "add_tokens": "public ConditionFactory atMost ( Duration timeout ) {", "del_tokens": "public ConditionFactory waitAtMost ( Duration timeout ) {", "commit_type": "implement"}
{"commit_tokens": ["Implemented", "virtual", "keypad", "functionality", "with", "example"], "add_tokens": "return \"This command enables/disables the virtual keypad. When enabled, all virtual keypad commands (Virt) from the application will be processed. All virtual keypad responses (i.e., menu, status lights updates) are automatically initiated by the IT-100 and sent to the application. When this command is disabled all virtual keypad commands (Virt) are ignored. The IT-100 does not send a response to this command unless there is a system error.\" ;", "del_tokens": "return \"This command enables/disables the virtual keypad. When enabled, all virtual keypad commands (Virt) from the application will be processed. All virtual keypad responses (i.e., menu, status lights updates) are automatically initiated by the IT-100 and sent to the application. When this com- mand is disabled all virtual keypad commands (Virt) are ignored. The IT-100 does not send a response to this command unless there is a system error.\" ;", "commit_type": "implement"}
{"commit_tokens": ["Remove", "no", "-", "store", "from", "Cache", "-", "control", "http", "header", "when", "returning", "manifest", "file"], "add_tokens": "response . setHeader ( \"Cache-control\" , \"no-cache, must-revalidate, pre-check=0, post-check=0\" ) ;", "del_tokens": "response . setHeader ( \"Cache-control\" , \"no-cache, no-store, must-revalidate, pre-check=0, post-check=0\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "no", "unique", "maximal", "instance", "message"], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) // The (T) cast prevents the commandline javac from choking \"no unique maximal instance\" return ( T ) this . mapper . convertValue ( data , this . resultType ) ;", "del_tokens": "return this . mapper . convertValue ( data , this . resultType ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "id", "to", "bottomLayout", "and", "modify", "condition", "to", "initialize", "animableView", "with", "a", "view", "or", "other", "inside", "ExpandablePanelView"], "add_tokens": "if ( animableViewId != DEFAULT_ANIMABLE_VIEW_ID ) { if ( animableView == null ) { throw new IllegalArgumentException ( \"Review your layout, you don't have a child of \" + \"ExpandablePanelView view with id \" + animableViewId ) ; }", "del_tokens": "if ( animableViewId == DEFAULT_ANIMABLE_VIEW_ID ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "context", "to", "exception", "to", "ease", "debugging", "."], "add_tokens": "import static java . lang . String . format ; final String unsafeLabelName = rule . labelNames . get ( i ) ; final String labelValReplacement = rule . labelValues . get ( i ) ; try { String labelName = safeName ( matcher . replaceAll ( unsafeLabelName ) ) ; String labelValue = matcher . replaceAll ( labelValReplacement ) ; if ( lowercaseOutputLabelNames ) { labelName = labelName . toLowerCase ( ) ; } if ( ! labelName . isEmpty ( ) && ! labelValue . isEmpty ( ) ) { labelNames . add ( labelName ) ; labelValues . add ( labelValue ) ; } } catch ( Exception e ) { throw new RuntimeException ( format ( \"Matcher '%s' unable to use: '%s' value: '%s'\" , matcher , unsafeLabelName , labelValReplacement ) , e ) ; }", "del_tokens": "String labelName = safeName ( matcher . replaceAll ( rule . labelNames . get ( i ) ) ) ; String labelValue = matcher . replaceAll ( rule . labelValues . get ( i ) ) ; if ( lowercaseOutputLabelNames ) { labelName = labelName . toLowerCase ( ) ; } if ( ! labelName . isEmpty ( ) && ! labelValue . isEmpty ( ) ) { labelNames . add ( labelName ) ; labelValues . add ( labelValue ) ; }", "commit_type": "add"}
{"commit_tokens": ["added", "new", "examples", "and", "support", "for", "subdocuments"], "add_tokens": "import org . apache . spark . api . java . JavaRDD ; public static < T extends IDeepType > void saveEntity ( JavaRDD < T > rdd , IMongoDeepJobConfig < T > config ) {", "del_tokens": "public static < T extends IDeepType > void saveEntity ( MongoJavaRDD < T > rdd , IMongoDeepJobConfig < T > config ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "better", "reporting", "for", "the", "messaging", "with", "RabbitMQ"], "add_tokens": "this . logger . info ( \"Loading application from \" + applicationFilesDirectory + \"...\" ) ;", "del_tokens": "this . logger . fine ( \"Loading application from \" + applicationFilesDirectory + \"...\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "functionality", "to", "install", "runtimes", "from", "Open", "Liberty", "repo"], "add_tokens": "private boolean useOpenLiberty ; if ( useOpenLiberty ) { // Download from the Open Liberty repo OpenLibertyInstaller installer = new OpenLibertyInstaller ( ) ; installer . setVersion ( version ) ; installer . setType ( type ) ; installer . install ( this ) ; } else { // Download from the Wasdev repo WasDevInstaller installer = new WasDevInstaller ( ) ; installer . setVersion ( version ) ; installer . setLicenseCode ( licenseCode ) ; installer . setType ( type ) ; installer . install ( this ) ; } public void setUseOpenLiberty ( boolean useOpenLiberty ) { this . useOpenLiberty = useOpenLiberty ; } public boolean getUseOpenLiberty ( ) { return useOpenLiberty ; }", "del_tokens": "WasDevInstaller installer = new WasDevInstaller ( ) ; installer . setVersion ( version ) ; installer . setLicenseCode ( licenseCode ) ; installer . setType ( type ) ; installer . install ( this ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "better", "suited", "status", "code", "when", "an", "invalid", "token", "is", "received", "on", "the", "check", "code", "method"], "add_tokens": "throw new AuthyException ( \"Invalid Token. Only digits accepted.\" , HttpURLConnection . HTTP_BAD_REQUEST , throw new AuthyException ( \"Invalid Token. Unexpected length.\" , HttpURLConnection . HTTP_BAD_REQUEST ,", "del_tokens": "throw new AuthyException ( \"Invalid Token. Only digits accepted.\" , HttpURLConnection . HTTP_UNAUTHORIZED , throw new AuthyException ( \"Invalid Token. Unexpected length.\" , HttpURLConnection . HTTP_UNAUTHORIZED ,", "commit_type": "use"}
{"commit_tokens": ["Add", "get", "group", "by", "path"], "add_tokens": "return getGroup ( groupId . toString ( ) ) ; } / * * * Get a group by path * * @ param path Path of the group * @ return * @ throws IOException * / public GitlabGroup getGroup ( String path ) throws IOException { String tailUrl = GitlabGroup . URL + \"/\" + path ;", "del_tokens": "String tailUrl = GitlabGroup . URL + \"/\" + groupId ;", "commit_type": "add"}
{"commit_tokens": ["use", "link", "urls", "in", "pax", "runner", "container"], "add_tokens": "url ( \"link:classpath:META-INF/links/org.ops4j.pax.exam.rbc.link\" ) , url ( \"link:classpath:META-INF/links/org.ops4j.pax.extender.service.link\" ) , url ( \"link:classpath:META-INF/links/org.osgi.compendium.link\" ) //url( \"link:classpath:META-INF/links/org.ops4j.pax.logging.api.link\" ), } ; / * * * * / public void cleanup ( ) m_target . cleanup ( ) ;", "del_tokens": "mavenBundle ( ) . groupId ( \"org.ops4j.pax.exam\" ) . artifactId ( \"pax-exam-container-rbc\" ) . version ( Info . getPaxExamVersion ( ) ) . update ( Info . isPaxExamSnapshotVersion ( ) ) . startLevel ( START_LEVEL_SYSTEM_BUNDLES ) , public void cleanup ( ) m_target . cleanup ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "method", "to", "search", "images", "on", "Docker", "Hub"], "add_tokens": "import com . spotify . docker . client . messages . ImageSearchResult ; private static final GenericType < List < ImageSearchResult > > IMAGES_SEARCH_RESULT_LIST = new GenericType < List < ImageSearchResult > > ( ) { } ; @ Override public List < ImageSearchResult > searchImages ( final String term ) throws DockerException , InterruptedException { final WebTarget resource = resource ( ) . path ( \"images\" ) . path ( \"search\" ) . queryParam ( \"term\" , term ) ; return request ( GET , IMAGES_SEARCH_RESULT_LIST , resource , resource . request ( APPLICATION_JSON_TYPE ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "ehcache", "as", "hibernate", "second", "level", "cache"], "add_tokens": "import javax . persistence . * ; @ Cacheable", "del_tokens": "import javax . persistence . Column ; import javax . persistence . Entity ; import javax . persistence . GeneratedValue ; import javax . persistence . Id ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bluetooth", "enabling", ".", "my", "bad", ":", ">"], "add_tokens": "return isBluetoothAvailable ( ) && ( enabled ? mBluetoothAdapter . enable ( )", "del_tokens": "return ! isBluetoothAvailable ( ) && ( enabled ? mBluetoothAdapter . enable ( )", "commit_type": "fix"}
{"commit_tokens": ["fixes", "bug", "in", "ImgFilter", ".", "applyTo", "(", "img", "x", "y", "w", "h", ")", "which", "applied", "to", "whole", "image", "instead", "of", "specified", "region"], "add_tokens": "{ applyTo ( img , false , x , y , width , height ) ; }", "del_tokens": "{ applyTo ( img , false , 0 , 0 , img . getWidth ( ) , img . getHeight ( ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Removing", "newlines", "to", "improve", "coverage"], "add_tokens": "private Iterators ( ) { }", "del_tokens": "private Iterators ( ) { }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "mock", "in", "bytestring", "test"], "add_tokens": "when ( ahcResponse . getResponseBody ( ) ) . thenReturn ( \"wsBody\" ) ; verify ( ahcResponse , times ( 1 ) ) . getResponseBody ( ) ; public void testBodyAsDefault ( ) { final Response ahcResponse = mock ( Response . class ) ; final StandaloneAhcWSResponse response = new StandaloneAhcWSResponse ( ahcResponse ) ; when ( ahcResponse . getContentType ( ) ) . thenReturn ( null ) ; when ( ahcResponse . getResponseBody ( ) ) . thenReturn ( \"wsBody\" ) ; final String body = response . getBody ( ) ; verify ( ahcResponse , times ( 1 ) ) . getResponseBody ( ) ; assertThat ( body ) . isEqualTo ( \"wsBody\" ) ; }", "del_tokens": "import play . libs . ws . DefaultBodyWritables ; when ( ahcResponse . getResponseBody ( StandardCharsets . UTF_8 ) ) . thenReturn ( \"wsBody\" ) ; verify ( ahcResponse , times ( 1 ) ) . getResponseBody ( StandardCharsets . UTF_8 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "default", "value", "for", "the", "RosettaProperty", "it", "has", "become", "clear", "that", "this", "can", "be", "used", "in", "conjunction", "with", "an", "@JsonIgnore", "so", "that", "rosetta", "uses", "the", "value", "when", "jackson", "does", "not", "."], "add_tokens": "String USE_DEFAULT_NAME = \"\" ; String value ( ) default USE_DEFAULT_NAME ;", "del_tokens": "String value ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "remaining", "usages", "of", "LocationImpl", "getCharactedOffset", "()", "to", "include", "BOM", "length"], "add_tokens": "final XMLStreamReaderImpl . LocationImpl loc = reader . getLocation ( ) ; length = loc . getCharacterOffset ( ) + loc . getBomLength ( ) ; final XMLStreamReaderImpl . LocationImpl loc = reader . getLocation ( ) ; vars . length = ( int ) ( loc . getCharacterOffset ( ) + loc . getBomLength ( ) - vars . offset ) ;", "del_tokens": "length = reader . getLocation ( ) . getCharacterOffset ( ) ; vars . length = ( int ) ( reader . getLocation ( ) . getCharacterOffset ( ) - vars . offset ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improved", "Fluent", "Answer", "fixed", "tests"], "add_tokens": "import org . camunda . bpm . engine . query . Query ; import java . util . List ; assertThat ( mock . asc ( ) ) . isEqualTo ( mock ) ; static class FluentBuilder implements SomeAspect , Query < FluentBuilder , Object > { @ Override public FluentBuilder asc ( ) { return null ; } @ Override public FluentBuilder desc ( ) { return null ; } @ Override public long count ( ) { return 0 ; } @ Override public Object singleResult ( ) { return null ; } @ Override public List < Object > list ( ) { return null ; } @ Override public List < Object > listPage ( final int firstResult , final int maxResults ) { return null ; }", "del_tokens": "import static org . mockito . Mockito . verify ; static class FluentBuilder implements SomeAspect {", "commit_type": "improve"}
{"commit_tokens": ["Allow", "for", "more", "wiggle", "room", "in", "table", "overlap", "ratio", "to", "correctly", "merge", "more", "tables"], "add_tokens": "private static final float IDENTICAL_TABLE_OVERLAP_RATIO = 0.9f ;", "del_tokens": "private static final float IDENTICAL_TABLE_OVERLAP_RATIO = 0.98f ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "deps", ".", "Fixed", "rtmptransport", "setup", "."], "add_tokens": "mina . setAddress ( \"0.0.0.0:1935\" ) ;", "del_tokens": "import java . net . InetSocketAddress ; mina . setConnector ( new InetSocketAddress ( \"0.0.0.0\" , 1935 ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "double", "-", "click", "anomaly", "."], "add_tokens": "Events . echoEvent ( Events . ON_CLICK , btnView , null ) ;", "del_tokens": "Events . postEvent ( Events . ON_CLICK , btnView , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "pom", "and", "docs", "for", "release"], "add_tokens": "* @ see # withDelay ( long , TimeUnit ) * @ see # withBackoff ( long , long , TimeUnit ) * @ see # withBackoff ( long , long , TimeUnit , int ) * @ see # withBackoff ( long , long , TimeUnit , int ) * @ see # withBackoff ( long , long , TimeUnit ) * @ see # withMaxDuration ( long , TimeUnit )", "del_tokens": "* @ see # withDelay ( Duration ) * @ see # withBackoff ( Duration , Duration ) * @ see # withBackoff ( Duration , Duration , int ) * @ see # withBackoff ( Duration , Duration , int ) * @ see # withBackoff ( Duration , Duration ) * @ see # withMaxDuration ( Duration )", "commit_type": "update"}
{"commit_tokens": ["Made", "client", "HTTP", "setup", "more", "failure", "tolerant"], "add_tokens": "@ Nonnull SSLConnectionSocketFactory aSSLSocketFactory = null ; aSSLSocketFactory = new SSLConnectionSocketFactory ( aSSLContext , new String [ ] { \"TLSv1\" } , null , SSLConnectionSocketFactory . getDefaultHostnameVerifier ( ) ) ; } catch ( final Throwable t ) { s_aLogger . error ( \"Failed to initialize keystore for service connection! Can only use http now!\" , t ) ; } try { final RegistryBuilder < ConnectionSocketFactory > aRB = RegistryBuilder . < ConnectionSocketFactory > create ( ) . register ( \"http\" , PlainConnectionSocketFactory . getSocketFactory ( ) ) ; if ( aSSLSocketFactory != null ) aRB . register ( \"https\" , aSSLSocketFactory ) ; final Registry < ConnectionSocketFactory > sfr = aRB . build ( ) ;", "del_tokens": "final SSLConnectionSocketFactory aSSLSocketFactory = new SSLConnectionSocketFactory ( aSSLContext , new String [ ] { \"TLSv1\" } , null , SSLConnectionSocketFactory . getDefaultHostnameVerifier ( ) ) ; final Registry < ConnectionSocketFactory > sfr = RegistryBuilder . < ConnectionSocketFactory > create ( ) . register ( \"http\" , PlainConnectionSocketFactory . getSocketFactory ( ) ) . register ( \"https\" , aSSLSocketFactory ) . build ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Adds", "new", "BitStore", "implementation", "for", "a", "single", "mutable", "bit", "."], "add_tokens": "//TODO could optimize further abstract class ImmutableBit extends AbstractBitStore { // fundamental methods // fundamental methods // accelerating methods @ Override public long getBits ( int position , int length ) { switch ( position ) { case 0 : switch ( length ) { case 0 : return 0L ; case 1 : return 1L ; } break ; case 1 : if ( length == 0L ) return 0L ; break ; } throw new IllegalArgumentException ( ) ; } // fundamental methods // accelerating methods @ Override public long getBits ( int position , int length ) { switch ( position ) { case 0 : switch ( length ) { case 0 : return 0L ; case 1 : return 0L ; } break ; case 1 : if ( length == 0L ) return 0L ; break ; } throw new IllegalArgumentException ( ) ; }", "del_tokens": "//TODO could optimize a lot abstract class ImmutableBit implements BitStore {", "commit_type": "add"}
{"commit_tokens": ["added", "checkstyle", "plugin", "disabled", "test", "failures", "due", "to", "checkstyle", "warnings", "for", "now", "until", "they", "can", "be", "cleaned", "up"], "add_tokens": "/ * * * Provides constants for all of the supported configuration options * for the mini clusters . * * @ author Shane Kumpf * / }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "problems", "with", "log4j"], "add_tokens": "for ( Field f : clazz . getDeclaredFields ( ) ) { if ( ! f . isAccessible ( ) ) f . setAccessible ( true ) ; String name = f . getName ( ) ; if ( \"title\" . equals ( name ) ) { assertEquals ( \"jwbf-generic\" , f . get ( clazz ) ) ; } else if ( \"version\" . equals ( name ) ) { assertEquals ( \"DEVEL\" , f . get ( clazz ) ) ; } } else { // TODO test load from inner MF", "del_tokens": "} for ( Field f : clazz . getDeclaredFields ( ) ) { if ( ! f . isAccessible ( ) ) f . setAccessible ( true ) ; String name = f . getName ( ) ; if ( \"title\" . equals ( name ) ) { assertEquals ( \"jwbf-generic\" , f . get ( clazz ) ) ; } else if ( \"version\" . equals ( name ) ) { assertEquals ( \"DEVEL\" , f . get ( clazz ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "test", "cases", "to", "run", "correctly", "in", "UTC", "mode", "and", "update", "readme", "with", "testing", "instructions", "."], "add_tokens": "import com . loadimpact . util . DateUtils ; GregorianCalendar calendar = new GregorianCalendar ( 2013 , 10 - 1 , 30 , 9 , 30 , 0 ) ; calendar . setTimeZone ( TimeZone . getTimeZone ( \"UTC\" ) ) ; assertThat ( jsonObject . toString ( ) , is ( \"{\\\"name\\\":\\\"aaa\\\",\\\"url\\\":\\\"http://foo.com\\\",\\\"created\\\":\\\"2013-10-30T09:30:00Z\\\",\\\"updated\\\":\\\"2013-10-30T09:30:00Z\\\",\\\"config\\\":{\\\"user_type\\\":\\\"sbu\\\"}}\" ) ) ;", "del_tokens": "GregorianCalendar calendar = new GregorianCalendar ( TimeZone . getTimeZone ( \"CET\" ) ) ; calendar . set ( 2013 , 10 - 1 , 30 , 9 , 30 , 0 ) ; assertThat ( jsonObject . toString ( ) , is ( \"{\\\"name\\\":\\\"aaa\\\",\\\"url\\\":\\\"http://foo.com\\\",\\\"created\\\":\\\"2013-10-30T09:30:00+01:00\\\",\\\"updated\\\":\\\"2013-10-30T09:30:00+01:00\\\",\\\"config\\\":{\\\"user_type\\\":\\\"sbu\\\"}}\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "custom", "validation", "test", "to", "use", "a", "bundle"], "add_tokens": "m . addError ( \"custom_message\" , \"message.for.custom.validator\" ) ; a ( p . errors ( ) . get ( \"custom_message\" ) ) . shouldBeEqual ( \"this is a test message!\" ) ;", "del_tokens": "m . addError ( \"custom_message\" , \"this is a test message!\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "minQueryLength", "support", "to", "kotlin", "extension"], "add_tokens": "if ( ! isDisposed ( ) && newQuery != null && newQuery . length ( ) >= minQueryLength ) {", "del_tokens": "if ( ! isDisposed ( ) && newQuery != null && newQuery . length ( ) > minQueryLength ) {", "commit_type": "add"}
{"commit_tokens": ["changed", "jvntextprowrapper", "to", "re", "-", "create", "the", "jvntextpro", "-", "object", "everytime", "the", "wrapper", "s", ".", "process", "()", "method", "gets", "called", "to", "avoid", "built", "up", "clutter", "from", "jvntextpro", "s", ".", "process", "()", "method", "that", "results", "in", "a", "garbage", "collection", "exception", "after", "a", "few", "calls", "."], "add_tokens": "createJVnTextProObject ( ) ; } private void createJVnTextProObject ( ) { / * * necessary every time . process ( ) gets called because calling jvntp . process ( ) * multiple times will result in a garbage collection OOM exception . wonky * implementation of JVnTextPro here . * / createJVnTextProObject ( ) ;", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["Add", "listed", "count", "in", "StreamUser", "class"], "add_tokens": "/ * * * * / private static final long serialVersionUID = 3558927430206936262L ; public enum Operation { public void setListedCount ( long listedCount ) { this . listedCount = listedCount ; } public long getListedCount ( ) { return listedCount ; }", "del_tokens": "public enum Operation {", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "cases", "with", "UTC", "vs", "CET", "issues", "."], "add_tokens": "GregorianCalendar calendar = new GregorianCalendar ( TimeZone . getTimeZone ( \"CET\" ) ) ; calendar . set ( 2013 , 10 - 1 , 30 , 9 , 30 , 0 ) ; Date date = calendar . getTime ( ) ;", "del_tokens": "Date date = new GregorianCalendar ( 2013 , 10 - 1 , 30 , 9 , 30 , 0 ) . getTime ( ) ; // System.out.println(\"jsonObject = \" + jsonObject); // System.out.println(\"jsonObject = \" + jsonObject);", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "environment", "destroy", "hook"], "add_tokens": "WebDriverCreationHook hooker = SenBotContext . getSenBotContext ( ) . getSeleniumManager ( ) . getWebDriverCreationHook ( ) ; ; if ( hooker != null ) { hooker . webdriverDestroyed ( webDriver ) ; }", "del_tokens": "* @ param webDriverConstructor", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "List<String", ">"], "add_tokens": "import java . util . ArrayList ; Orange orange = new Orange ( ) ; orange . content = new ArrayList < > ( ) ; orange . content . add ( \"First\" ) ; orange . content . add ( \"Second\" ) ; selectedFruit = orange ;", "del_tokens": "selectedFruit = new Orange ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "that", "call", "graph", "uses", "the", "self", "time", "of", "calls", "as", "the", "total", "time"], "add_tokens": "parentCall . setChildrenTime ( parentCall . getChildrenTime ( ) . plus ( call . getTime ( ) ) ) ;", "del_tokens": "parentCall . setTime ( parentCall . getTime ( ) . minus ( call . getTime ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "constructor", "javadocs", "and", "test", "for", "DAO<T", "V", ">", ";", "test", "needs", "to", "catch", "exception"], "add_tokens": "/ * * * < p > Only calls this from your derived class when you explicitly declare the generic types with concrete classes < / p > * < p > { @ code class MyDao extends DAO < MyEntity , String > } < / p > * * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "tests", "to", "relocate", "common", "filter", "authentication", "functionality", "to", "an", "abstract", "parent", "."], "add_tokens": "request . setContextPath ( \"/bigWebApp\" ) ; assertEquals ( \"/bigWebApp/hello\" , response . getRedirect ( ) ) ;", "del_tokens": "assertEquals ( \"/hello\" , response . getRedirect ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Made", "request", "building", "more", "robust", "."], "add_tokens": "String [ ] queryParams = queryString . split ( \"\\\".*?\\\".+&\" ) ; // ($string =~ /(\".*?\"|\\S+)/g);", "del_tokens": "String [ ] queryParams = queryString . split ( \"&\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "datatore", "from", "path", "and", "prepare", "for", "release"], "add_tokens": "return validateUrl ( String . format ( \"http://%s/%s/projects/%s\" ,", "del_tokens": "return validateUrl ( String . format ( \"http://%s/datastore/%s/projects/%s\" ,", "commit_type": "remove"}
{"commit_tokens": ["Changed", "networkStream", "to", "socketStream", "and", "pluggableNetworkStream", "to", "become", "networkStream", "as", "a", "way", "to", "create", "streams", "from", "arbitrary", "network", "receiver", "."], "add_tokens": "JavaDStream < String > lines = ssc . socketTextStream ( args [ 1 ] , Integer . parseInt ( args [ 2 ] ) ) ;", "del_tokens": "JavaDStream < String > lines = ssc . networkTextStream ( args [ 1 ] , Integer . parseInt ( args [ 2 ] ) ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "a", "way", "to", "load", "existing", "Properties", "instances"], "add_tokens": "public final class SystemPropertiesReader extends PropertiesReader { public SystemPropertiesReader ( ) { super ( System . getProperties ( ) ) ;", "del_tokens": "import java . util . Properties ; public final class SystemPropertiesReader implements ConfigurationReader < Properties > { / * * * { @ inheritDoc } * / public Properties readConfiguration ( ) throws Exception { return System . getProperties ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "operation", "fixup", "gated", "by", "Fast", "Property"], "add_tokens": "import com . netflix . config . DynamicBooleanProperty ; import com . netflix . evcache . util . EVCacheConfig ; final DynamicBooleanProperty fixup = EVCacheConfig . getInstance ( ) . getDynamicBooleanProperty ( _appName + \".addOperation.fixup\" , Boolean . FALSE ) ; if ( getPendingCount ( ) == 0 && fixup . get ( ) ) {", "del_tokens": "if ( getPendingCount ( ) == 0 ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "element", "for", "method", "and", "constructor", "invocations"], "add_tokens": "import tools . devnull . trugger . reflection . Execution ; import tools . devnull . trugger . util . registry . MapRegistry ; import tools . devnull . trugger . util . registry . Registry ; import java . util . LinkedHashMap ; import java . util . List ; import java . util . Map ; import java . util . Properties ; import java . util . ResourceBundle ; import static tools . devnull . trugger . reflection . ClassPredicates . type ; registry . register ( new ExecutionElementFinder ( ) ) . to ( type ( Execution . class ) ) ;", "del_tokens": "import tools . devnull . trugger . util . registry . MapRegistry ; import tools . devnull . trugger . util . registry . Registry ; import java . util . * ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "debug", "output", "for", "some", "look", "behind", "operations", "."], "add_tokens": "for ( i = 0 , q = s ; i < 7 && q < end && s >= 0 ; i ++ ) { while ( len -- > 0 ) if ( q < end ) Config . log . print ( new String ( new byte [ ] { bytes [ q ++ ] } ) ) ;", "del_tokens": "for ( i = 0 , q = s ; i < 7 && q < end ; i ++ ) { while ( len -- > 0 ) if ( q < this . end ) Config . log . print ( new String ( new byte [ ] { bytes [ q ++ ] } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "methods", "static", "because", "I", "could"], "add_tokens": "static String applyEscapes ( String input ) { private static boolean isEscaped ( String input , int index ) {", "del_tokens": "String applyEscapes ( String input ) { private boolean isEscaped ( String input , int index ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "space", "after", "clip", "reference", "for", "images", "."], "add_tokens": "this . sb . append ( getClipPathRef ( ) ) . append ( \" \" ) ; this . sb . append ( getClipPathRef ( ) ) . append ( \" \" ) ;", "del_tokens": "this . sb . append ( getClipPathRef ( ) ) ; this . sb . append ( getClipPathRef ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "JavaDoc", "for", "TPCH3", "Query", "to", "new", "filter", "constraints"], "add_tokens": "* the TPC - H benchmark including one join , some filtering and an * aggregation . * AND o_orderstatus = \"X\" * AND YEAR ( o_orderdate ) > Y * AND o_orderpriority LIKE \"Z%\" * Filters the orders table by year , orderstatus and orderpriority * * o_orderstatus = \"X\" * AND YEAR ( o_orderdate ) > Y * AND o_orderpriority LIKE \"Z\" / * * * { @ inheritDoc } * /", "del_tokens": "* the TPC - H benchmark including a join , aggregation , filtering and * projection . * AND o_custkey IN [ X ] * AND o_orderdate > [ Y ] * Filters the orders table by custKey and orderDate * TODO * o_custkey IN [ X ] AND o_orderdate > [ Y ] * o_orderstatus = \"F\" AND year ( o_orderdate ) = 1993 * AND o_orderPriority LIKE \"5%\"", "commit_type": "update"}
{"commit_tokens": ["Allow", "to", "overwrite", "alert", "properties", "via", "-", "D"], "add_tokens": "String value = System . getProperty ( key ) ; if ( value == null ) { value = alertsProperties . getProperty ( key , defaultValue ) ; } return value ;", "del_tokens": "return alertsProperties . getProperty ( key , defaultValue ) ;", "commit_type": "allow"}
{"commit_tokens": ["Changed", "to", "nonstatic", "to", "better", "detect", "name", "clashes"], "add_tokens": "private final Map < String , String > map = new HashMap < > ( ) ; public String makeJavaIdentifier ( String id ) public String makeJavaClassname ( String id )", "del_tokens": "private static final Map < String , String > map = new HashMap < > ( ) ; public static String makeJavaIdentifier ( String id ) public static String makeJavaClassname ( String id )", "commit_type": "change"}
{"commit_tokens": ["created", "decent", "monitor", "home", "page"], "add_tokens": "try { oOutput . writeObject ( serializable ) ; } finally { oOutput . close ( ) ; fStream . close ( ) ; } Serializable retval = null ; try { retval = ( Serializable ) oInput . readObject ( ) ; } finally { oInput . close ( ) ; fStream . close ( ) ; }", "del_tokens": "oOutput . writeObject ( serializable ) ; oOutput . close ( ) ; fStream . close ( ) ; Serializable retval = ( Serializable ) oInput . readObject ( ) ; oInput . close ( ) ; fStream . close ( ) ;", "commit_type": "create"}
{"commit_tokens": ["Change", "checkbox", "on", "drawables", "by", "transformation", "maps"], "add_tokens": "import java . io . FileNotFoundException ; import android . graphics . Color ; R . drawable . ha__text_select_handle_right_transformation , R . drawable . ha__btn_check_on_transformation , R . drawable . ha__btn_check_on_transformation_light // try { // Bitmap bitmap; // bitmap = getBitmapFromResource(R.drawable.btn_check_on_transformation, value); // bitmap = BitmapUtils.createTintTransformationMap(bitmap, Color.RED); // BitmapUtils.writeToFile(bitmap, \"\", \"ha__btn_check_on_transformation.png\"); // // bitmap = getBitmapFromResource(R.drawable.btn_check_on_transformation_light, value); // bitmap = BitmapUtils.createTintTransformationMap(bitmap, Color.RED); // BitmapUtils.writeToFile(bitmap, \"\", \"ha__btn_check_on_transformation_light.png\"); // } catch (FileNotFoundException e) { // // TODO Auto-generated catch block // e.printStackTrace(); // } catch (IOException e) { // // TODO Auto-generated catch block // e.printStackTrace(); // }", "del_tokens": "private static final int [ ] DARK_TINT_DRAWABLE_IDS = new int [ ] { R . drawable . ha__btn_check_comp_on_accent } ; R . drawable . ha__text_select_handle_right_transformation for ( int id : DARK_TINT_DRAWABLE_IDS ) { if ( resId == id ) return getTintendResourceStream ( resId , value , mPalette . getDarkAccentColor ( ) ) ; }", "commit_type": "change"}
{"commit_tokens": ["fixed", "a", "bug", "where", "fragmented", "placeholders", "were", "not", "replaced", "correctly"], "add_tokens": "run . replace ( matchStartIndex , matchEndIndex , \"\" ) ;", "del_tokens": "run . replace ( affectedRunsMatchStartIndex , affectedRunsMatchEndIndex , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "a", "small", "issue", "blocking", "me", "to", "run", "multiple", "tests", "in", "a", "test", "case", "."], "add_tokens": "if ( ! mBeanServer . isRegistered ( objectName ) ) mBeanServer . registerMBean ( classLoader , objectName ) ;", "del_tokens": "mBeanServer . registerMBean ( classLoader , objectName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "latex", "entension", "plugin", "module"], "add_tokens": "import android . support . annotation . ColorInt ; import android . support . annotation . Px ; public Builder tableCellPadding ( @ Px int tableCellPadding ) { public Builder tableBorderColor ( @ ColorInt int tableBorderColor ) { public Builder tableBorderWidth ( @ Px int tableBorderWidth ) { public Builder tableOddRowBackgroundColor ( @ ColorInt int tableOddRowBackgroundColor ) { public Builder tableEvenRowBackgroundColor ( @ ColorInt int tableEvenRowBackgroundColor ) { public Builder tableHeaderRowBackgroundColor ( @ ColorInt int tableHeaderRowBackgroundColor ) {", "del_tokens": "public Builder tableCellPadding ( int tableCellPadding ) { public Builder tableBorderColor ( int tableBorderColor ) { public Builder tableBorderWidth ( int tableBorderWidth ) { public Builder tableOddRowBackgroundColor ( int tableOddRowBackgroundColor ) { public Builder tableEvenRowBackgroundColor ( int tableEvenRowBackgroundColor ) { public Builder tableHeaderRowBackgroundColor ( int tableHeaderRowBackgroundColor ) {", "commit_type": "improve"}
{"commit_tokens": ["Add", "a", "few", "more", "tests"], "add_tokens": "private boolean shouldRetain ; // true -> not release native object, false -> release by free() long handle ; // hold pointer to alloc_slice* // constructors //------------------------------------------------------------------------- // public methods //------------------------------------------------------------------------- //------------------------------------------------------------------------- // private methods //------------------------------------------------------------------------- //------------------------------------------------------------------------- // native methods //------------------------------------------------------------------------- static native long init ( byte [ ] bytes ) ; static native void free ( long slice ) ; static native byte [ ] getBuf ( long slice ) ; static native long getSize ( long slice ) ;", "del_tokens": "static native long init ( byte [ ] bytes ) ; static native void free ( long slice ) ; static native byte [ ] getBuf ( long slice ) ; static native long getSize ( long slice ) ; private boolean shouldRetain ; // true -> not release native object, false -> release by free() long handle ; // hold pointer to alloc_slice* // public methods //------------------------------------------------------------------------- // native methods //-------------------------------------------------------------------------", "commit_type": "add"}
{"commit_tokens": ["Adding", "some", "tests", "for", "QueryManager"], "add_tokens": "import sherpa . protocol . CancelRequest ; public final int rows ; public List < String > messages = new ArrayList < String > ( ) ; public void record ( Object ... pairs ) { StringBuilder str = new StringBuilder ( ) ; int i = 0 ; while ( i < pairs . length ) { str . append ( pairs [ i ++ ] + \"=\" + pairs [ i ++ ] + \" \" ) ; } messages . add ( str . toString ( ) ) ; } record ( \"Message\" , \"query\" , \"sparql\" , query . sparql , \"params\" , query . parameters , \"props\" , query . properties ) ; record ( \"Message\" , \"data\" , \"queryId\" , dataRequest . queryId , \"startRow\" , dataRequest . startRow , \"maxSize\" , dataRequest . maxSize ) ; record ( \"Message\" , \"cancel\" , \"queryId\" , cancel . queryId ) ; record ( \"Message\" , \"close\" , \"queryId\" , close . queryId ) ;", "del_tokens": "import sherpa . protocol . CancelRequest ; private final int rows ;", "commit_type": "add"}
{"commit_tokens": ["remove", "antiquated", "comment", "about", "upper", "limits", "on", "expiration", "time"], "add_tokens": "* @ throws IllegalArgumentException if { @ code duration } is not positive * @ throws IllegalArgumentException if { @ code duration } is not positive", "del_tokens": "* @ throws IllegalArgumentException if { @ code duration } is not positive , or is * larger than one hundred years * @ throws IllegalArgumentException if { @ code duration } is not positive , or is * larger than one hundred years", "commit_type": "remove"}
{"commit_tokens": ["add", "a", "few", "methods", "to", "facilitate", "integration", "with", "java", "8", "streams", "API", "."], "add_tokens": "import java . util . function . BiConsumer ; import java . util . function . BiFunction ; import java . util . stream . Stream ; JsonElement e = entry . getValue ( ) . deepClone ( ) ; object . put ( entry . getKey ( ) , e ) ; public Stream < JsonElement > map ( BiFunction < String , JsonElement , JsonElement > f ) { return entrySet ( ) . stream ( ) . map ( e -> f . apply ( e . getKey ( ) , e . getValue ( ) ) ) ; } public void forEachString ( BiConsumer < String , String > f ) { forEach ( ( k , v ) -> { f . accept ( k , v . asString ( ) ) ; } ) ; }", "del_tokens": "object . put ( entry . getKey ( ) , entry . getValue ( ) . deepClone ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "for", "initial", "setting", "of", "predicates", "/", "processors"], "add_tokens": "if ( lenientSelector == null ) { predicates = getPredicates ( expectedMessageCount ) ; processors = getProcessors ( expectedMessageCount ) ; }", "del_tokens": "predicates = getPredicates ( expectedMessageCount ) ; processors = getProcessors ( expectedMessageCount ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "up", "some", "error", "messages", "."], "add_tokens": "Preconditions . checkArgument ( bit_rate > 0 , \"bitrate must be positive\" ) ; Preconditions . checkArgument ( isValidSize ( width ) , \"Width must be -1 or greater than zero\" ) ; Preconditions . checkArgument ( isValidSize ( height ) , \"Height must be -1 or greater than zero\" ) ; \"Both width and height must be -1 or greater than zero\" ) ; Preconditions . checkArgument ( channels > 0 , \"channels must be positive\" ) ; Preconditions . checkArgument ( sample_rate > 0 , \"sample rate must be positive\" ) ; Preconditions . checkArgument ( bit_rate > 0 , \"bitrate must be positive\" ) ; Preconditions . checkArgument ( quality >= 1 && quality <= 5 , \"quality must be in the range 1..5\" ) ; Preconditions . checkArgument ( targetSize > 0 , \"target size must be positive\" ) ; Preconditions . checkArgument ( bitrate > 0 , \"bitrate must be positive\" ) ;", "del_tokens": "Preconditions . checkArgument ( bit_rate > 0 ) ; Preconditions . checkArgument ( isValidSize ( width ) , \"Width must be valid greater than 0\" ) ; Preconditions . checkArgument ( isValidSize ( height ) , \"Height must be valid greater than 0\" ) ; \"Both width and height must be valid resolutions\" ) ; Preconditions . checkArgument ( channels > 0 ) ; Preconditions . checkArgument ( sample_rate > 0 ) ; Preconditions . checkArgument ( bit_rate > 0 ) ; Preconditions . checkArgument ( quality >= 1 && quality <= 5 ) ; Preconditions . checkArgument ( targetSize > 0 ) ; Preconditions . checkArgument ( bitrate > 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "ThymeleafAutoConfiguration", "works", "if", "imported", "directly"], "add_tokens": "@ ConditionalOnClass ( name = \"nz.net.ultraq.web.thymeleaf.LayoutDialect\" )", "del_tokens": "@ ConditionalOnClass ( { LayoutDialect . class } )", "commit_type": "make"}
{"commit_tokens": ["Added", "timestamp", "to", "timeline", "directory", "creation", ".", "--", "F", "."], "add_tokens": "import java . text . SimpleDateFormat ; import java . util . Date ; SimpleDateFormat sdf = new SimpleDateFormat ( \"yyyy-MM-dd-HH:mm:ss\" ) ; Date date = new Date ( Calendar . getInstance ( ) . getTimeInMillis ( ) ) ; String time = sdf . format ( date ) ; this . filePath = filePath + \"-\" + time ;", "del_tokens": "this . filePath = filePath ;", "commit_type": "add"}
{"commit_tokens": ["using", "the", "latest", "GH", "master", "(", "SPTEntry", "renaming", ")"], "add_tokens": "import com . graphhopper . storage . SPTEntry ; SPTEntry entry = createEdgeEntry ( node , weight ) ; SPTEntry old = fromMap . get ( node ) ; SPTEntry tmp1 = fromMap . get ( node ) ;", "del_tokens": "import com . graphhopper . storage . EdgeEntry ; EdgeEntry entry = createEdgeEntry ( node , weight ) ; EdgeEntry old = fromMap . get ( node ) ; EdgeEntry tmp1 = fromMap . get ( node ) ;", "commit_type": "use"}
{"commit_tokens": ["Made", "code", "use", "dependency", "injection", "to", "make", "it", "more", "testable"], "add_tokens": "import gsonpath . generator . AdapterGeneratorDelegate ; import gsonpath . generator . Generator ; import gsonpath . model . InterfaceFieldInfo ; import gsonpath . model . InterfaceInfo ; class ModelInterfaceGenerator extends Generator { AdapterGeneratorDelegate adapterGeneratorDelegate = new AdapterGeneratorDelegate ( ) ; ClassName outputClassName = ClassName . get ( modelClassName . packageName ( ) , adapterGeneratorDelegate . generateClassName ( modelClassName , \"GsonPathModel\" ) ) ;", "del_tokens": "import gsonpath . generator . BaseAdapterGenerator ; class ModelInterfaceGenerator extends BaseAdapterGenerator { @ Override protected String getClassNameSuffix ( ) { return \"GsonPathModel\" ; } ClassName outputClassName = ClassName . get ( modelClassName . packageName ( ) , generateClassName ( modelClassName ) ) ; static class InterfaceInfo { ClassName parentClassName ; InterfaceFieldInfo [ ] fieldInfo ; InterfaceInfo ( ClassName parentClassName , InterfaceFieldInfo [ ] fieldInfo ) { this . parentClassName = parentClassName ; this . fieldInfo = fieldInfo ; } } static class InterfaceFieldInfo { Element methodElement ; TypeName typeName ; String fieldName ; InterfaceFieldInfo ( Element methodElement , TypeName typeName , String fieldName ) { this . methodElement = methodElement ; this . typeName = typeName ; this . fieldName = fieldName ; } }", "commit_type": "make"}
{"commit_tokens": ["Improved", "JsonModel", "map", "()", "functionality", "."], "add_tokens": "if ( obj instanceof Map ) { return JSONObject . toJSONString ( ( Map < String , ? extends Object > ) obj ) ; } else if ( obj instanceof List ) { return JSONArray . toJSONString ( ( List < ? extends Object > ) obj ) ; } else { throw new UnsupportedOperationException ( obj . getClass ( ) . getName ( ) + \" can not be converted to JSON\" ) ; }", "del_tokens": "if ( ! ( obj instanceof JSONAware ) ) { throw new InvalidJsonException ( ) ; } JSONAware aware = ( JSONAware ) obj ; return aware . toJSONString ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "uuid", "generation", "in", "audit", "events"], "add_tokens": "* @ param object an object return ;", "del_tokens": "* @ param object an object", "commit_type": "add"}
{"commit_tokens": ["Added", "expression", "for", "setting", "jmeterIgnoreFailure", "from", "the", "command", "line"], "add_tokens": "* @ parameter expression = $ { jmeterIgnoreFailure }", "del_tokens": "* @ parameter", "commit_type": "add"}
{"commit_tokens": ["Add", "@OnClick", "method", "injection", "."], "add_tokens": "import butterknife . OnClick ; @ OnClick ( R . id . hello ) void sayHello ( ) { Toast . makeText ( SimpleActivity . this , \"Hello, views!\" , LENGTH_SHORT ) . show ( ) ; }", "del_tokens": "import android . view . View ; import static android . view . View . OnClickListener ; hello . setOnClickListener ( new OnClickListener ( ) { @ Override public void onClick ( View v ) { Toast . makeText ( SimpleActivity . this , \"Hello, views!\" , LENGTH_SHORT ) . show ( ) ; } } ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "check", "for", "operation", "types", "(", "in", "trades", ")"], "add_tokens": "trades . add ( new Trade ( Operation . buyAt ( 0 ) , Operation . sellAt ( 1 ) ) ) ; trades . add ( new Trade ( Operation . buyAt ( 2 ) , Operation . sellAt ( 3 ) ) ) ; trades . add ( new Trade ( Operation . buyAt ( 4 ) , Operation . sellAt ( 5 ) ) ) ; Trade trade = new Trade ( Operation . buyAt ( 0 ) , Operation . sellAt ( 1 ) ) ; trade = new Trade ( Operation . buyAt ( 1 ) , Operation . sellAt ( 2 ) ) ;", "del_tokens": "trades . add ( new Trade ( Operation . buyAt ( 0 ) , Operation . buyAt ( 1 ) ) ) ; trades . add ( new Trade ( Operation . buyAt ( 2 ) , Operation . buyAt ( 3 ) ) ) ; trades . add ( new Trade ( Operation . buyAt ( 4 ) , Operation . buyAt ( 5 ) ) ) ; Trade trade = new Trade ( Operation . buyAt ( 0 ) , Operation . buyAt ( 1 ) ) ; trade = new Trade ( Operation . buyAt ( 1 ) , Operation . buyAt ( 2 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "type", "Vector2", "."], "add_tokens": "if ( col != 0 || m . getColumnCount ( ) > 1 || row < 0 || row + m . getRowCount ( ) > getDimension ( ) )", "del_tokens": "if ( m . getColumnCount ( ) > 1 || row + m . getRowCount ( ) > getDimension ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "LIVETRIBE", "-", "78", ":", "Attributes", ".", "intersect", "()", "is", "buggy", "again", "."], "add_tokens": "* If a tag in the given < code > Attributes < / code > object contains the globbing character '*' , all attributes in this * < code > Attributes < / code > object that match will be retained . Attributes result = new Attributes ( ) ; for ( Iterator < Tag > tags = attributes . keySet ( ) . iterator ( ) ; tags . hasNext ( ) ; ) if ( tagToRetain . matches ( tag ) ) result . attributes . put ( tag , attributes . get ( tag ) ) ;", "del_tokens": "Attributes result = new Attributes ( this ) ; for ( Iterator < Tag > tags = result . attributes . keySet ( ) . iterator ( ) ; tags . hasNext ( ) ; ) if ( ! tagToRetain . matches ( tag ) ) tags . remove ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "the", "version", "in", "RaygunClientMessage"], "add_tokens": "setVersion ( \"3.0.5\" ) ;", "del_tokens": "setVersion ( \"3.0.0\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "setters", "to", "agiga", "document"], "add_tokens": "&& com . google . common . base . Objects . equal ( corefs , o . corefs ) ; //&& com.google.common.base.Objects.equal(prefs, o.prefs); public void setSents ( List < AgigaSentence > sents ) { this . sents = sents ; }", "del_tokens": "&& com . google . common . base . Objects . equal ( corefs , o . corefs ) && com . google . common . base . Objects . equal ( prefs , o . prefs ) ; public boolean eq ( Object a , Object b ) { // this is how java implements equals // test with two lists that contain null (they're equal) if ( a == null && b == null ) return true ; if ( a != null ) return a . equals ( b ) ; else return b . equals ( a ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "final", "modifier", "to", "synchronization", "object"], "add_tokens": "private final Map < String , PropertyDesc > propertyMap = Collections . synchronizedMap ( new LinkedHashMap < > ( ) ) ;", "del_tokens": "private Map < String , PropertyDesc > propertyMap = Collections . synchronizedMap ( new LinkedHashMap < > ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "missing", "versions", "in", "pom", "file", "and", "fix", "dateutils", "test", "cases", "breaking", "on", "non", "-", "CEST", "based", "systems", "."], "add_tokens": "GregorianCalendar expected = new GregorianCalendar ( TimeZone . getTimeZone ( \"UTC\" ) ) ; expected . set ( 2013 , 9 - 1 , 9 , 2 , 34 , 51 ) ; GregorianCalendar date = new GregorianCalendar ( TimeZone . getTimeZone ( \"UTC\" ) ) ; date . set ( 2013 , 9 - 1 , 9 , 2 , 34 , 51 ) ; GregorianCalendar expected = new GregorianCalendar ( TimeZone . getTimeZone ( \"CET\" ) ) ; expected . set ( 2013 , 9 - 1 , 10 , 17 , 38 , 36 ) ; GregorianCalendar c = new GregorianCalendar ( TimeZone . getTimeZone ( \"UTC\" ) ) ;", "del_tokens": "GregorianCalendar expected = new GregorianCalendar ( 2013 , 9 - 1 , 9 , 2 + 2 , 34 , 51 ) ; GregorianCalendar date = new GregorianCalendar ( 2013 , 9 - 1 , 9 , 2 , 34 , 51 ) ; GregorianCalendar expected = new GregorianCalendar ( 2013 , 8 , 10 , 17 , 38 , 36 ) ; GregorianCalendar c = new GregorianCalendar ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "multiple", "nodes", "in", "config"], "add_tokens": "int found = - 1 ; found = 0 ; found = i ; if ( found == - 1 ) { Node node = config . item ( found ) ;", "del_tokens": "boolean found = false ; found = true ; if ( ! found ) { Node node = config . item ( 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["moving", "addHeaders", "method", "to", "super", "class", "(", "RestMetricsDispatcher", ")"], "add_tokens": "import org . apache . http . client . fluent . Request ; public void postPayload ( String payload ) { Request postReq = Request . Post ( extension . getRestUri ( ) ) ; postReq . bodyString ( payload , ContentType . APPLICATION_JSON ) ; postReq = addHeaders ( postReq ) ; postReq . execute ( ) ; public Request addHeaders ( Request req ) { checkNotNull ( req ) ; for ( Map . Entry < String , String > entry : extension . getHeaders ( ) . entrySet ( ) ) { req . addHeader ( entry . getKey ( ) , entry . getValue ( ) ) ; } return req ; }", "del_tokens": "import static org . apache . http . client . fluent . Request . Post ; private void postPayload ( String payload ) { Post ( extension . getRestUri ( ) ) . bodyString ( payload , ContentType . APPLICATION_JSON ) . execute ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "the", "logging", "in", "the", "Ant", "task", "to", "display", "what", "the", "task", "is", "about", "to", "perform", "like", "other", "Ant", "tasks", "instead", "of", "what", "has", "been", "done"], "add_tokens": "log ( \"Creating debian package: \" + deb ) ; log ( \"Creating changes file: \" + changesOut ) ; log ( \"Saving changes to file: \" + changesSave ) ; changesProvider . save ( new FileOutputStream ( changesSave ) ) ;", "del_tokens": "log ( \"Created \" + deb ) ; log ( \"Created changes file \" + changesOut ) ; changesProvider . save ( new FileOutputStream ( changesSave ) ) ; log ( \"Saved changes to file \" + changesSave ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "Tags", "property", "to", "LogMsg"], "add_tokens": "import java . util . List ; / * * * List of Tags * / @ JsonProperty ( \"Tags\" ) private final List < String > tags ; / * * * @ return the List of Tags * / public List < String > getTags ( ) { return tags ; } . srcLine ( this . srcLine ) . tags ( this . tags ) ; this . tags = builder . tags ; / * * * The builder 's tags * / @ JsonProperty ( \"Tags\" ) private List < String > tags ; / * * * Sets the builder 's tags * @ param tags A list of tags associated to this LogMsg * @ return Reference to the current object * / public Builder tags ( final List < String > tags ) { this . tags = tags ; return this ; }", "del_tokens": ". srcLine ( this . srcLine ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "constructor", "with", "Mongo", "connection", "instead", "of", "URI"], "add_tokens": "import com . mongodb . Mongo ; private Mongo mongo ; / * * * < p > Constructor takes db . mongodb . Mongo object as a parameter . * < / p > < p > For more details about Mongo please see com . mongodb . Mongo * < / p > * @ param mongo uri to your db * @ see Mongo * / public Mongobee ( Mongo mongo ) { this . mongo = mongo ; this . dao = new ChangeEntryDao ( ) ; } if ( this . mongo != null ) { dao . connectMongoDb ( this . mongo , dbName ) ; } else { dao . connectMongoDb ( this . mongoClientURI , dbName ) ; }", "del_tokens": "dao . connectMongoDb ( mongoClientURI , dbName ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "classes", "SetOfMolecules", "ChemModel", "ChemSequence", "and", "ChemFile", "."], "add_tokens": "chemObjects . removeElement ( col ) ;", "del_tokens": "chemObjects . remove ( col ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "few", "minor", "bugs"], "add_tokens": "* * < p > This class keeps also track of the number of bytes read so far , so * to be able to implemented { @ link MeasurableInputStream # position ( ) } * independently of underlying input stream . * { @ link MeasurableInputStream } , then also * { @ link MeasurableInputStream # length ( ) } will work as expected . / * * The number of bytes ever read ( reset upon a call to { @ link # position ( long ) } ) . * In particular , this will always represent the index ( in the underlying input stream ) * of the first available byte in the buffer . * / else if ( noMoreCharacters ( ) ) { readBytes += read ; return read ; }", "del_tokens": "* { @ link MeasurableInputStream } , then the additional methods therein * specified will work as expected , and will not throw an * { @ link UnsupportedOperationException } . /** The number of bytes ever read (reset upon a call to {@link #position(long)}. */ else if ( noMoreCharacters ( ) ) return i ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "AO", "Fluent", "HTML", "for", "HTML", "generation", "."], "add_tokens": "import com . aoindustries . html . Html ; public void doView ( ServletContext servletContext , HttpServletRequest request , HttpServletResponse response , Html html , Page page ) throws ServletException , IOException , SkipPageException {", "del_tokens": "public void doView ( ServletContext servletContext , HttpServletRequest request , HttpServletResponse response , Page page ) throws ServletException , IOException , SkipPageException {", "commit_type": "use"}
{"commit_tokens": ["Add", "FragmentUnitTestCase", "for", "android", "-", "junit4", "-", "robolectric"], "add_tokens": "public FragmentUnitTestCase ( Class < T > fragmentClass ) { mFragmentClass = fragmentClass ;", "del_tokens": "public FragmentUnitTestCase ( Class < T > activityClass ) { mFragmentClass = activityClass ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "CASSANDRA", "-", "9", "JIRA", "."], "add_tokens": "import java . io . FileOutputStream ; / * * * Flushes the current memtable to disk . * * @ author alakshman * * / class Flusher implements Runnable { private CommitLog . CommitLogContext cLogCtx_ ; Flusher ( CommitLog . CommitLogContext cLogCtx ) { cLogCtx_ = cLogCtx ; } public void run ( ) { ColumnFamilyStore cfStore = Table . open ( table_ ) . getColumnFamilyStore ( cfName_ ) ; MemtableManager . instance ( ) . submit ( cfName_ , Memtable . this , cLogCtx_ ) ; } } /* Submit this Memtable to be flushed. */ Runnable flusher = new Flusher ( cLogCtx ) ; apartments_ . get ( cfName_ ) . submit ( flusher ) ; // MemtableManager.instance().submit(cfStore.getColumnFamilyName(), this, cLogCtx); ColumnFamily . serializer2 ( ) . serialize ( columnFamily , buffer ) ; ColumnFamily . serializer2 ( ) . serialize ( columnFamily , buffer ) ;", "del_tokens": "MemtableManager . instance ( ) . submit ( cfStore . getColumnFamilyName ( ) , this , cLogCtx ) ; ColumnFamily . serializer2 ( ) . serialize ( columnFamily , buffer ) ; ColumnFamily . serializer2 ( ) . serialize ( columnFamily , buffer ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "reading", "of", "runtime", "properties"], "add_tokens": "System . setProperty ( \"jreadline.editmode\" , \"vi\" ) ; System . setProperty ( \"jreadline.historypersistent\" , \"false\" ) ; System . setProperty ( \"jreadline.historydisabled\" , \"true\" ) ; System . setProperty ( \"jreadline.historysize\" , \"42\" ) ; System . setProperty ( \"jreadline.logging\" , \"false\" ) ; System . setProperty ( \"jreadline.disablecompletion\" , \"true\" ) ; assertEquals ( Settings . getInstance ( ) . getEditMode ( ) , Mode . VI ) ; assertEquals ( Settings . getInstance ( ) . isHistoryPersistent ( ) , false ) ; assertEquals ( Settings . getInstance ( ) . isHistoryDisabled ( ) , true ) ; assertEquals ( Settings . getInstance ( ) . getHistorySize ( ) , 42 ) ; assertEquals ( Settings . getInstance ( ) . isLogging ( ) , false ) ; assertEquals ( Settings . getInstance ( ) . isDisableCompletion ( ) , true ) ; System . setProperty ( \"jreadline.terminal\" , \"\" ) ; System . setProperty ( \"jreadline.editmode\" , \"\" ) ; System . setProperty ( \"jreadline.historypersistent\" , \"\" ) ; System . setProperty ( \"jreadline.historydisabled\" , \"\" ) ; System . setProperty ( \"jreadline.historysize\" , \"\" ) ; System . setProperty ( \"jreadline.logging\" , \"\" ) ; System . setProperty ( \"jreadline.disablecompletion\" , \"\" ) ; Settings . getInstance ( ) . resetToDefaults ( ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "make", "requests", "optional", "in", "config", "file", "."], "add_tokens": "JSONArray jsonArrayOfRequests = configJson . has ( ConfigKeys . REQUESTS ) ? configJson . getJSONArray ( ConfigKeys . REQUESTS ) : new JSONArray ( ) ;", "del_tokens": "JSONArray jsonArrayOfRequests = configJson . getJSONArray ( ConfigKeys . REQUESTS ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "content", "-", "available", "builder", "+", "unit", "tests"], "add_tokens": "import static org . junit . Assert . assertTrue ; import static org . junit . Assert . assertNull ; . categories ( \"sports\" , \"world cup\" ) @ Test public void contentAvailable ( ) { UnifiedMessage unifiedMessage = new UnifiedMessage . Builder ( ) . alert ( \"Hello from Java Sender API, via JUnit\" ) . sound ( \"default\" ) . contentAvailable ( ) . build ( ) ; assertTrue ( ( Boolean ) unifiedMessage . getAttributes ( ) . get ( \"content-available\" ) ) ; } @ Test public void noContentAvailable ( ) { UnifiedMessage unifiedMessage = new UnifiedMessage . Builder ( ) . alert ( \"Hello from Java Sender API, via JUnit\" ) . sound ( \"default\" ) . build ( ) ; assertNull ( unifiedMessage . getAttributes ( ) . get ( \"content-available\" ) ) ; }", "del_tokens": "import java . util . HashSet ; import java . util . Set ; . categories ( \"sports\" , \"world cup\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "unit", "test", "to", "check", "the", "actuality", "of", "the", "UAS", "data", "DTD"], "add_tokens": "/ * * * Path to the internal Document Type Definition ( DTD ) of UAS data files to be able to work completely offline * / protected static final String UASDATA_DEF = \"uadetector/uasxmldata.dtd\" ; / * * * URL to the Document Type Definition ( DTD ) of UAS data files * / protected static final String UASDATA_DEF_URL = \"http://user-agent-string.info/rpc/uasxmldata.dtd\" ; private StringBuilder buffer = new StringBuilder ( ) ; if ( UASDATA_DEF_URL . equals ( systemId ) ) {", "del_tokens": "private StringBuilder buffer = new StringBuilder ( ) ; / * * * Path to the internal Document Type Definition ( DTD ) of UAS data files to be able to work completely offline * / private static final String UASDATA_DEF = \"uadetector/uasxmldata.dtd\" ; if ( \"http://user-agent-string.info/rpc/uasxmldata.dtd\" . equals ( systemId ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "not", "working", "numbered", "backreferences", "with", "\\", "k", "syntax", "."], "add_tokens": "if ( syntax . strictCheckBackref ( ) && ( backNum > env . numMem || env . memNodes == null ) ) { newValueException ( ERR_INVALID_BACKREF ) ; token . type = TokenType . BACKREF ; token . setBackrefByName ( false ) ; token . setBackrefNum ( 1 ) ; token . setBackrefRef1 ( backNum ) ;", "del_tokens": "if ( syntax . strictCheckBackref ( ) ) { if ( backNum > env . numMem || env . memNodes == null ) newValueException ( ERR_INVALID_BACKREF ) ; token . type = TokenType . BACKREF ; token . setBackrefByName ( false ) ; token . setBackrefNum ( 1 ) ; token . setBackrefRef1 ( backNum ) ;", "commit_type": "fix"}
{"commit_tokens": ["improving", "the", "heatmap", "plotting", "routine"], "add_tokens": "import java . awt . Dimension ; sb . append ( \"SAXBitmap CLI converter v.0.1\" ) . append ( CR ) ; chart . setAxisThickness ( 0 ) ; chart . setTitle ( BitmapParameters . IN_FILE ) ; chart . setCellSize ( new Dimension ( 64 , 64 ) ) ; chart . saveToFile ( new File ( \"my-chart.png\" ) ) ; } else if ( 64 == shingledData . size ( ) ) { double [ ] [ ] heatmapData = new double [ 8 ] [ 8 ] ; int counter = 0 ; for ( String shingle : keys ) { Integer value = shingledData . get ( shingle ) ; heatmapData [ counter / 8 ] [ counter % 8 ] = value ; counter ++ ; } HeatChart chart = new HeatChart ( heatmapData ) ; chart . setAxisThickness ( 0 ) ; chart . setTitle ( BitmapParameters . IN_FILE ) ; chart . setCellSize ( new Dimension ( 32 , 32 ) ) ;", "del_tokens": "sb . append ( \"SAXBitmap CLI converter v.1\" ) . append ( CR ) ; // Create some dummy data. // Create our heat chart using our data. // Customise the chart. chart . setTitle ( \"This is my chart title\" ) ; chart . setXAxisLabel ( \"X Axis\" ) ; chart . setYAxisLabel ( \"Y Axis\" ) ; // Output the chart to a file.", "commit_type": "improve"}
{"commit_tokens": ["Removed", "no", "longer", "used", "read", "and", "write", "keys"], "add_tokens": "public RelayingSocketHandler ( final InetSocketAddress serverAddress ) {", "del_tokens": "public RelayingSocketHandler ( final InetSocketAddress serverAddress , final byte [ ] readKey , final byte [ ] writeKey ) {", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "problem", "with", "refactored", "JodaWorkingWeek", "."], "add_tokens": "int dayOfWeek = jodaToCalendarDayConstant ( date . getDayOfWeek ( ) ) ; return isWorkingDayFromCalendar ( dayOfWeek ) ; public JodaWorkingWeek withWorkingDayFromDateTimeConstant ( final boolean working , int dayOfWeek ) { dayOfWeek = jodaToCalendarDayConstant ( dayOfWeek ) ;", "del_tokens": "return isWorkingDayFromCalendar ( date . getDayOfWeek ( ) ) ; public JodaWorkingWeek withWorkingDayFromDateTimeConstant ( final boolean working , final int dayOfWeek ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "DEBUG", "logging", "from", "AbstractClient", "and", "WorkerImpl", "."], "add_tokens": "doEnqueue ( queue , ObjectMapperFactory . get ( ) . writeValueAsString ( job ) ) ;", "del_tokens": "final String msg = ObjectMapperFactory . get ( ) . writeValueAsString ( job ) ; log . debug ( \"enqueue queue={} msg={}\" , queue , msg ) ; doEnqueue ( queue , msg ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "flush", "methods", ".", "Created", "some", "tests"], "add_tokens": "this . stylesContainer . addNewDataStyleFromCellStyle ( style ) ; final DataStyle dataStyle = style . getDataStyle ( ) ; this . stylesContainer . addDataStyle ( dataStyle ) ;", "del_tokens": "final DataStyle dataStyle = style . getDataStyle ( ) ; assert dataStyle != null ; this . stylesContainer . addDataStyle ( dataStyle ) ; this . stylesContainer . addStyleToContentAutomaticStyles ( style ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "infinite", "loop", "translating", "format", "strings", "when", "there", "are", "format"], "add_tokens": "while ( isFormatFlagCharacter ( c ) && ++ i < str . length ( ) ) { c = str . charAt ( i ) ; / * * * Returns true if a specified character can be used as part of a format * specifier flag . For example , \"%-02d\" has '-' , '0' and '2' characters * to define the specifier flag for \"%d\" . * / private boolean isFormatFlagCharacter ( char c ) { return Character . isDigit ( c ) || c == '-' || c == '#' || c == '+' || c == ' ' || c == ',' || c == '(' || c == '+' || c == '.' ; }", "del_tokens": "while ( Character . isDigit ( c ) || c == '-' || c == '#' || c == '+' || c == ' ' || c == ',' || c == '(' || c == '+' || c == '.' ) { ++ i ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "encoding", "of", "ampersands", "in", "parameters", "get", "requests"], "add_tokens": "query = query + key + \"=\" + value . replace ( \"&\" , \"&amp;\" ) + \"&\" ; // what the hell is going on in java - no adequate way to encode query string // lets temporary replace \"&\" in the value, to encode it manually later // this routine will encode query string // re-create request to have validly encoded ampersand request = new HttpGet ( fullUrl + \"?\" + uri . getRawQuery ( ) . replace ( \"&amp;\" , \"%26\" ) ) ;", "del_tokens": "import org . apache . http . client . methods . HttpRequestBase ; query = query + key + \"=\" + value + \"&\" ; ( ( HttpRequestBase ) request ) . setURI ( uri ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "fake", "builder", "feature", "useful", "for", "testing"], "add_tokens": "import com . github . susom . database . DatabaseProvider . Builder ; void example ( Database db , String [ ] args ) { // For subclasses to override } void example ( Builder dbb , final String [ ] args ) { dbb . transact ( new DbCode ( ) { @ Override public void run ( Provider < Database > db ) { example ( db . get ( ) , args ) ; } } ) ; } // Put all Derby related files inside ./target to keep our working copy clean example ( DatabaseProvider . fromDriverManager ( url ) , args ) ;", "del_tokens": "abstract void example ( Database db , String [ ] args ) ; // Put all Derby related files inside ./build to keep our working copy clean DatabaseProvider . fromDriverManager ( url ) . transact ( new DbCode ( ) { @ Override public void run ( Provider < Database > db ) { example ( db . get ( ) , args ) ; } } ) ;", "commit_type": "fix"}
{"commit_tokens": ["adds", "remove", "method", "to", "JsonDBTemplate", "without", "the", "EntityClass", "parameter", "(", "like", "for", "upsert", "-", "API", ")"], "add_tokens": "public void testRemove_ValidObjectWithClass ( ) { / * * * Test to remove a single object from a collection * / @ Test public void testRemove_ValidObjectWithoutClass ( ) { List < Instance > instances = jsonDBTemplate . getCollection ( Instance . class ) ; int size = instances . size ( ) ; Instance instance = new Instance ( ) ; instance . setId ( \"05\" ) ; Instance removedObject = jsonDBTemplate . remove ( instance ) ; instances = jsonDBTemplate . getCollection ( Instance . class ) ; assertNotNull ( instances ) ; assertEquals ( size - 1 , instances . size ( ) ) ; assertNotNull ( removedObject ) ; assertEquals ( \"05\" , removedObject . getId ( ) ) ; }", "del_tokens": "public void testRemove_ValidObject ( ) {", "commit_type": "add"}
{"commit_tokens": ["Implement", "the", "public", "methods", "in", "Object", "for", "dynamic", "proxy"], "add_tokens": "if ( content != null && content . length > 0 ) {", "del_tokens": "if ( content . length > 0 ) {", "commit_type": "implement"}
{"commit_tokens": ["Adding", "support", "for", "a", "specific", "font", "to", "use", "for", "bold", "text"], "add_tokens": "return createSwingTerminal ( terminalFont , terminalFont , columns , rows ) ; } / * * * Creates a new { @ code SwingTerminal } object , a simple Swing terminal emulator , * with specified dimensions . * @ param terminalFont What font the terminal emulator should use to render * normal text , this should be a monospaced font * * @ param boldTerminalFont What font the terminal emulator should use to render * bold text , this should be a monospaced font * @ param columns Width of the terminal window , in text columns < b > not < / b > pixels * @ param rows Height of the terminal window , in text rows < b > not < / b > pixels * / public static SwingTerminal createSwingTerminal ( Font terminalFont , Font boldTerminalFont , int columns , int rows ) { return new SwingTerminal ( terminalFont , boldTerminalFont , columns , rows ) ;", "del_tokens": "return new SwingTerminal ( terminalFont , columns , rows ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "SSL", "Tools", "base", "64", "handling", "to", "use", "the", "new", "java", ".", "util", "class"], "add_tokens": "import javax . net . ssl . KeyManager ; import javax . net . ssl . KeyManagerFactory ; import javax . net . ssl . SSLContext ; import javax . net . ssl . SSLSocketFactory ; import javax . net . ssl . TrustManager ; import javax . net . ssl . TrustManagerFactory ; import java . security . KeyFactory ; import java . security . KeyManagementException ; import java . security . KeyStore ; import java . security . KeyStoreException ; import java . security . NoSuchAlgorithmException ; import java . security . PrivateKey ; import java . security . UnrecoverableKeyException ; // Strip all the whitespace since the PEM and DER allow them but they aren't valid in Base 64 encoding String base64 = pem . substring ( startIndex + beginDelimiter . length ( ) , endIndex ) . replaceAll ( \"\\\\s\" , \"\" ) ; System . out . println ( base64 ) ;", "del_tokens": "import javax . net . ssl . * ; import java . security . * ; String base64 = pem . substring ( startIndex + beginDelimiter . length ( ) , endIndex ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "dropwizard", "-", "discovery", "(", "disabled", "by", "default", ")"], "add_tokens": "import io . dropwizard . discovery . DiscoveryBundle ; import io . dropwizard . discovery . DiscoveryFactory ; private final DiscoveryBundle < SnowizardConfiguration > discoveryBundle = new DiscoveryBundle < SnowizardConfiguration > ( ) { @ Override public DiscoveryFactory getDiscoveryFactory ( final SnowizardConfiguration configuration ) { return configuration . getDiscoveryFactory ( ) ; } } ; bootstrap . addBundle ( discoveryBundle ) ;", "del_tokens": "// nothing to initialize", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "use", "GrailsApplication", "instance"], "add_tokens": "import org . codehaus . groovy . grails . commons . GrailsApplication ; import org . codehaus . groovy . grails . commons . GrailsDomainClass ; private GrailsApplication grailsApplication ; public void setGrailsApplication ( GrailsApplication application ) { this . grailsApplication = application ; GrailsDomainClass [ ] existingDomainClasses = this . grailsApplication . getGrailsDomainClasses ( ) ; Thread . currentThread ( ) . setContextClassLoader ( this . grailsApplication . getClassLoader ( ) ) ;", "del_tokens": "import org . codehaus . groovy . grails . domain . GrailsDomain ; import org . codehaus . groovy . grails . domain . GrailsDomainClass ; private GrailsDomain domain ; public void setDomain ( GrailsDomain domain ) { this . domain = domain ; GrailsDomainClass [ ] existingDomainClasses = this . domain . getGrailsDomainClasses ( ) ; Thread . currentThread ( ) . setContextClassLoader ( this . domain . getGrailsApplication ( ) . getClassLoader ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Move", "action", "bindings", "to", "listeners", "due", "to", "the", "fact", "that", "a", "bound", "property", "cannot", "have", "its", "value", "set", "programmatically"], "add_tokens": "enabled = new SimpleBooleanProperty ( this , \"enabled\" , true ) ;", "del_tokens": "enabled = new SimpleBooleanProperty ( this , \"enabled\" ) ; enabled . set ( true ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "referenceId", "for", "the", "LockCodec"], "add_tokens": "if ( allCodecModel . isEmpty ( ) ) { return ; } saveFile ( fileName , \"document\" , content ) ; Writer writer = filer . createResource ( location , packageName , fileName ) . openWriter ( ) ; writer . append ( content ) . close ( ) ;", "del_tokens": "Map < ProtocolFilePath , Writer > openFiles = new HashMap < ProtocolFilePath , Writer > ( ) ; saveFile ( fileName , \"document\" , content , false ) ; CodeGenerationUtils . setDocumentCreated ( true ) ; saveFile ( fileName , packageName , content , true ) ; } private void saveFile ( String fileName , String packageName , String content , boolean shouldCloseFile ) { if ( shouldCloseFile ) { Writer writer = filer . createResource ( location , packageName , fileName ) . openWriter ( ) ; writer . append ( content ) . close ( ) ; } else { ProtocolFilePath path = new ProtocolFilePath ( location , packageName , fileName ) ; Writer writer = openFiles . get ( path ) ; if ( null == writer ) { writer = filer . createResource ( location , packageName , fileName ) . openWriter ( ) ; openFiles . put ( path , writer ) ; } writer . append ( content ) . flush ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "recognition", "error", ".", "Applied", "for", "all", "recognizer", "versions", "."], "add_tokens": "if ( speechRecognizer != null ) { if ( error == SpeechRecognizer . ERROR_NO_MATCH && ! wasReadyForSpeech ) {", "del_tokens": "private String googleRecognizerVersion ; googleRecognizerVersion = RecognizerChecker . getGoogleRecognizerVersion ( context ) ; if ( speechRecognizer != null && affectedWithGoogleSearchProblem ( ) ) { / * * * Workaround for http : //stackoverflow.com/questions/31071650/speechrecognizer-throws-onerror-on-the-first-listening * @ return * / private boolean affectedWithGoogleSearchProblem ( ) { if ( googleRecognizerVersion != null ) { if ( googleRecognizerVersion . contains ( \"4.7.13.19\" ) ) { return true ; } } return false ; } // workaround for http://stackoverflow.com/questions/31071650/speechrecognizer-throws-onerror-on-the-first-listening if ( error == SpeechRecognizer . ERROR_NO_MATCH && affectedWithGoogleSearchProblem ( ) && ! wasReadyForSpeech ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "label", "check", "on", "gremlin", "parser", "."], "add_tokens": "TestGremlinCompileWithHas . class , TestGremlinCompileV . class , TestGremlinCompileE . class", "del_tokens": "TestGremlinCompileWithHas . class", "commit_type": "add"}
{"commit_tokens": ["Use", "current", "step", "for", "fallback", "on", "arrival", "if", "upcoming", "step", "is", "null", "and", "use", "upcoming", "step", "for", "default", "instruction"], "add_tokens": "return progress . getCurrentLegProgress ( ) . getCurrentStep ( ) . getManeuver ( ) . getInstruction ( ) ; . getUpComingStep ( ) . getManeuver ( ) . getInstruction ( ) )", "del_tokens": "return progress . getCurrentLegProgress ( ) . getUpComingStep ( ) . getManeuver ( ) . getInstruction ( ) ; . getCurrentStep ( ) . getManeuver ( ) . getInstruction ( ) )", "commit_type": "use"}
{"commit_tokens": ["removed", "category", ".", "setType", "(", ")", "in", "MovieDbParser", ".", "parseCategories", "so", "that", "this", "field", "keeps", "its", "UNKNOWN", "value"], "add_tokens": "import java . util . Arrays ; import com . moviejukebox . themoviedb . model . Category ; if ( ! isValidString ( apiKey ) ) { logger . severe ( \"TheMovieDb was initialized with a wrong API key!\" ) ; } if ( ! isValidString ( apiKey ) ) { logger . severe ( \"TheMovieDb was initialized with a wrong API key!\" ) ; } / * * * Set proxy parameters . * @ param host proxy host URL * @ param port proxy port * @ param username proxy username * @ param password proxy password * / / * * * Set web browser timeout . * @ param webTimeoutConnect * @ param webTimeoutRead * / / * * * Return the API key . * @ return * / / * * * Set the TMDb API key . * @ param apiKey a valid TMDb API key . * / / * * * Return the TMDb default language : en - US . * @ return * / public String getDefaultLanguage ( ) { return defaultLanguage ; }", "del_tokens": "import com . moviejukebox . themoviedb . model . Category ; import java . util . Arrays ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "where", "missing", "identifiers", "would", "be", "interpreted", "as", "null", "."], "add_tokens": "if ( value == null && isMissingError ) { } else if ( value != null ) { // We don't want to put nulls into our map. // Proctor interprets nulls correctly, but we want an accurate count of identifiers.", "del_tokens": "if ( isMissingError && value == null ) { } else {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "unit", "test", "by", "return", "a", "new", "Reader", "each", "time", "a", "mocked", "method", "is", "called", "."], "add_tokens": "import org . mockito . invocation . InvocationOnMock ; import org . mockito . stubbing . Answer ; when ( runFunc . run ( argThatHasItem ( \"-version\" ) ) ) . then ( new Answer < BufferedReader > ( ) { @ Override public BufferedReader answer ( InvocationOnMock invocation ) throws Throwable { return loadResource ( \"ffmpeg-version\" ) ; } } ) ; assertEquals ( \"ffmpeg version 0.10.9-7:0.10.9-1~raring1\" , ffmpeg . version ( ) ) ;", "del_tokens": "when ( runFunc . run ( argThatHasItem ( \"-version\" ) ) ) . thenReturn ( loadResource ( \"ffmpeg-version\" ) ) ; // Run twice, the second should be cached assertEquals ( \"ffmpeg version 0.10.9-7:0.10.9-1~raring1\" , ffmpeg . version ( ) ) ; verify ( runFunc , times ( 1 ) ) . run ( anyListOf ( String . class ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "init", "script", "to", "be", "in", "classpath"], "add_tokens": "import java . io . File ; import java . io . Reader ; import java . io . InputStreamReader ; import java . io . InputStream ; import java . io . FileNotFoundException ; Reader fileReader ; String fileName = config . getInitScript ( ) ; if ( new File ( fileName ) . exists ( ) ) { fileReader = new FileReader ( fileName ) ; } else { InputStream stream = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( fileName ) ; if ( stream == null ) { throw new FileNotFoundException ( fileName ) ; } fileReader = new InputStreamReader ( stream ) ; }", "del_tokens": "FileReader fileReader = new FileReader ( config . getInitScript ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "display", "name", "of", "node", "in", "order", "to", "retain", "consistency", "with", "support", "bundle"], "add_tokens": "return node instanceof Jenkins ? \"master\" : node . getDisplayName ( ) ;", "del_tokens": "return node instanceof Jenkins ? \"master\" : node . getNodeName ( ) ;", "commit_type": "use"}
{"commit_tokens": ["fixing", "some", "merging", "issues", "."], "add_tokens": "if ( response != null ) { register = response . getSession ( ) . createRequest ( response . getRequest ( ) . getMethod ( ) ) ; register = sipFactory . createRequest ( application , \"REGISTER\" , aor , aor ) ; register . addAuthHeader ( response , authentication ) ;", "del_tokens": "import org . mobicents . servlet . sip . restcomm . xml . rcml . attributes . From ; if ( response != null ) { register = response . getSession ( ) . createRequest ( response . getRequest ( ) . getMethod ( ) ) ; register = sipFactory . createRequest ( application , \"REGISTER\" , aor , aor ) ; register . addAuthHeader ( response , authentication ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "unique", "ID", "for", "notifications"], "add_tokens": "private static final int UPLOAD_NOTIFICATION_ID = 1234 ; // Something unique notificationManager . notify ( UPLOAD_NOTIFICATION_ID , notification . build ( ) ) ; notificationManager . notify ( UPLOAD_NOTIFICATION_ID , notification . build ( ) ) ; notificationManager . cancel ( UPLOAD_NOTIFICATION_ID ) ; notificationManager . notify ( UPLOAD_NOTIFICATION_ID , notification . build ( ) ) ; notificationManager . notify ( UPLOAD_NOTIFICATION_ID , notification . build ( ) ) ;", "del_tokens": "notificationManager . notify ( 0 , notification . build ( ) ) ; notificationManager . notify ( 0 , notification . build ( ) ) ; notificationManager . cancel ( 0 ) ; notificationManager . notify ( 0 , notification . build ( ) ) ; notificationManager . notify ( 0 , notification . build ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["moved", "module", "from", "main", "to", "src"], "add_tokens": "int checkSize = 162 ; //TODO update this if java files in src/main are have been removed or added", "del_tokens": "int checkSize = 161 ; //TODO update this if java files in src/main are have been removed or added", "commit_type": "move"}
{"commit_tokens": ["Added", "feature", "to", "be", "able", "to", "disable", "reorder", "or", "items", "when", "dragging", "."], "add_tokens": "import java . util . Collections ; private long mDragItemId = RecyclerView . NO_ID ; private long mDropTargetId = RecyclerView . NO_ID ; public void swapItems ( int pos1 , int pos2 ) { if ( mItemList != null && mItemList . size ( ) > pos1 && mItemList . size ( ) > pos2 ) { Collections . swap ( mItemList , pos1 , pos2 ) ; notifyDataSetChanged ( ) ; } } return RecyclerView . NO_POSITION ; void setDropTargetId ( long dropTargetId ) { mDropTargetId = dropTargetId ; } public long getDropTargetId ( ) { return mDropTargetId ; }", "del_tokens": "private long mDragItemId = - 1 ; return - 1 ;", "commit_type": "add"}
{"commit_tokens": ["added", "backward", "and", "modified", "handlers"], "add_tokens": "} else if ( HolidayHandlerType . BACKWARD . equals ( holidayHandlerType ) ) { cal . setHolidayHandler ( new BackwardHandler ( ) ) ; } else if ( HolidayHandlerType . MODIFIED_FOLLLOWING . equals ( holidayHandlerType ) ) { cal . setHolidayHandler ( new ModifiedFollowingHandler ( ) ) ; } else if ( HolidayHandlerType . MODIFIED_PRECEEDING . equals ( holidayHandlerType ) ) { cal . setHolidayHandler ( new ModifiedPreceedingHandler ( ) ) ; throw new UnsupportedOperationException ( \"Unsupported HolidayHandler: \" + holidayHandlerType ) ;", "del_tokens": "throw new UnsupportedOperationException ( \"only forward supported\" ) ; // } else if (HolidayHandlerType.BACKWARD.equals(holidayHandlerType)) { // cal.setHolidayHandler(new BackwardHandler()); // } else if // (HolidayHandlerType.MODIFIED_FOLLLOWING.equals(holidayHandlerType)) { // cal.setHolidayHandler(new ModifiedFollowingHandler()); // } else if // (HolidayHandlerType.MODIFIED_PRECEEDING.equals(holidayHandlerType)) { // cal.setHolidayHandler(new ModifiedPreceedingHandler()); // } // return cal;", "commit_type": "add"}
{"commit_tokens": ["Use", "Dagger", "in", "the", "AutoFactoryProcessor"], "add_tokens": "import javax . annotation . processing . ProcessingEnvironment ; import javax . inject . Inject ; import dagger . ObjectGraph ; @ Inject FactoryDescriptorGenerator factoryDescriptorGenerator ; @ Inject ProvidedChecker providedChecker ; @ Inject Messager messager ; @ Inject Elements elements ; @ Inject FactoryWriter factoryWriter ; @ Override public synchronized void init ( ProcessingEnvironment processingEnv ) { super . init ( processingEnv ) ; ObjectGraph . create ( new ProcessorModule ( processingEnv ) , new AutoFactoryProcessorModule ( ) ) . inject ( this ) ; }", "del_tokens": "Messager messager = processingEnv . getMessager ( ) ; Elements elements = processingEnv . getElementUtils ( ) ; ProvidedChecker providedChecker = new ProvidedChecker ( messager ) ; FactoryDescriptorGenerator factoryDescriptorGenerator = new FactoryDescriptorGenerator ( messager , elements ) ; FactoryWriter factoryWriter = new FactoryWriter ( processingEnv . getFiler ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "tests", "for", "\\", "A", "and", "\\", "Z", "."], "add_tokens": "assertThat ( \"a123\" , matches ( \"\\\\Aa\" , PatternFlags . ADVANCED ) ) ; assertThat ( \"ba123\" , not ( matches ( \"\\\\Aa\" , PatternFlags . ADVANCED ) ) ) ; assertThat ( \"a123\" , matches ( \"3\\\\Z\" , PatternFlags . ADVANCED ) ) ; assertThat ( \"a123b\" , not ( matches ( \"a\\\\Z\" , PatternFlags . ADVANCED ) ) ) ;", "del_tokens": "@ org . junit . Ignore assertThat ( \"a123\" , matches ( \"\\\\Aa\" ) ) ; assertThat ( \"ba123\" , not ( matches ( \"\\\\Aa\" ) ) ) ; @ org . junit . Ignore assertThat ( \"a123\" , matches ( \"\\\\Z3\" ) ) ; assertThat ( \"a123b\" , not ( matches ( \"\\\\Za\" ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "abstract", "implementations", "for", "listener", "and", "publisher"], "add_tokens": "@ Override public void onPopulateStart ( long version ) { } @ Override public void onPopulateComplete ( ProducerStatus status , long elapsed , TimeUnit unit ) { } @ Override public void onPublishComplete ( PublishStatus status , long elapsed , TimeUnit unit ) { }", "del_tokens": "@ Override public void onPublishComplete ( ProducerStatus status , long elapsed , TimeUnit unit ) { }", "commit_type": "fix"}
{"commit_tokens": ["use", "drop", "-", "in", "replacement", "statements"], "add_tokens": "import com . redhat . lightblue . client . response . LightblueResponseParseException ; MigrationJob [ ] jobs = response . parseProcessed ( MigrationJob [ ] . class ) ; } catch ( LightblueResponseParseException e ) { return response . parseModifiedCount ( ) ;", "del_tokens": "// verify this job is the first active thread processing the thread. // first extract processed data as MigrationJob JsonNode node = response . getJson ( ) . path ( \"processed\" ) ; MigrationJob [ ] jobs = mapper . readValue ( node . traverse ( ) , MigrationJob [ ] . class ) ; } catch ( IOException e ) { return response . getJson ( ) . findValue ( \"modifiedCount\" ) . asInt ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "anyone", "with", "a", "fork", "extra", "mad", "(", "formatting", ")", "."], "add_tokens": "* Prevents the template project from committing a redirect when it finishes handling the request in * { @ link hudson . model . AbstractProject # doConfigSubmit ( StaplerRequest , StaplerResponse ) } . /*package*/ TemplateStaplerResponseWrapper ( Stapler stapler , StaplerResponse response ) throws ServletException { super ( stapler , response ) ; } @ Override public void sendRedirect ( @ Nonnull String url ) throws IOException { // No-op } @ Override public void sendRedirect ( int var1 , @ Nonnull String var2 ) throws IOException { // No-op } @ Override public void sendRedirect2 ( @ Nonnull String var1 ) throws IOException { // No-op }", "del_tokens": "* Prevents the template project from committing a redirect when it finishes * handling the request in { @ link hudson . model . AbstractProject # doConfigSubmit ( StaplerRequest , StaplerResponse ) } . /*package*/ TemplateStaplerResponseWrapper ( Stapler stapler , StaplerResponse response ) throws ServletException { super ( stapler , response ) ; } @ Override public void sendRedirect ( @ Nonnull String url ) throws IOException { // No-op } @ Override public void sendRedirect ( int var1 , @ Nonnull String var2 ) throws IOException { // No-op } @ Override public void sendRedirect2 ( @ Nonnull String var1 ) throws IOException { // No-op }", "commit_type": "make"}
{"commit_tokens": ["adding", "tests", "for", "the", "new", "ExpiryDateEditText"], "add_tokens": "public void convertTwoDigitYearToFour_whenDateIsEarlyCenturyAndYearIsLarge_addsLowerBase ( ) { // In the year 2502, when you say \"95\", you probably mean 2495. assertEquals ( DateUtils . convertTwoDigitYearToFour ( 95 , earlyCenturyCalendar ) , 2495 ) ; // A more practical test earlyCenturyCalendar . set ( Calendar . YEAR , 2017 ) ; assertEquals ( DateUtils . convertTwoDigitYearToFour ( 99 , earlyCenturyCalendar ) , 1999 ) ; } @ Test public void convertTwoDigitYearToFour_whenDateIsMidCenturyAndYearIsLarge_addsNormalBase ( ) { Calendar midCenturyCalendar = Calendar . getInstance ( ) ; midCenturyCalendar . set ( Calendar . YEAR , 3535 ) ; assertEquals ( DateUtils . convertTwoDigitYearToFour ( 99 , midCenturyCalendar ) , 3599 ) ;", "del_tokens": "public void convertTwoDigitYearToFour_whenDateIsEarlyCenturyAndYearIsLarge_addsNormalBase ( ) { assertEquals ( DateUtils . convertTwoDigitYearToFour ( 95 , earlyCenturyCalendar ) , 2595 ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "get", "prefixes", "to", "StartedProcess", "."], "add_tokens": "public Process getProcess ( ) { public Future < ProcessResult > getFuture ( ) { / * * * @ return the started process . * @ deprecated use { @ link # getProcess ( ) } instead . * / public Process process ( ) { return getProcess ( ) ; } / * * * @ return asynchronous result of the started process . * @ deprecated use { @ link # getFuture ( ) } instead . * / public Future < ProcessResult > future ( ) { return getFuture ( ) ; }", "del_tokens": "public Process process ( ) { public Future < ProcessResult > future ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "Either", "type", "and", "or", "()", "combinator", "."], "add_tokens": "import java . util . stream . Stream ; / * * * Returns an event stream that emits all the events emitted from any of * the { @ code inputs } . The event type of the returned stream is the nearest * common super - type of all the { @ code inputs } . * * @ see EventStream # or ( EventStream ) * / Subscription [ ] subs = Stream . of ( inputs ) . map ( i -> i . subscribe ( this :: emit ) ) . toArray ( n -> new Subscription [ n ] ) ;", "del_tokens": "Subscription [ ] subs = new Subscription [ inputs . length ] ; for ( int i = 0 ; i < inputs . length ; ++ i ) { subs [ i ] = inputs [ i ] . subscribe ( value -> emit ( value ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["fix", "checkbox", ":", "required", "and", "not", "checked", "will", "fail"], "add_tokens": "this . value = null ;", "del_tokens": "this . value = \"false\" ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "0", "-", "sized", "ArrayList", "instead", "of", "a", "LinkedList"], "add_tokens": "List < Object > path = new ArrayList < Object > ( 0 ) ;", "del_tokens": "List < Object > path = new LinkedList < Object > ( ) ;", "commit_type": "use"}
{"commit_tokens": ["improved", "usage", "of", "StandardDataEntry", "ImportSection", "shows", "ASCII", "names", "of", "datadirentries"], "add_tokens": "import com . github . katjahahn . sections . idata . ImportSection ; ImportSection idata = loader . loadImportSection ( ) ; System . out . println ( idata . getInfo ( ) ) ;", "del_tokens": "System . out . println ( loader . loadImportSection ( ) . getInfo ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["fixed", "issue", "49", ":", "array", "[]", "problems", "in", "@Reference", "/", "@Embedded"], "add_tokens": "/** Connects to \"test\" database on localhost by default */", "del_tokens": "/** Connects to \"test\" database on localhost */", "commit_type": "fix"}
{"commit_tokens": ["Use", "auth0", "-", "api", "-", "java", "and", "fix", "errors"], "add_tokens": "import android . net . Uri ; import android . os . Parcel ; import android . os . Parcelable ; public class Auth0 implements Parcelable { public Auth0 ( String clientId , String domainUrl , String configurationUrl ) { public Auth0 ( String clientId , String domain ) { public static final Parcelable . Creator < Auth0 > CREATOR = new Parcelable . Creator < Auth0 > ( ) { public Auth0 createFromParcel ( Parcel in ) { return new Auth0 ( in ) ; public Auth0 [ ] newArray ( int size ) { return new Auth0 [ size ] ; private Auth0 ( Parcel in ) {", "del_tokens": "public class Auth0 implements Parcelable { public Auth0Account ( String clientId , String domainUrl , String configurationUrl ) { public Auth0Account ( String clientId , String domain ) { public static final Parcelable . Creator < Auth0Account > CREATOR = new Parcelable . Creator < Auth0Account > ( ) { public Auth0Account createFromParcel ( Parcel in ) { return new Auth0Account ( in ) ; public Auth0Account [ ] newArray ( int size ) { return new Auth0Account [ size ] ; private Auth0Account ( Parcel in ) {", "commit_type": "use"}
{"commit_tokens": ["Adding", "a", "public", "static", "metrics", "instance"], "add_tokens": "* Represents a factory class that creates metrics object that logs nothing . * This object is useful for null safe code which should be able to work with non - loggable metrics . * / * * * Static instance of the null metrics object . This instance is returned from * { @ link NullMetricsCreator # create ( ) } method . * / public static final Metrics NULL_METRICS = new NullMetrics ( ) ; / * * * Returns special metrics instance that does nothing on closing . * See also { @ link # NULL_METRICS } . * * { @ inheritDoc } * / return NULL_METRICS ; public void close ( ) { // do nothing", "del_tokens": "return new NullMetrics ( ) ; private volatile boolean closed = false ; public synchronized void close ( ) { if ( closed ) { throw new IllegalStateException ( ) ; } closed = true ;", "commit_type": "add"}
{"commit_tokens": ["Made", "all", "caches", "enabled", "by", "default"], "add_tokens": "private static volatile boolean cachesEnabled = true ;", "del_tokens": "private static volatile boolean cachesEnabled ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "unnecessary", "try", "catch", "+", "check", "debug", "level", "."], "add_tokens": "if ( logger . isDebugEnabled ( ) ) { logger . debug ( \"Request {} {} {} {} bytes\" , request . getMethod ( ) , request . getUrl ( ) , return client . executeRequest ( request , handler ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( \"Response HTTP/{} {}\\n{}\" , response . getStatusCode ( ) , response . getStatusText ( ) , response . getResponseBody ( ) ) ; }", "del_tokens": "try { logger . debug ( \"Request {} {} {} {} bytes\" , request . getMethod ( ) , request . getUrl ( ) , // return client . executeRequest ( request , handler ) ; } catch ( Throwable t ) { throw new ZendeskException ( t ) ; logger . debug ( \"Response HTTP/{} {}\\n{}\" , response . getStatusCode ( ) , response . getStatusText ( ) , response . getResponseBody ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "boolean", "attribute", "to", "element", "to", "indicate", "the", "type", "of", "registry", "being", "created"], "add_tokens": "import net . unicon . cas . addons . serviceregistry . ReadWriteJsonServiceRegistryDao ; return Boolean . valueOf ( element . getAttribute ( \"read-write\" ) ) ? ReadWriteJsonServiceRegistryDao . class : JsonServiceRegistryDao . class ; private static class AcceptUsersAuthenticationHandlerBeanDefinitionParser extends AbstractSingleBeanDefinitionParser { for ( Element e : userElements ) { if ( ldapPropsElem != null ) { for ( Element e : propElements ) {", "del_tokens": "return JsonServiceRegistryDao . class ; private static class AcceptUsersAuthenticationHandlerBeanDefinitionParser extends AbstractSingleBeanDefinitionParser { for ( Element e : userElements ) { if ( ldapPropsElem != null ) { for ( Element e : propElements ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "problem", "with", "logging", "of", "batch", "inserts"], "add_tokens": "if ( firstRowParameters == null ) {", "del_tokens": "if ( executeSql == null ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "copy", "/", "paste", "javadoc", "mistakes"], "add_tokens": "* Describes the capabilities of Azure with respect to Dasein volume operations .", "del_tokens": "* Describes the capabilities of Azure with respect to Dasein virtual machine operations .", "commit_type": "fix"}
{"commit_tokens": ["Change", "default", "FHIR", "service", "root", "."], "add_tokens": "private static final String ROOT = \"http://broker/DSTU1/\" ;", "del_tokens": "private static final String ROOT = \"http://broker/FHIR/\" ;", "commit_type": "change"}
{"commit_tokens": ["Added", "test", "for", "Integer", "and", "Long"], "add_tokens": "Contract . requireArgMin ( \"name1\" , 5 , 4 ) ; Contract . requireArgMin ( \"name3\" , 4 , 4 ) ; Contract . requireArgMin ( \"name3\" , Integer . valueOf ( 5 ) , Integer . valueOf ( 4 ) ) ; Contract . requireArgMin ( \"name4\" , 5L , 4L ) ; Contract . requireArgMin ( \"name5\" , Long . valueOf ( 5 ) , Long . valueOf ( 4 ) ) ; Contract . requireArgMin ( \"name6\" , 3 , 4 ) ; assertThat ( ex . getMessage ( ) ) . isEqualTo ( \"Min value of argument 'name6' is 4, but was: 3\" ) ;", "del_tokens": "Contract . requireArgMin ( \"name\" , 5 , 4 ) ; // TEST Contract . requireArgMin ( \"name\" , 4 , 4 ) ; // TEST Contract . requireArgMin ( \"name\" , 3 , 4 ) ; assertThat ( ex . getMessage ( ) ) . isEqualTo ( \"Min value of argument 'name' is 4, but was: 3\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "end", "points", "for", "getFolder", "and", "deleteFolder", "methods", "."], "add_tokens": "return this . getResource ( \"folders/\" + folderId , Folder . class ) ; this . deleteResource ( \"folders/\" + folderId , Folder . class ) ;", "del_tokens": "return this . getResource ( \"folder/\" + folderId , Folder . class ) ; this . deleteResource ( \"folder/\" + folderId , Folder . class ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "html", "pages", "for", "testing", "with", "selenium"], "add_tokens": "//TODO refactor areas. Should be list of areas with tooltips instead of just one rect area.", "del_tokens": "//TODO / * * errors : * 2. is 30 px left instead of 10 px * 3. is 30 px left which is not in range of 10 px to 20 px * 4. \"container\" is not specified in page spec * 5. is 30 px left instead of 10 px and is 5 px top instead of 10 px * 6. \"object\" is absent * 7. \"object\" is not visible * 8. \"container\" is absent * 9. \"container\" is not visible * / / * * General errors : * There is no validation for spec ... * / //TODO other specs", "commit_type": "add"}
{"commit_tokens": ["Added", "basic", "support", "for", "ANSI", "colors", "."], "add_tokens": "private static final String ANSI_COLORS = \"\\u001B\\\\[[;\\\\d]*m\" ; String rowDataWithoutColor = rowDataLine . replaceAll ( ANSI_COLORS , \"\" ) ; columnWidths [ column ] = Math . max ( columnWidths [ column ] , rowDataWithoutColor . length ( ) ) ;", "del_tokens": "columnWidths [ column ] = Math . max ( columnWidths [ column ] , rowDataLine . length ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "fields", "in", "references"], "add_tokens": "reference . setFields ( fields ) ; Map < String , Object > fields = reference . getFields ( ) ; JsonElement jsonElement = gson ( ) . toJsonTree ( reference , Component . class ) ; jsonObject . remove ( \"_fields\" ) ; for ( Map . Entry < String , Object > s : fields . entrySet ( ) ) { jsonObject . add ( s . getKey ( ) , jsonSerializationContext . serialize ( s . getValue ( ) ) ) ; }", "del_tokens": "// reference.setFields(fields); JsonElement jsonElement = gson ( ) . toJsonTree ( reference , Reference . class ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "generation", "of", "enums", "using", "implicit", "values"], "add_tokens": "return new EnumFieldContext ( mangleJavaConstantName ( field . getName ( ) ) , field . getValue ( ) ) ;", "del_tokens": "Preconditions . checkState ( field . getValue ( ) . get ( ) != null , \"field value for integer field %s is null!\" , field . getName ( ) ) ; return new EnumFieldContext ( mangleJavaConstantName ( field . getName ( ) ) , field . getValue ( ) . get ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "PID", "determination", "work", "on", "JDK", "9", ";"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; if ( process . getPid ( ) != null ) { writePidFile ( pidFile , process . getPid ( ) ) ; } public long getProcessId ( ) { Long pid = process . getPid ( ) ; protected void writePidFile ( File pidFile , long pid ) throws IOException {", "del_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; writePidFile ( pidFile , process . getPid ( ) ) ; public int getProcessId ( ) { Integer pid = process . getPid ( ) ; protected void writePidFile ( File pidFile , int pid ) throws IOException {", "commit_type": "make"}
{"commit_tokens": ["add", "checks", "for", "duplicate", "key", "when", "switching", "to", "lower", "case"], "add_tokens": "import com . google . common . base . Preconditions ; String k = entry . getKey ( ) . toLowerCase ( ) ; Preconditions . checkState ( ! retVal . containsKey ( k ) , \"Duplicate key [%s]\" , k ) ; retVal . put ( k , entry . getValue ( ) ) ;", "del_tokens": "retVal . put ( entry . getKey ( ) . toLowerCase ( ) , entry . getValue ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "capability", "to", "set", "poster"], "add_tokens": "log . warn ( \"Could not connect to Librato\" , cause ) ;", "del_tokens": "log . warn ( \"Could not connect to Librato: \" + cause ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "interface", "to", "monitor", "error", "."], "add_tokens": "import com . tmall . wireless . vaf . virtualview . listener . MonitorListener ; ( ( ViewGroup ) container ) . removeAllViews ( ) ; if ( mAppContext . getService ( MonitorListener . class ) != null ) { mAppContext . getService ( MonitorListener . class ) . onTemplateNotFound ( ) ; } ( ( View ) container ) . setLayoutParams ( marginLayoutParams ) ; return ( View ) container ;", "del_tokens": "( ( ViewGroup ) container ) . removeAllViews ( ) ; ( ( View ) container ) . setLayoutParams ( marginLayoutParams ) ; return ( View ) container ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "English", "in", "SpiderWeb", "per", "Matt"], "add_tokens": "// Move the tortoise the current length (of the line) --#1.1 // Increase the current length (of the line) by the current zoom --#8.1 // ------------- End of weaveOneLayer recipe --#9.3 // Change the current zoom so it is multiplied by 1.3 --#11", "del_tokens": "// Move the tortoise the length of a line --#1.1 // Increase the length of the line by the current zoom --#8.1 // ------------- End of weaveOneLayer recipe --#9.2 // Change the zoom so it is multiplied by 1.3 --#11", "commit_type": "update"}
{"commit_tokens": ["added", "the", "option", "for", "a", "shortcut", "command", "line", "overwrite", "for", "the", "domain", "to", "run", "the", "suite", "against", "by", "adding", "-", "Domain", "=", "whatever"], "add_tokens": "public WebElement fillFormField_fromView ( String viewName , String fieldName , String value ) throws IllegalArgumentException , IllegalAccessException { WebElement fieldEl = seleniumElementService . getElementFromReferencedView ( viewName , fieldName ) ; fieldEl . clear ( ) ; fieldEl . sendKeys ( getReferenceService ( ) . namespaceString ( value ) ) ; return fieldEl ; }", "del_tokens": "import org . openqa . selenium . By ; import com . gfk . senbot . framework . context . SenBotContext ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "new", "wicket", "module", "."], "add_tokens": "@ Transactional ( readOnly = true ) @ Transactional ( readOnly = true ) @ Transactional ( readOnly = true ) @ Transactional ( readOnly = true ) @ Transactional ( readOnly = true )", "del_tokens": "@ Transactional @ Transactional @ Transactional @ Transactional @ Transactional", "commit_type": "add"}
{"commit_tokens": ["Add", "ArrayList", "implementation", ".", "Update", "README"], "add_tokens": "public static < E > ConsList < E > empty ( ) { return ( ConsList < E > ) EMPTY ;", "del_tokens": "public static < A > ConsList < A > empty ( ) { return ( ConsList < A > ) EMPTY ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "method", "from", "Invocation"], "add_tokens": "// TODO: replace this check with an InvocationMocker", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Updated", "transform", "()", "/", "setTransform", "()", "."], "add_tokens": "t . concatenate ( this . transform ) ; setTransform ( t ) ; / * * * Sets the transform . * * @ param t the new transform ( < code > null < / code > permitted , resets to the * identity transform ) . * / public void setTransform ( AffineTransform t ) { if ( t == null ) { this . transform = new AffineTransform ( ) ; } else { this . transform = new AffineTransform ( t ) ; }", "del_tokens": "this . transform . concatenate ( t ) ; System . out . println ( \"transform(\" + t + \")\" ) ; public void setTransform ( AffineTransform transform ) { this . transform = transform ; System . out . println ( \"transform(\" + transform + \")\" ) ;", "commit_type": "update"}
{"commit_tokens": ["remove", "the", "final", "qualifier", "from", "AbstractBundleLinkRenderer", ".", "addComment"], "add_tokens": "protected void addComment ( String commentText , Writer out )", "del_tokens": "protected final void addComment ( String commentText , Writer out )", "commit_type": "remove"}
{"commit_tokens": ["Create", "the", "fastods", "-", "examples", "modules", "."], "add_tokens": "* An OdsFactory is the entry point for creating ODS documents .", "del_tokens": "* An OdsFactory is the entry point for creating ods documents .", "commit_type": "create"}
{"commit_tokens": ["added", "similarity", "measure", "to", "the", "mappings"], "add_tokens": "public class HashMapping < T > extends BaseMapping < T > implements IContextMapping < T > , IMappingFactory {", "del_tokens": "public class HashMapping < T > extends AbstractSet < IMappingElement < T > > implements IContextMapping < T > , IMappingFactory { private IContext sourceContext ; private IContext targetContext ; public IContext getSourceContext ( ) { return sourceContext ; } public IContext getTargetContext ( ) { return targetContext ; } public void setSourceContext ( IContext newContext ) { sourceContext = newContext ; } public void setTargetContext ( IContext newContext ) { targetContext = newContext ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "ScriptableObject", "that", "make", "classes", "with", "jsGet_", "but", "not", "jsFunction_", "work", "improperly", "."], "add_tokens": "public void jsFunction_resetCounter ( ) { public int jsGet_counter ( ) { public static Object jsFunction_varargs ( Context cx , Scriptable thisObj , Object [ ] args , Function funObj )", "del_tokens": "public void resetCounter ( ) { public int getCounter ( ) { public static Object varargs ( Context cx , Scriptable thisObj , Object [ ] args , Function funObj )", "commit_type": "fix"}
{"commit_tokens": ["updated", "tests", "for", "the", "new", "project", "structure"], "add_tokens": "import android . view . View ; Anvil . render ( renderable ) ; Anvil . render ( renderable ) ; Anvil . render ( renderable ) ;", "del_tokens": "import static trikita . anvil . Anvil . * ; import android . view . View ; render ( renderable ) ; render ( renderable ) ; render ( renderable ) ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "a", "System", ".", "out", ".", "println"], "add_tokens": "final static Integer TEST_INTEGER = 42 ; // System.out.println(StringUtil.deepToString(Color.yellow)); // System.out.println(StringUtil.deepToString(Color.pink, true, -1));", "del_tokens": "* < ! -- To change this template use Options | File Templates . -- > * < ! -- Created by IntelliJ IDEA . -- > * final static Integer TEST_INTEGER = new Integer ( 42 ) ; System . out . println ( StringUtil . deepToString ( Color . yellow ) ) ; System . out . println ( StringUtil . deepToString ( Color . pink , true , - 1 ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "it", "was", "setting", "null", "EndpointIdentifier"], "add_tokens": "if ( endpointIdentifierLocal != null && endpointIdentifierLocal . toString ( ) . equals ( endpointIdentifier . toString ( ) ) ) { if ( endpointIdentifier != null ) { activity . setEndpointIdentifier ( endpointIdentifier ) ; }", "del_tokens": "if ( endpointIdentifierLocal != null && endpointIdentifierLocal . equals ( endpointIdentifier ) ) { activity . setEndpointIdentifier ( endpointIdentifier ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "DiffSerializationFramework", "for", "data", "models", "containing", "Maps", "(", "bug", "introduced", "in", "yesterday", "s", "check", "-", "in", ")"], "add_tokens": "serializeObject ( rec , \"key\" , keyTypeName , entry . getKey ( ) ) ; serializeObject ( rec , \"value\" , valueTypeName , entry . getValue ( ) ) ;", "del_tokens": "FastBlobSchema collectionSchema = rec . getSchema ( ) ; FastBlobSchema elementSchema = getSerializer ( typeName ) . getFastBlobSchema ( ) ; rec . setSchema ( elementSchema ) ; rec . setSchema ( collectionSchema ) ; FastBlobSchema mapSchema = rec . getSchema ( ) ; FastBlobSchema keySchema = getSerializer ( keyTypeName ) . getFastBlobSchema ( ) ; FastBlobSchema valueSchema = getSerializer ( valueTypeName ) . getFastBlobSchema ( ) ; rec . setSchema ( keySchema ) ; serializeObject ( rec , \"key\" , entry . getKey ( ) ) ; rec . setSchema ( valueSchema ) ; serializeObject ( rec , \"value\" , entry . getValue ( ) ) ; rec . setSchema ( mapSchema ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "content", "specs", "weren", "t", "getting", "returned", "for", "topics", "."], "add_tokens": "import javax . persistence . criteria . Join ; import javax . persistence . criteria . JoinType ; import javax . persistence . criteria . Root ; import org . jboss . pressgang . ccms . model . contentspec . CSInfoNode ; private final Join < CSInfoNode , CSNode > csInfoNode ; csInfoNode = ( ( Root < CSNode > ) getRootPath ( ) ) . join ( \"CSInfoNode\" , JoinType . LEFT ) ; addEqualsCondition ( csInfoNode . get ( \"topicId\" ) . as ( Integer . class ) , ( Integer ) field . getData ( ) ) ; addEqualsCondition ( csInfoNode . get ( \"topicRevision\" ) . as ( Integer . class ) , ( Integer ) field . getData ( ) ) ;", "del_tokens": "addEqualsCondition ( getRootPath ( ) . get ( \"CSInfoNode\" ) . get ( \"topicId\" ) . as ( Integer . class ) , ( Integer ) field . getData ( ) ) ; addEqualsCondition ( getRootPath ( ) . get ( \"CSInfoNode\" ) . get ( \"topicRevision\" ) . as ( Integer . class ) , ( Integer ) field . getData ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "API", "to", "use", "separate", "setViewpoint", "call", "instead", "of", "extra", "parameter", "on", "requestVideo", "."], "add_tokens": "my_mission . requestVideo ( 320 , 240 ) ;", "del_tokens": "my_mission . requestVideo ( 320 , 240 , 0 ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "timespan", "calculation", "in", "SparkLineTileSkin"], "add_tokens": "int days = ( int ) ( timeSpan / DAY ) ; double hours = ( timeSpan - ( days * DAY ) ) / HOUR ; double minutes = ( timeSpan - ( hours * HOUR ) ) / MINUTE ; double seconds = ( timeSpan - ( minutes * MINUTE ) ) ;", "del_tokens": "int days = ( int ) ( timeSpan / DAY ) ; double hours = timeSpan % DAY ; double minutes = timeSpan % HOUR ; double seconds = timeSpan % MINUTE ;", "commit_type": "fix"}
{"commit_tokens": ["added", "test", "methods", "for", "FluentLogger#close", "()"], "add_tokens": "import java . util . Properties ; import org . fluentd . logger . sender . NullSender ; public void testClose ( ) throws Exception { // use NullSender Properties props = System . getProperties ( ) ; props . setProperty ( Config . FLUENT_SENDER_CLASS , NullSender . class . getName ( ) ) ; // create logger objects FluentLogger . getLogger ( \"tag1\" ) ; FluentLogger . getLogger ( \"tag2\" ) ; FluentLogger . getLogger ( \"tag3\" ) ; Map < String , FluentLogger > loggers ; { loggers = FluentLogger . getLoggers ( ) ; assertEquals ( 3 , loggers . size ( ) ) ; } // close and delete FluentLogger . close ( ) ; { loggers = FluentLogger . getLoggers ( ) ; assertEquals ( 0 , loggers . size ( ) ) ; } }", "del_tokens": "public void testWithNullSender ( ) throws Exception { assertTrue ( true ) ; // TODO #MN }", "commit_type": "add"}
{"commit_tokens": ["Add", "string", "encode", "/", "decode", "functions", "."], "add_tokens": "String decoded = \"\\\\\\0\\u08af\\b\\t\\n\\f\\ra\" ; String encoded = \"\\\\\\\\\\\\0\\\\u08AF\\\\b\\\\t\\\\n\\\\f\\\\ra\" ; / * * * Test decode failure due to invalid quoted character . * / @ Test ( expected = IllegalArgumentException . class ) public void testDecodeFailure1 ( ) { Strings . decode ( \"\\\\?\" ) ; } / * * * Test decode failure due to invalid encoded character . * / @ Test ( expected = IllegalArgumentException . class ) public void testDecodeFailure2 ( ) { Strings . decode ( \"\\\\uXXXXXx\" ) ; }", "del_tokens": "String decoded = \"\\0\\u0001\\b\\t\\n\\f\\ra\" ; String encoded = \"\\\\0\\\\u0001\\\\b\\\\t\\\\n\\\\f\\\\ra\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "::", "pop"], "add_tokens": "if ( n < 0 ) { throw new IllegalArgumentException ( \"ArgumentError: negative array size\" ) ; } while ( n > 0 && ! list . isEmpty ( ) ) { n -- ;", "del_tokens": "for ( int i = 0 ; i < n ; i ++ ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "performance", "improvement", ".", "Images", "being", "downloaded", "by", "the", "ImageLoader", "implementation", "is", "not", "going", "to", "be", "provided", "twice"], "add_tokens": "private final boolean [ ] loading ; this . loading = new boolean [ noxItems . size ( ) ] ; if ( ! isBitmapReady ( position ) && isResourceAvailable ( position ) && ! isDownloading ( position ) ) { loading [ position ] = true ; loading [ position ] = false ; } @ Override public void onError ( ) { loading [ position ] = false ; private boolean isDownloading ( int position ) { return loading [ position ] ; }", "del_tokens": "if ( ! isBitmapReady ( position ) && isResourceAvailable ( position ) ) {", "commit_type": "add"}
{"commit_tokens": ["Creating", "alert", "types", "enum", "for", "performance", "reason", "."], "add_tokens": "return new buffer . interval ( libtorrent_jni . buffer_data ( swigCPtr , this ) , true ) ; return libtorrent_jni . buffer_begin ( swigCPtr , this ) ; return libtorrent_jni . buffer_end ( swigCPtr , this ) ;", "del_tokens": "return new buffer . interval ( libtorrent_jni . buffer_data__SWIG_0 ( swigCPtr , this ) , true ) ; return libtorrent_jni . buffer_begin__SWIG_0 ( swigCPtr , this ) ; return libtorrent_jni . buffer_end__SWIG_0 ( swigCPtr , this ) ;", "commit_type": "create"}
{"commit_tokens": ["add", "methods", "to", "base", "wrapper", "make", "function", "objects", "static"], "add_tokens": "// System.out.println(\"alist size=\"+alist.size());", "del_tokens": "System . out . println ( \"alist size=\" + alist . size ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "unwrap", "util", "method", "for", "TtlRunnable", "/", "TtlCallable", "/", "TtlTimerTask"], "add_tokens": "* check the { @ link ThreadFactory } is { @ link DisableInheritableThreadFactory } or not .", "del_tokens": "* check the { @ link ThreadFactory } is { @ link DisableInheritableThreadFactory } or not .", "commit_type": "add"}
{"commit_tokens": ["adding", "slf4j", "class", "-", "less", "log", "declaration"], "add_tokens": "* Returns the Log4j2 logger for the calling class ( for Slf4j use Slogr ) . Can be used to determine the Logger , reduces * errors when copy & paste . < br / >", "del_tokens": "* Returns the logger for the calling class . Can be used to determine the Logger , reduces errors when copy & paste . < br / >", "commit_type": "add"}
{"commit_tokens": ["Added", "timeout", "await", "for", "local", "converter", "."], "add_tokens": "private final long processTimeout ; this . processTimeout = processTimeoutUnit . toMillis ( processTimeout ) ; executorService . shutdown ( ) ; try { executorService . awaitTermination ( processTimeout , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { LOGGER . info ( \"The documents4j local converter could not await termination\" , e ) ; } finally { conversionManager . shutDown ( ) ; }", "del_tokens": "conversionManager . shutDown ( ) ; executorService . shutdownNow ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "annotations", "for", "server", "definitions"], "add_tokens": "String value ( ) ; EeComponentType type ( ) ; EeComponentType [ ] requires ( ) ;", "del_tokens": "EeComponentType value ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "deprecated", "api", "of", "Bucket"], "add_tokens": "Assert . assertTrue ( url . contains ( \"QS QYACCESSKEYIDEXAMPLE:\" ) ) ; String zoneKey = \"testzone\" ; String bucketName = \"bucketname\" ; String objKey = \"objectName/dd.txt\" ; Bucket bucket = new Bucket ( ctx , zoneKey , bucketName ) ; Bucket . GetObjectInput input = new Bucket . GetObjectInput ( ) ; String url = null ; RequestHandler reqHandler = bucket . GetObjectBySignatureUrlRequest ( objKey , null , System . currentTimeMillis ( ) / 1000 ) ; url = reqHandler . getExpiresRequestUrl ( ) ; assert url != null ; 0 , url . indexOf ( \"https://bucketname.testzone.qingstor.com/objectName/dd.txt?\" ) ) ; input . setContentLength ( 10000L ) ;", "del_tokens": "Assert . assertEquals ( url . indexOf ( \"QS QYACCESSKEYIDEXAMPLE:\" ) >= 0 , true ) ; String req1 = null ; String req2 = null ; req1 = QSSignatureUtil . getObjectAuthRequestUrl ( ctx , \"testzone\" , \"bucketName\" , \"objectName/dd.txt\" , 1000 ) ; req1 . indexOf ( \"https://bucketName.testzone.qingstor.com/objectName/dd.txt?\" ) == 0 , true ) ; input . setContentLength ( 10000l ) ;", "commit_type": "remove"}
{"commit_tokens": ["adds", "placeholder", "for", "SQSTaskQueue", "initialization", "in", "the", "spring", "config", "."], "add_tokens": "@ Override context = null ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["made", "much", "progress", "...", "created", "the", "raw", "classes", "for", "the", "teplate", "finished", "helper", "-", "classes", "&", "resources", "also", "improved", "general", "framework", "design"], "add_tokens": "* contains some constants describing different levels of indication that the user is around . * Mainly used internally the following way : * for killing events : the weakest decides * for deciding presence : the strongest decides STRONG , WEAK , VERY_WEAK", "del_tokens": "* contains some constants describing different levels of indication that the user is around STRONG , WEAK , VERYWEAK", "commit_type": "make"}
{"commit_tokens": ["added", "ToHeader", "and", "FromHeader", "and", "the", "base", "stuff", "needed", "for", "those", "."], "add_tokens": "return getName ( ) . toString ( ) + \": \" + this . value . toString ( ) ;", "del_tokens": "return this . name . toString ( ) + \": \" + this . value . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "with", "byte", "/", "char", "/", "short", "array", "load", "/", "store", "."], "add_tokens": "} else if ( clazz . equals ( Short . TYPE ) ) { append ( new SALOAD ( ) ) ; } else if ( clazz . equals ( Character . TYPE ) ) { append ( new CALOAD ( ) ) ; } else if ( clazz . equals ( Integer . TYPE ) ) { } else { append ( new BALOAD ( ) ) ; } else if ( clazz . equals ( Short . TYPE ) ) { append ( new SASTORE ( ) ) ; } else if ( clazz . equals ( Character . TYPE ) ) { append ( new CASTORE ( ) ) ; } else if ( clazz . equals ( Integer . TYPE ) ) { } else { append ( new BASTORE ( ) ) ;", "del_tokens": "} else { } else {", "commit_type": "fix"}
{"commit_tokens": ["Made", "BoxRequestsDownload", "public", "so", "that", "we", "can", "change", "return", "type"], "add_tokens": "public abstract class BoxRequestDownload < E extends BoxObject , R extends BoxRequest < E , R > > extends BoxRequest < E , R > {", "del_tokens": "abstract class BoxRequestDownload < E extends BoxObject , R extends BoxRequest < E , R > > extends BoxRequest < E , R > {", "commit_type": "make"}
{"commit_tokens": ["updated", "SSL", "Certificate", "that", "is", "valid", "for", "a", "very", "long", "time", "(", "patched", "from", "Selenium", "source", "which", "itself", "was", "patched", "from", "Neustar", "/", "BrowserMob", "which", "itself", "is", "a", "fork", "of", "this", "very", "project", ":", "P", ")"], "add_tokens": "v3CertGen . setNotAfter ( new Date ( System . currentTimeMillis ( ) + 240 /* months */ * ( 1000L * 60 * 60 * 24 * 30 ) ) ) ;", "del_tokens": "v3CertGen . setNotAfter ( new Date ( System . currentTimeMillis ( ) + 48 /* months */ * ( 1000L * 60 * 60 * 24 * 30 ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Implemented", "U", ".", "save", "method", "and", "introduced", "stream", "close", "utils", "."], "add_tokens": "import java . io . FileOutputStream ; import java . io . OutputStream ; FileOutputStream out = null ; try { out = new FileOutputStream ( filename ) ; out . write ( content . getBytes ( ) ) ; close ( out , false ) ; } catch ( Exception e ) { close ( out , true ) ; throw rte ( e ) ; } } public static void close ( OutputStream out , boolean quiet ) { try { out . close ( ) ; } catch ( IOException e ) { if ( ! quiet ) { throw rte ( e ) ; } } } public static void close ( InputStream in , boolean quiet ) { try { in . close ( ) ; } catch ( IOException e ) { if ( ! quiet ) { throw rte ( e ) ; } }", "del_tokens": "// FIXME throw notReady ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Moved", "first", "level", "of", "indirect", "page", "references", "out", "of", "uber", "and", "revision", "root", "page", "."], "add_tokens": "private PageReference mIndirectNodePageReference ; mIndirectNodePageReference = null ; revisionRootPage . mIndirectNodePageReference = createPageReference ( ) ; revisionRootPage . mIndirectNodePageReference = readPageReference ( in ) ; revisionRootPage . mIndirectNodePageReference = clonePageReference ( committedRevisionRootPage . mIndirectNodePageReference ) ; PageReference reference = mIndirectNodePageReference ; for ( int i = 0 ; i < offsets . length ; i ++ ) { PageReference reference = mIndirectNodePageReference ; for ( int i = 0 ; i < offsets . length ; i ++ ) { commit ( pageWriter , mIndirectNodePageReference ) ; serialize ( out , mIndirectNodePageReference ) ;", "del_tokens": "private final PageReference [ ] mIndirectNodePageReferences ; mIndirectNodePageReferences = new PageReference [ IConstants . INP_REFERENCE_COUNT ] ; createPageReferences ( revisionRootPage . mIndirectNodePageReferences ) ; readPageReferences ( revisionRootPage . mIndirectNodePageReferences , in ) ; clonePageReferences ( revisionRootPage . mIndirectNodePageReferences , committedRevisionRootPage . mIndirectNodePageReferences ) ; PageReference reference = mIndirectNodePageReferences [ offsets [ 0 ] ] ; for ( int i = 1 ; i < offsets . length ; i ++ ) { PageReference reference = mIndirectNodePageReferences [ offsets [ 0 ] ] ; for ( int i = 1 ; i < offsets . length ; i ++ ) { commit ( pageWriter , mIndirectNodePageReferences ) ; serialize ( out , mIndirectNodePageReferences ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "new", "atom", "compatibility", "."], "add_tokens": "forPattern ( \"feed/entry/validTime/TimePeriod/beginPosition\" ) . withNamespaceURI ( \"http://www.opengis.net/gml\" ) . setBeanProperty ( ) . withName ( \"beginPosition\" ) ; forPattern ( \"feed/entry/validTime/TimePeriod/endPosition\" ) . withNamespaceURI ( \"http://www.opengis.net/gml\" )", "del_tokens": "/ * forPattern ( \"feed/entry/gml:validTime/gml:TimePeriod/gml:beginPosition\" ) . setBeanProperty ( ) . withName ( \"beginPosition\" ) ; forPattern ( \"feed/entry/gml:validTime/gml:TimePeriod/gml:endPosition\" ) * /", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "save", "/", "load"], "add_tokens": "Helper . writeSettings ( storageLocation + \"/settings\" , size , creationTime , nextEdgePointer , storageLocation ) ; storageLocation = ( String ) ob [ 3 ] ;", "del_tokens": "Helper . writeSettings ( storageLocation + \"/settings\" , size , creationTime , nextEdgePointer ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "label", "Container", "for", "directories", "archives", "and", "artifacts", "as", "it", "was", "ambiguous"], "add_tokens": "List < Object > earDescriptors = query ( \"match (ear:Enterprise:Application:Zip:Archive) return ear\" ) . getColumn ( \"ear\" ) ; List < Object > warDescriptors = query ( \"match (:Enterprise:Application)-[:CONTAINS]->(war:Web:Application:Zip:Archive) return war\" )", "del_tokens": "List < Object > earDescriptors = query ( \"match (ear:Enterprise:Application:Zip:Archive:Container) return ear\" ) . getColumn ( \"ear\" ) ; List < Object > warDescriptors = query ( \"match (:Enterprise:Application)-[:CONTAINS]->(war:Web:Application:Zip:Archive:Container) return war\" )", "commit_type": "remove"}
{"commit_tokens": ["remove", "unnecessary", "lang", "property", "on", "template", "html", "."], "add_tokens": "//@Ignore(\"for sample\") System . out . println ( result ) ;", "del_tokens": "@ Ignore ( \"for sample\" ) //System.out.println(result);", "commit_type": "remove"}
{"commit_tokens": ["removing", "unused", "fixture", "moving", "fake", "method"], "add_tokens": "private final net . vidageek . mirror . provider . sun15 . java . lang . reflect . Method method ; this . method = ( net . vidageek . mirror . provider . sun15 . java . lang . reflect . Method ) ( AnnotatedElement ) method ;", "del_tokens": "private final net . vidageek . mirror . provider . sun15 . Method method ; this . method = ( net . vidageek . mirror . provider . sun15 . Method ) ( AnnotatedElement ) method ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "checkstyle", "and", "update", "source", "to", "comply", ".", "Add", "Travis", "CI", "config", "."], "add_tokens": "static final class ColorState extends ConstantState {", "del_tokens": "final static class ColorState extends ConstantState {", "commit_type": "add"}
{"commit_tokens": ["Changes", "the", "type", "of", "accessTokenDuration", "refreshTokenDuration", "and", "idTokenDuration", "of", "Service", "from", "int", "to", "long", "."], "add_tokens": "private static final long serialVersionUID = 10L ; private long accessTokenDuration ; private long refreshTokenDuration ; private long idTokenDuration ; public long getAccessTokenDuration ( ) public Service setAccessTokenDuration ( long duration ) public long getRefreshTokenDuration ( ) public Service setRefreshTokenDuration ( long duration ) public long getIdTokenDuration ( ) public Service setIdTokenDuration ( long duration )", "del_tokens": "private static final long serialVersionUID = 9L ; private int accessTokenDuration ; private int refreshTokenDuration ; private int idTokenDuration ; public int getAccessTokenDuration ( ) public Service setAccessTokenDuration ( int duration ) public int getRefreshTokenDuration ( ) public Service setRefreshTokenDuration ( int duration ) public int getIdTokenDuration ( ) public Service setIdTokenDuration ( int duration )", "commit_type": "change"}
{"commit_tokens": ["improved", "the", "logic", "of", "loading", "the", "native", "DLL", "."], "add_tokens": "import java . net . URL ; loadNativeLibrary ( ) ; } private static void loadNativeLibrary ( ) { try { // load the native part of the code. // first try java.library.path System . loadLibrary ( \"com4j\" ) ; return ; } catch ( Throwable t ) { ; } // try loading com4j.dll in the same directory as com4j.jar URL res = COM4J . class . getClassLoader ( ) . getResource ( \"com4j/COM4J.class\" ) ; String url = res . toExternalForm ( ) ; if ( url . startsWith ( \"jar://\" ) ) { int idx = url . lastIndexOf ( '!' ) ; String filePortion = url . substring ( 6 , idx ) ; if ( filePortion . startsWith ( \"file://\" ) ) { File jarFile = new File ( filePortion . substring ( 7 ) ) ; File dllFile = new File ( jarFile . getParentFile ( ) , \"com4j.dll\" ) ; System . load ( dllFile . getPath ( ) ) ; return ; } } throw new UnsatisfiedLinkError ( \"Unable to load com4j.dll\" ) ;", "del_tokens": "System . loadLibrary ( \"com4j\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "IPoint", ".", "add", "(", "XY", "Point", ")", "."], "add_tokens": "@ Override // from IPoint public Point add ( XY other , Point result ) { return add ( other . x ( ) , other . y ( ) , result ) ; } @ Override // from IPoint @ Override // from IPoint", "del_tokens": "@ Override @ Override", "commit_type": "add"}
{"commit_tokens": ["adding", "sipp", "perf", "test", "for", "load", "balancer", "with", "jboss", "as", "a", "node"], "add_tokens": "ClientTransaction clientTransaction = responseEvent . getClientTransaction ( ) ; try { logger . log ( Level . SEVERE , \"Unexpected exception while forwarding the response \" + response + \" (transaction=\" + clientTransaction + \" / dialog=\" + responseEvent . getDialog ( ) + \"\" , ex ) ;", "del_tokens": "try { ClientTransaction clientTransaction = responseEvent . getClientTransaction ( ) ; logger . log ( Level . SEVERE , \"Unexpected exception while forwarding the response \" + response , ex ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "successful", "parsing", "of", "Ethereum", "Genesis", "block"], "add_tokens": "", "del_tokens": "private byte [ ] hashCache ; public byte [ ] getHashCache ( ) { return hashCache ; } public void setHashCache ( byte [ ] hashCache ) { this . hashCache = hashCache ; } this . hashCache = newEthereumBlockHeader . getHashCache ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "reading", "VARCHAR"], "add_tokens": "case VARCHAR : if ( this . trimRightSpaces || field . getType ( ) == DBFDataType . VARCHAR ) {", "del_tokens": "if ( this . trimRightSpaces ) {", "commit_type": "add"}
{"commit_tokens": ["allow", "use", "of", "JsonDataObject", "when", "adding", "things", "so", "you", "don", "t", "have", "to", "call", "getJsonObject", "()"], "add_tokens": "import com . github . jsonj . JsonDataObject ; import java . util . List ; import java . util . Map ; import java . util . Map . Entry ; public static JsonArray array ( final JsonDataObject ... elements ) { JsonArray jjArray = new JsonArray ( ) ; jjArray . add ( elements ) ; return jjArray ; } public static JsonSet set ( final JsonDataObject ... elements ) { JsonSet jjArray = new JsonSet ( ) ; jjArray . add ( elements ) ; return jjArray ; } } else if ( o instanceof JsonDataObject ) { return ( ( JsonDataObject ) o ) . getJsonObject ( ) ;", "del_tokens": "import java . util . List ; import java . util . Map ; import java . util . Map . Entry ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "trackbacks", "for", "variables", "added", "tests", "."], "add_tokens": "if ( o instanceof Trackable && tree instanceof ParserRuleContext && ! ( tree instanceof cqlParser . LogicContext ) ) { @ Override public Object visitLogic ( @ NotNull cqlParser . LogicContext ctx ) { Object lastResult = null ; // Loop through and call visit on each child (to ensure they are tracked) for ( int i = 0 ; i < ctx . getChildCount ( ) ; i ++ ) { lastResult = visit ( ctx . getChild ( i ) ) ; } // Return last result (consistent with super implementation and helps w/ testing) return lastResult ; }", "del_tokens": "if ( o instanceof Trackable && tree instanceof ParserRuleContext ) { track ( vs , ctx ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "setSchema", "method", "on", "AbstractNFSerializationRecord", "--", "fixes", "compilation", "error", "for", "HashSerializationFramework"], "add_tokens": "private FastBlobSchema schema ; } public void setSchema ( FastBlobSchema schema ) { this . schema = schema ; }", "del_tokens": "private final FastBlobSchema schema ; }", "commit_type": "add"}
{"commit_tokens": ["fixed", "potential", "error", "when", "using", "Stream#collect"], "add_tokens": "( ( Method ) arguments . get ( 1 ) ) . invoke ( null , Arrays . asList ( collectionElement , object ) ) ; return collectionElement ;", "del_tokens": "return ( ( Method ) arguments . get ( 1 ) ) . invoke ( null , Arrays . asList ( collectionElement , object ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "submodule", "issues", "with", "serialization", "of", "javaSparkObj"], "add_tokens": "//engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs//mllib/linalg/Vectors.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs//mllib/linalg/Matrices.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs//mllib/linalg/SingularValueDecomposition.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs//mllib/linalg/distributed/DistributedMatrix.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs//mllib/linalg/distributed/RowMatrix.js\") + \"');\"); // Not blindly loading mllib/regression any more for master or slave //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs/mllib/regression/IsotonicRegression.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs/mllib/regression/GeneralizedLinearModel.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs/mllib/regression/LinearRegressionModel.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs/mllib/regression/LinearRegressionWithSGD.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/eclairjs//mllib/regression/LabeledPoint.js\") + \"');\");", "del_tokens": "//engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/linalg/Vectors.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/linalg/Matrices.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/linalg/SingularValueDecomposition.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/linalg/distributed/DistributedMatrix.js\") + \"');\"); //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/linalg/distributed/RowMatrix.js\") + \"');\"); engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/eclairjs/mllib/regression/IsotonicRegression.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/eclairjs/mllib/regression/GeneralizedLinearModel.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/eclairjs/mllib/regression/LinearRegressionModel.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/eclairjs/mllib/regression/LinearRegressionWithSGD.js\" ) + \"');\" ) ; // Not blindly loading LabeledPoint any more for master or slave //engine.eval(\"load('\" + getResourceAsURLStirng(\"/mllib/regression/LabeledPoint.js\") + \"');\");", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "Asciidoc", "overview", "files", "."], "add_tokens": "import org . asciidoctor . asciidoclet . * ; * < 2 > The - overview option may refer to an Asciidoc file . If the file 's extension does not match * one of ` . ad ` , ` . adoc ` , ` . asciidoc ` or ` . txt ` , then the file is ignored and will be processed * by the standard doclet as an HTML overview . * return iterator . render ( rootDoc , renderer ) && standardAdapter . start ( rootDoc ) ;", "del_tokens": "import org . asciidoctor . asciidoclet . AsciidoctorRenderer ; import org . asciidoctor . asciidoclet . DocletIterator ; import org . asciidoctor . asciidoclet . DocletRenderer ; import org . asciidoctor . asciidoclet . StandardAdapter ; iterator . render ( rootDoc , renderer ) ; return standardAdapter . start ( rootDoc ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "polling", "interval", "configurable", "."], "add_tokens": "protected static int pollingInterval = 500 ; Thread . sleep ( pollingInterval ) ;", "del_tokens": "Thread . sleep ( 500 ) ;", "commit_type": "make"}
{"commit_tokens": ["Removing", "IntHolder", "and", "using", "HPPC", "s", "one", ".", "|"], "add_tokens": "import java . util . * ; import com . carrotsearch . hppc . mutables . IntHolder ;", "del_tokens": "import java . util . HashMap ; import java . util . Map ; import java . util . Random ; private static final class IntHolder { int value ; IntHolder ( int initial ) { value = initial ; } }", "commit_type": "remove"}
{"commit_tokens": ["Allow", "to", "match", "for", "other", "types", "then", "String", "in", "Condition", ".", "withPostBodyContainingJsonPath", "()", "method"], "add_tokens": "public static Condition withPostBodyContainingJsonPath ( final String pattern , final Object value ) {", "del_tokens": "public static Condition withPostBodyContainingJsonPath ( final String pattern , final String value ) {", "commit_type": "allow"}
{"commit_tokens": ["Updated", "the", "REST", "Reader", "to", "allow", "getting", "the", "closest", "Translation", "for", "a"], "add_tokens": "import java . util . HashSet ; import java . util . Set ; private Map < ErrorLevel , Set < String > > errors = new HashMap < ErrorLevel , Set < String > > ( ) ; public Map < ErrorLevel , Set < String > > getErrors ( ) public void setErrors ( final Map < ErrorLevel , Set < String > > errors ) errors . put ( level , new HashSet < String > ( ) ) ; public Set < String > getItemsOfType ( final ErrorLevel level ) return new HashSet < String > ( ) ;", "del_tokens": "import java . util . Collections ; private Map < ErrorLevel , ArrayList < String > > errors = new HashMap < ErrorLevel , ArrayList < String > > ( ) ; public Map < ErrorLevel , ArrayList < String > > getErrors ( ) public void setErrors ( final Map < ErrorLevel , ArrayList < String > > errors ) errors . put ( level , new ArrayList < String > ( ) ) ; public List < String > getItemsOfType ( final ErrorLevel level ) return Collections . emptyList ( ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "new", "options", "to", "url", "tag"], "add_tokens": "private Boolean useRootPath = null ; private Boolean secureCdnSubdomain = null ; private String urlSuffix = null ; if ( useRootPath != null ) url . useRootPath ( useRootPath ) ; if ( urlSuffix != null ) url . suffix ( urlSuffix ) ; if ( secureCdnSubdomain != null ) url . secureCdnSubdomain ( secureCdnSubdomain ) ; public Boolean getUseRootPath ( ) { return useRootPath ; } public void setUseRootPath ( Boolean useRootPath ) { this . useRootPath = useRootPath ; } public Boolean getSecureCdnSubdomain ( ) { return secureCdnSubdomain ; } public void setSecureCdnSubdomain ( Boolean secureCdnSubdomain ) { this . secureCdnSubdomain = secureCdnSubdomain ; } public String getUrlSuffix ( ) { return urlSuffix ; } public void setUrlSuffix ( String urlSuffix ) { this . urlSuffix = urlSuffix ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Implemented", "all", "necessary", "entities", "for", "lib", "-", "eventbus", "."], "add_tokens": "package android . ext . core ;", "del_tokens": "package android . ext . app ;", "commit_type": "implement"}
{"commit_tokens": ["Using", "LinkedHashSet", "instead", "of", "ArrayList", "for", "parents", "and", "children", "to", "detect", "duplicates", "."], "add_tokens": "import java . util . Set ; private final Set < PageRef > unmodifiableParentPages ; public Book ( String name , String cvsworkDirectory , Set < PageRef > parentPages , Properties properties ) { this . unmodifiableParentPages = AoCollections . optimalUnmodifiableSet ( parentPages ) ; public Set < PageRef > getParentPages ( ) {", "del_tokens": "import java . util . List ; private final List < PageRef > unmodifiableParentPages ; public Book ( String name , String cvsworkDirectory , List < PageRef > parentPages , Properties properties ) { this . unmodifiableParentPages = AoCollections . optimalUnmodifiableList ( parentPages ) ; public List < PageRef > getParentPages ( ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "contains", "function"], "add_tokens": "import static org . junit . Assert . * ; @ Test public void containsWithCaseSensitiveFalse_shouldReturnTrueWhenStringContainsNeedle ( ) throws Exception { String [ ] fixture = { \"foo bar\" , \"bar foo\" , \"foobar\" , \"foo\" } ; Arrays . stream ( fixture ) . forEach ( el -> assertTrue ( contains ( el , \"FOO\" ) ) ) ; } @ Test public void containsWithCaseSensitiveTrue_shouldReturnTrueWhenStringContainsNeedle ( ) throws Exception { String [ ] fixture = { \"foo bar\" , \"bar foo\" , \"foobar\" , \"foo\" } ; Arrays . stream ( fixture ) . forEach ( el -> assertFalse ( contains ( el , \"FOO\" , true ) ) ) ; }", "del_tokens": "import static org . junit . Assert . assertThat ;", "commit_type": "add"}
{"commit_tokens": ["fix", "exception", "handling", "when", "invoking", "handler", "methods"], "add_tokens": "import java . lang . reflect . InvocationTargetException ; catch ( InvocationTargetException e ) { Throwable target = e . getTargetException ( ) ; if ( target instanceof RpcException ) { resp = new RpcResponse ( req , ( RpcException ) target ) ; } else { logger . throwing ( \"Server\" , \"call\" , target ) ; resp = new RpcResponse ( req , RpcException . Error . UNKNOWN . exc ( target . getClass ( ) . getName ( ) + \": \" + target . getMessage ( ) ) ) ; }", "del_tokens": "catch ( RpcException e ) { resp = new RpcResponse ( req , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "only", "rely", "on", "ArquillianDescriptor", "creation", "event"], "add_tokens": "public void startup ( @ Observes ( precedence = - 100 ) ArquillianDescriptor descriptor ) {", "del_tokens": "public void startup ( @ Observes ( precedence = - 100 ) ManagerStarted event , ArquillianDescriptor descriptor ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "unions", "to", "TTextProtocol", "."], "add_tokens": "* Returns the Java class for the field name if it is an enum or a struct , protected Class < ? > getClassByFieldName ( String fieldName ) {", "del_tokens": "import org . apache . thrift . TEnum ; * Returns the Java enum class for the field name if it is an enum , protected Class < ? extends TEnum > getEnumClassByFieldName ( String fieldName ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "minor", "Bugs", "/", "wrong", "spelling"], "add_tokens": "eventManagerTestSetup . testListenerFalse ( isWorking , \"1\" ) ;", "del_tokens": "eventManagerTestSetup . testListenerfalse ( isWorking , \"1\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "system", "property", "qa", ".", "th", ".", "comm", ".", "ws", ".", "SO_TIMEOUT"], "add_tokens": "import org . apache . http . config . SocketConfig ; public static final String SYSPROP_SO_TIMEOUT = \"qa.th.comm.ws.SO_TIMEOUT\" ; cm . setDefaultSocketConfig ( SocketConfig . custom ( ) . setSoTimeout ( sysConfig . getIntProperty ( SYSPROP_SO_TIMEOUT , 0 ) ) . build ( ) ) ; WebServiceCommunication ws = new WebServiceCommunication ( \"127.0.0.0\" , 18088 ) ; headers = WebServiceCommunication . headUri ( \"https://127.0.0.1:18088/thr/dashboard.xhtml\" ) ;", "del_tokens": "WebServiceCommunication ws = new WebServiceCommunication ( \"ec2-54-226-209-194.compute-1.amazonaws.com\" , 9000 ) ; headers = WebServiceCommunication . headUri ( \"https://ec2-54-226-209-194.compute-1.amazonaws.com:9443/thr/dashboard.xhtml\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "@RestController", "to", "default", "server", "config"], "add_tokens": "@ Import ( { ZipkinServerConfiguration . class , ZipkinQueryApiV1 . class } )", "del_tokens": "@ Import ( { ZipkinServerConfiguration . class } )", "commit_type": "add"}
{"commit_tokens": ["Added", "24", "hour", "support", "for", "time", "picker", "."], "add_tokens": "private boolean autoClose = true ; private boolean hour24 ; / * * * False ( default ) change to 24 hours system . * @ return * / public boolean isHour24 ( ) { return hour24 ; } public void setHour24 ( boolean hour24 ) { this . hour24 = hour24 ; } initTimePicker ( input . getElement ( ) , getOrientation ( ) . getCssName ( ) , isAutoClose ( ) , isHour24 ( ) ) ; protected native void initTimePicker ( Element e , String orientation , boolean autoClose , boolean hour24 ) / * - { orientation : orientation , hour24 : hour24", "del_tokens": "private boolean autoClose ; initTimePicker ( input . getElement ( ) , getOrientation ( ) . getCssName ( ) , isAutoClose ( ) ) ; protected native void initTimePicker ( Element e , String orientation , boolean autoClose ) / * - { orientation : orientation", "commit_type": "add"}
{"commit_tokens": ["Make", "OutputStream", "use", "UTF", "-", "8", "Charset"], "add_tokens": "OutputStreamWriter out = new OutputStreamWriter ( conn . getOutputStream ( ) , \"UTF-8\" ) ;", "del_tokens": "OutputStreamWriter out = new OutputStreamWriter ( conn . getOutputStream ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "method", "for", "interaction", "model"], "add_tokens": "/ * * * Get the LDP interaction model for this resource * @ return the interaction model * / IRI getInteractionModel ( ) ;", "del_tokens": "/ * * * Test whether this resource is an LDP Container * @ return whether the resource is a Container * / default Boolean isContainer ( ) { return false ; } / * * * Test whether this resource is an LDP Direct Container * @ return whether the resource is a Direct Container * / default Boolean isDirectContainer ( ) { return false ; } / * * * Test whether this resource is an LDP Indirect Container * @ return whether the resource is an Indirect Container * / default Boolean isIndirectContainer ( ) { return false ; } / * * * Test whether this resource is an LDP RdfSource * @ return whether the resource is a RDF resource * / default Boolean isRdfSource ( ) { return false ; } / * * * Test whether this resource is an LDP NonRdfSource * @ return whether the resource is a Non - RDF resource * / default Boolean isNonRdfSource ( ) { return false ; }", "commit_type": "add"}
{"commit_tokens": ["Made", "EntityBuilder#createRole", "(", "String", "Guild", ")", "add", "the", "created", "Role", "to", "the", "Guild", "."], "add_tokens": "role . setName ( roleJson . getString ( \"name\" ) ) . setPosition ( roleJson . getInt ( \"position\" ) ) . setPermissions ( roleJson . getInt ( \"permissions\" ) ) . setManaged ( roleJson . getBoolean ( \"managed\" ) ) . setHoist ( roleJson . getBoolean ( \"hoist\" ) ) . setColor ( roleJson . getInt ( \"color\" ) ) ; guild . getRolesMap ( ) . put ( id , role ) ; return role ;", "del_tokens": "return role . setName ( roleJson . getString ( \"name\" ) ) . setPosition ( roleJson . getInt ( \"position\" ) ) . setPermissions ( roleJson . getInt ( \"permissions\" ) ) . setManaged ( roleJson . getBoolean ( \"managed\" ) ) . setHoist ( roleJson . getBoolean ( \"hoist\" ) ) . setColor ( roleJson . getInt ( \"color\" ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "Javadoc", "link", "."], "add_tokens": "* { @ link com . github . msoliter . iroh . container . annotations . Autowired } * annotation .", "del_tokens": "* { @ link @ Autowired } annotation .", "commit_type": "fix"}
{"commit_tokens": ["moved", "sql", "API", "to", "sql", "folder"], "add_tokens": "engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/sql/DataFrame.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/sql/DataFrameReader.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/sql/SQLContext.js\" ) + \"');\" ) ;", "del_tokens": "engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/DataFrame.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/SQLContext.js\" ) + \"');\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "service", "bus", "hashed", "namespace", "for", "BI", "."], "add_tokens": "final HashMap < String , String > events = new HashMap < > ( ) ; events . put ( TelemetryData . SERVICE_NAME , getClass ( ) . getPackage ( ) . getName ( ) . replaceAll ( \"\\\\w+\\\\.\" , \"\" ) ) ; events . put ( TelemetryData . ACCOUNT_HASH_NAME , sha256Hex ( properties . getAccountName ( ) ) ) ; telemetryProxy . trackEvent ( ClassUtils . getUserClass ( this . getClass ( ) ) . getSimpleName ( ) , events ) ;", "del_tokens": "final HashMap < String , String > customTelemetryProperties = new HashMap < > ( ) ; final String [ ] packageNames = this . getClass ( ) . getPackage ( ) . getName ( ) . split ( \"\\\\.\" ) ; if ( packageNames . length > 1 ) { customTelemetryProperties . put ( TelemetryData . SERVICE_NAME , packageNames [ packageNames . length - 1 ] ) ; } customTelemetryProperties . putIfAbsent ( TelemetryData . ACCOUNT_HASH_NAME , sha256Hex ( properties . getAccountName ( ) ) ) ; telemetryProxy . trackEvent ( ClassUtils . getUserClass ( this . getClass ( ) ) . getSimpleName ( ) , customTelemetryProperties ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "method", "and", "enum", "values", "to", "ClassType", "test"], "add_tokens": "VALUE_ADDED", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "ProcessorUtils", ".", "getNumCores", "returning", "0", "when", "it", "fails", "to", "search", "directory"], "add_tokens": "import android . util . Log ; return Runtime . getRuntime ( ) . availableProcessors ( ) ; //Return the number of cores (virtual CPU devices)", "del_tokens": "//Return the number of cores (virtual CPU devices) return 0 ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "message", "filtering", "on", "destinations", "."], "add_tokens": "public class UserInterfaceDestination < M > extends FilterDestination < M > { private final static Logger logger = LoggerFactory . getLogger ( UserInterfaceDestination . class ) ; * * @ param destination * the filtered destination . public UserInterfaceDestination ( Destination < M > destination ) { super ( destination ) ; } @ Override public String getId ( ) { return \"UserInterface@\" + destination . getId ( ) ;", "del_tokens": "public class UIDestinationAdapter < M > implements Destination < M > { private final static Logger logger = LoggerFactory . getLogger ( UIDestinationAdapter . class ) ; / * * * The adapted destination * / private Destination < M > destination ; * public UIDestinationAdapter ( Destination < M > destination ) { this . destination = destination ;", "commit_type": "implement"}
{"commit_tokens": ["improving", "the", "code", "readability", "and", "cleaning", "up", "a", "bit"], "add_tokens": "StringBuffer sb = new StringBuffer ( \"priority queue of \" ) . append ( this . elements . size ( ) ) . append ( \" nodes:\\n\" ) ;", "del_tokens": "StringBuffer sb = new StringBuffer ( \"Nodes: \" ) . append ( this . elements . size ( ) ) . append ( \"\\n\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["remove", "unused", "parameters", "from", "deployment"], "add_tokens": ". of ( \"deploy\" , appYaml1 . toString ( ) , \"--bucket\" , \"gs://a-bucket\" , \"--image-url\" , \"imageUrl\" , \"--promote\" , \"--server\" , \"appengine.google.com\" , \"--stop-previous-version\" , \"--version\" , \"v1\" , \"--project\" , \"project\" ) ; . of ( \"deploy\" , appYaml1 . toString ( ) , \"--no-promote\" , \"--no-stop-previous-version\" ) ;", "del_tokens": "configuration . setDockerBuild ( \"cloud\" ) ; configuration . setForce ( true ) ; . of ( \"deploy\" , appYaml1 . toString ( ) , \"--bucket\" , \"gs://a-bucket\" , \"--docker-build\" , \"cloud\" , \"--force\" , \"--image-url\" , \"imageUrl\" , \"--promote\" , \"--server\" , \"appengine.google.com\" , \"--stop-previous-version\" , \"--version\" , \"v1\" , \"--project\" , \"project\" ) ; configuration . setForce ( false ) ; . of ( \"deploy\" , appYaml1 . toString ( ) , \"--no-force\" , \"--no-promote\" , \"--no-stop-previous-version\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "in", "support", "for", "globally", "handling", "not", "found", "and", "unhandled", "exceptions"], "add_tokens": "import org . springframework . web . servlet . NoHandlerFoundException ; @ ExceptionHandler ( Exception . class ) public String oops ( Exception e ) { return \"oops\" ; } @ ExceptionHandler ( NoHandlerFoundException . class ) public String notFound ( NoHandlerFoundException e ) { return \"notFound\" ; }", "del_tokens": "import org . springframework . web . servlet . ModelAndView ; import org . statefulj . webapp . form . RegistrationForm ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "exclude", "strategy", "attribute", "in", "@Json", "annotation", "and", "some", "tests"], "add_tokens": "import es . cenobit . struts2 . json . example . objects . Etc ; public Bar barWithExcludeFields ( ) { @ Json ( exclude = { \"id\" , \"Bar.title\" , \"Bar.status\" } ) public Foo fooWithExcludeFields ( ) { @ Json public Etc etc ( ) { Bar bar = new Bar ( 1L , \"Mussum ipsum\" , \" M faiz elementum girarzis, nisi eros vermeio, in elementis m pra quem  amistosis quis leo\", new Date ( ) , Boolean . TRUE ) ; Foo foo = new Foo ( 2L , \"Interessantiss\" , bar ) ; Etc etc = new Etc ( 42L , \"Cevadis\" , bar , foo ) ; return etc ; } @ Json ( exclude = { \"id\" , \"Bar.title\" , \"Bar.status\" , \"Foo\" } ) public Etc etcWithExcludeFields ( ) { Bar bar = new Bar ( 1L , \"Mussum ipsum\" , \" M faiz elementum girarzis, nisi eros vermeio, in elementis m pra quem  amistosis quis leo\", new Date ( ) , Boolean . TRUE ) ; Foo foo = new Foo ( 2L , \"Interessantiss\" , bar ) ; Etc etc = new Etc ( 42L , \"Cevadis\" , bar , foo ) ; return etc ; }", "del_tokens": "public Bar barExcludes ( ) { @ Json ( exclude = { \"id\" , \"bar.title\" , \"bar.status\" } ) public Foo fooExcludes ( ) {", "commit_type": "add"}
{"commit_tokens": ["Implemented", "support", "for", "client", "coverage", "monitoring", ";"], "add_tokens": "import java . io . File ; private CoverageMonitor coverageMonitor ; this . testPath = core . getTestPath ( ) ; this . coverageMonitor = new CoverageMonitor ( this . url , new File ( core . getLogDir ( ) , core . getTestPath ( ) ) ) ; / * * * Determines which server capabilities are exercised by this query . * * @ param query * The ( decoded ) query string extracted from the request URI . * / public void checkCoverage ( String query ) { this . coverageMonitor . inspectQuery ( query ) ; } @ Override public String toString ( ) { return \"MonitorCall [url=\" + url + \", localName=\" + localName + \", NamespaceURI=\" + NamespaceURI + \", callId=\" + callId + \", modifiesResponse=\" + modifiesResponse + \", testPath=\" + testPath + \"]\" ; }", "del_tokens": "testPath = core . getTestPath ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "performance", "jitter", "caused", "by", "header", "draw", "alpha", "."], "add_tokens": "if ( mHeaderBottomPosition != headerHeight ) { canvas . saveLayerAlpha ( 0 , 0 , canvas . getWidth ( ) , canvas . getHeight ( ) , 255 * mHeaderBottomPosition / headerHeight , Canvas . ALL_SAVE_FLAG ) ; }", "del_tokens": "canvas . saveLayerAlpha ( 0 , 0 , canvas . getWidth ( ) , canvas . getHeight ( ) , ( int ) ( 0xff * ( float ) mHeaderBottomPosition / headerHeight ) , Canvas . HAS_ALPHA_LAYER_SAVE_FLAG ) ;", "commit_type": "fix"}
{"commit_tokens": ["Used", "more", "robust", "hashCode", "()", "and", "equals", "()"], "add_tokens": "if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; Message message = ( Message ) o ; if ( ! Arrays . equals ( payload , message . payload ) ) return false ; return ! ( routingKey != null ? ! routingKey . equals ( message . routingKey ) : message . routingKey != null ) ; int result = routingKey != null ? routingKey . hashCode ( ) : 0 ; result = 31 * result + ( payload != null ? Arrays . hashCode ( payload ) : 0 ) ; return result ;", "del_tokens": "if ( o == null || ! ( o instanceof Message ) ) { return false ; } Message m = ( Message ) o ; return routingKey . equals ( m . routingKey ) && Arrays . equals ( payload , m . payload ) ; int routingKeyHash = routingKey . hashCode ( ) ; int messageHash = payload . hashCode ( ) ; return routingKeyHash + messageHash ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "semi", "-", "colon", "to", "full", "stop", "in", "comment", ".", "As", "requested", "by", "@domesticmouse"], "add_tokens": "* Sets the default channel for requests ( can be overridden by requests ) . Only useful for Google Maps for Work clients .", "del_tokens": "* Sets the default channel for requests ( can be overridden by requests ) . Only useful for Google Maps for Work clients ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "test", "dependency", "manager", "injection"], "add_tokens": "@ SuppressWarnings ( \"FieldMayBeFinal\" ) private static Object DEPENDENCY_MANAGER = DEFAULT ; // used only by tests protected Capsule ( Path jarFile , Path cacheDir ) { this . dependencyManager = DEPENDENCY_MANAGER != DEFAULT ? DEPENDENCY_MANAGER : tryCreateDependencyManager ( ) ;", "del_tokens": "protected Capsule ( Path jarFile , Path cacheDir ) { this ( jarFile , cacheDir , DEFAULT ) ; } // Used directly by tests private Capsule ( Path jarFile , Path cacheDir , Object dependencyManager ) { this . dependencyManager = dependencyManager != DEFAULT ? dependencyManager : tryCreateDependencyManager ( ) ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "some", "geometrytyep", "issues", "-", "brought", "back", "the", "r2v", "v2r", "testcase", "to", "normality"], "add_tokens": "import static org . jgrasstools . gears . utils . geometry . GeometryUtilities . * ; import static org . jgrasstools . gears . utils . geometry . GeometryUtilities . * ; import org . opengis . feature . type . GeometryType ; GeometryType type = inGeodata . getSchema ( ) . getGeometryDescriptor ( ) . getType ( ) ; if ( getGeometryType ( type ) == GEOMETRYTYPE . POINT || getGeometryType ( type ) == GEOMETRYTYPE . MULTIPOINT ) { } else if ( getGeometryType ( type ) == GEOMETRYTYPE . LINE || getGeometryType ( type ) == GEOMETRYTYPE . MULTILINE ) { } else if ( getGeometryType ( type ) == GEOMETRYTYPE . POLYGON || getGeometryType ( type ) == GEOMETRYTYPE . MULTIPOLYGON ) {", "del_tokens": "String geometryType = inGeodata . getSchema ( ) . getGeometryDescriptor ( ) . getType ( ) . toString ( ) ; if ( geometryType . matches ( \".*[Pp][Oo][Ii][Nn][Tt].*\" ) ) { } else if ( geometryType . matches ( \".*[Ll][Ii][Nn][Ee].*\" ) ) { } else if ( geometryType . matches ( \".*[Pp][Oo][Ll][Yy][Gg][Oo][Nn].*\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "setting", "sync", "parameters"], "add_tokens": "public YubicoClientImpl ( Integer id , String key , String sync ) { this . clientId = id ; setKey ( key ) ; setSync ( sync ) ; } String syncParam = \"\" ; if ( sync != null ) { syncParam = String . format ( \"&sl=%s\" , sync ) ; } String paramStr = String . format ( \"id=%d&nonce=%s&otp=%s%s&timestamp=%s\" , clientId , nonce , otp , syncParam , \"1\" ) ;", "del_tokens": "String paramStr = String . format ( \"id=%d&nonce=%s&otp=%s&timestamp=%s\" , clientId , nonce , otp , \"1\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "additional", "parameter", "to", "JWPLDataMachine", "to", "define", "the", "prefix", "for", "discussion", "pages", "(", "currently", "the", "parameter", "is", "not", "necessary", ")"], "add_tokens": "private static final int DATADIR_ARG = 3 ; + \"\\tjava -jar JWPLDataMachine.jar <LANGUAGE> <TOP_CATEGORY_NAME> <DISAMBIGUATION_CATEGORY_NAME> <SOURCE_DIRECTORY>\\n\\n\" if ( args . length > 3 ) {", "del_tokens": "private static final int DISCUSSION_ARG = 3 ; private static final int DATADIR_ARG = 4 ; + \"\\tjava -jar JWPLDataMachine.jar <LANGUAGE> <TOP_CATEGORY_NAME> <DISAMBIGUATION_CATEGORY_NAME> <DISCUSSION_CATEGORY_PREFIX> <SOURCE_DIRECTORY>\\n\\n\" if ( args . length > 4 ) { config . setDiscussionCategoryPrefix ( args [ DISCUSSION_ARG ] ) ;", "commit_type": "remove"}
{"commit_tokens": ["Changed", "startUpdates", "()", "to", "startUpdates", "(", "boolean", "getPreviousUpdates", ")", "to", "allow", "the", "user", "to", "ignore", "all", "cached", "updates", "since", "the", "bot", "started", "up"], "add_tokens": "public void startUpdates ( boolean getPreviousUpdates ) { updateManager = new RequestUpdatesManager ( this , getPreviousUpdates ) ;", "del_tokens": "public void startUpdates ( ) { updateManager = new RequestUpdatesManager ( this ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "basic", "test", "view", "not", "completed", "but", "compiles", "and", "pullable", "."], "add_tokens": "} ) // . setPrettyPrinting ( ) // . create ( ) ;", "del_tokens": "} ) . create ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "feature", "to", "restrain", "the", "DatePicker", "and", "TimePicker", "to", "stay", "inside", "the", "screen", "working", "area", "."], "add_tokens": "// Calculate the default origin for the popup. int defaultX = timeTextField . getLocationOnScreen ( ) . x ; int defaultY = timeTextField . getLocationOnScreen ( ) . y + timeTextField . getSize ( ) . height - 1 ; // Set the popup location. (Shared function.) DatePicker . zSetPopupLocation ( popup , defaultX , defaultY , this , timeTextField , - 1 , 1 ) ;", "del_tokens": "// int popupX = toggleTimeMenuButton.getLocationOnScreen().x // + toggleTimeMenuButton.getBounds().width - popup.getBounds().width; int popupX = timeTextField . getLocationOnScreen ( ) . x ; // int popupY = toggleTimeMenuButton.getLocationOnScreen().y // + toggleTimeMenuButton.getBounds().height - 1; int popupY = timeTextField . getLocationOnScreen ( ) . y + timeTextField . getSize ( ) . height - 1 ; popup . setLocation ( popupX , popupY ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "comments", "to", "the", "fields", "in", "the", "emitted", "constructor", "case", "classes"], "add_tokens": "import com . pogofish . jadt . ast . JavaComment ; final List < JavaComment > javaDoc = commentProcessor . leftAlign ( commentProcessor . javaDocOnly ( constructor . comments ) ) ; final List < JavaComment > paramDoc = commentProcessor . paramDoc ( arg . name , javaDoc ) ; sink . write ( ASTPrinter . printComments ( \" \" , paramDoc ) ) ;", "del_tokens": "// TODO javadoc for fields", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "option", "to", "use", "SC", "-", "Zookeeper", "in", "a", "non", "-", "web", "app"], "add_tokens": "import com . netflix . client . config . IClientConfig ; import com . netflix . loadbalancer . AbstractServerList ; if ( this . serviceDiscovery == null ) { return Collections . EMPTY_LIST ; }", "del_tokens": "import com . netflix . client . config . IClientConfig ; import com . netflix . loadbalancer . AbstractServerList ;", "commit_type": "add"}
{"commit_tokens": ["Changing", "JComboBoxOperator", ".", "WaitListTimeout", "from", "60s", "to", "10s"], "add_tokens": "props . put ( \"JComboBoxOperator.WaitListTimeout\" , \"10000\" ) ;", "del_tokens": "props . put ( \"JComboBoxOperator.WaitListTimeout\" , \"60000\" ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "locating", "pominfo", ".", "properties", "of", "the", "application"], "add_tokens": "public void loadApplication ( Resolver resolver , Node docroot , Node descriptor ) throws IOException { // pws removes WEB-INF classes and uses target/classes instead ... properties = docroot . getParent ( ) . join ( \"classes\" , PROJECT_PROPERTIES ) ; System . out . println ( \"check:\" + properties + \" \" + properties . isFile ( ) ) ; if ( ! properties . isFile ( ) ) { properties = docroot . join ( \"WEB-INF/classes\" , PROJECT_PROPERTIES ) ; } loadLibrary ( resolver , docroot , descriptor , properties ) ; / * * * Core method for loading . A library is a module or an application * @ param base jar file for module , docroot for application * /", "del_tokens": "public void loadApplication ( Resolver resolver , Node base , Node descriptor ) throws IOException { properties = resolver . resolve ( base , \"WEB-INF/classes/\" + PROJECT_PROPERTIES ) ; loadLibrary ( resolver , base , descriptor , properties ) ; /** Core method for loading. A library is a module or an application */", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "boolean", "for", "indicating", "whether", "the", "initializer", "is", "static", "or", "not"], "add_tokens": "* @ param isStatic true if it should be an static initializer , false for an instance initializer . public JavaWriter beginInitializer ( Boolean isStatic ) throws IOException { if ( isStatic ) { out . write ( \"static\" ) ; out . write ( \" {\\n\" ) ; } else { out . write ( \"{\\n\" ) ; }", "del_tokens": "* @ param type such as \"static\" . public JavaWriter beginInitializer ( String type ) throws IOException { out . write ( type ) ; out . write ( \" {\\n\" ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "VersionClass", "to", "expose", "the", "gradle", "version", "number", "as", "a", "Java", "class"], "add_tokens": "import com . tiemens . secretshare . BuildVersion ; * Based on the first argument in args [ ] , this calls one of : return BuildVersion . UI_VERSION ;", "del_tokens": "* Based on the 1 st argument , calls one of : return \"1.3.0\" ;", "commit_type": "add"}
{"commit_tokens": ["Made", "coverBoundingBox", "()", "26%", "faster", "by", "avoiding", "building", "a", "TreeMap", "and", "using", "an", "array", "instead", "."], "add_tokens": "import java . util . Arrays ; private final long [ ] hashes ; private final int count ; public CoverageLongs ( long [ ] hashes , int count , double ratio ) { this . count = count ; public long [ ] getHashes ( ) { return Arrays . copyOf ( hashes , count ) ; if ( count == 0 ) return ( int ) ( hashes [ 0 ] & 0x0f ) ; return \"Coverage [hashes=\" + getHashes ( ) + \", ratio=\" + ratio + \"]\" ; } public int getCount ( ) { return count ;", "del_tokens": "import java . util . Set ; private final Set < Long > hashes ; public CoverageLongs ( Set < Long > hashes , double ratio ) { public Set < Long > getHashes ( ) { return hashes ; if ( hashes . size ( ) == 0 ) return ( int ) ( hashes . iterator ( ) . next ( ) & 0x0f ) ; return \"Coverage [hashes=\" + hashes + \", ratio=\" + ratio + \"]\" ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "/", "refactored", "some", "of", "the", "management", "support", "for", "messaging", "specifically", "dependency", "injection", "in", "place", "of", "static", "accessors", "and", "incorrect", "bean", "id", "fix"], "add_tokens": "import org . springframework . jms . core . JmsTemplate ; private JmsTemplate jmsTopicTemplate ; private JmsTemplate jmsQueueTemplate ; / * * * @ param jmsTopicTemplate - Template for Topic usage * @ param jmsQueueTemplate - Template for Queue usage * / public MessagingSupport ( final JmsTemplate jmsTopicTemplate , final JmsTemplate jmsQueueTemplate ) { this . jmsTopicTemplate = jmsTopicTemplate ; this . jmsQueueTemplate = jmsQueueTemplate ; } this . jmsTopicTemplate . send ( EventUtil . getTopicName ( eventName ) , new MessageCreator ( ) { this . jmsQueueTemplate . send ( destinationName , new MessageCreator ( ) {", "del_tokens": "import org . carewebframework . activemq . EventUtil ; EventUtil . getJmsTopicTemplate ( ) . send ( EventUtil . getTopicName ( eventName ) , new MessageCreator ( ) { EventUtil . getJmsQueueTemplate ( ) . send ( destinationName , new MessageCreator ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "constant", "singleton", "for", "PeppolURLProvider"], "add_tokens": "private static final IPeppolURLProvider URL_PROVIDER = PeppolURLProvider . INSTANCE ;", "del_tokens": "private static final IPeppolURLProvider URL_PROVIDER = new PeppolURLProvider ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "unclosed", "<p", ">", "tag", "in", "BoxAPIRequest", "javadocs"], "add_tokens": "* reported as 0. < / p >", "del_tokens": "* reported as 0. < p >", "commit_type": "fix"}
{"commit_tokens": ["Make", "URLConnections", "disconnect", "at", "appropriate", "times", "."], "add_tokens": "try { content . set ( readFromConnection ( connection ) ) ; contentType . set ( connection . getContentType ( ) ) ; } finally { if ( connection instanceof HttpURLConnection ) { ( ( HttpURLConnection ) connection ) . disconnect ( ) ; } }", "del_tokens": "content . set ( readFromConnection ( connection ) ) ; contentType . set ( connection . getContentType ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "support", "for", "PUT", "HTTP", "operations"], "add_tokens": "GET , POST , DELETE , HEAD , PUT @ Nullable public JsonElement putRequest ( @ NotNull String path , @ NotNull Header ... headers ) throws RestApiException { return request ( authData , path , null , Arrays . asList ( headers ) , HttpVerb . PUT ) ; } HttpEntity entity = response . getEntity ( ) ; if ( entity == null ) { return null ; InputStream resp = entity . getContent ( ) ; case PUT : method = new HttpPut ( uri ) ; break ;", "del_tokens": "GET , POST , DELETE , HEAD InputStream resp = response . getEntity ( ) . getContent ( ) ; if ( resp == null ) { String message = String . format ( \"Unexpectedly empty response.\" ) ; LOG . warn ( message ) ; throw new RestApiException ( message ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "duplicate", "types", "returned", "in", "EntityModel", ".", "allTypes"], "add_tokens": "import java . util . Set ; Set < Type < ? > > allTypes ( ) ;", "del_tokens": "import java . util . Collection ; Collection < Type < ? > > allTypes ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "the", "user", "to", "prevent", "cleanup", "of", "the", "PG", "data", "directory", "via", "a", "system", "property"], "add_tokens": "if ( System . getProperty ( \"ness.epg.no-cleanup\" ) == null ) { FileUtils . deleteDirectory ( dataDirectory ) ; } else { LOG . info ( \"Did not clean up directory %s\" , dataDirectory . getAbsolutePath ( ) ) ; }", "del_tokens": "FileUtils . deleteDirectory ( dataDirectory ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "bugs", "in", "replication", "of", "configurations", "."], "add_tokens": "private boolean complete ; if ( ! complete && doneHandler != null ) { complete = true ; complete = true ;", "del_tokens": "if ( doneHandler != null ) {", "commit_type": "fix"}
{"commit_tokens": ["move", "parameters", "to", "appropriate", "goals"], "add_tokens": "/ * * * Whether to allow SNAPSHOT versions in dependencies . * * @ since 1.2 . 2 * / @ Parameter ( property = \"allowSnapshots\" , defaultValue = \"false\" ) private boolean allowSnapshots = false ; * Whether to push to the remote . * @ since 1.3 . 0 @ Parameter ( property = \"pushRemote\" , defaultValue = \"true\" ) private boolean pushRemote ; / * * * Whether to use < code > -- ff - only < / code > option when merging . * * @ since 1.4 . 0 * / @ Parameter ( property = \"releaseMergeFFOnly\" , defaultValue = \"false\" ) private boolean releaseMergeFFOnly = false ;", "del_tokens": "* Whether to use < code > -- ff - only < / code > option when merging . * @ since 1.4 . 0 @ Parameter ( property = \"releaseMergeFFOnly\" , defaultValue = \"false\" ) private boolean releaseMergeFFOnly = false ;", "commit_type": "move"}
{"commit_tokens": ["Add", "unit", "tests", "for", "security", "filter"], "add_tokens": "else { throw new IllegalArgumentException ( \"Unknown Portlet Lifecycle Phase: \" + phase ) ; }", "del_tokens": "throw new IllegalArgumentException ( \"Unknown Portlet Lifecycle Phase: \" + phase ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "test", "-", "case", "to", "attr", ".", "shortform"], "add_tokens": "public void addTo_addTwoClasses ( ) throws Exception { @ Test ( expected = IllegalArgumentException . class ) public void addTo_stringWithStupidlyPlacedId ( ) throws Exception { System . out . println ( div ( attrs ( \"id1#id2\" ) ) . render ( ) ) ; }", "del_tokens": "public void addTwo_addTwoClasses ( ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Add", "failsafe", "-", "report", "(", "fix", ")"], "add_tokens": "import org . sitoolkit . wt . gui . infra . util . ResourceUtils ; ResourceUtils . copy ( \"distribution-pom.xml\" , pomFile ) ; ResourceUtils . copy ( \"site.xml\" , new File ( projectDir , \"src/site/site.xml\" ) ) ;", "del_tokens": "import java . io . IOException ; import java . net . URL ; import java . nio . file . Files ; import org . sitoolkit . wt . util . infra . UnExpectedException ; try { URL pomUrl = getClass ( ) . getResource ( \"/distribution-pom.xml\" ) ; Files . copy ( pomUrl . openStream ( ) , pomFile . toPath ( ) ) ; } catch ( IOException e ) { throw new UnExpectedException ( e ) ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "event", "support", "for", "fabric", "Java", "SDK"], "add_tokens": "import org . hyperledger . fabric . sdk . events . EventHub ; import org . hyperledger . fabric . sdk . exception . PeerException ; private EventHub eventHub ; this . eventHub = new EventHub ( ) ; public EventHub getEventHub ( ) { return this . eventHub ; } / * * * Set and connect to the peer to be used as the event source . * / public void eventHubConnect ( String peerUrl , String pem ) { this . eventHub . setPeerAddr ( peerUrl , pem ) ; this . eventHub . connect ( ) ; } ; / * * * Disconnect from the event source . * / public void eventHubDisconnect ( ) { this . eventHub . disconnect ( ) ; } ; } catch ( PeerException exp ) {", "del_tokens": "} catch ( Exception exp ) {", "commit_type": "add"}
{"commit_tokens": ["use", "saxpath", "for", "parsing", "xpath"], "add_tokens": "import org . jaxen . saxpath . SAXPathException ; public Node add ( String xpath ) throws SAXPathException { return add ( xpath , - 1 ) ; } public Node add ( String xpath , int minHits ) throws SAXPathException {", "del_tokens": "public Node add ( String xpath , int minHits ) {", "commit_type": "use"}
{"commit_tokens": ["Implemented", "command", "line", "option", "groups"], "add_tokens": "import de . undercouch . citeproc . helper . tool . OptionGroup ; private static OptionGroup < OID > options = new OptionBuilder < OID > ( ) . add ( new OptionBuilder < OID > ( \"Mendeley:\" ) . add ( OID . MENDELEY , \"mendeley\" , \"read input bibliography from Mendeley Web\" ) . add ( OID . MENDELEY_SYNC , \"mendeley-sync\" , \"synchronize with Mendeley Web, \" + \"implies --mendeley\" ) . build ( ) ) . add ( new OptionBuilder < OID > ( \"Miscellaneous:\" ) . add ( OID . HELP , \"help\" , \"h\" , \"display this help and exit\" ) . add ( OID . VERSION , \"version\" , \"V\" , \"output version information and exit\" ) . build ( ) )", "del_tokens": "import de . undercouch . citeproc . helper . tool . Option ; private static List < Option < OID > > options = new OptionBuilder < OID > ( ) . add ( OID . MENDELEY , \"mendeley\" , \"read input bibliography from Mendeley Web\" ) . add ( OID . MENDELEY_SYNC , \"mendeley-sync\" , \"synchronize with Mendeley Web, \" + \"implies --mendeley\" ) . add ( OID . HELP , \"help\" , \"h\" , \"display this help and exit\" ) . add ( OID . VERSION , \"version\" , \"V\" , \"output version information and exit\" )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "conflicts", "in", "case", "of", "log4j", ".", "properties", "loaded", "from", "the", "class", "path", "has", "conflicting", "entries", "of", "log4j", ".", "rootLogger", "and", "log4j", ".", "rootCategory", "keys", "."], "add_tokens": "private static final String LOG4J_ROOT_LOGGER = \"log4j.rootLogger\" ; private static final String LOG4J_ROOT_CATEGORY = \"log4j.rootCategory\" ; // If log4j properties is passed in as an override ignore the one that is loaded from log4j.properties. // This could be a problem if the loaded one uses \"log4j.rootLogger\" instead of \"log4j.rootCategory\" if ( ( props . getProperty ( LOG4J_ROOT_CATEGORY ) != null || props . getProperty ( LOG4J_ROOT_LOGGER ) != null ) ) { this . props . remove ( LOG4J_ROOT_CATEGORY ) ; this . props . remove ( LOG4J_ROOT_LOGGER ) ; } + consolidatedProps . getProperty ( LOG4J_ROOT_CATEGORY ) ) ; + consolidatedProps . getProperty ( LOG4J_ROOT_LOGGER ) ) ;", "del_tokens": "+ consolidatedProps . getProperty ( \"log4j.rootCategory\" ) ) ; + consolidatedProps . getProperty ( \"log4j.rootLogger\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "NOT", "LIKE", "so", "it", "works", "properly", "now", "."], "add_tokens": "private static final Set < OPEAR > NOT_OPEAR_SET = Sets . newHashSet ( OPEAR . N , OPEAR . NIN , OPEAR . ISN , OPEAR . NBETWEEN , OPEAR . NLIKE ) ; case NLIKE :", "del_tokens": "private static final Set < OPEAR > NOT_OPEAR_SET = Sets . newHashSet ( OPEAR . N , OPEAR . NIN , OPEAR . ISN , OPEAR . NBETWEEN ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "index", "on", "_message", "and", "_host", ".", "now", "also", "using", "new", "keys", "for", "syslog", "messages"], "add_tokens": "coll . ensureIndex ( new BasicDBObject ( \"deleted\" , 1 ) ) ; coll . ensureIndex ( new BasicDBObject ( \"_host\" , 1 ) ) ; coll . ensureIndex ( new BasicDBObject ( \"_message\" , 1 ) ) ; coll . ensureIndex ( new BasicDBObject ( \"_facility\" , 1 ) ) ; coll . ensureIndex ( new BasicDBObject ( \"_level\" , 1 ) ) ; dbObj . put ( \"_message\" , event . getMessage ( ) ) ; dbObj . put ( \"_host\" , event . getHost ( ) ) ; dbObj . put ( \"_facility\" , event . getFacility ( ) ) ; dbObj . put ( \"_level\" , event . getLevel ( ) ) ;", "del_tokens": "// XXX PERFORMANCE coll . ensureIndex ( new BasicDBObject ( \"host\" , 1 ) ) ; coll . ensureIndex ( new BasicDBObject ( \"facility\" , 1 ) ) ; coll . ensureIndex ( new BasicDBObject ( \"level\" , 1 ) ) ; dbObj . put ( \"message\" , event . getMessage ( ) ) ; dbObj . put ( \"host\" , event . getHost ( ) ) ; dbObj . put ( \"facility\" , event . getFacility ( ) ) ; dbObj . put ( \"level\" , event . getLevel ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "exception", "text", "for", "consistency", "and", "clarity", "."], "add_tokens": "throw new IllegalArgumentException ( \"Image must not be blank.\" ) ;", "del_tokens": "throw new IllegalArgumentException ( \"Invalid image.\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "method", "in", "Argon2Advanced", "which", "takes", "a", "pre", "-", "generated", "salt"], "add_tokens": "* < p > / * * * Hashes a password , using the given salt . * * @ param iterations Number of iterations * @ param memory Sets memory usage to x kibibytes * @ param parallelism Number of threads and compute lanes * @ param password Password to hash * @ param charset Charset of the password * @ param salt Salt * @ return Hashed password . * / String hash ( int iterations , int memory , int parallelism , char [ ] password , Charset charset , byte [ ] salt ) ;", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Updated", "constraint", "report", "transformation", "to", "reflect", "proper", "type", "values", "in", "cardinalities"], "add_tokens": "individual . addValue ( shaclTerm ( \"minCard\" ) , typedLiteral ( cardinality . min ( ) , \"integer\" ) ) ; individual . addValue ( shaclTerm ( \"maxCard\" ) , typedLiteral ( cardinality . max ( ) , \"integer\" ) ) ; private static < T > Literal < T > typedLiteral ( T value , String type ) { return DataSetUtils . newTypedLiteral ( value , URI . create ( \"http://www.w3.org/2001/XMLSchema#\" + type ) ) ; }", "del_tokens": "individual . addValue ( shaclTerm ( \"minCard\" ) , literal ( cardinality . min ( ) ) ) ; individual . addValue ( shaclTerm ( \"maxCard\" ) , literal ( cardinality . max ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "direct", "upload", "for", "Google", "Storage"], "add_tokens": "import com . google . api . client . googleapis . media . MediaHttpUploader ; import com . google . api . client . googleapis . media . MediaHttpUploaderProgressListener ; * < p > final File localFile = new File ( localPath . getLogFilePath ( ) ) ; Storage . Objects . Insert request = mClient . objects ( ) . insert ( gsBucket , storageObject , storageContent ) ; // Use direct upload as we are not handling resuming and it seems to be more stable. request . getMediaHttpUploader ( ) . setDirectUploadEnabled ( true ) ; request . getMediaHttpUploader ( ) . setProgressListener ( new MediaHttpUploaderProgressListener ( ) { @ Override public void progressChanged ( MediaHttpUploader uploader ) throws IOException { LOG . debug ( \"[{} %] upload file {} to gs://{}/{}\" , ( int ) uploader . getProgress ( ) * 100 , localFile , gsBucket , gsKey ) ; } } ) ; request . execute ( ) ; credential = GoogleCredential . fromStream ( new FileInputStream ( credentialsPath ) , httpTransport , JSON_FACTORY )", "del_tokens": "* File localFile = new File ( localPath . getLogFilePath ( ) ) ; mClient . objects ( ) . insert ( gsBucket , storageObject , storageContent ) . execute ( ) ; credential = GoogleCredential . fromStream ( new FileInputStream ( credentialsPath ) , httpTransport , JSON_FACTORY )", "commit_type": "use"}
{"commit_tokens": ["fixed", "edge", "direction", "when", "reading", "edges"], "add_tokens": "int source = edgeCount + 1 ; int target = edgeCount ; int source = edgeCount ; int target = edgeCount + 1 ;", "del_tokens": "int source = edgeCount ; int target = edgeCount + 1 ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bad", "link", "in", "javadocs", "[", "skip", "ci", "]"], "add_tokens": "* * * Creates a new { @ link ISO639ConversionFilter } from a supplied *", "del_tokens": "* * * Creates a new { @ link ISOConversionFilter } from a supplied *", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "initialization", "code", "blocks", "of", "some", "addins", "."], "add_tokens": "$ wnd . jQuery ( document ) . ready ( function ( ) { $ wnd . initSubheader ( subheader , container ) ; } ) ;", "del_tokens": "$ wnd . initSubheader ( subheader , container ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "test", "slightly", "more", "compatible", "with", "sync", "-", "gateway"], "add_tokens": "Assert . assertTrue ( lastSequence . contains ( \"2\" ) || lastSequence . contains ( \"3\" ) ) ;", "del_tokens": "Assert . assertTrue ( \"2\" . equals ( lastSequence ) || \"3\" . equals ( lastSequence ) ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "activator", "plug", "-", "in", "id", "added", "storm", "-", "api", "by", "jar", "instead", "of", "Android", "library", "due", "to", "workbench", "errors", "in", "spawned", "eclipse", "instance"], "add_tokens": "public static final String PLUGIN_ID = \"storm-gen-apt-plug-in\" ;", "del_tokens": "public static final String PLUGIN_ID = \"fozzy-gen-apt\" ;", "commit_type": "fix"}
{"commit_tokens": ["added", "bits", "in", "perf", "tests", "+", "showing", "new", "precision", "bug"], "add_tokens": "long spatialKey = algo . encode ( lat , lon ) ; throw new UnsupportedOperationException ( \"Cannot put element? Too many entries per area? Try increasing entries per leaf! \" + lat + \",\" + lon + \" spatial key:\" + spatialKey + \" value:\" + value + \" size:\" + size ) ;", "del_tokens": "return put ( algo . encode ( lat , lon ) , value ) ; } public T put ( long spatialKey , T value ) { throw new UnsupportedOperationException ( \"Cannot put element?? spatial key:\" + spatialKey + \" value:\" + value ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "tests", "for", "rotate", "()", "and", "transform", "()", "methods", "."], "add_tokens": "* { @ link # getFontMetrics } . AffineTransform t = getTransform ( ) ; t . rotate ( theta ) ; setTransform ( t ) ; AffineTransform tx = getTransform ( ) ; tx . concatenate ( t ) ; setTransform ( tx ) ; //this.gs.applyTransform(t); * * @ return A boolean . * * @ return A polygon .", "del_tokens": "import org . jfree . graphics2d . svg . SVGGraphics2D ; * { @ link SVGGraphics2D . getFontMetrics } . AffineTransform t = AffineTransform . getRotateInstance ( theta ) ; transform ( t ) ; t . concatenate ( this . transform ) ; setTransform ( t ) ; //this.gs.setTransform(t); * @ return * @ return", "commit_type": "fix"}
{"commit_tokens": ["Updated", "test", "to", "use", "predefined", "security", "markers"], "add_tokens": "Marker confidential = SecurityMarkers . CONFIDENTIAL ;", "del_tokens": "Marker confidential = MarkerFactory . getMarker ( \"CONFIDENTIAL\" ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "missing", "parameters", "in", "settings", "of", "Date", "field"], "add_tokens": "private String color ; private Boolean showInCalendars ; private DateFieldEndDateType endDate ; private DateFieldTimeEntryType timeEntry ; public String getColor ( ) { return color ; } public void setColor ( String color ) { this . color = color ; } @ JsonProperty ( \"calendar\" ) public Boolean getShowInCalendars ( ) { return showInCalendars ; } @ JsonProperty ( \"calendar\" ) public void setShowInCalendars ( Boolean showInCalendars ) { this . showInCalendars = showInCalendars ; } @ JsonProperty ( \"end\" ) public DateFieldEndDateType getEndDate ( ) { return endDate ; } @ JsonProperty ( \"end\" ) public void setEndDate ( DateFieldEndDateType endDate ) { this . endDate = endDate ; } @ JsonProperty ( \"time\" ) public DateFieldTimeEntryType getTimeEntry ( ) { return timeEntry ; } @ JsonProperty ( \"time\" ) public void setTimeEntry ( DateFieldTimeEntryType timeEntry ) { this . timeEntry = timeEntry ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "pause", "and", "resume", "methods", "to", "AIDialog", "class"], "add_tokens": "@ Override protected void onPause ( ) { if ( aiDialog != null ) { aiDialog . pause ( ) ; } super . onPause ( ) ; } @ Override protected void onResume ( ) { if ( aiDialog != null ) { aiDialog . resume ( ) ; } super . onResume ( ) ; }", "del_tokens": "import android . support . v7 . app . ActionBarActivity ;", "commit_type": "add"}
{"commit_tokens": ["Use", "pathToGroup", "function", "argument", "in", "ServletLimiterBuilder"], "add_tokens": "request -> Optional . ofNullable ( request . getUserPrincipal ( ) ) . map ( principalToGroup ) . orElse ( null ) , request -> Optional . ofNullable ( request . getPathInfo ( ) ) . map ( pathToGroup ) . orElse ( null ) ,", "del_tokens": "request -> Optional . ofNullable ( request . getUserPrincipal ( ) ) . map ( principalToGroup ) . orElse ( null ) , request -> Optional . ofNullable ( request . getPathInfo ( ) ) . orElse ( null ) ,", "commit_type": "use"}
{"commit_tokens": ["Move", "blowup", "of", "CompositionTimeToSample", ".", "Entry", "to", "CompositionTimeToSample"], "add_tokens": "int [ ] compositionTime = CompositionTimeToSample . blowupCompositionTimes ( origTrack . getCompositionTimeEntries ( ) ) ;", "del_tokens": "int [ ] compositionTime = blowupCompositionTimes ( origTrack . getCompositionTimeEntries ( ) ) ; / * * * Decompresses the list of entries and returns the list of composition times . * * @ return decoding time per sample * / public static int [ ] blowupCompositionTimes ( List < CompositionTimeToSample . Entry > entries ) { long numOfSamples = 0 ; for ( CompositionTimeToSample . Entry entry : entries ) { numOfSamples += entry . getCount ( ) ; } assert numOfSamples <= Integer . MAX_VALUE ; int [ ] decodingTime = new int [ ( int ) numOfSamples ] ; int current = 0 ; for ( CompositionTimeToSample . Entry entry : entries ) { for ( int i = 0 ; i < entry . getCount ( ) ; i ++ ) { decodingTime [ current ++ ] = entry . getOffset ( ) ; } } return decodingTime ; }", "commit_type": "move"}
{"commit_tokens": ["Added", "comment", "following", "code", "review"], "add_tokens": "// Note: This class is populate SubstepsExecutionConfig via Reflection, // therefore changes here must be // mirrored in that class private final boolean strict = true ; private final boolean fastFailParseErrors = true ;", "del_tokens": "private boolean strict = true ; private boolean fastFailParseErrors = true ;", "commit_type": "add"}
{"commit_tokens": ["add", "timezone", "for", "doc", "generating", "time"], "add_tokens": "DateFormat df = new SimpleDateFormat ( \"yyyy.MM.dd HH:mm:ssz\" ) ;", "del_tokens": "DateFormat df = new SimpleDateFormat ( \"yyyy.MM.dd HH:mm:ss\" ) ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "the", "tlbimp", "ant", "task", "."], "add_tokens": "import com4j . tlbimp . def . ICoClassDecl ; import com4j . tlbimp . def . IImplementedInterfaceDecl ;", "del_tokens": "import com4j . COM4J ; import com4j . GUID ; import com4j . tlbimp . def . ICoClassDecl ; import com4j . tlbimp . def . IImplementedInterfaceDecl ; final int count = t . countImplementedInterfaces ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "cloudquery", "methods", "into", "AVQuery"], "add_tokens": "import cn . leancloud . query . AVCloudQueryResult ; / * * * Cloud Query * / public static Observable < AVCloudQueryResult > doCloudQueryInBackground ( String cql ) { return AVCloudQuery . executeInBackground ( cql ) ; } public static Observable < AVCloudQueryResult > doCloudQueryInBackground ( String cql , Object ... params ) { return AVCloudQuery . executeInBackground ( cql , params ) ; } public static Observable < AVCloudQueryResult > doCloudQueryInBackground ( String cql , Class < ? extends AVObject > clazz ) { return AVCloudQuery . executeInBackground ( cql , clazz ) ; } public static Observable < AVCloudQueryResult > doCloudQueryInBackground ( String cql , final Class < ? extends AVObject > clazz , Object ... params ) { return AVCloudQuery . executeInBackground ( cql , clazz , params ) ; }", "del_tokens": "// TODO: need to implement doCloudQueryInBackground method yet.", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "provide", "content", "MD5", "for", "request", "signature", "to", "be", "generated", "for", "some", "of", "the", "requests", "that", "require", "it", "."], "add_tokens": "String signature = requestHelper . makeSignature ( new HttpGet ( url ) , FORMATTED_DATE , null ) ;", "del_tokens": "String signature = requestHelper . makeSignature ( new HttpGet ( url ) , FORMATTED_DATE ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "PasswordEncoder", "interface", "instead", "of", "impl"], "add_tokens": "import org . springframework . security . crypto . password . PasswordEncoder ; private PasswordEncoder passwordEncoder ; final String pwHash = passwordEncoder . encode ( user . getPassword ( ) ) ;", "del_tokens": "import org . springframework . security . crypto . bcrypt . BCryptPasswordEncoder ; private BCryptPasswordEncoder bcrypt ; final String pwHash = bcrypt . encode ( user . getPassword ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "ElementInputStream", "read", "(", "byte", "[]", "int", "int", ")", "to", "return", "-", "1", "when", "done", "."], "add_tokens": "if ( remaining > 0 ) { if ( length > remaining ) length = remaining ; ringRead ( position , buffer , offset , length ) ; position = wrapPosition ( position + length ) ; remaining -= length ; return length ; } else { return - 1 ; }", "del_tokens": "if ( length > remaining ) length = remaining ; ringRead ( position , buffer , offset , length ) ; position = wrapPosition ( position + length ) ; remaining -= length ; return length ;", "commit_type": "fix"}
{"commit_tokens": ["Upgraded", "Crittercism", ".", "Fixed", "log4jFilter"], "add_tokens": "LOGGER . info ( request . getMethod ( ) + \" \" + request . getRequestURI ( ) + ( queryString != null ? \"?\" + request . getQueryString ( ) : \"\" ) ) ;", "del_tokens": "LOGGER . info ( request . getMethod ( ) + ( queryString != null ? \" \" + request . getRequestURI ( ) + \"?\" + request . getQueryString ( ) : \"\" ) ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "AuthleteApiImpl", ".", "callGetApi", "."], "add_tokens": "webTarget = webTarget . queryParam ( param . getKey ( ) , param . getValue ( ) ) ;", "del_tokens": "webTarget . queryParam ( param . getKey ( ) , param . getValue ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "embarrassing", "bug", "in", "the", "JmxClient", "code", "which", "was", "improperly"], "add_tokens": "if ( info == null ) { throw new IllegalArgumentException ( \"Cannot find attribute named '\" + attrName + \"'\" ) ; } else { setAttribute ( name , attrName , stringToObject ( value , info . getType ( ) ) ) ; } MBeanOperationInfo [ ] operations ; try { operations = mbeanConn . getMBeanInfo ( objectName ) . getOperations ( ) ; } catch ( Exception e ) { throw createJmException ( \"Cannot get attribute info from \" + objectName , e ) ; MBeanAttributeInfo [ ] attributes ; try { attributes = mbeanConn . getMBeanInfo ( objectName ) . getAttributes ( ) ; } catch ( Exception e ) { throw createJmException ( \"Cannot get attribute info from \" + objectName , e ) ;", "del_tokens": "private MBeanAttributeInfo [ ] attributes ; private MBeanOperationInfo [ ] operations ; setAttribute ( name , attrName , stringToObject ( value , info . getType ( ) ) ) ; if ( operations == null ) { try { operations = mbeanConn . getMBeanInfo ( objectName ) . getOperations ( ) ; } catch ( Exception e ) { throw createJmException ( \"Cannot get attribute info from \" + objectName , e ) ; } if ( attributes == null ) { try { attributes = mbeanConn . getMBeanInfo ( objectName ) . getAttributes ( ) ; } catch ( Exception e ) { throw createJmException ( \"Cannot get attribute info from \" + objectName , e ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fix", "angularjs", "error", "when", "there", "is", "no", "controller"], "add_tokens": "int count = ( int ) Database . INSTANCE . count ( ) ; int nbPages = count / limit ;", "del_tokens": "long count = Database . INSTANCE . count ( ) ; long nbPages = count / limit ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "RAM", "-", "Hours", "and", "Kappa", "Statistic"], "add_tokens": "long lastEvaluateStartTime = evaluateStartTime ; double RAMHours = 0.0 ; long evaluateTime = TimingUtils . getNanoCPUTimeOfCurrentThread ( ) ; double time = TimingUtils . nanoTimeToSeconds ( evaluateTime - evaluateStartTime ) ; double timeIncrement = TimingUtils . nanoTimeToSeconds ( evaluateTime - lastEvaluateStartTime ) ; double RAMHoursIncrement = learner . measureByteSize ( ) / ( 1024.0 * 1024.0 * 1024.0 ) ; //GBs RAMHoursIncrement *= ( timeIncrement / 3600.0 ) ; //Hours RAMHours += RAMHoursIncrement ; lastEvaluateStartTime = evaluateTime ; \"evaluation time (\" : \"\" ) + \"seconds)\" , time ) , new Measurement ( \"model cost (RAM-Hours)\" , RAMHours ) } ,", "del_tokens": "( \"evaluation time (\" : \"\" ) + \"seconds)\" ) , TimingUtils . nanoTimeToSeconds ( TimingUtils . getNanoCPUTimeOfCurrentThread ( ) - evaluateStartTime ) ) } ,", "commit_type": "add"}
{"commit_tokens": ["Add", "feature", "to", "set", "default", "profile", "name", "via", "system", "property", "for", "ProfileCredentialsProvider"], "add_tokens": "String profileEnvVarOverride = System . getenv ( ProfilesConfigFile . AWS_PROFILE_ENVIRONMENT_VARIABLE ) ; profileEnvVarOverride = StringUtils . trim ( profileEnvVarOverride ) ; if ( ! StringUtils . isNullOrEmpty ( profileEnvVarOverride ) ) { this . profileName = profileEnvVarOverride ; String profileSysPropOverride = System . getProperty ( ProfilesConfigFile . AWS_PROFILE_SYSTEM_PROPERTY ) ; profileSysPropOverride = StringUtils . trim ( profileSysPropOverride ) ; if ( ! StringUtils . isNullOrEmpty ( profileSysPropOverride ) ) { this . profileName = profileSysPropOverride ; } else { this . profileName = ProfilesConfigFile . DEFAULT_PROFILE_NAME ; }", "del_tokens": "String profileOverride = System . getenv ( ProfilesConfigFile . AWS_PROFILE_ENVIRONMENT_VARIABLE ) ; profileOverride = StringUtils . trim ( profileOverride ) ; if ( ! StringUtils . isNullOrEmpty ( profileOverride ) ) { this . profileName = profileOverride ; this . profileName = ProfilesConfigFile . DEFAULT_PROFILE_NAME ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Jolokia", "instead", "of", "direct", "JMX", "calls"], "add_tokens": "// Jolokia JMX definition private static final int JMX_PORT = 28161 ;", "del_tokens": "//Broker JMX definition private static final int JMX_PORT = 20011 ;", "commit_type": "use"}
{"commit_tokens": ["add", "string", "attributes", "to", "measurements"], "add_tokens": "import static com . google . common . base . Preconditions . checkNotNull ; import java . util . Map ; private final Map < String , String > m_attributes ; this ( timestamp , resource , name , type , value , null ) ; public Measurement ( Timestamp timestamp , String resource , String name , MetricType type , double value , Map < String , String > attributes ) { m_timestamp = checkNotNull ( timestamp , \"timestamp\" ) ; m_resource = checkNotNull ( resource , \"resource\" ) ; m_name = checkNotNull ( name , \"name\" ) ; m_type = checkNotNull ( type , \"type\" ) ; m_value = checkNotNull ( value , \"value\" ) ; m_attributes = attributes ; Map < String , String > getAttributes ( ) { return m_attributes ; }", "del_tokens": "private final String m_units ; this ( timestamp , resource , name , type , null , value ) ; public Measurement ( Timestamp timestamp , String resource , String name , MetricType type , String units , double value ) { m_timestamp = timestamp ; m_resource = resource ; m_name = name ; m_type = type ; m_units = units ; m_value = value ; public String getUnits ( ) { return m_units ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "dynamic", "Thrift", "to", "Proto", "conversion"], "add_tokens": "import org . apache . thrift . TException ; import com . google . protobuf . Descriptors . DescriptorValidationException ; import com . google . protobuf . DynamicMessage ; import com . twitter . data . proto . tutorial . thrift . PhoneNumber ; import com . twitter . data . proto . tutorial . thrift . PhoneType ; @ Test public void testThriftToDynamicProto ( ) throws DescriptorValidationException { PhoneNumber thriftPhone = new PhoneNumber ( \"123-34-5467\" ) ; thriftPhone . type = PhoneType . HOME ; ThriftToDynamicProto < PhoneNumber > thriftToProto = new ThriftToDynamicProto < PhoneNumber > ( PhoneNumber . class ) ; DynamicMessage msg = thriftToProto . convert ( thriftPhone ) ; assertEquals ( thriftPhone . number , Protobufs . getFieldByName ( msg , \"number\" ) ) ; assertEquals ( thriftPhone . type . toString ( ) , Protobufs . getFieldByName ( msg , \"type\" ) ) ; }", "del_tokens": "import org . apache . thrift . TException ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "Jam", "Api", "methods", "for", "group", "cache", "management", "."], "add_tokens": "if ( MetricsCacheCollection . getMetricsCacheCollection ( ) . getMetricsCacheInstance ( groupName ) != null ) System . out . println ( \"Count GroupObjects In MetricCache : \" + MetricsCacheApi . countGroupObjectsInMetricCache ( groupName ) ) ; if ( MetricsCacheCollection . getMetricsCacheCollection ( ) . getMetricsCacheInstance ( groupName ) != null ) MetricsCacheApi . deleteGroupInMetricsCache ( groupName ) ; if ( MetricsCacheCollection . getMetricsCacheCollection ( ) . getMetricsCacheInstance ( groupName ) != null ) System . out . println ( \"Count GroupObjects In MetricCache : \" + MetricsCacheApi . countGroupObjectsInMetricCache ( groupName ) ) ; else System . out . println ( \"Group \" + groupName + \" does not exist.\" ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "select", "function", "so", "that", "the", "console", "can", "be", "programmatically", "selected", ".", "Moved", "the", "unused", "functions", "in", "HeadlessConsole", "to", "AbstractConsole", "."], "add_tokens": "/ * * Extend this class and fill it with methods ( also < code > public < / code > ) that you wish to", "del_tokens": "/ * * Extend this class ( child must be < code > public < / code > ) and fill it with methods ( also < code > public < / code > ) that you wish to", "commit_type": "add"}
{"commit_tokens": ["Fix", "several", "bugs", "in", "HTML", "Json", "writer"], "add_tokens": "private ArrayList < Boolean > isFirstValueStack = new ArrayList < Boolean > ( ) ; pushIsFirstValue ( true ) ; popIsFirstValue ( ) ; popIsFirstValue ( ) ; pushIsFirstValue ( true ) ; sb . append ( \"\\\"\" ) ; sb . append ( \"\\\"\" ) ; / * * * Prepend the key if not in an array . * * Note : if this isn 't the first key, we output a leading comma as well. * / if ( isFirstValue ( ) ) { popIsFirstValue ( ) ; pushIsFirstValue ( false ) ; } else { sb . append ( \",\" ) ; } sb . append ( \"\\\"\" ) ; sb . append ( \"\\\":\" ) ; private void pushIsFirstValue ( boolean isFirstValue ) { isFirstValueStack . add ( isFirstValue ) ; } private boolean popIsFirstValue ( ) { return isFirstValueStack . remove ( isFirstValueStack . size ( ) - 1 ) ; } private boolean isFirstValue ( ) { return isFirstValueStack . get ( isFirstValueStack . size ( ) - 1 ) ; }", "del_tokens": "sb . append ( \",\" ) ; sb . append ( \",\" ) ; sb . append ( \",\" ) ; sb . append ( \",\" ) ; sb . append ( \"'\" ) ; sb . append ( \"':\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "autoconfiguration", "in", "the", "absence", "of", "Spring", "Security", "OAuth2", "classes", "."], "add_tokens": "public ReactiveClientRegistrationRepository credHubReactiveClientRegistrationRepository ( ) {", "del_tokens": "public ReactiveClientRegistrationRepository clientRegistrationRepository ( ) {", "commit_type": "fix"}
{"commit_tokens": ["allow", "subypes", "to", "override", "the", "content", "type", "."], "add_tokens": "import org . apache . commons . io . output . CountingOutputStream ; import java . io . IOException ; import java . io . InputStreamReader ; import java . io . Reader ; import java . io . Writer ; setContentType ( rsp ) ; protected void setContentType ( StaplerResponse rsp ) { rsp . setContentType ( \"text/plain;charset=UTF-8\" ) ; }", "del_tokens": "import org . apache . commons . io . output . CountingOutputStream ; import java . io . IOException ; import java . io . Reader ; import java . io . InputStreamReader ; import java . io . Writer ; rsp . setContentType ( \"text/plain;charset=UTF-8\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "abstract", "class", "for", "binary", "operations"], "add_tokens": "public final class DefaultDiceOperand implements DiceOperand {", "del_tokens": "import com . bernardomg . tabletop . dice . notation . AbstractDiceNotationExpression ; public final class DefaultDiceOperand extends AbstractDiceNotationExpression implements DiceOperand {", "commit_type": "add"}
{"commit_tokens": ["Added", "in", "new", "searching", "options"], "add_tokens": "import org . dasein . cloud . compute . SnapshotFilterOptions ; public @ Nonnull Iterable < Snapshot > searchSnapshots ( @ Nonnull SnapshotFilterOptions options ) throws InternalException , CloudException { std . trace ( \"ENTER: \" + CinderSnapshot . class . getName ( ) + \".searchSnapshots(\" + options + \")\" ) ; if ( snapshot != null && options . matches ( snapshot , null ) ) {", "del_tokens": "public @ Nonnull Iterable < Snapshot > searchSnapshots ( @ Nullable String ownerId , @ Nullable String keyword ) throws InternalException , CloudException { std . trace ( \"ENTER: \" + CinderSnapshot . class . getName ( ) + \".searchSnapshots(\" + ownerId + \",\" + keyword + \")\" ) ; if ( snapshot != null ) { if ( ownerId != null && ! ownerId . equals ( snapshot . getProviderSnapshotId ( ) ) ) { continue ; } if ( keyword != null && ! snapshot . getName ( ) . contains ( keyword ) && ! snapshot . getDescription ( ) . contains ( keyword ) ) { continue ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "README", ".", "md", "to", "the", "project", "and", "update", "MainActivity", "to", "use", "HeaderSpanSizeLookup", "with", "a", "GridLayoutManager", "instead", "of", "a", "LinearLayoutManager"], "add_tokens": "* Returns true if the position type parameter passed as argument is equals to 0 and the adapter * has a not null header already configured . public boolean isHeaderPosition ( int position ) { return hasHeader ( ) && position == 0 ; * Returns true if the view type parameter passed as argument is equals to TYPE_HEADER . protected boolean isHeaderType ( int viewType ) { return viewType == TYPE_HEADER ;", "del_tokens": "* Returns true if the view type parameter passed as argument is equals to TYPE_HEADER . protected boolean isHeaderType ( int viewType ) { return viewType == TYPE_HEADER ; * Returns true if the position type parameter passed as argument is equals to 0 and the adapter * has a not null header already configured . protected boolean isHeaderPosition ( int position ) { return hasHeader ( ) && position == 0 ;", "commit_type": "add"}
{"commit_tokens": ["Make", "meta", "fields", "private", "and", "with", "field", "prefix"], "add_tokens": "insertRegion . add ( \"\\t\\tprivate final Map<String, MetaProperty<Object>> \" + prefix + \"map;\" ) ; insertRegion . add ( \"\\t\\t\\t\" + prefix + \"map = Collections.unmodifiableMap(temp);\" ) ; insertRegion . add ( \"\\t\\t\\treturn \" + prefix + \"map;\" ) ;", "del_tokens": "insertRegion . add ( \"\\t\\tprivate final Map<String, MetaProperty<Object>> map;\" ) ; insertRegion . add ( \"\\t\\t\\tmap = Collections.unmodifiableMap(temp);\" ) ; insertRegion . add ( \"\\t\\t\\treturn map;\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "numerb", "of", "errorprone", "warnings"], "add_tokens": "if ( o == null || ! ( o instanceof ConcurrentLimitRule ) ) {", "del_tokens": "if ( o == null || getClass ( ) != o . getClass ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "source", "code", "with", "debug", "bool", "parameter"], "add_tokens": "protected boolean debug ; public void setDebug ( boolean debug ) { this . debug = debug ; } public boolean getDebug ( ) { return this . debug ; } if ( this . getDebug ( ) ) System . out . println ( \"Unable to connect to Logentries\" ) ; e . printStackTrace ( ) ; if ( this . getDebug ( ) ) System . out . println ( \"Unable to transmit to Logentries\" ) ; e . printStackTrace ( ) ; if ( this . getDebug ( ) ) e . printStackTrace ( ) ;", "del_tokens": "e . printStackTrace ( ) ; e . printStackTrace ( ) ; e . printStackTrace ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "some", "more", "U", "tests", "..."], "add_tokens": "byte [ ] response = ( byte [ ] ) protocol . read ( new RedisInputStream ( is ) ) ; assertArrayEquals ( \"OK\" . getBytes ( Protocol . UTF8 ) , response ) ; expected2 . add ( \"OK\" . getBytes ( Protocol . UTF8 ) ) ;", "del_tokens": "String response = ( String ) protocol . read ( new RedisInputStream ( is ) ) ; assertEquals ( \"OK\" , response ) ; expected2 . add ( \"OK\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "number", "of", "secret", "bits", "configurable"], "add_tokens": "// the secret key. int bufferSize = config . getSecretBits ( ) / 8 ; byte [ ] buffer = new byte [ bufferSize ] ; byte [ ] secretKey = Arrays . copyOf ( buffer , bufferSize ) ;", "del_tokens": "/ * * * The number of bits of a secret key in binary form . Since the Base32 * encoding with 8 bit characters introduces an 160 % overhead , we just need * 80 bits ( 10 bytes ) to generate a 16 bytes Base32 - encoded secret key . * / private static final int SECRET_BITS = 80 ; // the secret key and the scratch codes. byte [ ] buffer = new byte [ SECRET_BITS / 8 ] ; byte [ ] secretKey = Arrays . copyOf ( buffer , SECRET_BITS / 8 ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "assorted", "type", "system", "bugs", "and", "crashes", "."], "add_tokens": "getJSType ( value ) ) ; if ( var != null ) { // There are two situations where we don't want to use type information // from the scope, even if we have it. // 1) The var is escaped in a weird way, e.g., // function f() { var x = 3; function g() { x = null } (x); } boolean isInferred = var . isTypeInferred ( ) ; boolean unflowable = isInferred && unflowableVarNames . contains ( varName ) ; // 2) We're reading type information from another scope for an // inferred variable. // var t = null; function f() { (t); } boolean nonLocalInferredSlot = isInferred && syntacticScope . getParent ( ) != null && var == syntacticScope . getParent ( ) . getSlot ( varName ) ; if ( ! unflowable && ! nonLocalInferredSlot ) { type = var . getType ( ) ; if ( type == null ) { type = getNativeType ( UNKNOWN_TYPE ) ; }", "del_tokens": "getJSType ( value ) ) ; if ( var != null && ! ( var . isTypeInferred ( ) && unflowableVarNames . contains ( varName ) ) ) { type = var . getType ( ) ; if ( type == null ) { type = getNativeType ( UNKNOWN_TYPE ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "name", "to", "FilterSpec", "and", "switched", "to", "a", "builder", "pattern", "."], "add_tokens": "environment . servlets ( ) . addFilter ( filterSpec . getName ( ) , filterSpec . getFilter ( ) ) ; filterSpec . getName ( ) ,", "del_tokens": "environment . servlets ( ) . addFilter ( filterSpec . getFilter ( ) . getClass ( ) . getSimpleName ( ) , filterSpec . getFilter ( ) ) ; filterSpec . getFilter ( ) . getClass ( ) . getSimpleName ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "additional", "ctor", "to", "avoid", "username", ".", "JCBC", "-", "38", "."], "add_tokens": "* Copyright ( C ) 2009 - 2012 Couchbase , Inc . / * * * Get the CouchbaseConnectionFactory set up with the provided parameters . * Note that a CouchbaseConnectionFactory requires the failure mode is set * to retry , and the locator type is discovered dynamically based on the * cluster you are connecting to . As a result , these values will be * overridden upon calling this function . * * @ param baseList a list of URI 's that will be used to connect to the cluster * @ param bucketName the name of the bucket to connect to , also used for * username * @ param pwd the password for the bucket * @ return a CouchbaseConnectionFactory object * @ throws IOException * / public CouchbaseConnectionFactory buildCouchbaseConnection ( final List < URI > baseList , final String bucketName , final String pwd ) throws IOException { return this . buildCouchbaseConnection ( baseList , bucketName , bucketName , pwd ) ; }", "del_tokens": "* Copyright ( C ) 2009 - 2011 Couchbase , Inc .", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "comments", "and", "style"], "add_tokens": ". option ( ChannelOption . CONNECT_TIMEOUT_MILLIS , connectTimeout )", "del_tokens": ". option ( ChannelOption . CONNECT_TIMEOUT_MILLIS , connectTimeout ) // Disable connect timeout", "commit_type": "fix"}
{"commit_tokens": ["Use", "SSL", "by", "default", "for", "communications", "with", "Bugsnag", ".", "com"], "add_tokens": "boolean useSSL = true ;", "del_tokens": "boolean useSSL = false ;", "commit_type": "use"}
{"commit_tokens": ["Add", "java", "doc", "for", "new", "methods"], "add_tokens": "* @ return A { @ code HashMap } contains { @ code TAV } and { @ code TAMP } , the key / * * * Calculate the reference evapotranspiration ( ETo ) by means of the * FAO - Penman Monteith equation . * * @ param data The data map * * @ return An { @ code ArrayList } of { @ code ETo } for daily weather record . * / / * * * Based on the location of weather station , return the adjustment * coefficient used for Solar radiation calculation . The default value is * 0.16 for interior locations and 0.19 for coastal locations * * @ param data The data map * @ return adjustment coefficient [ C - 0 .5] * / // TODO waiting for GIS system imported", "del_tokens": "* @ return An { @ code HashMap } contains { @ code TAV } and { @ code TAMP } , the key // default value of adjustment coefficient is 0.16 for interior locations and 0.19 for coastal locations. // TODO waiting for response", "commit_type": "add"}
{"commit_tokens": ["make", "FPFile", "parceable", "add", "fields", "to", "match", "API", "response", "add", "JSON", "constructor"], "add_tokens": "return new FPFile ( contentURI . toString ( ) , data ) ; return new FPFile ( downloadUrl ( url , filename , context ) , json ) ;", "del_tokens": "debug ( \"data: \" + data . toString ( ) ) ; String url = data . getString ( \"url\" ) ; String key = \"\" ; if ( data . getJSONObject ( \"data\" ) . has ( \"key\" ) ) { key = data . getJSONObject ( \"data\" ) . getString ( \"key\" ) ; } return new FPFile ( contentURI . toString ( ) , url , key ) ; String key = null ; try { key = json . getString ( \"key\" ) ; } catch ( JSONException e ) { debug ( \"No key in json\" ) ; } return new FPFile ( downloadUrl ( url , filename , context ) , url , key ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "IceBoxFlow", ".", "java", "to", "be", "child", "of", "KanbanyryFlow"], "add_tokens": "public interface IceBoxFlow extends KanbaneryFlow < Task > {", "del_tokens": "public interface IceBoxFlow {", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "maven", "repository", "aware", "osgi", "container"], "add_tokens": "package com . sinnerschrader . smaller . osgi ;", "del_tokens": "package com . sinnerschrader . smaller . sogi ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "command", "line", "options", "to", "code", "generator", "program"], "add_tokens": "private final boolean verbose ; public CodeGen ( File templatesFolder , File outputFolder , boolean verbose ) throws IOException { this . verbose = verbose ; if ( verbose ) { System . out . println ( \"File: \" + fileName ) ; System . out . println ( ) ; System . out . println ( sourceCode ) ; System . out . println ( \"---------------------------------------\" ) ; }", "del_tokens": "public CodeGen ( File templatesFolder , File outputFolder ) throws IOException { System . out . println ( \"File: \" + fileName ) ; System . out . println ( ) ; System . out . println ( sourceCode ) ; System . out . println ( \"---------------------------------------\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "toFormattedString", "method", "to", "Iban", "class"], "add_tokens": "/ * * * Returns formatted version of Iban . * * @ return A string representing formatted Iban for printing . * / public String toFormattedString ( ) { StringBuilder ibanBuffer = new StringBuilder ( value ) ; int length = ibanBuffer . length ( ) ; for ( int i = 0 ; i < length / 4 ; i ++ ) { ibanBuffer . insert ( ( i + 1 ) * 4 + i , ' ' ) ; } return ibanBuffer . toString ( ) . trim ( ) ;", "del_tokens": "private String toFormattedString ( ) { // TODO for next release return null ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "JavaDocs", "for", "some", "additional", "container", "lifecycle", "events", "."], "add_tokens": "/ * * * < p > * The event type of the third event fired by the container after it has * validated that there are no deployment problems and before creating contexts * or processing requests . If any observer method of the { @ code * AfterDeploymentValidation } event throws an exception , the exception is * treated as a deployment problem by the container . * < / p > * < p > * No requests will be processed by the deployment until all observers of this * event return . * < / p > * * @ author David Allen * / public interface AfterDeploymentValidation / * * * Registers a deployment problem with the container , causing the container * to abort deployment after all observers have been notified . * * @ param t The deployment problem as a { @ link java . lang . Throwable } * /", "del_tokens": "public interface AfterDeploymentValidation", "commit_type": "update"}
{"commit_tokens": ["Add", "<finalName", ">", "option", "to", "remap", "mojo"], "add_tokens": "/ * * * The name of the shaded artifactId . * < p / > * If you like to change the name of the native artifact , you may use the & lt ; build > & lt ; finalName > setting . * If this is set to something different than & lt ; build > & lt ; finalName > , no file replacement * will be performed , even if shadedArtifactAttached is being used . * / @ Parameter private String finalName ; boolean renamed = false ; // rename the output file if a specific finalName is set // but don't rename if the finalName is the <build><finalName> // because this will be handled implicitly later if ( finalName != null && finalName . length ( ) > 0 && ! finalName . equals ( project . getBuild ( ) . getFinalName ( ) ) ) { String finalFileName = finalName + \".\" + project . getArtifact ( ) . getArtifactHandler ( ) . getExtension ( ) ; File finalFile = new File ( outputDirectory , finalFileName ) ; replaceFile ( finalFile , outputFile ) ; renamed = true ; } } else if ( ! renamed ) {", "del_tokens": "} else {", "commit_type": "add"}
{"commit_tokens": ["fix", "GAME_EVENTS", "not", "being", "transient", "(", "thanks", "raz", ")"], "add_tokens": "Netmessages . CNETMsg_Tick . class Netmessages . CSVCMsg_ServerInfo . class Networkbasetypes . CSVCMsg_UserMessage . class . dependsOn ( TRANSIENT_DATA ) . dependsOn ( TRANSIENT_DATA ) . dependsOn ( USERMESSAGE_CONTAINER ) . append ( DotaUsermessages . CDOTAUserMsg_ChatEvent . class ) ;", "del_tokens": "Netmessages . CNETMsg_Tick . class Netmessages . CSVCMsg_ServerInfo . class Networkbasetypes . CSVCMsg_UserMessage . class . dependsOn ( TRANSIENT_DATA ) . dependsOn ( USERMESSAGE_CONTAINER ) . append ( DotaUsermessages . CDOTAUserMsg_ChatEvent . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "information", "leak", "about", "whether", "a", "user", "exists", "on", "the", "system"], "add_tokens": "RSAPublicKey key = keys . get ( username ) ; if ( key == null ) { throw new KeyNotFoundException ( ) ; } return key ;", "del_tokens": "return keys . get ( username ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixes", "very", "slow", "generation", "of", "large", "files"], "add_tokens": "BufferedWriter writer = new BufferedWriter ( new OutputStreamWriter ( fileStream , \"UTF-8\" ) ) ;", "del_tokens": "OutputStreamWriter writer = new OutputStreamWriter ( fileStream , \"UTF-8\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "method", "afterStep", "to", "place", "each", "manifest", "BufferedWriter", "in", "its", "own", "try", "/", "catch", "block", "for", "calling", "the", "close", "method", "."], "add_tokens": "LOGGER . debug ( \"Step complete with status: {}\" , stepExecution . getExitStatus ( ) ) ; } catch ( IOException ioe ) { LOGGER . error ( \"Error closing MD5 manifest BufferedWriter: \" , ioe ) ; } try { LOGGER . error ( \"Error closing SHA-256 manifest BufferedWriter: \" , ioe ) ;", "del_tokens": "LOGGER . debug ( \"Step complete with status: {}\" , stepExecution . getExitStatus ( ) ) ; LOGGER . error ( \"Error closing manifest BufferedWriter: \" , ioe ) ;", "commit_type": "update"}
{"commit_tokens": ["changed", "test", "program", "again", "according", "to", "ServerStatus", "model", "class"], "add_tokens": "import com . treasure_data . model . ServerStatus ; return new ServerStatusResult ( new ServerStatus ( msg ) ) ;", "del_tokens": "return new ServerStatusResult ( msg ) ;", "commit_type": "change"}
{"commit_tokens": ["using", "constants", "for", "internal", "GPSd", "names"], "add_tokens": "/** the GPSd internal name */ public static final String NAME = \"TPV\" ;", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["add", "negative", "cycle", "assertion", ".", "and", "a", "unittest", "."], "add_tokens": "import org . psjava . javautil . AssertStatus ; SingleSourceShortestPathCalcStatus < W > status = createInitialStatus ( graph , from , ns ) ; relaxEnough ( graph , status , ns ) ; relaxToCheckNegativeCycle ( graph , ns , status ) ; public static < W > SingleSourceShortestPathCalcStatus < W > createInitialStatus ( DirectedWeightedGraph < W > graph , final Object from , AddableNumberSystem < W > ns ) { return status ; } public static < W > void relaxEnough ( DirectedWeightedGraph < W > graph , SingleSourceShortestPathCalcStatus < W > status , AddableNumberSystem < W > ns ) { } private static < W > void relaxToCheckNegativeCycle ( DirectedWeightedGraph < W > graph , AddableNumberSystem < W > ns , SingleSourceShortestPathCalcStatus < W > status ) { for ( DirectedWeightedEdge < W > e : graph . getEdges ( ) ) { boolean relaxed = Relax . relax ( status . distance , status . previous , e , ns ) ; AssertStatus . assertTrue ( ! relaxed , \"contains negative cycle\" ) ; }", "del_tokens": "SingleSourceShortestPathCalcStatus < W > status = calcFinalCalcStatus ( graph , from , ns ) ; public static < W > SingleSourceShortestPathCalcStatus < W > calcFinalCalcStatus ( DirectedWeightedGraph < W > graph , final Object from , AddableNumberSystem < W > ns ) { return status ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "EventType", ".", "UPDATE", "(", "not", "used", "at", "the", "moment", ")"], "add_tokens": "DATA , GRAPHIC , UPDATE } ;", "del_tokens": "DATA , GRAPHIC } ;", "commit_type": "add"}
{"commit_tokens": ["update", "gitignore", "and", "add", "jar", "file"], "add_tokens": "private static volatile GuildWars2 instance = null ; / * * * This class is singleton to reduce the potential need to repeatably create new retrofit object * @ return instance of GuildWars2 * / public static GuildWars2 getInstance ( ) { if ( instance == null ) instance = new GuildWars2 ( ) ; return instance ; } //constructor private GuildWars2 ( ) { //TODO getAllPricesID", "del_tokens": "public GuildWars2 ( ) {", "commit_type": "update"}
{"commit_tokens": ["Implement", "NONE", "and", "ALL", "device", "events", "in", "MFPAnalytics", "."], "add_tokens": "case ALL : MFPActivityLifeCycleCallbackListener . init ( app ) ; break ; case NONE : break ;", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Using", "LogdocResolver", "as", "URIResolver", "for", "XSLT", "transformation", "."], "add_tokens": "String xsltPath = \"/META-INF/xslt/log_to_\" + className + \"_java.xslt\" ; xformerFactory . setURIResolver ( new LogdocResolver ( ) ) ; System . err . println ( \"About to perform XSLT transformation.\" ) ;", "del_tokens": "String xsltPath = \"/xslt/log_to_\" + className + \"_java.xslt\" ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "weak", "value", "test", "bugs"], "add_tokens": "Function < Integer , Integer > mappingFunction = key -> context . original ( ) . get ( key ) ;", "del_tokens": "Function < Integer , Integer > mappingFunction = key -> - key ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "method", "to", "Process", "to", "determine", "if", "it", "currently", "exists", "."], "add_tokens": "public boolean isDeleted ( ) {", "del_tokens": "boolean isDeleted ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "getTicketsByExternalId", "when", "searching", "for", "archived", "tickets"], "add_tokens": "return new PagedIterable < Ticket > ( tmpl ( \"/search.json{?query}{&type}\" ) . set ( \"query\" , \"external_id:\" + externalId ) . set ( \"type\" , \"ticket\" ) ,", "del_tokens": "return new PagedIterable < Ticket > ( tmpl ( \"/search.json{?query}\" ) . set ( \"query\" , \"external_id:\" + externalId + \" type:ticket\" ) ,", "commit_type": "fix"}
{"commit_tokens": ["updated", "comments", "in", "Problem", "interface"], "add_tokens": "* Creates a ( deep ) copy of the given solution .", "del_tokens": "* Creates a ( deep ) copy of the current solution .", "commit_type": "update"}
{"commit_tokens": ["Use", "the", "correct", "syntax", "for", "multivalued", "options", ":", "-", "flag", "value1", "-", "flag", "value2"], "add_tokens": "@ Option ( name = \"-list\" ) @ Option ( name = \"-string\" , multiValued = true ) // There is no OptionHandler for Arrays //@Option(name=\"-array\", multiValued=true) setArgs ( \"-list\" , \"one\" , \"-list\" , \"two\" , \"-list\" , \"three\" ) ; parser . parseArgument ( args ) ; parser . parseArgument ( \"-string\" , \"one\" , \"-string\" , \"two\" , \"-string\" , \"three\" ) ; parser . parseArgument ( \"-array\" , \"one\" , \"-array\" , \"two\" , \"-array\" , \"three\" ) ;", "del_tokens": "@ Option ( name = \"list\" ) @ Option ( name = \"string\" , multiValued = true ) @ Option ( name = \"array\" , multiValued = true ) parser . parseArgument ( \"-list\" , \"one\" , \"two\" , \"three\" ) ; parser . parseArgument ( \"-string\" , \"one\" , \"two\" , \"three\" ) ; parser . parseArgument ( \"-array\" , \"one\" , \"two\" , \"three\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Created", "constant", "for", "the", "number", "of", "seconds", "when", "scrolling", ";", "Removed", "FileNotFoundException"], "add_tokens": "private void buildupPropertiesBundles ( final File file ) throws IOException {", "del_tokens": "import java . io . FileNotFoundException ; * @ throws FileNotFoundException * if the file does not exists private void buildupPropertiesBundles ( final File file ) throws FileNotFoundException , IOException {", "commit_type": "create"}
{"commit_tokens": ["fixes", "the", "primitives", "wrapper", "but", "not", "the", "primitives", "themselves"], "add_tokens": "import java . lang . reflect . Array ; import java . lang . reflect . GenericArrayType ; if ( GenericArrayType . class . isInstance ( toType . getType ( ) ) ) { GenericArrayType arrayType = ( GenericArrayType ) toType . getType ( ) ; Class < ? > type = ( Class < ? > ) arrayType . getGenericComponentType ( ) ; Object array = Array . newInstance ( type , tokenizer . countTokens ( ) ) ; Array . set ( array , i ++ , this . simpleConvert ( token , toType ) ) ; System . err . println ( array . getClass ( ) . getComponentType ( ) ) ; System . err . println ( array ) ;", "del_tokens": "if ( ( ( Class < ? > ) toType . getRawType ( ) ) . isArray ( ) ) { Object [ ] array = new Object [ tokenizer . countTokens ( ) ] ; array [ i ++ ] = this . simpleConvert ( token , toType ) ;", "commit_type": "fix"}
{"commit_tokens": ["created", "map", "-", "matching", ".", "sh", "script"], "add_tokens": "static final String DATE_FORMAT = \"yyyy-MM-dd'T'HH:mm:ssZ\" ; static final String DATE_FORMAT_Z = \"yyyy-MM-dd'T'HH:mm:ss'Z'\" ; SimpleDateFormat formatterZ = new SimpleDateFormat ( DATE_FORMAT_Z ) ; factory . setValidating ( false ) ; String text = timeNodes . item ( 0 ) . getTextContent ( ) ; long millis ; if ( text . contains ( \"Z\" ) ) { millis = formatterZ . parse ( text ) . getTime ( ) ; } else { millis = formatter . parse ( revertTZHack ( text ) ) . getTime ( ) ; }", "del_tokens": "private static final String DATE_FORMAT = \"yyyy-MM-dd'T'HH:mm:ssZ\" ; factory . setValidating ( true ) ; long millis = formatter . parse ( revertTZHack ( timeNodes . item ( 0 ) . getTextContent ( ) ) ) . getTime ( ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "bug", "with", "empty", "serialized", "map", "(", "of", "PIs", ")"], "add_tokens": "// Correct system name for streams this . setSystemNameForStreams ( topology . getStreams ( ) ) ; // Add all PIs to a collection (map) for ( EntranceProcessingItem epi : entranceProcessingItems ) { SamzaEntranceProcessingItem sepi = ( SamzaEntranceProcessingItem ) epi ; piMap . put ( sepi . getName ( ) , sepi ) ; } for ( IProcessingItem pi : processingItems ) { SamzaProcessingItem spi = ( SamzaProcessingItem ) pi ; piMap . put ( spi . getName ( ) , spi ) ; }", "del_tokens": "// Correct system name for streams this . setSystemNameForStreams ( topology . getStreams ( ) ) ; piMap . put ( sepi . getName ( ) , sepi ) ; piMap . put ( spi . getName ( ) , spi ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "LDapSecurityUser", "hash", "code"], "add_tokens": "if ( super . equals ( obj ) ) return true ;", "del_tokens": "if ( ! super . equals ( obj ) ) return false ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "streetAddress", "()", "locality", "()", "region", "()", "and", "countryName", "()", "to", "CardBuilder", "."], "add_tokens": ". streetAddress ( \"1 Main St\" ) . locality ( \"Some Town\" ) . postalCode ( \"12345\" ) . region ( \"Some Region\" ) . countryName ( \"Some Country\" ) ; assertEquals ( \"1 Main St\" , builtCard . getJSONObject ( \"billingAddress\" ) . getString ( \"streetAddress\" ) ) ; assertEquals ( \"Some Town\" , builtCard . getJSONObject ( \"billingAddress\" ) . getString ( \"locality\" ) ) ; assertEquals ( \"Some Region\" , builtCard . getJSONObject ( \"billingAddress\" ) . getString ( \"region\" ) ) ; assertEquals ( \"Some Country\" , builtCard . getJSONObject ( \"billingAddress\" ) . getString ( \"countryName\" ) ) ; assertFalse ( builtCard . getJSONObject ( \"billingAddress\" ) . has ( \"streetAddress\" ) ) ; assertFalse ( builtCard . getJSONObject ( \"billingAddress\" ) . has ( \"locality\" ) ) ; assertFalse ( builtCard . getJSONObject ( \"billingAddress\" ) . has ( \"region\" ) ) ; assertFalse ( builtCard . getJSONObject ( \"billingAddress\" ) . has ( \"countryName\" ) ) ;", "del_tokens": ". postalCode ( \"12345\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "cache", "collections"], "add_tokens": "BoxRequestsCollections . GetCollectionItems request = new BoxRequestsCollections . GetCollectionItems ( id , getCollectionItemsUrl ( id ) , mSession ) ;", "del_tokens": "BoxRequestsCollections . GetCollectionItems request = new BoxRequestsCollections . GetCollectionItems ( getCollectionItemsUrl ( id ) , mSession ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "Natural", "language", "classifier", "url"], "add_tokens": "private static String URL = \"https://gateway.watsonplatform.net/natural-language-classifier-beta/api\" ;", "del_tokens": "private static String URL = \"https://gateway.watsonplatform.net/natural-language-classifier-experimental/api\" ;", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "Linux", "32", "bit", "."], "add_tokens": "linux32 , linux64 , case linux32 : case linux64 : exe = readResource ( \"/packr-linux-x64\" ) ; break ; if ( config . platform != Platform . linux32 && config . platform != Platform . linux64 ) { extensions . add ( \".so\" ) ; } if ( config . platform != Platform . windows ) { extensions . add ( \".dll\" ) ; } if ( config . platform != Platform . mac ) { extensions . add ( \".dylib\" ) ; }", "del_tokens": "linux , case linux : if ( config . platform == Platform . linux ) { extensions . add ( \".dylib\" ) ; extensions . add ( \".dll\" ) ; } if ( config . platform == Platform . windows ) { extensions . add ( \".dylib\" ) ; extensions . add ( \".so\" ) ; } if ( config . platform == Platform . mac ) { extensions . add ( \".so\" ) ; extensions . add ( \".dll\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "when", "destination", "file", "cannot", "be", "created", "."], "add_tokens": "boolean errorCreatingDestinationFile = false ; errorCreatingDestinationFile = true ; // If Destination file couldn't be created. Abort the data transfer. if ( errorCreatingDestinationFile == false ) { try { out = new FileOutputStream ( destinationFile , true ) ; outFd = ( ( FileOutputStream ) out ) . getFD ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } if ( in == null ) { updateDownloadFailed ( DownloadManager . ERROR_FILE_ERROR , \"Error in creating input stream\" ) ; } else if ( out == null ) { updateDownloadFailed ( DownloadManager . ERROR_FILE_ERROR , \"Error in writing download contents to the destination file\" ) ; } else { // Start streaming data transferData ( in , out ) ; }", "del_tokens": "boolean errorOccurred = false ; errorOccurred = true ; try { out = new FileOutputStream ( destinationFile , true ) ; outFd = ( ( FileOutputStream ) out ) . getFD ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } if ( in == null && errorOccurred == false ) { updateDownloadFailed ( DownloadManager . ERROR_FILE_ERROR , \"Error in creating input stream\" ) ; } else if ( out == null && errorOccurred == false ) { updateDownloadFailed ( DownloadManager . ERROR_FILE_ERROR , \"Error in writing download contents to the destination file\" ) ; } else { // Start streaming data transferData ( in , out ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "check", "for", "missing", "DiscoveryClient", "when", "using", "default", "EurekaHostsSupplier"], "add_tokens": "import com . netflix . dyno . connectionpool . exception . DynoConnectException ; throw new DynoConnectException ( \"HostSupplier not provided. Cannot init EurekaHostsSupplier which needs a non null DiscoveryClient\" ) ;", "del_tokens": "hostSupplier = new EurekaHostsSupplier ( clusterName ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "touch", "and", "unlock", "."], "add_tokens": ". addLast ( new BinaryCodec ( bucket ( ) , environment ( ) ) ) ;", "del_tokens": ". addLast ( new BinaryCodec ( environment ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "fairly", "sneaky", "test", "issue", "involving", "spring", "beanfactories"], "add_tokens": "import java . util . Arrays ; public enum FXMLNODES implements FxmlNode { public void can_instantiate_controller_as_prototype ( ) { final SAMPLE_CONTROL_CLASS inst1 = this . context . getBean ( SAMPLE_CONTROL_CLASS . class ) ; final SAMPLE_CONTROL_CLASS inst2 = this . context . getBean ( SAMPLE_CONTROL_CLASS . class ) ; assertThat ( Arrays . asList ( inst1 , inst2 ) ) . doesNotContainNull ( ) ; assertThat ( inst1 ) . isNotEqualTo ( inst2 ) ;", "del_tokens": "private enum FXMLNODES implements FxmlNode { public void can_instantiate_test_class ( ) { final SAMPLE_CONTROL_CLASS bean = this . context . getBean ( SAMPLE_CONTROL_CLASS . class ) ; assertThat ( bean ) . isNotNull ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "interface", "to", "control", "can", "scroll", "feature", "."], "add_tokens": "private boolean mCanScrollHorizontally ; private boolean mCanScrollVertically ; this . mCanScrollVertically = super . canScrollVertically ( ) ; this . mCanScrollHorizontally = super . canScrollHorizontally ( ) ; public void setCanScrollVertically ( boolean canScrollVertically ) { this . mCanScrollVertically = canScrollVertically ; } public void setCanScrollHorizontally ( boolean canScrollHorizontally ) { this . mCanScrollHorizontally = canScrollHorizontally ; } return mCanScrollHorizontally && ! mNoScrolling ; return mCanScrollVertically && ! mNoScrolling ;", "del_tokens": "return super . canScrollHorizontally ( ) && ! mNoScrolling ; return super . canScrollVertically ( ) && ! mNoScrolling ;", "commit_type": "add"}
{"commit_tokens": ["allow", "for", "instances", "rather", "than", "static", "mess", "."], "add_tokens": "public OrchestratedParameterized ( Class < ? extends OrchestratedTestBuilder > klass ) throws Throwable { Method getSpecifications = OrchestratedTestBuilder . class . getDeclaredMethod ( \"getSpecifications\" ) ; getSpecifications . setAccessible ( true ) ; List < OrchestratedTestSpecification > specifications = ( List ) getSpecifications . invoke ( klass . newInstance ( ) ) ;", "del_tokens": "public OrchestratedParameterized ( Class < OrchestratedTestBuilder > klass ) throws Throwable { //we want to recursive go up object tree to invoke configure() to 'simulate' inheritance Class currentClass = klass ; try { while ( currentClass != OrchestratedTestBuilder . class ) { Method configureMethod = currentClass . getMethod ( \"configure\" ) ; configureMethod . invoke ( null ) ; currentClass = currentClass . getSuperclass ( ) ; } } catch ( NoSuchMethodException e ) { throw new RuntimeException ( \"A public static void configure() method must be defined\" , e ) ; } Method specificationsMethod = klass . getMethod ( \"getSpecifications\" ) ; List < OrchestratedTestSpecification > specifications = ( List ) specificationsMethod . invoke ( null ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "extra", "tests", "to", "simulate", "real", "usage"], "add_tokens": "public static final class PreprocessingStatistics { public PreprocessingStatistics execute ( ) throws IOException { return stat ;", "del_tokens": "private static final class PreprocessingStatistics { public void execute ( ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["add", "db", "name", "to", "the", "verbose", "log"], "add_tokens": "if ( verbose ) getLog ( ) . info ( \"enable pagination service with mysql for context \" + context . getId ( ) ) ; if ( verbose ) getLog ( ) . info ( \"enable pagination service with postgresql for context \" + context . getId ( ) ) ; if ( verbose ) getLog ( ) . info ( \"enable geom service with postgresql for context \" + context . getId ( ) ) ;", "del_tokens": "if ( verbose ) getLog ( ) . info ( \"enable pagination service for context \" + context . getId ( ) ) ; if ( verbose ) getLog ( ) . info ( \"enable pagination service for context \" + context . getId ( ) ) ; if ( verbose ) getLog ( ) . info ( \"enable geom service for context \" + context . getId ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Option", ".", "flatMap", "(", "...", ")"], "add_tokens": "Option < Integer > mapped = option . map ( v -> v . length ( ) ) ; assertTrue ( mapped . isDefined ( ) ) ; assertEquals ( TEXT_VALUE . length ( ) , mapped . get ( ) . intValue ( ) ) ; } @ Test public void flatMap ( ) { Option < Integer > mapped = option . flatMap ( v -> Option . apply ( v . length ( ) ) ) ; assertTrue ( mapped . isDefined ( ) ) ; assertEquals ( TEXT_VALUE . length ( ) , mapped . get ( ) . intValue ( ) ) ;", "del_tokens": "assertTrue ( option . map ( v -> 666 ) . isDefined ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "typo", "in", "comment", "."], "add_tokens": "* For a predicate of arity n , the first n registers are used to receive its arguments in . Terms appearing directly", "del_tokens": "* For a predicate of arity n , the first n registers are used to recieve its arguments in . Terms appearing directly", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "for", "FieldDefinitionBuilder", ".", "Javadocs", "."], "add_tokens": "/ * * * Builder that allows to specify properties for a cron field supporting non - standard characters * / / * * * Constructor * @ param parserBuilder - ParserDefinitionBuilder * @ param fieldName - CronFieldName * / / * * * Registers the field supports the hash ( # ) special char * @ return this FieldSpecialCharsDefinitionBuilder instance * / / * * * Registers the field supports the L ( L ) special char * @ return this FieldSpecialCharsDefinitionBuilder instance * / / * * * Registers the field supports the W ( W ) special char * @ return this FieldSpecialCharsDefinitionBuilder instance * / / * * * Defines mapping between integer values with equivalent meaning * @ param source - higher value * @ param dest - lower value with equivalent meaning to source * @ return this FieldSpecialCharsDefinitionBuilder instance * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixing", "a", "typo", "in", "the", "classname", "for", "InstanceIdListenerTests"], "add_tokens": "public class InstanceIdListenerTests extends PatchedActivityInstrumentationTestCase { public InstanceIdListenerTests ( ) {", "del_tokens": "public class IInstanceIdListenerTests extends PatchedActivityInstrumentationTestCase { public IInstanceIdListenerTests ( ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "that", "type", "of", "quantity", "must", "be", "double", "or", "float", "before", "it", "ll", "be", "divided", "."], "add_tokens": "Modbus . checkEndAddress ( startAddress + ( int ) Math . ceil ( ( double ) quantity / 16 ) ) ;", "del_tokens": "Modbus . checkEndAddress ( startAddress + ( int ) Math . ceil ( quantity / 16 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["change", "the", "condition", "for", "showOkButtonByDefault"], "add_tokens": "if ( ! showOKButtonByDefault ) { private boolean showOKButtonByDefault = true ;", "del_tokens": "if ( showOKButtonByDefault ) { private boolean showOKButtonByDefault = false ;", "commit_type": "change"}
{"commit_tokens": ["Added", "runtime", "exception", "to", "say", "Any", ".", "otherThan", "()", "does", "not", "work", "for", "generics"], "add_tokens": "if ( others [ 0 ] . getClass ( ) . getTypeParameters ( ) . length > 0 ) { throw new RuntimeException ( \"otherThan() does not work for generics. Try Any.anonymous(new InstanceOf<MyType<GenericType>>() {}, otherThan(x,y,z))\" ) ; }", "del_tokens": "//todo doesn't work for generics", "commit_type": "add"}
{"commit_tokens": ["Changed", "date", "type", "MBean", "attributes", "from", "String", "into", "XMLGregorianCalendar"], "add_tokens": "import org . softee . management . annotation . ManagedOperation ; @ ManagedAttribute ( \"The time at which the MBean was started\" ) public XMLGregorianCalendar getStarted ( ) { return date ( noneAsNull ( started ) ) ; return ( millis != null ) ? date ( millis ) . toXMLFormat ( ) : null ;", "del_tokens": "import org . softee . management . annotation . ManagedOperation ; @ ManagedAttribute ( \"The time when the monitor was started\" ) public String getStarted ( ) { return dateString ( noneAsNull ( started ) ) ; if ( millis == null ) { return null ; } return date ( millis ) . toXMLFormat ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "buy", "share", "login", "and", "logout", "buttons"], "add_tokens": "/ * * * The Enum for WebViewHeightRatioType * * @ author Alvin Reyes * @ date 27 / Nov / 2016 * * / WEB_URL , POSTBACK , PHONE_NUMBER , ELEMENT_SHARE , ACCOUNT_LINK , ACCOUNT_UNLINK , PAYMENT ;", "del_tokens": "WEB_URL , POSTBACK , PHONE_NUMBER ;", "commit_type": "add"}
{"commit_tokens": ["change", "sample", "module", "package", "from", "com", ".", "github", ".", "andkulikov", ".", "transitions", ".", "everywhere", "to", "com", ".", "andkulikov", ".", "transitionseverywhere"], "add_tokens": "package com . andkulikov . transitionseverywhere ;", "del_tokens": "package com . github . andkulikov . transitions . everywhere ;", "commit_type": "change"}
{"commit_tokens": ["Added", "a", "equals", "with", "a", "specifiable", "tolerance", "to", "Vector"], "add_tokens": "public boolean equals ( Object obj , double range ) { if ( ! ( obj instanceof Vec ) ) return false ; Vec otherVec = ( Vec ) obj ; range = Math . abs ( range ) ; if ( this . length ( ) != otherVec . length ( ) ) return false ; for ( int i = 0 ; i < length ( ) ; i ++ ) if ( Math . abs ( this . get ( i ) - otherVec . get ( i ) ) > range ) return false ; return true ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "command", "line", "args", "fix", "comment"], "add_tokens": "public String aws_credentials ; // properties file for aws credentials", "del_tokens": "public String hdfs_datanode ; // Datanode root public String aws_credentials ; // do not preload HDFS keys public String auth ; // Require authentication for the webpages", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "int", "toRead", "in", "readNextInputChunk", "throwing", "exception", "Requested", "array", "larger", "than", "VM", "allowed", "size"], "add_tokens": "import java . io . * ; import org . nustaq . offheap . bytez . * ; import org . nustaq . offheap . bytez . onheap . * ; import org . nustaq . serialization . util . * ; int toRead = Integer . MAX_VALUE - 5 ;", "del_tokens": "import org . nustaq . offheap . bytez . BasicBytez ; import org . nustaq . offheap . bytez . onheap . HeapBytez ; import org . nustaq . serialization . util . FSTUtil ; import java . io . ByteArrayInputStream ; import java . io . IOException ; import java . io . InputStream ; int toRead = Math . max ( Integer . MAX_VALUE , bytes ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "Custom", "notification", "icon", "loader", "issue"], "add_tokens": "resourceId = context . getResources ( ) . getIdentifier ( resourceName , DRAWABLE , context . getPackageName ( ) ) ;", "del_tokens": "resourceId = context . getResources ( ) . getIdentifier ( DRAWABLE + \"/\" + resourceName , DRAWABLE , context . getPackageName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "soyutils", ".", "js", "so", "that", "it", "compiles", "with", "strict", "settings", "in", "the", "Closure", "Compiler", "."], "add_tokens": "import com . google . template . soy . sharedpasses . opti . OptiModule ; // Install OptiModule, which explicitly binds classes in the opti package. // We use a separate module rather than inlining the classes here to allow // classes in the package to be package-private. install ( new OptiModule ( ) ) ;", "del_tokens": "import com . google . template . soy . sharedpasses . opti . PreevalVisitorFactory ; import com . google . template . soy . sharedpasses . opti . PrerenderVisitorFactory ; // Bindings for when explicit dependencies are required. bind ( PreevalVisitorFactory . class ) ; bind ( PrerenderVisitorFactory . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "test", "file", "and", "fixed", "internal", "verification", "rule", "order", "(", "KSIJAVAAPI", "-", "309", ")"], "add_tokens": "rules . add ( new AggregationHashChainLinkMetadataRule ( ) ) ;", "del_tokens": "rules . add ( new AggregationHashChainLinkMetadataRule ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "hamcrest", "problem", "with", "Iteratables"], "add_tokens": "import org . hamcrest . Matcher ; List < SearchItem > dockerSearch = dockerClient . search ( \"busybox\" ) ; Matcher matcher = hasItem ( hasField ( \"name\" , equalTo ( \"busybox\" ) ) ) ; assertThat ( dockerSearch , matcher ) ; Matcher matcher = hasItem ( hasField ( \"id\" , startsWith ( container1 . id ) ) ) ; assertThat ( containers2 , matcher ) ; Matcher matcher = not ( hasItem ( hasField ( \"id\" , startsWith ( container . id ) ) ) ) ; assertThat ( containers2 , matcher ) ; Matcher matcher = not ( hasItem ( hasField ( \"id\" , startsWith ( imageId ) ) ) ) ; assertThat ( containers , matcher ) ;", "del_tokens": "List dockerSearch = dockerClient . search ( \"busybox\" ) ; assertThat ( dockerSearch , hasItem ( hasField ( \"name\" , equalTo ( \"busybox\" ) ) ) ) ; assertThat ( containers2 , hasItem ( hasField ( \"id\" , startsWith ( container1 . id ) ) ) ) ; assertThat ( containers2 , not ( hasItem ( hasField ( \"id\" , startsWith ( container . id ) ) ) ) ) ; assertThat ( containers , not ( hasItem ( hasField ( \"id\" , startsWith ( imageId ) ) ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "open", "/", "close", "to", "chat", "store", "abstract", "class", "and", "removed", "transactions", "when", "only", "querying", "data"], "add_tokens": "store . open ( ) ; store . close ( ) ; store . open ( ) ; store . close ( ) ; store . beginTransaction ( ) ; store . beginTransaction ( ) ; isSuccessful = store . upsert ( message ) ; isSuccessful = store . upsert ( message ) ; * @ return Observable emitting result .", "del_tokens": "store . beginTransaction ( ) ; store . endTransaction ( ) ; store . beginTransaction ( ) ; store . endTransaction ( ) ; store . beginTransaction ( ) ; store . beginTransaction ( ) ; isSuccessful = isSuccessful && store . upsert ( message ) ; isSuccessful = isSuccessful && store . upsert ( message ) ; * @ return bservable emitting result .", "commit_type": "add"}
{"commit_tokens": ["Use", "javax", ".", "faces", ".", "view", ".", "ViewScoped", "instead", "of", "our", "good", "old", "but", "not", "standard", "ViewScoped", "."], "add_tokens": "$ output . require ( \"java.io.Serializable\" ) ## * More info on login : http : //balusc.blogspot.fr/2013/01/apache-shiro-is-it-ready-for-java-ee-6.html $ output . dynamicAnnotationTakeOver ( \"javax.inject.Named\" , \"javax.faces.view.ViewScoped\" ) public class $ output . currentClass implements Serializable { private transient Logger log ; @ Inject private transient MessageUtil messageUtil ;", "del_tokens": "* more info on login : http : //balusc.blogspot.fr/2013/01/apache-shiro-is-it-ready-for-java-ee-6.html $ output . dynamicAnnotationTakeOver ( \"javax.inject.Named\" , \" ${WebFaces.packageName}.ViewScoped\" ) public class $ output . currentClass { private Logger log = Logger . getLogger ( $ { output . currentClass } . class . getName ( ) ) ; private MessageUtil messageUtil ;", "commit_type": "use"}
{"commit_tokens": ["Added", "warning", "for", "long", "entity", "/", "property", "names", "in", "case", "you", "forget", "adding", "some", "new", "attribute", "/", "class", "names"], "add_tokens": "/** Maximum number of chars recommended for a kind */ private int maxKindChars = 3 ; String kind = getKind ( clazz ) ; if ( kind . length ( ) > maxKindChars ) { log . warn ( kind + \" is a long name for an entity kind. Consider using @Entity to make it shorter, which will save space in the Datastore. Use \" + ClassMetadataFactory . class . getSimpleName ( ) + \".setMaxKindChars() to disable this warning\" ) ; } metadata . setKind ( kind ) ; / * * * Set maximum number of chars for an entity kind . Set to Integer . MAX_VALUE to disable the warning associated to long entity names * / public void setMaxKindChars ( int maxKindChars ) { this . maxKindChars = maxKindChars ; }", "del_tokens": "metadata . setKind ( getKind ( clazz ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "correct", "parent", "classloader", "to", "fix", "Java", "9", "style", "modules", "."], "add_tokens": "return new URLClassLoader ( urls . toArray ( new URL [ 0 ] ) ) ;", "del_tokens": "return new URLClassLoader ( urls . toArray ( new URL [ 0 ] ) , null ) ;", "commit_type": "use"}
{"commit_tokens": ["Removed", "JavaOne", "hack", "--", "seems", "to", "have", "no", "effect"], "add_tokens": "", "del_tokens": "import java . beans . PropertyChangeListener ; // ////////////////JavaOne Hack/////////////////// private PropertyChangeListener uniqueListener = null ; / * * * Adds a single property change listener . If a listener has been previously added then it will be replaced by the * new one . TODO : remove * @ param propertyName the property name * @ param listener the listener * / public void addUniquePropertyChangeListener ( String propertyName , PropertyChangeListener listener ) { if ( uniqueListener != null && uniqueListener != listener ) { removePropertyChangeListener ( propertyName , uniqueListener ) ; } if ( uniqueListener != listener ) { uniqueListener = listener ; addPropertyChangeListener ( propertyName , uniqueListener ) ; } } // ///////////////End JavaOne Hack/////////////////", "commit_type": "remove"}
{"commit_tokens": ["Adding", "JUnit", "runner", "using", "WeldSE", "adding", "threading", "subsystem", "to", "help", "tune", "/", "config", "thread", "pools", "centrally", "(", "maybe", "including", "hooking", "up", "with", "built", "-", "in", "functionality", "eventually", ")", "expanding", "the", "size", "of", "the", "model", "cache", "for", "resolving", "maven", "models", "in", "the", "tensor", "listener"], "add_tokens": ". concurrencyLevel ( 10 ) . maximumSize ( 10000 ) . weakKeys ( )", "del_tokens": ". maximumSize ( 100 )", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "dependencies", "and", "shade", "internal", "dependencies"], "add_tokens": "private String name ;", "del_tokens": "import javax . validation . constraints . Pattern ; @ Pattern ( regexp = \"^[0-9A-Za-z](?:[-+_0-9A-Za-z\\\\.]*[0-9A-Za-z])?$\" ) private String name ;", "commit_type": "remove"}
{"commit_tokens": ["Removed", "a", "bunch", "of", "warnings", "from", "PredicatesTest", "."], "add_tokens": "@ SuppressWarnings ( { \"unchecked\" , \"rawtypes\" } ) // varargs @ SuppressWarnings ( { \"rawtypes\" , \"unchecked\" } ) public void testOr_arrayDefensivelyCopied ( ) {", "del_tokens": "@ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs @ SuppressWarnings ( \"unchecked\" ) // varargs public void testOr_arrayDefensivelyCopied ( ) { @ SuppressWarnings ( \"unchecked\" ) // varargs", "commit_type": "remove"}
{"commit_tokens": ["changed", "jenkins", "report", "log", "level", "to", "info"], "add_tokens": "LoggerFactory . getLogger ( this . getClass ( ) ) . info ( message ) ;", "del_tokens": "/ * * * Making it an 'error' to guarantee that message will be shown with any log level settings * / LoggerFactory . getLogger ( this . getClass ( ) ) . error ( message ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "context", "listener", "and", "movel", "general", "filter", "."], "add_tokens": "package jpaoletti . jpm ;", "del_tokens": "package jpaoletti . jpm . struts . actions ;", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "to", "catch", "and", "log", "exceptions", "thrown", "by", "Publisher", ".", "enqueueSend", "()"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger log = LoggerFactory . getLogger ( Publisher . class ) ; scheduler . schedule ( this :: enqueueSendWithErrorLogging , maxLatencyMs , MILLISECONDS ) ; / * * * A wrapper around enqueueSend which catches and logs any exceptions that are thrown . This is * called by the executor , which will silently swallow exceptions if we don 't handle them here. * / private void enqueueSendWithErrorLogging ( ) { try { enqueueSend ( ) ; } catch ( Exception e ) { log . error ( \"Error while enqueueing or sending messages on background thread\" , e ) ; } }", "del_tokens": "scheduler . schedule ( this :: enqueueSend , maxLatencyMs , MILLISECONDS ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "IPC", "workaround", "intermediary", "step", "while", "trying", "to", "get", "CDI", "Conversations", "to", "work"], "add_tokens": "import javax . enterprise . context . ConversationScoped ; import java . io . Serializable ; @ ConversationScoped public class SelectedTaskBean implements Serializable { private static final long serialVersionUID = 1L ; // // String taskId = getSelectedTaskId ( ) ; conversation . begin ( ) ; businessProcess . startTask ( taskId , true ) ; public String getSelectedTaskId ( ) { return ( String ) getSharedSessionAttribute ( \"camunda.selected.task.id\" ) ; }", "del_tokens": "import javax . enterprise . context . ApplicationScoped ; //@ApplicationScoped public class SelectedTaskBean { // conversation.begin();", "commit_type": "add"}
{"commit_tokens": ["Make", "constructor", "accept", "collection", "instead", "of", "a", "list"], "add_tokens": "public JsonArray ( Collection existing ) {", "del_tokens": "import java . util . List ; public JsonArray ( List existing ) {", "commit_type": "make"}
{"commit_tokens": ["fixed", "problem", "with", "window", "dim"], "add_tokens": "if ( dialog . getWindow ( ) != null ) { if ( enterAnimation != NO_ANIMATION || exitAnimation != NO_ANIMATION ) { int style = getStyle ( enterAnimation , exitAnimation ) ; if ( style == - 1 ) { Log . w ( TAG , \"The animation selected is not available. Default animation will be used.\" ) ; } else { dialog . getWindow ( ) . getAttributes ( ) . windowAnimations = style ; }", "del_tokens": "if ( dialog . getWindow ( ) != null && ( enterAnimation != NO_ANIMATION || exitAnimation != NO_ANIMATION ) ) { int style = getStyle ( enterAnimation , exitAnimation ) ; if ( style == - 1 ) { Log . w ( TAG , \"The animation selected is not available. Default animation will be used.\" ) ; } else { dialog . getWindow ( ) . getAttributes ( ) . windowAnimations = style ;", "commit_type": "fix"}
{"commit_tokens": ["add", "ability", "of", "use", "TransitionSet", "of", "Transitions", "with", "different", "duration"], "add_tokens": "Transition transition = ( Transition ) mTransitions . get ( i ) . clone ( ) ; long duration = transition . getDuration ( ) ; clone . addTransition ( transition ) ; transition . setDuration ( duration ) ;", "del_tokens": "clone . addTransition ( ( Transition ) mTransitions . get ( i ) . clone ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "static", "file", "response", "writer"], "add_tokens": "import com . zandero . utils . StringUtils ; String message = exception . getMessage ( ) ; if ( StringUtils . isNullOrEmptyTrimmed ( message ) ) { response . end ( exception . toString ( ) ) ; } else { response . end ( message ) ; }", "del_tokens": "response . end ( exception . getMessage ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "syncCursor", "for", "inserts", "as", "well"], "add_tokens": "if ( ( size + promptLength ( ) + 1 ) % width == 1 && deltaChangedAtEndOfBuffer ) { builder . append ( syncCursor ( size + getPrompt ( ) . getLength ( ) , cursor + promptLength ( ) , width ) ) ;", "del_tokens": "if ( ( size + promptLength ( ) + 1 ) % width == 1 ) { //if cursor and and of buffer is on the same line: if ( size / width == cursor / width ) { builder . append ( moveNumberOfColumns ( size - cursor , 'D' ) ) ; } //if cursor and enf of buffer is on different lines, we need to move the cursor else { int numLines = ( size / width ) - ( cursor / width ) ; int sameLine = size - ( width * numLines ) ; if ( sameLine < cursor ) builder . append ( moveNumberOfColumns ( cursor - sameLine , 'C' ) ) ; else builder . append ( moveNumberOfColumns ( cursor - sameLine , 'D' ) ) ; }", "commit_type": "use"}
{"commit_tokens": ["Adding", "endpoint", "to", "get", "permissions", "by", "path", "and", "actor"], "add_tokens": "import reactor . core . publisher . Mono ; import org . springframework . credhub . support . permissions . Actor ; * @ author Alberto C . R o s static final String PERMISSIONS_PATH_ACTOR_URL_QUERY = PERMISSIONS_URL_PATH + \"?path={path}&actor={actor}\" ; @ Override public Mono < CredentialPermission > getPermissionsByPathAndActor ( final CredentialName path , final Actor actor ) { Assert . notNull ( path , \"credential path must not be null\" ) ; Assert . notNull ( actor , \"credential actor must not be null\" ) ; return credHubOperations . doWithWebClient ( webClient -> webClient . get ( ) . uri ( PERMISSIONS_PATH_ACTOR_URL_QUERY , path . getName ( ) , actor . getIdentity ( ) ) . retrieve ( ) . onStatus ( HttpStatus :: isError , ExceptionUtils :: buildError ) . bodyToMono ( CredentialPermission . class ) ) ; }", "del_tokens": "import reactor . core . publisher . Mono ;", "commit_type": "add"}
{"commit_tokens": ["implementing", "onIOError", "method", "for", "handling", "IOException", "errors"], "add_tokens": "onIOError ( ex ) ; onIOError ( ex ) ; / * * * Triggered on any IOException error . This method should be overridden for custom * implementation of error handling ( e . g . when network is not available ) . * @ param ex * / public void onIOError ( IOException ex ) { ex . printStackTrace ( ) ; }", "del_tokens": "ex . printStackTrace ( ) ; ex . printStackTrace ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "the", "resolution", "for", "the", "length", "computation", "to", "96", "DPI", "(", "CSS3", ")"], "add_tokens": "/** CSS3 uses a fixed value of 96DPI for computing the lengths */ public static final float dpi = 96.0f ; * Converts a length from a CSS length to 'px' .", "del_tokens": "* Converts a length from a CSS length to 'px' while using the current media resolution . float dpi = getResolution ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "AOP", "Alliance", "interceptors", ".", "Support", "registration", "with", "Guice", "."], "add_tokens": "import javax . inject . Inject ; import javax . inject . Named ; @ Inject public DriverManagerConnectionProvider ( @ Named ( \"jdbc.url\" ) @ NotNull String url , @ Named ( \"jdbc.login\" ) @ Nullable String user , @ Named ( \"jdbc.password\" ) @ Nullable String password ) {", "del_tokens": "public DriverManagerConnectionProvider ( @ NotNull String url , @ Nullable String user , @ Nullable String password ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "systemId", "used", "to", "parse", "xml", "files"], "add_tokens": "result = loadXml ( node . getIO ( ) , node . getURI ( ) . toString ( ) , src ) ;", "del_tokens": "result = loadXml ( node . getIO ( ) , node . getPath ( ) , src ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "NPE", "as", "reported", "by", "an", "user", ":"], "add_tokens": "if ( hudsonUrl == null ) return Hudson . getInstance ( ) . getRootUrl ( ) ; }", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["updating", "tests", "gitignore", "and", "adding", "abstraction", "for", "formatter"], "add_tokens": "private List < Piece > pieces = new ArrayList < > ( ) ; private Formatter formatter = new Formatter ( ) { @ Override public CharSequence format ( String input ) { return Html . fromHtml ( input ) ; } } ; return formatter . format ( input ) ; } / * * * Sets custom string formatter . It 's created for Unit Tests. * Default formatter format HTML tags . * Please be careful with this method and use it only when necessary ! * * @ param formatter implementation of formatter interface * @ return Kirai object * / public Kirai formatter ( Formatter formatter ) { this . formatter = formatter ; return this ;", "del_tokens": "private List < Piece > pieces = new ArrayList < > ( ) ; return Html . fromHtml ( input ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "new", "line", "at", "the", "end", "of", "some", "files"], "add_tokens": "}", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["add", "unit", "tests", "for", "CharSequenceReader"], "add_tokens": "if ( cs == null ) { throw new IOException ( \"Can't read form a closed Reader\" ) ; } return cs . charAt ( leftMostUnread ++ ) ;", "del_tokens": "} else { return cs . charAt ( leftMostUnread ++ ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "FileUtils", "to", "find", "files", "/", "folders", "given", "partial", "input", "from", "command"], "add_tokens": "import org . jboss . jreadline . util . ANSI ; console . pushToConsole ( ANSI . getAlternateBufferScreen ( ) ) ; console . pushToConsole ( ANSI . getMainBufferScreen ( ) ) ;", "del_tokens": "console . switchToAlternateScreenBuffer ( ) ; console . switchToMainScreenBuffer ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "no", "-", "arg", "Customer", ".", "cancelSubscription", "."], "add_tokens": "public static final String VERSION = \"1.0.8\" ;", "del_tokens": "public static final String VERSION = \"1.0.7\" ;", "commit_type": "add"}
{"commit_tokens": ["removed", "commons", "-", "lang", "dependency"], "add_tokens": "import java . util . Map . Entry ; import java . util . Properties ; import java . util . Set ; Map < String , String > variables = new LinkedHashMap < String , String > ( System . getenv ( ) ) ; addAll ( variables , System . getProperties ( ) ) ; substitutor = new StrSubstitutor ( variables ) ; } private void addAll ( Map < String , String > variables , Properties properties ) { Set < Entry < Object , Object > > entries = properties . entrySet ( ) ; for ( Entry < Object , Object > entry : entries ) variables . put ( ( String ) entry . getKey ( ) , ( String ) entry . getValue ( ) ) ;", "del_tokens": "import org . apache . commons . lang . text . StrSubstitutor ; Map < Object , Object > properties = new LinkedHashMap < Object , Object > ( System . getenv ( ) ) ; properties . putAll ( System . getProperties ( ) ) ; substitutor = new StrSubstitutor ( properties ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "message", "with", "an", "ALPHA", "string"], "add_tokens": "private String version = \"0.3.4\" ; return version ; return \"Stratio Streaming\" ;", "del_tokens": "return \"ALPHA\" ; return \"Init Banner Provider\" ;", "commit_type": "fix"}
{"commit_tokens": ["add", "three", "more", "analyzer", "[", "jcseg_complex", "jcseg_simple", "jcseg_detect", "]"], "add_tokens": "import org . lionsoul . jcseg . tokenizer . core . ADictionary ; File proFile = new File ( \"plugins/jcseg/jcseg.properties\" ) ; JcsegTaskConfig config = proFile . exists ( ) ? new JcsegTaskConfig ( proFile . getPath ( ) ) : new JcsegTaskConfig ( ) ; ADictionary dic = DictionaryFactory . createSingletonDictionary ( config ) ; //default new PreBuiltAnalyzerProviderFactory ( \"jcseg\" , AnalyzerScope . INDICES , new JcsegAnalyzer5X ( JcsegTaskConfig . COMPLEX_MODE , config , dic ) ) ) ; //complex mode indicesAnalysisService . analyzerProviderFactories ( ) . put ( \"jcseg_complex\" , new PreBuiltAnalyzerProviderFactory ( \"jcseg\" , AnalyzerScope . INDICES , new JcsegAnalyzer5X ( JcsegTaskConfig . COMPLEX_MODE , config , dic ) ) ) ; //simple mode indicesAnalysisService . analyzerProviderFactories ( ) . put ( \"jcseg_simple\" , new PreBuiltAnalyzerProviderFactory ( \"jcseg\" , AnalyzerScope . INDICES , new JcsegAnalyzer5X ( JcsegTaskConfig . SIMPLE_MODE , config , dic ) ) ) ; //detect mode indicesAnalysisService . analyzerProviderFactories ( ) . put ( \"jcseg_detect\" , new PreBuiltAnalyzerProviderFactory ( \"jcseg\" , AnalyzerScope . INDICES , new JcsegAnalyzer5X ( JcsegTaskConfig . DETECT_MODE , config , dic ) )", "del_tokens": "new PreBuiltAnalyzerProviderFactory ( \"jcseg\" , AnalyzerScope . INDICES , new JcsegAnalyzer5X ( JcsegTaskConfig . COMPLEX_MODE ) )", "commit_type": "add"}
{"commit_tokens": ["Move", "<script", ">", "in", "document"], "add_tokens": "t . emitStyle ( ) ; t . emitForm ( ) ; t . validate ( ) ; t . emitScript ( ) ;", "del_tokens": "t . emitIncludes ( ) ; t . emitForm ( ) ; t . validate ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Making", "column", "support", "comma", "and", "space", "separated", "list"], "add_tokens": "* @ author Pontus Enmark *", "del_tokens": "private static final String SEPARATOR = \",\" ; *", "commit_type": "make"}
{"commit_tokens": ["Improves", "the", "UnsafeArrayList", "so", "it", "functions", "more", "correctly", "as", "a", "List", "."], "add_tokens": "public static long firstFieldOffset ( Object obj ) { return firstFieldOffset ( obj . getClass ( ) ) ; } public static long sizeOfFields ( Object obj ) { return sizeOfFields ( obj . getClass ( ) ) ; } / * * * Size of all the fields * @ param clazz * @ return * / public static long sizeOfFields ( Class clazz ) { return sizeOf ( clazz ) - firstFieldOffset ( clazz ) ; }", "del_tokens": "", "commit_type": "improve"}
{"commit_tokens": ["Added", "expectAfter", "method", "to", "ExpectationBuilder", "interface"], "add_tokens": "import org . jmock . dynamic . InvocationMatcher ; public ExpectationBuilder addExpectation ( InvocationMatcher expectation ) { mocker . addMatcher ( expectation ) ; return this ; } return addExpectation ( new InvokeOnceMatcher ( ) ) ; public ExpectationBuilder expectAfter ( ExpectationBuilder previousCall ) { //TODO Complete this method return this ; }", "del_tokens": "mocker . addMatcher ( new InvokeOnceMatcher ( ) ) ; return this ;", "commit_type": "add"}
{"commit_tokens": ["added", "comment", "explaining", "why", "the", "exception", "is", "not", "logged", "in", "test"], "add_tokens": "//exception thrown for a non existing url, we do not need to call a real url, only to start the relevant leaking classes", "del_tokens": "//", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "delete", "paused", "requests", "directly", "."], "add_tokens": "public DeleteResult deletePausedRequest ( String requestId ) { return delete ( getPausedPath ( requestId ) ) ;", "del_tokens": "public void deletePausedRequest ( String requestId ) { delete ( getPausedPath ( requestId ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "workaround", "for", "JSR", "-", "310", "classes", "in", "request", "/", "response", "body", "types"], "add_tokens": "// default for all JSR-310 classes if ( type . startsWith ( \"java.time\" ) ) { builder . add ( key , \"date\" ) ; return ; }", "del_tokens": "case \"java.time.LocalDate\" :", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "database", "name", "for", "togglz"], "add_tokens": "this . collection = database . getCollection ( \"togglz\" ) ;", "del_tokens": "this . collection = database . getCollection ( \"menuitemconfiguration\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "POST", "method", "management", "in", "case", "of", "no", "parameter", "entry", "in", "the", "post", "data", "(", "no", "form", "-", "data", "or", "x", "-", "www", "-", "form", "-", "urlencoded", "contentType", ")", "but", "raw", "data", "like", "this", "kind", "of", "request", ":"], "add_tokens": "// Handle application/x-www-form-urlencoded if ( \"application/x-www-form-urlencoded\" . equalsIgnoreCase ( contentType ) ) { decodeParms ( postLine , parms ) ; } else if ( postLine . length ( ) != 0 ) { // Special case for raw POST data => create a special files entry \"postData\" with raw content data files . put ( \"postData\" , postLine ) ; } public String getQueryParameterString ( ) {", "del_tokens": "// Handle application/x-www-form-urlencoded decodeParms ( postLine , parms ) ; public String getQueryParameterString ( ) {", "commit_type": "improve"}
{"commit_tokens": ["adds", "bean", "name", "to", "liquibase", "method", "to", "prevent", "problems", "when", "renaming", "the", "method"], "add_tokens": "@ Bean ( \"liquibase\" )", "del_tokens": "@ Bean", "commit_type": "add"}
{"commit_tokens": ["fixed", "(", "missing", "start", "offset", "added", ")"], "add_tokens": "result [ i ] = getHashCode ( string , stringStart + i , stringStart + i + length ) ;", "del_tokens": "result [ i ] = getHashCode ( string , i , i + length ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "javadoc", "for", "any", "constant", "initialized", "with", "PropertyLoader", ".", "getTinaFwConfig"], "add_tokens": "/ * * * Configurable via the property \"tinafw.keep_browsers_open\" . * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["implemented", "Optimize", "action", ".", "Fixed", "a", "parameter", "setting", "bug", "on", "Stats", "&", "Status", "actions", "."], "add_tokens": "protected String buildURI ( ) {", "del_tokens": "public String getURI ( ) {", "commit_type": "implement"}
{"commit_tokens": ["add", "a", "validateTrace", "()", "method", "to", "map", "matching", "builder"], "add_tokens": "import com . mapbox . services . commons . models . Position ; import java . util . ArrayList ; private LineString trace ; // From https://www.mapbox.com/api-documentation/#map-matching trace = LineString . fromJson ( \"{ \\\"type\\\": \\\"LineString\\\", \\\"coordinates\\\": [ [13.418946862220764, 52.50055852688439], [13.419011235237122, 52.50113000479732], [13.419756889343262, 52.50171780290061], [13.419885635375975, 52.50237416816131], [13.420631289482117, 52.50294888790448] ] }\" ) ; . setTrace ( trace ) . setTrace ( trace ) . setTrace ( trace ) @ Test public void validCoordinates ( ) throws ServicesException { thrown . expect ( ServicesException . class ) ; thrown . expectMessage ( startsWith ( \"Using Mapbox Map Matching requires to set some coordinates\" ) ) ; new MapboxMapMatching . Builder ( ) . setAccessToken ( ACCESS_TOKEN ) . setProfile ( DirectionsCriteria . PROFILE_DRIVING ) . build ( ) ; } @ Test public void validCoordinatesTotal ( ) throws ServicesException { // Fake too many positions ArrayList < Position > positions = new ArrayList < > ( ) ; for ( int i = 0 ; i < 101 ; i ++ ) { positions . add ( Position . fromCoordinates ( 0.0 , 0.0 ) ) ; } thrown . expect ( ServicesException . class ) ; thrown . expectMessage ( startsWith ( \"The Map Matching API is limited to processing traces with up to 100 coordinates\" ) ) ; new MapboxMapMatching . Builder ( ) . setAccessToken ( ACCESS_TOKEN ) . setProfile ( DirectionsCriteria . PROFILE_DRIVING ) . setTrace ( LineString . fromCoordinates ( positions ) ) . build ( ) ; }", "del_tokens": "// // From https://www.mapbox.com/api-documentation/#map-matching // LineString trace = LineString.fromJson(\"{ \\\"type\\\": \\\"LineString\\\", \\\"coordinates\\\": [ [13.418946862220764, 52.50055852688439], [13.419011235237122, 52.50113000479732], [13.419756889343262, 52.50171780290061], [13.419885635375975, 52.50237416816131], [13.420631289482117, 52.50294888790448] ] }\");", "commit_type": "add"}
{"commit_tokens": ["Removed", "all", "external", "usage", "of", "an", "objectName", "String", "which", "was", "being", "confused", "with", "the", "JMX", "ObjectName", "."], "add_tokens": "/ * * * @ deprecated Should use { @ link # beanName ( ) } * / @ Deprecated public String objectName ( ) default \"\" ; public String beanName ( ) default \"\" ;", "del_tokens": "public String objectName ( ) default \"\" ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "error", "in", "state", "machine", "post", "event"], "add_tokens": "postStateTransition ( changedObject , previousState ) ;", "del_tokens": "postStateTransition ( object , previousState ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "mapping", "for", "mobile", "web"], "add_tokens": "if ( dcRequest . getMobile ( ) . getIsApp ( ) ) {", "del_tokens": "if ( dcRequest . hasMobile ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Move", "value", "interfaces", "to", "their", "own", "file", "."], "add_tokens": "private final ValueConverter converter ; public ValueConverter getConverter ( ) {", "del_tokens": "private final ConvertUtil . ValueConverter converter ; public ConvertUtil . ValueConverter getConverter ( ) {", "commit_type": "move"}
{"commit_tokens": ["Updated", "kernel", "to", "allow", "installing", "of", "file", "build", "by", "maven", "and", "plain", "osgi", "bundles", "from", "file"], "add_tokens": "framework . getBundleContext ( ) . registerService ( MavenInstaller . class , maven , null ) ; installBundles ( framework , maven , args ) ; private void installBundles ( final Framework framework , final MavenInstallerImpl maven , final String ... args ) throws IOException { } else if ( arg . startsWith ( \"install:\" ) ) { framework . getBundleContext ( ) . installBundle ( \"file:\" + arg . substring ( \"install:\" . length ( ) ) ) . start ( ) ;", "del_tokens": "framework . getBundleContext ( ) . registerService ( MavenInstaller . class . getName ( ) , maven , null ) ; installBundles ( maven , args ) ; private void installBundles ( final MavenInstallerImpl maven , final String ... args ) throws IOException {", "commit_type": "update"}
{"commit_tokens": ["Improve", "the", "welcome", "page", "of", "the", "archetype", "."], "add_tokens": "Assert . assertTrue ( response . getOutputAsString ( ) . contains ( \"Jogger\" ) ) ;", "del_tokens": "Assert . assertTrue ( response . getOutputAsString ( ) . contains ( \"test\" ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "more", "util", "methods", "to", "Throwables", "."], "add_tokens": "import java . lang . reflect . Field ; import org . junit . Assert ; private static final class TestException extends Exception { public TestException ( String message ) { super ( message , null , true , false ) ; } } @ Test public void testGetRootCause ( ) { @ Test public void testGetRootCauseLoop ( ) throws NoSuchFieldException , IllegalAccessException { Throwable root = new IOException ( ) ; Throwable chain = new IOException ( new IOException ( new IOException ( new IOException ( new IOException ( root ) ) ) ) ) ; Field causeField = Throwable . class . getDeclaredField ( \"cause\" ) ; try { causeField . setAccessible ( true ) ; causeField . set ( root , chain ) ; Throwables . getRootCause ( chain ) ; Assert . fail ( \"must throw IllegalStateException\" ) ; } catch ( IllegalStateException ex ) { Assert . assertEquals ( \"loop in casual chain\" , ex . getMessage ( ) ) ; } finally { causeField . setAccessible ( false ) ; } } @ Test public void testGetStackTrace ( ) { Exception exception = new TestException ( \"message\" ) ; String stackTrace = Throwables . getStackTrace ( exception ) ; Assert . assertEquals ( \"org.nightcode.common.base.ThrowablesTest$TestException: message\\n\" , stackTrace ) ; }", "del_tokens": "@ Test public void getRootCause ( ) {", "commit_type": "add"}
{"commit_tokens": ["removed", "some", "dublications", "in", "test"], "add_tokens": "* @ version $ Id : TestEnhancer . java , v 1.13 2002 / 09 / 27 15 : 54 : 34 baliuka Exp $ fail ( \"must throw an exception\" ) ; fail ( \"invalid exception type\" ) ; fail ( \"invalid exception type\" ) ;", "del_tokens": "* @ version $ Id : TestEnhancer . java , v 1.12 2002 / 09 / 27 15 : 50 : 06 baliuka Exp $ public void testCheckedException ( ) throws Throwable { Source source = ( Source ) Enhancer . enhance ( Source . class , null , NOOP_INTERCEPTOR ) ; try { source . throwChecked ( ) ; fail ( \"lost exeption\" ) ; } catch ( Source . CheckedException e ) { } } fail ( \"must throw exeption\" ) ; fail ( \"invalid exeption\" ) ; fail ( \"invalid exeption\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Improved", "matcher", "labeling", "for", "cleanliness", "and", "performance"], "add_tokens": "private String defaultLabel ; @ SuppressWarnings ( { \"UnusedDeclaration\" } ) public String getLabel ( ) { return label != null ? label : defaultLabel ; } @ SuppressWarnings ( { \"UnusedDeclaration\" } ) public boolean hasCustomLabel ( ) { public AbstractMatcher < V > defaultLabel ( String defaultLabel ) { this . defaultLabel = defaultLabel ; return this ; }", "del_tokens": "public String getLabel ( ) { return label ; } public boolean hasLabel ( ) {", "commit_type": "improve"}
{"commit_tokens": ["Fix", "gradient", "paint", "in", "CanvasGraphics2D", "."], "add_tokens": "this . sb . append ( \"g.addColorStop(0,'\" ) . append ( toCSSColorValue ( gp . getColor1 ( ) ) ) . append ( \"');\" ) ; this . sb . append ( \"g.addColorStop(1,'\" ) . append ( toCSSColorValue ( gp . getColor2 ( ) ) ) . append ( \"');\" ) ; + \",\" + c . getAlpha ( ) / 255.0f + \")\" ; this . sb . append ( \"ctx.fillStyle=\\\"\" ) . append ( toCSSColorValue ( ( Color ) this . paint ) ) . append ( \"\\\";\" ) ; t . concatenate ( this . transform ) ; setTransform ( t ) ;", "del_tokens": "this . sb . append ( \"g.addColorStop(0,\" ) . append ( toCSSColorValue ( gp . getColor1 ( ) ) ) . append ( \");\" ) ; this . sb . append ( \"g.addColorStop(1,\" ) . append ( toCSSColorValue ( gp . getColor2 ( ) ) ) . append ( \");\" ) ; + \",\" + c . getAlpha ( ) + \")\" ; this . sb . append ( \"ctx.fillStyle=\" ) . append ( toCSSColorValue ( ( Color ) this . paint ) ) . append ( \";\" ) ; t . concatenate ( this . transform ) ; setTransform ( t ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "too", "long", "wait", "task", "bug"], "add_tokens": "Thread . sleep ( timeToWait ) ; timeToWait = timeToWait > MAX_TIME_MS_TO_WAIT ? MAX_TIME_MS_TO_WAIT : timeToWait ;", "del_tokens": "Thread . sleep ( timeToWait > MAX_TIME_MS_TO_WAIT ? MAX_TIME_MS_TO_WAIT : timeToWait ) ;", "commit_type": "fix"}
{"commit_tokens": ["change", "log", "level", "to", "debug"], "add_tokens": "if ( log . isDebugEnabled ( ) ) log . debug ( \"Registered type: \" + id + \" talker: \" + talker ) ; if ( map . get ( id ) . remove ( talker ) ) { if ( log . isDebugEnabled ( ) ) log . debug ( \"Unregistered type: \" + id + \" talker: \" + talker ) ; }", "del_tokens": "log . info ( \"Registered type: \" + id + \" talker: \" + talker ) ; if ( map . get ( id ) . remove ( talker ) ) log . info ( \"Unregistered type: \" + id + \" talker: \" + talker ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "iterator", "to", "string", "util", "-", "extract", "from", "IterableToString"], "add_tokens": "return IteratorToString . toString ( iterable . iterator ( ) ) ; } private IterableToString ( ) {", "del_tokens": "StringBuilder sb = new StringBuilder ( ) ; sb . append ( '(' ) ; boolean first = true ; for ( T v : iterable ) { if ( first ) first = false ; else sb . append ( ',' ) ; sb . append ( v ) ; } sb . append ( ')' ) ; return sb . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "multipoint", "geometries"], "add_tokens": "g . writeStartArray ( ) ; if ( ! mp . isEmpty ( ) ) { MultiPointImpl mpImpl = ( MultiPointImpl ) mp . _getImpl ( ) ; AttributeStreamOfDbl zs = mp . hasAttribute ( Semantics . Z ) ? ( AttributeStreamOfDbl ) mpImpl . getAttributeStreamRef ( Semantics . Z ) : null ; Point2D p = new Point2D ( ) ; int n = mp . getPointCount ( ) ; for ( int i = 0 ; i < n ; i ++ ) { mp . getXY ( i , p ) ; g . writeStartArray ( ) ; writeDouble ( p . x , g ) ; writeDouble ( p . y , g ) ; if ( zs != null ) writeDouble ( zs . get ( i ) , g ) ; g . writeEndArray ( ) ; } g . writeEndArray ( ) ;", "del_tokens": "if ( mp . isEmpty ( ) ) { g . writeStartArray ( ) ; g . writeEndArray ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "parameters", "in", "getItemsByFieldAndTitle", "method"], "add_tokens": "import com . podio . common . ToStringUtil ; * @ param notItemIds * If supplied the items with these ids will not be returned * @ param limit * The maximum number of results to return . Default value : 13 public List < ItemMini > getItemsByFieldAndTitle ( int fieldId , String text , List < Integer > notItemIds , Integer limit ) { WebResource resource = getResourceFactory ( ) . getApiResource ( \"/item/field/\" + fieldId + \"/find\" ) ; if ( limit != null ) { resource = resource . queryParam ( \"limit\" , limit . toString ( ) ) ; } if ( notItemIds != null && notItemIds . size ( ) > 0 ) { resource = resource . queryParam ( \"not_item_id\" , ToStringUtil . toString ( notItemIds , \",\" ) ) ; } resource = resource . queryParam ( \"text\" , text ) ; return resource . get ( new GenericType < List < ItemMini > > ( ) {", "del_tokens": "public List < ItemMini > getItemsByFieldAndTitle ( int fieldId , String text ) { return getResourceFactory ( ) . getApiResource ( \"/item/field/\" + fieldId + \"/find\" ) . queryParam ( \"text\" , text ) . get ( new GenericType < List < ItemMini > > ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "safe", "implementation"], "add_tokens": "CAPACITY . set ( bb , ( int ) size ( ) ) ; return ptr . getLong ( STRUCT_FIELD_OFFSET_SIZE ) ;", "del_tokens": "CAPACITY . set ( bb , size ( ) ) ; return ptr . getLong ( ptrAddress + STRUCT_FIELD_OFFSET_SIZE ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "JAWR", "-", "351"], "add_tokens": "import net . jawr . web . util . StopWatch ; StopWatch stopWatch = ThreadLocalJawrContext . getStopWatch ( ) ; stopWatch . start ( \"Processing bundle '\" + bundle . getName ( ) + \"'\" ) ; stopWatch . stop ( ) ; stopWatch . start ( \"Global postprocessing\" ) ; stopWatch . stop ( ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Adding", "SafeHtml", "version", "of", "some", "code", "to", "mitigate", "against", "CSRF", "/", "XSS"], "add_tokens": "import com . google . gwt . safehtml . shared . SafeHtmlUtils ; break ; return \"<a href=\\\"\" + SafeHtmlUtils . htmlEscape ( hyperLinkValue ) + \"\\\">\" + SafeHtmlUtils . htmlEscapeAllowEntities ( valueString ) + \"</a>\" ; return \"<span class=\\\"tableContentHrefOrderHack\\\" title=\\\"\" + SafeHtmlUtils . htmlEscape ( valueStringRaw ) + \"\\\">\" + SafeHtmlUtils . htmlEscapeAllowEntities ( valueString ) + \"</span>\" ;", "del_tokens": "break ; return \"<a href=\\\"\" + hyperLinkValue + \"\\\">\" + valueString + \"</a>\" ; return \"<span class=\\\"tableContentHrefOrderHack\\\" title=\\\"\" + valueStringRaw + \"\\\">\" + valueString + \"</span>\" ;", "commit_type": "add"}
{"commit_tokens": ["allow", "definition", "of", "collection", "class", "tag"], "add_tokens": "String tag = getCollectionClassTag ( ) ; if ( StringUtils . isNotBlank ( tag ) ) { entityClass . add ( tag ) ; } / * * * Returns the collection tag to be added to a collection 's class. The * default is 'collection' . Can be overridden to change tag or set to return * < code > null < / code > or empty in which case no tag will be added . * @ return may be < code > null < / code > or empty . * / protected String getCollectionClassTag ( ) { return \"collection\" ; }", "del_tokens": "entityClass . add ( \"collection\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "back", "cache", "for", "product", "with", "file"], "add_tokens": "if ( products == null ) { products = list ; cache . put ( getContext ( ) , products ) ; return products ; }", "del_tokens": "//if( products == null ) { return list ; //cache.put(getContext(), products); //}", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "single", "cached", "exception", "for", "suspend", "logic", "."], "add_tokens": "final TranscodingSuspend cachedSuspend = new TranscodingSuspend ( null ) ; tc . cachedSuspend . result = ret ; throw tc . cachedSuspend ;", "del_tokens": "throw new TranscodingSuspend ( ret ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "there", "are", "no", "null", "option", "values", "."], "add_tokens": "String inputPathString = null == inputPath ? \"\" : inputPath . getAbsolutePath ( ) ; String outputPathString = null == outputPath ? \"\" : outputPath . getAbsolutePath ( ) ; String sourceMapFile = null == javaOptions . getSourceMapFile ( ) ? \"\" : javaOptions . getSourceMapFile ( ) . getAbsolutePath ( ) ;", "del_tokens": "String inputPathString = inputPath . getAbsolutePath ( ) ; String outputPathString = outputPath . getAbsolutePath ( ) ; String sourceMapFile = null == javaOptions . getSourceMapFile ( ) ? \"\" : javaOptions . getSourceMapFile ( ) . getAbsolutePath ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "Plugin", "annotation", "request", "API", "."], "add_tokens": "import io . nuun . kernel . api . plugin . request . RequestType ; RequestType type ( ) default RequestType . VIA_SPECIFICATION ; Class < ? > value ( ) default Void . class ; String valueString ( ) default \"\" ;", "del_tokens": "Class < ? extends Specification < Class < ? > > > value ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "AppendToReponse", "to", "contain", "multiple", "elements"], "add_tokens": "StringBuilder sb = new StringBuilder ( ) ; boolean first = Boolean . TRUE ; for ( String append : appendToResponse ) { if ( first ) { first = Boolean . FALSE ; } else { sb . append ( \",\" ) ; } sb . append ( append ) ; } addArgument ( APPEND_TO_RESPONSE , sb . toString ( ) ) ;", "del_tokens": "addArgument ( APPEND_TO_RESPONSE , appendToResponse [ 0 ] ) ;", "commit_type": "allow"}
{"commit_tokens": ["Create", "CBLiteDatabaseInternal", "and", "move", "a", "method", "into", "it", "that", "is", "not", "supposed", "to", "be", "in", "the", "public", "api"], "add_tokens": "CBLRevisionInternal readRev = database . getDbInternal ( ) . getLocalDocument ( rev1 . getDocId ( ) , null ) ; readRev = database . getDbInternal ( ) . getLocalDocument ( rev2 . getDocId ( ) , null ) ; readRev = database . getDbInternal ( ) . getLocalDocument ( revD . getDocId ( ) , null ) ;", "del_tokens": "CBLRevisionInternal readRev = database . getLocalDocument ( rev1 . getDocId ( ) , null ) ; readRev = database . getLocalDocument ( rev2 . getDocId ( ) , null ) ; readRev = database . getLocalDocument ( revD . getDocId ( ) , null ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "for", "LIVETRIBE", "-", "65", ":", "Attributes", "tags", "now", "support", "globbing", "."], "add_tokens": "byte [ ] tagsBytes = tagsToBytes ( getTags ( ) ) ; setTags ( Attributes . fromTags ( readString ( bytes , offset , tagsLength , false ) ) ) ;", "del_tokens": "byte [ ] tagsBytes = attributesToBytes ( getTags ( ) ) ; setTags ( Attributes . from ( readString ( bytes , offset , tagsLength , false ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "crash", "rendering", "unordered", "lists"], "add_tokens": "if ( flagsStr != null ) { int flags = Integer . parseInt ( flagsStr ) ; isOrderedList = ( flags & Element . F_LIST_ORDERED ) != 0 ; if ( isOrderedList ) { mOrderedListNumber . put ( element , 1 ) ; }", "del_tokens": "int flags = Integer . parseInt ( flagsStr ) ; isOrderedList = ( flags & Element . F_LIST_ORDERED ) != 0 ; if ( isOrderedList ) { mOrderedListNumber . put ( element , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "unneccessary", "(", "for", "Java", "6", ")", "@SuppressWarnings", "annotations", "."], "add_tokens": "public static < T > T firstNotNull ( T ... args ) {", "del_tokens": "public static < T > T firstNotNull ( @ SuppressWarnings ( \"unchecked\" ) T ... args ) {", "commit_type": "remove"}
{"commit_tokens": ["Adding", "initial", "ReadyState", "and", "few", "tests"], "add_tokens": "private ReadyState readyState = ReadyState . CLOSED ; / * * * The @ { ReadyState } for the underlying connection * / public ReadyState getReadyState ( ) { return readyState ; } readyState = ReadyState . CONNECTING ; readyState = ReadyState . CLOSED ; readyState = ReadyState . CLOSING ; readyState = ReadyState . OPEN ; readyState = ReadyState . CLOSED ; readyState = ReadyState . CLOSED ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["adding", "corporated", "user", "edit", "history"], "add_tokens": "import com . bullhornsdk . data . model . entity . core . type . EditHistoryEntity ; public class CorporateUser extends CustomFieldsA implements QueryEntity , AssociationEntity , EditHistoryEntity {", "del_tokens": "public class CorporateUser extends CustomFieldsA implements QueryEntity , AssociationEntity {", "commit_type": "add"}
{"commit_tokens": ["fix", "bad", "usage", "of", "install", ".", "packages", "(", "...", "dependencies", "=", "TRUE", ")"], "add_tokens": "eval ( \"install.packages('\" + pack . getName ( ) + \"',repos=NULL\" ) ; eval ( \"install.packages('\" + pack_files [ 0 ] . getName ( ) + \"',repos=NULL)\" , TRY_MODE ) ; eval ( \"install.packages('\" + pack + \"',repos='\" + repos + \"')\" , TRY_MODE ) ;", "del_tokens": "eval ( \"install.packages('\" + pack . getName ( ) + \"',repos=NULL,\" + /*(RserveConf.RLibPath == null ? \"\" : \"lib=\" + RserveConf.RLibPath + \",\") +*/ \"dependencies=TRUE)\" ) ; eval ( \"install.packages('\" + pack_files [ 0 ] . getName ( ) + \"',repos=NULL,\" + /*(RserveConf.RLibPath == null ? \"\" : \"lib=\" + RserveConf.RLibPath + \",\") +*/ \"dependencies=TRUE)\" , TRY_MODE ) ; eval ( \"install.packages('\" + pack + \"',repos='\" + repos + \"',\" + /*(RserveConf.RLibPath == null ? \"\" : \"lib=\" + RserveConf.RLibPath + \",\") +*/ \"dependencies=TRUE)\" , TRY_MODE ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "MPH", "API", "to", "reflect", "changes", "in", "SEER", "*", "API", "."], "add_tokens": "import retrofit2 . http . Query ; import com . imsweb . seerapi . client . mph . MphInput . MpHistologyMatchMode ; / * * * Uses multiple primary rules to compare two diseases using strict histology matching mode * @ param pair a pair of diseases * @ return a result indicating whether the two diseases are the same primary * / @ POST ( \"mph\" ) Call < MphOutput > mph ( @ Body MphInputPair pair ) ; * @ param matchMode Call < MphOutput > mph ( @ Body MphInputPair pair , @ Query ( \"histology-matching-mode\" ) MpHistologyMatchMode matchMode ) ;", "del_tokens": "Call < MphResult > mph ( @ Body MphInputPair pair ) ;", "commit_type": "update"}
{"commit_tokens": ["improve", "Beans", ".", "class", "repeated", "code", "integration"], "add_tokens": "val . setBoolean ( true ) ; private boolean isBoolean = false ; public boolean isBoolean ( ) { return isBoolean ; } public void setBoolean ( boolean isBoolean ) { this . isBoolean = isBoolean ; } @ Override if ( isBoolean != that . isBoolean ) return false ; result += ( isBoolean ? 2 : 0 ) ; \", isBoolean=\" + isBoolean +", "del_tokens": "@ Override", "commit_type": "improve"}
{"commit_tokens": ["Added", "ProjectType", "enforcement", "rule", "to", "the", "build", "reactor", "for", "all", "poms", ".", "Corrected", "nazgul_tool", "poms", "as", "a", "result", "."], "add_tokens": "/ * * * Aspect definition project , holding publicly available aspects . * / ASPECT ( \".*-aspect$\" , \".*\\\\.aspect$\" , \"bundle\" ) , * @ throws IllegalArgumentException if the given project could not be mapped to a [ single ] ProjectType . * The exception message holds", "del_tokens": "* @ throws IllegalArgumentException if a single ProjectType could not be * matched to the provided MavenProject .", "commit_type": "add"}
{"commit_tokens": ["Remove", "reference", "to", "unused", "class"], "add_tokens": "public void sink ( Spans input ) {", "del_tokens": "import org . apache . thrift . TException ; public void sink ( Spans input ) throws TException {", "commit_type": "remove"}
{"commit_tokens": ["fix", "empty", "conjunction", "internal", "state", "so", "compareTo", "works"], "add_tokens": "import java . util . Collections ; * * * this ( Collections . EMPTY_SET ) ; * @ Override Class < ? extends Conjunction > thisClass = this . getClass ( ) ; Class < ? extends Concept > otherClass = o . getClass ( ) ; // Otherwise order depends on the length and then on the order of // Need to catch this because elements in the conjunction", "del_tokens": "* * * * Class thisClass = this . getClass ( ) ; Class otherClass = o . getClass ( ) ; // Otherwise order depends on the length and then on the order of // Need to catch this because elements in the conjunction", "commit_type": "fix"}
{"commit_tokens": ["Updating", "the", "Conversation", "And", "Expression", "Assets", "(", "and", "tests", ")", "to", "reflect", "the", "new", "domain", "model"], "add_tokens": "import com . versionone . om . * ; import java . util . ArrayList ; import java . util . List ; * Filter for getting Expression . public class ExpressionFilter extends EntityFilter { return Expression . class ; public List < Conversation > belongsTo = newList ( ) ; //public List<Expression> expressionsInConversation = newList(); public List < Expression > inReplyTo = newList ( ) ; public List < Expression > replies = newList ( ) ; builder . relation ( \"BelongsTo\" , belongsTo ) ; //builder.multiRelation(\"ExpressionsInConversation\", expressionsInConversation);", "del_tokens": "import java . util . ArrayList ; import java . util . List ; import com . versionone . om . BaseAsset ; import com . versionone . om . Conversation ; import com . versionone . om . Entity ; import com . versionone . om . Member ; * Filter for getting Expression / Conversation . public class ConversationFilter extends EntityFilter { return Conversation . class ; public List < Conversation > conversation = newList ( ) ; public List < Conversation > expressionsInConversation = newList ( ) ; public List < Conversation > inReplyTo = newList ( ) ; public List < Conversation > replies = newList ( ) ; builder . relation ( \"Conversation\" , conversation ) ; builder . multiRelation ( \"ExpressionsInConversation\" , expressionsInConversation ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "command", "exec", "description", "grammar"], "add_tokens": "* < li > No two methods , of the same name , can have the same number of parameters . Make multiple methods with more specific names if they * must have the same number of parameters . < / li > if ( Modifier . isPublic ( m . getModifiers ( ) ) ) {", "del_tokens": "* < li > No two methods , of the same name , can have the same number of parameters . Make multiple methods with more specific names more * specific if they must have the same number of parameters . < / li > if ( Modifier . isPublic ( m . getModifiers ( ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "search", "for", "an", "equal", "min", "hash"], "add_tokens": "final CriteriaBuilder . In < Integer > in = criteriaBuilder . in ( topicRoot . < Integer > get ( \"topicId\" ) ) ; final CriteriaBuilder . In < Integer > inSubQuery = criteriaBuilder . in ( topicRoot . < Integer > get ( \"topicId\" ) ) ;", "del_tokens": "final CriteriaBuilder . In < Integer > in = criteriaBuilder . in ( topicRoot . < Integer > get ( \"topic\" ) . < Integer > get ( \"topicId\" ) ) ; final CriteriaBuilder . In < Integer > inSubQuery = criteriaBuilder . in ( topicRoot . < Integer > get ( \"topic\" ) . < Integer > get ( \"topicId\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "Android", "fix", "."], "add_tokens": "import static com . esotericsoftware . minlog . Log . * ; while ( buffer . hasRemaining ( ) ) { if ( bufferPositionFix ) { buffer . compact ( ) ; buffer . flip ( ) ; } }", "del_tokens": "import static com . esotericsoftware . minlog . Log . * ; import java . nio . IntBuffer ; import com . esotericsoftware . kryo . util . Util ; if ( bufferPositionFix ) { buffer . compact ( ) ; buffer . flip ( ) ; } while ( buffer . hasRemaining ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "imports", "for", "Test", "annotation"], "add_tokens": "import org . junit . Test ; @ Test ( expected = MacroExecutionException . class ) @ Test", "del_tokens": "@ org . junit . Test ( expected = MacroExecutionException . class ) @ org . junit . Test", "commit_type": "use"}
{"commit_tokens": ["Added", "getters", "and", "setters", "for", "match", "rules"], "add_tokens": "public void addMatchRule ( MatchRule newRule ) { / * * * Remove match rule from the scan * / public void removeMatchRule ( int index ) { rules . remove ( index ) ; } / * * * Get an existing match rule of the scan . * * If no match rule exists at the specified index , this method returns null . * / public MatchRule getMatchRule ( int index ) { if ( index < rules . size ( ) ) { return rules . get ( index ) ; } return null ; }", "del_tokens": "protected void addMatchRule ( MatchRule newRule ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "class", "AbstractItem", "."], "add_tokens": "public class Divider extends AbstractItem { super ( source ) ; * * @ param id * The divider 's id as an {@link Integer} value public Divider ( final int id ) { super ( id ) ; Divider clonedDivider = new Divider ( getId ( ) ) ; clonedDivider . setTitle ( getTitle ( ) ) ; return \"Divider [id=\" + getId ( ) + \", title=\" + getTitle ( ) + \"]\" ; int result = super . hashCode ( ) ; if ( ! super . equals ( obj ) ) super . writeToParcel ( dest , flags ) ;", "del_tokens": "import android . os . Parcelable ; import java . io . Serializable ; public class Divider implements Serializable , Cloneable , Parcelable { public Divider ( ) { Divider clonedDivider = new Divider ( ) ; clonedDivider . setTitle ( title ) ; return \"Divider [title=\" + title + \"]\" ; int result = 1 ; if ( obj == null ) @ Override public final int describeContents ( ) { return 0 ; }", "commit_type": "add"}
{"commit_tokens": ["make", "classic", "-", "graph", "use", "double", "for", "the", "weight", "property", "."], "add_tokens": "TinkerpopTest . class", "del_tokens": "TestSchema . class", "commit_type": "make"}
{"commit_tokens": ["Make", "BoxFolder", "class", "not", "final"], "add_tokens": "public class BoxFolder extends BoxItem implements Iterable < BoxItem . Info > {", "del_tokens": "public final class BoxFolder extends BoxItem implements Iterable < BoxItem . Info > {", "commit_type": "make"}
{"commit_tokens": ["Use", "name", "parameter", "for", "@ConditionalOnClass", "for", "spring", "integration", "metrics"], "add_tokens": "@ ConditionalOnClass ( name = \"org.springframework.integration.config.EnableIntegrationManagement\" )", "del_tokens": "@ ConditionalOnClass ( EnableIntegrationManagement . class )", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "test", "case", "for", "UNLV", "zone", "file"], "add_tokens": "/ * * * Test of doOCR method , of class Tesseract . * * @ throws java . lang . Exception * / @ Test public void testDoOCR_UNLV_Zone_File ( ) throws Exception { System . out . println ( \"doOCR on a PNG image with UNLV zone file .uzn\" ) ; //UNLV zone format: left top width height label String filename = String . format ( \"%s/%s\" , this . testResourcesDataPath , \"eurotext_unlv.png\" ) ; File imageFile = new File ( filename ) ; String expResult = \"& duck/goose, as 12.5% of E-mail\\n\\n\" + \"from aspammer@website.com is spam.\\n\\n\" + \"The (quick) [brown] {fox} jumps!\\n\" + \"Over the $43,456.78 <lazy> #90 dog\" ; String result = instance . doOCR ( imageFile ) ; System . out . println ( result ) ; assertEquals ( expResult , result . trim ( ) ) ; } System . out . println ( \"doOCR on a buffered image of a PNG\" ) ; File imageFile = new File ( this . testResourcesDataPath , \"eurotext.png\" ) ;", "del_tokens": "System . out . println ( \"doOCR on a buffered image of a GIF\" ) ; File imageFile = new File ( this . testResourcesDataPath , \"eurotext.gif\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "sane", "defaults", "for", "the", "info", "collector"], "add_tokens": "import nebula . plugin . metrics . MetricsLoggerFactory ; import nebula . plugin . metrics . model . * ; import org . slf4j . Logger ; import java . util . Map ; private final Logger logger = MetricsLoggerFactory . getLogger ( GradleInfoCollector . class ) ; // TODO Implement Map < String , String > manifest = plugin . buildManifest ( ) ; return new GenericSCM ( ) ; // TODO Complete implementation Map < String , String > manifest = plugin . buildManifest ( ) ; return new GenericCI ( ) ;", "del_tokens": "import nebula . plugin . metrics . model . CI ; import nebula . plugin . metrics . model . SCM ; return null ; return null ;", "commit_type": "add"}
{"commit_tokens": ["made", "the", "necessary", "changes", "for", "the", "new", "izou", "-", "version"], "add_tokens": "@ Override public boolean addDescriptor ( String descriptor ) { return descriptors . add ( descriptor ) ; } @ Override public boolean removeDescriptor ( String s ) { return descriptors . remove ( s ) ; @ Override public EventModel < Event > finalizeEvent ( ) { return new Event ( type , source , Collections . unmodifiableList ( new ArrayList < > ( descriptors ) ) ) ; }", "del_tokens": "/ * * * sets the Descriptors ( but not the Event - Type ) . * @ param descriptor a String describing the Event . * @ return the resulting Event ( which is the same instance ) * / public Event addDescriptor ( String descriptor ) { List < String > newDescriptors = new ArrayList < > ( ) ; newDescriptors . addAll ( descriptors ) ; newDescriptors . add ( descriptor ) ; return new Event ( getType ( ) , getSource ( ) , newDescriptors ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "reference", "field", "recording", "."], "add_tokens": "String desc = accessedField . desc ; if ( desc . startsWith ( \"L\" ) || desc . startsWith ( \"[\" ) ) { desc = VariableType . REFERENCE . signature ; } super . visitMethodInsn ( Opcodes . INVOKESTATIC , \"hu/advancedweb/scott/runtime/track/LocalVariableStateRegistry\" , \"trackFieldState\" , \"(\" + desc + \"Ljava/lang/String;IZLjava/lang/String;)V\" , false ) ; }", "del_tokens": "super . visitMethodInsn ( Opcodes . INVOKESTATIC , \"hu/advancedweb/scott/runtime/track/LocalVariableStateRegistry\" , \"trackFieldState\" , \"(\" + accessedField . desc + \"Ljava/lang/String;IZLjava/lang/String;)V\" , false ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "constructor", "to", "force", "the", "cursor", "value", "in", "the", "last", "page", "of", "results"], "add_tokens": "public static < J > CursorList < J > create ( SimpleQuery query , int size ) { return create ( query , size , false ) ; } * @ param forceCursor if true , the cursor will be not null even on the last page of results . Useful to check for new contents after the last page has been retrieved . public static < J > CursorList < J > create ( SimpleQuery query , int size , boolean cursorOnLastPage ) { if ( it . hasNext ( ) || cursorOnLastPage ) {", "del_tokens": "public static < J > CursorList < J > create ( SimpleQuery query , int size ) { if ( it . hasNext ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["Moves", "the", "call", "to", "generate", "the", "checksum", "of", "the", "content", "ID", "into", "a", "synchronized", "method", "to", "avoid", "memory", "consistency", "errors", "."], "add_tokens": "import java . io . File ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Date ; import java . util . Iterator ; import java . util . List ; import java . util . Map ; item . setContentIdHash ( getIdChecksum ( contentId ) ) ; // Allows use of the non-thread-safe ChecksumUtil in a threaded environment private synchronized String getIdChecksum ( String contentId ) { return checksumUtil . generateChecksum ( contentId ) ; }", "del_tokens": "import java . io . File ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Date ; import java . util . Iterator ; import java . util . List ; import java . util . Map ; import org . duracloud . error . ContentStoreException ; item . setContentIdHash ( checksumUtil . generateChecksum ( contentId ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "some", "tests", "for", "FileBackup"], "add_tokens": "if ( backupDir . mkdir ( ) ) { LOG . info ( \"Created backupDir: dir={}\" , backupDir ) ; } if ( ! backupDir . isDirectory ( ) || ! backupDir . canRead ( ) || ! backupDir . canWrite ( ) ) { throw new IllegalArgumentException ( \"backupDir[\" + backupDir + \"] needs to be a readable & writable directory\" ) ; }", "del_tokens": "if ( backupDir . mkdir ( ) ) { LOG . info ( \"Created backupDir: dir={}\" , backupDir ) ; }", "commit_type": "add"}
{"commit_tokens": ["Implement", "equals", "and", "hashCode", "for", "FlywayPreparer"], "add_tokens": "import java . util . Arrays ; import java . util . List ; import java . util . Objects ; private final List < String > locations ; return new FlywayPreparer ( f , Arrays . asList ( locations ) ) ; private FlywayPreparer ( Flyway flyway , List < String > locations ) { this . locations = locations ; @ Override public boolean equals ( Object obj ) { if ( ! ( obj instanceof FlywayPreparer ) ) { return false ; } return Objects . equals ( locations , ( ( FlywayPreparer ) obj ) . locations ) ; } @ Override public int hashCode ( ) { return Objects . hashCode ( locations ) ; }", "del_tokens": "return new FlywayPreparer ( f ) ; private FlywayPreparer ( Flyway flyway ) {", "commit_type": "implement"}
{"commit_tokens": ["Added", "TypePrefixes", "enum", "to", "list", "possible", "Types", "from", "the", "Reddit", "API", "."], "add_tokens": "import com . reddit . dev . api . jreddit . message . Message ;", "del_tokens": "import im . goel . jreddit . message . Message ;", "commit_type": "add"}
{"commit_tokens": ["Made", "sure", "both", "small", "and", "large", "files", "are", "tested"], "add_tokens": "List < PartETag > eTags = Lists . newArrayList ( ) ; request . setInputStream ( new ByteArrayInputStream ( buffer , 0 , bytesRead ) ) ;", "del_tokens": "List < PartETag > eTags = Lists . newArrayList ( ) ; request . setInputStream ( new ByteArrayInputStream ( buffer ) ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "701", "by", "reset", "UPHOST", "when", "mkblk", "returned"], "add_tokens": "Config . UP_HOST = ret . getHost ( ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Fix", "log", "messages", "in", "MessageExchange"], "add_tokens": "MessageExchange . LOGGER . info ( \"Notified of message {} in state {} from {}.\" , msg , status , source ) ; MessageExchange . LOGGER . debug ( \"Not waiting for message {} in state {} from {}.\" , msg , status , source ) ; MessageExchange . LOGGER . debug ( \"Accepted message {} in state {} from {}.\" , msg , status , source ) ; MessageExchange . LOGGER . warn ( \"Failed to notify Follower of message {} in state {} from {}.\" , msg , status , source , e ) ;", "del_tokens": "MessageExchange . LOGGER . info ( \"Follower {} notified of message {} in state {}.\" , this , msg , status ) ; MessageExchange . LOGGER . debug ( \"Follower {} not waiting for message {} in state {}.\" , this , msg , status ) ; MessageExchange . LOGGER . debug ( \"Follower {} accepted message {} in state {}.\" , this , msg , status ) ; MessageExchange . LOGGER . warn ( \"Notifying follower {} of message {} in state {} failed.\" , this , msg , status , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "a", "flag", "for", "selection", "status", "instead", "of", "relying", "on", "the", "UI", "of", "the"], "add_tokens": "import com . google . gwt . event . dom . client . ClickEvent ; import com . google . gwt . event . dom . client . ClickHandler ; private boolean isSelected ; label . addDomHandler ( new ClickHandler ( ) { @ Override public void onClick ( ClickEvent arg0 ) { isSelected = ! isSelected ; } } , ClickEvent . getType ( ) ) ; } ; return isSelected ; isSelected = value ;", "del_tokens": "} String style = label . getStyleName ( ) ; if ( style == null ) return false ; if ( style . contains ( \"ui-btn-down\" ) ) { return ! style . contains ( \"ui-checkbox-on\" ) ; } else { return style . contains ( \"ui-checkbox-on\" ) ; }", "commit_type": "use"}
{"commit_tokens": ["Fixing", "the", "resource", "util", "adding", "unit", "test"], "add_tokens": "return clazz . getClassLoader ( ) . getResourceAsStream ( resourceName ) ;", "del_tokens": "return clazz . getResourceAsStream ( resourceName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "connection", "validation"], "add_tokens": "if ( ! info . getClientId ( ) . equals ( newConnection ) ) { IllegalStateException exception = new IllegalStateException ( \"Neither offset nor exception!?\" ) ; log . error ( \"Error on segment: \" + segment , exception ) ; throw exception ;", "del_tokens": "if ( ! info . getClientId ( ) . equals ( connectionId ) ) { throw new IllegalStateException ( \"Neither offset nor exception!?\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "a", "test", "for", "DB", "output", "data", "provider", "(", "not", "implemented", ")", "."], "add_tokens": "} else if ( DataProvider . type . DB . toString ( ) . equals ( dataOut ) ) { // TODO DBDataProvider not implemented for outputDataProvider logger . error ( \"plugDataProvider: \" + e ) ;", "del_tokens": "logger . error ( e ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "to", "only", "reset", "restsession", "in", "the", "event", "that", "a", "401", "is", "returned", ".", "also", "crudresponses", "for", "failure", "calls", "are", "now", "returned", "properly", "instead", "of", "an", "error", "being", "thrown", "over", "the", "catch"], "add_tokens": "import org . springframework . http . * ; handleApiError ( tryNumber , e ) ; handleApiError ( tryNumber , e ) ; } catch ( RuntimeException e ) { handleApiError ( tryNumber , e ) ; if ( error . getStatusCode ( ) == HttpStatus . UNAUTHORIZED ) { resetBhRestToken ( uriVariables ) ; } private void handleApiError ( int tryNumber , Exception e ) {", "del_tokens": "import org . springframework . http . HttpEntity ; import org . springframework . http . HttpHeaders ; import org . springframework . http . HttpMethod ; import org . springframework . http . MediaType ; import org . springframework . http . ResponseEntity ; handleApiError ( uriVariables , tryNumber , e ) ; handleApiError ( uriVariables , tryNumber , e ) ; } catch ( Exception e ) { handleApiError ( uriVariables , tryNumber , e ) ; resetBhRestToken ( uriVariables ) ; private void handleApiError ( Map < String , String > uriVariables , int tryNumber , Exception e ) { resetBhRestToken ( uriVariables ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "SAM", "record", "and", "VCF", "variant", "context", "converters", "."], "add_tokens": "/ * * * Check the specified value is not null . * * @ param value value , must not be null * / protected final void checkNotNull ( final Object value ) { if ( value == null ) { throw new NullPointerException ( \"value must not be null\" ) ; } } * @ param converter converter , must not be null", "del_tokens": "* @ param converter converter , must not b null", "commit_type": "add"}
{"commit_tokens": ["Removed", "reading", "STDIN", "from", "ExampleDecoder", "=", ">", "messages", ".", "txt", "not", "needed", "anymore"], "add_tokens": "if ( ret != null && receiver != null && ret . distanceTo ( receiver ) > 600000 ) {", "del_tokens": "if ( ret != null && ret . distanceTo ( receiver ) > 600000 ) {", "commit_type": "remove"}
{"commit_tokens": ["Use", "constant", "instead", "of", "magic", "string"], "add_tokens": "public static final String HEADER_BEARER = \"Bearer\" ; . addHeader ( HEADER_NAME , HEADER_BEARER + \" \" + token )", "del_tokens": ". addHeader ( HEADER_NAME , \"Bearer \" + token )", "commit_type": "use"}
{"commit_tokens": ["Improve", "behavior", "when", "connections", "are", "errornous", ".", "Add", "JMX", "counter", "for", "that", "and", "invalidate", "connections", "if", "they", "have", "errors"], "add_tokens": "import java . io . IOException ; invalidate ( ) ; / * * * Invalidates this keyspace and client associated with it . * This method should be used when the keyspace had errors . * It returns the client to the pool and marks it as invalid ( essentially taking taking the client * out of the pool indefinitely ) and removed the keyspace from the client . * / private void invalidate ( ) { try { clientPools . invalidateClient ( client ) ; client . removeKeyspace ( this ) ; } catch ( Exception e ) { log . error ( \"Unable to invalidate client {}. Will continue anyhow.\" , client ) ; } } invalidate ( ) ; invalidate ( ) ; invalidate ( ) ; } catch ( IOException e ) { invalidate ( ) ; monitor . incCounter ( op . failCounter ) ; throw new UnavailableException ( ) ;", "del_tokens": "try { clientPools . invalidateClient ( client ) ; client . removeKeyspace ( this ) ; } catch ( Exception e ) { log . error ( \"Unable to invalidate client {}. Will continue anyhow.\" , client ) ; }", "commit_type": "improve"}
{"commit_tokens": ["added", "targetPackage", "configuration", "property", "to", "plugin"], "add_tokens": "/ * * * Package name used for generated Java classes . * * @ parameter * / private String targetPackage = \"\" ; * @ required * @ readonly Generate . generate ( sourceDirectory , targetPackage , outputDirectory ) ;", "del_tokens": "* @ required Generate . generate ( sourceDirectory , \"\" , outputDirectory ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "progress", "monitor", "methods", "from", "Visitable", "to", "Object"], "add_tokens": "CreateTraversingVisitorProgressMonitorInterface ( Outline outline , getOutput ( ) . method ( JMod . NONE , void . class , \"visited\" ) . param ( Object . class , \"aVisitable\" ) ; getOutput ( ) . method ( JMod . NONE , void . class , \"traversed\" ) . param ( Object . class , \"aVisitable\" ) ;", "del_tokens": "import com . sun . codemodel . JDefinedClass ; private final JDefinedClass visitable ; CreateTraversingVisitorProgressMonitorInterface ( JDefinedClass visitable , Outline outline , this . visitable = visitable ; getOutput ( ) . method ( JMod . NONE , void . class , \"visited\" ) . param ( visitable , \"aVisitable\" ) ; getOutput ( ) . method ( JMod . NONE , void . class , \"traversed\" ) . param ( visitable , \"aVisitable\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Moved", "webhooks", "implementation", "to", "separate", "package", "."], "add_tokens": "package com . constantcontact . webhooks . helper ;", "del_tokens": "package com . constantcontact . util ;", "commit_type": "move"}
{"commit_tokens": ["Add", "toString", "()", "method", "for", "Session", "s", "implementations"], "add_tokens": "* @ author Ronen Hamias , Anton Kharenko enum State {", "del_tokens": "* @ author Ronen Hamias public enum State {", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "retain", "raw", "request", "payload"], "add_tokens": "", "del_tokens": "private boolean retainPayload ; private byte [ ] rawPayload ; / * * * { @ inheritDoc } * * @ see jcifs . util . transport . Response # retainPayload ( ) * / @ Override public void retainPayload ( ) { this . retainPayload = true ; } / * * * { @ inheritDoc } * * @ see jcifs . util . transport . Response # isRetainPayload ( ) * / @ Override public boolean isRetainPayload ( ) { return this . retainPayload ; } / * * * { @ inheritDoc } * * @ see jcifs . util . transport . Response # getRawPayload ( ) * / @ Override public byte [ ] getRawPayload ( ) { return this . rawPayload ; } / * * * @ param rawPayload * the rawPayload to set * / @ Override public void setRawPayload ( byte [ ] rawPayload ) { this . rawPayload = rawPayload ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "parameter", "to", "control", "logging", "."], "add_tokens": "/ * * * By default , access log logging is turned off * / public static final String DEFAULT_LOGGING_ENABLED = \"false\" ; DEFAULT_SUPPORTS_CREDENTIALS , DEFAULT_PREFLIGHT_MAXAGE , DEFAULT_LOGGING_ENABLED ) ; this . loggingEnabled = false ; String loggingEnabled = filterConfig . getInitParameter ( PARAM_CORS_LOGGING_ENABLED ) ; exposedHeaders , supportsCredentials , preflightMaxAge , loggingEnabled ) ; * @ param loggingEnabled * Flag to control logging to access log . final String preflightMaxAge , final String loggingEnabled ) throws ServletException { if ( loggingEnabled != null ) { // For any value other then 'true' this will be false. boolean isLoggingEnabled = Boolean . parseBoolean ( loggingEnabled ) ; this . loggingEnabled = isLoggingEnabled ; }", "del_tokens": "DEFAULT_SUPPORTS_CREDENTIALS , DEFAULT_PREFLIGHT_MAXAGE ) ; this . loggingEnabled = true ; exposedHeaders , supportsCredentials , preflightMaxAge ) ; final String preflightMaxAge ) throws ServletException {", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "instrumented", "Jetty", "connectors", "."], "add_tokens": "import com . yammer . metrics . jetty . InstrumentedBlockingChannelConnector ; import com . yammer . metrics . jetty . InstrumentedSelectChannelConnector ; import com . yammer . metrics . jetty . InstrumentedSocketConnector ; final AbstractConnector connector = createConnector ( config . getPort ( ) ) ; private AbstractConnector createConnector ( int port ) { connector = new InstrumentedBlockingChannelConnector ( port ) ; connector = new InstrumentedSocketConnector ( port ) ; connector = new InstrumentedSelectChannelConnector ( port ) ;", "del_tokens": "import org . eclipse . jetty . server . nio . BlockingChannelConnector ; final AbstractConnector connector = createConnector ( ) ; private AbstractConnector createConnector ( ) { connector = new BlockingChannelConnector ( ) ; connector = new SocketConnector ( ) ; connector = new SelectChannelConnector ( ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "Result", "status", "default", "to", "200"], "add_tokens": "protected Result ( ) { status = Http . Status . OK ; }", "del_tokens": "protected Result ( ) { status = null ; }", "commit_type": "make"}
{"commit_tokens": ["move", "cache", "test", "to", "appropriate", "package"], "add_tokens": "package com . wizzardo . tools . cache ;", "del_tokens": "package com . wizzardo . tools ; import com . wizzardo . tools . cache . Cache ; import com . wizzardo . tools . cache . Computable ; import com . wizzardo . tools . cache . MemoryLimitedCache ; import com . wizzardo . tools . cache . SizeLimitedCache ;", "commit_type": "move"}
{"commit_tokens": ["fix", "Aggregate", "query", "as", "of", "attribute", "value", "setting"], "add_tokens": "public List applyOperationToFullCache ( EqualityOperation equalityOperation ) { CachedQuery cachedQuery = op . getResultObjectPortal ( ) . zFindInMemory ( getCombinedOp ( ) , null ) ; if ( cachedQuery != null ) { List joinedList = cachedQuery . getResult ( ) ; return mapper . map ( joinedList , equalityOperation ) ; } return null ; } return this . and ( MultiEqualityOperation . createEqOperation ( asOfEqOperations ) ) ;", "del_tokens": "return new MappedOperation ( mapper . insertAsOfOperationOnLeft ( asOfEqOperations ) , this . op ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "UI", "where", "newly", "-", "added", "repositories", "weren", "t", "deletable", "or", "addable", "to", "groups", "without", "reloading", "the", "content", ".", "Also", "fixing", "column", "headers", "for", "options", "to", "deploy", "points"], "add_tokens": "initKey ( ) ; { initKey ( ) ; return key ; } private void initKey ( )", "del_tokens": "return key ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "some", "warnings", "and", "restructuring"], "add_tokens": "item . add ( new BookmarkablePageLink < ComponentInfoPage > ( \"componentLink\" , ComponentInfoPage . class , params ) . add ( new Label ( \"name\" ) ) ) ;", "del_tokens": "item . add ( new BookmarkablePageLink ( \"componentLink\" , ComponentInfoPage . class , params ) . add ( new Label ( \"name\" ) ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "forced", "password", "change", "(", "in", "model", ")", "and", "non", "expiring", "password", "(", "in", "model", ")"], "add_tokens": "return createManagedUser ( username , null , null , passwordHash , false , false , false ) ; * @ param forcePasswordChange Whether or not user needs to change password on next login or not * @ param nonExpiryPassword Whether or not the users password ever expires or not final String passwordHash , final boolean suspended , final boolean forcePasswordChange , final boolean nonExpiryPassword ) { user . setForcePasswordChange ( forcePasswordChange ) ; user . setNonExpiryPassword ( nonExpiryPassword ) ;", "del_tokens": "return createManagedUser ( username , null , null , passwordHash , false ) ; final String passwordHash , final boolean suspended ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "@NonNull", "annotation", "for", "Loggi"], "add_tokens": "@ NonNull private final Loggi loggi = new Loggi ( ) ;", "del_tokens": "private final Loggi loggi = new Loggi ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "handling", "of", "List", "of", "Parcel"], "add_tokens": "List < SubParcel > parcelList ; public ConverterTarget ( byte b , Byte bobj , double d , Double dobj , float f , Float fobj , int i , Integer iobj , long l , Long lobj , byte [ ] bya , char [ ] ca , boolean [ ] ba , int [ ] ia , long [ ] la , float [ ] fa , double [ ] da , String [ ] sa , String s , List < String > list , Map < String , String > map , List < SubParcel > parcelList ) { this . parcelList = parcelList ; public List < SubParcel > getParcelList ( ) { return parcelList ; }", "del_tokens": "public ConverterTarget ( byte b , Byte bobj , double d , Double dobj , float f , Float fobj , int i , Integer iobj , long l , Long lobj , byte [ ] bya , char [ ] ca , boolean [ ] ba , int [ ] ia , long [ ] la , float [ ] fa , double [ ] da , String [ ] sa , String s , List list , Map < String , String > map ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "adding", "notes", "to", "elements", "as", "comments", "."], "add_tokens": "/** Options used for commenting nodes */ private static Options commentOptions ; public static Options getCommentOptions ( ) { return commentOptions ; } * Creates the base Options object . * This contains both the options specified on the command * Also create the globally accessible commentOptions object . commentOptions = new Options ( ) ; commentOptions . setOptions ( root . options ( ) ) ; commentOptions . setOptions ( findClass ( root , \"UMLCommentOptions\" ) ) ; commentOptions . shape = \"note\" ; opt . setOptions ( findClass ( root , \"UMLOptions\" ) ) ; /** Return the ClassDoc for the specified class; null if not found. */ private static ClassDoc findClass ( RootDoc root , String name ) { if ( cd . name ( ) . equals ( name ) )", "del_tokens": "* Creates the base Options object , that contains both the options specified on the command opt . setOptions ( findUMLOptions ( root ) ) ; private static ClassDoc findUMLOptions ( RootDoc root ) { if ( cd . name ( ) . equals ( \"UMLOptions\" ) )", "commit_type": "add"}
{"commit_tokens": ["fixing", "error", "prone", "build", "error", "#norelease"], "add_tokens": "if ( periodInfo . getEquipment ( ) != null && periodInfo . getEquipment ( ) . size ( ) > 0 ) {", "del_tokens": "if ( periodInfo . getEquipment ( ) != null && periodInfo . getEquipment ( ) != null && periodInfo . getEquipment ( ) . size ( ) > 0 ) { if ( periodInfo . getEquipment ( ) != null ) { }", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "BufferUnderflowException", "by", "assuming", "the", "CR", "and", "LF", "are", "available", "at"], "add_tokens": "public class ClientTest extends ClientBaseCase {", "del_tokens": "import junit . framework . TestCase ; public class ClientTest extends TestCase { MemcachedClient client = null ; private void initClient ( ) throws Exception { client = new MemcachedClient ( new InetSocketAddress ( \"127.0.0.1\" , 11211 ) ) ; } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; initClient ( ) ; } @ Override protected void tearDown ( ) throws Exception { // Shut down, start up, flush, and shut down again. Error tests have // unpredictable timing issues. client . shutdown ( ) ; client = null ; initClient ( ) ; assertTrue ( client . flush ( ) . get ( ) ) ; client . shutdown ( ) ; client = null ; super . tearDown ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "the", "issue", "16"], "add_tokens": "}", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["add", "type", "filter", "and", "refactor", "type", "package"], "add_tokens": "package com . freetmp . common . type . classreading ; import com . freetmp . common . type . AnnotationMetadata ; import com . freetmp . common . type . ClassMetadata ;", "del_tokens": "package com . freetmp . common . type ;", "commit_type": "add"}
{"commit_tokens": ["added", "any", "attribute", "and", "ordering", "to", "name", "entity", "layer"], "add_tokens": "public interface NamedEntity extends AnyAtrributes {", "del_tokens": "public interface NamedEntity {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "that", "could", "cause", "an", "NPE", "exception", "."], "add_tokens": "final byte [ ] contents = readFileContentsAsByteArray ( file ) ; return new String ( contents , \"UTF-8\" ) ;", "del_tokens": "return new String ( readFileContentsAsByteArray ( file ) , \"UTF-8\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "(", "but", "required", ")", "user", "registration", "property", "."], "add_tokens": "/** The date the user accepted WePay's TOS. Must be a unix_timestamp. Required. */ private String tosAcceptanceTime ; }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["added", "heapifyUpdatableSketch", "()", "method", "and", "tests"], "add_tokens": "Sketch < DoubleSummary > sketch2 = Sketches . heapifySketch ( new NativeMemory ( sketch1 . toByteArray ( ) ) ) ; Sketch < DoubleSummary > sketch2 = Sketches . heapifySketch ( new NativeMemory ( sketch1 . toByteArray ( ) ) ) ; @ Test ( expectedExceptions = RuntimeException . class ) public void deserializeWrongType ( ) { UpdatableSketch < Double , DoubleSummary > us = new UpdatableSketchBuilder < Double , DoubleSummary > ( new DoubleSummaryFactory ( ) ) . build ( ) ; for ( int i = 0 ; i < 8192 ; i ++ ) us . update ( i , 1.0 ) ; CompactSketch < DoubleSummary > sketch1 = us . compact ( ) ; @ SuppressWarnings ( \"unused\" ) UpdatableSketch < Double , DoubleSummary > sketch2 = Sketches . heapifyUpdatableSketch ( new NativeMemory ( sketch1 . toByteArray ( ) ) ) ; }", "del_tokens": "CompactSketch < DoubleSummary > sketch2 = new CompactSketch < DoubleSummary > ( new NativeMemory ( sketch1 . toByteArray ( ) ) ) ; CompactSketch < DoubleSummary > sketch2 = new CompactSketch < DoubleSummary > ( new NativeMemory ( sketch1 . toByteArray ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "default", "phase", "to", "verify", "and", "goal", "to", "report"], "add_tokens": "* @ phase verify", "del_tokens": "* @ phase test", "commit_type": "change"}
{"commit_tokens": ["Added", "test", "cases", "for", "access", "to", "elements", "of", "multi", "dimensional", "arrays", "."], "add_tokens": "int value = ints [ 0 ] [ 0 ] ;", "del_tokens": "for ( int i = 0 ; i < 1024 ; i ++ ) { ints [ i ] [ 0 ] = 1 ; }", "commit_type": "add"}
{"commit_tokens": ["Removed", "older", "doc", "fixed", "components", "path"], "add_tokens": "variables . put ( \"components-path\" , PathUtils . buildPath ( contextPath , webResourcesPath , \"bower_components\" ) ) ;", "del_tokens": "variables . put ( \"components-path\" , PathUtils . buildPath ( contextPath , webResourcesPath ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "non", "-", "volatile", "storage", "of", "the", "radio", "config"], "add_tokens": "import static nl . littlerobots . bean . internal . Protocol . MSG_ID_BT_SET_CONFIG_NOSAVE ; * This is equivalent to calling { @ link # setRadioConfig ( nl . littlerobots . bean . message . RadioConfig , boolean ) } with true for the * save parameter . * setRadioConfig ( config , true ) ; } / * * * Set the { @ link nl . littlerobots . bean . message . RadioConfig } * * @ param config the configuration to set * @ param save true to save the config in non - volatile storage , false otherwise . * / public void setRadioConfig ( RadioConfig config , boolean save ) { sendMessage ( save ? MSG_ID_BT_SET_CONFIG : MSG_ID_BT_SET_CONFIG_NOSAVE , config ) ;", "del_tokens": "sendMessage ( MSG_ID_BT_SET_CONFIG , config ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "a", "few", "exceptions", "to", "the", "new", "com", ".", "aoindustries", ".", "exception", "package", ":"], "add_tokens": "import com . aoindustries . exception . WrappedException ;", "del_tokens": "import com . aoindustries . util . WrappedException ;", "commit_type": "move"}
{"commit_tokens": ["Updated", "webp", "to", "capture", "failed", "process"], "add_tokens": "super ( \"Image parsing failed due to: \" + errors ) ;", "del_tokens": "super ( errors . get ( 0 ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Make", "URL", "InputFiles", "download", "to", "the", "system", "temporary", "directory", "."], "add_tokens": "tmpDirectory = new File ( System . getProperty ( \"java.io.tmpdir\" ) , \"jtelegrambot-\" + System . currentTimeMillis ( ) ) ; tmpDirectory . mkdirs ( ) ;", "del_tokens": "try { File jarDir = new File ( FileManager . class . getProtectionDomain ( ) . getCodeSource ( ) . getLocation ( ) . toURI ( ) . getPath ( ) ) ; tmpDirectory = new File ( jarDir , \"tmp\" ) ; tmpDirectory . mkdirs ( ) ; File [ ] contents = tmpDirectory . listFiles ( ) ; if ( contents != null ) { Arrays . stream ( contents ) . forEach ( FileUtils :: deleteQuietly ) ; } } catch ( URISyntaxException ignored ) { }", "commit_type": "make"}
{"commit_tokens": ["Changed", "the", "name", "of", "the", "module", "to", "Library"], "add_tokens": "/ * * Copyright ( c ) 2015. DineshPrasanth * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / import android . content . Context ; import android . graphics . Color ; private Context mContext ; private float mSize ; private Color mColor ; public ImageGenerator ( Context context ) { mContext = context ; } public void setFont ( float size ) { mSize = size ; } public void setmColor ( Color color ) { mColor = color ; }", "del_tokens": "/ * * * Created by DineshPrasanth on 06 - 01 - 2015. * /", "commit_type": "change"}
{"commit_tokens": ["Made", "other", "plugins", "respect", "ImmutablePlugin", ":", "Do", "not", "generate", "setter", "in", "interfaces", "etc", "."], "add_tokens": "public CollectionChangeEvent ( final Collection < E > source , final String methodName , final CollectionChangeEventType eventType , final Collection < E > oldItems , final Collection < ? extends E > newItems , final int index ) { return this . source ; return this . methodName ; return this . eventType ; return this . oldItems ; return this . newItems ; return this . index ;", "del_tokens": "public CollectionChangeEvent ( Collection < E > source , String methodName , CollectionChangeEventType eventType , Collection < E > oldItems , Collection < ? extends E > newItems , int index ) { return source ; return methodName ; return eventType ; return oldItems ; return newItems ; return index ;", "commit_type": "make"}
{"commit_tokens": ["Add", "thread", "to", "allocation", "log"], "add_tokens": "allocatorLog . printf ( \"timestamp,threadid,duration,size,physfree,totalswap,freeswap,committed%n\" ) ; allocatorLog . printf ( \"%d,%d,%d,%d,%d,%d,%d,%d%n\" , System . nanoTime ( ) - start , Thread . currentThread ( ) . getId ( ) , blockDuration , currentAllocation , PhysicalMemory . freePhysicalMemory ( ) , PhysicalMemory . totalSwapSpace ( ) , PhysicalMemory . freeSwapSpace ( ) , PhysicalMemory . ourCommittedVirtualMemory ( ) ) ;", "del_tokens": "allocatorLog . printf ( \"timestamp,duration,size,physfree,totalswap,freeswap,committed%n\" ) ; allocatorLog . printf ( \"%d,%d,%d,%d,%d,%d,%d%n\" , System . nanoTime ( ) - start , blockDuration , currentAllocation , PhysicalMemory . freePhysicalMemory ( ) , PhysicalMemory . totalSwapSpace ( ) , PhysicalMemory . freeSwapSpace ( ) , PhysicalMemory . ourCommittedVirtualMemory ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "package", ".", "html", "files", "for", "more", "packages", "."], "add_tokens": "TCP", "del_tokens": "TCP , MINA", "commit_type": "add"}
{"commit_tokens": ["Fix", "javadoc", "-", "errors", "and", "adjust", "javadoc", "somewhat"], "add_tokens": "* < / pre > * < / pre >", "del_tokens": "* < pre > * < pre >", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "the", "attach", "command", "."], "add_tokens": "import com . squareup . okhttp . ws . WebSocket ; import java . io . OutputStream ; public void open ( String protocol , WebSocket socket ) { }", "del_tokens": "public void open ( String protocol , Closeable close ) { }", "commit_type": "add"}
{"commit_tokens": ["Remove", "unnecessary", "implementation", "of", "joining", "()", "method"], "add_tokens": "return joining ( \"\" ) ; public static Collector < CharSequence , ? , String > joining ( final CharSequence delimiter , final CharSequence prefix , final CharSequence suffix , final String emptyValue ) {", "del_tokens": "return new Collector < CharSequence , StringBuilder , String > ( ) { @ Override public Supplier < StringBuilder > supplier ( ) { return new Supplier < StringBuilder > ( ) { @ Override public StringBuilder get ( ) { return new StringBuilder ( ) ; } } ; } @ Override public BiConsumer < StringBuilder , CharSequence > accumulator ( ) { return new BiConsumer < StringBuilder , CharSequence > ( ) { @ Override public void accept ( StringBuilder t , CharSequence u ) { t . append ( u ) ; } } ; } @ Override public Function < StringBuilder , String > finisher ( ) { return new Function < StringBuilder , String > ( ) { @ Override public String apply ( StringBuilder value ) { return value . toString ( ) ; } } ; } } ; public static Collector < CharSequence , ? , String > joining ( final CharSequence delimiter , final CharSequence prefix , final CharSequence suffix , final String emptyValue ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "for", "broken", "Twitter", "search", "when", "authenticated", "."], "add_tokens": "String adjustedUrl = adjustUrl ( url . toString ( ) ) ; OAuthRequest request = new OAuthRequest ( Verb . valueOf ( method . name ( ) ) , adjustedUrl ) ; Token token = new Token ( accessToken , accessTokenSecret ) ; service . signRequest ( token , request ) ; return request . getHeaders ( ) . get ( \"Authorization\" ) ; } private String adjustUrl ( String url ) { // Scribe assumes that the URL is not yet encoded, but the request // factory gives us a pre-encoded URL. So, decode it before giving // it to Scribe. // The hash sign (#), however, causes trouble in a URL because it // looks like a URL fragment marker. Leave it encoded. decodedUrl = decodedUrl . replace ( \"#\" , \"%23\" ) ; return decodedUrl ;", "del_tokens": "// Need to decode the URL given because Scribe is assuming that it // isn't UTF-8 encoded yet and will re-encode it. OAuthRequest request = new OAuthRequest ( Verb . valueOf ( method . name ( ) ) , decodedUrl ) ; Token token = new Token ( accessToken , accessTokenSecret ) ; service . signRequest ( token , request ) ; return request . getHeaders ( ) . get ( \"Authorization\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "exception", "when", "using", "jawr", ".", "css", ".", "image", ".", "classpath", ".", "use", ".", "servlet"], "add_tokens": "* Copyright 2007 - 2011 Jordi Hern nd ez S lls , M a t Rub , Ib r him Cha hoi * @ author Jordi Hern nd ez S lls * Determines the filename of a path .", "del_tokens": "* Copyright 2007 - 2011 Jordi Hernndez Sells , Matt Ruby , Ibrahim Chaehoi * @ author Jordi Hernndez Sells * Determines the parent path of a filename or a directory .", "commit_type": "add"}
{"commit_tokens": ["Make", "CancellationToken", ".", "State", "Private"], "add_tokens": "private static class State {", "del_tokens": "public static class State {", "commit_type": "make"}
{"commit_tokens": ["Added", "MongoDBOccurrenceStore", "for", "big", "corpus"], "add_tokens": "public static enum Type { MEMORY , FILE , MONGODB }", "del_tokens": "public static enum Type { MEMORY , FILE }", "commit_type": "add"}
{"commit_tokens": ["Add", "dynamic", "TTL", "to", "authorization", "request"], "add_tokens": "* @ deprecated in favor of { @ link # createAuthorizationRequest ( String , String , AuthPolicy , String , Integer ) } * @ deprecated in favor of { @ link # createAuthorizationRequest ( String , String ) } * @ deprecated in favor of { @ link # createAuthorizationRequest ( String ) } * @ param ttl Time for this authorization request to be valid . If no value is provided , the system default will be used . AuthorizationRequest createAuthorizationRequest ( String userIdentifier , String context , AuthPolicy policy , String title , Integer ttl )", "del_tokens": "AuthorizationRequest createAuthorizationRequest ( String userIdentifier , String context , AuthPolicy policy , String title ) * @ deprecated in favor of # cre @ Deprecated", "commit_type": "add"}
{"commit_tokens": ["Made", "Bounds", "public", "added", "exception", "checks", "for", "input", "args", "and", "test", "."], "add_tokens": "return Bounds . getUpperBound ( curCount , theta , numStdDev , empty ) ; return Bounds . getLowerBound ( curCount , theta , numStdDev , empty ) ;", "del_tokens": "return Bounds . approxLBforUsers ( curCount , theta , numStdDev , empty ) ; return Bounds . approxUBforUsers ( curCount , theta , numStdDev , empty ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "available", "space", "computation", "bug"], "add_tokens": "import tachyon . thrift . PartitionAlreadyExistException ; throws PartitionDoesNotExistException , SuspectedPartitionSizeException , PartitionAlreadyExistException , TException { if ( dstFile . exists ( ) ) { throw new PartitionAlreadyExistException ( \"Partition \" + datasetId + \"-\" + partitionId + \" already exists.\" ) ; }", "del_tokens": "throws PartitionDoesNotExistException , SuspectedPartitionSizeException , TException {", "commit_type": "fix"}
{"commit_tokens": ["add", "native", "support", "info", "to", "apkmeta"], "add_tokens": "public static final String LIB_PREFIX = \"lib/\" ; public static final String ARCH_ARMEABI = \"\" ; * the system style resource ids .", "del_tokens": "public static final String LIB_PreFIX = \"lib/\" ; * the system style resouce ids .", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "composition", "schedules", "can", "be", "used", "again", "for", "cancelled", "jobs"], "add_tokens": "private Integer initialExecutionsCount ; this . initialExecutionsCount = null ; if ( initialExecutionsCount == null ) { initialExecutionsCount = executionsCount ; } if ( initialExecutionsCount >= executionsCount ) { hasNotBeenExecuted = false ;", "del_tokens": "if ( hasNotBeenExecuted ) { hasNotBeenExecuted = false ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "configuration", "bug", "in", "DefaultImportationLinker"], "add_tokens": "* Get the filters ImporterServiceFilter and ImportDeclarationFilter from the properties , stop the instance if one of public void processProperties ( ) { } / * * * Called by iPOJO when the configuration of the DefaultImportationLinker is updated . * < p / > * Call # processProperties ( ) to get the updated filters ImporterServiceFilter and ImportDeclarationFilter . * Compute and apply the changes in the links relatives to the changes in the filters . * / @ Updated public void updated ( ) { processProperties ( ) ; processProperties ( ) ;", "del_tokens": "* Called by iPOJO when the configuration of the DefaultImportationLinker is updated . * < p / > * Get the filter ImporterServiceFilter and ImportDeclarationFilter from the properties , stop the instance if one of * Compute and apply the changes in the links relatives to the changes in the filters . @ Updated public void updated ( ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "sample", "upgrade", "libs", "allow", "plugin", "updates", "in", "samples", "better", "task", "integration", "."], "add_tokens": "import dart . henson . plugin . internal . GenerateHensonNavigatorTask ; public GenerateHensonNavigatorTask createHensonNavigatorGenerationTask ( BaseVariant variant ) { GenerateHensonNavigatorTask generateHensonNavigatorTask = taskManager . createHensonNavigatorGenerationTask ( variant , hensonNavigatorPackageName , destinationFolder ) ; return generateHensonNavigatorTask ;", "del_tokens": "public void createHensonNavigatorGenerationTask ( BaseVariant variant ) { taskManager . createHensonNavigatorGenerationTask ( variant , hensonNavigatorPackageName , destinationFolder ) ; variant . addJavaSourceFoldersToModel ( destinationFolder ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "small", "indentation", "issue"], "add_tokens": ". setApplicationName ( CLIENT_APPLICATION_NAME )", "del_tokens": ". setApplicationName ( CLIENT_APPLICATION_NAME )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "the", "smartsheet", "auto", "number", "column", "in", "DATETIME", "format"], "add_tokens": "* @ param id the id of the sheet * @ param id the id of the sheet * @ param id the id of the sheet", "del_tokens": "* @ param id the id * @ param id the id * @ param id the id", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "reference", "an", "unnamed", "Task", "or", "Phrase", "by", "class", "name", "(", "w", "/", "o", "a", "custom", "grammar", ")", "."], "add_tokens": "try { Class c = Class . forName ( name ) ; Bootstrappable b = ( Bootstrappable ) c . newInstance ( ) ; EntryType y = null ; if ( b instanceof Phrase ) { y = EntryType . PHRASE ; } else if ( b instanceof Task ) { y = EntryType . TASK ; } else { String msg = \"The specified class is neither a Phrase nor a Task: \" + name ; throw new RuntimeException ( msg ) ; } rslt = new Entry ( name , y , null , b . getFormula ( ) , new HashMap < Reagent , Object > ( ) , new LinkedList < Node > ( ) ) ; } catch ( ClassNotFoundException cnfe ) { String msg = \"The specified entry name does not match a known entry or an available class: \" + name ; throw new IllegalArgumentException ( msg ) ; } catch ( Throwable t ) { String msg = \"Error preparing the specified entry: \" + name ; throw new RuntimeException ( msg ) ; }", "del_tokens": "String msg = \"The specified entry is not defined: \" + name ; throw new IllegalArgumentException ( msg ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "test", "to", "extract", "values", "from", "the", "Persistence", "Unit", "instead", "of", "hard", "coded", "."], "add_tokens": "import java . util . Map ; Map < String , Object > properties = DataBaseManager . getEntityManagerFactory ( ) . getProperties ( ) ; ( ( JdbcDataSource ) ds ) . setPassword ( ( String ) properties . get ( \"javax.persistence.jdbc.password\" ) ) ; ( ( JdbcDataSource ) ds ) . setUser ( ( String ) properties . get ( \"javax.persistence.jdbc.user\" ) ) ; ( ( JdbcDataSource ) ds ) . setURL ( ( String ) properties . get ( \"javax.persistence.jdbc.url\" ) ) ;", "del_tokens": "( ( JdbcDataSource ) ds ) . setPassword ( \"\" ) ; ( ( JdbcDataSource ) ds ) . setUser ( \"vm_user\" ) ; ( ( JdbcDataSource ) ds ) . setURL ( \"jdbc:h2:file:data/test/validation-manager-test;AUTO_SERVER=TRUE\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "an", "addNearestNeighbours", "()", "method", "to", "the", "views", "."], "add_tokens": "public abstract void addNearestNeighbours ( Element element ) ; protected void addNearestNeighbours ( Element element , ElementType type ) { if ( element == null ) { return ; } addElement ( element ) ; Set < Relationship > relationships = getModel ( ) . getRelationships ( ) ; relationships . stream ( ) . filter ( r -> r . getSource ( ) . equals ( element ) && r . getDestination ( ) . isType ( type ) ) . map ( Relationship :: getDestination ) . forEach ( this :: addElement ) ; relationships . stream ( ) . filter ( r -> r . getDestination ( ) . equals ( element ) && r . getSource ( ) . isType ( type ) ) . map ( Relationship :: getSource ) . forEach ( this :: addElement ) ; } private void addRelationships ( ) {", "del_tokens": "public void addRelationships ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "task", "annotations", "to", "fix", "deprecation", "warnings"], "add_tokens": "import org . gradle . api . tasks . Console ; import org . gradle . api . tasks . Input ; import org . gradle . api . tasks . Internal ; import org . gradle . api . tasks . Optional ; @ Input @ Internal // see #getOutputFiles() @ Console @ Input @ Input @ Input @ Input @ Input @ Optional @ Input @ Optional @ Input @ Optional @ Input @ Optional @ Input @ Input @ Input @ Input @ Internal @ Input @ Input @ Optional @ Internal", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "dynamic", "suggestion", "height", "support"], "add_tokens": "return mColor . getName ( ) ;", "del_tokens": "return mColor . getName ( ) + \"fssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "validation", "to", "ensure", "people", "don", "t", "annotate", "generic", "classes", "with", "@DataParcel"], "add_tokens": "TypeMirror elementTypeMirror = element . asType ( ) ; // Ensure the root element isn't parameterized if ( elementTypeMirror instanceof DeclaredType ) { DeclaredType declaredType = ( DeclaredType ) elementTypeMirror ; List < ? extends TypeMirror > typeArguments = declaredType . getTypeArguments ( ) ; if ( typeArguments != null && typeArguments . size ( ) > 0 ) { error ( \"@DataParcel cannot be used directly on generic data classes.\" , element ) ; continue ; } } createParcel ( elementTypeMirror ) ;", "del_tokens": "TypeElement el = ( TypeElement ) element ; createParcel ( el . asType ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "disabled", "property", "and", "some", "related", "logic", "to", "menuitem", ".", "Other", "menu", "types", "will", "be", "discussed", "."], "add_tokens": "if ( menuItem . isDisabled ( ) ) if ( menuItem . getStyleClass ( ) != null ) menuItem . setStyleClass ( menuItem . getStyleClass ( ) + \" ui-state-disabled\" ) ; else menuItem . setStyleClass ( \"ui-state-disabled\" ) ; if ( menuItem . getOnclick ( ) != null && ! menuItem . isDisabled ( ) ) writer . writeAttribute ( \"onclick\" , menuItem . getOnclick ( ) , null ) ; if ( ! menuItem . isDisabled ( ) ) writer . writeAttribute ( \"onclick\" , command , null ) ;", "del_tokens": "if ( menuItem . getOnclick ( ) != null ) writer . writeAttribute ( \"onclick\" , menuItem . getOnclick ( ) , null ) ; writer . writeAttribute ( \"onclick\" , command , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "more", "tests", "improving", "javadocs", "."], "add_tokens": "", "del_tokens": "import java . util . List ; private int times = 0 ; double avg = 0 ; for ( double d : john . getScores ( ) ) { avg += d ; } final double finalavg = avg / john . getScores ( ) . size ( ) ; private Double average = finalavg ; @ JsonIgnore private List < Double > scores ; @ JsonProperty private int invocations = ++ times ;", "commit_type": "add"}
{"commit_tokens": ["Make", "Stream", ".", "single", "()", "method", "more", "strict", "and", "require", "the", "single", "element", "in", "stream"], "add_tokens": "* Returns the single element of stream . * If stream is empty , throws { @ code NoSuchElementException } . * @ return single element of stream * @ throws NoSuchElementException if stream is empty * @ throws IllegalStateException if stream contains more than one element . public T single ( ) { return singleCandidate ; throw new NoSuchElementException ( \"Stream contains no element\" ) ;", "del_tokens": "* Returns the single element wrapped by { @ code Optional } class . * If stream is empty , returns { @ code Optional . empty ( ) } . * @ return an { @ code Optional } with single element , { @ code Optional . empty ( ) } if stream is empty * or throw { @ code IllegalStateException } if stream contains more than one element . public Optional < T > single ( ) { return Optional . of ( singleCandidate ) ; return Optional . empty ( ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "b", ":", "tabView", "and", "b", ":", "tab"], "add_tokens": "public static final String SELECT_BOOLEAN_CHECKBOX_COMPONENT_TYPE = BSFCOMPONENT + \".SelectBooleanCheckbox\" ; public static final String TAB_COMPONENT_TYPE = BSFCOMPONENT + \".Tab\" ; public static final String TAB_VIEW_COMPONENT_TYPE = BSFCOMPONENT + \".TabView\" ;", "del_tokens": "public static final String SELECT_BOOLEAN_CHECKBOX_COMPONENT_TYPE = BSFCOMPONENT + \".SelectBooleanCheckbox\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "search", "parameters", "to", "url", "builder"], "add_tokens": "public Builder limit ( int limit ) { assert ( limit > 0 ) ; return parameter ( \"limit\" , String . valueOf ( limit ) ) ; } public Builder offset ( int offset ) { assert ( offset >= 0 ) ; return parameter ( \"offset\" , String . valueOf ( offset ) ) ; } public Builder type ( String type ) { assert ( type != null ) ; return parameter ( \"type\" , type ) ; }", "del_tokens": "StringBuilder stringBuilder = new StringBuilder ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "a", "bit", "of", "javadoc"], "add_tokens": "* The Izou context is a means for all addOns to get general information they might need . Every addOn its own context * and can use it to reach certain Izou components . It controls what an addOn has access to and what it does not have * access to . * < br > * For instance , the addOn should have access to a logger ( created in Izou for the addOn ) , but it should not have * access to classes like the AddOnManager , which loads all addOns at the start . Hence the logger is included in the * context , but the addOn manager is not . Anything that is not included in the context , and addOn does not have access to . * So in short , the context exists to give addOns access to higher Izou components while still denying access to other * components .", "del_tokens": "* @ author Leander Kurscheidt * @ version 1.0", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "File", "Entities", "and", "a", "couple", "of", "minor", "helper", "methods", "to", "other", "entities", "."], "add_tokens": "import org . hibernate . validator . constraints . NotBlank ; @ NotNull ( message = \"languageimage.locale.notBlank\" ) @ NotBlank ( message = \"languageimage.locale.notBlank\" )", "del_tokens": "@ NotNull", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "for", "correct", "URI", "when", "parsing", "href", "attributes", "."], "add_tokens": "if ( ! XLINK_NAMESPACE . equals ( attributes . getURI ( i ) ) ) break ;", "del_tokens": "/**/ Log . d ( TAG , \"skipCommaWhitespace: pos=\" + position ) ; /**/ Log . d ( TAG , \"@@@ parseLength: \" + val . substring ( 0 , end ) ) ; /**/ Log . d ( TAG , \"@@@ parseStrokeDashArray: dash=\" + dash ) ; /**/ Log . d ( TAG , \"@@@ parseStrokeDashArray: dash=\" + dash ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "a", "length", "error", "in", "the", "relation", "basis", "mapping"], "add_tokens": "// path. String relation = path . getRelation ( path . length ( ) - 1 ) ;", "del_tokens": "// path. The last relation is the length - 2, due to length - 1 being // the last node index and there are one-fewer relations than nodes. String relation = path . getRelation ( path . length ( ) - 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "trailing", "whitespace", "children", "improved"], "add_tokens": "private void removeTrailingWhitespaces ( ElementBox block ) if ( ! subbox . isBlock ( ) && subbox . collapsesSpaces ( ) ) { if ( subbox . isWhitespace ( ) ) it . remove ( ) ; else if ( subbox instanceof ElementBox ) removeTrailingWhitespaces ( ( ElementBox ) subbox ) ; }", "del_tokens": "private void removeTrailingWhitespaces ( BlockBox block ) if ( ! subbox . isBlock ( ) && subbox . collapsesSpaces ( ) && subbox . isWhitespace ( ) ) it . remove ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Made", "executeScript", "with", "parameters", "public"], "add_tokens": "public PowerShellResponse executeScript ( String scriptPath , String params ) {", "del_tokens": "private PowerShellResponse executeScript ( String scriptPath , String params ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "length", "()", "and", "extract", "()", "functions", "for", "space", "delimited", "parameter", "list", "."], "add_tokens": "Expression ex0 = get ( 0 ) . unpack ( formatter ) ; if ( ex0 . getClass ( ) == Operation . class ) { List < Expression > operants = ( ( Operation ) ex0 ) . getOperands ( ) ; if ( operants . size ( ) == 1 ) { Expression ex0_0 = operants . get ( 0 ) ; if ( ex0_0 . getClass ( ) == Operation . class && ( ( Operation ) ex0_0 ) . getOperator ( ) == ' ' ) { return ( ( Operation ) ex0_0 ) . getOperands ( ) ; } return operants ;", "del_tokens": "Expression ex0 = get ( 0 ) ; if ( ex0 . getClass ( ) == VariableExpression . class ) { ex0 = ( ( VariableExpression ) ex0 ) . getValue ( formatter ) ; if ( ex0 . getClass ( ) == Operation . class ) { return ( ( Operation ) ex0 ) . getOperands ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "erroneous", "tracking", "of", "QoS", "1", "messages", "in", "a", "datastructure", "for", "QoS", "0", "messages", "-", "resulting", "in", "QoS", "1", "message", "onSuccess", "being", "fired", "early", "(", "and", "potentially", "masking", "failure", "of", "QoS", "1", "delivery", ")"], "add_tokens": "if ( sr . qos == QOS . AT_MOST_ONCE ) { engineConnection . addInflightQos0 ( delta , new SendResponse ( sr , null ) , sr . getSender ( ) , this ) ; }", "del_tokens": "engineConnection . addInflightQos0 ( delta , new SendResponse ( sr , null ) , sr . getSender ( ) , this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "setter", "for", "RetryUtil", "in", "scheduler", "builder"], "add_tokens": "public static final int DEFAULT_RETRY_MAX_EXPONENT = 4 ; public Builder setRetryUtil ( RetryUtil retryUtil ) { this . retryUtil = retryUtil ; return this ; }", "del_tokens": "public static final int DEFAULT_RETRY_MAX_EXPONENT = 6 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "New", "features", "BlurKit", "fuzzy", "image"], "add_tokens": "package net . qiujuer . sample ; / * * * Created by QiuJu * on 2014 / 11 / 25. * *  * / }", "del_tokens": "ckage n t.q i ujuer.s a mple; }", "commit_type": "add"}
{"commit_tokens": ["added", "dependency", "to", "use", "assertReflectionEquals"], "add_tokens": "final MessageReference messageReference = new MessageReference ( ) ; messageReference . setHREF ( \"ANY_HREF\" ) ; messageReference . setTotalCount ( 30 ) ; contact . setMessages ( messageReference ) ;", "del_tokens": "final MessageReference messageReferance = new MessageReference ( ) ; messageReferance . setHREF ( \"ANY_HREF\" ) ; messageReferance . setTotalCount ( 30 ) ; contact . setMessages ( messageReferance ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "consistent", "naming", "convention", "for", "enums"], "add_tokens": "KS , CF , ROW , STATUS , TIMESTAMP , HOST ;", "del_tokens": "ks , cf , row , status , timestamp , host ;", "commit_type": "use"}
{"commit_tokens": ["Added", "test", "of", "JRebel", "reloading"], "add_tokens": "* To register , bind ClassMetadataReloader as an eager singleton . public void setPersistenceMetadataRepository ( PersistenceMetadataRepository persistenceMetadataRepository ) { this . persistenceMetadataRepository = persistenceMetadataRepository ; reloaderFactory . addClassReloadListener ( this ) ;", "del_tokens": "* To register , invoke ClassMetadataReloader . register ( ) once on application deployment . private ClassMetadataReloader ( ) { } public static final void register ( ) { reloaderFactory . addClassReloadListener ( new ClassMetadataReloader ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "up", "unpack", "locking", "."], "add_tokens": "import java . security . NoSuchAlgorithmException ; } finally { Preconditions . checkState ( unpackLockFile . delete ( ) , \"could not remove lock file %s\" , unpackLockFile . getAbsolutePath ( ) ) ; } else { int maxAttempts = 60 ; while ( ! pgDirExists . exists ( ) && -- maxAttempts > 0 ) { Preconditions . checkState ( pgDirExists . exists ( ) , \"Waited 60 seconds for postgres to be unpacked but it never finished!\" ) ; } catch ( final IOException | NoSuchAlgorithmException e ) { } catch ( final InterruptedException ie ) { Thread . currentThread ( ) . interrupt ( ) ; throw new ExceptionInInitializerError ( ie ) ;", "del_tokens": "finally { unpackLockFile . delete ( ) ; } } else { while ( ! pgDirExists . exists ( ) ) { } catch ( final Exception e ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "non", "-", "0", "port", "check", "to", "test"], "add_tokens": "import static org . junit . Assert . assertNotEquals ; import org . springframework . boot . test . WebIntegrationTest ; @ WebIntegrationTest ( value = \"spring.application.name=myTestService\" , randomPort = true ) assertNotEquals ( \"service port is 0\" , 0 , service . getPort ( ) . intValue ( ) ) ; assertEquals ( \"service id was wrong\" , context . getId ( ) , service . getId ( ) ) ; assertEquals ( \"service name was wrong\" , \"myTestService\" , service . getService ( ) ) ;", "del_tokens": "import org . springframework . boot . test . IntegrationTest ; import org . springframework . test . context . web . WebAppConfiguration ; @ IntegrationTest ( { \"server.port=0\" , \"spring.application.name=myTestService\" } ) @ WebAppConfiguration assertEquals ( \"service id was wrong\" , service . getId ( ) , context . getId ( ) ) ; assertEquals ( \"service name was wrong\" , service . getService ( ) , \"myTestService\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "in", "crud", "with", "directstore", "when", "root", "is", "not", "records", "."], "add_tokens": "String recordsKey = null ; for ( Map . Entry < String , Object > entry : jsonData . entrySet ( ) ) { if ( entry . getValue ( ) instanceof ArrayList ) { recordsKey = entry . getKey ( ) ; break ; if ( recordsKey != null ) { ArrayList < Object > records = ( ArrayList < Object > ) jsonData . get ( recordsKey ) ; directStoreModifyRecords = convertObjectEntriesToType ( records , directStoreEntryClass ) ; jsonParamIndex = 1 ; remainingParameters = new HashMap < String , Object > ( jsonData ) ; remainingParameters . remove ( recordsKey ) ; }", "del_tokens": "ArrayList < Object > records = ( ArrayList < Object > ) jsonData . get ( \"records\" ) ; directStoreModifyRecords = convertObjectEntriesToType ( records , directStoreEntryClass ) ; jsonParamIndex = 1 ; remainingParameters = new HashMap < String , Object > ( ) ; for ( Entry < String , Object > entry : jsonData . entrySet ( ) ) { if ( ! \"records\" . equals ( entry . getKey ( ) ) ) { remainingParameters . put ( entry . getKey ( ) , entry . getValue ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "tags", "to", "instagram", "item"], "add_tokens": "tags = new String [ tagSize ] ; tags [ tIndex ++ ] = tag ;", "del_tokens": "String [ ] tempTags = new String [ tagSize ] ; tempTags [ tIndex ++ ] = tag ;", "commit_type": "add"}
{"commit_tokens": ["added", "new", "method", "to", "query", "subscription", "sku", "details"], "add_tokens": "public void queryInventory ( final String [ ] itemSkus ) { _helper . queryInventoryAsync ( true , Arrays . asList ( itemSkus ) , _queryInventoryListener ) ; } } ) ; } public void queryInventory ( final String [ ] itemSkus , final String [ ] subsSkus ) { UnityPlayer . currentActivity . runOnUiThread ( new Runnable ( ) { @ Override public void run ( ) { _helper . queryInventoryAsync ( true , Arrays . asList ( itemSkus ) , Arrays . asList ( subsSkus ) , _queryInventoryListener ) ;", "del_tokens": "public void queryInventoryAndSkuDetails ( final String [ ] skus ) { Log . i ( TAG , \"***** queryInventory - SKU list length: \" + skus . length ) ; _helper . queryInventoryAsync ( true , Arrays . asList ( skus ) , _queryInventoryListener ) ; // TODO: implement public void consumeProducts ( String [ ] sku ) { }", "commit_type": "add"}
{"commit_tokens": ["use", "a", "nice", "queen", "image"], "add_tokens": "import javax . swing . ImageIcon ; import javax . swing . SwingConstants ; private static final String QUEEN_IMAGE_PATH = \"/org/drools/solver/examples/nqueens/swingui/queenImage.png\" ; private ImageIcon queenImageIcon ; queenImageIcon = new ImageIcon ( getClass ( ) . getResource ( QUEEN_IMAGE_PATH ) ) ; JButton button = new JButton ( new QueenAction ( queen ) ) ; button . setHorizontalTextPosition ( SwingConstants . CENTER ) ; button . setVerticalTextPosition ( SwingConstants . BOTTOM ) ; add ( button ) ; super ( \"[\" + queen . getId ( ) + \"]\" , queenImageIcon ) ;", "del_tokens": "add ( new JButton ( new QueenAction ( queen ) ) ) ; super ( \"[\" + queen . getId ( ) + \"]\" ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "special", "integer", "type", "handling"], "add_tokens": "if ( ( dtrDatatype . getBuiltInType ( ) == BuiltInType . INTEGER || dtrDatatype . getBuiltInType ( ) == BuiltInType . UNSIGNED_INTEGER )", "del_tokens": "if ( dtrDatatype . getBuiltInType ( ) == BuiltInType . INTEGER", "commit_type": "fix"}
{"commit_tokens": ["Fix", "packager", "issue", "in", "reactor", "mode", "."], "add_tokens": "File classes = new File ( mojo . basedir , \"target/classes\" ) ;", "del_tokens": "File classes = new File ( \"target/classes\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "stats", "command", "more", "real"], "add_tokens": "if ( keylen == 0 ) { return null ; } else { return new String ( bodyBuffer . array ( ) , extlen , keylen ) ; }", "del_tokens": "return new String ( bodyBuffer . array ( ) , extlen , keylen ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "the", "initial", "value", "of", "Tx", "Generator", "so", "there", "are", "is", "no", "clash", "between", "different", "commands", "sent"], "add_tokens": "private static int GEN = 1000 ;", "del_tokens": "private static int GEN = 1 ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "up", "documentation", "and", "reduce", "visibility", "of", "an", "API", "."], "add_tokens": "ProtoFile readProtoFile ( ) {", "del_tokens": "public ProtoFile readProtoFile ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "bugs", "in", "GerpPhase", "."], "add_tokens": "gerpMeta = new GerpMetaWrapper ( toClassNames ( ( String ) confs . get ( \"generators\" ) ) , toClassNames ( ( String ) confs . get ( \"evidencers\" ) ) , toClassNames ( ( String ) confs . get ( \"rankers\" ) ) , toClassNames ( ( String ) confs . get ( \"pruners\" ) ) ) ; // TODO Since the vbar in the descritpor should be removed and replaced with the YAML list // syntax, the returned value should be String array (String[]) private static List < String > toClassNames ( String options ) { for ( String option : options . split ( \"\\\\n+\" ) ) { throw new AnalysisEngineProcessException ( e ) ;", "del_tokens": "gerpMeta = new GerpMetaWrapper ( toClassNames ( ( String [ ] ) confs . get ( \"generators\" ) ) , toClassNames ( ( String [ ] ) confs . get ( \"evidencers\" ) ) , toClassNames ( ( String [ ] ) confs . get ( \"rankers\" ) ) , toClassNames ( ( String [ ] ) confs . get ( \"pruners\" ) ) ) ; private static List < String > toClassNames ( String [ ] options ) { for ( String option : options ) { throw new AnalysisEngineProcessException ( e ) ; } finally {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "additional", "Message", "http", "headers"], "add_tokens": "import java . util . Date ; import javax . ws . rs . core . MediaType ; . type ( message . getContentType ( ) ) String brokerProperties = clientResult . getHeaders ( ) . getFirst ( \"BrokerProperties\" ) ; String location = clientResult . getHeaders ( ) . getFirst ( \"Location\" ) ; MediaType contentType = clientResult . getType ( ) ; Date date = clientResult . getResponseDate ( ) ; if ( brokerProperties != null ) { result . setProperties ( mapper . fromString ( brokerProperties ) ) ; } if ( contentType != null ) { result . setContentType ( clientResult . toString ( ) ) ; } if ( location != null ) { result . getProperties ( ) . setLockLocation ( location ) ; } result . setDate ( date ) ;", "del_tokens": "// REVIEW: contentType will be needed // REVIEW: harden this - it's much too brittle. throws null exceptions very easily result . setProperties ( mapper . fromString ( clientResult . getHeaders ( ) . getFirst ( \"BrokerProperties\" ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "quotes", "from", "STRING", "and", "VALUESET", "when", "parsing", "make", "trackable", "use", "1", "-", "based", "char", "index", "add", "test", "for", "CMS146", "parsing"], "add_tokens": "dataCriteriaByHash . put ( sourceDataCriteria . hashCode ( ) , sourceDataCriteria ) ; existing = sourceDataCriteria ; valueSetsByHash . put ( valueSet . hashCode ( ) , valueSet ) ; existing = valueSet ;", "del_tokens": "existing = dataCriteriaByHash . put ( sourceDataCriteria . hashCode ( ) , sourceDataCriteria ) ; existing = valueSetsByHash . put ( valueSet . hashCode ( ) , valueSet ) ;", "commit_type": "remove"}
{"commit_tokens": ["use", "consistent", "syntax", "in", "logging", "statements"], "add_tokens": ": \"(\" + serialize ( arguments ) + \")\" ) + \"' -> '\" + serialize ( replTokens ) + \"'\" ,", "del_tokens": ": \"(\" + serialize ( arguments ) + \")\" ) + \"' --> '\" + serialize ( replTokens ) + \"'\" ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "missing", "trailing", "/", "in", "resource", "paths"], "add_tokens": ". addResourceLocations ( \"classpath:/resources/\" ) . addResourceLocations ( \"classpath:/static/\" )", "del_tokens": ". addResourceLocations ( \"classpath:/resources\" ) . addResourceLocations ( \"classpath:/static\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "that", "timeout", "is", "passed", "down", "to", "server", "through", "api"], "add_tokens": "public static final String BATCH_SIZE = \"batchSize\" ; public static final String TIMEOUT = \"timeout\" ;", "del_tokens": "public final static String BATCH_SIZE = \"batchSize\" ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "interface", "dropped", "redundant", "methods", "and", "pushed", "up", "the", "generate"], "add_tokens": "public abstract String getServiceSerialisation ( URI serviceUri , Syntax syntax ) public abstract boolean deleteService ( URI serviceUri ) public abstract boolean deleteServiceById ( String serviceId ) public String generateUniqueServiceId ( ) ;", "del_tokens": "public abstract URI addService ( String serviceId , String msmServiceDescription , URI sourceDocumentUri ) throws ServiceException ; public abstract String getService ( URI serviceUri , Syntax syntax ) public abstract URI deleteService ( URI serviceUri ) public abstract URI deleteServiceById ( String serviceId )", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "page", "url", "of", "an", "Item"], "add_tokens": "url = photo . getUrl ( ) ; String url = null ; public FlickrItem ( Photo photo , FlickrStreamUser streamUser ) { this ( photo ) ; //User that posted the photo this . streamUser = streamUser ; uid = streamUser . getId ( ) ; for ( MediaItem mItem : mediaItems ) { mItem . setUserId ( uid ) ; } }", "del_tokens": "String url = null ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "merge", "conflict", "in", "SessionManager", "(", "typo", "in", "error", "message", ")"], "add_tokens": "log . error ( \"Can't sleep before starting new webDriver...\" ) ;", "del_tokens": "log . error ( \"Oops! Can't sleep before starting new webDriver...\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "longpoll", "example", "again", "now", "that", "server", "-", "side", "issue", "has", "been", "identified", "and", "resolved", "."], "add_tokens": "long longpollTimeoutSecs = TimeUnit . MINUTES . toSeconds ( 2 ) ; // read timeout should be greater than our longpoll timeout and include enough buffer // for the jitter introduced by the server. The server will add a random amount of delay // to our longpoll timeout to avoid the stampeding herd problem. See // DbxFiles.listFolderLongpoll(String, long) documentation for details. System . err . println ( \"Consider increasing socket read timeout or decreasing longpoll timeout.\" ) ;", "del_tokens": "// Keep timeout low to avoid issue with reset/dropped connections long longpollTimeoutSecs = 30 ; // read timeout should be well above longpoll timeout to allow for flucuations in response times. return ; System . err . println ( \"Consider increasing socket read timeout and decreasing longpoll timeout\" ) ; return ;", "commit_type": "update"}
{"commit_tokens": ["Change", "idea", "of", "the", "library", "instead", "of", "1", "custom", "progressbar", "that", "change", "depending", "the", "xml", "properties", "now", "different", "custom", "progressBar", "will", "be", "define", "for", "the", "different", "progress", "animations", "."], "add_tokens": "import com . jpardogo . android . googleprogressbar . library . FoldingCirclesProgressBar ; FoldingCirclesProgressBar mProgressBar ;", "del_tokens": "import android . support . v7 . app . ActionBarActivity ; import com . jpardogo . android . googleprogressbar . library . GoogleProgressBar ; GoogleProgressBar mProgressBar ;", "commit_type": "change"}
{"commit_tokens": ["Use", "URI", "instead", "of", "URL", "to", "avoid", "MalformedUrlException"], "add_tokens": "import java . net . URI ; public void setUrl ( URI uri ) { this . endpoint = HostAndPort . fromParts ( uri . getHost ( ) , uri . getPort ( ) ) ; String userInfo = uri . getUserInfo ( ) ;", "del_tokens": "import java . net . URL ; public void setUrl ( URL url ) { this . endpoint = HostAndPort . fromParts ( url . getHost ( ) , url . getPort ( ) ) ; String userInfo = url . getUserInfo ( ) ;", "commit_type": "use"}
{"commit_tokens": ["allow", "clear", "caches", "only", "force", "minimal", "cache", "(", "1KB", ")"], "add_tokens": "* Clear caches and Set new value of maximal bytes used for nodes in cache . * @ param newsize size of cache in bytes ( 0 only clear caches ) if ( newsize >= 1024 ) { // 1KB minimal maxCacheSizeInBytes = newsize ; createReadCaches ( ) ; }", "del_tokens": "* Set new value of maximal bytes used for nodes in cache . * @ param newsize size of cache in bytes maxCacheSizeInBytes = newsize ; createReadCaches ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["adding", "fluent", "interface", "and", "NetworkEvents", "customization"], "add_tokens": "exception . printStackTrace ( ) ;", "del_tokens": "exception . printStackTrace ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "CloseableIter", "*", "classes", "to", "wrap", "any", "methods", "in", "guava", "that", "it", "makes", "sense", "to", "wrap", "with", "the", "exception", "of", "mergesort", ".", "For", "other", "methods", "calling", "the", "guava", "methods", "should", "have", "no", "side", "effects", "so", "use", "of", "those", "is", "preferred", "."], "add_tokens": "return from ( CloseableIterables . cycle ( this ) ) ; return from ( CloseableIterables . filter ( this , type ) ) ; return from ( CloseableIterables . skip ( this , numberToSkip ) ) ;", "del_tokens": "return from ( CloseableIterables . wrap ( Iterables . cycle ( this ) , this ) ) ; return from ( CloseableIterables . wrap ( Iterables . filter ( this , type ) , this ) ) ; return from ( CloseableIterables . wrap ( Iterables . skip ( this , numberToSkip ) , this ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "AWAY", "s", "key", ".", "away", "-", ">", "idle"], "add_tokens": "AWAY ( \"idle\" ) ,", "del_tokens": "AWAY ( \"away\" ) ,", "commit_type": "fix"}
